{"id": "25950624", "url": "https://en.wikipedia.org/wiki?curid=25950624", "title": "2010 AB78", "text": "2010 AB78\n\n is expected to become the first of the many thousands of discoveries to be accredited to the WISE space observatory. However, the official discoverer will only be defined upon the asteroid's numbering.\n\nThe first observation of by WISE was on January 12, 2010, being observed again the next day. The Mauna Kea Observatory observed it the days 18 and 19 of January, allowing the Minor Planet Center to publish a circular on January 22 confirming the discovery.\n\n orbits the Sun at a distance of 1.0–3.5 AU once every 3 years and 5 months (1,236 days). Its orbit has an eccentricity of 0.55 and an inclination of 33° with respect to the ecliptic. Due to its eccentric orbit it is also a Mars-crosser. has the lowest possible orbital uncertainty, which suggests that it will be numbered in the near future.\n\nThis near-Earth asteroid has an minimum orbital intersection distance with Earth of , which corresponds to 80.2 lunar distances. It does not make any notable close approaches to Earth within the next hundred years.\n\nAccording to the survey carried out by the NEOWISE mission of NASA's discovering WISE observatory, measures 1.671 kilometers in diameter and its surface has an albedo of 0.030. Objects known for such low albedos are the carbonaceous C, D and P-type asteroids.\n\nAs of 2018, no lightcurve has been obtained. The body's rotation period, shape and pole remain unknown.\n\nAs of 2018, this minor planet has not been named or numbered.\n\n"}
{"id": "53943737", "url": "https://en.wikipedia.org/wiki?curid=53943737", "title": "Air Force Office of Energy Assurance", "text": "Air Force Office of Energy Assurance\n\nThe Office of Energy Assurance (abbreviated OEA) was established by the United States Secretary of the Air Force and Chief of Staff of the Air Force in February 2016 to serve as a central management office dedicated to strategic energy and resiliency.\n\nOEA serves as an extension of the Air Force Civil Engineer Center and in conjunction with the Office of the Assistant Secretary of the Air Force for Installations, Environment and Energy to ensure alignment with Air Force priorities. OEA develops, implements and oversees an integrated facility energy portfolio, including privately financed, large-scale renewable and alternative energy projects as well as direct Air Force investments. OEA leverages partnerships with the Army's Office of Energy Initiatives and the Navy’s Resilient Energy Program Office.\n\nFor OEA, energy assurance represents a vast array of activities across three categories - preparation and planning; mitigation and response; and education and outreach - focused on the goal of energy resiliency. OEA uses a holistic, enterprise-level approach across all Air Force installations with a focus on optimizing cost and providing resilient and cleaner sources of energy to assure the mission. \n\nOEA's mission is to deliver creative installation energy resiliency solutions to meet 21st century threats. Its vision is to be the recognized leader for implementing innovative energy assurance solutions that provide the Air Force with mission-ready installations. \n\nOEA works with installations to determine energy requirements critical to the mission and provides practical tools and support to develop projects to meet those needs. OEA develops energy assurance projects on or near installations by collaborating with community stakeholders to identify shared interests, such as costs, risks and goals, and to develop mutually beneficial solutions. OEA leverages the expertise, resources and capabilities of private industry to design and execute creative solutions to energy challenges. The office seeks innovative solutions for energy assurance projects, including but not limited to alternative generation methods, smart controls, increased cyber security, infrastructure upgrades and storage.\n"}
{"id": "705144", "url": "https://en.wikipedia.org/wiki?curid=705144", "title": "Amurru (god)", "text": "Amurru (god)\n\nAmurru and Martu are names given in Akkadian and Sumerian texts to the god of the Amorite/Amurru people, often forming part of personal names. He is sometimes called \"Ilu Amurru\" (MAR.TU). He was the patron god of the Mesopotamian city of Ninab, whose exact location is unknown.\n\nAmurru/Martu was probably a western Semitic god originally. He is sometimes described as a 'shepherd' or as a storm god, and as a son of the sky-god Anu. He is sometimes called \"bêlu šadī\" or \"bêl šadê\", 'lord of the mountain'; dúr-hur-sag-gá sikil-a-ke, 'He who dwells on the pure mountain'; and kur-za-gan ti-[la], 'who inhabits the shining mountain'. In Cappadocian Zinčirli inscriptions he is called \"ì-li a-bi-a\", 'the god of my father'.\n\nAccordingly, it has been suggested by L. R. Bailey (1968) and Jean Ouelette (1969), that this \"Bêl Šadê\" might be the same as the Biblical \"’Ēl Šaddāi\" who is the God of Abraham, Isaac, and Jacob in the \"Priestly source\" of narrative, according to the documentary hypothesis. \"Bêl Šadê\" could also have become the fertility-god 'Ba'al', possibly adopted by the Canaanites, a rival and enemy of the Hebrew God YHWH, and famously combatted by the Hebrew prophet Elijah.\n\nAmurru also has storm-god features. Like Adad, Amurru bears the epithet \"ramān\" 'thunderer', and he is even called \"bāriqu\" 'hurler of the thunderbolt' and \"Adad ša a-bu-be\" 'Adad of the deluge'. Yet his iconography is distinct from that of Adad, and he sometimes appears alongside Adad with a baton of power or throwstick, while Adad bears a conventional thunderbolt.\n\nAmurru's wife is usually the goddess Ašratum (see Asherah) who in northwest Semitic tradition and Hittite tradition appears as wife of the god Ēl which suggests that Amurru may indeed have been a variation of that god. If Amurru was identical with Ēl, it would explain why so few Amorite names are compounded with the name \"Amurru\", but so many are compounded with \"Il\"; that is, with Ēl.\n\nAnother tradition about Amurru's wife (or one of Amurru's wives) gives her name as Belit-Sheri, 'Lady of the Desert'.\n\nA third tradition appears in a Sumerian poem in pastoral style, which relates how the god Martu came to marry Adg̃ar-kidug the daughter of the god Numushda of the city of Inab. It contains a speech expressing urbanite Sumerian disgust at uncivilized, nomadic Amurru life which Adg̃ar-kidug ignores, responding only: \"I will marry Martu!\".\n\n"}
{"id": "50444585", "url": "https://en.wikipedia.org/wiki?curid=50444585", "title": "Beberibe Cliffs Natural Monument", "text": "Beberibe Cliffs Natural Monument\n\nBeberibe Cliffs Natural Monument ( is a natural monument in the state of Ceará, Brazil.\n\nThe Beberibe Cliffs Natural Monument was instituted on 3 June 2004 by Ceará governor Lúcio Alcântara.\nAt the same ceremony he signed the decree creating the Mata Fresca Private Ecological Reserve.\nThe natural monument, of major environmental and tourist interest, is visited by about 400 people per day.\nThe decree turned it into a fully protected area so that only eco-tourism and research would be allowed, and that only with permission from the responsible agency.\nLocal youth were to be employed as guides, and explanatory signs installed.\n\nThe natural monument is in the municipality of Beberibe on the east coast of the state of Ceará, between the Morro Branco and Fontes beaches.\nIt has an area of and a perimeter of .\nThe objective of the reserve is to protect the cliffs against the environmental impacts that had occurred earlier.\nOther cliffs in the region are unprotected and are occupied by hotels and vacation houses.\n\nThe cliffs in the area run along the coast for about where the Barreiras tableland reaches the coast.\nThey are formed of sand-clay sediments from the Tertiary or Quaternary ages, with fine to medium grains, and with colors ranging from white to yellow to red.\nThey are evolving as the sea acts on their bases and wind and rain erodes their upper parts.\nThey are cut by gullies formed by the main streams that flow down to the sea.\nOne famous structure is the Gruta da Mãe D’água (Cave of the Water Mother) on the Fontes beach, outside the protected area.\nThis has been created by wave action on the cliffs, and is much visited by people.\nIt has been degraded by the visitors, and is at risk of collapse.\n\nImplementation of the protected area does not appear to have had a significant effect in slowing down degradation of the cliffs.\nIt has therefore been proposed to implement a buffer zone, or to implement a larger Environmental Protection Area around the cliffs including the Morro Branco and Fontes beaches so as to better manage the site.\n\n"}
{"id": "6732985", "url": "https://en.wikipedia.org/wiki?curid=6732985", "title": "Big Oak Tree State Park", "text": "Big Oak Tree State Park\n\nBig Oak Tree State Park is a state-owned nature preserve with recreational features encompassing in East Prairie, Missouri, United States. The state park was established in a large expanse of drained cropland in 1938 to protect some of the largest trees in the state and in the nation. The park was declared a National Natural Landmark in May 1986, recognized as a rare, untouched wet-mesic bottomland hardwood forest in the Mississippi Alluvial Plain portion of the Gulf Coastal Plain.\n\nBig Oak Tree State Park is the home of many current and past state and national champion trees—trees that are, for their species, the largest in the state or in the nation.\n\nThe park has two trails for hiking through the forest, including an accessible boardwalk trail, plus an interpretive center along the boardwalk and picnicking facilities.\n\n"}
{"id": "24559950", "url": "https://en.wikipedia.org/wiki?curid=24559950", "title": "Boso Triple Junction", "text": "Boso Triple Junction\n\nBoso Triple Junction (also known as Off-Boso Triple Junction) is a triple junction off the coast of Japan; it is the only known example of a trench-trench-trench triple junction on the Earth. It is the meeting point of the North American Plate (represented by the Okhotsk Plate) to the north, the Pacific Plate to the east and the Philippine Sea Plate to the south.\n\nThe Boso Triple Junction is named after the Boso peninsula.\n\nIt is formed from the junction of the Izu-Bonin-Mariana Arc where the Izu-Bonin Trench meets with the Japan Trench and the Sagami Trench.\n\nLocated some from the Boso triple junction, Tokyo is subject to quakes and tsunamis generated from slips along this junction. Furthermore, there is a large populated region along the coast of the main island that would also be subject to damage. This junction probably has the highest associated insurance risk in the world, due to its proximity to extensive urban development.\n\nThe 2011 Tōhoku earthquake and tsunami were generated along the Japan trench well to the north of the junction and did not involve the other two trenches, although quakes that may have been aftershocks have been observed there.\n"}
{"id": "22847720", "url": "https://en.wikipedia.org/wiki?curid=22847720", "title": "Centro de Estudios Científicos", "text": "Centro de Estudios Científicos\n\nCentro de Estudios Científicos (CECs; Center for Scientific Studies) is a private, non-profit corporation based in Valdivia, Chile, devoted to the development, promotion and diffusion of scientific research. CECs research areas include biophysics, molecular physiology, theoretical physics, glaciology and climate change. The centre was created in 1984 as Centro de Estudios Científicos de Santiago, with a grant of 150,000 dollars a year (for three years) from the Tinker Foundation of New York City. In 2004-2005 glaciologists from CECs organized the Chilean South Pole Expedition in collaboration with the Chilean Navy and Instituto Antártico Chileno. CECs was founded in Santiago but is since 2000 housed in the recently modernized, German-style Hotel Schuster located by Valdivia River. Claudio Bunster, a physicist and winner of Chile's National Prize for Exact Sciences, is the director of CECs.\n\nIn 2014 CECs discovered what would be a subglacial lake in the West Antarctica, They investigated and concluded after a year that it is a lake, which was named Lake CECs in honor of the institution. The conclusion was published in \"Geophysical Research Letters\" on May 22, 2015. \nThe authors of the discovery are Andrés Rivera, Jose Uribe, Rodrigo Zamora and Jonathan Oberreuter.\n"}
{"id": "146983", "url": "https://en.wikipedia.org/wiki?curid=146983", "title": "Earth's magnetic field", "text": "Earth's magnetic field\n\nEarth's magnetic field, also known as the geomagnetic field, is the magnetic field that extends from the Earth's interior out into space, where it meets the solar wind, a stream of charged particles emanating from the Sun. Its magnitude at the Earth's surface ranges from 25 to 65 microteslas (0.25 to 0.65 gauss). Approximately, it is the field of a magnetic dipole currently tilted at an angle of about 11 degrees with respect to Earth's rotational axis, as if there were a bar magnet placed at that angle at the center of the Earth. The North geomagnetic pole, located near Greenland in the northern hemisphere, is actually the south pole of the Earth's magnetic field, and the South geomagnetic pole is the north pole. The magnetic field is generated by electric currents due to the motion of convection currents of molten iron in the Earth's outer core driven by heat escaping from the core, a natural process called a geodynamo.\n\nWhile the North and South magnetic poles are usually located near the geographic poles, they can wander widely over geological time scales, but sufficiently slowly for ordinary compasses to remain useful for navigation. However, at irregular intervals averaging several hundred thousand years, the Earth's field reverses and the North and South Magnetic Poles relatively abruptly switch places. These reversals of the geomagnetic poles leave a record in rocks that are of value to paleomagnetists in calculating geomagnetic fields in the past. Such information in turn is helpful in studying the motions of continents and ocean floors in the process of plate tectonics.\n\nThe magnetosphere is the region above the ionosphere that is defined by the extent of the Earth's magnetic field in space. It extends several tens of thousands of kilometers into space, protecting the Earth from the charged particles of the solar wind and cosmic rays that would otherwise strip away the upper atmosphere, including the ozone layer that protects the Earth from harmful ultraviolet radiation.\n\nThe Earth's magnetic field serves to deflect most of the solar wind, whose charged particles would otherwise strip away the ozone layer that protects the Earth from harmful ultraviolet radiation. One stripping mechanism is for gas to be caught in bubbles of magnetic field, which are ripped off by solar winds. Calculations of the loss of carbon dioxide from the atmosphere of Mars, resulting from scavenging of ions by the solar wind, indicate that the dissipation of the magnetic field of Mars caused a near total loss of its atmosphere.\n\nThe study of past magnetic field of the Earth is known as paleomagnetism. The polarity of the Earth's magnetic field is recorded in igneous rocks, and reversals of the field are thus detectable as \"stripes\" centered on mid-ocean ridges where the sea floor is spreading, while the stability of the geomagnetic poles between reversals has allowed paleomagnetists to track the past motion of continents. Reversals also provide the basis for magnetostratigraphy, a way of dating rocks and sediments. The field also magnetizes the crust, and magnetic anomalies can be used to search for deposits of metal ores.\n\nHumans have used compasses for direction finding since the 11th century A.D. and for navigation since the 12th century. Although the magnetic declination does shift with time, this wandering is slow enough that a simple compass remains useful for navigation. Using magnetoreception various other organisms, ranging from some types of bacteria to pigeons, use the Earth's magnetic field for orientation and navigation.\n\nAt any location, the Earth's magnetic field can be represented by a three-dimensional vector. A typical procedure for measuring its direction is to use a compass to determine the direction of magnetic North. Its angle relative to true North is the \"declination\" () or \"variation\". Facing magnetic North, the angle the field makes with the horizontal is the \"inclination\" () or \"magnetic dip\". The \"intensity\" () of the field is proportional to the force it exerts on a magnet. Another common representation is in (North), (East) and (Down) coordinates.\nThe intensity of the field is often measured in gauss (G), but is generally reported in nanoteslas (nT), with 1 G = 100,000 nT. A nanotesla is also referred to as a gamma (γ). The tesla is the SI unit of the magnetic field, B. The Earth's field ranges between approximately 25,000 and 65,000 nT (0.25–0.65 G). By comparison, a strong refrigerator magnet has a field of about .\n\nA map of intensity contours is called an \"isodynamic chart\". As the World Magnetic Model shows, the intensity tends to decrease from the poles to the equator. A minimum intensity occurs in the South Atlantic Anomaly over South America while there are maxima over northern Canada, Siberia, and the coast of Antarctica south of Australia.\n\nThe inclination is given by an angle that can assume values between -90° (up) to 90° (down). In the northern hemisphere, the field points downwards. It is straight down at the North Magnetic Pole and rotates upwards as the latitude decreases until it is horizontal (0°) at the magnetic equator. It continues to rotate upwards until it is straight up at the South Magnetic Pole. Inclination can be measured with a dip circle.\n\nAn \"isoclinic chart\" (map of inclination contours) for the Earth's magnetic field is shown below.\n\nDeclination is positive for an eastward deviation of the field relative to true north. It can be estimated by comparing the magnetic north/south heading on a compass with the direction of a celestial pole. Maps typically include information on the declination as an angle or a small diagram showing the relationship between magnetic north and true north. Information on declination for a region can be represented by a chart with isogonic lines (contour lines with each line representing a fixed declination).\n\nComponents of the Earth's magnetic field at the surface from the World Magnetic Model for 2015.\n\nNear the surface of the Earth, its magnetic field can be closely approximated by the field of a magnetic dipole positioned at the center of the Earth and tilted at an angle of about 11° with respect to the rotational axis of the Earth. The dipole is roughly equivalent to a powerful bar magnet, with its south pole pointing towards the geomagnetic North Pole. This may seem surprising, but the north pole of a magnet is so defined because, if allowed to rotate freely, it points roughly northward (in the geographic sense). Since the north pole of a magnet attracts the south poles of other magnets and repels the north poles, it must be attracted to the south pole of Earth's magnet. The dipolar field accounts for 80–90% of the field in most locations.\n\nHistorically, the north and south poles of a magnet were first defined by the Earth's magnetic field, not vice versa, since one of the first uses for a magnet was as a compass needle. A magnet's North pole is defined as the pole that is attracted by the Earth's North Magnetic Pole when the magnet is suspended so it can turn freely. Since opposite poles attract, the North Magnetic Pole of the Earth is really the south pole of its magnetic field (the place where the field is directed downward into the Earth). \n\nThe positions of the magnetic poles can be defined in at least two ways: locally or globally. The local definition is the point where the magnetic field is vertical. This can be determined by measuring the inclination. The inclination of the Earth's field is 90° (downwards) at the North Magnetic Pole and -90° (upwards) at the South Magnetic Pole. The two poles wander independently of each other and are not directly opposite each other on the globe. They can migrate rapidly: movements of up to per year have been observed for the North Magnetic Pole. Over the last 180 years, the North Magnetic Pole has been migrating northwestward, from Cape Adelaide in the Boothia Peninsula in 1831 to from Resolute Bay in 2001. The \"magnetic equator\" is the line where the inclination is zero (the magnetic field is horizontal).\n\nThe global definition of the Earth's field is based on a mathematical model. If a line is drawn through the center of the Earth, parallel to the moment of the best-fitting magnetic dipole, the two positions where it intersects the Earth's surface are called the North and South geomagnetic poles. If the Earth's magnetic field were perfectly dipolar, the geomagnetic poles and magnetic dip poles would coincide and compasses would point towards them. However, the Earth's field has a significant non-dipolar contribution, so the poles do not coincide and compasses do not generally point at either.\n\nEarth's magnetic field, predominantly dipolar at its surface, is distorted further out by the solar wind. This is a stream of charged particles leaving the Sun's corona and accelerating to a speed of 200 to 1000 kilometres per second. They carry with them a magnetic field, the interplanetary magnetic field (IMF).\n\nThe solar wind exerts a pressure, and if it could reach Earth's atmosphere it would erode it. However, it is kept away by the pressure of the Earth's magnetic field. The magnetopause, the area where the pressures balance, is the boundary of the magnetosphere. Despite its name, the magnetosphere is asymmetric, with the sunward side being about 10 Earth radii out but the other side stretching out in a magnetotail that extends beyond 200 Earth radii.\nSunward of the magnetopause is the bow shock, the area where the solar wind slows abruptly.\n\nInside the magnetosphere is the plasmasphere, a donut-shaped region containing low-energy charged particles, or plasma. This region begins at a height of 60 km, extends up to 3 or 4 Earth radii, and includes the ionosphere. This region rotates with the Earth. There are also two concentric tire-shaped regions, called the Van Allen radiation belts, with high-energy ions (energies from 0.1 to 10 million electron volts (MeV)). The inner belt is 1–2 Earth radii out while the outer belt is at 4–7 Earth radii. The plasmasphere and Van Allen belts have partial overlap, with the extent of overlap varying greatly with solar activity.\n\nAs well as deflecting the solar wind, the Earth's magnetic field deflects cosmic rays, high-energy charged particles that are mostly from outside the Solar system. (Many cosmic rays are kept out of the Solar system by the Sun's magnetosphere, or heliosphere.) By contrast, astronauts on the Moon risk exposure to radiation. Anyone who had been on the Moon's surface during a particularly violent solar eruption in 2005 would have received a lethal dose.\n\nSome of the charged particles do get into the magnetosphere. These spiral around field lines, bouncing back and forth between the poles several times per second. In addition, positive ions slowly drift westward and negative ions drift eastward, giving rise to a ring current. This current reduces the magnetic field at the Earth's surface. Particles that penetrate the ionosphere and collide with the atoms there give rise to the lights of the aurorae and also emit X-rays.\n\nThe varying conditions in the magnetosphere, known as space weather, are largely driven by solar activity. If the solar wind is weak, the magnetosphere expands; while if it is strong, it compresses the magnetosphere and more of it gets in. Periods of particularly intense activity, called geomagnetic storms, can occur when a coronal mass ejection erupts above the Sun and sends a shock wave through the Solar System. Such a wave can take just two days to reach the Earth. Geomagnetic storms can cause a lot of disruption; the \"Halloween\" storm of 2003 damaged more than a third of NASA's satellites. The largest documented storm occurred in 1859. It induced currents strong enough to short out telegraph lines, and aurorae were reported as far south as Hawaii.\n\nThe geomagnetic field changes on time scales from milliseconds to millions of years. Shorter time scales mostly arise from currents in the ionosphere (ionospheric dynamo region) and magnetosphere, and some changes can be traced to geomagnetic storms or daily variations in currents. Changes over time scales of a year or more mostly reflect changes in the Earth's interior, particularly the iron-rich core.\n\nFrequently, the Earth's magnetosphere is hit by solar flares causing geomagnetic storms, provoking displays of aurorae. The short-term instability of the magnetic field is measured with the K-index.\n\nData from THEMIS show that the magnetic field, which interacts with the solar wind, is reduced when the magnetic orientation is aligned between Sun and Earth – opposite to the previous hypothesis. During forthcoming solar storms, this could result in blackouts and disruptions in artificial satellites.\n\nChanges in Earth's magnetic field on a time scale of a year or more are referred to as \"secular variation\". Over hundreds of years, magnetic declination is observed to vary over tens of degrees. A movie on the right shows how global declinations have changed over the last few centuries.\n\nThe direction and intensity of the dipole change over time. Over the last two centuries the dipole strength has been decreasing at a rate of about 6.3% per century. At this rate of decrease, the field would be negligible in about 1600 years. However, this strength is about average for the last 7 thousand years, and the current rate of change is not unusual.\n\nA prominent feature in the non-dipolar part of the secular variation is a \"westward drift\" at a rate of about 0.2 degrees per year. This drift is not the same everywhere and has varied over time. The globally averaged drift has been westward since about 1400 AD but eastward between about 1000 AD and 1400 AD.\n\nChanges that predate magnetic observatories are recorded in archaeological and geological materials. Such changes are referred to as \"paleomagnetic secular variation\" or \"paleosecular variation (PSV)\". The records typically include long periods of small change with occasional large changes reflecting geomagnetic excursions and reversals.\n\nAlthough generally Earth's field is approximately dipolar, with an axis that is nearly aligned with the rotational axis, occasionally the North and South geomagnetic poles trade places. Evidence for these \"geomagnetic reversals\" can be found in basalts, sediment cores taken from the ocean floors, and seafloor magnetic anomalies. Reversals occur nearly randomly in time, with intervals between reversals ranging from less than 0.1 million years to as much as 50 million years. The most recent geomagnetic reversal, called the Brunhes–Matuyama reversal, occurred about 780,000 years ago. A related phenomenon, a geomagnetic excursion, amounts to an incomplete reversal, with no change in polarity. The Laschamp event is an example of an excursion, it having occurred during the last ice age (41,000 years ago).\n\nThe past magnetic field is recorded mostly by strongly magnetic minerals, particularly iron oxides such as magnetite, that can carry a permanent magnetic moment. This remanent magnetization, or \"remanence\", can be acquired in more than one way. In lava flows, the direction of the field is \"frozen\" in small minerals as they cool, giving rise to a thermoremanent magnetization. In sediments, the orientation of magnetic particles acquires a slight bias towards the magnetic field as they are deposited on an ocean floor or lake bottom. This is called \"detrital remanent magnetization\".\n\nThermoremanent magnetization is the main source of the magnetic anomalies around mid-ocean ridges. As the seafloor spreads, magma wells up from the mantle, cools to form new basaltic crust on both sides of the ridge, and is carried away from it by seafloor spreading. As it cools, it records the direction of the Earth's field. When the Earth's field reverses, new basalt records the reversed direction. The result is a series of stripes that are symmetric about the ridge. A ship towing a magnetometer on the surface of the ocean can detect these stripes and infer the age of the ocean floor below. This provides information on the rate at which seafloor has spread in the past.\n\nRadiometric dating of lava flows has been used to establish a \"geomagnetic polarity time scale\", part of which is shown in the image. This forms the basis of magnetostratigraphy, a geophysical correlation technique that can be used to date both sedimentary and volcanic sequences as well as the seafloor magnetic anomalies.\n\nStudies of lava flows on Steens Mountain, Oregon, indicate that the magnetic field could have shifted at a rate of up to 6 degrees per day at some time in Earth's history, which significantly challenges the popular understanding of how the Earth's magnetic field works. This finding was later attributed to unusual rock magnetic properties of the lava flow under study, not rapid field change, by one of the original authors of the 1995 study.\n\nTemporary dipole tilt variations that take the dipole axis across the equator and then back to the original polarity are known as \"excursions\".\n\nPaleomagnetic studies of Paleoarchean lava in Australia and conglomerate in South Africa have concluded that the magnetic field has been present since at least about .\n\nAt present, the overall geomagnetic field is becoming weaker; the present strong deterioration corresponds to a 10–15% decline over the last 150 years and has accelerated in the past several years; geomagnetic intensity has declined almost continuously from a maximum 35% above the modern value achieved approximately 2,000 years ago. The rate of decrease and the current strength are within the normal range of variation, as shown by the record of past magnetic fields recorded in rocks.\n\nThe nature of Earth's magnetic field is one of heteroscedastic fluctuation. An instantaneous measurement of it, or several measurements of it across the span of decades or centuries, are not sufficient to extrapolate an overall trend in the field strength. It has gone up and down in the past for unknown reasons. Also, noting the local intensity of the dipole field (or its fluctuation) is insufficient to characterize Earth's magnetic field as a whole, as it is not strictly a dipole field. The dipole component of Earth's field can diminish even while the total magnetic field remains the same or increases.\n\nThe Earth's magnetic north pole is drifting from northern Canada towards Siberia with a presently accelerating rate— per year at the beginning of the 20th century, up to per year in 2003, and since then has only accelerated.\n\nThe Earth's magnetic field is believed to be generated by electric currents in the conductive material of its core, created by convection currents due to heat escaping from the core. However the process is complex, and computer models that reproduce some of its features have only been developed in the last few decades.\n\nThe Earth and most of the planets in the Solar System, as well as the Sun and other stars, all generate magnetic fields through the motion of electrically conducting fluids. The Earth's field originates in its core. This is a region of iron alloys extending to about 3400 km (the radius of the Earth is 6370 km). It is divided into a solid inner core, with a radius of 1220 km, and a liquid outer core. The motion of the liquid in the outer core is driven by heat flow from the inner core, which is about , to the core-mantle boundary, which is about . The heat is generated by potential energy released by heavier materials sinking toward the core (planetary differentiation, the iron catastrophe) as well as decay of radioactive elements in the interior. The pattern of flow is organized by the rotation of the Earth and the presence of the solid inner core.\n\nThe mechanism by which the Earth generates a magnetic field is known as a dynamo. The magnetic field is generated by a feedback loop: current loops generate magnetic fields (Ampère's circuital law); a changing magnetic field generates an electric field (Faraday's law); and the electric and magnetic fields exert a force on the charges that are flowing in currents (the Lorentz force). These effects can be combined in a partial differential equation for the magnetic field called the \"magnetic induction equation\",\n\nwhere is the velocity of the fluid; is the magnetic B-field; and is the magnetic diffusivity, which is inversely proportional to the product of the electrical conductivity and the permeability . The term is the time derivative of the field; is the Laplace operator and is the curl operator.\n\nThe first term on the right hand side of the induction equation is a diffusion term. In a stationary fluid, the magnetic field declines and any concentrations of field spread out. If the Earth's dynamo shut off, the dipole part would disappear in a few tens of thousands of years.\n\nIn a perfect conductor (formula_2), there would be no diffusion. By Lenz's law, any change in the magnetic field would be immediately opposed by currents, so the flux through a given volume of fluid could not change. As the fluid moved, the magnetic field would go with it. The theorem describing this effect is called the \"frozen-in-field theorem\". Even in a fluid with a finite conductivity, new field is generated by stretching field lines as the fluid moves in ways that deform it. This process could go on generating new field indefinitely, were it not that as the magnetic field increases in strength, it resists fluid motion.\n\nThe motion of the fluid is sustained by convection, motion driven by buoyancy. The temperature increases towards the center of the Earth, and the higher temperature of the fluid lower down makes it buoyant. This buoyancy is enhanced by chemical separation: As the core cools, some of the molten iron solidifies and is plated to the inner core. In the process, lighter elements are left behind in the fluid, making it lighter. This is called \"compositional convection\". A Coriolis effect, caused by the overall planetary rotation, tends to organize the flow into rolls aligned along the north-south polar axis.\n\nA dynamo can amplify a magnetic field, but it needs a \"seed\" field to get it started. For the Earth, this could have been an external magnetic field. Early in its history the Sun went through a T-Tauri phase in which the solar wind would have had a magnetic field orders of magnitude larger than the present solar wind. However, much of the field may have been screened out by the Earth's mantle. An alternative source is currents in the core-mantle boundary driven by chemical reactions or variations in thermal or electric conductivity. Such effects may still provide a small bias that are part of the boundary conditions for the geodynamo.\n\nThe average magnetic field in the Earth's outer core was calculated to be 25 gausses, 50 times stronger than the field at the surface.\n\nSimulating the geodynamo requires numerically solving a set of nonlinear partial differential equations for the magnetohydrodynamics (MHD) of the Earth's interior. Simulation of the MHD equations is performed on a 3D grid of points and the fineness of the grid, which in part determines the realism of the solutions, is limited mainly by computer power. For decades, theorists were confined to creating \"kinematic dynamo\" computer models in which the fluid motion is chosen in advance and the effect on the magnetic field calculated. Kinematic dynamo theory was mainly a matter of trying different flow geometries and testing whether such geometries could sustain a dynamo.\n\nThe first \"self-consistent\" dynamo models, ones that determine both the fluid motions and the magnetic field, were developed by two groups in 1995, one in Japan and one in the United States. The latter received attention because it successfully reproduced some of the characteristics of the Earth's field, including geomagnetic reversals.\n\nElectric currents induced in the ionosphere generate magnetic fields (ionospheric dynamo region). Such a field is always generated near where the atmosphere is closest to the Sun, causing daily alterations that can deflect surface magnetic fields by as much as one degree. Typical daily variations of field strength are about 25 nanoteslas (nT) (one part in 2000), with variations over a few seconds of typically around 1 nT (one part in 50,000).\n\nThe Earth's magnetic field strength was measured by Carl Friedrich Gauss in 1832 and has been repeatedly measured since then, showing a relative decay of about 10% over the last 150 years. The Magsat satellite and later satellites have used 3-axis vector magnetometers to probe the 3-D structure of the Earth's magnetic field. The later Ørsted satellite allowed a comparison indicating a dynamic geodynamo in action that appears to be giving rise to an alternate pole under the Atlantic Ocean west of South Africa.\n\nGovernments sometimes operate units that specialize in measurement of the Earth's magnetic field. These are geomagnetic observatories, typically part of a national Geological survey, for example the British Geological Survey's Eskdalemuir Observatory. Such observatories can measure and forecast magnetic conditions such as magnetic storms that sometimes affect communications, electric power, and other human activities.\n\nThe International Real-time Magnetic Observatory Network, with over 100 interlinked geomagnetic observatories around the world, has been recording the Earth's magnetic field since 1991.\n\nThe military determines local geomagnetic field characteristics, in order to detect \"anomalies\" in the natural background that might be caused by a significant metallic object such as a submerged submarine. Typically, these magnetic anomaly detectors are flown in aircraft like the UK's Nimrod or towed as an instrument or an array of instruments from surface ships.\n\nCommercially, geophysical prospecting companies also use magnetic detectors to identify naturally occurring anomalies from ore bodies, such as the Kursk Magnetic Anomaly.\n\nMagnetometers detect minute deviations in the Earth's magnetic field caused by iron artifacts, kilns, some types of stone structures, and even ditches and middens in archaeological geophysics. Using magnetic instruments adapted from airborne magnetic anomaly detectors developed during World War II to detect submarines, the magnetic variations across the ocean floor have been mapped. Basalt — the iron-rich, volcanic rock making up the ocean floor — contains a strongly magnetic mineral (magnetite) and can locally distort compass readings. The distortion was recognized by Icelandic mariners as early as the late 18th century. More important, because the presence of magnetite gives the basalt measurable magnetic properties, these magnetic variations have provided another means to study the deep ocean floor. When newly formed rock cools, such magnetic materials record the Earth's magnetic field.\n\nEach measurement of the magnetic field is at a particular place and time. If an accurate estimate of the field at some other place and time is needed, the measurements must be converted to a model and the model used to make predictions.\n\nThe most common way of analyzing the global variations in the Earth's magnetic field is to fit the measurements to a set of spherical harmonics. This was first done by Carl Friedrich Gauss. Spherical harmonics are functions that oscillate over the surface of a sphere. They are the product of two functions, one that depends on latitude and one on longitude. The function of longitude is zero along zero or more great circles passing through the North and South Poles; the number of such \"nodal lines\" is the absolute value of the \"order\" . The function of latitude is zero along zero or more latitude circles; this plus the order is equal to the \"degree\" ℓ. Each harmonic is equivalent to a particular arrangement of magnetic charges at the center of the Earth. A \"monopole\" is an isolated magnetic charge, which has never been observed. A \"dipole\" is equivalent to two opposing charges brought close together and a \"quadrupole\" to two dipoles brought together. A quadrupole field is shown in the lower figure on the right.\n\nSpherical harmonics can represent any scalar field (function of position) that satisfies certain properties. A magnetic field is a vector field, but if it is expressed in Cartesian components , each component is the derivative of the same scalar function called the \"magnetic potential\". Analyses of the Earth's magnetic field use a modified version of the usual spherical harmonics that differ by a multiplicative factor. A least-squares fit to the magnetic field measurements gives the Earth's field as the sum of spherical harmonics, each multiplied by the best-fitting \"Gauss coefficient\" or .\n\nThe lowest-degree Gauss coefficient, , gives the contribution of an isolated magnetic charge, so it is zero. The next three coefficients – , , and – determine the direction and magnitude of the dipole contribution. The best fitting dipole is tilted at an angle of about 10° with respect to the rotational axis, as described earlier.\n\nSpherical harmonic analysis can be used to distinguish internal from external sources if measurements are available at more than one height (for example, ground observatories and satellites). In that case, each term with coefficient or can be split into two terms: one that decreases with radius as and one that \"increases\" with radius as . The increasing terms fit the external sources (currents in the ionosphere and magnetosphere). However, averaged over a few years the external contributions average to zero.\n\nThe remaining terms predict that the potential of a dipole source () drops off as . The magnetic field, being a derivative of the potential, drops off as . Quadrupole terms drop off as , and higher order terms drop off increasingly rapidly with the radius. The radius of the outer core is about half of the radius of the Earth. If the field at the core-mantle boundary is fit to spherical harmonics, the dipole part is smaller by a factor of about 8 at the surface, the quadrupole part by a factor of 16, and so on. Thus, only the components with large wavelengths can be noticeable at the surface. From a variety of arguments, it is usually assumed that only terms up to degree or less have their origin in the core. These have wavelengths of about or less. Smaller features are attributed to crustal anomalies.\n\nThe International Association of Geomagnetism and Aeronomy maintains a standard global field model called the International Geomagnetic Reference Field. It is updated every five years. The 11th-generation model, IGRF11, was developed using data from satellites (Ørsted, CHAMP and SAC-C) and a world network of geomagnetic observatories. The spherical harmonic expansion was truncated at degree 10, with 120 coefficients, until 2000. Subsequent models are truncated at degree 13 (195 coefficients).\n\nAnother global field model, called the World Magnetic Model, is produced jointly by the United States National Centers for Environmental Information (formerly the National Geophysical Data Center) and the British Geological Survey. This model truncates at degree 12 (168 coefficients) with an approximate spatial resolution of 3,000 kilometers. It is the model used by the United States Department of Defense, the Ministry of Defence (United Kingdom), the United States Federal Aviation Administration (FAA), the North Atlantic Treaty Organization (NATO), and the International Hydrographic Office as well as in many civilian navigation systems.\n\nA third model, produced by the Goddard Space Flight Center (NASA and GSFC) and the Danish Space Research Institute, uses a \"comprehensive modeling\" approach that attempts to reconcile data with greatly varying temporal and spatial resolution from ground and satellite sources.\n\nFor users with higher accuracy needs, the United States National Centers for Environmental Information developed the Enhanced Magnetic Model (EMM), which extends to degree and order 790 and resolves magnetic anomalies down to a wavelength of 56 kilometers. It was compiled from satellite, marine, aeromagnetic and ground magnetic surveys. , the latest version, EMM2017, includes data from The European Space Agency's Swarm satellite mission.\n\nAnimals including birds and turtles can detect the Earth's magnetic field, and use the field to navigate during migration. Some researchers have found that cows and wild deer tend to align their bodies north-south while relaxing, but not when the animals are under high-voltage power lines, suggesting that magnetism is responsible. Other researchers reported in 2011 that they could not replicate those findings using different Google Earth images.\n\nResearchers found out that very weak electromagnetic fields disrupt the magnetic compass used by European robins and other songbirds to navigate using the Earth's magnetic field. Neither power lines nor cellphone signals are to blame for the electromagnetic field effect on the birds; instead, the culprits have frequencies between 2 kHz and 5 MHz. These include AM radio signals and ordinary electronic equipment that might be found in businesses or private homes.\n\n\n\n"}
{"id": "29866582", "url": "https://en.wikipedia.org/wiki?curid=29866582", "title": "Geothermal exploration", "text": "Geothermal exploration\n\nGeothermal exploration is the exploration of the subsurface in search of viable active geothermal regions with the goal of building a geothermal power plant, where hot fluids drive turbines to create electricity. Exploration methods include a broad range of disciplines including geology, geophysics, geochemistry and engineering.\n\nGeothermal regions with adequate heat flow to fuel power plants are found in rift zones, subduction zones and mantle plumes. Hot spots are characterized by four geothermal elements. An active region will have:\n\nExploration involves not only identifying hot geothermal bodies, but also low-density, cost effective regions to drill and already constituted plumbing systems inherent within the subsurface. This information allows for higher success rates in geothermal plant production as well as lower drilling costs.\n\nAs much as 42% of all expenses associated with geothermal energy production can be attributed to exploration. These costs are mostly from drilling operations necessary to confirm or deny viable geothermal regions. Some geothermal experts have gone to say that developments in exploration techniques and technologies have the potential to bring the greatest advancements within the industry.\n\nDrilling provides the most accurate information in the exploration process, but is also the most costly exploration method.\n\nThermal gradient holes (TGH), exploration wells (slim holes), and full-scale production wells (wildcats) provide the most reliable information on the subsurface. Temperature gradients, thermal pockets and other geothermal characteristics can be measured directly after drilling, providing valuable information.\nGeothermal exploration wells rarely exceed 4 km in depth. Subsurface materials associated with geothermal fields range from limestone to shale, volcanic rocks and granite. Most drilled geothermal exploration wells, up to the production well, are still considered to be within the exploration phase. Most consultants and engineers consider exploration to continue until one production well is completed successfully. \nGenerally, the first wildcat well has a success rate of 25%. Following more analysis and investigation, success rates then increase to a range from 60% to 80%. Although expenses vary significantly, drilling costs are estimated at $400/ft. Therefore, it is becoming paramount to investigate other means of exploration before drilling operations commence. To increase the chances of successfully drilling, innovations in remote sensing technologies have developed over the last 2 decades. These less costly means of exploration are categorized into multiple fields including geology, geochemistry and geophysics.\n\nSeismology has played a significant role in the oil and gas industry and is now being adapted to geothermal exploration. Seismic waves propagate and interact with subterranean components and respond accordingly. Two sub categories exist that are relevant to the source of the seismic signal. Active seismology relies on using induced/man-made vibrations at or near the surface. Passive seismology uses earthquakes, volcanic eruptions or other tectonic activity as sources.\n\nPassive seismic studies use natural wave propagation through the earth. Geothermal fields are often characterized by increased levels of seismicity. Earthquakes of lesser magnitude are much more frequent than ones of larger magnitude. Therefore, these micro earthquakes (MEQ), registering below 2.0 magnitude on the Richter scale, are used to reveal subsurface qualities relating to geothermal exploration. The high rate of MEQ in geothermal regions produce large datasets that don’t require long field deployments.\n\nActive Seismology, which has history in the oil and gas industry, involves studying man made vibrational wave propagation. In these studies geophones (or other seismic sensors) are spread across the study site. The most common geophone spreads are in line, offset, in-line with center shot and Fan shooting.\n\nMany analytical techniques can be applied to active seismology studies but generally all include Huygens Principle, Fermat’s Princeple and Snell’s law. These basic principles can be used to identify subsurface anomalies, reflective layers and other objects with high impedance contrasts.\n\nGravimetry studies use changes in densities to characterize subsurface properties. This method is well applied when identifying dense subsurface anomalies including granite bodies, which are vital to locate in the geothermal exploration projects. Subsurface fault lines are also identifiable with gravitational methods. These faults are often identified as prime drilling locations as their densities are much less than surrounding material. Developments in airborne gravitational studies yield large amounts of data, which can be used to model the subsurface 3 dimensionally with relatively high levels of accuracy.\n\nChanges in groundwater levels may also be measured and identified with gravitational methods. This recharge element is imperative in creating productive geothermal systems. Pore density and subsequent overall density are affected by fluid flow and therefore change the gravitational field. When correlated with current weather conditions, this can be measured and modeled to estimate the rate of recharge in geothermal reservoirs.\n\nUnfortunately, there are many other factors that must be realized before data from a gravity study can be interpreted. The average gravitational field the earth produces is 920 cm/c^2. Objects of concern produce a significantly smaller gravitational field. Therefore, instrumentation must detect variations as small as 0.00001%. Other considerations including elevation, latitude and weather conditions must be carefully observed and taken into account.\n\nMagnetotellurics (MT) measurements allow detection of resistivity anomalies associated with productive geothermal structures, including faults and the presence of a cap rock, and allow for estimation of geothermal reservoir temperatures at various depths. MT has successfully contributed to the successful mapping and development of geothermal resources around the world since the early 1980s, including in the U.S. and countries located on the Pacific Ring of Fire such as Japan, New Zealand, the Philippines, Ecuador, and Peru.\n\nGeological materials are generally poor electrical conductors and have a high resistivity. Hydrothermal fluids in the pores and fractures of the earth, however, increase the conductivity of the subsurface material. This change in conductivity is used to map the subsurface geology and estimate the subsurface material composition. Resistivity measurements are made using a series of probes distributed tens to hundreds of meters apart, to detect the electrical response of the Earth to injection of electrical impulses in order to reconstruct the distribution of electrical resistance in the rocks. Since flowing geothermal waters can be detected as zones of low resistance, it is possible to map geothermal resources using such a technique. However, care must be exercised when interpreting low resistivity zones since they may also be caused by changes in rock type and temperature.\n\nThe Earth’s magnetic field varies in intensity and orientation during the day inducing detectable electrical currents in the Earth’s crust. The range of the frequency of those currents allows a multispectral analysis of the variation in the electromagnetic local field. As a result, it is possible a tomographic reconstruction of geology, since the currents are determined by the underlying response of the different rocks to the changing magnetic field.\n\nThe most common application magnetism has in geothermal exploration involves identifying the depth of the curie point or curie temperature. At the curie point, materials will change from ferromagnetic to paramagnetic. Locating curie temperatures for known subsurface materials provides estimates on future plant productivity. For example, titanomagnetitite, a common material in geothermal fields, has a curie temperature between 200-570 degrees Celsius. Simple geometric anomalies modeled at different depths are used to best estimate the curie depth.\n\nThis science is readily used in geothermal exploration. Scientists within this field relate surface fluid properties and geologic data to geothermal bodies. Temperature, isotopic ratios, elemental ratios, mercury & CO2 concentrations are all data points under close examination. Geothermometers and other instrumentation are placed around field sites to increase the fidelity of subsurface temperature estimates.\n\nGeothermal Energy is an underdeveloped energy resource and warrants further investigation and exploration. According to the U.S. Department of Energy, Utah's geothermal capabilities alone, if fully developed, could provide 1/3 of the state's power needs. Currently, the United States is planning to organize national geothermal databases, expand USGS resources nationally and develop geophysical projects to validate advances in exploration technologies. Below lists U.S. counties and regions that potentially can utilize geothermal power and would warrant further exploration.\n\n"}
{"id": "26349919", "url": "https://en.wikipedia.org/wiki?curid=26349919", "title": "Harrington paradox", "text": "Harrington paradox\n\nHarrington paradox is a notion in the environmental and ecological economics describing the compliance of firms to the environmental regulations. The paradox was first described in Winston Harrington's paper in 1988 and was based on the research over monitoring, realization and compliance to ecological standards in the USA from the end of the 1970s to the beginning of the 1980s. According to the paradox, the firms in general comply with ecological standards in spite of the fact that:\n\n\nFirms' compliance at such level is contrary to the rational crime theory of Gary Becker which describes the behavior of profit maximizing entities. The rational firms will comply to the standards only in case the expected fine is higher than the cost of compliance. In order to explain the paradox it was suggested that firms exhibit altruism or self-image concern.\n\nThe empirical data observing the paradox is rare. In the research conducted by Norwegian Climate and Pollution Agency in 2001 no serious violations were revealed, but in the majority of firms (80%) there were minor deviations from standards. The fact that in Norway there is low frequency of monitoring and the fine system for minor violations is light can not bring strong evidence to the paradox, as major violations imply very strict punishments which is conforming to the rational crime theory.\n\n\n"}
{"id": "34373639", "url": "https://en.wikipedia.org/wiki?curid=34373639", "title": "Ion gun", "text": "Ion gun\n\nAn Ion Gun typically refers to an instrument that generates a beam of heavy ions with a well defined energy distribution. The ion beam is produced from a plasma that has been confined within a volume. Ions of a particular energy are extracted, accelerated, collimated and/or focused. The ion gun is composed of an ion source, extraction grid structure and a collimation/lensing structure. The plasma can be made up of an inert or reactive gas (e.g. N and O) or an easily condensable substance (e.g. C and B). The plasma can be formed from molecules that contain the substance which will form the beam, in which case, these molecules must be fragmented then ionized (e.g. H and CH can together be fragmented and ionized to create a beam for depositing diamond-like carbon films).\n\nThe ion current density (or similarly the ion flux), the ion energy spread, and the resolution of the ion beam are key factors in ion gun design. The ion current density is controlled by the ion source, the energy spread is determined primarily by the extraction grid, and the resolution is determined primarily by the optical column.\n\nThe ion gun is an important component in surface science in that it provides the scientist with a means to sputter etch a surface and generate an elemental or chemical depth profile. Modern ion guns can produce beam energies from 10eV to more than 10keV.\n\nA Nanocoulombmeter in combination with a Faraday cup can be used\nto detect and measure the beams emitted from ion guns.\n\nThe term \"ion gun\" might also refer to an accelerator of any charged particle. See the following:\n\n\n"}
{"id": "45557209", "url": "https://en.wikipedia.org/wiki?curid=45557209", "title": "Kovdorskite", "text": "Kovdorskite\n\nKovdorskite, MgPO(OH)·3HO, is a rare, hydrated, magnesium phosphate mineral. It was first described by Kapustin \"et al.\", and is found only in the Kovdor Massif near Kovdor, Kola Peninsula, Russia. It is associated with collinsite, magnesite, dolomite, hydrotalcite, apatite, magnetite, and forsterite.\n\n"}
{"id": "52793580", "url": "https://en.wikipedia.org/wiki?curid=52793580", "title": "L Carinae", "text": "L Carinae\n\nThe Bayer designations l Carinae and L Carinae are distinct.\n\n\n"}
{"id": "1430367", "url": "https://en.wikipedia.org/wiki?curid=1430367", "title": "Lechatelierite", "text": "Lechatelierite\n\nLechatelierite is silica glass, amorphous SiO, non-crystalline mineraloid.\n\nLechatelierite is a mineraloid as it does not have a crystal structure. Although not a true mineral, it is often classified in the quartz mineral group.\n\nOne common way in which lechatelierite forms naturally is by very high temperature melting of quartz sand during a lightning strike. The result is an irregular, branching, often foamy hollow tube of silica glass called a fulgurite. Not all fulgurites are lechatelierite; the original sand must be nearly pure silica.\n\nLechatelierite also forms as the result of high pressure shock metamorphism during meteorite impact cratering and is a common component of a type of glassy ejecta called tektites. Most tektites are blobs of impure glassy material, but tektites from the Sahara Desert in Libya and Egypt, known as \"Libyan desert glass\", are composed of almost pure silica that is almost pure lechatelierite. High pressure experiments have shown that shock pressures of 85 GPa are needed to produce lechatelierite in quartz grains embedded in granite.\n\nLechatelierite was formed during the impact of a meteorite into a layer of Coconino Sandstone at Meteor Crater in Arizona. During the rapid pressure reduction following the impact, steam expanded the newly formed lechatelierite. The shattered and expanded glass has a density less than that of water.\n\nLechatelierite may also form artificially, a unique example being the \"trinitite\" produced by melting of quartz sand at the first nuclear bomb explosion at Trinity Flats, White Sands, New Mexico.\n\n"}
{"id": "8816956", "url": "https://en.wikipedia.org/wiki?curid=8816956", "title": "List of Hygrocybe species", "text": "List of Hygrocybe species\n\nThis is an incomplete list of species in the genus \"Hygrocybe\". The genus has a widespread distribution and contains about 150 species.\n\n"}
{"id": "58791821", "url": "https://en.wikipedia.org/wiki?curid=58791821", "title": "List of Local Nature Reserves in Surrey", "text": "List of Local Nature Reserves in Surrey\n\nSurrey is a county in South East England. It has an area of and an estimated population of 1.1 million as of 2017. It is bordered by Greater London, Kent, East Sussex, West Sussex, Hampshire and Berkshire.\n\nLocal Nature Reserves are designated by local authorities under the National Parks and Access to the Countryside Act 1949. The local authority must have a legal control over the site, by owning or leasing it or having an agreement with the owner. Local Nature Reserves are sites which have a special local interest either biologically or geologically. Local authorities have a duty to care for them, and can apply local bye-laws to manage and protect them.\n\nAs of October 2018 there are 44 Local Nature Reserves in Surrey.\n\n"}
{"id": "16020311", "url": "https://en.wikipedia.org/wiki?curid=16020311", "title": "List of Rhode Island tornadoes", "text": "List of Rhode Island tornadoes\n\nThis is a list of all tornadoes reported in the US state of Rhode Island. Although tornadoes are very rare in this state, at least 15 have been recorded in modern history. Additionally, because of high population density and property values, Rhode Island ranks 5th among states in potential losses due to tornadoes.\n\n\n\n\n"}
{"id": "5892710", "url": "https://en.wikipedia.org/wiki?curid=5892710", "title": "List of Sites of Special Scientific Interest in Hampshire", "text": "List of Sites of Special Scientific Interest in Hampshire\n\nThis is a list of the Sites of Special Scientific Interest (SSSIs) in Hampshire, England, United Kingdom. In England the body responsible for designating SSSIs is Natural England, which chooses a site because of its fauna, flora, geological or physiographical features. Natural England uses the borders of Hampshire to mark one of its Areas of Search. , there are 118 sites designated in this Area of Search. There are 4 sites with a purely geological interest, and 108 listed for biological interest. A further 6 sites are designated for both reasons.\n\nNatural England took over the role of designating and managing SSSIs from English Nature in October 2006 when it was formed from the amalgamation of English Nature, parts of the Countryside Agency and the Rural Development Service. Natural England, like its predecessor, uses the 1974–1996 county system and as such the same approach is followed here. The data in the table is taken from Natural England in the form of citation sheets for each SSSI, and the County Background Datasheet for Hampshire.\n\nFor other counties, see List of SSSIs by Area of Search.\n"}
{"id": "17933460", "url": "https://en.wikipedia.org/wiki?curid=17933460", "title": "List of elephant species", "text": "List of elephant species\n\nThe list of elephant species includes all known extant and extinct (†) elephant species from the Elephantidae family.\n\n\n"}
{"id": "1028355", "url": "https://en.wikipedia.org/wiki?curid=1028355", "title": "List of longest rivers in the United States by state", "text": "List of longest rivers in the United States by state\n\nThis is a list of longest rivers in the United States by state. It includes rivers that pass through the state or compose a portion of the state's border, as well as rivers entirely contained within the state.\n\n\nSee also List of rivers of Alabama.\n\n\nSee also List of rivers of Alaska.\n\n\nSee also List of rivers of Arizona.\n\n\nSee also List of rivers of Arkansas.\n\n\n\nSee also List of rivers of California.\n\n\nSee also List of rivers of Colorado.\n\n\nSee also List of rivers of Connecticut.\n\n\nSee also List of rivers of Delaware.\n\n\n\nSee also List of rivers of Florida.\n\n\n\nSee also List of rivers of Georgia (U.S. state).\n\n\nSee also List of rivers of Hawaii.\n\n\n\nSee also List of rivers of Idaho.\n\n\n\nSee also List of rivers of Illinois.\n\n\nSee also List of rivers of Indiana.\n\n\nSee also List of rivers of Iowa.\n\n\nSee also List of rivers of Kansas.\n\n\n\nSee also List of rivers of Kentucky.\n\n\nSee also List of rivers of Louisiana.\n\n\n\nSee also List of rivers of Maine.\n\n\n\nSee also List of rivers of Maryland.\n\n\nSee also List of rivers of Massachusetts.\n\n\nThe Grand River is the longest river that is entirely within Michigan.\n\nSee also List of rivers of Michigan.\n\n\n\nSee also List of rivers of Minnesota.\n\n\n\nSee also List of rivers of Mississippi.\n\n\n\nSee also List of rivers of Missouri.\n\n\nSee also List of rivers of Montana.\n\n\nSee also List of rivers of Nebraska.\n\n\n\nSee also List of rivers of Nevada.\n\n\nSee also List of rivers of New Hampshire.\n\n\nThe Raritan River is the longest river entirely within New Jersey.\n\nSee also List of rivers of New Jersey.\n\n\nSee also List of rivers of New Mexico.\n\n\nSee also List of rivers of New York.\n\n\nSee also List of rivers of North Carolina.\n\n\nSee also List of rivers of North Dakota.\n\n\n\nSee also List of rivers of Ohio.\n\n\nSee also List of rivers of Oklahoma.\n\n\n\nSee also List of rivers of Oregon.\n\n\nSee also List of rivers of Pennsylvania.\n\n\nSee also List of rivers of Rhode Island.\n\n\nSee also List of rivers of South Carolina.\n\n\nSee also List of rivers of South Dakota.\n\n\n\nSee also List of rivers of Tennessee.\n\n\nSee also List of rivers of Texas.\n\n\n\nSee also List of rivers of Utah.\n\n\nSee also List of rivers of Vermont.\n\n\n\nSee also List of rivers of Virginia.\n\n\nSee also List of rivers of Washington.\n\n\n\nSee also List of rivers of West Virginia.\n\n\n\nSee also List of rivers of Wisconsin.\n\n\nSee also List of rivers of Wyoming.\n"}
{"id": "29006743", "url": "https://en.wikipedia.org/wiki?curid=29006743", "title": "List of rivers of Brunei", "text": "List of rivers of Brunei\n\nThis is a list of rivers in Brunei .\n\n"}
{"id": "8591795", "url": "https://en.wikipedia.org/wiki?curid=8591795", "title": "List of stars in Phoenix", "text": "List of stars in Phoenix\n\nThis is the list of notable stars in the constellation Phoenix, sorted by decreasing brightness.\n\n\n"}
{"id": "13841751", "url": "https://en.wikipedia.org/wiki?curid=13841751", "title": "List of trees of the Andaman Islands", "text": "List of trees of the Andaman Islands\n\nThe following is a list of the principal trees found in the Andaman Islands with - where available - native names:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "35478088", "url": "https://en.wikipedia.org/wiki?curid=35478088", "title": "Lists of Nature Preserves of Ukraine", "text": "Lists of Nature Preserves of Ukraine\n\nNature preserves of Ukraine are protected areas of Ukraine, nature conservation and science researching institutions of state importance that are part of the Nature-Preservation Fund of Ukraine.\n\n\n"}
{"id": "1939348", "url": "https://en.wikipedia.org/wiki?curid=1939348", "title": "Litharge", "text": "Litharge\n\nLitharge (from Greek lithargyros, lithos (stone) + argyros (silver) \"λιθάργυρος\") is one of the natural mineral forms of lead(II) oxide, PbO. Litharge is a secondary mineral which forms from the oxidation of galena ores. It forms as coatings and encrustations with internal tetragonal crystal structure. It is dimorphous with the orthorhombic form massicot. It forms soft (Mohs hardness of 2), red, greasy-appearing crusts with a very high specific gravity of 9.14–9.35. PbO may be prepared by heating lead metal in air at approximately 600°C (lead melts at only 300°C). At this temperature it is also the end product of oxidation of other lead oxides in air. This is often done with a set of bellows pumping air over molten lead and causing the oxidized product to slip or fall off the top into a receptacle, where it quickly solidifies in minute scales.\n\nHistorically, the term \"litharge\" has been combined to refer to other similar substances. For example, \"litharge of gold\" is litharge mixed with red lead, giving it a red color; \"litharge of bismuth\" is a similar result of the oxidation of bismuth; \"litharge of silver\" is litharge that comes as a by-product of separating silver from lead, in fact \"litharge\" originally meant the mineral residue from silver refining. The term has also been used as a synonym for white lead or red lead.\n\nAccording to Probert, \"silver ore, litharge (crude lead oxide) flux and charcoal were mixed and smelted in very small clay and stone furnaces. Resulting silver-bearing lead bullion was later refined in a second furnace which yielded fine silver, and litharge skimmings which were used again.\"\n\n"}
{"id": "32127609", "url": "https://en.wikipedia.org/wiki?curid=32127609", "title": "Margaret Warner Morley", "text": "Margaret Warner Morley\n\nMargaret Warner Morley (February 17, 1858 in Montrose, Iowa – December 12, 1923 in Washington, D.C.) was an American educator, biologist, and author of many children's books on nature and biology.\n\nMorley grew up in Brooklyn. She studied at State University of New York at Oswego and Hunter College. She continued her biology education at the Armour Institute (now the Illinois Institute of Technology) in Chicago and at the Woods Hole marine laboratory in Massachusetts. She worked as a teacher and was considered an expert in agriculture and beekeeping. She was most well known for her work as an illustrator, photographer, and author of books on nature.\n\nAs early as 1890 she visited Tryon, North Carolina with the painter Amelia Watson where she resided in the cottage of playwright William Gillette. She finally acquired her own home in Tryon where she lived for many years.\n\nIn one of her many trips she went to Europe to the Val Gardena the valley of toy carvers where she was inspired to write the novel \"Donkey John of the toy valley\".\n\nA collection of Morley's work is held at the Harriet Beecher Stowe Center in Hartford, Connecticut. The collection consists of travel logs and sketchbooks of rural North Carolina, and book manuscripts.\n\nThe North Carolina Museum of History owns a collection of original photographs that Morley donated to the museum in 1914.\n\nMorley died in 1923.\n\nDrawings by Morley from the original Val Gardena toys from \"Donkey John of the Toy Valley\":\n\n\n"}
{"id": "17588004", "url": "https://en.wikipedia.org/wiki?curid=17588004", "title": "Marine outfall", "text": "Marine outfall\n\nA marine outfall is a pipeline or tunnel that discharges municipal or industrial wastewater, stormwater, combined sewer overflows, cooling water, or brine effluents from water desalination plants to the sea. Usually they discharge under the sea's surface (submarine outfall). In the case of municipal wastewater, effluent is often being discharged after having undergone no or only primary treatment, with the intention of using the assimilative capacity of the sea for further treatment. Submarine outfalls are common throughout the world and probably number in the thousands. More than 200 outfalls alone have been listed in a single international database maintained by the Institute for Hydromechanics at Karlsruhe University for the International Association of Hydraulic Engineering and Research (IAHR) / International Water Association (IWA) Committee on Marine Outfall Systems.\n\nThe World's first marine outfall was built in Santa Monica, United States, in 1910. In Latin America and the Caribbean there were 134 outfalls with more than 500 m length in 2006 for wastewater disposal alone, according to a survey by the Pan American Center for Sanitary Engineering and Environmental Sciences (CEPIS) of PAHO. According to the survey, the largest number of municipal wastewater outfalls in the region exist in Venezuela (39), Chile (39) and Brazil (22). The World's largest marine outfall is located in Boston, United States.Currently, Boston has approximately 235 miles of combined sewers and 37 active CSO outfalls. Lots of outfalls are simply known by a public used name, e.g. Boston Outfall.\n\nAccording to the Australian engineer Sharon Beder the main advantages of marine outfalls for the discharge of wastewater are:\n\nThey also tend to be less expensive than advanced wastewater treatment plants, using the natural assimilative capacity of the sea instead of energy-intensive treatment processes in a plant. For example, preliminary treatment of wastewater is sufficient with an effective outfall and diffuser. The costs of preliminary treatment are about one tenth that of secondary treatment. Preliminary treatment also requires much less land than advanced wastewater treatment.\n\nMarine outfalls for partially treated or untreated wastewater remain controversial. Still according to Sharon Beder, the design calculation and computer models for pollution modeling have been criticized, arguing that dilution has been overemphasized and that other mechanisms work in the opposite direction, such as bioaccumulation of toxins, sedimentation of sludge particles and agglomeration of sewage particles with grease. Accumulative mechanisms include slick formation, windrow formation, flocculate formation and agglomerated formation. Grease or wax can interfere with dispersion, so that bacteria and viruses could be carried to remote locations where the concentration of bacterial predators would be low and the die-off rate much lower.\n\nOutfalls vary in diameter from as narrow as 15 cm to as wide as 8 m; the widest registered outfall in the world with 8 m diameter is located in Navia (Spain) for the discharge of industrial wastewater. Outfalls vary in length from 50 m to 55 km, the longest registered outfalls being the Boston outfall with a length of 16 km and an industrial outfall in Ankleshwar (India) with a length of 55 km. The depth of the deepest point of an outfall varies from 3 m to up to 60 m, the deepest registered outfall being located in Macuto, Vargas (Venezuela) for the discharge of untreated municipal wastewater.\n\nOutfall materials include polyethylene, stainless steel, carbon steel, glass-reinforced plastic, reinforced concrete, cast iron or tunnels through rock. Common installation methods for pipelines are float and sink, bottom pull and top pull.\n\nSubmarine outfalls exist, existed or have been considered in the following locations, among many others:\n\n\n\n\n\n\n\n\n\n\n\n\nIn the 1960s the city of Sydney decided to build ocean sewage outfalls to discharge partially treated sewage 2–4 km offshore at a cost of US$ 300 million. In the late 1980s, however, the government promised to upgrade the coastal treatment plants so that sewage would be treated to at least secondary treatment standards before discharge into the ocean.\n\nThe submarine outfall in Cartagena, Colombia was financed with a loan by the World Bank. It was subsequently challenged by residents claiming that the wastewater caused damage to the marine environment and to fisheries. The case was taken up by the World Bank's Inspection Panel, which contracted two independent three-dimensional modeling efforts in 2006. Both \"confirmed that the 2.85km long submarine outfall (was) adequate.\"\n\n\n"}
{"id": "20580", "url": "https://en.wikipedia.org/wiki?curid=20580", "title": "Motion (physics)", "text": "Motion (physics)\n\nIn physics, motion is a change in position of an object over time. Motion is mathematically described in terms of displacement, distance, velocity, acceleration, time, and speed. Motion of a body is observed by attaching a frame of reference to an observer and measuring the change in position of the body relative to that frame.\n\nIf the position of a body is not changing with respect to a given frame of reference (reference point), the body is said to be \"at rest\", \"motionless\", \"immobile\", \"stationary\", or to have constant (time-invariant) position. An object's motion cannot change unless it is acted upon by a force, as described. Momentum is a quantity which is used for measuring the motion of an object. An object's momentum is directly related to the object's mass and velocity, and the total momentum of all objects in an isolated system (one not affected by external forces) does not change with time, as described by the law of conservation of momentum.\n\nAs there is no absolute frame of reference, \"absolute motion\" cannot be determined. Thus, everything in the universe can be considered to be moving.\n\nMotion applies to objects, bodies, and matter particles, to radiation, radiation fields and radiation particles, and to space, its curvature and space-time. One can also speak of motion of shapes and boundaries. So, the term motion, in general, signifies a continuous change in the configuration of a physical system. For example, one can talk about motion of a wave or about motion of a quantum particle, where the configuration consists of probabilities of occupying specific positions.\n\nIn physics, motion is described through two sets of apparently contradictory laws of mechanics. Motions of all large-scale and familiar objects in the universe (such as projectiles, planets, cells, and humans) are described by classical mechanics. Whereas the motion of very small atomic and sub-atomic objects is described by quantum mechanics.\n\nClassical mechanics is used for describing the motion of macroscopic objects, from projectiles to parts of machinery, as well as astronomical objects, such as spacecraft, planets, stars, and galaxies. It produces very accurate results within these domains, and is one of the oldest and largest in science, engineering, and technology.\n\nClassical mechanics is fundamentally based on Newton's laws of motion. These laws describe the relationship between the forces acting on a body and the motion of that body. They were first compiled by Sir Isaac Newton in his work \"Philosophiæ Naturalis Principia Mathematica\", first published on July 5, 1687. Newton's three laws are:\n\nNewton's three laws of motion were the first to accurately provide a mathematical model for understanding orbiting bodies in outer space. This explanation unified the motion of celestial bodies and motion of objects on earth.\n\nClassical mechanics was further enhanced by Albert Einstein's special relativity and general relativity. Special relativity is concerned with the motion of objects with a high velocity, approaching the speed of light; general relativity is employed to handle gravitational motion at a deeper level.\n\nUniform Motion:\nWhen an object moves with a constant speed at a particular direction at regular intervals of time it's known as the \"uniform motion.\" For example: a bike moving in a straight line with a constant speed.\n\nEQUATIONS OF UNIFORM MOTION:\n\nIf v = final velocity, u = initial velocity, a = acceleration, t = time, s = displacement, then :\n\nQuantum mechanics is a set of principles describing physical reality at the atomic level of matter (molecules and atoms) and the subatomic particles (electrons, protons, neutrons, and even smaller elementary particles such as quarks). These descriptions include the simultaneous wave-like and particle-like behavior of both matter and radiation energy as described in the wave–particle duality.\n\nIn classical mechanics, accurate measurements and predictions of the state of objects can be calculated, such as location and velocity. In the quantum mechanics, due to the Heisenberg uncertainty principle, the complete state of a subatomic particle, such as its location and velocity, cannot be simultaneously determined. \n\nIn addition to describing the motion of atomic level phenomena, quantum mechanics is useful in understanding some large-scale phenomenon such as superfluidity, superconductivity, and biological systems, including the function of smell receptors and the structures of proteins.\n\nHumans, like all known things in the universe, are in constant motion; however, aside from obvious movements of the various external body parts and locomotion, humans are in motion in a variety of ways which are more difficult to perceive. Many of these \"imperceptible motions\" are only perceivable with the help of special tools and careful observation. The larger scales of imperceptible motions are difficult for humans to perceive for two reasons: Newton's laws of motion (particularly the third) which prevents the feeling of motion on a mass to which the observer is connected, and the lack of an obvious frame of reference which would allow individuals to easily see that they are moving. The smaller scales of these motions are too small to be detected conventionally with human senses.\n\nSpacetime (the fabric of the universe) is expanding meaning everything in the universe is stretching like a rubber band. This motion is the most obscure as it is not physical motion as such, but rather a change in the very nature of the universe. The primary source of verification of this expansion was provided by Edwin Hubble who demonstrated that all galaxies and distant astronomical objects were moving away from Earth, known as Hubble's law, predicted by a universal expansion.\n\nThe Milky Way Galaxy is moving through space and many astronomers believe the velocity of this motion to be approximately relative to the observed locations of other nearby galaxies. Another reference frame is provided by the Cosmic microwave background. This frame of reference indicates that the Milky Way is moving at around .\n\nThe Milky Way is rotating around its dense galactic center, thus the sun is moving in a circle within the galaxy's gravity. Away from the central bulge, or outer rim, the typical stellar velocity is between . All planets and their moons move with the sun. Thus, the solar system is moving.\n\nThe Earth is rotating or spinning around its axis. This is evidenced by day and night, at the equator the earth has an eastward velocity of . The Earth is also orbiting around the Sun in an orbital revolution. A complete orbit around the sun takes one year, or about 365 days; it averages a speed of about .\n\nThe Theory of Plate tectonics tells us that the continents are drifting on convection currents within the mantle causing them to move across the surface of the planet at the slow speed of approximately per year. However, the velocities of plates range widely. The fastest-moving plates are the oceanic plates, with the Cocos Plate advancing at a rate of per year and the Pacific Plate moving per year. At the other extreme, the slowest-moving plate is the Eurasian Plate, progressing at a typical rate of about per year.\n\nThe human heart is constantly contracting to move blood throughout the body. Through larger veins and arteries in the body, blood has been found to travel at approximately 0.33 m/s. Though considerable variation exists, and peak flows in the venae cavae have been found between . additionally, the smooth muscles of hollow internal organs are moving. The most familiar would be the occurrence of peristalsis which is where digested food is forced throughout the digestive tract. Though different foods travel through the body at different rates, an average speed through the human small intestine is . The human lymphatic system is also constantly causing movements of excess fluids, lipids, and immune system related products around the body. The lymph fluid has been found to move through a lymph capillary of the skin at approximately 0.0000097 m/s.\n\nThe cells of the human body have many structures which move throughout them. Cytoplasmic streaming is a way which cells move molecular substances throughout the cytoplasm, various motor proteins work as molecular motors within a cell and move along the surface of various cellular substrates such as microtubules, and motor proteins are typically powered by the hydrolysis of adenosine triphosphate (ATP), and convert chemical energy into mechanical work. Vesicles propelled by motor proteins have been found to have a velocity of approximately 0.00000152 m/s.\n\nAccording to the laws of thermodynamics, all particles of matter are in constant random motion as long as the temperature is above absolute zero. Thus the molecules and atoms which make up the human body are vibrating, colliding, and moving. This motion can be detected as temperature; higher temperatures, which represent greater kinetic energy in the particles, feel warm to humans who sense the thermal energy transferring from the object being touched to their nerves. Similarly, when lower temperature objects are touched, the senses perceive the transfer of heat away from the body as feeling cold.\n\nWithin each atom, electrons exist in an area around the nucleus. This area is called the electron cloud. According to Bohr's model of the atom, electrons have a high velocity, and the larger the nucleus they are orbiting the faster they would need to move. If electrons 'move' about the electron cloud in strict paths the same way planets orbit the sun, then electrons would be required to do so at speeds which far exceed the speed of light. However, there is no reason that one must confine one's self to this strict conceptualization, that electrons move in paths the same way macroscopic objects do. Rather one can conceptualize electrons to be 'particles' that capriciously exist within the bounds of the electron cloud. Inside the atomic nucleus, the protons and neutrons are also probably moving around due to the electrical repulsion of the protons and the presence of angular momentum of both particles.\n\nLight propagates at 299,792,458 m/s, often approximated as in a vacuum. The speed of light (or \"c\") is also the speed of all massless particles and associated fields in a vacuum, and it is the upper limit on the speed at which energy, matter, information or causation can travel; the speed of light is the limit of speed for all physical systems.\n\nIn addition, the speed of light is an invariant quantity: it has the same value, irrespective of the position or speed of the observer. This property makes the speed of light \"c\" a natural measurement unit for speed.\n\n\n\n"}
{"id": "55829912", "url": "https://en.wikipedia.org/wiki?curid=55829912", "title": "Natural Resources of Azerbaijan", "text": "Natural Resources of Azerbaijan\n\nThe Azerbaijan is a country with very favorable natural conditions and rich natural resources. Snowy peaks, high mountains, foothill fertile soils, wide plains, Lowest Land Points Below Ocean Level are the main landscape forms of republic. This complex landscape structure has caused the variety in natural conditions - climate, soil-vegetation, and water resources. This, in turn, led to the uneven distribution of population and farms on the territory, and the specialization of production on different types.\n\nGenerally, the natural resources are understood by all the natural components that people use in life and economic activities. Natural resources are divided into the following groups:\n\nSolar, geothermal, wind, nuclear energy, climate, water withdrawal and flood, sea currents.\n\nAll minerals and hydrocarbons.\n\nSoil, biological resources, water energy.\n\nThe richness of mining resources in Azerbaijan is related to the complexity of the geological structure.\n\nMining minerals in Azerbaijan are oil, gas, shale, peat, etc. The oil and gas industry are the most valuable among the other resources. Oil is extracted by means of both onshore and offshore (Caspian Sea) operations.\n\nThe territory of Republic (especially the Absheron peninsula) is one of the world's oldest oil producing regions. The extraction and distribution of oil from Absheron peninsula to other countries has started from VII-VI centuries of BC.\n\nAround 1.2 billion tons of oil (25% from offshore oilfields) has been produced in Azerbaijan until 1985. The oil produced in Azerbaijan territory is high quality, low-sulphuric and low-paraffin content. The density of oil changes in a large range (780–940 kg/m3). In Naftalan, the extracted oil from the Maykop and Agjagil sediments is considered to be the only oil in the world to have healing properties.\n\nThe flammable gases produced in the country are hydrocarbons composed. They are in various forms such as soluble gas in oil, gas cap and pure gas fields. A lot of gas condensate fields have been explored and executed during the last 30–50 years. There are currently 8 producing oil and gas fields (Absheron, Shamakhi-Gobustan, Ashaghi Kur, archipelago Baku , Ganja, Yevlakh-Aghjabadi, Guba-Khazaryani, Kur-Gabirri rivers) and 2 prospective fields regions can be mentioned (Acinohur and Jalilabad).\n\nThe main productive oil and gas producing layers are in Absheron, Shamakhi-Gobustan, Down-Kur and Baku archipelagi regions. The thickness of total layers consisting of sand, sandstone and mud reaches 4,000 meters (even more in some places).\n\nFields with productive layers (Balakhani-Sabunchu-Ramana, Surakhani-Garachukhur-Zykh, Gala, Bibiheybat, Neft Dashlari, Puta, May 28, Lokbatan-Binagadi, Sangachal-Deniz-Duvanny-Deniz-Bulla, Bulla-Deniz etc.) is horizontal and anticlinal structured. The largest oil and gas condensate fields are located in the Absheron, Baku archipelagi and the Lower Kuryani regions.\n\nMany shale and coal manifestations have been discovered in the Maykop-Absheron old sediments in the Republic.\n\n\"Main article:\" \"Yanar dag\"\n\nThe burning mountain is an unknown origin historical monument located in the Absheron Peninsula, near Baku, on the coast of the Caspian Sea, in the village of Mahammedi, occurred as a result of the released natural gas at the foot of the mountain.\n\nThe location is 27 km away from the city center of Baku, and about 2 km away from the village center, on the left side of the Mahammedi-Digah highway.\n\nThe flame in this area has been resulted from the burning of natural gas flowing to the surface from the underground oil and gas storing layers through cracks that was caused by volcanic-tectonic movements and processes. Sometimes, the height of flame reaches 10–15 meters.\n\nBy the Decree of the Azerbaijani President dated May 2, 2007, the territory of the \"Burning Mountain\" was declared to be state-cultural and nature preservation. The territory of this area is 64.55 hectares. This area includes the ‘’Gurd yuvasi’’, two cemeteries with age of thousand years and an ancient mosque, Gothursu fount, Ali Stone, Kardashi, Girmaki valley and Yanar dag.\n\nThese excavations (iron, aluminum, chromite, gold, silver, copper, lead, zinc, cobalt, molybdenum ore etc.) brings different ore deposits in the mountainous parts of the republic.\n\nIron ores (magnetite, hematite) are found in four classes in Azerbaijan: segregation-magmatic, skarn-magnetite (contact-metasomatic), hydrothermal-metasomatic and sedimentation. Only Dashkasan, South Dashkesen and İron ore-bearing regions with skarn-magnetite are for commercial use as ore-deposits. These deposits are composed of Kellovey, Oxford, Kimeric aged volcanogenic, pyroclastic and sedimentary-volcanogenic rocks. Industry reserves of the Dashkasen iron ore group deposits are 250mln tons.\n\nThe significant industrial cobalt ores is placed in the Dashkasek ore region. The cobalt ores are formed both independently (with the Yukhari Dashkasan field) and together with skarn-magnetite ores.\n\nThe gold deposits and manifestations are mainly found in the territory of the Lesser Caucasus: Söyüdü, Qızılbulaq, Dağ Qəsəmən, Veynəli, Qoşa, Gədəbəy, Çovdar; Shekerdere, Pyezbashi, Agyurt and Baskand deposits are spread in the Nakhchivan Autonomous Republic. The silver, copper, etc. mixtures are also can be found in these deposits.\n\nAt present, numerous manifestations of gold have been discovered (Tulallar, Kepez, Dabalt, Kungutchay, Keleki, Unus and others). Evaluation of gold deposits in powder form from Alincachay and Kurekchay Basin was carried out, initial reserves were calculated and industrial significance was determined.\n\nChromite deposits and manifestations (Goydere, Kazimbinasi, Ipek, Khatavang etc.) are mainly located in Kalbajar and Lachin regions.\n\nThe small sized deposits and manifestations of manganese are known in the Somxeti-Agdam (Mollacelli, Dash Salahli, etc.) of the LesserCaucasus, Vandam (Mugar, Balakenchay) and Araz (Bichanak, Alahi) of the Greater Caucasus structure-formation zones.\n\nCopper ore are copper-pyrite and copper-porphyry origin in Azerbaijan. The mineral content of copper-pyrite formations is mainly composed of pyrite and chalcopyrite. Copper-porphyry formations’ ores consist of molybdenum and small amount of noble metals.\n\nThere are many copper-porphyry formation’s ore in this region except Garadagh and Xarxar deposits (Gedebey ore region). There are copper-porphyte in the Mehmana ore-bearing region (Demirli and Xançincay).\n\nCopper-porphyry ore-bearing in the Nakhchivan Autonomous Republic, is mainly located on the Mehri-Ordubad granitoid batholite's exo and endocontact zones (Diakhchay, Goygol, Goydagh etc.). In addition, Halhal copper-pyrite, Goygol, Agridağ copper, Nashirvaz, Kilit-Katam copper-cobalt, Nergirvaz copper-polymetallic are known in this region.\n\nMolybdenum field are found in Dalidagh (Teymuruchandagh, Baghırsag, etc.) and Ordubad ore regions (Paraghachay Diachchay).\n\nThe largest field of aluminum ore (alunite) is in the Dashkasan region (Zaylik alunit deposit). Alunite - bearing is also found in Shamkir and Ordubad. The Zaylik alunite deposit has been operated since 1960. This deposit is the largest one in the Europe. Aluminum oxide together with potassium fertilizer, soda, sulfuric acid and so on. is extracted from this ore in Ganja aluminum plants.\n\nBauxite ore (Sadarak-Sharur districts) which is the best raw material of aluminum is found in areas where Permian deposit site are spread in the western part of the Nakhchivan Autonomous Republic.\n\nMercuric ore deposits are widely spread in the central part of the Lesser Caucasus (Kalbajar-Lachin zone). Mercuric ore reserves contained within the largest ore deposits as Agh-Yatagh, Shor-Bulag, Levchay (Kalbajar region), Jilgaz-chay, and Narzanly (Lachin region) have been evaluated. Mercuric mineralization (Cinnebar) occurs at various age and composition rocks, most commonly Upper Cretaceous volcanic-sedimentary rocks and area where hyperbasites and Miocene-Pliocene aged acid magmatic rocks are spread. The pyrite, chalcopyrite, antimonite, magnetite, hematite, sphalerite and other minerals are in association with Kinovar ore. Kishlak ores are found in Badamli-Ashaghi of Nakhchivan AR.\n\nThe largest deposits of Arsenic in Azerbaijan are found in the Gadabay (Bitibulag Enargit Field) and Julfa (Dardagh auripigment-real bed) areas. This field was exploited until 1941. Arsenic ore body has a shtok-shape geometry. The content of the ore consists of red orpiment, realgar, antimony and arsenopyrite.\n\nNon-metallic mining resources-play an important role in the overall balance of crude mineral resources of Azerbaijan. This group includes rock-salt, gypsum, anhydride, bentonite clays, building materials, pyrite, barite, semi-precious and colorful stones, dolomite, Icelandic quarry and so on.\n\nRock-salt deposits are located in Nakhchivan Autonomous Republic (Nehram, Düzdağ, Pusyan). The deposits are in the sandstone, clay and limestone sediments of Miocene. Balanced reserves of the Nehrame field are 73600min tons on the B + S1 category and 64200min on category S2. Reserves are estimated to be 2-2.5 billion tones. The industrial reserves of the Duzdag field are 94517 thousand tons on the A + B + S1 category and 37810 thousand tons on the S2 category.\n\nGypsum, anhydrite deposits are formed in homogenous way in the Chalky sediments of Yukhari Aghcakand and Manash villages of Goranboy region. They consist of separate stocks, with total inventory of 65-70 million tons. Industrial reserves of 120 km to the south-east of the city of Nakhchivan (Aras, Gypsum) and around the city of Ganja are 40632 thousand tons on the A + B + S1 category.\n\nThe field of Bentonite clay is identified in Gobustan, Goranboy, Sheki, etc. The largest field was found in Gazakh region (Dash Salahli). The field is mainly formed by the influence of hydrothermal product on the Santonian aged volcanism and its industrial reserves are 8,4553 tons.\n\nThere are lot of construction materials in the territory of Azerbaijan. Currently, the estimated commercial reserves of the sawn stone-block deposit on A + B + S1 category (Goyshtak, Garadagh, Guzdek, Stateyarlı, Dilagar, Shahbulag, Naftalan, Mardakan, Dash Salahli, Zayam and others) is 295836 thousand tons, whereas covering stone deposit (Dashkasan, Shahtakhti, Gulabli, Musakoy, Söyglu and others) is 23951 m thousand for the time being.\n\nThere are raw materials in the Garadagh field, which are suitable for cement production (Shakhga limestone, Garadagh clay, etc.). Many clay deposits for drilling, brick and ceramics are exploited. The limestone deposit with 8.3 thousand m is determined which is suitable for the production of flysch and carbide in the territory of Siyazan region.\n\nThe volcanic ash-tuff is a zeolite raw material and the belonged field (Aydagh) is located in 7 km north-western of Tovuz. The average thickness of the volcanic ash and tuff in the Aydagh field is 25-30m. And it is among Santonian-Campanian carbonate deposits. Moreover, zeolites(clinoptilolites) mixed with 20-80% silica have been found within these tuffs. The average amount of zeolite on that deposit is 55%. Estimated potential reserve of Aidagh tuffs is 20 mln tons.\n\nSemi-precious and precious minerals (gems) were reported to be associated with the Dashcasan and Ordubad skarn ore deposits (granite, garnet, amethyst) of Lesser Caucasus, as well as volcanic rocks with Gadabay (tourmaline) and Khanlar regions (chalcedony, agate, heliotrop).\n\nThere are large-scale deposits of dolomite nearby Nehram village (Nakhchivan AR) and Boyanata Mountain (Gobustan). Quartz sand for the glass production was found in Gobustan, Absheron peninsula and Guba region.\n\nThere are chemical paints in Dashkesen, Shamakhi, Kalbajar and Khanlar districts.\n\nThe mud with medical treatment properties is located in the Absheron Peninsula, Masazir Lake, Gobustan and Lower Kura and in areas where mud volcanoes outbursts are pervasive.\n\n\"Main article:\" \"Mud volcanos in Azerbaijan\"\n\nAzerbaijan is known as a unique and classic development zone of mud volcanoes on the Earth. The 344 of the 2000 widely known mud volcanoes on the Earth are located in the east of Azerbaijan and in the Caspian Sea boundary. Most of the mud volcanoes are spread over Baku and the Absheron Peninsula, and some of them have been formed as a natural monument.\n\nMud volcanoes play an important role in placing exploration wells of oil and gas fields without extra surveying costs. Additionally, mud volcano clays are considered to be useful and important minerals. Also, volcanic mud is successfully used in the treatment of many diseases - nervous system, skin and bone joints. At the same time, volcanoes are important in terms of prediction of events such as seismic events and earthquakes.\n\nCotton is named as \"white gold\" in Azerbaijan.\n\nIn the Caucasus regions, especially in Azerbaijan, cotton is spread by means of countries of the Ancient East, mainly by Iran. The exporting of textile made of cotton from the cities such as Barda, Nakhchivan, Beylagan, Ganja, Shamkir and others to abroad, as well as cotton fabrics exporting from Shamakhi to Russia in the 15th century can be highlighted.\n\nCotton exports from Azerbaijan to Russia have been expanded from XVII century. In the 18th century, there were large cotton fields on the plains of Mil-Mughan and Shirvan. At the beginning of the 19th century the cotton industry was being developed in Guba and Baku. In the 1930s, Egypt and America, as well as local Mazandaran and Iravan cotton varieties were being cultivated in Azerbaijan.\n\nAfter the Northern Azerbaijan was being joined to Russia, cotton production in Azerbaijan was developed especially since the end of the 19th century.\n\nAt the beginning of the 20th century, the cotton industry area was expanded in Azerbaijan due to Russian textile industry being down. In 1913 the cotton industry area was more than 100 thousand hectares, whereas the cotton production was 65 thousand tons.\n\nThere are five types of cotton in Azerbaijan:\n\n• Ordinary cotton (Gossypium hirsutum L.) (medicine purposed)\n\n• Gossipium Barbadenze (Gossypium barbadense)\n\n• Gossipium Triquspitatum\n\n• Gossipium Arboreum (Gossypium arboreum)\n\n• Gossipium Herboseum (Gossypium herbaceum)\n\nThere are 61 reservoirs (each of them has capacity of 1 mln m) available in Azerbaijan. The total volume of water reservoirs is 21.5 km. Water reservoirs are built on the riverbed as well as beyond it (in a distance from river). Most reservoirs are regulated according to seasons and used for irrigation purposes.\n\nThe largest Mingachevir reservoir of the republic started to be operated in 1953 and it is operated in a multi-year regime, the flow of the Kur River is completely regulated in its downstream and overfloods are prevented.\n\nThe river system of the Republic has more than 8350 rivers, 2 of them are the lengths of more than 500 km, the length of the 22 rivers are between 101–500 km, the length of the 324 rivers are between 11–100 km, and the length of majority rivers is less than 10 km.\n\nThe river system of the Republic consists of the Kur River and its branches, as well as rivers directed into the Caspian Sea.\n\nKur River is the main water source and artery of Azerbaijan. The flowing path of river goes through Turkey, Georgia and Azerbaijan. The cumulative area of the river is 188,000 square km, which of 58,000 square km or 31% of the area belongs to Azerbaijan. After passing the Georgian border, the Kur river’s flowrate in the Girag Kasaman settlement is 270 m / s or 8.52 km. Whereas, in the Kur-Salyan station the average perennial flowrate is 445 m / s or 14.04 km.\n\nThe Araz River, the second largest river in the Republic and the right branch of the Kur River flow path starts from Turkey territory, as well as it is a border river between Turkey and Armenia, Turkey and Azerbaijan and Iran and Azerbaijan. The cumulative area of the Araz River is 102,000 km, where the 18,740 km or 18% of the river area belongs to Azerbaijan. Average annual flowrate of Araz River through Novruzlu (Saatli) settlement is 121 m / s or 3.82 km.\n\nThe river system of the republic consists of three groups: transboundary, border and local rivers. The transboundary (flowing through two or several countries) rivers include Kur, Ganikh (Alazan), Gabrirri (Iori), Khrami, Arpachay and others. Border rivers (which are in border between two or more countries) include Araz, Samur, Bolgarchay and others. Local rivers are formed and flowing in the territory of the Republic.\n\nThe water collection area is supplied by 2 large rivers of the Republic (Kur and Araz), 12 medium rivers, and other small rivers. Only 4 of the local rivers (Pirsaat, Hekericay, Tertçay, and Kurekchay) can be considered as medium rivers.\n\nThe mountain rivers flowing from the southern slope of the Greater Caucasus (Balakanchay, Talacay, Kurmukchay, Kishchay, Turyanchay, Goychay, Girdimanchay, etc.) are the left branches of the Kur river, however, flowing from the north-eastern slope (Gusarchay, Gudyalchay, Garachay, Valvalachay, etc.) and the Gobustan rivers (Sumqayitchay, Pirsaat, etc.) are the rivers directed into the Caspian Sea. Moreover, the rivers flowing from the north-eastern slope of the Lesser Caucasus (Zeyamchay, Shamkirchay, Goshagachay, Ganjachay, Kurekchay etc.) flowing from the Karabakh Range (Khachinchay, Terterchay, Gargarchay, etc.) are the right branches of the Kur, however, flowing from the Zangazur Range (Nakhchivanchay, Alinjaychay, Gilanchay, etc.) and the rivers flowing from the south-western slope of the Lesser Caucasus (Hekerichay, Guruchay, Kondalanchay etc.) are the left branches of the Araz River.\n\nLankaran rivers (Vishonchay, Lankaranchay, Tengerchay, Astarachay and etc.) are the rivers directed into the Caspian Sea.\n\nCumulative 450 lakes with a total area of 395 km were identified in Azerbaijan, where 10 lakes have area over 10 km.\n\nThe largest lake of the Republic is Sarısu lake, located in the Kur-Araz lowland (water area 65.7 km, volume of water is 59.1 million m). The highest mountainous lake in the Republic is Tufangol (area 0.01 km, volume 0.11 million m) located in the basin of Damiraparanchay and at a height of 3277 m. One of the most attractive lakes of the Republic is the famous Lake Goygol. The lake was formed in the middle stream of Aghsuchay after strong earthquake at 1139.\n\nThe Goy-gol State Reserve which is the first protection area in Azerbaijan was established in 1925. The Gizilagac and Zagatala Reserves in 1929, and the Hirkan Reserve was established in 1936. So, four reserves have been functioning until 1958. The process of reserve establishments has actively continued from 1958 to 1990. Altiagac State Reserve was established in 1990. As well as Shahbuz in Nakhchivan Autonomous Republic in 2003, Eldar Shamı in 2004, Mud Volcanoes group in Baku and Absheron Peninsula in 2007, and Korchay State Reserve in 2008. At the same time, the Reserve of Turyanchay, Pirgulu, Ilisu, Gara-Yaz, Ismayilli in 2003 and Zagatala State Reserves in 2008 were being expanded.\n\nNatural Reserves include fish resources of the Caspian Sea, rivers, water reservoirs, mainly the various species of animals spread in the mountainous areas, reptiles in the plains (especially the Caucasian viper, which has a very valuable poison), many birds and so on.\n\nThe Regulation on the Ministry of Ecology and Natural Resources of Azerbaijan was approved by Decree #583 of the Azerbaijani President on September 18, 2001.\n\nAccording to the Regulation, the Ministry of Ecology and Natural Resources is the central executive body that implements state policy in the field of the protection of the environment, the use of natural resources, the rational utilization of underground waters, mineral raw materials and surface natural resources, their restoration, observation and prediction of hydro meteorological processes in the territory of the Republic, as well as In the section of the Caspian Sea (lake) belonging to the Azerbaijan.\n\n\n"}
{"id": "21066958", "url": "https://en.wikipedia.org/wiki?curid=21066958", "title": "Nuclear power in Ukraine", "text": "Nuclear power in Ukraine\n\nUkraine operates four nuclear power plants with 15 reactors located in Volhynia and South Ukraine. \nThe total installed nuclear power capacity is over 13 GWe, ranking seventh in the world in 2016.\nEnergoatom, a Ukrainian state enterprise, operates all four active nuclear power stations in Ukraine.\nIn 2014, nuclear power supplied 49.4% of Ukraine's electricity production of 168 TWh.\n\nUkraine relies to a large extent on nuclear energy. \nThe largest nuclear power plant in Europe, the Zaporizhzhia Nuclear Power Plant, is located in Ukraine. \nIn 2006, the government planned to build 11 new reactors by the year 2030, which would almost double the current amount of nuclear power capacity. \nUkraine's power sector is the twelfth-largest in the world in terms of installed capacity, with 54 gigawatts (GW). \nRenewable energy still plays a very modest role in electrical output; in 2005 energy production was met by the following sources: nuclear (47 percent), thermal (45 percent), hydroelectric and other (8 percent).\nThe Chernobyl disaster was a nuclear accident that occurred on 26 April 1986 at the Chernobyl Nuclear Power Plant in Ukraine. \nAn explosion and fire released large quantities of radioactive contamination into the atmosphere, which spread over much of Western USSR and Europe. \nIt is considered the worst nuclear power plant accident in history, and is one of only two classified as a level 7 event on the International Nuclear Event Scale (the other being the Fukushima Daiichi nuclear disaster). The battle to contain the contamination and avert a greater catastrophe ultimately involved over 500,000 workers and cost an estimated 18 billion rubles, crippling the Soviet economy.\n\nUkraine used to receive its nuclear fuel exclusively from Russia by the Russian company TVEL. Since 2008 the country also gets nuclear fuel from Westinghouse. \nSince 2014 Westinghouse's share of imports grew to more than 30% in 2016. In 2018 Westinghouse's contract to supply VVER fuel was extended to 2025. Oil and natural gas provide the remainder of the country's energy; these are also imported from the former Soviet Union.\n\nIn 2011 Energoatom began a project to bring safety into line with international standards at an estimated cost of $1.8 billion, with a target completion date of 2017. In 2015 the completion date was put back to 2020, due to financing delays. In 2015 some government agencies made corruption allegations against Energoatom, with concerns raised by Prime Minister Arseniy Yatsenyuk. In March 2016, Energoatom's assets and bank accounts were frozen by Ukrainian courts over allegedly unpaid debts; Energoatom appealed the decision, but the frozen finances led to contractual breaches. In June 2016 its bank accounts were unfrozen.\n\nIn February 2018 Ukraine secured $250 million of U.S. funding to build a spent nuclear fuel storage facility, which will avoid the need ship spent nuclear fuel to Russia.\n\nIn March 2018 Energoatom stated that electricity prices were too low to cover the cost of new nuclear fuel, and called for a price increase.\n\nIn 2005 there were 17 deposits on the state balance account. Three of them Vatutine, Central, and Michurinske were being developed, while at the Novokostiantyniv was being built an ore enrichment factory. Number of deposits are exhausted (i.e. Devladove, Zhovtorichenske, Pershotravneve, Bratske).\n\nAll of Ukraine's RBMK reactors (the type involved in the 1986 Chernobyl nuclear disaster) were located at the Chernobyl Nuclear Power Plant. All of the reactors there have been shut down, leaving only the much safer VVER reactors operating in the country. Three of the reactors listed were built in post-independence Ukraine, with the first one of these being constructed in 1995; the other sixteen reactors the country inherited from the Soviet Union.\n\n\n\n"}
{"id": "39415735", "url": "https://en.wikipedia.org/wiki?curid=39415735", "title": "Origin and occurrence of fluorine", "text": "Origin and occurrence of fluorine\n\nFluorine is relatively rare in the universe compared to other elements of nearby atomic weight. On earth, fluorine is essentially found only in mineral compounds because of its reactivity. The main commercial source, fluorite, is a common mineral.\n\nAt 400 ppb, fluorine is estimated to be the 24th most common element in the universe. It is comparably rare for a light element (elements tend to be more common the lighter they are). All of the elements from atomic number 6 (carbon) to atomic number 14 (silicon) are hundreds or thousands of times more common than fluorine except for 11 (sodium). One science writer described fluorine as a \"shack amongst mansions\" in terms of abundance. Fluorine is so rare because it is not a product of the usual nuclear fusion processes in stars. And any created fluorine within stars is rapidly eliminated through strong nuclear fusion reactions—either with hydrogen to form oxygen and helium, or with helium to make neon and hydrogen. The presence of fluorine at all—outside of temporary existence in stars—is somewhat of a mystery because of the need to escape these fluorine-destroying reactions.\n\nThree theoretical solutions to the mystery exist: In type II supernovae, atoms of neon could be hit by neutrinos during the explosion and converted to fluorine. In Wolf-Rayet stars (blue stars over 40 times heavier than the Sun), a strong solar wind could blow the fluorine out of the star before hydrogen or helium could destroy it. Finally, in asymptotic giant branch (a type of red giant) stars, fusion reactions occur in pulses and convection could lift fluorine out of the inner star. Only the red giant hypothesis has supporting evidence from observations.\n\nIn space, fluorine commonly combines with hydrogen to form hydrogen fluoride. (This compound has been suggested as a tracer to enable tracking reservoirs of hydrogen in the universe.) In addition to HF, monatomic fluorine has been observed in the interstellar medium. Fluorine cations have been seen in planetary nebulae and in stars, including our Sun.\n\nFluorine is the thirteenth most common element in Earth's crust, comprising between 600 and 700 ppm of the crust by mass. Because of its reactivity, it is essentially only found in compounds.\n\nThree minerals exist that are industrially relevant sources of fluorine: fluorite, fluorapatite, and cryolite.\n\nFluorite (CaF), also called fluorspar, is the main source of commercial fluorine. Fluorite is a colorful mineral associated with hydrothermal deposits. It is common and found worldwide. China supplies more than half of the world's demand and Mexico is the second-largest producer in the world\n\nThe United States produced most of the world's fluorite in the early 20th century, but its last mine, in Illinois, shut down in 1995. Canada also exited production in the 1990s. The United Kingdom has declining fluorite mining and has been a net importer since the 1980s.\n\nFluorapatite (Ca(PO)F) is mined along with other apatites for its phosphate content and is used mostly for production of fertilizers. Most of the Earth's fluorine is bound in this mineral, but because the percentage within the mineral is low (3.5%), the fluorine is discarded as waste. Only in the United States is there significant recovery. There, the hexafluorosilicates produced as byproducts are used to supply water fluoridation.\n\nCryolite (NaAlF) is the least abundant of the three major fluorine-containing minerals, but is a concentrated source of fluorine. It was formerly used directly in aluminium production. However, the main commercial mine, on the west coast of Greenland, closed in 1987.\n\nSeveral other minerals, such as the gemstone topaz, contain fluoride. Fluoride is not significant in seawater or brines, unlike the other halides, because the alkaline earth fluorides precipitate out of water. Commercially insignificant quantities of organofluorines have been observed in volcanic eruptions and in geothermal springs. Their ultimate origin (from biological sources or geological formation) is unclear.\n\nThe possibility of small amounts of gaseous fluorine within crystals has been debated for many years. One form of fluorite, antozonite, has a smell suggestive of fluorine when crushed. The mineral also has a dark black color, perhaps from free calcium (not bonded to fluoride). In 2012, a study reported detection of trace quantities (0.04% by weight) of diatomic fluorine in antozonite. It was suggested that radiation from small amounts of uranium within the crystals had caused the free fluorine defects.\n\n"}
{"id": "26210009", "url": "https://en.wikipedia.org/wiki?curid=26210009", "title": "Park Connector Network", "text": "Park Connector Network\n\nThe Park Connector Network (PCN) of Singapore is a network of walking/running/cycling paths that connects the various parks and other green spaces in Singapore. Both the parks and the PCN are managed by National Parks Board (NParks).\n\nAs part of the National Cycling Plan to promote cycling, the Land Transport Authority (LTA) is constructing networks of cycling paths within towns. These cycling paths connect with the PCN, enabling people to safely cycle both intra-town (e.g., from home to MRT station) and inter-town (longer distance cycling).\n\nThe proposal to form a park connector network was approved in 1991 by The Garden City Action Committee. In 1995, The Kallang Park Connector became the first park connector to be implemented. Stretching over nine kilometres, the park connector links two regional parks: Bishan Park and Kallang Riverside Park. In December 2007, the Eastern Coastal Loop, a 42-kilometre loop, was completed, providing a link from East Coast Park to Changi Beach Park. By January 2012, 200 kilometres of the PCN has been completed. In 2015, NParks has completed 300 kilometres of the PCN, along with the Central Urban Loop.\n\nSome of the park connectors form a loop. The list of completed loops include:\n\nThe individual completed park connectors include:\n\n\n"}
{"id": "11191703", "url": "https://en.wikipedia.org/wiki?curid=11191703", "title": "RADOM-7", "text": "RADOM-7\n\nRADOM is a Bulgarian Liulin-type spectrometry-dosimetry instrument, designed to precisely measure cosmic radiation around the Moon. It is installed on the Indian satellite Chandrayaan-1. Another three instruments were deployed on the International Space Station. All Liulin-type instruments are designed and build by the Solar-Terrestrial Influences Laboratory at the Bulgarian Academy of Sciences.\n"}
{"id": "49301338", "url": "https://en.wikipedia.org/wiki?curid=49301338", "title": "Rayleigh fractionation", "text": "Rayleigh fractionation\n\nRayleigh fractionation describes the evolution of a system with multiple phases in which one phase is continuously removed from the system through fractional distillation. It is used in particular to describe isotopic enrichment or depletion as material moves between reservoirs in an equilibrium process. Rayleigh fractionation holds particular importance in hydrology and meteorology as a model for the isotopic differentiation of meteoric water due to condensation.\n\nThe original Rayleigh equation was derived by Lord Rayleigh for the case of fractional distillation of mixed liquids. \n\nThis is an exponential relation that describes the partitioning of isotopes between two reservoirs as one reservoir decreases in size. The equations can be used to describe an isotope fractionation process if: (1) material is continuously removed from a mixed system containing molecules of two or more isotopic species (e.g., water with 18O and 16O, or sulfate with 34S and 32S), (2) the fractionation accompanying the removal process at any instance is described by the fractionation factor a, and (3) a does not change during the process. Under these conditions, the evolution of the isotopic composition in the residual (reactant) material is described by:\n\nformula_1\n\nwhere R = ratio of the isotopes (e.g., 18O/16O) in the reactant, Rº = initial ratio, X = the concentration or amount of the more abundant (lighter) isotope (e.g.,16O), and Xº = initial concentration. Because the concentration of X » Xh (heavier isotope concentration), X is approximately equal to the amount of original material in the phase. Hence, if formula_2 = fraction of material remaining, then:\n\nformula_3\n\nFor large changes in concentration, such as they occur during e.g. distillation of heavy water, these formula's need to be integrated over the distillation trajectory. For small changes such as occur during transport of water vapour through the atmosphere, the differentiated equation will usually be sufficient.\n"}
{"id": "14260277", "url": "https://en.wikipedia.org/wiki?curid=14260277", "title": "Regional African Satellite Communication Organization", "text": "Regional African Satellite Communication Organization\n\nThe Regional African Satellite Communication Organization (RASCOM) will provide telecommunication services, direct TV broadcast services and Internet access in rural areas of Africa. Under an agreement with RASCOM, RascomStar-QAF (a private company registered in Mauritius) will implement RASCOM's first 14communications satellite project. This joint African project is expected to lower the continent's dependency on international satellite networks such as Intelsat.\n\nRASCOM-QAF1 is the first satellite entirely dedicated to the African continent. Thales Alenia Space built the satellite in the Cannes Mandelieu Space Center, France. The company has delivered the satellite in-orbit, and will supply the ground infrastructure needed to operate it. The spacecraft is based on the Spacebus 4000B3 platform, with a payload of twelve Ku-band transponders and eight C-band transponders. It weighed about at launch. \n\nLaunch aboard an Ariane 5GS rocket took place on 2007-12-21. On 2007-12-29 Thales Alenia Space announced that a helium leak aboard the spacecraft would delay its activation. On 2008-01-08 the company announced the perigee of the satellite's orbit would be raised, and also acknowledged that if the satellite eventually reached geostationary orbit its useful lifetime would be significantly reduced. On 2008-02-04 Thales Alenia Space announced the satellite had reached its intended geostationary orbit at 2.85° East. They expect its lifetime to be slightly over 2 years.\n\nOn 2008-09-09 Thales Alenia Space announced it would supply RASCOMSTAR-QAF with a new satellite which will provide continuity of service for RASCOMSTAR-QAF customers. Like RASCOM-QAF1, RASCOM-QAF1R will be based on the Spacebus 4000 B3 platform and will be fitted with twelve Ku-band and eight C-band transponders.\nLaunch aboard an Ariane 5 ECA occurred on August 4, 2010.\n\n\n"}
{"id": "54385255", "url": "https://en.wikipedia.org/wiki?curid=54385255", "title": "Riesending cave rescue", "text": "Riesending cave rescue\n\nA rescue occurred at Riesending cave between 8 June and 19 June 2014 in Bavaria, Germany, after a speleologist, who had been exploring the cave in a group of three, suffered a traumatic brain injury as a result of a rockfall. It became one of the largest cave rescues in history, involving more than 700 people for eleven days and an estimated cost of close to one million euro.\n\nAround noon on 7 June 2014, speleologist and caver Johann Westhauser and two colleagues descended into the Riesending cave, the deepest and longest pit cave in Germany located in the south-eastern edge of the country on the border to Austria. It is known to be \"technically challenging from the first metres on\". The next day, 8 June, Westhauser was hit by rockfall around 1:30 am and suffered a brain trauma despite wearing a helmet. At this time, the team had already descended about 1,000 meters (3,280 feet) down the cave. While one of the teammates stayed with Westhauser, the second person started his 10 hour ascent towards the entrance, as there is no radio or cell phone reception inside, a distance of around 6 km (3.72 miles). After reaching daylight and making the urgent call, emergency procedures were initiated.\n\nOn the same evening, three groups of cave rescuers, eleven people in total, entered the cave to make their way towards Westhauser and the remaining teammate. A cave-link system was established to send and receive basic communication signals through solid rock, allowing the exchange of text messages between the cave entrance and the scene of the accident. Further mountain rescue teams from Germany and Austria reached the scene, supported by State- and Federal Police helicopters. On the evening of 11 June, a physician was able to reach the patient. A minor traumatic brain injury was diagnosed and together with a second physician arriving later at night, it was decided that Westhauser was fit to be transported. The paths within the cave had to be secured with additional fixed ropes, bolts and footrests. At peak times, up to 60 people were in the cave and 90% of all cave rescue equipment of the Bavarian mountain rescue (Bergwacht) had been fitted.\n\nThe transport through the narrow passages and supplies for the large number of people inside and outside the cave was challenging. The stretcher had been made shock proof to a certain extent. Luckily, Westhauser’s condition stabilized within the days of the rescue operation. There were no engines or other machinery available, so all work had to be done by hand. In vertical passages, the rescue staff used their own bodies as a counterweight to the stretcher. On 19 June at 11:44 am, they reached the surface and exited the Riesending with the help of a manual winch. Westhauser was then transported to the trauma hospital in Murnau via helicopter.\n\nThe operation became well known to the general public for the large rescue effort and was called a \"chapter of alpine rescue history\", taking eleven days by more than 700 members of a multinational group of cave rescuers, consisting of people from Italy, Austria, Germany, Switzerland, Croatia and others. In August, 2015 the interior ministry of Bavaria reported that the costs were estimated around 960,000 Euros, while the victim himself had been \"taking responsibility for a substantial amount\", although no bill was issued by the state government.\n\nAt the end of June, the entrance to the cave was sealed by police to prevent further accidents by curious people and tourists. A special permit is now required and only issued to people with justified interest, physical suitability and professional qualification.\n\nResearcher Westhauser was able to recover from his injuries and slowly started exploring caves again in 2016.\n"}
{"id": "51521802", "url": "https://en.wikipedia.org/wiki?curid=51521802", "title": "Saltese Uplands Conservation Area", "text": "Saltese Uplands Conservation Area\n\nThe Saltese Uplands Conservation Area is a 522 acre conservation area in Spokane County in the U.S. state of Washington. The conservation area covers the Saltese Uplands, overlooking the Saltese Flats, on the west slope of Carlson Hill. The area is open to the public and contains of trails.\nThe Saltese Uplands, are the driest part of the Spokane Valley and experience a semi-arid climate (Köppen \"Bsk\"). The Uplands are a shrub-steppe, and one of the only shrub-lands left in the Spokane area.\n"}
{"id": "9974076", "url": "https://en.wikipedia.org/wiki?curid=9974076", "title": "Salvador Namburete", "text": "Salvador Namburete\n\nSalvador Namburete is the Minister of Energy of Mozambique.\n\n"}
{"id": "3004834", "url": "https://en.wikipedia.org/wiki?curid=3004834", "title": "Selandian", "text": "Selandian\n\nThe Selandian is in the geologic timescale an age or stage in the Paleocene. It spans the time between . It is preceded by the Danian and followed by the Thanetian. Sometimes the Paleocene is subdivided in subepochs, in which the Selandian forms the \"Middle Paleocene\".\n\nThe Selandian was introduced in scientific literature by Alfred Rosenkrantz in 1924. It is named after the Danish island of Zealand (Danish: \"Sjælland\").\n\nThe base of the Selandian is close to the boundary between biozones NP4 and NP5. It is slightly after the first appearances of many new species of the calcareous nanoplankton genus \"Fasciculithus\" (\"F. ulii\", \"F. billii\", \"F. janii\", \"F. involutus\", \"F. tympaniformis\" and \"F. pileatus\") and close to the first appearance of calcareous nanoplankton species \"Neochiastozygus perfectus\". At the original type location in Denmark the base of the Selandian is an unconformity. The official GSSP was established in the Zumaia section (43° 18'N, 2° 16'W) at the beach of Itzurun in the Basque Country, northern Spain.\n\nThe top of the Selandian (the base of the Thanetian) is laid at the base of magnetic chronozone C26n.\n\nThe Selandian stage overlaps with the lower part of the Tiffanian North American Land Mammal Age, the Peligran, Tiupampan and lower Itaboraian South American Land Mammal Ages and part of the Nongshanian Asian Land Mammal Age. It is coeval with the lower part of the Wangerripian stage from the Australian regional timescale.\n\nThe start of the Selandian represents a sharp depositional change in the North Sea Basin, where there is a shift to siliciclastic deposition due to the uplift and erosion of the Scotland-Shetland area after nearly 40 million years of calcium carbonate deposition. This change occurs at the same time as the onset of a foreland basin formation in Spitsbergen due to compression between Greenland and Svalbard, suggesting a common tectonic cause that altered the relative motions of the Greenland Plate and the Eurasian Plate. This plate reorganisation event is also manifest as a change in seafloor spreading direction in the Labrador Sea around this time.\n\nThe fauna of the Selandian consisted of giant snakes (\"Titanoboa\"), crocodiles, champosaurs, Gastornithiformes Owls; while the mammalian fauna was composed of a few archaic forms of mammals, such as Mesonychids, Pantodonts, primate relatives Plesiadapids, and Multiberculates.\n\nThe flora was composed of cacti, ferns, angiosperms, and palm trees.\n\n"}
{"id": "3145438", "url": "https://en.wikipedia.org/wiki?curid=3145438", "title": "Sierra de la Laguna pine-oak forests", "text": "Sierra de la Laguna pine-oak forests\n\nThe Sierra de la Laguna pine-oak forests is a subtropical coniferous forest ecoregion, found in the Sierra de la Laguna mountain range at the southern tip of the Baja California Peninsula, Mexico.\n\nIt is found within Los Cabos Municipality and eastern La Paz Municipality of southern Baja California Sur state.\n\nThe ecoregion encompasses an area of . The pine-oak forests are found above in elevation, and are surrounded at lower elevations by the Sierra de la Laguna dry forests. The pine-oak forests have a unique and diverse flora and fauna, including 694 plant species, of which approximately 85 are endemic.\n\nThe higher elevation gives the ecoregion a subtropical to temperate climate, in contrast to the dry tropical climate of the lowlands. Rainfall is higher than the lower-elevation dry forests and deserts of the peninsula, averaging 760 mm annually. Rain falls mostly in the summer, with occasional winter rains.\n\nThe composition of the pine-oak forests varies with elevation; oak woodlands predominate from in elevation, with oak-pine woodlands between in elevation, transitioning to pine-oak forests above in elevation. Mosses and lichens are abundant throughout.\n\nThe oak woodlands from in elevation are warmer and drier, with evergreen oaks predominant (principally \"Quercus devia\"; \"Quercus arizonica\" and \"Quercus rugosa\" have a limited distribution), along with lower trees and shrubs such as \"Dodonaea viscosa\", \"Sideroxylon peninsulare\", and \"Buddleia crotonoides.\"\n\nAbove in elevation, the oak woodlands transition to oak-pine forests. The only pine present is an endemic subspecies of Mexican Pinyon, \"Pinus cembroides\" subsp. \"lagunae\", mixed with oaks, including \"Quercus devia\" and \"Quercus tuberculata\", and other broadleaf trees, including \"Arbutus peninsularis\" and \"Nolina beldingi\". Lower trees and understory shrubs include \"Calliandra peninsularis\", \"Mimosa xanti\", \"Heterotoma aurita\", \"Verbesina pustulata\" and \"Hypericum peninsulare\". Above in elevation, pine predominates, mixed with oaks, and with an understory of grasses (\"Muhlenbergia\" spp. and \"Festuca\" spp.).\n\n"}
{"id": "30552217", "url": "https://en.wikipedia.org/wiki?curid=30552217", "title": "Stellar mass", "text": "Stellar mass\n\nStellar mass is a phrase that is used by astronomers to describe the mass of a star. It is usually enumerated in terms of the Sun's mass as a proportion of a solar mass (). Hence, the bright star Sirius has around . A star's mass will vary over its lifetime as additional mass becomes accreted, such as from a companion star, or mass is ejected with the stellar wind or pulsational behavior.\n\nStars are sometimes grouped by mass based upon their evolutionary behavior as they approach the end of their nuclear fusion lifetimes.\n\n\"Very low mass stars\" with masses below 0.5 do not enter the asymptotic giant branch (AGB) but evolve directly into white dwarfs. (At least in theory; the lifetimes of such stars are long enough—longer than the age of the universe to date—that none has yet had time to evolve to this point and be observed.)\n\n\"Low mass stars\" with a mass below about 1.8–2.2 (depending on composition) do enter the AGB, where they develop a degenerate helium core.\n\n\"Intermediate-mass stars\" undergo helium fusion and develop a degenerate carbon-oxygen core.\n\n\"Massive stars\" have a minimum mass of 7–10 , but this may be as low as 5–6 . These stars undergo carbon fusion, with their lives ending in a core-collapse supernova explosion. Black holes created as a result of a stellar collapse are termed stellar mass black holes.\n\nThe combination of the radius and the mass of a star determines the surface gravity. Giant stars have a much lower surface gravity than main sequence stars, while the opposite is the case for degenerate, compact stars such as white dwarfs. The surface gravity can influence the appearance of a star's spectrum, with higher gravity causing a broadening of the absorption lines.\n\nOne of the most massive stars known is Eta Carinae, with ; its lifespan is very short—only several million years at most. A study of the Arches cluster suggests that is the upper limit for stars in the current era of the universe. The reason for this limit is not precisely known, but it is partially due to the Eddington luminosity which defines the maximum amount of luminosity that can pass through the atmosphere of a star without ejecting the gases into space. However, a star named R136a1 in the RMC 136a star cluster has been measured at 265 , putting this limit into question. A study has determined that stars larger than 150 in R136 were created through the collision and merger of massive stars in close binary systems, providing a way to sidestep the 150 limit.\n\nThe first stars to form after the Big Bang may have been larger, up to 300 or more, due to the complete absence of elements heavier than lithium in their composition. This generation of supermassive, population III stars is long extinct, however, and currently only theoretical.\n\nWith a mass only 93 times that of Jupiter (), or .09 , AB Doradus C, a companion to AB Doradus A, is the smallest known star undergoing nuclear fusion in its core. For stars with similar metallicity to the Sun, the theoretical minimum mass the star can have, and still undergo fusion at the core, is estimated to be about 75 . When the metallicity is very low, however, a recent study of the faintest stars found that the minimum star size seems to be about 8.3% of the solar mass, or about 87 . Smaller bodies are called brown dwarfs, which occupy a poorly defined grey area between stars and gas giants.\n\nIn the present day, the Sun is losing mass from the emission of electromagnetic energy and by the ejection of matter with the solar wind. It is expelling about (2–3) per year. The mass loss rate will increase when the Sun enters the red giant stage, climbing to (7–9) y when it reaches the tip of the red giant branch. This will rise to 10 y on the asymptotic giant branch, before peaking at a rate of 10 to 10 y as the Sun generates a planetary nebula. By the time the Sun becomes a degenerate white dwarf, it will have lost 46% of its starting mass.\n"}
{"id": "10828016", "url": "https://en.wikipedia.org/wiki?curid=10828016", "title": "Subparhelic circle", "text": "Subparhelic circle\n\nThe subparhelic circle is a rare halo, an optical phenomenon located below the horizon. It passes through both the subsun, below the sun, and the antisolar point, opposite to the sun. The subparhelic circle is the subhorizon counterpart to the parhelic circle located above the horizon.\n\nLocated on the subparhelic circle are several relatively rare optical phenomena: The subsun, the subparhelia, the 120° subparhelia, Liljequist subparhelia, the diffuse arcs, and the Parry antisolar arcs.\n\nOn the accompanying photo centred on the antisolar point, the subparhelic circle is viewable as a gently curved horizontal line intercepted by anthelic arcs.\n\n\n"}
{"id": "323221", "url": "https://en.wikipedia.org/wiki?curid=323221", "title": "Sun dog", "text": "Sun dog\n\nA sun dog (or sundog) or mock sun, formally called a parhelion (plural parhelia) in meteorology, is an atmospheric optical phenomenon that consists of a bright spot to one or both sides of the Sun. Two sun dogs often flank the Sun within a 22° halo.\n\nThe sun dog is a member of the family of halos, caused by the refraction of sunlight by ice crystals in the atmosphere. Sun dogs typically appear as a pair of subtly colored patches of light, around 22° to the left and right of the Sun, and at the same altitude above the horizon as the Sun. They can be seen anywhere in the world during any season, but are not always obvious or bright. Sun dogs are best seen and most conspicuous when the Sun is near the horizon.\n\nSun dogs are commonly caused by the refraction and scattering of light from plate-shaped hexagonal ice crystals either suspended in high and cold cirrus or cirrostratus clouds, or drifting in freezing moist air at low levels as diamond dust. The crystals act as prisms, bending the light rays passing through them with a minimum deflection of 22°. As the crystals gently float downwards with their large hexagonal faces almost horizontal, sunlight is refracted horizontally, and sun dogs are seen to the left and right of the Sun. Larger plates wobble more, and thus produce taller sundogs.\n\nSun dogs are red-colored at the side nearest the Sun; farther out the colors grade through oranges to blue. The colors overlap considerably and are muted, never pure or saturated. The colors of the sun dog finally merge into the white of the parhelic circle (if the latter is visible).\n\nThe same plate-shaped ice crystals that cause sun dogs are also responsible for the colorful circumzenithal arc, meaning that these two types of halo tend to co-occur. The latter is often missed by viewers, since it is located more or less directly overhead. Another halo variety often seen together with sun dogs is the 22° halo, which forms a ring at roughly the same angular distance from the sun as the sun dogs, thus appearing to interconnect them. As the Sun rises higher, the rays passing through the plate crystals are increasingly skewed from the horizontal plane, causing their angle of deviation to increase and the sun dogs to move farther from the 22° halo, while staying at the same elevation.\n\nIt is possible to predict the forms of sun dogs as would be seen on other planets and moons. Mars might have sun dogs formed by both water-ice and CO-ice. On the gas giant planets — Jupiter, Saturn, Uranus and Neptune—other crystals form clouds of ammonia, methane, and other substances that can produce halos with four or more sun dogs.\nA somewhat common misconception among the general public is to refer to any member of the ice halo family as a \"sun dog\" (especially the 22° halo, being one of the most common varieties). However, sun dogs represent just one of many different types of halos. Moreover, the term \"sun dog\" (singular) specifically refers to either of the two bright spots to the left and right of the Sun, each of them is a \"separate\" sun dog. Since they typically appear in pairs, it would thus be more accurate to use the plural \"sun dogs\". For referring to the atmospheric phenomenon in general, the term \"(ice crystal) halo(s)\" is more appropriate.\n\nThe exact etymology of \"sun dog\" largely remains a mystery. The \"Oxford English Dictionary\" states it as being \"of obscure origin\".\n\nIn Abram Palmer's 1882 book \"Folk-etymology: A Dictionary of Verbal Corruptions Or Words Perverted in Form Or Meaning, by False Derivation Or Mistaken Analogy\", sun-dogs are defined:\n\nAlternatively, Jonas Persson suggested that out of Norse mythology and archaic names — (sun dog), (sun dog), (sun wolf) — in the Scandinavian languages, constellations of two wolves hunting the Sun and the Moon, one after and one before, may be a possible origin for the term.\n\n\"Parhelion\" (plural \"parhelia\") comes from (, 'beside the sun'; from (, 'beside') and (, 'sun')).\n\nIn the Anglo-Cornish dialect of Cornwall, United Kingdom, sun dogs are known as \"weather dogs\" (described as \"a short segment of a rainbow seen on the horizon, foreshowing foul weather\"). It is also known as \"a lagas in the sky\" which comes from the Cornish language term for the sun dog meaning 'weather's eye' (, 'eye' and , 'weather/wind'). This is in turn related to the Anglo-Cornish term \"cock's eye\" for a halo round the sun or the moon, also a portent of bad weather.\n\nAristotle (Meteorology III.2, 372a14) notes that \"two mock suns rose with the sun and followed it all through the day until sunset.\" He says that \"mock suns\" are always to the side, never above or below, most commonly at sunrise or sunset, more rarely in the middle of the day.\n\nThe poet Aratus (Phaenomena 880–891) mentions parhelia as part of his catalogue of Weather Signs; according to him, they can indicate rain, wind, or an approaching storm.\n\nArtemidorus in his \"Oneirocritica\" ('On the Interpretation of Dreams') included the mock suns amongst a list of celestial deities.\n\nA passage in Cicero's \"On the Republic\" (54–51 BC) is one of many by Greek and Roman authors who refer to sun dogs and similar phenomena:\n\nSeneca makes an incidental reference to sun dogs in the first book of his \"Naturales Quaestiones\".\n\nThe 2nd century Roman writer and philosopher Apuleius in his \"Apologia\" XV says \"What is the cause of the prismatic colours of the rainbow, or of the appearance in heaven of two rival images of the sun, with sundry other phenomena treated in a monumental volume by Archimedes of Syracuse.\"\n\nThe prelude to the Battle of Mortimer's Cross in Herefordshire, England in 1461 is supposed to have involved the appearance of a halo display with three \"suns\". The Yorkist commander, later Edward IV of England, convinced his initially frightened troops that it represented the three sons of the Duke of York, and Edward's troops won a decisive victory. The event was dramatized by William Shakespeare in \"King Henry VI, Part 3\", and by Sharon Kay Penman in \"The Sunne In Splendour\".\n\nPossibly the earliest clear description of sun dogs is by Jacob Hutter, who wrote in his \"Brotherly Faithfulness: Epistles from a Time of Persecution\":\n\nThe observation most likely occurred in Auspitz (Hustopeče), Moravia on 31 October 1533. The original was written in German and is from a letter originally sent in November 1533 from Auspitz in Moravia to the Adige Valley in Tyrol. The Kuntz Maurer and Michel Schuster mentioned in the letter left Hutter on the Thursday after the feast day of Simon and Jude, which is 28 October. The Thursday after was 30 October. It is likely that the \"two rainbows with their backs turned toward each other, almost touching\" involved two further halo phenomena, possibly a circumzenithal arc (prone to co-occur with sun dogs) together with a partial 46° halo or supralateral arc.\n\nWhile mostly known and often quoted for being the oldest color depiction of the city of Stockholm, \"Vädersolstavlan\" (Swedish; \"The Sundog Painting\", literally \"The Weather Sun Painting\") is arguably also one of the oldest known depictions of a halo display, including a pair of sun dogs. For two hours in the morning of 20 April 1535, the skies over the city were filled with white circles and arcs crossing the sky, while additional suns (i.e., sun dogs) appeared around the sun. The phenomenon quickly resulted in rumours of an omen of God's forthcoming revenge on King Gustav Vasa (1496–1560) for having introduced Protestantism during the 1520s and for being heavy-handed with his enemies allied with the Danish king.\n\nHoping to end speculations, the Chancellor and Lutheran scholar Olaus Petri (1493–1552) ordered a painting to be produced documenting the event. When confronted with the painting, the king, however, interpreted it as a conspiracy – the real sun of course being himself threatened by competing fake suns, one being Olaus Petri and the other the clergyman and scholar Laurentius Andreae (1470–1552), both thus accused of treachery, but eventually escaping capital punishment. The original painting is lost, but a copy from the 1630s survives and can still be seen in the church Storkyrkan in central Stockholm.\n\nA series of complex parhelia displays in Rome in 1629, and again in 1630, were described by Christoph Scheiner in his book \"Parhelia\", one of the earliest works on the subject. It had a profound effect, causing René Descartes to interrupt his metaphysical studies and led to his work of natural philosophy called \"The World\".\n\nOn 20 February 1661 the people of Danzig witnessed a complex halo display, described by Georg Fehlau in a pamphlet, the \"Sevenfold Sun Miracle\", and again the following year by Johannes Hevelius in his book, \"Mercurius in Sole visus Gedani\".\n\nOn 18 June 1790 , in St Petersburg, observed a complex display of haloes and parhelia which included his Lowitz arcs.\n\nIn 1843, winter in the British Colony of Newfoundland was referred to as the 'Winter of Three Suns' and was unusually cold with 15 days of temperatures between 3-10 degrees below zero.\n\n\"Part of the time we marched in the teeth of a biting storm of snow, and at every hour of the day the sun could be discerned sulking behind soft grey mists in company with rivals, known in the language of the plains as 'Sun-dogs', whose parahelic splendors warned the traveler of the approach of the ever-to-be-dreaded 'blizzard'.\"\n\n"}
{"id": "37530", "url": "https://en.wikipedia.org/wiki?curid=37530", "title": "Tornado", "text": "Tornado\n\nA tornado is a rapidly rotating column of air that is in contact with both the surface of the Earth and a cumulonimbus cloud or, in rare cases, the base of a cumulus cloud. The windstorm is often referred to as a twister, whirlwind or cyclone, although the word cyclone is used in meteorology to name a weather system with a low-pressure area in the center around which winds blow counterclockwise in the Northern Hemisphere and clockwise in the Southern. Tornadoes come in many shapes and sizes, and they are often visible in the form of a condensation funnel originating from the base of a cumulonimbus cloud, with a cloud of rotating debris and dust beneath it. Most tornadoes have wind speeds less than , are about across, and travel a few miles (several kilometers) before dissipating. The most extreme tornadoes can attain wind speeds of more than , are more than in diameter, and stay on the ground for dozens of miles (more than 100 km).\n\nVarious types of tornadoes include the multiple vortex tornado, landspout and waterspout. Waterspouts are characterized by a spiraling funnel-shaped wind current, connecting to a large cumulus or cumulonimbus cloud. They are generally classified as non-supercellular tornadoes that develop over bodies of water, but there is disagreement over whether to classify them as true tornadoes. These spiraling columns of air frequently develop in tropical areas close to the equator, and are less common at high latitudes. Other tornado-like phenomena that exist in nature include the gustnado, dust devil, fire whirls, and steam devil.\n\nTornadoes occur in North America, particularly in the area of the United States known as tornado alley, as well as in northern and east-central South America, Southern Africa, northwestern and southeast Europe, western and southeastern Australia, Bangladesh and New Zealand. Tornadoes can be detected before or as they occur through the use of Pulse-Doppler radar by recognizing patterns in velocity and reflectivity data, such as hook echoes or debris balls, as well as through the efforts of storm spotters.\n\nThere are several scales for rating the strength of tornadoes. The Fujita scale rates tornadoes by damage caused and has been replaced in some countries by the updated Enhanced Fujita Scale. An F0 or EF0 tornado, the weakest category, damages trees, but not substantial structures. An F5 or EF5 tornado, the strongest category, rips buildings off their foundations and can deform large skyscrapers. The similar TORRO scale ranges from a T0 for extremely weak tornadoes to T11 for the most powerful known tornadoes. Doppler radar data, photogrammetry, and ground swirl patterns (trochoidal marks) may also be analyzed to determine intensity and assign a rating.\n\nThe word \"tornado\" comes from the Spanish word tornado (past participle of to turn, or to have torn). Tornadoes opposite phenomena are the derechoes (, from , \"straight\"). A tornado is also commonly referred to as a \"twister\", and is also sometimes referred to by the old-fashioned colloquial term \"cyclone\". The term \"cyclone\" is used as a synonym for \"tornado\" in the often-aired 1939 film \"The Wizard of Oz\". The term \"twister\" is also used in that film, along with being the title of the 1996 tornado-related film \"Twister\".\n\nA tornado is \"a violently rotating column of air, in contact with the ground, either pendant from a cumuliform cloud or underneath a cumuliform cloud, and often (but not always) visible as a funnel cloud\". For a vortex to be classified as a tornado, it must be in contact with both the ground and the cloud base. Scientists have not yet created a complete definition of the word; for example, there is disagreement as to whether separate touchdowns of the same funnel constitute separate tornadoes. \"Tornado\" refers to the vortex of wind, not the condensation cloud.\n\nA tornado is not necessarily visible; however, the intense low pressure caused by the high wind speeds (as described by Bernoulli's principle) and rapid rotation (due to cyclostrophic balance) usually cause water vapor in the air to condense into cloud droplets due to adiabatic cooling. This results in the formation of a visible funnel cloud or condensation funnel.\n\nThere is some disagreement over the definition of a funnel cloud and a condensation funnel. According to the \"Glossary of Meteorology\", a funnel cloud is any rotating cloud pendant from a cumulus or cumulonimbus, and thus most tornadoes are included under this definition. Among many meteorologists, the 'funnel cloud' term is strictly defined as a rotating cloud which is not associated with strong winds at the surface, and condensation funnel is a broad term for any rotating cloud below a cumuliform cloud.\n\nTornadoes often begin as funnel clouds with no associated strong winds at the surface, and not all funnel clouds evolve into tornadoes. Most tornadoes produce strong winds at the surface while the visible funnel is still above the ground, so it is difficult to discern the difference between a funnel cloud and a tornado from a distance.\n\nOccasionally, a single storm will produce more than one tornado, either simultaneously or in succession. Multiple tornadoes produced by the same storm cell are referred to as a \"tornado family\". Several tornadoes are sometimes spawned from the same large-scale storm system. If there is no break in activity, this is considered a tornado outbreak (although the term \"tornado outbreak\" has various definitions). A period of several successive days with tornado outbreaks in the same general area (spawned by multiple weather systems) is a tornado outbreak sequence, occasionally called an extended tornado outbreak.\n\nMost tornadoes take on the appearance of a narrow funnel, a few hundred yards (meters) across, with a small cloud of debris near the ground. Tornadoes may be obscured completely by rain or dust. These tornadoes are especially dangerous, as even experienced meteorologists might not see them. Tornadoes can appear in many shapes and sizes.\n\nSmall, relatively weak landspouts may be visible only as a small swirl of dust on the ground. Although the condensation funnel may not extend all the way to the ground, if associated surface winds are greater than , the circulation is considered a tornado. A tornado with a nearly cylindrical profile and relative low height is sometimes referred to as a \"stovepipe\" tornado. Large single-vortex tornadoes can look like large wedges stuck into the ground, and so are known as \"wedge tornadoes\" or \"wedges\". The \"stovepipe\" classification is also used for this type of tornado if it otherwise fits that profile. A wedge can be so wide that it appears to be a block of dark clouds, wider than the distance from the cloud base to the ground. Even experienced storm observers may not be able to tell the difference between a low-hanging cloud and a wedge tornado from a distance. Many, but not all major tornadoes are wedges.\n\nTornadoes in the dissipating stage can resemble narrow tubes or ropes, and often curl or twist into complex shapes. These tornadoes are said to be \"roping out\", or becoming a \"rope tornado\". When they rope out, the length of their funnel increases, which forces the winds within the funnel to weaken due to conservation of angular momentum. Multiple-vortex tornadoes can appear as a family of swirls circling a common center, or they may be completely obscured by condensation, dust, and debris, appearing to be a single funnel.\n\nIn the United States, tornadoes are around across on average and travel on the ground for . However, there is a wide range of tornado sizes. Weak tornadoes, or strong yet dissipating tornadoes, can be exceedingly narrow, sometimes only a few feet or couple meters across. One tornado was reported to have a damage path only long. On the other end of the spectrum, wedge tornadoes can have a damage path a mile (1.6 km) wide or more. A tornado that affected Hallam, Nebraska on May 22, 2004, was up to wide at the ground, and a tornado in El Reno, Oklahoma on May 31, 2013 was approximately wide, the widest on record.\n\nIn terms of path length, the Tri-State Tornado, which affected parts of Missouri, Illinois, and Indiana on March 18, 1925, was on the ground continuously for . Many tornadoes which appear to have path lengths of or longer are composed of a family of tornadoes which have formed in quick succession; however, there is no substantial evidence that this occurred in the case of the Tri-State Tornado. In fact, modern reanalysis of the path suggests that the tornado may have begun further west than previously thought.\n\nTornadoes can have a wide range of colors, depending on the environment in which they form. Those that form in dry environments can be nearly invisible, marked only by swirling debris at the base of the funnel. Condensation funnels that pick up little or no debris can be gray to white. While traveling over a body of water (as a waterspout), tornadoes can turn white or even blue. Slow-moving funnels, which ingest a considerable amount of debris and dirt, are usually darker, taking on the color of debris. Tornadoes in the Great Plains can turn red because of the reddish tint of the soil, and tornadoes in mountainous areas can travel over snow-covered ground, turning white.\n\nLighting conditions are a major factor in the appearance of a tornado. A tornado which is \"back-lit\" (viewed with the sun behind it) appears very dark. The same tornado, viewed with the sun at the observer's back, may appear gray or brilliant white. Tornadoes which occur near the time of sunset can be many different colors, appearing in hues of yellow, orange, and pink.\n\nDust kicked up by the winds of the parent thunderstorm, heavy rain and hail, and the darkness of night are all factors which can reduce the visibility of tornadoes. Tornadoes occurring in these conditions are especially dangerous, since only weather radar observations, or possibly the sound of an approaching tornado, serve as any warning to those in the storm's path. Most significant tornadoes form under the storm's \"updraft base\", which is rain-free, making them visible. Also, most tornadoes occur in the late afternoon, when the bright sun can penetrate even the thickest clouds. Night-time tornadoes are often illuminated by frequent lightning.\n\nThere is mounting evidence, including Doppler on Wheels mobile radar images and eyewitness accounts, that most tornadoes have a clear, calm center with extremely low pressure, akin to the eye of tropical cyclones. Lightning is said to be the source of illumination for those who claim to have seen the interior of a tornado.\n\nTornadoes normally rotate cyclonically (when viewed from above, this is counterclockwise in the northern hemisphere and clockwise in the southern). While large-scale storms always rotate cyclonically due to the Coriolis effect, thunderstorms and tornadoes are so small that the direct influence of the Coriolis effect is unimportant, as indicated by their large Rossby numbers. Supercells and tornadoes rotate cyclonically in numerical simulations even when the Coriolis effect is neglected. Low-level mesocyclones and tornadoes owe their rotation to complex processes within the supercell and ambient environment.\n\nApproximately 1 percent of tornadoes rotate in an anticyclonic direction in the northern hemisphere. Typically, systems as weak as landspouts and gustnadoes can rotate anticyclonically, and usually only those which form on the anticyclonic shear side of the descending rear flank downdraft (RFD) in a cyclonic supercell. On rare occasions, anticyclonic tornadoes form in association with the mesoanticyclone of an anticyclonic supercell, in the same manner as the typical cyclonic tornado, or as a companion tornado either as a satellite tornado or associated with anticyclonic eddies within a supercell.\n\nTornadoes emit widely on the acoustics spectrum and the sounds are caused by multiple mechanisms. Various sounds of tornadoes have been reported, mostly related to familiar sounds for the witness and generally some variation of a whooshing roar. Popularly reported sounds include a freight train, rushing rapids or waterfall, a nearby jet engine, or combinations of these. Many tornadoes are not audible from much distance; the nature of and the propagation distance of the audible sound depends on atmospheric conditions and topography.\n\nThe winds of the tornado vortex and of constituent turbulent eddies, as well as airflow interaction with the surface and debris, contribute to the sounds. Funnel clouds also produce sounds. Funnel clouds and small tornadoes are reported as whistling, whining, humming, or the buzzing of innumerable bees or electricity, or more or less harmonic, whereas many tornadoes are reported as a continuous, deep rumbling, or an irregular sound of \"noise\".\n\nSince many tornadoes are audible only when very near, sound is not to be thought of as a reliable warning signal for a tornado. Tornadoes are also not the only source of such sounds in severe thunderstorms; any strong, damaging wind, a severe hail volley, or continuous thunder in a thunderstorm may produce a roaring sound.\n\nTornadoes also produce identifiable inaudible infrasonic signatures.\n\nUnlike audible signatures, tornadic signatures have been isolated; due to the long distance propagation of low-frequency sound, efforts are ongoing to develop tornado prediction and detection devices with additional value in understanding tornado morphology, dynamics, and creation. Tornadoes also produce a detectable seismic signature, and research continues on isolating it and understanding the process.\n\nTornadoes emit on the electromagnetic spectrum, with sferics and E-field effects detected. There are observed correlations between tornadoes and patterns of lightning. Tornadic storms do not contain more lightning than other storms and some tornadic cells never produce lightning at all. More often than not, overall cloud-to-ground (CG) lightning activity decreases as a tornado touches the surface and returns to the baseline level when the tornado dissipates. In many cases, intense tornadoes and thunderstorms exhibit an increased and anomalous dominance of positive polarity CG discharges. Electromagnetics and lightning have little or nothing to do directly with what drives tornadoes (tornadoes are basically a thermodynamic phenomenon), although there are likely connections with the storm and environment affecting both phenomena.\n\nLuminosity has been reported in the past and is probably due to misidentification of external light sources such as lightning, city lights, and power flashes from broken lines, as internal sources are now uncommonly reported and are not known to ever have been recorded. In addition to winds, tornadoes also exhibit changes in atmospheric variables such as temperature, moisture, and pressure. For example, on June 24, 2003 near Manchester, South Dakota, a probe measured a 100 mbar (hPa) (2.95 inHg) pressure decrease. The pressure dropped gradually as the vortex approached then dropped extremely rapidly to 850 mbar (hPa) (25.10 inHg) in the core of the violent tornado before rising rapidly as the vortex moved away, resulting in a V-shape pressure trace. Temperature tends to decrease and moisture content to increase in the immediate vicinity of a tornado.\n\nTornadoes often develop from a class of thunderstorms known as supercells. Supercells contain mesocyclones, an area of organized rotation a few miles up in the atmosphere, usually across. Most intense tornadoes (EF3 to EF5 on the Enhanced Fujita Scale) develop from supercells. In addition to tornadoes, very heavy rain, frequent lightning, strong wind gusts, and hail are common in such storms.\n\nMost tornadoes from supercells follow a recognizable life cycle. That begins when increasing rainfall drags with it an area of quickly descending air known as the rear flank downdraft (RFD). This downdraft accelerates as it approaches the ground, and drags the supercell's rotating mesocyclone towards the ground with it.\nAs the mesocyclone lowers below the cloud base, it begins to take in cool, moist air from the downdraft region of the storm. The convergence of warm air in the updraft and cool air causes a rotating wall cloud to form. The RFD also focuses the mesocyclone's base, causing it to draw air from a smaller and smaller area on the ground. As the updraft intensifies, it creates an area of low pressure at the surface. This pulls the focused mesocyclone down, in the form of a visible condensation funnel. As the funnel descends, the RFD also reaches the ground, fanning outward and creating a gust front that can cause severe damage a considerable distance from the tornado. Usually, the funnel cloud begins causing damage on the ground (becoming a tornado) within a few minutes of the RFD reaching the ground.\n\nInitially, the tornado has a good source of warm, moist air flowing inward to power it, and it grows until it reaches the \"mature stage\". This can last anywhere from a few minutes to more than an hour, and during that time a tornado often causes the most damage, and in rare cases can be more than one mile (1.6 km) across. The low pressured atmosphere at the base of the tornado is essential to the endurance of the system. Meanwhile, the RFD, now an area of cool surface winds, begins to wrap around the tornado, cutting off the inflow of warm air which previously fed the tornado.\n\nAs the RFD completely wraps around and chokes off the tornado's air supply, the vortex begins to weaken, and become thin and rope-like. This is the \"dissipating stage\", often lasting no more than a few minutes, after which the tornado ends. During this stage the shape of the tornado becomes highly influenced by the winds of the parent storm, and can be blown into fantastic patterns. Even though the tornado is dissipating, it is still capable of causing damage. The storm is contracting into a rope-like tube and, due to conservation of angular momentum, winds can increase at this point.\n\nAs the tornado enters the dissipating stage, its associated mesocyclone often weakens as well, as the rear flank downdraft cuts off the inflow powering it. Sometimes, in intense supercells, tornadoes can develop cyclically. As the first mesocyclone and associated tornado dissipate, the storm's inflow may be concentrated into a new area closer to the center of the storm and possibly feed a new mesocyclone. If a new mesocyclone develops, the cycle may start again, producing one or more new tornadoes. Occasionally, the old (occluded) mesocyclone and the new mesocyclone produce a tornado at the same time.\n\nAlthough this is a widely accepted theory for how most tornadoes form, live, and die, it does not explain the formation of smaller tornadoes, such as landspouts, long-lived tornadoes, or tornadoes with multiple vortices. These each have different mechanisms which influence their development—however, most tornadoes follow a pattern similar to this one.\n\nA \"multiple-vortex tornado\" is a type of tornado in which two or more columns of spinning air rotate about their own axis and at the same time around a common center. A multi-vortex structure can occur in almost any circulation, but is very often observed in intense tornadoes. These vortices often create small areas of heavier damage along the main tornado path. This is a phenomenon that is distinct from a satellite tornado, which is a smaller tornado which forms very near a large, strong tornado contained within the same mesocyclone. The satellite tornado may appear to \"orbit\" the larger tornado (hence the name), giving the appearance of one, large multi-vortex tornado. However, a satellite tornado is a distinct circulation, and is much smaller than the main funnel.\n\nA \"waterspout\" is defined by the National Weather Service as a tornado over water. However, researchers typically distinguish \"fair weather\" waterspouts from tornadic waterspouts. Fair weather waterspouts are less severe but far more common, and are similar to dust devils and landspouts. They form at the bases of cumulus congestus clouds over tropical and subtropical waters. They have relatively weak winds, smooth laminar walls, and typically travel very slowly. They occur most commonly in the Florida Keys and in the northern Adriatic Sea. In contrast, tornadic waterspouts are stronger tornadoes over water. They form over water similarly to mesocyclonic tornadoes, or are stronger tornadoes which cross over water. Since they form from severe thunderstorms and can be far more intense, faster, and longer-lived than fair weather waterspouts, they are more dangerous. In official tornado statistics, waterspouts are generally not counted unless they affect land, though some European weather agencies count waterspouts and tornadoes together.\n\nA \"landspout\", or \"dust-tube tornado\", is a tornado not associated with a mesocyclone. The name stems from their characterization as a \"fair weather waterspout on land\". Waterspouts and landspouts share many defining characteristics, including relative weakness, short lifespan, and a small, smooth condensation funnel which often does not reach the surface. Landspouts also create a distinctively laminar cloud of dust when they make contact with the ground, due to their differing mechanics from true mesoform tornadoes. Though usually weaker than classic tornadoes, they can produce strong winds which could cause serious damage.\n\nA \"gustnado\", or \"gust front tornado\", is a small, vertical swirl associated with a gust front or downburst. Because they are not connected with a cloud base, there is some debate as to whether or not gustnadoes are tornadoes. They are formed when fast moving cold, dry outflow air from a thunderstorm is blown through a mass of stationary, warm, moist air near the outflow boundary, resulting in a \"rolling\" effect (often exemplified through a roll cloud). If low level wind shear is strong enough, the rotation can be turned vertically or diagonally and make contact with the ground. The result is a gustnado. They usually cause small areas of heavier rotational wind damage among areas of straight-line wind damage.\n\nA \"dust devil\" (also known as a whirlwind) resembles a tornado in that it is a vertical swirling column of air. However, they form under clear skies and are no stronger than the weakest tornadoes. They form when a strong convective updraft is formed near the ground on a hot day. If there is enough low level wind shear, the column of hot, rising air can develop a small cyclonic motion that can be seen near the ground. They are not considered tornadoes because they form during fair weather and are not associated with any clouds. However, they can, on occasion, result in major damage.\n\nSmall-scale, tornado-like circulations can occur near any intense surface heat source. Those that occur near intense wildfires are called \"fire whirls\". They are not considered tornadoes, except in the rare case where they connect to a pyrocumulus or other cumuliform cloud above. Fire whirls usually are not as strong as tornadoes associated with thunderstorms. They can, however, produce significant damage.\n\nA \"steam devil\" is a rotating updraft between 50 and 200 meters wide that involves steam or smoke. These formations do not involve high wind speeds, only completing a few rotations per minute. Steam devils are very rare. They most often form from smoke issuing from a power plant's smokestack. Hot springs and deserts may also be suitable locations for a tighter, faster-rotating steam devil to form. The phenomenon can occur over water, when cold arctic air passes over relatively warm water.\n\nThe Fujita scale and the Enhanced Fujita Scale rate tornadoes by damage caused. The Enhanced Fujita (EF) Scale was an update to the older Fujita scale, by expert elicitation, using engineered wind estimates and better damage descriptions. The EF Scale was designed so that a tornado rated on the Fujita scale would receive the same numerical rating, and was implemented starting in the United States in 2007. An EF0 tornado will probably damage trees but not substantial structures, whereas an EF5 tornado can rip buildings off their foundations leaving them bare and even deform large skyscrapers. The similar TORRO scale ranges from a T0 for extremely weak tornadoes to T11 for the most powerful known tornadoes. Doppler weather radar data, photogrammetry, and ground swirl patterns (cycloidal marks) may also be analyzed to determine intensity and award a rating.\n\nTornadoes vary in intensity regardless of shape, size, and location, though strong tornadoes are typically larger than weak tornadoes. The association with track length and duration also varies, although longer track tornadoes tend to be stronger.<ref name=\"width/length intensity relationship\"></ref> In the case of violent tornadoes, only a small portion of the path is of violent intensity, most of the higher intensity from subvortices.\n\nIn the United States, 80% of tornadoes are EF0 and EF1 (T0 through T3) tornadoes. The rate of occurrence drops off quickly with increasing strength—less than 1% are violent tornadoes (EF4, T8 or stronger). Outside Tornado Alley, and North America in general, violent tornadoes are extremely rare. This is apparently mostly due to the lesser number of tornadoes overall, as research shows that tornado intensity distributions are fairly similar worldwide. A few significant tornadoes occur annually in Europe, Asia, southern Africa, and southeastern South America, respectively.\n\nThe United States has the most tornadoes of any country, nearly four times more than estimated in all of Europe, excluding waterspouts. This is mostly due to the unique geography of the continent. North America is a large continent that extends from the tropics north into arctic areas, and has no major east-west mountain range to block air flow between these two areas. In the middle latitudes, where most tornadoes of the world occur, the Rocky Mountains block moisture and buckle the atmospheric flow, forcing drier air at mid-levels of the troposphere due to downsloped winds, and causing the formation of a low pressure area downwind to the east of the mountains. Increased westerly flow off the Rockies force the formation of a dry line when the flow aloft is strong, while the Gulf of Mexico fuels abundant low-level moisture in the southerly flow to its east. This unique topography allows for frequent collisions of warm and cold air, the conditions that breed strong, long-lived storms throughout the year. A large portion of these tornadoes form in an area of the central United States known as Tornado Alley. This area extends into Canada, particularly Ontario and the Prairie Provinces, although southeast Quebec, the interior of British Columbia, and western New Brunswick are also tornado-prone. Tornadoes also occur across northeastern Mexico.\n\nThe United States averages about 1,200 tornadoes per year, followed by Canada, averaging 62 reported per year. NOAA's has a higher average 100 per year in Canada. The Netherlands has the highest average number of recorded tornadoes per area of any country (more than 20, or 0.0013 per sq mi (0.00048 per km), annually), followed by the UK (around 33, or 0.00035 per sq mi (0.00013 per km), per year), although those are of lower intensity, briefer and cause minor damage.\nTornadoes kill an average of 179 people per year in Bangladesh, the most in the world. Reasons for this include the region's high population density, poor construction quality, and lack of tornado safety knowledge. Other areas of the world that have frequent tornadoes include South Africa, the La Plata Basin area, portions of Europe, Australia and New Zealand, and far eastern Asia.\n\nTornadoes are most common in spring and least common in winter, but tornadoes can occur any time of year that favorable conditions occur. Spring and fall experience peaks of activity as those are the seasons when stronger winds, wind shear, and atmospheric instability are present. Tornadoes are focused in the right front quadrant of landfalling tropical cyclones, which tend to occur in the late summer and autumn. Tornadoes can also be spawned as a result of eyewall mesovortices, which persist until landfall.\n\nTornado occurrence is highly dependent on the time of day, because of solar heating. Worldwide, most tornadoes occur in the late afternoon, between 3 pm and 7 pm local time, with a peak near 5 pm. Destructive tornadoes can occur at any time of day. The Gainesville Tornado of 1936, one of the deadliest tornadoes in history, occurred at 8:30 am local time.\n\nThe United Kingdom has the highest incidence of tornadoes, measured by unit area of land, than any other country in the world. Unsettled conditions and weather fronts transverse the Islands at all times of the years and are responsible for spawning the tornadoes, which consequently form at all times of the year. The United Kingdom has at least 34 tornadoes per year and possibly as many as 50, more than any other country in the world relative to its land area. Most tornadoes in the United Kingdom are weak, but they are occasionally destructive. For example, the Birmingham tornado of 2005 and the London tornado of 2006 both registered F2 on the Fujita scale and both caused significant damage and injury.\n\nAssociations with various climate and environmental trends exist. For example, an increase in the sea surface temperature of a source region (e.g. Gulf of Mexico and Mediterranean Sea) increases atmospheric moisture content. Increased moisture can fuel an increase in severe weather and tornado activity, particularly in the cool season.\n\nSome evidence does suggest that the Southern Oscillation is weakly correlated with changes in tornado activity, which vary by season and region, as well as whether the ENSO phase is that of El Niño or La Niña. Research has found that fewer tornadoes and hailstorms occur in winter and spring in the U.S. central and southern plains during El Niño, and more occur during La Niña, than in years when temperatures in the Pacific are relatively stable. Ocean conditions could be used to forecast extreme spring storm events several months in advance.\n\nClimatic shifts may affect tornadoes via teleconnections in shifting the jet stream and the larger weather patterns. The climate-tornado link is confounded by the forces affecting larger patterns and by the local, nuanced nature of tornadoes. Although it is reasonable to suspect that global warming may affect trends in tornado activity, any such effect is not yet identifiable due to the complexity, local nature of the storms, and database quality issues. Any effect would vary by region.\n\nRigorous attempts to warn of tornadoes began in the United States in the mid-20th century. Before the 1950s, the only method of detecting a tornado was by someone seeing it on the ground. Often, news of a tornado would reach a local weather office after the storm. However, with the advent of weather radar, areas near a local office could get advance warning of severe weather. The first public tornado warnings were issued in 1950 and the first tornado watches and convective outlooks came about in 1952. In 1953, it was confirmed that hook echoes were associated with tornadoes. By recognizing these radar signatures, meteorologists could detect thunderstorms probably producing tornadoes from several miles away.\n\nToday, most developed countries have a network of weather radars, which serves as the primary method of detecting hook signatures that are likely associated with tornadoes. In the United States and a few other countries, Doppler weather radar stations are used. These devices measure the velocity and radial direction (towards or away from the radar) of the winds within a storm, and so can spot evidence of rotation in storms from over away. When storms are distant from a radar, only areas high within the storm are observed and the important areas below are not sampled. Data resolution also decreases with distance from the radar. Some meteorological situations leading to tornadogenesis are not readily detectable by radar and tornado development may occasionally take place more quickly than radar can complete a scan and send the batch of data. Doppler radar systems can detect mesocyclones within a supercell thunderstorm. This allows meteorologists to predict tornado formations throughout thunderstorms.\nIn the mid-1970s, the U.S. National Weather Service (NWS) increased its efforts to train storm spotters so they could spot key features of storms that indicate severe hail, damaging winds, and tornadoes, as well as storm damage and flash flooding. The program was called Skywarn, and the spotters were local sheriff's deputies, state troopers, firefighters, ambulance drivers, amateur radio operators, civil defense (now emergency management) spotters, storm chasers, and ordinary citizens. When severe weather is anticipated, local weather service offices request these spotters to look out for severe weather and report any tornadoes immediately, so that the office can warn of the hazard.\n\nSpotters usually are trained by the NWS on behalf of their respective organizations, and report to them. The organizations activate public warning systems such as sirens and the Emergency Alert System (EAS), and they forward the report to the NWS.\nThere are more than 230,000 trained Skywarn weather spotters across the United States.\n\nIn Canada, a similar network of volunteer weather watchers, called Canwarn, helps spot severe weather, with more than 1,000 volunteers. In Europe, several nations are organizing spotter networks under the auspices of Skywarn Europe and the Tornado and Storm Research Organisation (TORRO) has maintained a network of spotters in the United Kingdom since 1974.\n\nStorm spotters are required because radar systems such as NEXRAD do not really detect tornadoes; merely signatures which hint at the presence of tornadoes. Radar may give a warning before there is any visual evidence of a tornado or an imminent one, but ground truth from an observer can either verify the threat or determine that a tornado is not imminent. The spotter's ability to see what radar can't is especially important as distance from the radar site increases, because the radar beam becomes progressively higher in altitude further away from the radar, chiefly due to curvature of Earth, and the beam also spreads out.\n\nStorm spotters are trained to discern whether or not a storm seen from a distance is a supercell. They typically look to its rear, the main region of updraft and inflow. Under that updraft is a rain-free base, and the next step of tornadogenesis is the formation of a rotating wall cloud. The vast majority of intense tornadoes occur with a wall cloud on the backside of a supercell.\n\nEvidence of a supercell is based on the storm's shape and structure, and cloud tower features such as a hard and vigorous updraft tower, a persistent, large overshooting top, a hard anvil (especially when backsheared against strong upper level winds), and a corkscrew look or striations. Under the storm and closer to where most tornadoes are found, evidence of a supercell and the likelihood of a tornado includes inflow bands (particularly when curved) such as a \"beaver tail\", and other clues such as strength of inflow, warmth and moistness of inflow air, how outflow- or inflow-dominant a storm appears, and how far is the front flank precipitation core from the wall cloud. Tornadogenesis is most likely at the interface of the updraft and rear flank downdraft, and requires a balance between the outflow and inflow.\n\nOnly wall clouds that rotate spawn tornadoes, and they usually precede the tornado between five and thirty minutes. Rotating wall clouds may be a visual manifestation of a low-level mesocyclone. Barring a low-level boundary, tornadogenesis is highly unlikely unless a rear flank downdraft occurs, which is usually visibly evidenced by evaporation of cloud adjacent to a corner of a wall cloud. A tornado often occurs as this happens or shortly afterwards; first, a funnel cloud dips and in nearly all cases by the time it reaches halfway down, a surface swirl has already developed, signifying a tornado is on the ground before condensation connects the surface circulation to the storm. Tornadoes may also develop without wall clouds, under flanking lines and on the leading edge. Spotters watch all areas of a storm, and the cloud base and surface.\n\nThe most record-breaking tornado in recorded history was the Tri-State Tornado, which roared through parts of Missouri, Illinois, and Indiana on March 18, 1925. It was likely an F5, though tornadoes were not ranked on any scale in that era. It holds records for longest path length (), longest duration (about 3.5 hours), and fastest forward speed for a significant tornado () anywhere on Earth. In addition, it is the deadliest single tornado in United States history (695 dead). The tornado was also the costliest tornado in history at the time (unadjusted for inflation), but in the years since has been surpassed by several others if population changes over time are not considered. When costs are normalized for wealth and inflation, it ranks third today.\n\nThe deadliest tornado in world history was the Daultipur-Salturia Tornado in Bangladesh on April 26, 1989, which killed approximately 1,300 people. Bangladesh has had at least 19 tornadoes in its history kill more than 100 people, almost half of the total in the rest of the world.\n\nThe most extensive tornado outbreak on record was the 2011 Super Outbreak, which spawned 360 confirmed tornadoes over the southeastern United States – 216 of them within a single 24-hour period. The previous record was the 1974 Super Outbreak which spawned 148 tornadoes.\n\nWhile direct measurement of the most violent tornado wind speeds is nearly impossible, since conventional anemometers would be destroyed by the intense winds and flying debris, some tornadoes have been scanned by mobile Doppler radar units, which can provide a good estimate of the tornado's winds. The highest wind speed ever measured in a tornado, which is also the highest wind speed ever recorded on the planet, is 301 ± 20 mph (484 ± 32 km/h) in the F5 Bridge Creek-Moore, Oklahoma, tornado which killed 36 people. Though the reading was taken about above the ground, this is a testament to the power of the strongest tornadoes.\n\nStorms that produce tornadoes can feature intense updrafts, sometimes exceeding . Debris from a tornado can be lofted into the parent storm and carried a very long distance. A tornado which affected Great Bend, Kansas, in November 1915, was an extreme case, where a \"rain of debris\" occurred from the town, a sack of flour was found away, and a cancelled check from the Great Bend bank was found in a field outside of Palmyra, Nebraska, to the northeast. Waterspouts and tornadoes have been advanced as an explanation for instances of raining fish and other animals.\n\nThough tornadoes can strike in an instant, there are precautions and preventative measures that people can take to increase the chances of surviving a tornado. Authorities such as the Storm Prediction Center advise having a pre-determined plan should a tornado warning be issued. When a warning is issued, going to a basement or an interior first-floor room of a sturdy building greatly increases chances of survival. In tornado-prone areas, many buildings have storm cellars on the property. These underground refuges have saved thousands of lives.\n\nSome countries have meteorological agencies which distribute tornado forecasts and increase levels of alert of a possible tornado (such as tornado watches and warnings in the United States and Canada). Weather radios provide an alarm when a severe weather advisory is issued for the local area, though these are mainly available only in the United States. Unless the tornado is far away and highly visible, meteorologists advise that drivers park their vehicles far to the side of the road (so as not to block emergency traffic), and find a sturdy shelter. If no sturdy shelter is nearby, getting low in a ditch is the next best option. Highway overpasses are one of the worst places to take shelter during tornadoes, as the constricted space can be subject to increased wind speed and funneling of debris underneath the overpass.\n\nFolklore often identifies a green sky with tornadoes, and though the phenomenon may be associated with severe weather, there is no evidence linking it specifically with tornadoes. It is often thought that opening windows will lessen the damage caused by the tornado. While there is a large drop in atmospheric pressure inside a strong tornado, it is unlikely that the pressure drop would be enough to cause the house to explode. Opening windows may actually increase the severity of the tornado's damage. A violent tornado can destroy a house whether its windows are open or closed.\n\nAnother commonly held misconception is that highway overpasses provide adequate shelter from tornadoes. This belief is partly inspired by widely circulated video captured during the 1991 tornado outbreak near Andover, Kansas, where a news crew and several other people take shelter under an overpass on the Kansas Turnpike and safely ride out a tornado as it passes by. However, a highway overpass is a dangerous place during a tornado, and the subjects of the video remained safe due to an unlikely combination of events: the storm in question was a weak tornado, the tornado did not directly strike the overpass, and the overpass itself was of a unique design. Due to the Venturi effect, tornadic winds are accelerated in the confined space of an overpass. Indeed, in the 1999 Oklahoma tornado outbreak of May 3, 1999, three highway overpasses were directly struck by tornadoes, and at each of the three locations there was a fatality, along with many life-threatening injuries. By comparison, during the same tornado outbreak, more than 2000 homes were completely destroyed, with another 7000 damaged, and yet only a few dozen people died in their homes.\n\nAn old belief is that the southwest corner of a basement provides the most protection during a tornado. The safest place is the side or corner of an underground room opposite the tornado's direction of approach (usually the northeast corner), or the central-most room on the lowest floor. Taking shelter in a basement, under a staircase, or under a sturdy piece of furniture such as a workbench further increases chances of survival.\n\nThere are areas which people believe to be protected from tornadoes, whether by being in a city, near a major river, hill, or mountain, or even protected by supernatural forces. Tornadoes have been known to cross major rivers, climb mountains, affect valleys, and have damaged several city centers. As a general rule, no area is safe from tornadoes, though some areas are more susceptible than others.\n\nMeteorology is a relatively young science and the study of tornadoes is newer still. Although researched for about 140 years and intensively for around 60 years, there are still aspects of tornadoes which remain a mystery. Scientists have a fairly good understanding of the development of thunderstorms and mesocyclones, and the meteorological conditions conducive to their formation. However, the step from supercell, or other respective formative processes, to tornadogenesis and the prediction of tornadic vs. non-tornadic mesocyclones is not yet well known and is the focus of much research.\n\nAlso under study are the low-level mesocyclone and the stretching of low-level vorticity which tightens into a tornado, in particular, what are the processes and what is the relationship of the environment and the convective storm. Intense tornadoes have been observed forming simultaneously with a mesocyclone aloft (rather than succeeding mesocyclogenesis) and some intense tornadoes have occurred without a mid-level mesocyclone.\n\nIn particular, the role of downdrafts, particularly the rear-flank downdraft, and the role of baroclinic boundaries, are intense areas of study.\n\nReliably predicting tornado intensity and longevity remains a problem, as do details affecting characteristics of a tornado during its life cycle and tornadolysis. Other rich areas of research are tornadoes associated with mesovortices within linear thunderstorm structures and within tropical cyclones.\n\nScientists still do not know the exact mechanisms by which most tornadoes form, and occasional tornadoes still strike without a tornado warning being issued. Analysis of observations including both stationary and mobile (surface and aerial) in-situ and remote sensing (passive and active) instruments generates new ideas and refines existing notions. Numerical modeling also provides new insights as observations and new discoveries are integrated into our physical understanding and then tested in computer simulations which validate new notions as well as produce entirely new theoretical findings, many of which are otherwise unattainable. Importantly, development of new observation technologies and installation of finer spatial and temporal resolution observation networks have aided increased understanding and better predictions.\n\nResearch programs, including field projects such as the VORTEX projects (Verification of the Origins of Rotation in Tornadoes Experiment), deployment of TOTO (the TOtable Tornado Observatory), Doppler On Wheels (DOW), and dozens of other programs, hope to solve many questions that still plague meteorologists. Universities, government agencies such as the National Severe Storms Laboratory, private-sector meteorologists, and the National Center for Atmospheric Research are some of the organizations very active in research; with various sources of funding, both private and public, a chief entity being the National Science Foundation. The pace of research is partly constrained by the number of observations that can be taken; gaps in information about the wind, pressure, and moisture content throughout the local atmosphere; and the computing power available for simulation.\n\nSolar storms similar to tornadoes have been recorded, but it is unknown how closely related they are to their terrestrial counterparts.\n\n\n"}
{"id": "700016", "url": "https://en.wikipedia.org/wiki?curid=700016", "title": "Warlord (comics)", "text": "Warlord (comics)\n\nThe Warlord is a sword and sorcery character appearing in American comic books published by DC Comics. Created by writer-artist Mike Grell, he debuted in \"1st Issue Special\" #8 (Nov. 1975). The titular character, Travis Morgan, obtains the name \"Warlord\" as he fights for the freedom of the people of Skartaris.\n\nThe character the Warlord debuted in \"1st Issue Special\" #8 (cover-dated Nov. 1975). The decision to give the Warlord his own series had already been made by the time his \"1st Issue Special\" debut went into production. He starred in \"The Warlord\" #1 (Feb. 1976), followed by an eight-month hiatus after issue #2, picking up again with #3 (Nov. 1976). The title lasted 133 issues until Winter 1988. Creator Mike Grell wrote and drew the comic for six years, handing over the art chores after issue #59 (July 1982); he continued writing the series through issue #71 (July 1983).\n\nA continuation of Jack Kirby's \"OMAC\" series, by Jim Starlin, was featured as a backup for several issues (#37–39 and #42–47). \"Arak, Son of Thunder\", created by Roy Thomas and Ernie Colón, first appeared in a special insert in \"The Warlord\" #48 (Aug. 1981). Claw the Unconquered appeared in a two–part backup feature in issues #48–49 by Jack C. Harris and Thomas Yeates. \"Dragonsword\" was a backup feature by Paul Levitz and Yeates which appeared in #51–54 (Nov. 1981–Feb. 1982). \"Arion\", a sword and sorcery title by writer Paul Kupperberg and artist Jan Duursema, began as a six–page backup feature in \"The Warlord\" #55 (March 1982). Another backup feature was \"The Barren Earth\" by writer Gary Cohn and artist Ron Randall, which was concluded in a four–issue limited series. A Bonus Book in issue #131 (Sept. 1988) featured artist Rob Liefeld's first work for DC.\n\nA six-issue miniseries ran cover-dated January to June 1992. It was written by Mike Grell and pencilled by Dameon Willich, with inks by Rick Hoberg (#1-3) and Tim Burgard (#4-6).\n\nDC attempted to update \"The Warlord\" in 2006 with Bruce Jones writing and Bart Sears providing the art. This series restarted the concept, beginning with Travis Morgan arriving in Skartaris. The series left a number of story points unanswered as issue #9 finished on a cliffhanger, while the tenth and final issue had a standalone story set sometime in the future.\n\nDC announced in July 2008 that \"The Warlord\" would return in an ongoing series written by Mike Grell in time for the original series' 35th anniversary. The series started in April 2009, featuring art by Joe Prado and Chad Hardin. It ran for 16 issues.\n\nVietnam War veteran SR-71 pilot Travis Morgan passed through a hole in the Earth's crust while flying over the north pole in 1969 and landed in the underground world of Skartaris, a place strongly reminiscent of Edgar Rice Burroughs's Pellucidar. There Travis, wielding his .44 AutoMag pistol and joined by Shamballah's Princess (later Queen) Tara, a scantily dressed savage, became The Warlord and fought villains such as the evil sorcerer Deimos as well as various kings. He gained various sidekicks such as Machiste, Shakira, a Russian scientist named Mariah and his magic-wielding daughter Jennifer Morgan. In one story arc, Morgan even becomes the U.S. President in the far future.\n\nAlthough The Warlord has a superficial resemblance to Oliver Queen, he is in reality based more upon his creator Mike Grell who was a former member of the Air Force. Grell is caricatured in The Warlord's first appearance, \"1st Issue Special\" #8 and is clearly sporting The Warlord's signature shaggy goatee. Grell and editor Jack C. Harris made a metafictional appearance in the story \"Gambit\" in \"The Warlord\" #35 (July 1980).\n\nVolume 4 of the series begins with an explorer finding perfectly preserved dinosaur remains in the Himalayas. She takes the head of one to a doctor and an expedition is set up to retrieve more samples. The team is spotted by the Chinese government and flee into the caves after losing several members. They discover a portal and after walking through find themselves in Skartaris where they encounter Travis Morgan. Travis Morgan is attacked by a giant bird and kills it with the help of Shakira. Refugees enter Shamballah and Morgan discovers that a new god has taken over the Shadow Kingdom and has overrun the Kingdom of Kiro, Machiste's homeland. One of the refugees is injured and he surprisingly carries a gunshot wound.\n\nThe machinations of Deimos' return pit Travis Morgan against Tinder. Just as Morgan realizes that Tinder is in fact his son Joshua, he becomes distracted and Tinder mortally wounds him. Travis Morgan's final words were \"I thought I'd have more time.\" Morgan is cremated and Tinder becomes the new Warlord.\n\nJoshua Morgan becomes the new Warlord. His costume is reminiscent of Travis Morgan's black outfit when he first arrived in Skartaris. Instead of carrying a sword and a gun as Travis did, Tinder carries a sword, a dagger, a quiver of arrows and a bow.\n\nIn the alternate timeline of the \"Flashpoint\" storyline, The Warlord is the pirate of a fleet when he was attacked by pirate Deathstroke in battle stealing their loot. During the battle, The Warlord's crew was killed while he escaped using the hovercraft. Later, The Warlord plans to attack Deathstroke and retrieve Jenny Blitz who has been in stasis since she was stolen from him. The Warlord ambushed Deathstroke and his fleet and demanded that they surrender. But in answer Deathstroke shot The Warlord's right eye using a scoped sniper rifle. He had been aiming for his mouth. Deathstroke fired at The Warlord's ship again, and it unexpectedly blew up. Each ship in Warlord's fleet subsequently exploded. The ships were destroyed by Jenny Blitz, now released from her stasis tube due to an earlier skirmish between Ocean Master and Icicle, one of Deathstroke's crewmen. Jenny appears to be able to project explosive force from her hands.\n\nThe Warlord appeared in the \"Justice League Unlimited\" episode \"Chaos at the Earth's Core\" voiced by Paul Guilfoyle. Green Lantern, Supergirl, Stargirl, and S.T.R.I.P.E. stumbled onto Skartaris and teamed up with him to stop Deimos and his unlikely allies Metallo and Silver Banshee of the Secret Society from stealing a huge piece of kryptonite rock. The Warlord dueled with Deimos, ending with Deimos plummeting down a ledge. Tara, Machiste, Mariah, Shakira, and Jennifer Morgan also appeared in this episode.\n\n\n\"The Warlord\" issue #89 (Jan. 1985) appears on a magazine rack in a convenience store in a deleted scene from \"The Goonies\" DVD.\n\n\n"}
{"id": "427992", "url": "https://en.wikipedia.org/wiki?curid=427992", "title": "Water hammer", "text": "Water hammer\n\nWater hammer (or, more generally, fluid hammer, also called hydraulic shock) is a pressure surge or wave caused when a fluid, usually a liquid but sometimes also a gas, in motion is forced to stop or change direction suddenly, a momentum change. A water hammer commonly occurs when a valve closes suddenly at an end of a pipeline system, and a pressure wave propagates in the pipe.\n\nThis pressure wave can cause major problems, from noise and vibration to pipe collapse. It is possible to reduce the effects of the water hammer pulses with accumulators, expansion tanks, surge tanks, blowoff valves, and other features.\n\nRough calculations can be made either using the Zhukovsky (Joukowsky) equation, or more accurate ones using the method of characteristics.\n\nIn the 1st century B.C., Marcus Vitruvius Pollio described the effect of water hammer in lead pipes and stone tubes of the Roman public water supply. Water hammer was exploited before there was even a word for it; in 1772, Englishman John Whitehurst built a hydraulic ram for a home in Cheshire, England. In 1796, French inventor Joseph Michel Montgolfier (1740–1810) built a hydraulic ram for his paper mill in Voiron. In French and Italian, the terms for \"water hammer\" come from the hydraulic ram: \"coup de bélier\" (French) and \"colpo d'ariete\" (Italian) both mean \"blow of the ram\". As the 19th century witnessed the installation of municipal water supplies, water hammer became a concern to civil engineers. Water hammer also interested physiologists who were studying the circulatory system.\n\nAlthough it was prefigured in work by Thomas Young, the theory of water hammer is generally considered to have begun in 1883 with the work of German physiologist Johannes von Kries (1853–1928), who was investigating the pulse in blood vessels. However, his findings went unnoticed by civil engineers. Kries's findings were subsequently derived independently in 1898 by the Russian fluid dynamicist Nikolay Yegorovich Zhukovsky (1847–1921), in 1898 by the American civil engineer Joseph Palmer Frizell (1832–1910), and in 1902 by the Italian engineer Lorenzo Allievi (1856–1941).\n\nWhen a pipe is suddenly closed at the outlet (downstream), the mass of water before the closure is still moving, thereby building up high pressure and a resulting shock wave. In domestic plumbing this is experienced as a loud banging resembling a hammering noise. Water hammer can cause pipelines to break if the pressure is high enough. Air traps or stand pipes (open at the top) are sometimes added as to water systems to absorb the potentially damaging forces caused by the moving water.\n\nIn hydroelectric generating stations, the water traveling along the tunnel or pipeline may be prevented from entering a turbine by closing a valve. For example, if there is 14 km of tunnel of 7.7 m diameter full of water travelling at 3.75 m/s, that represents approximately 8000 megajoules of kinetic energy that must be arrested. This arresting is frequently achieved by a surge shaft open at the top, into which the water flows. As the water rises up the shaft its kinetic energy is converted into potential energy, which causes the water in the tunnel to decelerate. At some HEP stations, such as the Saxon Falls Hydro Power Plant In Michigan, what looks like a water tower is actually one of these devices, known in these cases as a surge drum.\n\nIn the home, a water hammer may occur when a dishwasher, washing machine or toilet shuts off water flow. The result may be heard as a loud bang, repetitive banging (as the shock wave travels back and forth in the plumbing system), or as some shuddering.\n\nOn the other hand, when an upstream valve in a pipe closes, water downstream of the valve attempts to continue flowing creating a vacuum that may cause the pipe to collapse or implode. This problem can be particularly acute if the pipe is on a downhill slope. To prevent this, air and vacuum relief valves or air vents are installed just downstream of the valve to allow air to enter the line to prevent this vacuum from occurring.\n\nOther causes of water hammer are pump failure and check valve slam (due to sudden deceleration, a check valve may slam shut rapidly, depending on the dynamic characteristic of the check valve and the mass of the water between a check valve and tank). To alleviate this situation, it is recommended to install non-slam check valves as they do not rely on gravity or fluid flow for their closure. For vertical pipes, other suggestions include installing new piping that can be designed to include air chambers to alleviate the possible shockwave of water due to excess water flow.\n\nSteam distribution systems may also be vulnerable to a situation similar to water hammer, known as \"steam hammer\". In a steam system, a water hammer most often occurs when some of the steam condenses into water in a horizontal section of the piping. Steam picks up the water, forming a \"slug\", and hurls this at high velocity into a pipe fitting, creating a loud hammering noise and greatly stressing the pipe. This condition is usually caused by a poor condensate drainage strategy.\n\nWhere air filled traps are used, these eventually become depleted of their trapped air over a long period through absorption into the water. This can be cured by shutting off the supply, opening taps at the highest and lowest locations to drain the system (thereby restoring air to the traps), and then closing the taps and re-opening the supply.\n\nOn turbocharged internal combustion engines, a fluid hammer can take place when the throttle is closed while the turbocharger is forcing air into the engine. A pressure relief valve placed before the throttle prevents the air from surging against the throttle body by diverting it elsewhere, thus protecting the turbocharger from pressure damage. This valve can either recirculate the air into the turbocharger's intake (recirculation valve), or it can blow the air into the atmosphere and produce the distinctive hiss-flutter of an aftermarket turbocharger (blowoff valve).\n\nIf a stream of high pressure water impinges on a surface, water hammer can quickly erode and destroy it. In the 2009 Sayano–Shushenskaya hydroelectric power station accident, the lid to a 640 MW turbine was ejected upwards, hitting the ceiling above. During the accident, the rotor was seen flying through the air, still spinning, about 3 meters above the floor. Unrestrained, per second of water began to spray all over the generator hall. The geyser caused the structural failure of steel ceiling joists, precipitating a roof collapse around the failed turbine.\n\nWhen an explosion happens in an enclosed space, water hammer can cause the walls of the container to deform. However, it can also impart momentum to the enclosure if it is free to move. An underwater explosion in the SL-1 nuclear reactor vessel caused the water to accelerate upwards through of air before it struck the vessel head at with a pressure of . This pressure wave caused the steel vessel to jump 9 feet 1 inch (2.77 m) into the air before it dropped into its prior location. It is imperative to perform ongoing preventative maintenance to avoid water hammer as the results of these powerful explosions have resulted in fatalities.\n\nWater hammer has caused accidents and fatalities, but usually damage is limited to breakage of pipes or appendages. An engineer should always assess the risk of a pipeline burst. Pipelines transporting hazardous liquids or gases warrant special care in design, construction, and operation. Hydroelectric power plants especially must be carefully designed and maintained because the water hammer can cause water pipes to fail catastrophically.\n\nThe following characteristics may reduce or eliminate water hammer:\n\nOne of the first to successfully investigate the water hammer problem was the Italian engineer Lorenzo Allievi.\n\nWater hammer can be analyzed by two different approaches—\"rigid column theory\", which ignores compressibility of the fluid and elasticity of the walls of the pipe, or by a full analysis that includes elasticity. When the time it takes a valve to close is long compared to the propagation time for a pressure wave to travel the length of the pipe, then rigid column theory is appropriate; otherwise considering elasticity may be necessary.\nBelow are two approximations for the peak pressure, one that considers elasticity, but assumes the valve closes instantaneously, and a second that neglects elasticity but includes a finite time for the valve to close.\n\nThe pressure profile of the water hammer pulse can be calculated from the Joukowsky equation\n\nSo for a valve closing instantaneously, the maximum magnitude of the water hammer pulse is:\n\nwhere Δ\"P\" is the magnitude of the pressure wave (Pa), \"ρ\" is the density of the fluid (kg m), \"a\" is the speed of sound in the fluid (ms), and Δ\"v\" is the change in the fluid's velocity (ms). The pulse comes about due to Newton's laws of motion and the continuity equation applied to the deceleration of a fluid element.\n\nAs the speed of sound in a fluid is formula_3, the peak pressure depends on the fluid compressibility if the valve is closed abruptly.\n\nwhere\n\nWhen the valve is closed slowly compared to the transit time for a pressure wave to travel the length of the pipe, the elasticity can be neglected, and the phenomenon can be described in terms of inertance or rigid column theory:\n\nAssuming constant deceleration of the water column (\"dv\"/\"dt\" = \"v\"/\"t\"), gives:\n\nwhere:\n\nThe above formula becomes, for water and with imperial unit: P = 0.0135 V L/t.\nFor practical application, a safety factor of about 5 is recommended:\n\nwhere \"P\" is the inlet pressure in psi, \"V\" is the flow velocity in ft/sec, \"t\" is the valve closing time in seconds and \"L\" is the upstream pipe length in feet.\n\nWhen a valve with a volumetric flow rate Q is closed, an excess pressure ΔP is created upstream of the valve, whose value is given by the Joukowsky equation:\n\nIn this expression:\nThe hydraulic impedance \"Z\" of the pipeline determines the magnitude of the water hammer pulse. It is itself defined by:\n\nwith:\n\nThe latter follows from a series of hydraulic concepts: \n\nThus, the equivalent elasticity is the sum of the original elasticities:\n\nAs a result, we see that we can reduce the water hammer by:\n\nThe water hammer effect can be simulated by solving the following partial differential equations.\n\nwhere \"V\" is the fluid velocity inside pipe, \"formula_15\" is the fluid density and \"B\" is the equivalent bulk modulus, \"f\" is the Darcy-Weisbach friction factor.\n\nColumn separation is a phenomenon that can occur during a water-hammer event. If the pressure in a pipeline drops below the vapor pressure of the liquid, cavitation will occur (some of the liquid vaporizes, forming a bubble in the pipeline, keeping the pressure close to the vapor pressure). This is most likely to occur at specific locations such as closed ends, high points or knees (changes in pipe slope). When subcooled liquid flows into the space previously occupied by vapor the area of contact between the vapor and the liquid increases. This causes the vapor to condense into the liquid reducing the pressure in the vapor space. The liquid on either side of the vapor space is then accelerated into this space by the pressure difference. The collision of the two columns of liquid (or of one liquid column if at a closed end) causes a large and nearly instantaneous rise in pressure. This pressure rise can damage hydraulic machinery, individual pipes and supporting structures. Many repetitions of cavity formation and collapse may occur in a single water-hammer event.\n\nMost water hammer software packages use the method of characteristics to solve the differential equations involved. This method works well if the wave speed does not vary in time due to either air or gas entrainment in a pipeline. The Wave Method (WM) is also used in various software packages. WM lets operators analyze large networks efficiently. Many commercial and non commercial packages are available.\n\nSoftware packages vary in complexity, dependent on the processes modeled. The more sophisticated packages may have any of the following features:\n\n\n\n"}
{"id": "761974", "url": "https://en.wikipedia.org/wiki?curid=761974", "title": "Wave power", "text": "Wave power\n\nWave power is the capture of energy of wind waves to do useful work – for example, electricity generation, water desalination, or pumping water. A machine that exploits wave power is a wave energy converter (WEC).\n\nWave power is distinct from tidal power, which captures the energy of the current caused by the gravitational pull of the Sun and Moon. Waves and tides are also distinct from ocean currents which are caused by other forces including breaking waves, wind, the Coriolis effect, cabbeling, and differences in temperature and salinity.\n\nWave-power generation is not a widely employed commercial technology, although there have been attempts to use it since at least 1890.\n\nIn 2000 the world's first commercial Wave Power Device, the Islay LIMPET was installed on the coast of Islay in Scotland and connected to the National Grid. In 2008, the first experimental multi-generator wave farm was opened in Portugal at the Aguçadoura Wave Park.\n\nWaves are generated by wind passing over the surface of the sea. As long as the waves propagate slower than the wind speed just above the waves, there is an energy transfer from the wind to the waves. Both air pressure differences between the upwind and the lee side of a wave crest, as well as friction on the water surface by the wind, making the water to go into the shear stress causes the growth of the waves.\n\nWave height is determined by wind speed, the duration of time the wind has been blowing, fetch (the distance over which the wind excites the waves) and by the depth and topography of the seafloor (which can focus or disperse the energy of the waves). A given wind speed has a matching practical limit over which time or distance will not produce larger waves. When this limit has been reached the sea is said to be \"fully developed\".\n\nIn general, larger waves are more powerful but wave power is also determined by wave speed, wavelength, and water density.\n\nOscillatory motion is highest at the surface and diminishes exponentially with depth. However, for standing waves (clapotis) near a reflecting coast, wave energy is also present as pressure oscillations at great depth, producing microseisms. These pressure fluctuations at greater depth are too small to be interesting from the point of view of wave power.\n\nThe waves propagate on the ocean surface, and the wave energy is also transported horizontally with the group velocity. The mean transport rate of the wave energy through a vertical plane of unit width, parallel to a wave crest, is called the wave energy flux (or wave power, which must not be confused with the actual power generated by a wave power device).\n\nIn deep water where the water depth is larger than half the wavelength, the wave energy flux is\n\nwith \"P\" the wave energy flux per unit of wave-crest length, \"H\" the significant wave height, \"T\" the wave energy period, \"ρ\" the water density and \"g\" the acceleration by gravity. The above formula states that wave power is proportional to the wave energy period and to the square of the wave height. When the significant wave height is given in metres, and the wave period in seconds, the result is the wave power in kilowatts (kW) per metre of wavefront length.\n\nExample: Consider moderate ocean swells, in deep water, a few km off a coastline, with a wave height of 3 m and a wave energy period of 8 seconds. Using the formula to solve for power, we get\n\nmeaning there are 36 kilowatts of power potential per meter of wave crest.\n\nIn major storms, the largest waves offshore are about 15 meters high and have a period of about 15 seconds. According to the above formula, such waves carry about 1.7 MW of power across each metre of wavefront.\n\nAn effective wave power device captures as much as possible of the wave energy flux. As a result, the waves will be of lower height in the region behind the wave power device.\n\nIn a sea state, the average(mean) energy density per unit area of gravity waves on the water surface is proportional to the wave height squared, according to linear wave theory:\n\nwhere \"E\" is the mean wave energy density per unit horizontal area (J/m), the sum of kinetic and potential energy density per unit horizontal area. The potential energy density is equal to the kinetic energy, both contributing half to the wave energy density \"E\", as can be expected from the equipartition theorem. In ocean waves, surface tension effects are negligible for wavelengths above a few decimetres.\n\nAs the waves propagate, their energy is transported. The energy transport velocity is the group velocity. As a result, the wave energy flux, through a vertical plane of unit width perpendicular to the wave propagation direction, is equal to:\n\nwith \"c\" the group velocity (m/s).\nDue to the dispersion relation for water waves under the action of gravity, the group velocity depends on the wavelength \"λ\", or equivalently, on the wave period \"T\". Further, the dispersion relation is a function of the water depth \"h\". As a result, the group velocity behaves differently in the limits of deep and shallow water, and at intermediate depths:\n\nDeep water corresponds with a water depth larger than half the wavelength, which is the common situation in the sea and ocean. In deep water, longer-period waves propagate faster and transport their energy faster. The deep-water group velocity is half the phase velocity. In shallow water, for wavelengths larger than about twenty times the water depth, as found quite often near the coast, the group velocity is equal to the phase velocity.\n\nThe first known patent to use energy from ocean waves dates back to 1799, and was filed in Paris by Girard and his son. An early application of wave power was a device constructed around 1910 by Bochaux-Praceique to light and power his house at Royan, near Bordeaux in France. It appears that this was the first oscillating water-column type of wave-energy device. From 1855 to 1973 there were already 340 patents filed in the UK alone.\n\nModern scientific pursuit of wave energy was pioneered by Yoshio Masuda's experiments in the 1940s. He tested various concepts of wave-energy devices at sea, with several hundred units used to power navigation lights. Among these was the concept of extracting power from the angular motion at the joints of an articulated raft, which was proposed in the 1950s by Masuda.\n\nA renewed interest in wave energy was motivated by the oil crisis in 1973. A number of university researchers re-examined the potential to generate energy from ocean waves, among whom notably were Stephen Salter from the University of Edinburgh, Kjell Budal and Johannes Falnes from Norwegian Institute of Technology (now merged into Norwegian University of Science and Technology), Michael E. McCormick from U.S. Naval Academy, David Evans from Bristol University, Michael French from University of Lancaster, Nick Newman and C. C. Mei from MIT.\n\nStephen Salter's 1974 invention became known as Salter's duck or \"nodding duck\", although it was officially referred to as the Edinburgh Duck. In small scale controlled tests, the Duck's curved cam-like body can stop 90% of wave motion and can convert 90% of that to electricity giving 81% efficiency.\n\nIn the 1980s, as the oil price went down, wave-energy funding was drastically reduced. Nevertheless, a few first-generation prototypes were tested at sea. More recently, following the issue of climate change, there is again a growing interest worldwide for renewable energy, including wave energy.\n\nThe world's first marine energy test facility was established in 2003 to kick-start the development of a wave and tidal energy industry in the UK. Based in Orkney, Scotland, the European Marine Energy Centre (EMEC) has supported the deployment of more wave and tidal energy devices than at any other single site in the world. EMEC provides a variety of test sites in real sea conditions. Its grid-connected wave test site is situated at Billia Croo, on the western edge of the Orkney mainland, and is subject to the full force of the Atlantic Ocean with seas as high as 19 metres recorded at the site. Wave energy developers currently testing at the centre include Aquamarine Power, Pelamis Wave Power, ScottishPower Renewables and Wello.\n\nWave power devices are generally categorized by the method used to capture the energy of the waves, by location and by the power take-off system. Locations are shoreline, nearshore and offshore. Types of power take-off include: hydraulic ram, elastomeric hose pump, pump-to-shore, hydroelectric turbine, air turbine, and linear electrical generator. When evaluating wave energy as a technology type, it is important to distinguish between the four most common approaches: point absorber buoys, surface attenuators, oscillating water columns, and overtopping devices.\n\nThis device floats on the surface of the water, held in place by cables connected to the seabed. The point-absorber is deﬁned as having a device width much smaller than the incoming wavelength λ. A good point absorber has the same characteristics as a good wave-maker. The wave energy is absorbed by radiating a wave with destructive interference to the incoming waves. Buoys use the rise and fall of swells to generate electricity in various ways including directly via linear generators, or via generators driven by mechanical linear-to-rotary converters or hydraulic pumps. EMF generated by electrical transmission cables and acoustics of these devices may be a concern for marine organisms. The presence of the buoys may affect fish, marine mammals, and birds as potential minor collision risk and roosting sites. Potential also exists for entanglement in mooring lines. Energy removed from the waves may also affect the shoreline, resulting in a recommendation that sites remain a considerable distance from the shore.\n\nThese devices act similarly to point absorber buoys, with multiple floating segments connected to one another and are oriented perpendicular to incoming waves. A flexing motion is created by swells that drive hydraulic pumps to generate electricity. Environmental effects are similar to those of point absorber buoys, with an additional concern that organisms could be pinched in the joints.\n\nThese devices typically have one end fixed to a structure or the seabed while the other end is free to move. Energy is collected from the relative motion of the body compared to the fixed point. Oscillating wave surge converters often come in the form of floats, flaps, or membranes. Environmental concerns include minor risk of collision, artificial reefing near the fixed point, EMF effects from subsea cables, and energy removal effecting sediment transport. Some of these designs incorporate parabolic reflectors as a means of increasing the wave energy at the point of capture. These capture systems use the rise and fall motion of waves to capture energy. Once the wave energy is captured at a wave source, power must be carried to the point of use or to a connection to the electrical grid by transmission power cables.\n\nOscillating Water Column devices can be located on shore or in deeper waters offshore. With an air chamber integrated into the device, swells compress air in the chambers forcing air through an air turbine to create electricity. Significant noise is produced as air is pushed through the turbines, potentially affecting birds and other marine organisms within the vicinity of the device. There is also concern about marine organisms getting trapped or entangled within the air chambers.\n\nOvertopping devices are long structures that use wave velocity to fill a reservoir to a greater water level than the surrounding ocean. The potential energy in the reservoir height is then captured with low-head turbines. Devices can be either on shore or floating offshore. Floating devices will have environmental concerns about the mooring system affecting benthic organisms, organisms becoming entangled, or EMF effects produced from subsea cables. There is also some concern regarding low levels of turbine noise and wave energy removal affecting the nearfield habitat.\n\nSubmerged pressure differential based converters are a comparatively newer technology utilizing flexible (usually reinforced rubber) membranes to extract wave energy. These converters use the difference in pressure at different locations below a wave to produce a pressure difference within a closed power take-off fluid system. This pressure difference is usually used to produce flow, which drives a turbine and electrical generator. Submerged pressure differential converters frequently use flexible membranes as the working surface between the ocean and the power take-off system. Membranes offer the advantage over rigid structures of being compliant and low mass, which can produce more direct coupling with the wave’s energy. Their compliant nature also allows for large changes in the geometry of the working surface, which can be used to tune the response of the converter for specific wave conditions and to protect it from excessive loads in extreme conditions.\n\nA submerged converter may be positioned either on the sea floor or in midwater. In both cases, the converter is protected from water impact loads which can occur at the free surface. Wave loads also diminish in non-linear proportion to the distance below the free surface. This means that by optimizing the depth of submergence for such a converter, a compromise between protection from extreme loads and access to wave energy can be found. Submerged WECs also have the potential to reduce the impact on marine amenity and navigation, as they are not at the surface. Examples of submerged pressure differential converters include M3 Wave, Bombora Wave Power's mWave, and CalWave.\n\nCommon environmental concerns associated with marine energy developments include:\n\n\nThe Tethys database provides access to scientific literature and general information on the potential environmental effects of wave energy.\n\nThe worldwide resource of coastal wave energy has been estimated to be greater than 2 TW.\nLocations with the most potential for wave power include the western seaboard of Europe, the northern coast of the UK, and the Pacific coastlines of North and South America, Southern Africa, Australia, and New Zealand. The north and south temperate zones have the best sites for capturing wave power. The prevailing westerlies in these zones blow strongest in winter.\n\nThere is a potential impact on the marine environment. Noise pollution, for example, could have negative impact if not monitored, although the noise and visible impact of each design vary greatly. Other biophysical impacts (flora and fauna, sediment regimes and water column structure and flows) of scaling up the technology are being studied. In terms of socio-economic challenges, wave farms can result in the displacement of commercial and recreational fishermen from productive fishing grounds, can change the pattern of beach sand nourishment, and may represent hazards to safe navigation. Waves generate about 2,700 gigawatts of power. Of those 2,700 gigawatts, only about 500 gigawatts can be captured with the current technology. Since 2008, Seabased Industry AB (SIAB) has deployed several units of wave energy converters (WECs) manufactured with different designs. Offshore deployments of WECs and underswater substation are being complicated procedures. SIAB discussed these deployments in terms of economy and time efficiency, as well as safety. Certain solutions are suggested for the various problems encountered during the deployments. It is found that the offshore deployment process can be optimized in terms of cost, time efficiency and safety.\n\nA group of wave energy devices deployed in the same location is called wave farm, wave power farm or wave energy park. Wave farms represent a solution to achieve larger electricity production. The devices of a park are going to interact with each other hydrodynamically and electrically, according to the number of machines, the distance among them, the geometric layout, the wave climate, the local geometry, the control strategies. The design process of a wave energy farm is a multi-optimization problem with the aim to get a high power production and low costs and power fluctuations.\n\n\n\n\n\n\n\n\n"}
{"id": "33550", "url": "https://en.wikipedia.org/wiki?curid=33550", "title": "Wood", "text": "Wood\n\nWood is a porous and fibrous structural tissue found in the stems and roots of trees and other woody plants. It is an organic material, a natural composite of cellulose fibers that are strong in tension and embedded in a matrix of lignin that resists compression. Wood is sometimes defined as only the secondary xylem in the stems of trees, or it is defined more broadly to include the same type of tissue elsewhere such as in the roots of trees or shrubs. In a living tree it performs a support function, enabling woody plants to grow large or to stand up by themselves. It also conveys water and nutrients between the leaves, other growing tissues, and the roots. Wood may also refer to other plant materials with comparable properties, and to material engineered from wood, or wood chips or fiber.\n\nWood has been used for thousands of years for fuel, as a construction material, for making tools and weapons, furniture and paper. More recently it emerged as a feedstock for the production of purified cellulose and its derivatives, such as cellophane and cellulose acetate.\n\nAs of 2005, the growing stock of forests worldwide was about 434 billion cubic meters, 47% of which was commercial. As an abundant, carbon-neutral renewable resource, woody materials have been of intense interest as a source of renewable energy. In 1991 approximately 3.5 billion cubic meters of wood were harvested. Dominant uses were for furniture and building construction.\n\nA 2011 discovery in the Canadian province of New Brunswick yielded the earliest known plants to have grown wood, approximately 395 to 400 million years ago.\n\nWood can be dated by carbon dating and in some species by dendrochronology to determine when a wooden object was created.\n\nPeople have used wood for thousands of years for many purposes, including as a fuel or as a construction material for making houses, tools, weapons, furniture, packaging, artworks, and paper. Known constructions using wood date back ten thousand years. Buildings like the European Neolithic long house were made primarily of wood.\n\nRecent use of wood has been enhanced by the addition of steel and bronze into construction.\n\nThe year-to-year variation in tree-ring widths and isotopic abundances gives clues to the prevailing climate at the time a tree was cut.\n\nWood, in the strict sense, is yielded by trees, which increase in diameter by the formation, between the existing wood and the inner bark, of new woody layers which envelop the entire stem, living branches, and roots. This process is known as secondary growth; it is the result of cell division in the vascular cambium, a lateral meristem, and subsequent expansion of the new cells. These cells then go on to form thickened secondary cell walls, composed mainly of cellulose, hemicellulose and lignin.\n\nWhere the differences between the four seasons are distinct, e.g. New Zealand, growth can occur in a discrete annual or seasonal pattern, leading to growth rings; these can usually be most clearly seen on the end of a log, but are also visible on the other surfaces. If the distinctiveness between seasons is annual (as is the case in equatorial regions, e.g. Singapore), these growth rings are referred to as annual rings. Where there is little seasonal difference growth rings are likely to be indistinct or absent. If the bark of the tree has been removed in a particular area, the rings will likely be deformed as the plant overgrows the scar.\n\nIf there are differences within a growth ring, then the part of a growth ring nearest the center of the tree, and formed early in the growing season when growth is rapid, is usually composed of wider elements. It is usually lighter in color than that near the outer portion of the ring, and is known as earlywood or springwood. The outer portion formed later in the season is then known as the latewood or summerwood. However, there are major differences, depending on the kind of wood (see below).\n\nAs a tree grows, lower branches often die, and their bases may become overgrown and enclosed by subsequent layers of trunk wood, forming a type of imperfection known as a knot. The dead branch may not be attached to the trunk wood except at its base, and can drop out after the tree has been sawn into boards. Knots affect the technical properties of the wood, usually reducing the local strength and increasing the tendency for splitting along the wood grain, but may be exploited for visual effect. In a longitudinally sawn plank, a knot will appear as a roughly circular \"solid\" (usually darker) piece of wood around which the grain of the rest of the wood \"flows\" (parts and rejoins). Within a knot, the direction of the wood (grain direction) is up to 90 degrees different from the grain direction of the regular wood.\n\nIn the tree a knot is either the base of a side branch or a dormant bud. A knot (when the base of a side branch) is conical in shape (hence the roughly circular cross-section) with the inner tip at the point in stem diameter at which the plant's vascular cambium was located when the branch formed as a bud.\n\nIn grading lumber and structural timber, knots are classified according to their form, size, soundness, and the firmness with which they are held in place. This firmness is affected by, among other factors, the length of time for which the branch was dead while the attaching stem continued to grow.\n\nKnots do not necessarily influence the stiffness of structural timber, this will depend on the size and location. Stiffness and elastic strength are more dependent upon the sound wood than upon localized defects. The breaking strength is very susceptible to defects. Sound knots do not weaken wood when subject to compression parallel to the grain.\n\nIn some decorative applications, wood with knots may be desirable to add visual interest. In applications where wood is painted, such as skirting boards, fascia boards, door frames and furniture, resins present in the timber may continue to 'bleed' through to the surface of a knot for months or even years after manufacture and show as a yellow or brownish stain. A knot primer paint or solution (knotting), correctly applied during preparation, may do much to reduce this problem but it is difficult to control completely, especially when using mass-produced kiln-dried timber stocks.\n\nHeartwood (or duramen) is wood that as a result of a naturally occurring chemical transformation has become more resistant to decay. Heartwood formation is a genetically programmed process that occurs spontaneously. Some uncertainty exists as to whether the wood dies during heartwood formation, as it can still chemically react to decay organisms, but only once.\n\nHeartwood is often visually distinct from the living sapwood, and can be distinguished in a cross-section where the boundary will tend to follow the growth rings. For example, it is sometimes much darker. However, other processes such as decay or insect invasion can also discolor wood, even in woody plants that do not form heartwood, which may lead to confusion.\n\nSapwood (or alburnum) is the younger, outermost wood; in the growing tree it is living wood, and its principal functions are to conduct water from the roots to the leaves and to store up and give back according to the season the reserves prepared in the leaves. However, by the time they become competent to conduct water, all xylem tracheids and vessels have lost their cytoplasm and the cells are therefore functionally dead. All wood in a tree is first formed as sapwood. The more leaves a tree bears and the more vigorous its growth, the larger the volume of sapwood required. Hence trees making rapid growth in the open have thicker sapwood for their size than trees of the same species growing in dense forests. Sometimes trees (of species that do form heartwood) grown in the open may become of considerable size, or more in diameter, before any heartwood begins to form, for example, in second-growth hickory, or open-grown pines.\n\nThe term \"heartwood\" derives solely from its position and not from any vital importance to the tree. This is evidenced by the fact that a tree can thrive with its heart completely decayed. Some species begin to form heartwood very early in life, so having only a thin layer of live sapwood, while in others the change comes slowly. Thin sapwood is characteristic of such species as chestnut, black locust, mulberry, osage-orange, and sassafras, while in maple, ash, hickory, hackberry, beech, and pine, thick sapwood is the rule. Others never form heartwood.\n\nNo definite relation exists between the annual rings of growth and the amount of sapwood. Within the same species the cross-sectional area of the sapwood is very roughly proportional to the size of the crown of the tree. If the rings are narrow, more of them are required than where they are wide. As the tree gets larger, the sapwood must necessarily become thinner or increase materially in volume. Sapwood is relatively thicker in the upper portion of the trunk of a tree than near the base, because the age and the diameter of the upper sections are less.\n\nWhen a tree is very young it is covered with limbs almost, if not entirely, to the ground, but as it grows older some or all of them will eventually die and are either broken off or fall off. Subsequent growth of wood may completely conceal the stubs which will however remain as knots. No matter how smooth and clear a log is on the outside, it is more or less knotty near the middle. Consequently, the sapwood of an old tree, and particularly of a forest-grown tree, will be freer from knots than the inner heartwood. Since in most uses of wood, knots are defects that weaken the timber and interfere with its ease of working and other properties, it follows that a given piece of sapwood, because of its position in the tree, may well be stronger than a piece of heartwood from the same tree.\n\nIt is remarkable that the inner heartwood of old trees remains as sound as it usually does, since in many cases it is hundreds, and in a few instances thousands, of years old. Every broken limb or root, or deep wound from fire, insects, or falling timber, may afford an entrance for decay, which, once started, may penetrate to all parts of the trunk. The larvae of many insects bore into the trees and their tunnels remain indefinitely as sources of weakness. Whatever advantages, however, that sapwood may have in this connection are due solely to its relative age and position.\n\nIf a tree grows all its life in the open and the conditions of soil and site remain unchanged, it will make its most rapid growth in youth, and gradually decline. The annual rings of growth are for many years quite wide, but later they become narrower and narrower. Since each succeeding ring is laid down on the outside of the wood previously formed, it follows that unless a tree materially increases its production of wood from year to year, the rings must necessarily become thinner as the trunk gets wider. As a tree reaches maturity its crown becomes more open and the annual wood production is lessened, thereby reducing still more the width of the growth rings. In the case of forest-grown trees so much depends upon the competition of the trees in their struggle for light and nourishment that periods of rapid and slow growth may alternate. Some trees, such as southern oaks, maintain the same width of ring for hundreds of years. Upon the whole, however, as a tree gets larger in diameter the width of the growth rings decreases.\n\nDifferent pieces of wood cut from a large tree may differ decidedly, particularly if the tree is big and mature. In some trees, the wood laid on late in the life of a tree is softer, lighter, weaker, and more even-textured than that produced earlier, but in other trees, the reverse applies. This may or may not correspond to heartwood and sapwood. In a large log the sapwood, because of the time in the life of the tree when it was grown, may be inferior in hardness, strength, and toughness to equally sound heartwood from the same log. In a smaller tree, the reverse may be true.\n\nIn species which show a distinct difference between heartwood and sapwood the natural color of heartwood is usually darker than that of the sapwood, and very frequently the contrast is conspicuous (see section of yew log above). This is produced by deposits in the heartwood of chemical substances, so that a dramatic color variation does not imply a significant difference in the mechanical properties of heartwood and sapwood, although there may be a marked biochemical difference between the two.\n\nSome experiments on very resinous longleaf pine specimens indicate an increase in strength, due to the resin which increases the strength when dry. Such resin-saturated heartwood is called \"fat lighter\". Structures built of fat lighter are almost impervious to rot and termites; however they are very flammable. Stumps of old longleaf pines are often dug, split into small pieces and sold as kindling for fires. Stumps thus dug may actually remain a century or more since being cut. Spruce impregnated with crude resin and dried is also greatly increased in strength thereby.\n\nSince the latewood of a growth ring is usually darker in color than the earlywood, this fact may be used in visually judging the density, and therefore the hardness and strength of the material. This is particularly the case with coniferous woods. In ring-porous woods the vessels of the early wood often appear on a finished surface as darker than the denser latewood, though on cross sections of heartwood the reverse is commonly true. Otherwise the color of wood is no indication of strength.\n\nAbnormal discoloration of wood often denotes a diseased condition, indicating unsoundness. The black check in western hemlock is the result of insect attacks. The reddish-brown streaks so common in hickory and certain other woods are mostly the result of injury by birds. The discoloration is merely an indication of an injury, and in all probability does not of itself affect the properties of the wood. Certain rot-producing fungi impart to wood characteristic colors which thus become symptomatic of weakness; however an attractive effect known as spalting produced by this process is often considered a desirable characteristic. Ordinary sap-staining is due to fungal growth, but does not necessarily produce a weakening effect.\n\nWater occurs in living wood in three locations, namely:\n\nIn heartwood it occurs only in the first and last forms. Wood that is thoroughly air-dried retains 8–16% of the water in the cell walls, and none, or practically none, in the other forms. Even oven-dried wood retains a small percentage of moisture, but for all except chemical purposes, may be considered absolutely dry.\n\nThe general effect of the water content upon the wood substance is to render it softer and more pliable. A similar effect occurs in the softening action of water on rawhide, paper, or cloth. Within certain limits, the greater the water content, the greater its softening effect.\n\nDrying produces a decided increase in the strength of wood, particularly in small specimens. An extreme example is the case of a completely dry spruce block 5 cm in section, which will sustain a permanent load four times as great as a green (undried) block of the same size will.\n\nThe greatest strength increase due to drying is in the ultimate crushing strength, and strength at elastic limit in endwise compression; these are followed by the modulus of rupture, and stress at elastic limit in cross-bending, while the modulus of elasticity is least affected.\n\nWood is a heterogeneous, hygroscopic, cellular and anisotropic material. It consists of cells, and the cell walls are composed of micro-fibrils of cellulose (40–50%) and hemicellulose (15–25%) impregnated with lignin (15–30%).\n\nIn coniferous or softwood species the wood cells are mostly of one kind, tracheids, and as a result the material is much more uniform in structure than that of most hardwoods. There are no vessels (\"pores\") in coniferous wood such as one sees so prominently in oak and ash, for example.\n\nThe structure of hardwoods is more complex. The water conducting capability is mostly taken care of by vessels: in some cases (oak, chestnut, ash) these are quite large and distinct, in others (buckeye, poplar, willow) too small to be seen without a hand lens. In discussing such woods it is customary to divide them into two large classes, \"ring-porous\" and \"diffuse-porous\".\n\nIn ring-porous species, such as ash, black locust, catalpa, chestnut, elm, hickory, mulberry, and oak, the larger vessels or pores (as cross sections of vessels are called) are localized in the part of the growth ring formed in spring, thus forming a region of more or less open and porous tissue. The rest of the ring, produced in summer, is made up of smaller vessels and a much greater proportion of wood fibers. These fibers are the elements which give strength and toughness to wood, while the vessels are a source of weakness.\n\nIn diffuse-porous woods the pores are evenly sized so that the water conducting capability is scattered throughout the growth ring instead of being collected in a band or row. Examples of this kind of wood are alder, basswood, birch, buckeye, maple, willow, and the \"Populus\" species such as aspen, cottonwood and poplar. Some species, such as walnut and cherry, are on the border between the two classes, forming an intermediate group.\n\nIn temperate softwoods, there often is a marked difference between latewood and earlywood. The latewood will be denser than that formed early in the season. When examined under a microscope, the cells of dense latewood are seen to be very thick-walled and with very small cell cavities, while those formed first in the season have thin walls and large cell cavities. The strength is in the walls, not the cavities. Hence the greater the proportion of latewood, the greater the density and strength. In choosing a piece of pine where strength or stiffness is the important consideration, the principal thing to observe is the comparative amounts of earlywood and latewood. The width of ring is not nearly so important as the proportion and nature of the latewood in the ring.\n\nIf a heavy piece of pine is compared with a lightweight piece it will be seen at once that the heavier one contains a larger proportion of latewood than the other, and is therefore showing more clearly demarcated growth rings. In white pines there is not much contrast between the different parts of the ring, and as a result the wood is very uniform in texture and is easy to work. In hard pines, on the other hand, the latewood is very dense and is deep-colored, presenting a very decided contrast to the soft, straw-colored earlywood.\n\nIt is not only the proportion of latewood, but also its quality, that counts. In specimens that show a very large proportion of latewood it may be noticeably more porous and weigh considerably less than the latewood in pieces that contain less latewood. One can judge comparative density, and therefore to some extent strength, by visual inspection.\n\nNo satisfactory explanation can as yet be given for the exact mechanisms determining the formation of earlywood and latewood. Several factors may be involved. In conifers, at least, rate of growth alone does not determine the proportion of the two portions of the ring, for in some cases the wood of slow growth is very hard and heavy, while in others the opposite is true. The quality of the site where the tree grows undoubtedly affects the character of the wood formed, though it is not possible to formulate a rule governing it. In general, however, it may be said that where strength or ease of working is essential, woods of moderate to slow growth should be chosen.\n\nIn ring-porous woods, each season's growth is always well defined, because the large pores formed early in the season abut on the denser tissue of the year before.\n\nIn the case of the ring-porous hardwoods, there seems to exist a pretty definite relation between the rate of growth of timber and its properties. This may be briefly summed up in the general statement that the more rapid the growth or the wider the rings of growth, the heavier, harder, stronger, and stiffer the wood. This, it must be remembered, applies only to ring-porous woods such as oak, ash, hickory, and others of the same group, and is, of course, subject to some exceptions and limitations.\n\nIn ring-porous woods of good growth, it is usually the latewood in which the thick-walled, strength-giving fibers are most abundant. As the breadth of ring diminishes, this latewood is reduced so that very slow growth produces comparatively light, porous wood composed of thin-walled vessels and wood parenchyma. In good oak, these large vessels of the earlywood occupy from 6 to 10 percent of the volume of the log, while in inferior material they may make up 25% or more. The latewood of good oak is dark colored and firm, and consists mostly of thick-walled fibers which form one-half or more of the wood. In inferior oak, this latewood is much reduced both in quantity and quality. Such variation is very largely the result of rate of growth.\n\nWide-ringed wood is often called \"second-growth\", because the growth of the young timber in open stands after the old trees have been removed is more rapid than in trees in a closed forest, and in the manufacture of articles where strength is an important consideration such \"second-growth\" hardwood material is preferred. This is particularly the case in the choice of hickory for handles and spokes. Here not only strength, but toughness and resilience are important.\n\nThe results of a series of tests on hickory by the U.S. Forest Service show that:\n\nThe effect of rate of growth on the qualities of chestnut wood is summarized by the same authority as follows:\n\nIn the diffuse-porous woods, the demarcation between rings is not always so clear and in some cases is almost (if not entirely) invisible to the unaided eye. Conversely, when there is a clear demarcation there may not be a noticeable difference in structure within the growth ring.\n\nIn diffuse-porous woods, as has been stated, the vessels or pores are even-sized, so that the water conducting capability is scattered throughout the ring instead of collected in the earlywood. The effect of rate of growth is, therefore, not the same as in the ring-porous woods, approaching more nearly the conditions in the conifers. In general it may be stated that such woods of medium growth afford stronger material than when very rapidly or very slowly grown. In many uses of wood, total strength is not the main consideration. If ease of working is prized, wood should be chosen with regard to its uniformity of texture and straightness of grain, which will in most cases occur when there is little contrast between the latewood of one season's growth and the earlywood of the next.\n\nStructural material that resembles ordinary, \"dicot\" or conifer timber in its gross handling characteristics is produced by a number of monocot plants, and these also are colloquially called wood. Of these, bamboo, botanically a member of the grass family, has considerable economic importance, larger culms being widely used as a building and construction material and in the manufacture of engineered flooring, panels and veneer. Another major plant group that produces material that often is called wood are the palms. Of much less importance are plants such as \"Pandanus,\" \"Dracaena\" and \"Cordyline.\" With all this material, the structure and composition of the processed raw material is quite different from ordinary wood.\n\nThe single most revealing property of wood as an indicator of wood quality is specific gravity (Timell 1986), as both pulp yield and lumber strength are determined by it. Specific gravity is the ratio of the mass of a substance to the mass of an equal volume of water; density is the ratio of a mass of a quantity of a substance to the volume of that quantity and is expressed in mass per unit substance, e.g., grams per milliliter (g/cm or g/ml). The terms are essentially equivalent as long as the metric system is used. Upon drying, wood shrinks and its density increases. Minimum values are associated with green (water-saturated) wood and are referred to as \"basic specific gravity\" (Timell 1986).\n\nWood density is determined by multiple growth and physiological factors compounded into “one fairly easily measured wood characteristic” (Elliott 1970).\n\nAge, diameter, height, radial (trunk) growth, geographical location, site and growing conditions, silvicultural treatment, and seed source all to some degree influence wood density. Variation is to be expected. Within an individual tree, the variation in wood density is often as great as or even greater than that between different trees (Timell 1986). Variation of specific gravity within the bole of a tree can occur in either the horizontal or vertical direction.\n\nIt is common to classify wood as either softwood or hardwood. The wood from conifers (e.g. pine) is called softwood, and the wood from dicotyledons (usually broad-leaved trees, (e.g. oak) is called hardwood. These names are a bit misleading, as hardwoods are not necessarily hard, and softwoods are not necessarily soft. The well-known balsa (a hardwood) is actually softer than any commercial softwood. Conversely, some softwoods (e.g. yew) are harder than many hardwoods.\n\nThere is a strong relationship between the properties of wood and the properties of the particular tree that yielded it. The density of wood varies with species. The density of a wood correlates with its strength (mechanical properties). For example, mahogany is a medium-dense hardwood that is excellent for fine furniture crafting, whereas balsa is light, making it useful for model building. One of the densest woods is black ironwood.\n\nThe chemical composition of wood varies from species to species, but is approximately 50% carbon, 42% oxygen, 6% hydrogen, 1% nitrogen, and 1% other elements (mainly calcium, potassium, sodium, magnesium, iron, and manganese) by weight. Wood also contains sulfur, chlorine, silicon, phosphorus, and other elements in small quantity.\n\nAside from water, wood has three main components. Cellulose, a crystalline polymer derived from glucose, constitutes about 41–43%. Next in abundance is hemicellulose, which is around 20% in deciduous trees but near 30% in conifers. It is mainly five-carbon sugars that are linked in an irregular manner, in contrast to the cellulose. Lignin is the third component at around 27% in coniferous wood vs. 23% in deciduous trees. Lignin confers the hydrophobic properties reflecting the fact that it is based on aromatic rings. These three components are interwoven, and direct covalent linkages exist between the lignin and the hemicellulose. A major focus of the paper industry is the separation of the lignin from the cellulose, from which paper is made.\n\nIn chemical terms, the difference between hardwood and softwood is reflected in the composition of the constituent lignin. Hardwood lignin is primarily derived from sinapyl alcohol and coniferyl alcohol. Softwood lignin is mainly derived from coniferyl alcohol.\n\nAside from the lignocellulose, wood consists of a variety of low molecular weight organic compounds, called \"extractives\". The wood extractives are fatty acids, resin acids, waxes and terpenes. For example, rosin is exuded by conifers as protection from insects. The extraction of these organic materials from wood provides tall oil, turpentine, and rosin.\n\nWood has a long history of being used as fuel, which continues to this day, mostly in rural areas of the world. Hardwood is preferred over softwood because it creates less smoke and burns longer. Adding a woodstove or fireplace to a home is often felt to add ambiance and warmth.\n\nWood has been an important construction material since humans began building shelters, houses and boats. Nearly all boats were made out of wood until the late 19th century, and wood remains in common use today in boat construction. Elm in particular was used for this purpose as it resisted decay as long as it was kept wet (it also served for water pipe before the advent of more modern plumbing).\n\nWood to be used for construction work is commonly known as \"lumber\" in North America. Elsewhere, \"lumber\" usually refers to felled trees, and the word for sawn planks ready for use is \"timber\". In Medieval Europe oak was the wood of choice for all wood construction, including beams, walls, doors, and floors. Today a wider variety of woods is used: solid wood doors are often made from poplar, small-knotted pine, and Douglas fir.\nNew domestic housing in many parts of the world today is commonly made from timber-framed construction. Engineered wood products are becoming a bigger part of the construction industry. They may be used in both residential and commercial buildings as structural and aesthetic materials.\n\nIn buildings made of other materials, wood will still be found as a supporting material, especially in roof construction, in interior doors and their frames, and as exterior cladding.\n\nWood is also commonly used as shuttering material to form the mold into which concrete is poured during reinforced concrete construction.\n\nA solid wood floor is a floor laid with planks or battens created from a single piece of timber, usually a hardwood. Since wood is hydroscopic (it acquires and loses moisture from the ambient conditions around it) this potential instability effectively limits the length and width of the boards.\n\nSolid hardwood flooring is usually cheaper than engineered timbers and damaged areas can be sanded down and refinished repeatedly, the number of times being limited only by the thickness of wood above the tongue.\n\nSolid hardwood floors were originally used for structural purposes, being installed perpendicular to the wooden support beams of a building (the joists or bearers) and solid construction timber is still often used for sports floors as well as most traditional wood blocks, mosaics and parquetry.\n\nEngineered wood products, glued building products \"engineered\" for application-specific performance requirements, are often used in construction and industrial applications. Glued engineered wood products are manufactured by bonding together wood strands, veneers, lumber or other forms of wood fiber with glue to form a larger, more efficient composite structural unit.\n\nThese products include glued laminated timber (glulam), wood structural panels (including plywood, oriented strand board and composite panels), laminated veneer lumber (LVL) and other structural composite lumber (SCL) products, parallel strand lumber, and I-joists. Approximately 100 million cubic meters of wood was consumed for this purpose in 1991. The trends suggest that particle board and fiber board will overtake plywood.\n\nWood unsuitable for construction in its native form may be broken down mechanically (into fibers or chips) or chemically (into cellulose) and used as a raw material for other building materials, such as engineered wood, as well as chipboard, hardboard, and medium-density fiberboard (MDF). Such wood derivatives are widely used: wood fibers are an important component of most paper, and cellulose is used as a component of some synthetic materials. Wood derivatives can be used for kinds of flooring, for example laminate flooring.\n\nWood has always been used extensively for furniture, such as chairs and beds. It is also used for tool handles and cutlery, such as chopsticks, toothpicks, and other utensils, like the wooden spoon and pencil.\n\nFurther developments include new lignin glue applications, recyclable food packaging, rubber tire replacement applications, anti-bacterial medical agents, and high strength fabrics or composites.\nAs scientists and engineers further learn and develop new techniques to extract various components from wood, or alternatively to modify wood, for example by adding components to wood, new more advanced products will appear on the marketplace. Moisture content electronic monitoring can also enhance next generation wood protection.\n\nWood has long been used as an artistic medium. It has been used to make sculptures and carvings for millennia. Examples include the totem poles carved by North American indigenous people from conifer trunks, often Western Red Cedar (\"Thuja plicata\").\n\nOther uses of wood in the arts include:\n\nMany types of sports equipment are made of wood, or were constructed of wood in the past. For example, cricket bats are typically made of white willow. The baseball bats which are legal for use in Major League Baseball are frequently made of ash wood or hickory, and in recent years have been constructed from maple even though that wood is somewhat more fragile. NBA courts have been traditionally made out of parquetry.\n\nMany other types of sports and recreation equipment, such as skis, ice hockey sticks, lacrosse sticks and archery bows, were commonly made of wood in the past, but have since been replaced with more modern materials such as aluminium, titanium or composite materials such as fiberglass and carbon fiber. One noteworthy example of this trend is the family of golf clubs commonly known as the \"woods\", the heads of which were traditionally made of persimmon wood in the early days of the game of golf, but are now generally made of metal or (especially in the case of drivers) carbon-fiber composites.\n\nLittle is known about the bacteria that degrade cellulose. Symbiotic bacteria in \"Xylophaga\" may play a role in the degradation of sunken wood; while bacteria such as \"Alphaproteobacteria\", \"Flavobacteria\", \"Actinobacteria\", \"Clostridia\", and \"Bacteroidetes\" have been detected in wood submerged over a year.\n\n"}
{"id": "28650032", "url": "https://en.wikipedia.org/wiki?curid=28650032", "title": "Woolly Worm Festival", "text": "Woolly Worm Festival\n\nThe Woolly Worm Festival is an event held each October since 1973 in Banner Elk and Beech Mountain, North Carolina. The festival celebrates the supposed weather-predicting abilities of the woolly worm, also called \"woolly bear\" which is a caterpillar or larvae of the Isabella tiger moth. Events include a caterpillar race.\n\nThe Isabella Tiger Moth belongs to the subfamily Arctiinae which has 11,000 species around the world. Prior to settling in for winter, the woolly worm eats a variety of plants and then produces a kind of antifreeze which protects the creature from temperatures as low as -90 degrees Fahrenheit. This caterpillar seeks safety from bitter winter weather by sheltering under logs, boulders, boards, rocks, and other dark places until emerging from its \"frozen\" state in May.\n\nIt's accepted by organizers of the North Carolina woolly worm festival that the color of the worm's thirteen body segments or stripes can be read and interpreted as a forecaster of the severity of coming winter. Although not everyone recognizes the woolly worm as an accredited weather forecaster, the worm is held in esteem by festival celebrants because of its proclaimed 80-85 percent accuracy rate in predictions.\n\nEach year attendance at this mountain celebration averages 15,000-20-000 people. It's been featured in the world-famous Farmers' Almanac and the Kiwanis International Magazine.\n\nPresiding over the yearly festival is a Master of Ceremonies. With the help of the festival's mascot Merriweather, he's responsible for ensuring festival rules are rigorously kept, in particular in regard to the caterpillar race. About 1200 worms are entered to compete, in at least 50 heats. During each heat worms must race 42 inches up a vertical string attached to cardboard on the backboard of a flatbed trailer. People are allowed to 'holler' and whistle to encourage their worm to race. Each heat consists of 20 worms and races continue all day until the grand final at about 4:00 p.m. The winning worm is announced as official forecaster, and its owner wins a monetary prize. The festival proceeds after expenses are distributed for support of community efforts and charities.\n\n\n"}
{"id": "3977033", "url": "https://en.wikipedia.org/wiki?curid=3977033", "title": "Zincochromite", "text": "Zincochromite\n\nZincochromite is a zinc chromium oxide mineral with the formula ZnCrO. It is the zinc analogue of chromite, hence the name. It was first described in 1987 as an occurrence in a uranium deposit near Lake Onega, Russia. It has also been reported from Dolo Hill, New South Wales, Australia, and from the Tarkwa Mine in the Ashanti gold belt of Ghana.\n"}
