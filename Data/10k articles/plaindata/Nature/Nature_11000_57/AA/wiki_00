{"id": "56013066", "url": "https://en.wikipedia.org/wiki?curid=56013066", "title": "2017 QP1", "text": "2017 QP1\n\nThe orbit of is extremely eccentric, going from the orbit of planet Mercury out into the asteroid belt, located between Mars and Jupiter.\n\n"}
{"id": "53189036", "url": "https://en.wikipedia.org/wiki?curid=53189036", "title": "A Tauri", "text": "A Tauri\n\nThe Bayer designation A Tauri is shared by two stars in the constellation Taurus:\n"}
{"id": "201208", "url": "https://en.wikipedia.org/wiki?curid=201208", "title": "Afrotropical realm", "text": "Afrotropical realm\n\nThe Afrotropical realm is one of the Earth's eight biogeographic realms. It includes Africa south of the Sahara Desert, the southern and eastern fringes of the Arabian Peninsula, the island of Madagascar, southern Iran and extreme southwestern Pakistan, and the islands of the western Indian Ocean. It was formerly known as the Ethiopian Zone or Ethiopian Region.\n\nMost of the Afrotropic, with the exception of Africa's southern tip, has a tropical climate. A broad belt of deserts, including the Atlantic and Sahara deserts of northern Africa and the Arabian Desert of the Arabian Peninsula, separate the Afrotropic from the Palearctic realm, which includes northern Africa and temperate Eurasia.\n\nSouth of the Sahara, two belts of tropical grassland and savanna run east and west across the continent, from the Atlantic Ocean to the Ethiopian Highlands. Immediately south of the Sahara lies the Sahel belt, a transitional zone of semi-arid short grassland and acacia savanna. Rainfall increases further south in the Sudanian Savanna, also known simply as the Sudan, a belt of taller grasslands and savannas. The Sudanian Savanna is home to two great flooded grasslands, the Sudd wetland in South Sudan, and the Niger Inland Delta in Mali. The forest-savanna mosaic is a transitional zone between the grasslands and the belt of tropical moist broadleaf forests near the equator.\n\nSouth Arabia, expressed as being mostly Yemen and parts of western Oman and southwestern Saudi Arabia, has few permanent forests. Some of the notable are Jabal Bura', Jabal Raymah, and Jabal Badaj in the Yemeni highland escarpment, and the seasonal forests in eastern Yemen and the Dhofar region of Oman. Other woodlands scatter the land and are very small and are predominantly juniper or acacia forests.\n\nThe forest zone, a belt of lowland tropical moist broadleaf forests, runs across most of equatorial Africa's intertropical convergence zone. The Upper Guinean forests of West Africa extend along the coast from Guinea to Togo. The Dahomey Gap, a zone of forest-savanna mosaic that reaches to the coast, separates the Upper Guinean forests from the Lower Guinean forests, which extend along the Gulf of Guinea from eastern Benin through Cameroon and Gabon to the western Democratic Republic of the Congo. The largest tropical forest zone in Africa is the Congolian forests of the Congo Basin in Central Africa. A belt of tropical moist broadleaf forest also runs along the Indian Ocean coast, from southern Somalia to South Africa.\n\n\nAfromontane region, from the Ethiopian Highlands to the Drakensberg Mountains of South Africa, including the East African Rift. Distinctive flora, including \"Podocarpus\" and \"Afrocarpus\", as well as giant \"Lobelias\" and \"Senecios\".\n\n\n\nThe Cape floristic region, at Africa's southern tip, is a Mediterranean climate region that is home to a significant number of endemic taxa, as well as to plant families like the proteas (\"Proteaceae\") that are also found in the Australasian realm.\n\nMadagascar and neighboring islands form a distinctive sub-region of the realm, with numerous endemic taxa like the lemurs. Madagascar and the Seychelles are old pieces of the ancient supercontinent of Gondwana, and broke away from Africa millions of years ago. Other Indian Ocean islands, like the Comoros and Mascarene Islands, are volcanic islands that formed more recently. Madagascar contains several important biospheres, as its biodiversity and ratio of endemicism is extremely high.\n\nThe Afrotropical realm is home to a number of endemic plant families. Madagascar and the Indian Ocean Islands are home to ten endemic families of flowering plants; eight are endemic to Madagascar (Asteropeiaceae, Didymelaceae, Didiereaceae, Kaliphoraceae, Melanophyllaceae, Physenaceae, Sarcolaenaceae, and Sphaerosepalaceae), one to Seychelles (Mesdusagynaceae) and one to the Mascarene Islands (Psiloxylaceae). Twelve plant families are endemic or nearly endemic to South Africa (including Curtisiaceae, Heteropyxidaceae, Penaeaceae, Psiloxylaceae and Rhynchocalycaceae) of which five are endemic to the Cape floristic province (including Grubbiaceae). Other endemic Afrotropic families include Barbeyaceae, Montiniaceae, Myrothamnaceae and Oliniaceae.\n\nThe East African Great Lakes (Victoria, Malawi, and Tanganyika) are the center of biodiversity of many freshwater fishes, especially cichlids (they harbor more than two-thirds of the estimated 2,000 species in the family). The West African coastal rivers region covers only a fraction of West Africa, but harbours 322 of West African's fish species, with 247 restricted to this area and 129 restricted even\nto smaller ranges. The central rivers fauna comprises 194 fish species, with 119 endemics and only 33 restricted to small areas.\n\nThe Afrotropic has various endemic bird families, including ostriches (Struthionidae), sunbirds, the secretary bird (Sagittariidae), guineafowl (Numididae), and mousebirds (Coliidae). Also, several families of passerines are limited to the Afrotropics; These include rock-jumpers (Chaetopidae) and rockfowl (Picathartidae).\n\nAfrica has three endemic orders of mammals, the Tubulidentata (aardvarks), Afrosoricida (tenrecs and golden moles), and Macroscelidea (elephant shrews). The East-African plains are well known for their diversity of large mammals.\n\nFour species of great apes (Hominidae) are endemic to Africa: both species of gorilla (western gorilla, \"Gorilla gorilla\", and eastern gorilla, \"Gorilla beringei\") and both species of chimpanzee (common chimpanzee, \"Pan troglodytes\", and bonobo, \"Pan paniscus\"). Humans and their ancestors originated in Africa.\n\n\n\n"}
{"id": "42646366", "url": "https://en.wikipedia.org/wiki?curid=42646366", "title": "Anbaric Development Partners", "text": "Anbaric Development Partners\n\nAnbaric Development Partners (Anbaric) is an American electric power transmission and microgrid development company located in Wakefield, Massachusetts. The company develops smart grid, renewable energy, and large-scale electric transmission projects which use high-voltage direct current (HVDC) technology for clients in the United States and internationally.\n\nAnbaric delivers power from energy producers to population centers through the use of underground and submarine transmission lines. Anbaric specializes in the development stages of transmission projects including conceiving, designing, and leading projects' proposal processes, which can take years. Its customers include governments, investor-owned utilities, and public power generators. The company's headquarters are located in Wakefield, Massachusetts.\n\nEdward N. Krapels Ph.D is the chief executive officer and founder of Anbaric Holding, LLC, the parent company of Anbaric. In addition to his role at Anbaric, Krapels served as the chairman of Atlantic Energy Partners and is the former director of Energy Security Analysis Inc. Other senior leadership includes Timothy Vaill, the company's Chief Financial Officer, Clarke Bruno, the company's President of Transmission, Dirk van Ouwerkerk, President of Microgrid development, and project managers Bryan Sanderson, Stephen Conant, and Howard Kosel\n\nAnbaric Transmission, LLC was incorporated in 2004 by founder Edward Krapels. In 2001, Krapels began work as a market advisor for Atlantic Energy Partners on a project known as the Neptune Regional Transmission System, a submarine transmission connection between New Jersey and Long Island. Krapels has stated that he obtained an ownership interest in the project, from which he founded Anbaric in order to focus on such transmission projects. Anbaric was then part of the merchant group that developed the Neptune RTS project, which was completed in 2007. In the late 2000s the company, along with other partners, completed additional projects including the Hudson Transmission System, which brings power from upstate New Jersey to New York.\n\nIn February 2015, Anbaric announced plans to develop a series of microgrids in New York State in response to New York’s call for more distributed generation resources and increased energy reliability. Anbaric has partnered with Exelon Corporation to build 10-200 megawatt microgrids in New York.\n\nIn March 2017, Anbaric and Ontario Teachers' Pension Plan created a new development company, Anbaric Development Partners. The partnership was formed to develop clean energy infrastructure projects in North America, with Anbaric's management team leading the new company and Ontario Teachers’ committing to funding development costs, projected to produce $2 billion in fully constructed assets. The announcement marked the largest financial commitment by an investor in the company’s 15-year history.\n\nAnbaric's projects include the design and development of power transmission and distributed generation energy projects. Its completed projects include the Neptune Regional Transmission System and the Hudson Transmission System, while ongoing projects in development include the Bay State Offshore Wind Transmission System, Vermont Green Line, Maine Green Line, West Point Project, and Poseidon Project.\n\nThe Neptune Cable, or the Neptune Regional Transmission System, is a 660-MW high-voltage direct current line that connects Sayresville, New Jersey to Long Island. Construction on the $600 million project began in fall 2005. The 65-mile transmission line became operational in June 2007, and was developed by a merchant group including Anbaric. As of 2007, the line was the largest source of imported electricity to Long Island. In a 2007 report, the New York ISO noted that the Neptune cable reduced electricity prices in New York, and substantially reduced transmission congestion into Long Island and New York City.\n\nThe Hudson Project, or the Hudson Transmission System, is project developed by a partnership including Anbaric. It consists of a 660-MW high-voltage direct current system which connects upstate New Jersey and Manhattan by traveling beneath the Hudson River. The cable carries power from an electrical substation in Ridgefield Park, New Jersey to one located on West 49th Street, New York and provides enough power for 400,000 homes. The project was completed in 2013 and cost approximately $850 million.\n\nAnbaric’s target microgrid customers include real estate buildings, hospitals, industrial facilities, government buildings, and municipalities throughout New York. In the summer of 2015, Anbaric was part of a team that received funding from New York State’s NY Prize program to conduct microgrid feasibility studies in the Village of Freeport and Staten Island University Hospital.\n\nBy November 2011, Anbaric had filed an interconnection request with ISO New England for the Bay State Offshore Wind Transmission System. The planned project consists of two 1,000-MW HVDC lines and, if approved, would be New England's first offshore transmission trunk line.\n\nWest Point Partners, LLC, a subsidiary of Anbaric, submitted a proposal in June, 2013 to the New York Public Service Commission to create an 80-mile power line which would run beneath the Hudson River to bring power to the New York metro area. The line would carry 1,000-MW of power from wind, solar, and natural gas producers. Estimated costs of the project are around $900 million. Anbaric's partner, PowerBridge LLC, is developing the line.\n\nAnbaric subsidiary Poseidon Transmission, LLC, filed an application in October 2013 with the New York Public Service Commission to begin construction on the Poseidon Project. This project seeks to bring 500-MW of power to the Long Island power grid via an underground high-voltage direct current transmission cable which would connect the Deans Substation in South Brunswick, New Jersey to the Ruland Road Substation in Huntington, New York.\n\nAs of May 2013, the Vermont Green Line has been proposed by GII Development LLC, a subsidiary of Anbaric Holdings LLC managing the project. The proposal followed an April 2013 Customer Open Solicitation carried out by GII Development as per new guidelines issued by the Federal Energy Regulatory Commission. The solicitation received a strong response from energy producers with requests for transmission in excess of the lines potential capacity. If approved, the line would travel under Lake Champlain and carry 400-MW of electricity from Plattsburgh, New York to a Vermont Electric Power Company substation located in New Haven, Vermont. The company has begun the process of seeking permits from New York, Vermont, and the United States Army Corps of Engineers, which could take up to two years.\n\nOn December 9, 2014, Anbaric and National Grid announced the formation of Green Line Infrastructure Alliance. The Alliance aims to provide benefits to New England's energy consumers by providing consumers with access to large-scale, cost-effective sources of renewable and zero-emission energy; diversifying the region’s energy portfolio, thereby easing the constraints on the natural gas pipeline system and providing access to affordable clean energy; enabling the New England states to meet all current clean energy targets by 2020 at affordable prices and enhancing the reliability and resilience of the region’s power grid.\n\nThe Alliance's first project will be Maine Green Line, a hybrid land-and-sea HVDC project that will initially deliver 1,000MW of wind from northern Maine, firmed up by imports of hydropower from eastern Canada, via a submarine cable to Massachusetts. Maine-based constructor Cianbro Development Corporation will be a part of this project. Connecticut-based PowerBridge has been part of the Maine Green Line Development team.\n"}
{"id": "1484457", "url": "https://en.wikipedia.org/wiki?curid=1484457", "title": "Atmospheric focusing", "text": "Atmospheric focusing\n\nAtmospheric focusing is a phenomenon occurring when a large shock wave is produced in the atmosphere, as in a nuclear explosion or large extraterrestrial object impact. The shock wave is refracted horizontally by density variations in the atmosphere so that it can have impacts in localized areas much further away than the theoretical extent of its blast effect. In large bombs, some effects may thus be found hundreds of kilometers from the blast site (such as in the case of the Tsar Bomba test, where damage was caused up to approximately 1,000 km away).\n\nThis effect operates similarly to the patterns made by sunlight on the bottom of a pool, the difference is that the light is bent at the contact point with the water while the shock wave is distorted by density variations (e.g. due to temperature variations) in the atmosphere. Variations of wind can cause a similar effect. This will disperse the shock wave at some places and focus it at others. For powerful shock waves this can cause damage farther than expected; the shock wave energy density will decrease beyond expected values based on uniform geometry falloff for weak shock or acoustic waves, as expected at large distances).\n"}
{"id": "18950667", "url": "https://en.wikipedia.org/wiki?curid=18950667", "title": "Baptism for the dead", "text": "Baptism for the dead\n\nBaptism for the dead, vicarious baptism or proxy baptism today commonly refers to the religious practice of baptizing a person on behalf of one who is dead—a living person receiving the rite on behalf of a deceased person.\n\nBaptism for the dead is best known as a doctrine of the Latter Day Saint movement, which has practiced it since 1840. It is currently practiced by The Church of Jesus Christ of Latter-day Saints (LDS Church), where it is performed only in dedicated temples, as well as in several other current factions of the movement. Those who practice this rite view baptism as an essential requirement to enter the Kingdom of God, and therefore practice baptism for the dead to offer it by proxy to those who died without the opportunity to receive it. The LDS Church teaches that those who have died may choose to accept or reject the baptisms done on their behalf.\n\nThe modern term itself is derived from a phrase \"baptised for the dead\" occurring in one verse of the New Testament (), though the meaning of that phrase is an open question among scholars. Early heresiologists Epiphanius of Salamis (\"Panarion\" 28) and Chrysostom (\"Homilies\" 40) attributed the practice respectively to the Cerinthians and to the Marcionites, whom they identified as heretical \"Gnostic\" groups. For that reason, the practice was forbidden by the early Church, and is therefore not practiced in modern mainstream Christianity, whether Oriental Orthodox, Eastern Orthodox, Roman Catholic, or any Protestant churches.\n\nIn the practice of the LDS Church, a living person, acting as proxy, is baptized by immersion on behalf of a deceased person of the same sex. After giving a short prayer, which includes the name of the deceased individual, the proxy is immersed briefly in the water, then brought up again. Baptism for the dead is an ordinance of the church, performed only in temples, and is based on the belief that baptism is required for entry into the Kingdom of God.\n\nSome members of the early Reorganized Church of Jesus Christ of Latter Day Saints (RLDS Church; now known as the Community of Christ) also believed in baptism for the dead, but it was never officially sanctioned by that organization and was considered highly controversial.\n\nAt a 1970 church world conference, a revelation and two letters written by Joseph Smith appertaining to baptism for the dead were removed as sections and placed in the appendix of the RLDS Church's Doctrine and Covenants; at a 1990 world conference, the three documents were removed entirely from the RLDS Church's scriptural canon.\n\nIn the Restoration Branches movement, which broke from the RLDS Church in the 1980s, the question of baptism for the dead is at best unsettled. Many adherents reject the validity of the ordinance completely. Others regard it a legitimate rite, the permission for which has been withdrawn by God ever since the Latter Day Saints failed to complete the Nauvoo Temple within the specified time frame.\n\nOther Latter-day Saint denominations that accept baptism for the dead include the Church of Jesus Christ of Latter Day Saints (Strangite) and The Church of Jesus Christ (Cutlerite). The Strangite Church performed baptisms for the dead during the 1840s in Voree, Wisconsin, and later during the 1850s on Beaver Island, Michigan. In each case, the practice was authorized by on the basis of what James J. Strang reported as a revelation. The question of whether the Strangite Church still practices proxy baptism is an open one, but belief is considered orthodox.\n\nAs part of their sacraments, the New Apostolic Church and the Old Apostolic Church also practice baptism for the dead, as well as Communion and Sealing to the Departed. In this practice a proxy or substitute is baptised in the place of an unknown number of deceased persons. According to NAC and OAC doctrine the deceased do not enter the body of the substitute.\n\nOutside of Christianity, proxy baptisms were practiced by the Mandaeans of Iraq and Iran.\n\nMormon scholar, John A. Tvedtnes says: \"Baptism for the dead was performed by the dominant church until forbidden by the sixth canon of the Council of Carthage (397). Some of the smaller sects, however, continued the practice.\" He does not give the text of that canon, which, if it is included in what has been called the Code of Canons of the African Church as canon 18, reads: \"It also seemed good that the Eucharist should not be given to the bodies of the dead. For it is written: 'Take, Eat', but the bodies of the dead can neither 'take' nor 'eat'. Nor let the ignorance of the presbyters baptize those who are dead.\"\n\nTertullian attributes the practice of 1 Corinthians \"baptised for the dead\" to the Marcionites.\n\nEpiphanius of Salamis (between 310–320 – 403) reported that he had heard it said that, among followers of Cerinthus, if one of them died before baptism, another was baptized in that person's name:\nFor their school reached its height in this country, I mean Asia, and in Galatia as well. And in these countries I also heard of a tradition which said that when some of their people died too soon, without baptism, others would be baptized for them in their names, so that they would not be punished for rising unbaptized at the resurrection and become the subjects of the authority that made the world.\nJohn Chrysostom (c. 347–407) mockingly attributes to the Marcionites of the late 4th century a similar practice: if one of their followers who was being prepared for baptism died before receiving baptism, the dead person's corpse was addressed with the question whether he wished to be baptized, whereupon another answered affirmatively and was baptized for the dead person.\n\nTo the superstitious practice of baptizing dead bodies (baptism \"of\" the dead) John A. Tvedtnes applies the term \"baptism \"for\" the dead\":\n\nIn the context of insisting that \"in Christ shall all be made alive .. Christ the firstfruits; afterward they that are Christ's\", Paul wrote in : \"Else what shall they do which are baptized for the dead, if the dead rise not at all? why are they then baptized for the dead?\" Different views have been expressed on the meaning of the phrase \"baptized for the dead\", and on whether Paul gave his approval to the practice.\n\nThe Greek verb in Paul's phrase \"baptized for the dead\" is \"baptizein\", which in Jewish Greek has a wider reference than \"baptism\", applying primarily to the masculine noun \"baptismos\" \"ritual washing\" The verb occurs four times in the Septuagint in the context of ritual washing, \"baptismos\": Judith cleansing herself from menstrual impurity, Naaman washing seven times to be cleansed from leprosy, etc. In the New Testament only, the verb \"baptizein\" can also relate to the neuter noun \"baptisma\" \"baptism\", a neologism unknown in the Septuagint and other pre-Christian Jewish texts. This broadness in the meaning of \"baptizein\" is reflected in English Bibles rendering \"wash\", where Jewish ritual washing is meant, for example in Mark 7:4, which states that the Pharisees \"except they wash (Greek \"baptize\"), they do not eat\", and \"baptize\" where \"baptisma\", the new Christian rite, is intended. The older ritual washing use of \"baptizein\" is relevant in the context of funerals since any Jew coming into contact with the dead body must undertake ritual washing. During the Second Temple and early Rabbinical period the regulations on \"ritual washing\" (Greek masculine noun \"baptismos\") expanded and multiplied. This is documented in the Halakhah Tractate Yadayim and Dead Sea Scrolls Peter Leithart (2007) suggests that Paul's comment \"why do they..\" is an analogy between baptism (i.e. neuter concept noun \"baptisma\") with Jewish ritual washing (i.e. masculine concrete noun \"baptismos\") for contact with the dead following the Mosaic regulations in Numbers 19. The phrase \"ritually washed for the dead\" does not occur in intertestamental literature, but a possibly related idea of prayer for the dead occurs in 2 Maccabees. Since the New Testament idea of \"baptism\" (Greek \"baptisma\"), the rite of baptism, is not mentioned in the verse, it is open to interpretation whether the verb \"baptizein\" refers to \"ritual washing\" (Greek \"baptismos\") or \"the rite of baptism\" (Greek \"baptisma\") or is an analogy between both.\n\nIn his book \"Against Marcion\", Tertullian said that the vain practice (\"whatever it may have been\") to which Paul alluded in witnessed to belief in bodily resurrection, something that Marcion denied, and that, in fact, \"baptized for the dead\" means baptized for the body destined to die and rise again. Somewhat similarly, John Chrysostom explained Paul's mention of people being \"baptized for the dead\" as a reference to the profession of faith they made in their own future resurrection before being baptized.\n\nSome interpret \"baptized for the dead\" as a metaphor for martyrdom, as in and baptism is a metaphor for suffering or martyrdom; accordingly they would translate it as \"being baptized with a view to death\". In this interpretation, the phrase is closely linked with what Paul says immediately afterwards of the suffering that he himself faces and is enabled to endure precisely because of his faith in his resurrection. This interpretation is similar to that of John Chrysostom.\n\nOthers interpret the phrase as referring to simple baptism of an individual. For Martin Luther it regarded a practice of being baptized \"above\" (the first of the meanings of the preposition ὑπέρ, generally translated in this passage as \"for\") the tombs of the dead. John Calvin saw it as a reference to being baptized when close to death.\n\nYet another interpretation sees the phrase as referring to vicarious baptism on behalf of dead people performed in the belief that the dead were thereby benefitted in some way. This belief is put forward as the reason why, when Paul compares the Corinthians' experience to that of the Israelites in crossing the Red Sea and being fed on manna, he insists that the Israelites were not thereby prevented from sinning.\n\nThe Tyndale Bible Dictionary concludes that Paul probably did not approve the practice of baptism for the dead. He refers to its practitioners as \"they\", not as \"you\" (the Corinthian Christians to whom he wrote). The note in the Catholic New American Bible is more cautious: \"Baptized for the dead: this practice is not further explained here, nor is it necessarily mentioned with approval, but Paul cites it as something in their experience that attests in one more way to belief in the resurrection.\" In this, it stays close to what Tertullian wrote in the year 207 or 208, when he said that Paul's only aim in alluding to the practice of baptism for the dead, \"whatever it may have been\", was \"that he might all the more firmly insist upon the resurrection of the body, in proportion as they who were vainly baptized for the dead resorted to the practice from their belief of such a resurrection.\"\n\nElaine Pagels (1992) seeks to explain 1 Corinthians as having reference to the Valentinian sect later numbered among the \"Gnostic\" heresies. However Pagels view of Paul's epistles is not supported by other scholars.\n\nJoel R. White argues from the context of the passage that 1 Cor 15:29 is referring to the apostles, especially Apollos and Paul himself. \n\nMainstream Christian denominations generally do not accept the Latter-day Saint interpretation of \"baptism for the dead\", mentioned in , though a few contemporary Christian churches do practice such an ordinance.\n\nMembers of the LDS Church believe that baptism is a prerequisite for entry into the kingdom of God as stated by Jesus in : \"Except that a man be born of water and of the Spirit, he cannot enter into the kingdom of God\" (KJV).\n\nThe LDS Church teaches that performing baptisms for the dead allows this saving ordinance to be offered on behalf of those who have died without accepting or knowing Jesus Christ or his teachings during their mortal lives. It is taught that this is the method by which all who have lived upon the earth will have the opportunity to receive baptism and to thereby enter the Kingdom of God.\n\nAmong other Biblical references, Latter-day Saints cite Peter's statements that Jesus preached to the spirits of the dead (KJV 1 Peter 3:19; 4:6) as evidence that God in his justice provides an opportunity for the deceased to hear and accept the gospel, if they don't receive that chance in mortality. As Peter affirmed in Acts 2:37–38, the next step after acceptance of the gospel is baptism for the remission of sins, which \"doth also now save us\" (KJV 1 Peter 3:21).\n\nThe LDS Church teaches that those in the afterlife who have been baptized by proxy are free to accept or reject the ordinance done on their behalf. Baptism on behalf of a deceased individual is not binding if that individual chooses to reject it in the afterlife.\n\nAny member of the LDS Church, male or female, who is at least 12 years old and holds a current temple recommend may act as a proxy in this ordinance. Men must also hold the Aaronic priesthood prior to entering the temple. Men act as proxy for deceased men, and women as proxy for deceased women. The concept of a spiritual proxy is compared by some in the LDS Church to the belief that Jesus acted as proxy for every human when he atoned for the sins of the world.\n\nHistorically, only adult male holders of the Melchizedek priesthood who had undergone the endowment ordinance were permitted to baptize others as proxies for the dead. In 2018, this policy was changed to allow boys who hold the Aaronic priesthood office of priest, generally between 16 and 18-years old, to officiate in baptisms for the dead.\n\nAccording to the LDS Church, the practice of baptism for the dead is based on a revelation received by the prophet Joseph Smith. Smith first taught the doctrine at the funeral sermon of a deceased member of the church, Seymour Brunson. In a letter written on October 19, 1840, to the church's Quorum of the Twelve Apostles (who were on a mission in the United Kingdom at the time), Smith refers to the passage in (KJV):\nLDS Church scripture expands further upon this doctrine and states that such baptisms are to be performed in temples. Vicarious baptism is performed in connection with other vicarious ordinances in temples of the LDS Church, such as the endowment and celestial marriage.\n\nInitially, women could be baptized for dead men, and vice versa; this, however, was changed in order to ensure that the person being baptized for a dead man could also be ordained on their behalf to the priesthood.\n\nThe LDS Church teaches that deceased persons who have not accepted, or had the opportunity to accept, the gospel of Christ in this life will have such opportunity in the afterlife. The belief is that as all must follow Jesus Christ, they must also receive all the ordinances that a living person is expected to receive, including baptism. For this reason, members of the LDS Church are encouraged to research their genealogy. This research is then used as the basis for church performing temple ordinances for as many deceased persons as possible. As a part of these efforts, Mormons have performed temple ordinances on behalf of a number of high-profile people, including the Founding Fathers of the United States, U.S. Presidents, Pope John Paul II, John Wesley, Christopher Columbus, Adolf Hitler, Joan of Arc, Genghis Khan, Joseph Stalin, and Gautama Buddha.\n\nWhile members of the LDS Church consider vicarious ordinances for the deceased a great service, some non-members have taken offense. Sensitive to the issue of proxy baptizing for non-Mormons not related to church members, the church in recent years has published a general policy of performing temple ordinances only for relatives. For example, the church is in the process of removing sensitive names (such as Jewish Holocaust victims) from its International Genealogical Index (IGI). D. Todd Christofferson of the church's Presidency of the Seventy stated that removing the names is an \"ongoing, labor intensive process requiring name-by-name research ... When the Church is made aware of documented concerns, action is taken ... Plans are underway to refine this process.\" The LDS Church keeps records of the temple ordinances performed for deceased persons; however, FamilySearch, a web application for accessing the church's genealogical databases, shows information on temple ordinances only to registered LDS Church members and not to non-members.\n\nIn 2008, a directive from the Vatican Congregation for the Clergy directed Catholic dioceses to prevent the LDS Church from \"microfilming and digitizing information\" contained in Catholic sacramental registers so that those whose names were contained therein would not be subjected to vicarious Mormon baptism. Earlier, the Vatican had declared that Mormon baptisms were invalid.\n\nThe LDS Church performs vicarious baptisms for individuals regardless of their race, sex, creed, religion, or morality. Some members of the LDS Church have been baptized for both victims and perpetrators of The Holocaust, including Anne Frank and Adolf Hitler, contrary to church policy. Some Jewish Holocaust survivors and some Jewish organizations have objected to this practice.\n\nSince the early 1990s, the LDS Church has urged members to submit the names of only their own ancestors for ordinances, and to request permission of surviving family members of people who have died within the past 95 years. Hundreds of thousands of improperly submitted names not adhering to this policy have been removed from the records of the church. Church apostle Boyd K. Packer has stated the church has been open about its practice of using public records to further temple ordinance work.\n\nDespite the guidelines, some members of the church have submitted names without adequate permission. In December 2002, independent researcher Helen Radkey published a report showing that, following a 1995 promise from the church to remove Jewish Holocaust victims from its International Genealogical Index, the church's database included the names of about 19,000 who had a 40 to 50 percent chance \"to be Holocaust victims ... in Russia, Poland, France, and Austria.\" Genealogist Bernard Kouchel searched the International Genealogical Index, and discovered that many well known Jews had been vicariously baptized, including Maimonides, Albert Einstein, and Irving Berlin, without family permission.\n\nChurch official D. Todd Christofferson told \"The New York Times\" that the church expends massive amounts of resources attempting to purge improperly submitted names, but that it is not feasible to expect the church to find each and every last one, and that the agreement in 1995 did not place this type of responsibility on the centralized church leadership.\n\nJewish groups, including the Simon Wiesenthal Center, spoke out against the vicarious baptism of Holocaust perpetrators and victims in the mid-1990s and again in the 2000s when they discovered the practice, which they consider insensitive to the living and the dead, was continuing. The associate dean of the Simon Wiesenthal Center, Abraham Cooper, complained that infamous figures such as Adolf Hitler and Eva Braun appeared on LDS genealogical records: \"Whether official or not, the fact remains that this is exactly the kind of activity that enraged and hurt, really, so many victims of the Holocaust and caused alarm in the Jewish community.\"\n\nIn 2008, the American Gathering of Jewish Holocaust Survivors announced that, since church members had repeatedly violated previous agreements, it would no longer negotiate with the church to try to prevent vicarious baptism. Speaking on the anniversary of Kristallnacht, Ernest Michel, a Holocaust survivor who reported on the Nuremberg Trials, speaking as the honorary chairman of the American Gathering of Holocaust Survivors, called on the LDS Church to \"implement a mechanism to undo what [they] have done\", and declared that the LDS Church had repeatedly violated their agreements, and that talks with Mormon leaders were now ended. Jewish groups, he said, would now turn to the court of public opinion for justice. Michel called the practice a revision of history that plays into the hands of Holocaust deniers, stating: \"They tell me, that my parents' Jewishness has not been altered but ... 100 years from now, how will they be able to guarantee that my mother and father of blessed memory who lived as Jews and were slaughtered by Hitler for no other reason than they were Jews, will someday not be identified as Mormon victims of the Holocaust?\"\n\nChurch officials, in response, stated that the church does not teach that vicarious baptisms coerce deceased persons to become Mormons, nor does the church add those names to its list of church members. Church officials have also stated that, in accordance with the 1995 agreement, it has removed more than 300,000 names of Jewish Holocaust victims from its databases, as well as subsequently removing names later identified by Jewish groups. Church officials stated in 2008 that a new version of the FamilySearch application had been developed and was being implemented in an effort to prevent the submission of Holocaust victim names for temple ordinances.\n\nIn February 2012, the issue re-emerged after it was found that the parents of Holocaust survivor and Jewish rights advocate Simon Wiesenthal were added to the genealogical database. Shortly afterward, news stories announced that Anne Frank had been baptized by proxy for the ninth time, at the Santo Domingo Dominican Republic Temple.\n\n\n\n\n"}
{"id": "32168409", "url": "https://en.wikipedia.org/wiki?curid=32168409", "title": "Battle of Drummond's Island", "text": "Battle of Drummond's Island\n\nThe Battle of Drummond's Island was a conflict between the United States Exploring Expedition and the village of Utiroa on April 1841 at Drummond's Island, which is now named Tabiteuea. The cause of the conflict was the disappearance of the American seaman John Anderson, who was suspected to have been murdered by the village natives. In retaliation, the members of the expedition killed twelve of the natives and burned the village to the ground. \n\nThe USS \"Peacock\" was commanded by Lieutenant William L. Hudson, the commander of the United States Exploring Expedition. Charles Wilkes had ordered Hudson to explore Drummond's Island, named after a member of the expedition. Lieutenant Hudson learned from a member of his crew that a merchant ship had wrecked on a reef off the island's northwest coast years before. Most of its crew were massacred, except for a \"white woman\" and a child, who was supposed to still be alive. On April 6, the \"Peacock\" anchored off Utiroa on Drummond's Island. Hudson went ashore with a couple of Navy officers, a marine detachment, as well as the Scientific Corps.\n\nInitially, the natives were described as calm and peaceful; they led the Americans to their village center. means \"land of no chiefs\" in Gilbertese, and the natives themselves practiced egalitarianism, which meant the Americans had no tribal chief, or leader, to consult with.\n\nUtiroa was said to be where the massacre had taken place. Other than studying the flora and fauna of the island, Hudson wanted to inquire about the shipwreck and the stranded woman and child. The natives spoke nothing of the incident but \"parts of the vessel were found\" inside the village's huts, though most of the buildings were deemed off-limits.\n\nThe Americans returned to their ship after several hours but returned the next day, April 7. All was well until Lieutenant Hudson and his men were on their way back to the \"Peacock\". They noticed that a member of the procession, seaman John Anderson, was missing. A search was undertaken which went unnoticed by the Gilbertese, who appeared to be arming themselves with swords, spears, and other weapons.\n\nEventually, the search was discontinued. As the Americans were boarding their gig and armed boats, the natives tried to surround the sailors and marines. The natives threw rocks and waved their weapons as the boats shoved off. No one was harmed; Lieutenant Hudson decided to wait for Anderson until April 9, by which time the had arrived.\n\nAfter it became apparent that the sailor would not return, Hudson attacked the town to administer punishment against the natives. About eighty marines and sailors under Lieutenant William M. Walker of the Marine Corps were divided into three sections and landed at daylight. Meanwhile, the \"Peacock\" maneuvered into firing position off Utiroa and the \"Flying Fish\" covered the landing of men in seven boats. In case the landing party was overwhelmed, the schooner would provide covering fire and rescue the survivors.\nAround 700 Gilbertese warriors were dancing in the jungle near the beach and as the boats pulled in, Lieutenant Walker demanded they let Seaman Anderson go. However, the demand was ignored and the natives entered the water and headed for the boats, forcing them to retreat for a small distance. After this Walker turned his boats around and opened fire with a rocket at the mass of warriors. He then ordered his men to begin volley fire and devastated the natives according to the \"Peacock\"'s log book. A little while later the natives \"fled to the bush\" so the American vessels pulled in close to shore, within \"pistol shot\" range. Then the landing was made.\n\nThe Gilbertese were not gone for long. Many returned to defend their villages and they unsuccessfully skirmished with Americans for hours. When all the buildings of Utiroa were burned, Walker and his men moved on to another nearby village and destroyed it as well. They then tried to inquire about the shipwrecked survivors but again nothing was uncovered so Lieutenant Walker led his men back to the boats.\n\nThere were no American combat casualties, but the armed boats were damaged in some way during the action, and they were repaired aboard USS \"Peacock\" as she sailed to rejoin Commander Wilkes in the sloop-of-war with the USS \"Flying Fishing\" company. Twelve islanders were killed in the fighting and others were wounded. Later during the expedition, the \"Peacock\" sank without loss of life in July 1841, while sailing into the mouth of the Columbia River.\n\n\nBibliography\n"}
{"id": "41684043", "url": "https://en.wikipedia.org/wiki?curid=41684043", "title": "Bjerknes Centre for Climate Research", "text": "Bjerknes Centre for Climate Research\n\nThe Bjerknes Centre for Climate Research is a climate research centre in Bergen, Norway. The centres key areas of research is natural variability in the Earth system and man-made climate change. The centre combines observations with theoretical and modelling studies of past, present and future climates. Both Global and Polar regions are studied.\n\nThe centre was started in 2000 and is a co-operation between University of Bergen, Institute of Marine Research, the Nansen Environmental and Remote Sensing Center and Uni Research. The centre was part of Research Council of Norway's Centre of Excellence program from 2003 to 2013. Eystein Jansen headed the centre from 2000 to 2013, after which Tore Furevik has been director.\n\nResearchers from the Bjerknes Centre have taken part in the Intergovernmental Panel on Climate Change assessment reports; Eystein Jansen as one of the lead authors in the fourth report. Asgeir Sorteberg in the Special Report on managing the risks of extreme events and disasters to advance climate change adaption (SREX). Eystein Jansen, Peter Thorne and Christoph Heinze have been respectively lead authors and review editor in the IPCC Working Group 1, for the IPCC Fifth Assessment Report.\n\nIt is named after Vilhelm Bjerknes and his son Jacob Bjerknes.\n\nHomepage\n"}
{"id": "8494074", "url": "https://en.wikipedia.org/wiki?curid=8494074", "title": "Campos rupestres", "text": "Campos rupestres\n\nThe campos rupestres (\"rocky fields\") is an ecoregion of the montane subtropical savanna biome, located in eastern Brazil. It is situated within the South American Atlantic Forest, and borders the Cerrado subtropical savanna ecoregion.\n\nThe Portuguese term \"campos rupestres\" means \"rocky fields\", but is used to describe the shrubby savanna vegetation that grows in this habitat.\nIt is found at elevations from .\nIt is known for high levels of endemism at the genus and species levels.\nThe Köppen climate classification is \"Cwa\": warm temperate, dry winter, hot summer.\n\nThe ecoregion consists of a series of relatively small and isolated grasslands in the Espinhaço Mountains of eastern Brazil, surrounded by lowland and montane forests.\nIt also forms discontinuous enclaves in the Mantiqueira Mountains and the Serra dos Órgãos range. They are found in the states of Bahia, Espírito Santo, Minas Gerais, and Rio de Janeiro.\n\nThe soil of the Serra do Cachimbo in the Mato Grosso tropical dry forests ecoregion is white sand.\nIt has an extensive region of campos rupestres.\n\nThe campos rupestres ecoregion consists of open plant formations subject to drought growing on rocks that do not retain water.\nIn appearance it is similar to savanna, but the flora are different with species such as \"Calea lutea\" and others that are found in caatinga forest.\nThis montane savanna ecoregion is a chief center of biodiversity in the family Cactaceae.\nA large percentage of South American Cactaceae species are present within the campos rupestres.\n\nIndigenous mammals include tapirs, capybaras, bush dogs, and armadillos.\nIndigenous reptiles include crocodiles, lizards, tortoises and iguanas.\nThe riparian zones offer habitat for birds, reptiles, and mammals that require more water than the plateau species.\n\nEndangered mammals include fossorial giant rat (\"Kunsia fronto\"), orange-brown Atlantic tree-rat (\"Phyllomys brasiliensis\") and giant otter (\"Pteronura brasiliensis\").\nEndangered amphibians include Izecksohn's treefrog (\"Bokermannohyla izecksohni\") and the reticulate leaf frog (\"Phyllomedusa ayeaye\") .\nEndangered birds include Brazilian merganser (\"Mergus octosetaceus\") and yellow-bellied seedeater (\"Sporophila nigricollis\").\n\nThe campos rupestres ecoregion is well-preserved, but only 5% is protected by federal conservation units, mostly in the Serra do Cipó and Serra do Sincorá of the Espinhaço Range.\nThe main threats come from mining, extraction of native plants for ornamental use, cattle ranching, fires, tourism and urban expansion.\nThe ecoregion is altered by changes to the surrounding forests, which are being forested and cleared for pasturage, and by burning of savannas.\n\n\n"}
{"id": "18161344", "url": "https://en.wikipedia.org/wiki?curid=18161344", "title": "Canadian Nuclear Association", "text": "Canadian Nuclear Association\n\nThe Canadian Nuclear Association (CNA) was founded in 1960. Its mission is to represent the nuclear industry in Canada.\n\nLocated in Ottawa, Ontario, the CNA comprises over 100 member companies and organizations from across Canada as well as internationally. These companies include operators of nuclear power plants, nuclear reactor designers, engineering firms, suppliers, academic institutions, labour unions, as well as various professional services with business in Canada's nuclear industry such as research consultantancies and law firms.\n\nThe CNA undertakes several advocacy tasks related to nuclear technology in Canada, such as participating in relevant regulatory and environmental affairs, public, government, and media relations, education, and also provides several business functions such as conferences and workshops.\n\n"}
{"id": "48483266", "url": "https://en.wikipedia.org/wiki?curid=48483266", "title": "China Energy Research Report", "text": "China Energy Research Report\n\nThe China Energy Research Report (hereafter referred to as the Report) is one of the leading works of Prof. Yi-Ming Wei’s team in the Center of Energy & Environmental Policy Research. The Report is a publication of series in every two years with a specific theme at one time, based on China’s critical energy strategies, aiming to provide scientific and technical support for public and private policy decisions. 2014 saw the release of its fifth installment.\n\n\nThe 2014 Report is the fifth in a series of such reports. It is based on the fact that China, as the largest developing country, has been challenged with the more serious and more complicated energy poverty issue. This report reviews and summarizes the tools and methods of evaluating the global energy poverty, then establishes an indicator system of measuring and assessing China’s energy poverty from a temporal and spatial perspective. Besides, many critical issues like the relations between energy poverty and economic growth, climate change and energy accessibility, clean energy and energy poverty, solid fuels and health, policies and acts on energy poverty elimination, are also discussed in this Report.\n\nChina has been more relying on the import of fossil fuels since 2009 soon after China became the biggest energy consumer and second largest oil importer, giving rise to more crisis and risks. Under such circumstances, the 2012 Report systematically discusses a series of topics pertaining to energy security, such as the complexity of the global energy market, risks assessment of China’s energy import, policies for strategic energy reserves, energy crisis and China’s economic growth, renewables and energy poverty, the environmental and health effects of energy consumption, energy conservation potentials for key sectors and regions, energy supply security warning and studies of international energy security.\n\nEnergy, followed by CO2 emissions, is not only an environmental problem, but recognized as an economic, political and social strategic issue. In a global path of sustainable development, it is aware that achieving energy conservation as well as energy efficiency improvements is one of the most important and effective way to address climate change and energy challenges.\nThe 2010 Report proposes the connotation as well as the measurements of energy efficiency based on a comprehensive study of international energy situation. It is well extended to several analyses such as the effects of economic structure on the macro energy efficiency, the difference between urban and rural residential energy consumption and characteristics of regional residential energy consumption, energy efficiency of major industries and sectors, the effects of fuel price on oil demand, energy efficiency policy design and simulation.\n\nThe global climate change has posed a hard question of how to use fossil fuels wisely to human beings. In this context, the 2008 Report focuses on energy use and CO2 emissions. the characteristics of China’s energy consumption and CO2 emissions, factors of CO2 emissions under different economic growth levels, the emissions trajectory of China’s carbon-intensive sectors and regions, global carbon market, mitigation technologies and policies.\n\nEnergy has been considered as, the same as labor and capital, a basic productive factor and strategic resource. The 2006 Report, the first installment of the series, focuses on China’s energy strategies and management and provides implications according to different policy portfolios.\n\n"}
{"id": "1150710", "url": "https://en.wikipedia.org/wiki?curid=1150710", "title": "Christ Community Church", "text": "Christ Community Church\n\nChrist Community Church in Zion, Illinois, formerly the Christian Catholic Church or Christian Catholic Apostolic Church, is an evangelical non-denominational church founded in 1896 by John Alexander Dowie. The city of Zion was founded by Dowie as a religious community to establish a society on the principles of the Kingdom of God. Members are sometimes called Zionites (not to be confused with the German Zionites).\n\nOver the years there have been many changes to the church founded by John Alexander Dowie. He was a popular faith healer and started the church and the Zion community with utopian ideals. Under Wilbur Glenn Voliva, Dowie's successor, the church was noted for its adherence to a flat earth cosmology. The succession of pastors after Voliva moved the church back to mainstream Protestant doctrine.\n\nIn the early 20th century, the Christian Catholic Church had worldwide appeal. The church's magazine, \"The Leaves of Healing\", was distributed in the U.S., Australia, Europe, and southern Africa. At its height, Dowie's movement had some 20,000 adherents. The Zionist Churches of southern Africa trace their spiritual heritage back to Dowie and the Christian Catholic Church. Because of Dowie's emphasis on faith healing and restorationism the church is considered a forerunner of Pentecostalism.\n\nThe name Christian Catholic Church is still used for Christ Community Church's worldwide fellowship of churches and mission work. As of 2008, it has about 3,000 members in the United States and Canada. Missionary work is conducted in Japan, Philippines, Guyana, Palestine, Indonesia, and the Navajo Nation. Missionary work continues among the African Zionists under the banner of Zion Evangelical Ministries of Africa (ZEMA). ZEMA's goal is to convert the African Zionists from syncretism to mainstream Christian theology.\n\nJohn Alexander Dowie was born in Edinburgh, Scotland, May 25, 1847, to an evangelical family. The family emigrated to Australia in 1860, with Dowie returning to attend the University of Edinburgh from 1867 to 1872, at which time he once more sailed for Australia. In 1876 Dowie married and he began his evangelistic ministry three years later in Melbourne.\n\nDowie emigrated to San Francisco in 1888 where he founded the Ministry of Divine Healing. After years of traveling across the country preaching and healing, he finally settled in Chicago and in 1893 set up a tabernacle at the World's Columbian Exposition. During the next seven years, Dowie founded the Christian Catholic Church that met in several city locations including the Chicago Auditorium (1896). In 1900 he purchased land along the shores of Lake Michigan, north of Chicago near the Illinois–Wisconsin border and founded a religious utopian community that he called Zion.\n\nHe also founded a commercial enterprise, which came to be called Zion Industries, to support the community. Initially its main product was Scottish lace and it enjoyed considerable success.\n\nDowie proselytized vigorously both in person and by means of several serial publications, chief among them being \"Leaves of Healing,\" and gained a lot of adherents. At its height in 1905, the church claimed some 30,000 members worldwide, of whom some 7500 settled in Zion. Two notable features of Dowie's preaching were faith healing and what he called holy living—his followers were admonished to abstain from tobacco, alcohol, pork products, doctors and medicines, the \"apostate churches\", etc.\n\nDowie had progressive views on race relations for his day and welcomed blacks into his church, of whom some 200 settled in Zion. He later sent some of them as missionaries to South Africa, where they established churches that became very influential.\n\nAs the community of Zion grew in size and prosperity, Dowie adopted an increasingly lavish lifestyle, building himself a 25-room mansion and dressing himself in ornate ecclesiastical robes modeled after those worn by Aaron, the high priest, described in Leviticus. Due to this and other financial mismanagement, the church was threatened with bankruptcy. In 1905 Dowie suffered the first of a series of debilitating strokes. In 1906 his followers revolted, ousted him from leadership and elected Wilbur Glenn Voliva as the new leader of the church. A splinter group rejected the new leadership, left Zion, and some of them went on to become influential leaders of the budding Pentecostal movement. Dowie died of another stroke on March 9, 1907.\n\nA bizarre sidelight on Dowie's later years is that he became embroiled in an acrimonious public dispute with a controversial Indian Muslim religious figure, Mirza Ghulam Ahmad, founder of the Ahmadiyya movement. In 1903 they engaged in a widely publicized \"prayer duel,\" each calling upon God to punish the other to expose him as a false prophet. Ahmad and his followers proclaimed Dowie's rapidly ensuing illness, disgrace, and death as a vindication of their religious beliefs. Ahmad died in 1908, a year later than Dowie.\n\nWilbur Glenn Voliva succeeded Dowie as General Overseer of Zion in 1906 and renamed the church to \"Christian Catholic Apostolic Church\". He kept tight control on his some 6000 followers, which made up the community, even up to the point of dictating their choice of marriage partners. All real estate in Zion, while sold at market rates, was conveyed under an 1100-year lease, subject to many restrictions and subject to termination at the whim of the General Overseer. Religions other than the Christian Catholic Apostolic Church were effectively banned - visiting preachers from rival sects were harassed and hounded out of town by the city police force.\n\nHe diversified Zion Industries to include a bakery which produced the popular Zion brand fig bar cookies and White Dove chocolates. Zion was a one company town and its workers were paid substandard wages.\n\nA strict code of morality was imposed in the town on all persons who set foot inside city limits. It was unlawful for women to wear short dresses, high heels, bathing suits or lipstick. Ham, bacon, oysters, liquor and tobacco were banned, as were drugstores, medical buildings, movie theaters, and globes (as they challenged Voliva's flat-earth cosmology). A ten o'clock curfew was rigidly enforced. You could be arrested for whistling on Sunday. These laws were enforced by Voliva's police force, called the Praetorian Guard, whose helmets carried the word 'PATIENCE' and whose sleeves bore images of doves. Policemen wore Bibles and clubs on their belts.\n\nVoliva gained a lot of nationwide notoriety by his vigorous advocacy of flat earth doctrine. He offered a widely publicized $5000 challenge for anyone to disprove flat earth theory, but on terms of his own choosing. The church schools in Zion taught the flat earth doctrine. His 5,000 watt radio station, WCBD, broadcast his diatribes against round earth astronomy, and the evils of evolution.\n\nLike his predecessor Dowie, Voliva increasingly developed an overtly lavish lifestyle, which began to alienate his followers, especially after the hardships brought on by the Great Depression, which forced the town's sole employer, Zion Industries, into bankruptcy. In 1935 Voliva tried to revive the flagging fortunes of the church by instituting the annual Zion Passion Play, along the lines of the famous one in Oberammergau. However, in 1937 a disgruntled employee set the church's huge Shiloh Tabernacle, where the play took place, ablaze. Shortly thereafter, Voliva was forced into personal bankruptcy. In 1942 after being diagnosed with terminal cancer, Voliva made a tearful public confession to his followers that he had misappropriated church funds for his personal use and committed other misdeeds. Shortly thereafter on October 11, 1942 he died, and the church all but dissolved.\n\nA small remnant was reorganized under the leadership of Michael Mintern but a second fire destroyed the Zion Auditorium in April 11, 1959. At this time the Robson family from England were living in an apartment in the building. They were out of the building at the time. Had they been at home they would have perished, as the fire appliances were not able to reach the fourth floor. This was felt to be God's provision as He kept them out of the building that day. The church in Zion was later renamed to Christ Community Church.\n\n\n"}
{"id": "14424426", "url": "https://en.wikipedia.org/wiki?curid=14424426", "title": "Cloud iridescence", "text": "Cloud iridescence\n\nCloud iridescence or irisation is a colorful optical phenomenon that occurs in a cloud and appears in the general proximity of the Sun or Moon. The colors resemble those seen in soap bubbles and oil on a water surface. It is a type of photometeor. This fairly common phenomenon is most often observed in altocumulus, cirrocumulus, lenticular, and cirrus clouds. They sometimes appear as bands parallel to the edge of the clouds. Iridescence is also seen in the much rarer polar stratospheric clouds, also called nacreous clouds. \n\nThe colors are usually pastel, but can be very vivid or mingled together, sometimes similar to mother-of-pearl. When appearing near the Sun, the effect can be difficult to spot as it is drowned in the Sun's glare. This may be overcome by shielding the sunlight with one's hand or hiding it behind a tree or building. Other aids are dark glasses, or observing the sky reflected in a convex mirror or in a pool of water.\n\nIrisations are named after the Greek goddess Iris, goddess of rainbows and messenger of Zeus and Hera to the mortals below. \n\nIridescent clouds are a diffraction phenomenon caused by small water droplets or small ice crystals individually scattering light. Larger ice crystals do not produce iridescence, but can cause halos, a different phenomenon.\n\nIrisation is caused by very uniform water droplets diffracting light (within 10 degrees from the Sun) and by first order interference effects (Beyond about 10 degrees from the Sun). It can extend up to 40 degrees from the Sun.\n\nIf parts of clouds contain small water droplets or ice crystals of similar size, their cumulative effect is seen as colors. The cloud must be optically thin, so that most rays encounter only a single droplet. Iridescence is therefore mostly seen at cloud edges or in semi-transparent clouds, while newly forming clouds produce the brightest and most colorful iridescence. When the particles in a thin cloud are very similar in size over a large extent, the iridescence takes on the structured form of a corona, a bright circular disk around the Sun or Moon surrounded by one or more colored rings.\n\n\n"}
{"id": "372949", "url": "https://en.wikipedia.org/wiki?curid=372949", "title": "Cocobolo", "text": "Cocobolo\n\nCocobolo is a tropical hardwood of Central American trees belonging to the genus \"Dalbergia\". Only the heartwood of cocobolo is used; it is usually orange or reddish-brown, often with darker irregular traces weaving through the wood. The heartwood changes color after being cut, and can be polished to a lustrous, glassy finish; being quite dense, some has a specific gravity of over 1.0, and will sink in water. The sapwood (not often used) is a creamy yellow, with a sharp boundary between it and the heartwood.\n\nCocobolo is yielded by two to four closely related species of the genus \"Dalbergia\", of which the best known is \"Dalbergia retusa\", a fair-sized tree, reported to reach in height and in diameter; it probably is the species contributing most of the wood in the trade. Because of the high value of the timber, the trees yielding it have been heavily exploited, so they have become rare outside of national parks, reserves, and plantations. Only relatively small amounts of this prized wood reach the world market, and it is expensive.\n\nCocobolo heartwood contains oil, which lends a strong, unmistakable floral odor even to well seasoned wood and occasionally stains the hands with prolonged exposure. The high natural oil content of the wood makes it difficult to achieve a strong glue joint, as in applying veneers or guitar fingerboards, and can inhibit the curing of some varnishes, particularly oil-based finishes. Acetone may be used to remove surface oils before gluing. The oil can induce allergic reactions if inhaled or exposed to unprotected skin and eyes. A dust collection system, coupled with the use of personal protective equipment such as respirators, is highly recommended when machining this wood.\n\nBecause it stands up well to repeated handling and exposure to water, a common use is for gun grips and knife handles, and duck calls. It is very hard, fine textured, and dense, yet easily machined. The abundance of natural oils, however, causes the wood to clog abrasives and fine-toothed saw blades, like other hard, dense tropical woods. Besides its use on guns and knives, cocobolo is favored for fine inlay work on custom, high-end cue sticks, police batons, pens, brush backs, bowls, pipes, jewelry boxes, desktops and other expensive specialty items.\n\nDue to its density and hardness, even a large block of the cut wood will produce a clear musical tone if struck. Renowned for its \"warm, rich palette\", cocobolo is used to make musical instruments, such as oboes, flutes and clarinets--especially boutique, custom barrel joints for B-flat clarinets. Other woodwind instruments, such as bagpipes, (even the bagpipes' chanter's more basic relatives, duck and goose calls) have been successfully made using cocobolo instead of the orchestral and Celtic instruments' customary mpingo, or African blackwood, known in the trade as grenadilla. Additionally, cocobolo has been used to make fingerboards, as well as entire necks and bodies of guitars and bass guitars, having been employed as a substitute for Brazilian Rosewood since that fellow Dalbergia member was CITES listed in 1992. Additionally, cocobolo is used to an extent in building drums.\n\nLogs, sawn wood, and veneer sheets from the Guatemalan populations of Cocobolo (\"Dalbergia retusa\"), have been listed under CITES Appendix III since 2008. In 2011, Panama extended that listing to include all products except seeds and pollen and finished products packaged and ready for retail trade. \n\nAs of January 2, 2017, Cocobolo is protected as a CITES Appendix II species, along with Bubinga (Guibourtia demeusei, G. pellegriniana, and G. tessmanni), other true rosewoods (Dalbergia spp.) and related species found in the Dalbergia genus, such as Tulipwood, Kingwood, and African Blackwood.\n"}
{"id": "4634364", "url": "https://en.wikipedia.org/wiki?curid=4634364", "title": "Delos Mountain", "text": "Delos Mountain\n\nDelos or Delos Mountain was the ancient name of a mountain located in Boeotia, Greece, above the city of Tegyra. The mountain was sacred to Apollo, to whom temples on its slopes were dedicated.\n\n"}
{"id": "39639151", "url": "https://en.wikipedia.org/wiki?curid=39639151", "title": "Depletion force", "text": "Depletion force\n\nA depletion force is an effective attractive force that arises between large colloidal particles that are suspended in a dilute solution of \"depletants\", which are smaller solutes that are preferentially excluded from the vicinity of the large particles. One of the earliest reports of depletion forces that lead to particle coagulation is that of Bondy, who observed the separation or 'creaming' of rubber latex upon addition of polymer depletant molecules (sodium alginate) to solution. More generally, depletants can include polymers, micelles, osmolytes, ink, mud, or paint dispersed in a continuous phase.\n\nDepletion forces are often regarded as entropic forces, as was first explained by the established Asakura-Oosawa model. In this theory the depletion force arises from an increase in osmotic pressure of the surrounding solution when colloidal particles get close enough such that the excluded cosolutes (depletants) cannot fit in between them.\nBecause the particles were considered as hard-core (completely rigid) particles, the emerging picture of the underlying mechanism inducing the force was necessarily entropic.\n\nThe system of colloids and depletants in solution is typically modeled by treating the large colloids and small depletants as dissimilarly sized hard spheres. Hard spheres are characterized as non-interacting and impenetrable spheres. These two fundamental properties of hard spheres are described mathematically by the \"hard-sphere potential\". The hard-sphere potential imposes steric constraint around large spheres which in turn gives rise to \"excluded volume\", that is, volume that is unavailable for small spheres to occupy.\n\nIn a colloidal dispersion, the colloid-colloid interaction potential is approximated as the interaction potential between two hard spheres. For two hard spheres of diameter of formula_1, the interaction potential as a function of interparticle separation is:\n\ncalled the hard-sphere potential where formula_3 is the center-to-center distance between the spheres.\n\nIf both colloids and depletants are in a dispersion, there is interaction potential between colloidal particles and depletant particles that is described similarly by the hard-sphere potential. Again, approximating the particles to be hard-spheres, the interaction potential between colloids of diameter formula_4 and depletant sols of diameter formula_5 is:\n\nwhere formula_3 is the center-to-center distance between the spheres. Typically, depletant particles are very small compared to the colloids so formula_8\n\nThe underlying consequence of the hard-sphere potential is that dispersed colloids cannot penetrate each other and have no mutual attraction or repulsion.\n\nWhen both large colloidal particles and small depletants are in a suspension, there is a region which surrounds every large colloidal particle that is unavailable for the centers of the depletants to occupy. This steric restriction is due to the colloid-depletant hard-sphere potential. The volume of the excluded region is\n\nwhere formula_4 is the diameter of the large spheres and formula_5 is the diameter of the small spheres.\n\nWhen the large spheres get close enough, the excluded volumes surrounding the spheres intersect. The overlapping volumes result in a reduced excluded volume, that is, an increase in the total free volume available to small spheres. The reduced excluded volume, formula_12 can be written\n\nwhere formula_14 is half the width of the lens-shaped region of overlap volume formed by spherical caps. The volume available formula_15 for small spheres is the difference between the total volume of the system and the excluded volume. To determine the available volume for small spheres, there are two distinguishable cases: first, the separation of the large spheres is big enough so small spheres can penetrate in between them; second, the large spheres are close enough so that small spheres cannot penetrate between them. For each case, the available volume for small spheres is given by\n\nIn the latter case small spheres are depleted from the interparticle region between large spheres and a depletion force ensues.\n\nThe depletion force is described as an entropic force because it is fundamentally a manifestation of the second law of thermodynamics, which states that a system tends to increase its entropy. The gain in translational entropy of the depletants, owing to the increased available volume, is much greater than the loss of entropy from flocculation of the colloids. The positive change in entropy lowers the Helmholtz free energy and causes colloidal flocculation to happen spontaneously. The system of colloids and depletants in a solution is modeled as a canonical ensemble of hard spheres for statistical determinations of thermodynamic quantities.\n\nHowever, recent experiments and theoretical models found that depletion forces can be enthalpically driven. In these instances, the intricate balance of interactions between the solution components results in the net exclusion of cosolute from macromolecule. This exclusion results in an effective stabilization of the macromolecule self-association, which can be not only enthalpically dominated, but also entropically unfavorable.\n\nThe total volume available for small spheres increases when the excluded volumes around large spheres overlap. The increased volume allotted for small spheres allows them greater translational freedom which increases their entropy. Because the canonical ensemble is an athermal system at a constant volume the Helmholtz free energy is written\n\nwhere formula_18 is the Helmholtz free energy, formula_19 is the entropy and formula_20 is the temperature. The system's net gain in entropy is positive from increased volume, thus the Helmholtz free energy is negative and depletion flocculation happens spontaneously.\n\nThe free energy of the system is obtained from a statistical definition of Helmholtz free energy\n\nwhere formula_22 is the partition function for the canonical ensemble. The partition function contains statistical information that describes the canonical ensemble including its total volume, the total number of small spheres, the volume available for small spheres to occupy, and the de Broglie wavelength. If hard-spheres are assumed, the partition function formula_22 is\n\nThe volume available for small spheres,formula_15 was calculated above.formula_26 is the number of small spheres and formula_27 is the de Broglie wavelength. Substituting formula_22 into the statistical definition, the Helmholtz free energy now reads\n\nThe magnitude of the depletion force, formula_30 is equal to the change in Helmholtz free energy with distance between two large spheres and is given by\n\nThe entropic nature of depletion forces was proven experimentally in some cases. For example, some polymeric crowders induce entropic depletion forces that stabilize proteins in their native state.\nOther examples include many systems with hard-core only interactions.\n\nThe depletion force is an effect of increased osmotic pressure in the surrounding solution.\nWhen colloids get sufficiently close, that is when their excluded volumes overlap, depletants are expelled from the interparticle region. This region between colloids then becomes a phase of pure solvent. When this occurs, there is a higher depletant concentration in the surrounding solution than in the interparticle region. The resulting density gradient gives rise to an osmotic pressure that is anisotropic in nature, acting on the outer sides of the colloids and promoting flocculation. If the hard-sphere approximation is employed, the osmotic pressure is:\n\nwhere formula_33 is osmotic pressure and formula_34 is number density of small spheres and formula_35 is Boltzmann's constant.\n\nDepletion forces were first described by Sho Asakura and Fumio Oosawa in 1954. In their model, the force is always considered to be attractive. Additionally, the force is considered to be proportional to the osmotic pressure. The Asakura-Oosawa model assumes low macromolecule densities and that the density distribution, formula_36, of the macromolecules is constant. Asakura and Oosawa described four cases in which depletion forces would occur. They first described the most general case as two solid plates in a solution of macromolecules. The principles for the first case were then extended to three additional cases. \nIn the Asakura-Oosawa model for depletion forces, the change in free-energy imposed by an excluded cosolute, formula_37, is:\n\nwhere formula_39 is the osmotic pressure, and formula_40 is the change in excluded volume (which is related to molecular size and shape). The very same result can be derived using the Kirkwood-Buff solution theory.\n\nIn the first case, two solid plates are placed in a solution of rigid spherical macromolecules. If the distance between two plates, formula_41, is smaller than the diameter of solute molecules, formula_5, then no solute can enter between the plates. This results in pure solvent existing between the plates. The difference in concentration of macromolecules in the solution between the plates and the bulk solution causes a force equal to the osmotic pressure to act on the plates. In a very dilute and monodisperse solution the force is defined by\n\nwhere formula_44 is the force, and formula_26 is the total number of solute molecules. The force causes the entropy of the macromolecules to increase and is attractive when formula_46\n\nAsakura and Oosawa described the second case as consisting of two plates in a solution of rod like macromolecules. The rod like macromolecules are described as having a length, formula_47, where formula_48, the area of the plates. As the length of the rods increases, the concentration of the rods between the plates is decreased as it becomes more difficult for the rods to enter between the plates due to steric hindrances. As a result, the force acting on the plates increases with the length of the rods until it becomes equal to the osmotic pressure. In this context, it is worth mentioning that even the isotropic-nematic transition of lyotropic liquid crystals, as first explained in Onsager's theory, can in itself be considered a special case of depletion forces.\n\nThe third case described by Asakura and Oosawa is two plates in a solution of polymers. Due to the size of the polymers, the concentration of polymers in the neighborhood of the plates is reduced, which result the conformational entropy of the polymers being decreased. The case can be approximated by modeling it as diffusion in a vessel with walls which absorb diffusing particles. The force, formula_44, can then be calculated according to:\n\nIn this equation formula_51 is the attraction from the osmotic effect. formula_52 is the repulsion due to chain molecules confined between plates. formula_44 is on order of formula_54, the mean end-to-end distance of chain molecules in free space.\n\nThe final case described by Asakura and Oosawa describes two large, hard spheres of diameter formula_4, in a solution of small, hard spheres of diameter formula_5. If the distance between the center of the spheres, formula_3, is less than formula_58, then the small spheres are excluded from the space between the large spheres. This results in the area between the spheres having a reduced concentration of small spheres and therefore reduced entropy. This reduced entropy causes a force to act upon the large spheres pushing them together. This effect was convincingly demonstrated in experiments with vibrofluidized granular materials where attraction can be directly visualized.\n\nAsakura and Oosawa assumed low concentrations of macromolecules. However, at high concentrations of macromolecules, structural correlation effects in the macromolecular liquid become important. Additionally, the repulsive interaction strength strongly increases for large values of formula_59 (large radius/small radius). In order to account for these issues, the Derjaguin approximation, which is valid for any type of force law, has been applied to depletion forces. The Derjaguin approximation relates the force between two spheres to the force between two plates. The force is then integrated between small regions on one surface and the opposite surface, which is assumed to be locally flat. \n\nIf there are two spheres of radii formula_60 and formula_61 on the formula_62 axis, and the spheres are formula_63 distance apart, where formula_3 is much smaller than formula_60 and formula_61, then the force, formula_67, in the formula_68 direction is\n\nIn this equation, formula_70, and formula_71 is the normal force per unit area between two flat surfaces distance formula_68 apart. \nWhen the Derjaguin approximation is applied to depletion forces, and 0<h<2Rs, then the depletion force given by the Derjaguin approximation is\n\nIn this equation, formula_74 is the geometrical factor, which is set to 1, and formula_75, the interfacial tension at the wall-fluid interface.\n\nAsakura and Oosawa assumed a uniform particle density, which is true in a homogenous solution. However, if an external potential is applied to a solution, then the uniform particle density is disrupted, making Asakura and Oosawa's assumption invalid. Density functional theory accounts for variations in particle density by using the grand canonical potential. The grand canonical potential, which is a state function for the grand canonical ensemble, is used to calculate the probability density for microscopic states in macroscopic state. When applied to depletion forces, the grand canonical potential calculates the local particle densities in a solution.\n\nDensity functional theory states that when any fluid is exposed to an external potential, formula_76, then all equilibrium quantities become functions of number density profile, formula_77. As a result, the total free energy is minimized. The Grand canonical potential, formula_78, is then written\n\nwhere formula_80 is the chemical potential, formula_20 is the temperature, and formula_82 is the helmholtz free energy.\n\nThe original Asakura-Oosawa model considered only hard-core interactions. In such an athermal mixture the origin of depletion forces is necessarily entropic. If the intermolecular potentials also include repulsive and/or attractive terms, and if the solvent is considered explicitly, the depletion interaction can have additional thermodynamic contributions.\n\nThe notion that depletion forces can also be enthalpically driven has surfaced due to recent experiments regarding protein stabilization induced by compatible osmolytes, such as trehalose, glycerol, and sorbitol. These osmolytes are preferentially excluded from protein surfaces, forming a layer of preferential hydration around the proteins. When the protein folds - this exclusion volume diminishes, making the folded state lower in free energy. Hence the excluded osmolytes shift the folding equilibrium towards the folded state. This effect was generally thought to be an entropic force, in the spirit of the original Asakura-Oosawa model and of macromolecular crowding. However, thermodynamic breakdown of the free-energy gain due to osmolyte addition showed the effect is in fact enthalpically driven, whereas entropy can even be disfavorable.\n\nFor many cases, the molecular origin of this enthalpically driven depletion force can be traced to an effective \"soft\" repulsion in the potential of mean force between macromolecule and cosolute. Both Monte-Carlo simulations and a simple analytic model demonstrate that when the hard-core potential (as in Asakura and Oosawa's model) is supplemented with an additional repulsive \"softer\" interaction, the depletion force can become enthalpically dominated.\n\nDepletion forces have been observed and measured using a variety of instrumentation including atomic force microscopy, optical tweezers, and hydrodynamic force balance machines.\n\nAtomic force microscopy (AFM) is commonly used to directly measure the magnitude of depletion forces. This method uses the deflection of a very small cantilever contacting a sample which is measured by a laser. The force required to cause a certain amount of beam deflection can be determined from the change in angle of the laser. The small scale of AFM allows for dispersion particles to be measured directly yielding a relatively accurate measurement of depletion forces.\n\nThe force required to separate two colloid particles can be measured using optical tweezers. This method uses a focused laser beam to apply an attractive or repulsive force on dielectric micro and nanoparticles. This technique is used with dispersion particles by applying a force which resists depletion forces. The displacement of the particles is then measured and used to find the attractive force between the particles.\n\nHFB machines measure the strength of particle interactions using liquid flow to separate the particles. This method is used to find depletion force strength by adhering to a static plate one particle in a dispersion particle doublet and applying shear force through fluid flow. The drag created by the dispersion particles resists the depletion force between them, pulling the free particle away from the adhered particle. A force balance of the particles at separation can be used to determine the depletion force between the particles.\n\nDepletion forces are used extensively as a method of destabilizing colloids. By introducing particles into a colloidal dispersion, attractive depletion forces can be induced between dispersed particles. These attractive interactions bring the dispersed particles together resulting in flocculation. This destabilizes the colloid as the particles are no longer dispersed in the liquid but concentrated in floc formations. Flocs are then easily removed through filtration processes leaving behind a non-dispersed, pure liquid.\n\nThe use of depletion forces to initiate flocculation is a common process in water treatment. The relatively small size of dispersed particles in waste water renders typical filtration methods ineffective. However, if the dispersion was to be destabilized and flocculation occur, particles can then be filtered out to produce pure water. Therefore, coagulants and flocculants are typically introduced to waste water which create these depletion forces between the dispersed particles.\n\nSome wine production methods also use depletion forces to remove dispersed particles from wine. Unwanted colloidal particles can be found in wine originating from the must or produced during the winemaking process. These particles typically consist of carbohydrates, pigmentation molecules, or proteins which may adversely affect the taste and purity of the wine. Therefore, flocculants are often added to induce floc precipitation for easy filtration.\n\nThe table below lists common flocculants along with their chemical formulas, net electrical charge, molecular weight and current applications.\n\nThere are suggestions that depletion forces may be a significant contributor in some biological systems, specifically in membrane interactions between cells or any membranous structure. With concentrations of large molecules such as proteins or carbohydrates in the extracellular matrix, it is likely some depletion force effects are observed between cells or vesicles that are very close. However, due to the complexity of most biological systems, it is difficult to determine how much these depletion forces influence membrane interactions. Models of vesicle interactions with depletion forces have been developed, but these are greatly simplified and their applicability to real biological systems is questionable.\n\nDepletion forces in colloid-polymer mixtures drive colloids to form aggregates that are densely packed locally. This local dense packing is also observed in colloidal systems without polymer depletants. Without polymer depletants the mechanism is similar, because the particles in dense colloidal suspension act, effectively, as depletants for one another This effect is particularly striking for anisotropically shaped colloidal particles, where the anisotropy of the shape leads to the emergence of directional entropic forces that are responsible for the ordering of hard anisotropic colloids into a wide range of crystal structures.\n"}
{"id": "7160369", "url": "https://en.wikipedia.org/wiki?curid=7160369", "title": "EEStor", "text": "EEStor\n\nEEStor is a company based in Cedar Park, Texas, United States that claims to have developed a solid state polymer capacitor for electricity storage. The company claims the device stores more energy than lithium-ion batteries at a lower cost than lead-acid batteries used in gasoline-powered cars. Such a device would revolutionize the electric car industry. Many experts believe these claims are not realistic and EEStor has yet to publicly demonstrate these claims. The corporate slogan is \"Energy Everywhere\". \n\nThe claims are described in detail in several of the company's patents, and . and \n\nThe following is how EEStor's energy storage device (sometimes referred to the EESU) is claimed to compare to electrochemical batteries used for electric cars:\n\n\nSeveral delays in production occurred and there has not been a public demonstration of the uniquely high energy density claims of the inventors. This has led to the speculation that the claims are false. In January 2007 EEStor stated in a press release \"EEStor, Inc. remains on track to begin shipping production 15 kilowatt-hour Electrical Energy Storage Units (EESU) to ZENN Motor Company in 2007 for use in their electric vehicles.\" In September 2007, EEStor co-founder Richard Weir told CNET production would begin in the middle of 2008. In August 2008, it was reported he stated \"as soon as possible in 2009\". ZENN Motor Company (ZMC) denied there was a delay, just a clarification of the schedule, separating \"development\" and \"commercialization\". In March 2008 Zenn stated in a quarterly report a \"late 2009\" launch was scheduled for an EEStor-enabled EV. In December 2009 Zenn announced that production of the lead acid based ZENN LSV would end April 30, 2010. At that time Zenn did not announce a date for production of an EEstor based car.\n\nIn July 2009 ZENN Motor Company invested an additional $5 million in EEStor, increasing its share of ownership to 10.7%. A Zenn press release indicates they were able to get a 10.7% stake because other EEStor investors did not increase their stake.\n\nThe company continues to issue press releases on its ongoing research and activities. No products have been made for commercial sales. \nEEStor's claims for the EESU exceed by orders of magnitude the energy storage capacity of any capacitor currently sold. Many in the industry have expressed skepticism about the claims. Jim Miller, vice president of advanced transportation technologies at Maxwell Technologies and capacitor expert, stated he was skeptical because of current leakage typically seen at high voltages and because there should be microfractures from temperature changes. He stated \"I'm surprised that Kleiner has put money into it.\"\n\nEEStor's claims for the comprehensive permittivity, breakdown strength, and leakage performance of their dielectric material far exceeded those understood to be consistent with the fundamental physical capabilities of any known elemental material or composite structure. For example, the thermochemical theory of polar molecular bond strengths has been confirmed to be valid for a wide range of materials, and shows that there exists a near universal inverse relationship between a material's permittivity and its ultimate breakdown strength. EEstor's initially claimed material results exceeded the limits of this fundamental relationship by orders of magnitude.\n\nEEStor reports a large relative permittivity (19818) at an unusually high electric field strength of 350 MV/m, giving 10,000 J/cm in the dielectric. Voltage independence of permittivity was claimed up to 500 V/μm to within 0.25% of low voltage measurements. Variation in permittivity at a single voltage for 10 different components was claimed by measurements in the patent to be less than +/- 0.15%. If true, their capacitors store at least 30 times more energy per volume than (other) cutting-edge methods such as nanotube designs by Dr Schindall at M.I.T., Dr. Ducharme's plastics research, and breakthrough ceramics discussed by Dr. Cann. Northrop Grumman and BASF have also filed patents with similar theoretical energy density claims. \n\nThe EEStor patents cite a journal article and a Philips Corporation patent as exact descriptions of its \"calcined composition-modified barium titanate powder.\" The Philips patent describes \"doped barium-calcium-zirconium-titanate\" (CMBT) and reports a permittivity of up to 33,500 at 1.8 V/μm, but does not report the permittivity at high electric fields such as the 350 V/μm EEStor claims. EEStor coats its 0.64 micrometer (average size) CMBT particles with 10 nm aluminum oxide (6% by volume) and immerses them in 6% PET plastic by volume, giving 88% CMBT. The patent claims the aluminum oxide coating and PET matrix reduce the net permittivity to 88% of the CMBT permittivity. The Philips patent did not use either aluminum oxide or PET. The dielectric in solution is screen-printed and dried in 10 μm layers, alternating with 1 μm aluminum plates (used to apply the working 3500 V).\n\nEEStor's US patent 7033406 mentions aluminum oxide and calcium magnesium aluminosilicate glass as coatings, although their subsequent US patent 7466536 mentions only aluminum oxide. Nickel was mentioned in the earlier US patent as the electrode but the later patent uses 1 μm aluminum plates as a less expensive alternative. According to the patents, both changes were made possible by selecting the PET matrix because it is pliable enough to fill voids at only 180 °C.\n\nEEStor's latest (2016) US patent WO2016094310 mentions a polymer matrix which can include epoxy and ceramic powders including composition modified barium titanate (CMBT). The patent also mentions a layer thickness of 0.1 microns to 100 microns. It also indicates the CMBT particle density in the polymer matrix can be up to 95%. Phase 4 and Phase 5 testing reports used an epoxy/CMBT solution. More recent testing reports from March 2017 are showing samples with CMBT ratios of over 80% and in that same report EEStor mentions plans for near term samples with thickness of 70 microns with plans for greater levels of densification with near complete densification. A targeted near term goal of 110 wh/l energy density 70 micron layer is in development currently.\n\nIn July 2005, Kleiner Perkins Caufield & Byers invested $3 million in EEStor.\n\nIn April 2007, ZENN Motor Company, a Canadian electric vehicle manufacturer, invested $2.5 million in EEStor for 3.8% ownership and exclusive rights to distribute their devices for passenger and utility vehicles weighing up to 1,400 kg (excluding capacitor mass), along with other rights. In July 2009, Zenn invested another $5 million for a 10.7% stake. A Zenn press release indicates they were able to get a 10.7% stake because other EEStor investors did not increase their stake. Zenn has received $34 million from the equity markets in the past 3 years, and spent $10.1 million of the proceeds on EEStor ownership and technology rights. In December 2009 Zenn canceled plans for the car but plans to supply the drive train. By April 2010, Zenn had cancelled all production of electric vehicles, leaving ownership of EEStor and their rights to the technology as their focus. Zenn raised CAD$2 million in April 2012, mostly on the promise of EEStor's technology.\n\nIn January 2008, Lockheed-Martin signed an agreement with EEStor for the exclusive rights to integrate and market EESU units in military and homeland security applications. In December 2008, a patent application was filed by Lockheed-Martin that mentions EEStor's patent as a possible electrical energy storage unit.\n\nIn September 2008, Light Electric Vehicles Company announced an agreement with EEStor to exclusively provide EEStor's devices for the two and three wheel market.\n\nOn December 30, 2013 ZENN announces completion of the purchase of Series A preferred shares of EEStor (includes Kleiner Perkins Caufield & Byers shares and other private holders shares) and the associated rights for US$1.5 million which gives ZENN a total ownership of 41% in EEStor.\n\nOn May 8, 2014 ZENN and EEStor complete an exchange offer which gives ZENN a total ownership of 71.3% in EEStor. Following the ZENN controlling ownership on May 19, Ian Clifford assumes role of CEO following the resignation of James Kofman.\n\nZENN Motor Company Inc. has changed its name to \"EEStor Corporation\" to better reflect the focus and activities of the Company. The name change was approved by shareholders at the Company's annual and special meeting held on March 31, 2015. EEStor Corporation formerly (ZENN Motor Company) publicly trades on the Canadian exchanges as symbol ESU and on the US stock exchanges as OTC stock symbol ZNNMF. EEStor Corporation holds 71% equity while the other percent is held privately.\n\n"}
{"id": "2025734", "url": "https://en.wikipedia.org/wiki?curid=2025734", "title": "Entropic force", "text": "Entropic force\n\nIn physics, an entropic force acting in a system is an emergent phenomenon resulting from the entire system's statistical tendency to increase its entropy, rather than from a particular underlying force on the atomic scale.\nThe entropic force can be considered as a emergent of the entropic interaction. The concept of entropic interaction was usually used in a subjunctive mood. For example: \"macromolecule links, as if, entropically repulse from each other at a short distance and entropically are attracted to each other at a long distance”. In a modern view the entropic interaction is considered to be a real-life interaction, and it is viewed as a mutual influence of open thermodynamic systems on each other by means of transferring information about their states, changing their entropies and translation of these systems into more probable conditions. The entropic interaction is a quintessential physical interaction that is realized by well-known basic interactions (gravitational, electromagnetic, nuclear strong and weak) through the processes that occur elsewhere in the universe including the solar system, our planet Earth, and living organisms. The basic interactions are considered to be daughter of the entropic interaction. The entropic interaction is not a consequence of existence of some entropy charge and a field accompanying it. It should not be referred to as a distribution of the entropy in the space. Entropy interaction reflects only an “order” and “structure” of the space, the state of the space and physical systems in it and, ultimately, affects the energy, behavior and evolution of such systems as well as the space as a whole. The entropic interaction results in the alteration of symmetry, free energy, and other characteristics of the physical system. Using this interaction, all material objects in Nature exert a certain influence on each other, regardless of the distance between them.\n\nIn the canonical ensemble, the entropic force formula_1 associated to a macrostate partition formula_2 is given by:\nformula_3\nwhere formula_4 is the temperature, formula_5 is the entropy associated to the macrostate formula_6 and formula_7 is the present macrostate.\nHeat dispersion\n\nAccording to Mach's principle , local physics laws are determined by a large-scale structure of the universe and changes in any part of the universe affect a corresponding impact on all of its parts First of all, such changes are due by the entropic interaction. Once they have a place in one part of the universe, the entropy of the universe as a whole changes as well. That is, the entire universe “feels” such changes at the same time. In other words, the entropic interaction between different parts of any thermodynamic system happens instantly without the transfer of any material substance, meaning it is always a long-range action. After that, some processes emerge inside the system to transfer some substances or portions of energy in the appropriate direction. These actions are produced by one (or few) of basic interactions according to the mode of short-range action .\n\nHeat dispersion is one of the examples of the entropic interaction. When one side of a metal pole is heated, a non-homogeneous temperature distribution is created along the pole. Because of entropic interaction between different parts of the pole, the entropy of the entire pole will decrease instantly. At the same time, the tendency appears to obtain a homogeneous distribution of the temperature (and by that to increase the entropy of the pole). This would be a long-range action. The process of heat conductivity will emerge to realize this tendency by a short-range action. Overall, this is an example of co-existence of the long and short-range actions in one process.\n\nThe internal energy of an ideal gas depends only on its temperature, and not on the volume of its containing box, so it is not an energy effect that tends to increase the volume of the box as gas pressure does. This implies that the pressure of an ideal gas has an entropic origin.\n\nWhat is the origin of such an entropic force? The most general answer is that the effect of thermal fluctuations tends to bring a thermodynamic system toward a macroscopic state that corresponds to a maximum in the number of microscopic states (or micro-states) that are compatible with this macroscopic state. In other words, thermal fluctuations tend to bring a system toward its macroscopic state of maximum entropy.\n\nThe entropic approach to Brownian movement was initially proposed by R. M. Neumann. Neumann derived the entropic force for a particle undergoing three-dimensional Brownian motion using the Boltzmann equation, denoting this force as a \"diffusional driving force\" or \"radial force\". In the paper, three example systems are shown to exhibit such a force:\n\nA standard example of an entropic force is the elasticity of a freely-jointed polymer molecule. For an ideal chain, maximizing its entropy means reducing the distance between its two free ends. Consequently, a force that tends to collapse the chain is exerted by the ideal chain between its two free ends. This entropic force is proportional to the distance between the two ends. The entropic force by a freely-jointed chain has a clear mechanical origin, and can be computed using constrained Lagrangian dynamics.\n\nAnother example of an entropic force is the hydrophobic force. At room temperature, it partly originates from the loss of entropy by the 3D network of water molecules when they interact with molecules of dissolved substance. Each water molecule is capable of\nTherefore, water molecules can form an extended three-dimensional network. Introduction of a non-hydrogen-bonding surface disrupts this network. The water molecules rearrange themselves around the surface, so as to minimize the number of disrupted hydrogen bonds. This is in contrast to hydrogen fluoride (which can accept 3 but donate only 1) or ammonia (which can donate 3 but accept only 1), which mainly form linear chains.\n\nIf the introduced surface had an ionic or polar nature, there would be water molecules standing upright on 1 (along the axis of an orbital for ionic bond) or 2 (along a resultant polarity axis) of the four sp orbitals. These orientations allow easy movement, i.e. degrees of freedom, and thus lowers entropy minimally. But a non-hydrogen-bonding surface with a moderate curvature forces the water molecule to sit tight on the surface, spreading 3 hydrogen bonds tangential to the surface, which then become locked in a clathrate-like basket shape. Water molecules involved in this clathrate-like basket around the non-hydrogen-bonding surface are constrained in their orientation. Thus, any event that would minimize such a surface is entropically favored. For example, when two such hydrophobic particles come very close, the clathrate-like baskets surrounding them merge. This releases some of the water molecules into the bulk of the water, leading to an increase in entropy.\n\nAnother related and counter-intuitive example of entropic force is protein folding, which is a spontaneous process and where hydrophobic effect also plays a role. Structures of water-soluble proteins typically have a core in which hydrophobic side chains are buried from water, which stabilizes the folded state. Charged and polar side chains are situated on the solvent-exposed surface where they interact with surrounding water molecules. Minimizing the number of hydrophobic side chains exposed to water is the principal driving force behind the folding process,\n\nEntropic forces are important and widespread in the physics of colloids, where they are responsible for the depletion force, and the ordering of hard particles, such as the crystallization of hard spheres, the isotropic-nematic transition in liquid crystal phases of hard rods, and the ordering of hard polyhedra.\nEntropic forces arise in colloidal systems due to the osmotic pressure that comes from particle crowding. This was first discovered in, and is most intuitive for, colloid-polymer mixtures described by the Asakura-Oosawa model. In this model, polymers are approximated as finite-sized spheres that can penetrate one another, but cannot penetrate the colloidal particles. The inability of the polymers to penetrate the colloids leads to a region around the colloids in which the polymer density is reduced. If the regions of reduced polymer density around two colloids overlap with one another, by means of the colloids approaching one another, the polymers in the system gain an additional free volume that is equal to the volume of the intersection of the reduced density regions. The additional free volume causes an increase in the entropy of the polymers, and drives them to form locally dense-packed aggregates. A similar effect occurs in sufficiently dense colloidal systems without polymers, where osmotic pressure also drives the local dense packing of colloids into a diverse array of structures that can be rationally designed by modifying the shape of the particles.\n\nSome forces that are generally regarded as conventional forces have been argued to be actually entropic in nature. These theories remain controversial and are the subject of ongoing work. Matt Visser, professor of mathematics at Victoria University of Wellington, NZ in \"Conservative Entropic Forces\" criticizes selected approaches but generally concludes:\nIn 2009, Erik Verlinde argued that gravity can be explained as an entropic force. It claimed (similar to Jacobson's result) that gravity is a consequence of the \"information associated with the positions of material bodies\". This model combines the thermodynamic approach to gravity with Gerard 't Hooft's holographic principle. It implies that gravity is not a fundamental interaction, but an emergent phenomenon.\n\nIn the wake of the discussion started by Verlinde, entropic explanations for other fundamental forces have been suggested, including Coulomb's law, the electroweak and strong forces. The same approach was argued to explain dark matter, dark energy and Pioneer effect.\n\nIt was argued that causal entropic forces lead to spontaneous emergence of tool use and social cooperation. Causal entropic forces by definition maximize entropy production between the present and future time horizon, rather than just greedily maximizing instantaneous entropy production like typical entropic forces.\n\nA formal simultaneous connection between the mathematical structure of the discovered laws of nature, intelligence and the entropy-like measures of complexity was previously noted in 2000 by Andrei Soklakov in the context of Occam's razor principle.\n"}
{"id": "414770", "url": "https://en.wikipedia.org/wiki?curid=414770", "title": "GIUK gap", "text": "GIUK gap\n\nThe GIUK gap is an area in the northern Atlantic Ocean that forms a naval choke point. Its name is an acronym for \"Greenland, Iceland\", and the \"United Kingdom\", the gap being the open ocean between these three landmasses. The term is typically used in relation to military topics.\n\nThe GIUK gap was particularly important to the Royal Navy, as any attempt by northern European forces to break into the open Atlantic would have to be made either through the heavily defended English Channel, one of the world's busiest seaways, or through one of the exits on either side of Iceland. As the British also control the strategic port of Gibraltar at the entrance to the Mediterranean, this means Spain, France, and Portugal are the only Continental European countries that possess direct access to the Atlantic Ocean that cannot easily be blocked at a choke point by the Royal Navy.\n\nSince the beginning of the twentieth century, the exploitation of the GIUK gap by northern forces and measures to patrol and secure the gap by opposing forces have played an important role in naval and in overall military planning.\n\nFrom the start of World War II in 1939, German ships used the gap to break out from their bases in northern Germany (and from occupied Norway after April 1940) with a view to attacking Allied shipping convoys, but Allied blocking efforts in the North Sea and in the GIUK gap impeded such break-outs. British forces occupied the Faroe Islands in April 1940, and Iceland in May 1940; the United States of America took over effective control of Greenland in 1940. But the German \"Kriegsmarine\" profited greatly from the fall of France in June 1940, after which German submarines could operate from bases on the French coast. Between 1940 and 1942, the Denmark Strait between Iceland and Greenland remained one of the few areas that RAF patrol bombers could not reach, and thus became the centre for considerable action.\n\nThe origin of the term \"gap\" dates to this period, when there was a gap in air coverage known as the Mid-Atlantic gap or the \"Greenland air gap\". This gap was an area that land-based aircraft could not reach and where, as a result, they could not carry out their anti-submarine duties. The air-surveillance gap eventually closed in 1943 when longer-ranged versions of aircraft such as the Short Sunderland and B-24 Liberator came into service.\n\nThe GIUK gap again became the focus of naval planning in the 1950s, as it represented the only available outlet into the Atlantic Ocean for Soviet submarines operating from their bases on the Kola Peninsula. NATO worried that if the Cold War \"turned hot\", naval convoys reinforcing Europe from the U.S. would suffer unacceptable losses if Soviet submarines could operate in the North Atlantic. The United States and Britain based much of their post-war naval strategy on blocking the gap, installing a chain of underwater listening posts right across it during the 1950s - an example of a SOSUS \"sound surveillance system\". This deployment of sonar surveillance in the gap, and elsewhere, hampered the Soviet Northern Fleet's ability to deploy its submarines without detection.\n\nThe Royal Navy's primary mission during the Cold War, excluding its nuclear deterrent role, involved anti-submarine warfare (ASW). The development of the \"Invincible\"-class anti-submarine carriers stemmed from this doctrine: their primary mission involved anti-submarine warfare using Sea King helicopters. The Type 23 frigate originated as a pure ASW platform; its mission expanded following the Falklands War of 1982.\n\nThe Soviets planned to use the GIUK gap to intercept any NATO ships, especially aircraft carriers, heading towards the Soviet Union. Ships and submarines as well as Tupolev Tu-142 maritime-surveillance aircraft aimed to track any threatening ships.\n\nThe advent of longer-ranged Soviet submarine launched ballistic missiles (SLBM's) allowed the Soviet Navy to deploy their ballistic missile submarine (SSBN's) within protected bastions in the Barents Sea and reduced their need to transit the GIUK gap. The much reduced, post-Cold War Russian Navy has even less need to transit the GIUK gap.\n\nCrossing the GIUK gap was a major strategic move for Ocean Venture in 1992, in which 84 NATO ships, including 4 US aircraft carriers, departed from their usual August exercise pattern, deployed a decoy south toward the mid-Atlantic, and then entered waters in a move that had historically been associated with a risk of destabilizing detante.\n\nThe GIUK gap is also a route for migratory birds such as the northern wheatear to cross the Atlantic to reach Greenland and eastern Canada.\n\n\n\nLand:\n"}
{"id": "44770494", "url": "https://en.wikipedia.org/wiki?curid=44770494", "title": "Greg Gershuny", "text": "Greg Gershuny\n\nGreg Gershuny is the Managing Director and James E. Rogers Fellow for Energy Policy at the Aspen Institute's Energy and Environment Program, as of January 2016. Prior to joining The Aspen Institute, Gershuny was the Associate Director and Chief of Staff of the U.S. Department of Energy's Office of Energy Policy and Systems Analysis as of July 2015. Prior to that, he was the Director of Energy and Environment at the White House Office of Presidential Personnel, the Confidential Assistant to Carl Wieman at the White House Office of Science and Technology Policy, an Associate at the White House National Economic Council and a Field Organizer on the 2008 Barack Obama Campaign for Change in Hammond, Indiana.\n\nGershuny graduated from George Mason University with a bachelor's degree in Political Conflict History. He was born in New Jersey.\n\n"}
{"id": "45375579", "url": "https://en.wikipedia.org/wiki?curid=45375579", "title": "Himalayan Geothermal Belt", "text": "Himalayan Geothermal Belt\n\nThe Himalayan Geothermal Belt (HGB) is a region that extends for through India, Tibet, Yunnan, Myanmar and Thailand, and that contains many geothermal fields.\n\nThe Himalayan Geothermal Belt was formed as a result of the collision of the Indian Plate with the Eurasian Plate, which created the Himalayas.\nThe belt is more than wide.\nThe HGB has an extension to the westward that shows in warm or hot springs in the Peshawar region of Pakistan. \nThese are clustered along the Main Karakoram Thrust, Main Mantle Thrust and Main Central Thrust.\nSome authors consider that the belt extends yet further west and should be called the Mediterranean-Himalayan Geothermal Belt.\n\nHeat transfer in the HGB mainly occurs in \"heat bands\", wide, within which there are at least 600 associated geothermal systems. \nThese may be interpreted as segments of slip lines caused by deformation of the ductile crust in the Asian tectonic plate.\nIn the eastern Himalayas the heat bands transfer two to three times as much heat as in the western Himalayas. \nThis may be due to the Indian plate rotating in a counter-clockwise direction as it penetrates the Asian plate.\nThe thermal waters in Tibet were thought to be meteoric in origin, and the heat source to be decaying radioactive nuclides. \nDue to studies in the 1990s and deep drilling results it is now thought that the heat source is granite that has remelted to magma due to the collision of the plates.\n\nThe warmest hot spring in the westward extension at is the Garam Chashma Hot Springs, which emerge from in post-collisional leucogranites of the Hindu Kush Range that date from 20–18 Ma. Reservoir temperatures may be as high as .\nIt is not clear whether the circulation of deep groundwater in this region is driven by topography or by tectonic lateral stress.\n\nMore than 150 of the geothermal fields have the potential to generate energy.\nThere is a binary plant in Thailand that generates 300 kWe from 117 degrees C water.\nThe Yangbajain Geothermal Field is in the Lhasa-Gangdise terrane.\nIt is in an active part of a slip-fault zone of the Nyainqentanglha Mountains and fractured Himalayan granite. \nA shallow reservoir has temperatures up to , while a deep reservoir has temperatures up to . \nThe first 1 MWe turbine came into operation in September 1977, and capacity had been increased to 25.18 MWe by 1991.\nAs of 2007 another 7 MWe was being generated by seven small plants in Tibet and Yunnan.\n\n"}
{"id": "2407401", "url": "https://en.wikipedia.org/wiki?curid=2407401", "title": "Home Sweet Homediddly-Dum-Doodily", "text": "Home Sweet Homediddly-Dum-Doodily\n\n\"Home Sweet Homediddly-Dum-Doodily\" is the third episode of \"The Simpsons\"<nowiki>'</nowiki> seventh season. It originally aired on the Fox network in the United States on October 1, 1995. In the episode, the Simpson children are put in the custody of Ned and Maude Flanders after a series of misadventures. Homer and Marge are forced to attend a parenting class so they can get their children back. Learning that none of the children have been baptized, Flanders sets up a baptism, but Homer and Marge are able to stop him just in time.\n\nThe episode was written by Jon Vitti and directed by Susie Dietter. The story was pitched by another writer on the show, George Meyer. It was the first episode on which writers Bill Oakley and Josh Weinstein served as show runners. The episode features cultural references to the 1965 film \"Faster, Pussycat! Kill! Kill!\" and Sonny & Cher's song \"I Got You Babe\". Since airing, the episode has received positive reviews from television critics. It acquired a Nielsen rating of 9.0, and was the fourth highest-rated show on the Fox network the week it aired.\n\nWhen Bart is sent home from school with head lice and Lisa without shoes, Marge and Homer are accused of being negligent parents. Two Child Protective Services agents arrive at their house and take Bart, Lisa, and Maggie to a foster home—right next door, at the house of Ned Flanders. \n\nBart and Lisa hate living with the Flanders, but Maggie enjoys it as she gets more attention from Flanders than she did with Homer. Meanwhile, Homer and Marge are forced to attend a special class for bad parents so they can get their children back. \n\nWhen Flanders finds out that the children were not baptized, he takes it upon himself to give the kids an emergency baptism. When Homer and Marge are declared decent parents, they quickly head for the Springfield River to stop Flanders. Just as Flanders is about to pour holy water on Bart, Homer shoves Bart over to prevent the water from hitting him. The Simpson family is reunited, and they head home together.\n\n\"Home Sweet Homediddly-Dum-Doodily\" was the first episode to be made after Bill Oakley and Josh Weinstein became show runners of \"The Simpsons\". They wanted to start the season with an episode centering on the Simpson family. The story was pitched by writer George Meyer at a story retreat. Story retreats were held twice a year at a hotel room close to the studio lot, where all the writers gathered to pitch their ideas. Seventeen episodes were pitched at this particular story retreat. Out of them all, Weinstein considered this episode to be the best, and he thought the pitch by Meyer was the best he had ever heard. Oakley and Weinstein selected former full-time staff writer Jon Vitti to write the episode, wanting a \"heavy hitter\", since it was going to start the seventh production season. Vitti retained in his script most of what Meyer pitched at the retreat.\n\nThe episode was directed by Susie Dietter. There is a statue portraying \"The Simpsons\" writer John Swartzwelder outside the courthouse in the episode. Oakley said that this was a mistake because he and Weinstein thought that Springfield was located in Swartzwelder County, incorrectly going off a montage in the season three episode \"Dog of Death\". That montage depicts Springfield as being located in Springfield County; Swartzwelder is the adjoining county. The appearance of the female Child Protective Services agent is based on a teacher both Oakley and Weinstein had in high school that they hated. Cast member Hank Azaria's voice for the character Cletus was slightly distorted in this episode because, over the summer between seasons, Azaria and the producers had forgotten what Cletus sounds like.\n\nNed and Maude Flanders sing Maggie to bed with their own version of Sonny & Cher's song \"I Got You Babe\". The \"Itchy & Scratchy\" cartoon that Lisa and Bart watch is called \"Foster, Pussycat! Kill! Kill!\", a reference to the 1965 film \"Faster, Pussycat! Kill! Kill!\". Flanders says that he used to let his sons watch \"My Three Sons\", but it got them \"all worked up\" before bedtime. The headline of a newspaper that Marge gives to Lisa for her history project is \"40 Trampled at Poco Concert\", a reference to American rock band Poco. While riding in Flanders's car, Maggie spins her head around with a scary smile on her face to look at Bart and Lisa, as in the 1973 film \"The Exorcist\".\n\nIn its original broadcast, the episode finished 53rd in the ratings for the week of September 25 to October 1, 1995, with a Nielsen rating of 9.0. The episode was the fourth highest-rated show on the Fox network that week, following \"The X-Files\", \"Beverly Hills, 90210\", and \"Melrose Place\".\n\nSince airing, the episode has received mostly positive reviews from television critics. DVD Movie Guide's Colin Jacobson enjoyed the episode, saying that \"its best elements come from the amusing bizarreness of the Flanders home, but Homer and Marge’s classes are also fun. Chalk this one up as season seven's first great episode.\" Jennifer Malkowski of DVD Verdict considered the best part of the episode to be when Marge tells Bart and Lisa that someday they will have to be adults and take care of themselves, just before Homer comes to Marge about a spider near his car keys. She concluded her review by giving the episode a grade of B+. The authors of the book \"I Can't Believe It's a Bigger and Better Updated Unofficial Simpsons Guide\", Warren Martyn and Adrian Wood, called it \"one of the most disturbing episodes, as Bart and Lisa are dragged into the Flanders' sinister lifestyle.\" They thought the ending, when Ned tries to baptize the children, was \"nail-biting stuff\", and Maggie speaking was \"a truly shocking moment\". The authors added: \"It's astonishing that anything this radical made it on to prime time television. The final moments are perhaps the most moving in the entire series, a wonderful affirmation of everything the series, and the Simpson family, are about.\" Matt Groening, the creator of \"The Simpsons\", thought the episode was \"fantastic\" and he called it one of his favorites. He particularly liked the ending which he thought was \"sweet\".\n\n"}
{"id": "23252595", "url": "https://en.wikipedia.org/wiki?curid=23252595", "title": "Institute of Oil Transportation", "text": "Institute of Oil Transportation\n\nThe Institute of Oil Transportation (IOT) is a design and engineering company in Ukraine. It specialises in the transportation, handling, storage and distribution of crude oil and petroleum products in Ukraine and the Commonwealth of Independent States.\n\n\n\nList of oilfield service companies\n\n"}
{"id": "3125555", "url": "https://en.wikipedia.org/wiki?curid=3125555", "title": "List of Lepidoptera that feed on Eucalyptus", "text": "List of Lepidoptera that feed on Eucalyptus\n\nGum trees, Eucalyptus species, are used as food plants by the caterpillars of a number of Lepidoptera (butterflies and moths). These include:\n\nSpecies which feed exclusively on \"Eucalyptus\"\n\n\nSpecies which feed on \"Eucalyptus\" among other plants\n\n\n"}
{"id": "346404", "url": "https://en.wikipedia.org/wiki?curid=346404", "title": "List of U.S. state and territory flowers", "text": "List of U.S. state and territory flowers\n\nThis is a list of U.S. state and territory flowers:\n\n\n"}
{"id": "19127141", "url": "https://en.wikipedia.org/wiki?curid=19127141", "title": "List of books about nuclear issues", "text": "List of books about nuclear issues\n\nThis is a list of books about nuclear issues. They are non-fiction books which relate to uranium mining, nuclear weapons and/or nuclear power.\n\n\n\n"}
{"id": "10434904", "url": "https://en.wikipedia.org/wiki?curid=10434904", "title": "List of electric power companies in Greece", "text": "List of electric power companies in Greece\n\nThis is a list of every electric power company producing electrical energy in Greece as of March 2007.\n\nThe PPC S.A. (ΔΕΗ) is the biggest electric power company in Greece. It owns and operates 34 major thermal and hydroelectric power plants and 3 aeolic parks of the interconnected power grid of the mainland, as well as 60 autonomous power plants located on Crete, Rhodes and other Greek islands (33 thermal, 2 hydroelectric, 18 aeolic and 5 photovoltaic parks).\n\nThe total installed capacity of PPC's 97 power plants is 12276 MW with a net generation of 52.9 TWh in 2005.\n\n\nThessaloniki Energy S.A. is a subsidiary of Hellenic Petroleum. So far it owns and operates one thermoelectric power station fueled with natural gas of 390 MW installed capacity in Thessaloniki and aims to build two more of the same size and reach 1200 MW in total.\n\nTerna is part of the GEK Terna group. It operates through two subsidiaries in the energy sector.\n\nTerna Energy S.A. is actively involved in wind (Aeolian) power generation. It is one of the first private Greek companies ever to be involved in Renewable Energy Sources and has been licensed for more than 600 MW.\n\nTerna is involved in power generation from thermal units through its subsidiary Heron S.A., which is licensed for the construction and operation of thermoelectric power stations fuelled with natural gas. Heron owns and operates a 147 MW gas fired power plant in Viotia which is designed to cover the system's reserve needs, as well as the needs in periods of high demand, over the following years. The total investment in this project reached 80 million euros.\nAlso, Heron S.A. is registered for another 400 MW power plant, budgeted up to 220 million euros. This project is under development.\n\nProtergia, a subsidiary of Mytilineos Holdings, operates 1.2 GW of power generation facilities, including the 444.48 MW Agios Nikolaos power plant in Viotia, a 436.6 MW power plant, owned by Korinthos Power, at Agioi Theodoroi, a 334 MW power plant, owned by Aluminium of Greece, in Viotia. It also operates 54 MW of wind and solar facilities.\n\nFounded on 16 September 1999. Main shareholders of Enelco are: \n\nEnelco has submitted to the Regulatory Authority for Energy three applications for Generation Authorisations for Elefsina (Attiki), Levadia (Viotia) and Evros (Thrace) locations. Each power plant will be of 360-390 MW capacity and will be fuelled by natural gas. Two of whom (Evros, Levadia) have been already awarded to it.\n\nC.Rokas S.A. is an electric power company in Greece, that produces electricity from renewable energy sources. So far, it owns and operates wind farms with combined installed capacity of 193.3 MW, which produce annually over 525 GWh.\n\nThe main shareholder of C.Rokas S.A. is the Spanish electric power company Iberdrola with a percentage of 52.7%.\n\nKorinthos Power is a subsidiary of Mytilineos Holdings (65%) and Motor Oil Hellas (35%). It operates 436.6 MW power plant at Agioi Theodoroi.\n\n"}
{"id": "22386604", "url": "https://en.wikipedia.org/wiki?curid=22386604", "title": "List of largest National Wildlife Refuges", "text": "List of largest National Wildlife Refuges\n\nHere is a list of the 67 largest National Wildlife Refuges in the 50 United States. It includes all that are larger than 50,000 acres (200 km²), and excludes those in U.S. territories (also officially in the system). Acreage/Area includes water as well as land areas. Statistics are as of 30 September 2007. The eleven largest NWRs are all in the state of Alaska.\n\n"}
{"id": "43935342", "url": "https://en.wikipedia.org/wiki?curid=43935342", "title": "List of mountain passes in Pakistan", "text": "List of mountain passes in Pakistan\n\nThe following is a list of mountain passes in Pakistan:\n\n"}
{"id": "58499181", "url": "https://en.wikipedia.org/wiki?curid=58499181", "title": "List of pipeline accidents in the United States in 2003", "text": "List of pipeline accidents in the United States in 2003\n\nThe following is a list of pipeline accidents in the United States in 2003. It is one of several lists of U.S. pipeline accidents. See also list of natural gas and oil production accidents in the United States.\n\nThis is not a complete list of all pipeline accidents. For natural gas alone, the Pipeline and Hazardous Materials Safety Administration (PHMSA), a United States Department of Transportation agency, has collected data on more than 3,200 accidents deemed serious or significant since 1987.\n\nA \"significant incident\" results in any of the following consequences:\n\nPHMSA and the National Transportation Safety Board (NTSB) post incident data and results of investigations into accidents involving pipelines that carry a variety of products, including natural gas, oil, diesel fuel, gasoline, kerosene, jet fuel, carbon dioxide, and other substances. Occasionally pipelines are repurposed to carry different products.\n"}
{"id": "697481", "url": "https://en.wikipedia.org/wiki?curid=697481", "title": "List of protected areas of Illinois", "text": "List of protected areas of Illinois\n\nIllinois has a variety of protected areas, including 123 state protected areas - state parks, wildlife areas, recreation areas, nature reserves, and state forests. There are also federal and local level protected areas in the state. These levels interact to provide a variety of recreation opportunities and conservation schemes, sometimes in a small area. For instance, Shabbona Lake State Park lies in DeKalb County which has its own forest preserve system, while the city of DeKalb has a park system. There is one UNESCO World Heritage Site in Illinois, Cahokia.\n\nIllinois has a wide variety of state owned and administered protected areas: state parks, state forests, state recreation areas, state fish and wildlife areas, state natural areas, and one state trail. They are all administered by the Illinois Department of Natural Resources. In addition, several of the state historic sites, administered by its Illinois Historic Preservation Division, also include nature reserves.\n\nThere is also one national forest, Shawnee National Forest, and several other sites administered by the National Park Service, including portions of National Trails. There are also National Wildlife Refuges.\n\n\n\n\nThere are no national parks in Illinois but the Parks Service operates the federally owned Lincoln Home National Historic Site in Springfield, Illinois and the Pullman National Monument in Chicago. The Chicago Portage National Historic Site is a NPS-affiliated site which is located in the Forest Preserve District of Cook County’s Portage Woods and Ottawa Trail Woods units. In addition, the NPS partners in the Abraham Lincoln National Heritage Area.\n\n\nState parks are owned by the state and generally administered by the Illinois Department of Natural Resources. \n\nAround 50 usually smaller sites concerning historic structures are owned by the state and administered by the Illinois Historic Preservation Division, some of which may have a nature preservation component, including the Cahokia World Heritage Site and Lincoln's New Salem.\n\nA variety of county and town protected areas exist in Illinois, including city park districts and county-wide Forest Preserve Districts. One of the largest systems is the Forest Preserve District of Cook County, which includes Brookfield Zoo and the Chicago Botanic Garden as well as of open land, or 11 percent of Cook County’s land area.\n\n\n"}
{"id": "15759764", "url": "https://en.wikipedia.org/wiki?curid=15759764", "title": "List of songs about the environment", "text": "List of songs about the environment\n\nThis list of songs about the environment includes only songs whose author has an article in Wikipedia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "48161090", "url": "https://en.wikipedia.org/wiki?curid=48161090", "title": "List of star systems within 25–30 light-years", "text": "List of star systems within 25–30 light-years\n\nThis is a list of star systems within 25-30 light years of Earth.\n\n"}
{"id": "37313260", "url": "https://en.wikipedia.org/wiki?curid=37313260", "title": "List of wilderness study areas", "text": "List of wilderness study areas\n\nThis is a list of some of the wilderness study areas (WSA) in the United States as of December 2009. Wilderness study areas are designated lands that meet criteria of the Wilderness Act and are managed as wilderness by their parent agency, pending final determination by Congress.\n\nThese areas are administered as part of the National Landscape Conservation System managed by the Bureau of Land Management.\n\n"}
{"id": "1261001", "url": "https://en.wikipedia.org/wiki?curid=1261001", "title": "Macroecology", "text": "Macroecology\n\nMacroecology is the subfield of ecology that deals with the study of relationships between organisms and their environment at large spatial scales to characterise and explain statistical patterns of abundance, distribution and diversity. The term was coined by James Brown of the University of New Mexico and Brian Maurer of Michigan State University in a 1989 paper in \"Science\".\n\nMacroecology approaches the idea of studying ecosystems using a \"top down\" approach. It seeks understanding through the study of the properties of the system as a whole; Kevin Gaston and Tim Blackburn make the analogy to seeing the forest for the trees.\n\nMacroecology examines how global development in climate change affect wildlife populations. Classic ecological questions amenable to study through the techniques of macroecology include questions of species richness, latitudinal gradients in species diversity, the species-area curve, range size, body size, and species abundance. For example, the relationship between abundance and range size (why species that maintain large local population sizes tend to be widely distributed, while species that are less abundant tend to have restricted ranges) has received much attention.\n\nScientific journals covering macroecology:\n"}
{"id": "491022", "url": "https://en.wikipedia.org/wiki?curid=491022", "title": "Mass in special relativity", "text": "Mass in special relativity\n\nMass in special relativity incorporates the general understandings from the laws of motion of special relativity along with its concept of mass–energy equivalence. The word \"mass\" is given two meanings in special relativity: one (\"rest\" or \"invariant mass\", and its equivalent \"rest energy\") is an invariant quantity which is the same for all observers in all reference frames; the other (\"relativistic mass\" or the equivalent \"total energy\" of the body) is dependent on the velocity of the observer. The term \"relativistic mass\" tends not to be used in particle and nuclear physics and is often avoided by writers on special relativity. They do, however, talk about the (total) energy of a body, which is the equivalent to its relativistic mass, rather than the rest energy equivalent to its rest mass. The measurable inertia and gravitational attraction of a body in a given frame of reference is determined by its relativistic mass, not merely its rest mass. For example, light has zero rest mass but contributes to the inertia (and weight in a gravitational field) of any system containing it.\n\nFor a discussion of mass in general relativity, see mass in general relativity. For a general discussion including mass in Newtonian mechanics, see the article on mass.\n\nThe term \"mass\" in special relativity usually refers to the rest mass of the object, which is the Newtonian mass as measured by an observer moving along with the object. The \"invariant mass\" is another name for the \"rest mass\" of single particles. The more general invariant mass (calculated with a more complicated formula) loosely corresponds to the \"rest mass\" of a \"system\". Thus, invariant mass is a natural unit of mass used for systems which are being viewed from their center of momentum frame (COM frame), as when any closed system (for example a bottle of hot gas) is weighed, which requires that the measurement be taken in the center of momentum frame where the system has no net momentum. Under such circumstances the invariant mass is equal to the relativistic mass (discussed below), which is the total energy of the system divided by \"c\" (the speed of light squared).\n\nThe concept of invariant mass does not require bound systems of particles, however. As such, it may also be applied to systems of unbound particles in high-speed relative motion. Because of this, it is often employed in particle physics for systems which consist of widely separated high-energy particles. If such systems were derived from a single particle, then the calculation of the invariant mass of such systems, which is a never-changing quantity, will provide the rest mass of the parent particle (because it is conserved over time).\n\nIt is often convenient in calculation that the invariant mass of a system is the total energy of the system (divided by \"c\") in the COM frame (where, by definition, the momentum of the system is zero). However, since the invariant mass of any system is also the same quantity in all inertial frames, it is a quantity often calculated from the total energy in the COM frame, then used to calculate system energies and momenta in other frames where the momenta are not zero, and the system total energy will necessarily be a different quantity than in the COM frame. As with energy and momentum, the invariant mass of a system cannot be destroyed or changed, and it is thus conserved, so long as the system is closed to all influences. (The technical term is isolated system meaning that an idealized boundary is drawn around the system, and no mass/energy is allowed across it.)\n\nThe term \"relativistic mass\" is also sometimes used. This is the sum total quantity of energy in a body or system (divided by \"c\"). As seen from the center of momentum frame, the relativistic mass is also the invariant mass, as discussed above (just as the relativistic energy of a single particle is the same as its rest energy, when seen from its rest frame). For other frames, the relativistic mass (of a body or system of bodies) includes a contribution from the \"net\" kinetic energy of the body (the kinetic energy of the center of mass of the body), and is larger the faster the body moves. Thus, unlike the invariant mass, the \"relativistic mass\" depends on the observer's frame of reference. However, for given single frames of reference and for isolated systems, the relativistic mass is also a conserved quantity.\n\nAlthough some authors present relativistic mass as a \"fundamental\" concept of the theory, it has been argued that this is wrong as the fundamentals of the theory relate to space–time. There is disagreement over whether the concept is pedagogically useful. The notion of mass as a property of an object from Newtonian mechanics does not bear a precise relationship to the concept in relativity. \nOxford lecturer John Roche states that relativistic mass is not referenced in nuclear and particle physics, and that about 60% of authors writing about special relativity do not introduce it.\n\nIf a stationary box contains many particles, it weighs more in its rest frame, the faster the particles are moving. Any energy in the box (including the kinetic energy of the particles) adds to the mass, so that the relative motion of the particles contributes to the mass of the box. But if the box itself is moving (its center of mass is moving), there remains the question of whether the kinetic energy of the overall motion should be included in the mass of the system. The invariant mass is calculated excluding the kinetic energy of the system as a whole (calculated using the single velocity of the box, which is to say the velocity of the box's center of mass), while the relativistic mass is calculated including invariant mass \"plus\" the kinetic energy of the system which is calculated from the velocity of the center of mass.\n\nRelativistic mass and rest mass are both traditional concepts in physics, but the relativistic mass corresponds to the total energy. The relativistic mass is the mass of the system as it would be measured on a scale, but in some cases (such as the box above) this fact remains true only because the system on average must be at rest to be weighed (it must have zero net momentum, which is to say, the measurement is in its center of momentum frame). For example, if an electron in a cyclotron is moving in circles with a relativistic velocity, the mass of the cyclotron+electron system is increased by the relativistic mass of the electron, not by the electron's rest mass. But the same is also true of any closed system, such as an electron-and-box, if the electron bounces at high speed inside the box. It is only the lack of total momentum in the system (the system momenta sum to zero) which allows the kinetic energy of the electron to be \"weighed.\" If the electron is \"stopped\" and weighed, or the scale were somehow sent after it, it would not be moving with respect to the scale, and again the relativistic and rest masses would be the same for the single electron (and would be smaller). In general, relativistic and rest masses are equal only in systems which have no net momentum and the system center of mass is at rest; otherwise they may be different.\n\nThe invariant mass is proportional to the value of the total energy in one reference frame, the frame where the object as a whole is at rest (as defined below in terms of center of mass). This is why the invariant mass is the same as the rest mass for single particles. However, the invariant mass also represents the measured mass when the center of mass is at rest for systems of many particles. This special frame where this occurs is also called the center of momentum frame, and is defined as the inertial frame in which the center of mass of the object is at rest (another way of stating this is that it is the frame in which the momenta of the system's parts add to zero). For compound objects (made of many smaller objects, some of which may be moving) and sets of unbound objects (some of which may also be moving), only the center of mass of the system is required to be at rest, for the object's relativistic mass to be equal to its rest mass.\n\nA so-called \"massless\" particle (such as a photon, or a theoretical graviton) moves at the speed of light in every frame of reference. In this case there is no transformation that will bring the particle to rest. The total energy of such particles becomes smaller and smaller in frames which move faster and faster in the same direction. As such, they have no rest mass, because they can never be measured in a frame where they are at rest. This property of having no rest mass is what causes these particles to be termed \"massless.\" However, even massless particles have a relativistic mass, which varies with their observed energy in various frames of reference,\n\nThe invariant mass is the ratio of four-momentum (the four-dimensional generalization of classical momentum) to four-velocity:\n\nand is also the ratio of four-acceleration to four-force when the rest mass is constant. The four-dimensional form of Newton's second law is:\n\nThe relativistic expressions for \"E\" and \"p\" obey the relativistic energy–momentum relation:\n\nwhere the m is the rest mass, or the invariant mass for systems, and \"E\" is the total energy.\n\nThe equation is also valid for photons, which have m = 0:\n\nand therefore\n\nA photon's momentum is a function of its energy, but it is not proportional to the velocity, which is always c.\n\nFor an object at rest, the momentum p is zero, therefore\n\nThe rest mass is only proportional to the total energy in the rest frame of the object.\n\nWhen the object is moving, the total energy is given by\n\nTo find the form of the momentum and energy as a function of velocity, it can be noted that the four-velocity, which is proportional to formula_8, is the only four-vector associated with the particle's motion, so that if there is a conserved four-momentum formula_9, it must be proportional to this vector. This allows expressing the ratio of energy to momentum as\n\nresulting in a relation between E and v:\n\nThis results in \n\nand\n\nthese expressions can be written as\n\nwhere the factor formula_17\n\nWhen working in units where \"c\" = 1, known as the natural unit system, all the relativistic equations are simplified and the quantities energy, momentum, and mass have the same natural dimension: \n\nThe equation is often written this way because the difference formula_19 is the relativistic length of the energy momentum four-vector, a length which is associated with rest mass or invariant mass in systems. Where \"m\" > 0 and \"p\" = 0, this equation again expresses the mass-energy equivalence \"E\" = \"m\".\n\nThe rest mass of a composite system is not the sum of the rest masses of the parts, unless all the parts are at rest. The total mass of a composite system includes the kinetic energy and field energy in the system.\n\nThe total energy \"E\" of a composite system can be determined by adding together the sum of the energies of its components. The total momentum formula_20 of the system, a vector quantity, can also be computed by adding together the momenta of all its components. Given the total energy \"E\" and the length (magnitude) \"p\" of the total momentum vector formula_20, the invariant mass is given by:\n\nIn a mathematical system where c = 1, for systems of particles (whether bound or unbound) the total system invariant mass is given equivalently by the following:\n\nWhere, again, the particle momenta formula_20 are first summed as vectors, and then the square of their resulting total magnitude (Euclidean norm) is used. This results in a scalar number, which is subtracted from the scalar value of the square of the total energy.\n\nFor such a system, in the special center of momentum frame where momenta sum to zero, again the system mass (called the invariant mass) corresponds to the total system energy or, in units where c=1, is identical to it. This invariant mass for a system remains the same quantity in any inertial frame, although the system total energy and total momenta are functions of the particular inertial frame which is chosen, and will vary in such a way between inertial frames as to keep the invariant mass the same for all observers. Invariant mass thus functions for systems of particles in the same capacity as \"rest mass\" does for single particles.\n\nNote that the invariant mass of an isolated system (i.e., one closed to both mass and energy) is also independent of observer or inertial frame, and is a constant, conserved quantity for isolated systems and single observers, even during chemical and nuclear reactions. The concept of invariant mass is widely used in particle physics, because the invariant mass of a particle's decay products is equal to its rest mass. This is used to make measurements of the mass of particles like the Z boson or the top quark.\n\nTotal energy is an additive conserved quantity (for single observers) in systems and in reactions between particles, but rest mass (in the sense of being a sum of particle rest masses) may not be conserved through an event in which rest masses of particles are converted to other types of energy, such as kinetic energy. Finding the sum of individual particle rest masses would require multiple observers, one for each particle rest inertial frame, and these observers ignore individual particle kinetic energy. Conservation laws require a single observer and a single inertial frame.\n\nIn general, for isolated systems and single observers, relativistic mass is conserved (each observer sees it constant over time), but is not invariant (that is, different observers see different values). Invariant mass, however, is both conserved \"and\" invariant (all single observers see the same value, which does not change over time).\n\nThe relativistic mass corresponds to the energy, so conservation of energy automatically means that relativistic mass is conserved for any given observer and inertial frame. However, this quantity, like the total energy of a particle, is not invariant. This means that, even though it is conserved for any observer during a reaction, its absolute \"value\" will change with the frame of the observer, and for different observers in different frames.\n\nBy contrast, the rest mass and invariant masses of systems and particles are \"both\" conserved \"and\" also invariant. For example: A closed container of gas (closed to energy as well) has a system \"rest mass\" in the sense that it can be weighed on a resting scale, even while it contains moving components. This mass is the invariant mass, which is equal to the total relativistic energy of the container (including the kinetic energy of the gas) only when it is measured in the center of momentum frame. Just as is the case for single particles, the calculated \"rest mass\" of such a container of gas does not change when it is in motion, although its \"relativistic mass\" does change.\n\nThe container may even be subjected to a force which gives it an overall velocity, or else (equivalently) it may be viewed from an inertial frame in which it has an overall velocity (that is, technically, a frame in which its center of mass has a velocity). In this case, its total relativistic mass and energy increase. However, in such a situation, although the container's total relativistic energy and total momenta increase, these energy and momentum increases subtract out in the \"invariant mass\" definition, so that the moving container's invariant mass will be calculated as the same value as if it were measured at rest, on a scale.\n\nAll conservation laws in special relativity (for energy, mass, and momentum) require isolated systems, meaning systems that are totally isolated, with no mass-energy allowed in or out, over time. If a system is isolated, then both total energy and total momentum in the system are conserved over time for any observer in any single inertial frame, though their \"absolute values\" will vary, according to different observers in different inertial frames. The invariant mass of the system is also conserved, but does \"not\" change with different observers. This is also the familiar situation with single particles: all observers calculate \"the same\" particle rest mass (a special case of the invariant mass) no matter how they move (what inertial frame they choose), but different observers see different total energies and momenta for the same particle.\n\nConservation of invariant mass also requires the system to be enclosed so that no heat and radiation (and thus invariant mass) can escape. As in the example above, a physically enclosed or bound system does not need to be completely isolated from external forces for its mass to remain constant, because for bound systems these merely act to change the inertial frame of the system or the observer. Though such actions may change the total energy or momentum of the bound system, these two changes cancel, so that there is no change in the system's invariant mass. This is just the same result as with single particles: their calculated rest mass also remains constant no matter how fast they move, or how fast an observer sees them move.\n\nOn the other hand, for systems which are unbound, the \"closure\" of the system may be enforced by an idealized surface, inasmuch as no mass-energy can be allowed into or out of the test-volume over time, if conservation of system invariant mass is to hold during that time. If a force is allowed to act on (do work on) only one part of such an unbound system, this is equivalent to allowing energy into or out of the system, and the condition of \"closure\" to mass-energy (total isolation) is violated. In this case, conservation of invariant mass of the system also will no longer hold. Such a loss of rest mass in systems when energy is removed, according to \"E=mc\" where \"E\" is the energy removed, and \"m\" is the change in rest mass, reflect changes of mass associated with movement of energy, not \"conversion\" of mass to energy.\n\nAgain, in special relativity, the rest mass of a system is not required to be equal to the sum of the rest masses of the parts (a situation which would be analogous to gross mass-conservation in chemistry). For example, a massive particle can decay into photons which individually have no mass, but which (as a system) preserve the invariant mass of the particle which produced them. Also a box of moving non-interacting particles (e.g., photons, or an ideal gas) will have a larger invariant mass than the sum of the rest masses of the particles which compose it. This is because the total energy of all particles and fields in a system must be summed, and this quantity, as seen in the center of momentum frame, and divided by c, is the system's invariant mass.\n\nIn special relativity, mass is not \"converted\" to energy, for all types of energy still retain their associated mass. Neither energy nor invariant mass can be destroyed in special relativity, and each is separately conserved over time in closed systems. Thus, a system's invariant mass may change \"only\" because invariant mass is allowed to escape, perhaps as light or heat. Thus, when reactions (whether chemical or nuclear) release energy in the form of heat and light, if the heat and light is \"not\" allowed to escape (the system is closed and isolated), the energy will continue to contribute to the system rest mass, and the system mass will not change. Only if the energy is released to the environment will the mass be lost; this is because the associated mass has been allowed out of the system, where it contributes to the mass of the surroundings.\n\nConcepts that were similar to what nowadays is called \"relativistic mass\", were already developed before the advent of special relativity. For example, it was recognized by J. J. Thomson in 1881 that a charged body is harder to set in motion than an uncharged body, which was worked out in more detail by Oliver Heaviside (1889) and George Frederick Charles Searle (1897). So the electrostatic energy behaves as having some sort of electromagnetic mass formula_25, which can increase the normal mechanical mass of the bodies.\nThen, it was pointed out by Thomson and Searle that this electromagnetic mass also increases with velocity. This was further elaborated by Hendrik Lorentz (1899, 1904) in the framework of Lorentz ether theory. He defined mass as the ratio of force to acceleration, not as the ratio of momentum to velocity, so he needed to distinguish between the mass formula_26 parallel to the direction of motion and the mass formula_27 perpendicular to the direction of motion (where formula_28 is the Lorentz factor, \"v\" is the relative velocity between the aether and the object, and \"c\" is the speed of light). Only when the force is perpendicular to the velocity, Lorentz's mass is equal to what is now called \"relativistic mass\". Max Abraham (1902) called formula_29 \"longitudinal mass\" and formula_30 \"transverse mass\" (although Abraham used more complicated expressions than Lorentz's relativistic ones). So, according to Lorentz's theory no body can reach the speed of light because the mass becomes infinitely large at this velocity.\n\nAlso Albert Einstein initially used the concepts of longitudinal and transverse mass in his 1905 electrodynamics paper (equivalent to those of Lorentz, but with a different formula_30 by an unfortunate force definition, which was later corrected), and in another paper in 1906. However, he later abandoned velocity dependent mass concepts (see quote at the end of next section).\n\nThe precise relativistic expression (which is equivalent to Lorentz's) relating force and acceleration for a particle with non-zero rest mass formula_32 moving in the \"x\" direction with velocity \"v\" and associated Lorentz factor formula_33 is\n\nIn special relativity, an object that has nonzero rest mass cannot travel at the speed of light. As the object approaches the speed of light, the object's energy and momentum increase without bound.\n\nIn the first years after 1905, following Lorentz and Einstein, the terms longitudinal and transverse mass were still in use. However, those expressions were replaced by the concept of \"relativistic mass\", an expression which was first defined by Gilbert N. Lewis and Richard C. Tolman in 1909. They defined the total energy and mass of a body as\n\nand of a body at rest\n\nwith the ratio\n\nTolman in 1912 further elaborated on this concept, and stated: “the expression m(1 - v/c) is best suited for THE mass of a moving body.”\n\nIn 1934, Tolman argued that the relativistic mass formula formula_38 holds for all particles, including those moving at the speed of light, while the formula formula_39 only applies to a slower-than-light particle (a particle with a nonzero rest mass). Tolman remarked on this relation that \"We have, moreover, of course the experimental verification of the expression in the case of moving electrons to which we shall call attention in §29. We shall hence have no hesitation in accepting the expression as correct in general for the mass of a moving particle.\"\n\nWhen the relative velocity is zero, formula_33 is simply equal to 1, and the relativistic mass is reduced to the rest mass as one can see in the next two equations below. As the velocity increases toward the speed of light \"c\", the denominator of the right side approaches zero, and consequently formula_33 approaches infinity.\n\nIn the formula for momentum\n\nthe mass that occurs is the relativistic mass. In other words, the relativistic mass is the proportionality constant between the velocity and the momentum.\n\nWhile Newton's second law remains valid in the form\n\nthe derived form formula_44 is not valid because formula_45 in formula_46 is generally not a constant (see the section above on transverse and longitudinal mass).\n\nEven though Einstein initially used the expressions \"longitudinal\" and \"transverse\" mass in two papers (see previous section), in his first paper on formula_47 (1905) he treated \"m\" as what would now be called the \"rest mass\".\nEinstein never derived an equation for \"relativistic mass\", and in later years he expressed his dislike of the idea:\n\nOkun and followers reject the concept of relativistic mass. Also Arnold B. Arons has argued against teaching the concept of relativistic mass:\n\nFor many years it was conventional to enter the discussion of dynamics through derivation of the relativistic mass, that is the mass–velocity relation, and this is probably still the dominant mode in textbooks. More recently, however, it has been increasingly recognized that relativistic mass is a troublesome and dubious concept. [See, for example, Okun (1989).]... The sound and rigorous approach to relativistic dynamics is through direct development of that expression for \"momentum\" that ensures conservation of momentum in all frames:\nrather than through relativistic mass. \n\nC. Alder takes a similarly dismissive stance on mass in relativity. Writing on said subject matter, he says that \"its introduction into the theory of special relativity was much in the way of a historical accident\", noting towards the widespread knowledge of \"E=mc\" and how the public's interpretation of the equation has largely informed how it is taught in higher education. He instead supposes that the difference between rest and relativistic mass should be explicitly taught, so that students know why mass should be thought of as invariant \"in most discussions of inertia.\" \n\nMany contemporary authors such as Taylor and Wheeler avoid using the concept of relativistic mass altogether:\n\nWhile space-time has the unbounded geometry of Minkowski-space, the velocity-space is bounded by \"c\" and has the geometry of hyperbolic geometry where relativistic-mass plays an analogous role to that of Newtonian-mass in the barycentric-coordinates of Euclidean geometry. The connection of velocity to hyperbolic-geometry enables the 3-velocity-dependent relativistic-mass to be related to the 4-velocity Minkowski-formalism.\n\n\n"}
{"id": "53034433", "url": "https://en.wikipedia.org/wiki?curid=53034433", "title": "Mininco Formation", "text": "Mininco Formation\n\nMininco Formation () is a geological formation composed of sediments that deposited during the Pliocene in central Chile. Near Angol the formation reaches thicknesses of up to 300 m. The upper strata of the formation contain tuff layers and coal beds that are rich in leaf fossils. Other fossils that have been found in the formation include fresh-water diatoms and bivalves. \n"}
{"id": "12758957", "url": "https://en.wikipedia.org/wiki?curid=12758957", "title": "Mousterian Pluvial", "text": "Mousterian Pluvial\n\nThe Mousterian Pluvial was a prehistoric wet and rainy (pluvial) period in North Africa. It occurred during the Upper Paleolithic, toward the latter part of the Mousterian era. That is, it began around 50,000 years ago, lasted roughly 20,000 years, and ended about 30,000 years ago.\n\nDuring the Mousterian Pluvial, the now-desiccated regions of northern Africa were well-watered, bearing lakes, swamps, and river systems that no longer exist. What is now the Sahara desert supported typical African wildlife of grassland and woodland environments: herbivores from gazelle to giraffe to ostrich, predators from lion to jackal, even hippopotamus and crocodile, as well as extinct forms like the Pleistocene camel. In these respects the Mousterian Pluvial resembled the earlier Abbassia Pluvial; the later Neolithic Subpluvial was a weaker re-iteration of the same pattern.\n\nThe Mousterian Pluvial was caused by large-scale climatic changes during the last ice age. By 50,000 years ago, the Wisconsin glaciation (\"Würm glaciation\" in Europe) was well-advanced; growing ice sheets in North America and Europe displaced the standard climatic zones of the northern hemisphere southward. The temperate zones of Europe and North America acquired an Arctic or tundra climate, and the rain bands typical of the temperate zones dropped to the latitudes of northern Africa.\n\nCuriously, the same influences that created the Mousterian Pluvial also appear to have brought it to a close. In the period of its fullest development, c. 30,000 to 18,000 years ago, the Laurentide ice sheet covered an enormous geographic area and even increased its altitude to 1750 m (more than 1 mile). It generated its own long term weather patterns, which affected the jet stream passing over the North American continent. The jet stream effectively split in two, creating a new dominant weather pattern over the northern hemisphere that brought harsher conditions to several regions (including parts of Central Asia and the Middle East), changes that included an end to the Mousterian Pluvial and a return to a more arid climate in northern Africa.\n\n\n"}
{"id": "31165657", "url": "https://en.wikipedia.org/wiki?curid=31165657", "title": "Nuclear energy in Ghana", "text": "Nuclear energy in Ghana\n\nThere is only one nuclear reactor in Ghana, the Ghana Research Reactor, located in Accra.\nThe Ghana Atomic Energy Commission has been investigating the use of nuclear power and is a member of the International Nuclear Library Network. The commission is working with the International Atomic Energy Agency to implement nuclear power in Ghana as part of a wider project, Sustainable Energy Development for Sub-Saharan Africa. Ghana also has a Graduate School of Nuclear and Allied Sciences which trains undergraduate and postgraduate students in the techniques of nuclear science application in such areas as agriculture, medicine, and research. Both of these organizations focus more on research and the one research reactor located in Ghana than on nuclear power.\n\nThe government of Ghana planned to commission the building of a nuclear power plant by 2018. President John Agyekum Kufuor supported the future building of nuclear power plants, seeing it as part of a solution to the country's energy problems. He initiated a Nuclear Power Committee to study the issue. In 2011, the director of the National Nuclear Research Institute, Benjamin Nyarko, also said he believed nuclear power could prevent future energy crises. The ministry has created a section to co-ordinate activities on the nuclear power project. In May 2018 decision was made to build 2 units by Russia or China within 6 years.\n\n"}
{"id": "1735570", "url": "https://en.wikipedia.org/wiki?curid=1735570", "title": "Ozone depletion potential", "text": "Ozone depletion potential\n\nThe ozone depletion potential (ODP) of a chemical compound is the relative amount of degradation to the ozone layer it can cause, with trichlorofluoromethane (R-11 or CFC-11) being fixed at an ODP of 1.0. Chlorodifluoromethane (R-22), for example, has an ODP of 0.05. CFC 11, or R-11 has the maximum potential amongst chlorocarbons because of the presence of three chlorine atoms in the molecule.\n\nThe first proposal of ODP came from Wuebbles in 1983. It was defined as a measure of destructive effects of a substance compared to a reference substance.\n\nPrecisely, ODP of a given substance is defined as the ratio of global loss of ozone due to the given substance to the global loss of ozone due to CFC-11 of the same mass.\n\nODP can be estimated from the molecular structure of a given substance. Chlorofluorocarbons have ODPs roughly equal to 1. Brominated substances have usually higher ODPs in range 5–15, because of more aggressive bromine reaction with ozone. Hydrochlorofluorocarbons have ODPs mostly in range 0.005 - 0.2 due to the presence of the hydrogen which causes them to react readily in the troposphere, therefore reducing their chance to reach the stratosphere where the ozone layer is present. Hydrofluorocarbons (HFC) have no chlorine content, so their ODP is essentially zero.\n\nODP is often used in conjunction with a compound's global warming potential (GWP) as a measure of how environmentally detrimental it can be. GWP represents the potential of a substance to contribute to global warming.\n\nIn a broad sense, haloalkanes that contain no hydrogen are stable in the troposphere and decompose only in the stratosphere. Those compounds that contain hydrogen also react with OH radicals and can therefore be decomposed in the troposphere, as well. The ozone depletion potential increases with the heavier halogens since the C-\"X\" bond strength is lower. Note the trend of the CClF-X series in the table below.\n\n"}
{"id": "57769381", "url": "https://en.wikipedia.org/wiki?curid=57769381", "title": "ParkinsonSAT", "text": "ParkinsonSAT\n\nParkinsonSAT, PSat or Naval Academy OSCAR 84, is a U.S. technology demonstration satellite and an amateur radio satellite for Packet Radio. It was built at the U.S. Naval Academy and was planned as a double satellite (ParkinsonSAT A and B). The name ParkinsonSAT was chosen in honor of Bradford Parkinson, the father of the GPS system. After successful launch, the satellite was assigned the OSCAR number 84.\n\nThe satellite was launched on May 20, 2015, with an Atlas V rocket along with the main payload X-37B OTV-4 and 9 other CubeSat satellites (X-37B OTV-4, GEARRS 2, LightSail A, OptiCube 1, OptiCube 2, OptiCube 3, USS Langley, AeroCube 8A, AeroCube 8B and BRICSat-P) from Cape Canaveral AFS, Florida.\n\nParkinsonSAT is a student satellite project. It was partly funded by the Aerospace Corporation. It has a transponder for transmitting telemetry from remote measuring points (eg drifting buoys). This telemetry is to be transmitted to a network of ground stations. A second transponder enables multi-user text transmission in PSK31 mode. This transponder was built by the Brno University of Technology.\n\nOriginally, the project consisted of 2 identical satellites: PSat-A and PSat-B, 2 identical 1.5U Cubesats, which should be brought together in a 3U starter into space. During the long wait for a launch opportunity in 2014, the construction of the satellite was changed again. The solar cells have been replaced by new, more efficient cells. The other originally named PSat-B CubeSat was rebuilt and started as BRICSat-P.\n\n\n"}
{"id": "14387194", "url": "https://en.wikipedia.org/wiki?curid=14387194", "title": "Philip Heldrich", "text": "Philip Heldrich\n\nPhilip Heldrich was an American author of poetry, essays, short stories, and literary criticism, including \"Good Friday\", winner of the X.J. Kennedy Poetry Prize and \"Out Here in the Out There: Essays in a Region of Superlatives\", winner of the Mid-List Press First Series Award for Creative Nonfiction.\n\nHis work appeared widely in anthologies—such as \"American Nature Writing 2001\" edited by John A. Murray (Oregon State University Press) and \"Texas Bound Book III: 22 Texas Stories\" edited by Kay Cattarulla (Texas A&M University Press)--and literary journals including \"North American Review\", \"Florida Review\" (Winner of the Editor's Prize for Nonfiction), \"Flyway (magazine): Journal of Writing and Environment\", \"Ascent (journal)\", \"Seattle Review\", \"Connecticut Review\", \"Louisiana Literature\", \"Poet Lore\", \"South Dakota Review\", and more. His literary criticism and reviews have appeared in \"Studies in Short Fiction\", \"The Southern Quarterly\", \"Great Plains Quarterly\", \"Midwest Quarterly\", \"American Indian Culture and Research Journal\", and others.\n\nAbout \"Good Friday\", author Jonathan Holden remarked:\n\n\"In his magnificent poem 'Momentum,' as throughout \"Good Friday\", the poet Philip Heldrich, like the late W. C. Williams, demonstrates audaciously how, while 'pulled and tugged in the swirl of rush hour traffic,' we can, out of the American quotidian, locate and frame that which is beautiful.\"\n\nFinal Judge X.J. Kennedy added:\n\n\"Philip Heldrich writes shapely poems that go places and share some wisdom with us. . . . He can capture a good deal of territory in a limited number of well-crafted words.\"\nAbout his award-winning collection of essays, \"Out Here in the Out There: Essays in a Region of Superlatives\", the American Library Associations's \"Booklist\" noted:\n\"Poet and pop culture aficionado Heldrich searches for the lyrical within his small midwestern meatpacking town and beyond. For Heldrich, lover of words, there is beauty to be found at the local dump: magazines (Kansas Farmer), discarded beverage bottles (“Golden Sound Basil Seed Drink”), even machine names (the “cram-a-lot” baler is a favorite). The resulting essays are a happy melding of social commentary with the best sort of travel writing. A finely crafted ode to target practice and male bonding set in a high country meadow in Colorado quietly evolves into a memorial for a lost friend. Another piece perfectly captures the surreal nature of the academic conference, made even more dreamlike by taking place in Norman, Oklahoma, five hours before a championship football game. (Heldrich succumbs to Husker and Sooner mania.) Driving around “out there,” whether it be Disneyland or the Central Plains, the author puts pen to paper, accurately capturing the essence of American culture.\"\nPhilip Heldrich served as Executive Director of the Southwest/Texas Popular and American Culture Associations. He was an Associate Professor in the Interdisciplinary Arts & Sciences Program at the \"University of Washington Tacoma\".\n\nHeldrich was diagnosed with cancer in early 2009. He underwent chemotherapy treatment and continued to teach courses in writing fiction, creative nonfiction and poetry. He died on November 11, 2010, due to complications from his illness.\n\n\n\n"}
{"id": "51814784", "url": "https://en.wikipedia.org/wiki?curid=51814784", "title": "Primary minerals", "text": "Primary minerals\n\nA primary mineral is any mineral formed during the original crystallization of the host igneous primary rock and includes the essential mineral(s) used to classify the rock along with any accessory minerals. In ore deposit geology, hypogene processes occur deep below the earth's surface, and tend to form deposits of primary minerals, as opposed to supergene processes that occur at or near the surface, and tend to form secondary minerals.\n\nThe elemental and mineralogical composition of primary rocks is determined by the chemical composition of the volcanic or magmatic flow from which it is formed. Extrusive rocks (such as basalt, rhyolite, andesite and obsidian) and intrusive rocks (such as granite, granodiorite, gabbro and peridotite) contain primary minerals including quartz, feldspar, plagioclase, muscovite, biotite, amphibole, pyroxene and olivine in varying concentrations.\n\nFor the classical discussions of the origin of primary ores, see the two publications \"Ore Deposits\" (1903 and 1913). According to W.A. Tarr (1938) the primary mineral deposits are the result of direct magmatic action; he states that the splitting of magmas results in the basic igneous rocks and their accompanying group of accessory minerals formed by the first crystallization in the magma, on the one hand, and in the acidic igneous rocks and a second group of accessory minerals which were formed by deposition from the residual mother liquors.\n\nModern soil science offers the following definition: \"Primary Minerals: The thickness of the earth's crust varies from 10 km under the ocean to 30 km under the continents. Of the 88 naturally occurring elements on earth, only 8 make [up] most of the crust. The earth's crust and soils are dominated by the silicic acid in combination with Na, Al, K, Ca, Fe and O ions. ...Those elements are components of primary minerals, whereas primary minerals are components of parent rocks. There are almost 3000 known minerals, but only 20 are common and just 10 minerals make up 90 % of the earth's crust. Primary minerals are defined as minerals found in soil but not formed in soil. This definition is different from that of secondary minerals, which are defined as minerals formed in soils.\" This is further defined by Dr. Broome of North Carolina State:\n\nTwo types of minerals are found in natural systems: primary and secondary. \n\nPrimary rocks are the source of primary minerals and primary water.\n\n"}
{"id": "57074205", "url": "https://en.wikipedia.org/wiki?curid=57074205", "title": "SU(2) color superconductivity", "text": "SU(2) color superconductivity\n\nSeveral hundred metals, compounds, alloys and ceramics possess the property of superconductivity at low temperatures. The SU(2) color quark matter adjoins the list of superconducting systems. Although it is a mathematical abstraction, its properties are believed to be closely related to the SU(3) \ncolor quark matter, which exists in nature when ordinary matter is compressed at supranuclear densities above ~ 0.5 10 nucleon/cm<sup>3</sup >.\n\nSuperconducting materials are characterized by the loss of resistance and two parameters: a critical temperature T and a critical magnetic field which brings the \nsuperconductor to its normal state. In 1911, H. Kamerlingh Onnes discovered the superconductivity of mercury at a temperature below 4 K. Later, \nother substances with superconductivity at temperatures up to 30 K were found. Superconductors prevent the penetration of the external magnetic field \ninto the sample when the magnetic field strength is less than the critical value. This effect was called the Meissner effect.\nHigh-temperature superconductivity was discovered in the 1980s. Of the known compounds, the highest critical temperature T = 135 K belongs to \nHgBaCaCuO.\n\nLow-temperature superconductivity has found a theoretical explanation in the model of Bardeen, Cooper, and Schrieffer (BCS theory).\n\nThe physical basis of the model is the phenomenon of Cooper pairing of electrons. Since a pair of electrons carries an integer spin, the correlated states of the electrons can form a Bose-Einstein condensate.\nAn equivalent formalism was developed by Bogoliubov\nand Valatin \n\nCooper pairing of nucleons takes place in ordinary nuclei. The effect manifests itself in the Bethe–Weizsacker mass formula, the last pairing term \nof which describes the correlation energy of two nucleons. Because of the pairing, the binding energy of even-even nuclei systematically exceeds the binding energy of odd-even and \nodd-odd nuclei.\n\nThe superfluid phase of neutron matter exists in neutron stars. \nThe superfluidity is described by the BCS model with a realistic nucleon-nucleon interaction potential.\nBy increasing the density of nuclear matter above the saturation density, quark matter is formed. It is expected that dense quark matter at low \ntemperatures is a color superconductor.\n\nIn the case of the SU(3) color group, a Bose-Einstein condensate of the quark Cooper pairs carries an open color. To meet the requirement of confinement, \na Bose-Einstein condensate of colorless 6-quark states is considered, or the projected BCS theory is used\n\nThe BCS formalism is applicable without modifications to the description of quark matter with color group SU(2), where Cooper pairs are colorless. The Nambu-Jona-Lasinio model \npredicts the existence of the superconducting phase of SU(2) color quark matter at high densities\nThis physical picture is confirmed in the Polyakov-Nambu-Jona-Lasinio model\nand also in lattice QCD models\nin which the properties of cold quark matter can be described based on the first principles of quantum chromodynamics. \nThe possibility of modeling on the lattices of two-color QCD at finite chemical potentials for even numbers of the quark flavors is associated with the positive-definiteness \nof the integral measure and the absence of a sign problem.\n\n"}
{"id": "40946785", "url": "https://en.wikipedia.org/wiki?curid=40946785", "title": "Shkarofsky function", "text": "Shkarofsky function\n\nThe Shkarofsky function is a physics formula which describes the behavior of microwaves. It is named after Canadian physicist Issie Shkarofsky, who first identified the function in 1966.\n\nN.M. Temme and S.S. Sazhin later developed this idea further to give what they called the generalized Shkarofsky function.\n"}
{"id": "2747568", "url": "https://en.wikipedia.org/wiki?curid=2747568", "title": "Strongly symmetric matter", "text": "Strongly symmetric matter\n\nStrongly symmetric matter: If the predictions of supersymmetry and, more so, string theory are correct, then during the time of the Planck Epoch (10 seconds after the Big Bang) all four fundamental forces were of equal strength and united into a single fundamental force. However, shortly thereafter, during the grand unification epoch (10 seconds after the Big Bang) gravity began to separate from the other three forces of electromagnetism, the strong, and weak nuclear force. After gravity had separated, the strong nuclear force was quick to follow and separated itself from the electroweak force, ending the epoch. The phrase 'strongly symmetric matter' refers to the united forces present during the Planck Epoch.\n\n"}
{"id": "9525301", "url": "https://en.wikipedia.org/wiki?curid=9525301", "title": "Taslanizing", "text": "Taslanizing\n\nTaslanizing or taslanising is a process for making air-textured yarns. Taslan is an expired registered trademark of DuPont for this process, first registered on October 19, 1954. In German the word is Luftex. The process is simply feeding a bundle of continuous filament yarns into a small jet nozzle with various amounts of slack (overfeed). High pressure air ( > 100 PSI ) creates a suction and a turbulent airstream which tangles any slack into a yarn with a similar hand as a spun yarn. It is the turbulent airflow that tangles the fibers. This method of yarn productions creates a yarn that is normally more even than a spun yarn and does not pill like a spun yarn.\n\nTaslan is also a name for yarn made using this process.\n"}
{"id": "50701377", "url": "https://en.wikipedia.org/wiki?curid=50701377", "title": "Thiruvengadam Lakshman Sankar", "text": "Thiruvengadam Lakshman Sankar\n\nThiruvengadam Lakshman Sankar is an Indian energy expert, civil servant, corporate executive and the former head of \"Asian Energy Survey\" of the Asian Development Bank. He is a former chairman of the Andhra Pradesh Gas Power Corporation Limited and Transmission Corporation of Andhra Pradesh. Securing his MSc degree in physical chemistry from the University of Madras and MA degree in development economics from Wilson College, he entered the Indian Administrative Service where he held positions such as the Secretary of the Fuel Policy Committee from 1970 to 1975 and the Principal Secretary of the Working Group on Energy Policy from 1978 to 1979. In 2007, he headed a government committee, popularly known as the \"T. L. Shankar Committee\", which proposed ways of reforming Indian coal sector. He is a non-executive chairman of \"KSK Energy Ventures\" and a United Nations adviser on Energy to the governments of Sri Lanka, Tanzania, Jamaica, North Korea and Bangladesh. He is a former board member of Hindustan Petroleum Corporation and a former member of the Integrated Energy Policy Committee of the Planning Commission of India. The Government of India awarded him the third highest civilian honour of the Padma Bhushan, in 2004, for his contributions to society.\n"}
{"id": "38096337", "url": "https://en.wikipedia.org/wiki?curid=38096337", "title": "TurboSwing", "text": "TurboSwing\n\nTurboswing is a type of grease filter used in kitchen ventilation to remove grease particles from the air. It is typically installed inside the extractor hoods of restaurant kitchens. Its operation is based on a rotating filtering medium.\n\nThe main difference between turboswing and most common filters is that in turboswing filters the filtering medium is not static. There is a perforated disk rotating at high speed. When the grease particles go through the rotating disk they are separated from the air.\n\nAfter separation, centrifugal force due to the rotating disk throws particles against the inner walls of the filter. Particles then drip down the walls of the chamber onto the lower collection basin, where they stay until they are removed through the tap at the bottom of the filter dome.\n\nTurboswing filters can remove grease particles starting from 4μm, as opposed to 8μm for common filters. This is because the filtering medium is moving, and this increases the probability of collision between the filter and the particle.\n\nTurboswing filters can work with varying airflows. The grease extraction level is not affected by the airflow. This means that this kind of filter can be used in restaurants that turn down the air volumes at non-peak times in order to save energy.\n\nThe explanation is that if the airflow is lower, the particles go through the rotating disk at a slower speed, therefore increasing, the collision probability. Other filters like cyclonic filters require the airflow to be high on a permanent basis, or else the performance of the filter drops. Therefore, the use of filters like turboswing make it possible to save vast amounts of energy in restaurant kitchen ventilation.\n\nTurboswing grease filters make it possible to do heat recovery with the air of a kitchen. Unlike common filters, turboswing filters extract the small particles responsible for making the heat exchanger dirty.\n\nHeat recovery makes it possible to save energy in the ventilation of a building. In particular, kitchen air is hotter than the air in most other rooms, and therefore a large amount of energy can potentially be saved. However, when it comes to the ventilation of a kitchen, if the correct kind of filter is not used, heat recovery can be very difficult or even impossible, because of the presence of grease particles in the air. Grease particles accumulate at the heat exchanger, rendering it useless very quickly.\n\nIn order to have heat recovery in a kitchen, the air must be completely clear of grease, in other words, both large and small grease particles must be removed from the air. Static filters cannot adequately deal with small particles, therefore making it impossible to recover heat. Turboswing filters exhibit high performance in dealing with small particles, and this is why they enable heat recovery to be done with kitchen air.\n"}
