{"id": "3719339", "url": "https://en.wikipedia.org/wiki?curid=3719339", "title": "1,2-Dichlorotetrafluoroethane", "text": "1,2-Dichlorotetrafluoroethane\n\n1,2-Dichlorotetrafluoroethane, or R-114, also known as cryofluorane (INN), is a chlorofluorocarbon (CFC) with the molecular formula ClFCCFCl. Its primary use has been as a refrigerant. It is a non-flammable gas with a sweetish, chloroform-like odor with the critical point occurring at 145.6 °C and 3.26 MPa. When pressurized or cooled, it is a colorless liquid. It is listed on the Intergovernmental Panel on Climate Change's list of ozone depleting chemicals, and is classified as a Montreal Protocol Class I, group 1 ozone depleting substance.\n\nWhen used as a refrigerant, R-114 is classified as a medium pressure refrigerant.\n\nThe US Navy uses R-114 in its centrifugal chillers in preference to R-11 to avoid air and moisture leakage into the system. While the evaporator of an R-11 charged chiller runs at a vacuum during operation, R-114 yields approximately 0 psig operating pressure in the evaporator.\n\n"}
{"id": "7133058", "url": "https://en.wikipedia.org/wiki?curid=7133058", "title": "Association for International Broadcasting", "text": "Association for International Broadcasting\n\nThe Association for International Broadcasting - AIB - is the not-for-profit, non-governmental trade association that represents and supports international television and radio broadcasters and online broadcasters.\n\nFounded in 1993, the AIB has developed into a truly global organisation whose membership extends from New Zealand west through to the USA. The AIB provides its members with market intelligence, lobbying, networking and marketing support. It publishes the international media magazine, The Channel, that has a regular subscriber base of more than 7,000 senior executives in broadcasting and electronic media organisations in over 120 countries. The AIB also produces regular electronic news letters that reach the desktops of more than 27,000 people worldwide.\n\nThe AIB has an immense collection of data about broadcasting and electronic media covering territories throughout the world. \n\nThe AIB runs an awards festival that celebrates the best in factual TV and radio broadcasting. Called the AIBs, this annual festival attracts entries from broadcasters and independent production companies on every continent. In 2017, the AIBs will be hosted by Matthew Amroliwala, host of Global on BBC World News.\n\nThe AIB is a non-governmental, not-for-profit organisation with its headquarters in the United Kingdom. It is governed by an Executive Council of six members elected from the AIB's membership including representatives of BBC World News, Bloomberg Television, France Medias Monde, DD News, RT channel, Deutsche Welle and Radio Taiwan International. The AIB's permanent staff is led by Chief Executive Simon Spanswick.\n\n"}
{"id": "149270", "url": "https://en.wikipedia.org/wiki?curid=149270", "title": "Atlantic Wall", "text": "Atlantic Wall\n\nThe Atlantic Wall () was an extensive system of coastal defence and fortifications built by Nazi Germany between 1942 and 1944 along the coast of continental Europe and Scandinavia as a defence against an anticipated Allied invasion of Nazi-occupied Europe from the United Kingdom during World War II. The manning and operation of the Atlantic Wall was administratively overseen by the German Army, with some support from Luftwaffe ground forces. The German Navy maintained a separate coastal defence network, organised into a number of sea defence zones.\n\nHitler ordered the construction of the fortifications in 1942. Almost a million French workers were drafted to build it. The wall was frequently mentioned in Nazi propaganda, where its size and strength were usually exaggerated. The fortifications included colossal coastal guns, batteries, mortars, and artillery, and thousands of German troops were stationed in its defences. When the Allies eventually invaded the Normandy beaches in 1944, most of the defences were stormed within hours. Today, ruins of the wall exist in all of the nations where it was built, although many structures have fallen into the ocean or have been demolished over the years.\n\nWorld War II in Europe began on 1 September 1939, with Nazi Germany's invasion of Poland. Two days later, the UK and France declared war on Germany. Poland's geographical location, however, prevented the Allies from intervening directly. Four weeks into the attack, the Germans had successfully occupied Poland.\n\nLess than a month after this victory, Adolf Hitler issued a directive stating that Germany must be ready for an offensive through France and the Low Countries. However, the \"Oberkommando der Wehrmacht\" (German high command; OKW) was convinced that preparations would take at least until the following year. After furious arguments, Hitler reluctantly agreed to wait. In May 1940, three massive German army groups overran France and the Low Countries in little more than six weeks.\n\nPrior to the Atlantic Wall decision, following a number of commando raids, on 2 June 1941 Adolf Hitler asked for maps of the Channel Islands. These were provided next day and by 13 June Hitler had made a decision. Ordering additional men to the Islands and having decided the defences were inadequate, lacking tanks and coastal artillery, the Organisation Todt (OT) was instructed to undertake the building of 200-250 strongpoints in each of the larger islands. The plan was finalised by the OT and submitted to Hitler. The original defence order was reinforced with a second dated 20 October 1941, following a Fuhrer conference on 18 October to discuss the engineers assessment of requirements. Referring to the “permanent fortification” of the Islands to make an impregnable fortress to be completed within 14 months. \"Festungspionierkommandeur XIV\" was created to command the project of fortifying the Channel Islands.\n\nIt was six months later on 23 March 1942 that Hitler issued Führer Directive No. 40, which called for the creation of an \"Atlantic Wall\". He ordered naval and submarine bases to be heavily defended. Fortifications remained concentrated around ports until late in 1943, when defences were increased in other areas. This decision required the army engineers and the OT to organise quickly. Massive supplies of cement, steel reinforcing and armour plate would be required and everything would need to be transported.\n\nNazi propaganda claimed that the wall stretched from the cape of Norway down to the Spanish border.\n\nThe \"Regelbau\" (standard build) system used books of plans for each of over 600 approved types of bunker and casemate, each having a specific purpose, having been updated as enemy constructions were overrun and examined, even testing some to destruction for effectiveness. They incorporated standard features, such as an entrance door at right angles, armoured air intake, steel doors, ventilation and telephones, internal walls being lined with wood, emergency exit system. There were over 200 standardised armour parts.\n\nThe standardisation greatly simplified the manufacture of equipment, the supply of materials and the budgetary and financial control of the construction as well as the speed of planning for construction projects.\n\nTo offset shortages, captured equipment from the French and other occupied armies were incorporated in the defences, casemates designed for non-German artillery, anti tank and machine guns and the use of turrets from obsolete tanks in \"tobrukstand\" pill boxes (tobruk pits).\n\nOrganisation Todt (OT), formed in 1933, had designed the Siegfried Line during the prewar years along the Franco-German border. OT was the chief engineering group responsible for the design and construction of the wall's major gun emplacements and fortifications.\n\nThe OT supplied supervisors and labour as well as organising supplies, machinery and transport to supplement the staff and equipment of construction companies, many of them were German however construction companies in occupied counties bid for contracts. Companies could apply for OT work or could be conscripted. Companies failing to complete their work on time, which was always possible as the OT controlled the material and manpower of each firm, could find themselves closed down, or more likely fined, or taken over or merged with another firm to make a more efficient larger unit, successful firms however could make attractive profits.\n\nThe OT obtained quotes for necessary works and signed contracts with each construction company setting out the price and terms of the contract, such as bonus payments for efficiency, including the wage rates and bonus payments for OT workers (which depended on their nationality and skill). There could be several construction companies working on each site.\n\nLabour comprised skilled volunteers, engineers, designers and supervisors, who were paid and treated well. Second came volunteer workers, often skilled technicians, such as carpenters, plumbers, electricians and metal workers. Again, these workers were paid, took holidays and were well treated. Next came unskilled forced labour, paid very little and treated quite harshly. Lastly came effective slave labour, paid little, badly fed and treated very harshly. The OT ran training courses to improve labour skills.\n\nMassive numbers of workers were needed. The Vichy regime imposed a compulsory labour system, drafting some 600,000 French workers to construct these permanent fortifications along the Dutch, Belgian, and French coasts facing the English Channel. Efficiency of the OT decreased in late 1943 and 1944 as a result of manpower pressures, fuel shortages and the bombing of worksites, such as V-weapons sites, where some volunteer workers refused to work in such dangerous areas.\n\nOT Cherbourg in January 1944 dealt with 34 companies with 15,000 workers and 79 sub contractors. Daily, weekly and monthly reports showing progress, work variations, material used, stocks of material, labour hours used per skill type, the weather, equipment inventory and quality, level of supervision, employee absences, staffing levels, deaths and problems experienced all had to be filed with the OT.\n\nThroughout most of 1942–43, the Atlantic Wall remained a relaxed front for the Axis troops manning it, with only two large-scale British attacks. Operation Chariot, launched near St Nazaire in March 1942, successfully destroyed German pumping machinery for, and severely damaged, the Normandie dry dock and installations. The second attack was the Dieppe Raid, launched near the French port of Dieppe in August 1942 to test the German defences and provide combat experience for Canadian troops. The Germans were defeated at St. Nazaire, but had little difficulty in repulsing the attack at Dieppe, where they inflicted heavy casualties. Although the Dieppe raid was a disaster for the Allies, it alarmed Hitler, who was sure an Allied invasion in the West would shortly follow. Following Dieppe, Hitler gave Field Marshal Gerd von Rundstedt, the overall German Commander-in-Chief in the West, 15 further divisions to shore up the German positions.\n\nEarly in 1944, with an Allied invasion of Nazi-occupied Europe becoming ever more likely, Field Marshal Erwin Rommel was assigned to improve the wall's defences. Believing the existing coastal fortifications to be entirely inadequate, he immediately began strengthening them. Rommel's main concern was Allied air power. He had seen it first-hand when fighting the British and Americans in North Africa, and it had left a profound impression on him. He feared that any German counterattack would be broken up by Allied aircraft long before it could make a difference. Under his direction, hundreds of reinforced concrete pillboxes were built on the beaches, or sometimes slightly inland, to house machine guns, antitank guns, and light and heavy artillery. Land mines and antitank obstacles were planted on the beaches, and underwater obstacles and naval mines were placed in waters just offshore. The intent was to destroy the Allied landing craft before they could unload on the beaches.\n\nBy the time of the Allied invasion, the Germans had laid almost six million mines in Northern France. More gun emplacements and minefields extended inland along roads leading away from the beaches. In likely landing spots for gliders and parachutists, the Germans emplanted slanted poles with sharpened tops, which the troops called \"Rommelspargel\" (\"Rommel's Asparagus\"). Low-lying river and estuarine areas were intentionally flooded. Rommel believed that Germany would inevitably be defeated unless the invasion could be stopped on the beach, declaring, \"It is absolutely necessary that we push the British and Americans back from the beaches. Afterwards it will be too late; the first 24 hours of the invasion will be decisive.\"\n\nThe Channel Islands were heavily fortified, particularly the island of Alderney, which is closest to Britain. Hitler had decreed that one-twelfth of the steel and concrete used in the Atlantic Wall should go to the Channel Islands, because of the propaganda value of controlling British territory. The islands were some of the most densely fortified areas in Europe, with a host of Hohlgangsanlage tunnels, casemates, and coastal artillery positions.\n\nHowever, as the Channel Islands lacked strategic significance, the Allies bypassed them when they invaded Normandy. As a result, the German garrisons stationed on the islands did not surrender until 9 May 1945—one day after Victory in Europe Day. The garrison on Alderney did not surrender until 16 May. Because most of the German garrisons surrendered peacefully, the Channel Islands are host to some of the best-preserved Atlantic Wall sites.\n\nThe commander in Guernsey produced books giving detailed pictures, plans and descriptions of the fortifications in their island, \"Festung Guernsey\".\n\nMany major ports and positions were incorporated into the Atlantic Wall, receiving heavy fortifications. Hitler ordered all positions to fight to the end, and some of them remained in German hands until Germany's unconditional surrender. Several of the port fortresses were resupplied by submarines after being surrounded by Allied Forces. The defenders of these positions included foreign volunteers and Waffen-SS troops.\n\nImmediately after the war, there was little interest in preserving the wall due to the negative memories associated with the Nazi occupation. One of the best preserved parts is the Todt Battery. In 2011, renewed efforts to preserve the wall were spearheaded by organisations in Germany, the Netherlands, and the United Kingdom. Some of the beach fortifications have toppled or are underwater, while the ones further inland are still mainly exist due to their location.\n\nMany French construction companies benefited financially from helping construct the Atlantic wall; these companies were not penalised during the post war period.\n\nThe question has been raised over whether France should declare the wall a National Monument to ensure it is preserved; however no government so far has envisaged this.\n\nAlthough the defensive wall was never fully completed, many bunkers still exist near Ostend, Channel Islands, Scheveningen, Den Haag, Katwijk, and in Scandinavia.\n\n\n\n\n\nhttp://museegrandbunker.com/en/\n"}
{"id": "54991094", "url": "https://en.wikipedia.org/wiki?curid=54991094", "title": "Atlantic and Gulf Coastal Plain Province", "text": "Atlantic and Gulf Coastal Plain Province\n\nThe Atlantic and Gulf Coastal Plain Province is a coastal plain floristic province within the North American Atlantic Region, a floristic region within the Holarctic Kingdom. It lies to the east and south of the Appalachian Province, from southern Nova Scotia to northeastern Mexico. The narrow coastal strip in New England widens in New Jersey to a broad plain through the Delmarva Peninsula, Virginia, the Carolinas, southern Georgia, and much of Florida. Along the Mississippi Embayment, the province stretches up to the confluence of the Ohio and Mississippi rivers in Cairo, Illinois. The province can be further subdivided into the Atlantic coastal plain and Gulf coastal plain.\n\nAlthough no floristic treatment has been attempted on the province, it was designated the 36th biodiversity hotspot in 2016 due to having more than 1,500 endemic plant species combined with 70% habitat loss.\n"}
{"id": "58323037", "url": "https://en.wikipedia.org/wiki?curid=58323037", "title": "Azorus", "text": "Azorus\n\nAzorus or Azoros ( or Ἀζώριον) was a town and polis (city-state) in Perrhaebia in ancient Thessaly situated at the foot of Mount Olympus. Azorus, with the two neighbouring towns of Pythium and Doliche, formed a Tripolis. \n\nDuring the Roman–Seleucid War, the Tripolis was ravaged by an army of the Aetolian League in the year 191 BCE. During the Third Macedonian War the three towns surrendered to the army of Perseus of Macedon in the year 171 BCE, but that same year the Romans reconquered the three. In the year 169 BCE troops arrived from the Roman consul Quintus Marcius Philippus who camped between Azorus and Doliche.\n\nThe three cities minted a common coin with the inscription \"ΤΡΙΠΟΛΙΤΑΝ\".\n\nThe site of Azorus is the \"palaiokastro\" (old fort) at the modern village of Azoros.\n"}
{"id": "23469770", "url": "https://en.wikipedia.org/wiki?curid=23469770", "title": "Bamboo painting", "text": "Bamboo painting\n\nWorks of bamboo painting, usually in ink, are a recognized motif or subgenre of East Asian painting. In a work of bamboo painting in ink, a skilled artist and calligrapher will paint a bamboo stalk or group of stalks with leaves. The contrast between the foreground and background, and between the varying textures represented by the stalks and the leaves, gave scope to the painter to demonstrate his or her mastery with an inkpot and a brush.\n\nThe bamboo painter often inscribes a poem that accompanies the painting and further elucidates the motif. The poem is often an integral part of the work as a whole. A viewer of the work can compare the calligraphy of the poem with the calligraphy of the painting, as both are typically inscribed with the same brush and reflect a similar mood and state of awareness. \n\nA standard primer on classical East Asian bamboo painting is Hu Zhengyan's \"Ten Bamboo Studio Manual of Painting and Calligraphy\" (1633). Because of the volume of bamboo works painted over time, the production of a work of ink bamboo became one of the standard subjects to which an East Asian student could be set in a competitive examination.\nFrom the days of their common origin, Chinese painting and Chinese writing have been allied arts. They use the same equipment and share aims, techniques, and standards. Ever since the beginning, bamboo has been written and also been painted in the same manner, in other words, a work depicting bamboo is both a painting and a piece of calligraphy. There are so-called “bamboo painters” who all their lives paint only bamboo. The bamboo is strong, upright, and dependable. He may bend with the wind, the storm and the rain, but he never breaks. He is a true gentleman of courage and endurance (Ju 1989). \n\nThe bamboo plant came under close observation by many Asians because of its persistence and vegetative productivity. The plant was especially appreciated by men and women educated in the tradition of Confucius. It came to be seen as an exemplar of moral force, and appreciating the bamboo was seen as an act of self-cultivation. It was said of the ink bamboo painter Wen Tong that \"there are whole bamboos in his heart\" (胸有成竹).\n\nBamboo is not exclusive to the Four Noble Kind group. It also belongs to a distinct group where it openly fraternizes with pine trees and plum blossoms. Collectively, they are called the Three Friends of Winter because bamboo and pine do not wither on winter days and the plum blossoms starts blooming during the cold season. \n\nBamboo also exhibits a certain visual appeal on educated people because its silhouette cast by either the sun or moon on the paper windows of a Chinese house produced a poetic effect. Its straight stalk was the symbol of the sage, in that adversity could always bend it but it could never break it. The inner region of the bamboo stalk symbolizes the void that must be established in one's mind before thinking of useful ideas. To put it in simpler terms, one should always have clarity of mind when dealing with things to avoid chaos and to achieve desired results.\n\nOn the technical area, one needed to be an expert with the brush in order to execute perfectly cylindrical, smooth and hard internodes, and thin, translucid, nervous leaves placed in various perspectives. One should also have a keen talent in identifying where to place dark tones and light tones in the painting. \n\nThese characteristics are enough to validate that bamboo is a complete subject because it portrays lasting values one needed to get on with life and it commands a truly talented painter to create varying tones that never repeat.\n\n\nBuhot, Jean, \"Chinese and Japanese Art\"\n\nJu, I-Hsiung. The Book of Bamboo. Art Farm Gallery. 1989\n"}
{"id": "55491676", "url": "https://en.wikipedia.org/wiki?curid=55491676", "title": "Birdsall Briscoe", "text": "Birdsall Briscoe\n\nBirdsall Parmenas Briscoe (June 10, 1876 - 1971) was an American architect active in Texas, especially in Houston. He was known as \"Birdsall Briscoe\" or \"Birdsall P. Briscoe\". Several of his works have been listed on the U.S. National Register of Historic Places for their architecture.\n\nBriscoe was born on June 10, 1876, in Harrisburg, Texas, as son of Andrew Birdsall and Annie Frances (Paine) Briscoe. Andrew Briscoe was a grandfather and John Richardson Harris, founder of Harrisburg, was a great-grandfather. His parents owned a ranch near Goliad, Texas. He left the area to attend a San Antonio Academy, a preparatory school in San Antonio, Texas. He matriculated at Texas A&M University and the University of Texas.\n\nBriscoe trained as an architect under C. Lewis Wilson and Lewis Sterling Green, while later forming a three-year partnership with Green. He opened his own practice in 1912. He shared an office in downtown Houston with fellow architect, Maurice P. Sullivan. He was selected by the River Oaks Company as one of three architects to design nine model homes in the nascent subdivision.\n\nWhile still working outside of a partnership, Briscoe designed three homes in the private street subdivision of Courtlandt Place, Houston. He completed the J. J. Carroll House, the W. T. Carter Jr. House, and the Judson L. Taylor House before World War I. All three are listed on the National Register for Historic Places. He won commissions for two homes in Houston for William Lockhart Clayton, both of which are historic landmarks. The first was the Georgian-Revival home sited on a whole city block in the Southmore Addition. In 1924, Briscoe completed the William L. Clayton Summer House (NRHP-listed) in River Oaks, the first property to be developed in the subdivision.\n\nBriscoe's work can also be found in the Broadacres Historic District in Houston. He designed four houses on South Boulevard with his partner Sam H. Dixon Jr. Two of these the Clarence L. Carter and Walter H. Walne houses employed prominent bays to create an asymmetrical medieval motif. The partners built a federal-style house for William D. Cleveland Jr. and a Spanish-style house for John F. Dickson Jr. They severed the partnership in 1926, after which Briscoe designed another four houses in Broadacres as a sole-practitioner. The first of these, the Cotswold-style Bettie G. Lester House on North Boulevard, marks a transition in Briscoe's work. He built an Italian villa for Burdine Clayton Anderson, then two more homes on North Boulevard, one for Robert W. Wier, and another for Edmond Pincoffs. \n\nBriscoe served as associate architect to John F. Staub in the development of Bayou Bend, a sprawling mansion sited on a fourteen-acre lot in River Oaks. The home was built between 1926 and 1928 under the consultation of Ima Hogg, who lived there with her brothers, Will and Mike. Hogg bequeathed the estate to the Museum of Fine Arts, Houston, which operates the property as a museum annex for the Bayou Bend Collection of decorative arts. Bayou Bend is NRHP-listed.\n\nBriscoe was a veteran of the Spanish-American War and World War I.\n\nBriscoe died on September 19, 1971 in Houston. He was interred at Oak Hill Cemetery in Goliad.\n"}
{"id": "38499897", "url": "https://en.wikipedia.org/wiki?curid=38499897", "title": "Blackfish (film)", "text": "Blackfish (film)\n\nBlackfish is a 2013 American documentary film directed by Gabriela Cowperthwaite. It concerns Tilikum, an orca held by SeaWorld and the controversy over captive killer whales. The film premiered at the 2013 Sundance Film Festival on January 19, 2013, and was picked up by Magnolia Pictures and CNN Films for wider release. It was nominated for the BAFTA Award for Best Documentary.\n\nThe documentary concerns the captivity of Tilikum, an orca involved in the deaths of three individuals, and the consequences of keeping orcas in captivity. The coverage of Tilikum includes his capture in 1983 off the coast of Iceland and his purported harassment by fellow captive orcas at Sealand of the Pacific. Cowperthwaite argues these incidents contributed to the orca's aggression. \n\nThe film includes a testimonial from Lori Marino, director of science with the Nonhuman Rights Project. Cowperthwaite also focuses on SeaWorld's claims that lifespans of orcas in captivity are comparable to those in the wild, typically 30 years for males and 50 years for females, a claim the film argues is false. Other people interviewed include former SeaWorld trainers, such as John Hargrove, who describe their experiences with Tilikum and other captive whales.\n\nThe documentary reports that the whales have experienced extreme stress when their offspring were captured in the wild or when separated after breeding at water parks. The film features footage of attacks on trainers by Tilikum and other captive whales as well as interviews with witnesses.\n\nCowperthwaite began work on the film after the February 2010 death of Tilikum's trainer Dawn Brancheau and in response to the claim that the orca had targeted Brancheau because she had worn her hair in a ponytail. Cowperthwaite argued that this claim had been conjecture and that \"there had to be more to this story\".\n\nThe film premiered at the 2013 Sundance Film Festival on January 19, 2013, and was picked up by Magnolia Pictures and CNN Films for wider release.\n\nOn Rotten Tomatoes, a review aggregator, the film has a score of 98% based on 125 reviews with an average rating of 8/10. The site's critical consensus states, \"\"Blackfish\" is an aggressive, impassioned documentary that will change the way you look at performance killer whales.\" \n\nOn Metacritic, which assigns a weighted average score to reviews from mainstream critics, the film received an average score of 83 out of 100 based on 33 critics indicating \"universal acclaim.\" The \"Deseret News\" called it \"a gripping example of documentary filmmaking at its finest\".\n\nIn release for 14 weeks, the film earned $2,073,582 at the North American domestic box office.\n\nAfter the film's release, former SeaWorld trainer Bridgette Pirtle said the final film was \"a complete '180' from what was originally presented to me.\" In earlier statements, Pirtle praised the film's direction and supported its message. Mark Simmons, one of Tilikum's first trainers, believed few of his interview comments were used \"because the things I said flew in the face of the movie's clear agenda. What I contributed did not support Gabriela or Tim Zimmerman's intent with the film.\"\n\nMichael Scarpuzzi, the vice president for zoological operations and trainer for SeaWorld San Diego, says the film uses Brancheau's death and gruesome details to \"not inform the public, but, rather regrettably, because of the desire to sensationalize.\" He states, \"We have altered how we care for, display and train these extraordinary animals. We have changed the facilities, equipment and procedures at our killer whale habitats. The care and educational presentation of these animals at SeaWorld has been made safer than ever. Does \"Blackfish\" inform its viewers of that fact? No, it does not.\"\n\nIn January 2014, the family of the late trainer Dawn Brancheau said neither they nor the foundation named after her were affiliated with the film, and that they did not believe it accurately reflected Brancheau or her experiences.\n\nSeaWorld Entertainment refused to take part in the production of \"Blackfish\", and later claimed the film was inaccurate, saying in a statement:\nSeaWorld also responded with an open letter rebutting the claims. The Oceanic Preservation Society and The Orca Project, a non-profit focusing on orca in captivity, responded with open letters criticizing SeaWorld's claims. Marine researcher Debbie Giles also offered rebuttals to SeaWorld, finding its assertions inaccurate. Seaworld considers the film to be propaganda.\n\nOn December 31, 2013, the \"Orlando Business Journal\" posted a poll asking if \"Blackfish\" had changed readers' opinions on SeaWorld. The majority of votes stated that the film had not. It was later found that 180 out of 328 votes (55%) originated from a single SeaWorld-hosted IP address. SeaWorld defended the voting, stating that \"each of the votes that came from a SeaWorld domain were cast by team members who are passionate about the incredible work SeaWorld does and the experiences our parks provide.\"\n\nSeaWorld also created a section of its website titled \"Truth About Blackfish,\" addressing the claims stated above and highlighting what it considered other problems with the film.\n\nOn February 27, 2014, SeaWorld filed a complaint with the U.S. Department of Labor, claiming that Lara Padgett, the Occupational Safety and Health Administration investigator, had behaved unethically by aiding the filmmakers. Cowperthwaite denied claims of improper collaboration.\n\nStarting in the summer of 2014, SeaWorld, as Eric Davis, created a number of public relation sites such as Awesome Ocean, Stand With Sea World and I Love SeaWorld, in an effort to share their view, counter what they believed were inaccuracies happening in the public debate, and repair their brand.\n\nReaction to the documentary prompted the bands and singers Heart, Barenaked Ladies, Willie Nelson, Martina McBride, .38 Special, Cheap Trick, REO Speedwagon, Pat Benatar, The Beach Boys, Trace Adkins and Trisha Yearwood to cancel their concerts at the \"Bands, Brew & BBQ\" event at SeaWorld Orlando and Busch Gardens Tampa in 2014.\n\nSeaWorld announced afterward it had suffered a $15.9 million loss, which CEO James Atchison attributed in part to high ticket prices and poor weather.\n\nOverall attendance at SeaWorld parks and Busch Gardens declined by 5% in the first nine months of 2013, though it was unclear if the drop in attendance was due to the influence of the film. SeaWorld claimed attendance figures for its three marine parks — Orlando, San Diego and San Antonio — in the last three months of 2013 were at record levels for that quarter.\n\nIn response to the film, New York State Senator Greg Ball proposed legislation in New York that bans keeping orcas in captivity. In March 2014, California State Assemblyman Richard Bloom introduced the Orca Welfare and Safety Act, a bill in California that would ban entertainment-driven orca captivity and retire all current whales. In June 2014, U.S. Congressmen Adam Schiff and Jared Huffman attached an amendment to the Agriculture Appropriations Act, requiring the USDA to update the Animal Welfare Act in regards to cetacean captivity. It passed with \"unanimous bipartisan support.\" The bill allocates 1 million USD to studying the impacts of captivity on marine mammals. Schiff cited \"Blackfish\" as raising public concern.\n\nAfter the release of \"Blackfish\", Southwest Airlines came under pressure to end its 26-year relationship with SeaWorld. Southwest responded that it was aware of concerns and was \"engaged\" with SeaWorld over them, but that the partnership would continue. In July 2014, it was announced that the partnership would not be renewed. A press release stated that the break was mutual and based on \"shifting priorities\". The petitioning by activists was cited as a possible factor for the split.\n\nIn August 2014, the company announced that attendance and revenue were down about 1% to 2% for the second quarter of 2014 compared with the second quarter of 2013. Additionally, SeaWorld stock prices dropped by 33%. The company attributed the decline to the proposed government legislation related to the documentary. In November 2014, SeaWorld announced that attendance at the parks had dropped 5.2% from the previous year and profits had fallen 28% over that quarter. As of November 2014, the company's stock was down 50% from the previous year.\n\nIn September 2014, the Rosen Law Firm PA announced an investigation into \"potential securities claim\" on behalf of SeaWorld investors. According to the firm, SeaWorld \"acknowledged for the first time the negative publicity may have had a hit and may have been why the attendance has been flat for now and the past quarters.\" The firm will investigate if SeaWorld was aware of the impact and \"chose to downplay that as a reason for its performance results.\" In September 2014, the Rosen Law Firm filed a class action lawsuit. It alleges that SeaWorld \"misled investors by claiming the decrease in attendance at its parks was caused by Easter holiday and other factors\" rather than the release of \"Blackfish\" and improper practices.\n\nSeaWorld said in August 2014 that the film had hurt revenues at its park in San Diego. On December 11, 2014, SeaWorld announced that chief executive Jim Atchison would resign, with an interim successor replacing him on January 15, 2015. The company's share price had fallen 44% in 2014.\n\nIn August 2015, SeaWorld announced a 3% drop in revenue and an 84% drop in net income for the second quarter of 2015 when compared to the previous year. Attendance fell 1.6%, from 6.58 million to 6.48 million.\n\nThe ending to the Disney/Pixar film \"Finding Dory\" was revised after director Andrew Stanton and then-chief creative officer John Lasseter saw the film and spoke with director Gabriela Cowperthwaite. The depiction of a marine park in the film was altered. The film \"Paper Towns\", based on the book by John Green, had scenes featuring SeaWorld cut. Producer Wyck Godfrey explained, \"Since [John] wrote the book, the documentary [\"Blackfish\"] came out. I think it's a little less playful to go to SeaWorld now.\"\n\nIn November 2015, SeaWorld announced plans to end killer-whale shows at its theme park in San Diego. In March 2016, SeaWorld announced it would end its orca breeding program and begin to phase out all live performances using orcas.\n\nComposer Jeff Beal composed the original score, recording a small orchestra at his house in Agoura Hills. While no physical CDs were produced, the score is available for download on iTunes. In July 2016, the Hollywood Chamber Orchestra premiered the concert version of the score, live-to-picture, at the Montalban Theater, conducted by Beal.\n\n\"Blackfish\" was released on DVD and Blu-ray on August 26, 2013 in the UK (Region 2, PAL). Its U.S. release was on November 12, 2013.\n\nThe documentary was broadcast on CNN on October 24, 2013. After the broadcast, CNN aired an Anderson Cooper special with Jack Hanna, Gabriela Cowperthwaite, Naomi Rose and Jack Hurley. This was followed by a special edition of \"Crossfire\" with \"Blackfish\" associate producer Tim Zimmermann debating Grey Stafford, a conservationist, zoologist, and member of the International Marine Animal Trainers Association.\n\nThe documentary aired on BBC Four in the UK on November 21, 2013 as part of the \"Storyville\" documentary series.\n\n\n \n"}
{"id": "1200028", "url": "https://en.wikipedia.org/wiki?curid=1200028", "title": "Bombsite", "text": "Bombsite\n\nA bombsite is the wreckage that remains after a bomb has destroyed a building or other structure.\n\nAfter World War II many European cities remained severely damaged from bombing. London and other British cities which had suffered the Blitz were pock-marked with bombsites, vacant lots covered in the rubble of destroyed buildings. Many postwar children in urban areas shared a common memory of playing their games and riding their bicycles across these desolate environments. There were often abandoned bombshelters of the 'Anderson' type nearby.\n\nIn London, Liverpool, Bristol, etc., across the channel in Berlin and other places these sites were constant reminders of the death and destruction of the war. This was a contributory factor to the European psycho-sociological outlook of the 1950s and 1960s. The German city of Dresden suffered a previously unprecedented level of destruction.\n\nThe rubble of Viennese bombsites and the remnants of the city's battered infrastructure serve as a backdrop to much of the action in the movie \"The Third Man\", written by Graham Greene, an author who would return to this bombsite motif again in his 1954 short story \"The Destructors\".\n\n\n\n"}
{"id": "919617", "url": "https://en.wikipedia.org/wiki?curid=919617", "title": "Catgut", "text": "Catgut\n\nCatgut is a type of cord that is prepared from the natural fibre found in the walls of animal intestines. Catgut makers usually use sheep or goat intestines, but occasionally use the intestines of cattle, hogs, horses, mules, or donkeys. Despite the name, catgut manufacturers do not use cat intestines.\n\nThe word \"catgut\" may have been an abbreviation of the word \"cattlegut\". Alternatively, it may derive by folk etymology from \"kitgut\" or \"kitstring\"—the word \"kit\", meaning fiddle, having at some point been confused with the word \"kit\" for a young cat; The word kit, being derived from fiddle in Welsh, a language whose native speakers are very musical. \n\nFor a long time, catgut was the most common material for the strings of harps, lutes, violins, violas, cellos, and double basses, acoustic guitars and other stringed musical instruments, as well as older marching snare drums. Most musical instruments produced today use strings with cores made of other materials, generally steel or synthetic polymer. Gut strings are the natural choice for many classical and baroque string players, and gut strings are still most commonly preferred in concert-tension pedal/grand and some lever harps because they give a richer, darker sound as well as withstanding high tension within low alto, tenor, and high-bass ranges. Many acoustic guitarists moved away from gut strings in the early 1900s when the C. F. Martin & Company introduced steel strings, which gave greater volume to the guitar. \"The demand for steel came from ensemble players, who couldn't make themselves heard clearly without it.\" Within a few years the majority of Martin guitars were made with steel strings to accommodate the demand. After World War II, most classical and flamenco guitarists switched from catgut to the new nylon strings for their greater smoothness, durability, and stability of intonation.\n\nBefore 1900, the best strings for musical instruments were reputedly from Italy. Musicians believed the best were from Naples, though Rome and other Italian cities also produced excellent strings. Today high quality gut strings are produced mostly in Italy, Germany, and the United States. They are also made elsewhere, for example in India and Morocco, for local use.\n\nCatgut suture was once a widely used material in surgical settings. There is debate about whether to continue using catgut in a medical setting, since cotton is usually cheaper and wounds closed with either cotton or synthetic threads are less prone to infection. Catgut sutures remain in use in developing countries where they are locally less expensive and easier to obtain. Catgut treated with chromium salts, known as chromic catgut, is also used in surgery.\n\nNatural gut is still used as a high-performance string in tennis racquets, although it had more popularity in the past and is being displaced by synthetic strings.\n\nTo prepare catgut, workers clean the small intestines, free them from any fat, and steep them in water. Then they scrape off the external membrane with a blunt knife, and steep the intestines again for some time in potassium hydroxide. Then they smooth and equalize the intestines by drawing them out. Lean animals yield the toughest gut. Next, they twist the prepared gut strands together to make string. String diameter is determined by the thickness of the individual guts, and by the number used. A thin string, such as a violin E, uses only three or four guts, whereas a double bass string may use twenty or more. After twisting and drying, workers polish the strings to the required diameter.\n\nBefore the twentieth century, the strings were simply rubbed with an abrasive to smooth them. Today they are generally ground down to the desired diameter using a centerless grinder. After drying and polishing, workers bleach and disinfect the strings using sulfur dioxide, dye them if necessary, and sort them into sizes.\n\nCatgut sutures are normally treated with a chromium salt solution to resist body enzymes, to slow the absorption process, and are called catgut chromic sutures—whereas untreated catgut sutures are called catgut plain sutures.\n\n\n"}
{"id": "24507636", "url": "https://en.wikipedia.org/wiki?curid=24507636", "title": "Cockercombe tuff", "text": "Cockercombe tuff\n\nCockercombe Tuff is a greenish-grey, hard pyroclastic rock, formed by the compression of volcanic ash containing high quantities of chlorite, which gives it its distinctive colour. It is found almost exclusively in the south-eastern end of the Quantock Hills near Cockercombe, Somerset, England from where it has been quarried for centuries.\n\nQuantock Lodge is built from Cockercombe tuff.\n"}
{"id": "1877181", "url": "https://en.wikipedia.org/wiki?curid=1877181", "title": "Crataeis", "text": "Crataeis\n\nIn Greek mythology, Crataeis (Κραται-ίς, -ίδος, alt. Crataiis) is, by some accounts, the mother of Scylla. In Homer's \"Odyssey\", Circe tells Odysseus:\n\nSeveral authors follow Homer in assigning Crataeis as the mother of Scylla, see Ovid, \"Metamorphoses\" 13.749; Apollodorus, E7.20; Servius on Virgil \"Aeneid\" 3.420; and schol. on Plato, Republic 588c. Neither Homer nor Ovid mention a father for Scylla, but Apollodorus says that the father was either Trienus (Triton?) or Phorcus (a variant of Phorkys), similarly the Plato scholiast, perhaps following Apollodorus, gives the father as Tyrrhenus or Phorcus, while Eustathius on Homer, \"Odyssey\" 12.85 gives the father as Triton.\n\nOther authors have Hecate as Scylla's mother. The Hesiodic \"Megalai Ehoiai\" gives Hecate and Phorbas as the parents of Scylla, while Acusilaus says that Scylla's parents were Hecate and Phorkys (so also schol. \"Odyssey\" 12.85). Perhaps trying to reconcile these conflicting accounts, Apollonius of Rhodes says that Crataeis was another name for Hecate, and that she and Phorcys were the parents of Scylla. Likewise, Semos of Delos (\"FGrHist\" 396 F 22) says that Crataeis was the daughter of Hecate and Triton, and mother of Scylla by Deimos. Stesichorus (alone) names Lamia as the mother of Scylla, possibly the Lamia who was the daughter of Poseidon, while according to Hyginus, Scylla was the offspring of Typhon and Echidna.\n\n"}
{"id": "44503418", "url": "https://en.wikipedia.org/wiki?curid=44503418", "title": "Cretaceous–Paleogene extinction event", "text": "Cretaceous–Paleogene extinction event\n\nThe Cretaceous–Paleogene (K–Pg) extinction event,also known as the Cretaceous–Tertiary (K–T) extinction, was a sudden mass extinction of some three-quarters of the plant and animal species on Earth, approximately 66 million years ago. With the exception of some ectothermic species such as the leatherback sea turtle and crocodiles, no tetrapods weighing more than survived. It marked the end of the Cretaceous period and with it, the entire Mesozoic Era, opening the Cenozoic Era that continues today..\n\nIn the geologic record, the K–Pg event is marked by a thin layer of sediment called the K–Pg boundary, which can be found throughout the world in marine and terrestrial rocks. The boundary clay shows high levels of the metal iridium, which is rare in the Earth's crust, but abundant in asteroids.\n\nAs originally proposed in 1980 by a team of scientists led by Luis Alvarez and his son Walter Alvarez, it is now generally thought that the K–Pg extinction was caused by the impact of a massive comet or asteroid wide, 66 million years ago, which devastated the global environment, mainly through a lingering impact winter which halted photosynthesis in plants and plankton. The impact hypothesis, also known as the Alvarez hypothesis, was bolstered by the discovery of the Chicxulub crater in the Gulf of Mexico in the early 1990s, which provided conclusive evidence that the K–Pg boundary clay represented debris from an asteroid impact. The fact that the extinctions occurred simultaneously provides strong evidence that they were caused by the asteroid. A 2016 drilling project into the Chicxulub peak ring, confirmed that the peak ring comprised granite ejected within minutes from deep in the earth, but contained hardly any gypsum, the usual sulfate-containing sea floor rock in the region: the gypsum would have vaporized and dispersed as an aerosol into the atmosphere, causing longer term effects on the climate and food chain.\n\nOther causal or contributing factors to the extinction may have been the Deccan Traps and other volcanic eruptions, climate change, and sea level change.\n\nA wide range of species perished in the K–Pg extinction, the best-known being the non-avian dinosaurs. It also destroyed a plethora of other terrestrial organisms, including certain mammals, pterosaurs, birds, lizards, insects, and plants. In the oceans, the K–Pg extinction killed off plesiosaurs and the giant marine lizards (Mosasauridae) and devastated fish, sharks, mollusks (especially ammonites, which became extinct), and many species of plankton. It is estimated that 75% or more of all species on Earth vanished. Yet the extinction also provided evolutionary opportunities: in its wake, many groups underwent remarkable adaptive radiation—sudden and prolific divergence into new forms and species within the disrupted and emptied ecological niches. Mammals in particular diversified in the Paleogene, evolving new forms such as horses, whales, bats, and primates. Birds, fish, and perhaps lizards also radiated.\n\nThe K–Pg boundary represents one of the most dramatic turnovers in the fossil record for various calcareous nanoplankton that formed the calcium deposits for which the Cretaceous is named. The turnover in this group is clearly marked at the species level. Statistical analysis of marine losses at this time suggests that the decrease in diversity was caused more by a sharp increase in extinctions than by a decrease in speciation. The K–Pg boundary record of dinoflagellates is not so well understood, mainly because only microbial cysts provide a fossil record, and not all dinoflagellate species have cyst-forming stages, which likely causes diversity to be underestimated. Recent studies indicate that there were no major shifts in dinoflagellates through the boundary layer.\n\n The K–Pg extinction event was severe, global, rapid, and selective, eliminating a vast number of species. Based on marine fossils, it is estimated that 75% or more of all species were made extinct.\n\nThe event appears to have affected all continents at the same time. Non-avian dinosaurs, for example, are known from the Maastrichtian of North America, Europe, Asia, Africa, South America, and Antarctica, but are unknown from the Cenozoic anywhere in the world. Similarly, fossil pollen shows devastation of the plant communities in areas as far apart as New Mexico, Alaska, China, and New Zealand.\n\nDespite the event's severity, there was significant variability in the rate of extinction between and within different clades. Species that depended on photosynthesis declined or became extinct as atmospheric particles blocked sunlight and reduced the solar energy reaching the ground. This plant extinction caused a major reshuffling of the dominant plant groups. Omnivores, insectivores, and carrion-eaters survived the extinction event, perhaps because of the increased availability of their food sources. No purely herbivorous or carnivorous mammals seem to have survived. Rather, the surviving mammals and birds fed on insects, worms, and snails, which in turn fed on detritus (dead plant and animal matter).\n\nIn stream communities, few animal groups became extinct because such communities rely less directly on food from living plants and more on detritus washed in from the land, protecting them from extinction. Similar, but more complex patterns have been found in the oceans. Extinction was more severe among animals living in the water column than among animals living on or in the sea floor. Animals in the water column are almost entirely dependent on primary production from living phytoplankton, while animals on the ocean floor always or sometimes feed on detritus. Coccolithophorids and mollusks (including ammonites, rudists, freshwater snails, and mussels), and those organisms whose food chain included these shell builders, became extinct or suffered heavy losses. For example, it is thought that ammonites were the principal food of mosasaurs, a group of giant marine reptiles that became extinct at the boundary. The largest air-breathing survivors of the event, crocodyliforms and champsosaurs, were semi-aquatic and had access to detritus. Modern crocodilians can live as scavengers and survive for months without food, and their young are small, grow slowly, and feed largely on invertebrates and dead organisms for their first few years. These characteristics have been linked to crocodilian survival at the end of the Cretaceous.\n\nAfter the K–Pg extinction event, biodiversity required substantial time to recover, despite the existence of abundant vacant ecological niches.\n\nRadiolaria have left a geological record since at least the Ordovician times, and their mineral fossil skeletons can be tracked across the K–Pg boundary. There is no evidence of mass extinction of these organisms, and there is support for high productivity of these species in southern high latitudes as a result of cooling temperatures in the early Paleocene. Approximately 46% of diatom species survived the transition from the Cretaceous to the Upper Paleocene, a significant turnover in species but not a catastrophic extinction.\n\nThe occurrence of planktonic foraminifera across the K–Pg boundary has been studied since the 1930s. Research spurred by the possibility of an impact event at the K–Pg boundary resulted in numerous publications detailing planktonic foraminiferal extinction at the boundary, however, there is ongoing debate between groups that think the evidence indicates substantial extinction of these species at the K–Pg boundary, and those who think the evidence supports multiple extinctions and expansions through the boundary.\n\nNumerous species of benthic foraminifera became extinct during the event, presumably because they depend on organic debris for nutrients, while biomass in the ocean is thought to have decreased. As the marine microbiota recovered, however, it is thought that increased speciation of benthic foraminifera resulted from the increase in food sources. Phytoplankton recovery in the early Paleocene provided the food source to support large benthic foraminiferal assemblages, which are mainly detritus-feeding. Ultimate recovery of the benthic populations occurred over several stages lasting several hundred thousand years into the early Paleocene.\n\nThere is significant variation in the fossil record as to the extinction rate of marine invertebrates across the K–Pg boundary. The apparent rate is influenced by a lack of fossil records, rather than extinctions.\n\nOstracods, a class of small crustaceans that were prevalent in the upper Maastrichtian, left fossil deposits in a variety of locations. A review of these fossils shows that ostracod diversity was lower in the Paleocene than any other time in the Cenozoic. Current research cannot ascertain, however, whether the extinctions occurred prior to, or during, the boundary interval.\n\nApproximately 60% of late-Cretaceous Scleractinia coral genera failed to cross the K–Pg boundary into the Paleocene. Further analysis of the coral extinctions shows that approximately 98% of colonial species, ones that inhabit warm, shallow tropical waters, became extinct. The solitary corals, which generally do not form reefs and inhabit colder and deeper (below the photic zone) areas of the ocean were less impacted by the K–Pg boundary. Colonial coral species rely upon symbiosis with photosynthetic algae, which collapsed due to the events surrounding the K–Pg boundary, however, the use of data from coral fossils to support K–Pg extinction and subsequent Paleocene recovery, must be weighed against the changes that occurred in coral ecosystems through the K–Pg boundary.\n\nThe numbers of cephalopod, echinoderm, and bivalve genera exhibited significant diminution after the K–Pg boundary. Most species of brachiopods, a small phylum of marine invertebrates, survived the K–Pg extinction event and diversified during the early Paleocene.\nExcept for nautiloids (represented by the modern order Nautilida) and coleoids (which had already diverged into modern octopodes, squids, and cuttlefish) all other species of the molluscan class Cephalopoda became extinct at the K–Pg boundary. These included the ecologically significant belemnoids, as well as the ammonoids, a group of highly diverse, numerous, and widely distributed shelled cephalopods. Researchers have pointed out that the reproductive strategy of the surviving nautiloids, which rely upon few and larger eggs, played a role in outsurviving their ammonoid counterparts through the extinction event. The ammonoids utilized a planktonic strategy of reproduction (numerous eggs and planktonic larvae), which would have been devastated by the K–Pg extinction event. Additional research has shown that subsequent to this elimination of ammonoids from the global biota, nautiloids began an evolutionary radiation into shell shapes and complexities theretofore known only from ammonoids.\n\nApproximately 35% of echinoderm genera became extinct at the K–Pg boundary, although taxa that thrived in low-latitude, shallow-water environments during the late Cretaceous had the highest extinction rate. Mid-latitude, deep-water echinoderms were much less affected at the K–Pg boundary. The pattern of extinction points to habitat loss, specifically the drowning of carbonate platforms, the shallow-water reefs in existence at that time, by the extinction event.\n\nOther invertebrate groups, including rudists (reef-building clams) and inoceramids (giant relatives of modern scallops), also became extinct at the K–Pg boundary.\n\nThere are substantial fossil records of jawed fishes across the K–Pg boundary, which provide good evidence of extinction patterns of these classes of marine vertebrates. While the deep sea realm was able to remain seemingly unaffected, there was an equal loss between the open marine apex predators and the durophagous demersal feeders on the continental shelf.\n\nWithin cartilaginous fish, approximately 7 out of the 41 families of neoselachians (modern sharks, skates, and rays) disappeared after this event and batoids (skates and rays) lost nearly all the identifiable species, while more than 90% of teleost fish (bony fish) families survived.\n\nIn the Maastrichtian age, 28 shark families and 13 batoid families thrived, of which 25 and 9, respectively, survived the K-T boundary event. 47 of all neoselachian genera cross the K/T boundary, with 85% being sharks. Batoids display with 15% a comparably low survival rate.\n\nThere is evidence of a mass extinction of bony fishes at a fossil site immediately above the K–Pg boundary layer on Seymour Island near Antarctica, apparently precipitated by the K–Pg extinction event, however, the marine and freshwater environments of fishes mitigated environmental effects of the extinction event.\n\nInsect damage to the fossilized leaves of flowering plants from fourteen sites in North America was used as a proxy for insect diversity across the K–Pg boundary and analyzed to determine the rate of extinction. Researchers found that Cretaceous sites, prior to the extinction event, had rich plant and insect-feeding diversity. During the early Paleocene, however, flora were relatively diverse with little predation from insects, even 1.7 million years after the extinction event.\n\nThere is overwhelming evidence of global disruption of plant communities at the K–Pg boundary. Extinctions are seen both in studies of fossil pollen, and fossil leaves. In North America, the data suggests massive devastation and mass extinction of plants at the K–Pg boundary sections, although there were substantial megafloral changes before the boundary. In North America, approximately 57% of plant species became extinct. In high southern hemisphere latitudes, such as New Zealand and Antarctica, the mass die-off of flora caused no significant turnover in species, but dramatic and short-term changes in the relative abundance of plant groups. In some regions, the Paleocene recovery of plants began with recolonizations by fern species, represented as a fern spike in the geologic record; this same pattern of fern recolonization was observed after the 1980 Mount St. Helens eruption.\n\nDue to the wholesale destruction of plants at the K–Pg boundary, there was a proliferation of saprotrophic organisms, such as fungi, that do not require photosynthesis and use nutrients from decaying vegetation. The dominance of fungal species lasted only a few years while the atmosphere cleared and plenty of organic matter to feed on was present. Once the atmosphere cleared, photosynthetic organisms, initially ferns and other ground-level plants, returned. Just two species of fern appear to have dominated the landscape for centuries after the event.\n\nPolyploidy appears to have enhanced the ability of flowering plants to survive the extinction, probably because the additional copies of the genome such plants possessed, allowed them to more readily adapt to the rapidly changing environmental conditions that followed the impact.\n\nThere is limited evidence for extinction of amphibians at the K–Pg boundary. A study of fossil vertebrates across the K–Pg boundary in Montana concluded that no species of amphibian became extinct. Yet there are several species of Maastrichtian amphibian, not included as part of this study, which are unknown from the Paleocene. These include the frog \"Theatonius lancensis\" and the albanerpetontid \"Albanerpeton galaktion\"; therefore, some amphibians do seem to have become extinct at the boundary. The relatively low levels of extinction seen among amphibians probably reflect the low extinction rates seen in freshwater animals.\n\nThe choristoderes (semi-aquatic archosauromorphs) survived across the K–Pg boundary but would die out in the early Miocene. Studies on \"Champsosaurus\"' palatal teeth suggest that there were dietary changes among the various species across the KT event.\n\nMore than 80% of Cretaceous turtle species passed through the K–Pg boundary. Additionally, all six turtle families in existence at the end of the Cretaceous survived into the Paleogene and are represented by living species.\n\nThe living non-archosaurian reptile taxa, lepidosaurians (lizards and tuataras), survived across the K–Pg boundary. Living lepidosaurs include the tuataras (the only living rhynchocephalians) and the squamates.\n\nThe rhynchocephalians were a widespread and relatively successful group of lepidosaurians during the early Mesozoic, but began to decline by the mid-Cretaceous, although they were very successful in the Late Cretaceous of South America. They are represented today by a single genus, located exclusively in New Zealand.\n\nThe order Squamata, which is represented today by lizards, including snakes and amphisbaenians (worm lizards), radiated into various ecological niches during the Jurassic and was successful throughout the Cretaceous. They survived through the K–Pg boundary and are currently the most successful and diverse group of living reptiles, with more than 6,000 extant species. Many families of terrestrial squamates became extinct at the boundary, such as monstersaurians and polyglyphanodonts, and fossil evidence indicates they suffered very heavy losses in the KT event, only recovering 10 million years after it. Giant non-archosaurian aquatic reptiles such as mosasaurs and plesiosaurs, which were the top marine predators of their time, became extinct by the end of the Cretaceous. The ichthyosaurs had disappeared from fossil records before the mass extinction occurred.\n\nThe archosaur clade includes two surviving groups, crocodilians and birds, along with the various extinct groups of non-avian dinosaurs and pterosaurs.\n\nTen families of crocodilians or their close relatives are represented in the Maastrichtian fossil records, of which five died out prior to the K–Pg boundary. Five families have both Maastrichtian and Paleocene fossil representatives. All of the surviving families of crocodyliforms inhabited freshwater and terrestrial environments—except for the Dyrosauridae, which lived in freshwater and marine locations. Approximately 50% of crocodyliform representatives survived across the K–Pg boundary, the only apparent trend being that no large crocodiles survived. Crocodyliform survivability across the boundary may have resulted from their aquatic niche and ability to burrow, which reduced susceptibility to negative environmental effects at the boundary. Jouve and colleagues suggested in 2008 that juvenile marine crocodyliforms lived in freshwater environments as do modern marine crocodile juveniles, which would have helped them survive where other marine reptiles became extinct; freshwater environments were not so strongly affected by the K–Pg extinction event as marine environments were.\n\nOne family of pterosaurs, Azhdarchidae, was definitely present in the Maastrichtian, and it likely became extinct at the K–Pg boundary. These large pterosaurs were the last representatives of a declining group that contained ten families during the mid-Cretaceous. Several other pterosaur lineages may have been present during the Maastrichtian, such as the ornithocheirids, pteranodontids, nyctosaurids, as well as, a possible tapejarid, though they are represented by fragmentary remains that are difficult to assign to any given group. While this was occurring, modern birds were undergoing diversification; traditionally it was thought that they replaced archaic birds and pterosaur groups, possibly due to direct competition, or they simply filled empty niches, but there is no correlation between pterosaur and avian diversities that are conclusive to a competition hypothesis, and small pterosaurs were present in the Late Cretaceous. In fact, at least some niches previously held by birds were reclaimed by pterosaurs prior to the K–Pg event.\n\nMost paleontologists regard birds as the only surviving dinosaurs (see Origin of birds). It is thought that all non-avian theropods became extinct, including then-flourishing groups such as enantiornithines and hesperornithiforms. Several analyses of bird fossils show divergence of species prior to the K–Pg boundary, and that duck, chicken, and ratite bird relatives coexisted with non-avian dinosaurs. Large collections of bird fossils representing a range of different species provides definitive evidence for the persistence of archaic birds to within 300,000 years of the K–Pg boundary. The absence of these birds in the Paleogene is evidence that a mass extinction of archaic birds took place there. A small fraction of the Cretaceous bird species survived the impact, giving rise to today's birds. The only bird group known for certain to have survived the K–Pg boundary is the Aves. Avians may have been able to survive the extinction as a result of their abilities to dive, swim, or seek shelter in water and marshlands. Many species of avians can build burrows, or nest in tree holes or termite nests, all of which provided shelter from the environmental effects at the K–Pg boundary. Long-term survival past the boundary was assured as a result of filling ecological niches left empty by extinction of non-avian dinosaurs.\n\nExcluding a few controversial claims, scientists agree that all non-avian dinosaurs became extinct at the K–Pg boundary. The dinosaur fossil record has been interpreted to show both a decline in diversity and no decline in diversity during the last few million years of the Cretaceous, and it may be that the quality of the dinosaur fossil record is simply not good enough to permit researchers to distinguish between the options. There is no evidence that late Maastrichtian non-avian dinosaurs could burrow, swim, or dive, which suggests they were unable to shelter themselves from the worst parts of any environmental stress that occurred at the K–Pg boundary. It is possible that small dinosaurs (other than birds) did survive, but they would have been deprived of food, as herbivorous dinosaurs would have found plant material scarce and carnivores would have quickly found prey in short supply.\n\nThe growing consensus about the endothermy of dinosaurs (see dinosaur physiology) helps to understand their full extinction in contrast with their close relatives, the crocodilians. Ectothermic (\"cold-blooded\") crocodiles have very limited needs for food (they can survive several months without eating) while endothermic (\"warm-blooded\") animals of similar size need much more food to sustain their faster metabolism. Thus, under the circumstances of food chain disruption previously mentioned, non-avian dinosaurs died, while some crocodiles survived. In this context, the survival of other endothermic animals, such as some birds and mammals, could be due, among other reasons, to their smaller needs for food, related to their small size at the extinction epoch.\n\nWhether the extinction occurred gradually or suddenly has been debated, as both views have support from the fossil record. A study of 29 fossil sites in Catalan Pyrenees of Europe in 2010 supports the view that dinosaurs there had great diversity until the asteroid impact, with more than 100 living species. More recent research indicates that this figure is obscured by taphonomical biases, however, and the sparsity of the continental fossil record. The results of this study, which were based on estimated real global biodiversity, showed that between 628 and 1,078 non-avian dinosaur species were alive at the end of the Cretaceous and underwent sudden extinction after the Cretaceous–Paleogene extinction event. Alternatively, interpretation based on the fossil-bearing rocks along the Red Deer River in Alberta, Canada, supports the gradual extinction of non-avian dinosaurs; during the last 10 million years of the Cretaceous layers there, the number of dinosaur species seems to have decreased from about 45 to approximately 12. Other scientists have made the same assessment following their research.\n\nSeveral researchers support the existence of Paleocene non-avian dinosaurs. Evidence of this existence is based on the discovery of dinosaur remains in the Hell Creek Formation up to above and 40,000 years later than the K–Pg boundary. Pollen samples recovered near a fossilized hadrosaur femur recovered in the Ojo Alamo Sandstone at the San Juan River in Colorado, indicate that the animal lived during the Cenozoic, approximately (about 1 million years after the K–Pg extinction event). If their existence past the K–Pg boundary can be confirmed, these hadrosaurids would be considered a dead clade walking. Scientific consensus, however, is that these fossils were eroded from their original locations and then re-buried in much later sediments (also known as reworked fossils).\n\nAll major Cretaceous mammalian lineages, including monotremes (egg-laying mammals), multituberculates, metatherians, eutherians, dryolestoideans, and gondwanatheres survived the K–Pg extinction event, although they suffered losses. In particular, metatherians largely disappeared from North America, and the Asian deltatheroidans became extinct (aside from the lineage leadng to \"Gurbanodelta\"). In the Hell Creek beds of North America, at least half of the ten known multituberculate species and all eleven metatherians species, are not found above the boundary. Multituberculates in Europe and North America survived relatively unscathed and quickly bounced back in the Palaeocene, but Asian forms were decimated, never again to represent a significant component on mammalian faunas. A recent study indicates that metatherians suffered the heaviest losses at the KT event, followed by multituberculates, while eutherians recovered the quickest.\n\nMammalian species began diversifying approximately 30 million years prior to the K–Pg boundary. Diversification of mammals stalled across the boundary.\nCurrent research indicates that mammals did not explosively diversify across the K–Pg boundary, despite the environment niches made available by the extinction of dinosaurs. Several mammalian orders have been interpreted as diversifying immediately after the K–Pg boundary, including Chiroptera (bats) and Cetartiodactyla (a diverse group that today includes whales and dolphins and even-toed ungulates), although recent research concludes that only marsupial orders diversified after the K–Pg boundary.\n\nK–Pg boundary mammalian species were generally small, comparable in size to rats; this small size would have helped them find shelter in protected environments. In addition, it is postulated that some early monotremes, marsupials, and placentals were semiaquatic or burrowing, as there are multiple mammalian lineages with such habits today. Any burrowing or semiaquatic mammal would have had additional protection from K–Pg boundary environmental stresses.\n\nIn North American terrestrial sequences, the extinction event is best represented by the marked discrepancy between the rich and relatively abundant late-Maastrichtian palynomorph record and the post-boundary fern spike.\n\nAt present the most informative sequence of dinosaur-bearing rocks in the world from the K–Pg boundary is found in western North America, particularly the late Maastrichtian-age Hell Creek Formation of Montana. Comparison with the older Judith River Formation (Montana) and Dinosaur Park Formation (Alberta), which both date from approximately 75 Ma, provides information on the changes in dinosaur populations over the last 10 million years of the Cretaceous. However, these fossil beds are geographically limited, covering only part of one continent.\n\nThe middle–late Campanian formations show a greater diversity of dinosaurs than any other single group of rocks. The late Maastrichtian rocks contain the largest members of several major clades: \"Tyrannosaurus\", \"Ankylosaurus\", \"Pachycephalosaurus\", \"Triceratops\", and \"Torosaurus\", which suggests food was plentiful immediately prior to the extinction.\n\nIn addition to rich dinosaur fossils, there are also plant fossils that illustrate the reduction in plant species across the K–Pg boundary. In the sediments below the K–Pg boundary the dominant plant remains are angiosperm pollen grains, but the boundary layer contains little pollen and is dominated by fern spores. More usual pollen levels gradually resume above the boundary layer. This is reminiscent of areas blighted by modern volcanic eruptions, where the recovery is led by ferns, which are later replaced by larger angiosperm plants.\n\nThe mass extinction of marine plankton appears to have been abrupt and right at the K–Pg boundary. Ammonite genera became extinct at or near the K–Pg boundary; however, there was a smaller and slower extinction of ammonite genera prior to the boundary that was associated with a late Cretaceous marine regression. The gradual extinction of most inoceramid bivalves began well before the K–Pg boundary, and a small, gradual reduction in ammonite diversity occurred throughout the very late Cretaceous.\n\nFurther analysis shows that several processes were in progress in the late Cretaceous seas and partially overlapped in time, then ended with the abrupt mass extinction. The diversity of marine life decreased when the climate near the K–Pg boundary increased in temperature. The temperature increased about three to four degrees very rapidly between 65.4 and 65.2 million years ago, which is very near the time of the extinction event. Not only did the climate temperature increase, but the water temperature decreased, causing a drastic decrease in marine diversity.\n\nThe scientific consensus is that the asteroid impact at the K–Pg boundary left megatsunami deposits and sediments around the area of the Caribbean Sea and Gulf of Mexico, from the colossal waves created by the impact. These deposits have been identified in the La Popa basin in northeastern Mexico, platform carbonates in northeastern Brazil, in Atlantic deep-sea sediments, and in the form of the thickest-known layer of graded sand deposits, around 100 meters thick, in the Chicxulub crater itself, directly above the shocked granite ejecta.\n\nThe megatsunami has been estimated at more than tall, as the asteroid fell into relatively shallow seas; in deep seas it would have been tall.\n\nThe rapidity of the extinction is a controversial issue, because some theories about the extinction's causes imply a rapid extinction over a relatively short period (from a few years to a few thousand years) while others imply longer periods. The issue is difficult to resolve because of the Signor–Lipps effect; that is, the fossil record is so incomplete that most extinct species probably died out long after the most recent fossil that has been found. Scientists have also found very few continuous beds of fossil-bearing rock that cover a time range from several million years before the K–Pg extinction to a few million years after it. The sedimentation rate and thickness of K–Pg clay from three sites suggest rapid extinction, perhaps less than ten thousand years. At one site in the Denver Basin of Colorado, the ‘fern spike’ lasted about one thousand years (no more than 71 thousand years); the earliest Cenozoic mammals appeared about 185 thousand years (no more than 570 thousand years) after the K–Pg boundary layer was deposited.\n\nIn 1980, a team of researchers consisting of Nobel Prize–winning physicist Luis Alvarez, his son geologist Walter Alvarez, and chemists Frank Asaro and Helen Michel discovered that sedimentary layers found all over the world at the Cretaceous–Paleogene boundary contain a concentration of iridium many times greater than normal (30, 160, and 20 times in three sections originally studied). Iridium is extremely rare in Earth's crust because it is a siderophile element which mostly sank along with iron into Earth's core during planetary differentiation. As iridium remains abundant in most asteroids and comets, the Alvarez team suggested that an asteroid struck the Earth at the time of the K–Pg boundary. There were earlier speculations on the possibility of an impact event, but this was the first hard evidence.\n\nThis hypothesis was viewed as radical when first proposed, but additional evidence soon emerged. The boundary clay was found to be full of minute spherules of rock, crystallized from droplets of molten rock formed by the impact. Shocked quartz and other minerals were also identified in the K–Pg boundary. The identification of giant tsunami beds along the Gulf Coast and the Caribbean provided more evidence, and suggested that the impact may have occurred nearby – as did the discovery that the K–Pg boundary became thicker in the southern United States, with meter-thick beds of debris occurring in northern New Mexico.\nFurther research identified the giant Chicxulub crater, buried under Chicxulub on the coast of Yucatán, as the source of the K–Pg boundary clay. Identified in 1990 based on work by geophysicist Glen Penfield in 1978, the crater is oval, with an average diameter of roughly , about the size calculated by the Alvarez team. The discovery of the crater – a prediction of the impact hypothesis – provided conclusive evidence for a K–Pg impact, and strengthened the hypothesis that it caused the extinction.\n\nIn a 2013 paper, Paul Renne of the Berkeley Geochronology Center dated the impact at  million years ago, based on argon–argon dating. He further posits that the mass extinction occurred within 32,000 years of this date.\n\nIn 2007, it was proposed that the impactor belonged to the Baptistina family of asteroids. This link has been doubted, though not disproved, in part because of a lack of observations of the asteroid and its family. It was recently discovered that 298 Baptistina does not share the chemical signature of the K–Pg impactor. Further, a 2011 Wide-field Infrared Survey Explorer (WISE) study of reflected light from the asteroids of the family estimated their break-up at 80 Ma, giving them insufficient time to shift orbits and impact Earth by 66 Ma.\n\nIn , an international panel of 41 scientists reviewed 20 years of scientific literature and endorsed the asteroid hypothesis, specifically the Chicxulub impact, as the cause of the extinction, ruling out other theories such as massive volcanism. They had determined that a asteroid hurtled into Earth at Chicxulub on Mexico's Yucatán Peninsula. The collision would have released the same energy as – more than a billion times the energy of the atomic bombings of Hiroshima and Nagasaki.\n\nThe Chicxulub impact caused a global catastrophe. Some of the phenomena were brief occurrences immediately following the impact, but there were also long-term geochemical and climatic disruptions that devastated the ecology.\n\nThe reentry of ejecta into Earth's atmosphere would include a brief (hours long) but intense pulse of infrared radiation, cooking exposed organisms. A paper in 2013 by a prominent modeler of nuclear winter suggested that, based on the amount of soot in the global debris layer, the entire terrestrial biosphere might have burned, implying a global soot-cloud blocking out the sun and creating a nuclear winter effect. This is debated, however, with opponents arguing that local ferocious fires, probably limited to North America, fall short of global firestorms. This is the \"Cretaceous-Palaeogene firestorm debate\".\n\nAside from the hypothesized fire and/or nuclear winter effects, the impact would have created a dust cloud that blocked sunlight for up to a year, inhibiting photosynthesis. The asteroid hit an area of carbonate rock containing a large amount of combustible hydrocarbons and sulphur, much of which was vaporized, thereby injecting sulfuric acid aerosols into the stratosphere, which might have reduced sunlight reaching the Earth's surface by more than 50%, and would have caused acid rain. The resulting acidification of the oceans would kill many organisms that grow shells of calcium carbonate. At Brazos section, the sea surface temperature dropped as much as 7 °C for decades after the impact. It would take at least ten years for such aerosols to dissipate, and would account for the extinction of plants and phytoplankton, and subsequently herbivores and their predators. Creatures whose food chains were based on detritus would have a reasonable chance of survival, however. Freezing temperatures probably lasted for at least three years.\n\nIf widespread fires occurred, they would have increased the content of the atmosphere and caused a temporary greenhouse effect once the dust clouds and aerosol settled, and, this would have exterminated the most vulnerable organisms that survived the period immediately after the impact.\n\nAlthough most paleontologists now agree that an asteroid did hit the Earth at approximately the end of the Cretaceous, there is an ongoing dispute whether the impact was the sole cause of the extinctions.\n\nIn 2016, a scientific drilling project obtained deep rock core samples from the peak ring around the Chicxulub impact crater. The discoveries confirmed that the rock comprising the peak ring had been shocked by immense pressure and melted in just minutes from its usual state into its present form. Unlike sea-floor deposits, the peak ring was made of granite originating much deeper in the earth, which had been ejected to the surface by the impact. Gypsum is a sulfate-containing rock usually present in the shallow seabed of the region; it had been almost entirely removed, vaporized into the atmosphere. Further, the event was immediately followed by a megatsunami sufficient to lay down the largest known layer of sand separated by grain size directly above the peak ring.\n\nThese findings strongly support the impact's role in the extinction event. The impactor was large enough to create a 120-mile-wide (193 km) peak ring, to melt, shock, and eject deep granite, to create colossal water movements, and to eject an immense quantity of vaporized rock and sulfates into the atmosphere, where they would have persisted for a long time. This worldwide dispersal of dust and sulfates would have affected climate catastrophically, led to large temperature drops, and devastated the food chain.\n\nAlthough the concurrence of the end-Cretaceous extinctions with the Chicxulub asteroid impact strongly supports the impact hypothesis, some scientists continue to support other contributing causes: volcanic eruptions, climate change, sea level change, and other impact events. The end-Cretaceous event is the only mass extinction known to be associated with an impact, and other large impacts, such as the Manicouagan reservoir impact, do not coincide with any noticeable extinction events.\n\nBefore 2000, arguments that the Deccan Traps flood basalts caused the extinction were usually linked to the view that the extinction was gradual, as the flood basalt events were thought to have started around 68 Mya and lasted more than 2 million years. The most recent evidence shows that the traps erupted over a period of only 800,000 years spanning the K–Pg boundary, and therefore may be responsible for the extinction and the delayed biotic recovery thereafter.\n\nThe Deccan Traps could have caused extinction through several mechanisms, including the release of dust and sulfuric aerosols into the air, which might have blocked sunlight and thereby reduced photosynthesis in plants. In addition, Deccan Trap volcanism might have resulted in carbon dioxide emissions that increased the greenhouse effect when the dust and aerosols cleared from the atmosphere.\n\nIn the years when the Deccan Traps hypothesis was linked to a slower extinction, Luis Alvarez (d. 1988) replied that paleontologists were being misled by sparse data. While his assertion was not initially well-received, later intensive field studies of fossil beds lent weight to his claim. Eventually, most paleontologists began to accept the idea that the mass extinctions at the end of the Cretaceous were largely or at least partly due to a massive Earth impact. Even Walter Alvarez acknowledged that other major changes may have contributed to the extinctions.\n\nCombining these theories, some geophysical models suggest that the impact contributed to the Deccan Traps.\nThese models, combined with high-precision radiometric dating, suggest that the Chicxulub impact could have triggered some of the largest Deccan eruptions, as well as eruptions at active volcanoes anywhere on Earth.\n\nOther crater-like topographic features have also been proposed as impact craters formed in connection with Cretaceous-Paleogene extinction. This suggests the possibility of near-simultaneous multiple impacts, perhaps from a fragmented asteroidal object similar to the Shoemaker–Levy 9 impact with Jupiter. In addition to the Chicxulub Crater, there is the Boltysh crater in Ukraine (), the Silverpit crater in the North Sea () possibly formed by bolide impact, and the controversial and much larger Shiva crater. Any other craters that might have formed in the Tethys Ocean would have been obscured by the northward tectonic drift of Africa and India.\n\nThere is clear evidence that sea levels fell in the final stage of the Cretaceous by more than at any other time in the Mesozoic era. In some Maastrichtian stage rock layers from various parts of the world, the later layers are terrestrial; earlier layers represent shorelines and the earliest layers represent seabeds. These layers do not show the tilting and distortion associated with mountain building, therefore the likeliest explanation is a \"regression\", a drop in sea level. There is no direct evidence for the cause of the regression, but the currently accepted explanation is that the mid-ocean ridges became less active and sank under their own weight.\n\nA severe regression would have greatly reduced the continental shelf area, the most species-rich part of the sea, and therefore could have been enough to cause a \"marine\" mass extinction; however, this change would not have sufficed to cause the extinction of the ammonites. The regression would also have caused climate changes, partly by disrupting winds and ocean currents and partly by reducing the Earth's albedo and increasing global temperatures.\n\nMarine regression also resulted in the loss of epeiric seas, such as the Western Interior Seaway of North America. The loss of these seas greatly altered habitats, removing coastal plains that ten million years before had been host to diverse communities such as are found in rocks of the Dinosaur Park Formation. Another consequence was an expansion of freshwater environments, since continental runoff now had longer distances to travel before reaching oceans. While this change was favorable to freshwater vertebrates, those that prefer marine environments, such as sharks, suffered.\n\nProponents of multiple causation view the suggested single causes as either too small to produce the vast scale of the extinction, or not likely to produce its observed taxonomic pattern. In a review article, J. David Archibald and David E. Fastovsky discussed a scenario combining three major postulated causes: volcanism, marine regression, and extraterrestrial impact. In this scenario, terrestrial and marine communities were stressed by the changes in, and loss of, habitats. Dinosaurs, as the largest vertebrates, were the first affected by environmental changes, and their diversity declined. At the same time, particulate materials from volcanism cooled and dried areas of the globe. Then an impact event occurred, causing collapses in photosynthesis-based food chains, both in the already-stressed terrestrial food chains and in the marine food chains.\n\nRecent work led by Sierra Peterson at Seymour Island, Antarctica, showed two separate extinction events near the Cretaceous-Paleogene boundary, with one correlating to Deccan Trap volcanism and one correlated with the Chicxulub impact. The team analyzed combined extinction patterns using a new clumped isotope temperature record from a hiatus-free, expanded K-Pg boundary section. They documented a 7.8±3.3 °C warming synchronous with the onset of Deccan Traps volcanism and a second, smaller warming at the time of meteorite impact. They suggest local warming may have been amplified due to simultaneous disappearance of continental or sea ice. Intra-shell variability indicates a possible reduction in seasonality after Deccan eruptions began, continuing through the meteorite event. Species extinction at Seymour Island occurred in two pulses that coincide with the two observed warming events, directly linking the end-Cretaceous extinction at this site to both volcanic and meteorite events via climate change.\n\nThe K–Pg extinction had a profound effect on the evolution of life on Earth. The elimination of dominant Cretaceous groups allowed other organisms to take their place, spurring a remarkable series of adaptive radiations in the Paleogene. The most striking example is the replacement of dinosaurs by mammals. After the K–Pg extinction, mammals evolved rapidly to fill the niches left vacant by the dinosaurs. Also significant, within the mammalian genera, new species were approximately 9.1% larger after the K–Pg boundary.\n\nOther groups also underwent major radiations. Based on molecular sequencing and fossil dating, Neoaves appeared to radiate after the K–Pg boundary. They even produced giant, flightless forms, such as the herbivorous \"Gastornis\" and Dromornithidae, and the predatory Phorusrhacidae. The extinction of Cretaceous lizards and snakes may have led to the radiation of modern groups such as iguanas, monitor lizards, and boas. On land, giant boid and enormous madtsoiid snakes appeared, and in the seas, giant sea snakes radiated. Teleost fish diversified explosively, filling the niches left vacant by the extinction. Groups appearing in the Paleocene and Eocene include billfish, tunas, eels, and flatfish. Major changes are also seen in Paleogene insect communities. Many groups of ants were present in the Cretaceous, but in the Eocene ants became dominant and diverse, with larger colonies. Butterflies diversified as well, perhaps to take the place of leaf-eating insects wiped out by the extinction. The advanced mound-building termites, Termitidae, also appear to have risen in importance.\n\n"}
{"id": "2695452", "url": "https://en.wikipedia.org/wiki?curid=2695452", "title": "Delta Telescopii", "text": "Delta Telescopii\n\nThe Bayer designation Delta Telescopii (δ Tel, δ Telescopii) is shared by two stars in the southern constellation Telescopium. They are separated by 0.16° on the sky.\n\n"}
{"id": "44298", "url": "https://en.wikipedia.org/wiki?curid=44298", "title": "Drumlin", "text": "Drumlin\n\nA drumlin, from the Irish word \"droimnín\" (\"littlest ridge\"), first recorded in 1833, and in the classical sense is an elongated hill in the shape of an inverted spoon or half-buried egg formed by glacial ice acting on underlying unconsolidated till or ground moraine.\n\nDrumlins occur in various shapes and sizes, including symmetrical (about the long axis), spindle, parabolic forms, together with transverse asymmetrical forms; their long axis is parallel to the direction of movement of the formative flow at the time of formation.\n\nDrumlins are typically long, less than high and between wide. Drumlins generally have a length:width ratio of between 1:2 and 1:3.5, with the questionable assumption that more elongate forms correspond to faster ice motion. That is, since ice flows in laminar flow, the resistance to flow is frictional and depends on area of contact; elongate, subglacial landforms produced by ice would represent relatively slow flow rates.\n\nDrumlins and drumlin clusters are glacial landforms composed primarily of glacial till. They form near the margin of glacial systems, and within zones of fast flow deep within ice sheets, and are commonly found with other major glacially-formed features (including tunnel valleys, eskers, scours, and exposed bedrock erosion).\n\nDrumlins are often in drumlin fields of similarly shaped, sized and oriented hills. Many Pleistocene drumlin fields are observed to occur in a fan-like distribution. The Múlajökull drumlins of Hofsjökull are also arrayed in a splayed fan distribution around an arc of 180°.\n\nDrumlins may comprise layers constituting clay, silt, sand, gravel and boulders in various proportions – perhaps, indicating that material was repeatedly added to a core, which may be of rock or glacial till. Alternatively, drumlins may be residual, with the landforms resulting from erosion of material between the landforms. The dilatancy of glacial till was invoked as a major factor in drumlin formation. In other cases, drumlin fields include drumlins made up entirely of hard bedrock (e.g. granite or well-lithified limestone). These drumlins cannot be explained by the addition of soft-sediment to a core. Thus, accretion and erosion of soft-sediment by processes of subglacial deformation do not present unifying theories for all drumlins—some are composed of residual bedrock.\n\nConventional models of drumlin formation fall into two camps: \"constructional\", in which they form as sediment is manipulated into shape, for example via subglacial deformation; and \"remnant/erosional\", which proposes that drumlins form by erosion of material from an unconsolidated bed (reference). A hypothesis that catastrophic sub-glacial floods form drumlins by deposition or erosion challenges conventional explanations for drumlins. It includes deposition of glaciofluvial sediment in cavities scoured into a glacier bed by subglacial meltwater and remnant ridges left behind by erosion of soft-sediment or hard-rock by turbulent meltwater. This hypothesis requires huge, subglacial meltwater floods, each of which would raise sea-level by tens of centimetres in a few weeks. Studies of erosional forms in bedrock at French River, Ontario, Canada provide evidence for such floods.\n\nThe recent retreat of a marginal outlet glacier of Hofsjökull in Iceland exposed a drumlin field with more than 50 drumlins ranging from in length, in width, and in height. These formed through a progression of subglacial depositional and erosional processes, with each horizontal till bed within the drumlin created by an individual surge of the glacier. The above theory for the formation of these Icelandic drumlins gives the best explanations for one type of drumlin. However, it does not provide a unifying explanation of all drumlins. For example, drumlin fields including drumlins composed entirely of hard bedrock cannot be explained by deposition and erosion of unconsolidated beds. As well, hairpin scours around many drumlins are best explained by the erosive action of horseshoe vortices around obstacles in a turbulent boundary layer.\n\nErosion under a glacier in the immediate vicinity of a drumlin can be on the order of a meter's depth of sediment per year, with the eroded sediment forming a drumlin as it is repositioned and deposited.\n\nRecently formed drumlins often incorporate a thin \"A\" soil horizon (often referred to as \"'topsoil'\" which accumulated after formation) and a thin \"Bw\" horizon (commonly referred to as \"'subsoil'\"). The \"C\" horizon, which shows little evidence of being affected by soil forming processes (weathering), is close to the surface, and may be at the surface on an eroded drumlin. Below the C horizon the drumlin consists of multiple beds of till deposited by lodgment and bed deformation. On drumlins with longer exposure (e.g. in the Lake Ontario drumlin field in New York State) soil development is more advanced, for example with the formation of clay-enriched \"Bt\" horizons.\n\nThe retreat of Icelandic glacier Múlajökull, which is an outlet glacier of Hofsjökull, recently exposed a 50 drumlin cluster, which serves as the basis for improved understanding of drumlin formation.\nThe literature also documents extensive drumlin fields in England, Scotland and Wales, Switzerland, Poland, Estonia (Vooremaa), Latvia, Sweden, around Lake Constance north of the Alps, County Leitrim, County Monaghan, County Mayo and County Cavan in the Republic of Ireland, County Fermanagh, County Armagh and County Down in Northern Ireland, Germany, Hindsholm in Denmark, Finland and Greenland.\n\nThe largest drumlin fields in the world formed beneath the Laurentide Ice Sheet and are found in Canada—Nunavut, the Northwest Territories, northern Saskatchewan, northern Manitoba, northern Ontario and northern Quebec. Drumlins are common in Upstate New York (between the south shore of Lake Ontario and Cayuga Lake), the lower Connecticut River valley, eastern Massachusetts, the Monadnock Region of New Hampshire, Michigan (central and southern Lower Peninsula), Minnesota, the Puget Sound region of Washington state and Wisconsin. Drumlins, which are usually found in swarms or large groups, occur in every Canadian province and territory. Swarms of thousands of drumlins are found in Southern Ontario (along eastern end of Oak Ridges Moraine near Peterborough, as well as areas to the west near Dundas and Guelph), Central-Eastern Ontario (Douro-Dummer), the Thelon Plan of the Northwest Territories, Alberta, southwest of Amundsen Gulf in Nunavut and West Lawrencetown, Nova Scotia. The majority of those observed in North America were formed during the Wisconsin glaciation.\n\nDrumlins are found at Tiksi, Sakha Republic, Russia.\n\nExtensive drumlin fields are found in Patagonia, for example near Punta Arenas Carlos Ibáñez del Campo Airport and on Navarino and Gable Island in the Beagle Channel.\n\nIn 2007, drumlins were observed to be forming beneath the ice of a West Antarctic ice stream.\n\n\n\n\nFrench River outburst floods: https://www.youtube.com/watch?v=7L2rnpWE3jA\n"}
{"id": "18038146", "url": "https://en.wikipedia.org/wiki?curid=18038146", "title": "Energy market", "text": "Energy market\n\nEnergy markets are commodity markets that deal specifically with the trade and supply of energy. Energy market may refer to an electricity market, but can also refer to other sources of energy. Typically energy development is the result of a government creating an energy policy that encourages the development of an energy industry in a competitive manner.\n\nUntil the 1970s when energy markets underwent dramatic changes, they were characterised by monopoly-based organisational structures. Most of the world's petroleum reserves were controlled by the Seven Sisters. Circumstances changed considerably in 1973 as the influence of OPEC grew and the repercussions of the 1973 oil crisis affected global energy markets.\n\nEnergy markets have been liberalized in some countries; they are regulated by national and international authorities (including liberalized markets) to protect consumer rights and avoid oligopolies. Regulators includes the Australian Energy Market Commission in Australia, the Energy Market Authority in Singapore, the Energy Community in Europe, replacing the South-East Europe Regional Energy Market and the Nordic energy market for Nordic countries. Members of the European Union are required to liberalize their energy markets.\n\nRegulators seek to discourage volatility of prices, reform markets if needed, and search for evidence of anti-competitive behavior such as the formation of a monopoly.\n\nDue to the increase in oil price since 2003 and the increase of speculation, energy markets are being reviewed and by 2008, several conferences were organized to address the energy market sentiments of petroleum importing nations. In Russia, the markets are being reformed by the introduction of harmonized and all-Russian consumer prices.\n\nThe United States currently uses over four trillion kilowatt-hours per year in order to fulfill its energy needs. Data given by the United States Energy Information Administration (EIA) shows a steady growth in energy usage dating back to 1990, which showed the United States used around 3 trillion kilowatt hours of energy that year. Traditionally, the energy sources used to fulfill the United States energy needs have been oil, coal, nuclear, renewable energy, and natural gas. The breakdown of each of these fuels as a percentage of the overall consumption in the year 1993, according to the data given by the EIA is as follows; coal was 53%, nuclear energy was 19%, natural gas was 13%, renewable energy was 11%, and oil provided 4% of the overall energy needs. In the most recent year where data was analyzed, 2011, the breakdown was as follows; coal was 42%, nuclear was 19%, natural gas was 25%, renewable energy was 13% and oil dropped down to 1%. These figures show a dramatic drop in energy from coal, and a significant increase in both natural gas as well as renewable energy. \nAccording to the United States Geological Survey (USGS) data from 2006, hydroelectric power accounted for most of the renewable energy production in the United States. However, increasing government funding, grants, and incentives have been drawing many companies towards the biofuel, wind, and solar energy production industries.\n\nIn recent years, there has been a movement towards renewable and sustainable energy in the United States. This has been caused by many factors, including the threat of climate change, cost, government funding, tax incentives, and potential profits in the energy market of the United States. According to the most recent projections by the EIA out to the year 2040, the renewable energy industry will be growing from providing 13% of the power in the year 2011 to 16% in 2040. This is equivalent to 32% of the overall growth during this time period. This large increase has the potential to be very lucrative for companies wishing to tap into the renewable energy market in the United States. \nThis movement towards renewable energy has also been affected by the stability of the global market. Recent economic instability in countries in the Middle East and elsewhere has driven American companies to further develop American dependence on foreign sources of energy, such as oil. The long term projections by the United States Energy Information Administration for renewable energy capacity in the United States is also sensitive to factors such as the cost of domestic oil and natural gas production, prices, and availability.\n\nCurrently, the majority of the United States’ renewable energy production comes from hydroelectric power, solar power, and wind power. According to the U.S. Department of Energy, the cost of wind power doubled between the years of 2002 to 2008. However, since then, the prices of wind power have declined by 1/3, on average. Various factors have been contributing to the decline in the cost of wind power, such as government subsidies, tax breaks, technological advancement, and the cost of oil and natural gas. \nHydroelectric power has been the most predominant source of renewable energy for quite some time due to the fact that it has been proven to be reliable and has been in use for quite some time. This source of energy has provided the majority of renewable energy and has been a significant source of overall energy production in the United States. The problem with traditional hydroelectric power has been the requirement of damming rivers and other sources of water. The problem created by damming is that the natural environment of the area is disrupted due to the formation of a lake caused by the damming of the water source. This creates uproar by environmentalists and a large obstacle to clear before being able to build a hydroelectric plant. However, new forms of hydroelectric power that harness wave energy from the oceans have been in development in recent years. Although these power sources still need much development before they become economically viable, they do have potential to become significant sources of energy.\n\nIn recent years, wind energy and solar energy have made the largest steps towards significant energy production in the United States. These sources have little impact on the environment and have the highest potential of renewable energy sources used today. Advances in technology, government tax rebates, subsidies, grants, and economic need have all lead to huge steps towards the usage of sustainable wind and solar energy today.\n\nThe energy industry is the third-largest industry in the United States. This market is expected to have an investment of over $700 billion over the next two decades according to selectusa. This allows for large amount of advancement in technological development in the near future. There are also many federal resources enticing both domestic and foreign companies to send investments towards the renewable energy industry in the United States. These federal resources include the Department of Energy Loan Guarantee, the American Reinvestment and Recovery Act, the Smart Grid Stimulus Program, as well as an Executive Order on Industrial Energy Efficiency. All these programs allow for a very lucrative investment for companies wishing to compete in the energy industry in the United States. With the advancement of technology in recent years, harnessing the power of wind, solar, and hydroelectric resources in the United States will become the focus of the United States’ shift towards alternative energy. This should also drive down the prices of oil due to a decrease in demand. There are more incentives now than ever before to develop these technologies and bring them into greater use.\n\n"}
{"id": "10274", "url": "https://en.wikipedia.org/wiki?curid=10274", "title": "Enthalpy", "text": "Enthalpy\n\nEnthalpy , a property of a thermodynamic system, is equal to the system's internal energy plus the product of its pressure and volume. For processes at constant pressure, the heat absorbed or released equals the change in enthalpy.\n\nThe unit of measurement for enthalpy in the International System of Units (SI) is the joule. Other historical conventional units still in use include the British thermal unit (BTU) and the calorie.\n\nEnthalpy comprises a system's internal energy, which is the energy required to create the system, plus the amount of work required to make room for it by displacing its environment and establishing its volume and pressure.\n\nEnthalpy is defined as a state function that depends only on the prevailing equilibrium state identified by the system's internal energy, pressure, and volume. It is an extensive quantity.\n\nEnthalpy is the preferred expression of system energy changes in many chemical, biological, and physical measurements at constant pressure, because it simplifies the description of energy transfer. At constant pressure, the enthalpy change equals the energy transferred from the environment through heating or work other than expansion work.\n\nThe total enthalpy, \"H\", of a system cannot be measured directly. The same situation exists in classical mechanics: only a change or difference in energy carries physical meaning. Enthalpy itself is a thermodynamic potential, so in order to measure the enthalpy of a system, we must refer to a defined reference point; therefore what we measure is the change in enthalpy, Δ\"H\". The Δ\"H\" is a positive change in endothermic reactions, and negative in heat-releasing exothermic processes.\n\nFor processes under constant pressure, Δ\"H\" is equal to the change in the internal energy of the system, plus the pressure-volume work p ΔV done by the system on its surroundings (which is > 0 for an expansion and < 0 for a contraction). This means that the change in enthalpy under such conditions is the heat absorbed or released by the system through a chemical reaction or by external heat transfer. Enthalpies for chemical substances at constant pressure usually refer to standard state: most commonly 1 bar pressure. Standard state does not, strictly speaking, specify a temperature (see standard state), but expressions for enthalpy generally reference the standard heat of formation at 25 °C.\n\nEnthalpy of ideal gases and incompressible solids and liquids does not depend on pressure, unlike entropy and Gibbs energy. Real materials at common temperatures and pressures usually closely approximate this behavior, which greatly simplifies enthalpy calculation and use in practical designs and analyses.\n\nThe word \"enthalpy\" was coined relatively late, in the early 20th century, in analogy with the 19th-century terms \"energy\" (introduced in its modern sense by Thomas Young in 1802) and \"entropy\" (coined in analogy to \"energy\" by Rudolf Clausius in 1865).\nIt uses the root of Greek \"warmth, heat\" \nwhere \"energy\" has \"work\" and \"entropy\" \"transformation\", by analogy expressing the idea of \"heat-content\" where energy refers to \"work-content\" and entropy to \"transformation-content\".\nThe term does in fact stand in for the older term \"heat content\", \na term which is now mostly deprecated as misleading, as refers to the amount of heat absorbed in a process at constant pressure only, \nbut not in the general case (when pressure is variable). \nJosiah Willard Gibbs used the term \"a heat function for constant pressure\" for clarity.\n\nIntroduction of the concept of \"heat content\" is associated with Benoît Paul Émile Clapeyron and Rudolf Clausius (Clausius–Clapeyron relation, 1850).\n\nThe term \"enthalpy\" first appeared in print in 1909. It is attributed to Heike Kamerlingh Onnes, who most likely introduced it orally the year before, at the first meeting of the Institute of Refrigeration in Paris.\nIt gained currency only in the 1920s, notably with the \"Mollier Steam Tables and Diagrams\", published in 1927.\n\nUntil the 1920s, the symbol was used, somewhat inconsistently, for \"heat\" in general. \nThe definition of as strictly limited to enthalpy or \"heat content at constant pressure\" was formally proposed by Alfred W. Porter in 1922.\n\nThe enthalpy of a thermodynamic system is defined as\nwhere\nEnthalpy is an extensive property. This means that, for homogeneous systems, the enthalpy is proportional to the size of the system. It is convenient to introduce the specific enthalpy \"h\" = , where \"m\" is the mass of the system, or the molar enthalpy \"H\" = , where \"n\" is the number of moles (\"h\" and \"H\" are intensive properties). For inhomogeneous systems the enthalpy is the sum of the enthalpies of the composing subsystems:\n\nwhere the label \"k\" refers to the various subsystems. In case of continuously varying \"p\", \"T\" or composition, the summation becomes an integral:\n\nwhere \"ρ\" is the density.\n\nThe enthalpy of homogeneous systems can be viewed as function \"H\"(\"S\",\"p\") of the entropy \"S\" and the pressure \"p\", and a differential relation for it can be derived as follows. We start from the first law of thermodynamics for closed systems for an infinitesimal process:\n\nHere, \"δQ\" is a small amount of heat added to the system, and \"δW\" a small amount of work performed by the system. In a homogeneous system only reversible processes can take place, so the second law of thermodynamics gives , with \"T\" the absolute temperature of the system. Furthermore, if only \"pV\" work is done, . As a result,\n\nAdding \"d\"(\"pV\") to both sides of this expression gives\n\nor\n\nSo\n\nThe above expression of \"dH\" in terms of entropy and pressure may be unfamiliar to some readers. However, there are expressions in terms of more familiar variables such as temperature and pressure:\n\nHere \"C\" is the heat capacity at constant pressure and \"α\" is the coefficient of (cubic) thermal expansion:\n\nWith this expression one can, in principle, determine the enthalpy if \"C\" and \"V\" are known as functions of \"p\" and \"T\".\n\nNote that for an ideal gas, \"αT\" = 1, so that\n\nIn a more general form, the first law describes the internal energy with additional terms involving the chemical potential and the number of particles of various types. The differential statement for \"dH\" then becomes\n\nwhere \"μ\" is the chemical potential per particle for an \"i\"-type particle, and \"N\" is the number of such particles. The last term can also be written as (with \"dn\" the number of moles of component \"i\" added to the system and, in this case, \"μ\" the molar chemical potential) or as (with \"dm\" the mass of component \"i\" added to the system and, in this case, \"μ\" the specific chemical potential).\n\nThe \"U\" term can be interpreted as the energy required to create the system, and the \"pV\" term as the work that would be required to \"make room\" for the system if the pressure of the environment remained constant. When a system, for example, \"n\" moles of a gas of volume \"V\" at pressure \"p\" and temperature \"T\", is created or brought to its present state from absolute zero, energy must be supplied equal to its internal energy \"U\" plus \"pV\", where \"pV\" is the work done in pushing against the ambient (atmospheric) pressure.\n\nIn basic physics and statistical mechanics it may be more interesting to study the internal properties of the system and therefore the internal energy is used. In basic chemistry, experiments are often conducted at constant atmospheric pressure, and the pressure-volume work represents an energy exchange with the atmosphere that cannot be accessed or controlled, so that Δ\"H\" is the expression chosen for the heat of reaction.\n\nFor a heat engine a change in its internal energy is the difference between the heat input and the pressure-volume work done by the working substance while a change in its enthalpy is the difference between the heat input and the work done by the engine:\nwhere the work W done by the engine is: \n\nIn order to discuss the relation between the enthalpy increase and heat supply, we return to the first law for closed systems: . We apply it to the special case with a uniform pressure at the surface. In this case the work term can be split into two contributions, the so-called \"pV\" work, given by (where here \"p\" is the pressure at the surface, \"dV\" is the increase of the volume of the system) and all other types of work \"δW′\", such as by a shaft or by electromagnetic interaction. So we write . In this case the first law reads:\n\nor\n\nFrom this relation we see that the increase in enthalpy of a system is equal to the added heat:\n\nprovided that the system is under constant pressure (\"dp\" = 0) and that the only work done by the system is expansion work (\"δW\"' = 0).\n\nIn thermodynamics, one can calculate enthalpy by determining the requirements for creating a system from \"nothingness\"; the mechanical work required, \"pV\", differs based upon the conditions that obtain during the creation of the thermodynamic system.\n\nEnergy must be supplied to remove particles from the surroundings to make space for the creation of the system, assuming that the pressure \"p\" remains constant; this is the \"pV\" term. The supplied energy must also provide the change in internal energy, \"U\", which includes activation energies, ionization energies, mixing energies, vaporization energies, chemical bond energies, and so forth. Together, these constitute the change in the enthalpy \"U\" + \"pV\". For systems at constant pressure, with no external work done other than the \"pV\" work, the change in enthalpy is the heat received by the system.\n\nFor a simple system, with a constant number of particles, the difference in enthalpy is the maximum amount of thermal energy derivable from a thermodynamic process in which the pressure is held constant.\n\nThe total enthalpy of a system cannot be measured directly, the \"enthalpy change\" of a system is measured instead. Enthalpy change is defined by the following equation:\n\nwhere\n\nFor an exothermic reaction at constant pressure, the system's change in enthalpy equals the energy released in the reaction, including the energy retained in the system and lost through expansion against its surroundings. In a similar manner, for an endothermic reaction, the system's change in enthalpy is equal to the energy \"absorbed\" in the reaction, including the energy \"lost by\" the system and \"gained\" from compression from its surroundings. If Δ\"H\" is positive, the reaction is endothermic, that is heat is absorbed by the system due to the products of the reaction having a greater enthalpy than the reactants. On the other hand, if Δ\"H\" is negative, the reaction is exothermic, that is the overall decrease in enthalpy is achieved by the generation of heat.\n\nFrom the definition of enthalpy as formula_19 the enthalpy change at constant pressure formula_20 However for most chemical reactions, the work term formula_21 is much smaller than the internal energy change formula_22 which is approximately equal to formula_23 As an example, for the combustion of carbon monoxide 2 CO(g) + O(g) → 2 CO(g), formula_24 = –566.0 kJ and formula_22 = –563.5 kJ. Since the differences are so small, reaction enthalpies are often loosely described as reaction energies and analyzed in terms of bond energies.\n\nThe specific enthalpy of a uniform system is defined as \"h\" = where \"m\" is the mass of the system. The SI unit for specific enthalpy is joule per kilogram. It can be expressed in other specific quantities by , where \"u\" is the specific internal energy, \"p\" is the pressure, and \"v\" is specific volume, which is equal to , where \"ρ\" is the density.\n\nAn enthalpy change describes the change in enthalpy observed in the constituents of a thermodynamic system when undergoing a transformation or chemical reaction. It is the difference between the enthalpy after the process has completed, i.e. the enthalpy of the products, and the initial enthalpy of the system, i.e. the reactants. These processes are reversible and the enthalpy for the reverse process is the negative value of the forward change.\n\nA common standard enthalpy change is the enthalpy of formation, which has been determined for a large number of substances. Enthalpy changes are routinely measured and compiled in chemical and physical reference works, such as the CRC Handbook of Chemistry and Physics. The following is a selection of enthalpy changes commonly recognized in thermodynamics.\n\nWhen used in these recognized terms the qualifier \"change\" is usually dropped and the property is simply termed \"enthalpy of 'process\"'. Since these properties are often used as reference values it is very common to quote them for a standardized set of environmental parameters, or standard conditions, including: \nFor such standardized values the name of the enthalpy is commonly prefixed with the term \"standard\", e.g. \"standard enthalpy of formation\".\n\nChemical properties:\n\nPhysical properties:\n\nIn thermodynamic open systems, matter may flow in and out of the system boundaries. The first law of thermodynamics for open systems states: The increase in the internal energy of a system is equal to the amount of energy added to the system by matter flowing in and by heating, minus the amount lost by matter flowing out and in the form of work done by the system:\n\nwhere \"U\" is the average internal energy entering the system, and \"U\" is the average internal energy leaving the system.\n\nThe region of space enclosed by the boundaries of the open system is usually called a control volume, and it may or may not correspond to physical walls. If we choose the shape of the control volume such that all flow in or out occurs perpendicular to its surface, then the flow of matter into the system performs work as if it were a piston of fluid pushing mass into the system, and the system performs work on the flow of matter out as if it were driving a piston of fluid. There are then two types of work performed: \"flow work\" described above, which is performed on the fluid (this is also often called \"pV work\"), and \"shaft work\", which may be performed on some mechanical device.\n\nThese two types of work are expressed in the equation\n\nSubstitution into the equation above for the control volume (cv) yields:\n\nThe definition of enthalpy, \"H\", permits us to use this thermodynamic potential to account for both internal energy and \"pV\" work in fluids for open systems:\n\nIf we allow also the system boundary to move (e.g. due to moving pistons), we get a rather general form of the first law for open systems. In terms of time derivatives it reads:\n\nwith sums over the various places \"k\" where heat is supplied, matter flows into the system, and boundaries are moving. The \"Ḣ\" terms represent enthalpy flows, which can be written as\n\nwith \"ṁ\" the mass flow and \"ṅ\" the molar flow at position \"k\" respectively. The term represents the rate of change of the system volume at position \"k\" that results in \"pV\" power done by the system. The parameter \"P\" represents all other forms of power done by the system such as shaft power, but it can also be e.g. electric power produced by an electrical power plant.\n\nNote that the previous expression holds true only if the kinetic energy flow rate is conserved between system inlet and outlet. Otherwise, it has to be included in the enthalpy balance. During steady-state operation of a device (\"see turbine, pump, and engine\"), the average may be set equal to zero. This yields a useful expression for the average power generation for these devices in the absence of chemical reactions:\n\nwhere the angle brackets denote time averages. The technical importance of the enthalpy is directly related to its presence in the first law for open systems, as formulated above.\n\nThe enthalpy values of important substances can be obtained using commercial software. Practically all relevant material properties can be obtained either in tabular or in graphical form. There are many types of diagrams, such as \"h\"–\"T\" diagrams, which give the specific enthalpy as function of temperature for various pressures, and \"h\"–\"p\" diagrams, which give \"h\" as function of \"p\" for various \"T\". One of the most common diagrams is the temperature–specific entropy diagram (\"T\"–\"s\"-diagram). It gives the melting curve and saturated liquid and vapor values together with isobars and isenthalps. These diagrams are powerful tools in the hands of the thermal engineer.\n\nThe points a through h in the figure play a role in the discussion in this section.\n\nOne of the simple applications of the concept of enthalpy is the so-called throttling process, also known as Joule-Thomson expansion. It concerns a steady adiabatic flow of a fluid through a flow resistance (valve, porous plug, or any other type of flow resistance) as shown in the figure. This process is very important, since it is at the heart of domestic refrigerators, where it is responsible for the temperature drop between ambient temperature and the interior of the refrigerator. It is also the final stage in many types of liquefiers.\n\nFor a steady state flow regime, the enthalpy of the system (dotted rectangle) has to be constant. Hence\n\nSince the mass flow is constant, the specific enthalpies at the two sides of the flow resistance are the same:\n\nthat is, the enthalpy per unit mass does not change during the throttling. The consequences of this relation can be demonstrated using the \"T\"–\"s\" diagram above. Point c is at 200 bar and room temperature (300 K). A Joule–Thomson expansion from 200 bar to 1 bar follows a curve of constant enthalpy of roughly 425 kJ/kg (not shown in the diagram) lying between the 400 and 450 kJ/kg isenthalps and ends in point d, which is at a temperature of about 270 K. Hence the expansion from 200 bar to 1 bar cools nitrogen from 300 K to 270 K. In the valve, there is a lot of friction, and a lot of entropy is produced, but still the final temperature is below the starting value!\n\nPoint e is chosen so that it is on the saturated liquid line with . It corresponds roughly with and . Throttling from this point to a pressure of 1 bar ends in the two-phase region (point f). This means that a mixture of gas and liquid leaves the throttling valve. Since the enthalpy is an extensive parameter, the enthalpy in f (\"h\") is equal to the enthalpy in g (\"h\") multiplied by the liquid fraction in f (\"x\") plus the enthalpy in h (\"h\") multiplied by the gas fraction in f . So\n\nWith numbers: , so \"x\" = 0.64. This means that the mass fraction of the liquid in the liquid–gas mixture that leaves the throttling valve is 64%.\n\nA power \"P\" is applied e.g. as electrical power. If the compression is adiabatic, the gas temperature goes up. In the reversible case it would be at constant entropy, which corresponds with a vertical line in the \"T\"–\"s\" diagram. For example, compressing nitrogen from 1 bar (point a) to 2 bar (point b) would result in a temperature increase from 300 K to 380 K. In order to let the compressed gas exit at ambient temperature \"T\", heat exchange, e.g. by cooling water, is necessary. In the ideal case the compression is isothermal. The average heat flow to the surroundings is \"Q̇\". Since the system is in the steady state the first law gives\n\nThe minimal power needed for the compression is realized if the compression is reversible. In that case the second law of thermodynamics for open systems gives\n\nEliminating \"Q̇\" gives for the minimal power\n\nFor example, compressing 1 kg of nitrogen from 1 bar to 200 bar costs at least . With the data, obtained with the \"T\"–\"s\" diagram, we find a value of 476 kJ/kg.\n\nThe relation for the power can be further simplified by writing it as\n\nWith , this results in the final relation\n\n\n\n"}
{"id": "41687529", "url": "https://en.wikipedia.org/wiki?curid=41687529", "title": "FISA Improvements Act", "text": "FISA Improvements Act\n\nThe FISA Improvements Act is a proposed act by Senator Dianne Feinstein, Chair of the Senate Intelligence Committee. Prompted by the disclosure of NSA surveillance by Edward Snowden, it would establish the surveillance program as legal, but impose some limitations on availability of the data. Opponents say the bill would codify warrantless access to many communications of American citizens for use by domestic law enforcement.\n\nIn the wake of the Snowden disclosures, President Obama and many lawmakers believed that restoration of public trust would require legislative changes. More than 20 bills have been written with the goal of reining in government surveillance powers.\n\nOn October 28, 2013, Senator Dianne Feinstein, long described as a staunch defender of the National Security Agency (NSA), announced that a \"total review of all intelligence programs is necessary\".\n\nA bill was introduced by Feinstein on October 31, 2013. Amendments were offered and rejected. The same day it was introduced, the bill passed the United States Senate Select Committee on Intelligence by a vote of 11-4. The committee's report on the bill was published on November 12.\n\nFeinstein issued a press release saying that the bill would impose restrictions on how data is collected, including prohibiting bulk collection of the content of communications, and place a limit of five years on retention of the data. It would make unauthorized access to data obtained under the FISA orders punishable by ten years in prison. The bill would make the FISA court require \"reasonable articulable suspicion\" of association with international terrorism before records are reviewed. It also would set limits on the number of people with access to the data, and set limits on the number of \"hops\" (contact intermediaries) that can be searched. It would require the NSA to make an annual report of the number of queries made and the number of FBI investigations or probable cause orders issued. The bill would also require intelligence agencies to report violations of law to Congress, require a review once per by the Attorney General of collection procedures, and permit the FISA court to invite independent amicus curiae perspectives on cases. It would require Senate confirmation of appointments of the NSA director and NSA Inspector General.\n\nMSNBC reported that the bill \"purports to ban the NSA's controversial bulk collection of communications records under Section 215 of the Patriot Act\" but \"basically allows the NSA to continue bulk collection.\" Feinstein defended data collection in her press release, saying that \"The threats we face—from terrorism, proliferation and cyber attack, among others—are real, and they will continue. Intelligence is necessary to protect our national and economic security, as well as to stop attacks against our friends and allies around the world.\"\n\nThe Senate Intelligence Committee report recommended the bill, saying that the program was \"an effective counterterrorism tool\" and \"was determined by the Department of Justice in two Administrations and by at least fifteen different judges serving on the Foreign Intelligence Surveillance Court (FISC) to be lawful.\" While noting that the committee had encountered inadvertent violations of the law, the majority reported \"It remains the case that, through seven years of oversight of this metadata program under Section 215, the Committee has not identified a single case in which a government official engaged in a willful effort to circumvent or violate Section 215 in the conduct of the bulk telephone metadata program.\" The committee endorsed measures to codify and enhance privacy protections, saying these measures \"could not have been enacted absent the declassification of lawful intelligence activities that were, until recently, properly classified, as to do so would have revealed the programs to our adversaries and thereby compromised their effectiveness.\" However, it condemned the disclosures and said that the leaks \"have not exposed government wrongdoing.\"\n\nIn a minority view attached to the report, Senators Ron Wyden, Mark Udall, and Martin Heinrich wrote \"this bill would codify the government's authority to collect the phone records of huge numbers of law-abiding Americans, and also to conduct warrantless searches for individual Americans' phone calls and emails. We respectfully but firmly disagree with this approach.\" Feinstein's response in the report was that the bill \"does not provide any new legislative authority with which the government may acquire call records or any other information under Section 215--in fact, it narrows the existing authority for it.\"\n\nThe American Civil Liberties Union (ACLU) urged opposition, calling the bill a \"dream come true for the NSA\". The Electronic Frontier Foundation (EFF) called the bill a \"fake fix\" that would \"permanently entrench\" current surveillance practices.\n\nThe ACLU and EFF were among fifty-four \"civil liberties and public interest groups\" that authored a coalition letter to Congressional leadership urging them to oppose the act.\n\nOne area of concern raised by \"The Guardian\", crediting blogger Marcy Wheeler, regards a \"backdoor search provision\" which could allow domestic U.S. law enforcement agencies warrantless access to the data. A FISA court document declassified in 2011 and a leak by Edward Snowden previously published by the newspaper indicated that generally searches of the database for \"U. S. Persons\" was not permitted, but contained a provision that:\nAccording to \"The Guardian\", Section 6 of the Act \"blesses\" such a procedure, permitting intelligence agencies to search \"the contents of communications\" collected overseas for U.S. persons provided that the purpose pertained to \"foreign intelligence information\". The provision was also criticized by Senator Ron Wyden, who said that the bill \"would give intelligence agencies wide latitude to conduct warrantless searches for American phone calls and emails\", instead supporting the USA Freedom Act by Senators Patrick Leahy and F. James Sensenbrenner that would require a search warrant to obtain the information. Sensenbrenner called Feinstein's bill an effort \"for the first time in our country's history to allow unrestrained spying on the American people.\"\n\n\n"}
{"id": "543667", "url": "https://en.wikipedia.org/wiki?curid=543667", "title": "Flood geology", "text": "Flood geology\n\nFlood geology (also creation geology or diluvial geology) is the attempt to interpret and reconcile geological features of the Earth in accordance with a literal belief in the global flood described in Genesis . In the early 19th century, diluvial geologists hypothesized that specific surface features were evidence of a worldwide flood which had followed earlier geological eras; after further investigation they agreed that these features resulted from local floods or glaciers. In the 20th century, young Earth creationists revived flood geology as an overarching concept in their opposition to evolution, assuming a recent six-day Creation and cataclysmic geological changes during the Biblical Deluge, and incorporating creationist explanations of the sequence of rock strata.\n\nIn the early stages of development of the science of geology, fossils were interpreted as evidence of past flooding. The \"theories of the Earth\" of the 17th century proposed mechanisms based on natural laws, within a timescale set by the biblical chronology. As modern geology developed, geologists found evidence of an ancient Earth, and evidence inconsistent with the notion that the Earth had developed in a series of cataclysms, the most recent of which could be attributed to the Genesis flood. In early 19th-century Britain, \"Diluvialism\" attributed landforms and surface features such as beds of gravel and erratic boulders to the destructive effects of this supposed global Deluge, but by 1830 geologists increasingly found that the evidence only showed relatively local floods. Attempts were made by so-called scriptural geologists to give primacy to literal Biblical explanations, but they lacked background in geology and were marginalised by the scientific community, as well as having little influence on the church.\n\nFlood geology was revived as a field of study within creation science, which is a part of young Earth creationism.\nProponents hold to a literal reading of and view its passages to be historically accurate, using the Bible's internal chronology to place the Flood and the story of Noah's Ark within the last five thousand years.\n\nThe key tenets of flood geology are refuted by scientific analysis. Flood geology contradicts the scientific consensus in geology, stratigraphy, geophysics, physics, paleontology, biology, anthropology, and archeology. Modern geology, its sub-disciplines and other scientific disciplines utilize the scientific method. In contrast, flood geology does not adhere to the scientific method, and it is, therefore, a pseudoscience.\n\nIn pre-Christian times, fossils found on land were thought by Greek philosophers, including Xenophanes, Xanthus and Aristotle, to be evidence that the sea had in past ages covered the land. Their concept of vast time periods in an eternal cosmos was rejected by early Christian writers as incompatible with their belief in Creation by God. Among the church fathers, Tertullian spoke of fossils demonstrating that mountains had been overrun by water without explicitly saying when. Chrysostom and Augustine believed that fossils were the remains of animals that were killed and buried during the brief duration of the Biblical Genesis Flood, and later Martin Luther viewed fossils as having resulted from the Flood.\n\nOther scholars, including Avicenna, thought fossils were produced in the rock by \"petrifying virtue\" acting on \"seeds\" of plants and animals. In 1580 Bernard Palissy speculated that fossils had formed in lakes, and natural historians subsequently disputed the alternatives. Robert Hooke made empirical investigations, and doubted that the numbers of fossil shells or depth of shell beds could have formed in the one year of Noah's Flood. In 1616 Nicolas Steno showed how chemical processes changed organic remains into stone fossils. His fundamental principles of stratigraphy published in 1669 established that rock strata formed horizontally and were later broken and tilted, though he assumed these processes would occur within 6,000 years including a worldwide Flood.\n\nIn his influential \"Principles of Philosophy\" of 1644, René Descartes applied his mechanical physical laws to envisage swirling particles forming the Earth as a layered sphere. This natural philosophy was recast in Biblical terms by the theologian Thomas Burnet, whose \"Sacred Theory of the Earth\" published in the 1680s proposed complex explanations based on natural laws, and explicitly rejected the simpler approach of invoking miracles as incompatible with the methodology of natural philosophy (the precursor to science). Burnet maintained that less than 6,000 years ago the Earth had emerged from chaos as a perfect sphere, with paradise on land over a watery abyss. This crust had dried out and cracked, and its collapse caused the Biblical Deluge, forming mountains as well as underground caverns where the water retreated. He made no mention of fossils, but inspired other diluvial theories that did.\n\nIn 1695, John Woodward's \"An Essay Toward a Natural History of the Earth\" viewed the Genesis Flood as dissolving rocks and earth into a thick slurry which caught up all living things, and when the waters settled formed strata according to the specific gravity of these materials, including fossils of the organisms. When it was pointed out that lower layers were often less dense and forces that shattered rock would destroy organic remains, he resorted to the explanation that a divine miracle had temporarily suspended gravity. William Whiston's \"New Theory of the Earth\" of 1696 combined scripture with Newtonian physics to propose that the original chaos was the atmosphere of a comet with the days of Creation each taking a year, and the Genesis Flood had resulted from a second comet. His explanation of how the Flood caused mountains and the fossil sequence was similar to Woodward's. Johann Jakob Scheuchzer wrote in support of Woodward's ideas in 1708, describing some fossil vertebrae as bones of sinners who had perished in the Flood. A skeleton found in a quarry was described by him in 1726 as \"Homo diluvii testis\", a giant human testifying to the Flood. This was accepted for some time, but in 1812 it was shown to be a prehistoric salamander.\n\nThe modern science of geology developed in the 18th century, the term \"geology\" itself was popularised by the \"Encyclopédie\" of 1751. Steno's categorisation of strata was expanded by several geologists, including Johann Gottlob Lehmann who believed that the oldest mountains had formed early in the Creation, and categorised as \"Flötz-Gebürge\" stratified mountains with few ore deposits but with thin layers containing fossils, overlain by a third category of superficial deposits. In his 1756 publication he identified 30 different layers in this category which he attributed to the action of the Genesis Deluge, possibly including debris from the older mountains. Others including Giovanni Arduino attributed secondary strata to natural causes: Georg Christian Füchsel said that geologists had to take as standard the processes in which nature currently produces solids, \"we know no other way\", and only the most recent deposits could be attributed to a great Flood.\n\nLehman's classification was developed by Abraham Gottlob Werner who thought that rock strata had been deposited from a primeval global ocean rather than by Noah's Flood, a doctrine called Neptunism. The idea of a young Earth was further undermined in 1774 by Nicolas Desmarest, whose studies of a succession of extinct volcanoes in Europe showed layers which would have taken long ages to build up. The fact that these layers were still intact indicated that any later Flood had been local rather than universal. Against Neptunism, James Hutton proposed an indefinitely old cycle of eroded rocks being deposited in the sea, consolidated and heaved up by volcanic forces into mountains which in turn eroded, all in natural processes which continue to operate.\n\nThe first professional geological society, the Geological Society of London, was founded in 1807. By this time, geologists were convinced that an immense time had been needed to build up the huge thickness of rock strata visible in quarries and cliffs, implying extensive pre-human periods. Most accepted a basic time scale classifying rocks as primitive, transition, secondary, or tertiary. Several researchers independently found that strata could be identified by characteristic fossils: secondary strata in southern England were mapped by William Smith from 1799 to 1815.\n\nGeorges Cuvier, working with Alexandre Brongniart, examined tertiary strata in the region around Paris. Cuvier found that fossils identified rock formations as alternating between marine and terrestrial deposits, indicating \"repeated irruptions and retreats of the sea\" which he identified with a long series of sudden catastrophes which had caused extinctions. In his 1812 \"Discours préliminaire\" to his \"Recherches sur les ossemens fossiles de quadrupeds\" put forward a synthesis of this research into the long prehistoric period, and a historical approach to the most recent catastrophe. His historical approach tested empirical claims in the Biblical text of Genesis against other ancient writings to pick out the \"real facts\" from \"interested fictions\". In his assessment, Moses had written the account around 3,300 years ago, long after the events described. Cuvier only discussed the Genesis Flood in general terms, as the most recent example of \"an event of an universal catastrophe, occasioned by an irruption of the waters\" not set \"much further back than five or six thousand years ago\". The historical texts could be loosely related to evidence such as overturned strata and \"heaps of \"debris\" and rounded pebbles\". An English translation was published in 1813 with a preface and notes by Robert Jameson, Regius Professor of Natural History at the University of Edinburgh. He began the preface with a sentence which ignored Cuvier's historical approach and instead deferred to revelation: \n\nThis sentence was removed after the second edition, and Jameson's position changed as shown by his notes in successive editions, but it influenced British views of Cuvier's concept. In 1819 George Bellas Greenough, first president of The Geological Society, issued \"A Critical Examination of the First Principles of Geology\" stating that unless erratic boulders deposited hundreds of miles from their original sources had been moved by seas, rivers, or collapsing lakes, \"the only remaining cause, to which these effects can be ascribed, is a Debacle or Deluge.\"\n\nConservative geologists in Britain welcomed Cuvier's theory to replace Werner's Neptunism, and the Church of England clergyman William Buckland became the foremost proponent of Flood geology as he sought to get the new science of geology accepted on the curriculum of the University of Oxford. In 1818 he was visited by Cuvier, and in his inaugural speech in 1819 as the first professor of geology at the university he defended the subject against allegations that it undermined religion. His speech, published as \"Vindiciae Geologicae; or, The Connexion of Geology with Religion Explained\", equated the last of a long series of catastrophes with the Genesis Flood, and said that \"the grand fact of an universal deluge at no very remote period is proved on grounds so decisive and incontrovertible, that, had we never heard of such an event from Scripture, or any other, authority, Geology of itself must have called in the assistance of some such catastrophe, to explain the phenomena of diluvian action which are universally presented to us, and which are unintelligible without recourse to a deluge exerting its ravages at a period not more ancient than that announced in the Book of Genesis.\" The evidence he proposed included erratic boulders, extensive areas of gravel, and landforms which appeared to have been scoured by water.\n\nThis inaugural address influenced the geologists William Conybeare and William Phillips. In their 1822 book on \"Outlines of the Geology of England and Wales\" Conybeare referred to the same features in an introduction about the relationship between geology and religion, describing how a deluge causing \"the last great geological change to which the surface of our planet appears to have been exposed\" left behind the debris (which he named in Latin \"Diluvium\") as evidence for \"that great and universal catastrophe to which it seems most properly assignable\". In 1823 Buckland published his detailed account of \"Relics of the Flood\", \"Reliquiae Diluvianae;\" or, \"Observations on the Organic Remains Contained in Caves, Fissures, and Diluvial Gravel and on Other Geological Phenomena Attesting the Action of an Universal Deluge\", incorporating his research suggesting that animal fossils had been dragged into the Kirkdale Cave by hyenas then covered by a layer of red mud washed in by the Deluge.\n\nBuckland's views were supported by other Church of England clergymen naturalists: his Oxford colleague Charles Daubeny proposed in 1820 that the volcanoes of the Auvergne showed a sequence of lava flows from before and after the Flood had cut valleys through the region. In an 1823 article \"On the deluge\", John Stevens Henslow, professor of mineralogy at the University of Cambridge, affirmed the concept and proposed that the Flood had originated from a comet, but this was his only comment on the topic. Adam Sedgwick, Woodwardian Professor of Geology at Cambridge, presented two supportive papers in 1825, \"On the origin of alluvial and diluvial deposits\", and \"On diluvial formations\". At this time, most of what Sedgwick called \"The English school of geologists\" distinguished superficial deposits which were \"diluvial\", showing \"great irregular masses of sand, loam, and coarse gravel, containing through its mass rounded blocks sometimes of enormous magnitude\" and supposedly caused by \"some great irregular inundation\", from \"alluvial\" deposits of \"comminuted gravel, silt, loam, and other materials\" attributed to lesser events, the \"propelling force\" of rivers, or \"successive partial inundations\".\n\nIn America, Benjamin Silliman at Yale College spread the concept, and in an 1833 essay dismissed the earlier idea that most stratified rocks had been formed in the Flood, while arguing that surface features showed \"wreck and ruin\" attributable to \"mighty floods and rushing torrents of water\". He said that \"we must charge to moving waters the undulating appearance of stratified sand and gravel, often observed in many places, and very conspicuously in the plain of New Haven, and in other regions of Connecticut and New England\", while both \"bowlder stones\" and sandy deserts across the world could be attributed to \"diluvial agency\".\n\nOther naturalists were critical of Diluvialism: the Church of Scotland pastor John Fleming published opposing arguments in a series of articles from 1823 onwards. He was critical of the assumption that fossils resembling modern tropical species had been swept north \"by some violent means\", which he regarded as absurd considering the \"unbroken state\" of fossil remains. For example, fossil mammoths demonstrated adaptation to the same northern climates now prevalent where they were found. He criticized Buckland's identification of red mud in the Kirkdale cave as diluvial, when near identical mud in other caves had been described as fluvial. While Cuvier had reconciled geology with a loose reading of the Biblical text, Fleming argued that such a union was \"indiscreet\" and turned to a more literal view of Genesis:\nWhen Sedgwick visited Paris at the end of 1826 he found hostility to Diluvialism: Alexander von Humboldt ridiculed it \"beyond measure\", and Louis-Constant Prévost \"lectured against it\". In the summer of 1827 Sedgwick and Roderick Murchison travelled to investigate the geology of the Scottish Highlands, where they found \"so many indications of \"local diluvial\" operations\" that Sedgwick began to change his mind about it being worldwide. When George Poulett Scrope published his investigations into the Auvergne in 1827, he did not use the term \"diluvium\". He was followed by Murchison and Charles Lyell whose account appeared in 1829. All three agreed that the valleys could well have been formed by rivers acting over a long time, and a deluge was not needed. Lyell, formerly a pupil of Buckland, put strong arguments against diluvialism in the first volume of his \"Principles of Geology\" published in 1830, though suggesting the possibility of a deluge affecting a region such as the low-lying area around the Caspian Sea. Sedgwick responded to this book in his presidential address to the Geological Society in February 1830, agreeing that diluvial deposits had formed at differing times. At the society a year later, when retiring from the presidency, Sedgwick described his former belief that \"vast masses of diluvial gravel\" had been scattered worldwide in \"one violent and transitory period\" as \"a most unwarranted conclusion\", and therefore thought \"it right, as one of my last acts before I quit this Chair, thus publicly to read my recantation.\" However, he remained convinced that a flood as described in Genesis was not excluded by geology.\n\nOne student had seen the gradual abandonment of diluvialism: Charles Darwin had attended Jameson's geology lectures in 1826, and at Cambridge became a close friend of Henslow before learning geology from Sedgwick in 1831. At the outset of the \"Beagle\" voyage Darwin was given a copy of Lyell's \"Principles of Geology\", and at the first landfall began his career as a geologist with investigations which supported Lyell's concept of slow uplift while also describing loose rocks and gravel as \"part of the long disputed Diluvium\". Debates continued over the part played by repeated exceptional catastrophes in geology, and in 1832 William Whewell dubbed this view catastrophism, while naming Lyell's insistence on explanations based on current processes uniformitarianism.\n\nBuckland, too, gradually modified his views on the Deluge. In 1832 a student noted Buckland's view on cause of diluvial gravel, \"whether is Mosaic inundation or not, will not say\". In a footnote to his \"Bridgewater Treatise\" of 1836, Buckland backed down from his former claim that the \"violent inundation\" identified in his \"Reliquiae Diluvianae\" was the Genesis flood: \nFor a while, Buckland had continued to insist that \"some\" geological layers were related to the Great Flood, but grew to accept the idea that they represented multiple inundations which occurred well before humans existed. In 1840 he made a field trip to Scotland with the Swiss geologist Louis Agassiz, and became convinced that the \"diluvial\" features which he had attributed to the Deluge had, in fact, been produced by ancient ice ages. Buckland became one of the foremost champions of Agassiz's theory of glaciations, and diluvialism went out of use in geology. Active geologists no longer posited sudden ancient catastrophes with unknown causes, and instead increasingly explained phenomena by observable processes causing slow changes over great periods.\n\nScriptural geologists were a heterogeneous group of writers in the early nineteenth century, who claimed \"the primacy of literalistic biblical exegesis\" and a short Young Earth time-scale. Their views were marginalised and ignored by the scientific community of their time. They generally lacked any background in geology, and had little influence even in church circles.\n\nMany quoted out of date geological writings. Among the most prominent, Granville Penn argued in 1822 that \"mineral geology\" rejected revelation, while true \"Mosaical geology\" showed that God had created primitive rock formations directly, in correspondence with the laws which God then made to produce subsequent effects. A first revolution on the third day of creation deepened the oceans so water rushed in, and in the Deluge 1,656 years afterwards a second revolution sank land areas and raised the sea bed to cause a swirling flood which moved soil and fossil remains into stratified layers, after which God created new vegetation. As Genesis appeared to show that the rivers of Eden had survived this catastrophe, he argued that the verses concerned were an added \"parenthesis\" which should be disregarded. In 1837 George Fairholme expressed disappointment about disappearing belief in the deluge, and about Sedgwick and Buckland recanting diluvialism, while putting forward his own \"New and Conclusive Physical Demonstrations\" which ignored geological findings to claim that strata had been deposited in a quick continuous process while still moist.\n\nGeology was popularized by several authors. John Pye Smith's lectures published in 1840 reconciled an extended time frame with Genesis by the increasingly common gap theology or day-age theology, and said it was likely that the gravel and boulder formations were not \"diluvium\", but had taken long ages predating the creation of humans. He reaffirmed that the Flood was historical as a local event, something which the 17th century theologians Edward Stillingfleet and Matthew Poole had already suggested on a purely Biblical basis. Smith also denounced the \"fanciful\" writings of the scriptural geologists. Edward Hitchcock sought to ensure that geological findings could be corroborated by scripture, and dismissed the scriptural geology of Penn and Fairholme as misrepresenting both scripture and the facts of geology. He noted the difficulty of equating a violent deluge with the more tranquil Genesis account. Hugh Miller supported similar points with considerable detail.\n\nLittle attention was paid to Flood geology over the rest of the 19th century, its few supporters included the author Eleazar Lord in the 1850s and the Lutheran scholar Carl Friedrich Keil in 1860 and 1878. The visions of Ellen G. White published in 1864 formed Seventh-day Adventist Church views, and influenced 20th century creationism.\n\nThe Seventh-day Adventist Church, led by Ellen G. White, took a six-day creation literally, and put her prolific \"inspired\" writings on a level with the Bible. Her visions of the flood and its aftermath, published in 1864, described a catastrophic deluge which reshaped the entire surface of the Earth, followed by a powerful wind which piled up new high mountains, burying the bodies of men and beasts. Buried forests became coal and oil, and where God later caused these to burn, they reacted with limestone and water to cause \"earthquakes, volcanoes and fiery issues\".\n\nEllen G. White's visions prompted several books by one of her followers, George McCready Price, leading to the 20th-century revival of flood geology. After years selling White's books door-to-door, Price took a one-year teacher-training course and taught in several schools. When shown books on evolution and the fossil sequence which contradicted his beliefs, he found the answer in White's \"revealing word pictures\" which suggested how the fossils had been buried. He studied textbooks on geology and \"almost tons of geological documents\", finding \"how the actual facts of the rocks and fossils, \"stripped of mere theories\", splendidly refute this evolutionary theory of the invariable order of the fossils, \"which is the very backbone of the evolution doctrine\"\". In 1902 he produced a manuscript for a book proposing geology based on Genesis, in which the sequence of fossils resulted from the different responses of animals to the encroaching flood. He agreed with White on the origins of coal and oil, and conjectured that mountain ranges (including the Alps and Himalaya) formed from layers deposited by the flood which had then been \"folded and elevated to their present height by the great lateral pressure that accompanied its subsidence\". He then found a report describing paraconformities and a paper on thrust faults. He concluded from these \"providential discoveries\" that it was impossible to prove the age or overall sequence of fossils, and included these points in his self-published paperback of 1906, \"Illogical Geology: The Weakest Point in the Evolution Theory\". His arguments continued this focus on disproving the sequence of strata, and he ultimately sold more than 15,000 copies of his 1923 college textbook \"The New Geology\".\n\nPrice increasingly gained attention outside Adventist groups, and in the creation–evolution controversy other leading Christian fundamentalists praised his opposition to evolution - though none of them followed his young Earth arguments, retaining their belief in the gap or in the day-age interpretation of Genesis. Price corresponded with William Jennings Bryan and was invited to be a witness in the Scopes Trial of 1925, but declined as he was teaching in England and opposed to teaching Genesis in public schools as \"it would be an infringement on the cardinal American principle of separation of church and state\". Price returned from England in 1929 to rising popularity among fundamentalists as a scientific author. In the same year his former student Harold W. Clark self-published the short book \"Back to Creationism\", which recommended Price's flood geology as the new \"science of creationism\", introducing the label \"creationism\" as a replacement for \"anti-evolution\" of \"Christian Fundamentals\".\n\nIn 1935 Price and Dudley Joseph Whitney (a rancher who had co-founded the Lindcove Community Bible Church, and now followed Price) founded the \"Religion and Science Association\" (RSA). They aimed to resolve disagreements among fundamentalists with \"a harmonious solution\" which would convert them all to flood geology. Most of the organising group were Adventists, others included conservative Lutherans with similarly literalist beliefs. Bryon C. Nelson of the Norwegian Lutheran Church of America had included Price's geological views in a 1927 book, and in 1931 published \"The Deluge Story in Stone: A History of the Flood Theory of Geology\", which described Price as the \"one very outstanding advocate of the Flood\" of the century. The first public RSA conference in March 1936 invited various fundamentalist views, but opened up differences between the organisers on the antiquity of creation and on life before Adam. The RSA went defunct in 1937, and a dispute continued between Price and Nelson, who now viewed Creation as occurring over 100,000 years previously.\n\nIn 1938 Price, with a group of Adventists in Los Angeles, founded what became the \"Deluge Geology Society\" (DGS), with membership restricted to those believing that the creation week comprised \"six literal days, and that the Deluge should be studied as the cause of the major geological changes since creation\". Not all DGS-adherents were Adventists; early members included the Independent Baptist Henry M. Morris and the Missouri Lutheran Walter E. Lammerts. The DGS undertook field-work: in June 1941 their first \"Bulletin\" hailed the news that the Paluxy River dinosaur trackways in Texas appeared to include human footprints. Though Nelson had advised Price in 1939 that this was \"absurd\" and that the difficulty of human footprints forming during the turmoil of the deluge would \"knock the Flood theory all to pieces\", in 1943 the DGS began raising funds for \"actual excavation\" by a Footprint Research Committee of members including the consulting geologist Clifford L. Burdick. Initially they tried to keep their research secret from \"unfriendly scientists\". Then in 1945, to encourage backing, they announced giant human footprints, allegedly defeating \"at a single stroke\" the theory of evolution. The revelation that locals had carved the footprints, and an unsuccessful field trip that year, failed to dampen their hopes. However, by then doctrinal arguments had riven the DGS. The most extreme dispute began in late 1938 after Harold W. Clark observed deep drilling in oil fields and had discussions with practical geologists which dispelled the belief that the fossil sequence was random, convincing him that the evidence of thrust faults was \"almost incontrovertible\". He wrote to Price, telling his teacher that the \"rocks do lie in a much more definite sequence than we have ever allowed\", and proposing that the fossil sequence was explained by ecological zones before the flood. Price reacted with fury, and despite Clark emphasising their shared belief in literal recent Creation, the dispute continued. In 1946 Clark set out his views in a book, \"The New Diluvialism\", which Price denounced as \"Theories of Satanic Origin\".\n\nIn 1941 F. Alton Everest co-founded the American Scientific Affiliation (ASA) as a less confrontational forum for evangelical scientists. Some deluge geologists, including Lammerts and Price, urged close cooperation with the DGS, but Everest began to see their views as presenting an \"insurmountable problem\" for the ASA. In 1948 he requested J. Laurence Kulp, a geologist in fellowship with the Plymouth Brethren, to explore the issue. At the convention that year, Kulp examined hominid antiquity demonstrated by radiocarbon dating. At the 1949 convention a paper by Kulp was presented, giving a detailed critique of \"Deluge Geology\", which he said had \"grown and infiltrated the greater portion of fundamental Christianity in America primarily due to the absence of trained Christian geologists\". Kulp demonstrated that \"major propositions of the theory are contraindicated by established physical and chemical laws\". He focused on \"four basic errors\" commonly made by flood geologists:\n\n\nKulp accused Price of ignorance and deception, and concluded that \"this unscientific theory of flood geology has done and will do considerable harm to the strong propagation of the gospel among educated people\". Price said nothing during the presentation and discussion. When invited to speak, he \"said something very brief which missed what everyone was waiting for\". Further publications made the ASA's opposition to flood geology clear.\n\nIn 1942, Henry M. Morris was persuaded by Irwin A. Moon's \"Sermons from Science\" of the importance of harmonising science and the Bible, and was introduced to the concepts of a vapor canopy causing the Flood, and its geological effects. About a year later he found George McCready Price's \"New Geology\" a \"life-changing experience\", and joined the \"Deluge Geology Society\". His book \"That You Might Believe\" for college students included Price's flood geology, and was published in 1946.\n\nMorris had joined the American Scientific Affiliation (ASA) in 1949, and in the summer of 1953 he made a presentation on \"The Biblical Evidence for a Recent Creation and Universal Deluge\" at their annual conference, held at the Grace Theological Seminary's campus. He impressed a graduate student there, John C. Whitcomb, Jr. who was teaching Old Testament and Hebrew. To Whitcomb's distress, Morris was \"politely denounced\" by the ASA members at the presentation.\n\nIn 1955 the ASA held a joint meeting with the Evangelical Theological Society (ETS) at the same campus, and there was considerable discussion about \"The Christian View of Science and Scripture\" (1954) by theologian Bernard Ramm. This book dismissed flood geology as typifying the \"ignoble tradition\" of fundamentalism, and said that Price could not be taken seriously, as he lacked the necessary competence, training and integrity. Instead, Ramm proposed what he called progressive creationism in which the Genesis days were pictorial images revealing a process that had taken place over millions of years. Ramm's views were praised by ASA scientists, but the ETS theologians were unwilling to follow Ramm.\n\nThis encouraged Whitcomb to make his doctoral dissertation a response to Ramm and a defence of Price's position. He systematically asked evangelical professors of apologetics, archaeology and the Old Testament about creation and the flood, and in October told Morris that Ramm's book had been sufficient incentive for him to devote his dissertation to the topic. In 1957 Whitcomb's 450 page dissertation, \"The Genesis Flood\", was completed, and he promptly began summarising it for a book. Moody Publishers responded positively and agreed with him that chapters on scientific aspects should be carefully checked or written by someone with a PhD in science, but Whitcomb's attempts to find someone with a doctorate in geology were unsuccessful. Morris gave helpful advice, expressing concern that sections were too closely based on Price and Velikovsky who were \"both considered by scientists generally as crackpots\". Morris produced an outline of his planned three chapters, and in December 1957 agreed to co-author the book.\n\nMorris completed his draft in early 1959. His intended 100 pages grew to almost 350, around twice the length of Whitcomb's eventual contribution. Whitcomb raised concerns that \"For many people, our position would be somewhat discredited\" by prominent references to \"Price and Seventh-Day Adventism\", and these were deleted. By early 1960 they were impatient at delays when Moody Publishers had misgivings about the length and literal views of the book, and they went along with Rousas Rushdoony's recommendation of a small Philadelphia publishers.\n\n\"The Genesis Flood\" by Whitcomb and Morris was published by the Presbyterian and Reformed Publishing Company of Philadelphia in February 1961. Their premise was that the Bible is infallible, \"the basic argument of this volume is that the Scriptures are true.\" For Whitcomb, Genesis described a worldwide Flood which covered all the high mountains, Noah's ark with capacity equivalent to eight freight trains, flood waters from a canopy and the deeps, and subsequent dispersal of animals from Ararat to all the continents via land bridges. He disputed the views published by Arthur Custance and Bernard Ramm. Morris then confronted readers with the dilemma of whether to believe Scripture or accept the interpretations of trained geologists, and instead of the latter proposed \"a new scheme of historical geology\" true both to Scripture and to God's work revealed in nature. This was essentially Price's \"The New Geology\" updated for the 1960s, though with few direct references to Price.\n\nLike Price before him, Morris argued that most fossil bearing strata had been formed during the global Deluge, disputing uniformitarianism, multiple ice ages, and the geologic column. He explained the apparent fossil sequence as the outcome of marine organisms dying in the slurry of sediments in early stages of the Flood, moving currents sorting object by size and shape, and the mobility of vertebrates allowing them to initially escape the floodwaters. He cited Lammerts in support of Price's views about the thrust fault at Chief Mountain disproving the sequence. \nThe book went beyond Price in some areas. Morris extended the six day creation from the Earth to the entire universe, and said that death and decay had only begun with the Fall of Man, which had therefore introduced entropy and the second law of thermodynamics. He proposed that a vapor canopy, before providing water for the Flood, created a mild even climate and shielded the Earth from cosmic rays so radiocarbon dating would not work. He cited Clifford L. Burdick's testimony that some of the Paluxy River dinosaur trackways overlapped human footprints, but Burdick failed to confirm this and the section was removed from the third edition.\n\nIn a 1957 discussion with Whitcomb, Walter E. Lammerts suggested an \"informal association\" to exchange ideas, and possibly research, on flood geology. Morris was unavailable to get things started, then around 1961 Wiliam J. Tinkle got in touch, and they set about recruiting others. They had difficulty in finding supporters with scientific qualifications. The Creation Research Committee of ten they put together on 9 February 1962 had varying views on the age of the Earth, but all opposed evolution. They then succeeded in recruiting others into what became the Creation Research Society (CRS) in June 1963, and grew rapidly. Getting an agreed statement of belief was problematic, they affirmed that the Bible was \"historically and scientifically true in the original autographs\" so that \"the account of origins in Genesis is a factual presentation of simple historical truths\" and \"The great flood described in Genesis, commonly referred to as the Noachian Flood, was an historic event worldwide in its extent and effect\", but to Morris's disappointment they did not make flood geology mandatory. They lacked a qualified geologist, and Morris persuaded the group to appoint Clifford L. Burdick as their only Earth scientist, overcoming initial concerns raised by Lammerts. The CRS grew rapidly, with an increasing proportion of the membership adhering to strict young Earth flood geology.\n\nThe resources of the CRS for its first decade went into publication of the CRS \"Quarterly\", and a project to publish a creationist school book. Since the 1920s most U.S. schools had not taught pupils about evolution, but Sputnik exposed apparent weaknesses of U.S. science education and the Biological Sciences Curriculum Study produced textbooks in 1963 which included the topic. When the Texas Education Agency held a hearing in October 1964 about adopting these textbooks, creationist objectors were unable to name suitable creationist alternatives. Lammerts organised a CRS textbook committee which lined up a group of authors, with John N. Moore as senior editor bringing their contributions together into a suitable textbook.\n\nThe teaching of evolution, reintroduced in 1963 by the Biological Sciences Curriculum Study textbooks, was prohibited by laws in some states. These bans were contested; the \"Epperson v. Arkansas\" case which began late in 1965 was decided in 1968 by the United States Supreme Court ruling that such laws violated the Establishment Clause of the First Amendment to the United States Constitution.\n\nSome creationists thought a legal decision requiring religious neutrality in schools should shield their children from teachings hostile to their religion; Nell. J. Segraves and Jean E. Sumrall (a friend of Lammerts who was also associated with the Creation Research Society and the Bible-Science Association) petitioned the California State Board of Education to require that school biology texts designate evolution a theory. In 1966 Max Rafferty as California State Superintendent of Public Instruction suggested that they demand equal time for creation, as the Civil Rights Act of 1964 allowed teachers to mention religion as long as they did not promote specific doctrines. Their first attempt failed, but in 1969 controversy arose over a proposed \"Science Framework for California Schools\". Anticipating success, they and others in the Bible-Science Association formed \"Creation Science, Inc.\", to produce textbooks. A compromise acceptable to Segraves, Sumrall and the Board was suggested by Vernon L. Grose, and the revised 1970 \"Framework\" included \"While the Bible and other philosophical treatises also mention creation, science has independently postulated the various theories of creation. Therefore, creation in scientific terms is not a religious or philosophical belief.\" The result kept school texts free of creationism, but downgraded evolution to mere speculative theory.\n\nCreationists reacted to the California developments with a new confidence that they could introduce their ideas into schools by minimizing biblical references. Henry M. Morris declared that \"Creationism is on the way back, this time not primarily as a religious belief, but as an alternative scientific explanation of the world in which we live.\" In 1970 \"Creation Science, Inc.\", combined with a planned studies center at Christian Heritage College as the Creation-Science Research Center. Morris moved to San Diego to become director of the center and academic vice-president of the college. In the fall he presented a course at the college on \"Scientific Creationism\", the first time he is known to have used the term in public. (Two years later, the Creation-Science Research Center split with part becoming the Institute for Creation Research (ICR) led by Morris.)\n\nThe Creation Research Society (CRS) had found schoolbook publishers reluctant to take on their textbook, and eventually the Christian publishing company Zondervan brought out \"Biology: A Search for Order in Complexity\" in 1970. The ten thousand copies printed sold out within a year, and they produced 25,000 as the second impression, but hardly any public schools adopted the book. A preface by Morris claimed that there were two philosophies of creation, \"the doctrine of evolution and the doctrine of special creation\", attempting to give both equal validity. The book mostly covered uncontroversial details of biology, but asserted that these were correctly seen as \"God's creation\" or \"divine creation\", and presented biblical creation as the correct scientific view. A chapter on \"Weaknesses of Geologic Evidence\" disputed evolutionary theories while asserting a \"fact that most fossil material was laid down by the flood in Noah's time\". Another chapter disputed evolutionary theory.\n\nIn the \"Creation Research Society Quarterly\" for September 1971 Morris introduced the \"two-model approach\" asserting that evolution and creation were both equally scientific and equally religious, and soon afterwards he said they were \"competing scientific hypotheses\". For the third printing of \"Biology: A Search for Order in Complexity\" in 1974, the editor John N. Moore added a preface setting out this approach as \"the two basic viewpoints of origins\", the \"evolution model\" and the \"creation model\". When an Indiana school decided to use the book as their biology text, the \"Hendren v. Campbell\" district court case banned its use in public schools as infringing the Establishment Clause. Judge Michael T. Dugan, II, described it as \"a text obviously designed to present \"only\" the view of Biblical Creationism in a favorable light\", contravening the constitution by promotion of a specific sectarian religious view.\n\nAs a tactic to gain the same scientific status as evolution, flood geology proponents had effectively relabeled the Bible-based flood geology of George McCready Price as \"creation science\" or \"scientific creationism\" by the mid 1970s. At the CRS board meeting in the Spring of 1972, members were told to start using \"scientific creationism\", a phrase used interchangeably with \"creation science\"; Morris explained that preferences differed, though neither was ideal as \"one simple term\" could not \"identify such a complex and comprehensive subject.\" In the 1974 ICR handbook for high-school teachers titled \"Scientific Creationism\", Morris used the two-model approach to support his argument that creationism could \"be taught without reference to the book of Genesis or to other religious literature or to religious doctrines\", and in public schools only the \"basic scientific creation model\" should be taught, rather than biblical creationism which \"would open the door to wide interpretations of Genesis\" or to non-Christian cosmogonies. He did not deny having been influenced by the Bible. In his preface to the book dated July 1974, Morris as editor outlined how the \"Public School Edition\" of the book evaluated evidence from a \"strictly scientific point of view\" without \"reference to the Bible or other religious literature\", while the \"General Edition\" was \"essentially identical\" except for an additional chapter on \"Creation according to Scripture\" that \"places the scientific evidence in its proper biblical and theological context.\"\n\nThe main ideas in creation science are: the belief in \"creation \"ex nihilo\"\" (Latin: out of nothing); the conviction that the Earth was created within the last 6,000 years; the belief that mankind and other life on Earth were created as distinct fixed \"baraminological\" \"kinds\"; and the idea that fossils found in geological strata were deposited during a cataclysmic flood which completely covered the entire Earth. As a result, creation science also challenges the commonly accepted geologic and astrophysical theories for the age and origins of the Earth and Universe, which creationists acknowledge are irreconcilable to the account in the Book of Genesis.\n\nThe geologic column and the fossil record are used as major pieces of evidence in the modern scientific explanation of the development and evolution of life on Earth as well as a means to establish the age of the Earth. Young Earth Creationists such as Morris and Whitcomb in their 1961 book, \"The Genesis Flood\", say that the age of the fossils depends on the amount of time credited to the geologic column, which they ascribe to be about one year. Some flood geologists dispute geology's assembled global geologic column since index fossils are used to link geographically isolated strata to other strata across the map. Fossils are often dated by their proximity to strata containing index fossils whose age has been determined by its location on the geologic column. Oard and others say that the identification of fossils as index fossils has been too error-prone for index fossils to be used reliably to make those correlations, or to date local strata using the assembled geologic scale.\n\nOther creationists accept the existence of the geological column and believe that it indicates a sequence of events that might have occurred during the global flood. Institute for Creation Research creationists such as Andrew Snelling, Steven A. Austin and Kurt Wise take this approach, as does Creation Ministries International. They cite the Cambrian explosion — the appearance of abundant fossils in the upper Ediacaran (Vendian) Period and lower Cambrian Period — as the pre-Flood/Flood boundary, the presence in such sediments of fossils that do not occur later in the geological record as part of a pre–flood biota that perished and the absence of fossilized organisms that appear later (such as angiosperms and mammals) as due to erosion of sediments deposited by the flood as waters receded off the land. Creationists say that fossilization can only take place when the organism is buried quickly to protect the remains from destruction by scavengers or decomposition. They say that the fossil record provides evidence of a single cataclysmic flood and not of a series of slow changes accumulating over millions of years.\n\nFlood geologists have proposed numerous hypotheses to reconcile the sequence of fossils evident in the fossil column with the literal account of Noah's flood in the Bible. Whitcomb and Morris proposed three possible factors:\n\n\nSome creationists believe that oil and coal deposits formed rapidly in sedimentary layers as volcanoes or flood waters flattened forests and buried the debris. They believe the vegetation decomposed rapidly into oil or coal due to the heat of the subterranean waters as they were unleashed from the Earth during the flood or by the high temperatures created as the remains were compressed by water and sediment.\n\nCreationists continue to search for evidence in the natural world that they consider consistent with the above description, such as evidence of rapid formation. For example, there have been claims of raindrop marks and water ripples at layer boundaries, sometimes associated with the claimed fossilized footprints of men and dinosaurs walking together. Such footprint evidence has been debunked and some have been shown to be fakes.\n\nProponents of Flood Geology state that \"native global flood stories are documented as history or legend in almost every region on earth\". \"These flood tales are frequently linked by common elements that parallel the biblical account including the warning of the coming flood, the construction of a boat in advance, the storage of animals, the inclusion of family, and the release of birds to determine if the water level had subsided.\" They suggest that \"the overwhelming consistency among flood legends found in distant parts of the globe indicates they were derived from the same origin, but oral transcription has changed the details through time\".\n\nAnthropologist Patrick Nunn rejects this view and highlights the fact that much of the human population lives near water sources such as rivers and coasts, where unusually severe floods can be expected to occur occasionally and will be recorded in tribal mythology.\n\nGeorge McCready Price attempted to fit a great deal of earth's geological history into a model based on a few accounts from the Bible. Price's simple model was used by Whitcomb and Morris initially but they did not build on the model in the 60s and 70s. However, a rough sketch of a creationist model could be constructed from creationist publications and debate material. Recent creationist efforts attempt to build complex models that incorporate as much scientific evidence as possible into the Biblical narrative. Some scientific evidence used for these models was formerly rejected by creationists. These models attempt to explain continental movements in a short time frame, the order of the fossil record, and the Pleistocene ice age.\n\nIn the 60s and 70s a simple creationist model proposed that, \"The Flood split the land mass into the present continents.\" Steve Austin and other creationists proposed a preliminary model of catastrophic plate tectonics (CPT) in 1994. Their work built on earlier papers by John Baumgardner and Russell Humphreys in 1986. Baumgardner proposed a model of mantle convection that allows for runaway subduction and Humphrey associated mantle convection with rapid magnetic reversals in earth history. Baumgardner's proposal holds that the rapid plunge of former oceanic plates into the mantle (caused by an unknown trigger-mechanism) increased local mantle pressures to the point that its viscosity dropped several magnitudes according to known properties of mantle silicates. Once initiated, sinking plates caused the spread of low viscosity throughout the mantle resulting in runaway mantle-convection and catastrophic tectonic motion which dragged continents across the surface of the earth. Once the former ocean plates, which are thought to be denser than the mantle, reached the bottom of the mantle an equilibrium resulted. Pressures dropped, viscosity increased, runaway mantle-convection stopped, leaving the surface of the earth rearranged. Proponents point to subducted slabs in the mantle which are still relatively cool, which they regard as evidence that they have not been there for millions of years which would result in temperature equilibration.\n\nGiven that conventional plate tectonics accounts for much of the geomorphic features of continents and oceans, it is natural that creationists would seek to develop a high speed version of the same process. CPT explains many geological features, provides mechanisms for the Biblical flood, and minimizes appeals to miracles.\n\nSome prominent creationists (Froede, Oard, Read) oppose CPT for various technical reasons. One main objection is that the model assumes the super continent Pangaea was intact at the initiation of the year-long flood. The CPT process then tore Pangaea apart creating the current configuration of the continents. But the breakup of Pangaea started early in the Mesozoic, meaning that CPT only accounts for part of the entire Phanerozoic geological record. CPT in this form only explains part of the geological column that flood geology normally explains. Modifying the CPT model to account for the entire Phanerozoic including multiple Wilson Cycles would complicate the model considerably.\n\nOther objections of CPT include the amount of heat produced for the rapid plate movements, and the fact that the cooling of hot oceanic plates and the raising of continental plates would take a great deal of time and require multiple small scale catastrophes after the flood ended. The original CPT proposal of Austin and others in 1994 was admittedly preliminary but the major issues have not been solved.\n\nThe vast majority of geologists regard the hypothesis of catastrophic plate tectonics as pseudoscience; they reject it in favor of the conventional geological theory of plate tectonics. It has been argued that the tremendous release of energy necessitated by such an event would boil off the Earth's oceans, making a global flood impossible. Not only does catastrophic plate tectonics lack any plausible geophysical mechanism by which its changes might occur, it also is contradicted by considerable geological evidence (which is in turn consistent with conventional plate tectonics), including:\n\n\nConventional plate tectonics accounts for the geological evidence already, including innumerable details that catastrophic plate tectonics cannot, such as why there is gold in California, silver in Nevada, salt flats in Utah, and coal in Pennsylvania, without requiring any extraordinary mechanisms to do so.\n\nIsaac Vail (1840–1912), a Quaker schoolteacher, in his 1912 work \"The Earth's Annular System\", extrapolated from the nebular hypothesis what he called the annular system of earth history, with the earth being originally surrounded by rings resembling those of Saturn, or \"canopies\" of water vapor. Vail hypothesised that, one by one, these canopies collapsed on the Earth, resulting in fossils being buried in a \"succession of stupendous cataclysms, separated by unknown periods of time\". The Genesis flood was thought to have been caused by \"the last remnant\" of this vapor. Although this final flood was geologically significant, it was not held to account for as much of the fossil record as George McCready Price had asserted. \n\nVail's ideas about geology appeared in Charles Taze Russell's \"The Photo-Drama of Creation\" and subsequently in Joseph Franklin Rutherford's \"Creation\" of 1927 and later publications. The Seventh-day Adventist physicist Robert W. Woods also proposed a vapor canopy, before \"The Genesis Flood\" gave it prominent and repeated mention in 1961.\n\nThough the vapor-canopy theory has fallen into disfavour among most creationists, Dillow in 1981 and Vardiman in 2003 attempted to defend the idea. Among its more vocal adherents, controversial Young Earth Creationist Kent Hovind uses it as the basis for his eponymous \"Hovind Theory\". Jehovah's Witnesses propose as the water source of the deluge a \"heavenly ocean\" that was over the earth from the second creative day until the Flood.\n\nModern geology, its sub-disciplines and other scientific disciplines utilize the scientific method to analyze the geology of the earth. The key tenets of flood geology are refuted by scientific analysis and do not have any standing in the scientific community. Modern geology relies on a number of established principles, one of the most important of which is Charles Lyell's principle of uniformitarianism. In relation to geological forces it states that the shaping of the Earth has occurred by means of mostly slow-acting forces that can be seen in operation today. By applying these principles, geologists have determined that the Earth is approximately 4.54 billion years old. They study the lithosphere of the Earth to gain information on the history of the planet. Geologists divide Earth's history into eons, eras, periods, epochs, and faunal stages characterized by well-defined breaks in the fossil record (see Geologic time scale). In general, there is a lack of any evidence for any of the above effects proposed by flood geologists and their claims of fossil layering are not taken seriously by scientists.\n\nThe global flood cannot explain geological formations such as angular unconformities, where sedimentary rocks have been tilted and eroded then more sedimentary layers deposited on top, needing long periods of time for these processes. There is also the time needed for the erosion of valleys in sedimentary rock mountains. In another example, the flood, had it occurred, should also have produced large-scale effects spread throughout the entire world. Erosion should be evenly distributed, yet the levels of erosion in, for example, the Appalachians and the Rocky Mountains differ significantly.\n\nGeochronology is the science of determining the absolute age of rocks, fossils, and sediments by a variety of techniques. These methods indicate that the Earth as a whole is about 4.54 billion years old, and that the strata that, according to flood geology, were laid down during the Flood some 6,000 years ago, were actually deposited gradually over many millions of years.\n\nIf the flood were responsible for fossilization, then all the animals now fossilized must have been living together on the Earth just before the flood. Based on estimates of the number of remains buried in the Karoo fossil formation in Africa, this would correspond to an abnormally high density of vertebrates worldwide, close to 2100 per acre.\nCreationists argue that evidence for the geological column is fragmentary, and all the complex layers of chalk occurred in the approach to the 150th day of Noah's flood. However, the entire geologic column is found in several places, and shows multiple features, including evidence of erosion and burrowing through older layers, which are inexplicable on a short timescale. Carbonate hardgrounds and the fossils associated with them show that the so-called flood sediments include evidence of long hiatuses in deposition that are not consistent with flood dynamics or timing.\n\nProponents of Flood Geology are also unable to account for the alternation between calcite seas and aragonite seas through the Phanerozoic. The cyclical pattern of carbonate hardgrounds, calcitic and aragonitic ooids, and calcite-shelled fauna has apparently been controlled by seafloor spreading rates and the flushing of seawater through hydrothermal vents which changes its Mg/Ca ratio.\n\nPhil Senter's 2011 article, \"The Defeat of Flood Geology by Flood Geology\", in the journal \"Reports of the National Center for Science Education\", discusses \"sedimentologic and other geologic features that Flood geologists have identified as evidence that particular strata cannot have been deposited during a time when the entire planet was under water ... and distribution of strata that predate the existence of the Ararat mountain chain.\" These include continental basalts, terrestrial tracks of animals, and marine communities preserving multiple in-situ generations included in the rocks of most or all Phanerozoic periods, and the basalt even in the younger Precambrian rocks. Others, occurring in rocks of several geologic periods, include lake deposits and eolian (wind) deposits. Using their own words, Flood geologists find evidence in every Paleozoic and Mesozoic period, and in every epoch of the Cenozoic period, indicating that a global flood could not have occurred during that interval.\n\n\n\n\n\n\n\n"}
{"id": "21442245", "url": "https://en.wikipedia.org/wiki?curid=21442245", "title": "Fossil fuel exporters", "text": "Fossil fuel exporters\n\nPetroleum, natural gas, and coal are exported from various source countries to countries reliant on these fossil fuels.\n\nSaudi Arabia is the largest exporter of crude petroleum in the world.\n\nThis is a list of countries by crude oil exports mostly based on The World Factbook:\n\nThis is a list of countries by natural gas exports mostly based on The World Factbook:\n\nThis is a list of countries by coal exports mostly based on US Energy Information Administration:\n"}
{"id": "53475230", "url": "https://en.wikipedia.org/wiki?curid=53475230", "title": "Home energy storage", "text": "Home energy storage\n\nHome energy storage devices store electricity locally, for later consumption. At their heart are batteries, typically lithium-ion or lead-acid, and intelligent software. An energy storage technology, they are downstream relatives of battery-based grid energy storage and support the concept of distributed generation. When paired with on-site generation, they can virtually eliminate blackouts in an off-the-grid lifestyle.\n\nThe stored energy commonly originates from on-site solar photovoltaic panels, generated during daylight hours, and the stored electricity consumed after sundown, when domestic energy demand peaks in homes unoccupied during the day.\n\nElectric vehicles (EVs) used during weekdays, needing recharging overnight, are a good fit with home energy storage in homes with solar panels and low daylight-hour electrical consumption. EV manufacturers Tesla, Mercedes-Benz, BMW, Nissan and BYD market own-brand home energy storage devices to their customers, with Tesla's Powerwall enjoying significant media exposure.\n\nThe units can also be programmed to exploit a differential tariff, that provide lower priced energy during hours of low demand - seven hours from 12:30am in the case of Britain’s Economy 7 tariff - for consumption when prices are higher.\n\nSmart tariffs, stemming from the increasing prevalence of smart meters, will increasingly be paired with home energy storage devices to exploit low off-peak prices, and avoid higher-priced energy at times of peak demand.\n\nTransmission of electrical power from power stations to population centres is inherently inefficient, due to transmission losses in electrical grids, particularly within power-hungry dense conurbations where power stations are harder to site. By allowing a greater proportion of on-site generated electricity to be consumed on-site, rather than exported to the energy grid, home energy storage devices can reduce the inefficiencies of grid transport.\n\nHome energy storage devices, when connected to a server via the internet, can theoretically be ordered to provide very short-term services to the energy grid:-\n\nDue to the above efficiencies, and their ability to boost the amount of solar energy consumed on-site, the devices reduce the amount of power generated using fossil fuels, namely natural gas, coal, oil and diesel.\n\nLithium-ion batteries, a popular choice due to their relatively high charge cycle and lack of memory effect, are difficult to recycle.\n\nLead-acid batteries are relatively easier to recycle and, due to the high resale value of the lead, 99% of those sold in the US get recycled. They have much shorter useful lives than a lithium-ion battery of a similar capacity, due to having a lower charge cycle, narrowing the environmental-impact gap. In addition, lead is a toxic heavy metal and the sulphuric acid in the electrolyte has a high environmental impact.\n\nTo offset the environmental impact of batteries, some manufacturers extend the useful life of used batteries taken from electric vehicles at the point where the cells won't sufficiently hold charge. Though considered end of life for electric vehicles, the batteries will function satisfactorily in home energy storage devices. Manufacturers supporting this include Nissan, BMW and Powervault.\n\nHome Energy Storage devices can be paired with salt water batteries, which have a lower environmental impact due to their lack of toxic heavy metal and ease of recyclability.\n\nUsing a pumped-storage system of cisterns for energy storage and small generators, pico hydro generation may also be effective for \"closed loop\" home energy generation systems. \n\n"}
{"id": "37304289", "url": "https://en.wikipedia.org/wiki?curid=37304289", "title": "Illustrations of the Nests and Eggs of Birds of Ohio", "text": "Illustrations of the Nests and Eggs of Birds of Ohio\n\nIllustrations of the Nests and Eggs of Birds of Ohio is a two volume book of scientific illustrations published by subscription between the years 1879 and 1886. It was conceived by Genevieve Estelle Jones, who began work on the book in 1877 and was initially its principal illustrator. The book was completed by Jones's family after her death from typhoid fever.\n\nAs a child, Jones accompanied her father, Dr. Nelson Jones, as he visited patients. As they traveled, the two would collect birds' eggs and nests for the family's natural history cabinet. Jones developed an interest in ornithology. When Jones and her father acquired a nest of a Baltimore oriole, Jones searched for a book to use to research and identify it and was surprised that one did not exist. Her brother, Howard, later commented that if she would paint the images for such a book he would collect them for her. In 1876, Jones viewed James Audubon's \"The Birds of America\" at the World's Fair in Philadelphia and was inspired to undertake the project.\n\nThe initial installment of the book was extremely well received. Ornithologist Elliott Coues, writing in \"Bulletin of the Nuttall Ornithology Club\", wrote that \"there has been nothing since Audubon in the way of pictorial illustrations of American Ornithology to compare with the present work - nothing to claim the union of an equal degree of artistic skill and scientific accuracy.\" Naturalist William Brewster called her illustration of the nest of the Wood Thrush a \"perfect masterpiece.\"\n\nJones's family collaborated to complete the book after Jones's death. Jones's mother, Virginia Jones, took over first the coloring and then the actual drawing of the illustrations. Dr. Howard Jones wrote the accompanying text, as well as collecting the specimens featured in the illustrations. Jones's father, Dr. Nelson Jones, who had written the original prospectus for the piece, covered most of the costs of its continued publication.\n"}
{"id": "1930382", "url": "https://en.wikipedia.org/wiki?curid=1930382", "title": "Iusaaset", "text": "Iusaaset\n\nIusaaset (; \"the great one who comes forth\") or Iusaas () is a primordial goddess in Ancient Egyptian religion. In Egyptian texts, she is described as \"the grandmother of all of the deities\". This allusion is without any reference to a grandfather, so there might have been a very early, but now lost, myth with parthenogenesis as the means of the birth of the deities from the region where her cult arose near the delta of the Nile. There are many alternative spellings of her name, including \"Iusaaset\", \"Iusaas\", \"Juesaes\", \"Ausaas\", and \"Jusas\", as well as in Greek Saosis .\n\nIn Ancient Egyptian art, Iusaaset appears as a woman wearing the vulture crown of Mut, another mother goddess, topped with the solar disk between cow horns, the headdress of Hathor. She carries an ankh in one hand and a was sceptre in the other, and sometimes her crown bore a uraeus (Egyptian cobra), representing the goddess Wadjet. The Egyptian vulture that made up her crown symbolised the goddess Nekhbet, the other one of the Two Ladies protecting Egypt, alongside Wadjet. The Egyptian vulture was also thought to reproduce though parthenogenesis, which might be the basis for a similar view about the motherhood of Iusaaset. The vultures were also considered extremely good mothers, protecting their chicks at any cost, so it is not surprising that mother goddesses like Nekhbet, Iusaaset and Mut were portrayed as or with them.\n\nBecause of Iusaaset’s link to the vulture and uraeus, it can be assumed that she links together both upper and lower Egypt, much like the goddess Mut, with whom she is closely associated.\n\nAlthough her origins are unclear, Iusaaset seems to be attested quite early in the Egyptian pantheon, being associated with creation in general and the creation of the deities in particular. Many myths relate that she was seen as the mother of the first deities and the grandmother of the following deities, having \"watched over\" the birth of the ones that were her grandchildren. She remained a primary deity in the pantheon throughout all eras of the culture, even through the Persian, Hykso, Greek, and Roman occupations, and regardless of changes in the specific myths.\n\nIusaaset was associated with the acacia tree, considered the \"tree of life\" by the Egyptians. The oldest known acacia tree was situated just north of Heliopolis, which therefore became identified as the birthplace of the deities. Iusaaset was said to own this tree, just as Osiris owned the sacred willow. The acacia tree was renowned for its strength, hardiness, medical properties, and edibility. Many useful applications gave it a central importance in Egyptian culture.\n\nOne belief, particularly prominent in Heliopolis, held that Iusaaset and Atum were the parents of Shu and Tefnut, the first deities. In this myth she was often described as the shadow, sister, or wife of Atum. In later periods, other goddesses also became associated with Atum, and one variant even relates that he gave birth to the deities himself, although that variant seems to have been rejected by most cultural and religious centres.\n\nDuring the Old Kingdom, the Egyptians believed that Atum lifted the dead pharaoh's soul from the tomb to the starry heavens, associating him with the heavens, and in particular the greatest heavenly object in Egyptian thought: the Sun. By the time of the New Kingdom, the myth of Atum had merged with that of Ra, who was likewise described as a creator deity and a solar deity as his cult arose. Their two identities were joined together to form Atum-Ra. After they were combined, Ra came to be seen as the sun at midday and Atum as the sun when it sets in the west (depicted as an old man leaning on his staff), while Khepri was seen as the sun when it was rising. \n\nIn these later times Iusaaset was sometimes described as the Eye of Ra, associating her with other so-called Eye goddesses such as Hathor, Sekhmet and Bast.\n\n"}
{"id": "16472", "url": "https://en.wikipedia.org/wiki?curid=16472", "title": "Jet stream", "text": "Jet stream\n\nJet streams are fast flowing, narrow, meandering air currents in the atmospheres of some planets, including Earth. On Earth, the main jet streams are located near the altitude of the tropopause and are westerly winds (flowing west to east). Their paths typically have a meandering shape. Jet streams may start, stop, split into two or more parts, combine into one stream, or flow in various directions including opposite to the direction of the remainder of the jet.\n\nThe strongest jet streams are the polar jets, at above sea level, and the higher altitude and somewhat weaker subtropical jets at . The Northern Hemisphere and the Southern Hemisphere each have a polar jet and a subtropical jet. The northern hemisphere polar jet flows over the middle to northern latitudes of North America, Europe, and Asia and their intervening oceans, while the southern hemisphere polar jet mostly circles Antarctica all year round.\n\nJet streams are the product of two factors: the atmospheric heating by solar radiation that produces the large-scale Polar, Ferrel, and Hadley circulation cells, and the action of the Coriolis force acting on those moving masses. The Coriolis force is caused by the planet's rotation on its axis. On other planets, internal heat rather than solar heating drives their jet streams. The Polar jet stream forms near the interface of the Polar and Ferrel circulation cells; the subtropical jet forms near the boundary of the Ferrel and Hadley circulation cells.\n\nOther jet streams also exist. During the Northern Hemisphere summer, easterly jets can form in tropical regions, typically where dry air encounters more humid air at high altitudes. Low-level jets also are typical of various regions such as the central United States. There are also jetstreams in the thermosphere.\n\nMeteorologists use the location of some of the jet streams as an aid in weather forecasting. The main commercial relevance of the jet streams is in air travel, as flight time can be dramatically affected by either flying with the flow or against, which results in significant fuel and time cost savings for airlines. Often, the airlines work to fly 'with' the jet stream for this reason. Dynamic North Atlantic Tracks are one example of how airlines and air traffic control work together to accommodate the jet stream and winds aloft that results in the maximum benefit for airlines and other users. Clear-air turbulence, a potential hazard to aircraft passenger safety, is often found in a jet stream's vicinity, but it does not create a substantial alteration on flight times. These are narrow belts.\n\nAfter the 1883 eruption of the Krakatoa volcano, weather watchers tracked and mapped the effects on the sky over several years. They labelled the phenomenon the \"equatorial smoke stream\". In the 1920s, a Japanese meteorologist, Wasaburo Oishi, detected the jet stream from a site near Mount Fuji. He tracked pilot balloons, also known as pibals (balloons used to determine upper level winds), as they rose into the atmosphere. Oishi's work largely went unnoticed outside Japan because it was published in Esperanto. American pilot Wiley Post, the first man to fly around the world solo in 1933, is often given some credit for discovery of jet streams. Post invented a pressurized suit that let him fly above . In the year before his death, Post made several attempts at a high-altitude transcontinental flight, and noticed that at times his ground speed greatly exceeded his air speed.\nGerman meteorologist Heinrich Seilkopf is credited with coining a special term, \"Strahlströmung\" (literally \"jet current\"), for the phenomenon in 1939. (Modern German usage is \"Strahlstrom\".) Many sources credit real understanding of the nature of jet streams to regular and repeated flight-path traversals during World War II. Flyers consistently noticed westerly tailwinds in excess of in flights, for example, from the US to the UK. Similarly in 1944 a team of American meteorologists in Guam, including Reid Bryson, had enough observations to forecast very high west winds that would slow bombers going to Japan.\n\nPolar jet streams are typically located near the 250 hPa (about 1/4 atmosphere) pressure level, or above sea level, while the weaker subtropical jet streams are much higher, between . Jet streams wander laterally dramatically, and have large changes in their altitude. The jet streams form near breaks in the tropopause, at the transitions between the Polar, Ferrel and Hadley circulation cells, and whose circulation, with the Coriolis force acting on those masses, drives the jet streams. The Polar jets, at lower altitude, and often intruding into mid-latitudes, strongly affects weather and aviation. The polar jet stream is most commonly found between latitudes 30° and 60° (closer to 60°), while the subtropical jet streams are located close to latitude 30°. The northern Polar jet stream is said to \"follow the sun\" as it slowly migrates northward as that hemisphere warms, and southward again as it cools.\n\nThe width of a jet stream is typically a few hundred kilometres or miles and its vertical thickness often less than .\n\nJet streams are typically continuous over long distances, but discontinuities are common. The path of the jet typically has a meandering shape, and these meanders themselves propagate eastward, at lower speeds than that of the actual wind within the flow. Each large meander, or wave, within the jet stream is known as a Rossby wave (planetary wave). Rossby waves are caused by changes in the Coriolis effect with latitude. Shortwave troughs, are smaller scale waves superimposed on the Rossby waves, with a scale of long, that move along through the flow pattern around large scale, or longwave, \"ridges\" and \"troughs\" within Rossby waves. Jet streams can split into two when they encounter an upper-level low, that diverts a portion of the jet stream under its base, while the remainder of the jet moves by to its north.\n\nThe wind speeds are greatest where temperature differences between air masses are greatest, and often exceed . Speeds over have been measured.\n\nThe jet stream moves from West to East bringing changes of weather. Meteorologists now understand that the path of jet streams affects cyclonic storm systems at lower levels in the atmosphere, and so knowledge of their course has become an important part of weather forecasting. For example, in 2007 and 2012, Britain experienced severe flooding as a result of the polar jet staying south for the summer.\n\nThe polar and subtropical jets merge at some locations and times, while at other times they are well separated.\n\nIn general, winds are strongest immediately under the tropopause (except locally, during tornadoes, tropical cyclones or other anomalous situations). If two air masses of different temperatures or densities meet, the resulting pressure difference caused by the density difference (which ultimately causes wind) is highest within the transition zone. The wind does not flow directly from the hot to the cold area, but is deflected by the Coriolis effect and flows along the boundary of the two air masses.\n\nAll these facts are consequences of the thermal wind relation. The balance of forces acting on an atmospheric air parcel in the vertical direction is primarily between the gravitational force acting on the mass of the parcel and the buoyancy force, or the difference in pressure between the top and bottom surfaces of the parcel. Any imbalance between these forces results in the acceleration of the parcel in the imbalance direction: upward if the buoyant force exceeds the weight, and downward if the weight exceeds the buoyancy force. The balance in the vertical direction is referred to as hydrostatic. Beyond the tropics, the dominant forces act in the horizontal direction, and the primary struggle is between the Coriolis force and the pressure gradient force. Balance between these two forces is referred to as geostrophic. Given both hydrostatic and geostrophic balance, one can derive the thermal wind relation: the vertical gradient of the horizontal wind is proportional to the horizontal temperature gradient. If two air masses, one cold and dense to the North and the other hot and less dense to the South, are separated by a vertical boundary and that boundary should be removed, the difference in densities will result in the cold air mass slipping under the hotter and less dense air mass. The Coriolis effect will then cause poleward-moving mass to deviate to the East, while equatorward-moving mass will deviate toward the west. The general trend in the atmosphere is for temperatures to decrease in the poleward direction. As a result, winds develop an eastward component and that component grows with altitude. Therefore, the strong eastward moving jet streams are in part a simple consequence of the fact that the Equator is warmer than the North and South poles.\n\nThe thermal wind relation does not explain why the winds are organized into tight jets, rather than distributed more broadly over the hemisphere. One factor that contributes to the creation of a concentrated polar jet is the undercutting of sub-tropical air masses by the more dense polar air masses at the polar front. This causes surface low pressure and higher pressure at altitude. At high latitudes, lack of friction allows air to respond freely to the steep pressure gradient with low pressure at high altitude over the pole. This results in the formation of planetary wind circulations that experience a strong Coriolis deflection and thus can be considered 'quasi-geostrophic'. The polar front jet stream is closely linked to the frontogenesis process in midlatitudes, as the acceleration/deceleration of the air flow induces areas of low/high pressure respectively, which link to the formation of cyclones and anticyclones along the polar front in a relatively narrow region.\n\nA second factor which contributes to a concentrated jet, that is more applicable to the subtropical jet, which forms at the poleward limit of the tropical Hadley cell and to first order this circulation is symmetric with respect to longitude. Tropical air rises to the tropopause, and moves poleward before sinking; this is the Hadley cell circulation. As it does so it tends to conserve angular momentum, since friction with the ground is slight. Air masses that begin moving poleward are deflected eastward by the Coriolis force (true for either hemisphere), which for poleward moving air implies an increased westward component of the winds (note that leftward deflection in the southern hemisphere).\n\nJupiter's atmosphere has multiple jet streams, caused by the convection cells that form the familiar banded color structure; on Jupiter, these convection cells are driven by internal heating. The factors that control the number of jet streams in a planetary atmosphere is an active area of research in dynamical meteorology. In models, as one increases the planetary radius, holding all other parameters fixed, the number of jet streams decreases.\n\nThe subtropical jet stream rounding the base of the mid-oceanic upper trough is thought to be one of the reasons most of the Hawaiian Islands have been resistant to the long list of Hawaii hurricanes that have approached. For example, when Hurricane Flossie (2007) approached and dissipated just before reaching landfall, the U.S. National Oceanic and Atmospheric Administration (NOAA) cited vertical wind shear as evidenced in the photo.\n\nOn Earth, the northern polar jet stream is the most important one for aviation and weather forecasting, as it is much stronger and at a much lower altitude than the subtropical jet streams and also covers many countries in the Northern Hemisphere, while the southern polar jet stream mostly circles Antarctica and sometimes the southern tip of South America. The term \"jet stream\" in these contexts thus usually implies the northern polar jet stream.\n\nThe location of the jet stream is extremely important for aviation. Commercial use of the jet stream began on 18 November 1952, when Pan Am flew from Tokyo to Honolulu at an altitude of . It cut the trip time by over one-third, from 18 to 11.5 hours. Not only does it cut time off the flight, it also nets fuel savings for the airline industry. Within North America, the time needed to fly east across the continent can be decreased by about 30 minutes if an airplane can fly with the jet stream, or increased by more than that amount if it must fly west against it.\n\nAssociated with jet streams is a phenomenon known as clear-air turbulence (CAT), caused by vertical and horizontal wind shear caused by jet streams. The CAT is strongest on the cold air side of the jet, next to and just under the axis of the jet. Clear-air turbulence can cause aircraft to plunge and so present a passenger safety hazard that has caused fatal accidents, such as the death of one passenger on United Airlines Flight 826.\n\nScientists are investigating ways to harness the wind energy within the jet stream. According to one estimate, of the potential wind energy in the jet stream, only 1 percent would be needed to meet the world's current energy needs. The required technology would reportedly take 10–20 years to develop.\nThere are two major but divergent scientific articles about jet stream power. Archer & Caldeira claim that the Earth's jet streams could generate a total power of 1700 terawatts (TW) and that the climatic impact of harnessing this amount would be negligible. However, Miller, Gans, & Kleidon claim that the jet streams could generate a total power of only 7.5 TW and that the climatic impact would be catastrophic.\n\nNear the end of World War II the Japanese fire balloon was designed as a cheap weapon intended to make use of the jet stream over the Pacific Ocean to reach the west coast of Canada and the United States. They were relatively ineffective as weapons, but they were used in one of the few attacks on North America during World War II, causing six deaths and a small amount of damage.\n\nEl Niño-Southern Oscillation (ENSO) influences the average location of upper-level jet streams, and leads to cyclical variations in precipitation and temperature across North America, as well as affecting tropical cyclone development across the eastern Pacific and Atlantic basins. Combined with the Pacific Decadal Oscillation, ENSO can also impact cold season rainfall in Europe. Changes in ENSO also change the location of the jet stream over South America, which partially affects precipitation distribution over the continent.\n\nDuring El Niño events, increased precipitation is expected in California due to a more southerly, zonal, storm track. During the Niño portion of ENSO, increased precipitation falls along the Gulf coast and Southeast due to a stronger than normal, and more southerly, polar jet stream. Snowfall is greater than average across the southern Rockies and Sierra Nevada mountain range, and is well below normal across the Upper Midwest and Great Lakes states. The northern tier of the lower 48 exhibits above normal temperatures during the fall and winter, while the Gulf coast experiences below normal temperatures during the winter season. The subtropical jet stream across the deep tropics of the Northern Hemisphere is enhanced due to increased convection in the equatorial Pacific, which decreases tropical cyclogenesis within the Atlantic tropics below what is normal, and increases tropical cyclone activity across the eastern Pacific. In the Southern Hemisphere, the subtropical jet stream is displaced equatorward, or north, of its normal position, which diverts frontal systems and thunderstorm complexes from reaching central portions of the continent.\n\nAcross North America during La Niña, increased precipitation is diverted into the Pacific Northwest due to a more northerly storm track and jet stream. The storm track shifts far enough northward to bring wetter than normal conditions (in the form of increased snowfall) to the Midwestern states, as well as hot and dry summers. Snowfall is above normal across the Pacific Northwest and western Great Lakes. Across the North Atlantic, the jet stream is stronger than normal, which directs stronger systems with increased precipitation towards Europe.\n\nEvidence suggests the jet stream was at least partly responsible for the widespread drought conditions during the 1930s Dust Bowl in the Midwest United States. Normally, the jet stream flows east over the Gulf of Mexico and turns northward pulling up moisture and dumping rain onto the Great Plains. During the Dust Bowl, the jet stream weakened and changed course traveling farther south than normal. This starved the Great Plains and other areas of the Midwest of rainfall, causing extraordinary drought conditions.\n\nClimate scientists have hypothesized that the jet stream will gradually weaken as a result of global warming. Trends such as Arctic sea ice decline, reduced snow cover, evapotranspiration patterns, and other weather anomalies are expected to make the Arctic heat up faster than other parts of the globe. This in turn reduces the temperature gradient that drives jet stream winds, causing the jet stream to become weaker and more variable in its course.\n\nSince 2007, and particularly in 2012 and early 2013, the jet stream has been at an abnormally low latitude across the UK, lying closer to the English Channel, around 50°N rather than its more usual north of Scotland latitude of around 60°N. However, between 1979 and 2001, it has been found that the average position of the jet stream has been moving northward at a rate of per year across the Northern Hemisphere. Across North America, this type of change could lead to drier conditions across the southern tier of the United States and more frequent and more intense tropical cyclones in the tropics. A similar slow poleward drift was found when studying the Southern Hemisphere jet stream over the same time frame.\n\nThe polar-night jet stream forms mainly during the winter months when the nights are much longer, hence polar nights, in their respective hemispheres at around 60° latitude. The polar night jet moves at a greater height of about than it does during the summer. During these dark months the air high over the poles becomes much colder than the air over the Equator. This difference in temperature gives rise to extreme air pressure differences in the stratosphere, which, when combined with the Coriolis effect, create the polar night jets, that race eastward at an altitude of about . The polar vortex is circled by the polar night jet. The warmer air can only move along the edge of the polar vortex, but not enter it. Within the vortex, the cold polar air becomes increasingly cold with neither warmer air from lower latitudes nor energy from the Sun during the polar night.\n\nThere are wind maxima at lower levels of the atmosphere that are also referred to as jets.\n\nA barrier jet in the low levels forms just upstream of mountain chains, with the mountains forcing the jet to be oriented parallel to the mountains. The mountain barrier increases the strength of the low level wind by 45 percent. In the North American Great Plains a southerly low-level jet helps fuel overnight thunderstorm activity during the warm season, normally in the form of mesoscale convective systems which form during the overnight hours. A similar phenomenon develops across Australia, which pulls moisture poleward from the Coral Sea towards cut-off lows which form mainly across southwestern portions of the continent.\n\nA valley exit jet is a strong, down-valley, elevated air current that emerges above the intersection of the valley and its adjacent plain. These winds frequently reach a maximum of 20 m/s (45 mph or 72 km/h) at a height of 40–200 m above the ground. Surface winds below the jet may sway vegetation, but are significantly weaker.\n\nThey are likely to be found in valley regions that exhibit diurnal mountain wind systems, such as those of the dry mountain ranges of the US. Deep valleys that terminate abruptly at a plain are more impacted by these factors than are those that gradually become shallower as downvalley distance increases.\n\nThe mid-level African easterly jet occurs during the Northern Hemisphere summer between 10°N and 20°N above West Africa, and the nocturnal poleward low-level jet occurs in the Great Plains of east and South Africa. The low-level easterly African jet stream is considered to play a crucial role in the southwest monsoon of Africa, and helps form the tropical waves which move across the tropical Atlantic and eastern Pacific oceans during the warm season. The formation of the thermal low over northern Africa leads to a low-level westerly jet stream from June into October.\n\n\n"}
{"id": "935830", "url": "https://en.wikipedia.org/wiki?curid=935830", "title": "Kelvin wave", "text": "Kelvin wave\n\nA Kelvin wave is a wave in the ocean or atmosphere that balances the Earth's Coriolis force against a topographic boundary such as a coastline, or a waveguide such as the equator. A feature of a Kelvin wave is that it is non-dispersive, i.e., the phase speed of the wave crests is equal to the group speed of the wave energy for all frequencies. This means that it retains its shape as it moves in the alongshore direction over time.\n\nA Kelvin wave (fluid dynamics) is also a long scale perturbation mode of a vortex in superfluid dynamics; in terms of the meteorological or oceanographical derivation, one may assume that the meridional velocity component vanishes (i.e. there is no flow in the north–south direction, thus making the momentum and continuity equations much simpler). This wave is named after the discoverer, Lord Kelvin (1879).\n\nIn a stratified ocean of mean depth \"H\", free waves propagate along coastal boundaries (and hence become trapped in the vicinity of the coast itself) in the form of internal Kelvin waves on a scale of about 30 km. These waves are called coastal Kelvin waves, and have propagation speeds of approximately 2 m/s in the ocean. Using the assumption that the cross-shore velocity \"v\" is zero at the coast, \"v\" = 0, one may solve a frequency relation for the phase speed of coastal Kelvin waves, which are among the class of waves called boundary waves, edge waves, trapped waves, or surface waves (similar to the Lamb waves). The (linearised) primitive equations then become the following:\n\n\n\n\nIf one assumes that the Coriolis coefficient \"f\" is constant along the right boundary conditions and the zonal wind speed is set equal to zero, then the primitive equations become the following:\n\n\n\n\nThe solution to these equations yields the following phase speed: \"c\" = \"gH\", which is the same speed as for shallow-water gravity waves without the effect of Earth’s rotation. It is important to note that for an observer traveling with the wave, the coastal boundary (maximum amplitude) is always to the right in the northern hemisphere and to the left in the southern hemisphere (i.e. these waves move equatorward – negative phase speed – on a western boundary and poleward – positive phase speed – on an eastern boundary; the waves move cyclonically around an ocean basin).\n\nThe equatorial zone essentially acts as a waveguide, causing disturbances to be trapped in the vicinity of the Equator, and the equatorial Kelvin wave illustrates this fact because the Equator acts analogously to a topographic boundary for both the Northern and Southern Hemispheres, making this wave very similar to the coastally-trapped Kelvin wave. The primitive equations are identical to those used to develop the coastal Kelvin wave phase speed solution (U-momentum, V-momentum, and continuity equations) and the motion is unidirectional and parallel to the Equator. Because these waves are equatorial, the Coriolis parameter vanishes at 0 degrees; therefore, it is necessary to use the equatorial beta plane approximation that states: \n\nwhere \"β\" is the variation of the Coriolis parameter with latitude. This equatorial beta plane assumption requires a geostrophic balance between the eastward velocity and the north-south pressure gradient. The phase speed is identical to that of coastal Kelvin waves, indicating that the equatorial Kelvin waves propagate toward the east without dispersion (as if the earth were a non-rotating planet). For the first baroclinic mode in the ocean, a typical phase speed would be about 2.8 m/s, causing an equatorial Kelvin wave to take 2 months to cross the Pacific Ocean between New Guinea and South America; for higher ocean and atmospheric modes, the phase speeds are comparable to fluid flow speeds. \n\nWhen the motion at the Equator is to the east, any deviation toward the north is brought back toward the Equator because the Coriolis force acts to the right of the direction of motion in the Northern Hemisphere, and any deviation to the south is brought back toward the Equator because the Coriolis force acts to the left of the direction of motion in the Southern Hemisphere. Note that for motion toward the west, the Coriolis force would not restore a northward or southward deviation back toward the Equator; thus, equatorial Kelvin waves are only possible for eastward motion (as noted above). Both atmospheric and oceanic equatorial Kelvin waves play an important role in the dynamics of El Nino-Southern Oscillation, by transmitting changes in conditions in the Western Pacific to the Eastern Pacific.\n\nThere have been studies that connect equatorial Kelvin waves to coastal Kelvin waves. Moore (1968) found that as an equatorial Kelvin wave strikes an \"eastern boundary\", part of the energy is reflected in the form of planetary and gravity waves; and the remainder of the energy is carried poleward along the eastern boundary as coastal Kelvin waves. This process indicates that some energy may be lost from the equatorial region and transported to the poleward region.\n\nEquatorial Kelvin waves are often associated with anomalies in surface wind stress. For example, positive (eastward) anomalies in wind stress in the central Pacific excite positive anomalies in 20°C isotherm depth which propagate to the east as equatorial Kelvin waves.\n\n\n"}
{"id": "1342255", "url": "https://en.wikipedia.org/wiki?curid=1342255", "title": "Kordylewski cloud", "text": "Kordylewski cloud\n\nKordylewski clouds are large concentrations of dust that exist at the and Lagrangian points of the Earth–Moon system. They were first reported by Polish astronomer Kazimierz Kordylewski in the 1960s, and confirmed to exist in October 2018.\n\nThe existence of a photometrically confirmable concentration of dust at the libration (Lagrangian) points was predicted by Josef Witkowski in 1956 (1951? ).\n\nThe clouds were first seen by Kordylewski in 1956. Between 6 March and 6 April 1961, he succeeded in photographing two bright patches near the libration point. During the observation time, the patches hardly appeared to move relative to . The observations were taken from the mountain Kasprowy Wierch.\n\nIn 1967, J. Wesley Simpson made observations of the clouds using the Kuiper Airborne Observatory.\nIn October 2018, the existence of the Kordylewski clouds was reported to have been confirmed, even though, earlier, in 2009, the Japanese Hiten space probe, which passed through the libration points to detect trapped dust particles, did not find an obvious increase in dust levels above the density in surrounding space.\n\nThe Kordylewski clouds are a very faint phenomenon, comparable to the brightness of the gegenschein. They are very difficult to observe from Earth but may be visible to the unaided eye in an exceptionally dark and clear night sky. Most claimed observations have been made from deserts, at sea, or from mountains. The clouds appear somewhat redder than the gegenschein, indicating that they may be made of a different kind of particle.\n\nThe Kordylewski clouds are located near the and Lagrange points of the Earth–Moon system. They are about 6 degrees in angular diameter. The clouds can drift up to 6 to 10 degrees from those points. Other observations suggest they move around the libration points in ellipses of about 6 by 2 degrees.\n\n\n"}
{"id": "47198954", "url": "https://en.wikipedia.org/wiki?curid=47198954", "title": "List of Cladonia species", "text": "List of Cladonia species\n\nCladonia is a large genus of lichens in the family Lecanoraceae. , \"Index Fungorum\" lists 276 species in the genus.\n\nA B C D E F G H I J K L M N O P Q R S T U V U W X Y Z\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "24569588", "url": "https://en.wikipedia.org/wiki?curid=24569588", "title": "List of Eucalypt trees", "text": "List of Eucalypt trees\n\nThis table lists famous individual trees in the genus Eucalyptus.\n\n\n"}
{"id": "505485", "url": "https://en.wikipedia.org/wiki?curid=505485", "title": "List of national parks of Slovakia", "text": "List of national parks of Slovakia\n\nThere are nine national parks in Slovakia:\n\n\n"}
{"id": "46504577", "url": "https://en.wikipedia.org/wiki?curid=46504577", "title": "List of potato cultivars", "text": "List of potato cultivars\n\nThis is a list of potato varieties or cultivars. As a general rule of thumb, it is possible to segregate potato cultivars into either white, or colored.\n\n"}
{"id": "34642230", "url": "https://en.wikipedia.org/wiki?curid=34642230", "title": "List of rivers of Iraq", "text": "List of rivers of Iraq\n\nThis is a list of rivers in Iraq.\n\n\n\n\n"}
{"id": "36737681", "url": "https://en.wikipedia.org/wiki?curid=36737681", "title": "List of rivers of Seychelles", "text": "List of rivers of Seychelles\n\nThis is a list of rivers in Seychelles. This list is arranged by island, streams are listed clockwise starting from the north end of the island.\n\n"}
{"id": "73448", "url": "https://en.wikipedia.org/wiki?curid=73448", "title": "Mangrove", "text": "Mangrove\n\nA mangrove is a shrub or small tree that grows in coastal saline or brackish water. The term is also used for tropical coastal vegetation consisting of such species. Mangroves occur worldwide in the tropics and subtropics, mainly between latitudes ° N and ° S. The total mangrove forest area of the world in 2000 was , spanning 118 countries and territories.\n\nMangroves are salt-tolerant trees, also called halophytes, and are adapted to life in harsh coastal conditions. They contain a complex salt filtration system and complex root system to cope with salt water immersion and wave action. They are adapted to the low oxygen (anoxic) conditions of waterlogged mud.\n\nThe word is used in at least three senses: (1) most broadly to refer to the habitat and entire plant assemblage or \"mangal\", for which the terms \"mangrove forest biome\", and \"mangrove swamp\" are also used, (2) to refer to all trees and large shrubs in the mangrove swamp, and (3) narrowly to refer to the mangrove family of plants, the Rhizophoraceae, or even more specifically just to mangrove trees of the genus \"Rhizophora\".\n\nThe mangrove biome, or mangal, is a distinct saline woodland or shrubland habitat characterized by depositional coastal environments, where fine sediments (often with high organic content) collect in areas protected from high-energy wave action. The saline conditions tolerated by various mangrove species range from brackish water, through pure seawater (3 to 4%), to water concentrated by evaporation to over twice the salinity of ocean seawater (up to 9%).\nThe term \"mangrove\" comes to English from Spanish (perhaps by way of Portuguese), and is likely to originate from Guarani. It was earlier \"mangrow\" (from Portuguese ' or Spanish '), but this word was corrupted via folk etymology influence of the word \"grove\".\n\nMangrove swamps (mangals) are found in tropical and subtropical tidal areas. Areas where mangals occur include estuaries and marine shorelines.\n\nThe intertidal existence to which these trees are adapted represents the major limitation to the number of species able to thrive in their habitat. High tide brings in salt water, and when the tide recedes, solar evaporation of the seawater in the soil leads to further increases in salinity. The return of tide can flush out these soils, bringing them back to salinity levels comparable to that of seawater.\n\nAt low tide, organisms are also exposed to increases in temperature and desiccation, and are then cooled and flooded by the tide. Thus, for a plant to survive in this environment, it must tolerate broad ranges of salinity, temperature, and moisture, as well as a number of other key environmental factors—thus only a select few species make up the mangrove tree community.\n\nAbout 110 species are considered \"mangroves\", in the sense of being a tree that grows in such a saline swamp, though only a few are from the mangrove plant genus, \"Rhizophora\". However, a given mangrove swamp typically features only a small number of tree species. It is not uncommon for a mangrove forest in the Caribbean to feature only three or four tree species. For comparison, the tropical rainforest biome contains thousands of tree species, but this is not to say mangrove forests lack diversity. Though the trees themselves are few in species, the ecosystem that these trees create provides a home (habitat) for a great variety of other species.\n\nMangrove plants require a number of physiological adaptations to overcome the problems of anoxia, high salinity and frequent tidal inundation. Each species has its own solutions to these problems; this may be the primary reason why, on some shorelines, mangrove tree species show distinct zonation. Small environmental variations within a mangal may lead to greatly differing methods for coping with the environment. Therefore, the mix of species is partly determined by the tolerances of individual species to physical conditions, such as tidal inundation and salinity, but may also be influenced by other factors, such as predation of plant seedlings by crabs.\n\nOnce established, mangrove roots provide an oyster habitat and slow water flow, thereby enhancing sediment deposition in areas where it is already occurring. The fine, anoxic sediments under mangroves act as sinks for a variety of heavy (trace) metals which colloidal particles in the sediments have scavenged from the water. Mangrove removal disturbs these underlying sediments, often creating problems of trace metal contamination of seawater and biota.\n\nMangrove swamps protect coastal areas from erosion, storm surge (especially during hurricanes), and tsunamis. The mangroves' massive root systems are efficient at dissipating wave energy. Likewise, they slow down tidal water enough so its sediment is deposited as the tide comes in, leaving all except fine particles when the tide ebbs. In this way, mangroves build their own environments. Because of the uniqueness of mangrove ecosystems and the protection against erosion they provide, they are often the object of conservation programs, including national biodiversity action plans.\n\nMangrove swamps' effectiveness in terms of erosion control can sometimes be overstated. Wave energy is typically low in areas where mangroves grow, so their effect on erosion is measured over long periods. Their capacity to limit high-energy wave erosion is in relation to events such as storm surges and tsunamis.\n\nThe unique ecosystem found in the intricate mesh of mangrove roots offers a quiet marine region for young organisms. In areas where roots are permanently submerged, the organisms they host include algae, barnacles, oysters, sponges, and bryozoans, which all require a hard surface for anchoring while they filter feed. Shrimps and mud lobsters use the muddy bottoms as their home. Mangrove crabs munch on the mangrove leaves, adding nutrients to the mangal muds for other bottom feeders. In at least some cases, export of carbon fixed in mangroves is important in coastal food webs.\n\nMangrove plantations in Vietnam, Thailand, Philippines and India host several commercially important species of fishes and crustaceans. Despite restoration efforts, developers and others have removed over half of the world's mangroves in recent times.\n\nMangrove forests can decay into peat deposits because of fungal and bacterial processes as well as by the action of termites. It becomes peat in good geochemical, sedimentary and tectonic conditions. The nature of these deposits depends on the environment and the types of mangrove involved. In Puerto Rico the red (Rhizophora mangle), white (Laguncularia racemosa) and black (Avicennia germinans) mangroves occupy different ecological niches and have slightly different chemical compositions so the carbon content varies between the species as well between the different tissues of the plant e.g. leaf matter vs roots.\n\nIn Puerto Rico there is a clear succession of these three trees from the lower elevations which are dominated by red mangroves to farther inland with a higher concentration of white mangroves. Mangrove forests are an important part of the cycling and storage of carbon in tropical coastal ecosystems. Using this it is possible to attempt to reconstruct the environment and investigate changes to the coastal ecosystem for thousands of years by using sediment cores. However, an additional complication is the imported marine organic matter that also gets deposited in the sediment due to tidal flushing of mangrove forests.\n\nIn order to understand peat formation by mangroves, it is important to understand the conditions they grew in, and how they decayed. Termites are an important part of this decay, and so an understanding of their action on the organic matter is crucial to the chemical stabilization of mangrove peats.\n\nMangroves are an important source of blue carbon. Globally, mangroves stored 4.19 Pg of carbon in 2012. Two percent of global mangrove carbon was lost between 2000 and 2012, equivalent to a maximum potential of 316,996,250 t of CO emissions.\n\nOf the recognized 110 mangrove species, only about 54 species in 20 genera from 16 families constitute the \"true mangroves\", species that occur almost exclusively in mangrove habitats. Demonstrating convergent evolution, many of these species found similar solutions to the tropical conditions of variable salinity, tidal range (inundation), anaerobic soils and intense sunlight. Plant biodiversity is generally low in a given mangrove. The greatest biodiversity occurs in the mangal of New Guinea, Indonesia and Malaysia.\n\nRed mangroves, which can survive in the most inundated areas, prop themselves above the water level with stilt roots and can then absorb air through pores in their bark (lenticels). Black mangroves live on higher ground and make many pneumatophores (specialised root-like structures which stick up out of the soil like straws for breathing) which are also covered in lenticels.\n\nThese \"breathing tubes\" typically reach heights of up to 30 cm, and in some species, over 3 m. The four types of pneumatophores are stilt or prop type, snorkel or peg type, knee type, and ribbon or plank type. Knee and ribbon types may be combined with buttress roots at the base of the tree. The roots also contain wide aerenchyma to facilitate transport within the plants.\n\nRed mangroves exclude salt by having significantly impermeable roots which are highly suberised (impregnated with suberin), acting as an ultra-filtration mechanism to exclude sodium salts from the rest of the plant. Analysis of water inside mangroves has shown 90% to 97% of salt has been excluded at the roots. In a frequently cited concept that has become known as the \"sacrificial leaf\", salt which does accumulate in the shoot (sprout) then concentrates in old leaves, which the plant then sheds. However, recent research suggests the older, yellowing leaves have no more measurable salt content than the other, greener leaves. Red mangroves can also store salt in cell vacuoles. As seen in the photograph on the right, white or grey mangroves can secrete salts directly; they have two salt glands at each leaf base (correlating with their name—they are covered in white salt crystals).\n\nBecause of the limited fresh water available in salty intertidal soils, mangroves limit the amount of water they lose through their leaves. They can restrict the opening of their stomata (pores on the leaf surfaces, which exchange carbon dioxide gas and water vapour during photosynthesis). They also vary the orientation of their leaves to avoid the harsh midday sun and so reduce evaporation from the leaves. Anthony Calfo, a noted aquarium author, observed anecdotally a red mangrove in captivity only grows if its leaves are misted with fresh water several times a week, simulating frequent tropical rainstorms.\n\nBecause the soil is perpetually waterlogged, little free oxygen is available. Anaerobic bacteria liberate nitrogen gas, soluble ferrum (iron), inorganic phosphates, sulfides and methane, which make the soil much less nutritious. Pneumatophores (aerial roots) allow mangroves to absorb gases directly from the atmosphere, and other nutrients such as iron, from the inhospitable soil. Mangroves store gases directly inside the roots, processing them even when the roots are submerged during high tide.\n\nIn this harsh environment, mangroves have evolved a special mechanism to help their offspring survive. Mangrove seeds are buoyant and are therefore suited to water dispersal. Unlike most plants, whose seeds germinate in soil, many mangroves (e.g. red mangrove) are viviparous, whose seeds germinate while still attached to the parent tree. Once germinated, the seedling grows either within the fruit (e.g. \"Aegialitis\", \"Avicennia\" and \"Aegiceras\"), or out through the fruit (e.g. \"Rhizophora\", \"Ceriops\", \"Bruguiera\" and \"Nypa\") to form a propagule (a ready-to-go seedling) which can produce its own food via photosynthesis.\n\nThe mature propagule then drops into the water, which can transport it great distances. Propagules can survive desiccation and remain dormant for over a year before arriving in a suitable environment. Once a propagule is ready to root, its density changes so the elongated shape now floats vertically rather than horizontally. In this position, it is more likely to lodge in the mud and root. If it does not root, it can alter its density and drift again in search of more favorable conditions.\n\nThe following listing (modified from Tomlinson, 1986) gives the number of species of mangroves in each listed plant genus and family. Mangrove environments in the Eastern Hemisphere harbor six times as many species of trees and shrubs as do mangroves in the New World. Genetic divergence of mangrove lineages from terrestrial relatives, in combination with fossil evidence, suggests mangrove diversity is limited by evolutionary transition into the stressful marine environment, and the number of mangrove lineages has increased steadily over the Tertiary with little global extinction.\n\nMangroves can be found in over 118 countries and territories in the tropical and subtropical regions of the world. The largest percentage of mangroves is found between the 5° N and 5° S latitudes. Approximately 75% of world’s mangroves are found in just 15 countries. Asia has the largest amount (42%) of the world’s mangroves, followed by Africa (21%), North/Central America (15%), Oceania (12%) and South America (11%).\n\nThere are important mangrove swamps in Kenya, Tanzania, Democratic Republic of Congo (DRC) and Madagascar, with the latter even admixing at the coastal verge with dry deciduous forests.\n\nNigeria has Africa's largest mangrove concentration, spanning 36,000 km. Oil spills and leaks have destroyed many in the last 50 years, damaging the local fishing economy and water quality.\n\nAlong the coast of the Red Sea, both on the Egyptian side and in the Gulf of Aqaba, mangroves composed primarily of \"Avicennia marina\" and \"Rhizophora mucronata\" grow in about 28 stands that cover about 525 hectares. Almost all Egyptian mangrove stands are now protected.\n\nThere are mangroves off the east coast of South Africa extending as far south as the Tylomnqa River (33°13'26.1\"S 27°34'50.2\"E). Some mangrove stands exist in the St Lucia estuary within iSimangaliso Wetland Park.\n\nMangroves live in many parts of the tropical and subtropical coastal zones of North and South America.\n\nBecause of their sensitivity to subfreezing temperatures, mangroves in the continental United States are limited to the Florida peninsula (see Florida mangroves) and some isolated growths of black mangrove (\"Avicennia germinans\") at the southmost coast of Louisiana and South Texas.\n\nIn Mexico four species of mangrove predominate: \"Rhizophora mangle, Laguncularia racemosa, Avicennia germinans\" and \"Conocarpus erectus\". During an inventory conducted by CONABIO between 2006 and 2008, 770,057 hectares of mangrove were counted. Of this total, 55% are located in the Yucatán Peninsula.\n\nSignificant mangals include the Marismas Nacionales-San Blas mangroves found in Sinaloa and Nayarit.\n\nMangroves occur on the Pacific and Caribbean coasts of Belize, Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and Panama. Mangroves can also be found in many of the Antilles including Puerto Rico, Cuba, and Hispaniola, as well as other islands in the West Indies such as the Bahamas.\n\nThe nation of Belize has the highest overall percentage of forest cover of any of the Central American countries. In terms of Belize's mangrove cover—which assumes the form not only of mangrove 'forest', but also of scrubs and savannas, among others—a 2010 satellite-based study of Belize's mangroves by the World Wildlife Fund (WWF) and the Water Center for the Humid Tropics of Latin America and the Caribbean found, in 2010, mangroves covered some 184,548 acres (74,684 hectares) or 3.4% of Belize's territory.\n\nIn 1980, by contrast, mangrove cover stood at 188,417 acres (76,250 hectares)—also 3.4% of Belize's territory, although based on the work of mangrove researcher Simon Zisman, Belize's mangrove cover in 1980 was estimated to represent 98.7% of the precolonial extent of those ecosystems. Belize's mangrove cover in 2010 was thus estimated to represent 96.7% of the precolonial cover. Assessing changes in Belize's mangrove cover over a 30-year period was possible because of Belize's participation in the Regional Visualization and Monitoring System, a regional observatory jointly implemented by CATHALAC, RCMRD, ICIMOD, NASA, USAID, and other partners.\n\nBrazil contains approximately 26,000 km of mangals, 15% of the world's total.\n\nEcuador has substantial remaining mangrove forests in the provinces of El Oro, Guayas, Manabi and Esmeraldas with limited forest remaining in Santa Elena. The northern portion of Esmeraldas province has a large pristine mangrove forest that is preserved as the Reserva Ecológica Cayapas-Mataje (REMACAN) and is an original Ramsar site. This forest is the most preserved within Ecuador and likely the most pristine forest along the Pacific Coast of the Americas.\n\nThe only other major mangrove holding in Esmeraldas is in-and-around the community of Muisne and the Rio Muisne Estuary Swampland Wildlife Refuges. The mangroves in-and-around the estuaries of Muisne have decreased in area from 3222 ha in 1971 to 1065 ha as of 2005, during this time commercial shrimp aquaculture has become the dominant land-cover within this estuary environment.\n\nOn the border of Esmeraldas province and Manabí province is a formerly large area of mangrove within Cojimies Estuary. The mangroves in this estuary are some of the most degraded in Ecuador with only 19% of 1971 mangrove area remaining as of 1998, although mangrove has recovered since this date. Within Manabí the major mangrove holding estuary is the Chone estuary situated near the city of Bahía de Caráquez. Again, Chone has undergone substantial mangrove deforestation since the advent of commercial aquaculture in Ecuador. Although mangrove loss appears to have halted in this estuary and mangrove regrowth driven by local fisherman is now occurring.\n\nPeru has a very small region of mangrove located in the north-west of the country on the Ecuadorian Border.\n\nVenezuela's northern Caribbean island, Margarita, possesses mangrove forests in the Parque nacional Laguna de La Restinga. Venezuela has 4% of the world's mangroves, with an extension of 6735 km.\n\nColombia possesses large mangrove forests on both its Caribbean and Pacific coasts.\n\nThe Mangrove forests of Suriname have a height of 20–25 m and are found mainly in the coastal area. There are six types of mangroves, namely two types of parwa or black mangroves, three types of red mangroves (mangro) and a small mangrove species (white mangrove, akira or tjila).\n\nThe Sundarbans in the Ganges-Brahmaputra delta extend from the Hooghly River in West Bengal to the Baleswar River in Bangladesh, covering an area of about . This area comprises closed and open mangrove forests, agriculturally used land, mudflats and barren land. It is intersected by tidal streams and channels. Four protected areas in the Sundarbans, viz Sundarbans National Park, Sundarbans West, Sundarbans South and Sundarbans East Wildlife Sanctuaries are enlisted as UNESCO World Heritage Sites. Biodiversity includes at least 27 mangrove species, 40 mammal, 35 reptile and 260 bird species. More than 2.5 million people are estimated to live in the vicinity of the Sundarbans, making them one of the world's most densely populated areas.\nIt is the largest mangroves region and the largest single block of tidal halophytic mangrove forest in the world.\nSundri (\"Heritiera fomes\") trees provide durable hard timber. Palm, coconut, keora, agar, also grow in some parts of the delta. India's mangrove forests are habitat for saltwater crocodile (\"Crocodylus porosus\"), turtles, and snakes. This region is part of the Great Sundarbans and covers a National Park, Tiger reserve and a Biosphere Reserve.\nSundarbans was designated a Ramsar site on May 21, 1992. The fertile soils of the delta have been subject to intensive human use for centuries, and the ecoregion has been mostly converted to intensive agriculture, with few enclaves of forest remaining. The remaining forests, together with the Sundarbans mangroves, are important habitat for the endangered tiger. Additionally, the Sundarbans serves a crucial function as a protective flood barrier for the millions of inhabitants in and around Kolkata against the result of cyclone activity. \nSundarbans is home to many different species of birds, mammals, insects, reptiles and fish. It is estimated that there may be found more than 120 species of fish and over 260 species of birds and more than fifty species of reptiles and eight amphibians.\n\nAs per the ISFR 2017 report, the total area of mangrove cover of India is 4921 km, (181 km positively changed with respect to 2015 mangrove cover assessment) which contributes 3.3% to the global mangrove cover. The deltas of the Ganges, Mahanadi, Krishna, Godavari, and Kaveri rivers contain mangrove forests. Backwaters in Kerala have high density of mangrove forest on the shores. Indian mangroves consist of 46 species (4 of which are natural hybrids) belonging to 22 genera and 14 families, representing about 57% of the world’s mangrove species.\n\nThe following table shows the prevalence of mangroves in the states of India and the total area covered by them in square kilometres.\nThe Bhitarkanika mangroves form India’s second largest forest, located in the state of Odisha. Bhitarkanika is created by the two river deltas of Brahmani and Baitarani river and one of the important Ramsar Wetland in India. It is also the home of saltwater crocodiles and nesting olive ridley sea turtles.\n\nThe Godavari-Krishna mangroves lie in the delta of the Godavari and Krishna rivers in the state of Andhra Pradesh. Mangroves ecoregion is under protection for Calimere Wildlife and Pulicat Lake Bird Sanctuary.\n\nThe Pichavaram mangroves are situated at Pichavaram near Chidambaram in the state of Tamil Nadu. Pichavaram ranks amongst one of the most exquisite scenic spots in Tamil Nadu and has many species of aquatic birds.\n\nThe megacity Mumbai has mangroves on its coastline along the west coast of India. A total of 10 mangrove species were reported in this area, domiated by \"Avicennia marina\". These mangroves support a rich diversity of life forms, especially molluscs. The total mangrove area in Mumbai is 50 km. Mumbai's single largest mangrove belt is the western bank of Thane Creek. An extensive area of mangroves has been conserved by Soonabai Pirojsha Godrej Marine Ecology Centre, Vikhroli, Mumbai.\n\nThe Baratang Island mangroves are located within the Andaman and Nicobar Islands. The mangrove swamps of Baratang Island are situated between Middle and South Andaman Island.\n\nMangroves occur on Asia's south coast, throughout the Indian subcontinent, in all Southeast Asian countries, and on islands in the Indian Ocean, Persian gulf, Arabian Sea, Bay of Bengal, South China Sea, East China Sea and the Pacific.\n\nThe mangal is particularly prevalent in the deltas of large Asian rivers. The Sundarbans is the largest mangrove forest in the world, located in the Ganges River delta in Bangladesh and West Bengal, India.\n\nThe Pichavaram mangroves in Tamil Nadu is India's one of the largest mangrove forests. The Bhitarkanika Mangroves Forest of Odisha, by the Bay of Bengal, is India's second largest mangrove forest. Other major mangals occur on the Andaman and Nicobar Islands and the Gulf of Kutch in Gujarat.\n\nMangroves occur in certain muddy swampy islands of the Maldives.\n\nOn the Malayan Peninsula mangroves cover an estimated , while most of the remaining mangroves in Malaysia are on the island of Borneo.\n\nIn Vietnam, mangrove forests grow along the southern coast, including two forests: the Can Gio Mangrove Forest biosphere reserve and the U Minh mangrove forest in the sea and coastal region of Kiên Giang, Cà Mau and Bạc Liêu provinces.\n\nThe mangrove forests of Kompong Sammaki in Cambodia are of major ecological and cultural importance, as the human population relies heavily on the crabs and fish that live in the roots.\n\nThe three most important mangrove forests of Taiwan are: Tamsui River in Taipei, Jhonggang River in Miaoli and the Sihcao Wetlands in Tainan. According to research, four main types of mangrove exist in Taiwan. Some places have been developed as scenic areas, such as the log raft routes in Sihcao.\n\nThe most extensive mangrove forests of the Ryukyu Islands in East China Sea occur on Iriomote Island of the Yaeyama Islands, Okinawa, Japan. Seven types of mangroves are recognised on Iriomote Island.\n\nThe northern limit of mangrove forests in the Indo-Malaya ecozone is considered to be Tanegashima Island, Kyushu, Japan.\n\nIn the Indonesian Archipelago, mangroves occur around much of Papua province, Sumatra, Borneo, Sulawesi, Maluku and the surrounding islands. Further north, they are found along the coast of the Malay Peninsula. Indonesia has around 9.36 million hectares of mangrove forests, but 48% is categorized as 'moderately damaged' and 23% as 'badly damaged'.\n\nPakistani mangroves are located mainly along the delta of the Indus River (the Indus River Delta-Arabian Sea mangroves ecoregion). Major mangrove forests are found on the coastline of the provinces of Sindh and Balochistan.\n\nIn Karachi, land reclamation projects have led to the cutting down of mangrove forests for commercial and urban development. On 22 June 2013, Sindh Forest Department, Govt. of Sindh, Pakistan, with the help of 300 local coastal volunteer planters set the Guinness World Record by planting 847,250 mangrove saplings at Kharo Chan, Thatta, Sindh, Pakistan in a little over 12 hours. This is the highest number of saplings planted within a day under the Guinness World Record category of \"Maximum Number of Trees Planted in a Day\".\n\nSindh Forest Department, Government of Sindh Mangrove has played pioneer role for the conservation and protection of the mangroves in the Indus Delta since late 1950s when it was handed over the areas. A breakthrough success is the re-introduction of \"Rhizophora mucronata\" into the Indus Delta, which had become extinct there. More recently, a threatened mangrove shrub, \"Ceriops tagal\", has also been successfully re-introduced. A third species, \"Aegiceras corniculatum\", is under trials at the nursery stage.\n\nA gigantic initiative is under in the Sindh, Pakistan, to rehabilitate the degraded and blank mangrove mudflats. Since 2010 alone, around 55,000 Hectares of such area has been planted and rehabilitated. During this period, through concerted efforts and a rigorous conservation policy adopted by the Sindh Forest Department, Govt. of Sindh and the federal govt. a mangrove resource base of 150,000 plus Hectares has been created, with the support of local coastal communities. International organizations like IUCN and WWF are also playing critical role to support this initiative of the government. Other achievements include: (1) Declaring all the mangrove forests in the Indus Delta as Protected Forests in December 2010; Constitution of a Mangrove Conservation Committee at the provincial level which includes all stakeholders as members and overall awareness of the importance of mangroves and its ecosystem.\n\nMangrove forests are present in Iran between 25°11′N to 27°52′N, in the northern parts of the Persian Gulf and Sea of Oman. Pockets of the biome extend (from southwest to southeast) along the shores of the maritime provinces Bushehr, Hormozgan, and Sistan and Balouchestan.\n\nForests on and near the island of Qeshm in the Persian Gulf are dominated by the species \"Avicennia marina\", known locally as the \"hara\" or \"harra\" tree, and cover an area of approximately 20 km by 20 km. This area is protected as the UNESCO Hara Biosphere Reserve, where commercial use is restricted to fishing (mainly shrimp), tourist boat trips, and limited mangrove cutting for animal feed.\n\nOman, near Muscat, supports large areas of mangroves, in particular at Shinas, Qurm Park and Mahout Island. In Arabic, mangrove trees are known as \"qurm\", thus the mangrove area in Oman is known as Qurm Park. A small mangrove area is present in the Kingdom of Bahrain. Mangroves are also present extensively in neighbouring Yemen.\n\nMangrove is also widely seen in Tarut Island, east of Qatif in Saudi Arabia. In addition, large forest of mangrove surround the coast to the south of Qatif (Siahat Beach). Nonetheless, because of sea land re-claiming the mangrove is being cut down which makes lots of sea fish losses their natural habitats.\n\nThe mangrove forests that cover thousands of hectares of land along the UAE shoreline form an integral part of its coastal ecosystem. The Environment Agency – Abu Dhabi (EAD) is currently working on rehabilitation, conservation and protection of mangrove forests in seven key sites in Abu Dhabi including: Saadiyat Island, Jubail Island, Marawah Marine Biosphere Reserve (which also comprises famous Bu Tinah Island), Bu Syayeef Protected Area, Ras Gharab, the Eastern Corniche and Ras Ghanada.\n\nAustralia and Papua New Guinea both rank in the top five mangrove holding nations globally. More than five species of Rhizophoraceae grow in Australasia, with particularly high biodiversity on the island of New Guinea and northern Australia.\n\nAs of 2012 Australia has slightly below 1 million ha of mangrove and Papua New Guinea has just under approximately 500,000 ha +- 12% (CI 0.9, n = 7) of mangrove.\n\nNew Zealand also has mangrove forests extending to around 38°S (similar to Australia's latitudinal limit): the southernmost examples are at Raglan Harbour (37°48′S) on the west coast and Ohiwa Harbour (near Opotiki, 38°00′S) on the east coast.\n\"Avicennia marina australasica\" is the only mangrove in New Zealand.\n\nTwenty-five species of mangrove are found on various Pacific islands, with extensive mangals on some islands. Mangals on Guam, Palau, Kosrae and Yap have been badly affected by development.\n\nMangroves are not native to Hawaii, but the red mangrove, \"Rhizophora mangle\", and Oriental mangrove, \"Bruguiera sexangula\", have been introduced and are now naturalized. Both species are considered invasive species and classified as pests by the University of Hawaii Botany Department.\n\nAdequate data are only available for about half of the global area of mangroves. However, of those areas for which data has been collected, it appears that 35% of the mangroves have been destroyed. The United Nations Environment Programme and Hamilton (2013), estimate that shrimp farming causes approximately a quarter of the destruction of mangrove forests. Likewise, the 2010 update of the World Mangrove Atlas indicated that approximately one fifth of the world's mangrove ecosystems have been lost since 1980, although this rapid loss rate appears to have decreased since 2000 with global losses estimated at between 0.16% and 0.39% annually between 2000 and 2012. Despite global loss rates decreasing since 2000, Southeast Asia remains an area of concern with loss rates between 3.58% and 8.08% between 2000 and 2012.\n\nGrassroots efforts to save mangroves from development are becoming more popular as their benefits become more widely known. In the Bahamas, for example, active efforts to save mangroves are occurring on the islands of Bimini and Great Guana Cay. In Trinidad and Tobago as well, efforts are underway to protect a mangrove threatened by the construction of a steelmill and a port. In Thailand, community management has been effective in restoring damaged mangroves. Within northern Ecuador mangrove regrowth is reported in almost all estuaries and stems primarily from local actors responding to earlier periods of deforestation in the Esmeraldas region.\n\nMangroves have been reported to be able to help buffer against tsunami, cyclones, and other storms. One village in Tamil Nadu was protected from tsunami destruction—the villagers in Naluvedapathy planted 80,244 saplings to get into the Guinness Book of World Records. This created a kilometre-wide belt of trees of various varieties. When the tsunami struck, much of the land around the village was flooded, but the village itself suffered minimal damage.\n\nIn some areas, mangrove reforestation and mangrove restoration is also underway. Red mangroves are the most common choice for cultivation, used particularly in marine aquariums in a sump to reduce nitrates and other nutrients in the water. Mangroves also appear in home aquariums, and as ornamental plants, such as in Japan.\n\nIn Senegal, Haïdar El Ali has started the project, which (amongst others) focuses on reforesting several areas with mangroves.\n\nThe Manzanar Mangrove Initiative is an ongoing experiment in Arkiko, Eritrea, part of the Manzanar Project founded by Gordon H. Sato, establishing new mangrove plantations on the coastal mudflats. Initial plantings failed, but observation of the areas where mangroves did survive by themselves led to the conclusion that nutrients in water flow from inland were important to the health of the mangroves. Trials with the Eritrean Ministry of Fisheries followed, and a planting system was designed to provide the nitrogen, phosphorus, and iron missing from seawater.\n\nThe propagules are planted inside a reused galvanized steel can with the bottom knocked out; a small piece of iron and a pierced plastic bag with fertilizer containing nitrogen and phosphorus are buried with the propagule. , after six years of planting, 700,000 mangroves are growing; providing stock feed for sheep and habitat for oysters, crabs, other bivalves, and fish.\n\nIn terms of local and national studies of mangrove loss, the case of Belize's mangroves is illustrative in its contrast to the global picture. A recent, satellite-based study—funded by the World Wildlife Fund and conducted by the Water Center for the Humid Tropics of Latin America and the Caribbean (CATHALAC)—indicates Belize's mangrove cover declined by a mere 2% over a 30-year period. The study was born out of the need to verify the popular conception that mangrove clearing in Belize was rampant.\n\nInstead, the assessment showed, between 1980 and 2010, under of mangroves had been cleared, although clearing of mangroves near Belize's main coastal settlements (e.g. Belize City and San Pedro) was relatively high. The rate of loss of Belize's mangroves—at 0.07% per year between 1980 and 2010—was much lower than Belize's overall rate of forest clearing (0.6% per year in the same period). These findings can also be interpreted to indicate Belize's mangrove regulations (under the nation's) have largely been effective. Nevertheless, the need to protect Belize's mangroves is imperative, as a 2009 study by the World Resources Institute (WRI) indicates the ecosystems contribute US$174–249 million per year to Belize's national economy.\n\n\n\n"}
{"id": "8202165", "url": "https://en.wikipedia.org/wiki?curid=8202165", "title": "Marine chemist", "text": "Marine chemist\n\nA marine chemist is an environmental, occupational safety and health professional who is a trained professional who is responsible for ensuring that repair and construction of marine vessels can be made in safety whenever those repairs might result in fire, explosion, or exposure toxic vapors or chemicals. By virtue of his or her training, experience, and education, the Marine Chemist is uniquely qualified as a specialist in confined space safety and atmospheric sampling or monitoring. \n\nWhy do we need Marine Chemist? Lets take a moment to examine that question. Basic ship design... open decks and enclosed spaces for cargoes... has remained basically unchanged for decades. Structural materials and methods have changed, but in principle, the basic design concept has been the same for centuries. Today's cargoes, however, have shifted to a greater number of toxic substances. That has added the health concern of toxicity to the existing safety concerns of fire and explosion, not just during a voyage, but even when a vessel is in a shipyard for routine maintenance and repair.\n\nIn 1963, the National Fire Protection Association National Fire Protection Association assumed jurisdiction over the Marine Chemist program. The NFPA continues to oversee the profession which is based on the NFPA Standard 306: Standard for Control of Gas Hazards on Vessels.\n\n"}
{"id": "58255078", "url": "https://en.wikipedia.org/wiki?curid=58255078", "title": "National communication (Paris Agreement)", "text": "National communication (Paris Agreement)\n\nA \"National Communication\" is a type of report submitted by the countries that have ratified the Paris Agreement under the United Nations Framework Convention on Climate Change. Countries listed in Annex I of the agreement (mostly industrialized countries) are obliged to submit frequent National Communications. Non-Annex I countries do so less frequently. Some smaller non-Annex I countries have not submitted National Communications in the past 5-15 years, leaving their contributions to climate change mitigation unclear in spite of their ratification of the Paris Agreement. \n\nNational Communication reports are often several hundred pages long and represent the most standardized and comparable documents on the climate policies of different countries. The (Intended) Nationally Determined Contributions (NDCs) that form the basis of the Paris Agreement are shorter and less specific about how reductions in greenhouse gas emissions will be achieved. The National Communications are therefore the key documents on the climate policies of the world's countries.\n\nAlthough President Donald Trump has declared that the United States will withdraw from the Paris Agreement, this cannot be effectuated until the day after the 2020 presidential election in the United States. Until then, the United States will be obliged to continue reporting under the Paris Agreement. \n"}
{"id": "262606", "url": "https://en.wikipedia.org/wiki?curid=262606", "title": "Negative mass", "text": "Negative mass\n\nIn theoretical physics, negative mass is matter whose mass is of opposite sign to the mass of normal matter, e.g. −1 kg. Such matter would violate one or more energy conditions and show some strange properties, stemming from the ambiguity as to whether attraction should refer to force or the oppositely oriented acceleration for negative mass. It is used in certain speculative hypothesis, such as on the construction of traversable wormholes and the Alcubierre drive. Initially, the closest known real representative of such exotic matter is a region of negative pressure density produced by the Casimir effect.\n\nGeneral relativity describes gravity and the laws of motion for both positive and negative energy particles, hence negative mass, but does not include the other fundamental forces. On the other hand, the Standard Model describes elementary particles and the other fundamental forces, but it does not include gravity. A unified theory that explicitly includes gravity along with the other fundamental forces may be needed for a better understanding of the concept of negative mass.\n\nNegative mass is any region of space in which for some observers the mass density is measured to be negative. This could occur due to a region of space in which the stress component of the Einstein stress–energy tensor is larger in magnitude than the mass density. All of these are violations of one or another variant of the positive energy condition of Einstein's general theory of relativity; however, the positive energy condition is not a required condition for the mathematical consistency of the theory.\n\nEver since Newton first formulated his theory of gravity, there have been at least three conceptually distinct quantities called mass:\n\nEinstein’s equivalence principle postulates that inertial mass must equal passive gravitational mass. The law of conservation of momentum requires that active and passive gravitational mass be identical. All experimental evidence to date has found these are, indeed, always the same. In considering negative mass, it is important to consider which of these concepts of mass are negative. In most analyses of negative mass, it is assumed that the equivalence principle and conservation of momentum continue to apply, and therefore all three forms of mass are still the same.\n\nIn his 4th-prize essay for the 1951 Gravity Research Foundation competition, Joaquin Mazdak Luttinger considered the possibility of negative mass and how it would behave under gravitational and other forces.\n\nIn 1957, following Luttinger's idea, Hermann Bondi suggested in a paper in \"Reviews of Modern Physics\" that mass might be negative as well as positive. He pointed out that this does not entail a logical contradiction, as long as all three forms of mass are negative, but that the assumption of negative mass involves some counter-intuitive form of motion. For example, an object with negative inertial mass would be expected to accelerate in the opposite direction to that in which it was pushed (non-gravitationally).\n\nThere have been several other analyses of negative mass, such as the studies conducted by R. M. Price, however none addressed the question of what kind of energy and momentum would be necessary to describe non-singular negative mass. Indeed, the Schwarzschild solution for negative mass parameter has a naked singularity at a fixed spatial position. The question that immediately comes up is, would it not be possible to smooth out the singularity with some kind of negative mass density. The answer is yes, but not with energy and momentum that satisfies the dominant energy condition. This is because if the energy and momentum satisfies the dominant energy condition within a spacetime that is asymptotically flat, which would be the case of smoothing out the singular negative mass Schwarzschild solution, then it must satisfy the positive energy theorem, i.e. its ADM mass must be positive, which is of course not the case. However, it was noticed by Belletête and Paranjape that since the positive energy theorem does not apply to asymptotic de Sitter spacetime, it would actually be possible to smooth out, with energy–momentum that does satisfy the dominant energy condition, the singularity of the corresponding exact solution of negative mass Schwarzschild–de Sitter, which is the singular, exact solution of Einstein's equations with cosmological constant. In a subsequent article, Mbarek and Paranjape showed that it is in fact possible to obtain the required deformation through the introduction of the energy–momentum of a perfect fluid.\n\nAlthough no particles are known to have negative mass, physicists (primarily Hermann Bondi in 1957, William B. Bonnor in 1989, then Robert L. Forward) have been able to describe some of the anticipated properties such particles may have. Assuming that all three concepts of mass are equivalent the gravitational interactions between masses of arbitrary sign can be explored, based on the Einstein field equations and the equivalence principle:\n\n\nFor two positive masses, nothing changes and there is a gravitational pull on each other causing an attraction. Two negative masses would repel because of their negative inertial masses. For different signs however, there is a push that repels the positive mass from the negative mass, and a pull that attracts the negative mass towards the positive one at the same time.\n\nHence Bondi pointed out that two objects of equal and opposite mass would produce a constant acceleration of the system towards the positive-mass object, an effect called \"runaway motion\" by Bonnor who disregarded its physical existence, stating: \nSuch a couple of objects would accelerate without limit (except relativistic one); however, the total mass, momentum and energy of the system would remain 0.\n\nThis behavior is completely inconsistent with a common-sense approach and the expected behaviour of 'normal' matter; but is completely mathematically consistent and introduces no violation of conservation of momentum or energy. If the masses are equal in magnitude but opposite in sign, then the momentum of the system remains zero if they both travel together and accelerate together, no matter what their speed:\n\nAnd equivalently for the kinetic energy:\n\nHowever, this is perhaps not exactly valid if the energy in the gravitational field is taken into account.\n\nForward extended Bondi's analysis to additional cases, and showed that even if the two masses and are not the same, the conservation laws remain unbroken. This is true even when relativistic effects are considered, so long as inertial mass, not rest mass, is equal to gravitational mass.\n\nThis behaviour can produce bizarre results: for instance, a gas containing a mixture of positive and negative matter particles will have the positive matter portion increase in temperature without bound. However, the negative matter portion gains negative temperature at the same rate, again balancing out. Geoffrey A. Landis pointed out other implications of Forward's analysis, including noting that although negative mass particles would repel each other gravitationally, the electrostatic force would be attractive for like charges and repulsive for opposite charges.\n\nForward used the properties of negative-mass matter to create the concept of diametric drive, a design for spacecraft propulsion using negative mass that requires no energy input and no reaction mass to achieve arbitrarily high acceleration.\n\nForward also coined a term, \"nullification\", to describe what happens when ordinary matter and negative matter meet: they are expected to be able to cancel out or nullify each other's existence. An interaction between equal quantities of positive mass matter (hence of positive energy ) and negative mass matter (of negative energy ) would release no energy, but because the only configuration of such particles that has zero momentum (both particles moving with the same velocity in the same direction) does not produce a collision, all such interactions would leave a surplus of momentum, which is classically forbidden. So once this runaway phenomenon has been revealed, the scientific community considered negative mass could not exist in the universe.\n\nIn 1970, Jean-Marie Souriau demonstrated, through the complete Poincaré group of dynamic group theory, that reversing the energy of a particle (hence its mass, if the particle has one) is equal to reversing its arrow of time.\n\nThe universe according to general relativity is a Riemannian manifold associated to a metric tensor solution of Einstein’s field equations. In such a framework, the runaway motion prevents the existence of negative matter.\n\nSome bimetric theories of the universe propose that two parallel universes instead of one may exist with an opposite arrow of time, linked together by the Big Bang and interacting only through gravitation. The universe is then described as a manifold associated to two Riemannian metrics (one with positive mass matter and the other with negative mass matter). According to group theory, the matter of the conjugated metric would appear to the matter of the other metric as having opposite mass and arrow of time (though its proper time would remain positive). The coupled metrics have their own geodesics and are solutions of two coupled field equations:\n\nThe Newtonian approximation then provides the following interaction laws:\nThose laws are different to the laws described by Bondi and Bonnor, and solve the runaway paradox. The negative matter of the coupled metric, interacting with the matter of the other metric via gravity, could be an alternative candidate for the explanation of dark matter, dark energy, cosmic inflation and accelerating universe.\n\nIn electromagnetism one can derive the energy density of a field from Gauss's law, assuming the curl of the field is 0. Performing the same calculation using Gauss's law for gravity produces a negative energy density for a gravitational field.\n\nThe overwhelming consensus among physicists is that antimatter has positive mass and should be affected by gravity just like normal matter. Direct experiments on neutral antihydrogen have not been sensitive enough to detect any difference between the gravitational interaction of antimatter, compared to normal matter.\n\nBubble chamber experiments provide further evidence that antiparticles have the same inertial mass as their normal counterparts. In these experiments, the chamber is subjected to a constant magnetic field that causes charged particles to travel in helical paths, the radius and direction of which correspond to the ratio of electric charge to inertial mass. Particle–antiparticle pairs are seen to travel in helices with opposite directions but identical radii, implying that the ratios differ only in sign; but this does not indicate whether it is the charge or the inertial mass that is inverted. However, particle–antiparticle pairs are observed to electrically attract one another. This behavior implies that both have positive inertial mass and opposite charges; if the reverse were true, then the particle with positive inertial mass would be repelled from its antiparticle partner.\n\nPhysicist Peter Engels and a team of colleagues at Washington State University claimed to have observed negative mass behavior in rubidium atoms. On 10 April 2017 Engels team created negative \"effective\" mass by reducing the temperature of rubidium atoms to near absolute zero, generating a Bose–Einstein condensate. By using a laser-trap, the team were able to reverse the spin of some of the rubidium atoms in this state, and observed that once released from the trap, the atoms expanded and displayed properties of negative mass, in particular accelerating towards a pushing force instead of away from it.\nThis kind of negative effective mass is analogous to the well-known apparent negative effective mass of electrons in the upper part of the dispersion bands in solids. However, neither case is negative mass for the purposes of the stress–energy tensor.\n\nSome recent work with metamaterials suggests that some as-yet-undiscovered composite of superconductors, metamaterials and normal matter could exhibit signs of negative effective mass in much the same way as low temperature alloys melt at below the melting point of their components or some semiconductors have negative differential resistance.\nIn 1928, Paul Dirac's theory of elementary particles, now part of the Standard Model, already included negative solutions. The Standard Model is a generalization of quantum electrodynamics (QED) and negative mass is already built into the theory.\n\nMorris, Thorne and Yurtsever pointed out that the quantum mechanics of the Casimir effect can be used to produce a locally mass-negative region of space–time. In this article, and subsequent work by others, they showed that negative matter could be used to stabilize a wormhole. Cramer \"et al.\" argue that such wormholes might have been created in the early universe, stabilized by negative-mass loops of cosmic string. Stephen Hawking has proved that negative energy is a necessary condition for the creation of a closed timelike curve by manipulation of gravitational fields within a finite region of space; this proves, for example, that a finite Tipler cylinder cannot be used as a time machine.\n\nFor energy eigenstates of the Schrödinger equation, the wavefunction is wavelike wherever the particle's energy is greater than the local potential, and exponential-like (evanescent) wherever it is less. Naively, this would imply kinetic energy is negative in evanescent regions (to cancel the local potential). However, kinetic energy is an operator in quantum mechanics, and its expectation value is always positive, summing with the expectation value of the potential energy to yield the energy eigenvalue.\n\nFor wavefunctions of particles with zero rest mass (such as photons), this means that any evanescent portions of the wavefunction would be associated with a local negative mass–energy. However, the Schrödinger equation does not apply to massless particles; instead the Klein–Gordon equation is required.\n\nOne can achieve a negative mass independent of negative energy. According to mass–energy equivalence, mass is in proportion to energy and the coefficient of proportionality is . Actually, is still equivalent to although the coefficient is another constant such as . In this case, it is unnecessary to introduce a negative energy because the mass can be negative although the energy is positive. That is to say,\n\nUnder the circumstances,\n\nand so,\n\nWhen ,\n\nConsequently,\n\nwhere is invariant mass and invariant energy equals . The squared mass is still positive and the particle can be stable.\n\nFrom the above relation,\n\nThe negative momentum is applied to explain negative refraction, the inverse Doppler effect and the reverse Cherenkov effect observed in a negative index metamaterial. The radiation pressure in the metamaterial is also negative because the force is defined as . Negative pressure exists in dark energy too. Using these above equations, the energy–momentum relation should be\n\nSubstituting the Planck–Einstein relation and de Broglie's , we obtain the following dispersion relation \n\nwhen the wave consists of a stream of particles whose energy–momentum relation is formula_11 (wave–particle duality) and can be excited in a negative index metamaterial. The velocity of such a particle is equal to\n\nand range is from zero to infinity\n\nMoreover, the kinetic energy is also negative\n\nIn fact, negative kinetic energy exists in some models to describe dark energy (phantom energy) whose pressure is negative. In this way, the negative mass of exotic matter is now associated with negative momentum, negative pressure, negative kinetic energy and faster-than-light phenomena.\n\n"}
{"id": "32086658", "url": "https://en.wikipedia.org/wiki?curid=32086658", "title": "Nutrient cycle", "text": "Nutrient cycle\n\nA nutrient cycle (or ecological recycling) is the movement and exchange of organic and inorganic matter back into the production of matter. Energy flow is a unidirectional and noncyclic pathway, whereas the movement of mineral nutrients is cyclic. Mineral cycles include the carbon cycle, sulfur cycle, nitrogen cycle, water cycle, phosphorus cycle, oxygen cycle, among others that continually recycle along with other mineral nutrients into productive ecological nutrition.\n\nThe nutrient cycle is nature's recycling system. All forms of recycling have feedback loops that use energy in the process of putting material resources back into use. Recycling in ecology is regulated to a large extent during the process of decomposition. Ecosystems employ biodiversity in the food webs that recycle natural materials, such as mineral nutrients, which includes water. Recycling in natural systems is one of the many ecosystem services that sustain and contribute to the well-being of human societies.\n\nThere is much overlap between the terms for the biogeochemical cycle and nutrient cycle. Most textbooks integrate the two and seem to treat them as synonymous terms. However, the terms often appear independently. Nutrient cycle is more often used in direct reference to the idea of an intra-system cycle, where an ecosystem functions as a unit. From a practical point, it does not make sense to assess a terrestrial ecosystem by considering the full column of air above it as well as the great depths of Earth below it. While an ecosystem often has no clear boundary, as a working model it is practical to consider the functional community where the bulk of matter and energy transfer occurs. Nutrient cycling occurs in ecosystems that participate in the \"larger biogeochemical cycles of the earth through a system of inputs and outputs.\"\n\nEcosystems are capable of complete recycling. Complete recycling means that 100% of the waste material can be reconstituted indefinitely. This idea was captured by Howard T. Odum when he penned that \"it is thoroughly demonstrated by ecological systems and geological systems that all the chemical elements and many organic substances can be accumulated by living systems from background crustal or oceanic concentrations without limit as to concentration so long as there is available solar or another source of potential energy\" In 1979 Nicholas Georgescu-Roegen proposed the fourth law of entropy stating that complete recycling is impossible. Despite Georgescu-Roegen's extensive intellectual contributions to the science of ecological economics, the fourth law has been rejected in line with observations of ecological recycling. However, some authors state that complete recycling is impossible for technological waste.\n\nEcosystems execute closed loop recycling where demand for the nutrients that adds to the growth of biomass exceeds supply within that system. There are regional and spatial differences in the rates of growth and exchange of materials, where some ecosystems may be in nutrient debt (sinks) where others will have extra supply (sources). These differences relate to climate, topography, and geological history leaving behind different sources of parent material. In terms of a food web, a cycle or loop is defined as \"a directed sequence of one or more links starting from, and ending at, the same species.\" An example of this is the microbial food web in the ocean, where \"bacteria are exploited, and controlled, by protozoa, including heterotrophic microflagellates which are in turn exploited by ciliates. This grazing activity is accompanied by excretion of substances which are in turn used by the bacteria so that the system more or less operates in a closed circuit.\"\n\nAn example of ecological recycling occurs in the enzymatic digestion of cellulose. \"Cellulose, one of the most abundant organic compounds on Earth, is the major polysaccharide in plants where it is part of the cell walls. Cellulose-degrading enzymes participate in the natural, \"ecological recycling\" of plant material.\" Different ecosystems can vary in their recycling rates of litter, which creates a complex feedback on factors such as the competitive dominance of certain plant species. Different rates and patterns of ecological recycling leaves a legacy of environmental effects with implications for the future evolution of ecosystems.\n\nEcological recycling is common in organic farming, where nutrient management is \"fundamentally different\" compared to agri-business styles of soil management. Organic farms that employ ecosystem recycling to a greater extent support more species (increased levels of biodiversity) and have a different food web structure. Organic agricultural ecosystems rely on the services of biodiversity for the recycling of nutrients through soils instead of relying on the supplementation of synthetic fertilizers. The model for ecological recycling agriculture adheres to the following principals:\n\n\nThe persistent legacy of environmental feedback that is left behind by or as an extension of the ecological actions of organisms is known as niche construction or ecosystem engineering. Many species leave an effect even after their death, such as coral skeletons or the extensive habitat modifications to a wetland by a beaver, whose components are recycled and re-used by descendants and other species living under a different selective regime through the feedback and agency of these legacy effects. Ecosystem engineers can influence nutrient cycling efficiency rates through their actions.\n\nEarthworms, for example, passively and mechanically alter the nature of soil environments. Bodies of dead worms passively contribute mineral nutrients to the soil. The worms also mechanically modify the physical structure of the soil as they crawl about (bioturbation), digest on the molds of organic matter they pull from the soil litter. These activities transport nutrients into the mineral layers of soil. Worms discard wastes that create worm castings containing undigested materials where bacteria and other decomposers gain access to the nutrients. The earthworm is employed in this process and the production of the ecosystem depends on their capability to create feedback loops in the recycling process.\n\nShellfish are also ecosystem engineers because they: 1) Filter suspended particles from the water column; 2) Remove excess nutrients from coastal bays through denitrification; 3) Serve as natural coastal buffers, absorbing wave energy and reducing erosion from boat wakes, sea level rise and storms; 4) Provide nursery habitat for fish that are valuable to coastal economies.\n\nFungi contribute to nutrient cycling and nutritionally rearrange patches of ecosystem creating niches for other organisms. In that way fungi in growing dead wood allow xylophages to grow and develop and xylophages, in turn, affect dead wood, contributing to wood decomposition and nutrient cycling in the forest floor.\n\nNutrient cycling has a historical foothold in the writings of Charles Darwin in reference to the decomposition actions of earthworms. Darwin wrote about \"the continued Following the Greeks, the idea of a hydrological cycle (water is considered a nutrient) was validated and quantified by Halley in 1687.\n\nIn 1926 Vernadsky coined the term biogeochemistry as a sub-discipline of geochemistry. However, the term nutrient cycle pre-dates biogeochemistry in a pamphlet on silviculture in 1899: \"These demands by no means pass over the fact that at places where sufficient quantities of humus are available and where, in case of continuous decomposition of litter, a stable, nutrient humus is present, considerable quantities of nutrients are also available from the biogenic \"nutrient cycle\" for the standing timber. In 1898 there is a reference to the nitrogen cycle in relation to nitrogen fixing microorganisms. Other uses and variations on the terminology relating to the process of nutrient cycling appear throughout history:\n\n\nWater is also a nutrient. In this context, some authors also refer to precipitation recycling, which \"is the contribution of evaporation within a region to precipitation in that same region.\" These variations on the theme of nutrient cycling continue to be used and all refer to processes that are part of the global biogeochemical cycles. However, authors tend to refer to natural, organic, ecological, or bio-recycling in reference to the work of nature, such as it is used in organic farming or ecological agricultural systems.\n\nAn endless stream of technological waste accumulates in different spatial configurations across the planet and turns into a predator in our soils, our streams, and our oceans. This idea was similarly expressed in 1954 by ecologist Paul Sears: \"We do not know whether to cherish the forest as a source of essential raw materials and other benefits or to remove it for the space it occupies. We expect a river to serve as both vein and artery carrying away waste but bringing usable material in the same channel. Nature long ago discarded the nonsense of carrying poisonous wastes and nutrients in the same vessels.\" Ecologists use population ecology to model contaminants as competitors or predators. Rachel Carson was an ecological pioneer in this area as her book \"Silent Spring\" inspired research into biomagification and brought to the worlds attention the unseen pollutants moving into the food chains of the planet.\n\nIn contrast to the planets natural ecosystems, technology (or technoecosystems) is not reducing its impact on planetary resources. Only 7% of total plastic waste (adding up to millions upon millions of tons) is being recycled by industrial systems; the 93% that never makes it into the industrial recycling stream is presumably \"absorbed\" by natural recycling systems In contrast and over extensive lengths of time (billions of years) ecosystems have maintained a consistent balance with production roughly equaling respiratory consumption rates. The balanced recycling efficiency of nature means that production of decaying waste material has exceeded rates of recyclable consumption into food chains equal to the global stocks of fossilized fuels that escaped the chain of decomposition.\n\nMicroplastics and nanosilver materials flowing and cycling through ecosystems from pollution and discarded technology are among a growing list of emerging ecological concerns. For example, unique assemblages of marine microbes have been found to digest plastic accumulating in the worlds oceans. Discarded technology is absorbed into soils and creates a new class of soils called technosols. Human wastes in the Anthropocene are creating new systems of ecological recycling, novel ecosystems that have to contend with the mercury cycle and other synthetic materials that are streaming into the biodegradation chain. Microorganisms have a significant role in the removal of synthetic organic compounds from the environment empowered by recycling mechanisms that have complex biodegradation pathways. The effect of synthetic materials, such as nanoparticles and microplastics, on ecological recycling systems is listed as one of the major concerns for ecosystem in this century.\n\nRecycling in human industrial systems (or technoecosystems) differs from ecological recycling in scale, complexity, and organization. Industrial recycling systems do not focus on the employment of ecological food webs to recycle waste back into different kinds of marketable goods, but primarily employ people and technodiversity instead. Some researchers have questioned the premise behind these and other kinds of technological solutions under the banner of 'eco-efficiency' are limited in their capability, harmful to ecological processes, and dangerous in their hyped capabilities. Many technoecosystems are competitive and parasitic toward natural ecosystems. Food web or biologically based \"recycling includes metabolic recycling (nutrient recovery, storage, etc.) and ecosystem recycling (leaching and \"in situ\" organic matter mineralization, either in the water column, in the sediment surface, or within the sediment.\"\n\n\n"}
{"id": "22721", "url": "https://en.wikipedia.org/wiki?curid=22721", "title": "Obsidian", "text": "Obsidian\n\nObsidian is a naturally occurring volcanic glass formed as an extrusive igneous rock.\n\nObsidian is produced when felsic lava extruded from a volcano cools rapidly with minimal crystal growth. It is commonly found within the margins of rhyolitic lava flows known as obsidian flows, where the chemical composition (high silica content) induces a high degree of viscosity and polymerization of the lava. The inhibition of atomic diffusion through this highly viscous and polymerized lava explains the lack of crystal growth. Obsidian is hard and brittle and therefore fractures with very sharp edges. In the past it was used to manufacture cutting and piercing tools and it has been used experimentally as surgical scalpel blades.\n\nThe translation into English of \"Natural History\" written by Pliny the Elder of Rome shows a few sentences on the subject of a volcanic glass called obsidian (\"lapis obsidianus\"), discovered in Ethiopia by Obsidius, a Roman explorer.\n\nObsidian is the rock formed as a result of quickly cooled lava, which is the parent material. Extrusive formation of obsidian may occur when felsic lava cools rapidly at the edges of a felsic lava flow or volcanic dome or when lava cools during sudden contact with water or air. Intrusive formation of obsidian may occur when felsic lava cools along the edges of a dike.\n\nTektites were once thought by many to be obsidian produced by lunar volcanic eruptions, though few scientists now adhere to this hypothesis.\n\nObsidian is mineral-like, but not a true mineral because as a glass it is not crystalline; in addition, its composition is too variable to be classified as a mineral. It is sometimes classified as a mineraloid. Though obsidian is usually dark in color, similar to mafic rocks such as basalt, obsidian's composition is extremely felsic. Obsidian consists mainly of SiO (silicon dioxide), usually 70% or more. Crystalline rocks with obsidian's composition include granite and rhyolite. Because obsidian is metastable at the Earth's surface (over time the glass becomes fine-grained mineral crystals), no obsidian has been found that is older than Cretaceous age. This breakdown of obsidian is accelerated by the presence of water. Having a low water content when newly formed, typically less than 1% water by weight, obsidian becomes progressively hydrated when exposed to groundwater, forming perlite.\n\nPure obsidian is usually dark in appearance, though the color varies depending on the presence of impurities. Iron and other transition elements may give the obsidian a dark brown to black color. Very few samples are nearly colorless. In some stones, the inclusion of small, white, radially clustered crystals of cristobalite in the black glass produce a blotchy or snowflake pattern (\"snowflake obsidian\"). Obsidian may contain patterns of gas bubbles remaining from the lava flow, aligned along layers created as the molten rock was flowing before being cooled. These bubbles can produce interesting effects such as a golden sheen (\"sheen obsidian\"). An iridescent, rainbow-like sheen (\"rainbow obsidian\") is caused by inclusions of magnetite nanoparticles.\n\nObsidian can be found in locations which have experienced rhyolitic eruptions. It can be found in Argentina, Armenia, Azerbaijan, Australia, Canada, Chile, Georgia, Greece, El Salvador, Guatemala, Iceland, Italy, Japan, Kenya, Mexico, New Zealand, Papua New Guinea, Peru, Scotland, Turkey and the United States. Obsidian flows which may be hiked on are found within the calderas of Newberry Volcano and Medicine Lake Volcano in the Cascade Range of western North America, and at Inyo Craters east of the Sierra Nevada in California. Yellowstone National Park has a mountainside containing obsidian located between Mammoth Hot Springs and the Norris Geyser Basin, and deposits can be found in many other western U.S. states including Arizona, Colorado, New Mexico, Texas, Utah, Washington, Oregon and Idaho. Obsidian can also be found in the eastern U.S. states of Virginia, as well as Pennsylvania and North Carolina.\n\nThere are only four major deposit areas in the central Mediterranean: Lipari, Pantelleria, Palmarola and Monte Arci.\n\nAncient sources in the Aegean were Milos and Gyali.\n\nAcıgöl town and the Göllü Dağ volcano were the most important sources in central Anatolia, one of the more important source areas in the prehistoric Near East.\n\nThe first known archaeological evidence of usage was in Kariandusi and other sites of the Acheulian age (beginning 1.5 million years BP) dated 700,000 BC, although the number of objects found at these sites were very low relative to the Neolithic. Use of obsidian in pottery of the Neolithic in the area around Lipari was found to be significantly less at a distance representing two weeks journeying. Anatolian sources of obsidian are known to have been the material used in the Levant and modern-day Iraqi Kurdistan from a time beginning sometime about 12,500 BC. The first attested civilized use is dated to the late fifth millennium BC, known from excavations at Tell Brak. Obsidian was valued in Stone Age cultures because, like flint, it could be fractured to produce sharp blades or arrowheads. Like all glass and some other types of naturally occurring rocks, obsidian breaks with a characteristic conchoidal fracture. It was also polished to create early mirrors. Modern archaeologists have developed a relative dating system, obsidian hydration dating, to calculate the age of obsidian artifacts.\n\nIn the Ubaid in the 5th millennium BC, blades were manufactured from obsidian extracted from outcrops located in modern-day Turkey. Ancient Egyptians used obsidian imported from the eastern Mediterranean and southern Red Sea regions. Obsidian was also used in ritual circumcisions because of its deftness and sharpness. In the eastern Mediterranean area the material was used to make tools, mirrors and decorative objects.\n\nObsidian has also been found in Gilat, a site in the western Negev in Israel. Eight obsidian artifacts dating to the Chalcolithic Age found at this site were traced to obsidian sources in Anatolia. Neutron activation analysis (NAA) on the obsidian found at this site helped to reveal trade routes and exchange networks previously unknown.\n\nLithic analysis can be instrumental in understanding prehispanic groups in Mesoamerica. A careful analysis of obsidian in a culture or place can be of considerable use to reconstruct commerce, production, distribution and thereby understand economic, social and political aspects of a civilization. This is the case in Yaxchilán, a Maya city where even warfare implications have been studied linked with obsidian use and its debris. Another example is the archeological recovery at coastal Chumash sites in California indicating considerable trade with the distant site of Casa Diablo, California in the Sierra Nevada Mountains.\nPre-Columbian Mesoamericans' use of obsidian was extensive and sophisticated; including carved and worked obsidian for tools and decorative objects. Mesoamericans also made a type of sword with obsidian blades mounted in a wooden body. Called a \"macuahuitl\", the weapon was capable of inflicting terrible injuries, combining the sharp cutting edge of an obsidian blade with the ragged cut of a serrated weapon. The pole arm version of this weapon was called \"tepoztopilli\".\nNative American people traded obsidian throughout the Americas. Each volcano and in some cases each volcanic eruption produces a distinguishable type of obsidian, making it possible for archaeologists to trace the origins of a particular artifact. Similar tracing techniques have allowed obsidian to be identified in Greece also as coming from Milos, Nisyros or Gyali, islands in the Aegean Sea. Obsidian cores and blades were traded great distances inland from the coast.\n\nIn Chile obsidian tools from Chaitén Volcano have been found as far away as in Chan-Chan north of the volcano and also in sites 400 km south of it.\n\nObsidian was also used on Rapa Nui (Easter Island) for edged tools such as \"Mataia\" and the pupils of the eyes of their Moai (statues), which were encircled by rings of bird bone. Obsidian was used to inscribe the Rongorongo glyphs.\n\nObsidian can be used to make extremely sharp knives, and obsidian blades are a type of glass knife made using naturally occurring obsidian instead of manufactured glass. Obsidian is used by some surgeons for scalpel blades, although this is not approved by the US Food and Drug Administration (FDA) for use on humans. Well-crafted obsidian blades, as with any glass knife, can have a cutting edge many times sharper than high-quality steel surgical scalpels, the cutting edge of the blade being only about 3 nanometers thick. Even the sharpest metal knife has a jagged, irregular blade when viewed under a strong enough microscope; when examined even under an electron microscope an obsidian blade is still smooth and even. One study found that obsidian incisions produced fewer inflammatory cells and less granulation tissue at seven days, in a group of rats, although no differences were found after 21 days. Don Crabtree produced obsidian blades for surgery and other purposes, and has written articles on the subject. Obsidian scalpels may currently be purchased for surgical use on research animals.\nObsidian is also used for ornamental purposes and as a gemstone. It presents a different appearance depending on how it is cut: in one direction it is jet black, while in another it is glistening gray. \"Apache tears\" are small rounded obsidian nuggets often embedded within a grayish-white perlite matrix.\n\nPlinths for audio turntables have been made of obsidian since the 1970s; e.g. the grayish-black SH-10B3 plinth by Technics.\n\n\n"}
{"id": "18332824", "url": "https://en.wikipedia.org/wiki?curid=18332824", "title": "Political objections to the Bahá'í Faith", "text": "Political objections to the Bahá'í Faith\n\nOpponents of the Bahá'í Faith have accused the faith's followers of various political crimes, such as dual loyalty and being involved with foreign or hostile powers. These accusations (together with others with a more theological bent) are used to justify persecution of this religious minority.\n\nIn support of government and clergy-led persecution of the Bahá'ís, Iranian government officials and others have claimed that Bahá'ís have had ties to foreign powers, and were agents of Russian imperialism, British colonialism, American expansionism and Zionism, as well as being responsible for the policies of the previous Shah of Iran.\n\nThese accusations against the Bahá'í have been disputed, and described as based on misconceived, or exaggerated interpretations of historical fact. Bahá'u'lláh, the founder of the Bahá'í Faith, taught that Bahá'ís are to be loyal to one's government, not be involved in politics, and to obey the laws of the country they reside in.\n\nThe Bahá'í Faith and its predecessor, the Bábí religion, originated in nineteenth century Persia, arousing considerable opposition, initially on purely theological and doctrinal grounds; it was seen as threat to established power and authority.\n\nIn 1852, two years after the execution of the Báb, a fringe element in the Bábí community made an unskilled plot against the Shah, Nasser-al-Din Shah, in retaliation for the Báb's execution. While Bahá'u'lláh condemned the plan strongly, and renounced the movement's early anti-Qajar stance, on August 15, 1852 the radicalized Bábís attempted the assassination of the Shah and failed. Notwithstanding the assassins' claim that they were working alone, and that Bahá'u'lláh had not participated in the assassination attempt, the entire Bábí community was blamed, and a slaughter of several thousand Bábís followed. From that time Nasser al-Din Shah Qajar always remained suspicious of the Bábís and Baha'is and viewed them as agitators similar to the European anarchists.\n\nThe Shah of Iran and the Sultan of the Ottoman Empire, ‘Abdu’l-‘Aziz, successively exiled Bahá'u'lláh from Iran to Baghdad, Constantinople, and eventually to the fortress of Acre for lifetime incarceration.\n\nBy the end of the 19th century, there was growing dissension within the Qajar state, and in an effort to draw public attention away from the government and instead toward the evils of the 'devious sect', charges of subversion and conspiracy against the Bábís and Bahá'ís increased.\n\nIn the early 20th century, the Bahá'ís were seen as being non-conformist in a society looking for unanimity and fearful of losing its perceived unique Shi'a culture due to threats from outside its boundaries. During the 1940s the clerical and governmental groups started stating that the religion was entirely manufactured by colonialists and imperialists to destroy the \"unity of the Muslim nation\" and that those who did not share the beliefs of the Muslim nation were agents of foreign powers.\n\nBy the 1960s critics of the Bahá'í Faith increasingly used charges of spying, and of connections to foreign powers rather than simply labelling Bahá'ís as heretics. These new charges helped define a new 'other' and reaffirmed a threatened Shi'i self. This new attitude towards the Bahá'ís was now not confined to the clerics, but was also rampant among the secular Iranian middle-class. In the 1970s accusations of Bahá'ís being numerous in the Shah's regime surfaced, as well as there being a perception that Bahá'ís were generally better off than the rest of the population.\n\nChehabi notes that while the teachings of the Bahá'í Faith mitigate against a preferential attachment of Bahá'ís to Iran, Iran is seen by Bahá'ís as the \"Cradle of the Cause\" to which it owes a degree of affection by Bahá'ís worldwide.\n\nSince the founding of Israel, there have also been many accusations of Bahá'ís being associated with Zionism, largely on the grounds that the Bahá'í World Centre is located in current-day Israel, although this is an historic accident, rather than the result of deliberate action by the Baha'is. The Bahá'í World Centre has its historical origins in the area that was at the time part of Ottoman Syria. This dates back to the 1850s and 1860s and the repeated forced exiles of Baha'i leaders.\n\nAfter the overthrow of the Shah during the Iranian revolution, the Islamic regime targeted the Bahá'ís in Iran, since they held a deep hostility toward them as they saw them as infidels. As nationalism grew in Iran, Bahá'ís were viewed as unpatriotic and linked to foreign elements. During this time the Bahá'ís were accused of being anti-Islamic, agents of Zionism, friends of the Shah's regime, and being engaged with the US and British governments. The National Spiritual Assembly of the Bahá'ís of Iran, both privately and publicly, addressed the charges against them point by point, but received no response to their rebuttal.\n\nIn January 1980 with the election of President Bani Sadr and the continuing anti-Bahá'í sentiment, the Bahá'í Faith was officially described by the government as a political movement against the Iranian revolution and Islam. Before the revolution, Bani Sadr had connected the universal message of the Bahá'í Faith with Western colonialism. In February 1980, the Iranian ambassador to the United Nations stated that Bahá'ís were SAVAK agents and repeated the cleric's charges; only later when he broke with the regime in 1982 did he recant his previous statements.\n\nBy 1981, however, revolutionary courts no longer couched the execution of Bahá'ís with political terms, and they instead cited only religious reasons. Also documents were given out to Bahá'ís that if they would publicly embrace Islam, that their jobs, pensions and property would be reinstated. These documents were shown to the United Nations as evidence that the Iranian government was using the political accusations as a front to the real religious reason for the persecution of the Bahá'ís.\n\nIn 1983, Iran's prosecutor general once again stated that the Bahá'ís were not being persecuted because of their religious belief, but that instead they were spies, and that they were funnelling money outside the country. The National Spiritual Assembly of the Bahá'ís of Iran, once again, addressed the issues raised by the prosecutor point by point; the letter was sent to various government agencies. The letter acknowledged that funds were being sent abroad as Bahá'í contributions to the shrines and holy places, but denied all other points, and asked for proof of the charges. No response was obtained from the government to this letter. The clerics continued to persecute the Bahá'ís and charged the Bahá'ís with \"crimes against God\" and Zionism.\n\nIn 1983 to a report to the Human Rights Commission of the United Nations the official view of the Islamic Republic was published in a twenty-page document; the document stated that British encouraged the Bahá'í Faith in Iran, and that it was not a religion, but a political entity created by colonial powers, that there was a link between the Bahá'í Faith and Zionism and SAVAK. The United Nations Human Rights Commission Sub-Commission Expert Mr. Eide stated that the publication provided by the Iranian government \"recalled the publications disseminated in Europe in the 1920s and 1930s, which had contributed to severe prejudice costing the lives of hundreds of thousands of peoples. The Sub-Commission should be on guard against any recurrence of such campaigns\".\n\nThe Iranian government's statement was not accepted by the United Nations as the United Nations had received no evidence from the Iranian government regarding its claims. The representative from Germany stated that \"the documents concerning the Bahá'ís showed that the latter were persecuted, not for criminal offences, but simply for their religious beliefs\". The Iranian delegate dismissed the text of the Commission's resolution, and persecution of the Bahá'ís continued.\n\nIn 1991, the Iranian government again gave a statement to the United Nations stating that since the administrative centre of the Bahá'í Faith is located in Israel, it is directly controlled by Zionist forces, although the Bahá'í World Centre has its historical origins in the area that was once Ottoman Syria. In the late 1990s during Muhammad Khatami's presidency, the name-calling and outrageous accusations did not end, and with the election of President Mahmoud Ahmadinejad in 2005, the frequency and intensity of these accusations has increased.\n\nDuring the 19th century, Britain had firm control over India; at the same time Russia had been expanding south and east into the Caucasus and Central Asia toward India, and a rivalry started between Britain and Russia over territorial and political control in Central Asia. The middle zone of land that was located between India and Russian holdings, included Persia, and was a highly coveted region, where both Russia and Britain worked to gain influence.\n\nThe support of the United Kingdom during the Constitutional Revolution, the Anglo-Russian convention which solidified boundaries that identified control between Britain and Russia in Persia, Afghanistan, and Tibet, the occupation of Iranian territory during the First World War by the UK, Russia and the Ottoman Empire, as well as the coup d'état of 1921 which was backed by the British, all encouraged the development of antagonism to these foreign powers. Muslim clerics and other anti-Bahá'í groups connected the Bahá'í Faith, and its predecessor the Bábí movement, to the external governments of Britain and Russia to project the mistrust of these two latter groups onto the Bahá'ís.\n\nIn God Passes By, Shoghi Effendi alludes to the protection the Russian ambassador gave Bahá'u'lláh on different occasions, first after the attempted assassination of Naser al-Din Shah Qajar and again after the decision to exile Bahá’u’lláh from Iran, expressing his \"desire to take Bahá’u’lláh under the protection of his government, and offered to extend every facility for His removal to Russia.\" In his Súriy-i-Haykal, Bahá’u’lláh included the Lawh-i-Malik-i-Rús, praising Czar Alexander II of Russia in these terms: \"when this Wronged One was sore-afflicted in prison, the minister of the highly esteemed government (of Russia)—may God, glorified and exalted be He, assist him!—exerted his utmost endeavor to compass My deliverance. Several times permission for My release was granted. Some of the ‘ulamás of the city, however, would prevent it. Finally, My freedom was gained through the solicitude and the endeavor of His Excellency the Minister. …His Imperial Majesty, the Most Great Emperor—may God, exalted and glorified be He, assist him!—extended to Me for the sake of God his protection—a protection which has excited the envy and enmity of the foolish ones of the earth.\" When Bahá’u’lláh and his family traveled from Iran to Baghdad subsequent to his exile in 1853, they were accompanied by a representative of the Russian legation.\n\nOpponents of the faith base much of their amplification and exaggeration of these \"ties\" on a document, allegedly a \"memoir\" of Dolgorukov (also known as Dolgoruki), who was the Russian ambassador to Persia from 1846 to 1854. The memoir states that Dolgorukov created the Bábí and Bahá'í religions so as to weaken Iran and Shi'a Islam. The document was first published in 1943 in Persian in Mashhad, and shortly thereafter published again in Tehran with some of the most glaring errors corrected. The book still, however, contains so many historical errors that it is inconceivable that it is genuine.\n\nThe memoir states that Dolgorukov used to attend gatherings of Hakím Ahmad Gílání, where he would meet Bahá'u'lláh. However, Gílání died in 1835, three years before Dolgorukov's arrival in the Persia. There are numerous other errors relating to the dates and times of events that the memoir describes; the memoir describes events after the death of personages, or when the people involved were young children, or when they were in different parts of the world.\n\nDolgorukov actually only became aware of the Bábí movement in 1847, three years after it started, and his dispatches show that he was initially afraid of the movement spreading into the Caucasus, and asked that the Báb be moved away from the Russian border. In 1852, after a failed assassination attempt against the Shah for which the entire Bábí community was blamed, many Bábís, including Bahá'u'lláh, who had no role in the attempt and later severely condemned it, were arrested in a sweep. When Bahá'u'lláh was jailed by the Shah, his family went to Mírzá Majid Ahi who was married to a sister of Bahá'u'lláh, and was working as the secretary to the Russian Legation in Tehran. Bahá'u'lláh's family asked Mírzá Majid to go to Dolgorukov and ask him to intercede on behalf of Bahá'u'lláh, and Dolgorukov agreed.\n\nThe memoirs, however, extend this assistance to all facets of Bahá'u'lláh's life. In one edition of the memoir, Dolgorukov is said to have provided money for Bahá'u'lláh to build a house in Acre, but Dolgorukov died in 1867, before Bahá'u'lláh arrived in Acre. Thus newer editions of the memoir state that Dolgorukov sent money for a house to be built in Edirne. As Dolgorukov left the Russian diplomatic service in 1854 and died in 1867, he was unable to interact with Bahá'u'lláh in the manner in which the memoir states.\n\nCommunist Soviet sources produced polemical pamphlets in 1930, an encyclopedic article in 1933, and most seriously in 1938 \"monstrous accusations\" accusing Bahá'ís of being 'closely linked with the leaders of Trotskyite-Bukharinist and Dashnak-Musavat bands'. Following this numerous arrests and oppression of the religion, Bahá'ís across the Soviet Union were being sent to prisons and camps or sent abroad. Bahá'í communities in 38 cities across Soviet territories ceased to exist.\n\nThere have also been claims that the Bábí movement was started by the British, and that the Bahá'í Faith has ties to British imperialism; the connection to the British, however, has also been supported by false evidence. Firaydun Adamiyyat, in a biography on Nasser-al-Din Shah's first Prime Minister Amir Kabir, stated that Mulla Husayn, the Báb's first disciple, was really a British agent who was recruited by Arthur Conolly, a British intelligence officer, explorer and writer. Adamiyyat states that the evidence of such an accusation appears in Conolly's book \"Journey to the North of India Overland from England through Russia, Persia, and Affghaunistaun\", but no mention of Mulla Husayn or the Báb appears in the book. In later editions of Adamiyyat's biography on Amir Kabir, the fabrication has been removed.\n\nAccusations of ties to the British also arise from the knighting in 1920 of `Abdu'l-Bahá, then head of the religion, by the British Mandate of Palestine. According to Harry Charles Luke, an official in the British Colonial Office who served as assistant Governor of Jerusalem, `Abdu'l-Bahá \"on the 4th December, 1919, was created by King George V a K.B.E. for valuable services rendered to the British Government in the early days of the Occupation.\" According to a recent PhD, however, `Abdu'l-Bahá, received this award in recognition of his \"humanitarian work in Palestine\" during the war, especially his distribution of grain from his personal supply, which averted a famine in Northern Palestine. He was ceremonially knighted on April 27, 1920, an event which was prominently reported in the \"Star of the West\" as \"a most wonderful celebration.\"\n\nDuring this period, `Abdu'l-Bahá communicated with a number of different actors who were civilian, parliamentarians of the Young Turks, opposed to the reign of Sultan Abdul Hamid II, including Namık Kemal, Ziya Pasha and Midhat Pasha, in an attempt to disseminate Bahá'í thought into their political ideology. He emphasized Bahá'ís \"seek freedom and love liberty, hope for equality, are well-wishers of humanity and ready to sacrifice their lives to unite humanity\" but on a more broad approach than the Young Turks. Favorable relations included Abdullah Cevdet, one of the founders of the Committee of Union and Progress, who would go on trial for defense of Bahá'ís in a periodical he founded. Abdullah Cevdet considered the Bahá'í Faith an intermediary step between Islam and the ultimate abandonment of religious belief.\n\n‛Abdu'l-Bahá also had contact with military leaders as well, including such individuals as Bursalı Mehmet Tahir Bey and Hasan Bedreddin. The latter, who was involved in the overthrow of Sultan Abdülaziz, is commonly known as Bedri Paşa or Bedri Pasha and is referred to in Persian Bahá'í sources as Bedri Bey (Badri Beg). He was a Bahá'í who translated ‛Abdu’l-Baha's works into French.\n\n`Abdu'l-Bahá also met Muhammad Abduh, one of the key figures of Islamic Modernism and the Salafi movement, in Beirut, at a time when the two men were both opposed to the Ottoman \"ulama\" and shared similar goals of religious reform. Rashid Rida asserts that during his visits to Beirut, `Abdu'l-Bahá would attend Abduh's study sessions. Regarding the meetings of `Abdu'l-Bahá and Muhammad 'Abduh, Shoghi Effendi asserts that \"His several interviews with the well-known Shaykh Muhammad ‘Abdu served to enhance immensely the growing prestige of the community and spread abroad the fame of its most distinguished member.\"\n\nDue to the concerns of Hamid II views of `Abdu'l-Bahá's activities, a Commission of Inquiry interviewed him in 1905, with the result that he was almost exiled to Fezzan. In response, `Abdu'l-Bahá wrote the sultan a letter protesting that his followers refrain from involvement in partisan politics and that his \"tariqa\" had guided many Americans to Islam. Subsequent to the Young Turk Revolution `Abdu'l-Bahá was released from his imprisonment and allowed to travel away from Palestine. He freely expressed his disapproval of Sultan Abdul Hamid II and his policies. `Abdu'l-Bahá would continue to praise the Committee of Union and Progress, and during his tour of North America in 1912, the Ottoman embassy in Washington, D.C. held a dinner in his honor.\n\nBahá'ís have also been accused of ties to Zionism, a movement that calls for the self-determination of the Jewish people and a sovereign, Jewish national homeland. This claim is typically advanced by noting that the most holy shrines of the Bahá'ís are located in current-day Israel. However, Bahá'u'lláh was banished from Persia by Nasser-al-Din Shah, at which time Bahá'u'lláh went to Baghdad in the Ottoman Empire. Later he was later exiled by the Sultan of the Ottoman Empire, at the behest of the Persian Shah, to territories further away from Iran and finally to Acre in Syria, which only a century later was incorporated into the state of Israel.\n\nBahá'u'lláh died in 1892 near Acre, and the burial place is in Bahji. Following his death, Bahá'u'lláh's son `Abdu'l-Bahá took over the leadership of the religion until his death in 1921, and he is buried in Haifa, which was then in Palestine. Another important figure for Bahá'ís who is buried in current-day Israel is the Báb, whose remains were secretly transferred to Palestine and buried in Haifa in 1909. Israel was not formed until 1948, almost 60 years after Bahá'u'lláh's death, 40 years after the Báb's remains were brought to the region, and 27 years after `Abdu'l-Bahá's death.\n\nOn February 23, 1914, at the eve of World War I, Baron Edmond James de Rothschild, a member of the Rothschild banking family who was a leading advocate and financier of the Zionist movement, attended a general meeting at the home of `Abdu'l-Bahá during one of his early trips to Palestine. `Abdu'l-Bahá is recorded saying in part \"Unless the souls are believers in God and assured in the verses of God, wealth causes the hearts to be hardened and without light.\"\n\nSubsequent to the British occupation of Palestine following World War I, `Abdu'l-Bahá remarked,\nBahá'ís have from time to time negotiated with the government of Israel over such matters as the acquisition of properties that currently compose the Bahá'í World Centre buildings. For example, a cablegram sent by Shoghi Effendi on November 12, 1952 announced the \"acquisition of vitally-needed property\" of the Mansion of Bahjí and the area around it from \"the Development Authority of the State of Israel...The exchange of said property, including land and houses, was made possible by the precipitate flight of the former Arab owners.\"\n\nSimilarly, the mansion of Mazra'ih was transferred by the nascent Israeli government from a Muslim waqf to the Bahá'í administration in 1951.\n\n\"Masra'ih is a Moslem religious endowment, and it is consequently impossible, under existing laws in this country, for it to be sold. However, as the friends are aware, the Ministry of Religions, due to the direct intervention of the Minister himself, Rabbi Maimon, consented, in the face of considerable opposition, to deliver Masra'ih to the Baha'is as a Holy Place to be visited by Baha'i pilgrims. This means that we rent it from the Department of Moslem and Druze affairs in the Ministry of Religions. The head of this Department is also a Rabbi, Dr. Hirschberg. Recently he, his wife and party, visited all the Baha'i properties in Haifa and 'Akka, following upon a very pleasant tea party in the Western Pilgrim House with the members of the International Baha'i Council.\" (\"Bahá'í News\", no. 244, June 1951, p. 4) \n\nThe mansion was ultimately purchased by the Bahá'ís in 1973.\n\nSince the Iranian revolution there have been accusations that the Bahá'ís support Israel because they send fund contributions to the Bahá'í World Centre which is located in northern Israel. The donations are used in the Bahá'í World Centre for upkeep of the Bahá'í properties, as well as the administration of the worldwide Bahá'í community. The National Spiritual Assembly of the Bahá'ís of Iran in a 1983 letter to the Iranian government stated that while Muslims were praised for sending money out of the country to Iraq and Jerusalem for the upkeep of their religious shrines, when Bahá'ís sent money for the upkeep of their own shrines it was considered an unforgivable sin.\n\nAnother criticism claims that the Bahá'ís, during the time of the Pahlavi dynasty, collaborated with the SAVAK, the Iranian secret police, and held positions of power in the government. Even before the Iranian revolution, the Bahá'ís, viewed as the \"other\" in Iranian society, were held responsible by the rest of the Iranians for the abusive suppression by SAVAK and the Shah's unpopular policies. After the revolution, the assertion that the Bahá'ís were agents of the Shah perhaps partly originates because Bahá'ís did not help the revolutionary groups, since one of the tenets of the Bahá'í Faith is to obey the government of one's country.\n\nThe Bahá'í International Community has, however, stated that the Bahá'í community in Iran was the victim of the Shah's regime, and that SAVAK was one of the main ways of persecuting the Bahá'ís. For example, Reza Shah’s government ordered the closure of Bahá'í schools, such as Tehran’s Tarbiyat school for boys and girls, in 1934. Also during the month of Ramadan in 1955, when the Shah’s government needed to distract the general population from its decision to join the Baghdad Pact under pressure from the British and American governments, it sought the support of the clerics. Ayatollah Seyyed Hossein Borujerdi, acting as the Marja Taqlid, a Grand Ayatollah with the authority to make legal decisions within the confines of Islamic law, pushed the Shah's government to support the persecution of the Bahá'í community.\n\nThe 1955 attacks were particularly destructive and widespread due to an orchestrated campaign by the government and clergy who utilized the national Iranian radio station and its official newspapers to spread hatred which led to widespread mob violence against Bahá'ís. The Shah's military also occupied the Bahá'í centre in Tehran, which was destroyed in the violence. Mottahedeh states that under the Pahlavi dynasty, the Bahá'ís were actually more a \"political pawn\" than a collaborator, and that Reza Shah's government toleration of Bahá'ís in the early 20th-century was more a sign of secular rule and an attempt to weaken clerical influence than a signal of favour for the Bahá’ís. \nThere is also evidence that SAVAK collaborated with Islamic groups throughout the 1960s and 1970s in harassing Bahá'ís. SAVAK also had links to Hojjatieh, a radical anti-Bahá'í group. Rahnema and Nomani state that the Shah gave Hojjatieh free rein for their activities toward the Bahá'ís. Keddie states that the accusations of Bahá'ís being part of SAVAK were mainly false pretexts for persecution.\n\nWith regards to the accusation that Bahá'ís held many prominent positions in the government of Mohammad Reza Pahlavi, there is no empirical study that endeavours to determine the truth of such an accusation. There were a number of individuals who were part of the government and who had Bahá'í backgrounds, but were not Bahá'ís themselves. One problem that arises is the definition of a Bahá'í: a Bahá'í is a member of a voluntary association that admits people only when they meet certain religious qualifications, and one can choose to become, remain or cease to be a Bahá'í. However, Muslims who do not recognize the possibility of apostasy (leaving one's religion) may not understand that individuals are free to reject their previous, in this case Bahá'í, beliefs .\n\nBahá'ís have used the term Bahá'ízada to refer to people of Bahá'í background who are not Bahá'ís themselves or part of the Bahá'í community; there is no Muslim equivalent of the term. Of the Bahá'ís who held positions near the Shah, the best known is the Shah's personal physician, Abdol Karim Ayadi. While Asadullah Sanii, another Bahá'í, was appointed Minister of Defence, the Bahá'í community of Iran revoked his administrative rights — as he had accepted a political position and Bahá'ís are prohibited from involvement in partisan politics — the public, however, still continued to associate him with his previous religion. Parviz Sabeti, a SAVAK official, was raised in a Bahá'í family, but had left the religion and was not a member of the community by the time he started working with the agency.\n\nOther people who were associated with the Bahá'í Faith either had Bahá'í backgrounds or were not connected with the religion at all. For example, it was often rumoured that the Prime Minister Amir-Abbas Hoveida was a Bahá'í. While Hoveida's father had been a Bahá'í, he had left the religion and Hoveida himself was not religious. Other people rumoured to be Bahá'ís included Mahnaz Afkhami, who was the Minister for Women's Affairs and the daughter of a Bahá'í mother, and Farrokhroo Parsa, a cabinet member who was not connected to the religion at all. Chehabi notes that the allegations that half of the Shah's cabinet were Bahá'ís are fanciful and, given the persecution the Bahá'ís have suffered, irresponsible exaggerations.\n\nIranian critics of the Bahá'í Faith have accused the religion of having ties to Freemasonry. As Freemasonry was a secretive society originating from the West, many in Iran connected the movement with the introduction of foreign ideas into the country in order to undermine Iranian values. Claims were made that many of the earliest Freemason lodges, such as Malkom Khan's \"faramush-khanih\", which were founded in 1858, were linked to European lodges. However, Freemasonry was brought to Iran by Iranians who had seen the movement in other parts of the world.\n\nSpecific accusations connecting the Bahá'í Faith to Freemasonry often include an assertion that Dr. Dhabih Qurban, who was a well-known Bahá'í, was also a freemason. This assertion is based on an Iranian book publishing documents related to Freemasonry in the country; that book states that in specific pages of Fazel Mazandarani's book on the Bahá'í Faith there are statements that Dr. Dhabih Qurban is a Freemason, but in fact Freemasony is not mentioned in the pages of the referenced Bahá'í book. Furthermore, the Iranian book that is the source of the accusation includes a discussion between the Grand Master of the Great Lodge in Iran, and the Grand Master notes that \"no Bahá'ís have become masons and this is repeated by others present with no-one disagreeing.\"\n\nAt times and places where the Bahá'ís have not had access to their own specific venues, they have either hired, or used with permission those belonging to other organizations, with which they do not have other links. This has included Masonic lodges, such as the case with Ruth \"Ruhaniyyih\" Moffett during her visit to Puerto Rico in 1950 to introduce the religion there.\n\nOn the other hand, Shoghi Effendi, the head of the Bahá'í Faith in the first half of the 20th century, stated that the teachings of the Baha'i Faith expressly forbid membership in secret societies, and asked all Bahá'ís to remove their memberships from all secret societies, including the Freemasons, so that they can serve the teachings of the Bahá'í Faith without compromising their independence.\n\n\n"}
{"id": "17005657", "url": "https://en.wikipedia.org/wiki?curid=17005657", "title": "Preboreal", "text": "Preboreal\n\nThe Preboreal is a stage of the Holocene epoch. It is preceded by the Tarantian and succeeded by the Boreal. It lasted from 10,300 to 9,000BP in radiocarbon years or 8350BC to 7050BC in Gregorian calendar years (8th millennium BC). It is the first stage of the Holocene epoch.\n\nThe Holocene has not been formally divided by the IUGS. As a result the Preboreal is only a proposal, and as stratigraphy and dating techniques have improved since this 1972 proposal the dates would be different if proposed today. Instead others have begun to use the terms Early, Middle and Late, which strictly should be Lower, Middle and Upper for the Holocene. If this terminology were to be used the preboreal would be replaced by Lower Holocene which would be dated 11.7 - 8.2 ka B2K.\n"}
{"id": "12279468", "url": "https://en.wikipedia.org/wiki?curid=12279468", "title": "Recommended exposure limit", "text": "Recommended exposure limit\n\nA recommended exposure limit (REL) is an occupational exposure limit that has been recommended by the United States National Institute for Occupational Safety and Health to the Occupational Safety and Health Administration (OSHA) for adoption as a permissible exposure limit. The REL is a level that NIOSH believes would be protective of worker safety and health over a working lifetime if used in combination with engineering and work practice controls, exposure and medical monitoring, posting and labeling of hazards, worker training and personal protective equipment. No REL has ever been adopted by OSHA, but they have been used as guides by some industry and advocacy organizations. RELs for chemical exposures are usually expressed in parts per million (ppm), or sometimes in milligrams per cubic metre (mg/m). Although not legally enforceable limits, NIOSH RELs are considered by OSHA during the promulgation of legally enforceable PELs.\n\n"}
{"id": "140406", "url": "https://en.wikipedia.org/wiki?curid=140406", "title": "Rural Utilities Service", "text": "Rural Utilities Service\n\nThe United States Rural Utilities Service (RUS) administers programs that provide infrastructure or infrastructure improvements to rural communities. These include water and waste treatment, electric power, and telecommunications services. it is an operating unit of the USDA Rural Development agency of the United States Department of Agriculture (USDA). It was created in 1935 as the Rural Electrification Administration (REA), a New Deal agency promoting rural electrification.\n\nA total of 890 rural electric and 800 rural telecommunications utilities in 47 States, Puerto Rico, the Virgin Islands, Guam, the Marshall Islands, the Northern Mariana Islands, and the Federated States of Micronesia have received financial assistance. Approximately 7,200 rural communities are served through financial assistance received from water and waste loans and grants.\n\nThe RUS administers the following programs:\n\nRUS originated with the Rural Electrification Administration (REA), one of the agencies created under the New Deal in 1935 to promote rural electrification. In the 1930s, the U.S. lagged behind Europe in providing electricity to rural areas. In 1934, less than 11% of U.S. farms had electricity. That same year, in France and Germany, nearly 90% of farms had electricity.\n\nBacked by the 1936 Rural Electrification Act the REA gave loans and other help to rural organizations setting up their own power systems and was one of the New Deal's most successful programs. By 1937, hundreds of new municipal power utilities were created nationwide. In 1939, 288,000 households had their electricity provided by rural electric cooperatives. Most of these electric co-ops had applied for and received loans from REA. By 1942, nearly 50% of US farms had electricity, and by 1952 almost all US farms had electricity.\n\nIn 1949, the REA became authorized to provide loans to rural telephone cooperatives.\n\nUnder the Department of Agriculture Reorganization Act of 1994 the REA was absorbed by the Rural Utilities Service (RUS).\n\n"}
{"id": "42714267", "url": "https://en.wikipedia.org/wiki?curid=42714267", "title": "Sally Benson (professor)", "text": "Sally Benson (professor)\n\nSally M. Benson is a professor of energy engineering at Stanford University. In 2014, she was appointed as director of the Precourt Institute for Energy, the university's hub of energy research and education. Benson will continue on as director of Stanford’s Global Climate and Energy Project (GCEP), a position she has had since 2007.\n\nBenson has won various awards, including the 2012 Greenman Award, Michel T. Halbouty Distinguished Lecture Award from the Geological Society, and the ARCS American Pacesetter Award. Benson received a B.S. in geology from Barnard College, Columbia University, and a Ph.D. in materials and mineral engineering from the University of California-Berkeley.\n\nBenson has held several positions with the Lawrence Berkeley National Laboratory, Berkeley, California. These include 1980–2007, Staff scientist (director 1993–1997), Earth Sciences Division; 2001–2004, Deputy director for operations; 1997–2001, Associate laboratory director, Energy Sciences.\n\n\n"}
{"id": "29536", "url": "https://en.wikipedia.org/wiki?curid=29536", "title": "Stephen Schneider", "text": "Stephen Schneider\n\nStephen Henry Schneider (February 11, 1945 – July 19, 2010) was Professor of Environmental Biology and Global Change at Stanford University, a Co-Director at the Center for Environment Science and Policy of the Freeman Spogli Institute for International Studies and a Senior Fellow in the Stanford Woods Institute for the Environment. Schneider served as a consultant to federal agencies and White House staff in the Richard Nixon, Jimmy Carter, Ronald Reagan, George H. W. Bush, Bill Clinton, George W. Bush and Barack Obama administrations.\n\nSchneider's research included modeling of the atmosphere, climate change, and the effect of global climate change on biological systems. Schneider was the founder and editor of the journal \"Climatic Change\" and authored or co-authored over 450 scientific papers and other publications. He was a Coordinating Lead Author in Working Group II Intergovernmental Panel on Climate Change (IPCC) Third Assessment Report and was engaged as a co-anchor of the Key Vulnerabilities Cross-Cutting Theme for the Fourth Assessment Report (AR4) at the time of his death. During the 1980s, Schneider emerged as a leading public advocate of sharp reductions of greenhouse gas emissions to combat global warming. In 2006 Professor Schneider was an Adelaide Thinker in Residence advising the South Australian Government of Premier Mike Rann on climate change and renewable energy policies. In ten years South Australia went from zero to 31% of its electricity generation coming from renewables.\n\nAn annual award for outstanding climate science communication was created in Schneider's honor after his death, by the Commonwealth Club of California. The Stephen Schneider Memorial Lecture of the American Geophysical Union honors Schneider's life and work. \n\nSchneider grew up on Long Island, New York. He studied engineering at Columbia University, receiving his bachelor's degree in mechanical engineering in 1966. In 1971, he earned a Ph.D. in mechanical engineering and plasma physics. Schneider studied the role of greenhouse gases and suspended particulate material on climate as a postdoctoral fellow at NASA's Goddard Institute for Space Studies.\n\nIn 1971, Schneider was second author on a \"Science\" paper with S. Ichtiaque Rasool titled \"Atmospheric Carbon Dioxide and Aerosols: Effects of Large Increases on Global Climate\" (\"Science\" 173, 138–141). This paper used a one-dimensional radiative transfer model to examine the competing effects of cooling from aerosols and warming from CO. The paper concluded that:\n\nCarbon dioxide was predicted to have only a minor role. However, the model was very simple and the calculation of the CO effect was lower than other estimates by a factor of about three, as noted in a footnote to the paper.\n\nThe story made headlines in the \"New York Times\". Shortly afterwards, Schneider became aware that he had overestimated the cooling effect of aerosols, and underestimated the warming effect of CO by a factor of about three. He had mistakenly assumed that measurements of air particles he had taken near the source of pollution applied worldwide. He also found that much of the effect was due to natural aerosols which would not be affected by human activities, so the cooling effect of changes in industrial pollution would be much less than he had calculated. Having found that recalculation showed that global warming was the more likely outcome, he published a retraction of his earlier findings in 1974.\n\nIn a 1976 book \"The Genesis Strategy\" he discusses both long-term warming due to carbon dioxide and short-term cooling due to aerosols, and advocated for adopting policies that are resilient to future changes in climate.\n\nSchneider was a frequent contributor to commercial and noncommercial print and broadcast media on climate and environmental issues, e.g., \"Nova\", \"Planet Earth\", \"Nightline\", \"Today Show\", \"The Tonight Show\", Bill Maher's shows, \"Good Morning America\", \"Dateline\", The Discovery Channel, as well as appearances on the British, Canadian and Australian Broadcasting Corporations.\n\nSchneider commented about the frustrations and difficulties involved with assessing and communicating scientific ideas. In a January 2002 \"Scientific American\" article, he wrote:\nIn 1989, Schneider addressed the challenge scientists face trying to communicate complex, important issues without adequate time during media interviews. This citation sometimes was used by his critics to accuse him of supporting misuse of science for political goals:\n\nFor the original, together with Schneider's commentary on its misrepresentation, see also American Physical Society, \"APS News\" August/September 1996.\n\n\nSchneider was married to the biologist Terry Root. Schneider was a survivor of an aggressive cancer, mantle cell lymphoma. He documented his struggle to conquer the condition, including applying his own knowledge of science to design his own treatment regime, in a self-published 2005 book, \"The Patient from Hell\". He died unexpectedly on July 19, 2010 after suffering a pulmonary embolism while returning from a scientific meeting in , Sweden.\n\n\n\n\n"}
{"id": "17837013", "url": "https://en.wikipedia.org/wiki?curid=17837013", "title": "Subic Forest", "text": "Subic Forest\n\nThe Subic Forest is a national forest protected area that extends from Subic Bay National Park up the northwestern volcanic slope of Mount Natib in Bataan National Park in the Philippines.\n\nThe Subic Forest is located on western Luzon island in Bataan Province, in Central Luzon near the Angeles City area east of Manila. It is in the Luzon Montane Rainforests Ecoregion.\n\n"}
{"id": "20418621", "url": "https://en.wikipedia.org/wiki?curid=20418621", "title": "Vacuum airship", "text": "Vacuum airship\n\nA vacuum airship, also known as a vacuum balloon, is a hypothetical airship that is evacuated rather than filled with a lighter-than-air gas such as hydrogen or helium. First proposed by Italian Jesuit priest Francesco Lana de Terzi in 1670, the vacuum balloon would be the ultimate expression of lifting power per volume displaced.\n\nFrom 1886 to 1900 Arthur De Bausset attempted in vain to raise funds to construct his \"vacuum-tube\" airship design, but despite early support in the United States Congress, the general public was skeptical. Illinois historian Howard Scamehorn reported that Octave Chanute and Albert Francis Zahm \"publicly denounced and mathematically proved the fallacy of the vacuum principle\", however the author does not give his source. De Bausset published a book on his design and offered $150,000 stock in the Transcontinental Aerial Navigation Company of Chicago. His patent application was eventually denied on the basis that it was \"wholly theoretical, everything being based upon calculation and nothing upon trial or demonstration.\"\n\nIn 1921, Lavanda Armstrong discloses a composite wall structure with a vacuum chamber \"surrounded by a second envelop constructed so as to hold air under pressure, the walls of the envelope being spaced from one another and tied together\", including a honeycomb-like cellular structure, however leaving some uncertainty how to achieve adequate buoyancy given \"walls may be made as thick and strong as desired\".\n\nIn 1983, David Noel discussed the use of geodesic sphere covered with plastic film and \"a double balloon containing pressurized air between the\nskins, and a vacuum in the centre\".\n\nIn 1982–1985 Emmanuel Bliamptis elaborated on energy sources and use of \"inflatable strut rings\".\n\nIn 2004–2007 Akhmeteli and Gavrilin address choice of materials (\"beryllium, boron carbide ceramic, and diamond-like carbon\" or aluminum) in honeycomb double layer craft to address buckling issues.\n\nAn airship operates on the principle of buoyancy, according to Archimedes' principle. In an airship, air is the fluid in contrast to a traditional ship where water is the fluid.\n\nThe density of air at standard temperature and pressure is 1.28 g/l, so 1 liter of displaced air has sufficient buoyant force to lift 1.28 g. Airships use a bag to displace a large volume of air; the bag is usually filled with a lightweight gas such as helium or hydrogen. The total lift generated by an airship is equal to the weight of the air it displaces, minus the weight of the materials used in its construction including the gas used to fill the bag.\n\nVacuum airships would replace the helium gas with a near-vacuum environment, having no mass, density would be near to 0.00 g/l, which would theoretically be able to provide the full lift potential of displaced air, so every liter of vacuum could lift 1.28 g. Using the molar volume, the mass of 1 liter of helium (at 1 atmospheres of pressure) is found to be 0.178 g. If helium is used instead of vacuum, the lifting power of every liter is reduced by 0.178 g, so the effective lift is reduced by 14%. A 1-liter volume of hydrogen has a mass of 0.090 g.\n\nThe main problem with the concept of vacuum airships is that, with a near-vacuum inside the airbag, the exterior atmospheric pressure is not balanced by any internal pressure. This enormous imbalance of forces would cause the airbag to collapse unless it were extremely strong (in an ordinary airship, the force is balanced by helium, making this unnecessary). Thus the difficulty is in constructing an airbag with the additional strength to resist this extreme net force, without weighing the structure down so much that the greater lifting power of vacuum is negated.\n\nFrom the analysis by Akhmeteli and Gavrilin:\n\nThe total force on a hemi-spherical shell of radius formula_1 by an external pressure formula_2 is formula_3. Since the force on each hemisphere has to balance along the equator the compressive stress will be, assuming formula_4 \nwhere formula_6 is the shell thickness.\n\nNeutral buoyancy occurs when the shell has the same mass as the displaced air, which occurs when formula_7, where formula_8 is the air density and formula_9 is the shell density, assumed to be homogeneous. Combining with the stress equation gives \nFor aluminum and terrestrial conditions Akhmeteli and Gavrilin estimate the stress as formula_11 Pa, of the same order of magnitude as the compressive strength of aluminum alloys.\n\nAkhmeteli and Gavrilin note, however, that the compressive strength calculation disregards buckling, and using R. Zoelli's formula for the critical buckling pressure of a sphere\nwhere formula_13 is the modulus of elasticity and formula_14 is the Poisson ratio of the shell. Substituting the earlier expression gives a necessary condition for a feasible vacuum balloon shell:\nThe requirement is about formula_16.\n\nAkhmeteli and Gavrilin assert that this cannot even be achieved using diamond (formula_17), and \npropose that dropping the assumption that the shell is a homogeneous material may allow lighter and stiffer structures (e.g. a honeycomb structure).\n\nA vacuum airship should at least float (Archimedes law) and resist external pressure (strength law, depending on design, like the above R. Zoelli's formula for sphere). These two conditions may be rewritten as an inequality where a complex of several physical constants related to the material of the airship is to be lesser than a complex of atmospheric parameters. Thus, for a sphere (hollow sphere and, to a lesser extent, cylinder are practically the only designs for which a strength law is known) it is formula_18, where formula_19 is pressure within the sphere, while formula_20 («Lana coefficient») and formula_21 («Lana atmospheric ratio») are:\n\nwhere formula_28 formula_29 and formula_30 formula_31 are pressure and density of standard Earth atmosphere at sea level, formula_32 and formula_33 are molar mass (kg/kmol) and temperature (K) of atmosphere at floating area.\nOf all known planets and moons of the Sun system only the Venusian atmosphere has formula_21 big enough to surpass formula_20 for such materials as some composites (below altitude of ca. 15 km) and graphene (below altitude of ca. 40 km). Both materials may survive in the Venusian atmosphere. The equation for formula_21 shows that exoplanets with dense, cold and high-molecular (formula_37, formula_38, formula_39 type) atmospheres may be suitable for vacuum airships, but it is a rare type of atmosphere.\n\nIn the Edgar Rice Burroughs novel \"Tarzan at the Earth's Core\" Tarzan travels to Pellucidar in a vacuum airship constructed of the fictional material Harbenite.\n\nIn \"Passarola Rising\", novelist Azhar Abidi imagines what might have happened had Bartolomeu de Gusmão built and flown a vacuum airship.\n\nSpherical vacuum body airships using the Magnus effect and made of carbyne or similar superhard carbon are glimpsed in Neal Stephenson's novel \"The Diamond Age\".\n\nIn \"Maelstrom\" and \"Behemoth:B-Max\", author Peter Watts describes various flying devices, such as \"botflies\" and \"lifters\" that use \"vacuum bladders\" to keep them airborne.\n\nIn \"Feersum Endjinn\" by Iain M. Banks, a vacuum balloon is used by the narrative character Bascule in his quest to rescue Ergates. Vacuum dirigibles (airships) are also mentioned as a notable engineering feature of the space-faring utopian civilisation The Culture in Banks' novel \"Look to Windward\", and the vast vacuum dirigible Equatorial 353 is a pivotal location in the final Culture novel, \"The Hydrogen Sonata\".\n\n"}
{"id": "1933407", "url": "https://en.wikipedia.org/wiki?curid=1933407", "title": "Volcanic bomb", "text": "Volcanic bomb\n\nA volcanic bomb is a mass of molten rock (tephra) larger than 64 mm (2.5 inches) in diameter, formed when a volcano ejects viscous fragments of lava during an eruption. They cool into solid fragments before they reach the ground. Because volcanic bombs cool after they leave the volcano, they are extrusive igneous rocks. Volcanic bombs can be thrown many kilometres from an erupting vent, and often acquire aerodynamic shapes during their flight. Bombs can be extremely large; the 1935 eruption of Mount Asama in Japan expelled bombs measuring 5–6 m in diameter up to 600 m from the vent. Volcanic bombs are a significant volcanic hazard, and can cause severe injuries and death to people in an eruption zone. One such incident occurred at Galeras volcano in Colombia in 1993; six people near the summit were killed and several seriously injured by lava bombs when the volcano erupted unexpectedly. On July 16, 2018, 23 people were injured on a tour boat near the Kilauea volcano as a result of a basketball-sized lava bomb from the 2018 lower Puna eruption.\n\nVolcanic bombs are known to occasionally explode from internal gas pressure as they cool, but in most cases, most of the damage they cause is from impact, or subsequent fire damage. Bomb explosions are most often observed in \"bread-crust\" type bombs.\n\nBombs are named according to their shape, which is determined by the fluidity of the magma from which they are formed. \n\n"}
{"id": "406066", "url": "https://en.wikipedia.org/wiki?curid=406066", "title": "William Howitt", "text": "William Howitt\n\nWilliam Howitt (18 December 1792 – 3 March 1879), was a prolific English writer on history and other subjects. William and his wife Mary also owned a school still used today; Howitt Primary School in Heanor, Derbyshire.\n\nHowitt was born at Heanor, Derbyshire. His parents were Quakers, and he was educated at the Friends public school at Ackworth, Yorkshire. His younger brothers were Richard and Godrey whom he helped tutor. In 1814 he published a poem on the \"Influence of Nature and Poetry on National Spirit\". He married, in 1821, Mary Botham, who like himself was a Quaker and a poet. William and Mary Howitt collaborated throughout a long literary career, the first of their joint productions being \"The Forest Minstrels and other Poems\" (1821).\n\nIn 1831, William Howitt produced a work resulting naturally from his habits of observation and his genuine love of nature. It was a history of the changes in the face of the outside world in the different months of the year, and was entitled \"The Book of the Seasons, or the Calendar of Nature\" (1831). His \"Popular History of Priestcraft\" (1833) won him the favour of active Liberals and the office of alderman in Nottingham, where the Howitts had made their home.\n\nThey moved in 1837 to Esher, and became friends with Elizabeth Gaskell and her husband. 1838 saw publication of his \"Colonization and Christianity\", which was later quoted approvingly by Karl Marx in \"Capital, Volume I\". In 1840 they went to Heidelberg, primarily for the education of their children, remaining in Germany for two years. In 1841 William Howitt produced, under the pseudonym of Dr Cornelius, \"The Student Life of Germany\", the first of a series of works on German social life and institutions. Mary Howitt devoted herself to Scandinavian literature, and between 1842 and 1863 she translated the novels of Frederika Bremer and many of the stories of Hans Christian Andersen. With her husband she wrote in 1852 \"The Literature and Romance of Northern Europe\". In June of that year William Howitt, with two of his sons, set sail for Australia, where he spent two years in the goldfields. The results of his travels appeared in \"A Boy's Adventures in the Wilds of Australia\" (1854), \"Land, Labour and Gold; or, Two Years in Victoria\" (1855) and \"Tallangetta, the Squatter's Home\" (1857).\n\nOn his return to England Howitt had settled at Highgate and resumed his indefatigable book-making. From 1856 to 1862 he was engaged on Cassell's \"Illustrated History of England\", and from 1861 to 1864 he and his wife worked at the \"Ruined Abbeys and Castles of Great Britain\". The Howitts had left the Society of Friends in 1847, and became interested in Spiritualism. In 1863 he published \"The History of the Supernatural in all Ages and Nations, and in all Churches, Christian and Pagan, demonstrating a Universal Faith\". He added his own conclusions from a practical examination of the higher phenomena through a course of seven years.\n\nFrom 1870 onwards Howitt spent the summers in Tyrol and the winters in Rome, where he died. In 1880 Mary Howitt had a house built for her (which is still standing) in the spa town of Meran in South Tyrol (then part of Austria) and from then on divided her time between Rome and Meran.\nMary Howitt was much affected by William's death, and in 1882 she joined the Roman Catholic Church, towards which she had been gradually moving during her connection with spiritualism. She died at Rome on 30 January 1888.\n\nThe Howitts are remembered for their untiring efforts to provide wholesome and instructive literature. Their son, Alfred William Howitt, made a name for himself by his explorations in Australia. Anna Mary Howitt was both an artist and a poet, and married Alaric Alfred Watts. Mary Howitt's autobiography was edited by her daughter, Margaret Howitt, in 1889. William Howitt wrote some fifty books, and his wife's publications, inclusive of translations, number over a hundred.\n\n\nThis entry contains information from the Meran Stadtarchiv and an on the spot visit to the house in Meran, which has a plaque with her initials MAH and the date 1880.\n\n"}
{"id": "12992595", "url": "https://en.wikipedia.org/wiki?curid=12992595", "title": "World Population Conference", "text": "World Population Conference\n\nThe World Population Conference was held at the Salle Centrale, Geneva, Switzerland, from 29 August to 3 September 1927. Organized by the League of Nations and Margaret Sanger, the conference was an attempt to bring together international experts on population, food supply, fertility, migration and health to discuss the problem of human overpopulation. Sir Bernard Mallet presided over the meeting, and William H. Welch was vice-president.\n\nThe conference was truly international, with one hundred and twenty-three delegates from Argentina, Austria, Belgium, Brazil, Chile, China, Czechoslovakia, Denmark, Estonia, Finland, France, Germany, Great Britain, Greece, the Netherlands, India, Italy, Japan, Norway, Peru, Poland, Siam, Spain, the Soviet Union, Sweden, Switzerland, and the United States. Sessions included papers followed by open discussion on topics including biology and population growth, food and population, differential fertility, falling birth rates, international migration and migration restriction, heredity, and disease.\n\nThe World Population Conference succeeded in drawing attention to the study of population growth and established the International Union for the Scientific Study of Population. British Malthusian leader Charles Vickery Drysdale noted that the meeting was \"devoid of propagandism,\" and that the \"weight of authority at it has surpassed all the previous gatherings, and has been second to none in brilliance. The simple fact that nearly two hundred persons of the highest eminence in biological, economic and statistical science, sociologists, statesmen, and physicians have come from all parts of the world to Geneva to confer on this question is sufficient to show that it cannot be disregarded and that it will have to be considered by the Governments of all countries.\" \nA second World Population Conference, sponsored by the United Nations was held in 1954 in Rome, and a third in 1974 in Bucharest.\n\nMargaret Sanger conceived of the World Population Conference and organized a group of scientists including Raymond Pearl, Edward Murray East, and Clarence Cook Little, to develop the program and invite speakers. She agreed that birth control would not be discussed. She established an office to administer the conference in Geneva, but just before the Conference was to open, Sir Bernard Mallet removed her name and the names of her all-female administrative staff from the printed conference programs, using the excuse that administrators and clerical staff should not be listed in a scientific program. Sanger's staff quit in protest. Sanger persuaded most back, arguing that the meeting was more important than who was credited. Sanger edited the Proceedings of the World Population Conference.\n"}
{"id": "15184555", "url": "https://en.wikipedia.org/wiki?curid=15184555", "title": "Zuljanah", "text": "Zuljanah\n\nZuljanah () was the horse of Husayn ibn Ali. Zuljanah was a very important character in Karbala. It was bought and grown up by Muhammad.\n\n"}
