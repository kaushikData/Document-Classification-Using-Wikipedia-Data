{"id": "20948921", "url": "https://en.wikipedia.org/wiki?curid=20948921", "title": "A Guide to the Birds of Mexico and Northern Central America", "text": "A Guide to the Birds of Mexico and Northern Central America\n\nA Guide to the Birds of Mexico and Northern Central America is a field guide to birds, covering 1070 species found in Mexico and five other countries in northern Central America (Guatemala, Belize, El Salvador, Honduras and Nicaragua). It is a 1995 book by Steve N. G. Howell and Sophie Webb, published by Oxford University Press.\n\nA 60-page introduction outlines the geographical area covered, explains the areas geography and bird distribution within it, and discusses climate and habitat, and bird migration. Also included within this introduction are a section summarising the history of ornithology in the region, and essay on conservation, and a short summary of birding within the region. The introduction is followed by a 25-page section entitled \"Using this book\". This is then followed by the species accounts themselves, from pages 87 to 764.\n\nA series of five appendices covers extinct species, species of hypothetical occurrence, birds of Pacific islands, of Gulf and Caribbean islands, and those found in eastern Honduras. These are followed by a 26-page bibliography, and indexes to English and scientific names.\n\nThe covers are illustrated with paintings of Mexican birds: a black-throated magpie-jay on the front cover, a short-crested coquette on the spine, and an unspotted saw-whet owl and two plumbeous kites on the rear cover.\n\n71 colour plates are placed centrally within the book, between pages 400 and 401.\n\n"}
{"id": "18294989", "url": "https://en.wikipedia.org/wiki?curid=18294989", "title": "America's Wetland Foundation", "text": "America's Wetland Foundation\n\nAmerica's WETLAND Foundation (AWF) is a nonprofit, tax exempt 501(c)(3) organization with the stated mission to save and conserve coastal wetlands in the U.S. state of Louisiana. The organization aims to achieve this mission through a public awareness campaign on the impact Louisiana's wetland loss has on the state, region, nation and world.\n\nAWF is based in New Orleans, Louisiana. The public education campaign started in 2002, when the AWF board hired the public relations Marmillion + Company. \n\nSince being formed in 2003, America's Wetland officials say its message and outreach has resulted in more than 1 billion media impressions worldwide. That tally includes documentaries, news shows, feature stories, billboards, festivals, special events, public-service announcements and Web sites.\n\nIn 2001, Former Louisiana Governor Mike Foster launched what would become the America's WETLAND Campaign, and declared a \"holy war\" on coastal erosion. Since a previous 18 month state sponsored study had determined a comprehensive restoration effort would cost more than $14 billion, it was determined the only way to raise that amount of money was through federal funding and therefore widespread public support was necessary.\n\nIn 2003, AWF became an independent foundation supported by public donations, and private sponsors such as Shell Oil Company, Tabasco pepper sauce, and others.\n\nAWF has been supported by Republicans and Democrats including Foster's successor, Former Louisiana Governor Kathleen Blanco who joined the effort in 2004. AWF has grown into a multimillion-dollar campaign, and describes itself as \"the largest public education campaign in Louisiana history.\"\n\nHurricanes Katrina and Rita were predated by AWF's first \"Storm Warnings\" event, which sought to illustrate the role wetlands play as a natural hurricane buffer. The event ominously involved draping a blue tarp over a block of Royal Street to illustrate the flood levels if a Category 5 storm hit New Orleans. As a result, the America's WETLAND Foundation was a natural platform for Louisiana public officials to rally national public support to the region. Former Congressman Billy Tauzin stated in a \"Washington Post\" article following the disasters, \"We all came together around America's Wetland... [it] was the most coordination I ever saw.\"\n\nIn addition, then Governor Blanco asked AWF to provide support and assistance in establishing the Louisiana Disaster Recovery Foundation to receive donations to assist Louisiana victims of the hurricanes.\nAn AWF related organization, \"Women of the Storm\" (WOS), was created following the storms. The WOS is composed of 140 New Orleans area volunteers who advocate for members of the United States Congress to visit hurricane-damaged areas. As of January 2009, their efforts have resulted in 57 Senators and 147 Representatives witnessing damaged areas first hand.\nOne year after the hurricanes AWF launched \"Riding the Trail to Recovery\" a two-mile (3 km) cattle drive through lower Cameron Parish designed to help bring attention to victims of Hurricane Rita who may have felt forgotten by the larger focus on Hurricane Katrina.\n\nThe America's WETLAND Foundation's public awareness campaign focuses on two themes: one, the region is of world ecological significance and, two, it is critical to the economic and energy future of the United States. The Foundation supports the Coastal Protection and Restoration Authority's master plan for coastal restoration passed by the Louisiana Legislature in 2007.\n\nAWF's Progress Report states its public education campaign has five primary objectives:\n\n\nThe America's WETLAND Foundation is a multi-faceted campaign with many different related organizations, brands, and awareness events. Some of their annual awareness events include \"Storm Warnings,\" and \"Keep Your Eye on The Prize.\" The annual Storm Warnings event occurs around the start of each hurricane season (end of May) and is designed to help focus national attention on the importance of Louisiana's coast and the wetlands' role as a natural hurricane buffer.\n\n\"Storm Warnings IV: Last Stand\" was announced on February 2, 2009 and is set to take place May 30–31, 2009 and will include a large free concert in New Orleans. This will be followed the next day by flotillas of watercraft rendezvousing at the Houma Downtown Marina where they will point reflectors to the sun, to be photographed by satellite to illustrate how the land below the line will be lost if nothing is done to restore Louisiana's eroding coast.\n\n\"Keep Your Eye On The Prize\" is a two-month-long photo, art and poetry contest for Louisiana students in fourth through twelfth grade. The contest usually asks students to capture the importance or beauty of the wetlands through one of the above mediums. The 9 first-place winners (3 age divisions for each category) receive a $500 grant for their school to conduct a conservation project, usually in conjunction with the America's WETLAND Conservation Corps.\n\nThe \"Estuarians\" are an animated superhero conservation action team designed to help kids learn about the importance of the wetlands. They are also mascots who have been to multiple events including Mardi Gras, National Wetlands Research Center, and Ocean Commotion .\n\nThe America's WETLAND Foundation also helped sponsor and develop a comprehensive series of birding trails throughout the state of Louisiana in conjunction with Lieutenant Governor Mitch Landrieu. America's Wetland Birding Trail now consists of 264 sites on 26 loops and 10 scenic pathways statewide. Many of these sites are located in rural settings near rivers, deltas, open meadows, lagoons and in several pine and hardwood forests. The paths follow interstate, state and federal highways around the state as individual loops stand together as one tourist attraction within the transportation network of Louisiana.\n\nAWF also produces brochures, public service announcements, and documentaries.\n\nAWF sponsors educational and restoration programs, such as the America's WETLAND Conservation Corps, which is a partnership between the America's WETLAND Foundation and the Louisiana State University AgCenter. This AmeriCorps program, operating in conjunction with LSU AgCenter, places members at sites throughout Louisiana to coordinate hands-on coastal restoration projects that include vegetative plantings, restorative interventions, community wide cleanups, and hands-on education projects for volunteers and communities in an effort to promote stewardship and conservation, raising public awareness of the negative impact that the erosion of Louisiana's wetlands has on the state, national and worldwide ecosystems.\n\nAn AWF related organization, \"Women of the Storm,\" (WOS) was created following Hurricanes Katrina and Rita. The WOS is composed of 140 New Orleans area volunteers who advocate for members of Congress to visit hurricane-damaged areas. As of January 2009, their efforts have resulted in 57 Senators and 147 Representatives witnessing damaged areas first hand.\n\nAmerica's Energy Coast is an AWF related organization which joins the Gulf Coast energy producing states of Louisiana, Mississippi, Alabama, and Texas together to develop common solutions to ensure a sustainable coastal environment and the inextricably linked activities critical to the nation's energy and economic security. Its \"Accord for a New Sustainability For America's Energy Coast\" is a living framework of shared principles where its disparate member groups have come to consensus. The group claims its format \"will yield technology and solutions best practices, and policy recommendations at all levels of government.\"\n\nThe America's WETLAND Campaign has won over 45 awards such as MarCom Creative Awards, Southern Growth Innovator Award, Spotlight Awards, Summit Creative Award, Telly Award, Videographer Award, Natioinal Association of Government Communicators Award, Comunicator Award, and the League of American Communications Professionals for top 50 publicity campaigns.\nThe \"Houma Courier\" endorsed the accomplishments of the campaign saying in an editorial, \"Looking back to six years ago, when the America's Wetland Foundation was kicked off, it is easy to see how many real improvements have been made in our coastal challenges and how many of those challenges remain unabated. But this much is clear: Much of the progress that has been made can be directly or indirectly attributed to the America's Wetland and the vital work it is doing on our behalf.\"\n\nThe 2007 Miss Louisiana USA winner Elizabeth McNulty has worked with America's WETLAND Foundation as well as the America's WETLAND Conservation Corps.\n\n\n"}
{"id": "300082", "url": "https://en.wikipedia.org/wiki?curid=300082", "title": "Anechoic chamber", "text": "Anechoic chamber\n\nAn anechoic chamber (\"an-echoic\" meaning \"non-reflective, non-echoing, echo-free\") is a room designed to completely absorb reflections of either sound or electromagnetic waves. They are also often isolated from waves entering from their surroundings. This combination means that a person or detector exclusively hears direct sounds (no reverberant sounds), in effect simulating being inside an infinitely large room.\n\nAnechoic chambers, a term coined by American acoustics expert Leo Beranek, were initially exclusively used to refer to acoustic anechoic chambers. Recently, the term has been extended to RF anechoic chambers, which eliminate reflection and external noise caused by electromagnetic waves.\n\nAnechoic chambers range from small compartments the size of household microwave ovens to ones as large as aircraft hangars. The size of the chamber depends on the size of the objects and frequency ranges being tested.\n\nAnechoic chambers are commonly used in acoustics to conduct experiments in nominally \"free field\" conditions, free-field meaning that there are no reflected signals. All sound energy will be traveling away from the source with almost none reflected back. Common anechoic chamber experiments include measuring the transfer function of a loudspeaker or the directivity of noise radiation from industrial machinery. In general, the interior of an anechoic chamber is very quiet, with typical noise levels in the 10–20 dBA range. In 2005, the best anechoic chamber measured at −9.4 dBA. In 2015, an anechoic chamber on the campus of Microsoft broke the world record with a measurement of −20.6 dBA. The human ear can typically detect sounds above 0 dBA, so a human in such a chamber would perceive the surroundings as devoid of sound. Anecdotally, some people may not like such quietness and can become disoriented.\n\nThe mechanism by which anechoic chambers minimize the reflection of sound waves impinging onto their walls is as follows: In the included figure, an incident sound wave I is about to impinge onto a wall of an anechoic chamber. This wall is composed of a series of wedges W with height H. After the impingement, the incident wave I is reflected as a series of waves R which in turn \"bounce up-and-down\" in the gap of air A (bounded by dotted lines) between the wedges W. Such bouncing may produce (at least temporarily) a standing wave pattern in A. During this process, the acoustic energy of the waves R gets dissipated via the air's molecular viscosity, in particular near the corner C. In addition, with the use of foam materials to fabricate the wedges, another dissipation mechanism happens during the wave/wall interactions. As a result, the component of the reflected waves R along the direction of I that escapes the gaps A (and goes back to the source of sound), denoted R', is notably reduced. Even though this explanation is two-dimensional, it is representative and applicable to the actual three-dimensional wedge structures used in anechoic chambers.\n\nFull anechoic chambers aim to absorb energy in all directions. Semi-anechoic chambers have a solid floor that acts as a work surface for supporting heavy items, such as cars, washing machines, or industrial machinery, rather than the mesh floor grille over absorbent tiles found in full anechoic chambers. This floor is damped and floating on absorbent buffers to isolate it from outside vibration or electromagnetic signals. Recording studios are often semi-anechoic.\n\nThe internal appearance of the radio frequency (RF) anechoic chamber is sometimes similar to that of an acoustic anechoic chamber; however, the interior surfaces of the RF anechoic chamber are covered with radiation absorbent material (RAM) instead of acoustically absorbent material. Uses for RF anechoic chambers include testing antennae, radars, and is typically used to house the antennas for performing measurements of antenna radiation patterns, electromagnetic interference.\n\nPerformance expectations (gain, efficiency, pattern characteristics, etc.) constitute primary challenges in designing stand alone or embedded antennae. Designs are becoming ever more complex with a single device incorporating multiple technologies such as cellular, WiFi, Bluetooth, LTE, MIMO, RFID and GPS.\n\nRAM is designed and shaped to absorb incident RF radiation (also known as non-ionising radiation) as effectively as possible, from as many incident directions as possible. The more effective the RAM, the lower the resulting level of reflected RF radiation. Many measurements in electromagnetic compatibility (EMC) and antenna radiation patterns require that spurious signals arising from the test setup, including reflections, are negligible to avoid the risk of causing measurement errors and ambiguities.\n\nWaves of higher frequencies have shorter wavelengths and are higher in energy, while waves of lower frequencies have longer wavelengths and are lower in energy, according to the relationship formula_1 where lambda represents wavelength, v is phase velocity of wave, and formula_2 is frequency. To shield for a specific wavelength, the cone must be of appropriate size to absorb that wavelength. The performance quality of an RF anechoic chamber is determined by its lowest test frequency of operation, at which measured reflections from the internal surfaces will be the most significant compared to higher frequencies. Pyramidal RAM is at its most absorptive when the incident wave is at normal incidence to the internal chamber surface and the pyramid height is approximately equal to formula_3, where formula_4 is the free space wavelength. Accordingly, increasing the pyramid height of the RAM for the same (square) base size improves the effectiveness of the chamber at low frequencies but results in increased cost and a reduced unobstructed working volume that is available inside a chamber of defined size.\n\nAn RF anechoic chamber is usually built into a screened room, designed using the Faraday cage principle. This is because most of the RF tests that require an anechoic chamber to minimize reflections from the inner surfaces also require the properties of a screened room to attenuate unwanted signals penetrating inwards and causing interference to the equipment under test and prevent leakage from tests penetrating outside.\n\nAt lower radiated frequencies, far-field measurement can require a large and expensive chamber. Sometimes, for example for radar cross-section measurements, it is possible to scale down the object under test and reduce the chamber size, provided that the wavelength of the test frequency is scaled down in direct proportion by testing at a higher frequency.\n\nRF anechoic chambers are normally designed to meet the electrical requirements of one or more accredited standards. For example, the aircraft industry may test equipment for aircraft according to company specifications or military specifications such as MIL-STD 461E. Once built, acceptance tests are performed during commissioning to verify that the standard(s) are in fact met. Provided they are, a certificate will be issued to that effect. The chamber will need to be periodically retested.\n\nTest and supporting equipment configurations to be used within anechoic chambers must expose as few metallic (conductive) surfaces as possible, as these risk causing unwanted reflections. Often this is achieved by using non-conductive plastic or wooden structures for supporting the equipment under test. Where metallic surfaces are unavoidable, they may be covered with pieces of RAM after setting up to minimize such reflection as far as possible.\n\nA careful assessment may be required as to whether the test equipment (as opposed to the equipment under test) should be placed inside or outside the chamber. Typically most of it is located in a separate screened room attached to the main test chamber, in order to shield it from both external interference and from the radiation within the chamber. Mains power and test signal cabling into the test chamber require high quality filtering.\n\nFiber optic cables are sometimes used for the signal cabling, as they are immune to ordinary RFI and also cause little reflection inside the chamber.\n\nThe following health and safety risks are associated with RF anechoic chambers:\n\n\nPersonnel are not normally permitted inside the chamber during a measurement as this not only can cause unwanted reflections from the human body but may also be a radiation hazard to the personnel concerned if tests are being performed at high RF powers. Such risks are from RF or non-ionizing radiation and not from the higher energy ionizing radiation.\n\nAs RAM is highly absorptive of RF radiation, incident radiation will generate heat within the RAM. If this cannot be dissipated adequately there is a risk that hot spots may develop and the RAM temperature may rise to the point of combustion. This can be a risk if a transmitting antenna inadvertently gets too close to the RAM. Even for quite modest transmitting power levels, high gain antennas can concentrate the power sufficiently to cause high power flux near their apertures. Although recently manufactured RAM is normally treated with a fire retardant to reduce such risks, they are difficult to completely eliminate. Safety regulations normally require the installation of a gaseous fire suppression system including smoke detectors.\n\n\n"}
{"id": "2032832", "url": "https://en.wikipedia.org/wiki?curid=2032832", "title": "Antiprotonic helium", "text": "Antiprotonic helium\n\nAntiprotonic helium is a three-body atom composed of an antiproton and an electron orbiting around a helium nucleus. It is thus made partly of matter, and partly of antimatter. The atom is electrically neutral, since both electrons and antiprotons each have a charge of −1, whereas helium nuclei have a charge of +2. The antiprotonic helium atom is called an atomcule, as it has a structure like an atom, but has two nuclei like a molecule.\n\nThese exotic atoms can be produced by simply mixing antiprotons with ordinary helium gas; the antiproton spontaneously removes one of the two electrons contained in a normal helium atom in a chemical reaction, and then begins to orbit the helium nucleus in the electron's place. This will happen in the case of approximately 3% of the antiprotons introduced to the helium gas. The antiproton's orbit, which has a large principal quantum number and angular momentum quantum number of around 38, lies far away from the surface of the helium nucleus. The antiproton can thus orbit the nucleus for tens of microseconds, before finally falling to its surface and annihilating.\n\nAntiprotonic helium atoms are under study by the ASACUSA experiment at CERN. In these experiments, the atoms are first produced by stopping a beam of antiprotons in helium gas. The atoms are then irradiated by powerful laser beams, which cause the antiprotons in them to resonate and jump from one atomic orbit to another.\n\nBy measuring the particular frequency of the laser light needed to resonate the atom, \nthe ASACUSA experiment determined the mass of the antiproton, which they measured at times more massive than an electron. This is the same as the mass of a \"regular\" proton, within the level of certainty of the experiment.\nThis is a confirmation of a fundamental symmetry of nature called CPT (short for charge, parity, and time reversal). This law says that all physical laws would remain unchanged under simultaneous reversal of the charge axis, parity of the space axes, and the orientation of the time axis. One important prediction of this theory is that particles and their antiparticles should have exactly the same mass.\n\nBy comparing the above results on laser spectroscopy of antiprotonic helium with separate high-precision measurements of the antiproton's cyclotron frequency carried out by the ATRAP and BASE collaborations at CERN, the mass and electric charge of the antiproton can be precisely compared with the proton values. The most recent such measurements show that the antiproton's mass (and the absolute value of the charge) is the same as the proton's to a precision of 0.5 parts in a billion.\n\nAn antiprotonic helium ion is a two-body object composed of a helium nucleus and orbiting antiproton. It has an electric charge of +1. Cold ions with lifetimes of up to 100 ns were produced at CERN in 2005.\n\n"}
{"id": "1623868", "url": "https://en.wikipedia.org/wiki?curid=1623868", "title": "Baja California Desert", "text": "Baja California Desert\n\nThe Baja California Desert is a desert ecoregion of Mexico's Baja California Peninsula. This ecoregion occupies the western portion of the Baja California peninsula, and occupies most of the Mexican states of Baja California Sur and Baja California. It covers 77,700 square kilometers (30,000 square miles). The climate is dry, but the close proximity of the Pacific Ocean provides humidity and moderates the temperature. The flora mostly consists of xeric shrubs and over 500 species of recorded vascular plants.\n\nThe ecoregion covers 77,700 square kilometers (30,000 square miles) and includes most of the Peninsula's western slope. It is bounded on the west by the Pacific Ocean and on the east by the Peninsular Ranges and is centered on the coordinates . North of 30° north latitude, the Baja California desert transitions to the California chaparral and woodlands. The southern tip of the peninsula lies within the San Lucan xeric scrub ecoregion. To the north are the Sierra Juárez and San Pedro Mártir pine-oak forests, where a number of tree species are found including the near-threatened California Fan Palm.\n\nThe climate is dry and subtropical. Although rainfall is low, the Pacific Ocean provides some humidity and moderates the temperature compared to the Sonoran desert, which lies on the east slope of the Peninsular Ranges.\n\nThe Baja California Desert ecoregion occurs on the western portion of the Baja California peninsula and occupies most of the Mexican states of Baja California Sur and Baja California. Elevation is variable, ranging from mountain ranges on the western central part (1000 - 1500m), plains of median elevation (300 – 600m), and vast extensions of coastal dunes.\n\nThe ecoregion is mostly covered by xeric shrubs, which create varying associations based on elevation and soil conditions. The ecoregion has close to 500 species of vascular plants, of which a number are endemic, for example the Boojum tree or Creeping Devil.\n\n"}
{"id": "5942793", "url": "https://en.wikipedia.org/wiki?curid=5942793", "title": "Bloodwood", "text": "Bloodwood\n\nBloodwood is a common name for several unrelated trees, including:\n\n\n"}
{"id": "38451899", "url": "https://en.wikipedia.org/wiki?curid=38451899", "title": "Climate Data Operators", "text": "Climate Data Operators\n\nCDO is a command line suite for manipulating and analysing climate data. It provides more than 600 operators for this purpose and is an acronym for Climate Data Operators.\n\nSupported data formats are:\n\nCDO offers a scripting interface for Ruby and Python.\n\n"}
{"id": "7783", "url": "https://en.wikipedia.org/wiki?curid=7783", "title": "Coriolis force", "text": "Coriolis force\n\nIn physics, the Coriolis force is an inertial force that seems to act on objects that are in motion within a frame of reference that rotates with respect to an inertial frame. In a reference frame with clockwise rotation, the force acts to the left of the motion of the object. In one with anticlockwise (or counterclockwise) rotation, the force acts to the right. Deflection of an object due to the Coriolis force is called the Coriolis effect. Though recognized previously by others, the mathematical expression for the Coriolis force appeared in an 1835 paper by French scientist Gaspard-Gustave de Coriolis, in connection with the theory of water wheels. Early in the 20th century, the term \"Coriolis force\" began to be used in connection with meteorology.\n\nNewton's laws of motion describe the motion of an object in an inertial (non-accelerating) frame of reference. When Newton's laws are transformed to a rotating frame of reference, the Coriolis force and centrifugal force appear. Both forces are proportional to the mass of the object. The Coriolis force is proportional to the rotation rate and the centrifugal force is proportional to the square of the rotation rate. The Coriolis force acts in a direction perpendicular to the rotation axis and to the velocity of the body in the rotating frame and is proportional to the object's speed in the rotating frame (more precisely, to the component of its velocity that is perpendicular to the axis of rotation). The centrifugal force acts outwards in the radial direction and is proportional to the distance of the body from the axis of the rotating frame. These additional forces are termed inertial forces, fictitious forces or \"pseudo forces\". They allow the application of Newton's laws to a rotating system. They are correction factors that do not exist in a non-accelerating or inertial reference frame.\n\nIn popular (non-technical) usage of the term \"Coriolis effect\", the rotating reference frame implied is almost always the Earth. Because the Earth spins, Earth-bound observers need to account for the Coriolis force to correctly analyze the motion of objects. The Earth completes one rotation per day, so for motions of everyday objects the Coriolis force is usually quite small compared to other forces; its effects generally become noticeable only for motions occurring over large distances and long periods of time, such as large-scale movement of air in the atmosphere or water in the ocean. Such motions are constrained by the surface of the Earth, so only the horizontal component of the Coriolis force is generally important. This force causes moving objects on the surface of the Earth to be deflected to the right (with respect to the direction of travel) in the Northern Hemisphere and to the left in the Southern Hemisphere. The horizontal deflection effect is greater near the poles, since the effective rotation rate about a local vertical axis is largest there, and decreases to zero at the equator. Rather than flowing directly from areas of high pressure to low pressure, as they would in a non-rotating system, winds and currents tend to flow to the right of this direction north of the equator and to the left of this direction south of it. This effect is responsible for the rotation of large cyclones (see Coriolis effects in meteorology).\n\nFor an intuitive explanation of the origin of the Coriolis force, consider an object, constrained to follow the Earth's surface and moving northward in the northern hemisphere. Viewed from outer space, the object does not appear to go due north, but has an eastward motion (it rotates around toward the right along with the surface of the Earth). The further north you go, the smaller the \"horizontal diameter\" of the Earth (the minimum distance from the surface point to the axis of rotation, which is in a plane orthogonal to the axis), and so the slower the eastward motion of its surface. As the object moves north, to higher latitudes, it has a tendency to maintain the eastward speed it started with (rather than slowing down to match the reduced eastward speed of local objects on the Earth's surface), so it veers east (i.e. to the right of its initial motion). Though not obvious from this example, which considers northward motion, the horizontal deflection occurs equally for objects moving east or west (or any other direction).\n\nItalian scientist Giovanni Battista Riccioli and his assistant Francesco Maria Grimaldi described the effect in connection with artillery in the 1651 \"Almagestum Novum\", writing that rotation of the Earth should cause a cannonball fired to the north to deflect to the east. In 1674 Claude François Milliet Dechales described in his \"Cursus seu Mundus Mathematicus\" how the rotation of the Earth should cause a deflection in the trajectories of both falling bodies and projectiles aimed toward one of the planet's poles. Riccioli, Grimaldi, and Dechales all described the effect as part of an argument against the heliocentric system of Copernicus. In other words, they argued that the Earth's rotation should create the effect, and so failure to detect the effect was evidence for an immobile Earth. The Coriolis acceleration equation was derived by Euler in 1749 and the effect was described in the tidal equations of Pierre-Simon Laplace in 1778.\n\nGaspard-Gustave Coriolis published a paper in 1835 on the energy yield of machines with rotating parts, such as waterwheels. That paper considered the supplementary forces that are detected in a rotating frame of reference. Coriolis divided these supplementary forces into two categories. The second category contained a force that arises from the cross product of the angular velocity of a coordinate system and the projection of a particle's velocity into a plane perpendicular to the system's axis of rotation. Coriolis referred to this force as the \"compound centrifugal force\" due to its analogies with the centrifugal force already considered in category one. The effect was known in the early 20th century as the \"acceleration of Coriolis\", and by 1920 as \"Coriolis force\".\n\nIn 1856, William Ferrel proposed the existence of a circulation cell in the mid-latitudes with air being deflected by the Coriolis force to create the prevailing westerly winds.\n\nThe understanding of the kinematics of how exactly the rotation of the Earth affects airflow was partial at first. Late in the 19th century, the full extent of the large scale interaction of pressure-gradient force and deflecting force that in the end causes air masses to move along isobars was understood.\n\nIn non-vector terms: at a given rate of rotation of the observer, the magnitude of the Coriolis acceleration of the object is proportional to the velocity of the object and also to the sine of the angle between the direction of movement of the object and the axis of rotation.\n\nThe vector formula for the magnitude and direction of the Coriolis acceleration is derived through vector analysis and is\n\nwhere (here and below) formula_2 is the acceleration of the particle in the rotating system, formula_3 is the velocity of the particle with respect to the rotating system, and Ω is the angular velocity vector having magnitude equal to the rotation rate ω, with direction along the axis of rotation of the rotating reference frame, and the formula_4\nsymbol represents the cross product operator.\n\nThe equation may be multiplied by the mass of the relevant object to produce the Coriolis force:\n\nSee \"fictitious force\" for a derivation.\n\nThe \"Coriolis effect\" is the behavior added by the \"Coriolis acceleration\". The formula implies that the Coriolis acceleration is perpendicular both to the direction of the velocity of the moving mass and to the frame's rotation axis. So in particular:\n\nThe Coriolis force exists only when one uses a rotating reference frame. In the rotating frame it behaves exactly like a real force (that is to say, it causes acceleration and has real effects). However, the Coriolis force is a consequence of inertia, and is not attributable to an identifiable originating body, as is the case for electromagnetic or nuclear forces, for example. From an analytical viewpoint, to use Newton's second law in a rotating system, the Coriolis force is mathematically necessary, but it disappears in a non-accelerating, inertial frame of reference. For example, consider two children on opposite sides of a spinning roundabout (Merry-go-round ), who are throwing a ball to each other. From the children's point of view, this ball's path is curved sideways by the Coriolis force. Suppose the roundabout spins anticlockwise when viewed from above. From the thrower's perspective, the deflection is to the right. From the non-thrower's perspective, deflection is to the left. \"For a mathematical formulation see Mathematical derivation of fictitious forces.\" In meteorology, a rotating frame (the Earth) with its Coriolis force provides a more natural framework for explanation of air movements than a non-rotating, inertial frame without Coriolis forces. In long-range gunnery, sight corrections for the Earth's rotation are based on the Coriolis force. These examples are described in more detail below.\n\nThe acceleration entering the Coriolis force arises from two sources of change in velocity that result from rotation: the first is the change of the velocity of an object in time. The same velocity (in an inertial frame of reference where the normal laws of physics apply) is seen as different velocities at different times in a rotating frame of reference. The apparent acceleration is proportional to the angular velocity of the reference frame (the rate at which the coordinate axes change direction), and to the component of velocity of the object in a plane perpendicular to the axis of rotation. This gives a term formula_6. The minus sign arises from the traditional definition of the cross product (right-hand rule), and from the sign convention for angular velocity vectors.\n\nThe second is the change of velocity in space. Different positions in a rotating frame of reference have different velocities (as seen from an inertial frame of reference). For an object to move in a straight line, it must accelerate so that its velocity changes from point to point by the same amount as the velocities of the frame of reference. The force is proportional to the angular velocity (which determines the relative speed of two different points in the rotating frame of reference), and to the component of the velocity of the object in a plane perpendicular to the axis of rotation (which determines how quickly it moves between those points). This also gives a term formula_6.\n\nThe time, space and velocity scales are important in determining the importance of the Coriolis force. Whether rotation is important in a system can be determined by its Rossby number, which is the ratio of the velocity, \"U\", of a system to the product of the Coriolis parameter,formula_8, and the length scale, \"L\", of the motion:\nThe Rossby number is the ratio of inertial to Coriolis forces. A small Rossby number indicates a system is strongly affected by Coriolis forces, and a large Rossby number indicates a system in which inertial forces dominate. For example, in tornadoes, the Rossby number is large, in low-pressure systems it is low, and in oceanic systems it is around 1. As a result, in tornadoes the Coriolis force is negligible, and balance is between pressure and centrifugal forces. In low-pressure systems, centrifugal force is negligible and balance is between Coriolis and pressure forces. In the oceans all three forces are comparable.\n\nAn atmospheric system moving at \"U\" =  occupying a spatial distance of \"L\" = , has a Rossby number of approximately 0.1.\n\nA baseball pitcher may throw the ball at U =  for a distance of L = . The Rossby number in this case would be 32,000.\n\nBaseball players don't care about which hemisphere they're playing in. However, an unguided missile obeys exactly the same physics as a baseball, but can travel far enough and be in the air long enough to experience the effect of Coriolis force. Long-range shells in the Northern Hemisphere landed close to, but to the right of, where they were aimed until this was noted. (Those fired in the Southern Hemisphere landed to the left.) In fact, it was this effect that first got the attention of Coriolis himself.\n\nThe animation at the top of this article is a classic illustration of Coriolis force. Another visualization of the Coriolis and centrifugal forces is this animation clip.\n\nGiven the radius \"R\" of the turntable in that animation, the rate of angular rotation ω, and the speed of the cannonball (assumed constant) \"v\", the correct angle θ to aim so as to hit the target at the edge of the turntable can be calculated.\n\nThe inertial frame of reference provides one way to handle the question: calculate the time to interception, which is \"t\" = \"R\" / \"v\" . Then, the turntable revolves an angle ω \"t\" in this time. If the cannon is pointed an angle θ = ω \"t\" = ω \"R\" / \"v\", then the cannonball arrives at the periphery at position number 3 at the same time as the target.\n\nNo discussion of Coriolis force can arrive at this solution as simply, so the reason to treat this problem is to demonstrate Coriolis formalism in an easily visualized situation.\n\nThe trajectory in the inertial frame (denoted \"A\") is a straight line radial path at angle θ. The position of the cannonball in (\"x\", \"y\") coordinates at time \"t\" is:\nIn the turntable frame (denoted \"B\"), the \"x\"- \"y\" axes rotate at angular rate ω, so the trajectory becomes:\nand three examples of this result are plotted in the figure.\n\nTo determine the components of acceleration, a general expression is used from the article fictitious force:\n\nin which the term in Ω × v is the Coriolis acceleration and the term in Ω × (Ω × r) is the centrifugal acceleration. The results are (let α = θ − ω\"t\"):\n\nProducing a centrifugal acceleration:\n\nAlso:\n\nproducing a Coriolis acceleration:\n\nThese accelerations are shown in the diagrams for a particular example.\n\nIt is seen that the Coriolis acceleration not only cancels the centrifugal acceleration, but together they provide a net \"centripetal\", radially inward component of acceleration (that is, directed toward the center of rotation):\n\nand an additional component of acceleration perpendicular to r(\"t\"):\n\nThe \"centripetal\" component of acceleration resembles that for circular motion at radius \"r\", while the perpendicular component is velocity dependent, increasing with the radial velocity \"v\" and directed to the right of the velocity. The situation could be described as a circular motion combined with an \"apparent Coriolis acceleration\" of 2ω\"v\". However, this is a rough labelling: a careful designation of the true centripetal force refers to a local reference frame that employs the directions normal and tangential to the path, not coordinates referred to the axis of rotation.\n\nThese results also can be obtained directly by two time differentiations of r(\"t\"). Agreement of the two approaches demonstrates that one could start from the general expression for fictitious acceleration above and derive the trajectories shown here. However, working from the acceleration to the trajectory is more complicated than the reverse procedure used here, which is made possible in this example by knowing the answer in advance.\n\nAs a result of this analysis an important point appears: \"all\" the fictitious accelerations must be included to obtain the correct trajectory. In particular, besides the Coriolis acceleration, the centrifugal force plays an essential role. It is easy to get the impression from verbal discussions of the cannonball problem, which focus on displaying the Coriolis effect particularly, that the Coriolis force is the only factor that must be considered, but that is not so. A turntable for which the Coriolis force \"is\" the only factor is the parabolic turntable. A somewhat more complex situation is the idealized example of flight routes over long distances, where the centrifugal force of the path and aeronautical lift are countered by gravitational attraction.\nThe figure illustrates a ball tossed from 12:00 o'clock toward the center of a counter-clockwise rotating carousel. On the left, the ball is seen by a stationary observer above the carousel, and the ball travels in a straight line to the center, while the ball-thrower rotates counter-clockwise with the carousel. On the right the ball is seen by an observer rotating with the carousel, so the ball-thrower appears to stay at 12:00 o'clock. The figure shows how the trajectory of the ball as seen by the rotating observer can be constructed.\n\nOn the left, two arrows locate the ball relative to the ball-thrower. One of these arrows is from the thrower to the center of the carousel (providing the ball-thrower's line of sight), and the other points from the center of the carousel to the ball. (This arrow gets shorter as the ball approaches the center.) A shifted version of the two arrows is shown dotted.\n\nOn the right is shown this same dotted pair of arrows, but now the pair are rigidly rotated so the arrow corresponding to the line of sight of the ball-thrower toward the center of the carousel is aligned with 12:00 o'clock. The other arrow of the pair locates the ball relative to the center of the carousel, providing the position of the ball as seen by the rotating observer. By following this procedure for several positions, the trajectory in the rotating frame of reference is established as shown by the curved path in the right-hand panel.\n\nThe ball travels in the air, and there is no net force upon it. To the stationary observer the ball follows a straight-line path, so there is no problem squaring this trajectory with zero net force. However, the rotating observer sees a \"curved\" path. Kinematics insists that a force (pushing to the \"right\" of the instantaneous direction of travel for a \"counter-clockwise\" rotation) must be present to cause this curvature, so the rotating observer is forced to invoke a combination of centrifugal and Coriolis forces to provide the net force required to cause the curved trajectory.\nThe figure describes a more complex situation where the tossed ball on a turntable bounces off the edge of the carousel and then returns to the tosser, who catches the ball. The effect of Coriolis force on its trajectory is shown again as seen by two observers: an observer (referred to as the \"camera\") that rotates with the carousel, and an inertial observer. The figure shows a bird's-eye view based upon the same ball speed on forward and return paths. Within each circle, plotted dots show the same time points. In the left panel, from the camera's viewpoint at the center of rotation, the tosser (smiley face) and the rail both are at fixed locations, and the ball makes a very considerable arc on its travel toward the rail, and takes a more direct route on the way back. From the ball tosser's viewpoint, the ball seems to return more quickly than it went (because the tosser is rotating toward the ball on the return flight).\n\nOn the carousel, instead of tossing the ball straight at a rail to bounce back, the tosser must throw the ball toward the right of the target and the ball then seems to the camera to bear continuously to the left of its direction of travel to hit the rail (\"left\" because the carousel is turning \"clockwise\"). The ball appears to bear to the left from direction of travel on both inward and return trajectories. The curved path demands this observer to recognize a leftward net force on the ball. (This force is \"fictitious\" because it disappears for a stationary observer, as is discussed shortly.) For some angles of launch, a path has portions where the trajectory is approximately radial, and Coriolis force is primarily responsible for the apparent deflection of the ball (centrifugal force is radial from the center of rotation, and causes little deflection on these segments). When a path curves away from radial, however, centrifugal force contributes significantly to deflection.\n\nThe ball's path through the air is straight when viewed by observers standing on the ground (right panel). In the right panel (stationary observer), the ball tosser (smiley face) is at 12 o'clock and the rail the ball bounces from is at position one (1). From the inertial viewer's standpoint, positions one (1), two (2), three (3) are occupied in sequence. At position 2 the ball strikes the rail, and at position 3 the ball returns to the tosser. Straight-line paths are followed because the ball is in free flight, so this observer requires that no net force is applied.\n\nAn important case where the Coriolis force is observed involves the rotating Earth together with its atmosphere. The atmosphere rotates in sync with the surface of the earth due to frictional forces between the air molecules of the atmosphere (air viscosity) and the earth's surface which causes the air molecules to be carried along and move in step with the earth's surface. Unless otherwise stated, directions of forces and motion apply to the Northern Hemisphere.\n\nAs the Earth turns around its axis, everything attached to it, including the atmosphere, turns with it (imperceptibly to our senses). An object that is moving without being dragged along with the surface rotation or atmosphere such as an object in ballistic flight or an independent air mass within the atmosphere, travels in a straight motion over the turning Earth. From our rotating perspective on the planet, the direction of motion of an object in ballistic flight changes as it moves, bending in the opposite direction to our actual motion. When viewed from a stationary point in space directly above the north pole, any land feature in the Northern Hemisphere turns anticlockwise—and, fixing our gaze on that location, any other location in that hemisphere rotates around it the same way. The traced ground path of a freely moving body in ballistic flight traveling from one point to another therefore bends the opposite way, clockwise, which is conventionally labeled as \"right,\" where it will be if the direction of motion is considered \"ahead,\" and \"down\" is defined naturally.\n\nConsider a location with latitude \"φ\" on a sphere that is rotating around the north-south axis. A local coordinate system is set up with the \"x\" axis horizontally due east, the \"y\" axis horizontally due north and the \"z\" axis vertically upwards. The rotation vector, velocity of movement and Coriolis acceleration expressed in this local coordinate system (listing components in the order east (\"e\"), north (\"n\") and upward (\"u\")) are:\n\nWhen considering atmospheric or oceanic dynamics, the vertical velocity is small, and the vertical component of the Coriolis acceleration is small compared to gravity. For such cases, only the horizontal (east and north) components matter. The restriction of the above to the horizontal plane is (setting \"v\" = 0):\n\nwhere formula_8 is called the Coriolis parameter.\n\nBy setting \"v\" = 0, it can be seen immediately that (for positive φ and ω) a movement due east results in an acceleration due south. Similarly, setting \"v\" = 0, it is seen that a movement due north results in an acceleration due east. In general, observed horizontally, looking along the direction of the movement causing the acceleration, the acceleration always is turned 90° to the right and of the same size regardless of the horizontal orientation.\n\nAs a different case, consider equatorial motion setting φ = 0°. In this case, Ω is parallel to the north or \"n\"-axis, and:\n\nAccordingly, an eastward motion (that is, in the same direction as the rotation of the sphere) provides an upward acceleration known as the Eötvös effect, and an upward motion produces an acceleration due west.\n\nPerhaps the most important impact of the Coriolis effect is in the large-scale dynamics of the oceans and the atmosphere. In meteorology and oceanography, it is convenient to postulate a rotating frame of reference wherein the Earth is stationary. In accommodation of that provisional postulation, the centrifugal and Coriolis forces are introduced. Their relative importance is determined by the applicable Rossby numbers. Tornadoes have high Rossby numbers, so, while tornado-associated centrifugal forces are quite substantial, Coriolis forces associated with tornadoes are for practical purposes negligible.\n\nBecause surface ocean currents are driven by the movement of wind over the water's surface, the Coriolis force also affects the movement of ocean currents and cyclones as well. Many of the ocean's largest currents circulate around warm, high-pressure areas called gyres. Though the circulation is not as significant as that in the air, the deflection caused by the Coriolis effect is what creates the spiraling pattern in these gyres. The spiraling wind pattern helps the hurricane form. The stronger the force from the Coriolis effect, the faster the wind spins and picks up additional energy, increasing the strength of the hurricane.\n\nAir within high-pressure systems rotates in a direction such that the Coriolis force is directed radially inwards, and nearly balanced by the outwardly radial pressure gradient. As a result, air travels clockwise around high pressure in the Northern Hemisphere and anticlockwise in the Southern Hemisphere. Air around low-pressure rotates in the opposite direction, so that the Coriolis force is directed radially outward and nearly balances an inwardly radial pressure gradient.\n\nIf a low-pressure area forms in the atmosphere, air tends to flow in towards it, but is deflected perpendicular to its velocity by the Coriolis force. A system of equilibrium can then establish itself creating circular movement, or a cyclonic flow. Because the Rossby number is low, the force balance is largely between the pressure-gradient force acting towards the low-pressure area and the Coriolis force acting away from the center of the low pressure.\n\nInstead of flowing down the gradient, large scale motions in the atmosphere and ocean tend to occur perpendicular to the pressure gradient. This is known as geostrophic flow. On a non-rotating planet, fluid would flow along the straightest possible line, quickly eliminating pressure gradients. Note that the geostrophic balance is thus very different from the case of \"inertial motions\" (see below), which explains why mid-latitude cyclones are larger by an order of magnitude than inertial circle flow would be.\n\nThis pattern of deflection, and the direction of movement, is called Buys-Ballot's law. In the atmosphere, the pattern of flow is called a cyclone. In the Northern Hemisphere the direction of movement around a low-pressure area is anticlockwise. In the Southern Hemisphere, the direction of movement is clockwise because the rotational dynamics is a mirror image there. At high altitudes, outward-spreading air rotates in the opposite direction. Cyclones rarely form along the equator due to the weak Coriolis effect present in this region.\n\nAn air or water mass moving with speed formula_28 subject only to the Coriolis force travels in a circular trajectory called an 'inertial circle'. Since the force is directed at right angles to the motion of the particle, it moves with a constant speed around a circle whose radius formula_29 is given by:\n\nwhere formula_31 is the Coriolis parameter formula_32, introduced above (where formula_33 is the latitude). The time taken for the mass to complete a full circle is therefore formula_34. The Coriolis parameter typically has a mid-latitude value of about 10 s; hence for a typical atmospheric speed of the radius is , with a period of about 17 hours. For an ocean current with a typical speed of , the radius of an inertial circle is . These inertial circles are clockwise in the Northern Hemisphere (where trajectories are bent to the right) and anticlockwise in the Southern Hemisphere.\n\nIf the rotating system is a parabolic turntable, then formula_31 is constant and the trajectories are exact circles. On a rotating planet, formula_31 varies with latitude and the paths of particles do not form exact circles. Since the parameter formula_31 varies as the sine of the latitude, the radius of the oscillations associated with a given speed are smallest at the poles (latitude = ±90°), and increase toward the equator.\n\nThe Coriolis effect strongly affects the large-scale oceanic and atmospheric circulation, leading to the formation of robust features like jet streams and western boundary currents. Such features are in geostrophic balance, meaning that the Coriolis and \"pressure gradient\" forces balance each other. Coriolis acceleration is also responsible for the propagation of many types of waves in the ocean and atmosphere, including Rossby waves and Kelvin waves. It is also instrumental in the so-called Ekman dynamics in the ocean, and in the establishment of the large-scale ocean flow pattern called the Sverdrup balance.\n\nThe practical impact of the \"Coriolis effect\" is mostly caused by the horizontal acceleration component produced by horizontal motion.\n\nThere are other components of the Coriolis effect. Westward-travelling objects are deflected downwards (feel heavier), while Eastward-travelling objects are deflected upwards (feel lighter). This is known as the Eötvös effect. This aspect of the Coriolis effect is greatest near the equator. The force produced by this effect is similar to the horizontal component, but the much larger vertical forces due to gravity and pressure mean that it is generally unimportant dynamically.\n\nIn addition, objects travelling upwards (\"i.e.\", out) or downwards (\"i.e.\", in) are deflected to the west or east respectively. This effect is also the greatest near the equator. Since vertical movement is usually of limited extent and duration, the size of the effect is smaller and requires precise instruments to detect. However, in the case of large changes of momentum, such as a spacecraft being launched into orbit, the effect becomes significant. The fastest and most fuel-efficient path to orbit is a launch from the equator that curves to a directly eastward heading.\n\nImagine a train that travels through a frictionless railway line along the equator. Assume that, when in motion, it moves at the necessary speed to complete a trip around the world in one day (465 m/s). The Coriolis effect can be considered in three cases: when the train travels west, when it is at rest, and when it travels east. In each case, the Coriolis effect can be calculated from the rotating frame of reference on Earth first, and then checked against a fixed inertial frame. The image below illustrates the three cases as viewed by an observer at rest in a (near) inertial frame from a fixed point above the North Pole along the Earth's axis of rotation; the train are a few red pixels, fixed at the left side in the leftmost picture, moving in the others formula_38\n\nThis also explains why high speed projectiles that travel west are deflected down, and those that travel east are deflected up. This vertical component of the Coriolis effect is called the Eötvös effect.\n\nThe above example can be used to explain why the Eötvös effect starts diminishing when an object is travelling westward as its tangential speed increases above Earth's rotation (465 m/s). If the westward train in the above example increases speed, part of the force of gravity that pushes against the track accounts for the centripetal force needed to keep it in circular motion on the inertial frame. Once the train doubles its westward speed at 930 m/s that centripetal force becomes equal to the force the train experiences when it stops. From the inertial frame, in both cases it rotates at the same speed but in the opposite directions. Thus, the force is the same cancelling completely the Eötvös effect. Any object that moves westward at a speed above 930 m/s experiences an upward force instead. In the figure, the Eötvös effect is illustrated for a 10 kilogram object on the train at different speeds. The parabolic shape is because the centripetal force is proportional to the square of the tangential speed. On the inertial frame, the bottom of the parabola is centered at the origin. The offset is because this argument uses the Earth's rotating frame of reference. The graph shows that the Eötvös effect is not symmetrical, and that the resulting downward force experienced by an object that travels west at high velocity is less than the resulting upward force when it travels east at the same speed.\n\nContrary to popular misconception, water rotation in home bathrooms under \"normal\" circumstances is not related to the Coriolis effect or to the rotation of the Earth, and no consistent difference in rotation direction between toilet drainage in the Northern and Southern Hemispheres can be observed. The formation of a vortex over the plug hole may be explained by the conservation of angular momentum: The radius of rotation decreases as water approaches the plug hole, so the rate of rotation increases, for the same reason that an ice skater's rate of spin increases as they pull their arms in. Any rotation around the plug hole that is initially present accelerates as water moves inward.\n\nThe Coriolis force still affects the direction of the flow of water, but only minutely. Only if the water is so still that the effective rotation rate of the Earth is faster than that of the water relative to its container, and if externally applied torques (such as might be caused by flow over an uneven bottom surface) are small enough, the Coriolis effect may indeed determine the direction of the vortex. Without such careful preparation, the Coriolis effect is likely to be much smaller than various other influences on drain direction such as any residual rotation of the water and the geometry of the container. Despite this, the idea that toilets and bathtubs drain differently in the Northern and Southern Hemispheres has been popularized by several television programs and films, including \"Escape Plan\", \"Wedding Crashers\", \"The Simpsons\" episode \"Bart vs. Australia\", \"Pole to Pole\", and \"The X-Files\" episode \"Die Hand Die Verletzt\". Several science broadcasts and publications, including at least one college-level physics textbook, have also stated this.\n\nIn 1908, the Austrian physicist Ottokar Tumlirz described careful and effective experiments that demonstrated the effect of the rotation of the Earth on the outflow of water through a central aperture. The subject was later popularized in a famous 1962 article in the journal \"Nature\", which described an experiment in which all other forces to the system were removed by filling a tank with of water and allowing it to settle for 24 hours (to allow any movement due to filling the tank to die away), in a room where the temperature had stabilized. The drain plug was then very slowly removed, and tiny pieces of floating wood were used to observe rotation. During the first 12 to 15 minutes, no rotation was observed. Then, a vortex appeared and consistently began to rotate in an anticlockwise direction (the experiment was performed in Boston, Massachusetts, in the Northern Hemisphere). This was repeated and the results averaged to make sure the effect was real. The report noted that the vortex rotated, \"about 30,000 times faster than the effective rotation of the Earth in 42° North (the experiment's location)\". This shows that the small initial rotation due to the Earth is amplified by gravitational draining and conservation of angular momentum to become a rapid vortex and may be observed under carefully controlled laboratory conditions.\n\nThe Coriolis force is important in external ballistics for calculating the trajectories of very long-range artillery shells. The most famous historical example was the Paris gun, used by the Germans during World War I to bombard Paris from a range of about . The Coriolis force minutely changes the trajectory of a bullet, affecting accuracy at extremely long distances. It is adjusted for by accurate long-distance shooters, such as snipers. At the latitude of Sacramento a 1000 yard shot would be deflected 3 inches to the right. There is also a vertical component, explained in the Eötvös effect section above, which causes westward shots to hit low, and eastward shots to hit high.\n\nThe effects of the Coriolis force on ballistic trajectories should not be confused with the curvature of the paths of missiles, satellites, and similar objects when the paths are plotted on two-dimensional (flat) maps, such as the Mercator projection. The projections of the three-dimensional curved surface of the Earth to a two-dimensional surface (the map) necessarily results in distorted features. The apparent curvature of the path is a consequence of the sphericity of the Earth and would occur even in a non-rotating frame.\n\nTo demonstrate the Coriolis effect, a parabolic turntable can be used.\nOn a flat turntable, the inertia of a co-rotating object forces it off the edge. However, if the turntable surface has the correct paraboloid (parabolic bowl) shape (see the figure) and rotates at the corresponding rate, the force components shown in the figure make the component of gravity tangential to the bowl surface exactly equal to the centripetal force necessary to keep the object rotating at its velocity and radius of curvature (assuming no friction). (See .) This carefully contoured surface allows the Coriolis force to be displayed in isolation.\n\nDiscs cut from cylinders of dry ice can be used as pucks, moving around almost frictionlessly over the surface of the parabolic turntable, allowing effects of Coriolis on dynamic phenomena to show themselves. To get a view of the motions as seen from the reference frame rotating with the turntable, a video camera is attached to the turntable so as to co-rotate with the turntable, with results as shown in the figure. In the left panel of the figure, which is the viewpoint of a stationary observer, the gravitational force in the inertial frame pulling the object toward the center (bottom ) of the dish is proportional to the distance of the object from the center. A centripetal force of this form causes the elliptical motion. In the right panel, which shows the viewpoint of the rotating frame, the inward gravitational force in the rotating frame (the same force as in the inertial frame) is balanced by the outward centrifugal force (present only in the rotating frame). With these two forces balanced, in the rotating frame the only unbalanced force is Coriolis (also present only in the rotating frame), and the motion is an \"inertial circle\". Analysis and observation of circular motion in the rotating frame is a simplification compared to analysis or observation of elliptical motion in the inertial frame.\n\nBecause this reference frame rotates several times a minute rather than only once a day like the Earth, the Coriolis acceleration produced is many times larger and so easier to observe on small time and spatial scales than is the Coriolis acceleration caused by the rotation of the Earth.\n\nIn a manner of speaking, the Earth is analogous to such a turntable. The rotation has caused the planet to settle on a spheroid shape, such that the normal force, the gravitational force and the centrifugal force exactly balance each other on a \"horizontal\" surface. (See equatorial bulge.)\n\nThe Coriolis effect caused by the rotation of the Earth can be seen indirectly through the motion of a Foucault pendulum.\n\nA practical application of the Coriolis effect is the mass flow meter, an instrument that measures the mass flow rate and density of a fluid flowing through a tube. The operating principle involves inducing a vibration of the tube through which the fluid passes. The vibration, though not completely circular, provides the rotating reference frame that gives rise to the Coriolis effect. While specific methods vary according to the design of the flow meter, sensors monitor and analyze changes in frequency, phase shift, and amplitude of the vibrating flow tubes. The changes observed represent the mass flow rate and density of the fluid.\n\nIn polyatomic molecules, the molecule motion can be described by a rigid body rotation and internal vibration of atoms about their equilibrium position. As a result of the vibrations of the atoms, the atoms are in motion relative to the rotating coordinate system of the molecule. Coriolis effects are therefore present, and make the atoms move in a direction perpendicular to the original oscillations. This leads to a mixing in molecular spectra between the rotational and vibrational levels, from which Coriolis coupling constants can be determined.\n\nWhen an external torque is applied to a spinning gyroscope along an axis that is at right angles to the spin axis, the rim velocity that is associated with the spin becomes radially directed in relation to the external torque axis. This causes a Coriolis force to act on the rim in such a way as to tilt the gyroscope at right angles to the direction that the external torque would have tilted it. This tendency has the effect of keeping spinning bodies stably aligned in space.\n\nFlies (Diptera) and some moths (Lepidoptera) exploit the Coriolis effect in flight with specialized appendages and organs that relay information about the angular velocity of their bodies.\n\nCoriolis forces resulting from linear motion of these appendages are detected within the rotating frame of reference of the insects' bodies. In the case of flies, their specialized appendages are dumbbell shaped organs located just behind their wings called \"halteres\".\n\nThe fly's halteres oscillate in a plane at the same beat frequency as the main wings so that any body rotation results in lateral deviation of the halteres from their plane of motion.\n\nIn moths, their antennae are known to be responsible for the \"sensing\" of Coriolis forces in the similar manner as with the halteres in flies. In both flies and moths, a collection of mechanosensors at the base of the appendage are sensitive to deviations at the beat frequency, correlating to rotation in the pitch and roll planes, and at twice the beat frequency, correlating to rotation in the yaw plane.\n\nIn astronomy, Lagrangian points are five positions in the orbital plane of two large orbiting bodies where a small object affected only by gravity can maintain a stable position relative to the two large bodies. The first three Lagrangian points (L, L, L) lie along the line connecting the two large bodies, while the last two points (L and L) each form an equilateral triangle with the two large bodies. The L and L points, although they correspond to maxima of the effective potential in the coordinate frame that rotates with the two large bodies, are stable due to the Coriolis effect. The stability can result in orbits around just L or L, known as tadpole orbits, where trojans can be found. It can also result in orbits that encircle L, L, and L, known as horseshoe orbits.\n\n"}
{"id": "19446271", "url": "https://en.wikipedia.org/wiki?curid=19446271", "title": "Dismal Swamp State Park", "text": "Dismal Swamp State Park\n\nDismal Swamp State Park is a North Carolina state park in Camden County, North Carolina in the United States. The park was created as a state natural area in 1974 with the help of The Nature Conservancy, and on July 28, 2007 the NC General Assembly re-designated it as a state park. It opened to the public in 2008. This marked the first time that public access to Great Dismal Swamp was made possible in North Carolina. The park covers of protected land on the North Carolina/Virginia border. Park offices are three miles (5 km) south of the border on U.S. Route 17 near South Mills. Features of the park include the canal which is used regularly by boaters using the Intracoastal Waterway and several miles of hiking and biking trails.\n\nBy 1650, few American Indians remained in the Great Dismal Swamp area, and European settlers showed little interest in the swamp. In 1665, William Drummond, future governor of North Carolina, was the first European to explore the lake which now bears his name. William Byrd II led a surveying party into the swamp to draw a dividing line between Virginia and North Carolina in 1728. George Washington visited the swamp and called it a \"glorious paradise\". He then formed the Dismal Swamp Land Company in 1763, which proceeded to drain and harvest timber from part of the area. A five-mile (8 km) ditch on the west side of the current refuge still bears his name. In 1805, the Dismal Swamp Canal began serving as a commercial highway for timber coming out of the swamp.\n\nBefore and during the American Civil War, the Great Dismal Swamp was a hideout for runaway slaves from the surrounding area. Recent research showed that thousands of Great Dismal Swamp maroons lived in the swamp between the 1600s and 1865. Harriet Beecher Stowe's \"\" is based on them.\n\nWhile all efforts to drain the swamp failed, logging of the swamp proved to be a successful commercial activity. Logging operations continued as late as 1976. The entire swamp has been logged at least once, and many areas have been burned by periodic wildfires. Agricultural, commercial, and residential development destroyed much of the swamp, so that the remaining portion within and around the refuge represents less than half of the original size of the swamp.\n\nBefore the refuge was established, over of roads were constructed to provide access to the timber. These roads disrupted the swamp's natural hydrology, as the ditches which were dug to provide soil for the road beds drained water from the swamp. The roads also blocked the flow of water across the swamp's surface, flooding some areas of the swamp with stagnant water. The logging operations removed natural stands of bald cypress and Atlantic white cypress that were replaced by other forest types, particularly red maple. A drier swamp and the suppression of wildfires, which once cleared the land for seed germination, created ecological conditions that were less favorable to the survival of cypress stands. As a result, plant and animal variety decreased.\n\nDismal Swamp State Park opened in 2008. It is accessed via a floating bridge over the Dismal Swamp Canal. This is the only public access to the park's visitor's center, other than boat launches along the canal. Hiking and biking trails have opened and additional trails are under construction.\n\nDismal Swamp State Park is much drier than it was in the past. The efforts of man in the last 200 years to drain the swamp have left it drastically altered. Ditches and logging trails have cut off the normal flow of the swamp and created a series of stagnant pools and patches of dry land where continuously water covered swamps once stood. The trees of the area have changed from various types of cypress and other water loving plants to red maple and white cedar.\n\nThe white cedar thrives in the peat that is common in the area. These trees provide a habitat for several rare species. Hessel's hairstreak a species of butterfly that is dependent on the white cedar has been spotted at the park. Black-throated green warblers make their nests in the white cedars.\n\nThe drained swamp lands have converted to hardwood forests of red maple, black walnut, pawpaw and several species of oak. White-tailed deer, wild turkey, bobwhite and marsh rabbits live in the areas along the trails. Blackberry and blueberry patches line the trails. These berries attract a large number of American black bears to the area. Other common animals include the raccoon, opossum and gray fox as well as the occasional bobcat.\n\nButterflies are plentiful at Dismal Swamp State Park. Forty-three species have been found in the park, including large numbers of palamedes, zebra swallowtails, tiger swallowtails and Atlantic holly azures. Several varieties of warbler and vireo are common. Woodpeckers and hawks nest here as do barred owls.\n\nDismal Swamp State Park is open for year-round recreation. Dismal Swamp Canal is open to canoes and kayaks. A boat ramp at the park provides access to the canal. There are of logging trails open to hiking and mountain biking through swamp forests. Park rangers host environmental education and interpretive events. The visitor center is accessed from a floating bridge across the canal.\n\n"}
{"id": "26969915", "url": "https://en.wikipedia.org/wiki?curid=26969915", "title": "Einasleigh Uplands", "text": "Einasleigh Uplands\n\nThe Einasleigh Uplands is an interim Australian bioregion, with vegetation consisting of savanna and woodland located on a large plateau in inland Queensland, Australia.\n\nThe uplands are an area of eroded volcanic rock on and to the west of the Atherton Tableland in the northern section of Australia's Great Dividing Range running inland as far as the town of Croydon in the southwest. The plateau is covered in grassland dotted with eucalyptus trees and cut through with ridges, gorges and lava tubes. The area has rich fertile soil. Natural features include the Great Basalt Wall of dried volcanic lava and the lava tubes of Undara Volcanic National Park.\n\nThe climate is cooler than the coast with summer nights being as cool as 9 °C compared with 20 °C on the coast. The summer high temperatures are around 35 °C. There is a wet season between December and March.\n\nRivers that have their source in the uplands include the Flinders River which runs northwest to the Gulf of Carpentaria along with the Palmer, Mitchell and Gilbert-Einasleigh while the Burdekin and Herbert Rivers run south-east from the tablelands to the Coral Sea coast. \n\nUrban areas include Herberton and Croydon.\n\nEinasleigh Uplands is the name given to this area in the Interim Biogeographic Regionalisation for Australia survey of different ecosystems in the country, while in the World Wildlife Fund's bioregion mapping they are described as Einasleigh Upland Savanna. These descriptions are based on study of the climate, plant life and terrain compared with neighbouring areas. This area is inland from the moist Queensland coast but is not as dry as the Brigalow Belt and the Mitchell Grass savannas south, while the Cape York Peninsula to the north is lower-lying and wetter. The region contains a number of specialised habitats that add to the variety of wildlife found here. These include lava flows and caves such as those of Chillagoe.\n\nThis stony upland habitat is dominated by ironbark eucalyptus woodland but there are wetlands and patches of rainforest too. Lava flows are home to stands of thicker forest.\n\nThese woodlands are home to many animals including a number of marsupials such as the antilopine kangaroo, the large eastern grey kangaroo and the near-endemic Godman's rock-wallaby and Mareeba rock-wallaby. There are a number of endemic mammals, reptiles and insects in the region especially in the more thickly forested areas where a large number of endemic reptiles occur. The caves and lava flows harbour specific wildlife of their own as do the wetter east-facing slopes of the uplands. Rivers such as the Burdekin have important populations of waterbirds as do the unique (to Australia) wetlands of Innot Hot springs.\n\nThe area has long been used for cattle ranching but apart from the heavily farmed Atherton Tableland is thinly populated so the landscape is well preserved although it has been changed by overgrazing, clearance for agriculture and the introduction of weeds. Some areas of the acacia gidgee \"(Acacia cambagei)\" in the southeast of the uplands have suffered in particular. There are a number of protected areas containing a good variety of the different types of habitat found in the region, including Undara and the Great Basalt Wall as well as part of Bulleringa National Park and the caves of Chillagoe.\n"}
{"id": "6920790", "url": "https://en.wikipedia.org/wiki?curid=6920790", "title": "FIBA World Rankings", "text": "FIBA World Rankings\n\nThe FIBA World Rankings or NIKE-FIBA World Rankings are FIBA's rankings of national basketball teams. FIBA ranks men's and women's national teams in both senior and junior competitions. It also publishes combined rankings for all competitions involving both sexes.\n\nNot included are rankings for 3x3, which are tabulated for individual players.\n\nOnly FIBA tournaments for full five-a-side teams are used in calculations for the tournaments. Other tournaments, such as regional championships, invitationals, and friendlies are not included. Also not counted are tournaments in FIBA's official competition for three-on-three halfcourt basketball, 3x3.\n\nIn 2017, FIBA radically changed its ranking system for men's national teams, switching from the previous competition-based system to a game-based system. Every game played by a national team within the prior 8 years in the World Cup, Olympics, continental championships, and qualifiers for these events figures into the calculations. Until the Olympic Games 2016 the Olympic game and the men's world championship, gave identical score for being a world champion and Olympic, but since the new FIBA score emerged in 2017 these two tournaments devalued the score, passing from 5 points play an Olympic and world championship as it was until 2016, to award 2.5 points for playing a world championship, and 2 points for playing an Olympic game of basketball since 2017. Therefore, both tournaments will not grant a differential score with respect to others tournaments of National Teams, as they did in the past where there was no difference in points in the ranking for being world champion or Olympic, but if there was much difference until 2016 in fiba ranking points between these two tournaments and the rest of the competitions fiba as the continental tournaments. In the women will continue maintaining the score of 5 points for playing an Olympic or world game. But since 2017 will no longer keep the same score men.\n\nEach game in a ranking tournament is initially valued at 1,000 basis points, divided between the two teams as follows:\n\nThe basis points are adjusted based on the site of the game, with FIBA calling this adjustment home/away points. During the finals of ranking tournaments, only games played by a host team in its own country count as \"home\" games; all others are treated as neutral-site games. Adjustments are:\n\n\nThe basis points are also adjusted to reflect the strength of the opponent. FIBA determines what it calls opposition ranking points by the following formula:\n\n\nA team's final rating points for a particular game is the sum of basis, home/away, and opposition ranking points.\n\nThe new calculations still account for the specific tournament and region, as in the former procedure, but no longer explicitly consider a team's final tournament placement.\n\nIn a new feature, a time decay factor has been introduced into the calculations. More recent games carry the greatest weight, steadily declining until falling out of the calculations after 8 years:\n\nRegional weighting remains in the system, though the specific factors vary from those used in the past men's rankings: Until the men Olympic Games 2016, the Olympic games and the men's world championship gave identical score for being a world champion and Olympic, but since the new FIBA rakning fiba emerged in 2017 these two tournaments devalued the score, passing from 5 points play an Olympic and world championship as it was until 2016, to award 2.5 points for playing a world championship, and 2 points for playing an Olympic game of basketball since 2017. Therefore, both tournaments will not grant a differential score with respect to others tournaments of national teams, as they did in the past where there was no difference in points in the ranking for being world champion or Olympic, but if there was much difference until 2016 in fiba ranking points between these two tournaments, and the rest of the competitions fiba as the continental tournaments. In the women will continue maintaining the score of 5 points for playing an Olympic or world championship. but since 2017 will no longer keep the same ranking men.\n\nFIBA uses a weighted arithmetic mean to determine the statistical weight of each of the tournaments. Each event is assigned point weight that is based partly on how competitive the tournament is and partly on which national teams are participating:. There were constant changes in the system of the FIBA ranking, but it can be seen that until 2016 the FIBA world championship and the games awarded the same points in the FIBA ranking, therefore the FIBA world championship and the Olympic basketball games had the same value. Therefore, for those years the World Cup and the Olympic tournament had the same prestige according to the ranking of those years. In the year 2017, according to the ranking system in the FIBA ranking, published on October 11, 2017 for the first time in history, the FIBA world championship awards more points than the Olympic tournament: 2.5 points the world championship, against 2 points the olympics games. For all this the FIBA 2019 world championship will be the first more prestigious championship than an Olympic basketball, given that it will be worth 2.5 points and the Olympic 2020, 2 points.\n\nThe 2017 FIBA ranking started on October 11, 2017. Since that date, the FIBA World Cup is worth 2.5 and the Olympic Games 2 points, although the new ranking published on October 11, 2017 is not applicable to the tournaments played until 2016, given that both tournaments they maintain the same score (5 each one).\n\nIn the future, the World Cup will be worth 2.5 points and the Olympic basketball tournament 2 points, therefore in 2019 for the first time in history the FIBA World Cup will give more points than an Olympic basketball game.\n\nIn addition to the qualifying rounds, in Europe are also included the results of the FIBA European Championship for Small Countries.\n\nFrom 2017 forward, FIBA Asia and FIBA Oceania members compete for a single regional championship under the FIBA Asia banner. Results from the 2010–2016 period, during which FIBA Asia and FIBA Oceania held separate championships, will continue to figure into the rankings until results from 2016, the final year of separate championships in the two regions, drop from the calculations in 2025.\n\nIn a new feature, FIBA also weights game results by the competition stage.\n\nAdditionally, FIBA has added a round weighting to the system, giving each game in a final tournament (World Cup, Olympics, or continental championship) a weighting based on the round in which it takes place. Qualifying matches for these tournaments implicitly carry a round weighting of 1.0.\n\nIf a competition does not have a round of 16 and/or a quarterfinal round, the results from the rounds that are held are scaled according to the number of rounds, with the group stage remaining at a 1.0 weighting and the competition final remaining at 2.0.\n\nThe final weighting is the product of the time decay, regional, competition stage, and round weights.\n\nRankings are now updated after every individual game in a ranking tournament (including qualifiers for such tournaments).\n\nFor examples of the new ranking calculations, see this page on FIBA's official site.\n\nFIBA still uses the competition-based system to determine its women's rankings. As noted above, this system was also used to determine men's rankings prior to 2017. FIBA has announced that it will introduce a game-based ranking procedure similar to that currently used for men's rankings in the indeterminate future.\n"}
{"id": "15058693", "url": "https://en.wikipedia.org/wiki?curid=15058693", "title": "Fatih Birol", "text": "Fatih Birol\n\nFatih Birol (born 22 March 1958, in Ankara) is a Turkish economist and energy expert, who has been the Executive Director of the International Energy Agency (IEA) since 1 September 2015. He previously served as the Chief Economist and Director of Global Energy Economics at the IEA in Paris.\n\nHe is responsible for the IEA’s flagship \"World Energy Outlook\" publication, which is recognised as the most authoritative source for strategic analysis of global energy markets. He is founder and chair of the IEA Energy Business Council which provides a forum for cooperation between the energy industry and policymakers.\n\nBirol has been named by \"Forbes\" magazine among the most powerful people in terms of influence on the world’s energy scene. He is the Chairman of the World Economic Forum (Davos) Energy Advisory Board and a member of the UN Secretary-General's 'High-level Group on Sustainable Energy for All.'\n\nHe is a frequent contributor to print and electronic media and delivers numerous speeches each year at major international summits and conferences.\n\nBirol designs and directs the IEA's annual \"World Energy Outlook\". On 15 December 2008, George Monbiot, described Birol as one of the most powerful men on earth whose words are considered as the \"petroleum gospel\" by world governments. Monbiot interviewed Birol on the day the 2008 annual report was published and challenged the research conclusions regarding major changes in the global petroleum sector outlook.\n\nPaul Bulteel, Eurelectric Electricity Ambassador announced at the Eurelectric Annual Convention in Bologna on 4 June 2013, that the Eurelectric Award went to Birol for \"his outstanding contribution to improving understanding of the opportunities and challenges facing the power sector.\" Buleel added that Birol in his 'unique position\" raised awareness of power sector among policymakers, the financial community and other stakeholders. \"Under Dr Fatih Birol's direction, the IEA's World Energy Outlook has become the most authoritative source of forward-looking energy market analysis. It has drawn attention to the huge challenges that will need to be overcome to maintain electricity supply in the decades ahead. Its finding that 2.6 trillion USD needs to be invested in the EU's power sector through to 2035 has become an iconic figure for the industry. Fatih Birol has made a unique contribution to raising awareness among policymakers, the financial community and other stakeholders of the issues the power sector has to deal with\".\n\nIn an article published in Forbes magazine in 2009, T. Boone Pickens, American financier and Chairman and CEO of BP Capital, selected Birol as number four of seven most influential people in the world's energy sector. According to oil tycoon turned wind advocate Pickens, \"When he says things like, 'the world would need to find the equivalent of four times the crude oil reserves now held by Saudi Arabia to maintain current production plus six Saudi Arabias if it is to keep up with the expected increase in demand between now and 2030,' the world sits up and takes notice.\"\n\nPrior to joining the IEA as Chief Economist on 1 October 1995, Dr. Birol worked at the Organization of the Petroleum Exporting Countries (OPEC) in Vienna.\n\nA Turkish citizen, Birol was born in Ankara in 1958. He earned a BSc degree in power engineering from the Istanbul Technical University. He received his MSc and PhD in energy economics from the Technical University of Vienna. In 2013, Birol was awarded a Doctorate of Science honoris causa by Imperial College London. He was made an honorary life member of Galatasaray Football Club in 2013.\n\n"}
{"id": "47077272", "url": "https://en.wikipedia.org/wiki?curid=47077272", "title": "FlexGen Power Systems", "text": "FlexGen Power Systems\n\nFlexGen Power Systems is a United States veteran owned and operated energy storage and conversion company. The company is headquartered in Houston, Texas and was founded in 2009. The company also has locations in Durham, North Carolina and Virginia Beach, Virginia.\n\nFlexGen Power Systems is the producer of the FlexGen Solid State Generator, a hybrid power system used by drilling contractors and E&Ps in the upstream oil and gas industry.\n\nThe FlexGen Solid State Generator uses energy storage, power conversion and controls to eliminate load transients associated with diesel, dual fuel, or natural gas engines. The FlexGen Solid State Generator has shown fuel savings of 15-25% and maintenance savings of 35-45%.\n\nOriginally designed for the United States Military, these hybrid power systems have been sold to the US Marine Corps, US Army, US Navy SEALs, and the Joint Special Operations Forces-Afghanistan. Systems that were fielded in those military branches showed at least 52% reduction in fuel consumption and an 80% reduction in generator runtime.\nOn August 3, 2015, FlexGen Power Systems completed a $25.5M Series A venture capital funding round. Led by Denver-based Altira Group, the venture funding round also included investments from General Electric Ventures and Caterpillar Ventures.\n\n"}
{"id": "15643588", "url": "https://en.wikipedia.org/wiki?curid=15643588", "title": "Fuel cell bus", "text": "Fuel cell bus\n\nA fuel cell bus is a bus that uses a hydrogen fuel cell as its power source for electrically driven wheels, sometimes augmented in a hybrid fashion with batteries or a supercapacitor.\n\nSeveral companies are conducting hydrogen fuel cell research and practical fuel cell bus trials. These include:\n\nThere are also fuel cell powered buses currently active or in production, such as a fleet of Thor buses with UTC Power fuel cells in California, operated by SunLine Transit Agency.\n\nHydrogen-powered fuel-cell buses began operating in Beijing on an experimental basis in 2006. Three fuel cell buses, made by Daimler in Germany and purchased with a grant from the U.N. Development Programme, were the first fuel cell buses to enter operation in China. The technology has not gained broader use in the city because air pollution reduced the efficiency and operating life of fuel cells.\n\nThe first Brazilian hydrogen fuel cell bus prototype began operation in São Paulo during the first semester of 2009. The hydrogen bus was manufactured in Caxias do Sul, and the hydrogen fuel will be produced in São Bernardo do Campo from water through electrolysis. The programme, called \"Ônibus Brasileiro a Hidrogênio\" (Brazilian Hydrogen Autobus), includes three additional buses.\n\nThe town of Whistler in British Columbia, Canada owned and operated the largest fuel-cell bus fleet in the world, having been put in operation for the 2010 Winter Olympics. However, the costs were too high and the program halted in 2015.\n\nIn Aberdeen, Scotland, the Aberdeen Hydrogen Bus Project currently has 10 hydrogen fuel cell buses operating, the largest fleet in Europe.\n\nThe Fuel Cell Bus Club is a global cooperative effort in trial fuel cell buses. Ford began leasing E-350 shuttle buses in late 2006. It conducted some trials:\n\n\n"}
{"id": "682421", "url": "https://en.wikipedia.org/wiki?curid=682421", "title": "Galápagos (novel)", "text": "Galápagos (novel)\n\nGalápagos is the eleventh novel written by American author Kurt Vonnegut. The novel questions the merit of the human brain from an evolutionary perspective. The title is both a reference to the islands on which part of the story plays out, and a tribute to Charles Darwin on whose theory Vonnegut relies to reach his own conclusions. It was first published in 1985 by Delacorte Press.\n\n\"Galápagos\" is the story of a small band of mismatched humans who are shipwrecked on the fictional island of Santa Rosalia in the Galápagos Islands after a global financial crisis cripples the world's economy. Shortly thereafter, a disease renders all humans on Earth infertile, with the exception of the people on Santa Rosalia, making them the last specimens of humankind. Over the next million years, their descendants, the only fertile humans left on the planet, eventually evolve into a furry species resembling sea lions: though possibly still able to walk upright (it is not explicitly mentioned, but it is stated that they occasionally catch land animals), they have a snout with teeth adapted for catching fish, a streamlined skull and flipper-like hands with rudimentary fingers (described as \"nubbins\").\n\nThe story's narrator is a spirit who has been watching over humans for the last million years. This particular ghost is the immortal spirit of Leon Trotsky Trout, son of Vonnegut's recurring character Kilgore Trout. Leon is a Vietnam War veteran who is affected by the massacres in Vietnam. He goes AWOL and settles in Sweden, where he works as a shipbuilder and dies during the construction of the ship, the \"Bahía de Darwin\". This ship is used for the \"Nature Cruise of the Century\". Planned as a celebrity cruise, it was in limbo due to the economic downturn, and due to a chain of unconnected events the ship ended up allowing humans to reach and survive in the Galápagos.\n\nKilgore Trout —deceased— makes four appearances in the novel, urging his son to enter the \"blue tunnel\" that leads to the afterlife. When Leon refuses for the fourth time, Kilgore pledges that he, and the blue tunnel, will not return for one million years, which leaves Leon to observe the slow process of evolution that transforms the humans into aquatic mammals. The process begins when a Japanese woman on the island, the granddaughter of a Hiroshima survivor, gives birth to a fur-covered daughter.\n\nTrout maintains that all the sorrows of humankind were caused by \"the only true villain in my story: the oversized human brain\". Natural selection eliminates this problem, since the humans best fitted to Santa Rosalia were those who could swim best, which required a streamlined head, which in turn required a smaller brain.\n\n\nThe main storyline is told chronologically, but the author frequently mentions the outcome of future events (referring to 1986 as being one million years in the past). The most obvious example of this is the inclusion of an asterisk in front of a character's name if he or she will die before sunset.\n\nThe novel contains a large number of quotations from other authors. They are related to the story itself and are functionally inserted through Mandarax, a fictional voice translator that is also able to provide quotations from literature and history. The following authors are quoted (in order of their appearance in the book): Anne Frank, Alfred Tennyson, Rudyard Kipling, John Masefield, William Cullen Bryant, Ambrose Bierce, Lord Byron, Noble Claggett, John Greenleaf Whittier, Benjamin Franklin, John Heywood, Cesare Bonesana Beccaria, Bertolt Brecht, Saint John, Charles Dickens, Isaac Watts, William Shakespeare, Plato, Robert Browning, Jean de La Fontaine, François Rabelais, Patrick R. Chalmers, Michel de Montaigne, Joseph Conrad, George William Curtis, Samuel Butler, T. S. Eliot, A. E. Housman, Oscar Hammerstein II, Edgar Allan Poe, Charles E. Carryl, Samuel Johnson, Thomas Carlyle, Edward Lear, Henry David Thoreau, Sophocles, Robert Frost, and Charles Darwin.\n\nIn 2009, Audible.com produced an audio version of \"Galápagos\", narrated by Jonathan Davis, as part of its \"Modern Vanguard\" line of audiobooks.\n\nIn 2014, artists Tucker Marder and Christian Scheider adapted \"Galápagos\" into a live theatrical performance at the new Parrish Art Museum in Watermill, N.Y. Endorsed by the Kurt Vonnegut Estate, the multi-media production featured 26 performers including Bob Balaban; live orchestral underscoring composed and conducted by Forrest Gray featuring Max Feldschuh on vibraphone and Ken Sacks on mbira; animal costumes by Isla Hansen; a three-story scenic design by Shelby Jackson; experimental video projections by James Bayard; and choreography by Matt Davies.\n\n"}
{"id": "1352347", "url": "https://en.wikipedia.org/wiki?curid=1352347", "title": "Gas holder", "text": "Gas holder\n\nA gas holder, or gasometer, is a large container in which natural gas or town gas is stored near atmospheric pressure at ambient temperatures. The volume of the container follows the quantity of stored gas, with pressure coming from the weight of a movable cap. Typical volumes for large gas holders are about , with diameter structures. \n\nGas holders now tend to be used for balancing purposes, to ensure gas pipes can be operated within a safe range of pressures, rather than for actually storing gas for later use.\n\nAntoine Lavoisier devised the gazomètre to assist his work in pneumatic chemistry . These enabled him to weigh the gas in a pneumatic trough with the precision he required. He published his \"Traité Élémentaire de Chimie\" in 1789.\n\nJames Watt Junior had collaborated with Thomas Beddoes in constructing the pneumatic apparatus, a short lived piece of medical equipment that incorporated a gazomètre. He then adapted the gazomètre for coal gas storage. The anglicisation \"gasometer\" was adopted by William Murdoch, the inventor of gas lighting, in 1782, as the name for his gas holders. \n\nDespite the objections of Murdoch's associates that his so-called \"gasometer\" was not a meter but a container, the name was retained and came into general use. The term \"gasometer\" is discouraged for use in technical circles, where the term \"gas holder\" is preferred. The British Ordnance Survey have marked gas holders on their large-scale maps- calling them gasometers. This became used to label gas works, where there usually are several gas holders.\n\nThe spelling \"gas holder\" is used by the BBC, though the variant \"gasholder\" is commonly used by other publishers.\nThe meter used to measure the flow of gas through a particular pipe is a gas meter.\n\nBefore the mid-20th century, coal gas was produced in retorts by heating coal in the absence of air, the process being known as coal gasification. This was first used for municipal lighting; the gas passed through wooden or metal pipes from the retort to the lantern. The first public piped gas supply was to 13 gas lamps, installed along the length of Pall Mall, London in 1807. The credit for this goes to the German inventor and entrepreneur Fredrick Winsor. Digging up streets to lay pipes required legislation, and this delayed the roll-out of street lighting and the installation of gas for domestic illumination, heating, and cooking.\n\nMany people had experimented with coal distillation to produce a flammable gas. For instance Jean Tardin (1618), Clayton (1684) Jean-Pierre Minckelers, Leuven (1785) and Pickel (D)(1786). William Murdoch was successful. He had joined Boulton and Watt, at the Soho manufactory, Birmingham, in 1777, and in 1792 he built a retort to heat coal that produced gas that illuminated his home and office in Redruth. The system, however, lacked a storage method. James Watt Junior adapted a Lavoisier gazomètre for this purpose. A gasometer was incorporated into the first small gasworks built for the Soho manufactory in 1798.\n\nWilliam Murdoch and his pupil Samuel Clegg installed retorts in individual factories and work places. The earliest example was in 1805, at Lee and Phillips, Salford Twist Mill where 8 gas holders were installed. This was shortly followed by one in Sowerby Bridge, constructed by Clegg for Henry Lodge. The first independent commercial gas works was built by the London and Westminster Gas Light and Coke Company in Great Peter Street, Westminster in 1812 laying wooden pipes to illuminate Westminster Bridge with gas lights on New Year's Eve in 1813. Public gas lights were seen as a crime reduction measure, and as such, and until the 1840s, regulation lay with the Police Authority rather than the elected council.\n\nSafety concerns expressed by the Royal Society, limited the size of gas holders to and saw them being enclosed in gasometer houses. This concern proved unfounded, and any small leak from an enclosed gas holder created a potentially explosive buildup of air and gas within the building, a far greater danger, and the practice discontinued. In the United States, however, where the gas needed to be protected from extreme weather, gasometer houses continued to be built and were architecturally decorative.\n\nBy the 1850s, every small to medium-sized town and city had a gas plant to provide for street lighting. Private customers could also have piped lines to their houses. By this era, gas lighting became accepted. The advent of incandescent gas lighting in factories, homes and in the streets, replacing oil lamps and candles with steady clear light, almost matching daylight in its colour, turned night into day for many—making night shift work possible in industries where light was all important—in spinning, weaving and making up garments etc. Gas works were built in almost every town, main streets were brightly illuminated and gas was piped in the streets to the majority of urban households.\nThe telescopic gas holder was first invented as early as 1824, the cup and dip (grip) seal was patented by Hutchinson in 1833 :the first working example was built in Leeds. The benefits of the greatly increased storage the holders provided for local gas works were soon appreciated, and gas holders were built all around the country in great quantities from the middle of the century. The first were the two-lift, column supported type: later they could have four lifts being frame-guided and be retrofitted with an additional flying lift. The large gas holders at King's Cross were built in the 1860s to provide gas storage for a large part of London.\n\nWilliam Gadd of Gadd & Mason, from Manchester invented the spirally-guided gas holder in 1890. Instead of the use of external columns or guide frames, his design operated with spiral rails. The first commercial design was built in Northwich, Cheshire in the same year. By the end of the century, most towns in Britain had their own gas works and gas holders.\n\nThe inter-war years were marked by the development of improvements in storage, especially the waterless gas holder, and in distribution, with the advent of 2- to 4-inch steel pipes to convey gas at up to as feeder mains to the traditional cast-iron pipes. Municipal gas works became superfluous in the latter 20th century, but gas holders and production plant was still in use in steel works in 2016.\n\nA gas holder provided storage for the purified, metered gas. It acted as a buffer, removing the need for continuous gas production. The weight of the gas holder lift (cap) controlled the pressure of the gas in the mains, and provided back pressure for the gas-making plant.\n\nA watered gas holder consisted of two parts: a deep tank of water that was used to provide a seal, and a vessel that rose above the water as the gas volume increased. \n\nThere are two basic types of gas holder: the water-sealed and the rigid waterless.\n\nThe water-sealed gas holder consists of a tank of water with a closed vessel (the lift) that rises and falls to take the gas.\n\nRigid waterless gas holders were a very early design that neither expanded or contracted. There are modern versions of the waterless gas holder, e.g. oil-sealed, grease-sealed and \"dry seal\" (membrane) types. They consist of a fixed cylinder capped by a moving piston.\n\nThe earliest Boulton and Watt gas holders had a single lift. The tank was above ground and was lined with wood; the lift was guided by tripods and cables. Pulleys and weights were supplied to regulate the gas pressure. Brick tanks were introduced in 1818, when a gas holder would have a capacity of . The engineer John Malam devised a tank with a central rod-and-tube guide system.\n\nTelescoping holders fall into two subcategories. The earlier of the telescoping variety were column-guided variations and were built from 1824. To guide the telescoping walls, or \"lifts\", they have an external fixed frame, visible at a fixed height at all times. A refinement was the guide frame gas holder, where the heavy columns were replaced a lighter and more extensive framework. Vertical girders (standards) were intersected by horizontal girders and cross-braced. This could be bolted onto an underground or aboveground tank. The Cutler patented guide frame dispensed with the horizontal girders using diagonal triangulated framing instead. . Cable-guided gas holders, invented by Pease in 1880, had a limited use, but were useful on unstable ground where the rigid systems could buckle and jam the lift.\n\nSpiral-guided gas holders were built in the UK from 1890 until 1983. These have no frame, and each lift is guided by the one below, rotating as it goes up as dictated by helical runners. \n\nBoth telescoping types use the manometric property of water to provide a seal. The whole tank floats in a circular or annular water reservoir, held up by the roughly constant pressure of a varying volume of gas, the pressure determined by the weight of the structure, and the water providing the seal for the gas within the moving walls. Besides storing the gas, the tank's design serves to establish the pressure of the gas system. With telescoping (multiple-lift) tanks, the innermost tank has a ~1 ft wide by 2 ft high (30x60 cm) lip around the outside of the bottom edge, called a cup, which picks up water as it rises above the reservoir water level. This immediately engages a downward lip on the inner rim of the next outer lift, called a dip or grip, and as this grip sinks into the cup, it preserves the water seal as the inner tank continues to rise until the grip grounds on the cup, whereupon further injection of gas will start to raise that lift as well. Holders were built with as many as four lifts. An extra flying lift could be retrofitted into column or frame gas holders. This was an additional inner tank that extended above the standards, when the infrastructure would support the extra shear forces and weight. Though not exclusively, spiral guides were used.\n\nDry-seal gas holders have a static cylindrical shell, within which a piston rises and falls. As it moves, a grease seal, tar/oil seal or a sealing membrane which is rolled out and in from the piston keeps the gas from escaping. The MAN (\"Maschinenfabrik Augsburg-Nürnberg AG\") was introduced in 1915: it was polygonal and used a tar/oil seal. The Klonne dry seal gas holder was circular: it used a grease seal. The \"Dry-seal Wiggins gas holder\" was patented in 1952: it used a flexible curtain that was suspended from the piston. The largest low-pressure gas holders built was the Klonne gas holder built in 1938 in Gelsenkirchen. It was high and in diameter, which gave it a capacity of . There was a MAN type, built in 1934 in Chicago with a capacity of . \n\nGas holders hold a large advantage over other methods of storage. They are the only storage method which keeps the gas at district pressure (the pressure required in local gas mains). Once the District Low Pressure Switch falls, and the booster fans come on, the gas in these holders can be at homes, being used, in a very short period of time. Gas is stored in the holder throughout the day, when little gas is being used. At about 5 pm there is a great demand for gas, and the holder will come down, supplying the service area.\n\nHowever, where the distribution system is robust and contains regulators, the gas holder advantages are made redundant.\n\nThe pollution associated with gasworks and gas storage makes the land difficult to reclaim for other purposes, but some gas holders, notably in Vienna, have been converted into other uses such as living space and a shopping mall and historical archives for the city. Many sites, however, were never used for the production of 'town gas', therefore the land contamination is relatively low.\n\nGas holders have been a major part of the skylines of low-rise British cities for up to 200 years, due to their large distinctive shape and central location. They were originally used for balancing daily demand and generation of town gas. With the move to natural gas and construction of the national grid pipework, their use steadily diminished as the pipe network could both store gas under pressure, and eventually satisfy peak demand directly. London, Manchester, Sheffield, Birmingham, Leeds, Newcastle, Salisbury and Glasgow (which has the largest gasometers in the UK) are noted for having many gas holders.\n\nSome of these gas holders have become listed buildings. The gas holders behind King's Cross station in London were specially dismantled when the new Channel Tunnel Rail Link was being created, with Gas holder No 8 being re-erected on a nearby site behind St Pancras station as part of a housing development. It has been fashioned into a park. Most gas holders are no longer used, and a program of dismantling is underway to release the land for reuse.\n\nA gasworks in South Lotts, Dublin, Ireland, was converted into flats.\n\nIn the past, holder stations would have an operator living on site controlling their movement. However, with the process control systems now used on these sites, such an operator is obsolete. The tallest gasometer in Europe is tall and is located in Oberhausen.\n\nIn the U.K. as well as other European countries, a movement to preserve classic gasometers has emerged in recent years, especially after Britain's National Grid announced in 2013 their plans to tear down 76 gas holders, and soon afterwards, Southern and Scottish Gas networks announced that they would demolish 111 others. Christopher Costelloe, director of the Victorian Society, a leader in the campaign to preserve the gasometers said, “Gasometers, by their very size and structure, cannot help but become landmarks. [They] are singularly dramatic structures for all their emptiness.”\n\nGasometers are comparatively rare in the United States. The most notable of these were erected in St. Louis by the Laclede Gas Light Company in the early 20th century. These gasometers remained in use until the early first decade of the 21st century, when the last one was decommissioned and abandoned in place. The most recently used gasometer in the United States was on the southeast side of Indianapolis, but it has been demolished along with the Citizens Energy Group coke plant. Another pair of holders at the Newtown Holder Station, in Elmhurst, Queens, in New York City, was a popular landmark for traffic reporters until they were demolished in 1996 and became Elmhurst Park. The demolition of two larger \"Maspeth Tanks\" in nearby Greenpoint, Brooklyn, was described by The New York Times at length.\n\nA large MAN-type gas holder was erected just east of Baltimore, Maryland, by Koppers Inc. in 1949 and operated by Baltimore Gas and Electric for thirty-two years. The 307-foot-tall, 170-foot-diameter structure, which could hold 7 million cubic feet, was a landmark due to its unusual marking scheme, which had a red-and-white checkerboard pattern from 200 feet up. The structure was demolished in July 1984. \n\nAs of 2016, efforts were under way to save a gas holder building in Concord, New Hampshire.\n\nGasholders, though once common, have become rare in Australia. Most gasworks within the country were demolished or repurposed, and few gasometers remain because of this. A good example of a largely intact gasometer is located at the Launceston Gasworks site in Tasmania. Though the gas bell has been removed, all other components are intact. The remains of two older 1860s gasometers are also visible on site but only the foundations remain.\n\nFor many years, a huge gasholder towered over the Arden Street Oval, the home ground of the North Melbourne Football Club in the Victorian Football League. Television coverage of Australian Rules football matches played at the famous ground showed the gasholder dominating the landscape. It was demolished in late 1977/early 1978.\n\nGas more recently was stored in large underground reservoirs such as salt caverns. In modern times, however, line-packing is the preferred method.\n\nThroughout the 1960s and 1970s it was thought that gas holders could be replaced with high-pressure bullets (a cylindrical pressure vessel with hemispherical ends). However, regulations brought in meant that all new bullets must be built several miles out of towns and cities, and the security of storing large amounts of high-pressure natural gas above ground made them unpopular with local people and councils. Bullets are gradually being decommissioned. It is also possible to store natural gas in liquid form, and this is widely practised throughout the world.\n\n\n\n"}
{"id": "15066", "url": "https://en.wikipedia.org/wiki?curid=15066", "title": "Insulator (electricity)", "text": "Insulator (electricity)\n\nAn electrical insulator is a material whose internal electric charges do not flow freely; very little electric current will flow through it under the influence of an electric field. This contrasts with other materials, semiconductors and conductors, which conduct electric current more easily. The property that distinguishes an insulator is its resistivity; insulators have higher resistivity than semiconductors or conductors.\n\nA perfect insulator does not exist, because even insulators contain small numbers of mobile charges (charge carriers) which can carry current. In addition, all insulators become electrically conductive when a sufficiently large voltage is applied that the electric field tears electrons away from the atoms. This is known as the breakdown voltage of an insulator. Some materials such as glass, paper and Teflon, which have high resistivity, are very good electrical insulators. A much larger class of materials, even though they may have lower bulk resistivity, are still good enough to prevent significant current from flowing at normally used voltages, and thus are employed as insulation for electrical wiring and cables. Examples include rubber-like polymers and most plastics which can be thermoset or thermoplastic in nature.\n\nInsulators are used in electrical equipment to support and separate electrical conductors without allowing current through themselves. An insulating material used in bulk to wrap electrical cables or other equipment is called \"insulation\". The term \"insulator\" is also used more specifically to refer to insulating supports used to attach electric power distribution or transmission lines to utility poles and transmission towers. They support the weight of the suspended wires without allowing the current to flow through the tower to ground.\n\nElectrical insulation is the absence of electrical conduction. Electronic band theory (a branch of physics) says that a charge flows if states are available into which electrons can be excited. This allows electrons to gain energy and thereby move through a conductor such as a metal. If no such states are available, the material is an insulator.\n\nMost (though not all, see Mott insulator) insulators have a large band gap. This occurs because the \"valence\" band containing the highest energy electrons is full, and a large energy gap separates this band from the next band above it. There is always some voltage (called the breakdown voltage) that gives electrons enough energy to be excited into this band. Once this voltage is exceeded the material ceases being an insulator, and charge begins to pass through it. However, it is usually accompanied by physical or chemical changes that permanently degrade the material's insulating properties.\n\nMaterials that lack electron conduction are insulators if they lack other mobile charges as well. For example, if a liquid or gas contains ions, then the ions can be made to flow as an electric current, and the material is a conductor. Electrolytes and plasmas contain ions and act as conductors whether or not electron flow is involved.\n\nWhen subjected to a high enough voltage, insulators suffer from the phenomenon of electrical breakdown. When the electric field applied across an insulating substance exceeds in any location the threshold breakdown field for that substance, the insulator suddenly becomes a conductor, causing a large increase in current, an electric arc through the substance. Electrical breakdown occurs when the electric field in the material is strong enough to accelerate free charge carriers (electrons and ions, which are always present at low concentrations) to a high enough velocity to knock electrons from atoms when they strike them, ionizing the atoms. These freed electrons and ions are in turn accelerated and strike other atoms, creating more charge carriers, in a chain reaction. Rapidly the insulator becomes filled with mobile charge carriers, and its resistance drops to a low level. In a solid, the breakdown voltage is proportional to the band gap energy. When corona discharge occurs, the air in a region around a high-voltage conductor can break down and ionise without a catastrophic increase in current. However, if the region of air breakdown extends to another conductor at a different voltage it creates a conductive path between them, and a large current flows through the air, creating an \"electric arc\". Even a vacuum can suffer a sort of breakdown, but in this case the breakdown or vacuum arc involves charges ejected from the surface of metal electrodes rather than produced by the vacuum itself.\n\nIn addition, all insulators become conductors at very high temperatures as the thermal energy of the valence electrons is sufficient to put them in the conduction band.\n\nIn certain capacitors, shorts between electrodes formed due to dielectric breakdown can disappear when the applied electric field is reduced.\n\nA very flexible coating of an insulator is often applied to electric wire and cable, this is called \"insulated wire\". Wires sometimes don't use an insulating coating, just air, since a solid (e.g. plastic) coating may be impractical. However, wires that touch each other produce cross connections, short circuits, and fire hazards. In coaxial cable the center conductor must be supported exactly in the middle of the hollow shield to prevent EM wave reflections. Finally, wires that expose voltages higher than 60 V can cause human shock and electrocution hazards. Insulating coatings help to prevent all of these problems.\n\nSome wires have a mechanical covering with no voltage rating—e.g.: service-drop, welding, doorbell, thermostat wire. An insulated wire or cable has a voltage rating and a maximum conductor temperature rating. It may not have an ampacity (current-carrying capacity) rating, since this is dependent upon the surrounding environment (e.g. ambient temperature).\n\nIn electronic systems, printed circuit boards are made from epoxy plastic and fibreglass. The nonconductive boards support layers of copper foil conductors. In electronic devices, the tiny and delicate active components are embedded within nonconductive epoxy or phenolic plastics, or within baked glass or ceramic coatings.\n\nIn microelectronic components such as transistors and ICs, the silicon material is normally a conductor because of doping, but it can easily be selectively transformed into a good insulator by the application of heat and oxygen. Oxidised silicon is quartz, i.e. silicon dioxide, the primary component of glass.\n\nIn high voltage systems containing transformers and capacitors, liquid insulator oil is the typical method used for preventing arcs. The oil replaces air in spaces that must support significant voltage without electrical breakdown. Other high voltage system insulation materials include ceramic or glass wire holders, gas, vacuum, and simply placing wires far enough apart to use air as insulation.\n\nOverhead conductors for high-voltage electric power transmission are bare, and are insulated by the surrounding air. Conductors for lower voltages in distribution may have some insulation but are often bare as well. Insulating supports called \"insulators\" are required at the points where they are supported by utility poles or transmission towers. Insulators are also required where the wire enters buildings or electrical devices, such as transformers or circuit breakers, to insulate the wire from the case. These hollow insulators with a conductor inside them are called bushings.\n\nInsulators used for high-voltage power transmission are made from glass, porcelain or composite polymer materials. Porcelain insulators are made from clay, quartz or alumina and feldspar, and are covered with a smooth glaze to shed water. Insulators made from porcelain rich in alumina are used where high mechanical strength is a criterion. Porcelain has a dielectric strength of about 4–10 kV/mm. Glass has a higher dielectric strength, but it attracts condensation and the thick irregular shapes needed for insulators are difficult to cast without internal strains. Some insulator manufacturers stopped making glass insulators in the late 1960s, switching to ceramic materials.\n\nRecently, some electric utilities have begun converting to polymer composite materials for some types of insulators. These are typically composed of a central rod made of fibre reinforced plastic and an outer weathershed made of silicone rubber or ethylene propylene diene monomer rubber (EPDM). Composite insulators are less costly, lighter in weight, and have excellent hydrophobic capability. This combination makes them ideal for service in polluted areas. However, these materials do not yet have the long-term proven service life of glass and porcelain.\n\nThe electrical breakdown of an insulator due to excessive voltage can occur in one of two ways:\nMost high voltage insulators are designed with a lower flashover voltage than puncture voltage, so they flash over before they puncture, to avoid damage.\n\nDirt, pollution, salt, and particularly water on the surface of a high voltage insulator can create a conductive path across it, causing leakage currents and flashovers. The flashover voltage can be reduced by more than 50% when the insulator is wet. High voltage insulators for outdoor use are shaped to maximise the length of the leakage path along the surface from one end to the other, called the creepage length, to minimise these leakage currents. To accomplish this the surface is moulded into a series of corrugations or concentric disc shapes. These usually include one or more \"sheds\"; downward facing cup-shaped surfaces that act as umbrellas to ensure that the part of the surface leakage path under the 'cup' stays dry in wet weather. Minimum creepage distances are 20–25 mm/kV, but must be increased in high pollution or airborne sea-salt areas.\n\nThese are the common classes of insulator:\n\nPin-type insulators are unsuitable for voltages greater than about 69 kV line-to-line. Higher transmission voltages use suspension insulator strings, which can be made for any practical transmission voltage by adding insulator elements to the string.\n\nHigher voltage transmission lines usually use modular suspension insulator designs. The wires are suspended from a 'string' of identical disc-shaped insulators that attach to each other with metal clevis pin or ball and socket links. The advantage of this design is that insulator strings with different breakdown voltages, for use with different line voltages, can be constructed by using different numbers of the basic units. Also, if one of the insulator units in the string breaks, it can be replaced without discarding the entire string.\n\nEach unit is constructed of a ceramic or glass disc with a metal cap and pin cemented to opposite sides. To make defective units obvious, glass units are designed so that an overvoltage causes a puncture arc through the glass instead of a flashover. The glass is heat-treated so it shatters, making the damaged unit visible. However the mechanical strength of the unit is unchanged, so the insulator string stays together.\n\nStandard suspension disc insulator units are in diameter and long, can support a load of 80-120 kN (18-27 klbf), have a dry flashover voltage of about 72 kV, and are rated at an operating voltage of 10-12 kV. However, the flashover voltage of a string is less than the sum of its component discs, because the electric field is not distributed evenly across the string but is strongest at the disc nearest to the conductor, which flashes over first. Metal \"grading rings\" are sometimes added around the disc at the high voltage end, to reduce the electric field across that disc and improve flashover voltage.\n\nIn very high voltage lines the insulator may be surrounded by corona rings. These typically consist of toruses of aluminium (most commonly) or copper tubing attached to the line. They are designed to reduce the electric field at the point where the insulator is attached to the line, to prevent corona discharge, which results in power losses.\n\nThe first electrical systems to make use of insulators were telegraph lines; direct attachment of wires to wooden poles was found to give very poor results, especially during damp weather.\n\nThe first glass insulators used in large quantities had an unthreaded pinhole. These pieces of glass were positioned on a tapered wooden pin, vertically extending upwards from the pole's crossarm (commonly only two insulators to a pole and maybe one on top of the pole itself). Natural contraction and expansion of the wires tied to these \"threadless insulators\" resulted in insulators unseating from their pins, requiring manual reseating.\n\nAmongst the first to produce ceramic insulators were companies in the United Kingdom, with Stiff and Doulton using stoneware from the mid-1840s, Joseph Bourne (later renamed Denby) producing them from around 1860 and Bullers from 1868. Utility patent number 48,906 was granted to Louis A. Cauvet on 25 July 1865 for a process to produce insulators with a threaded pinhole: pin-type insulators still have threaded pinholes.\n\nThe invention of suspension-type insulators made high-voltage power transmission possible. As transmission line voltages reached and passed 60,000 volts, the insulators required become very large and heavy, with insulators made for a safety margin of 88,000 volts being about the practical limit for manufacturing and installation. Suspension insulators, on the other hand, can be connected into strings as long as required for the line's voltage.\n\nA large variety of telephone, telegraph and power insulators have been made; some people collect them, both for their historic interest and for the aesthetic quality of many insulator designs and finishes. One collectors organisation is the US National Insulator Association, which has over 9,000 members.\n\nOften a broadcasting radio antenna is built as a mast radiator, which means that the entire mast structure is energised with high voltage and must be insulated from the ground. Steatite mountings are used. They have to withstand not only the voltage of the mast radiator to ground, which can reach values up to 400 kV at some antennas, but also the weight of the mast construction and dynamic forces. Arcing horns and lightning arresters are necessary because lightning strikes to the mast are common.\n\nGuy wires supporting antenna masts usually have strain insulators inserted in the cable run, to keep the high voltages on the antenna from short circuiting to ground or creating a shock hazard. Often guy cables have several insulators, placed to break up the cable into lengths unwanted electrical resonances in the guy. These insulators are usually ceramic and cylindrical or egg-shaped (see picture). This construction has the advantage that the ceramic is under compression rather than tension, so it can withstand greater load, and that if the insulator breaks, the cable ends are still linked.\n\nThese insulators also have to be equipped with overvoltage protection equipment. For the dimensions of the guy insulation, static charges on guys have to be considered. At high masts these can be much higher than the voltage caused by the transmitter, requiring guys divided by insulators in multiple sections on the highest masts. In this case, guys which are grounded at the anchor basements via a coil - or if possible, directly - are the better choice.\n\nFeedlines attaching antennas to radio equipment, particularly twin lead type, often must be kept at a distance from metal structures. The insulated supports used for this purpose are called \"standoff insulators\".\n\nThe most important insulation material is air. A variety of solid, liquid, and gaseous insulators are also used in electrical apparatus. In smaller transformers, generators, and electric motors, insulation on the wire coils consists of up to four thin layers of polymer varnish film. Film insulated magnet wire permits a manufacturer to obtain the maximum number of turns within the available space. Windings that use thicker conductors are often wrapped with supplemental fiberglass insulating tape. Windings may also be impregnated with insulating varnishes to prevent electrical corona and reduce magnetically induced wire vibration. Large power transformer windings are still mostly insulated with paper, wood, varnish, and mineral oil; although these materials have been used for more than 100 years, they still provide a good balance of economy and adequate performance. Busbars and circuit breakers in switchgear may be insulated with glass-reinforced plastic insulation, treated to have low flame spread and to prevent tracking of current across the material.\n\nIn older apparatus made up to the early 1970s, boards made of compressed asbestos may be found; while this is an adequate insulator at power frequencies, handling or repairs to asbestos material can release dangerous fibers into the air and must be carried cautiously. Wire insulated with felted asbestos was used in high-temperature and rugged applications from the 1920s. Wire of this type was sold by General Electric under the trade name \"Deltabeston.\"\n\nLive-front switchboards up to the early part of the 20th century were made of slate or marble. Some high voltage equipment is designed to operate within a high pressure insulating gas such as sulfur hexafluoride. Insulation materials that perform well at power and low frequencies may be unsatisfactory at radio frequency, due to heating from excessive dielectric dissipation.\n\nElectrical wires may be insulated with polyethylene, crosslinked polyethylene (either through electron beam processing or chemical crosslinking), PVC, Kapton, rubber-like polymers, oil impregnated paper, Teflon, silicone, or modified ethylene tetrafluoroethylene (ETFE). Larger power cables may use compressed inorganic powder, depending on the application.\n\nFlexible insulating materials such as PVC (polyvinyl chloride) are used to insulate the circuit and prevent human contact with a 'live' wire – one having voltage of 600 volts or less. Alternative materials are likely to become increasingly used due to EU safety and environmental legislation making PVC less economic.\n\nAll portable or hand-held electrical devices are insulated to protect their user from harmful shock.\n\nClass 1 insulation requires that the metal body and other exposed metal parts of the device be connected to earth via a \"grounding wire\" that is earthed at the main service panel—but only needs basic insulation on the conductors. This equipment needs an extra pin on the power plug for the grounding connection.\n\nClass 2 insulation means that the device is \"double insulated\". This is used on some appliances such as electric shavers, hair dryers and portable power tools. Double insulation requires that the devices have both basic and supplementary insulation, each of which is sufficient to prevent electric shock. All internal electrically energized components are totally enclosed within an insulated body that prevents any contact with \"live\" parts. In the EU, double insulated appliances all are marked with a symbol of two squares, one inside the other.\n\n"}
{"id": "2727074", "url": "https://en.wikipedia.org/wiki?curid=2727074", "title": "John Clipperton", "text": "John Clipperton\n\nJohn Clipperton (1676 – June 1722) was an English privateer who fought against the Spanish in the 18th century. He was involved in two buccaneering expeditions to the South Pacific—the first led by William Dampier in 1703, and the second under his own command in 1719. He used Clipperton Island in the eastern Pacific Ocean as a base for his raids.\n\nJohn Clipperton was born in Great Yarmouth, Norfolk, in 1676 into a family of seafarers. In his younger days he sailed all the seas of Europe, made one trip to the West Indies and one around the world. He was an able pilot and seaman, but also a man of faults. He was a blunt, plain-spoken sailor. He was definitely no gentleman; but at times tried to be seen as one. Rash fits of rage would befall him, although he was soon appeased. Then he would be ready to repair any injustice that he had committed in the heat of anger—at least when this was possible.\n\nIn 1703 he sailed with the expedition of Captain William Dampier during the War of the Spanish Succession. Dampier appointed Clipperton captain of one of the Spanish ships they had taken as a prize. This first voyage of Clipperton did not proceed well. He led a mutiny against Dampier, and was later taken captive by the Spanish. The Marquis de Villa-Rocha, who would subsequently become governor of Panama, treated him with much indifference. Clipperton returned home in 1712 after four years of captivity.\n\nIt was, however, during this journey that he is said to have discovered Clipperton Island, which he would use as a hideout. He would later become captain of the \"Success\" as part of a different privateering syndicate, in which he also held under his nominal command Captain George Shelvocke of the \"Speedwell\". In his activities attacking Spanish targets on the west coast of the Americas, he used Clipperton Island as a base from which to stage his attacks and store loot and supplies, fortifying Clipperton Rock and expanding its cave network.\n\nMuch more is known about Clipperton's second voyage to the Pacific Ocean in 1719. By that time he had become an able and diligent captain, but he was still unable to control his rash temper. In 1718 a group of London merchants, the \"Gentleman Venturers\", had financed a privateering expedition in expectation of the outbreak of the War of the Quadruple Alliance, with a commission to cruise against the Spanish in the South Sea. Clipperton in the \"Success\" sailed with the \"Speedwell\", captained by George Shelvocke. Clipperton had replaced Shelvocke as overall commander of the expedition before the two ships left Plymouth in February 1719.\n\nThe ships lost contact with each other shortly after during a storm in the Bay of Biscay and did not meet up again until nearly two years later in the Pacific. On the voyage around Cape Horn, Clipperton dallied in the islands there hoping that \"Speedwell\", which had been separated from \"Success\" in the storm, would catch up. When the \"Success\" departed the area, Clipperton left two men marooned as punishment on Juan Fernández, which Alexander Selkirk (who may have partly inspired the Robinson Crusoe story) had been marooned on years before.\n\nClipperton sailed right around South America, raiding Spanish shipping about the coasts of Perú at the so-called \"Southern Seas\", where he was chased by Spanish admiral Blas de Lezo during the latter's first safety operations in the area. The privateer managed to escape Blas de Lezo and finally fled to Asian shores, where he was taken for dead. He captured his old enemy the Marquis de Villa-Rocha, whom he treated with much respect. Later, his travels carried him to Mexico and to Macau, where he stayed as his health deteriorated. He then sailed to Batavia (now Jakarta) in the Dutch East Indies, finally returning to his family in Galway in Ireland in June 1722. He died a week after returning home.\n"}
{"id": "21094535", "url": "https://en.wikipedia.org/wiki?curid=21094535", "title": "Lewis H. Nash", "text": "Lewis H. Nash\n\nLewis H. Nash (1852 – November 11, 1923) was an American engineer who invented the liquid-ring-vacuum pump, and was the holder of over a hundred United States patents for pumps, engines, and other equipment. He founded the Nash Engineering Company in 1905, and served as a member of the Connecticut House of Representatives.\n\nNash completed his public school education in South Norwalk, Connecticut, in 1869. As his parents were unable to pay for college, he took an apprenticeship course as a machinist at the Norwalk Iron Works. He next enrolled at a new institution, the Stevens Institute of Technology, which offered courses in the new field of Mechanical Engineering. He joined its third class, and graduated as class valedictorian.\n\nNash initially found his apprenticeship was of greater value in securing work than his degree, so he worked as a machinist in New Haven, Connecticut. In the meantime, he continued to work on a design he had conceived while in college for a new type of water measuring device. He built a model and took it to the National Meter Company of Brooklyn, New York. Though the device did not work satisfactorily in a test, its merits were appreciated, and he was employed with instructions to perfect the meter.\n\nIn a few months, Nash produced the \"Crown\" meter, the first of a large class of single-piston rotary meters, which practically superseded all other forms of water meters at that time. He received over sixty patents for water meters.\n\nOne type of meter, the \"Gem\", was built in sizes up to . The quantity of water that could be delivered by such a meter was nearly . This presented a problem in testing, as that amount of water could never be taken from the water supply of any city. In fact, a single meter of that size would pass enough water to supply a large town. Nash was given the task of devising a testing plant which re-circulated the water. He accomplished this by the use of a vertical screw pump which lifts the water to a reservoir, from which it passes through the meter to be tested and thence over a weir, where it is measured. The device and the meters both proved to be accurate.\n\nAfter seven years at the National Meter Company, Nash began the study of the gas engine and subsequently received sixty or more patents covering their design and operation. Many of them were extensively used by engine manufacturers, including the two cycle engine with piston controlled valves. Another patent covered the starting of gas engines by the use of compressed air, and this feature was adopted by all makes of large gas engines. The National Meter Company built the Nash engine in sizes up to about . These engines were used in municipal electric lighting and pumping plants as well as for general power purposes. Probably the largest installation of the Nash Engine was at the Phoenix Tube Company in Brooklyn, New York, and consisted of two Nash gas engines, totaling , operating on producer gas. The engines were directly connected to dynamos and although they operated under violently fluctuating load conditions, they ran well, both in regulation and economy modes. The company claimed that the Nash gas engine running on producer gas, using anthracite buckwheat coal, was the most economical of power products, costing twenty cents per .\n\nNash became chief engineer of the company, but his relations with them were not the best. The company never prosecuted infringements of their gas engine patents, and Nash's efforts were mostly unappreciated, for those at the head of the business not only failed to push his developments, but continually curtailed his authority.\n\nWhen Nash conceived the idea of a new type of vacuum pumping equipment, he decided not to assign the patents to the National Meter Company, but to manufacture the product himself. This was the beginning of the Nash Engineering Company (NEC), which initially had its offices on the third floor of his residence. In 1905, two of his friends joined to become officers and directors of the new corporation.\n\nAfter three years of designing and testing, manufacture was started at a factory over a shop on Water Street in South Norwalk. In 1911, Nash and his family moved to South Norwalk, and three years later he severed his connections with the National Meter Company to devote his entire time to his own firm. In 1909 Irving C. Jennings was hired part-time to help in testing pump technology, receiving pay in the form of company stock.\n\nWhile rounding out a line of vacuum pumps and compressors and of creating a demand for the pumps was slow. A micrometer plug gauge, another invention of Nash's, was made and generated enough profits to keep the company afloat. In 1912, a steady demand had been found for the pumps, and the first floor of the present building on Wilson Point Road was erected. The building was designed and built entirely from his plans and figures of Nash.\n\nIn that year, Nash's eldest son Douglas graduated from Stevens Institute of Technology, and it was his first task to superintend the construction of the new factory. Two years later, Harold, Nash's other son, became affiliated with the NEC after graduating from Stevens. The five years from 1918 to his death on November 17, 1923, Nash saw his company grow to be a prosperous, well-established concern, and was he able spend most of his time in his laboratory, where he could work out his many inventions and ideas. After his death Irving C. Jennings appointed was president of the NEC. In 1949 Ben Nash graduated from the Rensselaer Polytechnic and joined the NEC full-time. In 1958 Douglas Nash took over as president of the company with Irving Jennings as honorary chairman of the board. On the retirement of Douglas and Harold Nash in 1962 Benjamin Nash was elected as company resident.\n\nDuring World War I, he and his son, Harold, were working on an aeroplane engine which received favorable comment from the National Advisory Committee for Aeronautics and engineers such as Elmer Sperry, the inventor of the gyroscopic compass and stabilizing devices. The war ended before the engine was fully developed, and the idea was dropped.\n\nDuring the early years, NASH developed vacuum stream heating systems and vacuum sewage collection systems for many of the growing USA cities. NASH also developed vacuum pumps which were applied in the manufacture of pulp and paper and in the sugar industry. During the mid-20th century, NASH continued expanding into industrial markets such as paper, power, petrochemical, general industrial and food markets.\n\nNash further expanded into international markets with manufacturing, sales and services centers throughout these regions.\n\nIn 2002, Nash Engineering attracted private equity finance from Audax (Boston) and merged with Siemens to become Nash Elmo. A 2004 acquisition by Gardner Denver Inc. resulted in Gardner Denver Nash.\n\nSome works published by the Nash Engineering Company include:\n\nIn 1922 Nash was elected as a representative to the Connecticut State Legislature.\n\nIn 1921 Nash's \"alma mata\" the Stevens Institute recognized his outstanding achievements by awarding him the degree of Doctor of Engineering (E.D.).\n\n"}
{"id": "6786780", "url": "https://en.wikipedia.org/wiki?curid=6786780", "title": "Light pillar", "text": "Light pillar\n\nA light pillar is an atmospheric optical phenomenon in the form of a vertical band of light which appears to extend above and/or below a light source. The effect is created by the reflection of light from numerous tiny ice crystals suspended in the atmosphere or clouds. The light can come from the Sun (usually when it is near or even below the horizon) in which case the phenomenon is called a sun pillar or solar pillar. It can also come from the Moon or from terrestrial sources such as streetlights.\n\nSince they are caused by the interaction of light with ice crystals, light pillars belong to the family of halos. The crystals responsible for light pillars usually consist of flat, hexagonal plates, which tend to orient themselves more or less horizontally as they fall through the air. Their collective surfaces act as a giant mirror, which reflects the light source upwards and/or downwards into a virtual image. As the crystals are disturbed by turbulence, the angle of their surfaces deviates some degrees from the horizontal orientation, causing the reflection (i.e. the light pillar) to become elongated into a column. The larger the crystals, the more pronounced this effect becomes. More rarely, column-shaped crystals can cause light pillars as well. In very cold weather, the ice crystals can be suspended near the ground, in which case they are referred to as diamond dust.\n\nUnlike a light beam, a light pillar is not physically located above or below the light source. Its appearance of a vertical line is an optical illusion, resulting from the collective reflection off the ice crystals, only those of which that appear to lie in a vertical line direct the light rays towards the observer (similar to the reflection of a light source in a body of water).\n\n\n"}
{"id": "5439755", "url": "https://en.wikipedia.org/wiki?curid=5439755", "title": "List of Canadian plants by genus D", "text": "List of Canadian plants by genus D\n\nBelow is a list of Canadian plants by genus. Due to the vastness of Canada's biodiversity, this page is divided.\n\nThis is a (partial) list of the plant species considered native to Canada. Many of the plants seen in Canada are introduced, either intentionally or accidentally. For these plants, see List of introduced species to Canada.\n\nA | B | C | D | E | F | G | H | I J K | L | M | N | O | P Q | R | S | T | U V W | X Y Z\n\n\n\n\n\n\n\n\n\"See:\" Flora of Canada#References\n"}
{"id": "6188861", "url": "https://en.wikipedia.org/wiki?curid=6188861", "title": "List of Sites of Special Scientific Interest in Skye and Lochalsh", "text": "List of Sites of Special Scientific Interest in Skye and Lochalsh\n\nThe following is a list of Sites of Special Scientific Interest in the Skye and Lochalsh Area of Search. For other areas, see List of SSSIs by Area of Search.\n\n"}
{"id": "901831", "url": "https://en.wikipedia.org/wiki?curid=901831", "title": "List of U.S. state minerals, rocks, stones and gemstones", "text": "List of U.S. state minerals, rocks, stones and gemstones\n\nLeaders of states in the U.S. which have significant mineral deposits often create a state mineral, rock, stone or gemstone to promote interest in their natural resources, history, tourism, etc. Not every state has an official state mineral, rock, stone and/or gemstone, however.\n\nIn the chart below, a year which is listed within parentheses represents the year during which that mineral, rock, stone or gemstone was officially adopted as a state symbol or emblem.\n\n"}
{"id": "40288225", "url": "https://en.wikipedia.org/wiki?curid=40288225", "title": "List of ecoregions in Guatemala", "text": "List of ecoregions in Guatemala\n\nThis is a list of ecoregions of Guatemala as defined by the World Wildlife Fund and the Freshwater Ecoregions of the World database.\n\n\n\n\n\n\n\n\n\n"}
{"id": "145614", "url": "https://en.wikipedia.org/wiki?curid=145614", "title": "List of gardens", "text": "List of gardens\n\nThe List of gardens is a link page for any park or garden open to the public, anywhere in the world.\n\n\nAustralian Capital Territory\n\nNew South Wales\n\n\nQueensland\n\nSouth Australia\n\"See:\" \n\nVictoria\n\n\"See:\" Melbourne parks and gardens or \n\n\n\n\n\n\n\"See: \" List of parks and gardens in Paris\n\n\"See: \" Notable gardens of France\n\n\"See: \" List of urban public parks and gardens of Hong Kong\n\n\n\"See: \" Persian gardens\n\n\n\"See also:\" List of botanical gardens in Italy\n\n\n\"See:\" Parks and gardens in Tokyo\n\n\n\"See: \" List of parks and gardens in Malta\n\n\"See:\" List of parks and gardens in Pakistan and List of parks and gardens in Lahore\n\n\n\"See: \" Gardens in the Republic of Ireland\n\n\n\n\n"}
{"id": "32598425", "url": "https://en.wikipedia.org/wiki?curid=32598425", "title": "List of plants from the mountains of Romania", "text": "List of plants from the mountains of Romania\n\nA list of plants native to the mountain ranges of Romania.\n\nMany Romanian mountain ranges, mountains, and peaks are part of the Southern Carpathians System, and the Balkan mixed forests ecoregion.\n\n \n\n\n\n"}
{"id": "13213953", "url": "https://en.wikipedia.org/wiki?curid=13213953", "title": "List of pythonid species and subspecies", "text": "List of pythonid species and subspecies\n\nThis is a list of all genera, species, and subspecies of the family Pythonidae, otherwise referred to as pythonids or pythons. It follows the taxonomy of McDiarmid et al. (1999), which is available online through ITIS., updated with additional recently described species.\n\n\n"}
{"id": "56574537", "url": "https://en.wikipedia.org/wiki?curid=56574537", "title": "Lists of black holes", "text": "Lists of black holes\n\nThis is a list of lists of black holes.\n\n"}
{"id": "18298", "url": "https://en.wikipedia.org/wiki?curid=18298", "title": "Lunar eclipse", "text": "Lunar eclipse\n\nA lunar eclipse occurs when the Moon passes directly behind Earth and into its shadow. This can occur only when the Sun, Earth, and Moon are exactly or very closely aligned (in syzygy), with Earth between the other two. A lunar eclipse can occur only on the night of a full moon. The type and length of a lunar eclipse depend on the Moon's proximity to either node of its orbit.\n\nDuring a total lunar eclipse, Earth completely blocks direct sunlight from reaching the Moon. The only light reflected from the lunar surface has been refracted by Earth's atmosphere. This light appears reddish for the same reason that a sunset or sunrise does: the Rayleigh scattering of bluer light. Due to this reddish color, a totally eclipsed Moon is sometimes called a blood moon.\n\nUnlike a solar eclipse, which can be viewed only from a certain relatively small area of the world, a lunar eclipse may be viewed from anywhere on the night side of Earth. A total lunar eclipse lasts a few hours, whereas a total solar eclipse lasts only a few minutes as viewed from any given place, due to the smaller size of the Moon's shadow. Also unlike solar eclipses, lunar eclipses are safe to view without any eye protection or special precautions, as they are dimmer than the full Moon.\n\nFor the date of the next eclipse, see the section \"Recent and forthcoming lunar eclipses\".\n\nEarth's shadow can be divided into two distinctive parts: the umbra and penumbra. Earth totally occludes direct solar radiation within the umbra, the central region of the shadow. However, since the Sun's diameter appears about one-quarter of Earth's in the lunar sky, the planet only partially blocks direct sunlight within the penumbra, the outer portion of the shadow.\n\nA penumbral lunar eclipse occurs when the Moon passes through Earth's penumbra. The penumbra causes a subtle dimming of the lunar surface. A special type of penumbral eclipse is a total penumbral lunar eclipse, during which the Moon lies exclusively within Earth's penumbra. Total penumbral eclipses are rare, and when these occur, the portion of the Moon closest to the umbra may appear slightly darker than the rest of the lunar disk.\n\nA partial lunar eclipse occurs when only a portion of the Moon enters Earth's umbra, while a total lunar eclipse occurs when the entire Moon enters the planet's umbra. The Moon's average orbital speed is about , or a little more than its diameter per hour, so totality may last up to nearly 107 minutes. Nevertheless, the total time between the first and the last contacts of the Moon's limb with Earth's shadow is much longer and could last up to four hours.\n\nThe relative distance of the Moon from Earth at the time of an eclipse can affect the eclipse's duration. In particular, when the Moon is near apogee,the farthest point from Earth in its orbit, its orbital speed is the slowest. The diameter of Earth's umbra does not decrease appreciably within the changes in the Moon's orbital distance. Thus, the concurrence of a totally eclipsed Moon near apogee will lengthen the duration of totality.\n\nA central lunar eclipse is a total lunar eclipse during which the Moon passes through the centre of Earth's shadow, contacting the antisolar point. This type of lunar eclipse is relatively rare.\nA selenelion or selenehelion occurs when both the Sun and an eclipsed Moon can be observed at the same time. This can occur only just before sunset or just after sunrise, when both bodies will appear just above the horizon at nearly opposite points in the sky. This arrangement has led to the phenomenon being also called a horizontal eclipse.\n\nTypically, a number of high ridges undergoing sunrise or sunset can view it. Although the Moon is in Earth's umbra, both the Sun and an eclipsed Moon can be simultaneously seen because atmospheric refraction causes each body to appear higher in the sky than their true geometric positions.\n\nThe following scale (the Danjon scale) was devised by André Danjon for rating the overall darkness of lunar eclipses:\n\nThere is often confusion between a solar eclipse and a lunar eclipse. While both involve interactions between the Sun, Earth, and the Moon, they are very different in their interactions.\n\nThe Moon does not completely darken as it passes through the umbra because of the refraction of sunlight by Earth's atmosphere into the shadow cone; if Earth had no atmosphere, the Moon would be completely dark during the eclipse. The reddish coloration arises because sunlight reaching the Moon must pass through a long and dense layer of Earth's atmosphere, where it is scattered. Shorter wavelengths are more likely to be scattered by the air molecules and small particles; thus, the longer wavelengths predominate by the time the light rays have penetrated the atmosphere. Human vision perceives this resulting light as red. This is the same effect that causes sunsets and sunrises to turn the sky a reddish color. An alternative way of conceiving this scenario is to realize that, as viewed from the Moon, the Sun would appear to be setting (or rising) behind Earth.\n\nThe amount of refracted light depends on the amount of dust or clouds in the atmosphere; this also controls how much light is scattered. In general, the dustier the atmosphere, the more that other wavelengths of light will be removed (compared to red light), leaving the resulting light a deeper red color. This causes the resulting coppery-red hue of the Moon to vary from one eclipse to the next. Volcanoes are notable for expelling large quantities of dust into the atmosphere, and a large eruption shortly before an eclipse can have a large effect on the resulting color.\n\nSeveral cultures have myths related to lunar eclipses or allude to the lunar eclipse as being a good or bad omen. The Egyptians saw the eclipse as a sow swallowing the moon for a short time; other cultures view the eclipse as the Moon being swallowed by other animals, such as a jaguar in Mayan tradition, or a three legged toad in China. Some societies thought it was a demon swallowing the Moon, and that they could chase it away by throwing stones and curses at it. The Greeks were ahead of their time when they said the Earth was round and used the shadow from the lunar eclipse as evidence. Some Hindus believe in the importance of bathing in the Ganges River following an eclipse because it will help to achieve salvation.\n\nSimilarly to the Mayans, the Incans believed that lunar eclipses occurred when a jaguar would eat the Moon, which is why a blood moon looks red. The Incans also believed that once the jaguar finished eating the Moon, it could come down and devour all the animals on Earth, so they would take spears and shout at the Moon to keep it away.\n\nThe ancient Mesopotamians believed that a lunar eclipse was when the Moon was being attacked by seven demons. This attack was more than just one on the Moon, however, for the Mesopotamians linked what happened in the sky with what happened on the land, and because the king of Mesopotamia represented the land, the seven demons were thought to be also attacking the king. In order to prevent this attack on the king, the Mesopotamians made someone pretend to be the king so they would be attacked instead of the true king. After the lunar eclipse was over, the substitute king was made to disappear (possibly by poisoning).\n\nIn some Chinese cultures, people would ring bells to prevent a dragon or other wild animals from biting the Moon. In the nineteenth century, during a lunar eclipse, the Chinese navy fired its artillery because of this belief. During the Zhou Dynasty in the Book of Songs, the sight of a red Moon engulfed in darkness was believed to foreshadow famine or disease.\n\nCertain lunar eclipses have been referred to as \"blood moons\" in popular articles but this is not a scientifically-recognized term. This term has been given two separate, but overlapping, meanings.\n\nThe first, and simpler, meaning relates to the reddish color a totally eclipsed Moon takes on to observers on Earth. As sunlight penetrates the atmosphere of Earth, the gaseous layer filters and refracts the rays in such a way that the green to violet wavelengths on the visible spectrum scatter more strongly than the red, thus giving the Moon a reddish cast.\n\nThe second meaning of \"blood moon\" has been derived from this apparent coloration by two fundamentalist Christian pastors, Mark Blitz and John Hagee. They claimed that the 2014–15 \"lunar tetrad\" of four lunar eclipses coinciding with the feasts of Passover and Tabernacles matched the \"moon turning to blood\" described in the Book of Joel of the Hebrew Bible. This tetrad was claimed to herald the Second Coming of Christ and the Rapture as described in the Book of Revelation on the date of the first of the eclipses in this sequence on April 15, 2014.\n\nAt least two lunar eclipses and as many as five occur every year, although total lunar eclipses are significantly less common. If the date and time of an eclipse is known, the occurrences of upcoming eclipses are predictable using an eclipse cycle, like the saros.\n\nEclipses occur only during an eclipse season, when the Sun appears to pass near either node of the Moon's orbit.\n\n\n\n"}
{"id": "1575643", "url": "https://en.wikipedia.org/wiki?curid=1575643", "title": "Mass flow meter", "text": "Mass flow meter\n\nA mass flow meter, also known as an inertial flow meter is a device that measures mass flow rate of a fluid traveling through a tube. The mass flow rate is the mass of the fluid traveling past a fixed point per unit time.\n\nThe mass flow meter does not measure the volume per unit time (e.g., cubic meters per second) passing through the device; it measures the mass per unit time (e.g., kilograms per second) flowing through the device. Volumetric flow rate is the mass flow rate divided by the fluid density. If the density is constant, then the relationship is simple. If the fluid has varying density, then the relationship is not simple. The density of the fluid may change with temperature, pressure, or composition, for example. The fluid may also be a combination of phases such as a fluid with entrained bubbles.\nActual density can be determined due to dependency of sound velocity on the controlled liquid concentration.\n\nThere are two basic configurations of coriolis flow meter: the \"curved tube flow meter\" and the \"straight tube flow meter\". This article discusses the curved tube design.\n\nThe animations on the right do not represent an actually existing Coriolis flow meter design. The purpose of the animations is to illustrate the operating principle, and to show the connection with rotation.\n\nFluid is being pumped through the mass flow meter. When there is mass flow, the tube twists slightly. The arm through which fluid flows away from the axis of rotation must exert a force on the fluid, to increase its angular momentum, so it bends backwards. The arm through which fluid is pushed back to the axis of rotation must exert a force on the fluid to decrease the fluid's angular momentum again, hence that arm will bend forward. In other words, the inlet arm (containing an outwards directed flow), is lagging behind the overall rotation, the part which in rest is parallel to the axis is now skewed, and the outlet arm (containing an inwards directed flow) leads the overall rotation.\n\nThe animation on the right represents how curved tube mass flow meters are designed. The fluid is led through two parallel tubes. An actuator (not shown) induces equal counter vibrations on the sections parallel to the axis, to make the measuring device less sensitive to outside vibrations. The actual frequency of the vibration depends on the size of the mass flow meter, and ranges from 80 to 1000 Hz. The amplitude of the vibration is too small to be seen, but it can be felt by touch.\n\nWhen no fluid is flowing, the motion of the two tubes is symmetrical, as shown in the left animation. The animation on the right illustrates what happens during mass flow: some twisting of the tubes. The arm carrying the flow away from the axis of rotation must exert a force on the fluid to accelerate the flowing mass to the vibrating speed of the tubes at the outside (increase of absolute angular momentum), so it is lagging behind the overall vibration. The arm through which fluid is pushed back towards the axis of movement must exert a force on the fluid to decrease the fluid's absolute angular speed (angular momentum) again, hence that arm leads the overall vibration.\n\nThe inlet arm and the outlet arm vibrate with the same frequency as the overall vibration, but when there is mass flow the two vibrations are out of sync: the inlet arm is behind, the outlet arm is ahead. The two vibrations are shifted in phase with respect to each other, and the degree of phase-shift is a measure for the amount of mass that is flowing through the tubes.\n\nThe mass flow of a u-shaped coriolis flow meter is given as:\nformula_1\n\nwhere \"K\" is the temperature dependent stiffness of the tube, \"K\" a shape-dependent factor, \"d\" the width, \"τ\" the time lag, \"ω\" the vibration frequency and \"I\" the inertia of the tube. As the inertia of the tube depend on its contents, knowledge of the fluid density is needed for the calculation of an accurate mass flow rate.\n\nIf the density changes too often for manual calibration to be sufficient, the coriolis flow meter can be adapted to measure the density as well. The natural vibration frequency of the flow tubes depends on the combined mass of the tube and the fluid contained in it. By setting the tube in motion and measuring the natural frequency, the mass of the fluid contained in the tube can be deduced. Dividing the mass on the known volume of the tube gives us the \"density\" of the fluid.\n\nAn instantaneous density measurement allows the calculation of flow in volume per time by dividing mass flow with density.\n\nBoth mass flow and density measurements depend on the vibration of the tube. \nCalibration is affected by changes in the rigidity of the flow tubes.\n\nChanges in temperature and pressure will cause the tube rigidity to change, but these can be compensated for through pressure and temperature zero and span compensation factors.\n\nAdditional effects on tube rigidity will cause shifts in the calibration factor over time due to degradation of the flow tubes. These effects include pitting, cracking, coating, erosion or corrosion.\nIt is not possible to compensate for these changes dynamically, but efforts to monitor the effects may be made through regular meter calibration or verification checks.\nIf a change is deemed to have occurred, but is considered to be acceptable, the offset may be added to the existing calibration factor to ensure continued accurate measurement.\n\n\n"}
{"id": "2784383", "url": "https://en.wikipedia.org/wiki?curid=2784383", "title": "Microfibril", "text": "Microfibril\n\nA microfibril is a very fine fibril, or fiber-like strand, consisting of glycoproteins and cellulose. It is usually, but not always, used as a general term in describing the structure of protein fiber, e.g. hair and sperm tail. Its most frequently observed structural pattern is the 9+2 pattern in which two central protofibrils are surrounded by nine other pairs. Cellulose inside plants is one of the examples of non-protein compounds that are using this term with the same purpose. Cellulose microfibrils are laid down in the inner surface of the primary cell wall. As the cell absorbs water, its volume increases and the existing microfibrils separate and new ones are formed to help increase cell strength.\n\nCellulose is synthesized by cellulose synthase or Rosette terminal complexes which reside on a cells membrane. As cellulose fibrils are synthesized and grow extracellularly they push up against neighboring cells. Since the neighboring cell can not move easily the Rosette complex is instead pushed around the cell through the fluid phospholipid membrane. Eventually this results in the cell becoming wrapped in a microfibril layer. This layer becomes the cell wall. The organization of microfibrils forming the primary cell wall is rather disorganized. However, another mechanism is used in secondary cell walls leading to its organization. Essentially, lanes on the secondary cell wall are built with microtubules. These lanes force microfibrils to remain in a certain area while they wrap. During this process microtubules can spontaneously depolymerize and repolymerize in a different orientation. This leads to a different direction in which the cell continues getting wrapped.\n\nIn Marfan syndrome, there is a defect in fibrillin, the glycoprotein component of microfibrils.\n\n"}
{"id": "50218653", "url": "https://en.wikipedia.org/wiki?curid=50218653", "title": "Nicotinamide mononucleotide", "text": "Nicotinamide mononucleotide\n\nNicotinamide mononucleotide (\"NMN\" and \"β-NMN\") is a nucleotide derived from ribose and nicotinamide. Like nicotinamide riboside, NMN is a derivative of niacin, and humans have enzymes that can use NMN to generate nicotinamide adenine dinucleotide (NADH).\n\nBecause NADH is a cofactor for processes inside mitochondria, for sirtuins, and for PARP, NMN has been studied in animal models as a potential neuroprotective and anti-aging agent. Dietary supplement companies have aggressively marketed NMN products claiming those benefits, though there is no clinical study on humans published yet.\n"}
{"id": "31285443", "url": "https://en.wikipedia.org/wiki?curid=31285443", "title": "North Korea Cold Current", "text": "North Korea Cold Current\n\nThe North Korea Cold Current (NKCC) is a cold water oceanic current in the Sea of Japan (East Sea of Korea) that flows southward from near Vladivostok along the coastline of the eastern Korean Peninsula. It is a branch of the Liman Current from the Sea of Okhotsk and has a flow rate of about a half knot. The NKCC meets the northward flowing East Korean Warm Current at latitude 37–38° N, causing the flow to separate from the peninsula. At about latitude 40° N, the NKCC meets the Tsushima Warm Current.\n"}
{"id": "46835693", "url": "https://en.wikipedia.org/wiki?curid=46835693", "title": "Open Geosciences", "text": "Open Geosciences\n\nOpen Geosciences is a peer-reviewed open access scientific journal covering all aspects of the Earth sciences. It is published by De Gruyter Open and the editor-in-chief is Piotr Jankowski (San Diego State University). The journal was established in 2009 as the \"Central European Journal of Geosciences\", co-published by Versita and Springer Science+Business Media. In 2014, the journal was moved to the De Gruyter Open imprint. It obtained its current name in 2015 when it became open access.\n\nThe journals is abstracted and indexed by the following services:\n\nAccording to \"Journal Citation Reports\", the journal has a 2017 impact factor of 0.696.\n"}
{"id": "14434713", "url": "https://en.wikipedia.org/wiki?curid=14434713", "title": "Operation CHASE", "text": "Operation CHASE\n\nOperation CHASE (an acronym for \"Cut Holes And Sink 'Em\") was a United States Department of Defense program for the disposal of unwanted munitions at sea from May 1964 until the early 1970s. Munitions were loaded onto ships to be scuttled once they were at least 250 miles (400 km) offshore. While most of the sinkings involved conventional weapons, four of them involved chemical weapons. The disposal site for the chemical weapons was a three-mile (5 km) area of the Atlantic Ocean between the coast of the U.S. state of Florida and the Bahamas. The CHASE program was preceded by the United States Army disposal of 8000  of mustard and lewisite chemical warfare gas aboard the scuttled SS \"William C. Ralston\" in April 1958. These ships were sunk by having Explosive Ordnance Demolition (EOD) teams open seacocks on the ship after they arrived at the disposal site. The typical Liberty ship sank about three hours after the seacocks were opened.\n\nThe mothballed C-3 Liberty ship \"John F. Shafroth\" was taken from the National Defense Reserve Fleet at Suisun Bay and towed to the Concord Naval Weapons Station for stripping and loading. A major fraction of the munitions in CHASE 1 was Bofors 40 mm gun ammunition from the Naval Ammunition Depot at Hastings, Nebraska. CHASE 1 also included bombs, torpedo warheads, naval mines, cartridges, projectiles, fuzes, detonators, boosters, overage UGM-27 Polaris motors, and a quantity of contaminated cake mix an army court had ordered dumped at sea. \"Shafroth\" was sunk 47 miles (76 km) off San Francisco on 23 July 1964 with 9799 tons of munitions.\n\n\"Village\" was loaded with 7348 short tons of munitions at the Naval Weapons Station Earle and towed to a deep-water dump site on 17 September 1964. There were three large and unexpected detonations five minutes after \"Village\" slipped beneath the surface. An oil slick and some debris appeared on the surface. The explosion registered on seismic equipment all over the world. Inquiries were received regarding seismic activity off the east coast of the United States, and the Office of Naval Research and Advanced Research Projects Agency expressed interest in measuring the differences between seismic shocks and underwater explosive detonations to detect underwater nuclear detonations then banned by treaty.\n\n\"Coastal Mariner\" was loaded with 4040 short tons of munitions at the Naval Weapons Station Earle. The munitions included 512 tons of actual explosives. Four SOFAR bombs were packed in the explosives cargo hold with booster charges of 500 pounds (227 kg) of TNT to detonate the cargo at a depth of 1000 feet (300 m). The United States Coast Guard issued a notice to mariners and the United States Department of Fish and Wildlife and the United States Bureau of Commercial Fisheries sent observers. The explosives detonated seventeen seconds after \"Coastal Mariner\" slipped below the surface on 14 July 1965. The detonation created a 600-foot (200 m) water spout, but was not deep enough to be recorded on seismic instruments.\n\n\"Santiago Iglesias\" was loaded with 8715 tons of munitions at the Naval Weapons Station Earle, rigged for detonation at 1000 feet (300 m), and detonated 31 seconds after sinking on 16 September 1965.\n\n\"Isaac Van Zandt\" was loaded with 8000 tons of munitions (including 400 tons of high explosives) at the Naval Base Kitsap and rigged for detonation at 4000 feet (1.2 km). On 23 May 1966 the tow cable parted en route to the planned disposal area. Navy tugs USS \"Tatnuck\" (ATA-195) and USS \"Koka\" (ATA-185) recovered the tow within six hours, but the location of sinking was changed by the delay.\n\n\"Horace Greeley\" was loaded at the Naval Weapons Station Earle, rigged for detonation at 4000 feet (1.2 km), and detonated on 28 July 1966.\n\n\"Michael J. Monahan\" was loaded with overage UGM-27 Polaris motors at the Naval Weapons Station Charleston and sunk without detonation on 30 April 1967.\n\nThe first chemical weapons disposal via the program was in 1967 and designated CHASE 8. CHASE 8 disposed of mustard gas and GB-filled M-55 rockets.\n\n\"Eric C. Gibson\" was sunk on 15 June 1967.\n\nCHASE 10 dumped 3000 tons of United States Army nerve agent filled rockets encased in concrete vaults. Public controversy delayed CHASE 10 disposal until August 1970. Public awareness of operation CHASE 10 was increased by mass media reporting following delivery of information from the Pentagon to the office of U.S. Representative Richard McCarthy in 1969. Both American television and print media followed the story with heavy coverage. In 1970, 58 separate reports were aired on the three major network news programs on NBC, ABC and CBS concerning Operation CHASE. Similarly, \"The New York Times\" included Operation CHASE coverage in 42 separate issues during 1970, 21 of those in the month of August.\n\nCHASE 11 occurred in June 1968 and disposed of United States Army GB and VX, all sealed in tin containers.\n\nCHASE 12, in August 1968, again disposed of United States Army mustard agent and was numerically (although not chronologically) the final mission to dispose of chemical weapons.\n\nOperation CHASE was exposed to the public during a time when the army was under increasing public criticism, especially the army's Chemical Corps. CHASE was one of the incidents which led to the near-disbanding of the Chemical Corps in the aftermath of the Vietnam War. Concerns were raised over the program's effect on the ocean environment as well as the risk of chemical weapons washing up on shore. The concerns led to the Marine Protection, Research, and Sanctuaries Act of 1972, which prohibited such future missions.\n\n"}
{"id": "328274", "url": "https://en.wikipedia.org/wiki?curid=328274", "title": "Palynology", "text": "Palynology\n\nPalynology is the \"study of dust\" (from , \"strew, sprinkle\" and \"-logy\") or \"particles that are strewn\". A classic palynologist analyses particulate samples collected from the air, from water, or from deposits including sediments of any age. The condition and identification of those particles, organic and inorganic, give the palynologist clues to the life, environment, and energetic conditions that produced them.\n\nThe term is sometimes narrowly used to refer to a subset of the discipline, which is defined as \"the study of microscopic objects of macromolecular organic composition (i.e., compounds of carbon, hydrogen, nitrogen and oxygen), not capable of dissolution in hydrochloric or hydrofluoric acids\". It is the science that studies contemporary and fossil palynomorphs, including pollen, spores, orbicules, dinocysts, acritarchs, chitinozoans and scolecodonts, together with particulate organic matter (POM) and kerogen found in sedimentary rocks and sediments. Palynology does not include diatoms, foraminiferans or other organisms with siliceous or calcareous exoskeletons.\n\nPalynology is an interdisciplinary science and is a branch of earth science (geology or geological science) and biological science (biology), particularly plant science (botany). Stratigraphical palynology is a branch of micropalaeontology and paleobotany, which studies fossil palynomorphs from the Precambrian to the Holocene.\n\nThe earliest reported observations of pollen under a microscope are likely to have been in the 1640s by the English botanist Nehemiah Grew, who described pollen and the stamen, and concluded that pollen is required for sexual reproduction in flowering plants.\n\nBy the late 1870s, as optical microscopes improved and the principles of stratigraphy were worked out, Robert Kidston and P. Reinsch were able to examine the presence of fossil spores in the Devonian and Carboniferous coal seams and make comparisons between the living spores and the ancient fossil spores. Early investigators include Christian Gottfried Ehrenberg (radiolarians, diatoms and dinoflagellate cysts), Gideon Mantell (desmids) and Henry Hopley White (dinoflagellate cysts).\n\nQuantitative analysis of pollen began with Lennart von Post's published work. Although he published in the Swedish language, his methodology gained a wide audience through his lectures. In particular, his Kristiania lecture of 1916 was important in gaining a wider audience. Because the early investigations were published in the Nordic languages (Scandinavian languages), the field of pollen analysis was confined to those countries. The isolation ended with the German publication of Gunnar Erdtman's 1921 thesis. The methodology of pollen analysis became widespread throughout Europe and North America and revolutionized Quaternary vegetation and climate change research.\n\nEarlier pollen researchers include Früh (1885), who enumerated many common tree pollen types, and a considerable number of spores and herb pollen grains. There is a study of pollen samples taken from sediments of Swedish lakes by Trybom (1888); pine and spruce pollen was found in such profusion that he considered them to be serviceable as \"index fossils\". Georg F. L. Sarauw studied fossil pollen of middle Pleistocene age (Cromerian) from the harbour of Copenhagen. Lagerheim (in Witte 1905) and C. A.Weber (in H. A. Weber 1918) appear to be among the first to undertake 'percentage frequency' calculations.\n\nThe term \"palynology\" was introduced by Hyde and Williams in 1944, following correspondence with the Swedish geologist Ernst Antevs, in the pages of the \"Pollen Analysis Circular\" (one of the first journals devoted to pollen analysis, produced by Paul Sears in North America). Hyde and Williams chose \"palynology\" on the basis of the Greek words \"paluno\" meaning 'to sprinkle' and \"pale\" meaning 'dust' (and thus similar to the Latin word \"pollen\").\n\nPollen analysis in North America stemmed from Phyllis Draper, an MS student under Sears at the University of Oklahoma. During her time as a student, she developed the first pollen diagram from a sample that depicted the percentage of several species at different depths at Curtis Bog. This was the introduction of pollen analysis in North America; pollen diagrams today still often remain in the same format with depth on the y-axis and abundances of species on the x-axis.\n\nPollen analysis advanced rapidly in this period due to advances in optics and computers. Much of the science was revised by Johannes Iversen and Knut Fægri in their textbook on the subject.\n\nPalynomorphs are broadly defined as organic-walled microfossils between 5 and 500 micrometres in size. They are extracted from sedimentary rocks and sediment cores both physically, by ultrasonic treatment and wet sieving, and chemically, by chemical digestion to remove the non-organic fraction. Palynomorphs may be composed of organic material such as chitin, pseudochitin and sporopollenin. Palynomorphs that have a taxonomy description are sometimes referred to as palynotaxa.\n\nPalynomorphs form a geological record of importance in determining the type of prehistoric life that existed at the time the sedimentary formation was laid down. As a result, these microfossils give important clues to the prevailing climatic conditions of the time. Their paleontological utility derives from an abundance numbering in millions of cells per gram in organic marine deposits, even when such deposits are generally not fossiliferous. Palynomorphs, however, generally have been destroyed in metamorphic or recrystallized rocks.\n\nTypically, palynomorphs are dinoflagellate cysts, acritarchs, spores, pollen, fungi, scolecodonts (scleroprotein teeth, jaws and associated features of polychaete annelid worms), arthropod organs (such as insect mouthparts), chitinozoans and microforams. Palynomorph microscopic structures that are abundant in most sediments are resistant to routine pollen extraction including strong acids and bases, and acetolysis, or density separation.\n\nA palynofacies is the complete assemblage of organic matter and palynomorphs in a fossil deposit. The study of the palynofacies of a depositional environment of sediments can be used to learn about the depositional palaeoenvironments of sedimentary rocks. The term \"palynofacies\" was introduced by the French geologist André Combaz in 1964. Palynofacies studies are often linked to investigations of the palynology and organic geochemistry of sedimentary rocks.\n\nPalynofacies can be used in two ways:\n\nBoth types of palynofacies studies are used for geological interpretation of sedimentary basins in exploration geology, often in conjunction with palynological analysis and vitrinite reflectance.\n\nChemical digestion follows a number of steps. Initially the only chemical treatment used by researchers was treatment with Potassium hydroxide (KOH) to remove humic substances; defloculation was accomplished through surface treatment or ultra-sonic treatment, although sonification may cause the pollen exine to rupture. The use of hydrofluoric acid (HF) to digest silicate minerals was introduced by Assarson and Granlund in 1924, greatly reducing the amount of time required to scan slides for palynomorphs. Palynological studies using peats presented a particular challenge because of the presence of well-preserved organic material, including fine rootlets, moss leaflets and organic litter. This was the last major challenge in the chemical preparation of materials for palynological study. Acetolysis was developed by Gunnar Erdtman and his brother to remove these fine cellulose materials by dissolving them. In acetolysis the specimen is treated with acetic anhydride and sulfuric acid, dissolving cellulistic materials and thus providing better visibility for palynomorphs.\n\nSome steps of the chemical treatments require special care for safety reasons, in particular the use of HF which diffuses very fast through the skin and, causes severe chemical burns, and can be fatal.\n\nAnother treatment includes kerosene flotation for chitinous materials.\n\nOnce samples have been prepared chemically, they are mounted on microscope slides using silicon oil, glycerol or glycerol-jelly and examined using light microscopy or mounted on a stub for scanning electron microscopy.\n\nResearchers will often study either modern samples from a number of unique sites within a given area, or samples from a single site with a record through time, such as samples obtained from peat or lake sediments. More recent studies have used the modern analog technique in which paleo-samples are compared to modern samples for which the parent vegetation is known.\n\nWhen the slides are observed under a microscope, the researcher counts the number of grains of each pollen taxon. This record is next used to produce a pollen diagram. These data can be used to detect anthropogenic effects, such as logging, traditional patterns of land use or long term changes in regional climate\n\nPalynology can be applied to problems in many fields including geology, botany, paleontology, archaeology, pedology (soil study), and physical geography.\n\nPalynology is used for a diverse range of applications, related to many scientific disciplines:\n\n\nBecause the distribution of acritarchs, chitinozoans, dinoflagellate cysts, pollen and spores provides evidence of stratigraphical correlation through biostratigraphy and palaeoenvironmental reconstruction, one common and lucrative application of palynology is in oil and gas exploration.\n\nPalynology also allows scientists to infer the climatic conditions from the vegetation present in an area thousands or millions of years ago. This is a fundamental part of research into climate change.\n\n\n\n"}
{"id": "25690835", "url": "https://en.wikipedia.org/wiki?curid=25690835", "title": "Saman-Depe Gas Field", "text": "Saman-Depe Gas Field\n\nSaman-Depe Gas Field is a large natural gas field located in Lebap Province of Turkmenistan. The field belongs to contractual territory Bagtyyarlyk, a group of several fields on the right bank of Amu Darya River the maximum output of which is estimated at 25-30 billion cubic meters per year, combined. The peak of production is expected in 2015-2020. As per initial estimates, the fields will produce approximately 12 billion cubic meters in 2010. Saman-Depe along with Altyn-Asyr are considered to be the largest fields in the area. Contract area of Bagtyyarlyk is estimated at , however the precise data is yet to be confirmed. In total, there are 17 gas and gas condensate fields on the right bank of Amu Darya: \nSaman-Depe is proven to be the largest among 17 fields so far, with reserves equal to .\nThe first well No. 53/1 at a depth of was drilled by subcontractor \"Sichuan Petroleum\". CNPC will also be repairing nearly 50 wells prepared by Turkmen specialists in 1980's. \nIn December 2009, Presidents of Turkmenistan, China, Uzbekistan and Kazakhstan inaugurated the Turkmenistan-China gas pipeline and commencement of gas processing plant in Saman-Depe. The plant was built for refining, purification and annual production of of gas. Additionally, the plant will produce nearly 180,000 tonnes of stable condensate at full capacity. The construction of the facility was subcontracted to Sofregaz and Technip. Turkmenistan is planning on construction of the second plant with capacity for refining per year.\n\n"}
{"id": "635811", "url": "https://en.wikipedia.org/wiki?curid=635811", "title": "Sinope (mythology)", "text": "Sinope (mythology)\n\nIn Greek Mythology, Sinope (Ancient Greek: Σινώπη) was one of the daughters of Asopus and thought to be an eponym of the city Sinope on the Black Sea.\n\nAccording to Corinna and Diodorus Siculus, Sinope was carried away by the god Apollo to the place where later stood the city honouring her name. Diodorus adds that she bore to Apollo a son named Syrus, supposedly afterwards king of the Syrians, who were named after him.\n\nHowever, the Argonautica and Valerius Flaccus relate that Sinope was abducted to the site by Zeus, who, in his passion, swore to fulfil her dearest wish. Sinope declared she wished to remain a virgin. Sinope later tricked Apollo and the river Halys in the same fashion and remained a virgin all her life.\n"}
{"id": "1576445", "url": "https://en.wikipedia.org/wiki?curid=1576445", "title": "Sociological naturalism", "text": "Sociological naturalism\n\nSociological naturalism is a theory that states that the natural world and social world are roughly identical and governed by similar principles. Sociological naturalism, in sociological texts simply referred to as naturalism, can be traced back to the philosophical thinking of Auguste Comte in the 19th century, closely connected to positivism, which advocates use of the scientific method of the natural sciences in studying social sciences. It should not be identified too closely with Positivism, however, since whilst the latter advocates the use of controlled situations like experiments as sources of scientific information, naturalism insists that social processes should only be studied in their \"natural\" setting. A similar form of naturalism was applied to the scientific study of art and literature by Hippolyte Taine (see Race, milieu, and moment).\n\nContemporary sociologists do not generally dispute that social phenomena take place within the natural universe and, as such, are subject to natural constraints, such as the laws of physics. Up for debate is the nature of the distinctiveness of social phenomena as a subset of natural phenomena. Broad support exists for the antipositivist claim that crucial qualitative differences mean that one cannot explain social phenomena effectively using investigative tools or even standards of validity derived from other natural sciences. From this point of view, naturalism does not imply scientism. \n\nHowever, a classically positivist conflation of naturalism with scientism has not disappeared; this view is still dominant in some old and prestigious schools, such as the sociology departments at the University of Chicago in the United States, and McGill University in Montréal, Canada.\n\nMore recently, actor-network theory has analyzed the social construction of the nature/society distinction itself.\n\n"}
{"id": "19324604", "url": "https://en.wikipedia.org/wiki?curid=19324604", "title": "Sumarr and Vetr", "text": "Sumarr and Vetr\n\nIn Norse mythology, Sumarr (Old Norse \"Summer\") and Vetr (Old Norse \"Winter\") are personified seasons. Sumarr and Vetr, personified, are attested in the \"Poetic Edda\", compiled in the 13th century from earlier traditional sources, and the \"Prose Edda\", written in the 13th century by Snorri Sturluson. In both, the two are given genealogies, while in the \"Prose Edda\" the two figure into a number of kennings used by various skalds.\n\nIn the stanza 26 of the \"Poetic Edda\" poem \"Vafþrúðnismál\", the god Odin (disguised as \"Gagnráðr\") asks the jötunn Vafþrúðnir from where warm Sumarr and Vetr come from, stating that they arrived \"first among the Wise powers\". In stanza 27, Vafþrúðnir responds:\n\nThe second half of this stanza is missing from early manuscripts, but some later manuscripts feature the addition of:\n\nIn chapter 19 of the \"Prose Edda\" book \"Gylfaginning\", Gangleri (king Gylfi in disguise) asks why there's an evident difference between summer and winter. The enthroned figure of High responds, and (after scolding him for asking a question everyone knows the answer to) states that the father of Sumarr is Svásuðr, who is quite pleasant, while the father of Vetr is referred to as Vindsvalr or, alternately, Vindljóni, and that Vetr derives his countenance from his ancestors, as they are \"cruel and cold-hearted kinsmen\".\n\nSumarr and Vetr are additionally personified in the \"Prose Edda\" book \"Skáldskaparmál\", where they are referred to in kennings. Kennings for Sumarr are given in chapter 30, including \"son of Svásuðr\", \"comfort of the snakes\", \"growth of men\", exemplified in an excerpt given from a work by the skald Egill Skallagrímsson where \"Valley-fish's mercy\" points to \"Snake's mercy\", which signifies \"Summer\". Kennings are given for Vetr in chapter 26; \"Son of Vindsvalr\", \"snake's death\", and \"storm season\". Excerpts of works by the skalds Ormr Steinþórsson (who uses the kenning \"Vindsvalr's son\") and Ásgrímr (who employs the kenning \"snake woe\") are then given as examples. Both Sumarr and Vetr are given as terms for \"times\" in chapter 63.\n\n"}
{"id": "53190615", "url": "https://en.wikipedia.org/wiki?curid=53190615", "title": "SunShot Initiative", "text": "SunShot Initiative\n\nThe SunShot Initiative is a federal government program run by the US Department of Energy's Solar Energy Technologies Office. It bills itself as a national effort to support solar energy adoption in order to make solar energy affordable for all Americans. The initiative is a collaboration of private companies, universities, state and local governments, and nonprofits, as well as national laboratories.\n\nThe program began in 2011 with the initial goal of making solar energy competitive with traditional forms of electricity by 2020. The federal government invested $282 million in FY 2015 to fund the SunShot Initiative. According to the SunShot Q4 2016/Q1 2017 Solar Industry Update report, The United States installed 14.8 GW of PV in 2016, an increase of 97% from 2015, representing approximately $30 billion in deployed capital, along with another $2.2 billion in U.S.- manufactured PV products.\n\nBy 2016, the program achieved 90% of the progress towards the 2020 goal. In September 2017, it was announced that it had already reached its 2020 goal, and was now refocusing on grid reliability issues.\n\nWhen the program was first launched in 2011 it set a series of goals and cost targets:\nIn 2016, the SunShot Initiative announced new cost targets that it wanted to be achieved by the year 2030:\nAccording to the program, \"These cost targets inform the decisions SunShot makes to spur the country’s solar market and drive deployment of solar energy.\"\n\nThe SunShot Initiative is divided into five subprograms:\nAll subprograms issue competitive awards to universities, national laboratories, nonprofit organizations, solar companies, and state and local governments to fund research and development projects that will aid in lowering the cost of electricity generated from solar technology.\n\nBelow is a spending breakdown of the Soft Costs program for fiscal year 2015:\n"}
{"id": "44422413", "url": "https://en.wikipedia.org/wiki?curid=44422413", "title": "Tom Denniss", "text": "Tom Denniss\n\nTom Denniss (born 24 February 1961) is an Australian athlete, inventor, scientist, and entrepreneur. A Doctor of Mathematics and Oceanography, he invented a technology to convert energy in ocean waves into electricity, founded a company to commercialise that technology (originally named Energetech Australia Pty Ltd in 1997, later changed to Oceanlinx Ltd in 2007), played professional rugby league, was a finalist in the Australian of the Year Award, and in 2013 set a new world record for the Fastest Circumnavigation of the Earth on Foot. In October 2016, Denniss co-founded Wave Swell Energy with a technology expected to make wave energy commercially viable for the first time.\n\nDenniss was born in 1961 in Wollongong, 80 km south of Sydney, Australia. He attended Warilla North Primary School from 1966 to 1973, and Lake Illawarra High School from 1974 to 1979, and was Student Council President at high school in 1979. From 1980 to 1982 Denniss completed a degree in Mathematics at the University of Wollongong, and a Diploma in Education from the University of New South Wales in 1983.\n\nA professional musician in his early life, Denniss has played to international audiences in eight different countries.\n\nInitially a high school maths teacher, Denniss taught at Newtown High School in Sydney from 1984 to 1990. While working at Newtown High, he attended UNSW part-time during 1988/89, obtaining a First Class Honours degree in Science. In 1990 Denniss left teaching to pursue a PhD in Mathematics and Oceanography at the same university. While completing his doctorate, from 1990 to 1994, he was an Associate Lecturer in the School of Mathematics at UNSW.\n\nFrom 1994 to 1999, Denniss worked at Macquarie Bank, a leading Australian investment bank. During this period he founded Energetech Australia and, during his spare time, began commercialising the wave energy technology he had earlier invented. In 1999 Denniss became full-time CEO of Energetech Australia.\n\nIn late 2004, Denniss stood aside as the CEO of Energetech, but continued in the role of Chief Technology Officer of the company. In 2005 he was invited by Jeffrey Sachs, Special Adviser to the UN Secretary General, to be a member of the Global Roundtable on Climate Change, serving on this forum until 2009. In 2006 the wave energy technology Denniss invented was named by the US based International Academy of Science as one of Ten Most Outstanding Technologies in the World. At a ceremony in Hawaii in 2007, Denniss was the first person to be inducted into the International Ocean Energy Hall of Fame as an ocean energy pioneer. In Shenzhen, China, in 2009, his innovative technology was ranked third by the United Nations Industrial Development Organization (UNIDO) in its annual list of the Top Ten Renewable Energy Investment Opportunities in the World.\n\nDenniss served as the Australian Government's representative on the International Energy Agency's Ocean Energy Systems Committee from 2007 to 2011 and on the Australian Government's Advisory Board for the Clean Energy Innovation Centre in 2010/11. In October 2016, Denniss co-founded Wave Swell Energy with a technology widely predicted to make wave energy commercially viable for the first time.\n\nOn 31 December 2011, Denniss began a quest to run around the world. He set a new world record and while doing so raised money for Oxfam. Dennis completed the 26,232 km journey on 13 September 2013, becoming just the second person to successfully complete a fully documented world run according to the rules defined by the sport's international governing body, the World Runners Association, in the process setting a new world record of 622 days for the Fastest Circumnavigation of the Earth on Foot. His accomplishment was the equivalent of running 622 marathons in 622 days in extremes of heat and cold.\n\nDenniss was a member of the Warilla North Primary School 4 x 100-metre relay team which won three consecutive New South Wales state titles from 1971 to 1973, setting state records in 1971 (Junior Boys 57.4 sec) and 1973 (Senior Boys 52.7 sec). He was also a member of the Lake Illawarra High 15 years 4 x 100-metre relay team in 1976 which won the New South Wales Combined High Schools state title in record time (45.4 sec).\n\nAs a 17-year-old in 1978, Denniss was selected as a reserve in the NSW Combined High Schools Rugby League team. The same year he was chosen to play first grade for the Warilla-Lake South Gorillas rugby league team in the NSW South Coast Rugby League competition. He was a regular First Grader until his retirement from the game in late 1982, the same year he was selected to play in the NSW Country Team in the NSWRL's annual City versus Country match. Denniss was also the leading try scorer in the South Coast competition in 1980 and 1981 for the \"Warilla Gorillas\".\n\nDenniss has also run 100 metres in 10.90 seconds (24 July 1978) and 100 km in 9 hours 26 mins 12 secs (2 May 2008). It has been postulated he is the only person ever to have run both 100 metres in less than 11 seconds and 100 km in less than 11 hours. Denniss also won the 2015 Icarus Ultrafest 12 hour race in Fort Lauderdale, Florida, and placed 3rd overall in the 250 km six day Great Red Race in Australia’s Simpson Desert in June 2017.\n\n\nTom Denniss, \"The World At My Feet\" 1 July 2015 – autobiographical account of his world run\n"}
{"id": "525538", "url": "https://en.wikipedia.org/wiki?curid=525538", "title": "Topsoil", "text": "Topsoil\n\nTopsoil is the upper, outermost layer of soil, usually the top to . It has the highest concentration of organic matter and microorganisms and is where most of the Earth's biological soil activity occurs. Topsoil is composed of mineral particles, organic matter, water, and air. Organic matter varies in quantity on different soils. The strength of soil structure decreases with the presence of organic matter, creating weak bearing capacities. Organic matter condenses and settles in different ways under certain conditions, such as roadbeds and foundations. The structure becomes affected once the soil is dewatered. The soil's volume substantially decreases. It decomposes and suffers wind erosion.\n\nPlants generally concentrate their roots in and obtain most of their vital nutrients from this layer. Actual depth of the topsoil layer can be measured as the depth from the surface to the first densely packed soil layer known as subsoil.\n\nIn soil classification systems, topsoil is known as the \"O Horizon or A Horizon,\" therefore, it is the very top layer.\n\nCommercially available topsoil (manufactured or naturally occurring) in the United Kingdom should be classified to British Standard BS 3882 with the current version dated 2015. The standard has several classifications of topsoil with the final classification requiring material to meet certain threshold criteria such as Nutrient Content, Extractable Phytotoxic Elements, Particle Size Distribution, Organic Matter Content, Carbon:Nitrogen ratio, Electrical Conductivity, Loss on Ignition, pH, Chemical and Physical Contamination. The topsoil should be sampled in accordance with the British Standard and European Norm BS EN 12579:2013 Soil improvers and growing media - Sampling. During construction of garden areas for housing plots the topsoil should be underlain by a layer of suitably certified subsoil that conforms to the British Standard BS 8601:2013 Specification for subsoil and requirements for use.\n\nIt is always recommended that for construction projects that topsoil is placed in accordance with the DEFRA report Construction Code of Practice for the Sustainable Use of Soils on Construction Sites \n\nWhen starting a gardening project, it is crucial to check whether or not the soil is satisfactory. Different types of plants vary in their nutrient needs and preferred soil conditions, many are strongly adapted to particular conditions. However, some general guidelines for \"desired levels of Topsoil nutrients\" have been made, broadly suitable for many plants.\nThe two common types of Topsoil are Bulk and Bagged Topsoil. The following table illustrates major differences between the two.\nAlternatively the British Standard relates to other working values:\n\nThis is for a multipurpose grade and certain levels can alter with regard to soil pH. Other uses specified in the standard that allows for a variety of uses in different and specific scenarios includes:\n\nAcidic, Calcareous, Low Fertility, Low Fertility Acidic and Low Fertility Calcareous. These uses are limited to specific site scenarios and acceptance should be on a case by case basis for construction projects.\n\nTopsoil is the primary resource for plants to grow and crops to thrive and the main two parameters for this are Carbon and Nitrogen. The Carbon provides energy and Nitrogen is a tissue builder and plants require them in a range of ratios to enable suitable growth. An optimum figure for Topsoil in the UK is a ratio of less than 20:1. This ensures that the soil has a suitable energy reserve as well as tissue building material to enable the plants to thrive. A sawdust typically has a carbonaceous base and this a high C:N ratio (in the order of c. 400:1) while an Alfalfa Hay has a low carbonaceous content and can typically have a C:N ratio in the order of 12:1.\n\nA variety of soil mixtures are sold commercially as topsoil, usually for use in improving gardens and lawns, e.g. container gardens, potting soil and peat. Another important yet not commonly known use for topsoil is for proper surface grading near residential buildings such as homes. \"The ground around the home should slope down six inches for the first ten feet away from the home. This can often be done by adding topsoil (not sand or gravel).\"\n\nA major environmental concern known as topsoil erosion occurs when the topsoil layer is blown or washed away. Without topsoil, little plant life is possible. The estimated annual costs of public and environmental health losses related to soil erosion exceed $45 billion. Conventional agriculture encourages the depletion of topsoil because the soil must be plowed and replanted each year. Sustainable techniques attempt to slow erosion through the use of cover crops in order to build organic matter in the soil. The United States alone loses almost 3 tons of topsoil per acre per year. This is of great ecological concern as one inch of topsoil can take between 500 and 1,000 years to form naturally. On current trends, the world has about 60 years of topsoil left.\n\nBecause of its use in commercial application and due to the environmental concerns regarding erosion, it is important for consumers to accurately determine how much topsoil they need for a given project. Topsoil is mainly sold by the cubic yard in the United States. To calculate the amount of topsoil you will need, \"simply take your length (in feet) multiplied by your width (in feet) multiplied by your depth (in feet so if you wanted 5 inches that would be 5/12) then divide the total by 27. This will give you your cubic yards needed for the project. Ex: 10L x 10W x (5/12) = 41.66/27 = 1.54 cubic yards of topsoil needed.\".\n\n\n\n"}
{"id": "21201377", "url": "https://en.wikipedia.org/wiki?curid=21201377", "title": "Tornadoes in New England", "text": "Tornadoes in New England\n\nTornadoes are fairly uncommon in the US region of New England. Fewer tornadoes are recorded here than anywhere else east of the Rocky Mountains. However, these deadly and destructive storms do occur; on average, about eight tornadoes are reported in the region each year. Almost 200 people have been killed by these storms in recorded history, and two of the ten most destructive tornadoes in US history occurred in this region.\n\nTornadoes are a violent weather phenomenon that occur most often in the United States, to the east of the Rocky Mountains. However, they most often occur in the Southern and Central United States, and are comparatively rare in New England. However, no region is immune to tornadoes if the weather conditions are right.\n\nWhile tornadoes have been recorded in almost every county in New England, there is a region just east of The Berkshires with a much higher concentration of tornado occurrences. This area is analogous to the Tornado Alley of the Great Plains, but on a much smaller scale.\n\nOn average (1950–2008), more than two tornadoes per year strike the state of Massachusetts alone, with New England as a whole recording more than 8. Most tornadoes reported in the region are \"weak\", rated EF0 or EF1 on the Enhanced Fujita Scale (the Fujita scale prior to 2007). Around 30% are \"significant\" tornadoes (rated EF2 or greater), and only 1% are violent (rated EF4 or EF5, the highest damage rating). Weak tornadoes occur in all areas of New England, but EF3 or greater tornadoes have been reported only in New England's practical \"Tornado Alley\" of Massachusetts, Connecticut, and southern New Hampshire.\n\nPeak tornado activity in New England occurs during the summer months of June, July and August. Tornadoes typically strike between 3 and 9 pm local time, and move at a forward speed of around .\n\nThere have been 34 killer tornadoes in New England's recorded history. Several of these tornadoes have killed people:\n\n\n\nOnly two tornadoes in the history of New England have killed more than 10 people: the 1953 Worcester Tornado and the 1878 Wallingford tornado. The Worcester Tornado killed as many as 94 people in Worcester, Massachusetts, on June 9, 1953, and the Wallingford Tornado killed as many as 34 in Wallingford, Connecticut, on August 8, 1878. These two tornadoes, both estimated to be of F4 intensity on the Fujita scale, killed more people than the rest of the tornadoes in the region's recorded history combined. Since most New England tornadoes are weak and short-lived, it is understandable why tornadoes causing fatalities are a rare occurrence.\n\nOf the costliest tornadoes in US history (adjusted for inflation), two occurred in New England: The 1979 Windsor Locks, Connecticut tornado, which caused $200 million in damage ($ million in 2018 USD), and the 1953 Worcester tornado, which caused $52 million in damage ($ million in 2018 USD). The Worcester tornado damaged or destroyed thousands of homes over a wide swath of central Massachusetts; the Windsor Locks tornado by contrast had a relatively small damage path, but it caused significant damage to parts of Bradley International Airport, including the New England Air Museum, where dozens of expensive and historic aircraft were damaged or destroyed, leading to the large damage figure.\n\n\n"}
{"id": "32959901", "url": "https://en.wikipedia.org/wiki?curid=32959901", "title": "United Nations-Oceans", "text": "United Nations-Oceans\n\nThe United Nations-Oceans (UN-Oceans or UN-O) is an inter-agency coordination mechanism of the United Nations, set up to enhance cooperation and coordination of activities concerned with the world oceans and coasts. The UN-Oceans was formed in September 2003 by the United Nations System Chief Executive Board (CEB), to replace the Sub-Committee on Oceans and Coastal Areas (SOCA) of the Administrative Committee on coordination (ACC) that was formed in 1993.\n\nFollowing the Earth Summit that took place in Rio de Janeiro on June 13, 1992, 178 governments of the United Nations agreed upon Agenda 21 as an action plan for the 21st century for sustainable living. As part of this sustainable living, UN agencies involved in the coordination of ocean and coastal issues formed the 'Sub-Committee on Oceans and Coastal Issues' (SOCA) as part of the 'Administrative Committee on cooridination' (ACC). This was in compliance with chapter 17 of Agenda 21 which refers to the protection of the Earth's oceans and the rational use and development of their resources in the 21st century.\n\nIn 2001, the ACC (now the United Nations System Chief Executive Board) conducted a review of its subsidiary committees (including SOCA) and announced that they should cease to exist by the end of 2001; that task-oriented arrangements such as those to do with the ocean, and any inter-agency support requirements be handled by a lead agency. Following consultations between UN Programs, agencies and organisations involved in coordinating oceans and coasts, indications of interest in forming a new inter-agency coordination mechanism became apparent. The United Nations High Level-Committee on programmes approved the creation of the United Nations-Oceans in 2003 as the new network in the UN system.\n\nThe UN Atlas of the Oceans was created under the authority of the UN-Oceans, as an information system designed for policy-makers and scientists to help them to know more about the oceans such as its biology, geology, research and exploration; issues of concern such as sustainable development and food security; and the uses of the ocean such as human settlement and extraction.\n\n"}
{"id": "22620616", "url": "https://en.wikipedia.org/wiki?curid=22620616", "title": "Urgellet", "text": "Urgellet\n\nUrgellet () is a historical territory and a natural region of Catalonia. It is located in the Pyrenees exactly in the actual administrative comarca of Alt Urgell, that last includes Baridà, Urgellet and the banks of Oliana, Peramola and Bassella.\n\nThe mountainous territory of Urgellet is almost wholly part of the Alt Urgell, except for the eastern Baridà and the southern sector. The Mollet Gorge is the natural boundary between the Urgellet and Baridà.\n\nThe history of Urgellet is highly related to \"Sedes Urgelli\" (La Seu d'Urgell or city of Urgell), the Bishop of Urgell and the County of Urgell. In the latter case, the territory Urgellet was leading the county, with capital in la Seu d'Urgell, and extended southwards up to the comarques of Urgell and Pla d'Urgell, among others. For this reason some towns and two comarques in Lleida contain the name of \"Urgell\" that has its origin in the city of Urgell and Urgellet region.\nThe name \"Urgell\" has a specifically Pyrenean pre-Roman origin. Linguist Joan Coromines interprets the meaning as related to the presence of water.\n\n"}
{"id": "23917138", "url": "https://en.wikipedia.org/wiki?curid=23917138", "title": "Ventisquero", "text": "Ventisquero\n\nIn Spanish language a ventisquero is a zone in a mountain where heavy snow accumulations occur. Before the term \"glaciar\" (Spanish for glacier) became widespread many glaciers in Patagonia were titled with ventisquero, such as Ventisquero Negro or Grandes Ventisqueros. \n"}
{"id": "36677484", "url": "https://en.wikipedia.org/wiki?curid=36677484", "title": "Vineyard Power Co-operative", "text": "Vineyard Power Co-operative\n\nVineyard Power Co-operative is \"a community owned renewable energy co-operative based on the island of Martha's Vineyard, Massachusetts.\" \n\nVineyard Power develops local renewable energy projects and plans to assist the island of Martha's Vineyard to meet the energy goals of the Island Plan, and work towards a 100% renewable energy supply. The founding of Vineyard Power was inspired by the renewable energy vision of the people of Samso island in Denmark. \n\nOffshore wind development is another of the motivations for creating the Vineyard Power Co-op, with the recognition this energy source would need community support. The National Renewable Energy Lab (NREL) classifies the sound and ocean around Martha's Vineyard to be \"Excellent\" (between 7.5 and 8 meters per second (m/s) in regard to energy generation potential, at 50 meters altitude) or \"Outstanding\" (between 8.0 and 8.8 m/s). The first proposal for offshore wind in the area, known as Cape Wind, created significant opposition focused on the lack of community involvement, and visual impacts. https://www.nrel.gov/news/program/2011/1437.html That project obtained a lease for development in Federal waters six miles from land in Nantucket Sound. \n\nVineyard Power organized public input into the planning wind farm development off the southern shores of the island, with OffshoreMW, and Bureau of Ocean Energy Management, Regulation and Enforcement (BOEMRE). This collaboration began as the Martha's Vineyard Offshore Wind Alliance (MVOWA) in 2011. The Vineyard Power Co-op signed a Community Benefits Agreement with that one developer to formalize this arrangement for mutual benefit, and to pursue better community input and economic development for the people of Martha's Vineyard. The development is now called Vineyard Wind. The permitting process for this offshore windfarm is underway.\n\nDuring the years when the Federal process for offshore wind development moved slowly, the Co-op identified opportunities to develop solar projects on the island. The first of these were solar canopies in the parking lot at the locally-owned supermaket. Benefits for more citizens came through building solar on town-owned landfills. Town of Aquinnah chose the company, after an RFP, for a solar plant. Construction was started and completed in 2012. The most recent solar project completed is on the roof of the Boys and Girls Club.\n\n\nThe Co-op promotes planning and practices that reduce fossil fuel use and the replacement with renewable electricity. The first solar canopies built by the Co-op include electric vehicle chargers. The Co-op continues to support electric vehicle adoption. Leaders of island organizations met in September 2017 at the initiative of the Co-op and Environment Massachusetts to develop a vision of 100% renewable energy use for the island.\n\n"}
{"id": "95278", "url": "https://en.wikipedia.org/wiki?curid=95278", "title": "Wandjina", "text": "Wandjina\n\nThe Wandjina (sometimes Wondjina) are cloud and rain spirits from Australian Aboriginal mythology that are depicted prominently in rock art in Australia. Some of the artwork in the Kimberley region of Western Australia dates back approximately 4,000 years ago.\n\nThe stories of the Wandjina and the artwork depicting them remain important to the Mowanjum Community of Indigenous people.\n\nWandjina were the inspiration for a 1966 children's fantasy television series, \"Wandjina!\", produced by ABC Television in 1966.\n\nDreamtime stories say the Wandjina created the landscape and its inhabitants, and continue to have influence over both. When the spirits found the place they would die, they painted their images on cave walls and entered a nearby waterhole. These paintings were then refreshed by Aborigines as a method of regenerating life force.\n\nThe Wandjina can punish those who break the law with floods, lightning and cyclones.\n\nThe broad-stroke artwork of the Wandjina rock art dates around 3800–4000 years ago. The emergence of this art style follows the end of a millennium-long drought that gave way to a wetter climate characterised by regular monsoons.\n\nThe Wandjina paintings have common colors of black, red and yellow on a white background. The spirits are depicted alone or in groups, vertically or horizontally depending on the dimensions of the rock, and are sometimes depicted with figures and objects like the Rainbow Serpent or yams. Common composition is with large upper bodies and heads that show eyes and nose, but typically no mouth. Two explanations have been given for this: they are so powerful they do not require speech and if they had mouths, the rain would never cease. Around the heads of Wandjina are lines or blocks of color, depicting lighting coming out of transparent helmets.\n\nToday, the paintings are still believed to possess these powers and therefore are to be approached and treated respectfully. Each site and painting has a name.\nIndigenous people of the Mowanjum Community repaint the images to ensure the continuity of the Wandjina's presence.\nAnnual repainting in December or January also ensures the arrival of the monsoon rains, according to Mowanjum belief.\n\nRepainting has occurred so often that at one site the paint is over 40 layers deep. The painting style has evolved during this process: more recent figures are stockier and some now possess eyelashes.\n\nIn late 1960's and early 1970's several Mowanjum artists depicted traditional Wandjina on pieces of string bark. These artworks were sold mainly through the mission at Kalumbaru. Some of the important artists from this region include Alec Mingelmanganu, Charlie Numbelmoore and Jack Karedada. These artworks are now in major museum collections around the world. Initially as per tradition only men painted Wandjina but in the early 1970's several women artists like Lily Karedada and Ignatia Djangharra also painted Wandjina on bark and later on canvass.\n\nIn 2007, graffiti depictions of Wandjina appeared in Perth, Western Australia. Styles ranged from stencil-work to a spray painted Wandjina driving a pink car. Using Flickr and blogs, several people engaged in 'Wandjina watching', documenting the Wandjina graffiti they found. These 'wandering Wandjina' angered and upset some Indigenous people who said that only certain of their people are permitted to depict the Wandjina, without saying who these people are. A short film, \"Who Paintin' Dis Wandjina\", discussed the Aboriginal reaction.\n\nImages of the Wandjina are displayed on the walls of the Ringwood Magistrates Court in Victoria; these are referenced as produced the National Gallery of Victoria.\n\n"}
