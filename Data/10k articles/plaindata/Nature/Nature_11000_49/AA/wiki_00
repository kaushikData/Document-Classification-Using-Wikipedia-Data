{"id": "41248816", "url": "https://en.wikipedia.org/wiki?curid=41248816", "title": "2010 JL88", "text": "2010 JL88\n\nOn May 17, 2010, it passed from Earth. It is on the lower of the Sentry Risk Table.\n\n has an Earth minimum orbit intersection distance of 0.45 Lunar Distances However, it only has a 1 in 1,449,000 (0.000069%) chance of impacting into Earth sometime after 2049. Even if it did impact, is so small that it would simply disintegrate in a manner similar to the Chelyabinsk meteor.\n\nThe asteroid was found to have a rapid rotation by the Magdalena Ridge Observatory's 2.4-meter telescope. It rotates at an extremely rapid rate of 24.5 seconds. is the second fastest natural rotating object discovered in the Solar System, after 2014 RC, which has a period of 16 seconds but still an uncertain period solution.\n\nList of exceptional asteroids\nList of fast rotators (minor planets)\n\n"}
{"id": "38432844", "url": "https://en.wikipedia.org/wiki?curid=38432844", "title": "2012 YQ1", "text": "2012 YQ1\n\nWith a 4-day observation arc, the asteroid had a 1 in 3 million chance of impacting in 2106. With a 10-day observation arc, the asteroid had a 1 in 10 million chance of impacting in 2106. On 5 January 2013, the asteroid passed from Earth. It was removed from the Sentry Risk Table on 8 January 2013. It has an observation arc of 32 days and an orbital uncertainty of 7. Since the asteroid has a poorly known orbit, the cone of uncertainty quickly multiplies as a result of perturbations by the inner planets and prevents precise/reliable ephemeris data. Eliminating an entry on the Sentry Risk Table is a negative prediction; a prediction of where it will NOT be.\n\nIn 2013, an article, originally posted on The Voice of Russia had a poorly researched headline stating \"We have 93 years left till the next End of the World\". This story was reposted on Space Daily, but then astronomer Phil Plait clarified that it was \"a fascinating mix of fact and error. A lot of what it says is accurate, but the most important claim—that an asteroid will impact Earth in 2106—is simply wrong.\"\n\n"}
{"id": "48221668", "url": "https://en.wikipedia.org/wiki?curid=48221668", "title": "2015 TB145", "text": "2015 TB145\n\nThe asteroid was first observed on 10 October 2015 by Pan-STARRS at an apparent magnitude of 20 using a Ritchey–Chrétien telescope. The asteroid was not discovered sooner because it spends most of its time beyond the orbit of Mars, has a large orbital inclination, and spends most of its time well below the plane of the ecliptic. The asteroid last passed within of Earth on 29 October 1923 and will not pass that close again until 1 November 2088.\n\nThe media has nicknamed the asteroid the \"Great Pumpkin\" after the animated Halloween television special \"It's the Great Pumpkin, Charlie Brown\", \"Spooky\", the “Halloween Asteroid”, and the “Skull Asteroid” due to its human skull-like appearance following radio frequency images taken at Arecibo Observatory and closest approach coincidentally occurring on Halloween day.\n\nOn 31 October 2015 the asteroid passed from the Moon and then passed from Earth.\n\nThe last approach this close by an object with absolute magnitude brighter than 20 was on 3 July 2006 at 1.1 lunar distances. The next object this large known to pass this close to Earth is that will pass about 1 lunar distance from Earth on 7 August 2027. It is estimated that there are about 2400 near-Earth asteroids 300–500 meters in diameter, of which about 1100 have been discovered.\n\nDuring closest approach to Earth the asteroid reached about apparent magnitude 10, which is much too faint to be seen by the naked eye. Even at peak brightness, the asteroid was a challenging target for amateur astronomers with small telescopes, best seen in the Northern hemisphere. The glare from an 80% waning gibbous Moon also hindered observations.\n\nAt 11:00 UT the asteroid was in the constellation of Taurus about 9 degrees from the Moon and moving at a rate of 3.4 degrees per hour. At the time of closest approach of 17:00 UT the asteroid was in the constellation of Ursa Major about 56 degrees from the Moon and moving at a rate of 14.7 degrees per hour. After closest approach it quickly became too faint and too close to the Sun in the sky to be seen.\n\nOn 11 November 2018 the flyby about from Earth. It will only brighten to magnitude 19.\n\nAfter it had been unobservable for almost three years, has been recovered on 7 October 2018 by L. Buzzi at Schiaparelli Observatory, at apparent magnitude 21.\n\nThe close approach was studied with radar using Goldstone, the Green Bank Telescope, and the Arecibo Observatory. It was one of the best radar targets of the year with a resolution as high as per pixel. Bistatic radar images created with the Green Bank Telescope had a resolution of per pixel. Arecibo images had a resolution of per pixel.\n\nThe high orbital inclination and eccentricity suggest may be an extinct comet that has shed its volatiles after numerous passes around the Sun. Orbital calculations by Petrus Jenniskens and Jérémie Vaubaillon showed that it was not expected to produce associated meteors in 2015. Any meteoroids were expected to pass more than from Earth's orbit. If meteoroids related to this asteroid were to cross Earth's path, the radiant is expected to be near Northern Eridanus. Cameras for Allsky Meteor Surveillance (CAMS) did not detect any activity in the presumed area of the sky during 2013 and 2014. The object has a low albedo of 0.06, which is only slightly more than a typical comet that has an albedo of 0.03-0.05.\n\n"}
{"id": "57744417", "url": "https://en.wikipedia.org/wiki?curid=57744417", "title": "AT2018cow", "text": "AT2018cow\n\nAT2018cow (ATLAS name: ATLAS18qqn; also known as Supernova 2018cow, SN 2018cow, and \"The Cow\") was a very powerful astronomical explosion, 10 – 100 times brighter than a normal supernova, spatially coincident with galaxy , approximately distant in the Hercules constellation. It was first detected on 16 June 2018 by the ATLAS-HKO telescope, and had generated significant interest among astronomers throughout the world. Later, on 10 July 2018, and after AT2018cow had significantly faded, astronomers, based on followup studies with the Nordic Optical Telescope (NOT), formally described AT2018cow as SN 2018cow, a type Ib supernova, showing an \"unprecedented spectrum for a supernova of this class\"; although others, mostly at first but also more recently, have referred to it as a type Ic-BL supernova. An explanation to help better understand the unique features of AT2018cow has been presented.\n\nOn 2 November 2018, two independent teams of astronomers both concluded that the AT2018cow event was \"either a newly formed black hole in the process of accreting matter, or the frenetic rotation of a neutron star.\"\n\nAT2018cow (ATLAS name: ATLAS18qqn; also known as Supernova 2018cow, SN 2018cow, and \"The Cow\") was first detected on 16 June 2018 at 10:35:02 UTC by the ATLAS-HKO telescope, a twin system, at the Haleakala Observatory in Hawaii. It was a powerful astronomical explosion (discovery magnitude 14.739; redshift 0.014145, 0.0136), 10 – 100 times brighter than a normal supernova, spatially coincident with galaxy , approximately distant in the Hercules constellation.\n\nBy 22 June 2018, this transient astronomical event had generated significant interest among astronomers throughout the world. At least 24 major telescopes were observing the event, the largest number, to date, of concurrent observations (over 35 posted on 27 June 2018) of any astronomical event ever reported on \"The Astronomer's Telegram\". The event had been tentatively identified as a supernova and given the designation Supernova 2018cow and classification SN Ic-BL.\n\nOn 25 June 2018, astronomers, using the Liverpool Telescope and the telescope at Palomar Observatory, noted on \"The Astronomer's Telegram\": \"AT2018cow has faded every night since our first observations (). ... observations suggest that although a link to Ic-BL SNe and GRBs remains credible given the smooth spectra and luminous radio and X-ray counterpart (), AT2018cow is distinct in other ways and its true identity remains unclear. Observations are continuing.\" On 29 June 2018, astronomers, using telescopes at the Beijing Astronomical Observatory, and on 30 June 2018, using the Swift/XRT telescope, reported further support for the fading of AT2018cow.\n\nOn 2 July 2018, astronomers, using the Fermi Large Area Telescope (LAT), reported that there were no significant >100 MeV gamma-ray emissions between 19–26 June 2018. Further, on 3 July 2018, astronomers reported, using the Cadmium Zinc Telluride Imager (CZTI) detector aboard the AstroSat space observatory, no hard X-ray transients were detected between 13–16 June 2018 (event detection time) and, using the UVIT fitted with a F172M filter, observed an AB magnitude of an estimated 17.6 at the AT2018cow location on 3 July 2018. Moreover, astronomers on 3 July 2018 reported, using the MAXI GSC detector aboard the ISS, that no significant X-ray emissions were detected between 11–21 June 2018. On 4 July 2018, astronomers, using NuSTAR, reported a lessening of hard X-ray emissions from AT2018cow. On 12 July 2018, astronomers, using INTEGRAL, reported no detections of the source from 30 June – 8 July 2018; however, GRB-like bursts may have been observed earlier in the vicinity, on 12 and 15 June 2018, although association of these bursts with AT2018cow may be \"disfavored\".\n\nRadio emissions, at 5 GHz with a flux density of ~ 170 microJy, were detected from the location of AT2018cow on 3–4 July 2018 by e-MERLIN; radio emissions at the AT2018cow location were detected by ATCA at 5.5 GHz with ~0.4 mJy flux density and at 9 GHz with ~1.0 mJy on 3 July 2018, and at 34 GHz with ~10 mJy on 5 July 2018. VLBI observations at 22 GHz, with the NRAO, using the VLBA and Effelsberg radio telescopes, found a total flux density of ~5 mJy around 8 July 2018 at a reportedly more accurate (but consistent within uncertainties) astrometric location of AT2018cow (RA=16h 16m 00.2242s, DEC=22d 16' 04.890\") than that of e-MERLIN.\n\nOn 10 July 2018, astronomers, based on followup studies with the Nordic Optical Telescope (NOT), formally described AT2018cow as SN 2018cow and as a type Ib supernova, showing an \"unprecedented spectrum for a supernova of this class\". On 19 July 2018, astronomers, using the Kanata telescope at the \nHigashi-Hiroshima Observatory, observed further declines in the optical and near-infrared luminosity of the AT2018cow position in early July 2018, and noted that the large decline rates of the light curves were \"quite large\" compared to Type Ic (Ic-BL) and Type Ib/c supernovae.\n\nOn 6 August 2018, ultraviolet observations of the AT2018cow location, using the Wide Field Camera 3 (WFC3) on the Hubble Space Telescope (HST), detected brightness (Vega mag) of about 19 on all four bands (F218W, F225W, F275W, F336W) studied. On 12 August 2018, astronomers at the Giant Metrewave Radio Telescope (GMRT) detected a low frequency radio emission (1390 MHz band; 438+/-82 uJy) at the AT2018cow position.\n\nOn 15 August 2018, astronomers using the High Energy Stereoscopic System (H.E.S.S.) array of Cherenkov telescopes (CTA) reported no significant gamma-ray source at the AT2018cow location on 3–5 July 2018, which, as a consequence, resulted in the preliminary determination of upper limits on the integrated flux of the Very-High-Energy (VHE) gamma emission from AT2018cow as follows: above the energy threshold 220 GeV (±2sd) an upper limit of 5e-12 ph cm^-2 s^-1; above 1 TeV (±2sd) an upper limit of 5e-13 ph cm^-2 s^-1.\n\nAccording to astronomers at the time of its discovery, the explosion, with a surface temperature of over and traveling , may have been a cataclysmic variable star (CV), gamma-ray burst (GRB), gravitational wave (GW), supernova (SN), or something else. According to astronomer Kate Maguire of Queen's University Belfast: \"It really just appeared out of nowhere. There are other objects that have been discovered that are as fast, but the fastness and the brightness, that's quite unusual.\"\n\nThe classification of type Ic-BL indicates a spectrum with very unusually broad lines, but with no hydrogen lines and weak or missing helium lines. Such a spectrum is produced by the explosion of a very large star which has lost its outer layers of hydrogen and helium. However, according to astronomer Shubham Srivastav, associated with the Himalayan Chandra Telescope (HCT): \"Although spectroscopic features indicate a tentative similarity with broad line Ic supernovae, its true nature remains a puzzle.\" Also, according to Maguire: \"We're not sure yet what it is, but the normal powering mechanism for a supernova is radioactive decay of nickel, and this event is too bright and too fast for that.\" The AT2018cow explosion could have been accompanied by a GW emission, but the GW emission could not be detected since the LIGO detectors in the states of Washington and Louisiana were down at the time of the event due to service upgradings.\n\nAn explanation to help better understand the unique features of AT2018cow, particularly as a white dwarf tidal disruption event, has been presented.\n\nAs of 29 September 2018, AT2018cow has been explained in various ways, including as a type Ic supernova, a gamma-ray burst, an interaction between a white dwarf and black hole, and as a magnetar. Preliminary studies to better understand the exact physical nature of AT2018cow, using the European VLBI Network (EVN), have been presented.\n\nOn 2 November 2018, two independent teams of astronomers both concluded that the AT2018cow event was \"either a newly formed black hole in the process of accreting matter, or the frenetic rotation of a neutron star.\"\n\n\n"}
{"id": "51529492", "url": "https://en.wikipedia.org/wiki?curid=51529492", "title": "Acquired neuroprotection", "text": "Acquired neuroprotection\n\nAcquired neuroprotection is a synaptic-activity-dependent form of adaptation in the nervous system that renders neurons more resistant to harmful conditions. The term was coined by Hilmar Bading. This use-dependent enhancement of cellular survival activity requires changes in gene expression triggered by neuronal activity and nuclear calcium signaling. In rodents, components of the neuroprotective gene program can reduce brain damage caused by seizure-like activity or by a stroke. In acute and chronic neurodegenerative diseases, gene regulatory events important for acquired neuroprotection are antagonized by extrasynaptic NMDA receptor signaling leading to increased vulnerability, loss of structural integrity, and bioenergetics dysfunction.\n"}
{"id": "37658639", "url": "https://en.wikipedia.org/wiki?curid=37658639", "title": "Adaptive Coloration in Animals", "text": "Adaptive Coloration in Animals\n\nAdaptive Coloration in Animals is a 500-page textbook about camouflage, warning coloration and mimicry by the Cambridge zoologist Hugh Cott, first published during the Second World War in 1940; the book sold widely and made him famous.\n\nThe book's general method is to present a wide range of examples from across the animal kingdom of each type of coloration, including marine invertebrates and fishes as well as terrestrial insects, amphibians, reptiles, birds and mammals. The examples are supported by a large number of Cott's own drawings, diagrams, and photographs. This essentially descriptive natural history treatment is supplemented with accounts of experiments by Cott and others. The book had few precedents, but to some extent follows (and criticises) Abbott Handerson Thayer's 1909 \"Concealing-Coloration in the Animal Kingdom\".\n\nThe book is divided into three parts: concealment, advertisement, and disguise. Part 1, concealment, covers the methods of camouflage, which are colour resemblance, countershading, disruptive coloration, and shadow elimination. The effectiveness of these, arguments for and against them, and experimental evidence, are described. Part 2, advertisement, covers the methods of becoming conspicuous, especially for warning displays in aposematic animals. Examples are chosen from mammals, insects, reptiles and marine animals, and empirical evidence from feeding experiments with toads is presented. Part 3, disguise, covers methods of mimicry that provide camouflage, as when animals resemble leaves or twigs, and markings and displays that help to deflect attack or to deceive predators with deimatic displays. Both Batesian mimicry and Müllerian mimicry are treated as adaptive resemblance, much like camouflage, while a chapter is devoted to the mimicry and behaviour of the cuckoo. The concluding chapter admits that the book's force is cumulative, consisting of many small steps of reasoning, and being a wartime book, compares animal to military camouflage.\n\nCott's textbook was at once well received, being admired both by zoologists and naturalists and among allied soldiers. Many officers carried a copy of the book with them in the field. Since the war it has formed the basis for experimental investigation of camouflage, while its breadth of coverage and accuracy have ensured that it remains frequently cited in scientific papers.\n\n\"Adaptive Coloration in Animals\" is a 500-page book, in its first edition. It was published by Methuen (in London) and Oxford University Press (in New York) in 1940. It is full of detailed observations of types of camouflage and other uses of colour in animals, and illustrated by the author with clear drawings and photographs. There is a coloured frontispiece showing eight of Cott's paintings of tropical amphibians. The book has 48 monotone plates and several illustrations.\n\nCott's method is to provide a large number of examples, illustrated with his own drawings or photographs, showing animals from different groups including fish, reptiles, birds and insects, especially butterflies. The examples are chosen to illustrate specific adaptations. For example, the fish \"Chaetodon capistratus\" is described as follows:\n\nCott was well aware that he was publishing in wartime. There are, as Julian Huxley remarks in his 'Introduction', references throughout the book to the human analogues of animal camouflage and concealment. For example, in the section on 'Adaptive Silence', the kestrel is said to \"practise dive-bombing attacks\", or \"after the fashion of a fighter 'plane\" to fly down other birds, while \"Owls have solved the problem of the silent air-raid\"; Cott spends the rest of that paragraph on the \"method which has recently been rediscovered and put into practice\" of shutting off a bomber's engines and \"gliding noiselessly down towards their victims\" at Barcelona in the Spanish Civil War. In the concluding chapter, Cott explicitly states \"The innumerable visible devices used .. in peace-time and in war-time .. are merely rediscovered .. applications of colour that have already reached a high .. degree of specialization and perfection .. in the animal world\", mentioning predator-prey relationships, sexual selection and signalling to rivals. He then compares the \"hunting disguises put on .. as a means of approaching, ambushing or alluring game, and the sniping suits, concealed machine-gun posts, and booby traps\" with the camouflage of animal predators; and similarly he compares \"protective disguises\" with the \"photographer's hide and the gunner's observation post.\" In the same section, Cott compares intentionally visible signs with animal warning colours: \"The policeman's white gloves have their parallel in the white stripes or spots of nocturnal skunks and carabids. The Automobile Association has adopted a system of coloration <nowiki>[black and yellow]</nowiki> whose copyright belongs by priority to wasps and salamanders.\"\n\nThe book addresses its subject under three main headings: concealment, advertisement, and disguise.\n\n\nCott sets out his view that we have to be re-taught how to see, mentioning Ruskin's \"innocence of the eye\". He argues that camouflage should, and in animals actually does, use four mechanisms: colour resemblance, obliterative shading (i.e. countershading, the graded shading which conceals self-shadowing of the lower body), disruptive coloration, and shadow elimination.\n\nChapter 1. General colour resemblance. \n\nChapter 2. Variable colour resemblance. Caterpillars and pupae (as in Poulton's famous experiment) are coloured to match their environment. Mountain hares change colour in winter; many fish, cephalopods, frogs, and crustacea can change colour rapidly.\n\nChapter 3. Obliterative shading. \n\nChapter 4. Disruptive coloration. \n\nCott goes on to explain that the right-hand drawing shows the effect \"of broken surroundings in further blending and confusing the picture\", observing that this is the closest to what is seen in nature. His readers are invited to look first at the right-hand images to gain an idea of the power of \"these optical devices\" as camouflage, putting off the moment when the animal is actually recognised.\n\nChapter 5. Coincident disruptive coloration.\n\nChapter 6. Concealment Of the shadow. \n\n\nChapter 7. Concealment in defence, mainly as illustrated by birds. \n\nChapter 8. Concealment In offence. \n\nChapter 9. Objections and evidence bearing on the theory of concealing coloration. \n\nChapter 10. The effectiveness of concealing coloration. \n\n\nChapter 1. The appearance and behaviour of aposematic animals. \n\nChapter 2. Warning displays. \n\nChapter 3. Adventitious warning coloration. \n\nChapter 4. The nature and function of warning coloration, as illustrated by the mammalia. \n\nChapter 5. The Protective Attributes Of Aposematic Animals In General. \n\nChapter 6. The relation between warning colours and distasteful attributes. \n\nChapter 7. The effectiveness of protective attributes associated with warning colours. \n\nChapter 8. Experimental evidence that vertebrate enemies learn by experience. \n\nChapter 9. Evidence of selective feeding by vertebrate enemies in a state of nature. \n\n\nChapter 1. Special resemblance to particular objects.\n\nChapter 2. Adaptive behaviour in relation to special cryptic resemblance.\n\nChapter 3. Adventitious Concealing Coloration.\nChapter 4. Deflective marks.\n\nChapter 5. Directive marks.\n\nChapter 6. Alluring coloration.\n\nChapter 7. Mimicry: the attributes of mimics.\n\nChapter 8. Breeding parasitism and mimicry in cuckoos. \n\nThe final chapter confirms that \"The force of the facts and arguments used in this work is cumulative in effect.\" Many small steps of reasoning combine to show that \"adaptive coloration ... has been ... one of the main achievements of organic evolution.\" The book ends by comparing human artefacts and \"natural adaptations\", both of which can have goals (recall the publication date of 1940, early in the Second World War) including \"the frustration of a predatory animal or of an aggressive Power\".\n\nJulian S. Huxley wrote a foreword (labelled 'Introduction') which defends the Darwinian concept of adaptation, especially of colour (in animals) and within that frame of mimicry. He makes it clear that \"in these last thirty years\" (that is, from about 1910 to 1940) he believed that \"experimental biologists\" professed, even if they did not actually hold, \"a radical scepticism on the subject of adaptations\", in other words about whether natural selection really could have created the enormous diversity of pattern and colour seen in nature. Huxley quoted the now long-forgotten Aaron Franklin Shull's 1936 \"Evolution\" which stated \"These special forms <nowiki>[</nowiki>sexual selection, warning colours, mimicry and signalling<nowiki>]</nowiki> of the selection idea ... seem destined to be dropped, or at least relegated to very minor places in the Evolution discussion.\", and more sharply that \"aggressive and alluring resemblance\" (Huxley's words) \"must probably be set down as products of fancy belonging to uncritical times.\" Huxley's reply is simply\n\nWith objections dismissed, Huxley remarks that \"Dr. Cott is a true follower of Darwin in driving his conclusions home by sheer weight of example,\" observing that \"Faced with his long lists of demonstrative cases, the reader is tempted to wonder why adaptive theories of coloration have been singled out for attack by anti-selectionists.\" Huxley also noted Cott's \"constant cross-reference to human affairs\", and that it was good to know that Cott was applying his principles \"to the practice of camouflage in war\".\n\nHuxley concluded his introduction by describing \"Adaptive Coloration\" as \"in many respects the last word on the subject\", upholding the great tradition of \"scientific natural history\".\n\nReviewers had little to compare \"Adaptive Coloration\" with. The English zoologist Edward Bagnall Poulton, a Darwinian, had written a 360-page book, \"The Colours of Animals\", fifty years earlier in 1890, and he was able, at age 84, to review Cott's work in \"Nature\" on its appearance in 1940, beginning with the words\n\nThe ichthyologist Carl Leavitt Hubbs, reviewing the book for \"American Naturalist\" in 1942, began\n\nHubbs notes that Cott is seeming concerned about the scarcity of experimental data for the survival value of camouflage, and accordingly relies on Sumner and Isely's \"clear-cut results\", but at once continues that Cott relies on \"the general lore of natural history\". Hubbs also remarks on the \"resurgence to Darwinian views\", referring to the scepticism about the power of natural selection among both geneticists of the time and to the Lamarckist views of Trofim Lysenko.\n\nHubbs observes that Cott is both an artist and a naturalist as well as a scientist: \"In section after section, rivaling one another in fascination, this master of art and of natural history unfolds the biological significance of adaptive coloration in animals.\" And Cott's emphasis on disruptive patterning and (following Thayer) countershading clearly affected the reviewer: \"Particularly impressive is the author's treatment of \"coincident disruptive coloration\", in which a ruptive mark crosses structural boundaries, so as to obliterate visually such ordinarily conspicuous parts as the eye and the limbs. Concealment of an animal's ordinarily telltale shadow is also stressed\". Hubbs's review ends \"This book is the work of an artist, and it is a work of art. Every biologist with an interest in any phase of natural history or evolution should keep it at hand.\"\n\n\"W.L.S.\", reviewing Cott in The Geographical Journal in 1940, begins with \"In this large and well-illustrated volume the author discusses at length reason or reasons for the various colour patterns found in the animal kingdom.\" The reviewer goes on \"He has presented us with a vast number of facts and observations which are somewhat difficult to analyse.\" However \"W.L.S.\" admits that disruptive coloration \"is discussed at considerable length by Mr. Cott and many remarkable instances of it are considered in detail\". The review ends by mentioning that while biologists (of the 1930s) usually \"reject the influence of Natural Selection in evolution, the facts of adaptive coloration as given in Mr. Cott's work are a strong argument in its favour, and must be given due weight. This is what Mr. Cott claims to have accomplished in a volume which will certainly take its place as a most valuable contribution to zoological literature.\"\n\nPeter Forbes, in his book \"Dazzled and Deceived\", wrote that\nOver 60 years after its publication, \"Adaptive Coloration in Animals\" remains a core reference on the subject. Sören Nylin and colleagues observe in a 2001 paper that\n\nAs a natural history narrative on what has become an intensely researched experimental subject, \"Adaptive Coloration\" could be thought obsolete, but instead, Peter Forbes observes \"But Cott's book is still valuable today for its enormous range, for its passionate exposition of the theories of mimicry and camouflage\". This width of coverage and continuing relevance can be seen in the introduction to Sami Merilaita and Johan Lind's 2005 paper on camouflage, \"Background-Matching and Disruptive Coloration, and the Evolution of Cryptic Coloration\", which cites \"Adaptive Coloration\" no fewer than eight times, quoting his terms \"cryptic coloration or camouflage\", \"concealing coloration\", \"background matching (also called cryptic resemblance)\", \"disruptive coloration\", resemblance to visual background, and the difficulty a predator has to detect a prey visually.\n\nSteven Vogel, in a review of Peter Forbes's book \"Dazzled and Deceived\" (2009), echoes Julian Huxley's words of seventy years before (in his 'Introduction') by writing\nCamouflage researcher Roy Behrens cites and discusses \"Adaptive Coloration\" frequently in his writings. For example, in his \"Camoupedia\" blog, related to the book of the same name, he writes of Cott's drawings of the hind limbs of the Common frog: \"Reproduced above is one of my favorite drawings from what is one of my favorite books.\" He continues \"What makes these drawings (and the book itself) even more interesting is that Cott (1900-1987) was not just a zoologist—he was a highly skilled scientific illustrator (these are his own pen-and-ink drawings), a wildlife photographer, and a prominent British camoufleur in World War II.\" Still in 2011, Behrens can write of Cott's way of thinking, citing his words as models of clear and accurate explanation of the mechanisms of camouflage: \"As he so aptly explained it, disruptive patterns work 'by the optical destruction of what is present', while continuous patterns work 'by the optical construction of what is not present.'\"\n\n\"Adaptive Coloration in Animals\" has been published as follows:\n\n\n\n"}
{"id": "6491732", "url": "https://en.wikipedia.org/wiki?curid=6491732", "title": "Alexander Hugh Chisholm", "text": "Alexander Hugh Chisholm\n\nAlexander Hugh Chisholm (1890-1977) also known as Alec Chisholm, was a noted Australian journalist, newspaper editor, author and amateur ornithologist. He was a member of the Royal Australasian Ornithologists Union (RAOU), President of the RAOU 1939-1940, and Editor of its journal the \"Emu\" 1926-1928. He was elected a Fellow of the RAOU in 1941. He was the first recipient of the Australian Natural History Medallion in 1940 for his work in ornithology and popularising natural history. Chisholm was a prolific writer of articles and books.\n\nChisholm spent seven years as a journalist in Queensland, moving to Sydney in 1922 where he became news editor of the \"Daily Telegraph\" and later editor of the \"Sunday Pictorial\". He was also president of the Institute of Journalists. After moving to Melbourne, he was for many years editor of the \"Australasian\", before being appointed editor of \"The Argus\" in June 1937.\n\n\nIn 1923 Chisholm married Olive May Haseler in Brisbane.\n\n"}
{"id": "39014655", "url": "https://en.wikipedia.org/wiki?curid=39014655", "title": "Arsameia", "text": "Arsameia\n\nArsameia on the Nymphaios (, , ) is an ancient city located in Old Kâhta (Eski Kâhta) in Kâhta district, Adıyaman Province, Turkey. The site is near Kâhtaçay, known in ancient times as Nymphaios. Arsameia was a royal seat of the kingdom of Commagene. It is best known for the Hierothesion of King Mithridates I Kallinikos, built for him by his son and heir Antiochos I.\n\nThe ancient town of Nymphaios was renamed Arsameia in the third century BCE by the Armenian king Arsames (255–225 BCE). It was then taken in 235 BCE by the Seleukid Antiochus Hierax who was fleeing from his brother Seleucus II, who was later claimed as an ancestor by the Commagenian King Antiochus I. The city had already been abandoned again by Roman times, stones from local graves were used by Roman soldiers or building bridges.\n\nThe Greek word Hierothesion (ἱεροθέσιον) is term for the holy burial areas of those belonging to the royal house, and is only known from Commagene. Apart from the Hierothesion which Antiochos himself built on Nemrut Dağı, and the second one on Karakuş which his son Mithridates II built for the female members of the royal house, a third is to be found in Arsameia, the burial site and the associated cultic area for Antiochus' father Mithridates. A processional way leads up the mountain in the form of a Z and passes three sites which its discoverer Friedrich Karl Dörner marked as Sites I–III. At the first of these, Site II, stands the fragment described as the Mithras Relief. It is the right hand side of a dexiosis, which shows Antiochos or Mithridates shaking hands with the sun god Mithras. Antiochus and those associated with him depicted themselves as being on the same level as the gods through these representations which are distributed throughout Commagene. Dörner was able to re-erect the upper and lower halves of Mithras, of the left-hand side of the relief only part of a shoulder was found, which Dörner however identified with one of the kings due to its clothing.\n\nOn the first bend of the path is located Site I. Here too can be seen the remains of the depiction of a dexiosis, in which the portraits can no longer be identified. In addition to this there is a hallway carved into the rock, from which 14 steps lead up to a further room, nine meters high and about eight by eight meters in size. The function of this is not clear; Dörner took it to be a temple to Mithras, while other archaeologists conjecture that it could be the burial site of Mithridates.\n\nThe path leads on further to Site III. Here on a wall of rock was found an inscription of Antiochos in five columns, in which he relates the story of how the city was founded and the building of the Hierothesion as well as detailed instructions about how to carry out the rites that needed to be performed. Since the inscription had been almost completely covered in earth from ancient times it is still in an amazing condition. In the lower part of the inscribed wall a walkway begins that goes steeply up the rock and then suddenly ends after 158 metres. Nothing is known about its purpose. Above the wall stands the best preserved dexiosis relief of Commagene. It shows one of the two kings, either Antiochos or Mithridates shaking hands with a naked Herakles, recognizable from his club.\n\nThe processional way leads further beyond this site as far as the summit of the mountain. There was found the foundations of buildings with mosaic flooring, which can be dated back to the Second Century before Christ. On the basis of fragments of sculpture Dörner takes it that this is where the mausoleum of Mithridates stood, decorated with statues.\n\nAbout two kilometers away, on the other side of the Kahtaçay, lies the fortress of Yenikale (English: \"New Castle\"). Here according to the inscription at Site III lay the Palace buildings of the Commagenian rulers. Today one can see a Mameluke castle. In its interior are found building and restoration inscriptions from the sultans Qala'un (1279–90), Al-Ashraf Khalil (1290–93) and al-Nasir Muhammad (1293–1341). An earlier building had already been conquered and destroyed in 1286 by Kara Sonkar, the governor of Aleppo. A path leads from the lower part of the castle on the side of the river to a building known as the \"Pigeon Castle\", which is positioned under an overhanging ledge of rock. It was used to provide water to the castle, as well as relaying it over a bridge to the Eski Kale. On the top floor is a room set up as a homing pigeon house, with a rectangular hole entry hole and 32 nesting niches. It was still being used for communications as late as the 13th century when the Sultan Qala'un was seeking information about the troop movements of the hostile Ilkhanate before the Second Battle of Homs.\n\nTo the west of the two mountains of Yenikale and Eskikale Dörner and his colleague Wilhelm Winkelmann discovered an area of iron smelting, the first in Commagene. The remains of furnace walls, bits of slag, salamanders (the remains of pig iron left when smelting), as well as sharp pieces and coins.\n\nDuring the course of investigations at Nemrut Dağı in 1951 Dörner's was drawn by a local to the \"Picture Stone\". After careful examination this proved to be the relief representing Mithras from Site II. When he later found the inscriptional wall of Site III, which he could read straight away thanks to its excellent state of preservation, he was able to identify the site as the Commagenian royal seat of Arsameia. In 1953 he undertook the first excavations. Along with the American Theresa Goell he uncovered between the years 1953–56 the finds that are visible today. From 1963 further excavations took place. Some of the finds are now exhibited in the Archaeological Museum at Gaziantep.\n\n\n"}
{"id": "26114602", "url": "https://en.wikipedia.org/wiki?curid=26114602", "title": "Back-story (production)", "text": "Back-story (production)\n\nBack-story, in the production of consumer goods, is information about the effects of their production.\n\n"}
{"id": "20909548", "url": "https://en.wikipedia.org/wiki?curid=20909548", "title": "Baduhenna", "text": "Baduhenna\n\nIn Germanic paganism, Baduhenna is a goddess. Baduhennna is solely attested by Tacitus's \"Annals\" where Tacitus records that a grove in ancient Frisia was dedicated to her, and that near this grove 900 Roman soldiers were killed in 28 CE. Scholars have analyzed the name of the goddess and linked the figure to the Germanic Matres and Matronae. \n\nThe first element of the goddess's name, \"Badu-\", may be cognate to Proto-Germanic \"*badwa-\" meaning \"battle.\" The second portion of the name \"-henna\" appears as \"-henae\" in the names of matrons, Germanic goddesses widely attested from the 1st to 5th century CE on votive stones and votive altars. Rudolf Simek states that the goddess's name etymology implies that the goddess is associated with war, and Simek points out that sacred groves are commonly associated with the Germanic peoples.\n\nBaduhenna is solely attested in book 4, chapter 73 of Tacitus's \"Annals\". In chapters 73 and 74 of \"Annals\", Tacitus describes the defeat of the Roman army in ancient Frisia:\n\n\n"}
{"id": "740171", "url": "https://en.wikipedia.org/wiki?curid=740171", "title": "Baptism with the Holy Spirit", "text": "Baptism with the Holy Spirit\n\nIn Christian theology, baptism with the Holy Spirit (also called baptism in the Holy Spirit or Spirit baptism) or baptism with the Holy Ghost, is distinguished from baptism with water. It is frequently associated with incorporation into the Christian Church, the bestowal of spiritual gifts, and empowerment for Christian ministry.\n\nThe term \"baptism with the Holy Spirit\" originates in the New Testament, and all Christian traditions accept it as a theological concept. Nevertheless, different Christian denominations and traditions have interpreted its meaning in a variety of ways due to differences in the doctrines of salvation and ecclesiology. As a result, Spirit baptism has been variously defined as part of the sacraments of initiation into the church, as being synonymous with regeneration, as being synonymous with Christian perfection, or as being a second work of grace that empowers a person for Christian life and service.\n\nBefore the emergence of the holiness movement in the mid-19th century and Pentecostalism in the early 20th century, most denominations believed that Christians received the baptism with the Holy Spirit either upon conversion and regeneration or through rites of Christian initiation, such as water baptism and confirmation. Since the growth and spread of Pentecostal and charismatic churches, however, the belief that the baptism with the Holy Spirit is an experience distinct from Christian initiation has come into increasing prominence.\n\nIn Christian theology, the work of the Holy Spirit under the Old Covenant is viewed as less extensive than that under the New Covenant inaugurated on the day of Pentecost. The Spirit was restricted to certain chosen individuals, such as high priests and prophets. Often termed the “spirit of prophecy” in rabbinic writings, the Holy Spirit was closely associated with prophecy and divine inspiration. It was anticipated that in the future messianic age God would pour out his spirit upon all of Israel, which would become a nation of prophets.\n\nWhile the exact phrase \"baptism with the Holy Spirit\" is not found in the New Testament, two forms of the phrase are found in the canonical gospels using the verb \"baptize\", from the Greek word \"baptizein\" meaning to \"immerse\" or \"plunge\". The baptism was spoken about by John the Baptist, who contrasted his water baptism for the forgiveness of sins with the baptism of Jesus. In Mark 1 and John 1, the Baptist proclaimed that Jesus \"will baptize in (the) Holy Spirit\"; while in Matthew 3 and Luke 3, he \"will baptize with Holy Spirit and fire\".\n\nJesus is considered the first person to receive the baptism with the Holy Spirit. The Holy Spirit descended on Jesus during his baptism and anointed him with power. Afterward, Jesus began his ministry and displayed his power by casting out demons, healing the sick, and teaching with authority.\n\nThe phrase \"baptized in the Holy Spirit\" occurs two times in Acts of the Apostles, first in Acts 1:4–5 and second in Acts 11:16. Other terminology is used in Acts to indicate Spirit baptism, such as \"filled\". \"Baptized in the Spirit\" indicates an outward immersion into the reality of the Holy Spirit, while \"filled with the Spirit\" suggests an internal diffusion. Both terms speak to the totality of receiving the Spirit. The baptism with the Holy Spirit is described in various places as the Spirit \"poured out upon\", \"falling upon\", \"coming upon\" people. To \"pour out\" suggests abundance and reflects John 3:34, \"God gives the Spirit without limit\". Another expression, \"come upon\" is related to a statement by Jesus in Luke 24:49, \"I am sending the promise of my Father upon you. But stay in the city until you are clothed with power from on high\". The language of \"come on\" and \"clothed with\" suggest possession by and endowment with the Holy Spirit.\n\nThe narrative of Acts begins after Jesus’ crucifixion and resurrection. The resurrected Jesus directed his disciples to wait in Jerusalem for the baptism in the Holy Spirit and promised, \"you will receive power when the Holy Spirit has come upon you, and you will be my witnesses in Jerusalem and in all Judea and Samaria, and to the end of the earth\". After his ascension, he was given authority to pour out the Holy Spirit.\n\nIn the New Testament, the messianic expectations found in early Judaism were fulfilled on the day of Pentecost as recorded in Acts. The Christian community was gathered together in Jerusalem when a sound from heaven like rushing wind was heard and tongues like tongues of flame rested on everyone. They were filled with the Holy Spirit and began to speak in tongues, miraculously praising God in foreign languages. A crowd gathered and was addressed by the Apostle Peter who stated that the occurrence was the fulfillment of the prophecy of Joel 2, \"And in the last days it shall be, God declares, that I will pour out my Spirit on all flesh, and your sons and your daughters shall prophesy\". He then explained how the Spirit came to be poured out, recounting Jesus’ ministry and passion and then proclaiming his resurrection and enthronement at the right hand of God. In response, the crowd asked Peter what they should do. He responded that they should repent and be baptized for the forgiveness of sins in order to receive the gift of the Holy Spirit. Peter finished his speech stating that the promise \"is for you and for your children and for all who are far off, everyone whom the Lord our God calls to himself\".\n\nBaptism in the Holy Spirit occurs elsewhere in Acts. The gospel had been proclaimed in Samaria and the apostles Peter and John were sent from Jerusalem. The new believers had been baptized in water, but the Holy Spirit had not yet fallen on them. The Samaritans received the Holy Spirit when Peter and John laid their hands on them. The Apostle Paul was also filled with the Holy Spirit when Ananias of Damascus laid hands on him, and afterwards Paul was baptized with water.\n\nLater in Acts, Peter preached the gospel to the household of Cornelius the Centurion, a gentile. While he preached, the Holy Spirit fell on the gentiles, and they began to speak in tongues. The Jewish believers with Peter were amazed, and the household was water baptized. While the apostle Paul was in Ephesus, he found disciples there and discovered that they did not know of the existence of the Holy Spirit and had only received John the Baptist’s baptism. After baptizing them in Jesus’ name, Paul laid his hands on them, and they began to speak in tongues and prophesy.\n\nIn the early Church, the laying on of hands on the newly baptized to impart the gift of the Holy Spirit was the origin of the sacrament of confirmation. In the Eastern church, confirmation continued to be celebrated immediately after water baptism. The two rites were separated in the Western church. According to Pentecostal historian H. Vinson Synan, \"the basic premise of Pentecostalism, that one may receive later effusions of the Spirit after initiation/conversion, can be clearly traced in Christian history to the beginnings of the rite of confirmation in the Western churches\".\n\nHuldrych Zwingli, a leading Protestant Reformer in Switzerland, taught three distinct baptisms: water baptism, teaching baptism (having been educated about the Christian religion) and Spirit baptism. While full baptism included all three, Zwingli emphasized that the external baptisms of water and teaching could not provide salvation. The inner baptism of the Spirit alone could save because it conferred faith. According to Zwingli, the three baptisms could be given separately; Spirit baptism could occur first or last in the sequence.\n\nMany Puritans believed that the conversion experience was followed by a later and distinct experience of the Holy Spirit. This experience was characterized by receiving assurance of one's salvation. English Puritan Thomas Goodwin equated this experience with the baptism in the Holy Spirit and the \"seal of the Spirit\" referenced in Ephesians 1.\n\nSynan traces the influence of Catholic and Anglican mystical traditions on John Wesley's doctrine of Christian perfection or entire sanctification, from which Pentecostal beliefs on Spirit baptism developed. Furthermore, theologian James Dunn notes early Methodist beliefs can be directly linked to Puritan teaching on the Holy Spirit.\n\nWesley taught that while the new birth was the start of the Christian life, \"inbred sin\" remained and must be removed through a lifelong process of moral cleansing. John Fletcher, Wesley's designated successor, called Christian perfection a \"baptism in the Holy Spirit\". His \"Checks to Antinomianism\" later became a standard for Pentecostally-inclined holiness teachers. On the subject, Fletcher wrote:\nIn mid-19th century America, the Wesleyan holiness movement began to teach that entire sanctification was less a process and more of a state that one entered into by faith at a definite moment in time. This second blessing (or second work of grace), as it was commonly called, allowed Christians to be freed from the power of sin. Among adherence of the holiness movement, baptism in the Holy Spirit was synonymous with second blessing sanctification.\n\nAfter his conversion in 1821, Presbyterian minister and revivalist Charles Grandison Finney experienced what he called \"baptism in the Holy Spirit\" accompanied by \"unutterable gushings\" of praise. Finney and other Reformed writers, known as Oberlin perfectionists, agreed that there was a life altering experience after conversion, but unlike their Wesleyan holiness counterparts, they conceived of it as an ongoing process enabling believers to devote themselves wholly to Christ's service. Similarly, the English Higher Life movement taught that the second blessing was an \"enduement of power\". According to this view, Spirit baptism gave Christians the ability to be witnesses for the gospel and to perform Christian service. Wesleyan teachers emphasized purity while Oberlin and higher life advocates stressed power as the defining outcome of Spirit baptism.\n\nIn the early 1890s, R.C. Horner, a Canadian holiness evangelist, introduced a theological distinction that would be important for the development of Pentecostalism. He argued in his books \"Pentecost\" (1891) and \"Bible Doctrines\" (1909) that the baptism in the Holy Spirit was not synonymous with the second blessing but was actually a third work of grace subsequent to salvation and sanctification that empowered the believer for service. Charles Fox Parham would build on this doctrinal foundation when he identified speaking in tongues as the Bible evidence of Spirit baptism.\n\nThe diverse views on Spirit-baptism held among Christian traditions can be categorized into three main groups. These are baptism with the Spirit as sacramental initiation (Orthodox and Catholic churches), regeneration (Reformed tradition), and empowerment for witness and vocation (Pentecostals and charismatics).\n\nOrthodox Churches believe that baptism in the Holy Spirit is conferred with water baptism. The individual is anointed with oil (chrism) immediately after baptism. According to Cyril of Jerusalem:\nThe Catholic Church teaches that baptism, confirmation, and the Eucharist—the sacraments of Christian initiation—lay the foundations of the Christian life. The Christian life is based on baptism. It is \"the gateway to life in the Spirit\" and \"signifies and actually brings about the birth of water and the Spirit\". The post-baptismal anointing (Chrismation in the Eastern churches) signifies the gift of the Holy Spirit and announces a second anointing to be conferred later in confirmation that completes the baptismal anointing.\n\nConfirmation, then, is necessary for the completion of baptismal grace. When confirmed, Catholics receive the \"special outpouring of the Holy Spirit as once granted to the apostles on the day of Pentecost\". For the confirmand it increases the seven gifts of the Holy Spirit (wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord), unites more fully to Christ and the Church, and gives strength to confess Christ and defend the faith. The rite of confirmation orients toward mission, and many liturgical texts remind the initiate that the gift of the Holy Spirit should be used for service to the church and the world.\n\nThe main position on Spirit baptism among the Reformed churches, dispensationalists, and many Baptists is that the baptism with the Holy Spirit occurs simultaneously with regeneration, when those who have faith in Jesus Christ receive the Holy Spirit and are incorporated into the body of Christ.\n\nWithin Methodism and the broader Wesleyan tradition, baptism with the Holy Spirit has often been linked to living a sanctified life. The United Methodist Church has a sacramental view of baptism and confirmation, in which the believer receives and is strengthened by the Holy Spirit, respectively. At the same time, the United Methodist Confession of Faith also affirms Wesley's doctrine of Christian perfection (also known as entire sanctification), the second work of grace:\n\nSimilarly, the churches in the holiness movement emphasize entire sanctification as a definite experience linked to Spirit baptism:\nAccording to the Articles of Faith of the Church of the Nazarene, sanctification is a work of God after regeneration \"which transforms believers into the likeness of Christ\" and is made possible by \"initial sanctification\" (which occurs simultaneously with regeneration and justification), entire sanctification, and \"the continued perfecting work of the Holy Spirit culminating in glorification\". Entire sanctification (as opposed to initial sanctification) is an act of God in which a believer is made free from original sin and able to devote him or herself entirely to God:\n\nIn classical Pentecostalism, the baptism with the Holy Spirit is understood to be a separate and distinct experience occurring sometime after regeneration. Influenced by the Holiness movement, baptism with the Holy Spirit was regarded by the first Pentecostals as being the third work of grace, following the new birth (first work of grace) and entire sanctification (second work of grace). Baptism with the Holy Spirit is an empowering experience, equipping Spirit-filled believers for witness and ministry. Extending from this is the belief that all the spiritual gifts mentioned in the New Testament are to be sought and exercised to build up the church. Pentecostals believe that Spirit baptism will be accompanied by the physical evidence of speaking in tongues (glossolalia).\n\nAccording to Pentecostal biblical interpretation, the Gospel of John 20:22 shows that the disciples of Jesus were already born again before the Holy Spirit fell at Pentecost. They then cite biblical examples in the Book of Acts 2, 8, 10, and 19 to show that it was common in the New Testament for Spirit baptism to occur after conversion. In following the biblical pattern, they argue, Christians today should also pray for this baptism which results in greater power for ministry and witness.\n\nOn the subject of Spirit baptism, Donald Gee wrote of the Christians on the Day of Pentecost:\n\nIn Pentecostal experience, Spirit baptism can be quite dramatic, as shown by William Durham's account of his Spirit baptism:\n\nIn some accounts of Spirit baptism, Pentecostals report receiving visions, such as the account of Lucy Leatherman, an Azusa Street participant:\n\nCharismatics trace their historical origins to the charismatic movement of the 1960s and 1970s. They are distinguished from Pentecostals because they tend to allow for differing viewpoints on whether Spirit baptism is subsequent to conversion and whether tongues is always a sign of receiving the baptism.\n\nThe Catholic Charismatic Renewal believes that there is a further experience of empowerment with the Holy Spirit. As stated by Rev. Fr. Raniero Cantalamessa, \"baptism in the Spirit is not a sacrament, but it is related to a sacrament…to the sacraments of Christian initiation. The baptism in the Spirit makes real and in a way renews Christian initiation\". Emphasis of the event is on the release of existing spiritual gifts already given to the individual through baptism in water and confirmation.\n\nDuring the 1980s, another renewal movement emerged called the \"Third Wave of the Holy Spirit\" (the first wave was Pentecostalism and the second wave was the charismatic movement). Third wave charismatics stress that the preaching of the gospel, following the New Testament pattern, should be accompanied by \"signs, wonders, and miracles\". They believe that all Christians are baptized with the Holy Spirit at conversion, and prefer to call subsequent experiences as \"filling\" with the Holy Spirit. John Wimber and the Vineyard churches are most prominently associated with this label.\n\nIn the Latter Day Saint movement, the \"Baptism of fire and of the Holy Ghost\" refers to the experience of one who undergoes the ordinance of confirmation with the laying on of hands to receive the gift of the Holy Ghost. It follows baptism in water and is essential to salvation. The gift of the Holy Ghost is the privilege of receiving inspiration, divine manifestations, direction, spiritual gifts, and other blessings from the Holy Spirit (see Gifts of the Spirit in Mormonism). It begins the lifetime process of sanctification.\n\n\n\n\n\n"}
{"id": "31213588", "url": "https://en.wikipedia.org/wiki?curid=31213588", "title": "Cabarceno Natural Park", "text": "Cabarceno Natural Park\n\nThe Natural Park is located in Cabárceno, Pisueña Valley (region of Pas-Miera) from Santander, located in a former iron mine in the town of Cabárceno Township Penagos (Cantabria, Spain). The park belongs to Cantur, a company whose purpose is the promotion of tourism and which is owned by the Government of Cantabria.\n\nCabárceno Park has two roles: one is the conservation of endangered species and the other is environmental education.\n\n\"The natural park of Cabárceno\" is neither a zoo nor a natural park (\"parque natural\") in the normal Spanish use of the term. It is a naturalized space reclaimed from of a former open pit mine to the primitive beauty of the karst landscape.\n\nThe natural park is home to a hundred animal species from five continents living in semi-free conditions, which are distributed in large enclosures where one or more species coexist.\n\nExcept for food provided to them, the rest of the animal's activities are marked by their almost total freedom. Almost all of them trigger fights and mating season struggles for control of females.\nMore than of roads cross the park, leading to gorges, lakes, and rock figures. Throughout the park are parking areas and trails.\n\nVenomous snakes such as cobras, rattlesnakes, and giant snakes, and turtles and lizards, can be seen. The reptiles' section is located at the entrance of Obregon Park, next to the café La Mina.\n\nThe park has many animal species, for example:\n\n\nThe Nature Park Cabárceno hosts throughout the year thousands of people.\n\nThe facilities that host animals are internationally recognized as one of the best there exist in the world.\n\nFacilities available at the park include nursing, public phones, ATM, reptiles, environmental classroom, picnic areas, parking areas, self-service, cafeteria, restaurant, and souvenir shops.\n\nLocated in the heart of the Park, opposite the exhibition of ostriches and antelopes. A cafeteria and souvenir shop, with snacks, sandwiches and drinks. It has a terrace with the bear enclosure in the background. The Restaurant \"Bears\" has a capacity for 280 diners.\nLocated in the area of environmental education, has a capacity of 400 guests.\n\nLocated next to the elephant enclosure and the lake of the same name.\n\nLocated next to the reptile house at the main entrance of the park. It has a gift shop and terrace.\n\nThere are 24 of the 100 trees in the park grown in three of the most visited places: tigers, hyenas, wolves and lions.\n\nBotanical paths are paths that are located near animal enclosures, in which plant species are displayed.\n\nIn the gardens there are yew, oak, walnut, bamboo, birch, olive, oak, pine, cherry, horse chestnut, alder, oaks, holly, cypress, laurels, figs, bananas, strawberry, laurel, oleander, Atlas cedar, ginkgo, an ornamental barberry (Bordeaux color), mock orange, pistosporos, etc. ..\n\nHyenas: birch, olive, cherry, oak (also known as cajiga or Carbayo), oaks, chestnut oaks, elders, etc.\n\nLobos: laurel, willow, oak, lime and beech trees.\n\nPines, olive trees, oaks, chestnut, fig, maples, oaks, chestnuts pines, maritime pine trees, cherry, medlar, oleander, Pyracantha, cordelynes, griñoleras, etc.\n\nThe Environmental Education Workshop Nature Park Cabárceno has educational programs for grade levels between 3 and 18.\n\nOne of the issues that justify the existence of zoos today in addition to the conservation of endangered species is undoubtedly the ability to undertake research to assist the conservation of these species.\n\nSo the park has pioneered, in collaboration with the Deutsches Primatenzentrum and the University of Göttingen (Germany), the development of techniques that have allowed the knowledge of the sexual cycle in female African elephant by noninvasive methods (using samples feces and urine).\n\nThe park collaborates in behavioral studies of the male African elephant, verifying, also by non-invasive, hormone profiles and thereby study the reason for the highly aggressive showing male elephant at certain times of the year. Known by the name \"Musht\", in this state the male is dangerous and causes accidents.\n\nThe park collaborates with zoos and partnerships in the conservation of endangered species like tigers, lions, bobcats, rhinos, etc.\n\nThe park is a member of AIZA and EAZA (Iberian Association of Zoos and Aquaria European), of Endangered Species threatened with Extinction (EEP) and in the herd books (studbook) of most species in the park.\n\n"}
{"id": "43559445", "url": "https://en.wikipedia.org/wiki?curid=43559445", "title": "Cibeet River", "text": "Cibeet River\n\nCibeet River is a river in Dayeuhluhur, Cilacap Regency, Indonesia.\n\nThe river source is at The Forbidden Forest of the Upper Cibeet River, Dayeuhluhur Mountain. Two important tributaries of this river are Cikawalon River and Cidayeuh River.\n\nIts mouth is where it merges into Cijolang river at Bingkeng village.\n\nCibeet River has the purest river water in Cilacap Regency, because it comes from a dense and undeveloped tropical forest.\nThis river has a Keeper key (juru kunci) for guarding its spirituality. In Dayeuhluhuran (Sundanese Religion), this river is sacred. The key is held by Ceceng Rusmana.\n\n"}
{"id": "37648306", "url": "https://en.wikipedia.org/wiki?curid=37648306", "title": "Cooperative luminescence and cooperative absorption", "text": "Cooperative luminescence and cooperative absorption\n\nCooperative luminescence is the radiative process in which two excited ions simultaneously make downward transition to emit one photon with the sum of their excitation energies. The inverse process is cooperative absorption, in which a photon can be absorbed by a coupled pair of two ions, making them excited simultaneously.\n\nE. Nakazawa, and S. Shionoya, Phys. Rev. Lett. 25, 1710 (1970).\nD. L. Dexter, Phys. Rev. 126, 1962 (1962).\n"}
{"id": "87410", "url": "https://en.wikipedia.org/wiki?curid=87410", "title": "Coral reef", "text": "Coral reef\n\nA coral reef is an underwater ecosystem characterized by reef-building corals. Reefs are formed of colonies of coral polyps held together by calcium carbonate. Most coral reefs are built from stony corals, whose polyps cluster in groups.\n\nCoral belongs to the class \"Anthozoa\" in the animal phylum \"Cnidaria\", which includes sea anemones and jellyfish. Unlike sea anemones, corals secrete hard carbonate exoskeletons that support and protect the coral. Most reefs grow best in warm, shallow, clear, sunny and agitated water.\n\nOften called \"rainforests of the lo campo\", shallow coral reefs form some of Earth's most diverse ecosystems. They occupy less than 0.1% of the world's ocean area, about half the area of France, yet they provide a home for at least 25% of all marine species, including fish, mollusks, worms, crustaceans, echinoderms, sponges, tunicates and other cnidarians. Coral reefs flourish in ocean waters that provide few nutrients. They are most commonly found at shallow depths in tropical waters, but deep water and cold water coral reefs exist on smaller scales in other areas.\n\nCoral reefs deliver ecosystem services for tourism, fisheries and shoreline protection. The annual global economic value of coral reefs is estimated between US$30–375 billion. Coral reefs are fragile, partly because they are sensitive to water conditions. They are under threat from excess nutrients (nitrogen and phosphorus), rising temperatures, oceanic acidification, overfishing (e.g., from blast fishing, cyanide fishing, spearfishing on scuba), sunscreen use overuse and harmful land-use practices, including runoff and seeps (e.g., from injection wells and cesspools).\n\nMost coral reefs were formed after the last glacial period when melting ice caused sea level to rise and flood continental shelves. Most coral reefs are less than 10,000 years old. As communities established themselves, the reefs grew upwards, pacing rising sea levels. Reefs that rose too slowly could become drowned, without sufficient light. Coral reefs are found in the deep sea away from continental shelves, around oceanic islands and atolls. The majority of these islands are volcanic in origin. Others have tectonic origins where plate movements lifted the deep ocean floor.\n\nIn \"The Structure and Distribution of Coral Reefs\", Charles Darwin set out his theory of the formation of atoll reefs, an idea he conceived during the voyage of the \"Beagle\". He theorized that uplift and subsidence of the Earth's crust under the oceans formed the atolls. Darwin set out a sequence of three stages in atoll formation. A fringing reef forms around an extinct volcanic island as the island and ocean floor subsides. As the subsidence continues, the fringing reef becomes a barrier reef and ultimately an atoll reef.\n\nDarwin predicted that underneath each lagoon would be a bedrock base, the remains of the original volcano. Subsequent research supported this hypothesis. Darwin's theory followed from his understanding that coral polyps thrive in the tropics where the water is agitated, but can only live within a limited depth range, starting just below low tide. Where the level of the underlying earth allows, the corals grow around the coast to form fringing reefs, and can eventually grow become a barrier reef.\n\nWhere the bottom is rising, fringing reefs can grow around the coast, but coral raised above sea level dies. If the land subsides slowly, the fringing reefs keep pace by growing upwards on a base of older, dead coral, forming a barrier reef enclosing a lagoon between the reef and the land. A barrier reef can encircle an island, and once the island sinks below sea level a roughly circular atoll of growing coral continues to keep up with the sea level, forming a central lagoon. Barrier reefs and atolls do not usually form complete circles, but are broken in places by storms. Like sea level rise, a rapidly subsiding bottom can overwhelm coral growth, killing the coral and the reef, due to what is called \"coral drowning\". Corals that rely on zooxanthellae can die when the water becomes too deep for their symbionts to adequately photosynthesize, due to decreased light exposure.\n\nThe two main variables determining the geomorphology, or shape, of coral reefs are the nature of the substrate on which they rest, and the history of the change in sea level relative to that substrate.\n\nThe approximately 20,000-year-old Great Barrier Reef offers an example of how coral reefs formed on continental shelves. Sea level was then lower than in the 21st century. As sea level rose, the water and the corals encroached on what had been hills of the Australian coastal plain. By 13,000 years ago, sea level had risen to lower than at present, and many hills of the coastal plains had become continental islands. As sea level rise continued, water topped most of the continental islands. The corals could then overgrow the hills, forming cays and reefs. Sea level on the Great Barrier Reef has not changed significantly in the last 6,000 years. The age of living reef structure is estimated to be between 6,000 and 8,000 years. Although the Great Barrier Reef formed along a continental shelf, and not around a volcanic island, Darwin's principles apply. Development stopped at the barrier reef stage, since Australia is not about to submerge. It formed the world's largest barrier reef, from shore, stretching for .\n\nHealthy tropical coral reefs grow horizontally from per year, and grow vertically anywhere from per year; however, they grow only at depths shallower than because of their need for sunlight, and cannot grow above sea level.\n\nAs the name implies, coral reefs are made up of coral skeletons from mostly intact coral colonies. As other chemical elements present in corals become incorporated into the calcium carbonate deposits, aragonite is formed. However, shell fragments and the remains of coralline algae such as the green-segmented genus \"Halimeda\" can add to the reef's ability to withstand damage from storms and other threats. Such mixtures are visible in structures such as Eniwetok Atoll.\n\nSince Darwin's identification of the three classical reef formations – the fringing reef around a volcanic island becoming a barrier reef and then an atoll – scientists have identified further reef types. While some sources find only three, Thomas and Goudie list four \"principal large-scale coral reef types\" – the fringing reef, barrier reef, atoll and table reef – while Spalding \"et al.\" list five \"main types\" – the fringing reef, barrier reef, atoll, \"bank or platform reef\" and patch reef.\n\nA fringing reef, also called a shore reef, is directly attached to a shore, or borders it with an intervening narrow, shallow channel or lagoon. It is the most common reef type. Fringing reefs follow coastlines and can extend for many kilometres. They are usually less than 100 metres wide, but some hundreds of metres wide. Fringing reefs are initially formed on the shore at the low water level and expand seawards as they grow in size. The final width depends on where the sea bed begins to drop steeply. The surface of the fringe reef generally remains at the same height: just below the waterline. In older fringing reefs, whose outer regions pushed far out into the sea, the inner part is deepened by erosion and eventually forms a lagoon. Fringing reef lagoons can become over 100 metres wide and several metres deep. Like the fringing reef itself, they run parallel to the coast. The fringing reefs of the Red Sea are \"some of the best developed in the world\" and occur along all its shores except off sandy bays.\n\nBarrier reefs are separated from a mainland or island shore by a deep channel or lagoon. They resemble the later stages of a fringing reef with its lagoon, but differ from the latter mainly in size and origin. Their lagoons can be several kilometres wide and 30 to 70 metres deep. Above all, the offshore outer reef edge formed in open water rather than next to a shoreline. Like an atoll, it is thought that these reefs are formed either as the seabed lowered or sea level rose. Formation takes considerably longer than for a fringing reef, thus barrier reefs are much rarer.\n\nThe best known and largest example of a barrier reef is the Australian Great Barrier Reef. Other major examples are the Belize Barrier Reef and the New Caledonian Barrier Reef. Barrier reefs are also found on the coasts of Providencia, Mayotte, the Gambier Islands, on the southeast coast coast of Kalimantan, on parts of the coast of Sulawesi, southeastern New Guinea and the south coast of the Louisiade Archipelago.\n\nPlatform reefs, variously called bank or table reefs, can form on the continental shelf, as well as in the open ocean, in fact anywhere where the seabed rises close enough to the surface of the ocean to enable the growth of zooxanthemic, reef-forming corals. Platform reefs are found in the southern Great Barrier Reef, the Swain and Capricorn Group on the continental shelf, about 100–200 km from the coast. Some platform reefs of the northern Mascarenes are several thousand kilometres from the mainland. Unlike fringing and barrier reefs which extend only seaward, platform reefs grow in all directions. They are variable in size, ranging from a few hundred metres to many kilometres across. Their usual shape is oval to elongated. Parts of these reefs can reach the surface and form sandbanks and small islands around which may form fringing reefs. A lagoon may form In the middle of a platform reef.\n\nPlatform reefs can be found within atolls. There they are called patch reefs and may reach only a few dozen metres in diameter. Where platform reefs form on an elongated structure, e. g. an old, eroded barrier reef, they can form a linear arrangement. This is the case, for example, on the east coast of the Red Sea near Jeddah. In old platform reefs, the inner part can be so heavily eroded that it forms a pseudo-atoll. These can be distinguished from real atolls only by detailed investigation, possibly including core drilling. Some platform reefs of the Laccadives are U-shaped, due to wind and water flow.\n\nAtolls or atoll reefs are a more or less circular or continuous barrier reef that extends all the way around a lagoon without a central island. They are usually formed from fringing reefs around volcanic islands. Over time, the island erodes away and sinks below sea level. Atolls may also be formed by the sinking of the seabed or rising of the sea level. A ring of reefs results, which enclose a lagoon. Atolls are numerous in the South Pacific, where they usually occur in mid-ocean, for example, in the Caroline Islands, the Cook Islands, French Polynesia, the Marshall Islands and Micronesia.\n\nAtolls are found in the Indian Ocean, for example, in the Maldives, the Chagos Islands, the Seychelles and around Cocos Island. The entire Maldives consist of 26 atolls.\n\n\nCoral reef ecosystems contain distinct zones that host different kinds of habitats. Usually, three major zones are recognized: the fore reef, reef crest, and the back reef (frequently referred to as the reef lagoon).\n\nThe three zones are physically and ecologically interconnected. Reef life and oceanic processes create opportunities for exchange of seawater, sediments, nutrients and marine life.\n\nMost coral reefs exist in waters less than 50 m deep. Some inhabit tropical continental shelves where cool, nutrient-rich upwelling does not occur, such as the Great Barrier Reef. Others are found in the deep ocean surrounding islands or as atolls, such as in the Maldives. The reefs surrounding islands form when islands subside into the ocean, and atolls form when an island subsides below the surface of the sea.\n\nAlternatively, Moyle and Cech distinguish six zones, though most reefs possess only some of the zones.\n\nThe reef surface is the shallowest part of the reef. It is subject to surge and tides. When waves pass over shallow areas, they shoal, as shown in the adjacent diagram. This means the water is often agitated. These are the precise condition under which corals flourish. The light is sufficient for photosynthesis by the symbiotic zooxanthellae, and agitated water brings plankton to feed the coral.\n\nThe off-reef floor is the shallow sea floor surrounding a reef. This zone occurs next to reefs on continental shelves. Reefs around tropical islands and atolls drop abruptly to great depths, and do not have such a floor. Usually sandy, the floor often supports seagrass meadows which are important foraging areas for reef fish.\n\nThe reef drop-off is, for its first 50 m, habitat for reef fish who find shelter on the cliff face and plankton in the water nearby. The drop-off zone applies mainly to the reefs surrounding oceanic islands and atolls.\n\nThe reef face is the zone above the reef floor or the reef drop-off. This zone is often the reef's most diverse area. Coral and calcareous algae provide complex habitats and areas that offer protection, such as cracks and crevices. Invertebrates and epiphytic algae provide much of the food for other organisms. A common feature on this forereef zone is spur and groove formations that serve to transport sediment downslope.\n\nThe reef flat is the sandy-bottomed flat, which can be behind the main reef, containing chunks of coral. This zone may border a lagoon and serve as a protective area, or it may lie between the reef and the shore, and in this case is a flat, rocky area. Fish tend to prefer it when it is present.\n\nThe reef lagoon is an entirely enclosed region, which creates an area less affected by wave action and often contains small reef patches.\n\nHowever, the \"topography of coral reefs is constantly changing. Each reef is made up of irregular patches of algae, sessile invertebrates, and bare rock and sand. The size, shape and relative abundance of these patches changes from year to year in response to the various factors that favor one type of patch over another. Growing coral, for example, produces constant change in the fine structure of reefs. On a larger scale, tropical storms may knock out large sections of reef and cause boulders on sandy areas to move.\"\n\nCoral reefs are estimated to cover 284,300 km (109,800 sq mi), just under 0.1% of the oceans' surface area. The Indo-Pacific region (including the Red Sea, Indian Ocean, Southeast Asia and the Pacific) account for 91.9% of this total. Southeast Asia accounts for 32.3% of that figure, while the Pacific including Australia accounts for 40.8%. Atlantic and Caribbean coral reefs account for 7.6%.\n\nAlthough corals exist both in temperate and tropical waters, shallow-water reefs form only in a zone extending from approximately 30° N to 30° S of the equator. Tropical corals do not grow at depths of over . The optimum temperature for most coral reefs is , and few reefs exist in waters below . However, reefs in the Persian Gulf have adapted to temperatures of in winter and in summer. 37 species of scleractinian corals inhabit such an environment around Larak Island.\n\nDeep-water coral inhabits greater depths and colder temperatures at much higher latitudes, as far north as Norway. Although deep water corals can form reefs, little is known about them.\n\nCoral reefs are rare along the west coasts of the Americas and Africa, due primarily to upwelling and strong cold coastal currents that reduce water temperatures in these areas (the Peru, Benguela and Canary Currents respectively). Corals are seldom found along the coastline of South Asia—from the eastern tip of India (Chennai) to the Bangladesh and Myanmar borders—as well as along the coasts of northeastern South America and Bangladesh, due to the freshwater release from the Amazon and Ganges Rivers respectively.\n\n\nWhen alive, corals are colonies of small animals embedded in calcium carbonate shells. Coral heads consist of accumulations of individual animals called polyps, arranged in diverse shapes. Polyps are usually tiny, but they can range in size from a pinhead to across.\n\nReef-building or hermatypic corals live only in the photic zone (above 50 m), the depth to which sufficient sunlight penetrates the water.\n\nCoral polyps do not photosynthesize, but have a symbiotic relationship with microscopic algae (dinoflagellates) of the genus \"Symbiodinium\", commonly referred to as zooxanthellae. These organisms live within the polyps' tissues and provide organic nutrients that nourish the polyp in the form of glucose, glycerol and amino acids. Because of this relationship, coral reefs grow much faster in clear water, which admits more sunlight. Without their symbionts, coral growth would be too slow to form significant reef structures. Corals get up to 90% of their nutrients from their symbionts. In return, as an example of mutualism, the corals shelter the zooxanthellae, averaging one million for every cubic centimeter of coral, and provide a constant supply of the carbon dioxide they need for photosynthesis.\n\nThe varying pigments in different species of zooxanthellae give them an overall brown or golden-brown appearance, and give brown corals their colors. Other pigments such as reds, blues, greens, etc. come from colored proteins made by the coral animals. Coral that loses a large fraction of its zooxanthellae becomes white (or sometimes pastel shades in corals that are pigmented with their own proteins) and is said to be bleached, a condition which, unless corrected, can kill the coral.\n\nThere are eight clades of \"Symbiodinium\" phylotypes. Most research has been conducted on clades A–D. Each clade contributes their own benefits as well as less compatible attributes to the survival of their coral hosts. Each photosynthetic organism has a specific level of sensitivity to photodamage to compounds needed for survival, such as proteins. Rates of regeneration and replication determine the organism's ability to survive. Phylotype A is found more in the shallow waters. It is able to produce mycosporine-like amino acids that are UV resistant, using a derivative of glycerin to absorb the UV radiation and allowing them to better adapt to warmer water temperatures. In the event of UV or thermal damage, if and when repair occurs, it will increase the likelihood of survival of the host and symbiont. This leads to the idea that, evolutionarily, clade A is more UV resistant and thermally resistant than the other clades.\n\nClades B and C are found more frequently in deeper water, which may explain their higher vulnerability to increased temperatures. Terrestrial plants that receive less sunlight because they are found in the undergrowth are analogous to clades B, C, and D. Since clades B through D are found at deeper depths, they require an elevated light absorption rate to be able to synthesize as much energy. With elevated absorption rates at UV wavelengths, these phylotypes are more prone to coral bleaching versus the shallow clade A.\n\nClade D has been observed to be high temperature-tolerant, and has a higher rate of survival than clades B and C during modern bleaching events.\n\nReefs grow as polyps and other organisms deposit calcium carbonate, the basis of coral, as a skeletal structure beneath and around themselves, pushing the coral head's top upwards and outwards. Waves, grazing fish (such as parrotfish), sea urchins, sponges and other forces and organisms act as bioeroders, breaking down coral skeletons into fragments that settle into spaces in the reef structure or form sandy bottoms in associated reef lagoons.\nTypical shapes for coral species are named by their resemblance to terrestrial objects such as wrinkled brains, cabbages, table tops, antlers, wire strands and pillars. These shapes can depend on the life history of the coral, like light exposure and wave action, and events such as breakages.\n\nCorals reproduce both sexually and asexually. An individual polyp uses both reproductive modes within its lifetime. Corals reproduce sexually by either internal or external fertilization. The reproductive cells are found on the mesenteries, membranes that radiate inward from the layer of tissue that lines the stomach cavity. Some mature adult corals are hermaphroditic; others are exclusively male or female. A few species change sex as they grow.\n\nInternally fertilized eggs develop in the polyp for a period ranging from days to weeks. Subsequent development produces a tiny larva, known as a planula. Externally fertilized eggs develop during synchronized spawning. Polyps across a reef simultaneously release eggs and sperm into the water en masse. Spawn disperse over a large area. The timing of spawning depends on time of year, water temperature, and tidal and lunar cycles. Spawning is most successful given little variation between high and low tide. The less water movement, the better the chance for fertilization. Ideal timing occurs in the spring. Release of eggs or planula usually occurs at night, and is sometimes in phase with the lunar cycle (three to six days after a full moon). The period from release to settlement lasts only a few days, but some planulae can survive afloat for several weeks. They are vulnerable to predation and environmental conditions. The lucky few planulae that successfully attach to substrate then compete for food and space.\n\nCorals are the most prodigious reef-builders. However many other organisms living in the reef community contribute skeletal calcium carbonate in the same manner as corals. These include coralline algae and some sponges. Reefs are always built by the combined efforts of these different phyla, with different organisms leading reef-building in different geological periods.\n\nCoralline algae are important contributors to reef structure. Although their mineral deposition-rates are much slower than corals, they are more tolerant of rough wave-action, and so help to create a protective crust over those parts of the reef subjected to the greatest forces by waves, such as the reef front facing the open ocean. They also strengthen the reef structure by depositing limestone in sheets over the reef surface.\n\n\"Sclerosponge\" is the descriptive name for all \"Porifera\" that build reefs. In the early Cambrian period, \"Archaeocyatha\" sponges were the world's first reef-building organisms, and sponges were the only reef-builders until the Ordovician. Sclerosponges still assist corals building modern reefs, but like coralline algae are much slower-growing than corals and their contribution is (usually) minor.\n\nIn the northern Pacific Ocean cloud sponges still create deep-water mineral-structures without corals, although the structures are not recognizable from the surface like tropical reefs. They are the only extant organisms known to build reef-like structures in cold water.\n\nIn \"The Structure and Distribution of Coral Reefs\", published in 1842, Darwin described how coral reefs were found in some tropical areas but not others, with no obvious cause. The largest and strongest corals grew in parts of the reef exposed to the most violent surf and corals were weakened or absent where loose sediment accumulated.\n\nTropical waters contain few nutrients yet a coral reef can flourish like an \"oasis in the desert\". This has given rise to the ecosystem conundrum, sometimes called \"Darwin's paradox\": \"How can such high production flourish in such nutrient poor conditions?\"\n\nCoral reefs support over one-quarter of all marine species. This diversity results in complex food webs, with large predator fish eating smaller forage fish that eat yet smaller zooplankton and so on. However, all food webs eventually depend on plants, which are the primary producers. Coral reefs typically produce 5–10 grams of carbon per square meter per day (gC·m·day) biomass.\n\nOne reason for the unusual clarity of tropical waters is their nutrient deficiency and drifting plankton. Further, the sun shines year-round in the tropics, warming the surface layer, making it less dense than subsurface layers. The warmer water is separated from deeper, cooler water by a stable thermocline, where the temperature makes a rapid change. This keeps the warm surface waters floating above the cooler deeper waters. In most parts of the ocean, there is little exchange between these layers. Organisms that die in aquatic environments generally sink to the bottom, where they decompose, which releases nutrients in the form of nitrogen (N), phosphorus (P) and potassium (K). These nutrients are necessary for plant growth, but in the tropics, they do not directly return to the surface.\n\nPlants form the base of the food chain and need sunlight and nutrients to grow. In the ocean, these plants are mainly microscopic phytoplankton which drift in the water column. They need sunlight for photosynthesis, which powers carbon fixation, so they are found only relatively near the surface, but they also need nutrients. Phytoplankton rapidly use nutrients in the surface waters, and in the tropics, these nutrients are not usually replaced because of the thermocline.\n\nAround coral reefs, lagoons fill in with material eroded from the reef and the island. They become havens for marine life, providing protection from waves and storms.\n\nMost importantly, reefs recycle nutrients, which happens much less in the open ocean. In coral reefs and lagoons, producers include phytoplankton, as well as seaweed and coralline algae, especially small types called turf algae, which pass nutrients to corals. The phytoplankton form the base of the food chain and are eaten by fish and crustaceans. Recycling reduces the nutrient inputs needed overall to support the community.\n\nCorals also absorb nutrients, including inorganic nitrogen and phosphorus, directly from water. Many corals extend their tentacles at night to catch zooplankton that pass near. Zooplankton provide the polyp with nitrogen, and the polyp shares some of the nitrogen with the zooxanthellae, which also require this element.\n\nSponges live in crevices in the reefs. They are efficient filter feeders, and in the Red Sea they consume about 60% of the phytoplankton that drifts by. Sponges eventually excrete nutrients in a form that corals can use.\nThe roughness of coral surfaces is key to coral survival in agitated waters. Normally, a boundary layer of still water surrounds a submerged object, which acts as a barrier. Waves breaking on the extremely rough edges of corals disrupt the boundary layer, allowing the corals access to passing nutrients. Turbulent water thereby promotes reef growth. Without the access to nutrients brought by rough coral surfaces, even the most effective recycling would not suffice.\n\nDeep nutrient-rich water entering coral reefs through isolated events may have significant effects on temperature and nutrient systems. This water movement disrupts the relatively stable thermocline that usually exists between warm shallow water and deeper colder water. Temperature regimes on coral reefs in the Bahamas and Florida are highly variable with temporal scales of minutes to seasons and spatial scales across depths.\n\nWater can pass through coral reefs in various ways, including current rings, surface waves, internal waves and tidal changes. Movement is generally created by tides and wind. As tides interact with varying bathymetry and wind mixes with surface water, internal waves are created. An internal wave is a gravity wave that moves along density stratification within the ocean. When a water parcel encounters a different density it oscillates and creates internal waves. While internal waves generally have a lower frequency than surface waves, they often form as a single wave that breaks into multiple waves as it hits a slope and moves upward. This vertical breakup of internal waves causes significant diapycnal mixing and turbulence. Internal waves can act as nutrient pumps, bringing plankton and cool nutrient-rich water to the surface.\n\nThe irregular structure characteristic of coral reef bathymetry may enhance mixing and produce pockets of cooler water and variable nutrient content. Arrival of cool, nutrient-rich water from depths due to internal waves and tidal bores has been linked to growth rates of suspension feeders and benthic algae as well as plankton and larval organisms. The seaweed \"Codium isthmocladum\" reacts to deep water nutrient sources because their tissues have different concentrations of nutrients dependent upon depth. Aggregations of eggs, larval organisms and plankton on reefs respond to deep water intrusions. Similarly, as internal waves and bores move vertically, surface-dwelling larval organisms are carried toward the shore. This has significant biological importance to cascading effects of food chains in coral reef ecosystems and may provide yet another key to unlocking the paradox.\n\nCyanobacteria provide soluble nitrates via nitrogen fixation.\n\nCoral reefs often depend on surrounding habitats, such as seagrass meadows and mangrove forests, for nutrients. Seagrass and mangroves supply dead plants and animals that are rich in nitrogen and serve to feed fish and animals from the reef by supplying wood and vegetation. Reefs, in turn, protect mangroves and seagrass from waves and produce sediment in which the mangroves and seagrass can root.\n\nCoral reefs form some of the world's most productive ecosystems, providing complex and varied marine habitats that support a wide range of other organisms. Fringing reefs just below low tide level have a mutually beneficial relationship with mangrove forests at high tide level and sea grass meadows in between: the reefs protect the mangroves and seagrass from strong currents and waves that would damage them or erode the sediments in which they are rooted, while the mangroves and sea grass protect the coral from large influxes of silt, fresh water and pollutants. This level of variety in the environment benefits many coral reef animals, which, for example, may feed in the sea grass and use the reefs for protection or breeding.\n\nReefs are home to a variety of animals, including fish, seabirds, sponges, cnidarians (which includes some types of corals and jellyfish), worms, crustaceans (including shrimp, cleaner shrimp, spiny lobsters and crabs), mollusks (including cephalopods), echinoderms (including starfish, sea urchins and sea cucumbers), sea squirts, sea turtles and sea snakes. Aside from humans, mammals are rare on coral reefs, with visiting cetaceans such as dolphins the main exception. A few species feed directly on corals, while others graze on algae on the reef. Reef biomass is positively related to species diversity.\n\nThe same hideouts in a reef may be regularly inhabited by different species at different times of day. Nighttime predators such as cardinalfish and squirrelfish hide during the day, while damselfish, surgeonfish, triggerfish, wrasses and parrotfish hide from eels and sharks.\n\nReefs are chronically at risk of algal encroachment. Overfishing and excess nutrient supply from onshore can enable algae to outcompete and kill the coral. Increased nutrient levels can be a result of sewage or chemical fertilizer runoff. Runoff can carry nitrogen and phosphorus which promote excess algae growth. Algae can sometimes out-compete the coral for space. The algae can then smother the coral by decreasing the oxygen supply available to the reef. Decreased oxygen levels can slow down calcification rates, weakening the coral and leaving it more susceptible to disease and degradation. Algae inhabit a large percentage of surveyed coral locations. The algal population consists of turf algae, coralline algae and macro algae. Some sea urchins (such as \"Diadema antillarum\") eat these algae and could thus decrease the risk of algal encroachment.\n\nSponges are essential for the functioning of the coral reef that system. Algae and corals in coral reefs produce organic material. This is filtered through sponges which convert this organic material into small particles which in turn are absorbed by algae and corals.\n\nOver 4,000 species of fish inhabit coral reefs. The reasons for this diversity remain unclear. Hypotheses include the \"lottery\", in which the first (lucky winner) recruit to a territory is typically able to defend it against latecomers, \"competition\", in which adults compete for territory, and less-competitive species must be able to survive in poorer habitat, and \"predation\", in which population size is a function of postsettlement piscivore mortality. Healthy reefs can produce up to 35 tons of fish per square kilometer each year, but damaged reefs produce much less.\n\nSea urchins, \"Dotidae\" and sea slugs eat seaweed. Some species of sea urchins, such as \"Diadema antillarum\", can play a pivotal part in preventing algae from overrunning reefs. Researchers are investigating the use of native collector urchins, \"Tripneustes gratilla\", for their potential as biocontrol agents to mitigate the spread of invasive algae species on coral reefs. \"Nudibranchia\" and sea anemones eat sponges.\n\nA number of invertebrates, collectively called \"cryptofauna,\" inhabit the coral skeletal substrate itself, either boring into the skeletons (through the process of bioerosion) or living in pre-existing voids and crevices. Animals boring into the rock include sponges, bivalve mollusks, and sipunculans. Those settling on the reef include many other species, particularly crustaceans and polychaete worms.\n\nCoral reef systems provide important habitats for seabird species, some endangered. For example, Midway Atoll in Hawaii supports nearly three million seabirds, including two-thirds (1.5 million) of the global population of Laysan albatross, and one-third of the global population of black-footed albatross. Each seabird species has specific sites on the atoll where they nest. Altogether, 17 species of seabirds live on Midway. The short-tailed albatross is the rarest, with fewer than 2,200 surviving after excessive feather hunting in the late 19th century.\n\nSea snakes feed exclusively on fish and their eggs. Marine birds, such as herons, gannets, pelicans and boobies, feed on reef fish. Some land-based reptiles intermittently associate with reefs, such as monitor lizards, the marine crocodile and semiaquatic snakes, such as \"Laticauda colubrina\". Sea turtles, particularly hawksbill sea turtles, feed on sponges.\n\nCoral reefs deliver ecosystem services to tourism, fisheries and coastline protection. The global economic value of coral reefs has been estimated to be between US $29.8 billion and $375 billion per year.\n\nThe economic cost over a 25-year period of destroying one kilometer of coral reef has been estimated to be somewhere between $137,000 and $1,200,000.\n\nTo improve the management of coastal coral reefs, the World Resources Institute (WRI) developed and published tools for calculating the value of coral reef-related tourism, shoreline protection and fisheries, partnering with five Caribbean countries. As of April 2011, published working papers covered St. Lucia, Tobago, Belize, and the Dominican Republic. The WRI was \"making sure that the study results support improved coastal policies and management planning\". The Belize study estimated the value of reef and mangrove services at $395–559 million annually.\n\nBermuda's coral reefs provide economic benefits to the Island worth on average $722 million per year, based on six key ecosystem services, according to Sarkis \"et al\" (2010).\n\nCoral reefs protect shorelines by absorbing wave energy, and many small islands would not exist without reefs. Coral reefs can reduce wave energy by 97%. Reefs can attenuate waves as well as or better than artificial structures designed for coastal defence such as breakwaters. An estimated 197 million people who live both below 10 m elevation and within 50 km of a reef consequently may receive risk reduction benefits from reefs. Restoring reefs is significantly cheaper than building artificial breakwaters in tropical environments. Expected damages from flooding would double, and costs from frequent storms would triple without the topmost meter of reefs. For 100-year storm events, flood damages would increase by 91% to $US 272 billion without the top meter.\n\nAbout six million tons of fish are taken each year from coral reefs. Well-managed reefs have an average annual yield of 15 tons of seafood per square kilometer. Southeast Asia's coral reef fisheries alone yield about $2.4 billion annually from seafood.\n\nCoral reefs are dying around the world. In particular, runoff, pollution, overfishing, blast fishing, disease, invasive species, overuse by humans and coral mining and the digging of canals and access into islands and bays are localized threats to coral ecosystems. Broader threats are sea temperature rise, sea level rise and ocean acidification, all associated with greenhouse gas emissions. Other threats include the ocean's role as a carbon dioxide sink, atmospheric changes, ultraviolet light, ocean acidification, viruses, impacts of dust storms carrying agents to far-flung reefs, and algal blooms.\n\nAir pollution can stunt the growth of coral reefs; including coal-burning and volcanic eruptions. Pollutants, such as Tributyltin, a biocide released into water from anti-fouling paint can be toxic to corals.\n\nIn 2011, researchers suggested that \"extant marine invertebrates face the same synergistic effects of multiple stressors\" that occurred during the end-Permian extinction, and that genera \"with poorly buffered respiratory physiology and calcareous shells\", such as corals, were particularly vulnerable.\n\nRock coral on seamounts are threatened by bottom trawling. Reportedly up to 50% of the catch is rock coral, and the practice smashes coral structures to rubble. These ecosystems take years to regrow, destroying coral communities faster than they can rebuild.\n\nAnother cause for the death of coral reefs is bioerosion. Various fishes graze corals and change the morphology of coral reefs making them more susceptible to other threats. Only the algae growing on dead corals is eaten and the live ones are not. However, this act still destroys the top layer of coral substrate and makes it harder for the reefs to sustain.\n\nIn El Niño-year 2010, global coral bleaching reached its worst level since El Niño year 1998, when 16% of the world's reefs died as a result of increased water temperature. In Indonesia's Aceh province, surveys showed some 80% of bleached corals died. Bleaching leaves corals vulnerable to disease, stunts their growth, and affects their reproduction, while severe bleaching kills them. In July, Malaysia closed several dive sites where virtually all the corals were damaged by bleaching.\n\nCoral reefs with one type of zooxanthellae are more prone to bleaching than are reefs with another, more hardy, species.\n\nEcotourism in the Great Barrier Reef contributes to coral disease. Chemicals in sunscreens may contribute to the impact of viruses on zooxanthellae and impact reproduction.\n\nIn a large-scale systematic study of Jarvis Island coral community, scientists have observed ten coral bleaching events from 1960 to 2016.\n\nMarine protected areas (MPAs) are designated areas that provide various kinds of protection to ocean and/or estuarine areas. They are intended to promote responsible fishery management and habitat protection. MPAs can encompass both social and biological objectives, including reef restoration, aesthetics, biodiversity and economic benefits.\n\nHowever, research in Indonesia, Philippines and Papua New Guinea found no significant difference between an MPA site and an unprotected site. Further, they can generate conflicts driven by lack of community participation, clashing views of the government and fisheries, effectiveness of the area and funding. In some situations, as in the Phoenix Islands Protected Area, MPAs provide revenue, potentially equal to the income they would have generated without controls.\n\nAccording to the Caribbean Coral Reefs - Status Report 19702-2012, states that; stop overfishing especially fishes key to coral reef like parrotfish, coastal zone management that reduce human pressure on reef, (for example restricting coastal settlement, development and tourism) and control pollution specially sewage, may reduce coral decline or even reverse it. The report shows that healthier reefs in the Caribbean are those with large populations of parrotfish in countries that protect these key fishes and sea urchins, banning fish trapping and spearfishing, creating \"resilient reefs\".\n\nTo help combat ocean acidification, some laws are in place to reduce greenhouse gases such as carbon dioxide. The United States Clean Water Act puts pressure on state governments to monitor and limit runoff.\n\nMany land use laws aim to reduce CO emissions by limiting deforestation. Deforestation can release significant amounts of CO absent sequestration via active follow-up forestry programs. Deforestation can also cause erosion, which flows into the ocean, contributing to ocean acidification. Incentives are used to reduce miles traveled by vehicles, which reduces carbon emissions into the atmosphere, thereby reducing the amount of dissolved CO in the ocean. State and federal governments also regulate land activities that affect coastal erosion. High-end satellite technology can monitor reef conditions.\n\nDesignating a reef as a biosphere reserve, marine park, national monument or world heritage site can offer protections. For example, Belize's barrier reef, Sian Ka'an, the Galapagos islands, Great Barrier Reef, Henderson Island, Palau and Papahānaumokuākea Marine National Monument are world heritage sites.\n\nIn Australia, the Great Barrier Reef is protected by the Great Barrier Reef Marine Park Authority, and is the subject of much legislation, including a biodiversity action plan. Australia compiled a Coral Reef Resilience Action Plan. This plan consists of adaptive management strategies, including reducing carbon footprint. A public awareness plan providezs education on the \"rainforests of the sea\" and how people can reduce carbon emissions.\n\nInhabitants of Ahus Island, Manus Province, Papua New Guinea, have followed a generations-old practice of restricting fishing in six areas of their reef lagoon. Their cultural traditions allow line fishing, but no net or spear fishing. Both biomass and individual fish sizes are significantly larger than in places where fishing is unrestricted.\n\nCoral aquaculture, also known as coral farming or coral gardening, is showing promise as a potentially effective tool for restoring coral reefs.\n\nThe \"gardening\" process bypasses the early growth stages of corals when they are most at risk of dying. Coral seeds are grown in nurseries, then replanted on the reef. Coral is farmed by coral farmers whose interests range from reef conservation to increased income.\n\nEfforts to expand the size and number of coral reefs generally involve supplying substrate to allow more corals to find a home. Substrate materials include discarded vehicle tires, scuttled ships, subway cars and formed concrete, such as reef balls. Reefs grow unaided on marine structures such as oil rigs. In large restoration projects, propagated hermatypic coral on substrate can be secured with metal pins, superglue or milliput. Needle and thread can also attach A-hermatype coral to substrate.\n\nBiorock is a substrate produced by a patented process that runs low voltage electrical currents through seawater to cause dissolved minerals to precipitate onto steel structures. The resultant white carbonate (aragonite) is the same mineral that makes up natural coral reefs. Corals rapidly colonize and grow at accelerated rates on these coated structures. The electrical currents also accelerate formation and growth of both chemical limestone rock and the skeletons of corals and other shell-bearing organisms, such as oysters. The vicinity of the anode and cathode provides a high-pH environment which inhibits the growth of competitive filamentous and fleshy algae. The increased growth rates fully depend on the accretion activity.\n\nUnder the influence of the electric field, corals display an increased growth rate, size and density.\n\nOne case study with coral reef restoration was conducted on the island of Oahu in Hawaii. The University of Hawaii operates a Coral Reef Assessment and Monitoring Program to help relocate and restore coral reefs in Hawaii. A boat channel from the island of Oahu to the Hawaii Institute of Marine Biology on Coconut Island was overcrowded with coral reefs. Many areas of coral reef patches in the channel had been damaged from past dredging in the channel.\n\nDredging covers corals with sand. Coral larvae cannot settle on sand; they can only build on existing reefs or compatible hard surfaces, such as rock or concrete. Because of this, the University decided to relocate some of the coral. They transplanted them with the help of United States Army divers, to a site relatively close to the channel. They observed little if any damage to any of the colonies during transport and no mortality of coral reefs was observed on the transplant site. While attaching the coral to the transplant site, they found that coral placed on hard rock grew well, including on the wires that attached the corals to the site.\n\nNo environmental effects were seen from the transplantation process, recreational activities were not decreased, and no scenic areas were affected.\n\nAnother possibility for coral restoration is gene therapy: inoculating coral with genetically modified bacteria, or naturally-occurring heat-tolerant varieties of coral symbiotes, may make it possible to grow corals that are more resistant to climate change and other threats.\n\nHawaiian coral reefs smothered by the spread of invasive algae were managed with a two-prong approach: divers manually removed invasive algae, with the support of super-sucker barges. Grazing pressure on invasive algae needed to be increased to prevent the regrowth of the algae.\n\nResearchers found that native collector urchins were reasonable candidate grazers for algae biocontrol, to extirpate the remaining invasive algae from the reef.\n\nThe times of maximum reef development were in the Middle Cambrian (513–501 Ma), Devonian (416–359 Ma) and Carboniferous (359–299 Ma), owing to order Rugosa extinct corals and Late Cretaceous (100–66 Ma) and all Neogene (23 Ma–present), owing to order Scleractinia corals.\n\nNot all reefs in the past were formed by corals: those in the Early Cambrian (542–513 Ma) resulted from calcareous algae and archaeocyathids (small animals with conical shape, probably related to sponges) and in the Late Cretaceous (100–66 Ma), when reefs formed by a group of bivalves called rudists existed; one of the valves formed the main conical structure and the other, much smaller valve acted as a cap.\n\nMeasurements of the oxygen isotopic composition of the aragonitic skeleton of coral reefs, such as \"Porites\", can indicate changes in sea surface temperature and sea surface salinity conditions during the growth of the coral. This technique is often used by climate scientists to infer a region's paleoclimate.\n\n\n"}
{"id": "274317", "url": "https://en.wikipedia.org/wiki?curid=274317", "title": "Dwarf star", "text": "Dwarf star\n\nA dwarf star is a star of relatively small size and low luminosity. Most main sequence stars are dwarf stars. The term was originally coined in 1906 when the Danish astronomer Ejnar Hertzsprung noticed that the reddest stars—classified as K and M in the Harvard scheme could be divided into two distinct groups. They are either much brighter than the Sun, or much fainter. To distinguish these groups, he called them \"giant\" and \"dwarf\" stars, the dwarf stars being fainter and the giants being brighter than the Sun. Most stars are currently classified under the \"Morgan Keenan System\" using the letters O, B, A, F, G, K, and M, a sequence from the hottest: \"O type\", to the coolest: \"M type\". The scope of the term \"dwarf\" was later expanded to include the following:\n\n\n"}
{"id": "7173874", "url": "https://en.wikipedia.org/wiki?curid=7173874", "title": "Ecophysiology", "text": "Ecophysiology\n\nEcophysiology (from Greek , \"oikos\", \"house(hold)\"; , \"physis\", \"nature, origin\"; and , \"-logia\"), environmental physiology or physiological ecology is a biological discipline that studies the adaptation of an organism's physiology to environmental conditions. It is closely related to comparative physiology and evolutionary physiology. Ernst Haeckel's coinage bionomy is sometimes employed as a synonym.\n\nPlant ecophysiology is concerned largely with two topics: mechanisms (how plants sense and respond to environmental change) and scaling or integration (how the responses to highly variable conditions—for example, gradients from full sunlight to 95% shade within tree canopies—are coordinated with one another), and how their collective effect on plant growth and gas exchange can be understood on this basis.\n\nIn many cases, animals are able to escape unfavourable and changing environmental factors such as heat, cold, drought or floods, while plants are unable to move away and therefore must endure the adverse conditions or perish (animals go places, plants grow places). Plants are therefore phenotypically plastic and have an impressive array of genes that aid in adapting to changing conditions. It is hypothesized that this large number of genes can be partly explained by plant species' need to adapt to a wider range of conditions.\n\nAs with most abiotic factors, light intensity (irradiance) can be both suboptimal and excessive. Light intensity is also an important component in determining the temperature of plant organs (energy budget).The light response curve of net photosynthesis (PI curve) is particularly useful in characterising a plant's tolerance to different light intensities.\n\nSuboptimal light (shade) typically occurs at the base of a plant canopy or in an understory environment. Shade tolerant plants have a range of adaptations to help them survive the altered quantity and quality of light typical of shade environments.\n\nExcess light occurs at the top of canopies and on open ground when cloud cover is low and the sun's zenith angle is low, typically this occurs in the tropics and at high altitudes. Excess light incident on a leaf can result in photoinhibition and photodestruction. Plants adapted to high light environments have a range of adaptations to avoid or dissipate the excess light energy, as well as mechanisms that reduce the amount of injury caused.\n\nIn response to extremes of temperature, plants can produce various proteins. These protect them from the damaging effects of ice formation and falling rates of enzyme catalysis at low temperatures, and from enzyme denaturation and increased photorespiration at high temperatures. As temperatures fall, production of antifreeze proteins and dehydrins increases. As temperatures rise, production of heat shock proteins increases. Metabolic imbalances associated with temperature extremes result in the build-up of reactive oxygen species, which can be countered by antioxidant systems. Cell membranes are also affected by changes in temperature and can cause the membrane to lose its fluid properties and become a gel in cold conditions or to become leaky in hot conditions. This can affect the movement of compounds across the membrane. To prevent these changes, plants can change the composition of their membranes. In cold conditions, more unsaturated fatty acids are placed in the membrane and in hot conditions more saturated fatty acids are inserted.\n\nPlants can avoid overheating by minimising the amount of sunlight absorbed and by enhancing the cooling effects of wind and transpiration. Plants can reduce light absorption using reflective leaf hairs, scales, and waxes. These features are so common in warm dry regions that these habitats can be seen to form a ‘silvery landscape’ as the light scatters off the canopies. Some species, such as \"Macroptilium purpureum\", can move their leaves throughout the day so that they are always orientated to avoid the sun (\"paraheliotropism\"). Knowledge of these mechanisms has been key to breeding for heat stress tolerance in agricultural plants.\n\nPlants can avoid the full impact of low temperature by altering their microclimate. For example, \"Raoulia\" plants found in the uplands of New Zealand are said to resemble ‘vegetable sheep’ as they form tight cushion-like clumps to insulate the most vulnerable plant parts and shield them from cooling winds. The same principle has been applied in agriculture by using plastic mulch to insulate the growing points of crops in cool climates in order to boost plant growth.\n\nToo much or too little water can damage plants. If there is too little water then tissues will dehydrate and the plant may die. If the soil becomes waterlogged then the soil will become anoxic (low in oxygen), which can kill the roots of the plant.\n\nThe ability of plants to access water depends on the structure of their roots and on the water potential of the root cells. When soil water content is low, plants can alter their water potential to maintain a flow of water into the roots and up to the leaves (Soil plant atmosphere continuum). This remarkable mechanism allows plants to lift water as high as 120 m by harnessing the gradient created by transpiration from the leaves.\n\nIn very dry soil, plants close their stomata to reduce transpiration and prevent water loss. The closing of the stomata is often mediated by chemical signals from the root (i.e., abscisic acid). In irrigated fields, the fact that plants close their stomata in response to drying of the roots can be exploited to ‘trick’ plants into using less water without reducing yields (see partial rootzone drying). The use of this technique was largely developed by Dr Peter Dry and colleagues in Australia (see nominative determinism).\n\nIf drought continues, the plant tissues will dehydrate, resulting in a loss of turgor pressure that is visible as wilting. As well as closing their stomata, most plants can also respond to drought by altering their water potential (osmotic adjustment) and increasing root growth. Plants that are adapted to dry environments (Xerophytes) have a range of more specialized mechanisms to maintain water and/or protect tissues when desiccation occurs.\n\nWaterlogging reduces the supply of oxygen to the roots and can kill a plant within days. Plants cannot avoid waterlogging, but many species overcome the lack of oxygen in the soil by transporting oxygen to the root from tissues that are not submerged. Species that are tolerant of waterlogging develop specialised roots near the soil surface and aerenchyma to allow the diffusion of oxygen from the shoot to the root. Roots that are not killed outright may also switch to less oxygen-hungry forms of cellular respiration. Species that are frequently submerged have evolved more elaborate mechanisms that maintain root oxygen levels, perhaps most notable being the dramatic aerial roots seen in Mangrove forests.\n\nHowever, for many terminally overwatered houseplants, the initial symptoms of waterlogging can resemble those due to drought. This is particularly true for flood-sensitive plants that show drooping of their leaves due to epinasty (rather than wilting).\n\n is vital for plant growth, as it is the substrate for photosynthesis. Plants take in through stomatal pores on their leaves. At the same time as enters the stomata, moisture escapes. This trade-off between gain and water loss is central to plant productivity. The trade-off is all the more critical as Rubisco, the enzyme used to capture , is efficient only when there is a high concentration of in the leaf. Some plants overcome this difficulty by concentrating within their leaves using carbon fixation or Crassulacean acid metabolism. However, most species used carbon fixation and must open their stomata to take in whenever photosynthesis is taking place.\n\nWind has three very different effects on plants.\n\nWind influences the way leaves regulate moisture, heat, and carbon dioxide. When no wind is present, a layer of still air builds up around each leaf. This is known as the boundary layer and in effect insulates the leaf from the environment, providing an atmosphere rich in moisture and less prone to convective heating or cooling. As wind speed increases, the leaf environment becomes more closely linked to the surrounding environment. It may become difficult for the plant to retain moisture as it is exposed to dry air. On the other hand, a moderately high wind allows the plant to cool its leaves more easily when exposed to full sunlight. Plants are not entirely passive in their interaction with wind. Plants can make their leaves less vulnerable to changes in wind speed, by coating their leaves in fine hairs (trichomes) to break up the air flow and increase the boundary layer. In fact, leaf and canopy dimensions are often finely controlled to manipulate the boundary layer depending on the prevailing environmental conditions.\n\nPlants can sense the wind through the deformation of its tissues. This signal leads to inhibits the elongation and stimulates the radial expansion of their shoots, while increasing the development of their root system. This syndrome of responses known as thigmomorphogenesis results in shorter, stockier plants with strengthened stems, as well as to an improved ancorage. It was once believed that this occurs mostly in very windy areas. But it has been found that it happens even in areas with moderate winds, so that wind-induced signal were found to be a major ecological factor.\n\nTrees have a particularly well-developed capacity to reinforce their trunks when exposed to wind.From the parctical size, this realisation prompted arboriculturalists in the UK in the 1960s to move away from the practice of staking young amenity trees to offer artificial support.\n\nWind can damage most of the organs of the plants. Leaf abrasion (due to the rubbing of leaves and branches or to the effect of air-borne particle such as sand) and leaf of branch breakage are rather common phenomena, that plants have to accommodate. In the more extreme cases, plants can be mortally damaged or uprooted by wind. This has been a major selective pressure acting over terrestrial plants. Nowadays, it is one of the major threatening for agriculture and forestry even in temperate zones. It is worse for agriculture in hurricane-prone regions, such as the banana-growing Windward Islands in the Caribbean.\n\nWhen this type of disturbance occurs in natural systems, the only solution is to ensure that there is an adequate stock of seeds or seedlings to quickly take the place of the mature plants that have been lost- although, in many cases a successional stage will be needed before the ecosystem can be restored to its former state.\n\nThe environment can have major influences on human physiology. Environmental effects on human physiology are numerous; one of the most carefully studied effects is the alterations in thermoregulation in the body due to outside stresses. This is necessary because in order for enzymes to function, blood to flow, and for various body organs to operate, temperature must remain at consistent, balanced levels.\n\nTo achieve this, the body alters three main things to achieve a constant, normal body temperature:\n\n\nThe hypothalamus plays an important role in thermoregulation. It connects to thermal receptors in the dermis, and detects changes in surrounding blood to make decisions of whether to stimulate internal heat production, or to stimulate evaporation.\n\nThere are two main types of stresses that can be experienced due to extreme environmental temperatures: heat stress and cold stress.\n\nHeat stress is physiologically combated in four ways: radiation, conduction, convection, and evaporation. Cold stress is physiologically combated by shivering, accumulation of body fat, circulatory adaptations (that provide an efficient transfer of heat to the epidermis), and increased blood flow to the extremities.\n\nThere is one part of the body fully equipped to deal with cold stress. The respiratory system protects itself against damage by warming the incoming air to 80-90 degrees Fahrenheit before it reaches the bronchi. This means that not even the most frigid of temperatures can damage the respiratory tract.\n\nIn both types of temperature related stress, it is important to remain well-hydrated. Hydration reduces cardiovascular strain, enhances the ability of energy processes to occur, and reduces feelings of exhaustion.\n\nExtreme temperatures are not the only obstacles that humans face. High altitudes also pose serious physiological challenges on the body. Some of these effects are reduced arterial formula_1, the rebalancing of the acid-base content in body fluids, increased hemoglobin, increased RBC synthesis, enhanced circulation, and increased levels of the glycolysis byproduct 2,3 diphosphoglycerate, which promotes off-loading of O by hemoglobin in the hypoxic tissues.\n\nEnvironmental factors can play a huge role in the human body's fight for homeostasis. However, humans have found ways to adapt, both physiologically and tangibly.\n\nGeorge A. Bartholomew (1919–2006) was a founder of animal physiological ecology. He served on the faculty at UCLA from 1947 to 1989, and almost 1,200 individuals can trace their academic lineages to him. Knut Schmidt-Nielsen (1915–2007) was also an important contributor to this specific scientific field as well as comparative physiology.\n\nHermann Rahn (1912–1990) was an early leader in the field of environmental physiology. Starting out in the field of zoology with a PhD from University of Rochester (1933), Rahn began teaching physiology at the University of Rochester in 1941. It is there that he partnered with Wallace O. Fenn to publish \"A Graphical Analysis of the Respiratory Gas Exchange\" in 1955. This paper included the landmark O-CO diagram, which formed basis for much of Rahn's future work. Rahn's research into applications of this diagram led to the development of aerospace medicine and advancements in hyperbaric breathing and high-altitude respiration. Rahn later joined the University at Buffalo in 1956 as the Lawrence D. Bell Professor and Chairman of the Department of Physiology. As Chairman, Rahn surrounded himself with outstanding faculty and made the University an international research center in environmental physiology.\n\n\n"}
{"id": "33399769", "url": "https://en.wikipedia.org/wiki?curid=33399769", "title": "Energy in Turkey", "text": "Energy in Turkey\n\nTurkey consumes 1700 terawatt hours (TW/h) of primary energy per year, a little over 20 megawatt hours (MW/h) per person: most energy is imported fossil fuels but policy is to reduce that proportion, including by generating more electricity in the west to match demand.\n\nSince 1990 annual primary energy consumption has almost tripled to 1700 TW/h in 2016; including 31% oil, 28% gas and 27% coal; and CO emissions from fuel combustion have risen from 130 megatonnes (Mt) to 340 Mt. Almost all fossil fuel apart from lignite (brown coal) is imported. Turkey's energy policy prioritises reducing imports.\n\nElectricity is generated mainly from coal, gas (about a third each) and hydro (about a quarter) with a small but growing amount from other renewables such as wind and solar. Nuclear power plants are under construction.\n\nTurkey produces a lot of lignite, almost all of which is burnt in power stations, which churns out large amounts of carbon dioxide with a comparably low level of efficiency. Government subsidises coal-fired power stations despite the environmental impact of the coal industry and would like more to be built.\n\nAnnual gas demand is 50bcm, over 30% of Turkey’s total energy demand, and over half of which is supplied by Russia.\nAll 81 provinces in Turkey are supplied with natural gas, which supplies most of the heat.\n\nWith the TurkStream pipeline from Russia still under construction currently most gas comes from Russia via the Blue Stream pipeline. \nIranian gas comes through the Tabriz–Ankara pipeline. Azerbaijan supplies Turkey through the Trans-Anatolian gas pipeline (which they claim is the cheapest that Turkey buys) and South Caucasus Pipeline. Iraq may also supply gas in future, through the Southern Gas Corridor and gas from the Eastern Mediterranean is also a possibility.\n\nAlso 16.5% of gas is imported as LNG, which together with storage is important for meeting the winter demand peak.\n\nAt the moment only a small proportion of gas imports are re-exported to the EU. However Turkey aims to become a gas trading hub in 2018 and more re-export more.\nState-owned BOTAŞ controls 80% of the market\n91 mt of CO2 were emitted by burning natural gas in 2015.\n\nAlmost all oil is imported: mostly from Iraq, Iran and Russia and oil also transits from Azerbajan.\n92 mt of CO2 were emitted by burning oil in 2015.\n\nTurkey has no operational nuclear reactors, but it is building its first nuclear power plant at Akkuyu, with expected operation in 2023.\nMore nuclear power plants are planned.\n\nHydroelectricity in Turkey is the largest renewable source of electricity however solar power looks likely to increase rapidly. Wind power in Turkey is mainly in the west.\n\nGeothermal power in Turkey is used mainly for heating.\n\nBy massively increasing production of solar power in the south and wind power in the west Turkey could meet its entire predicted 2020 energy demand from renewable sources.\n\nTurkey produces and consumes about 300 TWh annually, only about 1% is imported or exported. Prices on the wholesale market are controlled by the state electricity generation company, and prices to end consumers are regulated.\n\nAccording to the Ministry of Energy and Natural Resources, Turkey has the potential to cut 15 to 20 percent of total consumption through energy conservation.\n\nWith the increase in electricity generated by solar panels storage may become more important.\n\nTesting in Ankara suggested a payback time between 18 months and 3 years for adding ice thermal storage to hypermarket cooling systems.\n\nTurkey could generate 20% of its total electricity from wind and solar by 2026 without extra transmission system costs.\n\n"}
{"id": "10606531", "url": "https://en.wikipedia.org/wiki?curid=10606531", "title": "Flow tracer", "text": "Flow tracer\n\nA flow tracer is any fluid property used to track flow, magnitude, direction, and circulation patterns. Tracers can be chemical properties, such as radioactive material, or chemical compounds, physical properties, such as density, temperature, salinity, or dyes, and can be natural or artificially induced. Flow tracers are used in many fields, such as physics, hydrology, limnology, oceanography, and atmospheric studies.\n\nConservative tracers remain constant following fluid parcels, whereas reactive tracers (such as compounds undergoing a mutual chemical reaction) grow or decay with time. \"Active tracers\" dynamically alter the flow of the fluid by changing fluid properties which appear in the equation of motion such as density or viscosity, while \"passive tracers\" have no influence on flow.\n\nOcean tracers are used to deduce small scale flow patterns, large-scale ocean circulation, water mass formation and changes, “dating” of water masses, and carbon dioxide storage and uptake.\n\nTracers such are temperature, salinity, density, and other conservative tracers are often used to track currents, circulation and water mass mixing. An interesting example was when 28,000 plastic ducks fell over board from a container ship in the middle of the Pacific Ocean. The following twelve years oceanographers recorded where the ducks washed ashore, some thousands of miles from the spill site, and this data was used to calibrate and verify the circulation patters of the North Pacific Gyre.\n\nTransient tracers change over time, such as radioactive material (Tritium and Cesium-137) and chemical concentrations (CFCs and SF6), which are used to date water masses and can also track mixing. In the mid-1900s, Nuclear weapons testing and chemical production, released tons of compounds that are not naturally found in the environment. While extremely unfortunate, scientists were able to use the concentrations of anthropogenic compounds and half-lives of radioactive material to determine how old a water body is. The Fukushima nuclear disaster was really well studied by oceanographers, who tracked the radioactive material spread through out the Pacific Ocean, and used that to better understand ocean currents and mixing patterns.\n\nBiological tracers can also be used to track water masses in the ocean. Phytoplankton blooms can be seen by satellites and move with the changing currents. They can be used as a “check point” to see how well water masses are mixing. Subtropical water is often warm, which is ideal for phytoplankton, but nutrient poor, which inhibits their growth, while subpolar water is cold and nutrient rich. When these two types of water masses mix, such as the Kuroshio Current in the north Pacific, it often causes huge phytoplankton blooms, because they now how conditions they need to grow—warm temperatures and high nutrients. Vertical mixing and eddy formation can also cause phytoplankton blooms, and these blooms are tracked by satellites to observe current patterns and mixing.\n\n\n<br>\n"}
{"id": "58991", "url": "https://en.wikipedia.org/wiki?curid=58991", "title": "Fog", "text": "Fog\n\nFog is a visible aerosol consisting of minute water droplets or ice crystals suspended in the air at or near the Earth's surface. Although it has no Latin name, fog can be considered a type of low-lying cloud, usually resembling stratus, and is heavily influenced by nearby bodies of water, topography, and wind conditions. In turn, fog has affected many human activities, such as shipping, travel, and warfare.\n\nThe term \"fog\" is typically distinguished from the more generic term \"cloud\" in that fog is low-lying, and the moisture in the fog is often generated locally (such as from a nearby body of water, like a lake or the ocean, or from nearby moist ground or marshes).\n\nBy definition, fog reduces visibility to less than , whereas mist causes lesser impairment of visibility.\n\nFor aviation purposes in the UK, a visibility of less than but greater than is considered to be mist if the relative humidity is 70% or greater; below 70%, haze is reported.\n\nFog forms when the difference between air temperature and dew point is less than .\n\nFog begins to form when water vapor condenses into tiny liquid water droplets suspended in the air. Six examples of ways that water vapor is added to the air are by wind convergence into areas of upward motion; precipitation or virga falling from above; daytime heating evaporating water from the surface of oceans, water bodies, or wet land; transpiration from plants; cool or dry air moving over warmer water; and lifting air over mountains. Water vapor normally begins to condense on condensation nuclei such as dust, ice, and salt in order to form clouds. Fog, like its elevated cousin stratus, is a stable cloud deck which tends to form when a cool, stable air mass is trapped underneath a warm air mass.\n\nFog normally occurs at a relative humidity near 100%. This occurs from either added moisture in the air, or falling ambient air temperature. However, fog can form at lower humidities, and can sometimes fail to form with relative humidity at 100%. At 100% relative humidity, the air cannot hold additional moisture, thus, the air will become supersaturated if additional moisture is added.\n\nFog commonly produces precipitation in the form of drizzle or very light snow. Drizzle occurs when the humidity of fog attains 100% and the minute cloud droplets begin to coalesce into larger droplets. This can occur when the fog layer is lifted and cooled sufficiently, or when it is forcibly compressed from above by descending air. Drizzle becomes freezing drizzle when the temperature at the surface drops below the freezing point.\n\nThe thickness of a fog layer is largely determined by the altitude of the inversion boundary, which in coastal or oceanic locales is also the top of the marine layer, above which the air mass is warmer and drier. The inversion boundary varies its altitude primarily in response to the weight of the air above it, which is measured in terms of atmospheric pressure. The marine layer, and any fogbank it may contain, will be \"squashed\" when the pressure is high, and conversely, may expand upwards when the pressure above it is lowering.\n\nFog can form in a number of ways, depending on how the cooling that caused the condensation occurred.\n\nRadiation fog is formed by the cooling of land after sunset by infrared thermal radiation in calm conditions with a clear sky. The cooling ground then cools adjacent air by conduction, causing the air temperature to fall and reach the dew point, forming fog. In perfect calm, the fog layer can be less than a meter thick, but turbulence can promote a thicker layer. Radiation fog occurs at night, and usually doesn't last long after sunrise, but it can persist all day in the winter months especially in areas bounded by high ground. Radiation fog is most common in autumn and early winter. Examples of this phenomenon include the Tule fog.\n\nGround fog is fog that obscures less than 60% of the sky and does not extend to the base of any overhead clouds. However, the term is usually a synonym for radiation fog which is very shallow; in some cases the depth of the fog is on the order of tens of centimeters over certain kinds of terrain with the absence of wind. \nAdvection fog occurs when moist air passes over a cool surface by advection (wind) and is cooled. It is common as a warm front passes over an area with significant snow-pack. It is most common at sea when moist air encounters cooler waters, including areas of cold water upwelling, such as along the California coast (\"see\" San Francisco fog). A strong enough temperature difference over water or bare ground can also cause advection fog.\n\nAlthough strong winds often mix the air and can disperse, fragment, or prevent many kinds of fog, markedly warmer and humid air blowing over a snowpack can continue to generate advection fog at elevated velocities up to or more – this fog will be in a turbulent, rapidly moving, and comparatively shallow layer, observed as a few centimeters/inches in depth over flat farm fields, flat urban terrain and the like, and/or form more complex forms where the terrain is different such as rotating areas in the lee of hills or large buildings and so on. \n\nThe advection of fog along the California coastline is propelled onto land by one of several processes. A cold front can push the marine layer coast-ward, an occurrence most typical in the spring or late fall. During the summer months, a low pressure trough produced by intense heating inland creates a strong pressure gradient, drawing in the dense marine layer. Also during the summer, strong high pressure aloft over the desert southwest, usually in connection with the summer monsoon, produces a south to southeasterly flow which can drive the offshore marine layer up the coastline; a phenomenon known as a \"southerly surge\", typically following a coastal heat spell. However, if the monsoonal flow is sufficiently turbulent, it might instead break up the marine layer and any fog it may contain. Moderate turbulence will typically transform a fog bank, lifting it and breaking it up into shallow convective clouds called stratocumulus.\n\nEvaporation fog or steam fog forms over bodies of water overlain by much colder air; this situation can also lead to steam devils forming. Lake effect fog is of this type, sometimes in combination with other causes like radiation fog. It tends to differ from most advective fog formed over land in that it is, like lake-effect snow, a convective phenomenon, resulting in fog which can be quite a bit denser, deeper, and looks fluffy from above. Most other fog is stratiform; steam devils, which look like their dust counterparts, are often seen in this situation.\n\nFrontal fog forms in much the same way as stratus cloud near a front when raindrops, falling from relatively warm air above a frontal surface, evaporate into cooler air close to the Earth's surface and cause it to become saturated. This type of fog can be the result of a very low frontal stratus cloud subsiding to surface level in the absence of any lifting agent after the front passes.\n\nIce fog forming in very low temperatures can be the result of other mechanisms mentioned here, as well as the exhalation of moist warm air by herds of animals. It can be associated with the diamond dust form of precipitation, in which very small crystals of ice form and slowly fall. This often occurs during blue sky conditions which can cause many types of halos and other results of refraction of sunlight by the airborne crystals.\n\nFreezing fog, which deposits rime, is composed of droplets of supercooled water which freezes to surfaces on contact.\n\nPrecipitation fog (or frontal fog) forms as precipitation falls into drier air below the cloud, the liquid droplets evaporate into water vapor. The water vapor cools and at the dewpoint it condenses and fog forms.\n\nHail fog sometimes occurs in the vicinity of significant hail accumulations due to decreased temperature and increased moisture leading to saturation in a very shallow layer near the surface. It most often occurs when there is a warm, humid layer atop the hail and when wind is light. This ground fog tends to be localized but can be extremely dense and abrupt. It may form shortly after the hail falls; when the hail has had time to cool the air and as it absorbs heat when melting and evaporating.\n\nUpslope fog forms when moist air is going up the slope of a mountain or hill (orographic lifting) which condenses into fog on account of adiabatic cooling, and to a lesser extent the drop in pressure with altitude.\n\n occurs when liquid fog droplets freeze to surfaces, forming white soft or hard rime. This is very common on mountain tops which are exposed to low clouds. It is equivalent to freezing rain, and essentially the same as the ice that forms inside a freezer which is not of the \"frostless\" or \"frost-free\" type. The term \"freezing fog\" may also refer to fog where water vapor is super-cooled, filling the air with small ice crystals similar to very light snow. It seems to make the fog \"tangible\", as if one could \"grab a handful\".\n\nIn the western United States, freezing fog may be referred to as pogonip. It occurs commonly during cold winter spells, usually in deep mountain valleys.\nThe word pogonip is derived from the Shoshone word \"paγi̵nappi̵h\", which means \"cloud\".\nIn \"The Old Farmer's Almanac,\" in the calendar for December, the phrase \"Beware the Pogonip\" regularly appears.\nIn his anthology \"Smoke Bellew\", Jack London described a pogonip which surrounded the main characters, killing one of them.\n\nThe phenomenon is also extremely common in the inland areas of the Pacific Northwest, with temperatures in the range. The Columbia Plateau experiences this phenomenon most years due to temperature inversions, sometimes lasting for as long as three weeks. The fog typically begins forming around the area of the Columbia River and expands, sometimes covering the land to distances as far away as LaPine, Oregon, almost due south of the river and into south central Washington.\n\nFrozen fog (also known as ice fog) is any kind of fog where the droplets have frozen into extremely tiny crystals of ice in midair. Generally this requires temperatures at or below , making it common only in and near the Arctic and Antarctic regions. It is most often seen in urban areas where it is created by the freezing of water vapor present in automobile exhaust and combustion products from heating and power generation. Urban ice fog can become extremely dense and will persist day and night until the temperature rises. Extremely small amounts of ice fog falling from the sky form a type of precipitation called ice crystals, often reported in Utqiagvik, Alaska. Ice fog often leads to the visual phenomenon of light pillars.\n\nUp-slope fog or hill fog forms when winds blow air up a slope (called orographic lift), adiabatically cooling it as it rises, and causing the moisture in it to condense. This often causes freezing fog on mountaintops, where the cloud ceiling would not otherwise be low enough.\n\nValley fog forms in mountain valleys, often during winter. It is essentially a radiation fog confined by local topography, and can last for several days in calm conditions. In California's Central Valley, valley fog is often referred to as tule fog.\n\nSea fog (also known as \"haar\" or \"fret\") is heavily influenced by the presence of sea spray and microscopic airborne salt crystals. Clouds of all types require minute hygroscopic particles upon which water vapor can condense. Over the ocean surface, the most common particles are salt from salt spray produced by breaking waves. Except in areas of storminess, the most common areas of breaking waves are located near coastlines, hence the greatest densities of airborne salt particles are there.\n\nCondensation on salt particles has been observed to occur at humidities as low as 70%, thus fog can occur even in relatively dry air in suitable locations such as the California coast. Typically, such lower humidity fog is preceded by a transparent mistiness along the coastline as condensation competes with evaporation, a phenomenon that is typically noticeable by beachgoers in the afternoon. Another recently discovered source of condensation nuclei for coastal fog is kelp seaweed. Researchers have found that under stress (intense sunlight, strong evaporation, etc.), kelp releases particles of iodine which in turn become nuclei for condensation of water vapor, causing fog that diffuses direct sunlight.\n\nSea smoke, also called steam fog or evaporation fog, is the most localized form and is created by cold air passing over warmer water or moist land. It often causes freezing fog, or sometimes hoar frost.\n\nArctic sea smoke is similar to sea smoke, but occurs when the air is very cold. Instead of condensing into water droplets, columns of freezing, rising, and condensing water vapor is formed. The water vapor produces the \"sea smoke fog\", and is usually misty and smoke-like.\n\nGarúa fog near the coast of Chile and Peru, occurs when typical fog produced by the sea travels inland, but suddenly meets an area of hot air. This causes the water particles of fog to shrink by evaporation, producing a \"transparent mist\". Garua fog is nearly invisible, yet it still forces drivers to use windshield wipers because of deposition of liquid water on hard surfaces.\n\nDepending on the concentration of the droplets, visibility in fog can range from the appearance of haze, to almost zero visibility. Many lives are lost each year worldwide from accidents involving fog conditions on the highways, including multiple-vehicle collisions.\n\nThe aviation travel industry is affected by the severity of fog conditions. Even though modern auto-landing computers can put an aircraft down without the aid of a pilot, personnel manning an airport control tower must be able to see if aircraft are sitting on the runway awaiting takeoff. Safe operations are difficult in thick fog, and civilian airports may forbid takeoffs and landings until conditions improve.\n\nA solution for landing returning military aircraft developed in World War II was called Fog Investigation and Dispersal Operation (FIDO). It involved burning enormous amounts of fuel alongside runways to evaporate fog, allowing returning fighter and bomber pilots sufficient visual cues to safely land their aircraft. The high energy demands of this method discourage its use for routine operations.\n\nShadows are cast through fog in three dimensions. The fog is dense enough to be illuminated by light that passes through gaps in a structure or tree, but thin enough to let a large quantity of that light pass through to illuminate points further on. As a result, object shadows appear as \"beams\" oriented in a direction parallel to the light source. These voluminous shadows are created the same way as crepuscular rays, which are the shadows of clouds. In fog, it is solid objects that cast shadows.\n\nSound typically travels fastest and farthest through solids, then liquids, then gases such as the atmosphere. Sound is affected during fog conditions due to the small distances between water droplets, and air temperature differences.\n\nMolecular effect: Though fog is essentially liquid water, the many droplets are separated by small air gaps. High-pitched sounds have a high frequency, which in turn means they have a short wavelength. To transmit a high frequency wave, air must move back and forth very quickly. Short-wavelength high-pitched sound waves are reflected and refracted by many separated water droplets, partially cancelling and dissipating their energy (a process called \"damping\"). In contrast, low pitched notes, with a low frequency and a long wavelength, move the air less rapidly and less often, and lose less energy to interactions with small water droplets. Low-pitched notes are less affected by fog and travel further, which is why foghorns use a low-pitched tone.\n\nTemperature effect: A fog can be caused by a temperature inversion where cold air is pooled at the surface which helped to create the fog, while warmer air sits above it. The inverted boundary between cold air and warm air reflects sound waves back toward the ground, allowing sound that would normally radiate out escaping into the upper atmosphere to instead bounce back and travel near the surface. A temperature inversion increases the distance that lower frequency sounds can travel, by reflecting the sound between the ground and the inversion layer.\n\nThe foggiest place in the world is Hamilton, New Zealand, followed closely by the Grand Banks off the coast of Newfoundland (the meeting place of the cold Labrador Current from the north and the much warmer Gulf Stream from the south). Some of the foggiest land areas in the world include Argentia (Newfoundland) and Point Reyes (California), each with over 200 foggy days per year. Even in generally warmer southern Europe, thick fog and localized fog are often found in lowlands and valleys, such as the lower part of the Po Valley and the Arno and Tiber valleys in Italy; Ebro Valley in northeastern Spain; as well as on the Swiss plateau, especially in the Seeland area, in late autumn and winter. Other notably foggy areas include coastal Chile (in the south); coastal Namibia; Nord, Greenland; and the Severnaya Zemlya islands.\n\nRedwood forests in California receive approximately 30–40% of their moisture from coastal fog by way of fog drip. Change in climate patterns could result in relative drought in these areas. Some animals, including insects, depend on wet fog as a principal source of water, particularly in otherwise desert climes, as along many African coastal areas. Some coastal communities use fog nets to extract moisture from the atmosphere where groundwater pumping and rainwater collection are insufficient.\n\nArtificial fog is man-made fog that is usually created by vaporizing a water- and glycol-based or glycerine-based fluid. The fluid is injected into a heated metal block, and evaporates quickly. The resulting pressure forces the vapor out of a vent. Upon coming into contact with cool outside air, the vapor condenses in microscopic droplets and appears as fog. Such fog machines are primarily used for entertainment applications.\n\nThe presence of fog has often played a key role in historical events, such as strategic battles. One example is the Battle of Long Island (August 27, 1776), when American general George Washington and his command were able to evade imminent capture by the British Army, using fog to conceal their escape. Another example is D-Day (June 6, 1944) during World War II, when the Allies landed on the beaches of Normandy, France during fog conditions. Both positive and negative results were reported from both sides during that battle, due to impaired visibility.\n\n\n\n\nUnder \"[ ^ \"Federal Meteorological Handbook Number 1: Chapter 8 – Present Weather\" (PDF). Office of the Federal Coordinator for Meteorology. 1 September 2005. pp. 8–1, 8–2. Retrieved 9 October 2010. ] \" ….\n\nActually use the following link- http://www.ofcm.gov/publications/fmh/FMH1/FMH1.pdf and proceed to Chapter 8, etc.\n\n\n"}
{"id": "1263784", "url": "https://en.wikipedia.org/wiki?curid=1263784", "title": "George McCready Price", "text": "George McCready Price\n\nGeorge McCready Price (26 August 1870 – 24 January 1963) was a Canadian creationist. He produced several anti-evolution and creationist works, particularly on the subject of flood geology. His views did not become common among creationists until after his death, particularly with the modern creation science movement starting in the 1960s.\n\nPrice was born in Havelock, New Brunswick, Canada. His father died in 1882, and his mother joined the Seventh-day Adventist Church. Price attended Battle Creek College (now Andrews University) between 1891 and 1893. In 1896, he enrolled in a one-year teacher training course at the Provincial Normal School of New Brunswick (now the University of New Brunswick), where he took some elementary courses in some of the natural sciences, including some mineralogy.\n\nPrice taught at a series of small-town schools from 1897 onwards, including at a high school in Tracadie between 1899 and 1902. Here he socially met Alfred Corbett Smith (head of the medical department at a local leprosarium), who loaned him scientific literature in his possession. Since he believed that the Earth was young, Price concluded that geologists had misinterpreted their data. In 1902, Price completed the manuscript \"Outlines of Modern Christianity and Modern Science\" before leaving Tracadie to serve brief stints as an Adventist evangelist on Prince Edward Island and the head of a new Adventist boarding academy in Nova Scotia. He briefly returned to book-selling in 1904, and then moved to New York City in an attempt to become a magazine and newspaper writer.\n\nIn a response to a plea from his wife, the Adventist church first employed Price as a construction worker in Maryland. He then was principal of a small Adventist school in Oakland, California, before becoming a construction worker and handyman at a newly purchased Adventist sanitarium in Loma Linda, California, where he published \"Illogical Geology: The Weakest Point in the Evolution Theory\" in 1906. In \"Illogical Geology\", Price offered $1000 \"to any one who will, in the face of the facts here presented, show me how to prove that one kind of fossil is older than another.\"\n\nFrom 1907 to 1912, Price taught at the Seventh-day Adventist-run College of Medical Evangelists, now known as Loma Linda University, which awarded him a B.A., based partially on his authorship and independent study. From 1912 to 1914, he taught at the San Fernando Academy in San Fernando, California, and from 1914 to 1916 at Lodi Academy, Lodi, California.\n\nBeginning in 1920, Price taught at Pacific Union College, Angwin, California, where he was awarded an M.A. (described by Ronald L. Numbers as a \"gift\"). From 1924 to 1928, Price taught at Stanborough Missionary College in Watford, England, where he served as president from 1927 to 1928. He then taught at Emmanual Missionary College (now Andrews University) in Berrien Springs, Michigan from 1929 to 1933, and Walla Walla College near Walla Walla, Washington from 1933 to 1938.\n\nWhile Price claimed that his book-selling travels gave him invaluable \"firsthand knowledge of field geology\", his \"familiarity with the outside world\" remained rudimentary, with even his own students noting that he could \"barely tell one fossil from another\" on a field trip shortly before he retired.\n\nIn 1943, he moved to Loma Linda, California, where he died 20 years later at the age of 92.\n\nDavid Starr Jordan, president of Stanford University, and a leading American expert on fossil fishes, wrote a review of Price's \"Illogical Geology\", in which he stated that Price should not expect \"any geologist to take [his work] seriously.\" This led to a correspondence over the next twenty years in which Price once promised \"to become an evolutionist within twenty-four hours\" if \"the foremost ichthyologist in the world\" could prove that one fossil was older than another, and Jordan attempted to enlighten Price that his views were:\n\nJordan also unsuccessfully urged Price to \"undertake some constructive work in Paleontology in the field and in laboratories.\"\n\nNumbers says that Seventh-day Adventism is grounded on the Sabbath doctrine of a literal Creation week. To Price, the Sabbath doctrine is what saved Adventists from evolutionism. He adopted Ellen G. White's position on creationism as his own and he sought to persuade the world that a recent creation was required by the Bible and science.\n\nPrice criticized the 'geologic ages' and strict Lyellian uniformitarianism on which they are based. As an alternative explanation of the geology of the earth, he re-invented Flood Geology. He pondered ways to reinterpret the apparent order of the fossils that seemingly implied ancient bygone eras. After studying a wide variety of geologic literature, Price deduced that the \"facts of the rocks and fossils, stripped of mere theories, splendidly refute this evolutionary theory of the invariable order of the fossils, which is the very backbone of the evolutionary doctrine.\" He had read of strata containing fossils of a young era lying conformably on strata containing fossils of very old eras. The geologist who described these lithically identical layers said that \"one would naturally suppose that a single formation was being dealt with, were it not for fossil evidence.\" To Price, that, and the lack of any evidence of erosion between the strata, implied that little time could have occurred between the two layers of rock. Price also discovered in the literature examples of similar conformable strata, but in the reverse order, the old rocks on top and the young strata below according to interpretation of the fossils. Although appearing \"to succeed one another conformably\" the Canadian Geologic Survey contended for over-thrusting principally based on the fossil content. Price's interpretation of the evidence was that \"the geological record does not prove succession of ages, but rather shows a \"taxonomic\" series representing different but contemporaneous zones of antediluvian life.\"\n\nSo, in Price's 1913 book, \"The Fundamentals of Geology\", an expanded version of \"Illogical Geology\", he presented the \"Law of Conformable Stratigraphic Sequences\" which states \"any kind of fossiliferous rock may occur conformably on any other kind of fossiliferous rock, old or young.\" To Price this law was \"by all odds the most important law ever formulated with reference to the order in which the strata occur.\"\n\nYale geologist Schuchert's review of \"The New Geology\" for the magazine \"Science\" stated that Price was \"harboring a geological nightmare\". However, the creationists welcomed the new book. Harry Rimmer claimed that it was \"a masterpiece of REAL science [that] explodes in a convincing manner some of the ancient fallacies of science 'falsely so called'\". Within a couple of years, Price appeared prominently in several conservative religious periodicals. A \"Science\" editor described him as \"the principal scientific authority of the Fundamentalists\".\n\nPrice, concerned about scientific methodology, had read Whithead and other philosophers and understood that facts were always subject to interpretation. While Price was confident that \"inductive geology\" inferred a recent Creation, he acknowledged that debate between creationism and naturalism lay outside of science, \"across the boundary-line in the domain of philosophy and theology.\" Just as naturalists regarded facts \"through the colored spectacles of Darwin and Lyell\" Creationists used the Bible to interpret the natural world. He said that the Creationary account of origins could never have been developed as a hypothesis from the study of nature alone, rather it was \"suggested by our religion.\" In choosing between \"the two alternatives now before the world,\" naturalistic geology versus world-catastrophe, there was but one suitable inquiry: \"Will it give the most rational account nature's evidence?\"\n\nPrice's defense of creation science (and attacks on evolution) first achieved wide notability in 1925 when his theories and arguments were utilized heavily by William Jennings Bryan in the famous Scopes Trial. Bryan had appealed to Price for assistance, but Price was busy teaching in England. Price advised Bryan to avoid science during the trial if possible. During the trial, defense counsel Clarence Darrow, sneered \"You mentioned Price because he is the only human being in the world so far as you know that signs his name as a geologist that believes like you do . . . every scientist in this country knows [he] is a mountebank and a pretender and not a geologist at all.\"\n\nPrice's ideas were borrowed again in the early 1960s by Henry M. Morris and John Whitcomb in their book \"The Genesis Flood\", a work that skeptic Martin Gardner calls \"the most significant attack on evolution...since the Scopes trial\". Morris, in his 1984 book \"History of Modern Creationism\", spoke glowingly of Price's logic and writing style, and referred to reading \"The New Geology\" as \"a life-changing experience for me\".\n\nPrice was more conservative in his views than Old Earth creationists such as William Jennings Bryan, Harry Rimmer or William Bell Riley. Contrary to Bryan, Rimmer and Riley, Price rejected the idea of a local flood and insisted on a pure literal 6-day creation consisting of six 24-hour days. He felt that Riley's day-age creationist views were \"the devil's counterfeit\". Price was equally dismissive of Rimmer, and his gap creationism for most of his career.\n\n\n\n\n"}
{"id": "54087650", "url": "https://en.wikipedia.org/wiki?curid=54087650", "title": "Hans Schimpf", "text": "Hans Schimpf\n\nHans Schimpf (1890 – 10 April 1935 in Breslau) was a German Navy, () officer and intelligence officer. During the interwar period he helped co-found on instruction from the Reichsluftfahrtministerium, the Signals intelligence organization called the Forschungsamt (Abbr. FA), along with Hermann Göring and Gottfried Schapper. He was responsible for the organization between 1933 and 1935.\n\nHans Schimpf who was the son of the entrepreneur Ernst Schimpf, and entered the German Navy () at a young age, where he had achieved the rank of a corvette captain () by 1933.\n\nIn 1933, Schimpf came to the notice of Hermann Göring who was looking for new trained personnel for his new agency, the Forschungsamt. Schimpf had been acting as a liaison officer between the Kriegsmarine Signals intelligence service, B-Dienst and the German Army signals intercept service, the Abwehr cipher bureau. At that time, Schimpf was a personal friend of Göring and an Nazi.\n\nDuring his time at the Reichswehr cipher bureau, Schimpf was somewhat of a dark horse, who had organized within it an Nazi Party cell, in secret. He undertook several trips abroad to link the Abwehr cipher bureau with Italian Armed Forces, e.g. Servizio Informazioni Militare and also set up a small illicit German intercept station on an private estate near Barcelona in Spain. The intercept station was configured to intercept shipping traffic in the Mediterranean, for the Kriegsmarine. It also monitored French radio stations in North Africa and southwestern France.\n\nSchimpf has made a large number of contacts, and leading personalities with fascist organizations in Italy and Spain, which attracted Göring. Schimpf was entrusted to start the new agency. He selected 8 people, along with Gottfried Schapper, who had the original idea for the FA agency to be the new key people in the unit. All were Nazi Party members. Schimpf started the new FA agency, in March 1933.\n\nBy 30 June 1934, during the Night of the Long Knives, Schimpf was promoted to ministerial rank (), which ensured for himself a position of great power.\n\nIn early 1933, Reinhard Heydrich, the head of the Reich Main Security Office, who was competing with Goering's research office, tried to persuade Schimpf to work for him and Heinrich Himmler and the SS, without the knowledge of Göring, which he refused. Instead, Heydrich is supposed to have tried to extort abuse because of his numerous foreign affairs.\n\nIn mid-April 1935, Schimpf, who could always be reached by telephone, had \"gone away for an indefinite period\". Rumours began to circulate, due to the conflicting information that was coming from the agency, then it was confirmed: Schimpf was dead. Several versions of his death were reported, including a car accident, that happened in Silesia, then in Berlin, then in Künigsberg. Later people were informed he committed suicide, with a dozen locations mentioned as the place of death, with one story that he killed himself with a lady friend. Deviated reports suggest that he was killed by a Czech agent.\n\nThe American historian Jonathan Petropoulos, who in his book 'Royals and the Reich. The Princes of Hesse in Nazi Germany', also discussed Schimpf's successor, Prince Christoph of Hesse, who was an SS member, and was appointed new director of the FA the day after Schimpfs' body was discovered, argues that the most likely scenario is an assassination of Schimpf as office chief () on behalf of Heinrich Himmler and Reinhard Heydrich, seeing the FA as an unwelcome competitor to the security service of the SS, which was under their control.\n\nWilhelm F. Flicke, a German second world war veteran cipher officer, who was commissioned by General Erich Fellgiebel, to write a history of German cryptography and cryptanalysis during World War II wrote in his book \"War secrets in the ether\" the following:\n\nOn the 10 April 1935, when Göring was getting married, Schimpf was found in Grünewald with a bullet hole in his head. There can be no doubt that Schimpf did not commit suicide but was assassinated by the Gestapo. Schimpf was a generally happy individual who was extremely fond of life, but became dangerous to both Göring and Himmler, and had to be killed.\n\nSchimpf was cremated in a crematory in Wilmersdorf in an elaborate ceremony carried out by Göring. A large wreath was delivered with the inscription:\n\n\"To my Faithful Collaborator Hans Schimpf, In Gratitude Hermann Göring\"\n\nThis was followed by an address by State Secretary by Erhard Milch and a salute of honour.\n"}
{"id": "1093068", "url": "https://en.wikipedia.org/wiki?curid=1093068", "title": "Horseshoe crab", "text": "Horseshoe crab\n\nHorseshoe crabs are marine and brackish water arthropods of the family Limulidae, suborder Xiphosurida, and order Xiphosura. Their popular name is actually a misnomer, for they bear little resemblance to horseshoes, and they are not true crabs.\n\nHorseshoe crabs live primarily in and around shallow coastal waters on soft sandy or muddy bottoms. They occasionally come onto shore to mate. They are commonly eaten in Asia, and used as fishing bait, in fertilizer and in science (especially \"Limulus\" amebocyte lysate). In recent years, population declines have occurred as a consequence of coastal habitat destruction and overharvesting. Tetrodotoxin may be present in \"Carcinoscorpius rotundicauda\".\n\nBecause of their origin 450 million years ago, horseshoe crabs are considered living fossils.\n\nHorseshoe crabs superficially resemble crustaceans but belong to a separate subphylum of the arthropods, Chelicerata, and are closely related to arachnids. Horseshoe crabs are closely related to the extinct eurypterids (sea scorpions), which include some of the largest arthropods to have ever existed, and the two may be sister groups. (Other studies have placed eurypterids closer to the arachnids in a group called Metastomata.) The earliest horseshoe crab fossils are found in strata from the late Ordovician period, roughly 450 million years ago.\n\nThe Limulidae are the only recent family of the order Xiphosura, and contains all four living species of horseshoe crabs:\n\n\nThe entire body of the horseshoe crab is protected by a hard carapace. It has two compound lateral eyes, each composed of about 1,000 ommatidia, plus a pair of median eyes that are able to detect both visible light and ultraviolet light, a single endoparietal eye, and a pair of rudimentary lateral eyes on the top. The latter become functional just before the embryo hatches. Also, a pair of ventral eyes is located near the mouth, as well as a cluster of photoreceptors on the telson. The horseshoe crab has five additional eyes on top of its shell. Despite having relatively poor eyesight, the animals have the largest rods and cones of any known animal, about 100 times the size of humans', and their eyes are a million times more sensitive to light at night than during the day. The mouth is located in the center of the legs, whose bases are referred to as gnathobases and have the same function as jaws and help grind up food. The horseshoe crab has five pairs of legs for walking, swimming, and moving food into the mouth, each with a claw at the tip, except for the last pair.\n\nBehind its legs, the horseshoe crab has book gills, which exchange respiratory gases, and are also occasionally used for swimming.\nAs in other arthropods, a true endoskeleton is absent, but the body does have an endoskeletal structure made up of cartilaginous plates that support the book gills. They are more often found on the ocean floor searching for worms and molluscs, which are their main food. They may also feed on crustaceans and even small fish.\n\nFemales are about 20–30% larger than males. The smallest species is \"C. rotundicauda\" and the largest is \"T. tridentatus\". On average, males of \"C. rotundicauda\" are about long, including a tail (telson) that is about , and their carapace (prosoma) is about wide. Some southern populations (in the Yucatán Peninsula) of \"L. polyphemus\" are somewhat smaller, but otherwise this species is larger. In the largest species, \"T. tridentatus\", females can reach as much as long, including their tail, and up to in weight. This is only about longer than the largest females of \"L. polyphemus\" and \"T. gigas\", but roughly twice the weight. The juveniles grow about 33% larger with every molt until reaching adult size.\n\nDuring the breeding season, horseshoe crabs migrate to shallow coastal waters. A male selects a female and clings to her back. Often, several males surround the female and all fertilize together, which makes it easy to spot and count females as they are the large center carapace surrounded by 3-5 smaller ones. The female digs a hole in the sand and lays her eggs while the male(s) fertilize them. The female can lay between 60,000 and 120,000 eggs in batches of a few thousand at a time. In \"L. polyphemus\", the eggs take about two weeks to hatch; shore birds eat many of them before they hatch. The larvae molt six times during the first year.\n\nNatural breeding of horseshoe crabs in captivity has proven to be difficult. Some evidence indicates that mating takes place only in the presence of the sand or mud in which the horseshoe crab's eggs were hatched. It is not known with certainty what is in the sand that the crabs can sense or how they sense it. Artificial insemination and induced spawning have been done on a relatively large scale in captivity, and eggs and juveniles collected from the wild are often raised to adulthood in captivity.\n\nHorseshoe crabs use hemocyanin to carry oxygen through their blood. Because of the copper present in hemocyanin, their blood is blue. Their blood contains amebocytes, which play a similar role to the white blood cells of vertebrates in defending the organism against pathogens. Amebocytes from the blood of \"L. polyphemus\" are used to make \"Limulus\" amebocyte lysate (LAL), which is used for the detection of bacterial endotoxins in medical applications. This means there is a high demand for the blood, the harvest of which involves collecting and bleeding the animals, and then releasing them back into the sea. Most of the animals survive the process; mortality is correlated with both the amount of blood extracted from an individual animal, and the stress experienced during handling and transportation. Estimates of mortality rates following blood harvesting vary from 3–15% to 10–30%. Approximately 500,000 crabs are harvested annually.\n\nBleeding may also prevent female horseshoe crabs from being able to spawn or decrease the number of eggs they are able to lay. Up to 30% of an individual's blood is removed, according to the biomedical industry, and the horseshoe crabs spend between one and three days away from the ocean before being returned. Some scientists are skeptical that certain companies return their horseshoe crabs to the ocean at all, instead suspecting them of selling the horseshoe crabs as fishing bait.\n\nThe harvesting of horseshoe crab blood in the pharmaceutical industry is in decline. In 1986, Kyushu University researchers discovered that the same test could be achieved by using isolated Limulus clotting factor C (rFC), an enzyme found in LAL, as by using LAL itself. Jeak Ling Ding, a National University of Singapore researcher, would go on to patent a process for manufacturing rFC; on 8 May 2003, synthetic isolated rFC made via her patented process was put on sale for the first time. Industry at first took little interest in the new product however, as it was patent-encumbered, not yet approved by regulators, and sold by a single manufacturer, Lonza Group. In 2013, however, Hyglos GmbH also began manufacturing its own rFC product. This, combined with the acceptance of rFC by European regulators, the comparable cost between LAL and rFC, and support from Eli Lilly and Company, which has committed to use rFC in lieu of LAL, is projected to all but end the practice of blood harvesting from horseshoe crabs.\n\nHorseshoe crabs are used as bait to fish for eels (mostly in the United States) and whelk, or conch. However, fishing with horseshoe crab was banned indefinitely in New Jersey in 2008 with a moratorium on harvesting to protect the red knot wading bird, which eats the crab's eggs. A moratorium was restricted to male crabs in Delaware, and a permanent moratorium is in effect in South Carolina. The eggs are eaten in parts of Southeast Asia and China.\n\nA low horseshoe crab population in the Delaware Bay is hypothesized to endanger the future of the red knot. Red knots, long-distance migratory shorebirds, feed on the protein-rich eggs during their stopovers on the beaches of New Jersey and Delaware. An effort is ongoing to develop adaptive-management plans to regulate horseshoe crab harvests in the bay in a way that protects migrating shorebirds.\n\nDevelopment along shorelines is dangerous to horseshoe crab spawning, limiting available space and degrading habitat. Bulkheads can block access to intertidal spawning regions as well.\n\n"}
{"id": "24953216", "url": "https://en.wikipedia.org/wiki?curid=24953216", "title": "Hydrogen turboexpander-generator", "text": "Hydrogen turboexpander-generator\n\nA hydrogen turboexpander-generator or generator loaded expander for hydrogen gas is an axial flow turbine or radial expander for energy recovery through which a high pressure hydrogen gas is expanded to produce work that is used to drive an electrical generator. It replaces the control valve or regulator where the pressure drops to the appropriate pressure for the low pressure network.\n\nPer stage 200 bar is handled with up to 15,000 kW power and a maximum expansion ratio of 14, the generator loaded expander for hydrogen gas is fitted with automatic thrust balance, a dry gas seal and a programmable logic control with remote monitoring and diagnostics.\n\nThe hydrogen turboexpander-generators are used for hydrogen pipeline transport in combination with hydrogen compressors and for the recovery of energy in underground hydrogen storage. A variation are the compressor loaded turboexpanders which are used in the liquefaction of gases such as liquid hydrogen\n\n\n"}
{"id": "2939202", "url": "https://en.wikipedia.org/wiki?curid=2939202", "title": "Inner core", "text": "Inner core\n\nThe Earth's inner core is the Earth's innermost part. It is primarily a solid ball with a radius of about , which is about 70% of the Moon's radius. It is composed of an iron–nickel alloy and some other elements. The temperature at the inner core's surface is approximately or 9806 °F, which is about the temperature at the surface of the Sun.\n\nThe Earth was discovered to have a solid inner core distinct from its molten outer core in 1936, by the Danish seismologist Inge Lehmann, who deduced its presence by studying seismograms from earthquakes in New Zealand. She observed that the seismic waves reflect off the boundary of the inner core and can be detected by sensitive seismographs on the Earth's surface. This boundary is known as the Bullen discontinuity, or sometimes as the Lehmann discontinuity. A few years later, in 1940, it was hypothesized that this inner core was made of solid iron; its rigidity was confirmed in 1971.\n\nThe outer core was determined to be molten from observations showing that compressional waves pass through it, but elastic shear waves do not – or do so only very weakly. The solidity of the inner core had been difficult to establish because the elastic shear waves that are expected to pass through a solid mass are very weak and difficult for seismographs on the Earth's surface to detect, since they become so attenuated on their way from the inner core to the surface by their passage through the liquid outer core. Dziewonski and Gilbert established that measurements of normal modes of vibration of Earth caused by large earthquakes were consistent with a liquid outer core. In 2005, shear waves were detected passing through the inner core; these claims were initially controversial, but are now gaining acceptance.\n\nBased on the relative prevalence of various chemical elements in the Solar System, the theory of planetary formation, and constraints imposed or implied by the chemistry of the rest of the Earth's volume, the inner core is believed to consist primarily of a nickel-iron alloy. Pure iron was found to be denser than the core by approximately 3%, implying the presence of light elements in the core (e.g. silicon, oxygen, sulfur) in addition to the probable presence of nickel.\n\nFurther, if the primordial and mostly \"fluid\" (still forming) earth contained any significant mass(es) of elements denser than iron and nickel, namely the white (appearance) precious metals (and a few others) \"except\" silver, specifically the siderophile elements, then these would necessarily have differentiated to the very center of the core into concentric nested spheres by planetary differentiation, with the most dense (and stable, i.e. platinum, iridium, and osmium, (etc.) in order of density) of these forming the innermost spheroid(s). While \"unstable\" elements of such trans-iron/nickel density would have mostly decayed to iron/nickel/lead by the time the earth formed a discrete core. It then necessarily follows that all, or almost all, of these denser elements we have mined (or are even able to) at the surface (or near surface, or even at all \"above\" the core) have been delivered later as part of impact objects/masses.\n\nThe temperature of the inner core can be estimated by considering both the theoretical and the experimentally demonstrated constraints on the melting temperature of impure iron at the pressure which iron is under at the boundary of the inner core (about 330 GPa). These considerations suggest that its temperature is about . The pressure in the \nEarth's inner core is slightly higher than it is at the boundary between the outer and inner cores: it ranges from about . Iron can be solid at such high temperatures only because its melting temperature increases dramatically at pressures of that magnitude (see the Clausius–Clapeyron relation).\n\nA report published in the journal \"Science\" concludes that the melting temperature of iron at the inner core boundary is 6230 ± 500 K.\n\nThe Earth's inner core is thought to be slowly growing as the liquid outer core at the boundary with the inner core cools and solidifies due to the gradual cooling of the Earth's interior (about 100 degrees Celsius per billion years). Many scientists had initially expected that the inner core would be found to be homogeneous, because the solid inner core was originally formed by a gradual cooling of molten material, and continues to grow as a result of that same process. Even though it is growing into liquid, it is solid, due to the very high pressure that keeps it compacted together even if the temperature is extremely high. It was even suggested that Earth's inner core might be a single crystal of iron. However, this prediction was disproved by observations indicating that in fact there is a degree of disorder within the inner core. Seismologists have found that the inner core is not completely uniform, but instead contains large-scale structures such that seismic waves pass more rapidly through some parts of the inner core than through others. In addition, the properties of the inner core's surface vary from place to place across distances as small as 1 km. This variation is surprising, since lateral temperature variations along the inner-core boundary are known to be extremely small (this conclusion is confidently constrained by magnetic field observations). Discoveries in 1994 suggest that the solid inner core itself is composed of layers, separated by a transition zone about 250 to 400 km thick. If the inner core grows by small frozen sediments falling onto its surface, then some liquid can also be trapped in the pore spaces and some of this residual fluid may still persist to some small degree in much of its interior.\n\nBecause the inner core is not rigidly connected to the Earth's solid mantle, the possibility that it rotates slightly more quickly or slowly than the rest of Earth has long been entertained. In the 1990s, seismologists made various claims about detecting this kind of super-rotation by observing changes in the characteristics of seismic waves passing through the inner core over several decades, using the aforementioned property that it transmits waves more quickly in some directions. Estimates of this super-rotation are around one degree of extra rotation per year.\n\nGrowth of the inner core is thought to play an important role in the generation of Earth's magnetic field by dynamo action in the liquid outer core. This occurs mostly because it cannot dissolve the same amount of light elements as the outer core and therefore freezing at the inner core boundary produces a residual liquid that contains more light elements than the overlying liquid. This causes it to become buoyant and helps drive convection of the outer core. The existence of the inner core also changes the dynamic motions of liquid in the outer core as it grows and may help fix the magnetic field since it is expected to be a great deal more resistant to flow than the outer core liquid (which is expected to be turbulent).\n\nSpeculation also continues that the inner core might have exhibited a variety of internal deformation patterns. This may be necessary to explain why seismic waves pass more rapidly in some directions than in others. Because thermal convection alone appears to be improbable, any buoyant convection motions will have to be driven by variations in composition or abundance of liquid in its interior. S. Yoshida and colleagues proposed a novel mechanism whereby deformation of the inner core can be caused by a higher rate of freezing at the equator than at polar latitudes, and S. Karato proposed that changes in the magnetic field might also deform the inner core slowly over time.\n\nThere is an East–West asymmetry in the inner core seismological data. There is a model which explains this by differences at the surface of the inner core – melting in one hemisphere and crystallization in the other. The western hemisphere of the inner core may be crystallizing, whereas the eastern hemisphere may be melting. This may lead to enhanced magnetic field generation in the crystallizing hemisphere, creating the asymmetry in the Earth's magnetic field.\n\nBased on rates of cooling of the core, it is estimated that the current solid inner core started solidifying approximately 0.5 to 2 billion years ago out of a fully molten core (which formed just after planetary formation). If true, this would mean that the Earth's solid inner core is not a primordial feature that was present during the planet's formation, but a feature younger than the Earth (the Earth is about 4.5 billion years old).\n\n"}
{"id": "22775557", "url": "https://en.wikipedia.org/wiki?curid=22775557", "title": "Liquid rheostat", "text": "Liquid rheostat\n\nA liquid rheostat or water rheostat or salt water rheostat is a type of variable resistor. \nThis may be used as a dummy load or as a starting resistor for large slip ring motors.\n\nIn the simplest form it consists of a tank containing brine or other electrolyte solution, in which electrodes are submerged to create an electrical load. The electrodes may be raised or lowered into the liquid to respectively decrease or increase the electrical resistance of the load. To stabilize the load, the mixture must not be allowed to boil.\n\nModern designs use stainless steel electrodes, and sodium carbonate, or other salts, and do not use the container as one electrode. In some designs the electrodes are fixed and the liquid is raised and lowered by an external cylinder or pump. Motor start systems with a rapid starting cadenza may include water circulation to external heat exchangers. In such cases anti-freeze and anti-corrosion additives must be carefully chosen to not change the resistance or support the growth of algae or bacteria.\n\nThe salt water rheostat operates at unity power factor and presents a resistance with negligible series inductance compared to a wire wound equivalent, and was widely used by generator assemblers, until 20 years ago, as a matter of course. They are still sometimes constructed on-site for the commissioning of large diesel generators in remote places, where discarded oil drums and scaffold tubes may form an improvised tank and electrodes.\n\nTypically a traditional liquid rheostat consists of a steel cylinder (the negative), about in size, standing on insulators, in which was suspended a hollow steel cylinder. This acted as the positive electrode and was supported by a steel rope and insulator from an adjustable pulley. The water pipe connection included an insulated section. The tank contained salt water, but not at the concentration that could be described as “brine”. The whole device was fenced off for safety.\n\nOperation was very simple, as adding more salt, more water or varying the height of the centre electrode would vary the load. The load proved to be quite stable, varying only slightly as the water heated up. It never came to the boil. Power dissipation was about 1 megawatt, at a potential of about 700 volts and current of about 1,500 amperes.\n\nModern designs use stainless steel electrodes, and sodium carbonate, or other salts, and do not use the container as one electrode.\n\nSystems with a rapid starting cadenza may include water circulation to external heat exchangers. In such cases anti-freeze and anti-corrosion additives must be carefully chosen to not change the resistance or support the growth of algae or bacteria.\n\nAn advantage is silent operation, with none of the fan noise of current resistive grid designs.\n\nDisadvantages include:\n\nRailways commonly used salt water load banks in the 1950s to test the output power of diesel-electric locomotives. They were subsequently replaced by specially designed resistive load banks. These later designs, rated for , currently cost in the region of 100,000 to 180,000 euro. Hence, it is economically advantageous for railways to build their own salt-water type. Some electric locomotives also used liquid rheostats, in particular in Italy for early three-phase AC types such as the FS Class E550. Some direct current designs also used them as starting resistors.\n\nLiquid rheostats were sometimes used in large (thousands of kilowatts/horsepower) wound rotor motor drives, to control the rotor circuit resistance and so the speed of the motor. Electrode position could be adjusted with a small electrically operated winch or a pneumatic cylinder. A cooling pump and heat exchanger were provided to allow slip energy to be dissipated into process water or other water system.\n\nHigh voltage distribution networks use fixed electrolyte resistors to ground the neutral, to provide a current limiting action, so that the voltage across the ground during fault is kept to a safe level. Unlike a solid resistor, the liquid resistor is self healing in the event of overload. Normally the resistance is set up during commissioning, and then left fixed.\n\nModern motor starters are totally enclosed and the electrode movement is servo motor controlled. Typically a 1 tonne tank will start a 1 megawatt slip ring type motor, but there is considerable variation in start time depending on application.\n\nThe fully salt-water load bank dates from an earlier, less regulated and litigious era. To pass current safety legislation requires more enclosed designs.\n\nThey are no more dangerous than electrode heaters, which work on the same principle, but with plain water, or electrical immersion heaters, provided the correct precautions are used. This requires connecting the container to both ground and neutral and breaking all poles with a linked over-current circuit breaker. If in the open, safety barriers are required.\n\n"}
{"id": "2588836", "url": "https://en.wikipedia.org/wiki?curid=2588836", "title": "List of Category 5 Atlantic hurricanes", "text": "List of Category 5 Atlantic hurricanes\n\nThis is a List of Category 5 Atlantic hurricanes. A total of 33 recorded tropical cyclones have reached Category 5 strength on the Saffir–Simpson hurricane wind scale in the Atlantic Ocean north of the equator, the Caribbean Sea, and the Gulf of Mexico. Hurricanes of such intensity occur once every three years in this region on average.\n\nOnly in six seasons—1932, 1933, 1961, 2005, 2007, and 2017—has more than one Category 5 hurricane formed. Only in 2005 have more than two Category 5 hurricanes formed, and only in 2007 and 2017 did more than one make landfall at Category 5 strength.\n\nA Category 5 Atlantic hurricane is one that is considered by the United States National Hurricane Center (NHC), to have had sustained wind speeds greater than on the Saffir–Simpson scale. The NHC considers sustained wind speeds to be those that occur over a one-minute period at above ground. These wind speeds are estimated by using a blend of data from a variety of sources, which include observations from nearby ships, reconnaissance aircraft, or automatic weather stations and pictures from various satellites.\nOfficially, from 1924 to 2017, 33 Category 5 hurricanes have been recorded. No Category 5 hurricanes were observed officially before 1924. It can be presumed that earlier storms reached Category 5 strength over open waters, but the strongest winds were not measured. The anemometer, a device used for measuring wind speed, was invented in 1846. However, during major hurricane strikes, the instruments as a whole were often blown away, leaving the hurricane's peak intensity unrecorded. For example, as the Great Beaufort Hurricane of 1879 struck North Carolina, the anemometer cups were blown away when indicating .\n\n, a reanalysis of weather data was ongoing by researchers who may upgrade or downgrade other Atlantic hurricanes currently listed at Categories 4 and 5. For example, the 1825 Santa Ana hurricane is suspected to have reached Category 5 strength. Furthermore, paleotempestological research aims to identify past major hurricanes by comparing sedimentary evidence of recent and past hurricane strikes. For example, a \"giant hurricane\" significantly more powerful than Hurricane Hattie (Category 5) has been identified in Belizean sediment, having struck the region sometime before 1500.\nOfficially, the decade with the most Category 5 hurricanes is 2000–2009, with eight Category 5 hurricanes having occurred: Isabel (2003), Ivan (2004), Emily (2005), Katrina (2005), Rita (2005), Wilma (2005), Dean (2007), and Felix (2007).\nThe previous decades with the most Category 5 hurricanes were the 1930s and 1960s, with six occurring between 1930 and 1939 (before naming began).\n\nNine Atlantic hurricanes—Camille, Allen, Andrew, Isabel, Ivan, Dean, Felix, Irma and Maria—reached Category 5 intensity on more than one occasion; that is, by reaching Category 5 intensity, weakening to a Category 4 status or lower, and then becoming a Category 5 hurricane again. Such hurricanes have their dates shown together. Camille, Andrew, Dean, Felix, Irma, and Maria each attained Category 5 status twice during their lifespans. Allen, Isabel, and Ivan reached Category 5 intensity on three separate occasions. However, no Atlantic hurricane has reached Category 5 intensity more than three times during its lifespan. The 1932 Cuba hurricane holds the record for the most time spent as a Category 5 hurricane (although it took place before satellite or aircraft reconnaissance, so this record may be somewhat suspect). Irma holds the record for the longest continuous span as a Category 5 storm in the satellite era.\n\nThirty-three Category 5 hurricanes have been recorded in the Atlantic basin since 1851, when records began. Only one Category 5 has been recorded in July, eight in August, nineteen in September, five in October, and one in November. There have been no officially recorded June or off-season Category 5 hurricanes.\n\nThe July and August Category 5 hurricanes reached their high intensities in both the Gulf of Mexico and the Caribbean Sea. These are the areas most favorable for tropical cyclone development in those months.\n\nSeptember sees the most Category 5 hurricanes. This coincides with the climatological peak of the Atlantic hurricane season, which occurs in early September. September Category 5s reached their strengths in any of the Gulf of Mexico, Caribbean Sea, and open Atlantic. These places are where September tropical cyclones are likely to form. Many of these hurricanes are either Cape Verde-type storms, which develop their strength by having a great deal of open water; or so-called Bahama busters, which intensify over the warm Loop Current in the Gulf of Mexico.\n\nAll six Category 5 hurricanes in October and November reached their intensities in the western Caribbean, a region that Atlantic hurricanes strongly gravitate toward late in the season. This is due to the climatology of the area, which sometimes has a high-altitude anticyclone that promotes rapid intensification late in the season, as well as warm waters.\n\nAll Atlantic Category 5 hurricanes have made landfall at some location at hurricane strength. Most Category 5 hurricanes in the Atlantic make landfall because of their proximity to land in the Caribbean and Gulf of Mexico, where the usual synoptic weather patterns carry them towards land, as opposed to the westward, oceanic mean track of Eastern Pacific hurricanes. Sixteen of the storms made landfall while at Category 5 intensity; 2007 and 2017 are the only years in which two storms made landfall at this intensity.\n\nMany of these systems made landfall shortly after weakening from a Category 5 hurricane. This weakening can be caused by dry air near land, shallower waters due to shelving, interaction with land, or cooler waters near shore. In southern Florida, the return period for a Category 5 hurricane is roughly once every 50 years.\n\nThe following table lists these hurricanes by landfall intensity.\n\n\n"}
{"id": "2442268", "url": "https://en.wikipedia.org/wiki?curid=2442268", "title": "List of Delaware state forests", "text": "List of Delaware state forests\n\nDelaware has three state forests, one in each county, totaling more than . These natural resource areas are managed by the Delaware Department of Agriculture Forest Service.\n\nsee also Delaware State Forests\n\nLocated north of Smyrna, Blackbird State Forest covers approximately on the border of New Castle/Kent counties. The ten tracts of Blackbird State Forest are open to the public for nature walks, hiking, jogging, and horseback riding all year. It features a 1/2-mile, wheelchair-accessible wildlife and nature interpretation trail on the Tybout Tract and the Blackbird Education Center on the Meadows Tract. Long-range management plans for Blackbird State Forest outline goals for timber production, wildlife habitat, recreation, soil and water protection, wetland and endangered species protection, and public education.\n\nMany educational programs are available at the Blackbird State Forest Education Center on the Meadows Tract. Complementing a center at Redden State Forest, the facility has two meeting spaces and interactive displays: The Life Cycle of a Forest, Tree Identification, Invasive Species, Urban/Community Forestry, and Wildland Firefighting. Visitors can see a diorama of a beaver pond, a working beehive, and exotic and native insects. Work has also begun on a new nature trail, demonstration saw mill, and arboretum.\n\nAs a state forest, Blackbird began with the 1941 acquisition of the Tybout Tract, purchased for $6,916.20 when land prices in New Castle County presented a rare opportunity for the Forestry Department. \n1941’s Annual Report of the Forestry Department stated: \n\nRedden State Forest contains 18 separate tracts covering over in Sussex County just north of Georgetown, the county seat. The modern Redden State Forest is the consolidation of several Sussex County forest tracts, including the Ellendale State Forest. The Ellendale State Forest Picnic Facility was listed on the National Register of Historic Places in 1991. The first land was acquired in 1928, and since then the forest has continued to grow, with acquisitions as late as 2008. Popular activities at the forest include in-season hunting, horseback-riding, nature observation, and hiking.\n\nRedden State Forest is also home to one of Delaware's two forest education centers. The Redden Forest Education Center includes exhibits on the history of forestry in Delaware, forest pests, urban forestry, and the importance of forests within watersheds.\n\nMuch of Redden State Forest’s history is tied to the railroad. The Junction & Breakwater Railroad, one of Delaware’s earliest rail systems, was completed in 1868. A railroad station was established in 1870 near what would later become Redden State Forest. The station was originally known as Carey’s Station, but a short time later was renamed for Col. William O. Redden. Col. Redden played a prevalent role in Sussex County as he served in the Civil War, was sheriff of Sussex County from 1838–1840, a member of Delaware’s House of Representatives from 1840–1846, including Speaker of the House in 1843, and was instrumental in establishing a railroad system in Delaware.\n\nIn 1877 a farm near the Redden Station and owned by William W. Donovan proceeded through Orphan’s Court following his death. This land is now a portion of Redden State Forest’s Headquarters Tract. Transcripts of the court proceedings mention a large, two-story dwelling with an attached single story, which fits the description of Redden State Forest’s Manager’s House (currently the Redden office).\n\nCharles C. Stockley, the Governor of Delaware from 1872 to 1876, purchased the Donovan Farm in 1879. In 1901 Frank Thompson purchased of land including the original Donovan Farm. Mr. Thompson was the son of the president of the Pennsylvania Railroad Company. In 1903 the club house (Redden Lodge) appeared on Sussex County tax records. From 1903 to 1919 the Lodge was used by Pennsylvania Railroad Company officials and guests for hunting (primarily quail, since much of the surrounding area at that time was fields and hedgerows). Visitors arrived at the Redden Station by train from Philadelphia and proceeded to the Lodge by horse and buggy. The carriages and horses were kept in the Horse Barn, which is now the Redden Education Center.\n\nIn 1936 under the leadership of Delaware’s first State Forester, William S. Taber, the State Forestry Department purchased the that is now the Headquarters Tract from Richard Houghton, who had acquired the property following its use by the Pennsylvania Railroad Company. Since that time, the Headquarters Tract has grown to over . On July 4, 1970, lightning struck the Lodge, and the resulting fire burned the entire west wing and kitchen. The burned section was rebuilt in 1976. In 1990 the Lodge, Manager’s House, and Horse Barn were placed on the National Register of Historic Places. \n\nThe Delaware Forest Service acquired funding from the Delaware General Assembly and, working with the Delaware Department of Administrative Services, Division of Facilities Management, renovated these historic structures. The Redden Lodge was rededicated in 1996, the Manager’s House opened as the Redden office in 1998, and the Horse Barn opened in 2000 as the Education Center. These three structures are now the centerpiece of Redden State Forest.\n\nTaber State Forest covers over in Kent County and is located southwest of Harrington. Parker Road south off of Delaware Route 14, and the Maryland state line generally form the western boundary. About actually extends westward into the state of Maryland. Burrsville Road running southeast from Parker Road cuts through near the center of the land holdings. Saulsbury Creek Road generally forms a boundary for the southwest extent of the property. \n\nTaber State Forest is a primitive use facility and there is no formal office onsite. It is primarily used for hunting, hiking, and wildlife habitat. In addition, the forest is also managed for timber production.\n\nAlthough officially dedicated in 1994, the origin of Taber State Forest was 1984, when the Delaware Forest Service received the Saulsbury Farm. Also included at Taber State Forest is the building known as the Smith School House (now a residence on the property). The Cooper and Cooper Study (found in the holdings of the Delaware Division of Historical and Cultural Affairs) describes the Smith School as a one-teacher schoolhouse with an average student population of 23. The school operated 180 days of the year. \n\nSaulsbury Farm Gravesite: The Saulsbury Tract is home of the Saulsbury family burial grave, which contains a memorial to Gove Saulsbury, the 41st governor of Delaware (1865–1871). This historic gravesite is approximately . by . with 16 graves. The site has one large group monument and three small grave stones with a two-rail split rail fence around the site. Deed restrictions state this parcel must remain as a burial site and be maintained as such.\n\n"}
{"id": "5894536", "url": "https://en.wikipedia.org/wiki?curid=5894536", "title": "List of Lycosidae species", "text": "List of Lycosidae species\n\nThis page lists all described species of the spider family Lycosidae as of Dec. 29, 2013.\n\"Acantholycosa\" \n\n\"Adelocosa\" \n\n\"Agalenocosa\" \n\n\"Aglaoctenus\" \n\n\"Algidus\" \n\n\"Allocosa\" \n\n\"Allotrochosina\" \n\n\"Alopecosa\" \n\n\"Amblyothele\" \n\n\"Anomalomma\" \n\n\"Anomalosa\" \n\n\"Anoteropsis\" \n\n\"Arctosa\" \n\n\"Arctosippa\" \n\n\"Arctosomma\" \n\n\"Artoria\" \n\n\"Artoriellula\" \n\n\"Artoriopsis\" \n\n\"Aulonia\" \n\n\"Auloniella\" \n\n\"Birabenia\" \n\n\"Bogdocosa\" \n\n\"Brevilabus\" \n\n\"Bristowiella\" \n\n\"Camptocosa\" \n\n\"Caporiaccosa\" \n\n\"Caspicosa\" \n\n\"Costacosa\" \n\n\"Crocodilosa\" \n\n\"Cynosa\" \n\n\"Dejerosa\" \n\n\"Deliriosa\" \n\n\"Diahogna\" \n\n\"Diapontia\" \n\n\"Dingosa\" \n\n\"Dolocosa\" \n\n\"Donacosa\" \n\n\"Dorjulopirata\" \n\n\"Draposa\" \n\n\"Edenticosa\" \n\n\"Evippa\" \n\n\"Evippomma\" \n\n\"Foveosa\" \n\n\"Geolycosa\" \n\n\"Gladicosa\" \n\n\"Gnatholycosa\" \n\n\"Hesperocosa\" \n\n\"Hippasa\" \n\n\"Hippasella\" \n\n\"Hoggicosa\" \n\n\"Hogna\" \n\n\"Hognoides\" \n\n\"Hyaenosa\" \n\n\"Hygrolycosa\" \n\n\"Kangarosa\" \n\n\"Katableps\" \n\n\"Knoelle\" \n\n\"Lobizon\" \n\n\"Loculla\" \n\n\"Lycosa\" \n\n\"Lycosella\" \n\n\"Lysania\" \n\n\"Mainosa\" \n\n\"Malimbosa\" \n\n\"Margonia\" \n\n\"Megarctosa\" \n\n\"Melocosa\" \n\n\"Minicosa\" \n\n\"Molitorosa\" \n\n\"Mongolicosa\" \n\n\"Mustelicosa\" \n\n\"Navira\" \n\n\"Notocosa\" \n\n\"Oculicosa\" \n\n\"Ocyale\" \n\n\"Orinocosa\" \n\n\"Orthocosa\" \n\n\"Paratrochosina\" \n\n\"Pardosa\" \n\n\"Pardosella\" \n\n\"Passiena\" \n\n\"Pavocosa\" \n\n\"Phonophilus\" \n\n\"Pirata\" \n\n\"Piratula\" \n\n\"Proevippa\" \n\n\"Prolycosides\" \n\n\"Pseudevippa\" \n\n\"Pterartoria\" \n\n\"Pterartoriola\" \n\n\"Pyrenecosa\" \n\n\"Rabidosa\" \n\n\"Satta\" \n\n\"Schizocosa\" \n\n\"Shapna\" \n\n\"Sibirocosa\" \n\n\"Sosippus\" \n\n\"Syroloma\" \n\n\"Tapetosa\" \n\n\"Tasmanicosa\" \n\n\"Tetralycosa\" \n\n\"Tigrosa\" \n\n\"Trabea\" \n\n\"Trabeops\" \n\n\"Trebacosa\" \n\n\"Tricassa\" \n\n\"Trochosa\" \n\n\"Trochosippa\" \n\n\"Tuberculosa\" \n\n\"Varacosa\" \n\n\"Venator\" \n\n\"Venatrix\" \n\n\"Venonia\" \n\n\"Vesubia\" \n\n\"Wadicosa\" \n\n\"Xerolycosa\" \n\n\"Zantheres\" \n\n\"Zenonina\" \n\n\"Zoica\" \n\n\"Zyuzicosa\" \n\n"}
{"id": "7823492", "url": "https://en.wikipedia.org/wiki?curid=7823492", "title": "List of mountains in Turkey", "text": "List of mountains in Turkey\n\n"}
{"id": "58704628", "url": "https://en.wikipedia.org/wiki?curid=58704628", "title": "List of pipeline accidents in the United States in 2017", "text": "List of pipeline accidents in the United States in 2017\n\nThe following is a list of pipeline accidents in the United States in 2017. It is one of several lists of U.S. pipeline accidents. See also list of natural gas and oil production accidents in the United States.\n\nThis is not a complete list of all pipeline accidents. For natural gas alone, the Pipeline and Hazardous Materials Safety Administration (PHMSA), a United States Department of Transportation agency, has collected data on more than 3,200 accidents deemed serious or significant since 1987.\n\nA \"significant incident\" results in any of the following consequences:\n\nPHMSA and the National Transportation Safety Board (NTSB) post incident data and results of investigations into accidents involving pipelines that carry a variety of products, including natural gas, oil, diesel fuel, gasoline, kerosene, jet fuel, carbon dioxide, and other substances. Occasionally pipelines are repurposed to carry different products.\n\n"}
{"id": "20597406", "url": "https://en.wikipedia.org/wiki?curid=20597406", "title": "List of rivers of Montserrat", "text": "List of rivers of Montserrat\n\nThis is a list of rivers of Montserrat. Rivers are listed in clockwise order, starting at the north end of the island.\n\n\n"}
{"id": "5230861", "url": "https://en.wikipedia.org/wiki?curid=5230861", "title": "Madagascar dry deciduous forests", "text": "Madagascar dry deciduous forests\n\nThe Madagascar dry deciduous forests represent a tropical dry forest ecoregion situated in the western and northern part of Madagascar. The area has high numbers of endemic plant and animal species but has suffered large-scale clearance for agriculture. They are among the world's richest and most distinctive dry forests and included in the Global 200 ecoregions by the World Wide Fund. The area is also home to distinctive limestone karst formations known as tsingy, including the World Heritage Site of Bemaraha.\n\nThere are two separate areas within the ecoregion: the western side of Madagascar from the Ampasindava peninsula in the north to Belo-sur-Tsiribihina and Maromandia in the south (this is most of Mahajanga Province); and the northern tip of the island (apart from the high areas of Amber Mountain). Geological substrate is varied and includes the tsingy limestone massifs.\n\nThese dry deciduous forests span the coastal plain with its limestone plateaus emanating virtually at sea level to higher altitudes to roughly . The area includes wetlands and grasslands (mostly created by forest clearance for agriculture) as well as dry forests characterized by a deciduous canopy extending to a height of .\n\nClimate is tropical, with summer daytime temperatures commonly exceeding , and a wet season between October and April. Rainfall, ranging from 1,000 to 1,500 mm, is more abundant than in the spiny thickets and succulent woodlands, but lower than in the eastern lowland rainforests.\n\nWhile the absolute number of plant species is lower than in the eastern rainforests of the island, the dry deciduous forests of Madagascar have a higher ratio of endemic species. Trees have adapted to the dry climate by shedding leaves in the dry winter season to limit evapotranspiration. Moreover, some species like baobabs and \"Moringa\" have adapted by evolving the ability to store copious water in their large bulbous trunks. Four species of baobabs, including three endemics (\"Adansonia grandidieri\", \"A. madagascariensis\" and \"A. suarezensis\") occur in this ecoregion. Other notable tree species include flamboyant tree (\"Delonix regia\"), \"Pachypodium\" species, and several Fabaceae and Rubiaceae. Forest understory plants include \"Lissochilus\" orchids such as Oeceoclades calcarata, a large, cool growing, showy, terrestrial orchid which grows at medium elevation (1000 to 2000 meters) in western Madagascar. Its habitat is semi-arid and it is found growing in sandy or rocky soils in dry moss and lichen forests.\n\nOne characteristic in common with other tropical and subtropical dry broadleaf forests is the presence of relatively high densities of mammalian biomass. Several of Madagascar's characteristic lemur species are found here including the fat-tailed dwarf lemur, five subspecies of \"Propithecus\", three species of \"Lepilemur\", and five species of \"Microcebus\". Endemic mammals include three endangered species, golden-crowned sifaka (\"Propithecus tattersalli\") and Perrier's sifaka (\"Propithecus diadema perrieri\") and western forest rat (\"Nesomys lambertoni\") as well as mongoose lemur (\"Eulemur mongoz\"), golden-brown mouse lemur (\"Microcebus ravelobensis\"), northern rufous mouse lemur (\"M. tavaratra\"), pygmy mouse lemur (\"M. myoxinus\"), Milne-Edwards' sportive lemur (\"Lepilemur edwardsi\"), and greater big-footed mouse (\"Macrotarsomys ingens\"). As well as lemurs the dry forests are home to the island's largest predator, the fossa (\"Cryptoprocta ferox\") and some smaller carnivorans.\n\nThe lakes and rivers of the dry forest region are homes to most of Madagascar's bird species. Among reptiles, many chameleon and gecko species occur here, as well as the Madagascar sideneck turtle and the critically endangered ploughshare tortoise.\n\nMost dry forests have already been destroyed by human action, especially near the Central Highlands. The remaining forest is severely fragmented. Burning, grazing, and logging are the major threats, and siltation, overfishing and invasive species impact the wetlands. Some species such as lemurs suffer from hunting.\n\nProtected areas of dry deciduous forest include:\n\nThe Ankarana Massif consists of a limestone shelf which imposes a picturesque land-form on the few adventurers who find this remote forest. As the limestone has weathered over geologic time, this karst formation often exhibits spiry pinnacles, called \"tsingy\" locally. The name derives from the Malagasy word which means \"walk on tiptoe\", used by the earliest settlers from around 1500 years ago to describe the sharpness of the rugged limestone shelves. There are an abundance of limestone caves and virgin forests that shelter the diverse wildlife of the Ankarana region. In places the cave roofs have collapsed to form isolated forests and the vegetation of the gorges is also protected by the topography. Subterranean rivers provide a natural perennial irrigation system.\n\nThe Ankarana Special Reserve is one of the northernmost reaches of the Madagascar dry deciduous forests, and is very hot from December through March with this equatorial proximity. Access to wildlife viewing is through strenuous hiking, given the elevation differences, complex terrain and heat, but four-wheel drive vehicles can reach most of the actual campsites. Below the massif, and to the west, is a grassy savannah-with-palms that leads to the Indian Ocean. Within the massif, Lac Vert is found among tsingy formations.\n\nMammals found in this forest include the apex predator fossa (\"Cryptoprocta ferox\"), the fanaloka (\"Fossa fossana\"), northern ring-tailed mongoose and numerous bat species. Lemurs occurring here include the crowned lemur, northern sportive lemur, gray mouse lemur, Sanford's brown lemur and the aye-aye. Numerous geckos inhabit the reserve including the Henkel's leaf-tailed gecko, big-headed gecko and day gecko. Other local reptiles are the Madagascar ground boa, the white-lipped chameleon (\"Furcifer minor\") and Oustalet's chameleon, the world's largest chameleon, which can attain 68 centimetres in length.\n\nSome bird species commonly seen are the hook-billed vanga, Madagascar pygmy kingfisher, crested coua, white-breasted mesite and Madagascar ibis. Raptors sighted in the reserve include the Madagascar harrier-hawk and the Madagascar scops owl. Other avafauna occurring here include red-capped coua and Coquerel's coua, and the vangas Van Dam's vanga, rufous vanga and sickle-billed vanga. Vangas are significant in Madagascar, as 15 of the 16 vanga species are endemic to Madagascar. The greater vasa parrot and Madagascar green pigeon are also indigenous. An important endangered species, the Madagascar fish eagle, has a number of breeding pairs located in the Ankarana Reserve.\n\nAnjajavy Forest is an example of a purely lowland dry deciduous forest in northwest Madagascar. It is punctuated with numerous tsingy outcroppings and limestone karst caves, and in many locations abuts the Indian Ocean, especially where the dramatic tsingy formations jut out into the ocean. The canopy height is typically 15 to 25 meters high, and is at its lowest at the coastal verge, where growth may be impeded by saline rocky soils. The forest resides on a small peninsula of land poking into the Indian Ocean, that is bounded on the north and part of its eastern extent by the Bay of Narinda and on the south by the Bay of Majajamba. Access to this forest is difficult since there are no roads connecting this peninsula to the Madagascar highway system; however, arrival by sea and by air are accomplished with some effort.\n\nIn many places at the ocean edge as well as forest interior, several tree species are capable of taking root directly in the tsingy rocks. Several species of baobab and tamarind are among the tallest species forming the canopy. Considering the lower precipitation rates on the west coast (about 1,300 mm per annum at Anjajavy Forest), the vegetation is surprisingly verdant in the beginning of the dry season, but eventually will become mostly leafless by late winter. The forest understory is moderately dense but not impenetrable. Nor is the understory heavily thorned in most locations.\n\nThe Anjajavy Forest is named for a kind of \"Salvadora\" species, the \"jajavy\" tree, which might be endemic only to the forest itself. Abundant diurnal lemurs that are found here include the Coquerel's sifaka and the common brown lemur. Three nocturnal species of mouse lemur are seen, but their precise species are yet to be documented. A large variety of birds are present including the endangered Madagascar fish eagle, which has four (of the approximately 99 known) breeding pairs resident in Anjajavy Forest. Other birdlife present are the sacred ibis, crested coua, kingfishers and Madagascar wagtail. Butterflies include the magpie crow. Numerous lizards, chameleons and snakes populate the forest and are easily seen from the sparse trail network.\n\nThe dry forest is invaded by fingers of mangrove swamp in the form of riparian zones at several small coastal estuaries at the western verge of the Anjajavy Forest, where small tidal streams flow into the Indian Ocean. The species of the mangrove swamps are, of course, totally different from the dry forest, and the transition zone supports an interesting ecotone, providing unusual niches for several species of animals.\n\n\n"}
{"id": "19322", "url": "https://en.wikipedia.org/wiki?curid=19322", "title": "Mesozoic", "text": "Mesozoic\n\nThe Mesozoic Era ( or ) is an interval of geological time from about . It is also called the Age of Reptiles, a phrase introduced by the 19th century paleontologist Gideon Mantell who viewed it as dominated by diapsids such as \"Iguanodon\", \"Megalosaurus\", \"Plesiosaurus\" and \"Pterodactylus\". To paleobotanists, this Era is also called the Age of Conifers.\n\n\"Mesozoic\" means \"middle life\", deriving from the Greek prefix \"meso-\"/\"μεσο-\" for \"between\" and \"zōon\"/\"ζῷον\" meaning \"animal\" or \"living being\". The name \"Mesozoic\" was proposed in 1840 by the British geologist John Phillips (1800–1874). It is one of three geologic eras of the Phanerozoic Eon, preceded by the Paleozoic (\"ancient life\") and succeeded by the Cenozoic (\"new life\"). The era is subdivided into three major periods: the Triassic, Jurassic, and Cretaceous, which are further subdivided into a number of epochs and stages.\n\nThe era began in the wake of the Permian–Triassic extinction event, the largest well-documented mass extinction in Earth's history, and ended with the Cretaceous–Paleogene extinction event, another mass extinction whose victims included the non-avian dinosaurs. The Mesozoic was a time of significant tectonic, climate and evolutionary activity. The era witnessed the gradual rifting of the supercontinent Pangaea into separate landmasses that would move into their current positions during the next era. The climate of the Mesozoic was varied, alternating between warming and cooling periods. Overall, however, the Earth was hotter than it is today. Dinosaurs appeared in the Late Triassic and became the dominant terrestrial vertebrates early in the Jurassic, occupying this position for about 135 million years until their demise at the end of the Cretaceous. Birds first appeared in the Jurassic, having evolved from a branch of theropod dinosaurs. The first mammals also appeared during the Mesozoic, but would remain small—less than 15 kg (33 lb)—until the Cenozoic.\n\nFollowing the Paleozoic, the Mesozoic extended roughly 186 million years, from when the Cenozoic Era began. This time frame is separated into three geologic periods. From oldest to youngest:\n\nThe lower boundary of the Mesozoic is set by the Permian–Triassic extinction event, during which approximately 90% to 96% of marine species and 70% of terrestrial vertebrates became extinct. It is also known as the \"Great Dying\" because it is considered the largest mass extinction in the Earth's history. The upper boundary of the Mesozoic is set at the Cretaceous–Paleogene extinction event (or K–Pg extinction event), which may have been caused by an asteroid impactor that created Chicxulub Crater on the Yucatán Peninsula. Towards the Late Cretaceous, large volcanic eruptions are also believed to have contributed to the Cretaceous–Paleogene extinction event. Approximately 50% of all genera became extinct, including all of the non-avian dinosaurs.\n\nThe Triassic ranges roughly from 252 million to 201 million years ago, preceding the Jurassic Period. The period is bracketed between the Permian–Triassic extinction event and the Triassic–Jurassic extinction event, two of the \"big five\", and it is divided into three major epochs: Early, Middle, and Late Triassic.\n\nThe Early Triassic, about 252 to 247 million years ago, was dominated by deserts in the interior of the Pangaea supercontinent. The Earth had just witnessed a massive die-off in which 95% of all life became extinct, and the most common vertebrate life on land were \"lystrosaurus\", labyrinthodonts, and \"euparkeria\" along with many other creatures that managed to survive the Permian extinction. Temnospondyls evolved during this time and would be the dominant predator for much of the Triassic. \n\nThe Middle Triassic, from 247 to 237 million years ago, featured the beginnings of the breakup of Pangaea and the opening of the Tethys Sea. Ecosystems had recovered from the Permian extinction. Algae, sponge, corals, and crustaceans all had recovered, and new aquatic reptiles evolved, such as ichthyosaurs and nothosaurs. On land, pine forests flourished, as did groups of insects like mosquitoes and fruit flies. Reptiles began to get bigger and bigger, and the first crocodilians evolved, which sparked competition with the large amphibians that had previously ruled the freshwater world.\n\nFollowing the bloom of the Middle Triassic, the Late Triassic, from 237 to 201 million years ago, featured frequent heat spells and moderate precipitation (10-20 inches per year). The recent warming led to a boom of reptilian evolution on land as the first true dinosaurs evolved, as well as pterosaurs. During the Late Triassic, some advanced cynodonts gave rise to the first Mammaliaformes. All this climatic change, however, resulted in a large die-out known as the Triassic-Jurassic extinction event, in which many archosaurs (excluding pterosaurs, dinosaurs and crocodylomorphs), most synapsids, and almost all large amphibians became extinct, as well as 34% of marine life, in the Earth's fourth mass extinction event. The cause is debatable;flood basalt eruptions at the Central Atlantic magmatic province is cited as one possible cause.\n\nThe Jurassic ranges from 200 million years to 145 million years ago and features 3 major epochs: The Early Jurassic, the Middle Jurassic, and the Late Jurassic.\n\nThe Early Jurassic spans from 200 to 175 million years ago. The climate was tropical, much more humid than the Triassic. In the oceans, plesiosaurs, ichthyosaurs and ammonites were abundant. On land, dinosaurs and other archosaurs staked their claim as the dominant race, with theropods such as \"Dilophosaurus\" at the top of the food chain. The first true crocodiles evolved, pushing the large amphibians to near extinction. All-in-all, archosaurs rose to rule the world. Meanwhile, the first true mammals evolved, remaining relatively small but spreading widely; the Jurassic \"Castorocauda\", for example, had adaptations for swimming, digging and catching fish. \"Fruitafossor\", from the late Jurassic period about 150 million years ago, was about the size of a chipmunk, and its teeth, forelimbs and back suggest that it dug open the nests of social insects (probably termites, as ants had not yet appeared). The first multituberculates like \"Rugosodon\" evolved, while volaticotherians took to the skies.\n\nThe Middle Jurassic spans from 175 to 163 million years ago. During this epoch, dinosaurs flourished as huge herds of sauropods, such as \"Brachiosaurus\" and \"Diplodocus\", filled the fern prairies, chased by many new predators such as \"Allosaurus\". Conifer forests made up a large portion of the forests. In the oceans, plesiosaurs were quite common, and ichthyosaurs flourished. This epoch was the peak of the reptiles. \n\nThe Late Jurassic spans from 163 to 145 million years ago. During this epoch, the first avialans, like \"Archaeopteryx\", evolved from small coelurosaurian dinosaurs. The increase in sea levels opened up the Atlantic seaway, which has grown continually larger until today. The divided landmasses gave opportunity for the diversification of new dinosaurs.\n\nThe Cretaceous is the longest period of the Mesozoic, but has only two epochs: Early and Late Cretaceous. \n\nThe Early Cretaceous spans from 145 to 100 million years ago. The Early Cretaceous saw the expansion of seaways, and as a result, the decline and extinction of sauropods (except in South America). Some island-hopping dinosaurs, like \"Eustreptospondylus\", evolved to cope with the coastal shallows and small islands of ancient Europe. Other dinosaurs rose up to fill the empty space that the Jurassic-Cretaceous extinction left behind, such as \"Carcharodontosaurus\" and \"Spinosaurus\". Of the most successful was the \"Iguanodon\", which spread to every continent. Seasons came back into effect and the poles got seasonally colder, but some dinosaurs still inhabited the polar forests year round, such as \"Leaellynasaura\" and \"Muttaburrasaurus\". The poles were too cold for crocodiles, and became the last stronghold for large amphibians like \"Koolasuchus\". Pterosaurs got larger as genera like \"Tapejara\" and \"Ornithocheirus\" evolved. Mammals continued to expand their range: eutriconodonts produced fairly large, wolverine-like predators like \"Repenomamus\" and \"Gobiconodon\", early therians began to expand into metatherians and eutherians, and cimolodont multituberculates went on to become common in the fossil record.\n\nThe Late Cretaceous spans from 100 to 66 million years ago. The Late Cretaceous featured a cooling trend that would continue in the Cenozoic era. Eventually, tropics were restricted to the equator and areas beyond the tropic lines experienced extreme seasonal changes in weather. Dinosaurs still thrived, as new taxa such as \"Tyrannosaurus\", \"Ankylosaurus\", \"Triceratops\" and hadrosaurs dominated the food web. In the oceans, mosasaurs ruled, filling the role of the ichthyosaurs, which, after declining, had disappeared in the Cenomanian-Turonian boundary event. Though pliosaurs had gone extinct in the same event, long-necked plesiosaurs such as \"Elasmosaurus\" continued to thrive. Flowering plants, possibly appearing as far back as the Triassic, became truly dominant for the first time. Pterosaurs in the Late Cretaceous declined for poorly understood reasons, though this might be due to tendencies of the fossil record, as their diversity seems to be much higher than previously thought. Birds became increasingly common and diversified into a variety of enantiornithe and ornithurine forms. Though mostly small, marine hesperornithes became relatively large and flightless, adapted to life in the open sea. Metatherians and primitive eutherian also became common and even produced large and specialised genera like \"Didelphodon\" and \"Schowalteria\". Still, the dominant mammals were multituberculates, cimolodonts in the north and gondwanatheres in the south. At the end of the Cretaceous, the Deccan traps and other volcanic eruptions were poisoning the atmosphere. As this continued, it is thought that a large meteor smashed into earth 66 million years ago, creating the Chicxulub Crater in an event known as the K-Pg Extinction (formerly K-T), the fifth and most recent mass extinction event, in which 75% of life became extinct, including all non-avian dinosaurs. Everything over 10 kilograms became extinct. The age of the dinosaurs was over.\n\nCompared to the vigorous convergent plate mountain-building of the late Paleozoic, Mesozoic tectonic deformation was comparatively mild. The sole major Mesozoic orogeny occurred in what is now the Arctic, creating the Innuitian orogeny, the Brooks Range, the Verkhoyansk and Cherskiy Ranges in Siberia, and the Khingan Mountains in Manchuria. \n\nThis orogeny was related to the opening of the Arctic Ocean and subduction of the North China and Siberian cratons under the Pacific Ocean. In contrast, the era featured the dramatic rifting of the supercontinent Pangaea, which gradually split into a northern continent, Laurasia, and a southern continent, Gondwana. This created the passive continental margin that characterizes most of the Atlantic coastline (such as along the U.S. East Coast) today.\n\nBy the end of the era, the continents had rifted into nearly their present forms, though not their present positions. Laurasia became North America and Eurasia, while Gondwana split into South America, Africa, Australia, Antarctica and the Indian subcontinent, which collided with the Asian plate during the Cenozoic, giving rise to the Himalayas.\n\nThe Triassic was generally dry, a trend that began in the late Carboniferous, and highly seasonal, especially in the interior of Pangaea. Low sea levels may have also exacerbated temperature extremes. With its high specific heat capacity, water acts as a temperature-stabilizing heat reservoir, and land areas near large bodies of water—especially oceans—experience less variation in temperature. Because much of Pangaea's land was distant from its shores, temperatures fluctuated greatly, and the interior probably included expansive deserts. Abundant red beds and evaporites such as halite support these conclusions, but some evidence suggests the generally dry climate of was punctuated by episodes of increased rainfall. The most important humid episodes were the Carnian Pluvial Event and one in the Rhaetian, a few million years before the Triassic–Jurassic extinction event.\n\nSea levels began to rise during the Jurassic, probably caused by an increase in seafloor spreading. The formation of new crust beneath the surface displaced ocean waters by as much as above today's sea level, flooding coastal areas. Furthermore, Pangaea began to rift into smaller divisions, creating new shoreline along the Tethys Sea. Temperatures continued to increase, then began to stabilize. Humidity also increased with the proximity of water, and deserts retreated.\n\nThe climate of the Cretaceous is less certain and more widely disputed. Probably, higher levels of carbon dioxide in the atmosphere are thought to have almost eliminated the north-south temperature gradient: temperatures were about the same across the planet, and about 10°C higher than today. The circulation of oxygen to the deep ocean may also have been disrupted, preventing the decomposition of large volumes of organic matter, which was eventually deposited as \"black shale\".\n\nNot all data support these hypotheses, however. Even with the overall warmth, temperature fluctuations should have been sufficient for the presence of polar ice caps and glaciers, but there is no evidence of either. Quantitative models have also been unable to recreate the flatness of the Cretaceous temperature gradient.\n\nDifferent studies have come to different conclusions about the amount of oxygen in the atmosphere during different parts of the Mesozoic, with some concluding oxygen levels were lower than the current level (about 21%) throughout the Mesozoic, some concluding they were lower in the Triassic and part of the Jurassic but higher in the Cretaceous, and some concluding they were higher throughout most or all of the Triassic, Jurassic and Cretaceous.\n\nThe dominant land plant species of the time were gymnosperms, which are vascular, cone-bearing, non-flowering plants such as conifers that produce seeds without a coating. This is opposed to the earth's current flora, in which the dominant land plants in terms of number of species are angiosperms. One particular plant genus, \"Ginkgo\", is thought to have evolved at this time and is represented today by a single species, \"Ginkgo biloba\". As well, the extant genus \"Sequoia\" is believed to have evolved in the Mesozoic.\n\nFlowering plants radiated sometime in the early Cretaceous, first in the tropics, but the even temperature gradient allowed them to spread toward the poles throughout the period. By the end of the Cretaceous, angiosperms dominated tree floras in many areas, although some evidence suggests that biomass was still dominated by cycads and ferns until after the Cretaceous–Paleogene extinction.Some plant species had distributions that were markedly different from succeeding periods; for example, the Schizeales, a fern order, were skewed to the Northern Hemisphere in the Mesozoic, but are now better represented in the Southern Hemisphere.\n\nThe extinction of nearly all animal species at the end of the Permian Period allowed for the radiation of many new lifeforms. In particular, the extinction of the large herbivorous pareiasaurs and carnivorous gorgonopsians left those ecological niches empty. Some were filled by the surviving cynodonts and dicynodonts, the latter of which subsequently became extinct.\n\nRecent research indicates that it took much longer for the reestablishment of complex ecosystems with high biodiversity, complex food webs, and specialized animals in a variety of niches, beginning in the mid-Triassic 4M to 6M years after the extinction, and not fully proliferated until 30M years after the extinction. Animal life was then dominated by various archosaurs: dinosaurs, pterosaurs, and aquatic reptiles such as ichthyosaurs, plesiosaurs, and mosasaurs.\n\nThe climatic changes of the late Jurassic and Cretaceous favored further adaptive radiation. The Jurassic was the height of archosaur diversity, and the first birds and eutherian mammals also appeared. Some have argued that insects diversified in symbiosis with angiosperms, because insect anatomy, especially the mouth parts, seems particularly well-suited for flowering plants. However, all major insect mouth parts preceded angiosperms, and insect diversification actually slowed when they arrived, so their anatomy originally must have been suited for some other purpose.\n"}
{"id": "34740056", "url": "https://en.wikipedia.org/wiki?curid=34740056", "title": "Mid-Brunhes Event", "text": "Mid-Brunhes Event\n\nThe Mid-Brunhes Event (MBE) is a climatic shift evident in a number of marine sediment and Antarctic ice cores. It corresponds to an increase in amplitude of glacial-interglacial cycles.\n\nThe MBE roughly corresponds to the transition between MIS 12 and MIS 11 (Termination V) about 430 kyr ago.\n\nIt is characterized by a further increase of ice-volume variations with, from then to the present day, four large-amplitude 100-kyr-dominated glacial–interglacial cycles.\n"}
{"id": "53584442", "url": "https://en.wikipedia.org/wiki?curid=53584442", "title": "Minesweeper flotilla (Kriegsmarine)", "text": "Minesweeper flotilla (Kriegsmarine)\n\nMinesweeper flotillas of the Kriegsmarine were administrative units which grouped German minesweepers together. There were three types of minesweeper flotillas: standard minesweepers, auxiliary minesweepers, and \"mine barrage\" vessels. Flotilla commanders operated from a shore office, and were usually commanded by an officer ranked as a \"Korvettenkapitän\". All minesweeper flotillas were under the command of the \"Führer der Minensuchboote\" (Leader of Minesweepers) which, by 1940, had been divided into three separate offices for activities in the North Sea, Baltic Sea, and off the coast of France.\n\nWhen operationally deployed, the minesweepers were under a separate chain of command under the authority of harbor security commanders.\n\nThe first minesweeper flotilla of the Kriegsmarine was formed in 1936 from pre-existing units of the Reichsmarine, which had maintained two minesweeper and one auxiliary minesweeper flotillas during the inter-war years. The standard German minesweeper flotilla of World War II contained between seven and fifteen minesweeper class vessels. \n\nIn addition to the standard minesweeper flotillas, twenty \"auxiliary minesweeper\" (R boat) flotillas (\"Räumboots-Flottille\") were formed during the Second World War.\n\nEstablished in October 1937, with boats: R 17, R 18, R 19, R 20, R 21, R 22, R 23, R 24.\n\nEstablished in November 1938, with boats: R 25, R 26, R 27, R 28, R 29, R 29, R 30, R 31, R 32.\n\nEstablished in 1939 at Pillau, with boats: R 33, R 34, R 35, R 36, R 37, R 38, R 39, R 40.\n\nEstablished in April 1940, with boats: R 41, R 42, R 43, R 44, R 45, R 46, R 47, R 48, R 49, R 50, R 51, R 52.\n\nEstablished in August 1939, with boats: R 1, R 3, R 4, R 5, R 6, R 7, R 8, R 9, R 10, R 11, R 12, R 13.\n\nEstablished in July 1941 at Cuxhaven, with boats: R 9, R 10, R 11, R 12, R 13, R 14, R 15, R 16.\n\nEstablished in October 1940, with boats: R 151, R 152, R 153, R 154, R 155, R 156, R 157, R 158, R 159, R 160, R 161, R 162.\n\nEstablished in January 1942, with boats: R 92, R 93, R 94, R 95, R 96, R 97, R 98, R 99, R 100, R 101.\n\nEstablished in May–June 1942 at Rotterdam.\n\nEstablished in February–March 1942 at Cuxhaven\n\nEstablished in September 1939, with 8 fishing trawlers and 1 escort ship. In October 1940, was renamed 7th Minesweeper Flotilla and assigned purpose-built R-boats.\nEstablished in May 1942 at Bruges; then moved into the Mediterranean. Dissolved in February 1945.\n\nEstablished on 15 November 1943; used in the German Bight. In 1957, the flotilla was transferred to the new German Navy (\"Bundesmarine\") from the German Mine Sweeping Administration.\n\nEstablished in December 1943; used in the English Channel. After the invasion of France in June 1944 was used in the German Bight and the Baltic Sea.\n\nEstablished on 1 July 1944; used in the Baltic Sea, including Finnish waters. Disbanded after the German surrender.\n\nEstablished in October 1944, main base Haugesund, Norway. Dissolved on 25 November 1947.\n\nEstablished in July 1944 with school and training boats; initially named Räumbootsflottille zbV, and used in the Baltic Sea. Dissolved late 1947.\n\nEstablished in July 1943. The flotilla consisted of 12 large escort minesweepers (Geleit-Räumbooten) based at Bergen, Norway. Dissolved early 1946.\n\nEstablished in the summer of 1945 at Denmark with boats from various flotillas, for the German Mine Sweeping Administration. Dissolved early 1946.\n\nEstablished in June 1943 with small Dutch minesweepers and moved into the Black Sea. Dissolved in August 1944.\n\nMine barrage flotillas (\"Sperrbrecherflottille\") were composed of auxiliary naval ships and merchant vessels that had been converted to enter minefields ahead of other ships in order to detonate enemy mines. These \"Sperrbrecher\" vessels were heavily armored and were occasionally outfitted as anti-aircraft platforms. The Kriegsmarine first organized the mine barrage vessels into \"Speerbrechergruppe\" (mine barrage groups) at the start of World War II. Each group contained various auxiliary vessels designated by roman numerals augmented by a naval tender.\n\nOriginal mine barrage groups\n\n\nIn June 1940, the Kriegsmarine formed a mine barrage unit in the Low Countries known as \"Sperrbrechergruppe Niederlande\". Shortly thereafter, the Kriegsmarine began to designate mine barrage vessels with capitol letters, but only three such vessels were ever declared (\"Sperrbrecher\" A, B, & C). By late 1940, the mine barrage vessels were designated with standard numbers while the mine barrage groups were re-designated as flotillas. Eight flotillas were authorized with seven eventually formed; the standard rank for a mine barrage flotilla commander was \"Fregattenkapitän\". As the \"Sperrbrecher\" ships were mostly auxiliary vessels, the flotillas were considered administrative in nature and operated from shore offices.\n\nMine barrage flotillas\n\nIn addition to the standard \"Sperrbrecher\" craft, some flotillas possessed support and tender vessels for refit and supply duties\n\nMine barrage support vessels\n\n"}
{"id": "3010833", "url": "https://en.wikipedia.org/wiki?curid=3010833", "title": "Negawatt power", "text": "Negawatt power\n\nNegawatt power is a theoretical unit of power representing an amount of electrical power (measured in watts) saved. The energy saved is a direct result of energy conservation or increased energy efficiency. The term was coined by the chief scientist of the Rocky Mountain Institute and environmentalist Amory Lovins in 1985, within the article, \"Saving Gigabucks with Negawatts,\" where he argued that utility customers don’t want kilowatt-hours of electricity; they want energy services such as hot showers, cold beer, lit rooms, and spinning shafts, which can come more cheaply if electricity is used more efficiently. Lovins felt an international behavioral change was necessary in order to decrease countries' dependence on excessive amounts of energy. The concept of a negawatt could influence a behavioral change in consumers by encouraging them to think about the energy that they spend.\n\nA negawatt market can be thought of as a secondary market, in which electricity is allocated from one consumer to another consumer within the energy market. In this market, negawatts could be treated as a commodity. Commodities have the ability to be traded across time and space, which would allow negawatts to be incorporated in the international trading system. Roughly 10% of all U.S. electrical generating capacity is in place to meet the last 1% of demand and there is where the immediate efficiency opportunity exists.\n\nOn March 15, 2011, the Federal Energy Regulatory Commission (FERC), the agency that regulates the U.S. electrical grid, approved a rule establishing the approach to compensation for demand response resources intended to benefit customers and help improve the operation and competitiveness of organized wholesale energy markets. This means that negawatts produced by reducing electrical use can demand the same market prices as real megawatts of generated electricity.\nThe incentives for a negawatt market include receiving money, reduction of national energy dependency, and the local electricity deregulation within certain nations or states. As for the cost incentive, those who produce negawatts or simply conserve energy can earn money by selling the saved energy. The negawatt market could help nations or states obtain a deregulated electricity system by creating another market to purchase electricity from. \nThe negawatt market also has two main drawbacks. Currently, there is no way to precisely measure the amount of energy saved in negawatts, and electricity providers may not want customers to use less energy due to the loss of profit.\nNegawatt power is a theoretical unit of power representing an amount of electrical power (measured in Watts) saved. Energy is saved by either increased efficiency or reduced energy consumption; the conserved energy is a \"negawatthour\". The concept of a negawatt is simply a measure of power that is not used. Negawatts are a form of encouragement to motivate consumers to conserve energy. Amory Lovins considers the concept of conservation \"a change in behavior based on the attitude 'Do Less to Use Less.'\" He makes a distinction between conservation and efficiency by defining efficiency as \"the application of technologies and best practices to eliminate waste based on the attitude, 'Do the same or more with less.'\"\n\nCost for negawatt power can be calculated using cost-effectiveness analysis or CEA. For energy efficiency investments a CEA calculation produces the value of saved energy or \"negawatts\" in $/kWh. Such a valuation allows comparing the price of negawatts with price of energy such as electricity from the grid or the cheapest renewable alternative. Specifically, Tuominen et al. have suggested using the dynamic generation cost type of CEA for energy efficiency investments as it includes the best accounting for the time value among the various CEA methods available.\n\nA negawatt is a unit in watts of electrical power saved. The term negawatt is derived from megawatt and was created by Amory Lovins. Lovins saw a typo — \"negawatt\" instead of \"megawatt\" — in a Colorado Public Utilities Commission report in 1989. He adopted the term to describe electricity that was not created using energy efficiency and conservation. He was concerned with the large inefficiencies of energy use and came up with ways to remedy the problem. Lovins advocated for more efficient light bulbs and reflective metals that increase the intensity of light produced. He wanted consumers to use the energy produced in a smarter way by \"wringing more work from the electricity we already have.\" Lovins felt an international behavioral change was necessary in order to decrease countries' dependence on excessive amounts of energy. The concept of a negawatt could influence a behavioral change in consumers by encouraging them to think about the energy that they spend.\n\nAccording to Lovins, energy efficiency represents a profitable global market and American companies have at their disposal the technical innovations to lead the way. Not only should they \"upgrade their plants and office buildings, but they should encourage the formation of negawatt markets\". Lovins sees negawatt markets as a win-win solution to many environmental problems. Because it is \"now generally cheaper to save fuel than to burn it, global warming, acid rain, and urban smog can be reduced not at a cost but at a profit\".\n\nLovins explains that many companies are already enjoying the financial and other rewards that come from saving electricity. Yet progress in converting to electricity saving technologies has been slowed by the indifference or outright opposition of some utilities. A second obstacle to efficiency is that many electricity-using devices are purchased by people who won’t be paying their running costs and thus have little incentive to consider efficiency. Lovins also believes that many customers \"don't know what the best efficiency buys are, where to get them, or how to shop for them\".\n\nIn 2003 in France under the guide of Thierry Salomon 23 scientists wrote \"Le manifeste Négawatt.\" Megawatt and negawatt seem to be reminiscent to the larger concept of ecological footprint, handprint handprint, and by following this line of thought toward compatibility and comparability a second frame of concept seems appropriate: mindprint — the impact in another frame or setting where units or numbers can not be compared (see paradigm shift). See association négaWatt.\n\nAmory Lovins has advocated a \"negawatt revolution\", arguing that utility customers don’t want kilowatt-hours of electricity; they want energy services such as hot showers, cold beer, lit rooms, and spinning shafts, which can come more cheaply if electricity is used more efficiently. Lovins, defines the negawatt market as a way to reduce the gap between the cost of making and saving electricity.\n\nThe negawatt market can be thought of as a secondary market where electricity is allocated from areas of less use to areas of greater use. This would be a secondary market, due to the fact that it would reallocate electricity from one consumer to another within the already existing energy market. Some feel that to establish a viable market, legislation and cooperation between primary producers, distributors, traders and consumers, may be required. This proposal would encourage the market to have legislative regulations, while still allowing the market to work within itself to set prices and allocate resources.\n\nA negawatt market would allow \"demand side resources\" to participate in wholesale energy markets. These markets are commonly referred to as a demand response. Demand response can be defined as \"enrolling large users of energy in programs to lower their usage in return for compensation, which helps take pressure off the grid\" This market would help take pressure off the grid because electricity could \"be treated as a commodity just like copper or sowbellies,\" and therefore traded to areas that need it more than others. As any commodity, negawatts would have to be \"tradable across time and space\" to be an effective market. Being able to trade negawatts across time and space would allow for an international trading system. To create a market for negawatts, energy companies will need to put more focus toward energy efficiency. This shift in focus would require a new \"business structure that will thrive in the 'negawatt market'\", which has not yet been developed. Market possibilities are being implemented internationally, implying that one day an official negawatt market will become a reality.\n\nNegawatt power is being implemented in many states in the U.S. and is emerging as an international strategy to reduce energy consumption. \"Test negawatt auctions began in 1999 in Connecticut and Georgia and more than a dozen utility exchanges were in existence\" in 2000. In an effort to move toward energy efficiency, New York has created programs \"supported through Energy $mart, which is run by the New York State Energy Research and Development Authority (NYSERDA), with money from a small surcharge on utility bills.\" Negawatt power is implemented in California as well as Texas. \"Some Texas congressmen and energy companies are trying to help California avert blackouts and utility price shocks this summer with [...] 'negawatts'.\n\nOn January 1, 2009, the states of South Australia and Victoria (Australia) became the first in Australia to offer \"householders energy efficiency incentives programs delivered via local electricity retailers.\"\n\nThe UK is looking to balance the demand of electricity by proposing a bill in which \"the government may pay major users for each “negawatt” of capacity they switch off\" during high use. Payment may also be issued for supplying the grid.\n\nThe negawatt market is being used by governments and companies. Aluminum manufacturers in the Pacific Northwest shut down their power plants and sold the unused energy because selling the negawatts was more profitable for the company than selling the aluminum product. This was possible because \"The smelters hold power contracts with the federal Bonneville Power Administration that contain clauses allowing them to market the electricity.\"\n\nThe Associated Electric company in rural Missouri is implementing the usage and spreading the knowledge of negawatts by performing energy audits at their customer's homes to show them where they could be saving electricity. Rebates are being given to help cutomers pay for more energy-efficient, Energy Star appliances. Keith Hartner, the CEO of Associated Electric Cooperative Inc., feels that negawatts are generating savings for their customers and for the company as well: “The goal of this program is to save money not only at the generator but also at the meter for the members.”\n\nIndividual households can practice negawatts through using energy-efficient lighting and Energy Star appliances as well as simply reducing standby power. The resulting savings sometimes offset the investment in new high efficient light bulbs and appliances. These efficiencies can offset a portion of the cost of a residential photovoltaic system. Negawatts reduces the overall size of the photovoltaic system required for the household, because they are consuming less electricity. This results in a faster payback period for the photovoltaic system. The City of San Diego has created a negawatts initiative called \"Reduce then Produce\" to promote this idea.\n\nThe most noteworthy advantage in creating a negawatt market is the cost incentive. As many will say, \"The cheapest watt is the one that's never created.\" In this market, the consumers who increase their home efficiency, or decrease their energy consumption, can earn money by selling the saved electricity. This is similar to an emissions trading or a cap-and-trade system, in which the energy that is not used can be bought from the consumers who saved the energy and sold to those who need to purchase the extra energy. Providers of electricity can encourage consumers to sell back their unused energy, or negawatthours, especially during peak hours. A major question that electric companies need to ask themselves is whether it is less expensive to pay consumers to reduce consumption for a few instances a year or to build and maintain a side-supply resource that would only be used a few times a year. Many argue that the \"cost of foregone consumption is less than the cost of increasing the supply of electricity.\"\n\nIf a consumer conserves a substantial amount of energy then there can even be an allowance for a tax deduction. According to the Negawatt Power Solutions Group, a \"building that achieved a 50% energy cost reduction may be eligible for tax deduction up to $1.80 per square foot.\" Negawatts can help alleviate some of the costs of constructing new, efficient buildings. \"The negawatt revolution now provides a way to cut construction costs, capture big returns on capital in renovations, [and] dramatically cut operating expenses.\" Existing buildings can be made more efficient by renovating the insulation to cut back on electricity used for heating, installing more efficient light fixtures, and an upgraded HVAC design. Renovating a building to be more energy efficient will cost less than creating entirely new, more efficient buildings.\n\nThe reduction of the amount of energy that a region emits can slowly separate a nation from a high energy consumption of oil. The desire to become a less energy-dependent country may promote behavioral changes and a different societal outlook on energy usage. These potential societal perspective changes could lead to an overall more sustainable country. The reduced consumption of energy would also produce less greenhouse gases, which could have positive outcomes on the economy, political parties, and interest groups, such as environmentalists. According to Lovins, improvements in energy efficiency and conservation, due to a change in behavioral attitudes, have a huge potential to reduce a country's \"long-term energy needs,\" such as the United States.\n\nSome conservatives claim that the negawatt market could help nations or states have a deregulated electricity system. This would allow a nation or a state to experiment with \"electricity deregulation,\" in which \"demand reductions could be purchased with a minimum of disruption to businesses, workers and the economy.\" In the United States, for instance, the negawatt market could assist California with rolling blackouts by making more power available from consumers who choose to conserve energy or increase their negawatts. California could achieve the goal of deregulation by allowing a deficit area to \"purchase an emergency supply from anywhere within with West\" in which \"the ultimate purpose of deregulation was to allow competition in the electricity market and consumer choice of electricity providers.\" Negawatt power would allow the consumers in a country's economy to decide how the energy will be distributed: essentially benefiting regions that hope to have a deregulated electricity system.\n\nCurrently, there is no way to precisely measure the amount of energy saved in negawatts; it can only be theoretically determined based on the consumer’s history of energy use. Visualizing has a very important role in “enabling residents to understand and manage their energy use,” which serves as a form of encouragement for consumers to conserve energy. Without the visualization of the energy use, it is difficult to conceptualize negawatts because the consumer cannot see a precise value of the amount of saved energy. Smart meters are becoming a more developed technology to measure energy usage, but \"consumers are calling on state regulators to move cautiously on smart meters, citing complaints in some states that the meters are raising electric bills rather than lowering them.\"\n\nSome municipally owned utilities and cooperatives argue that negawatt power \"lets consumers treat electricity as a property right rather than a service [...giving them] legal entitlement to power [that they] don't consume.” This would indicate that consumers would treat electricity as a property, not a service. Some people, including the senior vice president Joe Nipper from the American Public Power Association, oppose the idea that people would receive money for power that they did not even spend.\n\nElectricity price caps may also need to be implemented in order for the emerging negawatts market to function correctly. To some, government limitations on markets are unfavorable. There is a current view that negawatts are worth pursuing, but that they are unlikely to satisfy the world's thirst for energy to the extent their advocates assume.\n\nSaving energy by the negawatt and creating a negawatt market can present several drawbacks for manufacturers and electricity providers. Manufacturers are less inclined to make energy-efficient devices which meet a specific standard, such as Energy star's standard, because of increased time and cost, while receiving minimal profit. Overall, electricity providers may not want customers to use less energy due to the loss of profit. Some even argue that producing energy-efficient products, such as light bulbs, actually simulate more demand, “resulting in more energy being purchased for conversion into light.\"\n\nCustomers may also be less inclined to buy products that are more energy efficient due to the increase in cost and time spent. \"Even when the information is known and, despite the overall long-term cost-saving potential, the price of energy is too low...for individuals to justify the initial cost of energy efficiency measures.\" Not only are energy efficient devices more expensive, but \"consumers are poorly informed about the savings on offer. Even when they can do the sums, the transaction costs are high: it is a time-consuming chore for someone to identify the best energy-saving equipment, buy it and get it installed.\"\n\nThe technology used to measure the amount of energy that a consumer uses and saves, known as smart meters, grid systems, or energy dashboards, require time for the consumer to understand. Some argue that people need to have access to “simple yet effective information systems to help users understand their energy without having to become technology experts.” The current visual energy measuring devices could be made simpler and less expensive, which may encourage customers to save more energy, thus increasing their negawatts.\n\nThe capital cost of energy-efficiency is erroneously argued by some to exceed the energy savings (energy required for raw materials, manufacture and transport to point of sale versus running costs). For instance they argue that the capital cost of buying a new energy efficient car will not be recouped unless the car runs for more than ten years. However increased energy efficiency leads to less usage and longer life.\n\n\n"}
{"id": "50972911", "url": "https://en.wikipedia.org/wiki?curid=50972911", "title": "Oil and Gas Regulatory Authority", "text": "Oil and Gas Regulatory Authority\n\nThe Oil and Gas Regulatory Authority (, abbreviated as OGRA) is an agency of the Government of Pakistan, which is responsible for regulating the oil and gas sector in Pakistan. It was established in 2002.\n\n"}
{"id": "40885800", "url": "https://en.wikipedia.org/wiki?curid=40885800", "title": "Oil toxicity", "text": "Oil toxicity\n\nOil toxicity (or oil intoxication) is a wildlife disease resulting from the accidental exposure of animals to oil. Major sources of such oil in the environment include accidental oil spills from off-shore sites, oil tankers, pipelines, and other facilities that store and process oil. Wildlife exposure to oil can result in both external and internal damage. Oil intoxication has the greatest impact on bird species, aquatic mammals, and other aquatic organisms. Affected wildlife can usually be identified via visual inspection, and can be treated if found early on.\n\nThe main cause of oil toxicity in wildlife is accidental exposure resulting from oil spills. Oil spills occur most commonly near oil-shipping routes, pipelines, wells and refineries. Oil spills have a more drastic impact in the late winter and early spring months, because large populations of overwintering birds gather near shores. The Deepwater Horizon Oil Spill (also known as the BP Oil Spill) was estimated to have killed over 8,000 birds, sea turtles and marine mammals from April to September in 2010.\n\nOil toxicity can affect animals both externally and internally. Animals come into direct contact with the oil, and may ingest, inhale or absorb it. Animals may also become contaminated by eating other contaminated animals.\n\nAny animal can come into direct contact with an oil spill. However, marine species are more likely to be impacted by an oil spill.\n\nOf the many species affected by oil toxicity, birds are usually the most severely affected. Birds that nest near the shoreline are most likely to be affected, including loons (\"Gavia\" spp.), grebes (Family: Podicipedidae), murres (\"Uria\" spp.), pelicans (Family: Pelecanidae), and penguins (Family: Spheniscidae). The species of bird and the type of oil can vary the effects of oil exposure. Birds affected by oil toxicity often die from hypothermia, starvation, exhaustion, or drowning. Birds exposed to oil become more susceptible to other diseases due to a reduced immunologic function.\n\nBirds can come into contact with oil through direct exposure, which leads to ingestion, inhalation, and absorption. Birds coated with oil lose the insulation and waterproofing properties of their feathers, and can also ingest oil during preening. Bird that are coated with oil lose the ability to thermo-regulate, fly, and float on water. Ingestion of oil can result in lung, liver and kidney damage, often leading to death. The oil can also affect the eggs laid by affected females, often resulting in embryonic death or low birth weight. 5-20 microliters of oil can kill embryos if the egg comes into contact. Eggs laid prior to an oil spill can also become damaged if an affected animal sits on the nest.\n\nMammals are affected by oil spills in many of the same ways birds are, including organ damage, immune system suppression, skin irritation, and behavioral changes. Oil toxicity generally affects terrestrial mammals that feed on other affected animals that are directly exposed to oil. This includes scavengers, such as raccoons and skunks. Oil toxicity affects a variety of marine mammals, including sea otters (\"Enhydra lutris\"), whales (Order: Cetacea), dolphins (Suborder: Odontoceti), seals (Clade: Pinnipedia), and manatees (\"Trichechus\" spp.). Sea otters are among the most susceptible of marine mammals, because the oil interrupts their ability to trap air within their fur for insulation.\n\nOther species, such as marine turtles (Superfamily: Chelonioidea), fish, and shellfish can also be adversely affected by oil spills. Sea turtles may become affected when they return to shores to lay eggs. Fish are impacted by the oil that is taken in by their gills and digestive system. Many species of shellfish can survive exposure to oil, but accumulate high levels in containment in their bodies. Oil in water can contaminate algae, plankton, and fish eggs, which in turn contaminate fish that feed on them.\n\nAnimals affected externally by oil toxicity can often be seen or found via the smell. In some light, transparent oils may be difficult to detect visually. Animals can also be internally diagnosed via necropsy by identifying petroleum hydrocarbons in their fat, liver, or kidney tissues For damage assessments, the death of the animal must have occurred after the oil spill.\n\nThe severity of damage directly correlates with the amount of oil spilled and the animal's exposure to oil. However, a small spill at a more sensitive season or environment may have more drastic impacts than a large spill in a less sensitive season or environment. External exposure to oil often leads to destroyed insulating fur or feathers, resulting in death from hypothermia. Contact with oil can also result in blindness, which impairs animals' ability to compete for food or to avoid predators.\n\nThe ingestion of oil can cause a variety of internal problems. These include anemia, reproductive impairment, and damage to the stomach and intestines. These animals can also suffer from dehydration and pneumonia, due to a decreased thermo-regulation.\n\nAnimals affected by oil toxicity should be cleaned and allowed to recover from stress. Animals should be kept in a quiet and warm environment while they recover. Direct contact with oil or oiled wildlife can be hazardous to human health. Only trained professionals should attempt treatment. In the event of a spill in the United States of America, call the National Response Center 800-424-8802. To report oiled or injured wildlife, call the United States Fish and Wildlife Service at 800-440-0858.\n"}
{"id": "2444797", "url": "https://en.wikipedia.org/wiki?curid=2444797", "title": "Rhaetian", "text": "Rhaetian\n\nThe Rhaetian is, in geochronology, the latest age of the Triassic period or in chronostratigraphy the uppermost stage of the Triassic system. It lasted from to million years ago. It was preceded by the Norian and succeeded by the Hettangian (the lowermost stage or earliest age of the Jurassic).\n\nIn this age, Pangaea began to break up, though the Atlantic Ocean was not yet formed.\n\nThe Rhaetian is named after the Rhaetian Alps, a mountain chain stretching over parts of eastern Switzerland, northern Italy and western Austria. The stage was introduced in scientific literature by Austrian geologist Eduard Suess and German paleontologist Albert Oppel in 1856.\n\nThe base of the Rhaetian did not yet have a unanimously agreed upon definition in 2009. In the Tethyan domain, the base of the ammonite biozone of \"Sagenites reticulatus\" is used, in the boreal domain (where this species is not found) the base of the biozone of \"Cochloceras amoenum\" is used instead. The base is also close to the first appearances of conodont species \"Misikella spp.\" and \"Epigondolella mosheri\" and radiolarite species \"Proparvicingula moniliformis\".\n\nThe top of the Rhaetian (the base of the Hettangian stage, the Lower Jurassic series and the Jurassic system) is at the first appearance of ammonite genus \"Psiloceras\".\n\nIn the Tethyan domain, the Rhaetian contains two ammonite biozones. The highest ammonite biozone is that of \"Choristoceras marshi\", the lower one that of \"Rhabdoceras suesii\". The end of this period is marked by the Triassic-Jurassic extinction event .\n\n\n\n"}
{"id": "31982764", "url": "https://en.wikipedia.org/wiki?curid=31982764", "title": "Rhizotron", "text": "Rhizotron\n\nRhizotron (from \"rhízōma\" \"mass of roots\", from \"cause to strike root\") is a laboratory constructed underground in order to study the soil and its interactions with plants and animals. Rhizotrons are typically equipped with a central corridor with viewing windows into the soil profiles on either side. On the outside, separate bays are constructed to enable specific experiments to be carried out by varying the soil composition and the plant and animals contained therein.\n\nRhizotrons are in use at Kew Gardens, at the USDA Northern Research Station at Houghton, Michigan, and at Treborth Botanic Garden, near Bangor, Gwynedd, U.K.\n"}
{"id": "22637112", "url": "https://en.wikipedia.org/wiki?curid=22637112", "title": "Richard Schodde", "text": "Richard Schodde\n\nRichard Schodde, OAM (born 23 September 1936) is an Australian botanist and ornithologist.\n\nSchodde studied at the University of Adelaide where he received a BSc (Hons) in 1960 and a PhD in 1970. During the 1960s he was a botanist with the CSIRO Division of Land Research and Regional Survey in Papua New Guinea. From 1970 to 1998 he was the foundation Curator and Director of the Australian National Wildlife Collection (ANWC) in the CSIRO Division of Wildlife and Ecology, following which he became a Research Fellow there. During this time he led the flora and fauna surveys that helped establish Kakadu National Park and the designation of the wet tropics of north-eastern Queensland as Australia's first World Heritage Site. These surveys resulted in the accession of almost 50,000 specimens to the ANWC, as well as 15,000 samples of frozen tissue for molecular studies. In the 2009 Queen's birthday honours, Schodde was awarded an OAM for his contribution to the natural sciences, particularly ornithology.\n\nSchodde has also been a Corresponding Fellow, and later an Honorary Fellow, of the AOU, Honorary Vice President of the 25th International Ornithological Congress (2010), chair of the Standing Committee on Ornithological Nomenclature of the International Ornithological Committee, and convener of symposia on the origin and evolutionary radiations of Australasian birds at the 1974 and 1990 International Ornithological Congresses.\n\nAs well as numerous scientific papers, books authored, coauthored or edited by Schodde include:\n\n"}
{"id": "4386085", "url": "https://en.wikipedia.org/wiki?curid=4386085", "title": "Roadway air dispersion modeling", "text": "Roadway air dispersion modeling\n\nRoadway air dispersion modeling is the study of air pollutant transport from a roadway or other linear emitter. Computer models are required to conduct this analysis, because of the complex variables involved, including vehicle emissions, vehicle speed, meteorology, and terrain geometry. Line source dispersion has been studied since at least the 1960s, when the regulatory framework in the United States began requiring quantitative analysis of the air pollution consequences of major roadway and airport projects. By the early 1970s this subset of atmospheric dispersion models were being applied to real world cases of highway planning, even including some controversial court cases.\n\nThe basic concept of the roadway air dispersion model is to calculate air pollutant levels in the vicinity of a highway or arterial roadway by considering them as line sources. The model takes into account source characteristics such as traffic volume, vehicle speeds, truck mix, and fleet emission controls; in addition, the roadway geometry, surrounding terrain and local meteorology are addressed. For example, many air quality standards require that certain near worst case meteorological conditions be applied.\n\nThe calculations are sufficiently complex that a computer model is essential to arrive at authoritative results, although workbook type manuals have been developed as screening techniques. In some cases where results must be refereed (such as legal cases), model validation may be needed with field test data in the local setting; this step is not usually warranted, because the best models have been extensively validated over a wide spectrum of input data variables.\n\nThe product of the calculations is usually a set of isopleths or mapped contour lines either in plan view or cross sectional view. Typically these might be stated as concentrations of carbon monoxide, total reactive hydrocarbons, oxides of nitrogen, particulate or benzene. The air quality scientist can run the model successively to study techniques of reducing adverse air pollutant concentrations (for example, by redesigning roadway geometry, altering speed controls or limiting certain types of trucks). The model is frequently utilized in an Environmental Impact Statement involving a major new roadway or land use change which will induce new vehicular traffic.\n\nThe logical building block for this theory was the use of the Gaussian air pollutant dispersion equation for point sources. One of the early point source air pollutant plume dispersion equations was derived by Bosanquet and Pearson in 1936. Their equation did not include the effect of ground reflection of the pollutant plume. Sir Graham Sutton derived a point source air pollutant plume dispersion equation in 1947 which included the assumption of Gaussian distribution for the vertical and crosswind dispersion of the plume and also addressed the effect of ground reflection of the plume. Further advances were made by G. A. Briggs in model refinement and validation and by D.B. Turner for his user-friendly workbook that included screening calculations which do not require a computer.\n\nIn seeing the need to develop a line source model to approach the study of roadway air pollution,\nMichael Hogan and Richard Venti developed a closed form solution to integrating the point source equation in a series of publications.\n\nWhile the ESL mathematical model was completed for a line source by 1970, model refinement resulted in a “strip source”, emulating the horizontal extent of the roadway surface. This theory would be the precursor of area source dispersion models. But their focus was roadway simulation, so they proceeded with the development of a computer model by adding to the team Leda Patmore, a computer programmer in the field of atmospheric physics and satellite trajectory calculations. A working computer model was produced by late 1970; then the model was calibrated with carbon monoxide field measurements targeting from traffic on U.S. Route 101 in Sunnyvale, California.\n\nThe ESL model received endorsement from the U.S. Environmental Protection Agency (EPA) in the form of a major grant to validate the model using actual roadway tests of tracer gas sulfur hexafluoride dispersion. That gas was chosen since it does not occur naturally or in vehicular emissions and provides a unique tracer for such dispersion studies. Part of the Environmental Protection Agency’s motives may have been to bring the model into public domain. After a successful validation through the EPA research, the model was soon put to use in a variety of settings to forecast air pollution levels in the vicinity of roadways. The ESL group applied the model to the U.S. Route 101 bypass project in Cloverdale, California, the extension of Interstate 66 through Arlington, Virginia, the widening of the New Jersey Turnpike through Raritan and East Brunswick, New Jersey, and several transportation projects in Boston for the Boston Transportation Planning Review.\n\nBy the early 1970s at least two other research groups were known to be actively developing some type to roadway air dispersion model: the Environmental Research and Technology group of Lexington, Massachusetts and Caltrans headquarters in Sacramento, California. The Caline model of Caltrans borrowed some of the technology from the ESL Inc. group, since Caltrans funded some of the early model application work in Cloverdale and other locations and was given rights to use parts of their model.\n\nThe resulting solution for an infinite line source is:\n\nformula_1\nwhere:\n\n\"x\" is the distance from the observer to the roadway\n\n\"y\" is the height of the observer\n\n\"u\" is the mean wind speed\n\n\"α\" is the angle of tilt of the line source relative to the reference frame\n\n\"c\" and \"d\" are the standard deviation of horizontal and vertical wind directions (measured in radians) respectively.\n\nThis equation was integrated into a closed form solution using the error function (erf), and variations in geometry can be performed to include the full infinite line, line segment, elevated line, or arc made from segments. In any case one can calculate three-dimensional contours of resulting air pollutant concentrations and use the mathematical model to study alternative roadway designs, various assumptions of worst case meteorology or varying traffic conditions (for example, variations in truck mix, fleet emission controls, or vehicle speed).\n\nThe ESL research group also extended their model by introducing the area source concept of a vertical strip to simulate the mixing zone on the highway produced by vehicle turbulence. This model too was validated in 1971 and showed good correlation with field test data.\n\nThere were several early applications of the model in somewhat dramatic cases. In 1971 the Arlington Coalition on Transportation (ACT) was the plaintiff in an action against the Virginia Highway Commission over the extension of Interstate 66 through Arlington, Virginia, having filed a suit in the federal district court. The ESL model was used to produce calculations of air quality in the vicinity of the proposed highway. ACT won this case after a decision by the U.S. Fourth Circuit Court of Appeals. The court paid special attention to the plaintiff's expert calculations and testimony projecting that air quality levels would violate Federal ambient air quality standards as set forth in the Clean Air Act.\n\nA second contentious case took place in East Brunswick, New Jersey where the New Jersey Turnpike Authority planned a major widening of the Turnpike. Again the roadway air dispersion model was employed to predict levels of air pollution for residences, schools and parks near the Turnpike. After an initial hearing in Superior Court where the ESL model results were set forth, the judge ordered the Turnpike Authority to negotiate with the plaintiff, Concerned Citizens of East Brunswick and develop air quality mitigation for the adverse effects. The Turnpike Authority hired ERT as its expert, and the two research teams negotiated a settlement to this case using the newly created roadway air dispersion models.\n\nThe CALINE3 model is a steady-state Gaussian dispersion model designed to determine air pollution concentrations at receptor locations downwind of highways located in relatively uncomplicated terrain. CALINE3 is incorporated into the more elaborate CAL3QHC and CAL3QHCR models. CALINE3 is in widespread use due to its user friendly nature and promotion in governmental circles, but it falls short of analyzing the complexity of cases addressed by the original Hogan-Venti model. CAL3QHC and CAL3QHCR models are available in the Fortran programming language. They have options to model either particulate matter or carbon monoxide, and include algorithms to simulate queued traffic at signalized intersections .\n\nIn addition, several more recent models have been developed that employ non-steady state Lagrangian puff algorithms. The HYROAD dispersion model has been developed through the National Cooperative Highway Research Program's Project 25-06, incorporating ROADWAY-2 model puff and steady-state plume algorithms (Rao et al., 2002).\n\nThe TRAQSIM model was developed in 2004 as part of a Ph.D dissertation with support by the U.S. Department of Transportation's Volpe National Transportation Systems Center Air Quality Facility. The model incorporates dynamic vehicle behavior with a non-steady state Gaussian puff algorithm. Unlike HYROAD, TRAQSIM combines traffic simulation, second-by-second modal emissions, and Gaussian puff dispersion into a fully integrated system (a true simulation) that models individual vehicles as discrete moving sources. TRAQSIM was developed as a next generation model to be the successor to the current CALINE3 and CAL3QHC regulatory models. The next step in the development of TRAQSIM is to incorporate methods to model the dispersion of particulate matter (PM) and hazardous air pollutants (HAPs).\n\nSeveral models have been developed that handle complex urban meteorology resulting from urban canyons and highway configurations. The earliest such model development (1968-1970) was by the Air Pollution Control Office of the U.S. EPA in conjunction with New York City. The model was successfully applied to the Spadina Expressway in Toronto by Jack Fensterstock of the New York City Department of Air Resources. Other examples include the Turner-Fairbank Highway Research Center's Canyon Plume Box model, now in version 3 (CPB-3), the National Environmental Research Institute of Denmark's Operational Street Pollution Model (OSPM), and the MICRO-CALGRID model, which includes photochemistry, allowing for both primary and secondary species to be modeled. Cornell University's CTAG model, which resolves vehicle-induced turbulence (VIT), road-induced turbulence (RIT), chemical transformation and aerosol dynamics of air pollutants using turbulence reacting flow models. The CTAG model has also been applied to characterize highway-building environments and study effects of vegetation barriers on near-road air pollution.\n\nRecent health literature indicating that residents near major roads face elevated rates of several adverse health outcomes has prompted legal dispute over the responsibility of transportation agencies to use roadway air dispersion models to characterize the impacts of new and expanded roadways, bus terminals, truck stops, and other sources.\n\nRecently, the Sierra Club of Nevada sued the Nevada Department of Transportation and the Federal Highway Administration over its failure to assess the impact of the expansion of U.S. Route 95 in Las Vegas on neighborhood air quality. The Sierra Club asserted that a supplemental Environmental Impact Statement should be issued to address emissions of hazardous air pollutants and particulate matter from new motor vehicle traffic. The plaintiffs asserted that modeling tools were available, including the Environmental Protection Agency's MOBILE6.2 model, the CALINE3 dispersion model, and other relevant models. The defendants won in the U.S. District Court under Judge Philip Pro, who ruled that the transportation agencies had acted in a manner that was not \"arbitrary and capricious,\" despite the agencies' technical arguments regarding the lack of available modeling tools being contradicted by a number of peer-reviewed studies published in scientific journals (e.g. Korenstein and Piazza, Journal of Environmental Health, 2002). On appeal to the U.S. Ninth Circuit, the Appeals Court stayed new construction on the highway pending the court's final decision. The Sierra Club and the defendants settled out of court, setting up a research program on the air quality impacts of U.S. Route 95 on nearby schools.\n\nA number of other high-profile cases have prompted environmental groups to call for dispersion modeling to be used to assess the air quality impacts of new transportation projects on nearby communities, but to date state transportation agencies and the Federal Highways Administration has claimed that no tools are available, despite models and guidance available through EPA's Support Center for Regulatory Air Models (SCRAM).\n\nAmong the more contentious of cases the Detroit Intermodal Freight Terminal and Detroit River International Crossing (Michigan, USA), and the expansion of Interstate 70 East in Denver (Colorado, USA).\n\nIn all of these cases, community-based organizations have asserted that modeling tools are available, but transportation planning agencies have asserted that too much uncertainty exists in all of the steps. A major concern for community-based organizations has been transportation agencies' unwillingness to define the level of uncertainty that they are willing to tolerate in air quality analyses, how that compares to the Environmental Protection Agency's guideline on air quality models, which addresses uncertainty and accuracy in model use.\n\n\n"}
{"id": "407302", "url": "https://en.wikipedia.org/wiki?curid=407302", "title": "Soft water", "text": "Soft water\n\nSoft water is surface water that contains low concentrations of ions and in particular is low in ions of calcium and magnesium. Soft water naturally occurs where rainfall and the drainage basin of rivers are formed of hard, impervious and calcium-poor rocks. Examples in the UK include Snowdonia in Wales and the Western Highlands in Scotland.\n\nThe term may also be used to describe water that has been produced by a water softening process although such water is more correctly termed \"softened water\". In these cases the water may also contain elevated levels of sodium and/or bicarbonate ions .\n\nBecause soft water has few calcium ions, there is no inhibition of the lathering action of soaps and no soap scum is formed in normal washing. Similarly, soft water produces no calcium deposits in water heating systems. Water that is not soft is referred to as hard water.\n\nIn the UK, water is regarded as soft if the hardness is less than 50 mg/l of calcium carbonate. Water containing more than 50 mg/l of calcium carbonate is termed hard water. In the United States soft water is classified as having less than 60 mg/l of calcium carbonate.\n\nThe hardness of water is determined by the concentration of multivalent cations in the water. Common cations found in hard water include Ca and Mg. These ions enter a water supply by leaching from minerals within an aquifer. Common calcium-containing minerals are calcite and gypsum. A common magnesium mineral is dolomite (which also contains calcium). Rainwater and distilled water are soft, because they contain few ions.\n\nAreas with complex geology can produce varying degrees of hardness of water over short distances.\n\nCalcium and magnesium ions are required for normal metabolism in many organisms including mammals. The lack of these ions in soft water have given rise to concerns about the possible health impacts of drinking soft water, including sudden cardiac death.\n"}
{"id": "36376157", "url": "https://en.wikipedia.org/wiki?curid=36376157", "title": "Solar power in Myanmar", "text": "Solar power in Myanmar\n\nSolar power in Myanmar has the potential to generate 51,973.8 TWh/year, with an average of over 5 sun hours per day.\n\nIn rural areas, photovoltaics are used for charging batteries and pumping water. 70% of the Burmese population of 50 million live in rural areas.\n\n"}
{"id": "1815428", "url": "https://en.wikipedia.org/wiki?curid=1815428", "title": "Solifluction", "text": "Solifluction\n\nSolifluction is a collective name for gradual mass wasting slope processes related to freeze-thaw activity. This is the standard modern meaning of solifluction, which differs from the original meaning given to it by Johan Gunnar Andersson in 1906.\n\nIn the original sense it meant the movement of waste saturated in water found in periglacial regions. However it was later discovered that various slow waste movements in periglacial regions did not required saturation in water, but were rather associated to freeze-thaw processes. The term solifluction was appropriated to refer to these slow processes, and therefore excludes rapid periglacial movements. In slow periglacial solifluction there are not clear gliding planes, and therefore skinflows and active layer detachments are not included in the concept. On the other hand, movement of waste saturated in water can occur in any humid climate, and therefore this kind of solifluction is not restricted to cold climates.\n\nSlow periglacial solifluction is classified into four types:\nSlow solifluction acts much slower than some geochemical fluxes or than other erosion processes. The relatively low rates at which solifluction operates contrast with its occurrence over wide mountain areas and periglaciated lowlands. Since solifluction is associated with humidity and cold climates it can be used to infer past climates.\n\nDeposits of slow periglacial solifluction compromise poorly stratified diamicton and diamicton where stratification is wholly lacking. When stratification can be seen it is often distinguished by a buried organic soil. Some other solifluction deposits that have a more defined stratification consist of alternating layers of diamicton and open-work beds, these last representing buried stone-banked lobes and sheets. A common feature in solifluction deposits is the orientation of clasts parallel to the slope.\n\nIt was suggested that solifluction might be active on Mars, even relatively recently (within the last few million years), as observed martian lobates bear many similarities with solifluction lobes known from Svalbard.\n\n\n"}
{"id": "275128", "url": "https://en.wikipedia.org/wiki?curid=275128", "title": "Tektite", "text": "Tektite\n\nTektites (from Greek τηκτός \"tēktós\", \"molten\") are gravel-sized bodies composed of black, green, brown, or gray natural glass formed from terrestrial debris ejected during meteorite impacts. The term was coined by Austrian geologist Franz Eduard Suess (1867–1941), son of Eduard Suess. They generally range in size from millimeters to centimeters. Millimeter-scale tektites are known as microtektites.\n\nTektites are characterized by:\n\nAlthough tektites are superficially similar to some terrestrial volcanic glasses (obsidians), they have unusual distinctive physical characteristics that distinguish them from such glasses. First, they are completely glassy and lack any microlites or phenocrysts, unlike terrestrial volcanic glasses. Second, although high in silica (>65 wt%), the bulk chemical and isotopic composition of tektites is closer to those of shales and similar sedimentary rocks and quite different from the bulk chemical and isotopic composition of terrestrial volcanic glasses. Third, tektites contain virtually no water (<0.02 wt%), unlike terrestrial volcanic glasses. Fourth, the flow-banding within tektites often contains particles and bands of lechatelierite, which are not found in terrestrial volcanic glasses. Finally, a few tektites contain partly melted inclusions of shocked and unshocked mineral grains, i.e. quartz, apatite, and zircon, as well as coesite.\n\nThe difference in water content can be used to distinguish tektites from terrestrial volcanic glasses. When heated to their melting point, terrestrial volcanic glasses turn into a foamy glass because of their content of water and other volatiles. Unlike terrestrial volcanic glass, a tektite produces only a few bubbles at most when heated to its melting point, because of its much lower water and other volatiles content.\n\nOn the basis of morphology and physical characteristics, tektites have traditionally been divided into four groups. Those found on land have traditionally been subdivided into three groups: (1) splash-form (normal) tektites, (2) aerodynamically shaped tektites, and (3) Muong Nong-type (layered) tektites. Splash-form and aerodynamically shaped tektites are only differentiated on the basis of their appearance and some of their physical characteristics. Splash-form tektites are centimeter-sized tektites that are shaped like spheres, ellipsoids, teardrops, dumbbells, and other forms characteristic of isolated molten bodies. They are regarded as having formed from the solidification of rotating liquids, and not atmospheric ablation. Aerodynamically shaped tektites, which are mainly part of the Australasian strewn field, are splash-form tektites (buttons) which display a secondary ring or flange. The secondary ring or flange is argued as having been produced during the high-speed re-entry and ablation of a solidified splash-form tektite into the atmosphere. Muong Nong tektites are typically larger, greater than 10 cm in size and 24 kg in weight, irregular, and layered tektites. They have a chunky, blocky appearance, exhibit a layered structure with abundant vesicles, and contain mineral inclusions, such as zircon, baddeleyite, chromite, rutile, corundum, cristobalite, and coesite.\n\nMicrotektites, the fourth group of tektites, are less than 1 mm in size. They exhibit a variety of shapes ranging from spherical to dumbbell, disc, oval, and teardrop. Their colors range from colorless and transparent to yellowish and pale brown. They frequently contain bubbles and lechatelierite inclusions. Microtektites are typically found in deep-sea sediments that are of the same ages as those of the four known strewn fields. Microtektites of the Australasian strewn field have also been found on land within Chinese loess deposits, and in sediment-filled joints and decimeter-sized weathering pits developed within glacially eroded granite outcrops of the Victoria Land Transantarctic Mountains, Antarctica.\n\nSince 1963, the majority of known tektites have been known to occur only within four geographically extensive strewn fields: the Australasian, Central European, Ivory Coast, and North American. As summarized by Koeberl, the tektites within each strewn field are related to each other with respect to the criteria of petrological, physical, and chemical properties, as well as their age. In addition, three of the four strewn fields have been clearly linked with impact craters using those same criteria. Recognized types of tektites, grouped according to their known strewn fields, their associated craters, and ages are:\n\nComparing the number of known impact craters versus the number of known strewn fields, Artemieva considered essential factors such as the crater must exceed a certain diameter to produce distal ejecta, and that the event must be relatively recent. Limiting to diameters 10 km or more and younger than 50 Ma, the study yielded a list of 13 candidate craters, of which the youngest eight are given below, \nPreliminary papers in the late 1970s suggested either Zhamanshin or Elgygytgyn as the source of the Australasian strewnfield.\n\nPovenmire and others have proposed the existence of an additional tektite strewn field, the Central American strewn field. Evidence for this reported tektite strewn field consists of tektites recovered from western Belize in the area of the villages of Bullet Tree Falls, Santa Familia, and Billy White. This area lies about 55 km east-southeast of Tikal, where 13 tektites, two of which were dated as being 820,000 years old, of unknown origin were found. A limited amount of evidence is interpreted as indicating that the proposed Central American strewn field likely covers Belize, Honduras, Guatemala, Nicaragua, and possibly parts of southern Mexico. The hypothesized Pantasma Impact Crater in northern Nicaragua might be the source of these tektites.\n\nThe ages of tektites from the four strewnfields have been determined using radiometric dating methods. The age of moldavites, a type of tektite found in the Czech Republic, was determined to be 14 million years, which agrees well with the age determined for the Nördlinger Ries crater (a few hundred kilometers away in Germany) by radiometric dating of Suevite (an impact breccia found at the crater). Similar agreements exist between tektites from the North American strewnfield and the Chesapeake Bay impact crater and between tektites from the Ivory Coast strewnfield and the Lake Bosumtwi Crater. Ages of tektites have usually been determined by either the K-Ar method, fission-track dating, the Ar-Ar technique, or combination of these techniques.\n\nThe overwhelming consensus of Earth and planetary scientists is that tektites consist of terrestrial debris that was ejected during the formation of an impact crater. During the extreme conditions created by an hypervelocity meteorite impact, near-surface terrestrial sediments and rocks were either melted, vaporized, or some combination of these, and ejected from an impact crater. After ejection from the impact crater, the material formed millimeter- to centimeter-sized bodies of molten material, which as they re-entered the atmosphere, rapidly cooled to form tektites that fell to Earth to create a layer of distal ejecta hundreds or thousands of kilometers away from the impact site.\n\nThe terrestrial source for tektites is supported by well-documented evidence. The chemical and isotopic composition of tektites indicates that they are derived from the melting of silica-rich crustal and sedimentary rocks, which are not found on the Moon. In addition, some tektites contain relict mineral inclusions (quartz, zircon, rutile, chromite, and monazite) that are characteristic of terrestrial sediments and crustal and sedimentary source rocks. Also, three of the four tektite strewnfields have been linked by their age and chemical and isotopic composition to known impact craters. A number of different geochemical studies of tektites from the Australasian strewnfield concluded that these tektites consist of melted Jurassic sediments or sedimentary rocks that were weathered and deposited about 167 My ago. Their geochemistry suggests that the source of Australasian tektites is a single sedimentary formation with a narrow range of stratigraphic ages close to 170 Mya more or less. This effectively refutes multiple impact hypotheses.\n\nAlthough the formation of and widespread distribution of tektites is widely accepted to require the intense (superheated) melting of near-surface sediments and rocks at the impact site and the following high-velocity ejection of this material from the impact crater, the exact processes involved remain poorly understood. One possible mechanism for the formation of tektites is by the jetting of highly shocked and superheated melt during the initial contact/compression stage of impact crater formation. Alternatively, various mechanisms involving the dispersal of shock-melted material by an expanding vapor plume, which is created by a hypervelocity impact, have been used to explain the formation of tektites. Any mechanism by which tektites are created must explain chemical data that suggest that parent material from which tektites were created came from near-surface rocks and sediments at an impact site. In addition, the scarcity of known strewn fields relative to the number of identified impact craters indicate that very special and rarely met circumstances are required for tektites to be created by a meteorite impact.\n\nThough the meteorite impact theory of tektite formation is widely accepted, there has been considerable controversy about their origin in the past. As early as 1897, the Dutch geologist Rogier Diederik Marius Verbeek (1845–1926) suggested an extraterrestrial origin for tektites: he proposed that they fell to Earth from the Moon. Verbeek's proposal of an extraterrestrial origin for tektites was soon seconded by the German geologist Franz E. Suess. Subsequently it was argued that tektites consist of material that was ejected from the Moon by major hydrogen-driven lunar volcanic eruptions and then drifted through space to later fall to Earth as tektites. The major proponents of the lunar origin of tektites include NASA scientist John A. O'Keefe, NASA aerodynamicist Dean R. Chapman, meteorite and tektite collector Darryl Futrell, and long-time tektite researcher Hal Povenmire. From the 1950s to the 1990s, O'Keefe argued for the lunar origin of tektites based upon their chemical, i.e. rare-earth, isotopic, and bulk, composition and physical properties. Chapman used complex orbital computer models and extensive wind tunnel tests to argue that the so-called Australasian tektites originated from the Rosse ejecta ray of the large crater Tycho on the Moon's near side. O'Keefe, Povenmire, and Futrell claimed on the basis of behavior of glass melts that the homogenization, which is called \"fining\", of silica melts that characterize tektites could not be explained by the terrestrial-impact theory. They also argued that the terrestrial-impact theory could not explain the vesicules and extremely low water and other volatile content of tektites. Futrell also reported the presence of microscopic internal features within tektites, which argued for a volcanic origin.\n\nAt one time, theories advocating the lunar origin of tektites enjoyed considerable support as part of a spirited controversy about the origin of tektites that occurred during the 1960s. Starting with the publication of research concerning lunar samples returned from the Moon, the consensus of Earth and planetary scientists shifted in favor of theories advocating a terrestrial impact versus lunar volcanic origin. For example, one problem with the lunar origin theory is that the arguments for it that are based upon the behavior of glass melts use data from pressures and temperatures that are vastly uncharacteristic of and unrelated to the extreme conditions of hypervelocity impacts. In addition, various studies have shown that hypervelocity impacts are likely quite capable of producing low volatile melts with extremely low water content. The consensus of Earth and planetary scientists regards the chemical, i.e. rare-earth, isotopic, and bulk composition evidence as decisively demonstrating that tektites are derived from terrestrial crustal rock, i.e. sedimentary rocks, that are unlike any known lunar crust.\n\nIn 1960, another nonterrestrial hypothesis for the origin of tektites was proposed by the Russian-born mathematician Matest M. Agrest, who suggested that tektites were formed as a result of nuclear blasts produced by extraterrestrial beings. He used this as an argument to support his paleocontact hypothesis.\n\n\n\n"}
{"id": "2795914", "url": "https://en.wikipedia.org/wiki?curid=2795914", "title": "Valanginian", "text": "Valanginian\n\nIn the geologic timescale, the Valanginian is an age or stage of the Early or Lower Cretaceous. It spans between 139.8 ± 3.0 Ma and 132.9 ± 2.0 Ma (million years ago). The Valanginian stage succeeds the Berriasian stage of the Lower Cretaceous and precedes the Hauterivian stage of the Lower Cretaceous.\n\nThe Valanginian was first described and named by Édouard Desor in 1853. It is named after Valangin, a small town north of Neuchâtel in the Jura Mountains of Switzerland.\n\nThe base of the Valanginian is at the first appearance of calpionellid species \"Calpionellites darderi\" in the stratigraphic column. A global reference section (a GSSP) had in 2009 not yet been appointed.\n\nThe top of the Valanginian (the base of the Hauterivian) is at the first appearance of the ammonite genus \"Acanthodiscus\".\n\nThe Valanginian is often subdivided in Lower and Upper substages. The Upper substage begins at the first appearance of ammonite species \"Saynoceras verrucosum\" and the major marine transgression Va3.\n\nIn the Tethys domain, the Valanginian stage contains five ammonite biozones:\n\n\n\n"}
{"id": "274441", "url": "https://en.wikipedia.org/wiki?curid=274441", "title": "Willie Aames", "text": "Willie Aames\n\nWillie Aames (born Albert William Upton on July 15, 1960) is an American actor, film and television director, television producer, and screenwriter. He is best known for playing Tommy Bradford, one of Tom Bradford's (played by Dick Van Patten) sons, on the 1970s television series \"Eight Is Enough\", Buddy Lembeck on the 1980s series \"Charles in Charge\" and the title character in the direct-to-video series, \"Bibleman\" (1995–2003).\n\nAames was born in Newport Beach, California, in 1960. He attended Edison High School in Huntington Beach, California, and was in both the choir and the Madrigal Ensemble.\n\nAames began acting in the late 1960s as a child, appearing in shows such as \"Gunsmoke\", \"The Wonderful World of Disney\", \"Adam-12\", and \"The Courtship of Eddie's Father\". In 1971, he originated the role of Leonard Unger, the son of Felix Unger (Tony Randall), on the ABC-TV series \"The Odd Couple\", a part that was later played by Leif Garrett. The following year, he voiced the character of Jamie Boyle in the animated series \"Wait Till Your Father Gets Home\".\n\nHe guest-starred on various television series, including \"The Waltons\". In 1974, he portrayed a 12-year-old Benjamin Franklin in the miniseries \"Benjamin Franklin\". The next year, he co-starred in the series \"Swiss Family Robinson\".\n\nIn 1977, he landed the role of Tommy Bradford in the comedy-drama \"Eight Is Enough\". During this period, he played in a band called \"Willie Aames & Paradise,\" in which he was lead singer/guitarist. Formed while Aames was in junior high school, the group eventually landed a recording contract with CBS Custom Label. During this time, Aames appeared in his first movie role, \"Scavenger Hunt\". After the series ended in 1981, Aames appeared in more film roles, including \"Zapped!\" opposite Scott Baio and \"Paradise\" with Phoebe Cates.\n\nBefore portraying the role of Buddy Lembeck in \"Charles in Charge\" in 1984, Aames played the character of Robbie Hamlin on the ABC soap opera \"The Edge of Night\". From 1983 to 1985, he was the voice of Hank on the cartoon \"Dungeons & Dragons\". After the end of \"Charles in Charge\" in 1990, Aames hosted the game show \"The Krypton Factor\".\n\nAames began the role of Miles Peterson / Bibleman in the direct-to-video Christian superhero series from 1995 to 2003 before leaving to spend more time with his family. He was replaced by Robert T. Schlipp.\n\nAames has been married three times. Aames married Vicki Weatherman in 1979, having one child, Christopher. He married Maylo McCaslin in 1986, having one child, Harleigh Jean. Aames is currently married to Winnie Hung.\n\nFor some years, Aames had been fighting alcohol addiction. In 2008, he faced ongoing drug abuse and private bankruptcy and worked construction jobs after investing in a failed TV show. After getting clean, Aames found work as a cruise ship director.\n"}
