{"id": "1834711", "url": "https://en.wikipedia.org/wiki?curid=1834711", "title": "Basajaun", "text": "Basajaun\n\nIn Basque mythology, Basajaun (\"Lord of the Woods\", plural: basajaunak) is a huge, hairy hominid dwelling in the woods. They were thought to build megaliths, protect flocks of livestock, and teach skills such as agriculture and ironworking to humans.\n\n"}
{"id": "4757", "url": "https://en.wikipedia.org/wiki?curid=4757", "title": "Bestiary", "text": "Bestiary\n\nA bestiary, or bestiarum vocabulum, is a compendium of beasts. Originating in the ancient world, bestiaries were made popular in the Middle Ages in illustrated volumes that described various animals and even rocks. The natural history and illustration of each beast was usually accompanied by a moral lesson. This reflected the belief that the world itself was the Word of God, and that every living thing had its own special meaning. For example, the pelican, which was believed to tear open its breast to bring its young to life with its own blood, was a living representation of Jesus. The bestiary, then, is also a reference to the symbolic language of animals in Western Christian art and literature.\n\nThe earliest bestiary in the form in which it was later popularized was an anonymous 2nd century Greek volume called the \"Physiologus\", which itself summarized ancient knowledge and wisdom about animals in the writings of classical authors such as Aristotle's \"Historia Animalium\" and various works by Herodotus, Pliny the Elder, Solinus, Aelian and other naturalists.\n\nFollowing the \"Physiologus\", Saint Isidore of Seville (Book XII of the \"Etymologiae\") and Saint Ambrose expanded the religious message with reference to passages from the Bible and the Septuagint. They and other authors freely expanded or modified pre-existing models, constantly refining the moral content without interest or access to much more detail regarding the factual content. Nevertheless, the often fanciful accounts of these beasts were widely read and generally believed to be true. A few observations found in bestiaries, such as the migration of birds, were discounted by the natural philosophers of later centuries, only to be rediscovered in the modern scientific era.\n\nMedieval bestiaries are remarkably similar in sequence of the animals of which they treat. Bestiaries were particularly popular in England and France around the 12th century and were mainly compilations of earlier texts. The Aberdeen Bestiary is one of the best known of over 50 manuscript bestiaries surviving today.\n\nBestiaries influenced early heraldry in the Middle Ages, giving ideas for charges and also for the artistic form. Bestiaries continue to give inspiration to coats of arms created in our time.\n\nTwo illuminated Psalters, the Queen Mary Psalter (British Library Ms. Royal 2B, vii) and the Isabella Psalter (State Library, Munich), contain full Bestiary cycles. The bestiary in the Queen Mary Psalter is found in the \"marginal\" decorations that occupy about the bottom quarter of the page, and are unusually extensive and coherent in this work. In fact the bestiary has been expanded beyond the source in the Norman bestiary of Guillaume le Clerc to ninety animals. Some are placed in the text to make correspondences with the psalm they are illustrating.\n\nThe Italian artist Leonardo da Vinci also made his own bestiary.\n\nA \"volucrary\" is a similar collection of the symbols of birds that is sometimes found in conjunction with bestiaries. The most widely known volucrary in the Renaissance was Johannes de Cuba's \"Gart der Gesundheit\" which describes 122 birds and which was printed in 1485.\n\nMedieval bestiaries often contained detailed descriptions and illustrations of species native to Western Europe, exotic animals and what in modern times are considered to be imaginary animals. Descriptions of the animals included the physical characteristics associated with the creature, although these were often physiologically incorrect, along with the Christian morals that the animal represented. The description was then normally followed with an artistic illustration of the animal as described in the bestiary.\n\nBestiaries were organized in different ways based upon the text. The descriptions could be organized by animal groupings, such as terrestrial and marine creatures, or presented in an alphabetical manner. However, the texts gave no distinction between existing and imaginary animals. Descriptions of creatures such as dragons, unicorns, basilisk, griffin and caladrius were common in such works and found intermingled amongst accounts of bears, boars, deer, lions, and elephants.\n\nThis lack of separation has often been associated with the assumption that people during this time believed in what the modern period classifies as nonexistent or \"imaginary creatures\". However, this assumption is currently under debate, with various explanations being offered.\n\nSome scholars, such as Pamela Gravestock, have written on the theory that medieval people did not actually think such creatures existed but instead focused on the belief in the importance of the Christian morals these creatures represented, and that the importance of the moral did not change regardless if the animal existed or not.\n\nThe contents of medieval bestiaries were often obtained and created from combining older textual sources and accounts of animals, such as the \"Physiologus\", with newer observations and writings. In this way, the content of such written works was constantly added to and built upon.\n\nIn modern times, artists such as Henri de Toulouse-Lautrec and Saul Steinberg have produced their own bestiaries. Jorge Luis Borges wrote a contemporary bestiary of sorts, the \"Book of Imaginary Beings\", which collects imaginary beasts from bestiaries and fiction. Nicholas Christopher wrote a literary novel called \"The Bestiary\" (Dial, 2007) that describes a lonely young man's efforts to track down the world's most complete bestiary. John Henry Fleming's \"Fearsome Creatures of Florida\" (Pocol Press, 2009) borrows from the medieval bestiary tradition to impart moral lessons about the environment. Caspar Henderson's The Book of Barely Imagined Beings (Granta 2012, Chicago University Press 2013), subtitled \"A 21st Century Bestiary,\" explores how humans imagine animals in a time of rapid environmental change. In July 2014, Jonathan Scott wrote The Blessed Book of Beasts, Eastern Christian Publications, featuring 101 animals from the various translations of the Bible, in keeping with the tradition of the bestiary found in the writings of the Saints, including Saint John Chrysostom.\n\n\n"}
{"id": "4931538", "url": "https://en.wikipedia.org/wiki?curid=4931538", "title": "Brian's Winter", "text": "Brian's Winter\n\nBrian's Winter also known as Hatchet: Winter is a 1996 young adult novel by Gary Paulsen. It is the third novel in the \"Hatchet\" series, but second in terms of chronology as an alternate ending sequel to \"Hatchet\".\n\nIt was also released as \"Hatchet: Winter\" by Pan Macmillan on February 9, 1996.\n\nAt the end of \"Hatchet\", thirteen-year-old Brian Robeson, who has been trapped in the Canadian wilderness after a plane accident, decides to dive for a \"survival pack\" from the submerged aircraft. He almost drowns trying to tear the plane open. He recovers, among other things, an emergency transmitter. Within hours, a pilot receives the beacon and rescues him. The book begins with a foreword that Brian, who learned wilderness survival through trial and error, probably would not have survived the upcoming harsh winter on his own.\n\nPaulsen says that many readers wrote to him, complaining about the deus ex machina ending. In response, Paulsen wrote \"Brian's Winter\", which explores what would have happened if Brian had not activated the transmitter.\n\nThe story deals with Brian, still stranded at the L-shaped lake during the fall and winter, constructing a winter shelter, building snow shoes, being confronted by a bear, befriending and naming a skunk and learning how to make a bow more powerful. Eventually, Brian meets a family of Cree trappers, the Smallhorns, who help him return home.\n\n\"Brian's Winter\" is followed chronologically by the two sequels, \"Brian's Return\" and \"Brian's Hunt\" as they recognize the book as a series canon. \"The River\" does not and includes no mention that the events of \"Brian's Winter\" ever took place as Brian tells Derek Holtzer that he only spent fifty-four days in the wilderness. This is because \"The River\" was published in 1991, five years before the release of \"Brian's Winter\".\n"}
{"id": "3306369", "url": "https://en.wikipedia.org/wiki?curid=3306369", "title": "Buddhist atomism", "text": "Buddhist atomism\n\nBuddhist atomism is a school of atomistic Buddhist philosophy that flourished on the Indian subcontinent during two major periods . During the first phase, which began to develop prior to the 6th century BCE, Buddhist atomism had a very qualitative, Aristotelian-style atomic theory. This form of atomism identifies four kinds of atoms, corresponding to the standard elements. Each of these elements has a specific property, such as solidity or motion, and performs a specific function in mixtures, such as providing support or causing growth. Like the Hindus and Jains, the Buddhists were able to integrate a theory of atomism with their logical presuppositions. \n\nAccording to Noa Ronkin, this kind of atomism was developed in the Sarvastivada and Sautrantika schools for whom material reality can be: reduced to discrete momentary atoms, namely, the four primary elements. These momentary atoms, through their spatial arrangement and by their concatenation with prior and posterior atoms of the same type, create the illusion of persisting things as they appear in our everyday experience. Atomic reality is thus understood first and foremost as change, though not in the sense of a thing x transforming into y. That is, change itself is the very nature of atomic reality rather than its being made of enduring substances the qualities of which undergo change. Atoms that appear to endure are, in fact, a series of momentary events that ascend and fall in rapid succession and in accordance with causal relations. Unlike the atoms of the Vaifesika, the atoms of the Sarvastivada-Vaibhasika and the Sautrantika are not permanent: they come into being and cease from one moment to the next going through a process of birth, continuance, decay and destruction. Yet the material compounds that consist of these atoms are real, if only in the minimal, phenomenological sense.The second phase of Buddhist atomism, which flourished in the 7th century CE, was very different from the first. Indian Buddhist philosophers, including Dharmakirti and Dignāga, considered atoms to be point-sized, durationless, and made of energy. In discussing Buddhist atomism, Stcherbatsky writes:\n\n\n"}
{"id": "5220401", "url": "https://en.wikipedia.org/wiki?curid=5220401", "title": "Cloud height", "text": "Cloud height\n\nThe cloud height, more commonly known as cloud thickness or depth, is the distance between the cloud base and the cloud top. It is traditionally expressed either in metres or as a pressure difference in hectopascal (hPa, equivalent to millibar). Sometimes, the expression \"cloud height\" is used instead of \"cloud base\", in which case the context has to clarify whether the intent is to designate the height of the base of the cloud or the size of it.\n\n\"Cloud height\" is not measured directly but is derived from separate measurements of cloud base and cloud top altitudes.\n\nCloud height is often related to the intensity of precipitation generated by a cloud: deeper clouds tend to produce more intense rainfall. For instance, cumulonimbus clouds can develop vertically through a substantial part of the troposphere and often result in thunderstorms with lightning and heavy showers. By contrast, very thin clouds (such as cirrus clouds) do not generate any precipitation at the surface of the Earth.\n\nFor a synthetic discussion of the impact of clouds on the climate system, see the IPCC Third Assessment Report, in particular chapter 7.2.\n\n"}
{"id": "155097", "url": "https://en.wikipedia.org/wiki?curid=155097", "title": "Cocos Island", "text": "Cocos Island\n\nCocos Island () is an island designated as a National Park off the shore of Costa Rica, that does not allow inhabitants other than Costa Rican Park Rangers. It constitutes the 11th of the 13 districts of Puntarenas Canton of the province of Puntarenas. It is located in the Pacific Ocean, approximately from the Pacific shore of Costa Rica. With an area of approximately , about and a perimeter of around , this island is more or less rectangular in shape. It is the southernmost point on the North American continent if outer islands are included.\n\nSurrounded by deep waters with counter-currents, Cocos Island is admired by scuba divers for its populations of hammerhead sharks, rays, dolphins and other large marine species. The extremely wet climate and oceanic character give Cocos an ecological character that is not shared with either the Galápagos Archipelago or any of the other islands (for example, Malpelo, Gorgona or Coiba) in this region of the world.\n\nCocos Island was declared a Costa Rican National Park by means of Executive Decree in 1978. Cocos Island National Park was designated a World Heritage Site by UNESCO in 1997. In 2002, the World Heritage Site designation was extended to include an expanded marine zone of . In addition, it is included in the list of \"Wetlands of International Importance\".\n\nIn 2009 Cocos Island was short-listed as a candidate to be declared one of the New7Wonders of Nature of the world by the New7Wonders of the World Foundation, and ranked second in the islands category.\n\nThanks to the breathtaking marine life in its waters (see Fauna section below), Cocos Island was named one of the best 10 scuba diving spots in the world by PADI (Professional Association of Diving Instructors) and a \"must do\" according to diving experts. For many, the main attractions are the large pelagic fish species, which are very abundant in this unique meeting point between deep and shallow waters. The largest schools of hammerhead sharks in the World are consistently reported there. Encounters with dozens if not hundreds of these and other large animals are nearly certain in every dive. Smaller and colorful species are also abundant in one of the most extensive and rich reefs of the south eastern Pacific. The famous oceanographer Jacques Cousteau visited the island several times and in 1994 called it \"the most beautiful island in the world\". These numerous accolades highlight the urgent need to protect Cocos Island and surrounding waters from illegal large-scale fishing, poaching and other threats.\n\nThe only persons allowed to live on Cocos Island are Costa Rican Park Rangers, who have established two encampments, including one at English Bay. Tourists and ship crew members are allowed ashore only with permission of island rangers, and are not permitted to camp, stay overnight or collect any flora, fauna or minerals from the island. Occasional amateur radio DXpeditions are allowed to visit.\n\nThis island is popular in pirate lore as well. It is said that over 300 expeditions have gone in search of treasure such as the hoard of Benito Bonito, the Treasure of Lima, and many others. Some incidents of small caches have been discovered, leading many to believe the stories of vast pirate treasures to be valid.\n\nTreasure hunting is strictly prohibited by the Costa Rican government. Permits are not being issued.\n\nCocos Island is an oceanic island of both volcanic and tectonic origin. It is the only emergent island of the Cocos Plate, one of the minor tectonic plates. Potassium-argon dating established the age of the oldest rocks between 1.91 and 2.44 million years (Late Pliocene) and it is composed primarily of basalt, which is formed by cooling lava.\n\nThe landscape is mountainous and irregular and the summit is Cerro Iglesias at . In spite of its mountainous character, there are flatter areas between 200–260 m in elevation in the central part of the island, which are said to be a transitional stage of the geomorphological cycle of V-shaped valleys. With four bays, three of them in the north side (Wafer, Chatham and Weston), Cocos Island has a number of short rivers and streams that drain the abundant rainfall into them. Due to large, 300-foot cliffs that ring much of the island, the easiest point of entry is at Chatham Bay. The largest rivers are the Genio and the Pittier, which drain their water into Wafer Bay. The mountainous landscape and the tropical climate combine to create over 200 waterfalls throughout the island. The island’s soils are classified as entisols which are highly acidic and could be easily eroded by the island’s high rainfall on the steep slopes, were it not for the dense forest coverage.\n\nThe climate of the island is mostly determined by the latitudinal movement of the Intertropical Convergence Zone which creates cloudiness and precipitation that is constant throughout the year. This makes the climate in the island humid and tropical with an average annual temperature of and an average annual rainfall of over . Rainfall is high throughout the year, although lower from January through March and slightly lower during late September and October. Numerous oceanic currents from the central Pacific Ocean that converge on the island also have an important influence.\n\nCocos Island is home to dense tropical moist forests. It is the only oceanic island in the eastern Pacific region with such rain forests and their characteristic types of flora and fauna. The cloud forests at higher elevations are also unique in the eastern Pacific. The island was never linked to a continent, so the flora and fauna arrived via long distance dispersal from the Americas. The island has therefore a high proportion of endemic species.\n\nThe island has 235 known species of flowering plants, of which 70, or nearly 30%, are endemic. A good comprehensive study on the flora of the island is provided in the journal \"Proceedings of the California Academy of Sciences\". Also, 74 species of ferns and fern allies (lycopodiophytes and pteridophytes, see), and 128 species of mosses and liverworts (bryophytes, see), 90 species of fungi and 41 species of slimemolds have been reported. Nevertheless, more exhaustive investigations are expected to reveal many more species.\n\nThe island has three main plant communities. The coastal forests extend from the seacoast up to 50 meters elevation. Purple coral tree (\"Erythrina fusca\"), coconut palm (\"Cocos nucifera\"), and pond-apple (\"Annona glabra\") are the predominant trees, with an understory of ferns, shrubs of the Rubiaceae and Solanaceae families, sedges and grasses, and herbaceous plants of the Leguminosae and Malvaceae families.\n\nThe inland forests extend from 50 to 500 meters elevation. \"Palo de hierro\" or huriki (\"Sacoglottis holdridgei\"), \"avocado\" (\"Ocotea insularis\") and the endemic \"Cecropia pittieri\" are the most common canopy trees. The trees are festooned at all levels with epiphytic plants, including orchids, ferns, bromeliads and mosses. The understory includes sedges such as \"Hypolitrum amplum\" and various species of ferns and tree ferns including \"Cyathea armata\" and \"Danaea media\". The endemic palm \"Rooseveltia frankliniana\" is also common.\n\nCloud forests are found at the highest elevations, over 500 meters. \"Melastoma\" spp. is predominant.\n\nThe general vegetation of Cocos Island has greatly changed since the island was first named and described by Europeans. Captain Wafer, who visited the island in 1685 and whose name was given to the landing place, describes extensive coconut groves extending inland into the interior of the island. Thor Heyerdahl posited that it was very unlikely that these groves developed naturally, and that pre-European man must once have cleared considerable areas in the ravine bottoms and interior plateaus and ridges, utilizing the clearings for coconut plantations of substantial extent. Heyerdahl theorized that these plantations were used to provide fresh liquid and food for pre-Columbian voyages (balsa rafts using \"guara\" navigation) between Guatemala and northwestern South America. After the Spanish conquest and its consequences, these voyages ended and the tropical jungle recovered the land that had been laboriously cleared by early human hands.\n\nThe island has over 400 known species of insects, of which 65 (16%) are endemic. The greatest diversity is found among the Lepidoptera and Formicidae. Over 50 species of other arthropods have been described (spiders, centipedes, millipedes, and isopods).\n\nTwo species of lizard are found on the island, an anole (\"Anolis townsendii\") and a gecko (\"Sphaerodactylus pacificus\"); both are endemic. No amphibians have been reported.\n\nNearly 90 bird species have been reported. The island and neighboring rocks are home to large nesting colonies of migratory seabirds, including the brown booby (\"Sula leucogaster\"), red-footed booby (\"Sula sula\"), great frigatebird (\"Fregata minor\"), white tern (\"Gygis alba\") and brown noddy (\"Anous stolidus\"). Seven species of land birds inhabit the island, including three endemics: the Cocos cuckoo (\"Coccyzus ferrugineus\"), Cocos flycatcher (\"Nesotriccus ridgwayi\") and Cocos finch (\"Pinaroloxias inornata\").\n\nThe island has five land mammal species: pigs, deer, goats, cats, and rats. All these land mammals were introduced by humans. The Costa Rican government has vowed to control the populations of these animals, as they are harmful to the local ecosystems.\n\nThe rich coral reef, volcanic tunnels, caves, massifs and deeper waters surrounding Cocos Island are home to more than 30 species of coral, 60 species of crustaceans, 600 species of molluscs and over 300 species of fish. These include large populations of yellowfin tuna (\"Thunnus albacares\"), giant mantas (\"Manta birostris\"), sailfish (\"Istiophorus platypterus\") and sharks, such as whitetip reef shark (\"Triaenodon obesus\") and scalloped hammerhead shark (\"Sphyrna lewini\"). The largest of all species of fish is also present, the whale shark (\"Rhincodon typus\"). In December 2017, a female tiger shark (a species that returned to the waters of Isla del Coco in 2012, after 30 years of not being seen in the area) killed New Yorker Rohina Bhandari while she was scuba diving in Manuelita in the Isla del Coco National Park.\n\nOther large marine animals include humpback whales (\"Megaptera novaeangliae\"), orcas (\"orcinus orca\"), pilot whales (\"Globicephala macrorhynchus\"), bottlenose dolphins (\"Tursiops truncatus\"), and sea lions (\"Zalophus californianus\").\n\nThere are also reptiles: hawksbill turtles (\"Eretmochelys imbricata\"), green turtles (\"Chelonia mydas\") and olive ridley turtles (\"Lepidochelys olivacea\").\n\nThe 16th-century historian Gonzalo Fernández de Oviedo informs in his book \"Historia General y Natural de las Indias, Islas y Tierra Firme del Mar Océano\" (Seville, 1535) about the discovery of the island due to the Spanish navigator from Avilés Juan de Cabezas (also known as Juan de Grado) in 1526. D. Lievre, \"Una isla desierta en el Pacífico; la isla del Coco\" in \"Los viajes de Cockburn y Lievre por Costa Rica\" (1962: 134) tells that the first document with the name \"Isle de Coques\" is a map painted on parchment, called that of Henry II that appeared in 1542 during the reign of Francis I of France. The planisphere of Nicolas Desliens (1556, Dieppe) places this \"Ysle de Coques\" about one and half degrees north of the Equator. (See also Mario A. Boza and Rolando Mendoza, \"Los parques nacionales de Costa Rica\", Madrid, 1981.) Blaeu's \"Grand Atlas\", originally published in 1662, has a colour world map on the back of its front cover which shows \"I. de Cocos\" right on the Equator. Frederik De Witt's \"Atlas, 1680\" shows it similarly. The \"Hondius Broadside map\" of 1590 shows \"I. de Cocos\" at the latitude of 2 degrees and 30 minutes northern latitude, while in 1596 Theodore de Bry shows the Galápagos Islands near 6 degrees north of the Equator. Emanuel Bowen, \"A Complete system of Geography\", Volume II (London, 1747: 586) states that the Galápagos stretch 5 degrees north of the Equator.\n\nThe island became part of Costa Rica in 1832 by decree No. 54 of the Constitutional Assembly of the free state of Costa Rica.\n\nWhalers stopped at Cocos Island regularly until the mid-19th century, when inexpensive kerosene started to replace whale oil for lighting.\n\nIn October 1863 the ship \"Adelante\" dumped 426 Tongan ex-slaves on the island when it was discovered that they were affected with smallpox and a danger to his crew. When they were saved by the \"Tumbes\", one month later, only 38 had survived, as the rest had perished from smallpox. (See: ʻAta ).\n\nIn 1897 the Costa Rican government named the German adventurer and treasure hunter August Gissler the first Governor of Cocos Island and allowed him to establish a short-lived colony there.\n\nOn May 12, 1970 the insular territory of Cocos Island was incorporated administratively into Central Canton of the Province of Puntarenas by means of Executive Decree No. 27, making it the Eleventh District of Central Canton. The island's 33 residents, the Costa Rican park rangers, were allowed to vote for the first time in Costa Rica's February 5, 2006, election.\n\nThe first claims of treasure buried on the island came from a woman named Mary Welsh, who claimed 350 tons of gold (about $16 billion in today's money) raided from Spanish galleons had been buried on the island. She had been a member of a pirate crew led by Captain Bennett Graham, and was transported to an Australian penal colony for her crimes. She possessed a chart showing where Graham's treasure was supposed to be hidden. On her release she returned to the island with an expedition, which had no success in finding anything, with the points of reference in the chart having disappeared.\n\nAnother pirate supposed to have buried treasure on the island was the Portuguese Benito Bonito. Though Bonito was hunted down and executed, his treasure was never retrieved.\n\nThe best known of the treasure legends tied to the island is that of the Treasure of Lima. In 1820, with the army of José de San Martín approaching Lima, Viceroy José de la Serna is supposed to have entrusted treasure from the city to British trader Captain William Thompson for safekeeping until the Spaniards could secure the country. Instead of waiting in the harbor as they were instructed, Thompson and his crew killed the Viceroy's men and sailed to Cocos, where they buried the treasure. Shortly afterwards, they were apprehended by a Spanish warship. All of the crew except Thompson and his first mate were executed for piracy. The two said they would show the Spaniards where they had hidden the treasure in return for their lives – but after landing on Cocos, they escaped into the forest.\n\nHundreds of attempts to find treasure on the island have failed. Several early expeditions were mounted on the basis of claims by a man named Keating, who was supposed to have befriended Thompson. On one trip, Keating was said to have retrieved gold and jewels from the treasure. Prussian adventurer August Gissler lived on the island for most of the period from 1889 until 1908, hunting the treasure with the small success of finding six gold coins.\n\n is an art project curated by Nadim Samman for Thyssen-Bornemisza Art Contemporary Academy and commissioned by Francesca von Habsburg. Works by forty internationally celebrated artists were placed inside an exhibition architecture (that is, contemporary ‘treasure’ chest) designed by architects Aranda\\Lasch and then buried at a secret location on Cocos Island in May 2014. The GPS coordinates (or ‘map’) of the exhibition location were logged at the site of burial. These coordinates were then given to the Dutch artist Constant Dullaart, who worked with a leading cryptographer to encode them. The resulting string of code was then made physical as a 3D printed steel cylinder and placed inside a second version of the chest. This chest will be auctioned to raise funds for a shark research and conservation initiative on Cocos Island. The buyer will not receive the decryption key.\n\nTreasure of Lima: A Buried Exhibition brought artists, marine biologists, collectors, and sailors together to engage with conservation issues while exploring the history of piracy on Cocos, the politics of access and exclusion in the fields of art and natural heritage, as well as the limits of the exhibition format.\n\nThe mostly unperturbed habitats are, however, under growing human pressure. Illegal poaching of large marine species in and around its protected waters has become a main concern. Growing local and worldwide demand for tuna, shark fin soup and other seafood is threatening the island's fragile ecosystems. The government of Costa Rica has been openly accused of passivity and even benefiting corruptly from illegal shark fin and other seafood trade to large markets, such as China and other Asian countries. The government has shown some willingness to protect the island's natural riches and prosecute poachers. However, efforts to effectively patrol the waters and enforce environmental laws face big financial and bureaucratic difficulties, as well as being prone to the corruption of local, national and international authorities.\n\nRecent events show that large-scale illegal poaching keeps happening. Despite initial hope in stopping and charging poachers, who have been caught with abundant evidence, they have been quickly released under suspicious circumstances. Also, efforts to raise funds for protection have been dwarfed.\n\nMarvin Orlando Cerdas, a judge with the local Puntarenas Court of Justice, obscurely allowed 22 poachers caught red-handed to escape the country.\n\nAlso under highly suspicious and allegedly corrupt circumstances, District Attorney Michael Morales Molina stopped the auction for public benefit of confiscated goods, immediately after the spokesman of the large illegal poacher ship \"Tiuna\" simply made the request.\n\nThe book \"Desert Island\" proposed the highly detailed theory that Daniel Defoe used the Isla del Coco as an accurate model for his descriptions of the island inhabited by the marooned Robinson Crusoe. However Defoe placed Crusoe's island not in the Pacific, but rather off the coast of Venezuela in the Atlantic Ocean.\n\nRobinson's neighbouring \"Terra Firma\" is shown on the colour map of Joannes Jansson (Amsterdam) depicting the northeastern corner of South America, entitled \"Terra Firma et Novum Regnum Granatense et Popayan\". It belongs to the early group of plates printed by Willem Blaeu from 1630 onwards. The properly called Terra Firma was the Isthmus of Darien. Crusoe's two references to Mexico are against a South American island as well.\n\nMichael Crichton's \"Jurassic Park\" novel (and subsequent movies) takes place in the fictitious \"Isla Nublar\" of Costa Rica, which is modeled after Cocos Island. The video game \"\", from 1998, uses a map of Cocos Island to illustrate the island.\n\n"}
{"id": "32428639", "url": "https://en.wikipedia.org/wiki?curid=32428639", "title": "Deglaciation", "text": "Deglaciation\n\nDeglaciation describes the transition from full glacial conditions during ice ages, to warm interglacials, characterized by global warming and sea level rise due to change in continental ice volume (\"IPCC AR5\"). Thus, it refers to the retreat of a glacier, an ice sheet or frozen surface layer, and the resulting exposure of the Earth's surface. The decline of the cryosphere due to ablation can occur on any scale from global to localized to a particular glacier. After the Last Glacial Maximum (ca. 21,000 years ago), the last deglaciation begun, which lasted until the early Holocene. Around much of Earth, deglaciation during the last 100 years has been accelerating as a result of climate change, partly brought on by anthropogenic changes to greenhouse gases.\n\nThe previous deglaciation took place between approximately 22ka until 11.5ka. This occurred when there was an annual mean atmospheric temperature on the earth that increased by roughly 5 °C, which was also accompanied by regional high-latitude warming that exceeded 10 °C. This was also followed by noteworthy deep-sea and tropical-sea warming, between about 1-2 °C (deep-sea) and 2-4 °C (tropical sea). Not only did this warming occur, but the global hydrological budget also experienced noticeable changes and regional precipitation patterns changed. As a result of all of this, the world's main ice sheets, including the ones located in Eurasia, North America and parts of the Antarctic melted. As a consequence, sea levels rose roughly 120 metres. These processes did not occur steadily, and they also did not occur at the same time.\n\nThe process of deglaciation reflects a lack of balance between existing glacial extent and climatic conditions. As a result of net negative mass balance over time, glaciers and ice sheets retreat. The repeated periods of increased and decreased extent of the global cryposhere (as deduced from observations of ice and rock cores, surface landforms, sub-surface geologic structures, the fossil record, and other methods of dating) reflect the cyclical nature of global and regional glaciology measured by ice ages and smaller periods known as glacials and interglacials. Since the end of the Last glacial period about 12,000 years ago, ice sheets have retreated on a global scale, and Earth has been experiencing a relatively warm interglacial period marked by only high-altitude alpine glaciers at most latitudes with larger ice sheet and sea ice at the poles. However, since the onset of the Industrial Revolution, human activity has contributed to a rapid increase in the speed and scope of deglaciation globally.\n\nResearch published in 2014 suggests that below Greenland's Russell Glacier's ice sheet, methanotrophs could serve as a biological methane sink for the subglacial ecosystem, and the region was at least during the sample time, a source of atmospheric methane. Based on dissolved methane in water samples, Greenland may represent a significant global methane source, and may contribute significantly more due to ongoing deglaciation. A study in 2016 concluded based on past evidence, that below Greenland's and Antarctica's ice sheet may exist methane clathrates.\n\nAt every scale, climate influences the condition of snow and ice on Earth's surface. In colder periods massive ice sheets may extend toward the Equator, while in periods warmer than today, the Earth may be completely free of ice. A significant, empirically demonstrated, positive relationship exists between the surface temperature and concentration of Greenhouse gases such as CO in the atmosphere. The higher concentration, in turn, has a drastic negative impact on the global extent and stability of the cryosphere. On the millennial time scales of Pleistocene glacial and interglacial cycles, the pacemaker of glaciation onset and melting are changes in orbital parameters termed the Milankovitch cycles. Specifically, low summer insolation in the northern hemisphere permits growth of ice sheets, while high summer insolation causes more ablation than winter snow accumulation.\n\nHuman activities promoting climate change, notably the extensive use of fossil fuels over the last 150 years and the resulting increase in atmospheric CO concentrations, are the principal cause of the more rapid retreat of alpine glaciers and continental ice sheets all across the world. For example, the West Antarctic Ice Sheet has receded significantly, and is now contributing to a positive feedback loop that threatens further deglaciation or collapse. Newly exposed areas of the Southern Ocean contain long-sequestered stores of CO which are now being emitted into the atmosphere and are continuing to impact glacial dynamics.\n\nThe principle of isostasy applies directly to the process of deglaciation, especially post-glacial rebound, which is one of main mechanisms through which isostasy is observed and studied. Post-glacial rebound refers to the increase in tectonic uplift activity immediately following glacial retreat. Increased rates and abundance of volcanic activity have been found in regions experiencing post-glacial rebound. If on a large enough scale, an increase in volcanic activity provides a positive feedback to the process of deglaciation as a result CO and methane released from volcanos.\n\nPeriods of deglaciation are also caused in part by oceanic processes. For example, interruptions of the usual deep cold water circulation and penetration depths in the North Atlantic have feedbacks that promote further glacial retreat.\n\nDeglaciation influences sea level because water previously held on land in solid form turns into liquid water and eventually drains into the ocean. The recent period of intense deglaciation has resulted in an average global sea level rise of 1.7 mm/year for the entire 20th century, and 3.2 mm/year over the past two decades, a very rapid increase.\n\nThe physical mechanisms by which deglaciation occurs include melting, evaporation, sublimation, calving, and aeolian processes such as wind scouring.\n\nThroughout the Pleistocene Epoch, the Laurentide Ice sheet covered large areas of northern North America, with over 5,000,000 square miles of coverage. The Laurentide ice sheet was 10,000 feet deep in some areas, and reached as far south as 37°N. Mapped extent of the Laurentide Ice Sheet during deglaciation has been prepared by Dyke et al. Cycles of deglaciation are driven by various factors, with the main driver being changes in incoming summer solar radiation, or insolation, in the Northern Hemisphere. But, as not all of the rises in insolation throughout time caused deglaciation, to the current ice volumes that we witness today. This leads to a different conclusion, one that suggests that there is a possible climatic threshold, in terms of ice sheets retreating, and eventually disappearing. As Laurentide was the largest mass ice sheet in the Northern Hemisphere, much study has been conducted regarding its disappearance, unloading energy balance models, atmosphere-ocean general circulation models, and surface energy balance models. These studies concluded that the Laurentide ice sheet presented a positive surface mass balance during almost the entirety of its deglaciation, which indicates that the loss of mass throughout its deglaciation was more than likely due to dynamic discharge. It was not until the early Holocene when the surface mass balance switched to become negative. This change to a negative surface mass balance suggested that surface ablation became the driver that resulted in the loss of mass of ice in the Laurentide ice sheet. It is concluded then that the Laurentide ice sheet only began to exhibit behaviours and patterns of deglaciation after radiative forcing and summer temperatures began to rise at the beginning of the Holocene.\n\nWhen the Laurentide ice sheet progressed through the process of deglaciation, it created many new landforms and had various effects of the land. First and foremost, as huge glaciers melt, there is a consequently large volume of meltwater. The volumes of meltwater created many features, including proglacial freshwater lakes, which can be sizable. Not only was there meltwater that formed lakes, there were also storms that blew over the inland freshwater. These storms created waves strong enough to erode the ice shores. Once ice cliffs were exposed, due to rising sea levels and erosion caused by waves, the ice bergs were split and shed (calved) off. Large lakes became prevalent, but so did smaller, shallower, relatively short-lived lakes. This appearance and disappearance of small, shallow lakes influenced much of the plant growth, spread and diversity that we see today. The lakes acted as barriers to plant migration, but when these lakes drained, the plants could migrate and spread very efficiently.\n\nThe period between the end of the Last Glacial Maximum to the early Holocene (ca. 19k-11k years ago), shows changes in greenhouse gas concentrations and of the Atlantic meridional overturning circulation (AMOC), when sea-level rose by 80 meters. Additionally, the last deglaciation is marked by three abrupt CO2 pulses, and records of volcanic eruptions show that subaerial volcanism increased globally by two to six times above background levels between 12 ka and 7 ka.\n\nBetween roughly 19ka, the end of the Last Glacial Maximum (or LGM) to 11ka, which was the early Holocene, the climate system experienced drastic transformation. Much of this change was occurring at an astonishing rate, as the earth was dealing with the end of the last ice age. Changes in insolation was the principal reason for this drastic global change in climate, as this was linked with several other changes globally, from the alteration of ice sheets, to the concentration of greenhouse gases fluctuating, and many other feedbacks that resulted in distinct responses, both globally and regionally. Not only were ice sheets and greenhouse gases experiencing alteration, but also additionally to this, there was sudden climate change, and many occurrences of fast, and sizeable rising of sea level. The melting of the ice sheets, along with the rising sea levels did not happen until after 11ka. Nonetheless, the globe had arrived at its present interglacial period, where climate is comparatively constant and stable, and greenhouse gas concentrations exhibit near pre-industrial levels. This data is all available due to studies and information gathered from proxy records, both from the terrestrial and ocean, which illustrates overall global patterns of changes in climate whilst in the period of Deglaciation. \nDuring the Last Glacial Maximum (LGM), there were apparent low atmospheric concentration of Carbon Dioxide (CO2), which was believed to be as a result of larger containment of carbon in the deep ocean, via the process of stratification within the Southern Ocean. These Southern Ocean deep waters contained the least δ13C, which consequently resulted in them being the location with the greatest density, and most salt content during the LGM. The discharge of such sequestered carbon was perhaps a direct outcome of the deep Southern Ocean overturning, driven by heightened wind-driven upwelling, and sea-ice retreat, which are directly correlated to the warming of the Antarctic, and also coinciding with the cold events, the Oldest and Younger Dryas, in the north.\n\nThroughout the LGM in North America, the east was populated by cold-tolerant conifer forests, while the southeast and northwest of the United States sustained open forests in locations that have closed forests today, which suggests that during the LGM temperatures were cooler and overall conditions were much drier than those that we experience today. There is also indication that the southwest of the United States was much wetter during the LGM compared to today, as there was open forest, where today we see desert and steppe. In the United States, the general variation of vegetation implies an overall fall in temperatures of (at minimum 5 °C), a shift of the westerly storm tracks to the south, and a very steep latitudinal temperature gradient. \n\nSeveral landforms visible today are distinctive of the powerful erosional forces at play during, or immediately after, deglaciation. The distribution of such landforms helps to inform the understanding of the glacial dynamics and geologic periods of the past. Studying exposed landforms can also inform the understanding of the present and near future as glaciers all over the world retreat in the current period of climate change. In general, recently deglacialized landscapes are inherently unstable and will tend to move towards an equilibrium.\n\nA sampling of common landforms caused by deglaciation, or caused by the successive geomorphic processes after exposure due to deglaciation:\n\n"}
{"id": "20739459", "url": "https://en.wikipedia.org/wiki?curid=20739459", "title": "Dissolved load", "text": "Dissolved load\n\nDissolved load is the portion of a stream's total sediment load that is carried in solution, especially ions from chemical weathering. It is a major contributor to the total amount of material removed from a river's drainage basin, along with suspended load and bed load. The amount of material carried as dissolved load is typically much smaller than the suspended load, though this is not always the case, particularly when the available river flow is mostly harnessed for purposes such as irrigation or industrial uses. Dissolved load comprises a significant portion of the total material flux out of a landscape, and its composition is important in regulating the chemistry and biology of the stream water.\n\nThe dissolved load is primarily controlled by the rate of chemical weathering, which depends on climate and weather conditions such as moisture and temperature. Dissolved load has many useful applications within the field of geology, including erosion, denudation, and reconstructing climate in the past.\n\nDissolved load is typically measured by taking samples of water from a river and running various scientific tests on them. First, the pH, conductivity, and bicarbonate alkalinity of the sample are measured. Next, samples are filtered to remove any suspended sediments and preserved with chloroform to prevent growth of microorganisms, while the others are acidified with hydrochloric acid added to keep dissolved ions from precipitating out of solution. Then, various chemical tests were applied to determine the concentration of each solute. For example, the concentrations of sodium and potassium ions can be determined by flame photometry, while the calcium and magnesium ion concentrations can be determined by atomic absorption spectrophotometry.\n\nDissolved load can provide valuable information about the rate of soil formation and other processes of chemical erosion. In particular, the mass balance between the dissolved load and solid phase is helpful in determining surface dynamics. In addition, dissolved load can be used to reconstruct the climate of the Earth in the past. This is because chemical weathering is the major contributor to the dissolved load of a stream. The chemical weathering of silicate rocks is the primary sink for carbon dioxide in the atmosphere, because atmospheric carbon dioxide is converted into carbonate rocks in the carbonate–silicate cycle. Carbon dioxide concentrations are the primary control of the greenhouse effect, which determines the temperature of the Earth.\n\nDenudation is the process of wearing away the top layers of Earth's landscape. Because the rate of denudation is normally too small to directly measure, it can be indirectly determined by measuring the sediment load of the streams that drain the area in question. This is possible because any material that passes through a certain point on a stream is guaranteed to have come from somewhere in the stream's drainage basin upstream of that point. As topographic relief increases, the dissolved load's contribution to the total stream load decreases due to the fact that on steeper surfaces, rain is less likely to infiltrate the rocks, leading to less chemical weathering, which decreases the dissolved load.\n\nThe process of carrying salts by water to the sea or a land-locked lake from a river basin is called salt export. When adequate salt export is not occurring, the river basin area gradually converts into saline soils and/or alkali soils, particularly in lower reaches.\n\nUSGS CMG InfoBank: Suspended and Dissolved Loads\n"}
{"id": "58544695", "url": "https://en.wikipedia.org/wiki?curid=58544695", "title": "Donbettyr", "text": "Donbettyr\n\nDonbettyr () is the god of all waters, and the protector of fish and fishermen in Ossetian mythology. He is related to a Scythian deity of the same name. He is the Ossetian equivalent of the Greek Poseidon. His beautiful daughters are the Ossetian equivalent of sea nymphs. Through them, he is the ancestor of many of the heroes of the epic Nart saga of the north Caucasus, including Uryzmaeg, Satanaya, Xaemyts, and Batraz. \n\nDonbettyr's golden-haired daughter Dzerassae was the mother of Uryzmaeg, Satanaya, and Xaemyts. \n\nDonbettyr is also the maternal grandfather of the Nart hero Batraz, through the marriage of the hunter Xaemyts to an unnamed daughter of Donbettyr. In the story of their marriage, Xaemyts is chasing a white rabbit and shooting at it. It dies, but returns to life three times, before escaping to the coast where it dives into the sea. Donbettyr rises from the water and declares that the hare was actually his daughter and that Xaemyts must marry her. Xaemyts agrees, only to be told that his wife will appear on earth during the day in the form of a tortoise. Only at night will she take the form of the beautiful woman he married.\n\nWhen Uryzmaeg had a son, Donbettyr took it upon himself to raise the boy, deep beneath the sea. \n"}
{"id": "650321", "url": "https://en.wikipedia.org/wiki?curid=650321", "title": "Duricrust", "text": "Duricrust\n\nDuricrust is a hard layer on or near the surface of soil. Duricrusts can range in thickness from a few millimeters or centimeters to several meters.\n\nIt is a general term (not to be confused with duripan) for a zone of chemical precipitation and hardening formed at or near the surface of sedimentary bodies through pedogenic and (or) non-pedogenic processes. It is typically formed by the accumulation of soluble minerals deposited by mineral-bearing waters that move upward, downward, or laterally by capillary action, commonly assisted in arid settings by evaporation. Minerals often found in duricrust include silica, iron, calcium, and gypsum.\n\nDuricrusts need to be formed in absolute accumulation, therefore they must have a source, transfer and precipitation. Duricrust is often studied during missions to Mars because it may help prove the planet once had more water. Duricrust was found on Mars at the Viking 2 landing site, and a similar structure, nicknamed \"Snow Queen,\" was found under the Phoenix landing site. Phoenix's duricrust was later confirmed to be water-based.\n\n\n\n"}
{"id": "19174720", "url": "https://en.wikipedia.org/wiki?curid=19174720", "title": "Electric battery", "text": "Electric battery\n\nAn electric battery is a device consisting of one or more electrochemical cells with external connections provided to power electrical devices such as flashlights, smartphones, and electric cars. When a battery is supplying electric power, its positive terminal is the cathode and its negative terminal is the anode. The terminal marked negative is the source of electrons that will flow through an external electric circuit to the positive terminal. When a battery is connected to an external electric load, a redox reaction converts high-energy reactants to lower-energy products, and the free-energy difference is delivered to the external circuit as electrical energy. Historically the term \"battery\" specifically referred to a device composed of multiple cells, however the usage has evolved to include devices composed of a single cell.\n\nPrimary (single-use or \"disposable\") batteries are used once and discarded; the electrode materials are irreversibly changed during discharge. Common examples are the alkaline battery used for flashlights and a multitude of portable electronic devices. Secondary (rechargeable) batteries can be discharged and recharged multiple times using an applied electric current; the original composition of the electrodes can be restored by reverse current. Examples include the lead-acid batteries used in vehicles and lithium-ion batteries used for portable electronics such as laptops and smartphones.\n\nBatteries come in many shapes and sizes, from miniature cells used to power hearing aids and wristwatches to small, thin cells used in smartphones, to large lead acid batteries used in cars and trucks, and at the largest extreme, huge battery banks the size of rooms that provide standby or emergency power for telephone exchanges and computer data centers.\n\nAccording to a 2005 estimate, the worldwide battery industry generates US$48 billion in sales each year, with 6% annual growth.\n\nBatteries have much lower specific energy (energy per unit mass) than common fuels such as gasoline. In automobiles, this is somewhat offset by the higher efficiency of electric motors in converting chemical energy to mechanical work, compared to combustion engines. \n\nThe usage of \"battery\" to describe a group of electrical devices dates to Benjamin Franklin, who in 1748 described multiple Leyden jars by analogy to a battery of cannon (Benjamin Franklin borrowed the term \"battery\" from the military, which refers to weapons functioning together).\n\nItalian physicist Alessandro Volta built and described the first electrochemical battery, the voltaic pile, in 1800. This was a stack of copper and zinc plates, separated by brine-soaked paper disks, that could produce a steady current for a considerable length of time. Volta did not understand that the voltage was due to chemical reactions. He thought that his cells were an inexhaustible source of energy, and that the associated corrosion effects at the electrodes were a mere nuisance, rather than an unavoidable consequence of their operation, as Michael Faraday showed in 1834.\n\nAlthough early batteries were of great value for experimental purposes, in practice their voltages fluctuated and they could not provide a large current for a sustained period. The Daniell cell, invented in 1836 by British chemist John Frederic Daniell, was the first practical source of electricity, becoming an industry standard and seeing widespread adoption as a power source for electrical telegraph networks. It consisted of a copper pot filled with a copper sulfate solution, in which was immersed an unglazed earthenware container filled with sulfuric acid and a zinc electrode.\n\nThese wet cells used liquid electrolytes, which were prone to leakage and spillage if not handled correctly. Many used glass jars to hold their components, which made them fragile and potentially dangerous. These characteristics made wet cells unsuitable for portable appliances. Near the end of the nineteenth century, the invention of dry cell batteries, which replaced the liquid electrolyte with a paste, made portable electrical devices practical.\n\nBatteries convert chemical energy directly to electrical energy. In many cases, the electrical energy released is the difference in the cohesive or bond energies of the metals, oxides, or molecules undergoing the electrochemical reaction. For instance, energy can be stored in Zn or Li, which are high-energy metals because they are not stabilized by d-electron bonding, unlike transition metals. Batteries are designed such that the energetically favorable redox reaction can occur only if electrons move through the external part of the circuit.\n\nA battery consists of some number of voltaic cells. Each cell consists of two half-cells connected in series by a conductive electrolyte containing metal \"cations\". One half-cell includes electrolyte and the negative electrode, the electrode to which anions (negatively charged ions) migrate; the other half-cell includes electrolyte and the positive electrode, to which cations (positively charged ions) migrate. Cations are reduced (electrons are added) at the cathode, while metal atoms are oxidized (electrons are removed) at the anode. Some cells use different electrolytes for each half-cell; then a separator is used to prevent mixing of the electrolytes while allowing ions to flow between half-cells to complete the electrical circuit.\n\nEach half-cell has an electromotive force (\"emf\", measured in volts) relative to a standard. The net emf of the cell is the difference between the emfs of its half-cells. Thus, if the electrodes have emfs formula_1 and formula_2, then the net emf is formula_3; in other words, the net emf is the difference between the reduction potentials of the half-reactions.\n\nThe electrical driving force or formula_4 across the terminals of a cell is known as the \"terminal voltage (difference)\" and is measured in volts. The terminal voltage of a cell that is neither charging nor discharging is called the open-circuit voltage and equals the emf of the cell. Because of internal resistance, the terminal voltage of a cell that is discharging is smaller in magnitude than the open-circuit voltage and the terminal voltage of a cell that is charging exceeds the open-circuit voltage. An ideal cell has negligible internal resistance, so it would maintain a constant terminal voltage of formula_5 until exhausted, then dropping to zero. If such a cell maintained 1.5 volts and produce a charge of one coulomb then on complete discharge it would have performed 1.5 joules of work. In actual cells, the internal resistance increases under discharge and the open-circuit voltage also decreases under discharge. If the voltage and resistance are plotted against time, the resulting graphs typically are a curve; the shape of the curve varies according to the chemistry and internal arrangement employed.\n\nThe voltage developed across a cell's terminals depends on the energy release of the chemical reactions of its electrodes and electrolyte. Alkaline and zinc–carbon cells have different chemistries, but approximately the same emf of 1.5 volts; likewise NiCd and NiMH cells have different chemistries, but approximately the same emf of 1.2 volts. The high electrochemical potential changes in the reactions of lithium compounds give lithium cells emfs of 3 volts or more.\n\nBatteries are classified into primary and secondary forms:\n\n\nSome types of primary batteries used, for example, for telegraph circuits, were restored to operation by replacing the electrodes. Secondary batteries are not indefinitely rechargeable due to dissipation of the active materials, loss of electrolyte and internal corrosion.\n\nPrimary batteries, or primary cells, can produce current immediately on assembly. These are most commonly used in portable devices that have low current drain, are used only intermittently, or are used well away from an alternative power source, such as in alarm and communication circuits where other electric power is only intermittently available. Disposable primary cells cannot be reliably recharged, since the chemical reactions are not easily reversible and active materials may not return to their original forms. Battery manufacturers recommend against attempting to recharge primary cells. In general, these have higher energy densities than rechargeable batteries, but disposable batteries do not fare well under high-drain applications with loads under 75 ohms (75 Ω). Common types of disposable batteries include zinc–carbon batteries and alkaline batteries.\n\nSecondary batteries, also known as \"secondary cells\", or \"rechargeable batteries\", must be charged before first use; they are usually assembled with active materials in the discharged state. Rechargeable batteries are (re)charged by applying electric current, which reverses the chemical reactions that occur during discharge/use. Devices to supply the appropriate current are called chargers.\n\nThe oldest form of rechargeable battery is the lead–acid battery, which are widely used in automotive and boating applications. This technology contains liquid electrolyte in an unsealed container, requiring that the battery be kept upright and the area be well ventilated to ensure safe dispersal of the hydrogen gas it produces during overcharging. The lead–acid battery is relatively heavy for the amount of electrical energy it can supply. Its low manufacturing cost and its high surge current levels make it common where its capacity (over approximately 10 Ah) is more important than weight and handling issues. A common application is the modern car battery, which can, in general, deliver a peak current of 450 amperes.\n\nThe sealed valve regulated lead–acid battery (VRLA battery) is popular in the automotive industry as a replacement for the lead–acid wet cell. The VRLA battery uses an immobilized sulfuric acid electrolyte, reducing the chance of leakage and extending shelf life. VRLA batteries immobilize the electrolyte. The two types are:\n\n\nOther portable rechargeable batteries include several sealed \"dry cell\" types, that are useful in applications such as mobile phones and laptop computers. Cells of this type (in order of increasing power density and cost) include nickel–cadmium (NiCd), nickel–zinc (NiZn), nickel metal hydride (NiMH), and lithium-ion (Li-ion) cells. Li-ion has by far the highest share of the dry cell rechargeable market. NiMH has replaced NiCd in most applications due to its higher capacity, but NiCd remains in use in power tools, two-way radios, and medical equipment.\n\nIn the 2000s, developments include batteries with embedded electronics such as USBCELL, which allows charging an AA battery through a USB connector, nanoball batteries that allow for a discharge rate about 100x greater than current batteries, and smart battery packs with state-of-charge monitors and battery protection circuits that prevent damage on over-discharge. Low self-discharge (LSD) allows secondary cells to be charged prior to shipping.\n\nMany types of electrochemical cells have been produced, with varying chemical processes and designs, including galvanic cells, electrolytic cells, fuel cells, flow cells and voltaic piles.\n\nA \"wet cell\" battery has a liquid electrolyte. Other names are \"flooded cell\", since the liquid covers all internal parts, or \"vented cell\", since gases produced during operation can escape to the air. Wet cells were a precursor to dry cells and are commonly used as a learning tool for electrochemistry. They can be built with common laboratory supplies, such as beakers, for demonstrations of how electrochemical cells work. A particular type of wet cell known as a concentration cell is important in understanding corrosion. Wet cells may be primary cells (non-rechargeable) or secondary cells (rechargeable). Originally, all practical primary batteries such as the Daniell cell were built as open-top glass jar wet cells. Other primary wet cells are the Leclanche cell, Grove cell, Bunsen cell, Chromic acid cell, Clark cell, and Weston cell. The Leclanche cell chemistry was adapted to the first dry cells. Wet cells are still used in automobile batteries and in industry for standby power for switchgear, telecommunication or large uninterruptible power supplies, but in many places batteries with gel cells have been used instead. These applications commonly use lead–acid or nickel–cadmium cells.\n\nA \"dry cell\" uses a paste electrolyte, with only enough moisture to allow current to flow. Unlike a wet cell, a dry cell can operate in any orientation without spilling, as it contains no free liquid, making it suitable for portable equipment. By comparison, the first wet cells were typically fragile glass containers with lead rods hanging from the open top and needed careful handling to avoid spillage. Lead–acid batteries did not achieve the safety and portability of the dry cell until the development of the gel battery.\n\nA common dry cell is the zinc–carbon battery, sometimes called the dry Leclanché cell, with a nominal voltage of 1.5 volts, the same as the alkaline battery (since both use the same zinc–manganese dioxide combination). A standard dry cell comprises a zinc anode, usually in the form of a cylindrical pot, with a carbon cathode in the form of a central rod. The electrolyte is ammonium chloride in the form of a paste next to the zinc anode. The remaining space between the electrolyte and carbon cathode is taken up by a second paste consisting of ammonium chloride and manganese dioxide, the latter acting as a depolariser. In some designs, the ammonium chloride is replaced by zinc chloride.\n\nMolten salt batteries are primary or secondary batteries that use a molten salt as electrolyte. They operate at high temperatures and must be well insulated to retain heat.\n\nA reserve battery can be stored unassembled (unactivated and supplying no power) for a long period (perhaps years). When the battery is needed, then it is assembled (e.g., by adding electrolyte); once assembled, the battery is charged and ready to work. For example, a battery for an electronic artillery fuze might be activated by the impact of firing a gun. The acceleration breaks a capsule of electrolyte that activates the battery and powers the fuze's circuits. Reserve batteries are usually designed for a short service life (seconds or minutes) after long storage (years). A water-activated battery for oceanographic instruments or military applications becomes activated on immersion in water.\n\nA battery's characteristics may vary over load cycle, over charge cycle, and over lifetime due to many factors including internal chemistry, current drain, and temperature. At low temperatures, a battery cannot deliver as much power. As such, in cold climates, some car owners install battery warmers, which are small electric heating pads that keep the car battery warm.\n\nA battery's \"capacity\" is the amount of electric charge it can deliver at the rated voltage. The more electrode material contained in the cell the greater its capacity. A small cell has less capacity than a larger cell with the same chemistry, although they develop the same open-circuit voltage. Capacity is measured in units such as amp-hour (A·h). The rated capacity of a battery is usually expressed as the product of 20 hours multiplied by the current that a new battery can consistently supply for 20 hours at , while remaining above a specified terminal voltage per cell. For example, a battery rated at 100 A·h can deliver 5 A over a 20-hour period at room temperature. The fraction of the stored charge that a battery can deliver depends on multiple factors, including battery chemistry, the rate at which the charge is delivered (current), the required terminal voltage, the storage period, ambient temperature and other factors.\n\nThe higher the discharge rate, the lower the capacity. The relationship between current, discharge time and capacity for a lead acid battery is approximated (over a typical range of current values) by Peukert's law:\n\nwhere\n\nBatteries that are stored for a long period or that are discharged at a small fraction of the capacity lose capacity due to the presence of generally irreversible \"side reactions\" that consume charge carriers without producing current. This phenomenon is known as internal self-discharge. Further, when batteries are recharged, additional side reactions can occur, reducing capacity for subsequent discharges. After enough recharges, in essence all capacity is lost and the battery stops producing power.\n\nInternal energy losses and limitations on the rate that ions pass through the electrolyte cause battery efficiency to vary. Above a minimum threshold, discharging at a low rate delivers more of the battery's capacity than at a higher rate. Installing batteries with varying A·h ratings does not affect device operation (although it may affect the operation interval) rated for a specific voltage unless load limits are exceeded. High-drain loads such as digital cameras can reduce total capacity, as happens with alkaline batteries. For example, a battery rated at 2 A·h for a 10- or 20-hour discharge would not sustain a current of 1 A for a full two hours as its stated capacity implies.\n\nThe C-rate is a measure of the rate at which a battery is being charged or discharged. It is defined as the current through the battery divided by the theoretical current draw under which the battery would deliver its nominal rated capacity in one hour. A 1C discharge rate would deliver the battery's rated capacity in 1 hour. A 2C discharge rate means it will discharge twice as fast (30 minutes). A 1C discharge rate on a 1.6 Ah battery means a discharge current of 1.6 A. A 2C rate would mean a discharge current of 3.2 A. Standards for rechargeable batteries generally rate the capacity over a 4-hour, 8 hour or longer discharge time. Because of internal resistance loss and the chemical processes inside the cells, a battery rarely delivers nameplate rated capacity in only one hour. Types intended for special purposes, such as in a computer uninterruptible power supply, may be rated by manufacturers for discharge periods much less than one hour.\n\nThe C-rate presents a dimensional error: C is in ampere-hours and not amperes, and one can not express a current in ampere-hours. For this reason the concept I was introduced by the international standard IEC61434, I being equal to the capacity C divided by one hour, hence allowing a mathematically correct method of current designation. The figures used for expressing the discharge rate remain the same: one can speak of \"2 I rate\" instead of the dimensionally incorrect \"2 C rate\".\n\n, lithium iron phosphate () battery technology was the fastest-charging/discharging, fully discharging in 10–20 seconds.\n\n, the world's largest battery was built in South Australia by Tesla. It can store 129 MWh. A battery in Hebei Province, China which can store 36 MWh of electricity was built in 2013 at a cost of $500 million. Another large battery, composed of Ni–Cd cells, was in Fairbanks, Alaska. It covered —bigger than a football pitch—and weighed 1,300 tonnes. It was manufactured by ABB to provide backup power in the event of a blackout. The battery can provide 40 MW of power for up to seven minutes. Sodium–sulfur batteries have been used to store wind power. A 4.4 MWh battery system that can deliver 11 MW for 25 minutes stabilizes the output of the Auwahi wind farm in Hawaii.\n\nLithium–sulfur batteries were used on the longest and highest solar-powered flight.\n\nBattery life (and its synonym battery lifetime) has two meanings for rechargeable batteries but only one for non-chargeables. For rechargeables, it can mean either the length of time a device can run on a fully charged battery or the number of charge/discharge cycles possible before the cells fail to operate satisfactorily. For a non-rechargeable these two lives are equal since the cells last for only one cycle by definition. (The term shelf life is used to describe how long a battery will retain its performance between manufacture and use.) Available capacity of all batteries drops with decreasing temperature. In contrast to most of today's batteries, the Zamboni pile, invented in 1812, offers a very long service life without refurbishment or recharge, although it supplies current only in the nanoamp range. The Oxford Electric Bell has been ringing almost continuously since 1840 on its original pair of batteries, thought to be Zamboni piles.\n\nDisposable batteries typically lose 8 to 20 percent of their original charge per year when stored at room temperature (20–30 °C). This is known as the \"self-discharge\" rate, and is due to non-current-producing \"side\" chemical reactions that occur within the cell even when no load is applied. The rate of side reactions is reduced for batteries stored at lower temperatures, although some can be damaged by freezing.\n\nOld rechargeable batteries self-discharge more rapidly than disposable alkaline batteries, especially nickel-based batteries; a freshly charged nickel cadmium (NiCd) battery loses 10% of its charge in the first 24 hours, and thereafter discharges at a rate of about 10% a month. However, newer low self-discharge nickel metal hydride (NiMH) batteries and modern lithium designs display a lower self-discharge rate (but still higher than for primary batteries).\n\nInternal parts may corrode and fail, or the active materials may be slowly converted to inactive forms.\n\nThe active material on the battery plates changes chemical composition on each charge and discharge cycle; active material may be lost due to physical changes of volume, further limiting the number of times the battery can be recharged. Most nickel-based batteries are partially discharged when purchased, and must be charged before first use. Newer NiMH batteries are ready to be used when purchased, and have only 15% discharge in a year.\n\nSome deterioration occurs on each charge–discharge cycle. Degradation usually occurs because electrolyte migrates away from the electrodes or because active material detaches from the electrodes. Low-capacity NiMH batteries (1,700–2,000 mA·h) can be charged some 1,000 times, whereas high-capacity NiMH batteries (above 2,500 mA·h) last about 500 cycles. NiCd batteries tend to be rated for 1,000 cycles before their internal resistance permanently increases beyond usable values.\n\nFast charging increases component changes, shortening battery lifespan.\n\nIf a charger cannot detect when the battery is fully charged then overcharging is likely, damaging it.\n\nNiCd cells, if used in a particular repetitive manner, may show a decrease in capacity called \"memory effect\". The effect can be avoided with simple practices. NiMH cells, although similar in chemistry, suffer less from memory effect.\n\nAutomotive lead–acid rechargeable batteries must endure stress due to vibration, shock, and temperature range. Because of these stresses and sulfation of their lead plates, few automotive batteries last beyond six years of regular use. Automotive starting batteries have many thin plates to maximize current. In general, the thicker the plates the longer the life. They are typically discharged only slightly before recharge.\n\n\"Deep-cycle\" lead–acid batteries such as those used in electric golf carts have much thicker plates to extend longevity. The main benefit of the lead–acid battery is its low cost; its main drawbacks are large size and weight for a given capacity and voltage. Lead–acid batteries should never be discharged to below 20% of their capacity, because internal resistance will cause heat and damage when they are recharged. Deep-cycle lead–acid systems often use a low-charge warning light or a low-charge power cut-off switch to prevent the type of damage that will shorten the battery's life.\n\nBattery life can be extended by storing the batteries at a low temperature, as in a refrigerator or freezer, which slows the side reactions. Such storage can extend the life of alkaline batteries by about 5%; rechargeable batteries can hold their charge much longer, depending upon type. To reach their maximum voltage, batteries must be returned to room temperature; discharging an alkaline battery at 250 mA at 0 °C is only half as efficient as at 20 °C. Alkaline battery manufacturers such as Duracell do not recommend refrigerating batteries.\n\nPrimary batteries readily available to consumers range from tiny button cells used for electric watches, to the No. 6 cell used for signal circuits or other long duration applications. Secondary cells are made in very large sizes; very large batteries can power a submarine or stabilize an electrical grid and help level out peak loads.\n\nA battery explosion is generally caused by misuse or malfunction, such as attempting to recharge a primary (non-rechargeable) battery, or a short circuit.\n\nWhen a battery is recharged at an excessive rate, an explosive gas mixture of hydrogen and oxygen may be produced faster than it can escape from within the battery (e.g. through a built-in vent), leading to pressure build-up and eventual bursting of the battery case. In extreme cases, battery chemicals may spray violently from the casing and cause injury. Overcharging - that is, attempting to charge a battery beyond its electrical capacity - can also lead to a battery explosion, in addition to leakage or irreversible damage. It may also cause damage to the charger or device in which the overcharged battery is later used.\n\nCar batteries are most likely to explode when a short-circuit generates very large currents. Such batteries produce hydrogen, which is very explosive, when they are overcharged (because of electrolysis of the water in the electrolyte). During normal use, the amount of overcharging is usually very small and generates little hydrogen, which dissipates quickly. However, when \"jump starting\" a car, the high current can cause the rapid release of large volumes of hydrogen, which can be ignited explosively by a nearby spark, e.g. when disconnecting a jumper cable.\n\nDisposing of a battery via incineration may cause an explosion as steam builds up within the sealed case.\n\nRecalls of devices using Lithium-ion batteries have become more common in recent years. This is in response to reported accidents and failures, occasionally ignition or explosion. An expert summary of the problem indicates that this type uses \"liquid electrolytes to transport lithium ions between the anode and the cathode. If a battery cell is charged too quickly, it can cause a short circuit, leading to explosions and fires\".\n\nMany battery chemicals are corrosive, poisonous or both. If leakage occurs, either spontaneously or through accident, the chemicals released may be dangerous. For example, disposable batteries often use a zinc \"can\" both as a reactant and as the container to hold the other reagents. If this kind of battery is over-discharged, the reagents can emerge through the cardboard and plastic that form the remainder of the container. The active chemical leakage can then damage or disable the equipment that the batteries power. For this reason, many electronic device manufacturers recommend removing the batteries from devices that will not be used for extended periods of time.\n\nMany types of batteries employ toxic materials such as lead, mercury, and cadmium as an electrode or electrolyte. When each battery reaches end of life it must be disposed of to prevent environmental damage. Batteries are one form of electronic waste (e-waste). E-waste recycling services recover toxic substances, which can then be used for new batteries. Of the nearly three billion batteries purchased annually in the United States, about 179,000 tons end up in landfills across the country. In the United States, the Mercury-Containing and Rechargeable Battery Management Act of 1996 banned the sale of mercury-containing batteries, enacted uniform labeling requirements for rechargeable batteries and required that rechargeable batteries be easily removable. California and New York City prohibit the disposal of rechargeable batteries in solid waste, and along with Maine require recycling of cell phones. The rechargeable battery industry operates nationwide recycling programs in the United States and Canada, with dropoff points at local retailers.\n\nThe Battery Directive of the European Union has similar requirements, in addition to requiring increased recycling of batteries and promoting research on improved battery recycling methods. In accordance with this directive all batteries to be sold within the EU must be marked with the \"collection symbol\" (a crossed-out wheeled bin). This must cover at least 3% of the surface of prismatic batteries and 1.5% of the surface of cylindrical batteries. All packaging must be marked likewise.\n\nBatteries may be harmful or fatal if swallowed. Small button cells can be swallowed, in particular by young children. While in the digestive tract, the battery's electrical discharge may lead to tissue damage; such damage is occasionally serious and can lead to death. Ingested disk batteries do not usually cause problems unless they become lodged in the gastrointestinal tract. The most common place for disk batteries to become lodged is the esophagus, resulting in clinical sequelae. Batteries that successfully traverse the esophagus are unlikely to lodge elsewhere. The likelihood that a disk battery will lodge in the esophagus is a function of the patient's age and battery size. Disk batteries of 16 mm have become lodged in the esophagi of 2 children younger than 1 year. Older children do not have problems with batteries smaller than 21–23 mm. Liquefaction necrosis may occur because sodium hydroxide is generated by the current produced by the battery (usually at the anode). Perforation has occurred as rapidly as 6 hours after ingestion.\n\nMany important cell properties, such as voltage, energy density, flammability, available cell constructions, operating temperature range and shelf life, are dictated by battery chemistry. \n\nOn 28 February 2017, The University of Texas at Austin issued a press release about a new type of solid-state battery, developed by a team led by Lithium-ion (Li-Ion) inventor John Goodenough, \"that could lead to safer, faster-charging, longer-lasting rechargeable batteries for handheld mobile devices, electric cars and stationary energy storage\". \nMore specifics about the new technology were published in the peer-reviewed scientific journal Energy & Environmental Science.\n\nIndependent reviews of the technology discuss the risk of fire and explosion from Lithium-ion batteries under certain conditions because they use liquid electrolytes. The newly developed battery should be safer since it uses glass electrolytes, that should eliminate short circuits. The solid-state battery is also said to have \"three times the energy density\" increasing its useful life in electric vehicles, for example. It should also be more ecologically sound since the technology uses less expensive, earth-friendly materials such as sodium extracted from seawater. They also have much longer life; (\"the cells have demonstrated more than 1,200 cycles with low cell resistance\"). The research and prototypes are not expected to lead to a commercially viable product in the near future, if ever, according to Chris Robinson of LUX Research. \"This will have no tangible effect on electric vehicle adoption in the next 15 years, if it does at all. A key hurdle that many solid-state electrolytes face is lack of a scalable and cost-effective manufacturing process,\" he told The American Energy News in an e-mail.\n\nAlmost any liquid or moist object that has enough ions to be electrically conductive can serve as the electrolyte for a cell. As a novelty or science demonstration, it is possible to insert two electrodes made of different metals into a lemon, potato, etc. and generate small amounts of electricity. \"Two-potato clocks\" are also widely available in hobby and toy stores; they consist of a pair of cells, each consisting of a potato (lemon, et cetera) with two electrodes inserted into it, wired in series to form a battery with enough voltage to power a digital clock. Homemade cells of this kind are of no practical use.\n\nA voltaic pile can be made from two coins (such as a nickel and a penny) and a piece of paper towel dipped in salt water. Such a pile generates a very low voltage but, when many are stacked in series, they can replace normal batteries for a short time.\n\nSony has developed a biological battery that generates electricity from sugar in a way that is similar to the processes observed in living organisms. The battery generates electricity through the use of enzymes that break down carbohydrates.\n\nLead acid cells can easily be manufactured at home, but a tedious charge/discharge cycle is needed to 'form' the plates. This is a process in which lead sulfate forms on the plates, and during charge is converted to lead dioxide (positive plate) and pure lead (negative plate). Repeating this process results in a microscopically rough surface, increasing the surface area, increasing the current the cell can deliver.\n\nDaniell cells are easy to make at home. Aluminium–air batteries can be produced with high-purity aluminium. Aluminium foil batteries will produce some electricity, but are not efficient, in part because a significant amount of (combustible) hydrogen gas is produced.\n\n\n"}
{"id": "11329485", "url": "https://en.wikipedia.org/wiki?curid=11329485", "title": "Energy Exchange Austria", "text": "Energy Exchange Austria\n\nThe Energy Exchange Austria (EXAA) is a Central European energy exchange headquartered in Vienna. Currently, the EXAA Market encompasses trading areas in the entire of Austria and Germany.\n\nEXAA was founded 2001 and started day-ahead spot market trading of electric energy on March 21, 2002. Since then, EXAA has developed into a major platform for efficient trading that makes use of the possibilities offered by a liberalized energy market in Central Europe. In June 2005, trading started in European CO emissions allowances (EUAs) in the market segment for environmental products, which resulted in 2011 into a joint effort with the Greenmarket environmental exchange.\n\nEnergy exchanges have become an established part of the liberalized energy markets in Europe. They serve as an important supplement to short-term OTC trading and also function as an independent price indicator for electric energy on the wholesale market.\n\nWhile the energy markets in Central Europe often involve a single electricity producer, or multiple electricity producers that auction their energy in tranches, or via long-term bilateral supply contracts,\nan energy exchange contributes to increasing price efficiency and allows electric utilities to react flexibly when facing a changing demand/supply structure. Ultimately, an energy exchange can reduce dramatically the price risk related to short-term spikes in load profiles.\n\nEXAA was founded as a public limited company and the shareholders are Wiener Börse AG (25.1%) and the APCS AG (34.5%), as well as a number of different companies from the Austrian energy sector holding smaller shares (April 2013).\nSince 2005 EXAA forms part of the CISMOgroup, a group comprising a number of different service providers for the energy sector.\n\nThe CISMOgroup covers a broad range of specialized services for the electricity markets, such as clearing and settlement of the electricity market, capacity allocation and auctioning, international consulting for projects related to electricity markets,\nas well as the regulation and management of feed-in tariffs for green energy in Austria.\n\nAs of the April, 2013, more than 70 companies from 14 different countries were trading at the EXAA electricity spot market.\n\n EXAA operates a day-ahead electricity spot market, with a single daily auction point at 10:15 AM. Traders place closed buy (bid) and sell (ask) orders for electric energy, to be physically delivered the following day, until 10:12 AM when the orderbook closes. Traders can place bids and asks for electric power in individual hours, as well as in standardized blocks (comprising several hours).\n\nThe matching algorithm then evaluates the orders and sets a market clearing price (MCP) for each hour and product to maximize the traded volume. At 10:15 AM all exchange members are notified of their allocations. Orders are evaluated according to specific rules of precedence, where market orders are always fulfilled before block orders and lastly single hour orders. The surplus (non-matched) grey power volume is then offered for sale again at the MCP during a short 3 minute period from 10:16 to 10:19 AM called the post-trading.\n\nIn post-trading, the prices for all hours are already known (the MCP being determined during the auction before) and the surplus volumes are sold and bought on a first-come, first-served basis, offering the traders a last-minute opportunity to sell or buy volumes at a known price.\n\nTrading at EXAA takes place 5 days a week, from Monday to Friday, with the volumes for Saturday, Sunday and Monday being traded together on the Friday before. This set-up has its advantages as well as its disadvantages. It is often not possible for utilities to correctly predict their required electricity volumes two days ahead in order to cover their requirements on Friday. Additionally, some trading companies whose main objective is arbitrage (trading for profit without physical procurement or delivery), may miss out on potential trading opportunities that arise over the weekend. On the other hand, a 5-day trading week reflects the reality of smaller utilities that usually cannot or do not want to staff their trading department seven days a week. Another important factor is that even at the big trading floors, the head traders capable of leveraging sudden market developments are usually not present seven days a week. The trading itself is conducted by means of the EXAA online trading system, accessible from any standard internet browser supporting SSL encryption. The security of the system is guaranteed by means of RSA key fobs and the EXAA market operations team that continuously monitors every auction.\n\nPrice volatility on the electricity markets is an important factor in the decision-making process of all involved stakeholders. In general, increased price volatility increases also the risk involved in trading for all parties. Price volatility on the electricity market is influenced mainly by unexpected changes in the supply-demand structure on the markets, which are mainly caused by unpredictable weather patterns (especially due to wind), as well as by unplanned power plant outages.\n\nOn the supply side (distribution), the electric utilities are bound to adapt to consumer load profiles, in order to keep the electricity grid balanced. These load-profiles are statistically planned in advance and usually covered by long-term supply contracts, or own production of electric energy. Often however, irregularities in the long-term prognosis occur and the utilities are obliged to procure, or sell the outstanding quantities of electric energy on the market. The irregularities on the demand side are usually determined by the varying consumption of electric power by households and the industry, which depend again mostly on the changing weather conditions.\nIn the recent years, the European markets have witnessed a steady rise of price volatility that was caused among other factors, by the augmented use of renewable energy sources - which can be explained by the fact that a larger portion of the overall electricity production in Europe depends nowadays on weather, especially wind power plants.\n\nAll electricity producing installations have to adhere to their declared schedule (a production plan specifying the volume of their electricity production for every hour of the day). It is the responsibility of the electric utilities that own the power plants to match their production and the consumption. The electricity consumption is calculated from historic data (load profile of the electric consumption in the given area and serves as the lead indicator for the future volumes that will be required to cover the demand. The Electric utility faces a number of options how to procure the necessary volumes of electric energy. If the company owns its own power plants, which is usually the case, it produces a part of the electricity itself. Depending on the production capacity of the company, a major part of the outstanding volume is acquired, or sold via long-term bilateral contracts. The rest can be obtained via the OTC market and the short-term demand is covered via day-ahead, or even intra-day trading. The relative rigidity of the production, which cannot be flexibly adjusted and the relative uncertainty about the actual consumption, which depends on a number of factors such as weather, industrial production levels etc., are bound to create unpredicted spikes in electricity prices.\n\nThere is one major factor that had a dramatic influence on the electricity spot prices in the recent years, which is the wind. The portion of the wind energy in the overall electricity production increased significantly in the last couple of years in many European countries due to heavily subsidized governmental programs favoring investments into renewable energy sources. In some countries such as Germany, the wind power installations are required by law to make full use of the prevailing weather conditions and always produce the maximum possible amount of electric energy.\nFirstly it has to be stated that the wind is a completely flexible energy source per se, since the head of the wind turbine can be rotated, thereby stopping to turn and to produce electric energy. However, this flexibility is taken away by the prevailing environmental and energy laws in order to maximize the share of renewable energy in the production portfolio to the fullest extent possible.\nSecondly, wind is a highly unpredictable factor and the schedules for wind installations are often far off, despite major efforts to statistically predict the short-term wind conditions.\nThe two above mentioned factors combined introduce a new source of volatility into an already volatile system that gives rise to electricity prices.\n\nWhile the measures aiming at increasing the electricity production of renewable energy sources can be considered highly effective and successful, they lead to price distortions and exerted increased pressure on the markets, as well as on the electricity grid.\n\n In order to start trading at the EXAA, companies can become either a direct clearing member, or employ the services of a broker and become a non-clearing member. Before being accepted as a direct clearing member, companies have to complete the membership procedure and provide a security deposit to back their future transactions. Companies that don’t necessarily require a full membership can nevertheless participate in electricity trading via a broker.\n\nThe broker (agent clearing member) provides the necessary collaterals and acquires/sells the required electricity volumes for its clients, in return for a small brokerage fee. In either case, EXAA functions as a central counter-party to every trading transaction, which means that EXAA guarantees the physical fulfillment of every trade.\n\nBesides its function as a marketplace for spot electricity, EXAA also supports regional initiatives related to electricity markets and provides a training program - teem, for electric utilities and different stakeholders from the energy industry.\nThe Training for Energy and Environmental Markets was developed by EXAA in cooperation with experts from the CISMO Group and from different strategic partners covering all segments of the energy sector. The goal was to develop a training with focus on the practical aspects of the electricity industry, using the newest data to analyze trends and market developments and provide a wide range of professionals with insights from market practitioners. The transparent and coherent energy insights as well as current developments are not only interesting for energy newcomers but also for employees who want to broaden and update their knowledge. \nteem has already achieved the position of market leader in the energy training segment as it convinces delegates with its up-to-date and compact contentcs as well as its great value for money.\n\nPrice stiffness could be considered the \"opposite\" of the price elasticity function. While the price elasticity is a measure indicating the change of the demand or supply given a certain change in the price, the \"price stiffness\" used by EXAA is set out to determine the impact of a change in the supply and demand structure on the market clearing price.\nThe reason behind investigating such a measure is to assess the influence of bids (especially market orders) on the market clearing price (the price for each product calculated during the auction).\nTraders are often forced to enter bids as market orders (a bid specifying only the required quantity, not limited by a certain price) in order to have a certainty of being able to procure the necessary volumes to close their positions. Market orders can potentially have a major impact on the outcome of the auction since particularly significant bid/s can cause a dramatic shift in the aggregated demand, or in the aggregated supply curve leading to unwanted price spikes. (Note: While a certain number of significant price spikes is bound to occur due to extreme market conditions, one of the characteristics of a stable market is how well does it absorb single bids and what are the usual levels of volatility on average.) This aspect resents a potential risk in smaller markets, where large market orders might cause a dramatic price shift. The price stiffness analysis is based on a simulation, which replays past auctions, while injecting additional market orders of differing magnitude into the auction, thus obtaining a virtual price for multiple critical scenarios.\nA central part of EXAA publications is the Daily Spotlight, which is a brief summary of the recent trends in price and volume development at the EXAA. It is compiled on a daily basis and made publicly available at the EXAA website.\n\n"}
{"id": "25680731", "url": "https://en.wikipedia.org/wiki?curid=25680731", "title": "European Conference on Radar in Meteorology and Hydrology", "text": "European Conference on Radar in Meteorology and Hydrology\n\nEuropean Conference on Radar in Meteorology and Hydrology (ERAD) is an international scientific conference that is organised every two years from 2000.\n\nThe idea of ERAD, which has been perpetuated since its first edition in 2000, is to create an open forum between students, academics, engineers, end users and operational radar operators working with or using weather radars and weather radar data. The goal of this conference is to facilitate mutual understanding between data producers and data users and to help young generations accessing state-of-the-art knowledge on radars, radar signal and radar applications through communication with the most renowned scientists of the field.\n\n\n\n"}
{"id": "1471147", "url": "https://en.wikipedia.org/wiki?curid=1471147", "title": "Ferberite", "text": "Ferberite\n\nFerberite is the iron endmember of the manganese - iron wolframite solid solution series. The manganese endmember is hübnerite. Ferberite is a black monoclinic mineral composed of iron(II) tungstate, FeWO.\n\nFerberite and hübnerite often contain both divalent cations of iron and manganese, with wolframite as the intermediate species for which the solid solution series is named.\n\nFerberite occurs as granular masses and as slender prismatic crystals. It has a Mohs hardness of 4.5 and a specific gravity of 7.4 to 7.5. Ferberite typically occurs in pegmatites, granitic greisens, and high temperature hydrothermal deposits. It is a minor ore of tungsten.\n\nFerberite was discovered in 1863 in Sierra Almagrera, Spain, and named after the German mineralogist Moritz Rudolph Ferber (1805–1875).\n\n\n"}
{"id": "9056438", "url": "https://en.wikipedia.org/wiki?curid=9056438", "title": "Geoforecasting", "text": "Geoforecasting\n\nGeoforecasting is the science of predicting the movement of tectonic plates and the future climate, shape, and other geological elements of the planet.\n\nGeoforecasting is particularly important in the siting of epositories for radioactive materials. It also is useful in other areas with long term management issues such as water management.\n\n"}
{"id": "48497658", "url": "https://en.wikipedia.org/wiki?curid=48497658", "title": "Geophysical signal analysis", "text": "Geophysical signal analysis\n\nGeophysical signal analysis is concerned with the detection and a subsequent processing of signals. Any signal which is varying conveys valuable information. Hence to understand the information embedded in such signals, we need to 'detect' and 'extract data' from such quantities. Geophysical signals are of extreme importance to us as they are information bearing signals which carry data related to petroleum deposits beneath the surface and seismic data. Analysis of geophysical signals also offers us a qualitative insight into the possibility of occurrence of a natural calamity such as earthquakes or volcanic eruptions.\n\nGravitational and magnetic fields are detected using extremely sensitive gravitometers and magnetometers respectively. The gravitational field changes are measured using devices such as atom interferometers. A superconducting quantum interference device (SQUID) is an extremely sensitive device which measures minute changes in the magnetic field. After detection, the data from these signals is extracted by performing spectral analysis, filtering and beamforming techniques. These techniques can be used in oil exploration to estimate the position of underground objects, harnessing geothermal energy.\n\nThe position of underground objects can be determined by measuring the gradient in Earth's gravitational field. It is known that an object with heavier mass “attracts” other objects of a considerably lower value of mass. This force of attraction is explained by understanding the following topics.\n\nTemporal frequency is the number of occurrences of an event in unit \"time\". It is defined relative to time. Frequency of a wave can be X cycles per second. Spatial frequency on the other hand is the characteristic of any entity that periodically varies in space.\n\nDigitizing of any signal has two aspects : \"digitizing in time domain\" and \"digitizing in space domain\". These concepts pertain to the signals varying in space, time or both.\n\n\nTo explain the concept of a tensor, consider the definition of a vector: “Vector is a quantity having both magnitude and direction. Vectors are tensors with rank 1”. There is only basis vector for a component. Ex: Velocity is represented as Ai + Bj + Ck where i,j,k are unit vectors in the x,y,z directions respectively. We can see that there is a one-one mapping between the basis vector and its component.\n\nTensor, on the other hand has rank greater than one. Gravitational field is an example for a tensor.\n\nThe set of figures on the left represent the various components of the gravitational field. These components fully characterize all the forces acting on a body. These can be represented in a matrix form as follows:\n\nNow that we are familiar with the concepts of gravity and tensors, a qualitative discussion of gravity and its significance in geophysical analysis can be done. A certain mass distribution creates a gravitational force field around it, In other words, the object under consideration has a finite mass ‘M’ and hence bends the space around it. The gravitational field gradient is given by the divergence of the gravitational field.\n\nThe method being discussed here assumes that the mass distribution of the underground objects of interest is already known and hence the problem of estimating their location boils down to parametric localisation. Since the mass distribution of objects of interest is already known, say underground objects with center of masses(CM, CM…CM) are located under the earth and at positions p, p...p. The gravity gradient(components of the gravity field) is measured using a spinning wheel with accelerometers also called as the gravity gradiometer. The instrument is positioned in different orientations to measure the respective component of gravitational field. The values of gravitational gradient tensors are calculated and analyzed. The analysis includes observing the contribution of each object under consideration. A maximum likelihood procedure is followed and Cramér–Rao bound (CRB) is computed to assess the quality of location estimate.\n\nMagnetometers are used to measure the magnetic fields, magnetic anomalies in the earth. The sensitivity of magnetometers depends upon the requirement. Ex, the variations in the geomagnetic fields can be to the order of several aT where 1aT = 10^-18T . In such cases, specialized magnetometers such as a superconducting quantum interference device (SQUID) are used.\n\nJim Zimmerman co-developed the superconducting quantum interference device during his tenure at Ford research lab. However, events leading to the invention of squid were in fact, serendipitous. John Lambe, during his experiments on nuclear magnetic resonance noticed that the electrical properties of indium varied due to a change in the magnetic field of the order of few nT. But, Lambe was not able to fully recognise the utility of SQUID.\n\nSQUIDs have the capability to detect magnetic fields of extremely low magnitude. This is due to the virtue of Josephson junctions. Jim Zimmerman pioneered the development of SQUID by proposing a new approach to making the Josephson junctions. He made use of niobium wires and niobium ribbons to form two Josephson junctions connected in parallel. The ribbons act as the interruptions to the superconducting current flowing through the wires. The junctions are very sensitive to the magnetic fields and hence are very useful in measuring fields of the order of 10 T.\n\nThe motion of any mass is affected by the gravitational field. The motion of planets is affected by the Sun's enormous gravitational field. Likewise, a heavier object will influence the motion of other objects of smaller mass in its vicinity. However, this change in the motion is very small compared to the motion of heavenly bodies. Hence, special instruments are required to measure such a minute change.\n\nAtom interferometers work on the principle of diffraction. The diffraction gratings are nano fabricated materials with a separation of a quarter wavelength of light. When a beam of atoms pass through a diffraction grating, due the inherent wave nature of atoms, they split and form interference fringes on the screen. An atom interferometer is very sensitive to the changes in the positions of atoms. As heavier objects shifts the position of the atoms nearby, displacement of the atoms can be measured by detecting a shift in the interference fringes.\n\nAny signal conveys information in two ways :\n\n\nThe Fourier expansion of a time domain signal is the representation of the signal as a sum of its frequency components, specifically sum of sines and cosines. came up with the Fourier representation to estimate the heat distribution of a body. The same approach can be followed to analyse the multi-dimensional signals such as electromagnetic waves.\n\nThe 4d - Fourier representation of such signals is given by:\nS(K, ω) = ∫ ∫ s(x,t) exp [-j(ωt- k'x)] dx dt\n\nSimply put, space time signal filtering problem can be thought as localizing the speed and direction of a particular signal. The design of filters for spacetime signals follows a similar approach as that of 1-D signals. The filters for 1-D signals are designed in such a way that if the requirement of the filter is to extract frequency components in a particular non-zero range of frequencies, a band-pass filter with appropriate passband and stop band frequencies in determined. Similarly, in the case of multi-dimensional systems, the wavenumber-frequency response of filters is designed in such a way thatit is unity in the designed region of (k, ω) a.k.a. wavenumber - frequency and zero elsewhere.\n\nThis approach is applied for filtering spacetime signals. It is designed to isolate signals travelling in a particular direction. One of the simplest filters is weighted delay and sum beamformer. The output is the average of the linear combination of delayed signals. In other words, the beamformer output is formed by averaging weighted and delayed versions of receiver signals. The delay is chosen such that the passband of beamformer is directed to a specific direction in the space.\n\nThis method can be used to estimate the depth of the magnetic materials beneath the earth. The magnetic data is processed by the spectral methods such as Fourier transforms. The FFT algorithm makes the spectral analysis of signals fast, easy and efficient.The FFT computations can be performed in the machines which allow us to perform contour mapping. The upward continuation method attenuates the wave number anomalies associated with the shallow magnetic sources. Thus the signal components contain the information about the objects situated deep beneath the earth.\n\nThe gravity data is collected from a detailed geographical surveys. The gravitational field intensity is measured using the gravimeter. Also, the elevations have to measured to account for the height corrections. The Bouguer anomalies in the gravity data are analysed. The Bouguer anomaly is a correction of the gravitational data which takes into account the heights of different terrains.\n\nThe Bouguer data is coupled with other magnetic and seismic measurements of the region. This data is instrumental in revealing the tectonic and structural geography that area.\n\nAfter the data is obtained, some of the observations from the Bouguer data indicate the following:\n\n\nThe process of oil exploration] starts with finding a layer of impermeable substance under which oil is buried. Until a well is drilled, one can't accurately determine the presence of oil. However, by the efficient use of geothermal techniques, we can detect a layer beneath which oil may be trapped.\n\nThere are several approaches to detect the \"oil traps\"\n\n\n"}
{"id": "1359269", "url": "https://en.wikipedia.org/wiki?curid=1359269", "title": "Hatchettite", "text": "Hatchettite\n\nHatchettite (also mountain tallow, mineral tallow, mineral adipocire, or adipocerite) is a mineral hydrocarbon.\n\nHatchettite occurs in the coal measures of Belgium and elsewhere, occupying in some cases the interior of hollow concretions of iron-ore, but more generally the cavities of fossil shells or crevices in the rocks.\nIt is of yellow colour, and translucent, but darkens and becomes opaque on exposure. It has no odour, is greasy to the touch, and has a slightly glistening lustre. Its hardness is that of soft wax. The melting point is 46 to 47 °C, and the composition is C 85.55 %, H 14.45 %.\n\n\n"}
{"id": "12969359", "url": "https://en.wikipedia.org/wiki?curid=12969359", "title": "Honey dipper", "text": "Honey dipper\n\nA honey dipper is a kitchen utensil used to collect viscous liquid (generally honey) from a container, which it then exudes to another location. It is often made of turned wood. Besides the handle, the tool consists of equally-spaced coaxial grooves. \n\nOne method of using the tool is to dip the grooved end into the liquid, then slowly twirl the handle between the thumb and fingers while in transport, to prevent dripping. It is commonly used to drizzle honey on bread, biscuits, or other foods of that nature. The tool is sometimes made of plastic or glass.\n\nThe mascot of Honey Nut Cheerios, \"BuzzBee\", has carried various incarnations of honey dippers.<ref name=\"Cheerios/XXL\">\nSources that show a honey dipper has been carried by the Honey Nut Cheerios mascot:\n\nSince the 1920s, the term \"honey dipper\" has been used as a term of disparagement for the workers who empty septic tanks, clean latrines, and do similar work.<ref name=\"Cassel/NPD\">\nSources for the alternative slang meaning of \"honey dipper\":\n"}
{"id": "1722070", "url": "https://en.wikipedia.org/wiki?curid=1722070", "title": "Iron cycle", "text": "Iron cycle\n\nIn ecology or geoscience, the iron cycle \"(Fe)\" is the biogeochemical cycle of iron through landforms, the atmosphere, and oceans. The iron cycle affects dust deposition and aerosol iron bioavailability.\n\nIron ranges in oxidation states from -2 to +7; however, in Earth's crust it is predominantly in its +2 (ferrous) or +3 (ferric) redox state. The cycling of iron between its ferrous and ferric oxidation states is referred to as the iron cycle. This process can be entirely abiotic, or facilitated by microorganisms. Some examples of this include the rusting of iron-bearing metals (in this case Fe is abiotically oxidized to Fe) by oxygen, and the abiotic reduction of Fe to Fe by iron-sulfide minerals. The iron cycle can also be facilitated by microorganisms, such as by Fe-oxidizing bacteria, which can oxidize Fe to Fe, extracting one electron in the process for energy. Fe-reducing bacteria can reduce Fe back to Fe by utilizing it as a terminal electron acceptor.\n\nIron is an important element on earth. It is 4th in abundance in the crust, and is an essential co-factor in many biological enzymes. Due to the high reactivity of Fe with oxygen and low solubility of Fe, iron is a limiting nutrient to phytoplankton, the photosynthetic primary producers in the ocean. Thus, the iron cycle is intrinsically linked to the cycling of other biologically-important elements.\n\nIn the early earth, when atmospheric oxygen levels were 0.001% of those present today, dissolved iron was thought to have been a lot more abundant in the oceans, and thus more bioavailable to microbial life present in that era. At this time, before the onset of oxygenic photosynthesis, primary production may have been dominated by photoferrotrophs, which would obtain energy from sunlight, and use the electrons from Fe to fix carbon.[citation needed]\n\n\n"}
{"id": "33220800", "url": "https://en.wikipedia.org/wiki?curid=33220800", "title": "Kathleen Meyer", "text": "Kathleen Meyer\n\nKathleen Meyer (born 7 December 1942) is a contemporary American nature writer whose first work, \"How To Shit in the Woods\" was published in 1989. Her writing is characterized by the use of humor and irreverence. She has only two published works in print: \"How to Shit in the Woods\" and \"Barefoot Hearted\".\n\n\"How to Shit in the Woods\" was published by Ten Speed Press in 1989. This first book by Meyer does, indeed, revolve around the many strategies she has noticed for defecating where there is no modern toilet and running water. As one reads the book, it quickly becomes obvious that Meyer's concern is not so much for the comfort of the camper or hiker, but for the impact that human waste leaves on pristine natural ecosystems. She talks about digging \"environmentally sound\" holes, locating the high water line, so as not to inadvertently pollute a stream or ground water source, and what types of soil facilitate quickest decomposition without risk of environmental contamination. The damage to humans and wildlife from carelessly disposed human waste comes in many forms including giardia, diarrhea, and intestinal diseases. A second edition of the book was issued in 1994 and a third edition in 2011. Meyer holds humans uniquely responsible for the spread of giardia in the wilderness areas of the United States: \"Until 1970, there were no reports in the United States of waterborne outbreaks of giardia. The first . . . occurred in Aspen, Colorado, in 1970. Over the next four years, many cases were documented in travelers returning from . . . Leningrad . . . The Soviet Union became more open to visitation by Westerners at about this time and Leningrad's municipal water supply was full of Giardia cysts.\"\n\nIn its various editions, the book has been reviewed by \"Audubon Magazine\", The New Zealand Dominion Post, and The Globe and Mail Audubon magazine writer Frank Graham wrote “Kathleen Meyer has contributed to environmental awareness while lending a grand old English word the respectability it hasn’t had since Chaucer’s day.”\n\nIn \"Barefoot-Hearted\", published by Random House in 2001, Meyer writes about renovating a dilapidated barn in which to live with her new boyfriend. Her book explores the many adversities of trying to live in a barn, not the least of which is how the smell of resident skunks under the floor permeates and resides in her clothes and hair and how the barn is infested with flies and mice. In the manner of nature writers who often use a small animal or plant as a symbol of an ecological principle, Meyer explains that she doesn't feel guilty about trapping and killing mice, because they are abundant and their population ever growing. By contrast, she notes the comparative frailty of bears who often stumble upon human habitations looking for food. When the humans get scared, the bear is often removed and killed. In the same book, Meyer also chronicles her adventure riding a horse and buggy across a large region of northwest America. \"Barefoot Hearted\" was widely reviewed, though not always with great affection. \"Kirkus Reviews\" found it an \"annoying saga about a house full of pests.\" The book was reviewed by \"Publishers Weekly\".\n\nMeyer lives in Victor, Montana where she has an editing business.\n\n"}
{"id": "30992302", "url": "https://en.wikipedia.org/wiki?curid=30992302", "title": "L. Harrison Matthews", "text": "L. Harrison Matthews\n\nLeonard Harrison Matthews FRS (12 June 1901 – 27 November 1986) was a British zoologist, especially known for his research and writings on marine mammals.\n\nMatthews was born in Bristol. He studied biological sciences at Cambridge University. He was involved with the British Colonial Office backed Discovery Investigations from 1924 to 1929, during which he was largely based on the subantarctic island of South Georgia studying the biology of whales and southern elephant seals. He then held an academic position at the University of Bristol. During the Second World War he worked on radio communications and radar. He served as scientific director of the Zoological Society of London from 1951 to 1966.\n\nHis younger brother was the physiologist Sir Bryan Harold Cabot Matthews CBE FRS.\n\n\nAs well as numerous scientific papers and reports, Matthews also authored several books about his experiences in South Georgia. His publications include:\n"}
{"id": "13323546", "url": "https://en.wikipedia.org/wiki?curid=13323546", "title": "Lake Beyşehir National Park", "text": "Lake Beyşehir National Park\n\nLake Beyşehir National Park (), established in 1993, is a national park in Konya Province, central Turkey.\n\nThe national park is located within the districts Beyşehir and Hüyük of Konya Province. It is bordered by the Lake Beyşehir in the west, Beyşehir in the south and Hüyük in the north. The national park has an elevation of . Lake Beyşehir is Turkey's third biggest lake, and the biggest freshwater lake. As of covered area, the national park with was the largestof the country until 2004 when Mount Ararat National Park was established.\n\nThe national park habitats 85 families, 305 genera, 545 species, 54 subspecies and 140 varieties within its boundaries. 88 of the 560 taxa in the park area are endemic. Some plants spread in and around the protected area are Turkish cedar, (\"Cedrus libani\"), common juniper (\"Juniperus communis\"), Phoenicean juniper (\"Juniperus phoenicea\"), fir (\"Abies\"), pine (\"Pinus\"), kermes oak (\"Quercus coccifera\"), ash tree (\"Fraxinus\"), walnut tree (\"Juglans\"), mulberry (\"Morus\"), male fern (\"Dryopteris filix-mas\"), windflower (\"Anemone nemorosa\"), poppy (\"Papaver somniferum\"), dyer's madder (\"Rubia tinctorum\"), sage (\"Salvia\"), snowdrop (\"Galanthus\") and \"cyclamen\".\n\nLake Beyşehir and its creeks are habitat for 16 freshwater fish species including zander, carp and zarte.\n\nThe lake is quite important for water birds. There are 153 bird species in the park area. Bird species such as coot, pelican, heron, grebe, mallard, little grebe and tufted duck are observed on the islets and the shallow banks of the lake.\n\nThe area around the lake is also rich in species of amphibians, reptiles and mammals. It is habitat for three amphibian, 14 reptile and 34 mammal species.\n\nThe national park offers opportunities for diverse recreational outdoor activities such as trekking, hiking and mountain biking. There is also possibility of boat ride on the lake.\n\nThere are picnic areas, off-road park, campgrounds for tent and camper in the park. The park has no lodging facilities. The nearby town Beyşehir provides hotels, motels and hostels to stay.\n\nBest time to perform recreational activities in the national park is between May and October.\n\nState highway between Konya and Isparta runs through the national par. The park is in a distance of to Konya, and is far from Isparta.\n\n"}
{"id": "4082353", "url": "https://en.wikipedia.org/wiki?curid=4082353", "title": "Leimakid", "text": "Leimakid\n\nIn Greek Mythology, Leimakids were nymphs of meadows. They are also known as Leimoniads.\n\nReference: Enclopedia of Fairies in World Folklore and Mythology, page 213, under \"Lemiakid\" <nowiki>https://books.google.ca/books?id=nSuXAAAAQBAJ&pg=PA213&lpg=PA213&dq=Leimakid&source=bl&ots=lTQP6k7aax&sig=9uFlGaVX26GUPeYJY_sFkDCBR3Y&hl=en&sa=X&ved=0ahUKEwjutt-08eHUAhWs6YMKHQvSBxc4FBDoAQgeMAE#v=onepage&q=Leimakid&f=false}}</nowiki>"}
{"id": "7535157", "url": "https://en.wikipedia.org/wiki?curid=7535157", "title": "List of Canadian plants by family B", "text": "List of Canadian plants by family B\n\nMain page: List of Canadian plants by family\n\nFamilies:\nA | B | C | D | E | F | G | H | I J K | L | M | N | O | P Q | R | S | T | U V W | X Y Z\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "38676095", "url": "https://en.wikipedia.org/wiki?curid=38676095", "title": "List of nature centers in South Dakota", "text": "List of nature centers in South Dakota\n\nThis is a list of nature centers and environmental education centers in the state of South Dakota.\n\nTo use the sortable tables: click on the icons at the top of each column to sort that column in alphabetical order; click again for reverse alphabetical order.\n\n"}
{"id": "26652654", "url": "https://en.wikipedia.org/wiki?curid=26652654", "title": "List of professional gardeners", "text": "List of professional gardeners\n\nThis is a list of people noted for their contribution to gardening, either by working as gardeners or garden designers by occupation, or by commissioning famous gardens. \n\nIt does not include the innumerable people who count gardening among their hobbies.\n\nThe following are or were gardeners or garden designers by occupation. The list includes garden designers and landscape gardeners, who are involved chiefly in the design of gardens rather than the practical aspects of horticulture. It also includes experts noted for their writing or broadcasting on the subject.\n\n\nOther people whose primary profession was not gardening have made notable contributions to horticulture by planning or commissioning significant gardens. \n\n\n\n"}
{"id": "19815598", "url": "https://en.wikipedia.org/wiki?curid=19815598", "title": "List of pseudoscientific water fuel inventions", "text": "List of pseudoscientific water fuel inventions\n\nThis article attempts to list pseudoscientific inventions wherein common water is used to either augment or generate a fuel to power an engine, boiler or other source of power. This is not to be confused with legitimate inventions (such as hydroelectricity) in which the kinetic energy of flowing water is used for power.\n\nThe electrolysis of water splits water into hydrogen and oxygen, producing a usable fuel. However, the energy required for electrolysis is greater than the energy released by burning this fuel, so this is not a viable way to manufacture energy. Nonetheless, several people have claimed to create devices that do exactly this.\n\n\n\nWater is claimed to be transformed into a fuel itself, by the addition of some ingredient. This may be either a highly concentrated addition, or a catalyst (i.e. not consumed in use).\n\n"}
{"id": "8591770", "url": "https://en.wikipedia.org/wiki?curid=8591770", "title": "List of stars in Norma", "text": "List of stars in Norma\n\nThis is the list of notable stars in the constellation Norma, sorted by decreasing brightness.\n\n\n"}
{"id": "53179065", "url": "https://en.wikipedia.org/wiki?curid=53179065", "title": "List of stellar explosion types", "text": "List of stellar explosion types\n\nStellar explosion can refer to\n\n"}
{"id": "8538231", "url": "https://en.wikipedia.org/wiki?curid=8538231", "title": "List of wildlife of the Skagit River Basin", "text": "List of wildlife of the Skagit River Basin\n\nThis is a list of wildlife found in the Skagit River basin of the Pacific Northwest.\n\nSalmon and trout\n\nMinnows, carp\n\nSuckers\nCodfishes\n\nSculpins\n\nSticklebacks\n\nTurtles\n\nLizards\nSnakes\nSalamanders\nFrogs and toads\n\nOpossums\n\nShrews\nMoles\n\nBats\n\nPikas\nRabbits and hares \n\nMountain beaver\nChipmunks, marmots, squirrels \nBeavers\nMice, woodrats, voles\nPorcupines\n\nNutrias\n\nCoyotes, wolves, foxes\nBears \n\nRaccoons\n\nWeasels\nCats\n\nElk, deer, moose\n\nGoats\n\nLoons\n\nGrebes\nHerons and bitterns\n\nSwans, geese, ducks\n\nRaptors\n\nGrouse, ptarmigan, quail\n\nRails and coots\n\nShorebirds\nGulls and terns\nAlcids\n\nPigeons and doves\nOwls\n\nNighthawks and swifts\nHummingbirds\n\nKingfishers\nWoodpeckers\nFlycatchers\nLarks\n\nSwallows\nJays, crows, ravens\n\nChickadees, nuthatches, creepers\nWrens\n\nDippers\n\nKinglets\nBluebirds, robins, thrushes\nCatbirds\nPipits \n\nWaxwings\n\nShrikes\n\nStarlings\nVireos \n\nWarblers\nTanagers \n\nBlackbirds, meadowlarks, orioles\nGrosbeaks, buntings, sparrows\n"}
{"id": "56696679", "url": "https://en.wikipedia.org/wiki?curid=56696679", "title": "Loiyangalani–Suswa High Voltage Power Line", "text": "Loiyangalani–Suswa High Voltage Power Line\n\nLoiyangalani–Suswa High Voltage Power Line is a high voltage electricity power line under construction in Kenya, connecting the high voltage substation at Loyangalani, in Marsabit County, to another high voltage substation at Suswa, in Narok County.\n\nThe power line starts at the Lake Turkana Wind Power Station in Loiyangalani, Marsabit County and runs in a southerly direction for approximately to end at the Kenya Electricity Transmission Company electricity substation, at Suswa, in Narok County.\n\nThe 400kV power line is intended to evacuate the electricity generated at the Turkana Wind Power Station, to the Ketraco substation at Suswa. The Government of Spain is lending the Kenyan government a total of €142 million (approx. US$174.6 million), to have this line constructed. The contract between Isolux and Ketraco is for a construction price of US$208.1 million. The government of Kenya will provide the balance of approximately US$33.5 million as equity in the power line, along with any associated land acquisition costs.\n\nIn 2011, the Spanish company, Isolux Ingeniera SA won the contract to construct this power line. Due to a prolonged land acquisition process, work did not actually start until November 2015. Sixteen months into construction, on a project allocated 24 months, the parent company of the main contractor, Isolux Corsán, ran out of money and filed bankruptcy in Spain. In August 2017, Ketraco terminated the contract with Isolux, with about 30 percent of the work completed.\n\nIn February 2018, the Kenya government, through Ketraco, contracted a consortium of Chinese firms at a cost of US$96 million, to complete the work left pending by Isolux. Work is expected to conclude in August 2018. The consortium, comprising \"NARI Group Corporation\" and \"Power China Guizhou Engineering Company\", has committed in writing to pay US$10 million in fines, for every month the work goes beyond the 31 August 2018 deadline.\n\nIn September 2018, Reuters reported that construction of the power station was complete and was awaiting testing and commissioning.\n\nIn January 2017, the owners of Lake Turkana Wind Power Station started to bill the Kenya Power Company a monthly \"capacity charge\" of KSh700 million (approx. US$7 million), for power produced by the power station that cannot be evacuated due to lack a high voltage line to transmit it to the substation at Suswa. Following negotiations, in September 2017, the government of Kenya agreed to pay the developers of Lake Turkana Wind Power Station, a total of Sh5.7 billion (approx. US$55.83 million), in monthly installments, spread over a six year period. The monthly payment will amount to Sh78,600,000 (approx. US$769,833). The monthly surcharge will be passed on to the consumers, beginning in May 2018.\n\n\n"}
{"id": "53201736", "url": "https://en.wikipedia.org/wiki?curid=53201736", "title": "M Puppis", "text": "M Puppis\n\nThe Bayer designations m Puppis and M Puppis are distinct. Due to , both designations link here. For the star\n\n"}
{"id": "54866690", "url": "https://en.wikipedia.org/wiki?curid=54866690", "title": "Maas–Hoffman model", "text": "Maas–Hoffman model\n\nThe Maas–Hoffman model is a mathematical tool to characterize the relation between crop production and soil salinity. It describes the crop response by a broken line of which the first part is horizontal and the second is sloping downward. The \"breakpoint\" (Pb) or \"threshold\" is also called \"tolerance\" because up to that point the yield is unaffected by the salinity, so the salt is tolerated, while at greater salinity values the crops are affected negatively and the yield goes down.\n\nMathematically the two lines are represented by the equations:\n\nwhere \"Y\" = crop production or yield, \"C\" = maximum yield, \"X\" = soil salinity, \"A\" = slope (regression coefficient) of the descending line, and \"B\" = regression constant of that line.\n\nIn the example of the figure: \"C\" = 1.2, \"A\" = —0.10, Pb = 7.0\n\nThe value of Pb is to be found by regression analysis and optimization so that the goodness of fit of the data to the model is maximum.\n\nThe Maas–Hoffman model is used in crop tolerance to seawater.\n\nFor growth factors, like the depth of the watertable, that affect crop production negatively at low values while there is no effect at high values, the inverted Maas–Hoffman model can be used.\n\n"}
{"id": "2923194", "url": "https://en.wikipedia.org/wiki?curid=2923194", "title": "Off-the-grid", "text": "Off-the-grid\n\nOff-the-grid is a system and lifestyle designed to help people function without the support of remote infrastructure, such as an electrical grid. In electricity, off-grid can be stand-alone power system or mini-grids typically to provide a smaller community with electricity.\n\n\"Off-grid electrification\" is an approach to access electricity used in countries and areas with little access to electricity, due to scattered or distant population. The term off-the-grid (OTG) can refer to living in a self-sufficient manner without reliance on one or more public utilities. Namely the electrical grid. People who adopt this lifestyle are called \"off-gridders\".\n\nOff-the-grid homes aim to achieve autonomy; they do not rely on one or more of municipal water supply, sewer, gas, electrical power grid, or similar utility services. A common misconception is that a true off-grid house is able to operate completely independently of all traditional public utility services. Although this is not the case. The term \"off the grid\" traditionally refers to the electrical grid only.\n\nThe idea has been recently popularized by certain celebrities including Ed Begley, Jr. who stars in the \"Living with Ed\" television show on the Home & Garden Television (HGTV) network. Actress Daryl Hannah promotes off-grid living and constructed her home in Colorado according to those principles, as does survival expert and \"Dual Survival\" co-star Cody Lundin, who lives in a self-designed, passive solar earth house in the high-desert wilderness of Northern Arizona, collecting rainwater, composting waste, and paying nothing for utilities.\n\nElectrical power can be generated on-site with renewable energy sources such as solar (particularly with photovoltaics), wind, micro hydro, geothermal; with a generator or Micro combined heat and power with adequate fuel reserves. Such a system is called a stand-alone power system or sometimes referred to as a Hybrid power system. In addition, it is possible to simply eliminate electric power such as in Old Order Amish and Old Order Mennonite communities.\n\nRemote locations that are expensive to connect to main electricity grids are particularly suited for off-grid renewable energy developments, for example remote islands or tundra locations.\n\nSelf-supply of water and sanitation is possible to be independent of municipal water supply and sanitation services.\n\nOn-site water sources can include a well, stream, tank, or lake. These sources may require pumps or filtration. Rainwater can also be harvested. Filters can be advanced running off an energy source of boiling and storage.\n\nOff-the-grid houses are not connected to a sewer system, but may instead rely on various types of dry toilets, such as composting toilets or urine-diverting dry toilets.\n\nOn 13 April 2006, \"USA Today\" reported that there were \"some 180,000 families living off-grid, a figure that has jumped 33% a year for a decade,\" and cited Richard Perez, publisher of Home Power Magazine, as the source.\n\nAssuming the same rate of growth, there would be a quarter million off-grid households in the United States by late 2007. Because many Third World citizens have never had the chance to go on the grid, current estimates are that 1.7 billion people live off-grid worldwide. A wave of TV shows and articles came out after the publication of \"Off the Grid, Inside the Movement for More Space, Less Government and True Independence in Modern America\" by Nick Rosen in 2010.\n\n The concept of a sustainable off-grid community must take into consideration the basic needs of all who live in the community. To become truly self-sufficient, the community would need to provide all of its own electrical power, food, shelter and water. Using renewable energy, an on-site water source, sustainable agriculture and vertical farming techniques is paramount in taking a community off the grid. A recent concept design by Eric Wichman shows a multi-family community, which combines all of these technologies into one self-sufficient neighborhood. To grow the community you simply add neighborhoods using the same model as the first. A self-sustained community reduces its impact on the environment by controlling its waste and carbon footprint.\n\nThe State of California is encouraging solar and wind power generation that is connected to the electrical grid to avoid the use of toxic lead acid batteries for night time storage. Grid-tie systems are generally less expensive than off-grid systems due to the lack of additional equipment like charge controllers and the batteries. However, some systems may mitigate this difference by using old car batteries that can no longer supply enough current to start a car.\n\nIt is often done to residential buildings only occasionally occupied, such as vacation cabins, to avoid high initial costs of traditional utility connections. Other persons choose to live in houses where the cost of outside utilities is prohibitive, or such a distance away as to be impractical. In his book \"How to live off-grid\" Nick Rosen lists seven reasons for going off-grid. The top two are saving money, and reducing the carbon footprint. Others include survivalists, preparing for the collapse of the oil economy and bringing life back to the countryside.\n\nCanada has about 175 aboriginal and northern off-grid communities, defined as \"a community that is neither connected to the North American electrical grid nor to the piped natural gas network; it is permanent or long-term (5 years or more), and the settlements have at least 10 permanent buildings.\"\nAboriginal Affairs and Northern Development Canada lists the following environmental concerns for these off-grid communities:\n\nIn situations where grid parity has been reached, it becomes cheaper to generate one's own electricity rather than purchasing it from the grid. This depends on equipment costs, the availability of renewable energy sources (wind, sun), and the cost of a grid connection. For example, in certain remote areas a grid connection would be prohibitively expensive, resulting in grid parity being reached immediately.\n\nThe photovoltaic off-grid market has been researched by international institutes, universities and market research companies. The cumulative installed PV capacity is estimated in 2010 between 1 and 2 GW depending on the source. The market research company Infinergia has gone further by mapping national cumulative installed off-grid PV capacity on 100 countries worldwide.\n\nIn Africa, small and inexpensive pico solar electric lights and solar home systems are becoming readily available. Inexpensive solar panels, lithium ion batteries and high-efficiency LED lights make the systems affordable.\n\n"}
{"id": "14162739", "url": "https://en.wikipedia.org/wiki?curid=14162739", "title": "Oscillator strength", "text": "Oscillator strength\n\nIn spectroscopy, oscillator strength is a dimensionless quantity that expresses the probability of absorption or emission of electromagnetic radiation in transitions between energy levels of an atom or molecule. The oscillator strength can be thought of as the ratio between the quantum mechanical transition rate and the classical absorption/emission rate of a single electron oscillator with the same frequency as the transition.\n\nAn atom or a molecule can absorb light and undergo a transition from\none quantum state to another.\n\nThe oscillator strength formula_1 of a transition from a lower state\nformula_2 to an upper state formula_3 may be defined by\nwhere formula_5 is the mass of an electron and formula_6 is\nthe reduced Planck constant. The quantum states formula_7 1,2, are assumed to have several\ndegenerate sub-states, which are labeled by formula_8. \"Degenerate\" means\nthat they all have the same energy formula_9.\nThe operator formula_10 is the sum of the x-coordinates formula_11\nof all formula_12 electrons in the system, etc.:\nThe oscillator strength is the same for each sub-state formula_14.\n\nTo make equations of the previous section applicable to the states belonging to the continuum spectrum, they should be rewritten in terms of matrix elements of the momentum formula_15. In absence of magnetic field, the Hamiltonian can be written as formula_16, and calculating a commutator formula_17 in the basis of eigenfunctions of formula_18 results in the relation between matrix elements\n\nNext, calculating matrix elements of a commutator formula_20 in the same basis and eliminating matrix elements of formula_21, we arrive at\n\nBecause formula_23, the above expression results in a sum rule\n\nwhere formula_25 are oscillator strengths for quantum transitions between the states formula_26 and formula_27. This is the Thomas-Reiche-Kuhn sum rule, and the term with formula_28 has been omitted because in confined systems such as atoms or molecules the diagonal matrix element formula_29 due to the time inversion symmetry of the Hamiltonian formula_18. Excluding this term eliminates divergency because of the vanishing denominator.\n\nIn crystals, energy spectrum of electrons has a band structure formula_31. Near the minimum of an isotropic energy band, electron energy can be expanded in powers of formula_15 as formula_33 where formula_34 is the electron effective mass. It can be shown that it satisfies the equation\n\nHere the sum runs over all bands with formula_36. Therefore, the ratio formula_37 of the free electron mass formula_38 to its effective mass formula_34 in a crystal can be considered as the oscillator strength for the transition of an electron from the quantum state at the bottom of the formula_26 band into the same state.\n\n"}
{"id": "15533919", "url": "https://en.wikipedia.org/wiki?curid=15533919", "title": "Peter Crawford (filmmaker)", "text": "Peter Crawford (filmmaker)\n\nPeter Crawford is a British award-winning, freelance film-maker, author and lecturer. \n\nPeter Crawford is perhaps best known for his natural history documentary films and TV series in the United Kingdom and United States including, in 1990, the first television series to attempt to comprehensively document North America's wildlife, \"Land of the Eagle\" (WNET New York) and in 1999; \"Living Britain\" (BBC 2), a series of ten 30 minute films which portrayed the natural history of Great Britain and Ireland. \"Living Britain\" was accompanied by a book written by Peter Crawford which became a Number 1 Best Seller for BBC Books.\n\nAlthough Peter Crawford is now freelance and specialises in lecturing and writing on Polynesia and the people and wildlife of the Pacific Ocean, he spent most of his career working in the world-renowned BBC Natural History Unit. Whilst there he was instrumental in bringing, via the television screen, a new-found interest in environmentalism and the relationship of people and the natural world to the living rooms of the United Kingdom.\n\nHe pioneered new ways of bringing natural history and environmental issues to wide audiences. 'World Safari' and 'Global Sunrise' highlighted his ambitious style of presentation.\n\nPeter Crawford studied Zoology and Marine Biology at the University of Exeter in England and made further studies in Anthropology at the University of Mainz in Germany. In 2008, he was appointed Honorary Visiting Professor at his Alma Mater - Exeter University.\n\n\n\n\n\n"}
{"id": "33880265", "url": "https://en.wikipedia.org/wiki?curid=33880265", "title": "Potamides", "text": "Potamides\n\nPotamides (; Greek: Ποταμίδες) were a type of water nymphs of Greco-Roman mythology. They were assigned as a class of nymphs of fresh water known as naiads, and as such belonged to a category that presided over rivers and streams.\n\nPotamides were identified by the names associated with the rivers of their origin such as the \"Anigrides\", \"Ismenides\", \"Amnisiades\", the \"Pactolides\" from the Pactolus river, and the \"Acheloides\" from the Achelous river. However they had their individual names and also sometimes could be distinguished by the name of the country in which they inhabited.\n\nThe rivers were the domains of potamides as well as of the nymphs \"Fluviales\". Every creek had its potamide, who as local divinities, and like all the naiads, were daughters of the gods of rivers, also called \"Potamoi\" deities. Even the rivers of the marshy regions are described as having their nymphs; hence no exception was made to the waters of Greek underworld ruled by god Hades, as was quoted in Latin: \"Nymphae infernae paludis and Avernales\", which means \"swampy \"Avernales\", the infernal nymphs\". And many of these hellish potamides, the \"Avernales\", were believed to be owners of prophetic ability, and to express that gift to their chosen men.\n\nLike any nymph, potamides were considered subject to mortality but with a long life. For the Greek historian Plutarch their term of life reached about 9720 years, and according to Greek poet Hesiod there were about three thousand nymphs wandering on the world, and their lives lasted several thousand years.\n\nPotamides showed themselves very favorably inclined to young girls, and gently removed the freckles from all who bathed in their streams. On the other hand, they had an aggressive behavior directed at young men coming near their watery territories, whom they dragged down to their abodes. It was believed by the ancients that they carried water for their river parents, as was quoted: \"In the lonely hour of noon the naiads sat with their water-pitcher at the spring-sending forth from it the warbling brook.\"\n\nRegarded as a profuse class of minor female divinities, they were believed to inspire those that drank of their waters. Thus potamides, and nymphs in general, were conceived to be endowed with oracular power, to inspire men with the same prophetic gift, and to bestow upon them the natural talent of poetry. Hence, as water is a necessity to all the creation, the water nymphs, along with the gods Dionysus and Demeter, were also worshipped as providing life and blessings to all existing beings, and this attribute is manifested by a diversity of epithets.\n\nAccordingly, in many parts of Greece, offerings of honey, oil, milk, but never of wine, and sometimes sacrifices of a lamb or goat were presented to these divinities. In Sicily was commemorated an annual celebration in their honor. Although they had no temples, the most beautiful spots in forests, gardens and so forth, were regarded as the favorite places of nymphs and invisible spirits, and thus esteemed with special veneration.\n"}
{"id": "620735", "url": "https://en.wikipedia.org/wiki?curid=620735", "title": "Qu Yuan", "text": "Qu Yuan\n\nQu Yuan (–278 BC) was a Chinese poet and minister who lived during the Warring States period of ancient China. He is known for his patriotism and contributions to classical poetry and verses, especially through the poems of the \"Chu Ci\" anthology (also known as \"The Songs of the South\" or \"Songs of Chu\"): a volume of poems attributed to or considered to be inspired by his verse writing. Together with the \"Shi Jing\", the \"Chu Ci\" is one of the two greatest collections of ancient Chinese verse. He is also remembered in connection to the supposed origin of the Dragon Boat Festival.\n\nHistorical details about Qu Yuan's life are few, and his authorship of many \"Chu Ci\" poems has been questioned at length. However, he is widely accepted to have written \"Li Sao\", the most well-known of the \"Chu Ci\" poems. The first known reference to Qu Yuan appears in a poem written in 174 BC by Jia Yi, an official from Luoyang who was slandered by jealous officials and banished to Changsha by Emperor Wen of Han. While traveling, he wrote a poem describing the similar fate of a previous \"Qu Yuan.\" Eighty years later, the first known biography of Qu Yuan's life appeared in Han dynasty historian Sima Qian's \"Records of the Grand Historian\", though it contains a number of contradictory details.\nSima Qian's biography of Qu Yuan in the \"Records of the Grand Historian (Shiji)\", though circumstantial and probably influenced greatly by Sima's own identification with Qu, is the only source of information on Qu's life. Sima wrote that Qu was a member of the Chu royal clan and served as an official under King Huai of Chu (reigned 328–299 BC).\n\nDuring the early days of King Huai's reign, Qu Yuan was serving the State of Chu as its Left Minister. However, King Huai exiled Qu Yuan to the region north of the Han River, because corrupt ministers slandered him and influenced the king. Eventually, Qu Yuan was reinstated and sent on a diplomatic mission to the State of Qi. He tried to resume relations between Chu and Qi, which King Huai had broken under the false pretense of King Hui of Qin to cede territory near Shangyu.\n\nDuring King Qingxiang's reign, Prime Minister Zilan slandered Qu Yuan. This caused Qu Yuan's exile to the regions south of the Yangtze River. It is said that Qu Yuan returned first to his home town. In his exile, he spent much of this time collecting legends and rearranging folk odes while traveling the countryside. Furthermore, he wrote some of the greatest poetry in Chinese literature and expressed deep concerns about his state. According to legend, his anxiety brought him to an increasingly troubled state of health. During his depression, he would often take walks near a certain well to look upon his thin and gaunt reflection in the water. This well became known as the \"Face Reflection Well.\" On a hillside in Xiangluping (at present-day Zigui County, Hubei Province), there is a well that is considered to be the original well from the time of Qu Yuan.\n\nIn 278 BC, learning of the capture of his country's capital, Ying, by General Bai Qi of the state of Qin, Qu Yuan is said to have collected folktales and written the lengthy poem of lamentation called \"Lament for Ying\". Eventually, he committed suicide by wading into the Miluo River in today's Hubei Province while holding a rock. The reason why he took his life remained controversial and was argued by Chinese scholars for centuries. Typical explanations including martyrdom for his deeply beloved but falling motherland, which was suggested by the philosopher Zhu Xi of Song Dynasty, or feeling extreme despair to the situation of the politics in Chu while his lifelong political dream would never be realized. But according to Yu Fu, widely considered to be written by Qu himself or at least, a person who was very familiar with Qu, his suicide was an ultimate way to protect his innocence and life principles.\n\nQu Yuan is regarded as the first author of verse in China to have his name associated to his work, since prior to that time, poetic works were not attributed to any specific authors. He is considered to have initiated the so-called \"sao\" style of verse, which is named after his work \"Li Sao\", in which he abandoned the classic four-character verses used in poems of \"Shi Jing\" and adopted verses with varying lengths. This resulted in poems with more rhythm and latitude in expression. Qu Yuan is also regarded as one of the most prominent figures of Romanticism in Chinese classical literature, and his masterpieces influenced some of the greatest Romanticist poets in Tang Dynasty such as Li Bai. During the Han Dynasty, Qu Yuan became established as a heroic example of how a scholar and official who was denied public recognition suitable to their worth should behave.\n\nChu was located in what is now the Yangzi River area of central China. At this time, Chu represented the southern fringe of the Chinese cultural area, having for a time been part of both the Shang dynasty and the Zhou dynasty empires; however, the Chu culture also retained certain characteristics of local traditions such as shamanism, the influence of which can be seen in the \"Chu Ci\".\n\nThe \"Chu Ci\" was compiled and annotated by Wang Yi (died AD 158), which is the source of transmission of these poems and any reliable information about them to subsequent times; thus, the role which Qu Yuan had in the authoring, editing, or retouching of these works remains unclear. The \"Chu Ci\" poems are important as being direct precursors of the \"fu style\" of Han Dynasty literature. The \"Chu Ci\", as a preservation of early literature, has provided invaluable data for linguistic research into the history of the Chinese language, from Chen Di on.\n\nFollowing his suicide, Qu Yuan was sometimes revered as a water god, including by Taiwanese Taoists, who number him among the Kings of the Water Immortals.\n\nQu Yuan began to be treated in a nationalist way as \"China's first patriotic poet\" during World War II. Wen Yiduo—a socialist poet and scholar later executed by the KMT—wrote in his \"Mythology & Poetry\" that, \"although Qu Yuan did not write about the life of the people or voice their sufferings, he may truthfully be said to have acted as the leader of a people's revolution and to have struck a blow to avenge them. Qu Yuan is the only person in the whole of Chinese history who is fully entitled to be called 'the people's poet'.\" Guo Moruo's 1942 play \"Qu Yuan\" gave him similar treatment, drawing parallels to \"Hamlet\" and \"King Lear\". Their view of Qu's social idealism and unbending patriotism became canonical under the People's Republic of China after the 1949 Communist victory in the Chinese Civil War. For example, one high-school Chinese textbook from 1957 began with the sentence \"Qu Yuan was the first great patriotic poet in the history of our country's literature\". This cult status increased Qu Yuan's position within China's literary canon, seeing him placed on postage stamps since the 1950s and the Dragon Boat Festival elevated to a national holiday in 2005. It has, however, come at the expense of more the critical scholarly appraisals of Qu Yuan's historicity and alleged body of work that had developed during the late Qing and early Republic.\n\nPopular legend has it that villagers carried their dumplings and boats to the middle of the river and desperately tried to save Qu Yuan after he immersed himself in the Miluo but were too late to do so. However, in order to keep fish and evil spirits away from his body, they beat drums and splashed the water with their paddles, and they also threw rice into the water both as a food offering to Qu Yuan's spirit and also to distract the fish away from his body. However, the legend continues, that late one night, the spirit of Qu Yuan appeared before his friends and told them that he died because he had taken himself under the river. Then, he asked his friends to wrap their rice into three-cornered silk packages to ward off the dragon.\n\nThese packages became a traditional food known as \"zongzi\", although the lumps of rice are now wrapped in leaves instead of silk. The act of racing to search for his body in boats gradually became the cultural tradition of dragon boat racing, held on the anniversary of his death every year. Today, people still eat \"zongzi\" and participate in dragon boat races to commemorate Qu Yuan's sacrifice on the fifth day of the fifth month of the traditional lunisolar Chinese calendar. The countries around China, such as Vietnam and Korea, also celebrate variations of this Dragon Boat Festival as part of their shared cultural heritage.\n\n\n\n"}
{"id": "1494813", "url": "https://en.wikipedia.org/wiki?curid=1494813", "title": "Ramsauer–Townsend effect", "text": "Ramsauer–Townsend effect\n\nThe Ramsauer–Townsend effect, also sometimes called the Ramsauer effect or the Townsend effect, is a physical phenomenon involving the scattering of low-energy electrons by atoms of a noble gas. Since its explanation requires the wave theory of quantum mechanics, it demonstrates the need for physical theories more sophisticated than those of Newtonian physics.\n\nWhen an electron moves through a gas, its interactions with the gas atoms cause scattering to occur. These interactions are classified as \"inelastic\" if they cause excitation or ionization of the atom to occur and \"elastic\" if they do not.\n\nThe \"probability of scattering\" in such a system is defined as the number of electrons scattered, per unit electron current, per unit path length, per unit pressure at 0 °C, per unit solid angle. The \"number of collisions\" equals the total number of electrons scattered elastically and inelastically in all angles, and the \"probability of collision\" is the total number of collisions, per unit electron current, per unit path length, per unit pressure at 0 °C.\n\nBecause noble gas atoms have a relatively high first ionization energy and the electrons do not carry enough energy to cause excited electronic states, ionization and excitation of the atom are unlikely, and the probability of elastic scattering over all angles is approximately equal to the probability of collision.\n\nThe effect is named for Carl Ramsauer (1879-1955) and John Sealy Townsend (1868-1957), who each independently studied the collisions between atoms and low-energy electrons in the early 1920s.\n\nIf one tries to predict the probability of collision with a classical model that treats the electron and atom as hard spheres, one finds that the probability of collision should be independent of the incident electron energy (see Kukolich). However, Ramsauer and Townsend observed that for slow-moving electrons in argon, krypton, or xenon, the probability of collision between the electrons and gas atoms obtains a minimum value for electrons with a certain amount of kinetic energy (about 1 electron volts for xenon gas). This is the Ramsauer–Townsend effect.\n\nNo good explanation for the phenomenon existed until the introduction of quantum mechanics, which explains that the effect results from the wave-like properties of the electron. A simple model of the collision that makes use of wave theory can predict the existence of the Ramsauer-Townsend minimum. Bohm presents one such model that considers the atom as a finite square potential well.\n\nPredicting from theory the kinetic energy that will produce a Ramsauer-Townsend minimum is quite complicated since the problem involves understanding the wave nature of particles. However, the problem has been extensively investigated both experimentally and theoretically and is well understood (see Johnson and Guet).\n\nIn 1970 Gryzinski has proposed classical explanation of Ramsauer effect using effective picture of atom as oscillating multipole of electric field (dipole, quadrupole, octupole), which was a consequence of his free-fall atomic model.\n\n"}
{"id": "30870968", "url": "https://en.wikipedia.org/wiki?curid=30870968", "title": "Shadow blister effect", "text": "Shadow blister effect\n\nThe shadow blister effect is a visual effect whereby adjacent shadows appear to bulge (or blister) towards one another when cast by one or more non-point light sources. It is the result of overlapping shadow penumbra on the surface and the perception by the brain of a contrast barrier formed by the merging of the penumbra. The visual effect is proportionate to the distance of the obstructions to the shadow surface (as the penumbras become larger), as well as the angular diameter of the light source(s). Penumbras can be easily demonstrated using Ray Theory.\n\nThis effect is commonly visible on Earth by shadows cast by the sun. A common example is the shadows of leaves on the ground which are fuzzy and seem to bulge to one another, however any two objects held at an average human's height from the ground can produce this effect.\n\nThe appearance of the shadow blister may be more striking as the mind perceives a contrast line within the linear distribution of light within the penumbra (the shadow's blister).\n\n"}
{"id": "59046", "url": "https://en.wikipedia.org/wiki?curid=59046", "title": "Silly Putty", "text": "Silly Putty\n\nSilly Putty is a toy based on silicone polymers that have unusual physical properties. It bounces, but it breaks when given a sharp blow, and it can also flow like a liquid. It contains a viscoelastic liquid silicone, a type of non-Newtonian fluid, which makes it act as a viscous liquid over a long time period but as an elastic solid over a short time period. It was originally created during research into potential rubber substitutes for use by the United States in World War II.\nThe name \"Silly Putty\" is a trademark of Crayola LLC. Other names are used to market similar substances from other manufacturers.\n\nAs a bouncing putty, Silly Putty is noted for its unusual characteristics: it bounces but breaks when given a sharp blow; it can also float in a liquid and will form a puddle given enough time. Silly Putty and most other retail putty products have viscoelastic agents added to reduce the flow and enable the putty to hold its shape.\n\nThe original coral-colored Silly Putty is composed of 65% dimethylsiloxane (hydroxy-terminated polymers with boric acid), 17% silica (crystalline quartz), 9% Thixatrol ST (castor oil derivative), 4% polydimethylsiloxane, 1% decamethyl cyclopentasiloxane, 1% glycerine, and 1% titanium dioxide.\n\nSilly Putty's unusual flow characteristics are due to the ingredient polydimethylsiloxane (PDMS), a viscoelastic substance. Viscoelasticity is a type of non-Newtonian flow, characterizing material that acts as a viscous liquid over a long time period but as an elastic solid over a short time period. Because its apparent viscosity increases directly with respect to the amount of force applied, Silly Putty can be characterized as a dilatant fluid.\n\nSilly Putty is also a fairly good adhesive. When newspaper ink was petroleum based, Silly Putty could be used to transfer newspaper images to other surfaces, providing amusement by distorting the transferred image afterwards. Newer papers with soy-based inks are more resistant to this process.\n\nGenerally, Silly Putty is difficult to remove from textured items such as hair and clothing. Hand sanitizers containing alcohol are often helpful. Silly Putty will dissolve when in contact with an alcohol; after the alcohol evaporates, the material will not exhibit its original properties. The maker, Crayola, suggests WD-40.\n\nIf Silly Putty is submerged in warm or hot water, it will become softer and thus \"melt\" much faster. It also becomes harder to remove small amounts of it from surfaces. After a long period of time, it will return to its original viscosity.\n\nSilly Putty is sold as a piece of clay inside an egg-shaped plastic container. The Silly Putty brand is owned by Crayola LLC (formerly the Binney & Smith company). , twenty thousand eggs of Silly Putty are sold daily. Since 1950, more than 300 million eggs of Silly Putty (approximately ) have been sold. It is available in various colors, including glow-in-the-dark and metallic. Other brands offer similar materials, sometimes in larger-sized containers, and in a similarly wide variety of colors or with different properties, such as magnetism and iridescence.\n\nDuring World War II, Japan invaded rubber-producing countries as it expanded its sphere of influence in the Pacific Rim. Rubber was vital for the production of rafts, tires, vehicle and aircraft parts, gas masks, and boots. In the US, all rubber products were rationed; citizens were encouraged to make their rubber products last until the end of the war and to donate spare tires, boots, and coats. Meanwhile, the government funded research into synthetic rubber compounds to attempt to solve this shortage.\n\nCredit for the invention of Silly Putty is disputed and has been attributed variously to Earl Warrick of the then newly formed Dow Corning; Harvey Chin; and James Wright, a Scottish-born inventor working for General Electric in New Haven, Connecticut. Throughout his life, Warrick insisted that he and his colleague, Rob Roy McGregor, received the patent for Silly Putty before Wright did; but Crayola's history of Silly Putty states that Wright first invented it in 1943. Both researchers independently discovered that reacting boric acid with silicone oil would produce a gooey, bouncy material with several unique properties. The non-toxic putty would bounce when dropped, could stretch farther than regular rubber, would not go moldy, and had a very high melting temperature. However, the substance did not have all the properties needed to replace rubber.\n\nIn 1949, toy store owner Ruth Fallgatter came across the putty. She contacted marketing consultant Peter C.L. Hodgson (1912–1976). The two decided to market the bouncing putty by selling it in a clear case. Although it sold well, Fallgatter did not pursue it further. However, Hodgson saw its potential.\n\nAlready US$12,000 in debt, Hodgson borrowed US$147 to buy a batch of the putty to pack portions into plastic eggs for US$1, calling it Silly Putty. Initially, sales were poor, but after a \"New Yorker\" article mentioned it, Hodgson sold over 250,000 eggs of silly putty in three days. However, Hodgson was almost put out of business in 1951 by the Korean War. Silicone, the main ingredient in silly putty, was put on ration, harming his business. A year later, the restriction on silicone was lifted and the production of Silly Putty resumed. Initially, it was primarily targeted towards adults. However, by 1955, the majority of its customers were aged 6 to 12. In 1957, Hodgson produced the first televised commercial for Silly Putty, which aired during the \"Howdy Doody Show\".\n\nIn 1961, Silly Putty went worldwide, becoming a hit in the Soviet Union and Europe. In 1968, it was taken into lunar orbit by the Apollo 8 astronauts.\n\nPeter Hodgson died in 1976. A year later, Binney & Smith, the makers of Crayola products, acquired the rights to Silly Putty. , annual Silly Putty sales exceeded six million eggs.\n\nSilly Putty was inducted into the National Toy Hall of Fame on May 28, 2001.\n\nIn addition to its success as a toy, other uses for the putty have been found. In the home, it can be used to remove substances such as dirt, lint, pet hair, or ink from various surfaces. The material's unique properties have found niche use in medical and scientific applications. Physical therapists use it for rehabilitative therapy of hand injuries. A number of other brands (such as \"Power Putty\" and \"TheraPutty\") alter the material's properties, offering different levels of resistance. The material is also used as a tool to help reduce stress, and exists in various viscosities based on the user's preference.\n\nBecause of its adhesive characteristics, it was used by Apollo astronauts to secure their tools in zero-gravity. Scale model building hobbyists use the putty as a masking medium when spray painting model assemblies. The Steward Observatory uses a Silly-Putty backed lap to grind astronomical telescope mirrors.\n\nResearchers from Trinity College Dublin School of Physics (Centre for Research on Adaptive Nanostructures and Nanodevices (CRANN) and Advanced Materials and Bioengineering Research (AMBER) Research Centers) have discovered nano composite mixtures of graphene and Silly Putty behave as surprisingly sensitive pressure sensors, claiming the ability to measure the footsteps of a spider crawling on it.\n\n\n"}
{"id": "9083935", "url": "https://en.wikipedia.org/wiki?curid=9083935", "title": "Submarine earthquake", "text": "Submarine earthquake\n\nA submarine, undersea, or underwater earthquake is an earthquake that occurs underwater at the bottom of a body of water, especially an ocean. They are the leading cause of tsunamis. The magnitude can be measured scientifically by the use of the moment magnitude scale and the intensity can be assigned using the Mercalli intensity scale.\n\nUnderstanding plate tectonics helps to explain the cause of submarine earthquakes. The Earth's surface or lithosphere comprises tectonic plates which average approximately 50 miles in thickness, and are continuously moving very slowly upon a bed of magma in the asthenosphere and inner mantle. The plates converge upon one another, and one subducts below the other, or, where there is only shear stress, move horizontally past each other (see transform plate boundary below). Little movements called fault creep are minor and not measurable. The plates meet with each other, and if rough spots cause the movement to stop at the edges, the motion of the plates continue. When the rough spots can no longer hold, the sudden release of the built-up motion releases, and the sudden movement under the sea floor causes a submarine earthquake. This area of slippage both horizontally and vertically is called the epicenter, and has the highest magnitude, and causes the greatest damage.\n\nAs with a continental earthquake the severity of the damage is not often caused by the earthquake at the rift zone, but rather by events which are triggered by the earthquake. Where a continental earthquake will cause damage and loss of life on land from fires, damaged structures, and flying objects; a submarine earthquake alters the seabed, resulting in a series of waves, and depending on the length and magnitude of the earthquake, tsunami, which bear down on coastal cities causing property damage and loss of life.\n\nSubmarine earthquakes can also damage submarine communications cables, leading to widespread disruption of the Internet and international telephone network in those areas. This is particularly common in Asia, where many submarine links cross submarine earthquake zones such as the Pacific Ring of Fire.\n\nThe different ways in which tectonic plates rub against each other under the ocean or sea floor to create submarine earthquakes. The type of friction created may be due to the characteristic of the geologic fault or the plate boundary as follows. Some of the main areas of large tsunami producing submarine earthquakes are the Pacific Ring of Fire and the Great Sumatran fault.\n\nThe older, and denser plate moves below the lighter plate. The further down it moves, the hotter it becomes, until finally melting altogether at the asthenosphere and inner mantle and the crust is actually destroyed. The location where the two oceanic plates actually meet become deeper and deeper creating trenches with each successive action. There is an interplay of various densities of lithosphere rock, asthenosphere magma, cooling ocean water and plate movement for example the Pacific Ring of Fire. Therefore, the site of the sub oceanic trench will be a site of submarine earthquakes; for example the Mariana Trench, Puerto Rico Trench, and the volcanic arc along the Great Sumatran fault.\n\nA transform-fault boundary, or simply a transform boundary is where two plates will slide past each other, and the irregular pattern of their edges may catch on each other. The lithosphere is neither added to from the asthenosphere nor is it destroyed as in convergent plate action. For example, along the San Andreas fault strike-slip fault zone, the Pacific Tectonic Plate has been moving along at about 5 cm/yr in a northwesterly direction, whereas the North American Plate is moving south-easterly.\n\nRising convection currents occur where two plates are moving away from each other. In the gap, thus produced hot magma rises up, meets the cooler sea water, cools, and solidifies, attaching to either or both tectonic plate edges creating an oceanic spreading ridge. When the fissure again appears, again magma will rise up, and form new lithosphere crust. If the weakness between the two plates allows the heat and pressure of the asthenosphere to build over a large amount of time, a large quantity of magma will be released pushing up on the plate edges and the magma will solidify under the newly raised plate edges, see formation of a submarine volcano. If the fissure is able to come apart because of the two plates moving apart, in a sudden movement, an earthquake tremor may be felt for example at the Mid-Atlantic Ridge between North America and Africa.\n\nThe following is a list of major submarine earthquakes since the 17th century.\n\n"}
{"id": "23141532", "url": "https://en.wikipedia.org/wiki?curid=23141532", "title": "Sverdrup wave", "text": "Sverdrup wave\n\nA Sverdrup wave (also known as Poincaré wave, or rotational gravity wave ) is a wave in the ocean, which is affected by gravity and Earth's rotation (see Coriolis effect).\n\nFor a non-rotating fluid, shallow water waves are affected only by gravity (see Gravity wave), where the phase velocity of shallow water gravity wave (\"c\") can be noted as \n\nand the group velocity (\"c\") of shallow water gravity wave can be noted as\n\nwhere \"g\" is gravity, \"λ\" is the wavelength and \"H\" is the total depth.\n\nWhen the fluid is rotating, gravity waves with a long enough wavelength (discussed below) will also be affected by rotational forces. The linearized, shallow-water equations with a constant rotation rate, \"f\", are \nwhere \"u\" and \"v\" are the horizontal velocities and \"h\" is the instantaneous height of the free surface. Using Fourier analysis, these equations can be combined to find the dispersion relation for Sverdrup waves:\nwhere \"k\" and \"l\" are the wavenumbers associated with the horizontal and vertical directions, and formula_8 is the frequency of oscillation.\n\nThere are two primary modes of interest when considering Poincaré waves:\nwhere formula_10 is the Rossby radius of deformation. In this limit, the dispersion relation reduces to the solution for a non-rotating gravity wave.\nwhich looks like inertial oscillations driven purely by rotational forces.\n\nFor a wave traveling in one direction (formula_12), the horizontal velocities are found to be equal to\nThis shows that the inclusion of rotation will cause the wave to develop oscillations at 90° to the wave propagation at the opposite phase. In general, these are elliptical orbits that depend on the relative strength of gravity and rotation. In the long wave limit, these are circular orbits characterized by inertial oscillations.\n\n"}
{"id": "8412193", "url": "https://en.wikipedia.org/wiki?curid=8412193", "title": "The Breadknife", "text": "The Breadknife\n\nThe Breadknife is a volcanic dyke in New South Wales, Australia. It is nearly 90 metres high, but often is only 4 m wide, which is particularly rare. The Breadknife was part of a large shield volcano, that first erupted about 17 million years ago and stopped about 13 million years ago. It is composed of peralkaline trachyte.\n\nNearby volcanic remnants include the Belougery Spire, Belougery Split Rock, Crater Bluff, Bluff Mountain and Mount Exmouth. A network of walking tracks are used to access the steep mountains and ridges surrounding the dyke. The shortest walk completely around the Breadknife is hard and steep, taking roughly five hours to complete.\n\nA huge shield-shaped volcano formed as volcanic explosions occurred over millions of years. This shield volcano rose about 1,000 m and is now largely eroded, forming the Warrumbungles. The Breadknife was formed when hot magma spread through a soft rock. When the magma solidified and became harder than the soft rock, erosion exposed a dyke. \n\nThe village in the Animated series Adventures of the Little Koala took place within the shadow of the Breadknife.\n\n"}
{"id": "17545414", "url": "https://en.wikipedia.org/wiki?curid=17545414", "title": "The budgetary rule", "text": "The budgetary rule\n\nThe budgetary rule () is a rule concerning the usage of capital gains from The Government Pension Fund - Global of Norway. The rule states that a maximum of 3% of the fund's value should be allocated to the yearly government budget. Its main stated justification is to avoid the Dutch disease in the Norwegian economy due to the large influx of oil-sourced revenue. \n\nThe rule was introduced in 2001 during the First cabinet Stoltenberg, and has a broad cross-party support. \n\nThe rule was last changed from 4% to 3% february 2017. Every party in the parliament was in favour of the change, except the right wing Progress Party (Norway).\n\n"}
{"id": "24173968", "url": "https://en.wikipedia.org/wiki?curid=24173968", "title": "The profitable arte of gardening", "text": "The profitable arte of gardening\n\nThe profitable arte of gardening was the first book about gardening published in England, being first published in 1563 under the title A most briefe and pleasaunte treatise, teaching how to dresse, sowe, and set a garden. It was written by Thomas Hill who went on to write the even more successful work, \"The Gardener's Labyrinth\".\n\nTo protect against hail, the book advised hanging the skin of a crocodile, hyena or seal.\n"}
{"id": "1855209", "url": "https://en.wikipedia.org/wiki?curid=1855209", "title": "Trindade and Martin Vaz", "text": "Trindade and Martin Vaz\n\nTrindade and Martin Vaz (, ) is an archipelago located in the Southern Atlantic Ocean about east of the coast of Espírito Santo, Brazil, which it constitutes a part of. The archipelago has a total area of and a population of 32 (Brazilian Navy personnel). The archipelago consists of five islands and several rocks and stacks; Trindade is the largest island, with an area of ; about east of it are the tiny Martin Vaz islets, with a total area of .\n\nThe islands are of volcanic origin and have rugged terrain. They are largely barren, except for the southern part of Trindade. They were discovered in 1502 by Portuguese explorer Estêvão da Gama and stayed Portuguese until they became part of Brazil at its independence in 1822. From 1895 to 1896, Trindade was occupied by the United Kingdom until an agreement with Brazil was reached. During the period of British occupation, Trindade was known as \"South Trinidad.\"\n\nThe islands are situated some southwest of Ascension Island and west of Saint Helena, while the distance to the west coast of Africa is .\n\nThe individual islands with their respective locations are given in the following:\n\n\nThe small island of Trindade, with an area of 10.3 km², lies at the eastern end of an E-W-trending chain of submarine volcanoes and guyots extending about 1,000 km (620 mi) from the continental shelf off the Brazilian coast. The island lies more than halfway between Brazil and the Mid-Atlantic Ridge near the eastern end of the submarine Vitória-Trindade Ridge.\n\nTrindade is a mountainous, desiccated volcanic island with numerous phonolitic lava domes and steep-sided volcanic plugs. The highest summit is Pico Desejado, near the center, high. Nearby to the northwest are Pico da Trindade () and Pico Bonifácio (). Pico Monumento, a remarkable peak in the form of a slightly inclined cylinder, rises from the west coast to . The youngest volcanism, at Vulcão do Paredão () on the southeast tip of the island, constructed a pyroclastic cone with lava flows that are no older than the Holocene (Almeida, 1961). Remnants of the crater of the cinder cone are still preserved. Lava flows traveled from the cone to the north, where they formed an irregular shoreline and offshore islands. Smaller volcanic centers of the latest volcanic stage are found in the Morro Vermelho () area in the south-central part of the island.\n\nUntil 1850, the island was covered 85% of its length by a forest of \"Colubrina glandulosa\" trees, 15m in height and 40 cm trunk diameter. The introduction of non-native animals like goats, pigs, sheep, etc. and the indiscriminate cutting of trees led to total extirpation of the same, causing heavy erosion throughout the island with a loss of about 1 to 2 meter of fertile soils. The effect of this devastation impaired the flow of water streams, with the depletion of several springs.\n\nThere is a small settlement in the north on the shore of a cove called Enseada dos Portugueses, supporting a garrison of the Brazilian Navy, 32 strong.\n\nThe archipelago is the main nesting site of the green sea turtle in Brazil. There are also large numbers of breeding seabirds, including the endemic subspecies of the Great frigatebird (\"Fregata minor nicolli\") and Lesser frigatebird (\"F. ariel trinitatis\"), and it is only Atlantic breeding site for the Trindade petrel. Humpback whales have been confirmed to use the Trindade island as a nursery.\n\nThe Trindade and Martin Vaz Islands were discovered in 1502 by Portuguese navigators led by Estêvão da Gama, and, along with Brazil, became part of the Portuguese Empire.\n\nMany visitors have been to Martin Vaz, the most famous of whom was the English astronomer Edmund Halley, who took possession of the island on behalf of the British Monarchy in 1700. Wild goats and hogs, descendants of ones set free by Halley, were still found on Martin Vaz in 1939.\n\n, a 198-ton, 12-gun cutter-rigged sloop, was wrecked on Trindade on 21 October 1781, shortly after Commander Philippe d'Auvergne had taken over command. \"Rattlesnake\" had been ordered to survey the island to ascertain whether it would make a useful base for outward-bound Indiamen. She anchored, but that evening the wind increased and by seven o’clock she was dragging. Two hours later the first cable parted and Commander d’Auvergne club-hauled his way out, setting main and fore sails, and using the remaining anchor cable as a spring. This successfully put \"Rattlesnake\"’s head to seaward. The remaining cable was then cut, and the sloop wore round and stood out to sea. However the ground now shallowed quite rapidly and suddenly \"Rattlesnake\" struck a submerged rock. She started filling with water, so, in order to preserve the lives of the crew, d'Auvergne ran her ashore. Commodore Johnstone on board had previously wished to colonise the island and claim it for Britain, so d'Auvergne agreed to stay on the tiny island with 30 sailors, 20 captured French sailors, one French woman, some animals and supplies. They were resupplied by another ship in January 1782, then they appear to have been forgotten, as they lived on the tiny island for a year until and a convoy of Indiamen, which fortuitously called there, rescued them in late December 1782.\n\nCaptain La Pérouse stopped there at the outset of his 1785 voyage to the Pacific.\n\nIn 1889, Edward Frederick Knight went treasure hunting on the island. He was unsuccessful but he wrote a detailed description of the island and his expedition, titled \"The Cruise of the Alerte\".\n\nIn 1893 another American, James Harden-Hickey, claimed the island and declared himself as James I, Prince of Trinidad. According to James Harden-Hickey's plans, Trinidad, after being recognized as an independent country, would become a military dictatorship and have him as dictator. He designed postage stamps, a national flag, and a coat of arms; established a chivalric order, the \"Cross of Trinidad\"; bought a schooner to transport colonists; appointed M. le Comte de la Boissiere as Secretary of State; opened a consular office at 217 West 36th Street in New York City; and even issued government bonds to finance construction of infrastructure on the island. Despite his plans, his idea was ridiculed or ignored by the world.\nIn July 1895, the British again tried to take possession of this strategic position in the Atlantic. The British planned to use the island as a cable station. However, Brazilian diplomatic efforts, along with Portuguese support, reinstated Trindade Island to Brazilian sovereignty.\n\nIn order to clearly demonstrate sovereignty over the island, now part of the State of Espírito Santo and the municipality of Vitória, a landmark was built on January 24, 1897. Nowadays, Brazilian presence is marked by a permanent Brazilian Navy base on the main island.\n\nIn July 1910 the ship \"Terra Nova\" carrying the last expedition of Captain Robert Falcon Scott to the Antarctic arrived at the island, at the time uninhabited. Some members of the Scott's expedition explored the island with scientific purposes, and a description of it is included in \"The Worst Journey in the World\", by Apsley Cherry-Garrard, one of the members of the expedition.\n\nIn August 1914, the Imperial German Navy established a supply base for its warships off Trindade. On September 14, 1914, the Royal Navy auxiliary cruiser fought the German off Trindade in the Battle of Trindade. \"Carmania\" sank \"Cap Trafalgar\", but sustained severe damage herself.\n\n\n\n"}
{"id": "218320", "url": "https://en.wikipedia.org/wiki?curid=218320", "title": "Ultraviolet catastrophe", "text": "Ultraviolet catastrophe\n\nThe ultraviolet catastrophe, also called the Rayleigh–Jeans catastrophe, was the prediction of late 19th century/early 20th century classical physics that an ideal black body at thermal equilibrium will emit radiation in all frequency ranges, emitting more energy as the frequency increases. By calculating the total amount of radiated energy (i.e., the sum of emissions in all frequency ranges), it can be shown that a blackbody would release an infinite amount of energy, contradicting the principles of conservation of energy and indicating that a new model for the behaviour of blackbodies was needed.\n\nThe term \"ultraviolet catastrophe\" was first used in 1911 by Paul Ehrenfest, but the concept originated with the 1900 derivation of the Rayleigh–Jeans law. The phrase refers to the fact that the Rayleigh–Jeans law accurately predicts experimental results at radiative frequencies below 10 GHz, but begins to diverge with empirical observations as these frequencies reach the ultraviolet region of the electromagnetic spectrum. Since the first appearance of the term, it has also been used for other predictions of a similar nature, as in quantum electrodynamics and such cases as ultraviolet divergence.\n\nThe ultraviolet catastrophe results from the equipartition theorem of classical statistical mechanics which states that all harmonic oscillator modes (degrees of freedom) of a system at equilibrium have an average energy of formula_1.\n\nAn example, from Mason's \"A History of the Sciences\", illustrates multi-mode vibration via a piece of string. As a natural vibrator, the string will oscillate with specific modes (the standing waves of a string in harmonic resonance), dependent on the length of the string. In classical physics, a radiator of energy will act as a natural vibrator. And, since each mode will have the same energy, most of the energy in a natural vibrator will be in the smaller wavelengths and higher frequencies, where most of the modes are.\n\nAccording to classical electromagnetism, the number of electromagnetic modes in a 3-dimensional cavity, per unit frequency, is proportional to the square of the frequency. This therefore implies that the radiated power per unit frequency should follow the Rayleigh–Jeans law, and be proportional to frequency squared. Thus, both the power at a given frequency and the total radiated power is unlimited as higher and higher frequencies are considered: this is clearly unphysical as the total radiated power of a cavity is not observed to be infinite, a point that was made independently by Einstein and by Lord Rayleigh and Sir James Jeans in 1905.\n\nMax Planck derived the correct form for the intensity spectral distribution function by making some strange (for the time) assumptions. In particular, Planck assumed that electromagnetic radiation can be emitted or absorbed only in discrete packets, called quanta, of energy: formula_2, where \"h\" is Planck's constant. Planck's assumptions led to the correct form of the spectral distribution functions: formula_3. Albert Einstein and Satyendra Nath Bose solved the problem by postulating that Planck's quanta were real physical particles — what we now call photons, not just a mathematical fiction. They modified statistical mechanics in the style of Boltzmann to an ensemble of photons. Einstein's photon had an energy proportional to its frequency and also explained an unpublished law of Stokes and the photoelectric effect. This published postulate was specifically cited by the Nobel Prize in Physics committee in their decision to award the prize for 1921 to Einstein.\n\n\n"}
{"id": "7700389", "url": "https://en.wikipedia.org/wiki?curid=7700389", "title": "White Shark Café", "text": "White Shark Café\n\nThe White Shark Café is a remote mid-Pacific Ocean area noted as a winter and spring habitat of otherwise coastal great white sharks.\n\nThe area, halfway between Baja California and Hawaii, received its unofficial name in 2002 from researchers at Stanford University's Hopkins Marine Station who were studying the great white shark species using satellite tracking tags. They identified a zone with a radius of approximately centered at approximately . The findings, which were initially published in the January 3, 2002 issue of the journal \"Nature\", showed three of four tagged sharks traveled to the Café during a six-month period after they were tagged off the central coast of California.\n\nAlthough the area had not previously been suspected as a shark habitat, when mapping the satellite tracking data, researchers discovered that members of the species frequently travel to and loiter in the area. It was once believed the area has very little food for the animals (researchers described it as the shark equivalent of a desert), but research in early 2018 by the vessel \"Falkor\" showed that there is a rich and diverse food chain too deep to be detected by satellites that provides a potentially abundant food supply for the sharks. Male, female, and juvenile great whites have been tracked there.\n\nThe sharks tracked to the area came from diverse rookeries along the North American coast. They typically took up to 100 days to arrive, traveling around , during which they make periodic dives as deep as . While at the Café, they dive to depths of as often as once every ten minutes.\n\nBy 2006, researchers had observed consistent migration and other behavior. Tracking data indicates that white sharks will leave feeding grounds near the coast in winter, travel to the Café, and some may even summer near Hawaii. But many linger in the Café, often for months, before returning to the coast in the fall, coinciding with the elephant seal breeding season (a favored prey).\n\n\n"}
{"id": "7895482", "url": "https://en.wikipedia.org/wiki?curid=7895482", "title": "Winterization", "text": "Winterization\n\nWinterization is the process of preparing something for winter.\n\nIn emergency or disaster response situations, such as managed by the UNHCR, winterization activities include the distribution of items including blankets, quilts, kerosene, heating stoves, jerry cans, as well as thermal floor mats and insulation to make tents warmer and more resistant to harsh winter conditions. \n\nSome summer homes, also known as cabins or cottages, were built for summer use only and need to be winterized each Autumn. This entails locking them up, turning off water, electricity, and phone lines, and protecting various features from heavy snowfall.\n\nIn the New England area, many wealthy families living in cities during the 19th century had summer homes in the mountains. This was to flee the onset of yellow fever and other epidemics which often struck in the summer months, when city plumbing problems and stagnant horse manure in the streets caused a health hazard. Winterization would take place each Fall when the families returned to the cities (often when school started). In those days, winterization just referred to a lock-down of all movable parts as protection from winter storms. An example of such a summer home that needs to be winterized each fall is the scene of the movie \"On Golden Pond\", which was filmed on Squam Lake.\n\nIn the 20th century, these summer mountain homes in turn were winterized to enable winter holidays, as the popularity of skiing in the mountains increased that of summer camping. In this sense, winterization refers to the addition of modern amenities such as heating and insulation, often entailing a complete rebuild of the cottage.\n\nEquipment designed for use in particularly extreme cold conditions (such as the polar regions) also undergoes a \"winterization\" process. Many complex devices (automobiles, electronics and radios) as well as common materials (metals, rubbers, petroleum lubricants) are not designed to operate at extremely low temperatures and must be winterized to operate without severe damage from the elements in such conditions. This might involve a chemical treatment process, additional waterproofing/insulation, or even the total substitution of new parts. An example would be the internal combustion engine of an automobile; the installation of heaters on the engine block and battery as well as the substitution of winter-grade coolants and lubricants allows the vehicle to start and run in sub-freezing conditions where a non-winterized engine would quickly break down.\n\nWinterization of equipment can be thought of as the winter-weather extension of ruggedization.\n\nBoats, boat lifts, PWCs, and other watercrafts needs to be properly winterized. This includes draining water from the hull, and the cooling system, inspect stern drive to remove plant life, add fuel, add oil to the engine, and clean the bilges. Thoroughly cleaning the interiors, draining any refrigerators, lock all drawers, and remove valuables. It's also important to properly shrink wrap a boat to protect from moisture, snow, ice, and debris. \n\nWatercrafts can be winterized and stored outdoors or in an indoor storage facility.\n\nSome fountains, such as the Ontario Science Centre FUNtain Hydraulophone and the flame fountain in Nathan Philips Square, are designed to run year-round by virtue of heated water, whereas others require that the water be drained and that all apertures be covered to keep rainwater from entering the fountain and freezing inside. Fountains and other water features are often drained and sealed up so that water inside does not freeze or cause breakage of the pipes in the fountain.\n\nFish ponds require several additional steps to ensure that the fish are well taken care of. A properly maintained water feature containing fish can operate even in freezing temperatures. Steps should be taken to ensure adequate cleaning of the pond from any loose debris.\n\n"}
