{"id": "55857394", "url": "https://en.wikipedia.org/wiki?curid=55857394", "title": "(163899) 2003 SD220", "text": "(163899) 2003 SD220\n\nIt passed about 28 lunar distances (LD) from the Earth on 25 December 2015. Observations are planned for favorable flybys in December 2018, 2021, 2024, and 2027.\n\nIt will pass about 7 LD (0.0189 AU) on 22 December 2018. Its peak brightness will be about 13.13 magnitude on 16 December 2018. It will pass with 14 LD (0.0363 AU) on 17 December 2021, and 34 LD (0.0884 AU) on 2 December 2024, and 54 LD (0.1382 AU) on 12 November 2027.\n\nPatrick Taylor of Arecibo Observatory suggested it could be a target for a future robotic mission.\n\nIt was observed in December 2015 at a distance of 28.3 lunar distances (0.07296 AU) on December 24, and its brightest was 15.22 magnitude on December 16. It showed an elongated shape, up to 2 km wide, described as being shaped like a sweet potato. \n\n will pass its closest distance of 7.34 LD (0.01899 AU) on 22 December 2018. It is on the list of upcoming Goldstone targets for December 2018 to gain more information for the Near-Earth Object Human Space Flight Accessible Targets Study (NHATS).\n\nIts peak brightness will be about 13.13 magnitude on 16 December 2018, moving south from Ursa major and Boötes into Ophiuchus at closest approach and into Sagittarius.\n will pass at a distance of 14.1  lunar distances (0.03628 AU) on December 17, 2021.\n\n"}
{"id": "38685708", "url": "https://en.wikipedia.org/wiki?curid=38685708", "title": "2012 KP24", "text": "2012 KP24\n\nIt was discovered on 23 May 2012 by the Mount Lemmon Survey at an apparent magnitude of 20.8 using a reflecting telescope. On 28 May 2012 at 15:20 UT, the asteroid passed from the center-point of Earth. The asteroid is estimated to be in diameter. It was removed from the Sentry Risk Table on 8 August 2013 after Sentry updated to planetary ephemeris (DE431). It has an uncertainty parameter of 6. While listed on the Sentry Risk Table, virtual clones of the asteroid that fit the uncertainty region in the known trajectory showed a 1 in 9,091,000 chance that the asteroid could impact Earth on 2032 May 28. With a Palermo Technical Scale of −7.22, the odds of impact by in 2032 were about 16 million times less than the background hazard level of Earth impacts which is defined as the average risk posed by objects of the same size or larger over the years until the date of the potential impact.\n"}
{"id": "20599992", "url": "https://en.wikipedia.org/wiki?curid=20599992", "title": "Agroecological restoration", "text": "Agroecological restoration\n\nAgroecological restoration is the practice of re-integrating natural systems into agriculture in order to maximize sustainability, ecosystem services, and biodiversity. This is one example of a way to apply the principles of agroecology to an agricultural system.\n\nFarms cannot be restored to a purely natural state because of the negative economic impact on farmers, but returning processes, such as pest control to nature with the method of intercropping, allows a farm to be more ecologically sustainable and, at the same time, economically viable. Agroecological restoration works toward this balance of sustainability and economic viability because conventional farming is not sustainable over the long run without the integration of natural systems and because the use of land for agriculture has been a driving force in creating the present world biodiversity crisis. Its efforts are complementary to, rather than a substitute for, biological conservation.\n\"...biodiversity is just as important on farms and in fields as it is in deep river valleys or mountain cloud forests.\"\nFAO, 15 October 2004\n\nAgriculture creates a conflict over the use of land between wildlife and humans. Though the domestication of crop plants occurred 10,000 years ago, a 500% increase in the amount of pasture and crop land over the last three hundred years has led to the rapid loss of natural habitats. In recent years, the world community acknowledged the value of biodiversity in treaties, such as the 1992 landmark Convention on Biological Diversity.\n\nThe reintegration of agricultural systems into more natural systems will result in decreased yield and produce a more complex system, but there will be considerable gains in biodiversity and ecosystem services.\n\nThe Food and Agriculture Organization of the United Nations estimates that more than 40% of earth’s land surface is currently used for agriculture. And because so much land has been converted to agriculture, habitat loss is recognized as the driving force in biodiversity loss (FAO). This biodiversity loss often occurred in two steps, as in the American Midwest, with the introduction of mixed farming carried out on small farms and then with the widespread use of mechanized farming and monoculture beginning after World War II. The decline in farmland biodiversity can now be traced to changes in farming practices and increased agricultural intensity.\n\nHeterogeneity (here, the diversity or complexity of the landscape) has been shown to be associated with species diversity. For example, the abundance of butterflies has been found to increase with heterogeneity. One important part of maintaining heterogeneity in the spaces between different fields is made up of habitat that is not cropped, such as grass margins and strips, scrub along field boundaries, woodland, ponds, and fallow land. These seemingly unimportant pieces of land are crucial for the biodiversity of a farm. The presence of field margins benefits many different taxa: the plants attract herbivorous insects, will which attract certain species of birds and those birds will attract their natural predators. Also, the cover provided by the no cropped habitat allows the species that need a large range to move across the landscape.\n\nIn the absence of cover, species face a landscape in which their habitat is greatly fragmented. The isolation of a species to a small habitat that it can’t safely wander from can create a genetic bottleneck, decreasing the resilience of the particular population, and be another factor leading to the decline of the total population of the species. Monoculture, the practice of producing a single crop over a wide area, causes fragmentation. In conventional farming, monoculture, such as with rotations of corn and soybean crops planted in alternating growing seasons, is used so that very high yields can be produced. After the mechanization of farming, monoculture became a standard practice in corn-beans rotation, and had broad implications for the long-term sustainability and biodiversity of farms. Whereas organic fertilizers, had kept the soil’s nutrients fixed to the ecosystem, the introduction of monoculture removed the nutrients and farmers compensated for that loss by using inorganic fertilizers. It is estimated that humans have doubled the rate of nitrogen input into the nitrogen cycle, mostly since 1975. As a result, the biological processes that controlled the way crops used the nutrients changed and the leached nitrogen from farmland soils has become a source of pollution.\n\nOrganic farming is defined in different legal terms by different nations, but its main distinction from conventional farming is that it prohibits the use of synthetic chemicals in crop and livestock production. Often, it also includes diverse crop rotations and provides non-cropped habitat for insects that provide ecosystem services, such as pest control and pollination. However, it is merely encouraged that organic farmers follow those kinds of wildlife friendly practices, and as a result there is a great difference between the ecosystem services that similarly sized but distinctly managed organic farms provide. A recent review of the 76 studies concerning the relationship between biodiversity and organic farming listed three practices associated with organic farming that accounted for the higher biodiversity counts found in organic farms as compared to conventional farms. \n\"1. \"Prohibition/reduced use of chemical pesticides and inorganic fertilizers\" is likely to have a positive impact through the removal of both direct and indirect negative effects on arable plants, invertebrates and vertebrates.\n2. \"Sympathetic management of non-crop habitats and field margins\" can enhance diversity and abundance of arable plants, invertebrates, birds and mammals.\n3. \"Preservation of mixed farming\" is likely to positively impact farmland biodiversity through the provision of greater habitat heterogeneity at a variety of temporal and spatial scales within the landscape.\"\n\n"}
{"id": "10934212", "url": "https://en.wikipedia.org/wiki?curid=10934212", "title": "Air pollution", "text": "Air pollution\n\nAir pollution occurs when harmful or excessive quantities of substances including gases, particulates, and biological molecules are introduced into Earth's atmosphere. It may cause diseases, allergies and even death to humans; it may also cause harm to other living organisms such as animals and food crops, and may damage the natural or built environment. Both human activity and natural processes can generate air pollution.\n\nIndoor air pollution and poor urban air quality are listed as two of the world's worst toxic pollution problems in the 2008 Blacksmith Institute World's Worst Polluted Places report. According to the 2014 World Health Organization report, air pollution in 2012 caused the deaths of around 7 million people worldwide, an estimate roughly echoed by one from the International Energy Agency.\n\nAn air pollutant is a material in the air that can have adverse effects on humans and the ecosystem. The substance can be solid particles, liquid droplets, or gases. A pollutant can be of natural origin or man-made.\nPollutants are classified as primary or secondary. Primary pollutants are usually produced by processes such as ash from a volcanic eruption. Other examples include carbon monoxide gas from motor vehicle exhausts or sulphur dioxide released from the factories. Secondary pollutants are not emitted directly. Rather, they form in the air when primary pollutants react or interact. Ground level ozone is a prominent example of secondary pollutants. Some pollutants may be both primary and secondary: they are both emitted directly and formed from other primary pollutants.\n\nSubstances emitted into the atmosphere by human activity include:\nSecondary pollutants include:\nMinor air pollutants include:\n\nPersistent organic pollutants (POPs) are organic compounds that are resistant to environmental degradation through chemical, biological, and photolytic processes. Because of this, they have been observed to persist in the environment, to be capable of long-range transport, bioaccumulate in human and animal tissue, biomagnify in food chains, and to have potentially significant impacts on human health and the environment.\n\nThere are various locations, activities or factors which are\nresponsible for releasing pollutants into the atmosphere. These sources can be classified into two major categories.\n\nThese are mostly related to the burning of multiple types of fuel.\n\n\nAir pollutant emission factors are reported representative values that attempt to relate the quantity of a pollutant released to the ambient air with an activity associated with the release of that pollutant. These factors are usually expressed as the weight of pollutant divided by a unit weight, volume, distance, or duration of the activity emitting the pollutant (e.g., kilograms of particulate emitted per tonne of coal burned). Such factors facilitate estimation of emissions from various sources of air pollution. In most cases, these factors are simply averages of all available data of acceptable quality, and are generally assumed to be representative of long-term averages.\n\nThere are 12 compounds in the list of persistent organic pollutants. Dioxins and furans are two of them and intentionally created by combustion of organics, like open burning of plastics. These compounds are also endocrine disruptors and can mutate the human genes.\n\nThe United States Environmental Protection Agency has published a compilation of air pollutant emission factors for a wide range of industrial sources. The United Kingdom, Australia, Canada and many other countries have published similar compilations, as well as the European Environment Agency.\n\nAir pollution risk is a function of the hazard of the pollutant and the exposure to that pollutant. Air pollution exposure can be expressed for an individual, for certain groups (e.g. neighborhoods or children living in a country), or for entire populations. For example, one may want to calculate the exposure to a hazardous air pollutant for a geographic area, which includes the various microenvironments and age groups. This can be calculated as an inhalation exposure. This would account for daily exposure in various settings (e.g. different indoor micro-environments and outdoor locations). The exposure needs to include different age and other demographic groups, especially infants, children, pregnant women and other sensitive subpopulations. The exposure to an air pollutant must integrate the concentrations of the air pollutant with respect to the time spent in each setting and the respective inhalation rates for each subgroup for each specific time that the subgroup is in the setting and engaged in particular activities (playing, cooking, reading, working, spending time in traffic, etc.). For example, a small child's inhalation rate will be less than that of an adult. A child engaged in vigorous exercise will have a higher respiration rate than the same child in a sedentary activity. The daily exposure, then, needs to reflect the time spent in each micro-environmental setting and the type of activities in these settings. The air pollutant concentration in each microactivity/microenvironmental setting is summed to indicate the exposure. For some pollutants such as black carbon, traffic related exposures may dominate total exposure despite short exposure times since high concentrations coincide with proximity to major roads or participation to (motorized) traffic.\n\nA lack of ventilation indoors concentrates air pollution where people often spend the majority of their time. Radon (Rn) gas, a carcinogen, is exuded from the Earth in certain locations and trapped inside houses. Building materials including carpeting and plywood emit formaldehyde (HCO) gas. Paint and solvents give off volatile organic compounds (VOCs) as they dry. Lead paint can degenerate into dust and be inhaled. Intentional air pollution is introduced with the use of air fresheners, incense, and other scented items. Controlled wood fires in stoves and fireplaces can add significant amounts of smoke particulates into the air, inside and out. Indoor pollution fatalities may be caused by using pesticides and other chemical sprays indoors without proper ventilation.\n\nCarbon monoxide poisoning and fatalities are often caused by faulty vents and chimneys, or by the burning of charcoal indoors or in a confined space, such as a tent. Chronic carbon monoxide poisoning can result even from poorly-adjusted pilot lights. Traps are built into all domestic plumbing to keep sewer gas and hydrogen sulfide, out of interiors. Clothing emits tetrachloroethylene, or other dry cleaning fluids, for days after dry cleaning.\n\nThough its use has now been banned in many countries, the extensive use of asbestos in industrial and domestic environments in the past has left a potentially very dangerous material in many localities. Asbestosis is a chronic inflammatory medical condition affecting the tissue of the lungs. It occurs after long-term, heavy exposure to asbestos from asbestos-containing materials in structures. Sufferers have severe dyspnea (shortness of breath) and are at an increased risk regarding several different types of lung cancer. As clear explanations are not always stressed in non-technical literature, care should be taken to distinguish between several forms of relevant diseases. According to the World Health Organization (WHO), these may defined as; asbestosis, \"lung cancer\", and \"Peritoneal Mesothelioma\" (generally a very rare form of cancer, when more widespread it is almost always associated with prolonged exposure to asbestos).\n\nBiological sources of air pollution are also found indoors, as gases and airborne particulates. Pets produce dander, people produce dust from minute skin flakes and decomposed hair, dust mites in bedding, carpeting and furniture produce enzymes and micrometre-sized fecal droppings, inhabitants emit methane, mold forms on walls and generates mycotoxins and spores, air conditioning systems can incubate Legionnaires' disease and mold, and houseplants, soil and surrounding gardens can produce pollen, dust, and mold. Indoors, the lack of air circulation allows these airborne pollutants to accumulate more than they would otherwise occur in nature.\n\nIn 2012, air pollution caused premature deaths on average of 1 year in Europe, and was a significant risk factor for a number of pollution-related diseases, including respiratory infections, heart disease, COPD, stroke and lung cancer. The health effects caused by air pollution may include difficulty in breathing, wheezing, coughing, asthma and worsening of existing respiratory and cardiac conditions. These effects can result in increased medication use, increased doctor or emergency department visits, more hospital admissions and premature death. The human health effects of poor air quality are far reaching, but principally affect the body's respiratory system and the cardiovascular system. Individual reactions to air pollutants depend on the type of pollutant a person is exposed to, the degree of exposure, and the individual's health status and genetics.\nThe most common sources of air pollution include particulates, ozone, nitrogen dioxide, and sulphur dioxide. Children aged less than five years that live in developing countries are the most vulnerable population in terms of total deaths attributable to indoor and outdoor air pollution.\n\nThe World Health Organization estimated in 2014 that every year air pollution causes the premature death of some 7 million people worldwide. India has the highest death rate due to air pollution. India also has more deaths from asthma than any other nation according to the World Health Organization. In December 2013 air pollution was estimated to kill 500,000 people in China each year. There is a positive correlation between pneumonia-related deaths and air pollution from motor vehicle emissions.\n\nAnnual premature European deaths caused by air pollution are estimated at 430,000. An important cause of these deaths is nitrogen dioxide and other nitrogen oxides (NOx) emitted by road vehicles. In a 2015 consultation document the UK government disclosed that nitrogen dioxide is responsible for 23,500 premature UK deaths per annum. Across the European Union, air pollution is estimated to reduce life expectancy by almost nine months. Causes of deaths include strokes, heart disease, COPD, lung cancer, and lung infections.\n\nUrban outdoor air pollution is estimated to cause 1.3 million deaths worldwide per year. Children are particularly at risk due to the immaturity of their respiratory organ systems.\n\nThe US EPA estimated in 2004 that a proposed set of changes in diesel engine technology (\"Tier 2\") could result in 12,000 fewer \"premature mortalities\", 15,000 fewer heart attacks, 6,000 fewer emergency department visits by children with asthma, and 8,900 fewer respiratory-related hospital admissions each year in the United States.\n\nThe US EPA has estimated that limiting ground-level ozone concentration to 65 parts per billion, would avert 1,700 to 5,100 premature deaths nationwide in 2020 compared with the 75-ppb standard. The agency projected the more protective standard would also prevent an additional 26,000 cases of aggravated asthma, and more than a million cases of missed work or school. Following this assessment, the EPA acted to protect public health by lowering the National Ambient Air Quality Standards (NAAQS) for ground-level ozone to 70 parts per billion (ppb).\n\nA new economic study of the health impacts and associated costs of air pollution in the Los Angeles Basin and San Joaquin Valley of Southern California shows that more than 3,800 people die prematurely (approximately 14 years earlier than normal) each year because air pollution levels violate federal standards. The number of annual premature deaths is considerably higher than the fatalities related to auto collisions in the same area, which average fewer than 2,000 per year.\n\nDiesel exhaust (DE) is a major contributor to combustion-derived particulate matter air pollution. In several human experimental studies, using a well-validated exposure chamber setup, DE has been linked to acute vascular dysfunction and increased thrombus formation.\n\nThe mechanisms linking air pollution to increased cardiovascular mortality are uncertain, but probably include pulmonary and systemic inflammation.\n\nA 2007 review of evidence found ambient air pollution exposure is a risk factor correlating with increased total mortality from cardiovascular events (range: 12% to 14% per 10 microg/m increase).\n\nAir pollution is also emerging as a risk factor for stroke, particularly in developing countries where pollutant levels are highest. A 2007 study found that in women, air pollution is not associated with hemorrhagic but with ischemic stroke. Air pollution was also found to be associated with increased incidence and mortality from coronary stroke in a cohort study in 2011. Associations are believed to be causal and effects may be mediated by vasoconstriction, low-grade inflammation and atherosclerosis Other mechanisms such as autonomic nervous system imbalance have also been suggested.\nResearch has demonstrated increased risk of developing asthma and COPD from increased exposure to traffic-related air pollution. Additionally, air pollution has been associated with increased hospitalization and mortality from asthma and COPD. Chronic obstructive pulmonary disease (COPD) includes diseases such as chronic bronchitis and emphysema.\n\nA study conducted in 1960–1961 in the wake of the Great Smog of 1952 compared 293 London residents with 477 residents of Gloucester, Peterborough, and Norwich, three towns with low reported death rates from chronic bronchitis. All subjects were male postal truck drivers aged 40 to 59. Compared to the subjects from the outlying towns, the London subjects exhibited more severe respiratory symptoms (including cough, phlegm, and dyspnea), reduced lung function (FEV and peak flow rate), and increased sputum production and purulence. The differences were more pronounced for subjects aged 50 to 59. The study controlled for age and smoking habits, so concluded that air pollution was the most likely cause of the observed differences.\nMore recent studies have shown that air pollution exposure from traffic reduces lung function development in children and lung function may be compromised by air pollution even at low concentrations. Air pollution exposure also cause lung cancer in non smokers.\n\nIt is believed that much like cystic fibrosis, by living in a more urban environment serious health hazards become more apparent. Studies have shown that in urban areas patients suffer mucus hypersecretion, lower levels of lung function, and more self-diagnosis of chronic bronchitis and emphysema.\n\nA review of evidence regarding whether ambient air pollution exposure is a risk factor for cancer in 2007 found solid data to conclude that long-term exposure to PM2.5 (fine particulates) increases the overall risk of non-accidental mortality by 6% per a 10 microg/m increase. Exposure to PM2.5 was also associated with an increased risk of mortality from lung cancer (range: 15% to 21% per 10 microg/m increase) and total cardiovascular mortality (range: 12% to 14% per a 10 microg/m increase). The review further noted that living close to busy traffic appears to be associated with elevated risks of these three outcomes – increase in lung cancer deaths, cardiovascular deaths, and overall non-accidental deaths. The reviewers also found suggestive evidence that exposure to PM2.5 is positively associated with mortality from coronary heart diseases and exposure to SO increases mortality from lung cancer, but the data was insufficient to provide solid conclusions. Another investigation showed that higher activity level increases deposition fraction of aerosol particles in human lung and recommended avoiding heavy activities like running in outdoor space at polluted areas.\n\nIn 2011, a large Danish epidemiological study found an increased risk of lung cancer for patients who lived in areas with high nitrogen oxide concentrations. In this study, the association was higher for non-smokers than smokers. An additional Danish study, also in 2011, likewise noted evidence of possible associations between air pollution and other forms of cancer, including cervical cancer and brain cancer.\n\nIn December 2015, medical scientists reported that cancer is overwhelmingly a result of environmental factors, and not largely down to bad luck. Maintaining a healthy weight, eating a healthy diet, minimizing alcohol and eliminating smoking reduces the risk of developing the disease, according to the researchers.\n\nIn the United States, despite the passage of the Clean Air Act in 1970, in 2002 at least 146 million Americans were living in non-attainment areas—regions in which the concentration of certain air pollutants exceeded federal standards. These dangerous pollutants are known as the criteria pollutants, and include ozone, particulate matter, sulphur dioxide, nitrogen dioxide, carbon monoxide, and lead.\nProtective measures to ensure children's health are being taken in cities such as New Delhi, India where buses now use compressed natural gas to help eliminate the \"pea-soup\" smog. A recent study in Europe has found that exposure to ultrafine particles can increase blood pressure in children.\nAccording to a WHO report-2018, polluted air is a main cause poisoning millions of children under the age of 15 years and ruining their lives which resulting to death of some six hundred thousand children annually.\n\nAmbient levels of air pollution have been associated with preterm birth and low birth weight. A 2014 WHO worldwide survey on maternal and perinatal health found a statistically significant association between low birth weights (LBW) and increased levels of exposure to PM2.5. Women in regions with greater than average PM2.5 levels had statistically significant higher odds of pregnancy resulting in a low-birth weight infant even when adjusted for country-related variables. The effect is thought to be from stimulating inflammation and increasing oxidative stress.\n\nA study by the University of York found that in 2010 exposure to PM2.5 was strongly associated with 18% of preterm births globally, which was approximately 2.7 million premature births. The countries with the highest air pollution associated preterm births were in South and East Asia, the Middle East, North Africa, and West sub-Saharan Africa.\n\nThe source of PM 2.5 differs greatly by region. In South and East Asia, pregnant women are frequently exposed to indoor air pollution because of the wood and other biomass fuels used for cooking which are responsible for more than 80% of regional pollution. In the Middle East, North Africa and West sub-Saharan Africa, fine PM comes from natural sources, such as dust storms. The United States had an estimated 50,000 preterm births associated with exposure to PM2.5 in 2010.\n\nA study performed by Wang, et al. between the years of 1988 and 1991 has found a correlation between sulphur Dioxide (SO2) and total suspended particulates (TSP) and preterm births and low birth weights in Beijing. A group of 74,671 pregnant women, in four separate regions of Beijing, were monitored from early pregnancy to delivery along with daily air pollution levels of sulphur Dioxide and TSP (along with other particulates). The estimated reduction in birth weight was 7.3 g for every 100 µg/m3 increase in SO2 and 6.9g for each 100 µg/m3 increase in TSP. These associations were statistically significant in both summer and winter, although, summer was greater. The proportion of low birth weight attributable to air pollution, was 13%. This is the largest attributable risk ever reported for the known risk factors of low birth weight. Coal stoves, which are in 97% of homes, are a major source of air pollution in this area.\n\nBrauer et al. studied the relationship between air pollution and proximity to a highway with pregnancy outcomes in a Vancouver cohort of pregnant woman using addresses to estimate exposure during pregnancy. Exposure to NO, NO2, CO PM10 and PM2.5 were associated with infants born small for gestational age (SGA). Women living <50meters away from an expressway or highway were 26% more likely to give birth to a SGA infant.\n\nEven in the areas with relatively low levels of air pollution, public health effects can be significant and costly, since a large number of people breathe in such pollutants. A study published in 2017 found that even in areas of the U.S. where ozone and PM2.5 meet federal standards, Medicare recipients who are exposed to more air pollution have higher mortality rates. A 2005 scientific study for the British Columbia Lung Association showed that a small improvement in air quality (1% reduction of ambient PM2.5 and ozone concentrations) would produce $29 million in annual savings in the Metro Vancouver region in 2010. This finding is based on health valuation of lethal (death) and sub-lethal (illness) affects.\n\nData is accumulating that air pollution exposure also affects the central nervous system.\n\nIn a June 2014 study conducted by researchers at the University of Rochester Medical Center, published in the journal \"Environmental Health Perspectives\", it was discovered that early exposure to air pollution causes the same damaging changes in the brain as autism and schizophrenia. The study also shows that air pollution also affected short-term memory, learning ability, and impulsivity. Lead researcher Professor Deborah Cory-Slechta said that \"When we looked closely at the ventricles, we could see that the white matter that normally surrounds them hadn't fully developed. It appears that inflammation had damaged those brain cells and prevented that region of the brain from developing, and the ventricles simply expanded to fill the space. Our findings add to the growing body of evidence that air pollution may play a role in autism, as well as in other neurodevelopmental disorders.\" Air pollution has a more significant negative effect on males than on females.\n\nIn 2015, experimental studies reported the detection of significant episodic (situational) cognitive impairment from impurities in indoor air breathed by test subjects who were not informed about changes in the air quality. Researchers at the Harvard University and SUNY Upstate Medical University and Syracuse University measured the cognitive performance of 24 participants in three different controlled laboratory atmospheres that simulated those found in \"conventional\" and \"green\" buildings, as well as green buildings with enhanced ventilation. Performance was evaluated objectively using the widely used Strategic Management Simulation software simulation tool, which is a well-validated assessment test for executive decision-making in an unconstrained situation allowing initiative and improvisation. Significant deficits were observed in the performance scores achieved in increasing concentrations of either volatile organic compounds (VOCs) or carbon dioxide, while keeping other factors constant. The highest impurity levels reached are not uncommon in some classroom or office environments. Air pollution increases the risk of dementia in people over 50 years old.\n\nIn India in 2014, it was reported that air pollution by black carbon and ground level ozone had reduced crop yields in the most affected areas by almost half in 2011 when compared to 1980 levels.\n\nAir pollution costs the world economy $5 trillion per year as a result of productivity losses and degraded quality of life, according to a joint study by the World Bank and the Institute for Health Metrics and Evaluation (IHME) at the University of Washington. These productivity losses are caused by deaths due to diseases caused by air pollution. One out of ten deaths in 2013 was caused by diseases associated with air pollution and the problem is getting worse. The problem is even more acute in the developing world. \"Children under age 5 in lower-income countries are more than 60 times as likely to die from exposure to air pollution as children in high-income countries.\" The report states that additional economic losses caused by air pollution, including health costs and the adverse effect on agricultural and other productivity were not calculated in the report, and thus the actual costs to the world economy are far higher than $5 trillion.\n\nThe world's worst short-term civilian pollution crisis was the 1984 Bhopal Disaster in India. Leaked industrial vapours from the Union Carbide factory, belonging to Union Carbide, Inc., U.S.A. (later bought by Dow Chemical Company), killed at least 3787 people and injured from 150,000 to 600,000. The United Kingdom suffered its worst air pollution event when the December 4 Great Smog of 1952 formed over London. In six days more than 4,000 died and more recent estimates put the figure at nearer 12,000. An accidental leak of anthrax spores from a biological warfare laboratory in the former USSR in 1979 near Sverdlovsk is believed to have caused at least 64 deaths. The worst single incident of air pollution to occur in the US occurred in Donora, Pennsylvania in late October, 1948, when 20 people died and over 7,000 were injured.\n\nThere are now practical alternatives to the principal causes of air pollution:\n\nVarious air pollution control technologies and strategies are available to reduce air pollution. At its most basic level, land-use planning is likely to involve zoning and transport infrastructure planning. In most developed countries, land-use planning is an important part of social policy, ensuring that land is used efficiently for the benefit of the wider economy and population, as well as to protect the environment.\n\nBecause a large share of air pollution is caused by combustion of fossil fuels such as coal and oil, the reduction of these fuels can reduce air pollution drastically. Most effective is the switch to clean power sources such as wind power, solar power, hydro power which don't cause air pollution. Efforts to reduce pollution from mobile sources includes primary regulation (many developing countries have permissive regulations), expanding regulation to new sources (such as cruise and transport ships, farm equipment, and small gas-powered equipment such as string trimmers, chainsaws, and snowmobiles), increased fuel efficiency (such as through the use of hybrid vehicles), conversion to cleaner fuels or conversion to electric vehicles.\n\nTitanium dioxide has been researched for its ability to reduce air pollution. Ultraviolet light will release free electrons from material, thereby creating free radicals, which break up VOCs and NOx gases. One form is superhydrophilic.\n\nIn 2014, Prof. Tony Ryan and Prof. Simon Armitage of University of Sheffield prepared a 10 meter by 20 meter-sized poster coated with microscopic, pollution-eating nanoparticles of titanium dioxide. Placed on a building, this giant poster can absorb the toxic emission from around 20 cars each day.\n\nA very effective means to reduce air pollution is the transition to renewable energy. According to a study published in Energy and Environmental Science in 2015 the switch to 100% renewable energy in the United States would eliminate about 62,000 premature mortalities per year and about 42,000 in 2050, if no biomass were used. This would save about $600 billion in health costs a year due to reduced air pollution in 2050, or about 3.6% of the 2014 U.S. gross domestic product.\n\nThe following items are commonly used as pollution control devices in industry and transportation. They can either destroy contaminants or remove them from an exhaust stream before it is emitted into the atmosphere.\n\nIn general, there are two types of air quality standards. The first class of standards (such as the U.S. National Ambient Air Quality Standards and E.U. Air Quality Directive) set maximum atmospheric concentrations for specific pollutants. Environmental agencies enact regulations which are intended to result in attainment of these target levels. The second class (such as the North American Air Quality Index) take the form of a scale with various thresholds, which is used to communicate to the public the relative risk of outdoor activity. The scale may or may not distinguish between different pollutants.\n\nIn Canada, air pollution and associated health risks are measured with the Air Quality Health Index or (AQHI). It is a health protection tool used to make decisions to reduce short-term exposure to air pollution by adjusting activity levels during increased levels of air pollution.\n\nThe Air Quality Health Index or \"AQHI\" is a federal program jointly coordinated by Health Canada and Environment Canada. However, the AQHI program would not be possible without the commitment and support of the provinces, municipalities and NGOs. From air quality monitoring to health risk communication and community engagement, local partners are responsible for the vast majority of work related to AQHI implementation. The AQHI provides a number from 1 to 10+ to indicate the level of health risk associated with local air quality. Occasionally, when the amount of air pollution is abnormally high, the number may exceed 10. The AQHI provides a local air quality current value as well as a local air quality maximums forecast for today, tonight and tomorrow and provides associated health advice.\n\nAs it is now known that even low levels of air pollution can trigger discomfort for the sensitive population, the index has been developed as a continuum: The higher the number, the greater the health risk and need to take precautions. The index describes the level of health risk associated with this number as 'low', 'moderate', 'high' or 'very high', and suggests steps that can be taken to reduce exposure.\n\nThe measurement is based on the observed relationship of Nitrogen Dioxide (NO), ground-level Ozone (O) and particulates (PM) with mortality, from an analysis of several Canadian cities. Significantly, all three of these pollutants can pose health risks, even at low levels of exposure, especially among those with pre-existing health problems.\n\nWhen developing the AQHI, Health Canada's original analysis of health effects included five major air pollutants: particulates, ozone, and nitrogen dioxide (NO2), as well as sulphur dioxide (SO), and carbon monoxide (CO). The latter two pollutants provided little information in predicting health effects and were removed from the AQHI formulation.\n\nThe AQHI does not measure the effects of odour, pollen, dust, heat or humidity.\n\nTA Luft is the German air quality regulation.\n\nAir pollution hotspots are areas where air pollution emissions expose individuals to increased negative health effects. They are particularly common in highly populated, urban areas, where there may be a combination of stationary sources (e.g. industrial facilities) and mobile sources (e.g. cars and trucks) of pollution. Emissions from these sources can cause respiratory disease, childhood asthma, cancer, and other health problems. Fine particulate matter such as diesel soot, which contributes to more than 3.2 million premature deaths around the world each year, is a significant problem. It is very small and can lodge itself within the lungs and enter the bloodstream. Diesel soot is concentrated in densely populated areas, and one in six people in the U.S. live near a diesel pollution hot spot.\n\nWhile air pollution hotspots affect a variety of populations, some groups are more likely to be located in hotspots. Previous studies have shown disparities in exposure to pollution by race and/or income. Hazardous land uses (toxic storage and disposal facilities, manufacturing facilities, major roadways) tend to be located where property values and income levels are low. Low socioeconomic status can be a proxy for other kinds of social vulnerability, including race, a lack of ability to influence regulation and a lack of ability to move to neighborhoods with less environmental pollution. These communities bear a disproportionate burden of environmental pollution and are more likely to face health risks such as cancer or asthma.\n\nStudies show that patterns in race and income disparities not only indicate a higher exposure to pollution but also higher risk of adverse health outcomes. Communities characterized by low socioeconomic status and racial minorities can be more vulnerable to cumulative adverse health impacts resulting from elevated exposure to pollutants than more privileged communities. Blacks and Latinos generally face more pollution than whites and Asians, and low-income communities bear a higher burden of risk than affluent ones. Racial discrepancies are particularly distinct in suburban areas of the US South and metropolitan areas of the US West. Residents in public housing, who are generally low-income and cannot move to healthier neighborhoods, are highly affected by nearby refineries and chemical plants.\n\nAir pollution is usually concentrated in densely populated metropolitan areas, especially in developing countries where environmental regulations are relatively lax or nonexistent. However, even populated areas in developed countries attain unhealthy levels of pollution, with Los Angeles and Rome being two examples. Between 2002 and 2011 the incidence of lung cancer in Beijing near doubled. While smoking remains the leading cause of lung cancer in China, the number of smokers is falling while lung cancer rates are rising. Another project focusing on the effects on pollution in vegetation has been researched by the local university in Sheffield, UK.\n\nIn Europe, Council Directive 96/62/EC on ambient air quality assessment and management provides a common strategy against which member states can \"set objectives for ambient air quality in order to avoid, prevent or reduce harmful effects on human health and the environment . . . and improve air quality where it is unsatisfactory\".\n\nOn 25 July 2008 in the case Dieter Janecek v Freistaat Bayern CURIA, the European Court of Justice ruled that under this directive citizens have the right to require national authorities to implement a short term action plan that aims to maintain or achieve compliance to air quality limit values.\n\nThis important case law appears to confirm the role of the EC as centralised regulator to European nation-states as regards air pollution control. It places a supranational legal obligation on the UK to protect its citizens from dangerous levels of air pollution, furthermore superseding national interests with those of the citizen.\n\nIn 2010, the European Commission (EC) threatened the UK with legal action against the successive breaching of PM10 limit values. The UK government has identified that if fines are imposed, they could cost the nation upwards of £300 million per year.\n\nIn March 2011, the Greater London Built-up Area remains the only UK region in breach of the EC's limit values, and has been given 3 months to implement an emergency action plan aimed at meeting the EU Air Quality Directive. The City of London has dangerous levels of PM10 concentrations, estimated to cause 3000 deaths per year within the city. As well as the threat of EU fines, in 2010 it was threatened with legal action for scrapping the western congestion charge zone, which is claimed to have led to an increase in air pollution levels.\n\nIn response to these charges, Boris Johnson, Mayor of London, has criticised the current need for European cities to communicate with Europe through their nation state's central government, arguing that in future \"A great city like London\" should be permitted to bypass its government and deal directly with the European Commission regarding its air quality action plan.\n\nThis can be interpreted as recognition that cities can transcend the traditional national government organisational hierarchy and develop solutions to air pollution using global governance networks, for example through transnational relations. Transnational relations include but are not exclusive to national governments and intergovernmental organisations, allowing sub-national actors including cities and regions to partake in air pollution control as independent actors.\n\nParticularly promising at present are global city partnerships. These can be built into networks, for example the C40 Cities Climate Leadership Group, of which London is a member. The C40 is a public 'non-state' network of the world's leading cities that aims to curb their greenhouse emissions. The C40 has been identified as 'governance from the middle' and is an alternative to intergovernmental policy. It has the potential to improve urban air quality as participating cities \"exchange information, learn from best practices and consequently mitigate carbon dioxide emissions independently from national government decisions\". A criticism of the C40 network is that its exclusive nature limits influence to participating cities and risks drawing resources away from less powerful city and regional actors.\n\n\n\n\n"}
{"id": "1287367", "url": "https://en.wikipedia.org/wiki?curid=1287367", "title": "Bern Physiologus", "text": "Bern Physiologus\n\nThe Bern Physiologus (Bern, Burgerbibliothek, \"Codex Bongarsianus\" 318) is a 9th-century illuminated copy of the Latin translation of the \"Physiologus\". It was probably produced at Reims about 825-850. It is believed to be a copy of a 5th-century manuscript. Many of its miniatures are set, unframed, into the text block, which was a characteristic of late-antique manuscripts. It is one of the oldest extant illustrated copies of the \"Physiologus\".\n\n"}
{"id": "9021244", "url": "https://en.wikipedia.org/wiki?curid=9021244", "title": "Brownhill Creek Recreation Park", "text": "Brownhill Creek Recreation Park\n\nBrownhill Creek Recreation Park is a protected area located about south of the Adelaide city centre in City of Mitcham along part of the course of the Brown Hill Creek. The recreation park was proclaimed under the \"National Parks and Wildlife Act 1972\" in 1972 to \"provide recreation opportunities for the Adelaide and eastern metropolitan region and to conserve remnant aged river red gums and the riparian zone habitat\". The land previously subject to protected area status as a \"National Pleasure Resort\" since 1915. The recreation park is classified as an IUCN Category III protected area.\n\n\n"}
{"id": "173961", "url": "https://en.wikipedia.org/wiki?curid=173961", "title": "Center of mass", "text": "Center of mass\n\nIn physics, the center of mass of a distribution of mass in space is the unique point where the weighted relative position of the distributed mass sums to zero, or the point where if a force is applied it moves in the direction of the force without rotating. The distribution of mass is balanced around the center of mass and the average of the weighted position coordinates of the distributed mass defines its coordinates. Calculations in mechanics are often simplified when formulated with respect to the center of mass.\nIt is a hypothetical point where entire mass of an object may be assumed to be concentrated to visualise its motion.\nIn other words, the center of mass is the particle equivalent of a given object for application of Newton's laws of motion.\n\nIn the case of a single rigid body, the center of mass is fixed in relation to the body, and if the body has uniform density, it will be located at the centroid. The center of mass may be located outside the physical body, as is sometimes the case for hollow or open-shaped objects, such as a horseshoe. In the case of a distribution of separate bodies, such as the planets of the Solar System, the center of mass may not correspond to the position of any individual member of the system.\n\nThe center of mass is a useful reference point for calculations in mechanics that involve masses distributed in space, such as the linear and angular momentum of planetary bodies and rigid body dynamics. In orbital mechanics, the equations of motion of planets are formulated as point masses located at the centers of mass. The center of mass frame is an inertial frame in which the center of mass of a system is at rest with respect to the origin of the coordinate system.\n\nThe concept of \"center of mass\" in the form of the center of gravity was first introduced by the great ancient Greek physicist, mathematician, and engineer Archimedes of Syracuse. He worked with simplified assumptions about gravity that amount to a uniform field, thus arriving at the mathematical properties of what we now call the center of mass. Archimedes showed that the torque exerted on a lever by weights resting at various points along the lever is the same as what it would be if all of the weights were moved to a single point—their center of mass. In work on floating bodies he demonstrated that the orientation of a floating object is the one that makes its center of mass as low as possible. He developed mathematical techniques for finding the centers of mass of objects of uniform density of various well-defined shapes.\n\nLater mathematicians who developed the theory of the center of mass include Pappus of Alexandria, Guido Ubaldi, Francesco Maurolico, Federico Commandino, Simon Stevin, Luca Valerio, Jean-Charles de la Faille, Paul Guldin, John Wallis, Louis Carré, Pierre Varignon, and Alexis Clairaut.\n\nNewton's second law is reformulated with respect to the center of mass in Euler's first law.\n\nThe center of mass is the unique point at the center of a distribution of mass in space that has the property that the weighted position vectors relative to this point sum to zero. In analogy to statistics, the center of mass is the mean location of a distribution of mass in space.\n\nIn the case of a system of particles , each with mass that are located in space with coordinates , the coordinates R of the center of mass satisfy the condition\nSolving this equation for R yields the formula\nwhere is the sum of the masses of all of the particles.\n\nIf the mass distribution is continuous with the density ρ(r) within a solid \"Q\", then the integral of the weighted position coordinates of the points in this volume relative to the center of mass R over the volume V is zero, that is\nSolve this equation for the coordinates R to obtain\nwhere M is the total mass in the volume.\n\nIf a continuous mass distribution has uniform density, which means ρ is constant, then the center of mass is the same as the centroid of the volume.\n\nThe coordinates R of the center of mass of a two-particle system, \"P\" and \"P\", with masses \"m\" and \"m\" is given by\nLet the percentage of the total mass divided between these two particles vary from 100% \"P\" and 0% \"P\" through 50% \"P\" and 50% \"P\" to 0% \"P\" and 100% \"P\", then the center of mass R moves along the line from \"P\" to \"P\". The percentages of mass at each point can be viewed as projective coordinates of the point R on this line, and are termed barycentric coordinates. Another way of interpreting the process here is the mechanical balancing of moments about an arbitrary point. The numerator gives the total moment that is then balanced by an equivalent total force at the center of mass. This can be generalized to three points and four points to define projective coordinates in the plane, and in space, respectively.\n\nFor particles in a system with periodic boundary conditions two particles can be neighbours even though they are on opposite sides of the system. This occurs often in molecular dynamics simulations, for example, in which clusters form at random locations and sometimes neighbouring atoms cross the periodic boundary. When a cluster straddles the periodic boundary, a naive calculation of the center of mass will be incorrect. A generalized method for calculating the center of mass for periodic systems is to treat each coordinate, \"x\" and \"y\" and/or \"z\", as if it were on a circle instead of a line.\nThe calculation takes every particle's \"x\" coordinate and maps it to an angle,\nwhere \"x\" is the system size in the \"x\" direction and formula_7. From this angle, two new points formula_8 can be generated, which can be weighted by the mass of the particle formula_9 for the center of mass or given a value of 1 for the geometric center:\nIn the formula_12 plane, these coordinates lie on a circle of radius 1. From the collection of formula_13 and formula_14 values from all the particles, the averages formula_15 and formula_16 are calculated.\n\nwhere is the sum of the masses of all of the particles.\n\nThese values are mapped back into a new angle, formula_19, from which the \"x\" coordinate of the center of mass can be obtained:\nThe process can be repeated for all dimensions of the system to determine the complete center of mass. The utility of the algorithm is that it allows the mathematics to determine where the \"best\" center of mass is, instead of guessing or using cluster analysis to \"unfold\" a cluster straddling the periodic boundaries. If both average values are zero, formula_22, then formula_19 is undefined. This is a correct result, because it only occurs when all particles are exactly evenly spaced. In that condition, their \"x\" coordinates are mathematically identical in a .\n\nA body's center of gravity is the point around which the resultant torque due to gravity forces vanishes. Where a gravity field can be considered to be uniform, the mass-center and the center-of-gravity will be the same. However, for satellites in orbit around a planet, in the absence of other torques being applied to a satellite, the slight variation (gradient) in gravitational field between closer-to (stronger) and further-from (weaker) the planet can lead to a torque that will tend to align the satellite such that its long axis is vertical. In such a case, it is important to make the distinction between the center-of-gravity and the mass-center. Any horizontal offset between the two will result in an applied torque.\n\nIt is useful to note that the mass-center is a fixed property for a given rigid body (e.g. with no slosh or articulation), whereas the center-of-gravity may, in addition, depend upon its orientation in a non-uniform gravitational field. In the latter case, the center-of-gravity will always be located somewhat closer to the main attractive body as compared to the mass-center, and thus will change its position in the body of interest as its orientation is changed.\n\nIn the study of the dynamics of aircraft, vehicles and vessels, forces and moments need to be resolved relative to the mass center. That is true independent of whether gravity itself is a consideration. Referring to the mass-center as the center-of-gravity is something of a colloquialism, but it is in common usage and when gravity gradient effects are negligible, center-of-gravity and mass-center are the same and are used interchangeably.\n\nIn physics the benefits of using the center of mass to model a mass distribution can be seen by considering the resultant of the gravity forces on a continuous body. Consider a body Q of volume V with density ρ(r) at each point r in the volume. In a parallel gravity field the force f at each point r is given by,\nwhere dm is the mass at the point r, g is the acceleration of gravity, and \"k\" is a unit vector defining the vertical direction.\nChoose a reference point R in the volume and compute the resultant force and torque at this point,\nand\nIf the reference point R is chosen so that it is the center of mass, then\nwhich means the resultant torque T=0. Because the resultant torque is zero the body will move as though it is a particle with its mass concentrated at the center of mass.\n\nBy selecting the center of gravity as the reference point for a rigid body, the gravity forces will not cause the body to rotate, which means the weight of the body can be considered to be concentrated at the center of mass.\n\nThe linear and angular momentum of a collection of particles can be simplified by measuring the position and velocity of the particles relative to the center of mass. Let the system of particles \"P\", \"i\"=1...,\"n\" of masses \"m\" be located at the coordinates r with velocities v. Select a reference point R and compute the relative position and velocity vectors,\nThe total linear and angular momentum vectors relative to the reference point R are\nand\n\nIf R is chosen as the center of mass these equations simplify to\nwhere \"m\" is the total mass of all the particles, p is the linear momentum, and L is the angular momentum\n\nThe Law of Conservation of Momentum predicts that for any system not subjected to external forces the momentum of the system will remain constant, which means the center of mass will move with constant velocity. This applies for all systems with classical internal forces, including magnetic fields, electric fields, chemical reactions, and so on. More formally, this is true for any internal forces that cancel in accordance with Newton's Third Law.\nThe experimental determination of the center of mass of a body uses gravity forces on the body and relies on the fact that in the parallel gravity field near the surface of the earth the center of mass is the same as the center of gravity.\n\nThe center of mass of a body with an axis of symmetry and constant density must lie on this axis. Thus, the center of mass of a circular cylinder of constant density has its center of mass on the axis of the cylinder. In the same way, the center of mass of a spherically symmetric body of constant density is at the center of the sphere. In general, for any symmetry of a body, its center of mass will be a fixed point of that symmetry.\n\nAn experimental method for locating the center of mass is to suspend the object from two locations and to drop plumb lines from the suspension points. The intersection of the two lines is the center of mass.\n\nThe shape of an object might already be mathematically determined, but it may be too complex to use a known formula. In this case, one can subdivide the complex shape into simpler, more elementary shapes, whose centers of mass are easy to find. If the total mass and center of mass can be determined for each area, then the center of mass of the whole is the weighted average of the centers. This method can even work for objects with holes, which can be accounted for as negative masses.\n\nA direct development of the planimeter known as an integraph, or integerometer, can be used to establish the position of the centroid or center of mass of an irregular two-dimensional shape. This method can be applied to a shape with an irregular, smooth or complex boundary where other methods are too difficult. It was regularly used by ship builders to compare with the required displacement and center of buoyancy of a ship, and ensure it would not capsize.\n\nAn experimental method to locate the three-dimensional coordinates of the center of mass begins by supporting the object at three points and measuring the forces, F, F, and F that resist the weight of the object, formula_32 (formula_33 is the unit vector in the vertical direction). Let r, r, and r be the position coordinates of the support points, then the coordinates R of the center of mass satisfy the condition that the resultant torque is zero,\nor\nThis equation yields the coordinates of the center of mass R* in the horizontal plane as,\nThe center of mass lies on the vertical line L, given by\nThe three-dimensional coordinates of the center of mass are determined by performing this experiment twice with the object positioned so that these forces are measured for two different horizontal planes through the object. The center of mass will be the intersection of the two lines L and L obtained from the two experiments.\n\nEngineers try to design a sports car so that its center of mass is lowered to make the car handle better, that is maintaining traction while executing relatively sharp turns. \n\nThe characteristic low profile of the U. S. military Humvee was designed in part to allow it tilt farther than taller vehicles, without a rollover, because its low center of mass would stay over the space bounded the four wheels even at angles far from the horizontal.\n\nThe center of mass is an important point on an aircraft, which significantly affects the stability of the aircraft. To ensure the aircraft is stable enough to be safe to fly, the center of mass must fall within specified limits. If the center of mass is ahead of the forward limit, the aircraft will be less maneuverable, possibly to the point of being unable to rotate for takeoff or flare for landing. If the center of mass is behind the aft limit, the aircraft will be more maneuverable, but also less stable, and possibly so unstable that it is impossible to fly. The moment arm of the elevator will also be reduced, which makes it more difficult to recover from a stalled condition.\n\nFor helicopters in hover, the center of mass is always directly below the rotorhead. In forward flight, the center of mass will move forward to balance the negative pitch torque produced by applying cyclic control to propel the helicopter forward; consequently a cruising helicopter flies \"nose-down\" in level flight.\n\nThe center of mass plays an important role in astronomy and astrophysics, where it is commonly referred to as the \"barycenter\". The barycenter is the point between two objects where they balance each other; it is the center of mass where two or more celestial bodies orbit each other. When a moon orbits a planet, or a planet orbits a star, both bodies are actually orbiting around a point that lies away from the center of the primary (larger) body. For example, the Moon does not orbit the exact center of the Earth, but a point on a line between the center of the Earth and the Moon, approximately 1,710 km (1,062 miles) below the surface of the Earth, where their respective masses balance. This is the point about which the Earth and Moon orbit as they travel around the Sun. If the masses are more similar, e.g., Pluto and Charon, the barycenter will fall outside both bodies.\n\nWhen high jumpers perform a \"Fosbury Flop\", they bend their respective bodies in such a way that they clear the bar while their respective centers of mass do not necessarily do so. Because it is the height of the center of gravity (rather than of the highest part of the body) that constrains the minimum energy investment for \"clearing\" the bar, \"snaking over\" the bar can reduce the energy expended in propelling the body upward.\nIn kinesiology and biomechanics, the center of mass is an important parameter that assists people in understanding their human locomotion. Typically, a human’s center of mass is detected with one of two methods: The reaction board method is a static analysis that involves the person lying down on that instrument, and use of their static equilibrium equation to find their center of mass; the segmentation method relies on a mathematical solution based on the physical principle that the summation of the torques of individual body sections, relative to a specified axis, must equal the torque of the whole system that constitutes the body, measured relative to the same axis.\n\n\n"}
{"id": "9568523", "url": "https://en.wikipedia.org/wiki?curid=9568523", "title": "Chivay obsidian source", "text": "Chivay obsidian source\n\nThe Chivay obsidian source (15.6423° S, 71.5355° W, 4972 masl) is the geological origin of a chemical group of obsidian that is found throughout the south-central Andean highlands including southern Peru and western Bolivia. Chemical characterization studies using X-ray fluorescence (XRF) and Neutron Activation Analysis (NAA) have shown that the Chivay obsidian source, also known as the Cotallalli type or the Titicaca Basin type, makes up over 90% of the obsidian artifacts analyzed from the Lake Titicaca Basin.\n\nObsidian from the Chivay source is found in large and homogeneous nodules in a high altitude volcanic depression approximately ten km to the east of the town of Chivay in the Colca Valley (Caylloma, Arequipa, Peru).\n\nObsidian from the Chivay source has been chemically identified among artifacts from over fifty sites in the south-central Andes. Chivay obsidian was the predominant type found at the Archaic and Formative site of Jiskairumoko on the western side of Lake Titicaca in the Ilave Valley of Puno, Peru.\n\n"}
{"id": "52676490", "url": "https://en.wikipedia.org/wiki?curid=52676490", "title": "Clonia (nymph)", "text": "Clonia (nymph)\n\nClonia is a nymph in Greek mythology, consort of Hyrieus. By her, he became the father of Nycteus and Lycus.\n\n"}
{"id": "5966", "url": "https://en.wikipedia.org/wiki?curid=5966", "title": "Compost", "text": "Compost\n\nCompost ( or ) is organic matter that has been decomposed in a process called composting. This process recycles various organic materials otherwise regarded as waste products and produces a soil conditioner (the \"compost\").\n\nCompost is rich in nutrients. It is used, for example, in gardens, landscaping, horticulture, urban agriculture and organic farming. The compost itself is beneficial for the land in many ways, including as a soil conditioner, a fertilizer, addition of vital humus or humic acids, and as a natural pesticide for soil. In ecosystems, compost is useful for erosion control, land and stream reclamation, wetland construction, and as landfill cover (see compost uses).\n\nAt the simplest level, the process of composting requires making a heap of wet organic matter (also called green waste), such as leaves, grass, and food scraps, and waiting for the materials to break down into humus after a period of months. However, composting also can take place as a multi-step, closely monitored process with measured inputs of water, air, and carbon- and nitrogen-rich materials. The decomposition process is aided by shredding the plant matter, adding water and ensuring proper aeration by regularly turning the mixture when open piles or \"windrows\" are used. Earthworms and fungi further break up the material. Bacteria requiring oxygen to function (aerobic bacteria) and fungi manage the chemical process by converting the inputs into heat, carbon dioxide, and ammonium.\n\nComposting is an aerobic method (meaning that it requires the presence of air) of decomposing organic solid wastes. It can therefore be used to recycle organic material. The process involves decomposition of organic material into a humus-like material, known as compost, which is a good fertilizer for plants. Composting requires the following three components: human management, aerobic conditions, development of internal biological heat.\n\nComposting organisms require four equally important ingredients to work effectively:\n\nCertain ratios of these materials will provide microorganisms to work at a rate that will heat up the pile. Active management of the pile (e.g. turning) is needed to maintain sufficient supply of oxygen and the right moisture level. The air/water balance is critical to maintaining high temperatures (135°-160° Fahrenheit / 50° - 70° Celsius) until the materials are broken down.\n\nThe most efficient composting occurs with an optimal carbon:nitrogen ratio of about 25:1. Hot container composting focuses on retaining the heat to increase decomposition rate and produce compost more quickly. Rapid composting is favored by having a C/N ratio of ~30 or less. Above 30 the substrate is nitrogen starved, below 15 it is likely to outgas a portion of nitrogen as ammonia.\n\nNearly all plant and animal materials have both carbon and nitrogen, but amounts vary widely, with characteristics noted above (dry/wet, brown/green). Fresh grass clippings have an average ratio of about 15:1 and dry autumn leaves about 50:1 depending on species. Mixing equal parts by volume approximates the ideal C:N range. Few individual situations will provide the ideal mix of materials at any point. Observation of amounts, and consideration of different materials as a pile is built over time, can quickly achieve a workable technique for the individual situation.\n\nWith the proper mixture of water, oxygen, carbon, and nitrogen, micro-organisms are able to break down organic matter to produce compost. The composting process is dependent on micro-organisms to break down organic matter into compost. There are many types of microorganisms found in active compost of which the most common are:\n\n\nIn addition, earthworms not only ingest partly composted material, but also continually re-create aeration and drainage tunnels as they move through the compost.\n\nUnder ideal conditions, composting proceeds through three major phases:\n\n\nThere are many proponents of rapid composting that attempt to correct some of the perceived problems associated with traditional, slow composting. Many advocate that compost can be made in 2 to 3 weeks. Many such short processes involve a few changes to traditional methods, including smaller, more homogenized pieces in the compost, controlling carbon-to-nitrogen ratio (C:N) at 30 to 1 or less, and monitoring the moisture level more carefully. However, none of these parameters differ significantly from the early writings of compost researchers, suggesting that in fact modern composting has not made significant advances over the traditional methods that take a few months to work. For this reason and others, many scientists who deal with carbon transformations are sceptical that there is a \"super-charged\" way to get nature to make compost rapidly. \n\nBoth sides may be right to some extent. The bacterial activity in rapid high heat methods breaks down the material to the extent that pathogens and seeds are destroyed, and the original feedstock is unrecognizable. At this stage, the compost can be used to prepare fields or other planting areas. However, most professionals recommend that the compost be given time to cure before using in a nursery for starting seeds or growing young plants. The curing time allows fungi to continue the decomposition process and eliminating phytotoxic substances.\n\nComposting can destroy pathogens or unwanted seeds. Unwanted living plants (or weeds) can be discouraged by covering with mulch/compost. The \"microbial pesticides\" in compost may include thermophiles and mesophiles.\n\nThermophilic (high-temperature) composting is well known to destroy many seeds and nearly all types of pathogens (exceptions may include prions). The sanitizing qualities of (thermophilic) composting are desirable where there is a high likelihood of pathogens, such as with manure.\n\nComposting is a process used for resource recovery. It can recycle an unwanted by-product from another process (a waste) into a useful new product.\n\nComposting is a process for converting decomposable organic materials into useful stable products. Therefore, valuable landfill space can be used for other wastes by composting these materials rather than dumping them on landfills. It may however be difficult to control inert and plastics contamination from municipal solid waste.\n\nCo-composting is a technique that processes organic solid waste together with other input materials such as dewatered fecal sludge or sewage sludge.\n\nIndustrial composting systems are being installed to treat organic solid waste and recycle it rather than landfilling it. It is one example of an advanced waste processing system. Mechanical sorting of mixed waste streams combined with anaerobic digestion or in-vessel composting is called mechanical biological treatment. It is increasingly being used in developed countries due to regulations controlling the amount of organic matter allowed in landfills. Treating biodegradable waste before it enters a landfill reduces global warming from fugitive methane; untreated waste breaks down anaerobically in a landfill, producing landfill gas that contains methane, a potent greenhouse gas.\n\nOn many farms, the basic composting ingredients are animal manure generated on the farm and bedding. Straw and sawdust are common bedding materials. Non-traditional bedding materials are also used, including newspaper and chopped cardboard. The amount of manure composted on a livestock farm is often determined by cleaning schedules, land availability, and weather conditions. Each type of manure has its own physical, chemical, and biological characteristics. Cattle and horse manures, when mixed with bedding, possess good qualities for composting. Swine manure, which is very wet and usually not mixed with bedding material, must be mixed with straw or similar raw materials. Poultry manure also must be blended with carbonaceous materials - those low in nitrogen preferred, such as sawdust or straw.\n\nHuman excreta can also be added as an input to the composting process since human excreta is a nitrogen-rich organic material. It can be either composted directly, like in composting toilets, or indirectly (as sewage sludge), after it has undergone treatment in a sewage treatment plant.\n\nUrine can be put on compost piles or directly used as fertilizer. Adding urine to compost can increase temperatures and therefore increase its ability to destroy pathogens and unwanted seeds. Unlike feces, urine does not attract disease-spreading flies (such as houseflies or blowflies), and it does not contain the most hardy of pathogens, such as parasitic worm eggs. Urine usually does not smell for long, particularly when it is fresh, diluted, or put on sorbents.\n\nCompost can be used as an additive to soil, or other matrices such as coir and peat, as a tilth improver, supplying humus and nutrients. It provides a rich \"growing medium\", or a porous, absorbent material that holds moisture and soluble minerals, providing the support and nutrients in which plants can flourish, although it is rarely used alone, being primarily mixed with soil, sand, grit, bark chips, vermiculite, perlite, or clay granules to produce loam. Compost can be tilled directly into the soil or growing medium to boost the level of organic matter and the overall fertility of the soil. Compost that is ready to be used as an additive is dark brown or even black with an earthy smell.\n\nGenerally, direct seeding into a compost is not recommended due to the speed with which it may dry and the possible presence of phytotoxins in immature compost that may inhibit germination, and the possible tie up of nitrogen by incompletely decomposed lignin. It is very common to see blends of 20–30% compost used for transplanting seedlings at cotyledon stage or later.\n\nVarious approaches have been developed to handle different ingredients, locations, throughput and applications for the composted product.\n\nIndustrial-scale composting can be carried out in the form of in-vessel composting, aerated static pile composting, vermicomposting, or windrow composting, and takes place in most Western countries now.\n\nVermicompost is the product or process of organic material degradation using various species of worms, usually red wigglers, white worms, and earthworms, to create a heterogeneous mixture of decomposing vegetable or food waste (excluding meat, dairy, fats, or oils), bedding materials, and vermicast. Vermicast, also known as worm castings, worm humus or worm manure, is the end-product of the breakdown of organic matter by species of earthworm.\n\nVermicomposting can also be applied for treatment of sewage sludge.\n\nA composting toilet collects human excreta. These are added to a compost heap that can be located in a chamber below the toilet seat. Sawdust and straw or other carbon rich materials are usually added as well. Some composting toilets do not require water or electricity; others may. If they do not use water for flushing they fall into the category of dry toilets. Some composting toilet designs use urine diversion, others do not. When properly managed, they do not smell. The composting process in these toilets destroys pathogens to some extent. The amount of pathogen destruction depends on the temperature (mesophilic or thermophilic conditions) and composting time.\n\nComposting toilets with a large composting container (of the type Clivus Multrum and derivations of it) are popular in United States, Canada, Australia, New Zealand and Sweden. They are available as commercial products, as designs for self builders or as \"design derivatives\" which are marketed under various names.\n\nBlack soldier fly (\"Hermetia illucens\") larvae are able to rapidly consume large amounts of organic material when kept at around 30 °C. Black soldier fly larvae can reduce the dry matter of the organic waste by 73% and convert 16-22% of the dry matter in the waste to biomass. The resulting compost still contains nutrients and can be used for biogas production, or further traditional composting or vermicomposting The larvae are rich in fat and protein, and can be used as, for example, animal feed or biodiesel production. Enthusiasts have experimented with a large number of different waste products. Some sell starter kits to the public.\n\nThe practice of making raised garden beds or mounds filled with rotting wood is also called \"hügelkultur\" in German. It is in effect creating a nurse log that is covered with soil.\n\nBenefits of \"hügelkultur\" garden beds include water retention and warming of soil. Buried wood acts like a sponge as it decomposes, able to capture water and store it for later use by crops planted on top of the \"hügelkultur\" bed.\n\nBokashi is a method that uses a mix of microorganisms to cover food scraps or wilted plants to decrease smell, reduce the risk of attracting pests and increase the speed of decomposition. Bokashi (ぼかし) is Japanese for \"shading off\" or \"gradation.\" It derives from the practice of Japanese farmers centuries ago of covering food scraps with rich, local soil that contained the microorganisms that would ferment the material.\n\nThe technique relies on effective microorganisms. These essential microbes are typically added to the food scraps using an inoculated bokashi bran.\n\nNewspaper fermented in a lactobacillus culture can be substituted for bokashi bran for a successful bokashi bucket.\n\nThe first stage of bokashi preserves the ingredients in a lactic acid fermentation. The acid is a natural disinfectant, used as such in household cleaning products, so that what enters the second (digestion) stage is essentially free of microbial pathogens.\n\nCompost teas are defined as water extracts leached from composted materials. Compost teas are generally produced from adding one volume of compost to 4-10 volumes of water, but there has also been debate about the benefits of aerating the mixture. Field studies have shown the benefits of adding compost teas to crops due to the adding of organic matter, increased nutrient availability and increased microbial activity. They have also been shown to have an effect on plant pathogens.\n\nOrganic ingredients intended for composting can also be used to generate biogas through anaerobic digestion. This process stabilizes organic material. The residual material, sometimes in combination with sewage sludge can be treated by a composting process before selling or giving away the compost.\n\nThere are process and product guidelines in Europe that date to the early 1980s (Germany, the Netherlands, Switzerland) and only more recently in the UK and the US. In both these countries, private trade associations within the industry have established loose standards, some say as a stop-gap measure to discourage independent government agencies from establishing tougher consumer-friendly standards.\n\nThe USA is the only Western country that does not distinguish sludge-source compost from green-composts, and by default in the USA 50% of states expect composts to comply in some manner with the federal EPA 503 rule promulgated in 1984 for sludge products.\n\nCompost is regulated in Canada and Australia as well.\n\nMany countries such as Wales and some individual cities such as Seattle and San Francisco require food and yard waste to be sorted for composting (San Francisco Mandatory Recycling and Composting Ordinance).\n\nLarge-scale composting systems are used by many urban areas around the world.\n\n\nComposting as a recognized practice dates to at least the early Roman Empire, and was mentioned as early as Cato the Elder's 160 BCE piece \"De Agri Cultura\". Traditionally, composting involved piling organic materials until the next planting season, at which time the materials would have decayed enough to be ready for use in the soil. The advantage of this method is that little working time or effort is required from the composter and it fits in naturally with agricultural practices in temperate climates. Disadvantages (from the modern perspective) are that space is used for a whole year, some nutrients might be leached due to exposure to rainfall, and disease-producing organisms and insects may not be adequately controlled.\n\nComposting was somewhat modernized beginning in the 1920s in Europe as a tool for organic farming. The first industrial station for the transformation of urban organic materials into compost was set up in Wels, Austria in the year 1921. Early frequent citations for propounding composting within farming are for the German-speaking world Rudolf Steiner, founder of a farming method called biodynamics, and Annie Francé-Harrar, who was appointed on behalf of the government in Mexico and supported the country 1950–1958 to set up a large humus organization in the fight against erosion and soil degradation.\n\nIn the English-speaking world it was Sir Albert Howard who worked extensively in India on sustainable practices and Lady Eve Balfour who was a huge proponent of composting. Composting was imported to America by various followers of these early European movements by the likes of J.I. Rodale (founder of Rodale Organic Gardening), E.E. Pfeiffer (who developed scientific practices in biodynamic farming), Paul Keene (founder of Walnut Acres in Pennsylvania), and Scott and Helen Nearing (who inspired the back-to-the-land movement of the 1960s). Coincidentally, some of the above met briefly in India - all were quite influential in the U.S. from the 1960s into the 1980s.\n\nThe term \"composting\" is used worldwide with differing meanings.\n\n\"Humanure\" is a portmanteau of \"human\" and \"manure\", designating human excrement (feces and urine) that is recycled via composting for agricultural purposes. The term was first used in 1994 in a book by Joseph Jenkins that advocates the use of this organic soil amendment. The term humanure is used by compost enthusiasts in the United States but not widely used elsewhere. Because the term \"humanure\" has no authoritative definition it is subject to various uses. News reporters may use the term also for sewage sludge or biosolids.\n\n"}
{"id": "52001960", "url": "https://en.wikipedia.org/wiki?curid=52001960", "title": "Contact guidance", "text": "Contact guidance\n\nContact guidance refers to a phenomenon for which the orientation of cells and stress fibers is influenced by geometrical patterns such as nano/microgrooves on substrates, or collagen fibers in gels and soft tissues. This phenomenon was discovered in 1912, and the terminology was introduced in 1945, but it is with the development of tissue engineering that researchers drew increasing attention on this topic, seeing the potential of contact guidance in influencing the morphology and organization of cells. Nevertheless, the biological processes underlying contact guidance are still unclear.\n\nWhen cells are seeded onto flat substrates, they generally exhibit a random orientation. Conversely, when substrates have topographical patterns, the orientation of cells cultured on these surfaces is influenced by these geometrical cues. For example, if a substrate has nano/microgrooves running parallel to each other, cells orient along the direction of these topographical patterns. Therefore, cells seem to be able to sense the morphological characteristics of their surrounding and consequently respond by adopting the orientation of topographical stimuli. A similar effect can be obtained when cells are cultured on flat surfaces with lines of proteins printed on top (to which cells can adhere), interspersed by repellent lines; also in that case, cells align along the patterns.\nIt has been observed that the phenomenon of contact guidance on microgrooved surfaces is influenced by the groove width. For instance, osteoblast-like cells align along the nanogrooves only for grooves wider than 75 nm. A similar behavior has been observed with other cell types, such as fibroblasts, which align along these topographical patterns when the grooves are wider than 150 nm. On the other hand, too large values of groove widths can also decrease the effects of contact guidance \n\nCells can orient in response to contact guidance also when located inside three-dimensional structures, such as collagen gels, scaffolds, and soft tissues. For those conditions, it has been demonstrated that the geometrical cues provided by collagen or scaffold fibers are able to influence the orientation of cells. For example, it has been observed that endothelial colony forming cells align along the direction of the fibers present in electrospun scaffolds. Similarly, it has been demonstrated that the collagen fibers present in collagen gels and soft tissues can influence cell alignment, providing the most important stimulus in terms of cell orientation \n\nRecent research has highlighted the importance of cellular alignment for the mechanical properties and functionality of the prostheses developed using the principles of tissue engineering. Currently, scientists are investigating the mechanisms and potential of contact guidance to control cellular alignment, which would ultimately lead to the control of their cellular forces and certain aspects of collagen remodeling.\n\nMany researchers have formulated hypotheses on the biological mechanisms determining contact guidance. In general, cellular contraction, stress fibers and focal adhesions seem to play an important role. Recently, a computational model has been developed that is able to simulate the re-alignment of cells and stress fibers on top of grooved surfaces. Briefly, it has been supposed that cells, once seeded, form focal adhesions on top of the ridges and not above the grooves. Once formed, the focal adhesions produce a signal that starts to diffuse into the cell inducing stress fiber assembly. At this point, there are two different possibilities, depending on the groove size. On the one hand, when the groove size is small, the intracellular signal produced by focal adhesions on the ridges can homogenously reach all locations in the cell. In that case, the stress fiber assembly is isotropic, and these fibers can pull on their surroundings in an isotropic fashion, and consequently the resulting cell shape is isotropic (without a preferred alignment). On the other hand, when the groove size is relatively large, the intracellular signal cannot reach the locations of the cell situated on top of the grooves, as diffusion is limited. As a result, stress fibers form only close to the ridges, and these acto-myosin bundles pull on their surroundings anisotropically. Due to the anisotropic cellular contraction, stress fibers and cells align along the direction of the microgrooves. Further experiments are necessary to validate this theory.\n"}
{"id": "8386455", "url": "https://en.wikipedia.org/wiki?curid=8386455", "title": "Eastern Himalayan broadleaf forests", "text": "Eastern Himalayan broadleaf forests\n\nThe Eastern Himalayan broadleaf forests is a temperate broadleaf forest ecoregion found in the middle elevations of the eastern Himalayas, including parts of Nepal, India, and Bhutan. These forests have an outstanding richness of wildlife.\n\nThis ecoregion covers an area of and constitutes a band of temperate broadleaf forests lying on steep mountain slopes of the Himalayas between approximately . It extends from the Kali Gandaki River in Nepal across Sikkim and West Bengal in India, Bhutan, and the Indian state of Arunachal Pradesh.\n\nThe temperate broadleaf forests transition into the Himalayan subtropical pine forests and the Himalayan subtropical broadleaf forests at lower elevations, and into the Eastern Himalayan subalpine conifer forests at higher elevations. This area receives over 2000 mm of rainfall per year, mostly falling from May to September during the monsoon.\n\nThe Eastern Himalayan broadleaf forests are diverse and species-rich, with a great diversity (of oaks and rhododendrons in particular) and many endemic species including plants of Indomalayan, Indochinese, Himalayan, Eastern Asiatic and even Gondwanan origin. \n\nThe ecoregion has two broad forest types: evergreen and deciduous. Evergreen forests are characterized by oaks \"(Quercus\" spp.), chiefly \"Quercus lamellosa,\" together with \"Lithocarpus pachyphylla, Rhododendron arboreum, Rhododendron falconeri, Rhododendron thomsonii, Michelia excelsa, Michelia cathcartii, Bucklandia populnea, Symplocos cochinchinensis, Magnolia\" spp., \"Cinnamomum\" spp., and \"Machilus\" spp. The many rhododendron species include more than fifty in Sikkim and another sixty in Bhutan. \n\nIn the deciduous forests meanwhile the predominant tree species are Himalayan maple (\"Acer campbellii\"), \"Juglans regia\", \"Alnus nepalensis\", \"Betula alnoides\", \"Betula utilis\", and \"Echinocarpus dasycarpus\".\n\nFinally in Eastern Nepal there are wetter areas dominated by a mixture of \"Magnolia campbellii\", \"Acer campbellii\" and \"Osmanthus suavis\" along with Himalayan hazel (\"Corylus ferox\").\n\nThe forests are home to over 500 species of bird some of which migrate to the higher Himalayas in the hot summer. There are twelve near-endemic bird species as well as the strictly endemic rufous-throated wren-babbler. A number of bird species especially pheasant, tragopan and hornbill are easily threatened by changes to their habitat and those found here include the globally threatened rufous-necked hornbill (\"Aceros nipalensis\"), Sclater's monal (\"Lophophorus sclateri\"), white-bellied heron (\"Ardea insignis\"), Blyth's tragopan (\"Tragopan blythii\") and Ward's trogon (\"Harpactes wardi\").\n\nThere are four endemic or near-endemic mammals including Gee's golden langur (\"Trachypithecus geei\") which is found north of the Brahmaputra River between the Sankosh and Manas Rivers. Other endemic mammals are Hodgson's giant flying squirrel (\"Petaurista magnificus\"), Namdapha flying squirrel (\"Biswamoyopterus biswasi\") and Brahma white-bellied rat (\"Niviventer brahma\"), while endangered species found here include a population of Bengal tigers adapted to higher mountain slopes and having a high conservation priority. Other endangered species include takin (\"Budorcas taxicolor\") and Himalayan serow (a subspecies of \"Capricornis sumatraensis\") as well as the vulnerable Mandelli's mouse-eared bat (\"Myotis sicarius\"), Assam macaque (\"Macaca assamensis\"), stump-tailed macaque (\"Macaca arctoides\"), dhole (\"Cuon alpinus\"), back-striped weasel (\"Mustela strigidorsa\"), clouded leopard (\"Neofelis nebulosa\"), and Irrawaddy squirrel (\"Callosciurus pygerythrus\"). The area also includes patches of fir forest with a bamboo undergrowth that are home to the endangered red panda (\"Ailurus fulgens\").\n\nMost of the forest is intact as these are steep inaccessible slopes, although the \"Quercus lanata\" forests of the lower elevations are vulnerable to clearance, while the upper slopes are liable to be used for livestock grazing, especially in more densely populated Nepal. Protected areas include Namdapha National Park and Mehao Wildlife Sanctuary in Arunachal Pradesh, Makalu Barun National Park in Nepal, and parts of Thrumshingla, Jigme Dorji, and Jigme Singye Wangchuck National Parks and Kulong Chu Wildlife Sanctuary in Bhutan. There are plans to create corridors of protection linking some of these areas in Bhutan and in India. The area around Namdapha National Park has been increasingly settled by Chakma refugees from Bangladesh. Another threat is the plan to build a dam on the Dihing River. One area of importance that is currently unprotected is Mount Phulchowki in the Kathmandu valley.\n\nIn 1997, the World Wildlife Fund identified 15 protected areas in the ecoregion, with a combined area of approximately that includes 7% of the ecoregion's area.\n\n\n\n"}
{"id": "5027448", "url": "https://en.wikipedia.org/wiki?curid=5027448", "title": "Geological Survey of Pakistan", "text": "Geological Survey of Pakistan\n\nThe Geological Survey of Pakistan (reporting name: GSP), is an autonomous and independent institution under Ministry of Petroleum and Natural Resources which is tasked and mandate with advancing the geoscience knowledge and carrying out systematic studies on official mapping and area surveying.\n\nThe scientists of GSP thoroughly studies the landscape of Pakistan, its natural resources, and the natural hazards that threaten it. Apart from studying geology, it has various major science disciplines, concerning biology, engineering, hydrology, chemistry and physics. Due to its reputation and studies on fact-finding research, it has undertaken various efforts and studies on mineral exploration and extraction as well.\n\nHeadquartered in Quetta, it has a main office in Islamabad and other regional offices in all over the country, and as of current, Mrs Yasmin Rizvi is the current and designated director-general of the Geological Survey of Pakistan.\n\nAs early as 1836–51, the British crown government decided to set up the geological survey to explore the British Indian Empire under the British geologist David Williams who later founded the Geological Survey of India.\n\nAfter the independence of Pakistan from the British Indian Empire, the Geological Survey of India's north-west branch, staff and assets were evolved into creating to Geological Survey of Pakistan (GSP).\n\nAt the time of its establishment, the GSP had consisted of only six geologist and two chemists under British scientist H.L. Crookshank, who was at that time was the most senior scientist working. Immediately, H.L. Crookshank was appointed first director general of GSP which he remained until 1955. Under Crookshank, the technical staff was increased to 30 geoscientists in 1948. In its formative years, the GSP did the pioneering work in hydrogeology and engineering but the efforts were transfer to engineering units of the military. In 1949–55, the GSP initiated a rigorous tradition of field investigations with the governmental support, and reconnaissance technology was transferred to GSP through the Colombo Plan. Due to these activities, it increased the operational, scientific capabilities, and expansion of facilities of the GSP by 1956; it became one of the pioneering scientific institution of the government. In 1955, English geologist, E.R. Gee, took over the GSP who initiated a massive expansion programme for GSP, including engineering, photogeology sections, as well as systematic publications journals were established. In 1959, the construction of new headquarters in Quetta was completed with Dr. N.M. Khan becoming first native GSP's director.\n\nBy 1956, the GSP worked extremely close with the United States Geological Survey (USGS); the USGS established multimillion-dollar work laboratories and facilities in all over the country and cooperation continued until 1970. In 1957, the GSP discovered the large stockpiles of uranium in Sindh and Punjab. In addition, the GSP helped established country's universities to teach geoscience and engineering as part of their university programmes.\n\nIn the 1970s, due to its expansion and scientific capabilities, the GSP was instrumental in carrying out work on nuclear geography, when its scientists frequently visited in various mountain ranges of the country. The GSP notably carried out an ingenious work on nuclear geology and geography as part of the clandestine atomic bomb project, and played an integral role in the selection of the test sites. Throughout this time, the GSP's scientists continued exploring uranium and plutonium, as well as other material sources in all over the country.\n\nIn 1992, The GSP announced the discovery of the huge deposits of coal at Thar Desert in Sindh. The GSP sponsored and published various studies on the geology of Thar Desert. In the 1990s, the GSP issued and produced several maps of atlas of Pakistan, with mapping at 1:1 000 000 scale and a variety of themes published at 1:5 000 000. Economic liberalization policies of government in 1992 led the ADB to sponsor a 10-year-long multibillion-dollar mineral exploration programme to cover 14 identified mineralized zones in the country. In the 1990s, the GSP also discovered the large deposits of Gold and Copper in Western Balochistan, southwest Pakistan.\n\nIn the 2000s, the GSP gained international and public prominence when its scientists discovered and unearthed the first ever dinosaur fossils in Pakistan. The remains were thought to be around ~70 million years old and were found by geologists mapping the Barkhan district of the country's arid Balochistan province. The specimens include legs and vertebrae.\n\n\nThe GSP researchers, engineers, technicians, and scientists publish the results of their science in a variety of ways. Many researchers publish their science in peer-reviewed scientific journals as well as in one of a variety of series that includes series for preliminary results, maps data, and final results. All publications are published by the GSP and are available as public domains.\n\nIn 2006, the Geological Survey's two scientists published an assessed report, predicting the hydrological threat posed to the country. The survey was conducted immediately after the devastated earthquake in 2005, and the GSP's scientists began to study the hazards in the region, which were still geologically unstable.\n\nIn 2009, the GSP submitted another report that recommended the potentially hazardous areas of Northern Pakistan where the earthquake and seismic activities were suspected. The survey also found out that the earthquake cracks were found in all over the Atta Abad lake region. The GSP declared the eastern part of the Atta Abad as \"High Hazard\" area, and recommendations were submitted to evacuate the area.\n\n\n"}
{"id": "376049", "url": "https://en.wikipedia.org/wiki?curid=376049", "title": "Godparent", "text": "Godparent\n\nA godparent (also known as a sponsor), in many denominations of Christianity, is someone who bears witness to a child's baptism and then aids in their catechesis, as well as their lifelong spiritual formation. In the past, in some countries, the role carried some legal obligations as well as religious responsibilities. In both religious and civil views, a godparent tends to be an individual chosen by the parents to take an interest in the child's upbringing and personal development, to offer mentorship or claim legal guardianship of the child should anything happen to the parents. \n\nA male godparent is a godfather, and a female godparent is a godmother. The child is a godchild (i.e. godson for boys and goddaughter for girls).\n\nAs early as the 2nd century AD, infant baptism had begun to gain acceptance among Christians for the spiritual purification and social initiation of infants, the requirement for some confession of faith necessitated the use of adults who acted as sponsors for the child. They vocalized the confession of faith and acted as guarantors of the child’s spiritual beliefs. \n\nNormally, these sponsors were the natural parents of a child, as emphasized in 408 by St. Augustine who suggested that they could, it seems exceptionally, be other individuals. Within a century, the \"Corpus Juris Civilis\" indicates that parents had been replaced in this role almost completely. This'll was clarified in 813 when the Council of Munich prohibited natural parents from acting as godparents to their own children.\n\nBy the 5th century, male sponsors were referred to as \"spiritual fathers\", and by the end of the 6th century, they were being noted to as \"compaters\" and \"commaters\", suggesting that these were being seen as spiritual co-parents. This pattern was marked by the creation of legal barriers to marriage that paralleled those for other forms of kin. A decree of Justinian, dated to 530, outlawed marriage between a godfather and his goddaughter, and these barriers continued to multiply until the 11th century, forbidding marriage between natural and spiritual parents, or those directly related to them. As confirmation emerged as a separate rite from baptism from the 8th century, a second set of sponsors, with similar prohibitions, also emerged. The exact extent of these spiritual relationships as a bar to marriage in Catholicism was unclear until the Council of Trent, which limited it to relationships between the godparents, the child, and the parents.\n\nLuther, Zwingli, and Calvin preserved infant baptism against the attacks of more radical reformers including Anabaptists, and with it, sponsors at baptism. However, Luther strongly objected to the marriage barriers it created, Zwingli stressed the role of parents and pastors, rather than the \"witnesses\", in religious instruction, and Calvin and his followers tended to prefer the sponsors to be the natural parents. A single godparent was retained in baptism at Geneva and among French Calvinists, but some followers of Calvin, most notably in Scotland and eventually the English colonies in America, rejected them altogether.\n\nIn the early church, one sponsor seems to have been the norm, but in the early Middle Ages, there seems to have been two, one of each sex, and this practice has been largely maintained in Orthodox Christianity. In 888, the Catholic Council of Metz attempted to limit the number to one, but proliferation seems to have continued. In early 14th-century Spain, as many as 20 godparents were being chosen. In England, the Synod of Worcester (1240) stipulated three sponsors (two of the same sex and one of the opposite), and this has remained the norm in the Church of England. The Council of Trent attempted to limit the numbers of godparents to one or two, but practice has differed across the Catholic world.\n\nThe Church of England, the mother Church of the Anglican Communion, retained godparents in baptism, formally removing the marriage barriers in 1540, but the issue of the role and status of godparents continued to be debated in the English Church. They were abolished in 1644 by the Directory of Public Worship promulgated by the English Civil War Parliamentary regime, but continued to be used in some parishes in the north of England. After the Restoration in 1660, they were reintroduced to Anglicanism, with occasional objections, but dropped by almost every dissenting church. There is some evidence that the restored institution had lost some of its social importance as well as its universality.\n\nAt present, in the Church of England, relatives can stand as godparents, and although it is not clear that parents can be godparents, they sometimes are. Godparents should be both baptized and confirmed (although it is not clear in which Church), but the requirement for confirmation can be waived. There is no requirement for clergy to baptize those from outside their parishes, and baptism can be reasonably delayed so that the conditions, including suitable godparents, can be met. As a result, individual clergy have considerable discretion over the qualifications of godparents. Many \"contemporary Anglican rites likewise require parents and godparents to respond on behalf of infant [baptismal] candidates.\"\n\nLutherans follow a similar theology of godparents as Roman Catholics. They believe that godparents \"help [children] with their Christian upbringing, especially if they should lose their parents\". Lutherans, like Roman Catholics, believe that a godparent must be both a baptized and confirmed Christian. Some Lutherans also follow the Roman Catholic tradition that a Christian who is not affiliated with the Lutheran denomination may serve as a witness rather than a godparent.\n\nThe Book of Discipline stipulates that it is the duty of a godparent, also known as a sponsor, \"to provide training for the children of the Church throughout their childhood that will lead to a personal commitment to Jesus Christ as Lord and Savior, to an understanding of the Christian faith, and to an appreciation of the privileges and obligations of baptism and membership (¶ 225.4).\" John Wesley, the founder of the Methodist Church, wrote a homily titled \"Serious Thoughts Concerning Godfathers and Godmothers\" in which he stated that godparents are \"spiritual parents to the baptized, whether they were infants or [adults]; and were expected to supply whatever spiritual helps were wanting either through the death or neglect of the natural parents.\" He described the role of godparents, instructing that they should call upon their godchild \"to hear sermons, and shall provide that he(/she) may learn the Creed, the Lord's Prayer, and the Ten Commandments, and all other things which a Christian ought to know and believe to his soul's health; and that this child be virtuosly brought up, to lead a godly and a Christian life.\" As such, the Book of Worship states that godparents/sponsors should be \"selected carefully\" and \"should be members of Christ's holy Church; and it is the duty of pastors to instruct them concerning the significance of Holy Baptism, their responsibilities for the Christian training of the baptized child, and how these obligations may be fulfilled.\"\n\nThe Orthodox institution of godparenthood has been the least affected of the major traditions by change. In some Orthodox churches (Serbian, Greek) usually the best man (kum, кум, koumbaros) or bridesmaid (kuma, кума, koumbara) at a couple's wedding act as a godparent to the first or all children of the marriage. In some instances, the godfather is responsible for naming the child. A godparent to a child will then act as a sponsor at the child's wedding. Godparents are expected to be in good standing in the Orthodox church, including its rulings on divorce, and aware of the meaning and responsibilities of their role. They cannot be a minor or a parent of the child, and at least one sponsor must be Orthodox.\n\nIn the Reformed tradition that includes the Continental Reformed, Congregationalist and Presbyterian Churches, the godparents are more often referred to as \"sponsors\", who have the role of standing with the child during infant baptism and pledging to instruct the child in the faith. In the bapismal liturgy of Reformed Geneva, \"the traditional presence of godparents was retained\". John Calvin, the progenitor of the Reformed tradition, himself served as a godparent during forty-seven baptisms. The Reformed Church in Geneva, in order to ensure confessional orthodoxy, \"expected parents to select Reformed godparents.\" Today, many Reformed churches invite parents to select godparents for their prospective neophyte, while other parishes entrust this responsibility to the whole congregation.\n\nThe Catholic institution of godparenthood survived the Reformation largely unchanged. A godparent must normally be an appropriate person, at least sixteen years of age, a confirmed Catholic who has received the Eucharist, not under any canonical penalty, and may not be the parent of the child. Someone who belongs to another Christian church cannot become a godparent but can be a 'witness' in conjunction with a Catholic sponsor. A witness does not have any religious role recognized by the Church.\n\nIn 2015, the Vatican declared that transgender Catholics cannot become godparents, stating in response to a transgender man's query that transgender status \"reveals in a public way an attitude opposite to the moral imperative of solving the problem of sexual identity according to the truth of one's own sexuality\" and that, \"[t]herefore it is evident that this person does not possess the requirement of leading a life according to the faith and in the position of godfather and is therefore unable to be admitted to the position of godfather or godmother.\"\n\nIn some Catholic and Orthodox countries, particularly in southern Europe, Latin America, and the Philippines, the relationship between parents and godparents or co-godparents has been seen as particularly important and distinctive. These relationships create mutual obligations and responsibilities that may be socially useful for participants. The Portuguese and Spanish \"compadre\" (literally, \"co-father\") and \"comadre\" (\"co-mother\"), the French \"marraine\" and \"parrain\", and the archaic meaning of the English word \"gossip\" (from \"godsib,\" \"godsibling\"), describe these relationships. By extension, they can also be used to describe a friendship.\n\nThe Spanish and Portuguese words for the godparent roles are used for members of the wedding party—\"padrino/padrinho\" meaning \"godfather\" or \"best man\" and \"madrina/madrinha\" meaning \"godmother\" or \"matron of honor\", reflecting the custom of baptismal sponsors acting in this role in a couple's wedding.\n\nThe Spanish custom was also adopted in the Philippines, a predominantly Christian country in Southeast Asia that was a former part of the Spanish Empire. The Filipino terms \"ninong\" for godfather and \"ninang\" for godmother, were also borrowed from Hispanic custom, and apply to godparents in both a child's Baptism and the child's later Confirmation. In the context of a wedding, the terms instead refer to the principal sponsors of the couple.\n\nGodparents are noted features of fairy tales and folklore written from the 17th century onwards, and by extension, have found their way into many modern works of fiction. In \"Godfather Death\", presented by the Brothers Grimm, the archetype is, unusually, a supernatural godfather. However, most are a fairy godmother as in versions of \"Cinderella\", \"Sleeping Beauty\", and \"The Blue Bird\". This feature may simply reflect the Catholic milieu in which most fairy tales were created, or at least recorded, and the accepted role of godparents as helpers from outside the family, but feminist Marina Warner suggests that they may be a form of wish fulfilment by female narrators.\n\nIn the Yoruba religion Santería, godparents must have completed their santo or their Ifá. A person gets his Madrina and Yubona (co-godmother) or his Padrino and Yubon (co-godfather). A santero, aside from his co-godparents, may have an oluo (babalawo, initiate of ifa) who consults him with an ekuele (divinating chain).\n\nThere are two roles in the Jewish circumcision ceremony that are sometimes translated as \"godparent\". The sandek holds the baby boy while he is circumcised. Among Orthodox Ashkenazi, the kvater (or kvaterin if female) is the person who takes the child from his mother and carries him into the room in which the circumcision is performed. Kvater is etymologically derived from the archaic German \"Gevatter\" (\"godfather\").\n\nSome Chinese communities practise the custom of matching a child with a relative or family friend who becomes the godmother (乾媽) or godfather (乾爹). This practice is largely non-religious in nature, but commonly done to strengthen ties or to fulfill the wish of a childless adult to have a \"son/daughter\". In most circumstances, an auspicious day is selected during which a ceremony takes place, involving the godchild paying his/her respects to his new godfather/godmother in the presence of relatives or friends.\n\nAlternatively, as it is already common in Chinese kinship to use kinship terms among people that are not related (e.g. addressing a respected coworker as \"brother\" or one's father's friend may be referred to as \"uncle\"), an older friend or family friend with a deep friendship and a sufficient age gap will also informally address the other as his godparent or godchild, a gesture often initiated by the older person.\n\n"}
{"id": "26288862", "url": "https://en.wikipedia.org/wiki?curid=26288862", "title": "Green wedding", "text": "Green wedding\n\nA green wedding or an eco-friendly wedding is any wedding where the couple tries to decrease the impact of their event on the planet. Couples plan their weddings by integrating eco-friendly alternatives, such as eco-friendly invitations, flowers, dress, photography and more. \n\nA green wedding is one that is eco-friendly and conscious of the consumption of resources that would otherwise be used in the wedding. \nThis can include recycling waste, choosing a sustainable venue and even neglecting to participate in traditional practices that could be considered unsustainable such as buying diamond rings. \nMany people who live green lifestyles believe it is necessary to continue with making sure their weddings are green as well. Others choose green weddings to raise awareness to others of how sustainability is important in daily activities and celebrations. The largest factor that contributes to the growing number of green weddings is the impact wedding celebrations can have on the environment. Many argue that without being conscious of practices and items used, the average wedding can generate a large amount of waste.\n\nOne key concept for keeping a wedding eco-friendly is to ensure that the items being used will not quickly become waste, mainly one-time disposable items such as hosiery, plates, cups, ornaments or wedding favors. Many green weddings have instead opted for borrowed or recycled items. Another option chosen is to rent items needed for the wedding instead of buying all new equipment/decorations instead to control the amount of waste that could be created. \nIn other matters that consist of planning a wedding, the main basis is to prevent or reduce all harmful impacts that could be placed on the environment either directly or indirectly by resources used for the wedding. The average wedding produces 400 lbs of garbage and 63 tons of CO2. Together, American weddings are equivalent to 8.3 million cars driving on the road for a year. This can include flowers, paper (invitations), textiles (dress, suits), gas emissions (transportation), and everything else that can occur from the wedding. \nAnother important factor that is considered important is picking of the flowers. Flowers can add a huge impact on the environment due to fertilizers used and gas emissions that are released to transport the flowers. Many green wedding planners opt to have their flowers supplied by organic florist or even to grow their own. \nAnother common practice is to consider what to do with the flowers after the wedding. Some weddings have had flowers that are replanted after the big day to minimize waste and allow the flowers to continue to grow afterwards. \n\nSome people decorate wedding halls with potted plants without picking flowers. If they give the plant to the guests as a gift, they can grow flowers while thinking about the bride and groom.\nThere is a large amount of paper used in weddings throughout the entire process. One large reason paper is used so largely is because of invitations. Green wedding planners are careful when selecting how to invite others due to the impact this can have. \nSome options that are more sustainable are \n\nFood is one important factor that affects how sustainable a wedding is. Some planners choose to get all their food supplied by local/organic growers to help eliminate the amount of chemicals that would have used in the growing of the food or the transportation of it. Wedding cakes are generally made out of all organic ingredients as well to reduce the chemicals used in the production of the ingredients. \nMany sustainable practices that are done in green weddings are to have the leftovers composted after or to have untouched meals donated to local charities.\n\nOne of the biggest contributors to waste that can be generated is the wedding dress. Many argue that one of the ways to continue with a sustainable wedding to use a dress that can be re-worn or borrowed from another. This eliminates the one-time use principle violation. Also choosing a wedding dress that is made out of organic fibre ensures that the garment had minimal impact on the environment during its production. \nMany green brides opt to purchase a vintage/second hand dress and have it altered instead of buying a new dress instead. Other brides choose to sell or donate their dress after the wedding or have it recycled to create a new garment.\n\n"}
{"id": "23276824", "url": "https://en.wikipedia.org/wiki?curid=23276824", "title": "Guatemalan National Natural History Museum", "text": "Guatemalan National Natural History Museum\n\nThe Guatemalan National Natural History Museum or Museo de Historia Natural is a national natural history museum in Guatemala City, Guatemala. The museum has an extensive collection of Guatemalan flora and fauna specimens, and has a significant number of archives from geology and paleontology in the country.\n\n"}
{"id": "25865522", "url": "https://en.wikipedia.org/wiki?curid=25865522", "title": "International Magnetospheric Study", "text": "International Magnetospheric Study\n\nThe International Magnetospheric Study (IMS) was proposed in 1970 as a concerted effort to acquire coordinated ground-based, balloon, rocket, and satellite data needed to improve our understanding of the behavior of earth's plasma environment.\n\nProjects done as a contribution to International Magnetospheric Study:\n\n"}
{"id": "1749464", "url": "https://en.wikipedia.org/wiki?curid=1749464", "title": "Kerangas forest", "text": "Kerangas forest\n\nSundaland heath forest, also known as \"Kerangas\" forest, is a type of tropical moist forest found on the island of Borneo, which is divided between Brunei, Indonesia, and Malaysia, as well as on the Indonesian islands of Belitung and Bangka, which lie to the west of Borneo.\n\nThe word \"Kerangas\", which means \"land which cannot grow rice\", came from the Iban language. Heath forests occur on acidic sandy soils that are the result of the area's siliceous parent rocks. Permanently waterlogged heath forests are known as \"kerapah\" forests. The sandy soil of the heath forest are often lacking in nutrients; it is generally considered that nitrogen is the nutrient which is most lacking for plant growth in these forests. This is in contrast to many other lowland rain forests where phosphorus is considered to be lacking.\n\nA more recent hypothesis, proposed by Proctor (1999), is that these forests are growing on soils which are highly acidic, such that hydrogen ion toxicity prevents the growth of non-adapted species.\n\nThe Sundaland heath forests are distinct from the surrounding Borneo lowland rain forests in species composition, structure, texture, and color. The heath forests have a low, uniform canopy, with thick underbrush and rich growth of moss and epiphytes.\n\nMany tree and plant species in the nutrient-deprived heath forests have developed unconventional ways to get their nutrients. Some tree species (\"Gymnostoma nobile\", for example) utilise rhizobia (nitrogen fixing bacteria) in their root nodules. Myrmecophytes, including \"Myrmecodia\" spp. and \"Hydnophytum\" spp., are tree species that develop symbiotic associations with ants to get their nutrients. Other plants, including pitcher plants \"(Nepenthes\" spp.), sundews \"(Drosera\" ssp.), and bladderwort \"(Utricularia\" ssp.), are carnivorous, trapping and digesting insects.\n\nThe heath forests are characterized by many plants of Australasian origin, including trees of families Myrtaceae and Casuarinaceae and the southern hemisphere conifers \"Agathis\", \"Podocarpus\", and \"Dacrydium\".\n\n"}
{"id": "1183639", "url": "https://en.wikipedia.org/wiki?curid=1183639", "title": "Laurel forest", "text": "Laurel forest\n\nLaurel forest, also called laurisilva or laurissilva, is a type of subtropical forest found in areas with high humidity and relatively stable, mild temperatures. The forest is characterized by broadleaf tree species with evergreen, glossy and elongated leaves, known as \"laurophyll\" or \"lauroid\". Plants from the laurel family (Lauraceae) may or may not be present, depending on the location.\n\nLaurel forests are specific to wet forests from sea level to the highest mountains, but are poorly represented in areas with a pronounced dry season.\nThey need an ecosystem of high humidity, such as cloud forests, with abundant rainfall throughout the year. Laurel forests typically occur on the slopes of tropical or subtropical mountains, where the moisture from the ocean condenses so that it falls as rain or fog and soils have high moisture levels. Some evergreen tree species will survive short frosts, but most species will not survive hard freezes and prolonged cool weather. They need a mild climate with annual temperature oscillation moderated by the proximity of the ocean. These conditions of temperature and moisture occur in four different geographical regions:\n\n\nSome laurel forests are a type of cloud forest. Cloud forests are found on mountain slopes where the dense moisture from the sea or ocean is precipitated as warm moist air masses blowing off the ocean are forced upwards by the terrain, which cools the air mass to the dew point. The moisture in the air condenses as rain or fog, creating a habitat characterized by cool, moist conditions in the air and soil. The resulting climate is wet and mild, with the annual oscillation of the temperature moderated by the proximity of the ocean.\n\nLaurel forests are characterized by evergreen and hardwood trees, reaching up to in height. Laurel forest, laurisilva, and laurissilva all refer to plant communities that resemble the laurel bay.\n\nSome species belong to the true laurel family or Lauraceae, but many have similar foliage to the Lauraceae due to convergent evolution. As in any other rainforest, plants of the laurel forests must adapt to high rainfall and humidity. The trees adapted in response to these ecological drivers by developing analogous structures, leaves that repel water. Laurophyll or lauroid leaves are characterized by a generous layer of wax, making them glossy in appearance, and a narrow, pointed oval shape with an \"apical mucro\" or \"drip tip\", which permits the leaves to shed water despite the humidity, allowing perspiration and respiration. The scientific names \"laurina\", \"laurifolia\", \"laurophylla\", \"lauriformis\", and \"lauroides\" are often used to name species of other plant families that resemble the Lauraceae. The term \"Lucidophyll\", referring to the shiny surface of the leaves, was proposed in 1969 by Tatuo Kira. The scientific names \"Daphnidium\", \"Daphniphyllum\", \"Daphnopsis\", \"Daphnandra\", \"Daphne\" from Greek: Δάφνη, meaning \"laurel\", \"laural\", \"Laureliopsis\", \"laureola\", \"laurelin\", \"Laurelindorinan\", \"laurifolia\", \"Cistus laurifolius\" (Laurel Rockrose), \"laurifolius\", \"lauriformis\", \"laurina\", \"laurophylla\", \"laurocerasus\", \"laurus\", \"Prunus laurocerasus\" (English laurel), \"Prunus lusitanica\" (Portugal laurel), \"Corynocarpus laevigatus\" (New Zealand Laurel), and \"Corynocarpus rupestris\" designate species of other plant families that resemble Lauraceae. The term \"lauroid\" is also applied to climbing plants such as ivies whose leaves resemble those of the Lauraceae.\n\nMature laurel forests typically have a dense tree canopy and low light levels at the forest floor. Some forests are characterized by an overstory of emergent trees.\n\nLaurel forests are typically multi-species, and diverse in both the number of species and the genera and families represented. In the absence of strong environmental selective pressure, the number of species sharing the arboreal stratum is high, although not reaching the value of tropical forests; nearly 100 tree species have been described in the laurisilva rainforest of Misiones (Argentina), about 20 in the Canary Islands. This species diversity contrasts with other temperate forest types, which typically have a canopy dominated by one or a few species. Species diversity generally increases towards the tropics. In this sense, the laurel forest is a transitional type between temperate forests and tropical rainforests.\n\nLaurel forests are composed of vascular plants that evolved millions of years ago. Lauroid floras have included forests of Podocarpaceae and southern beech.\n\nThis type of vegetation characterized parts of the ancient supercontinent of Gondwana and once covered much of the tropics. Some lauroid species that are found outside laurel forests are relicts of vegetation that covered much of the mainland of Australia, Europe, South America, Antarctica, Africa, and North America when their climate was warmer and more humid. Cloud forests are believed to have retreated and advanced during successive geological eras, and their species adapted to warm and wet conditions were replaced by more cold-tolerant or drought-tolerant sclerophyll plant communities. Many of the late Cretaceous – early Tertiary Gondwanan species of flora became extinct, but some survived as relict species in the milder, moister climate of coastal areas and on islands. Thus Tasmania and New Caledonia share related species extinct on the Australian mainland, and the same case occurs on the Macaronesia islands of the Atlantic and on the Taiwan, Hainan, Jeju, Shikoku, Kyūshū, and Ryūkyū Islands of the Pacific.\n\nAlthough some remnants of archaic flora, including species and genera extinct in the rest of the world, have persisted as endemic in such coastal mountain and shelter sites, their biodiversity was reduced. Isolation in these fragmented habitats, particularly on islands, has led to the development of vicariant species and genera. Thus, fossils dating from before the Pleistocene glaciations show that species of \"Laurus\" were formerly distributed more widely around the Mediterranean and North Africa. Isolation gave rise to \"Laurus azorica\" in the Azores Islands, \"Laurus nobilis\" on the mainland, and \"Laurus novocanariensis\" in the Canary Islands.\n\nLaurel forests occur in small areas where their particular climatic requirements prevail, in both the northern and southern hemispheres. Inner laurel forest ecoregions, a related and distinct community of vascular plants, evolved millions of years ago on the supercontinent of Gondwana, and species of this community are now found in several separate areas of the Southern Hemisphere, including southern South America, southernmost Africa, New Zealand, Australia and New Caledonia. Most Laurel forest species are evergreen, and occur in tropical, subtropical, and mild temperate regions and cloud forests of the northern and southern hemispheres, in particular the Macaronesian islands, southern Japan, Madagascar, New Caledonia, Tasmania, and central Chile, but they are pantropical, and for example in Africa they are endemic in the Congo region, Cameroon, Sudan, Tanzania, and Uganda, in lowland forest and Afromontane areas.\nSince laurel forests are archaic populations that diversified as a result of isolation on islands and tropical mountains, their presence is a key to dating climatic history.\n\nLaurel forests are common in subtropical eastern Asia, and form the climax vegetation in far southern Japan, Taiwan, southern China, the mountains of Indochina, and the eastern Himalayas. In southern China, laurel forest once extended throughout the Yangtze Valley and Sichuan Basin from the East China Sea to the Tibetan Plateau. The northernmost laurel forests in East Asia occur at 39° N. on the Pacific coast of Japan. Altitudinally, the forests range from sea-level up to 1000 metres in warm-temperate Japan, and up to 3000 metres elevation in the subtropical mountains of Asia. Some forests are dominated by Lauraceae, while in others evergreen laurophyll trees of the beech family (Fagaceae) are predominant, including ring-cupped oaks (\"Quercus\" subgenus \"Cyclobalanopsis\"), chinquapin (\"Castanopsis\") and tanoak (\"Lithocarpus\"). Other characteristic plants include \"Schima\" and \"Camellia\", which are members of the tea family (Theaceae), as well as magnolias, bamboo, and rhododendrons. These subtropical forests lie between the temperate deciduous and conifer forests to the north and the subtropical/tropical monsoon forests of Indochina and India to the south.\n\nAssociations of Lauraceous species are common in broadleaved forests; for example, \"Litsea\" spp., \"Litsea cupola, Persea odoratissima, Persea duthiei,\" etc., along with such others as \"Engelhardtia spicata, Rhododendron arboreum, Lyonia ovalifolia, Pyrus pashia, Rhus\" spp., \"Acer oblongum, Myrica esculenta, Michelia kisopa\", and \"Betula alnoides\". Some other common trees and large shrub species of subtropical forests are \"Semecarpus anacardium, Cretaeava unilocularis, Trewia nudiflora, Premna interrupta, Ulmus lancifolia, Ulmus chumlia, Glochidium velutinum, Callicarpa arborea, Toona ciliata, Ficus\" spp., \"Mahosama similicifolia, Trevesia palmate, Xylosma longifolium, Boehmeria rugulosa, Scheffera venulosa, Michelia\" spp., \"Casearia graveilens, Rhus wallichii, Actinodaphne reticulata, Sapimum insegne, Alnus nepalensis, Ardisia thyrsiflora, Ilex\" spp, \"Macaranga pustulata, Trichilia cannoroides, Celtis tetranda, Wenlendia puberula, Saurauia nepalensis, Ligustrum confusum, Quercus glauca, Zizyphus incurva, Camellia kissi, Hymenodictyon flaccidum, Maytenus thomsonii, Zanthoxylum armatum, Rhus succednea, Eurya acuminata, Myrsine semiserrata, Slonea tomentosa, Hydrangea asper, Symplocus\" spp., \"Cleyrea\" spp. and \"Quercus lamellose\".\n\nIn the temperate zone, the cloud forest between 2,000 and 3,000 m altitude supports broadleaved evergreen forest dominated by plants such as \"Quercus lamillosa\" and \"Q. semicarpifolia\" in pure or mixed stands. \"Lindera\" and \"Litsea\" species, \"Tsuga dumosa\", and \"Rhododendron\" spp. are also present in the upper levels of this zone. Other important species are \"Magnolia campbellii, Michelia doltsopa, Pieris ovalifolia, Daphnephyllum himalayanse, Acer campbellii, Acer pectinatum\", and \"Sorbus cuspidata\", but these species do not extend toward the west beyond central Nepal. \"Alnus nepalensis\", a pioneer tree species, grows gregariously and forms pure patches of forests on newly exposed slopes, in gullies, beside rivers, and in other moist places.\n\nThe common forest types of this zone include \"Rhododendron arboreum, Rhododendron barbatum, Lyonia\" spp., \"Pieris formosa; Tsuga dumosa\" forest with such deciduous taxa as \"Acer\" and \"Magnolia\"; deciduous mixed broadleaved forest of \"Acer campbellii, Acer pectinatum, Sorbus cuspidata\", and \"Magnolia campbellii\"; mixed broadleaved forest of \"Rhododendron arboreum, Acer campbellii, Symplocos ramosissima\" and Lauraceae.\n\nThis zone is habitat for many other important tree and large shrub species such as \"Abies pindrow, Betula utilis, Buxus rugulosa, Benthamidia capitata, Corylus ferox, Deutzia staminea, Euonymus tingens, Abies spectalbilis, Acanthopanax cissifolius, Acer campbellii, Acer pectinatum, Betula alnoides, Coriaria terminalis, Fraxinus macrantha, Dodecadenia grandiflora, Eurya cerasifolia, Hydrangea heteromala, Ilex dipyrena, Ligustrum\" spp., \"Litsea elongata, Juglans regia, Lichelia doltsopa, Myrsine capitallata, Neolitsea umbrosa, Philadelphus tomentosus, Osmanthus fragrans, Prunus cornuta, Rhododendron companulatum, Sorbus cuspidate\", and \"Viburnum continifolium\".\n\nIn ancient times, laurel forests (\"shoyojurin\") were the predominant vegetation type in the Taiheiyo evergreen forests ecoregion of Japan, which encompasses the mild temperate climate region of southeastern Japan's Pacific coast. There were three main types of evergreen broadleaf forests, in which \"Castanopsis\", \"Machilus\", or \"Quercus\" predominated. Most of these forests were logged or cleared for cultivation and replanted with faster-growing conifers, like pine or hinoki, and only a few pockets remain.\n\n\nLaurel forests occupy the humid tropical highlands of the Malay Peninsula, Greater Sunda Islands, and Philippines above elevation. The flora of these forests is similar to that of the warm-temperate and subtropical laurel forests of East Asia, including oaks \"(Quercus)\", tanoak \"(Lithocarpus)\", chinquapin \"(Castanopsis)\", Lauraceae, Theaceae, and Clethraceae.\n\nEpiphytes, including orchids, ferns, moss, lichen, and liverworts, are more abundant than in either temperate laurel forests or the adjacent lowland tropical rain forests. Myrtaceae are common at lower elevations, and conifers and rhododendrons at higher elevations. These forests are distinct in species composition from the lowland tropical forests, which are dominated by Dipterocarps and other tropical species.\n\n\nLaurel forests are found in the islands of Macaronesia in the eastern Atlantic, in particular the Azores, Madeira Islands, and Canary Islands from 400 to 1200 metres elevation. Trees of the genera \"Apollonias\" (Lauraceae), \"Ocotea\" (Lauraceae), \"Persea\" (Lauraceae), \"Clethra\" (Clethraceae), \"Dracaena\" (Ruscaceae), and \"Picconia\" (Oleaceae) are characteristic. The Madeira Islands laurel forest was designated a World Heritage site by UNESCO in 1999. The paleobotanical record of Madeira reveals that laurissilva forests has existed in this island for at least 1.8 million years.\n\nMillions of years ago, laurel forests were widespread around the Mediterranean Basin. The drying of the region since the Pliocene and cooling during the Ice Ages caused these rainforests to retreat. Some relict Mediterranean laurel forest species, such as sweet bay \"(Laurus nobilis)\" and European holly \"(Ilex aquifolium)\", are fairly widespread around the Mediterranean basin.\n\nIn the Mediterranean there are other areas with species adapted to the same habitat, but which do not form a laurel forest. The most important is the ivy, a climber or vine that is well represented in most of Europe, where it spread again after the glaciations. The \"loro\" (\"Prunus lusitanica\") is the only tree that survives as a relict in some Iberian riversides, especially in the western part of the peninsula, particularly the Extremadura, and to a small extent in the Northeast. In other cases, the presence of Mediterranean laurel (\"Laurus nobilis\") provides an indication of the previous existence of laurel forest. This species survives natively in Morocco, Italy, Portugal, Greece, the Mediterranean islands, and some areas of Spain, including the Parque Natural Los Alcornocales in the province of Cádiz and in coastal mountains, especially in the Girona Province of Catalonia, which keeps the best \"lauredales\", and isolated in the Valencia area. Cortegada Island in Galicia is famous for its vast forest of laurels, but this forest is not indigenous to the island, but originated in plantings after the native vegetation had been destroyed. The myrtle spread through North Africa. Tree Heath \"(Erica arborea)\" grows in southern Iberia, but without reaching the dimensions observed in the temperate evergreen forest or North Africa. The subspecies \"Rhododendron ponticum baeticum\" and/or \"Rhamnus frangula baetica\" still persist in humid microclimates, such as stream valleys, in Spain's Baetic Cordillera, in the Portuguese mountains of Monchique, and the Rif Mountains of Morocco.\n\nAlthough the Atlantic laurisilva is more abundant in the Macaronesian archipelagos, where the weather has fluctuated little since the Tertiary, there are small representations and some species contribution to the oceanic and Mediterranean ecoregions of Europe, Asia minor and west and north of Africa, where microclimates in the coastal mountain ranges form inland \"islands\" favorable to the persistence of laurel forests. In some cases these were genuine islands in the Tertiary, and in some cases simply areas that remained ice-free. When the Strait of Gibraltar reclosed, the species repopulated toward the Iberian Peninsula to the north and were distributed along with other African species, but the seasonally drier and colder climate, prevented them reaching their previous extent. In Atlantic Europe, subtropical vegetation is interspersed with taxa from Europe and North African in bioclimatic enclaves such as Monchique, Sintra, and the coastal mountains from Cadiz to Algeciras. In the Mediterranean region, remnant laurel forest is present in some islands of the Aegean Sea, on the Black Sea coast of Iran and Turkey, including the laurifolia castanopsis and true laurus forests, associated with \"Prunus laurocerasus\", and conifers such as \"Taxus baccata\", \"Cedrus atlantica\", and \"Abies pinsapo\".\n\nIn Europe the laurel forest has been badly damaged by timber harvesting, by fire (both accidental and deliberate to open fields for crops), by the introduction of exotic animal and plant species that have displaced the original cover, and by replacement with arable fields, exotic timber plantations, cattle pastures, and golf courses and tourist facilities. Most of the biota is in serious danger of extinction. The laurel forest flora are usually strong and vigorous, so the forest regenerates easily; its decline is due to external forces.\n\nIn the Himalayas, in Nepal, subtropical forest consists of species such as \"Schima wallichii\", \"Castanopsis indica\", and \"Castanopsis tribuloides\" in relatively humid areas. Some common forest types in this region include \"Castanopsis tribuloides\" mixed with \"Schima wallichi, Rhododendron\" spp., \"Lyonia ovalifolia, Eurya acuminata\", and \"Quercus glauca\"; \"Castanopsis\"-Laurales forest with \"Symplocas\" spp.; \"Alnus nepalensis\" forests; \"Schima wallichii-Castanopsis indica\" hygrophile forest; \"Schima-Pinus\" forest; \"Pinus roxburghii\" forests with \"Phyllanthus emblica. Semicarpus anacardium\", \"Rhododendron arboreum\" and \"Lyoma ovalifolia; Schima-Lagestromea parviflora\" forest, \"Quercus lamellosa\" forest with \"Quercus lenata\" and 'Quercus glauca; \"Castanopsis\" forests with \"Castanopsis hystrix\" and Lauraceae.\n\nLaurel forests are also prevalent in the montane rain forests of the South Western Ghats in southern India.\n\nLaurel forest occurs in the montane rain forest of Sri Lanka.\n\nThe Afromontane laurel forests describe the plant and animal species common to the mountains of Africa and the southern Arabian Peninsula. The afromontane regions of Africa are discontinuous, separated from each other by lowlands, resembling a series of islands in distribution. Patches of forest with Afromontane floristic affinities occur all along the mountain chains. Afromontane communities occur above elevation near the equator, and as low as elevation in the Knysna-Amatole montane forests of South Africa. Afromontane forests are cool and humid. Rainfall is generally greater than , and can exceed in some regions, occurring throughout the year or during winter or summer, depending on the region. Temperatures can be extreme at some of the higher altitudes, where snowfalls may occasionally occur.\n\nIn Subsaharan Africa, laurel forests are found in the Cameroon Highlands forests along the border of Nigeria and Cameroon, along the East African Highlands, a long chain of mountains extending from the Ethiopian Highlands around the African Great Lakes to South Africa, in the Highlands of Madagascar, and in the montane zone of the São Tomé, Príncipe, and Annobón moist lowland forests. These scattered highland laurophyll forests of Africa are similar to one another in species composition (known as the Afromontane flora), and distinct from the flora of the surrounding lowlands.\n\nThe main species of the Afromontane forests include the broadleaf canopy trees of genus \"Beilschmiedia\", with \"Apodytes dimidiata\", \"Ilex mitis\", \"Nuxia congesta\", \"N. floribunda\", \"Kiggelaria africana\", \"Prunus africana\", \"Rapanea melanophloeos\", \"Halleria lucida\", \"Ocotea bullata\", and \"Xymalos monospora\", along with the emergent conifers \"Podocarpus latifolius\" and \"Afrocarpus falcatus\". Species composition of the Subsaharan laurel forests differs from that of Eurasia. Trees of the Laurel family are less prominent, limited to \"Ocotea\" or \"Beilschmiedia\" due to exceptional biological and paleoecological interest and the enormous biodiversity mostly but with many endemic species, and the members of the beech family (Fagaceae) are absent. \n\nTrees can be up to tall and distinct strata of emergent trees, canopy trees, and shrub and herb layers are present. Tree species include: Real Yellowwood (\"Podocarpus latifolius\"), Outeniqua Yellowwood (\"Podocarpus falcatus\"), White Witchhazel (\"Trichocladus ellipticus\"), \"Rhus chirendensis\", \"Curtisia dentata\", \"Calodendrum capense\", \"Apodytes dimidiata\", \"Halleria lucida\", \"llex mitis\", \"Kiggelaria africana\", \"Nuxia floribunda\", \"Xymalos monospora\", and \"Ocotea bullata\". Shrubs and climbers are common and include: Common Spikethorn (\"Maytenus heterophylla\"), Cat-thorn (\"Scutia myrtina\"), Numnum (\"Carissa bispinosa\"), \"Secamone alpinii\", \"Canthium ciliatum\", \"Rhoicissus tridentata\", \"Zanthoxylum capense\", and \"Burchellia bubalina\". In the undergrowth grasses, herbs and ferns may be locally common: Basketgrass (\"Oplismenus hirtellus\"), Bushman Grass (\"Stipa dregeana\" var. \"elongata\"), Pigs-ears (\"Centella asiatica\"), \"Cyperus albostriatus\", \"Polypodium polypodioides\", \"Polystichum tuctuosum\", \"Streptocarpus rexii\", and \"Plectranthus\" spp. Ferns, shrubs and small trees such as Cape Beech (\"Rapanea melanophloeos\") are often abundant along the forest edges.\n\nAccording to the recent study by Box and Fujiwara (Evergreen Broadleaved Forests of the Southeastern United States: Preliminary Description), laurel forests occur in patches in the southeastern United States from southeast North Carolina southward to Florida, and west to Texas, mostly along the coast and coastal plain of the Gulf and south Atlantic coast. In the southeastern United States, evergreen Hammock (ecology) (i.e. topographically induced forest islands) contain many laurel forests. These laurel forests occur mostly in moist depression and floodplains. In many portions of the coastal plain, a low-lying mosaic topography of white sand, silt, and limestone (mostly in Florida), separate these laurel forests. Frequent fire is also thought to be responsible for the disjointed geography of laurel forests across the coastal plain of the southeastern United States.\n\nDespite being located in a humid climate zone, much of the broadleaf Laurel forests in the Southeast USA are semi-sclerophyll in character. The semi-sclerophyll character is due (in part) to the sandy soils and often periodic semi-arid nature of the climate. As one moves south into central Florida, the sclerophyll character slowly declines and more tree species from the tropics (Caribbean) increase as the temperate species decline. As such, the southeastern laurel forests gives way to tropical savanna.\n\nThere are several different broadleaved evergreen canopy trees in the laurel forests of the southeastern United States. In some areas, the evergreen forests are dominated by species of Live Oak (\"Quercus virginiana\"), Laurel Oak (\"Quercus hemisphaerica\"), Southern Magnolia (\"Magnolia grandiflora\"), Red Bay (\"Persea borbonia\"), Cabbage Palm (\"Sabal palmetto\"), and Sweetbay Magnolia (\"Magnolia virginiana\"). In several areas on the barrier islands, a stunted \"Quercus geminata\" or mixed \"Quercus geminata\" and \"Quercus virginiana\" forest dominates, with a dense evergreen understory of scrub palm \"Serenoa repens\" and a variety of vines, including \"Bignonia capreolata\", as well as \"Smilax\" and \"Vitis species\"'. \"Gordonia lasianthus\", \"Ilex opaca\" and \"Osmanthus americanus\" also may occur as canopy co-dominant in coastal dune forests, with \"Cliftonia monophylla\" and \"Vaccinium arboreum\" as a dense evergreen understory (Box and Fujiwara 1988).\n\nThe lower shrub layer of the evergreen forests is often mixed with other evergreen species from the palm family (\"Rhapidophyllum hystrix\"), Bush palmetto(\"Sabal minor\"), and Saw Palmetto (\"Serenoa repens\"), and several species in the Ilex family, including \"Ilex glabra\", Dahoon Holly, and Yaupon Holly. In many areas, \"Cyrilla racemiflora\", \"Lyonia fruticosa\", Wax Myrtle \"Myrica\" is present as an evergreen understory. Several species of \"Yucca\" and \"Opuntia\" are native as well to the drier sandy coastal scrub environment of the region, including \"Yucca aloifolia\", \"Yucca filamentosa\", \"Yucca gloriosa\", and \"opuntia stricta\".\n\nDuring the Miocene, oak-laurel forests were found in Central and Southern California. Typical tree species included oaks ancestral to present-day California oaks, as well as an assemblage of trees from the Laurel family, including \"Nectandra\", \"Ocotea\", \"Persea\", and \"Umbellularia\". Only one native species from the Laurel family (Lauraceae), \"Umbellularia californica,\" remains in California today.\n\nThere are however, several areas in Mediterranean California, as well as isolated areas of southern Oregon that have evergreen forests. Several species of evergreen \"Quercus\" forests occur, as well as a mix of evergreen scrub typical of Mediterranean climates. Species of \"Notholithocarpus\", \"Arbutus menziesii\", and \"Umbellularia californica\" can be canopy species in several areas.\n\nThe laurel forest is the most common Central American temperate evergreen cloud forest type. They are found in mountainous areas of southern Mexico and almost all Central American countries, normally more than above sea level. Tree species include evergreen oaks, members of the Laurel family, and species of \"Weinmannia\", \"Drimys\", and \"Magnolia\". The cloud forest of Sierra de las Minas, Guatemala, is the largest in Central America. In some areas of southeastern Honduras there are cloud forests, the largest located near the border with Nicaragua. In Nicaragua the cloud forests are found in the border zone with Honduras, and most were cleared to grow coffee. There are still some temperate evergreen hills in the north. The only cloud forest in the Pacific coastal zone of Central America is on the Mombacho volcano in Nicaragua. In Costa Rica there are laurisilvas in the \"Cordillera de Tilarán\" and Volcán Arenal, called Monteverde, also in the Cordillera de Talamanca.\n\n\nThe Yungas are typically evergreen forests or jungles, and multi-species, which often contain many species of the laurel forest. They occur discontinuously from Venezuela to northwestern Argentina including in Brazil, Bolivia, Chile, Colombia, Ecuador, and Peru, usually in the Sub-Andean Sierras. The forest relief is varied and in places where the Andes meet the Amazon, it includes steeply sloped areas. Characteristic of this region are deep ravines formed by the rivers, such as that of the Tarma River descending to the San Ramon Valley, or the Urubamba River as it passes through Machu Picchu. Many of the Yungas are degraded or are forests in recovery that have not yet reached their climax vegetation.\n\nThe laurel forests of the region are known as the \"Laurisilva Misionera\", after Argentina's Misiones Province. The Araucaria moist forests occupy a portion of the highlands of southern Brazil, extending into northeastern Argentina. The forest canopy includes species of Lauraceae (\"Ocotea pretiosa\" and \"O. catharinense\"), Myrtaceae (\"Campomanesia xanthocarpa\"), and Leguminosae (\"Parapiptadenia rigida\"), with an emergent layer of the conifer Brazilian Araucaria (\"Araucaria angustifolia\") reaching up to in height. The subtropical Serra do Mar coastal forests along the southern coast of Brazil have a tree canopy of Lauraceae and Myrtaceae, with emergent trees of Leguminaceae, and a rich diversity of bromeliads and trees and shrubs of family Melastomaceae. The inland Alto Paraná Atlantic forests, which occupy portions of the Brazilian Highlands in southern Brazil and adjacent parts of Argentina and Paraguay, are semi-deciduous.\n\nThe Valdivian temperate rain forests, or \"Laurisilva Valdiviana\", occupy southern Chile and Argentina from the Pacific Ocean to the Andes between 38° and 45° latitude. Rainfall is abundant, from according to locality, distributed throughout the year, but with some subhumid Mediterranean climate influence for 3–4 months in summer. The temperatures are sufficiently invariant and mild, with no month falling below , and the warmest month below .\n\nLaurel forest appears on mountains of the coastal strip of New South Wales in Australia, New Guinea, New Caledonia, Tasmania, and New Zealand. The laurel forests of Australia, Tasmania, and New Zealand are home to species related to those in the Valdivian laurel forests, including Southern Beech (\"Nothofagus\", fossils of which have recently been found in Antarctica) through the connection of the Antarctic flora. Other typical flora include Winteraceae, Myrtaceae, Southern Sassafras (Atherospermataceae), conifers of Araucariaceae, Podocarpaceae, and Cupressaceae, and tree ferns.\n\nNew Caledonia was an ancient fragment of the supercontinent Gondwana. Unlike many of the Pacific Islands, which are of relatively recent volcanic origin, New Caledonia is part of Zealandia, a fragment of the ancient Gondwana that separated from Australia 60–85 million years ago, and the ridge linking New Caledonia to New Zealand has been deeply submerged for millions of years. This isolated New Caledonia from the rest of the world's landmasses, preserving a snapshot of Gondwanan forests. New Caledonia and New Zealand are separated by continental drift of Australia 85 million years ago. The islands still shelter an extraordinary diversity of endemic plants and animals of Gondwanan origin that have later spread to the southern continents.\n\nThe laurel forest of Australia, New Caledonia (\"Adenodaphne\"), and New Zealand have a number of species related to those of the Valdivian laurel forest, through the connection of the Antarctic flora of gymnosperms like the podocarpus and deciduous Nothofagus. \"Beilschmiedia tawa\" is often the dominant canopy species of genus \"Beilschmiedia\" in lowland laurel forests in the North Island and the northeast of the South Island, but will also often form the subcanopy in primary forests throughout the country in these areas, with podocarps such as Kahikatea, Matai, Miro and Rimu. Genus \"Beilschmiedia\" are trees and shrubs widespread in tropical Asia, Africa, Australia, New Zealand, Central America, the Caribbean, and South America as far south as Chile. In the Corynocarpus family, \"Corynocarpus laevigatus\" is called laurel of New Zealand, while \"Laurelia novae-zelandiae\" belongs to the same genus as \"Laurelia sempervirens\". The tree niaouli grows in Australia, New Caledonia, and Papua.\n\nNew Caledonia lies at the northern end of the ancient continent Zealandia, while New Zealand rises at the plate boundary that bisects it. These land masses are two outposts of the Antarctic flora, including Araucarias and Podocarps. At Curio Bay, fossilized logs can be seen of trees closely related to modern Kauri and Norfolk Pine that grew on Zealandia about 180 million years ago during the Jurassic period, before it split from Gondwana.\n\nDuring glacial periods more of Zealandia became a terrestrial rather than a marine environment. Zealandia was originally thought to have no native land mammals, but a recent discovery in 2006 of a fossil mammal jaw from the Miocene in the Otago region shows otherwise.\n\nThe New Guinea and Northern Australian ecoregions are closely related. Over time Australia drifted north and became drier; the humid Antarctic flora from Gondwana retreated to the east coast and Tasmania, while the rest of Australia became dominated by sclerophyll forest and xeric shrubs and grasses. Humans arrived in Australia 50–60,000 years ago, and used fire to reshape the vegetation of the continent; as a result, the Antarctic flora, also known as the \"Rainforest flora\" in Australia, retreated to a few isolated areas composing less than 2% of Australia's land area.\n\nThe eastern end of Malesia, including New Guinea and the Aru Islands of eastern Indonesia, is linked to Australia by a shallow continental shelf, and shares many marsupial mammal and bird taxa with Australia. New Guinea also has many additional elements of the Antarctic flora, including southern beech (\"Nothofagus\") and Eucalypts. New Guinea has the highest mountains in Malesia, and vegetation ranges from tropical lowland forest to tundra.\n\nThe highlands of New Guinea and New Britain are home to montane laurel forests, from about elevation. These forests include species typical of both Northern Hemisphere laurel forests, including \"Lithocarpus, Ilex,\" and Lauraceae, and Southern Hemisphere laurel forests, including Southern Beech \"Nothofagus\", \"Araucaria\", Podocarps, and trees of the Myrtle family (Myrtaceae). New Guinea and Northern Australia are closely related. Around 40 million years ago, the Indo-Australian tectonic plate began to split apart from the ancient supercontinent Gondwana. As it collided with the Pacific Plate on its northward journey, the high mountain ranges of central New Guinea emerged around 5 million years ago. In the lee of this collision zone, the ancient rock formations of what is now Cape York Peninsula remained largely undisturbed.\n\nThe WWF identifies several distinct montane laurel forest ecoregions on New Guinea, New Britain, and New Ireland.\n"}
{"id": "33394204", "url": "https://en.wikipedia.org/wiki?curid=33394204", "title": "List of New Jersey tornadoes", "text": "List of New Jersey tornadoes\n\nThis is a list of all tornadoes reported in the U.S. state of New Jersey.\n\n\n"}
{"id": "3482778", "url": "https://en.wikipedia.org/wiki?curid=3482778", "title": "List of North Carolina hurricanes", "text": "List of North Carolina hurricanes\n\nThe list of North Carolina hurricanes includes 413 known tropical or subtropical cyclones that have affected the U.S. state of North Carolina. Due to its location, many hurricanes have hit the state directly, and numerous hurricanes have passed near or through North Carolina in its history; the state is ranked fourth, after Florida, Texas, and Louisiana, in the number of cyclones that produced hurricane-force winds in a U.S. state. Hurricanes in North Carolina history are responsible for over $11 billion in damage (2008 USD) and almost 1,000 total fatalities.\n\nAs to statistical hurricane research between 1883 and 1996 by the North Carolina State Climatology Office, a tropical cyclone makes landfall along the coastline about once every four years. An estimated 17.5 percent of all North Atlantic tropical cyclones have affected the state. Additionally, the remnants of a few Pacific tropical cyclones struck the state. Cape Hatteras is most affected by storms within the state, though Cape Lookout and Cape Fear are also regularly affected; the increased activity in three areas is because it protrudes from elsewhere along the Atlantic coastline. After Southern Florida, Cape Hatteras has the lowest return period, or the frequency at which a certain intensity or category of hurricane can be expected within 86 mi (139 km) of a given location, in the country. As the Outer Banks are a narrow strip of low-lying land, hurricanes occasionally leave portions of the land partially or fully submerged. Additionally, the remnants of inland tropical cyclones have produced flooding and landslides in the state's western region.\n\nTropical cyclones have affected North Carolina in every month between May and December; about 35 percent of the storms struck the state in September, and 80 percent affected the state between August and October, which coincides with the peak of the hurricane season. The earliest storm to affect the state was Subtropical Storm Andrea on May 7, 2007, and the latest was a tropical storm that moved across the Outer Banks on December 2, 1925. The strongest storm to strike the state was Hurricane Hazel on October 15, 1954, which made landfall as a Category 4 hurricane on the Saffir–Simpson Hurricane Scale.\n\nThe list of North Carolina hurricanes before 1900 encompasses 139 tropical cyclones that affected the U.S. state of North Carolina. Collectively, cyclones in North Carolina during the time period resulted in over 775 direct fatalities during the period. Seven cyclones affected the state in the 1893 season, which was the year with the most tropical cyclones devastating the state during the time period. From the beginning of the official Atlantic hurricane record in 1851 to 1899, there were 12 years without a known tropical cyclone affecting the state.\n\nHistorical data prior to 1700 is sparse due to lack of significant European settlements along the coastline; the few storms listed are largely records from Roanoke Colony and later the Province of Carolina. Modern meteorologists believe early storms were tropical cyclones, though due to the time period confirmation is impossible. One theory explaining the disappearance of Roanoke Colony suggests a hurricane destroyed the village, though there is no evidence to prove the theory. It is considered unlikely due to lack of damage to a fence around the village, on which the villagers left an inscription.\n\nBetween 1900 and 1949, 75 tropical cyclones or their remnants affected the state. Collectively, cyclones in North Carolina during that time period resulted in 53 total fatalities during the period, as well as about $328 million in damage (2008 USD). Tropical cyclone affected the state in all but nine seasons. In the 1916 season, five storms affected the state, which was the season with the most storms devastating the state. The strongest hurricanes to affect the state during the time period were the 1933 Outer Banks hurricane and the 1944 Great Atlantic Hurricane, which produced winds of Category 3 status on the Saffir–Simpson Hurricane Scale within the state. The 1933 Outer Banks hurricane was the deadliest hurricane in the state during the time period, which killed 21 people. The remnants of a hurricane in 1940 dropped heavy rainfall in the state, which caused over $150 million in damage (2008 USD) from flooding and landslides.\n\nA total of 79 tropical or subtropical cyclones affected North Carolina between 1950 and 1979. Collectively, cyclones during the time period resulted in 37 total fatalities during the period, as well as about $3 billion in damage (2008 USD). A cyclone affected the state in every year during the time period, and in three seasons a total of five cyclones assailed the state. The strongest hurricane to hit the state during the time period was Hurricane Hazel, which struck the state as a Category 4 hurricane on the Saffir–Simpson Hurricane Scale. Hazel was both the costliest and deadliest cyclone during the period, causing over $1 billion in damage (2008 USD) and 19 deaths. Most storms affected the state in September, though cyclones lashed the state between May and October.\n\nThe period from 1980 to the present encompasses 120 tropical or subtropical cyclones that affected the state. Collectively, cyclones in North Carolina during the time period resulted in over $10 billion in damage (2010 USD), primarily from hurricanes Fran and Floyd. Additionally, tropical cyclones in North Carolina were responsible for 77 direct fatalities and at least 44 indirect casualties during the period. Eight cyclones affected the state in the 1985 season, which was the year with the most tropical cyclones striking the state. Every year included at least one tropical cyclone affecting the state.\n\nThe strongest hurricane to hit the state during the time period was Hurricane Fran in 1996, which struck near Wilmington as a Category 3 hurricane on the Saffir–Simpson Hurricane Scale; Hurricane Emily in 1993 brushed the Outer Banks also as a Category 3 hurricane. The deadliest hurricane during the period was Hurricane Floyd in 1999, which caused 35 fatalities and record–breaking flooding in the eastern portion of the state. Hurricane Irene hit the Outer Banks on August 27th 2011 as a Category 1, making it the first of its kind to make landfall since Hurricane Ike in 2008.\n\nThe following major hurricanes either made landfall on the state or brought winds of Category 3 status to the state. Storms are listed since 1851, which is the official start of the Atlantic hurricane database.\n\nThe table lists hurricanes by death tolls of over 20 fatalities. Direct deaths are those that are directly caused by the storm passage, such as drownings or deaths from being struck by windblown objects. Indirect deaths, which are not included in the toll of Hurricane Floyd, are those that are related to the storm, but not directly from its storm effects. Due to lack of data, many early hurricanes have overall death tolls that do not specify indirect or direct.\n\n"}
{"id": "22475010", "url": "https://en.wikipedia.org/wiki?curid=22475010", "title": "List of Superfund sites in New Mexico", "text": "List of Superfund sites in New Mexico\n\nThis is a list of Superfund sites in New Mexico designated under the Comprehensive Environmental Response, Compensation, and Liability Act (CERCLA) environmental law. The CERCLA federal law of 1980 authorized the United States Environmental Protection Agency (EPA) to create a list of polluted locations requiring a long-term response to clean up hazardous material contaminations. These locations are known as Superfund sites, and are placed on the National Priorities List (NPL). \n\nThe NPL guides the EPA in \"determining which sites warrant further investigation\" for environmental remediation. As of May 16, 2017, there were sixteen Superfund sites on the National Priorities List in New Mexico. In addition, four other sites have been cleaned up and removed from the list.\n\n\n"}
{"id": "44623828", "url": "https://en.wikipedia.org/wiki?curid=44623828", "title": "List of Trichoderma species", "text": "List of Trichoderma species\n\nCurrently the List of \"Trichoderma\" species includes 89 accepted species within the \"Trichoderma\" genus of fungi. \"Hypocrea\" are teleomorphs of \"Trichoderma\" which themselves have \"Hypocrea\" as anamorphs.\n\n\"Trichoderma\" species include:\n\n"}
{"id": "32371088", "url": "https://en.wikipedia.org/wiki?curid=32371088", "title": "List of ecoregions in Ethiopia", "text": "List of ecoregions in Ethiopia\n\nThe following is a list of ecoregions in Ethiopia, as identified by the Worldwide Fund for Nature (WWF).\n\n\"by major habitat type\"\n\n\n\n\n\n"}
{"id": "32370454", "url": "https://en.wikipedia.org/wiki?curid=32370454", "title": "List of ecoregions in South Sudan", "text": "List of ecoregions in South Sudan\n\nThe following is a list of ecoregions in South Sudan, as identified by the Worldwide Fund for Nature (WWF).\n\n\"by major habitat type\"\n\n\n\n\n\n"}
{"id": "44686", "url": "https://en.wikipedia.org/wiki?curid=44686", "title": "List of national parks of France", "text": "List of national parks of France\n\nThe national parks of France is a system of ten national parks throughout metropolitan France and its overseas departments, coordinated by the government agency Parcs Nationaux de France.\n\nThe first national park was established in 1963 and the most recent park was created in 2012. The French national parks protect a total area of in core area and in buffer zones in metropolitan France.\n\nThis puts over 2% of the total area of metropolitan France under some level of protection. French national parks draw over seven million visitors every year. \n\n\n"}
{"id": "44648", "url": "https://en.wikipedia.org/wiki?curid=44648", "title": "List of national parks of Germany", "text": "List of national parks of Germany\n\nThe following are the 16 national parks of Germany, sorted from North to South:\n\nGermany also has 14 Biosphere Reserves, as well as 98 nature parks.\n\n\n"}
{"id": "15025536", "url": "https://en.wikipedia.org/wiki?curid=15025536", "title": "List of parks and gardens in Tokyo", "text": "List of parks and gardens in Tokyo\n\nTokyo, Japan contains many parks and gardens.\n\nNote: Figures in bold are approximate values.\n\nThere are four national parks in Tokyo Prefecture:\n"}
{"id": "58665738", "url": "https://en.wikipedia.org/wiki?curid=58665738", "title": "List of pipeline accidents in the United States in 2014", "text": "List of pipeline accidents in the United States in 2014\n\nThe following is a list of pipeline accidents in the United States in 2014. It is one of several lists of U.S. pipeline accidents. See also list of natural gas and oil production accidents in the United States.\n\nThis is not a complete list of all pipeline accidents. For natural gas alone, the Pipeline and Hazardous Materials Safety Administration (PHMSA), a United States Department of Transportation agency, has collected data on more than 3,200 accidents deemed serious or significant since 1987.\n\nA \"significant incident\" results in any of the following consequences:\n\nPHMSA and the National Transportation Safety Board (NTSB) post incident data and results of investigations into accidents involving pipelines that carry a variety of products, including natural gas, oil, diesel fuel, gasoline, kerosene, jet fuel, carbon dioxide, and other substances. Occasionally pipelines are repurposed to carry different products.\n\n"}
{"id": "51812597", "url": "https://en.wikipedia.org/wiki?curid=51812597", "title": "List of rivers and water bodies of Montreal Island", "text": "List of rivers and water bodies of Montreal Island\n\nThe rivers and water bodies of Montreal are few and mostly artificial. Hydrography of the island of Montreal remained intact until approximately XIXth where Montreal will undergo major urban works including the construction of Lachine Canal and the creation of the first major parks of Montreal.\n\nAfter the Ice Age, around -13 000 years, Montreal and the Saint Lawrence Lowlands are flooded by the Champlain sea. Within a few centuries, as and when these waters recede, the Mount Royal and its three summits are emerged into islands. With the complete withdrawal of the sea, water is retained in some depression of the island. This is the case among other Beaver Lake, located in the palm of Mount Royal. This will dry gradually to become a fen. He was regrooved artificially in 1938.\n\nThere used to be a complex hydrographic, now destroyed or channeled.\n\n\nToday there are only a handful of streams and lakes in nature. However, many parks have ponds or artificial lakes of large size.\n\nBelow is a partial list of current waters bodies of the island:\n\n\n"}
{"id": "366317", "url": "https://en.wikipedia.org/wiki?curid=366317", "title": "List of rivers of Germany", "text": "List of rivers of Germany\n\nThis is a list of rivers, which are at least partially located in Germany. Rivers that flow into the sea are sorted geographically, along the coast. Rivers that flow into other rivers are sorted by the proximity of their points of confluence to the sea (the lower in the list, the more upstream). Some rivers (e.g. Meuse) do not flow through Germany themselves, but they are mentioned for having German tributaries. They are given in \"italics\". For clarity, only rivers that are longer than (or have longer tributaries) are shown. An alphabetical list of all German rivers that have an article in Wikipedia is given at the end.\n\nThe rivers of Germany flow into the Baltic Sea, the Black Sea and the North Sea. The most important rivers of Germany are:\n\nThe rivers in this section are sorted north-west (Danish border) to east (Polish border).\n\n\n\nThe rivers in this section are sorted south-west (Netherlands) to east (Danish border).\n\n\nAabach, Aar, Abens, Acher, Agger, Ahr, Aland, Alf, Aller, Alme, Alsenz, Alster, Altmühl, Alz, Ammer (Neckar), Ammer/Amper, Aue (Elbe), Aue, Berkel, Bever, Biber, Biela, Bille, Bist, Black Elster, Blau, Blies, Bode, Böhme, Breg, Breitach, Brend, Brenz, Brigach, Chamb, Chemnitz, Dahme, Danube, Diemel, Dill, Dinkel, Dosse, Dreisam, Düssel, Echaz, Eder, Eider, Elbe, Elde, Else, Elz (Neckar), Elz (Rhine), Elzbach, Ems, Emscher, Ennepe, Enz, Enz (Prüm), Erft\n\nFeller Bach, Fils, Franconian Saale, Franconian Rezat, Franconian Saale, Freiberger Mulde, Friedberger Ach, Fuhse, Fulda, Garte, Gera, Glan, Gose/Abzucht, Gottleuba, Große Laber, Günz, Hamme, Hase, Haune, Havel, Heller, Hönne, Hörsel, Hunte, Ihme, Iller, Ilm (Bavaria), Ilm (Thuringia), Ilmenau, Ilz, Inde, Inn, Innerste, Isar, Isen, Itz, Jade, Jagst, Jeetzel, Kammel, Kander, Kinzig (Main), Kinzig (Rhine), Kocher, Kyll\n\nLahn, Lauchert, Lauter (Glan), Lauter (Rhine), Lech, Leda, Leibi, Leine, Lenne, Lesum, Lieser, Lippe, Löcknitz, Loisach, Lusatian Neisse, Lutter (Lachte), Lutter (Leine), Lutter (Oder), Main, Mandau, Maurine, Mindel, Möhne, Moselle, Mulde, Münstersche Aa, Murg, Murr, Mže/Mies, Naab, Nahe, Nebel, Neckar, Neetze, Nette (Innerste), Nette (Niers), Nette (Rhine), Nidda, Nied, Niers, Nims, Nister, Nuthe, Oder, Oder (Harz), Ohm, Ohre, Ohře/Eger, Oker, Orla, Örtze, Oste, Oude IJssel, Our\n\nPaar, Pader, Parthe, Peene, Pegnitz, Pfinz, Plane, Pleiße, Prims, Prüm, Queich, Recknitz, Red Main, Rednitz, Regen, Regnitz, Rems, Rench, Rheider Au, Rhin, Rhine, Rhume, Riß, Rot, Red Weißeritz, Red Main, Rott, another Rott, Ruhr, Rur, Ruwer, Ryck, Saalach, Saale, Saar, Salm, Salzach, Sauer, Sauer (France), Scheppau, Schmutter, Schozach, Schwarze Elster, Schunter, Schutter, Swabian Rezat, Schwalm (Eder), Schwalm (Meuse), Schwarza, Schwarzbach (Blies), Schwarze Laber, Schwentine, Seeve, Selbitz, Selz, Sieg, Soeste, Spree, Sprotte, Stepenitz (Elbe), Stepenitz (Trave), Stör, Sulm, Swist\n\nTanger, Tauber, Tiroler Achen, Tollense, Trave, Treene, Uecker, Ulster, Unstrut, Usa, Vechte, Vils (Danube), Vils (Lech), Vils (Naab), Volme, Wakenitz, Warnow, Weida, Weil, Weiße Elster, Weißeritz, Werra, Werre, Wertach, Wesenitz, Weser, Westfälische Aa, Wetter, White Elster, White Main, Wied, Wiese, Wild Weißeritz, Wipper (Saale), Wipper (Unstrut), Wisper, Wörnitz, Wümme, Wupper, Würm, Wurm, Wutach, Zaber, Zeegenbach, Zschopau, Zusam, Zwickauer Mulde\n\n"}
{"id": "49818851", "url": "https://en.wikipedia.org/wiki?curid=49818851", "title": "List of species described in 2016", "text": "List of species described in 2016\n\nList of species formally described and other new taxa of organism in 2016 classified by time of publication.\n\n\n\n\n"}
{"id": "8591805", "url": "https://en.wikipedia.org/wiki?curid=8591805", "title": "List of stars in Pisces", "text": "List of stars in Pisces\n\nThis is the list of notable stars in the constellation Pisces, sorted by decreasing brightness.\n\n\n"}
{"id": "8591853", "url": "https://en.wikipedia.org/wiki?curid=8591853", "title": "List of stars in Serpens", "text": "List of stars in Serpens\n\nThis is the list of notable stars in the constellation Serpens, sorted by decreasing brightness.\n\n\n"}
{"id": "18837760", "url": "https://en.wikipedia.org/wiki?curid=18837760", "title": "List of tributaries of the Niger", "text": "List of tributaries of the Niger\n\nThis is a list of the Tributaries of the Niger River. They are listed by nation, at the point they converge into the Niger.\n\n\n\n\n\n\n\n"}
{"id": "36383032", "url": "https://en.wikipedia.org/wiki?curid=36383032", "title": "Mass generation", "text": "Mass generation\n\nIn theoretical physics, a mass generation mechanism is a theory that describes the origin of mass from the most fundamental laws of physics. Physicists have proposed a number of models that advocate different views of the origin of mass. The problem is complicated because the primary role of mass is to mediate gravitational interaction between bodies, and no theory of gravitational interaction reconciles with the currently popular Standard Model of particle physics.\n\nThere are two types of mass generation models: gravity-free models and models that involve gravity.\n\nThe Higgs mechanism is based on a symmetry-breaking scalar field potential, such as the quartic. The Standard Model uses this mechanism as part of the Glashow–Weinberg–Salam model to unify electromagnetic and weak interactions. This model was one of several that predicted the existence of the scalar Higgs boson.\n\nIn these theories, as in the Standard Model itself, the gravitational interaction either is not involved or does not play a crucial role.\n\nTechnicolor models break electroweak symmetry through gauge interactions, which were originally modeled on quantum chromodynamics.\n\nColeman–Weinberg mechanism generates mass through spontaneous symmetry breaking through radiative corrections.\n\n\n"}
{"id": "50612621", "url": "https://en.wikipedia.org/wiki?curid=50612621", "title": "Maternal transfer in aquatic mammals", "text": "Maternal transfer in aquatic mammals\n\nIn aquatic mammals, maternal transfer is the movement of contaminants from mother to offspring, typically of lipophilic contaminants while in utero or through the mother’s milk. This has become important with the increase in usage of persistent organic pollutants (POPs). POPs biomagnify due to their lipophilic nature and become accumulated in the lipid tissues of aquatic mammals. These lipids are used as energy for the mother during the development of offspring, which releases the POPs into the circulatory fluid. This leads to a transfer of the toxicants into the developing embryos during gestation as well as into milk that an aquatic mammal produces during lactation.\n\nMarine mammals are exposed to a variety of chemicals throughout their life, mostly through their diet. Once the chemicals are accumulated in the body tissues of the mammals, a portion of these chemicals in the female mammals are transferred to their offspring during gestation and lactation.\n\nThe degree of maternal-fetal transfer of chemical pollutants is affected by chemical and physical properties of those compounds. Lipophilicity, protein binding, and active transport mechanisms all influence the absorption and distribution of such chemicals in maternal tissues. Lipophilic chemicals, such as many POPs, can be transferred through the fatty portion of milk, while hydrophilic components can be transferred along with the liquid portion of the milk. The placenta provides a barrier to some contaminants, but is partially permeable to others, including many organics and certain heavy metals such as lead, mercury and cadmium, particularly when combined with organic molecules.\n\nThe transfer of contaminants from mother to pup through lactation is most likely the largest mass transfer of contaminants, greater than that of in-utero transfers. When the mother begins lactation, blubber lipids are converted into milk lipids to feed her offspring. During this process, toxicants that were stored in blubber lipids are moved into the milk and subsequently are transferred to the nursing pup.\n\nThe transfer of toxicants through lactation is driven by the log Kow of the toxicants. Chemical compounds with a high affinity for lipids (a higher log Kow) will more readily be transferred through lactation due to the high lipid content of milk. The transfer of toxicants from blubber to milk is not fully understood, and selective transfer of contaminants has been observed.\n\nMass balance of toxicants is difficult during lactation due to milk lipids originating from blubber lipids as well as being synthesized locally in mammary tissue. The change in toxicant solubility between blubber and circulatory fluid as well as the breakdown and resynthesis of blubber lipids and circulatory lipids also contributes to the difficulties of mass balance of toxicants between blubber, circulatory, and milk lipids.\n\nHowever, even with difficulties of mass balancing, it has generally been observed in grey seals and harbor porpoises that residues in pup blubber lipids are generally similar or slightly higher than in maternal milk lipids, and are approximately half of the residues in maternal blubber lipids.\n\nThe transfer of POPs from mother to fetus via the placenta is less than that of lactation but can still cause adverse effects. Fatty acids from the mother’s plasma are transported either through diffusion or active transport through the placenta to be used in important processes such as brain development. Sources of fatty acids are mainly derived from blubber in seals, porpoises, and whales.\n\nLipophilic chemicals such as PCBs previously stored within the mother’s fatty tissue can be transferred to the fetus via the circulatory fluid. Some lipophilic chemicals can be metabolized by the fetus using mostly CYP enzymes, but others are quickly incorporated into developing fetal adipose tissue. The storage and release of these chemicals within the fetus can lead to endocrine disruption, immunosuppression, thyroid disruption, and neurotoxicity in seals and orcas.\n\nIn mammals, maternal factors can be transferred via the placenta, in the colostrum, and in normal milk during lactation. Marine mammal offspring are especially vulnerable during the time when their own immune systems have not yet matured. When females provide milk to their young, they can have a dramatic impact on offspring fitness during ontogeny, as well as when the offspring matures into an adult. Female marine mammals pass on most of their POP burden to their first-born offspring, while the calf is in utero and afterwards during lactation. The large amount of POPs transferred to the offspring as well as the fast rate of transfer, can sometimes prove fatal.\n\nThe POP burden carried by male and female marine mammals tends to increase with time until they reach the age of sexual maturity. After that point, the burden in males continues to grow, as they continue to absorb POPs from their food. However, with female marine mammals, the POP burden carried decreases after birth but can then increase until the next reproductive cycle.\n"}
{"id": "2454408", "url": "https://en.wikipedia.org/wiki?curid=2454408", "title": "Mediterranean Basin", "text": "Mediterranean Basin\n\nIn biogeography, the Mediterranean Basin (also known as the Mediterranean region or sometimes Mediterranea) is the region of lands around the Mediterranean Sea that have a Mediterranean climate, with mild, rainy winters and hot, dry summers, which supports characteristic Mediterranean forests, woodlands, and scrub vegetation.\n\nThe Mediterranean basin covers portions of three continents: Europe, Asia, and Africa\n\nIt has a varied and contrasting topography. The Mediterranean Region offers an ever-changing landscape of high mountains, rocky shores, impenetrable scrub, semi-arid steppes, coastal wetlands, sandy beaches and a myriad islands of various shapes and sizes dotted amidst the clear blue sea. Contrary to the classic sandy beach images portrayed in most tourist brochures, the Mediterranean is surprisingly hilly. Mountains can be seen from almost anywhere.\n\nThe Mediterranean Basin extends into Western Asia, covering the western and southern portions of the peninsula of Turkey, excluding the temperate-climate mountains of central Turkey. It includes the Mediterranean climate Levant at the eastern end of the Mediterranean, bounded on the east and south by the Syrian and Negev deserts.\n\nThe northern portion of the Maghreb region of northwestern Africa has a Mediterranean climate, separated from the Sahara Desert, which extends across North Africa, by the Atlas Mountains. In the eastern Mediterranean the Sahara extends to the southern shore of the Mediterranean, with the exception of the northern fringe of the peninsula of Cyrenaica in Libya, which has a dry Mediterranean climate.\n\nEurope lies to the north, and three large Southern European peninsulas, the Iberian Peninsula, Italian Peninsula, and the Balkan Peninsula, extend into the Mediterranean-climate zone. A system of folded mountains, including the Pyrenees dividing Spain from France, the Alps dividing Italy from Central Europe, the Dinaric Alps along the eastern Adriatic, and the Balkan and Rhodope mountains of the Balkan Peninsula divide the Mediterranean from the temperate climate regions of Western and Central Europe.\n\nThe Mediterranean Basin was shaped by the ancient collision of the northward-moving African-Arabian continent with the stable Eurasian continent. As Africa-Arabia moved north, it closed the former Tethys Sea, which formerly separated Eurasia from the ancient super continent of Gondwana, of which Africa was part. At about the same time, 170 mya in the Jurassic period, a small Neotethys ocean basin formed shortly before the Tethys Sea was closed at the eastern end. The collision pushed up a vast system of mountains, extending from the Pyrenees in Spain to the Zagros Mountains in Iran. This episode of mountain building, known as the Alpine orogeny, occurred mostly during the Oligocene (34 to 23 million years ago (mya)) and Miocene (23 to 5.3 mya) epochs. The Neotethys became larger during these collisions and associated folding and subduction.\n\nAbout 6 mya during the late Miocene, the Mediterranean was closed at its western end by drifting Africa, which caused the entire sea to evaporate. There followed several (debated) episodes of sea drawdown and re-flooding known as the Messinian Salinity Crisis, which ended when the Atlantic last re-flooded the basin at the end of the Miocene. Recent research has suggested that a desiccation-flooding cycle may have repeated several times\nduring the last 630,000 years of the Miocene epoch, which could explain several events of large amounts of salt deposition. Recent studies, however, show that repeated desiccation and re-flooding is unlikely from a geodynamic point of view.\n\nThe end of the Miocene also marked a change in the Mediterranean Basin's climate. Fossil evidence shows that the Mediterranean Basin had a relatively humid subtropical climate with summer rainfall during the Miocene, which supported laurel forests. The shift to a Mediterranean climate occurred within the last 3.2–2.8 million years, during the Pliocene epoch, as summer rainfall decreased. The subtropical laurel forests retreated, although they persisted on the islands of Macaronesia off the Atlantic coast of Iberia and North Africa, and the present Mediterranean vegetation evolved, dominated by coniferous trees and sclerophyllous trees and shrubs, with small, hard, waxy leaves that prevent moisture loss in the dry summers. Much of these forests and shrublands have been altered beyond recognition by thousands of years of human habitation. There are now very few relatively intact natural areas in what was once a heavily wooded region.\n\nPhytogeographically, the Mediterranean basin together with the nearby Atlantic coast, the Mediterranean woodlands and forests and Mediterranean dry woodlands and steppe of North Africa, the Black Sea coast of northeastern Anatolia, the southern coast of Crimea between Sevastopol and Feodosiya and the Black Sea coast between Anapa and Tuapse in Russia forms the \"Mediterranean Floristic Region\", which belongs to the Tethyan Subkingdom of the Boreal Kingdom and is enclosed between the Circumboreal, Irano-Turanian, Saharo-Arabian and Macaronesian floristic regions.\n\nThe Mediterranean Region was first proposed by German botanist August Grisebach in the late 19th century.\n\nDrosophyllaceae, recently segregated from Droseraceae, is the only plant family endemic to the region. Among the endemic plant genera are:\nThe genera \"Aubrieta\", \"Sesamoides\", \"Cynara\", \"Dracunculus\", \"Arisarum\" and \"Biarum\" are nearly endemic. Among the endemic species prominent in the Mediterranean vegetation are the Aleppo pine, stone pine, Mediterranean cypress, bay laurel, Oriental sweetgum, holm oak, kermes oak, strawberry tree, Greek strawberry tree, mastic, terebinth, common myrtle, oleander, \"Acanthus mollis\" and \"Vitex agnus-castus\". Moreover, many plant taxa are shared with one of the four neighboring floristic regions only. According to different versions of Armen Takhtajan's delineation, the Mediterranean Region is further subdivided into seven to nine floristic provinces: Southwestern Mediterranean (or Southern Moroccan and Southwestern Mediterranean), Ibero-Balearian (or Iberian and Balearian), Liguro-Tyrrhenian, Adriatic, East Mediterranean, South Mediterranean and Crimeo-Novorossiysk.\n\nThe Mediterranean Basin is the largest of the world's five Mediterranean forests, woodlands, and scrub regions. It is home to a number of plant communities, which vary with rainfall, elevation, latitude, and soils.\n\nThe Mediterranean Basin is home to considerable biodiversity, including 22,500 endemic vascular plant species. Conservation International designates the region as a biodiversity hotspot, because of its rich biodiversity and its threatened status. The Mediterranean Basin has an area of 2,085,292 km, of which only 98,009 km remains undisturbed.\n\nEndangered mammals of the Mediterranean Basin include the Mediterranean monk seal, the Barbary macaque, and the Iberian lynx.\n\n\nNeanderthals inhabited western Asia and the non-glaciated portions of Europe starting about 230,000 years ago. Modern humans moved into western Asia from Africa less than 100,000 years ago. Modern humans, known as Cro-Magnons, moved into Europe approximately 50-40,000 years ago.\n\nThe most recent glacial period, the Wisconsin glaciation, reached its maximum extent approximately 21,000 years ago, and ended approximately 12,000 years ago. A warm period, known as the Holocene climatic optimum, followed the ice age.\n\nFood crops, including wheat, chickpeas, and olives, along with sheep and goats, were domesticated in the eastern Mediterranean in the 9th millennium BCE, which allowed for the establishment of agricultural settlements. Near Eastern crops spread to southeastern Europe in the 7th millennium BCE. Poppy and oats were domesticated in Europe from the 6th to the 3rd millennium BCE. Agricultural settlements spread around the Mediterranean Basin. Megaliths were constructed in Europe from 4500 – 1500 BCE.\n\nA strengthening of the summer monsoon 9000–7000 years ago increased rainfall across the Sahara, which became a grassland, with lakes, rivers, and wetlands. After a period of climatic instability, the Sahara settled into a desert state by the 4th millennium BCE.\n\nWheat is the dominant grain grown around the Mediterranean Basin. Pulses and vegetables are also grown. The characteristic tree crop is the olive. Figs are another important fruit tree, and citrus, especially lemons, are grown where irrigation is present. Grapes are an important vine crop, grown for fruit and to make wine. Rice and summer vegetables are grown in irrigated areas.\n\n\n\n"}
{"id": "1408963", "url": "https://en.wikipedia.org/wiki?curid=1408963", "title": "Mercerised cotton", "text": "Mercerised cotton\n\nMercerisation is a textile finishing treatment for cellulose fabric and yarn, mainly cotton and flax, which improves dye uptake and tear strength, reduces fabric shrinkage, and imparts a silk-like luster.\n\nThe process was devised about 1844 by John Mercer, who treated cotton with solutions of 55–65°Tw (20–30%) sodium hydroxide, followed by washing. Mercer observed that the treated fabrics shrank, had increased tensile strength, and an increased affinity for dyes. In the original process of Mercer, no tension was applied. The product was termed \"fulled cotton\", a nod to the process of fulling in woven wool fabric. Mercer regarded the increased affinity for dyes as the most important technical aspect. Mercer also experimented with sulfuric acid and zinc chloride solutions, and discovered the parchmentising effect of sulfuric acid.\n\nThe silk-like lustre now commonly associated with mercerising is produced by tension, and was discovered by Horace Lowe in 1890.\n\nTreatment with sodium hydroxide destroys the spiral form of the cellulose with formation of alkali cellulose, which is changed to cellulose hydrate on washing out the alkali. Caustic soda concentrations of 20–26 % are used. Effective mercerization requires the use of wetting agents.\n\nThe improved lustre of mercerised cotton is due to the production of nearly circular cotton fibres under tension. Another characteristic feature is the untwisting (deconvolution) of the cotton hair.\n\nIn dry mercerization, the process is carried out while drying the fabric on a stenter.\n\n"}
{"id": "55800218", "url": "https://en.wikipedia.org/wiki?curid=55800218", "title": "Musée de l'Histoire vivante", "text": "Musée de l'Histoire vivante\n\nThe Musée de l'Histoire vivante (Museum of Living History) is an historical museum located in Montreuil-sous-bois, adjacent to the eastern part of Paris, France.\n\nCreated in 1937 by the Association pour l'Histoire Vivante (Association for Living History) under the impulse of Communist politician Jacques Duclos, it opened its doors on 23 March 1939 for the 150th anniversary of the French Revolution. was entrusted with the management of the project. He then dealt with the history of social movements, colonization and decolonization, as well as the suburbs and industrial heritage of the city of Montreuil. Since then, its domain has expanded, notably through temporary exhibitions. \n\nDuring the Second World War, the museum's collections were hidden in a farm in Seine-et-Marne. It officially reopened to the public on 22 June 1946. Later, it presented new rooms devoted to the Occupation and Libération. A room is also dedicated to Karl Marx. \n\nIn the 1960s and 1970s, a significant drop in attendance led to the museum's semi-closing, not all spaces being opened to the visitors.\n\nAfter a complete renovation (refurbishment of the rooms, creation of a reserve, computerization of funds, new presentation of the permanent exhibition), the museum reopened its doors in September 1988, with a temporary exhibition devoted to \"Jean Jaurès and the French Revolution\". It then acquired the status of a museum controlled by the .\n\nThe museum houses iconographic collections from the Revolution to the 1960s as well as archival collections of several activists and leaders of the French Communist Party (Jacques Duclos, Daniel Renoult, , archives of socialist and far-left activists, in particular. \n\nThe museum houses a space dedicated to the memory of Hô Chi Minh, the first President of the Democratic Republic of Vietnam, for his fight against colonialism.\n\nThe institution publishes or co-produces historical works, exhibition catalogues, postcards and documentary films. It is also a place of archival resources for researchers and historians.\n\nIts pedagogical activity has intensified and it works in partnership with the association \"Citoyenneté Jeunesse\" to present teachers and their students with various pedagogical workshops. Modules of images introduce the pupils of schools (from primary to secondary school) to different themes: French revolution, colonial imagery, the image and representation of woman/women from the French Revolution to the present day, urban habitat: garden cities and large complexes, discovery and liberation of Nazi camps, image of propaganda...).\n\n"}
{"id": "9578085", "url": "https://en.wikipedia.org/wiki?curid=9578085", "title": "National Geophysical Research Institute", "text": "National Geophysical Research Institute\n\nThe National Geophysical Research Institute (NGRI) is a geoscientific research organization established in 1961 under the Council of Scientific and Industrial Research (CSIR), India's largest Research and Development organization. It is supported by more than 200 scientists and other technical staff whose research activities are published in several journals of national and international interest.\n\nResearch areas covered by this institute include hydrocarbon and coal exploration, mineral exploration, deep seismic sounding studies, exploration and management of groundwater resources, earthquake hazard assessment, structure of earth's interior and its evolution (theoretical studies), and geophysical instrument development.\n\nThe major facilities available at NGRI include: \n\n"}
{"id": "21415608", "url": "https://en.wikipedia.org/wiki?curid=21415608", "title": "National Reserve", "text": "National Reserve\n\nA National Reserve is a land designation for protecting conservation values:\n\n\n"}
{"id": "30864576", "url": "https://en.wikipedia.org/wiki?curid=30864576", "title": "Norian", "text": "Norian\n\nThe Norian is a division of the Triassic geological period. It has the rank of an age (geochronology) or stage (chronostratigraphy). The Norian lasted from ~227 to million years ago. It was preceded by the Carnian and succeeded by the Rhaetian.\n\nThe Norian was named after the Noric Alps in Austria. The stage was introduced into scientific literature by Austrian geologist Edmund Mojsisovics von Mojsvar in 1869.\n\nThe Norian stage begins at the base of the ammonite biozones of \"Klamathites macrolobatus\" and \"Stikinoceras kerri\", and at the base of the conodont biozones of \"Metapolygnathus communisti\" and \"Metapolygnathus primitius\". A global reference profile for the base (a GSSP) had in 2009 not yet been appointed.\n\nThe top of the Norian (the base of the Rhaetian) is at the first appearance of ammonite species \"Cochloceras amoenum\". The base of the Rheatian is also close to the first appearance of conodont species \"Misikella spp.\" and \"Epigondolella mosheri\" and the radiolarid species \"Proparvicingula moniliformis\".\n\nIn the Tethys domain, the Norian stage contains six ammonite biozones:\n\n\n\n\n"}
{"id": "28007238", "url": "https://en.wikipedia.org/wiki?curid=28007238", "title": "North Pacific High", "text": "North Pacific High\n\nThe North Pacific High is a semi-permanent, subtropical anticyclone located in the northeastern portion of the Pacific Ocean, located northeast of Hawaii and west of California. It is strongest during the northern hemisphere summer and shifts towards the equator during the winter, when the Aleutian Low becomes more active. It is responsible for California's typically dry summer and fall and typically wet winter and spring, as well as Hawaii's year-round trade winds.\n"}
{"id": "1228393", "url": "https://en.wikipedia.org/wiki?curid=1228393", "title": "Passive nuclear safety", "text": "Passive nuclear safety\n\nPassive nuclear safety is a design approach for safety features, implemented in a nuclear reactor, that does not require any active intervention on the part of the operator or electrical/electronic feedback in order to bring the reactor to a safe shutdown state, in the event of a particular type of emergency (usually overheating resulting from a loss of coolant or loss of coolant flow). Such design features tend to rely more on the engineering of components such that their predicted behaviour would slow down, rather than accelerate, the deterioration of the reactor state; typically take advantages of natural forces or phenomena such as gravity, buoyancy, pressure differences, conduction or natural heat convection to accomplish safety functions without requiring an active power source.Many older common reactor designs use passive safety systems to a limited extent, rather, relying on active safety systems such as diesel powered motors. Some newer rector designs feature more passive systems; the motivation being that they are highly reliable and reduce the cost associated with the installation and maintenance of systems that would otherwise require multiple trains of equipment and redundant safety class power supplies in order the achieve the same level of reliability. However, weak driving forces that power many passive safety features can pose significant challenges to effectiveness of a passive system, particularly in the short term following an accident.\n\nTerming a reactor 'passively safe' is more a description of the strategy used in maintaining a degree of safety, than it is a description of the level of safety. Whether a reactor employing passive safety systems is to be considered safe or dangerous will depend on the criteria used to evaluate the safety level. This said, modern reactor designs have focused on increasing the amount of passive safety, and thus most passively safe designs incorporate both active and passive safety systems, making them substantially safer than older installations. They can be said to be \"relatively safe\" compared to previous designs.\n\nReactor vendors like to call their new generation reactors 'passively safe' but this term is sometimes confused with 'inherently safe' in the public perception. It is very important to understand that there are no 'passively safe' reactors or 'passively safe' systems, only 'passively safe' \"components\" of safety systems exist. Safety systems are used to maintain control of the plant if it goes outside normal conditions in case of anticipated operational occurrences or accidents, while the control systems are used to operate the plant under normal conditions. Sometimes a system combines both features. Passive safety refers to safety system components, whereas inherent safety refers to control system process regardless of the presence or absence of safety specific subsystems.\n\nAs an example of a safety system with 'passively safe' components, let us consider the containment of a nuclear reactor. 'Passively safe' components are the concrete walls and the steel liner, but in order to fulfil its mission active systems have to operate, e.g. valves to ensure the closure of the piping leading outside the containment, feedback of reactor status to external instrumentation and control (I&C) both of which may require external power to function.\n\nThe International Atomic Energy Agency (IAEA) classifies the degree of \"passive safety\" of components from category A to D depending on what the system does not make use of:\n\nIn category A (1+2+3+4) is the fuel cladding, the protective and nonreactive outer layer of the fuel pellet, which uses none of the above features: It is always closed and keeps the fuel and the fission products inside and is not open before arriving at the reprocessing plant. In category B (2+3+4) is the surge line, which connects the hot leg with the pressurizer and helps to control the pressure in the primary loop of a PWR and uses a moving working fluid when fulfilling its mission. In category C (3+4) is the accumulator, which does not need signal input of 'intelligence' or external power. Once the pressure in the primary circuit drops below the set point of the spring-loaded accumulator valves, the valves open and water is injected into the primary circuit by compressed nitrogen. In category D (4 only) is the SCRAM which utilizes moving working fluids, moving mechanical parts and signal inputs of 'intelligence' but not external power or forces: the control rods drop driven by gravity once they have been released from their magnetic clamp. But nuclear safety engineering is never that simple: Once released the rod may not fulfil its mission: It may get stuck due to earthquake conditions or due to deformed core structures. This shows that though it is a passively safe system and has been properly actuated, it may not fulfil its mission. Nuclear engineers have taken this into consideration: Typically only a part of the rods dropped are necessary to shut down the reactor. Samples of safety systems with passive safety components can be found in almost all nuclear power stations: the containment, hydro-accumulators in PWRs or pressure suppression systems in BWRs.\n\nIn most texts on 'passively safe' components in next generation reactors, the key issue is that no pumps are needed to fulfil the mission of a safety system and that all active components (generally I&C and valves) of the systems work with the electric power from batteries.\n\nIAEA explicitly uses the following caveat:\nNuclear reactor response properties such as Temperature coefficient of reactivity and Void coefficient of reactivity usually refer to the thermodynamic and phase-change response of the neutron moderator heat transfer \"process\" respectively. Reactors whose heat transfer process has the operational property of a negative void coefficient of reactivity are said to possess an \"inherent safety\" process feature. An operational failure mode could potentially alter the process to render such a reactor unsafe.\n\nReactors could be fitted with a hydraulic safety system component that increases the inflow pressure of coolant (esp. water) in response to increased outflow pressure of the moderator and coolant without control system intervention. Such reactors would be described as fitted with such a \"passive safety\" component that could – if so designed – render in a reactor a negative void coefficient of reactivity, regardless of the operational property of the reactor in which it is fitted. The feature would only work if it responded faster than an emerging (steam) void and the reactor components could sustain the increased coolant pressure. A reactor fitted with both safety features – if designed to constructively interact – is an example of a safety interlock. Rarer operational failure modes could render both such safety features useless and detract from the overall relative safety of the reactor.\n\nTraditional reactor safety systems are \"active\" in the sense that they involve electrical or mechanical operation on command systems (e.g., high-pressure water pumps). But some engineered reactor systems operate entirely passively, e.g., using pressure relief valves to manage overpressure. Parallel redundant systems are still required. Combined \"inherent\" and \"passive\" safety depends only on physical phenomena such as pressure differentials, convection, gravity or the \"natural\" response of materials to high temperatures to slow or shut down the reaction, not on the functioning of engineered components such as high-pressure water pumps.\n\nCurrent pressurized water reactors and boiling water reactors are systems that have been designed with one kind of passive safety feature. In the event of an excessive-power condition, as the water in the nuclear reactor core boils, pockets of steam are formed. These steam voids moderate fewer neutrons, causing the power level inside the reactor to lower. The BORAX experiments and the SL-1 meltdown accident proved this principle.\n\nA reactor design whose \"inherently\" safe process directly provides a \"passive\" safety component during a specific failure condition in \"all\" operational modes is typically described as relatively fail-safe to that failure condition. However most current water-cooled and -moderated reactors, when scrammed, can not remove residual production and decay heat without either process heat transfer or the active cooling system. In other words, whilst the inherently safe heat transfer process provides a passive safety component preventing excessive heat while the reactor is operating, the same inherently safe heat transfer process \"does not\" provide a passive safety component if the reactor is shut down (SCRAMed). The Three Mile Island accident exposed this design deficiency: the reactor and steam generator were shut down but with loss of coolant it still suffered a partial meltdown.\n\nThird generation designs improve on early designs by incorporating passive or inherent safety features which require \"no\" active controls or (human) operational intervention to avoid accidents in the event of malfunction, and may rely on pressure differentials, gravity, natural convection, or the natural response of materials to high temperatures.\n\nIn some designs the core of a fast breeder reactor is immersed into a pool of liquid metal. If the reactor overheats, thermal expansion of the metallic fuel and cladding causes more neutrons to escape the core, and the nuclear chain reaction can no longer be sustained. The large mass of liquid metal also acts as a heatsink capable of absorbing the decay heat from the core, even if the normal cooling systems would fail.\n\nThe pebble bed reactor is an example of a reactor exhibiting an inherently safe process that is also capable of providing a passive safety component for all operational modes. As the temperature of the \"fuel\" rises, Doppler broadening increases the probability that neutrons are captured by U-238 atoms. This reduces the chance that the neutrons are captured by U-235 atoms and initiate fission, thus reducing the reactor's power output and placing an inherent upper limit on the temperature of the fuel. The geometry and design of the fuel pebbles provides an important passive safety component.\n\nSingle fluid fluoride molten salt reactors feature fissile, fertile and actinide radioisotopes in molecular bonds with the fluoride coolant. The molecular bonds provide a passive safety feature in that a loss-of-coolant event corresponds with a loss-of-fuel event. The molten fluoride fuel can not itself reach criticality but only reaches criticality by the addition of a neutron reflector such as pyrolytic graphite. The higher density of the fuel along with additional lower density FLiBe fluoride coolant without fuel provides a flotation layer passive safety component in which lower density graphite that breaks off control rods or an immersion matrix during mechanical failure does not induce criticality. Gravity driven drainage of reactor liquids provides a passive safety component.\n\nLow power pool-type reactors such as the SLOWPOKE and TRIGA have been licensed for \"unattended\" operation in research environments because as the temperature of the low-enriched (19.75% U-235) uranium alloy hydride fuel rises, the molecular bound hydrogen in the fuel cause the heat to be transferred to the fission neutrons as they are ejected. This Doppler shifting or spectrum hardening dissipates heat from the fuel more rapidly throughout the pool the higher the fuel temperature increases ensuring rapid cooling of fuel whilst maintaining a much lower water temperature than the fuel. Prompt, self-dispersing, high efficiency hydrogen-neutron heat transfer rather than inefficient radionuclide-water heat transfer ensures the fuel cannot melt through accident alone. In uranium-zirconium alloy hydride variants, the fuel itself is also chemically corrosion resistant ensuring a sustainable safety performance of the fuel molecules throughout their lifetime. A large expanse of water and the concrete surround provided by the pool for high energy neutrons to penetrate ensures the process has a high degree of intrinsic safety. The core is visible through the pool and verification measurements can be made directly on the core fuel elements facilitating total surveillance and providing nuclear non-proliferation safety. Both the fuel molecules themselves and the open expanse of the pool are passive safety components. Quality implementations of these designs are arguably the safest nuclear reactors.\n\nThree Mile Island Unit 2 was unable to contain about 480 PBq of radioactive noble gases from release into the environment and around 120 kL of radioactive contaminated cooling water from release beyond the containment into a neighbouring building. The pilot-operated relief valve at TMI-2 was designed to shut automatically after relieving excessive pressure inside the reactor into a quench tank. However the valve mechanically failed causing the PORV quench tank to fill, and the relief diaphragm to eventually rupture into the containment building. The containment building sump pumps automatically pumped the contaminated water outside the containment building. Both a working PORV with quench tank and separately the containment building with sump provided two layers of passive safety. An unreliable PORV negated its designed passive safety. The plant design featured only a single open/close indicator based on the status of its solenoid actuator, instead of a separate indicator of the PORV's actual position. This rendered the mechanical reliability of the PORV indeterminate directly, and therefore its passive safety status indeterminate. The automatic sump pumps and/or insufficient containment sump capacity negated the containment building designed passive safety.\n\nThe notorious RBMK graphite moderated, water-cooled reactors of Chernobyl Power Plant disaster were designed with a positive void coefficient with boron control rods on electromagnetic grapples for reaction speed control. To the degree that the control systems were reliable, this \"design\" did have a corresponding degree of \"active\" inherent safety. The reactor was unsafe at low power levels because erroneous control rod movement would have a counter-intuitively magnified effect. Chernobyl Reactor 4 was built instead with manual crane driven boron control rods that were tipped with the moderator substance, graphite, a neutron reflector. It was designed with an Emergency Core Cooling System (ECCS) that depended on either grid power or the backup Diesel generator to be operating. The ECCS safety component was decidedly not passive. The design featured a partial containment consisting of a concrete slab above and below the reactor – with pipes and rods penetrating, an inert gas filled metal vessel to keep oxygen away from the water-cooled hot graphite, a fire-proof roof, and the pipes below the vessel sealed in secondary water filled boxes. The roof, metal vessel, concrete slabs and water boxes are examples of passive safety components. The roof in the Chernobyl Power Plant complex was made of bitumen – against design – rendering it ignitable. Unlike the Three Mile Island accident, neither the concrete slabs nor the metal vessel could contain a steam, graphite and oxygen driven hydrogen explosion. The water boxes could not sustain high pressure failure of the pipes. The passive safety components as designed were inadequate to fulfill the safety requirements of the system.\n\nThe General Electric Company ESBWR (Economic Simplified Boiling Water Reactor, a BWR) is a design reported to use passive safety components. In the event of coolant loss, no operator action is required for three days.\n\nThe Westinghouse AP1000 (\"AP\" standing for \"Advanced Passive\") uses passive safety components. In the event of an accident, no operator action is required for 72 hours. Recent version of the Russian VVER have added a passive heat removal system to the existing active systems, utilising a cooling system and water tanks built on top of the containment dome.\n\nThe integral fast reactor was a fast breeder reactor run by the Argonne National Laboratory. It was a sodium cooled reactor capable of withstanding a loss of (coolant) flow without SCRAM and loss of heatsink without SCRAM. This was demonstrated throughout a series of safety tests in which the reactor successfully shut down without operator intervention. The project was canceled due to proliferation concerns before it could be copied elsewhere.\n\nThe Molten-Salt Reactor Experiment (MSRE) was a molten salt reactor run by the Oak Ridge National Laboratory. It was nuclear graphite moderated and the coolant salt used was FLiBe, which also carried the uranium-233 fluoride fuel dissolved in it. The MSRE had a negative temperature coefficient of reactivity: as the FLiBe temperature increased, it expanded, along with the uranium ions it carried; this decreased density resulted in a reduction of fissile material in the core, which decreased the rate of fission. With less heat input, the net result was that the reactor would cool. Extending from the bottom of the reactor core was a pipe that lead to passively cooled drain tanks. The pipe had a \"freeze valve\" along its length, in which the molten salt was actively cooled to a solid plug by a fan blowing air over the pipe. If the reactor vessel developed excessive heat or lost electric power to the air cooling, the plug would melt; the FLiBe would be pulled out of the reactor core by gravity into dump tanks, and criticality would cease as the salt lost contact with the graphite moderator.\n\nThe General Atomics HTGR design features a fully passive and inherently safe decay heat removal system, termed the Reactor Cavity Cooling System (RCCS). In this design, an array of steel ducts line the concrete containment (and hence surround the reactor pressure vessel) which provide a flow path for air driven natural circulation from chimneys positioned above grade. Derivatives of this RCCS concept (with either air or water as the working fluid) has also been featured in other gas-cooled reactor designs, including the Japanese High-temperature engineering test reactor, the Chinese HTR-10, the South African PBMR, and the Russian GT-MHR. While none of these designs have been commercialized for power generation research in these areas is active, specifically in support of the Generation IV initiative and NGNP programs, with experimental facilities at Argonne National Laboratory (home to the Natural convection Shutdown heat removal Test Facility, a 1/2 scale air-cooled RCCS) and the University of Wisconsin (home to separate 1/4 scale air and water-cooled RCCS).\n\n\n"}
{"id": "7332857", "url": "https://en.wikipedia.org/wiki?curid=7332857", "title": "Pollutant Standards Index", "text": "Pollutant Standards Index\n\nThe Pollutant Standards Index, or PSI, is a type of air quality index, which is a number used to indicate the level of pollutants in air. \n\nInitially PSI was based on five air pollutants, but since 1 April 2014 it has also included fine particulate matter (PM). \n\nIn addition to the PSI derived by averaging data collected for the past 24 hours, Singapore also publishes a 3h-PSI based on PM concentrations for the past 3 hours. 1-hr PM concentrations are also published every hour.\n\nBesides Singapore, some other countries also use air quality indices. However, the calculations used to derive their air quality indices may differ. Different countries also use different names for their indices such as Air Quality Health Index, Air Pollution Index and Pollutant Standards Index.\n\nThe PSI is based on a scale devised by the United States Environmental Protection Agency (USEPA) to provide a way for broadcasts and newspapers to report air quality on a daily basis. The PSI has been used in a number of countries including the United States and Singapore. \n\nSince 1999, the United States EPA has replaced the Pollution Standards Index (PSI) with the Air Quality Index (AQI) to incorporate new PM2.5 and ozone standards.\n\nPrior to 1 April 2014, Singapore published the PSI and the 1-hour PM2.5 reading separately. This 3-hour PSI is unique to Singapore and was introduced in 1997 to provide additional air quality information which would better reflect a more current air quality situation. In 2016, the 3-hour PSI was phased out on the grounds that the 1-hour PM2.5 reading was a better indicator of the current air quality. \n\nThe PSI considers six air pollutants - sulphur dioxide (SO), particulate matter (PM), fine particulate matter (PM), nitrogen dioxide (NO), carbon monoxide (CO) and ozone (O). \n\nThe concentrations of these pollutants in the ambient air are measured via a network of air monitoring stations located around Singapore. \n\nA sub-index value is computed for each pollutant based on the pollutant's ambient air concentration. The highest sub-index value is then taken as the PSI value. In other words, the PSI is determined by the pollutant with the most significant concentration. \n\nDuring haze episodes, PM is the most significant pollutant. \n\nThe PSI is reported as a number on a scale of 0 to 500. The index figures enable the public to determine whether the air pollution levels in a particular location are good, unhealthy, hazardous or worse. The following PSI table is grouped by index values and descriptors, explaining the effects of the levels, according to Singapore's National Environment Agency (NEA).\n\nNote: This chart reflects the guidelines used in Singapore and may differ from other countries. Health advisories are based on the USEPA’s guidelines. Only the 24-hour PSI value and not the 3-hour PSI value is correlated to the health effects outlined in NEA’s advisories. \n\nSingapore has been regularly hit by smoke haze from forest fires in nearby Sumatra, Indonesia, brought over by wind. These forest fires have been attributed to the slash-and-burn method favoured by several large plantation owners to clear their land, as opposed to a more expensive and inconvenient mechanical approach using excavators and bulldozers. In June 2013, severe haze hit Singapore, pushing the nation's PSI into \"Hazardous\" levels for the first time in its history. Presently, the highest 3-hour PSI reading on record in Singapore is 471 on 20 October 2015 at 11 pm (GMT+8).</ref>\n\n"}
{"id": "7579959", "url": "https://en.wikipedia.org/wiki?curid=7579959", "title": "Seasonal adjustment", "text": "Seasonal adjustment\n\nSeasonal adjustment is a statistical method for removing the seasonal component of a time series that exhibits a seasonal pattern. It is usually done when wanting to analyse the trend, and cyclical deviations from trend, of a time series independently of the seasonal components. It is normal to report seasonally adjusted data for unemployment rates to reveal the underlying trends and cycles in labor markets. Many economic phenomena have seasonal cycles, such as agricultural production and consumer consumption, e.g. greater consumption leading up to Christmas. It is necessary to adjust for this component in order to understand what underlying trends are in the economy and so official statistics are often adjusted to remove seasonal components.\n\nThe investigation of many economic time series becomes problematic due to seasonal fluctuations. Time series are made up of four components:\n\n\nThe difference between seasonal and cyclic patterns:\n\nThe relation between decomposition of time series components\n\nUnlike the trend and cyclical components, seasonal components, theoretically, happen with similar magnitude during the same time period each year. The seasonal components of a series are sometimes considered to be uninteresting and to hinder the interpretation of a series. Removing the seasonal component directs focus on other components and will allow better analysis.\n\nDifferent statistical research groups have developed different methods of seasonal adjustment, for example X-13-ARIMA and X-12-ARIMA developed by the United States Census Bureau; TRAMO/SEATS developed by the Bank of Spain; MoveReg (for weekly data) developed by the United States Bureau of Labor Statistics, STAMP developed by a group led by S. J. Koopman; and “Seasonal and Trend decomposition using Loess” (STL) developed by Cleveland et al. (1990). While X-12/13-ARIMA can only be applied to monthly or quarterly data, STL decomposition can be used on data with any type of seasonality. Furthermore, unlike X-12-ARIMA, STL allows the user to control the degree of smoothness of the trend cycle and how much the seasonal component changes over time. X-12-ARIMA can handle both additive and multiplicative decomposition whereas STL can only be used for additive decomposition. In order to achieve a multiplicative decomposition using STL, the user can take the log of the data before decomposing, and then back-transform after the decomposition.\n\nBrief introduction to process of X-12-ARIMA:\n\nFor example: description assumes monthly data.\nAdditive decomposition: formula_5:\nMultiplicative decomposition: formula_8\n\nRepeat whole process two more times with modified data. On final iteration, the 3 * 5 MA of Steps 11 and 12 is replaced by either a 3 * 3, 3 * 5, or 3 * 9 moving average, depending on the variability in the data.\n\n6. Time series\nEach group provides software supporting their methods. Some versions are also included as parts of larger products, and some are commercially available. For example, SAS includes X-12-ARIMA, while Oxmetrics includes STAMP. A recent move by public organisations to harmonise seasonal adjustment practices has resulted in the development of Demetra+ by Eurostat and National Bank of Belgium which currently includes both X-12-ARIMA and TRAMO/SEATS. R includes STL decomposition. The X-12-ARIMA method can be utilized via the R package \"X12\" . EViews supports X-12, X-13, Tramo/Seats, STL and MoveReg.\n\nOne well-known example is the rate of unemployment, which is represented by a time series. This rate depends particularly on seasonal influences, which is why it is important to free the unemployment rate of its seasonal component. Such seasonal influences can be due to school graduates or dropouts looking to enter into the workforce and regular fluctuations during holiday periods. Once the seasonal influence is removed from this time series, the unemployment rate data can be meaningfully compared across different months and predictions for the future can be made. Seasonal adjustment is used in the official statistics implemented by statistical software like Demetra+.\n\nWhen seasonal adjustment is not performed with monthly data, year-on-year changes are utilised in an attempt to avoid contamination with seasonality.\n\nDue to the various seasonal adjustment practices by different institutions, a group was created by Eurostat and the European Central Bank to promote standard processes. In 2009 a small group composed of experts from European Union statistical institutions and central banks produced the ESS Guidelines on Seasonal Adjustment, which is being implemented in all the European Union statistical institutions. It is also being adopted voluntarily by other public statistical institutions outside the European Union.\n\nBy the Frisch–Waugh–Lovell theorem it does not matter whether dummy variables for all but one of the seasons are introduced into the regression equation, or if the independent variable is first seasonally adjusted (by the same dummy variable method), and the regression then run.\n\nSince seasonal adjustment introduces a \"non-revertible\" moving average (MA) component into time series data, unit root tests (such as the Phillips–Perron test) will be biased towards non-rejection of the unit root null.\n\nUse of seasonally adjusted time series data can be misleading. This is because the seasonally adjusted series contains both the trend-cycle component and the error component. As such, the seasonally adjusted data will not be \"smooth\" and what appears to be \"downturns\" or \"upturns\" may actually be randomness in the data. For this reason, if the purpose is finding turning points in a series, it is better to use the trend-cycle component rather than the seasonally adjusted data.\n\n\n\n"}
{"id": "36591692", "url": "https://en.wikipedia.org/wiki?curid=36591692", "title": "Society for the Preservation of Natural History Collections", "text": "Society for the Preservation of Natural History Collections\n\nThe Society for the Preservation of Natural History Collections (abbreviated SPNHC, often pronounced \"spinach\") \"is an international society whose mission is to improve the preservation, conservation and management of natural history collections to ensure their continuing value to society\".\n\nFounded in 1985, the society was created to cater to the needs of those involved in the care, management and development of natural history collections. Society activities include annual meetings, the publication of a newsletter, and an active list-serv in which members consult one another about natural history collections management issues. The mission of SPNHC continues to grow, broadly encompassing archival materials such as field notes, and new and growing efforts in digitization and mobilization of collections resources.\n\n"}
{"id": "26304433", "url": "https://en.wikipedia.org/wiki?curid=26304433", "title": "Soil biomantle", "text": "Soil biomantle\n\nThe soil biomantle can be described and defined in several ways. Most simply, the soil biomantle is the organic-rich bioturbated upper part of the soil, including the topsoil where most biota live, reproduce, die, and become assimilated. The biomantle is thus the upper zone of soil that is predominantly a product of organic activity and the area where bioturbation is a dominant process. Soil bioturbation consists predominantly of three subsets: \"faunalturbation\" (animal burrowings), \"floralturbation\" (root growth, tree-uprootings), and \"fungiturbation\" (mycelia growth). All three processes promote soil parent material destratification, mixing, and often particle size sorting, leading with other processes to the formation of soil and its horizons. While the general term bioturbation refers mainly to these three mixing processes, unless otherwise specified it is commonly used as a synonym to faunalturbation (animal burrowings).\n\nThe biomantle includes the topsoil, or A horizon of soils, and also, any underlying lighter-colored (E) horizon that may be present. For midlatitude and subtropical soils that have typical A-E-B-C horizons and profiles, the biomantle is normally that part above the B horizon. In gravelly parent materials where soil particle biosorting by animals has led to the formation of a stonelayer horizon (SL), the base of the stonelayer (SL) defines the base of the biomantle. Biomantles with basal stonelayers are two-layered biomantles that form in parent materials with heterogeneous particle sizes (mixtures of fines and gravels); those lacking stonelayers are one-layered biomantles that form in homogeneous materials (either sands, loess, or gravels of approximately uniform size). If two-layered, the soil profile horizon notations in midlatitude and some subtropical soils are: A-E-SL-B-C, where the A-E-SL horizons constitute the biomantle.\n\nSince midlatitude type Bt (argillic) horizons are often lacking in tropical soils owing to an abundance of active and deep bioturbators that move large volumes of soil to the surface (ants, termites, worms, etc.), horizon notations are: M-SL-W, where M is the mineral soil (extended topsoil), SL is stonelayer, and W is the underlying weathered or saprolite zone. In this tropical soil scheme the M horizon is the main biomantle and the SL horizon constitutes its base. Stonelayers occupy the base of biomantles in many, if not most, tropical soils and in many midlatitude soils. Where present they often function as subsurface “French drains” for soil-water movements and storage.\n\nBecause the soil biomantle is the main zone of bioturbation, it is invariably permeable and of low density. It thus plays several essential hydropedological roles in the environment. For example, it promotes the downward percolation of rainwater and snowmelt through often-abundant biochannels and interconnected biopores. The biomantle also promotes downslope soil-water (throughflow, interflow) movements if it is formed above a clay-enriched Bt (argillic) horizon, or above some other dense subsoil horizon (e.g., duripan, fragipan, etc.) or bedrock – all of which generally function as aquitards or aquicludes to vertical soil water flow. In such cases the stonelayer, if present, can actually function as an aquifer for free water flow. Hence it is not uncommon to see soil water seepage above Bt horizons on slopes where soil stonelayers outcrop. Ground water recharge can occur through any of these biomantle-related processes. Recharge, of course, can also occur when the soil dries appreciably and shrinks, as during droughts, which allows vertical leakage to temporarily occur immediately after drought-breaking rainfalls.\n\nThe pedosphere, or soil, is the planetary interface where Earth’s five great global ‘spheres’ interact. These are the atmosphere, biosphere, hydrosphere, lithosphere, and pedosphere. The \"critical zone\", a recent conceptual framework, encompasses the Earth’s outer layer in which most surface and near-surface life sustaining processes operate. In practice and theory, the critical zone essentially equates to the pedosphere, whereas the ‘biomantle’ deals with the uppermost critical zone, or pedosphere, encompassing its epidermal layer (where most biota live).\n\nIn midlatitude soils where most bioturbation is relatively shallow, seasonal, and without many bioturbators, the biomantle is relatively thin, often less than 1–2 m thick. However, in humid tropical and subtropical erosionally stable regions where both greater volumes of soil are biotransfered and deeper bioturbations occur—and bioturbation is year-round and performed by more invertebrate animals (termites, ants, worms, etc.), the biomantle is often thicker, sometimes 5–6 m or more thick. Where such soils are formed in conjunction with saprolite production, the biomantle is the bioturbated zone above the structured (unbioturbated) saprolite, with its base commonly defined by a stonelayer. In most subtropical and tropical areas where deep and large volume bioturbators dwell, and in some midlatitudes like South Africa, such thick, two-layered biomantles (those with stonelayers) above structured saprolite are very common.\n\nIn some desert soils, in many mountain soils with moderate to steep slopes, in many recently eroded bedrock soils, and in various other soils, the biomantle constitutes the entire soil. That is, neither soil horizons nor weathering zones underlie the biomantle. Such biomantles are \"whole-soil biomantles\".\n\nAs originally defined, a biomantle must exhibit at least 50% biofabric. This criterion denotes small, often pelletized microbiofabric and mesobiofabric produced by invertebrates (ants, worms, termites), usually observed under hand lens or higher magnification (soil thin sections). The criterion, however, becomes moot and irrelevant in the case of megabiofabric produced in some biomantles – namely the cloddy and chunky surface-spoil heaps produced by small-to-large burrowing vertebrates (rodents, badgers, aardvarks, elephants) and by tree uprooting.\n\nApart from a few stratified cave sites—and those rare open-air sites where archaeological materials were deposited so rapidly that bioturbation and resultant destratifications failed to keep pace with deposition, most prehistoric cultural materials of the world reside in the soil biomantle. Such materials are thus mixed, and technically and theoretically out of its original context. Since many cultural materials (cleavers, choppers' core-stones, metates, manos, pestles, etc.) are invariably larger than burrow diameters of most key bioturbators at such sites (small rodents, ants, termites, worms), they settle downward and form a stonelayer, and thus become part of a two-layered biomantle. Smaller artifacts (flakes, debitage) often are homogenized throughout the upper biomantle, and commonly observed in recent bioturbational spoil heaps, like those produced by pocket gophers, moles, and mole-rats. Beginning with Darwin, the earthworm has been recognized as a key bioturbator of soil biomantles and human artifacts on many continents and islands.\n\nSoil biomantles, and soils, have been forming from the time that life began inhabiting land. Although little formal work has been done on this interesting theme, important first steps are being made.\n\nThe biomantle is an organic-rich near-surface layer in which bioturbation is a dominant process, with all other biological and more traditional soil processes normally being subsidiary (e.g., organic matter productions, eluviations-illuviations, weathering-biochemical transformations, wind and water erosions-depositions, freeze-thaw, dilations-contractions, shrink-swell, gravity movements, geochemical-capillary surface-wickings and precipitations, etc.). The expression \"dynamic denudation\" is the sum of all these processes, with bioturbation and organic impacts commonly dominant.\n\nThe role of plants in soil formation is undisputedly great, both agronomically and silviculturally, and is well appreciated and reasonably well understood by geomorphologists, pedologists, soil scientists, farmers, gardeners, and others., However, the role of animals in soil formation, and in creating soil and soil horizons, and creating various soil-landscape entities (biomantles, Mima mounds, stone lines, etc.), has poorly understood until recently.\n\nWilkinson and Humphreys offer evidence that “bioturbation appears to be the most active pedogenic process operating in many soils.” While probably close to the mark, research over multiple decades strongly indicates that bioturbation is the dominant process in the upper part of most soils, notable exceptions possibly being vertisols and cryosols, where shrink-swell and freeze-thaw processes, respectively, appear dominant.\n\nSoil bioturbations consist of three upper soil disorganizing and organizing sub-processes that can overlap, and that collectively promote particle abrasions and size reductions, termed \"particle comminution\". The three bioturbation sub-processes are \"biomixing\", \"biotransfers\", and \"biosorting\".\n\n\"Biomixing\" refers to the kind of soil bioturbations typically caused by surface-, shallow-, and intermediate-burrowing vertebrates, such as rodents (pocket gophers, tuco-tucos, mole-rats), insectivores (moles), mustelids (badgers), canids (wolves, coyotes, foxes), marsupials (marsupial moles, wombats), aardvarks, armadillos, pigs, and other similar organisms. Though animal bioturbations are dominant, tree uprooting is still an important process.\n\n\"Biotransfers\" refers to transfers of soil by animals, vertebrates or invertebrates, either to the surface, within the biomantle, or from lower levels. Biotransfers can be effected by any burrowing animal, but the term is most applicable to deep burrowing, so-called conveyor-belt animals, such as ants, termites, and worms. Termites, for example, may burrow downward many meters into weathered and unweathered parent material to collect moist soil for constructing their surface mounds (termitaria). Ants, particularly leaf-cutter ants, can also biotransfer tremendous amounts of soil to the surface in the process of excavating their innumerable multipurpose subterranean chambers. Enormous amounts of soil and sediment are annually biotransferred onto tropical-subtropical landscapes in this process, and even onto some midlatitude landscapes (e.g., Texas, Louisiana), resulting in notably thick biomantles on stable (low slope) surfaces.\n\n\"Biosorting\" refers to particle sorting, typically in gravelly (mixed particle) soils, that leads to the formation of a stonelayer (SL) horizon at the base of the biomantle, which results in a two-layered biomantle. The process begins as animals burrow and only soil particles smaller than their burrow diameters are moved; larger particles settle downward as smaller particles are moved upward from below them. The stonelayer (SL) forms at rates roughly proportional to the numbers of bioturbators and the intensity and style of burrowing. Conveyor-belt soil invertebrates (ants, termites, worms, etc.) are the primary biosorters in most tropical, subtropical, and some midlatitude soils, and thus often produce deep, two-layered biomantles if the soils contain gravels, as many do. Small fossorial vertebrates (pocket gophers, moles, tuco tucos, etc.), on the other hand, tend to be dominant biosorters in many midlatitude soils, especially deserts, prairies, and steppes. In more humid areas, like northeastern U.S. and W. Europe, conveyor-belt ants and worms are probably dominant or co-dominant.\n\n"}
{"id": "9394749", "url": "https://en.wikipedia.org/wiki?curid=9394749", "title": "Temperate deciduous forest", "text": "Temperate deciduous forest\n\nTemperate deciduous or temperate broad-leaf forests are a variety of temperate forest dominated by trees that lose their leaves each year. They are found in areas with warm moist summers and cool winters. The six major areas of this forest type occur in the Northern Hemisphere: North America, East Asia, Central and Western Europe (except Brittany, Cornwall, Wales, Ireland and western Scotland), Denmark, southern Sweden and southern Norway. Smaller areas occur in Australasia and southern South America. Examples of typical trees in the Northern Hemisphere's deciduous forests include oak, maple, beech and elm, while in the Southern Hemisphere, trees of the genus \"Nothofagus\" dominate this type of forest. The diversity of tree species is higher in regions where the winter is milder, and also in mountainous regions that provide an array of soil types and microclimates. The largest intact temperate deciduous forest in the world is protected inside of the six-million-acre Adirondack Park in Upstate New York.\n\nHumans have often colonized areas in the temperate deciduous forest. They have harvested wood for timber and charcoal. During the settlement of North America, potash made from tree ashes was exported back to Europe as fertilizer. This left less than one-quarter of original forests to remain. Many forests are now small fragments dissected by fields and roads; these islands of green often differ substantially from the original forests, particularly along the edges. The introduction of exotic diseases continues to be a threat to forest trees, and hence, the forest; examples include the loss of chestnut and elm. At the same time, species such as deer, which are clearing rather than true forest animals, have expanded their range and proliferated in these altered landscapes. Large deer populations have deleterious effects on tree regeneration overall, but particularly for edible species including yew, yellow birch, and hemlock. Deer grazing also has significant negative effects on the number and kind of herbaceous flowering plants. The continuing pressure to increase deer populations, and the continued killing of top carnivores, suggests that overgrazing by deer will continue to be a significant forest conservation problem. Objective criteria for the restoration of deciduous forest include large trees, coarse woody debris, spring ephemeral, and top predators.\n\n\n"}
