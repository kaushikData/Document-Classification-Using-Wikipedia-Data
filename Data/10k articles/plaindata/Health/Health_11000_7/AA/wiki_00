{"id": "15458182", "url": "https://en.wikipedia.org/wiki?curid=15458182", "title": "Acute chest syndrome", "text": "Acute chest syndrome\n\nThe acute chest syndrome is a vaso-occlusive crisis of the pulmonary vasculature commonly seen in people with sickle cell anemia. This condition commonly manifests with a new opacification of the lung(s) on a chest x-ray.\n\nThe crisis is a common complication in sickle-cell patients and can be associated with one or more symptoms including fever, cough, excruciating pain, sputum production, shortness of breath, or low oxygen levels.\n\nAcute chest syndrome is often precipitated by a lung infection, and the resulting inflammation and loss of oxygen saturation leads to further sickling of red cells, thus exacerbating pulmonary and systemic hypoxemia, sickling, and vaso-occlusion.\nThe diagnosis of acute chest syndrome is made difficult by its similarity in presentation with pneumonia. Both may present with a new opacification of the lung on chest x-ray. The presence of fevers, low oxygen levels in the blood, increased respiratory rate, chest pain, and cough are also common in acute chest syndrome. Diagnostic workup includes chest x-ray, complete cell count, reticulocyte count, ECG, and blood and sputum cultures. Patients may also require additional blood tests or imaging (e.g. a CT scan) to exclude a heart attack or other pulmonary pathology. \nHydroxyurea is a medication that can help to prevent acute chest syndrome. It may cause a low white blood cell count, which can predispose the person to some types of infection.\n\nBroad spectrum antibiotics to cover common infections such as \"Streptococcus pneumoniae\" and mycoplasma, pain control, and blood transfusion. Acute chest syndrome is an indication for exchange transfusion.\n\nBronchodilators may be useful but have not been well studied.\n\nIt may result in death, and it is one of the most common causes of death for people with sickle cell anemia.\n"}
{"id": "58113303", "url": "https://en.wikipedia.org/wiki?curid=58113303", "title": "Andrea Gore", "text": "Andrea Gore\n\nAndrea C. Gore is a neuroendocrinology professor at the University of Texas at Austin in the Division of Toxicology and Pharmacology, where she holds the Vacek Chair of Pharmacology. She is a prominent contributor to the field of reproductive endocrinology. Her research interests span from the neurological basis of reproductive aging to endocrine disruptors in the nervous system. From January 2013 through December 2017, she was Editor-in-Chief of the journal \"Endocrinology.\" Gore has authored or co-authored four books and published over 170 peer-reviewed articles. \n\nGore graduated cum laude from Princeton University in 1985 with a A.B. in Biology. She received her Ph.D. in Neuroscience from University of Wisconsin-Madison in 1990. For her Ph.D. she studied hormonal control of puberty onset in rhesus monkeys. From 1991-1995, she completed a postdoctoral fellowship in Molecular Medicine at Mount Sinai School of Medicine. \n\nAfter her postdoctoral fellowship, she became an Assistant Professor in Neurobiology at Mount Sinai School of Medicine. In 2002, she became an Associate Professor at Mount Sanai. From 2008 to present, Gore serves as a Gustavus & Louise Pfeiffer Professor Professor of Pharmacology at University of Austin. \n\nEndocrine Society Laureate Award, Outstanding Public Service Award (2016)\n\nEdith Clarke Woman of Excellence Award by the Senate of College Councils (2016)\n\nDistinguished Scientist Award, Society for Experimental Biology and Medicine (2013)\n\nWomen in Endocrinology, Janet W. McArthur Achievement Award (1996)\n\n"}
{"id": "14102440", "url": "https://en.wikipedia.org/wiki?curid=14102440", "title": "Ash pit", "text": "Ash pit\n\nAn ash pit is a remnant of a wildfire. It is a hole in the ground filled with ash, possibly containing hot embers beneath. It is one of the many hazards faced by those fighting wildfires. It is also a danger to residents and their pets returning after a wildfire has gone out.\n\nAn ash pit may be imperceptible from the ground above, and can remain hot for days. Those accidentally walking into one may be severely burned or killed. \n\nAfter a wildfire has gone out, firefighters may detect ash pits from helicopters using infrared sensors. Then can then dig down into them, and extinguish them to prevent flare ups.\n\nAfter a fire burns underground fuels, it can create a void that becomes filled with ash from the burned fuel. There are several environmental factors that increase the likelihood of an ash pit being formed. It may result from the presence of extensive root systems of trees and shrubs, as well as peat and deep duff covering mineral soil. Holes created by animals, such as coyote and badger dens, can become ash pits. Abandoned rodent holes can become filled with dry, organic debris. Once this debris is burned, an ash pit may be produced. Areas that have been modified by humans may also become hazardous ash pits. Examples include areas modified with heavy equipment, former bulldozer piles, as well as sawmill sites and timber yards.\n\nAn ash pit may sometimes be detected by the presence of white ash or swarms of insects hovering about.\n\nNearly translucent smoke that quickly dissipates may be visible emanating from an ash pit when it is between the observer and the sun.\n\nDue to incomplete burning, an ash pit may also produce a smell of burning creosote or incomplete combustion.\n\nUpon detection, marking or flagging ash pits is advised. Landscapes that have the potential to produce ash pits should be avoided.\n"}
{"id": "26651080", "url": "https://en.wikipedia.org/wiki?curid=26651080", "title": "Bill for the Benefit of the Indigent Insane", "text": "Bill for the Benefit of the Indigent Insane\n\nThe Bill for the Benefit of the Indigent Insane (also called the Land-Grant Bill For Indigent Insane Persons, formally the bill \"Making a grant of public lands to the several States for the benefit of indigent insane persons\") was proposed legislation that would have established asylums for the indigent insane, and also blind, deaf, and dumb, via federal land grants to the states.\nThe bill was the signature initiative of activist Dorothea Dix, and passed both houses of Congress in 1854. However, it was vetoed on May 3, 1854 by President Franklin Pierce, the first of his nine vetoes. Pierce argued that the federal government should not commit itself to social welfare, which he believed was properly the responsibility of the states.\n\nThe main provision of the bill was to set aside of federal land: for the benefit of the insane, and the remainder to be sold for the benefit of the \"blind, deaf, and dumb\", with proceeds distributed to the states to build and maintain asylums.\n\nThe initial request, on June 23, 1848, had been for five million acres (20,000 km²), which was subsequently expanded.\n\nThe bill was part of the first wave of public mental health initiatives in the United States, which saw the establishment of asylums.\n\nThe bill is seen as a landmark in social welfare legislation in the United States. Pierce's veto established a precedent for federal non-participation in social welfare that lasted over 70 years, until the emergency legislation and New Deal of the 1930s Great Depression. Compare instead the county institution of the poor farm.\n\nNo further federal legislation on mental health occurred for over 90 years until 1946 when the National Mental Health Act was passed, establishing federal mental health policy.\n\n"}
{"id": "43518554", "url": "https://en.wikipedia.org/wiki?curid=43518554", "title": "CAMBRA", "text": "CAMBRA\n\nCAMBRA is an acronym for Caries Management by Risk Assessment. It describes a preventative form of dentistry in which patients are categorized by their relative risk for developing dental caries, based on risk factors including diet, oral hygiene, fluoride regiment, and past oral health history.\n"}
{"id": "56129137", "url": "https://en.wikipedia.org/wiki?curid=56129137", "title": "Cannabis in El Salvador", "text": "Cannabis in El Salvador\n\nThe possession and use of cannabis is illegal in El Salvador for both recreational and medical purposes. The country is a signatory of the 1988 United Nations Convention Against Illicit Traffic in Narcotic Drugs and Psychotropic Substances, and has criminalized the production and distribution of the drug.\n\nEl Salvador (along with Peru and Bolivia) is one of the most conservative countries in Latin America in regard to drug policy. According to a 2016 study published by the \"International Journal of Drug Policy\", only 17% of Salvadorans reported having used cannabis.\n\nIn 2014, over 700 people protested in San Salvador in favor of decriminalizing the consumption and personal cultivation of cannabis. The demonstration was organized by the activist group La María Guanaca and backed by the Evangelical Protestant Church of El Salvador. \n\nHowever, support for cannabis reform remains very low. A 2014 survey by AmericasBarometer found that a mere 8% of Salvadorans supported legalization of the drug. According to the survey, support was highest among people with higher levels of education, and low among people who consider religion to be especially important in their lives.\n\n"}
{"id": "53834411", "url": "https://en.wikipedia.org/wiki?curid=53834411", "title": "Cannabis in Iran", "text": "Cannabis in Iran\n\nCannabis in Iran is illegal, but the law is often not strictly enforced. The use of cannabis has become increasingly popular in Iranian cities according to various reports, although the government does not keep official usage statistics.\n\nIn 1989 the Iranian government enacted a law providing the death penalty for possession of hashish in excess of five kilograms.\n\nThe popularization of cannabis is apocryphally attributed to Sheikh Haydar (d. 1221 CE), a Sufi saint who lived in Khurasan province of what is now Iran.\n\nIn 2015, Saeed Sefatian, who leads the working group on drug demand reduction within the Council for the Discernment of the Expediency of the State (or Expediency Council) presented a lecture outlining steps towards legalizing cannabis.\n"}
{"id": "23830565", "url": "https://en.wikipedia.org/wiki?curid=23830565", "title": "Capital punishment in Mexico", "text": "Capital punishment in Mexico\n\nCapital punishment in Mexico was officially abolished on 15 March 2005, having not been used in civil cases since 1937, and in military cases since 1961. Mexico is the world's most populous country to have completely abolished the death penalty.\n\nThere is significant history of abolitionism in Mexico, dating back to the 19th century. Following the Plan of Ayutla, the 1857 constitution was drafted, which specifically outlawed the death penalty for political crimes, and allowed abolition for ordinary crimes in the future. Mexico's government at that time was quite unstable, and the express abolition of political crimes could have been linked to concern that the lawmakers themselves could become subject to the punishment if there was an uprising. Personal experiences too may have been a factor, as many Mexicans had experienced political repression. There was widespread condemnation of the death penalty in the media, and many Mexican literates were familiar with the work of Cesare, Marquis of Beccaria. Following the rule of Porfirio Díaz, the death penalty article was amended in the reform which led to the current Constitution of Mexico.\n\nThe last non-military execution in Mexico was in 1937, and the last military execution (of a soldier charged with insubordination and murder) was in 1961, so the official abolition of the military death penalty in 2005 and of the civil death penalty in 1976 lagged the \"de facto\" cessations by 68 and 15 years, respectively.\n\nMexico is a majority Roman Catholic country, with 88% of the population identifying themselves as adherents. The Vatican has made numerous statements criticizing capital punishment, and this may be a factor in the debate in Mexico.\n\nDuring a debate in 2018 during the Mexican general election, 2018 candidate Jaime Rodríguez Calderón proposed to reinstate the death penalty for drug traffickers, hijackers, infanticides and serial killers.\n\nThe Mexican Drug War has fueled rising rates of violent crimes such as kidnapping and murder, prompting a reemergence of capital punishment into the political discourse. The Ecologist Green Party of Mexico (PVEM), the fourth biggest political force in the country, waged a campaign to promote restoration of the death penalty, including the use of billboards, as part of promotion of the party for the 2009 election for seats in Congress. There have been proposals to amend the 1917 Constitution to allow capital punishment from both the PVEM and the Institutional Revolutionary Party (PRI), but both were rejected. \nSurveys in 2009 suggested that up to 70% of the population supported the restoration of the death penalty, however it is unlikely that the constitution will be changed, as both religious and human rights groups have strongly opposed restoration.\n\nA 2017 poll study found younger Mexicans are more likely to support capital punishment.\nConstitution: Article 22\n\nCruel and unusual punishment is prohibited. Specifically, penalties of death, mutilation, infamy, marks, physical punishments, torments, excessive fines, confiscation of assets, and others are abolished.\n\nConfiscation of assets does not include the application of said assets to pay for civil responsibilities caused by a crime, or when used to pay taxes or other fines. Nor will it be confiscation when said assets are part of illegal activities, or when they are related to organized crime, or when proof of ownership cannot be established.\n\nIn 1981, Mexico ratified the American Convention on Human Rights, a treaty of the Organization of American States, which prohibits the death penalty from being restored if eliminated. Mexico does not extradite to countries that are seeking the death penalty, and has successfully defended 400 of its citizens charged with a capital offence in the United States. This has in the past led to American fugitives crossing the border into Mexico in order to avoid the death penalty.\n\nIn 2002, President Vicente Fox cancelled a trip to the United States to meet US President George W. Bush, in protest of the then imminent execution of a Mexican national, Javier Suárez Medina, in the U.S. state of Texas. Medina had been convicted in 1989 for killing an undercover police officer in Dallas. According to Mexican officials, Suárez was not informed about his right to consular access, and fourteen countries lobbied the United States Supreme Court on behalf of him.\n\nIn 2003 Mexico filed a complaint against the United States at the International Court of Justice, alleging that the US had contravened the Vienna Convention by not allowing 54 Mexicans sentenced to death to contact diplomatic officials.\n\n\n"}
{"id": "40822796", "url": "https://en.wikipedia.org/wiki?curid=40822796", "title": "Capital punishment in the Republic of Macedonia", "text": "Capital punishment in the Republic of Macedonia\n\nCapital punishment in the Republic of Macedonia is prohibited by its Constitution.\n\nThe 1991 (amended in 2001) Constitution of the Republic of Macedonia at Art. 10 states:\n\nMacedonia is a member of the Council of Europe. It has also signed and ratified Protocol no.13.\n\nSource: SPSK Database\n"}
{"id": "51623871", "url": "https://en.wikipedia.org/wiki?curid=51623871", "title": "Cora Sherlock", "text": "Cora Sherlock\n\nCora Sherlock is a pro-life campaigner in the Republic of Ireland. She is deputy chairperson of the Pro Life Campaign. In 2014, she was included in BBC's 100 Women series..\n\nShe studied Law at University College Dublin in 1993, and during that period she joined the Pro Life Campaign. Sherlock completed a Masters in Queen's University Belfast and qualified as a solicitor. Sherlock is also a member of Toastmasters.\n\nShe has been an anti-abortion campaigner and activist since the early 1990s. As deputy chairperson of the Pro Life Campaign she has often written articles in national newspapers, or appeared on radio and TV on the abortion debate in Ireland.\n\nCora Sherlock called for a yes vote on the Twenty-fifth Amendment of the Constitution Bill, 2002 (Ireland). The Pro Life Campaign also called for a yes vote.\n\nShe voted against the Treaty of Nice in the 2001 referendum.\n\nCora Sherlock was opposed to the Protection of Life During Pregnancy Act 2013.\n\nCora Sherlock was opposed to the referendum on the Eighth Amendment, which passed with a two-thirds majority. She was opposed to the Citizens Assembly., and has spoken in favour of keeping the Eighth Amendment on newspaper, radio, and TV.\n\n\n"}
{"id": "2409211", "url": "https://en.wikipedia.org/wiki?curid=2409211", "title": "DAZ Studio", "text": "DAZ Studio\n\nDaz Studio is a software application developed and offered for free by Daz 3D. Daz Studio is a 3D scene creation and rendering application used to produce images as well as video. Renders can be done by leveraging either the 3Delight render engine, or the Iray render engine, both of which ship for free along with Daz Studio, or with a variety of purchasable add-on render engine plugins for Daz Studio from various vendors and companies.\n\nDaz Studio also supports the import and export of various file formats for 3D objects and animations to allow for the use of other 3D content within Daz Studio, as well as to get content out of Daz Studio for use in other 3D applications.\n\nDaz Studio is available for free, but registration is required. Version 1.0 was released in Fall 2005. Until version 1.7 it was officially known as DAZ|Studio. On February 1, 2012, DAZ 3D Inc. announced it would be giving away DAZ Studio Pro for free.\n\nIn 2017 Daz 3D also began offering Hexagon and Daz Studio together for free, thus adding 3D modeling capabilities to the Daz Studio offering.\n\nOne of the main differences between Daz Studio and other software applications such as Poser is that Daz 3D has also included support for its various generations of the \"Genesis\" technology which is used as the basis for its human figures.\n\nDaz 3D has had many versions of its human figures and characters, but in 2011 they launched a significant change in the underlying technology. Instead of each figure being designed individually, Daz 3D moved to their Genesis platform, in which figures were derived as morphs from the base mesh. Two of the key differences that this technology created were: The ability for characters to be blended into a huge variety of shapes, and since these shapes were all derived from a common base, add-on content like clothing, hair, and additional morphs would not only work on all characters, but could actually change with the characters.\n\nThe Genesis platform has gone through several versions since the launch in 2011:\n\nGenesis 2:\n\nOne of the shortcomings of the Genesis platform was that although it allowed extremely flexibility in the shape of characters and clothing, it also toned down some of the elements of what made a male or female figure unique. Genesis 2 changed this by splitting the Genesis base figure into two separate base figures: Genesis 2 Male and Genesis 2 Female.\n\nGenesis 3:\n\nUp until Genesis 3 the Genesis figures had been using TriAx Weight Maps, where many other industry platforms were using Dual Quaternion. This changed in Genesis 3 to allow Daz 3D figures to be more compatible with other 3D software platforms as well as Game Development platforms.\n\nGenesis 8:\n\nThe jump in version naming from Genesis 3 to Genesis 8 was in order to address confusion in naming conventions. Although Genesis had reached its fourth version, most of the Daz 3D flagship characters were now on their eight versions. In order to avoid the confusion of Victoria 8 or Michael 8 being Genesis 4 characters, Daz 3D shifted the versioning of Genesis to match with the character versions.\n\nGenesis 8 also includes significant changes in the figure's backward compatibility with previous generation's and their content as well as Joint and muscle bends and flexing and facial expressions.\n\nDAZ Studio is designed to allow users to manipulate \"ready to use\" models and figures as well as other supporting 3D content. It is aimed at users who are interested in posing human and non-human figures for illustrations and animation. It was created as an alternative to Poser, the industry-leading software in use for character manipulation and rendering. Daz 3D began its business model selling 3D models of human beings (and a few non-humans), as well as giving away a few of the more popular base models for free from time to time, and clothing and props for the same, and all of these models were constructed to be used in Poser. Daz eventually created their own character manipulation software, and elected to distribute it for free (originally just the base edition, but eventually even the 'pro' version). Initially Daz Studio handled the same file formats that Poser did, but Daz eventually introduced Daz Studio-specific character and file formats (although they also introduced their DSON file importer to make it possible to import Daz Studio characters into Poser).\n\nDAZ 3D follows the \"Razor and blades business model\" - DAZ Studio is the \"razor\" free-of-charge core program with the required features for the creation of imagery and animations, while relegating other features to the \"blades\" add-on 'plug-ins', usually commercial, which the user may add. Initially it was possible to easily create new content in another DAZ program, Carrara. Beginning in 2017 Daz 3D began offering another of their programs, Hexagon, and distributing that as a package with DAZ Studio.\n\nIn October 2017 Daz Studio added dForce capabilities to the free offering. dForce is a physics engine that Daz Studio uses for simulating the draping of cloth due to gravity, wind, and collision with other objects.\n\n"}
{"id": "1839836", "url": "https://en.wikipedia.org/wiki?curid=1839836", "title": "Defense blood standard system", "text": "Defense blood standard system\n\nThe Defense Blood Standard System (DBSS) is a FDA-regulated, Class II Medical Device designed to handle blood collection, processing and tracking procedures, and automation of standards and safeguards for the Military Health System (MHS) blood supply. DBSS is also identified by the FDA as a Blood Establishment Software item.\n\nThe DBSS supports the Armed Services Blood Program Office, which manages the blood program for the Department of Defense, and services more than 8.7 million MHS beneficiaries.\n"}
{"id": "41863605", "url": "https://en.wikipedia.org/wiki?curid=41863605", "title": "EPODE International Network", "text": "EPODE International Network\n\nEPODE International Network (EIN) is a not for profit, non-governmental organisation that seeks to support childhood obesity-prevention programmes across the world, via best practice sharing and capacity building.\n\nThe name EPODE comes from ‘Ensemble Prévenons l'ObésitéDes Enfants’ Together Let's Prevent Childhood Obesity\n\nThe EPODE International Network (EIN), is a Nonprofit organization, and is a contribution to the response to the need and demand from the global community in the fight against childhood obesity and Non-communicable diseases (NCDs), through sustainable and large-sale Community Based Programmes (CBPs) for childhood obesity prevention.\n\nIn light of the encouraging experiences and results of the EPODE methodology (Towns in Belgium that implemented the program saw a 22 per cent decrease in overweight children ), the EPODE International Network, was created in 2011 as a response to the global demand for action concerning the increasing international prevalence of overweight and obesity and the related non-communicable diseases. The EPODE International Network works to promote and enhance the global movement to prevent childhood obesity by supporting Community Based Programmes (CBPs) for childhood obesity prevention through sustainable and large-sale strategies that mobilise a multi-stakeholder dynamic.\n\nThe EPODE International Network is an NGO, a network of community-based and school-based childhood obesity-prevention programmes as well as healthy active initiatives aimed at preventing childhood adiposity & overweight in children. This NGO facilitates the sharing of experiences, best practices and tools at the global level for continuous improvement and strengthening of its members. EIN also endeavours to ensure the sustainability of CBPs, SBPs & HAIs over time, contributing to the global movement to reduce and prevent childhood overweight and obesity.\n\nThe network is coordinated by a dedicated unit and is supported by 3 platforms gathering a broad diversity of actors:\n\n\nIn addition, the EPODE International Network holds regional and global forums which represent a call for global perspectives, solutions and commitments to solve the obesity and NCDs crisis worldwide.\n\nEPODE International Network’s overall objective is to build international capacity and capability for multi-partner community-based childhood obesity-prevention programmes (CBPs) in countries by:\n\n\nThe EPODE International Network has more than 30 childhood obesity-prevention programme members in over 20 countries. By 2015 EPODE International Network will involve more than 400,000,000 people worldwide.\n\nIn order to support its member childhood obesity-prevention programmes, the EIN organises regional and global meetings in order to facilitate best practice sharing and hold capacity building workshops, specific to the needs of its members. The EIN Scientific Advisory Board is also active in providing key support to members of the network in numerous ways and notably providing valuable evaluation support and assisting programme members with the publication of their results.\n\nSome activities include attempts to curb fast-food outlets near schools.\n\nIn France, Fleurbaix-Laventie Ville Santé (FLVS), a food and nutrition project, were taken up by 10 mid-sized French towns as part of a wider pilot scheme, EPODE, aimed at preventing obesity among five to 12-year-olds.\n\nThe following countries around the world are members of the EPODE International Network:\n\n\nThe EIN Ministers’ Club facilitates personal relationships between elected representatives from EPODE Programmes and existing community-based programmes from international regions or countries interested in developing obesity-prevention strategies. Members of the Ministers’ Club includes elected representatives such as ministers and secretaries (health, sports, urbanism, education, agriculture…), members of parliaments, governors, and mayors of cities involved in community-based childhood obesity-prevention programs.\n\n\n\nThe following global founding partners support the EPODE International Network:\n\n\n\n\n"}
{"id": "31631211", "url": "https://en.wikipedia.org/wiki?curid=31631211", "title": "Elda Emma Anderson", "text": "Elda Emma Anderson\n\nElda Emma Anderson (October 5, 1899 – April 17, 1961) was an American physicist and health researcher. During World War II, she worked on the Manhattan Project at Princeton University and the Los Alamos Laboratory, where she prepared the first sample of pure uranium-235 at the laboratory. A graduate of the University of Wisconsin, she became professor of physics at Milwaukee-Downer College in 1929. After the war, she became interested in health physics. She worked in the Health Physics Division of the Oak Ridge National Laboratory, and established the professional certification agency known as the American Board of Health Physics.\n\nElda Emma Anderson was born in Green Lake, Wisconsin, on October 5, 1899, to Edwin A. Anderson (born in Wisconsin) and his wife, Lena (née Heller) (born in Germany). Anderson was one of three children. Although she was captivated by numbers at an early age, Anderson actually sought to become a kindergarten teacher. This would shift to an interest in science later, partially due to the influence of her older sister, who was an assistant chemistry instructor. As a whole, although her family had certain lofty expectations for their younger daughter, they all supported her in her academic endeavors. Anderson earned a Bachelor of Arts (AB) degree from Ripon College in 1922, then a master of arts (AM) in physics from the University of Wisconsin in 1924. From 1924 to 1927, she taught at Estherville Junior College in Iowa, where she was the dean of physics, chemistry and mathematics. In 1929, she became professor of physics at Milwaukee-Downer College, then head of the physics department in 1934.\n\nIn 1941 Anderson completed her PhD at the University of Wisconsin, writing her thesis on \"Low energy levels in the atomic spectra Co VII and Ni VIII\". Immediately after finishing her PhD, Anderson requested time off from her position at Milwaukee-Downer College, in order to conduct war research related to the Manhattan Project at the Office of Scientific Research and Development at Princeton University. Not long after, Anderson was recruited to continue her work specifically at Los Alamos Laboratory. At her new location, Anderson studied basic fission parameters, including analyzing the time delays associated with the absorption and emission of neutrons. Such work often entailed working upwards of sixteen hours a day. Among other accomplishments at Los Alamos, Anderson prepared the first sample of pure uranium-235 at the laboratory. While there, she lived in a dormitory, and being older than most of the other residents (she was aged fifty), she was put in charge. She often worked at night, wearing jeans and a plaid shirt – not the usual attire for a woman at the time.\n\nFollowing the war, in 1947, Anderson left Los Alamos and returned to teaching at Milwaukee-Downer College, but her involvement in atomic physics led to an interest in the health effects of radiation. In 1949, she left teaching to begin a career in health physics. At the Health Physics Division of the Oak Ridge National Laboratory in Tennessee, which was only five years old when she joined, she became the first chief of education and training. She spent her career helping to establish the new training program in health physics, teaching and advising graduate fellows in health physics from 1949.\n\nIn 1949, Anderson moved to Oak Ridge, Tennessee to become the first chief of education and training in the Health Physics Division of the Oak Ridge National Laboratory. Anderson also worked with faculty members at Vanderbilt University in Nashville, Tennessee, to create a master's degree program in health physics at that institution.\n\nOutside of necessary obligations, Anderson was also known for helping students with problems both academic and personal, lending helpful guidance. In some cases, Anderson was known to have given loans to students, as well share a drink in troubling times.\n\nAnderson organized the first international course in her field in Stockholm in 1955; she organized similar courses in Belgium in 1957 and Mumbai in 1958. She supported the establishment of the Health Physics Society in 1955, serving as secretary pro tem and then charter secretary, and eventually as president of the Society from 1959 to 1960. In 1960, she established the professional certification agency known as the American Board of Health Physics. Despite contracting leukemia in 1956, Anderson remained undeterred in her career and maintained her position for several years until her eventual death in 1961.\n\nIn 1956, Anderson, who never married and had no children, developed leukemia. She died nearly five years later in Oak Ridge, Tennessee, of breast cancer and leukemia, possibly as the result of her work with radioactive materials, on 17 April 1961. Anderson was buried at Green Lake Cemetery in Green Lake, Wisconsin. She was survived by her sister, Lucille McConnell and niece, Natalie Tarr Millemann. Dr. Anderson's obituary was well covered in the press and scientific journals. Tributes were written by colleagues and former students. \n\nAnderson is honored each year at the annual meeting of the Health Physics Society when the Elda E. Anderson Award is presented to a young member of the Society.\n\n"}
{"id": "11334051", "url": "https://en.wikipedia.org/wiki?curid=11334051", "title": "Eusebio Oehl", "text": "Eusebio Oehl\n\nEusebio Oehl (December 5, 1827 – April 10, 1903) was an Italian histologist and physiologist who was a native of Lodi. \n\nHe studied medicine at the University of Pavia, and following graduation (1850), he continued his education in Vienna under Joseph Hyrtl (1810-1894) and Ernst Wilhelm von Brücke (1819-1892). Afterwards, he returned to Pavia, where he taught classes in histology at the Collegio Ghislieri and at the university. In 1864 he attained the chair of physiology at the institute of physiology in Pavia.\n\nAt Pavia, he introduced microscopic studies in the fields of anatomy and histology, being credited with developing systematic studies of cell structure via the microscope. He conducted pioneer physiological studies on salivation, and described \"Oehl's muscles\", defined as strands of muscle fibers in the \"chordae tendineae\" of the left atrioventricular valve. Among his better known students were Camillo Golgi (1843-1926), Camillo Bozzolo (1845-1920), Giulio Bizzozero (1846-1901) and Enrico Sertoli (1842-1910).\n\n\n"}
{"id": "35999447", "url": "https://en.wikipedia.org/wiki?curid=35999447", "title": "Federal Service for Alcohol Market Regulation", "text": "Federal Service for Alcohol Market Regulation\n\nThe Federal Service for Alcohol Market Regulation or Rosalkogolregulirovanie (in Russian: Федеральная служба по регулированию алкогольного рынка, Росалкогольрегулирование) is a federal law enforcement agency of executive authority responsible for drafting and implementing state policy and legal regulation in the production and circulation of ethyl alcohol and alcohol products, as well as functions to control the production and trafficking ethyl alcohol and alcohol-containing products, to oversee and provide services in this area\n\nThe Service is under the jurisdiction of the Federal Government of Russia.\n\nThe Federal Service for Alcohol Market Regulation was established by Presidential Decree from 31 December 2008 No. 1883 \"On the formation of the Federal Service for Alcohol Market Regulation\".\n\nIn Section 2 of the Government direction from 24 February 2009 No. 154 \"On the Federal Service for Alcohol Market Regulation,\" found that the Federal Service for Alcohol Market Regulation is the unification of various functions from the Ministry of Agriculture, Ministry of Finance, the Federal Tax Service and the Federal Service for Tariff in respect of all obligations in the sphere of production and turnover of ethyl alcohol and alcohol-containing products, including obligations arising from the execution of court decisions.\n\nOn November 30, 2009 the Federal Service for Alcohol Market Regulation issued an order No. 17 \"On the establishment and administration of the minimum price of vodka for retail sale until January 1, 2010\" according to which from 1 January 2010, the minimum price of vodka for retail sale was set at a rate of 89 rubles per 0.5 liter of the finished product (€2.52 per liter circa).\n\n\n\n"}
{"id": "1037159", "url": "https://en.wikipedia.org/wiki?curid=1037159", "title": "Fort Bovisand", "text": "Fort Bovisand\n\nFort Bovisand is a fort in Devon, England near the beach of Bovisand. It was built on the mainland to defend the entrance of Plymouth Sound, at the narrows opposite the east end of Plymouth Breakwater. The fort is beside Bovisand harbour.\n\n\n\"Fort Bovisand\", Kendal McDonald, \n\n\nImages:-\n"}
{"id": "54097060", "url": "https://en.wikipedia.org/wiki?curid=54097060", "title": "Gomul", "text": "Gomul\n\nGomul () refers to a number of powdered coatings, toppings, fillings, or dips in Korean cuisine.\n\n\"Gomul\" is used to improve the appearance and taste of \"tteok\" (rice cake), including \"injeolmi\", \"danja\", and \"gyeongdan\", as well as between-layer fillings for \"siru-tteok\" (steamed rice cake). It helps with even cooking of steamed rice cakes, being the less dense layer (compared to the rice flour layer, which tend to turn stickier as it steams) through which steam passes more easily.\n\n\"Gomul\" is also used for topping \"bingsu\" (shaved ice). Sometimes, soybean \"gomul\" is served with grilled \"samgyeopsal\" (pork belly), with meat dipped in the soybean powder when eaten.\n\nRed bean or mung bean \"gomul\" is used in winter, while soybean or sesame \"gomul,\" which don't spoil as fast, are preferred in summer.\n\nCommon varieties and their preparation are:\n"}
{"id": "10309703", "url": "https://en.wikipedia.org/wiki?curid=10309703", "title": "Gråsjøen", "text": "Gråsjøen\n\nGråsjøen is a lake/reservoir in the municipality of Surnadal (and a very small part in the northeastern corner of the lake is in Rindal) in Møre og Romsdal county, Norway. The lake is located in the northern part of the Trollheimen mountain range. The lake is dammed and the water is used in the Gråsjø power station. The water flows out of the lake and into the lake Foldsjøen. Mount Snota lies just south of the lake.\n"}
{"id": "1770360", "url": "https://en.wikipedia.org/wiki?curid=1770360", "title": "Guillermo Rawson", "text": "Guillermo Rawson\n\nDr. Guillermo Rawson (24 June 1821 - 20 January 1890) was a medical doctor and politician in nineteenth-century Argentina. As Interior Minister in 1862 he met Captain Love Jones-Parry and Lewis Jones who were on their way to Patagonia to investigate whether it was suitable for the creation of a Welsh settlement there. Rawson came to an agreement with them, and this resulted in the creation of a colony in the Chubut Valley in the following years. The city of Rawson, the capital of the province of Chubut was named after him.\n\nGuillermo Rawson's parents were Dr. Aman Rawson, a doctor who had emigrated from the United States to Argentina, and Justina Rojo, a daughter of a wealthy family in San Juan, where Guillermo was born. His elder brother was the artist Franklin Rawson.\nAfter a Jesuit education in San Juan, Rawson graduated from the Medical Faculty of University of Buenos Aires in 1844. Rawson became interested in politics and democracy. In 1853 he was jailed for opposing Nazario Benavidez, the \"caudillo\" or \"de facto\" governor of San Juan. The following year he was a member of the Paraná Congress, and from 1862 he was Interior Minister in the government of Bartolomé Mitre.\n\nApart from politics, Rawson was interested in medicine and hygiene. In 1876 he attended the Centennial Exposition in Philadelphia to present his work on public health in Buenos Aires, the most developed body of work on the subject at the time. In 1879, he was elected a member of the American Antiquarian Society.\n\nRawson spent a year in Paris in 1881 for medical treatment, before returning to Argentina. He returned to France for further treatment in 1885 and died in Paris in 1890.\n\nThe building of the first Medical School in Buenos Aires is named after him (Escuela Dr Guillermo Rawson).\n\n\n"}
{"id": "46353964", "url": "https://en.wikipedia.org/wiki?curid=46353964", "title": "Hole in the Horn Buck", "text": "Hole in the Horn Buck\n\nThe Hole in the Horn Buck is officially listed as the second largest non-typical white-tailed deer of all time by the Boone and Crockett Club. The buck’s antlers score 328 2/8 non-typical points. The name of the buck derives from the mysterious hole in the buck’s right antler. It was later claimed by eyewitness, George Winters, to be caused from a piece of chain-link fence that pierced the antler shortly before it died.\n\nThe Hole in the Horn buck was found dead along a railroad in Kent, Ohio in 1940. The buck was discovered by a group of railroad workers who had noticed the dead animal stuck under a nearby chain-link fence of the Ravenna Arsenal. The group of men freed the massive set of antlers. A shoulder mount of the buck was made by a local taxidermist and hung in the nearby Kent Canadian Club. It hung on the wall of the private hunting club for the next 40 years.\n\nThe world-record class mount was virtually anonymous to the public and had never been officially scored until 1983. The antlers were scored for the first time on August 27, 1983 by Phil Wright, chairman of the Boone & Crockett Scoring Committee. The initial score came out to be 342 3/8 non-typical points. Based upon the initial score, North American Whitetail Magazine declared the buck as the new world-record in the December 1983 issue of their magazine.\n\nIn 1986, the Hole in the Horn buck was re-measured by a judges’ panel of official Boone & Crockett scorers. The panel submitted a final score of 328 2/8, which placed it as the number two overall non-typical white-tailed deer, falling just short of the 333 7/8 measurement of the Missouri Monarch buck which was found in 1981 in St. Louis County, Missouri.\n\nThe Hole in the Horn buck is one of the most famous bucks in the world due to its enormous size, mysterious hole in the right antler, and controversial score. The Hole in the Horn buck was part of the original Legendary Whitetails collection owned by Larry Huffman. Replica mounts of the Hole in the Horn buck exist in many outdoor retail stores, including Cabela’s and Bass Pro Shops and also one hangs in the front office at Legendary Whitetails corporate headquarters. The original set of antlers was purchased with Larry’s entire collection of Legendary Whitetails by Bass Pro Shops in 2002. The mount now hangs in the King of Bucks collection in the American National Fish and Wildlife Museum in Springfield, Missouri.\n\n\n"}
{"id": "31202512", "url": "https://en.wikipedia.org/wiki?curid=31202512", "title": "Human Resources for Health", "text": "Human Resources for Health\n\nHuman Resources for Health is a peer-reviewed open-access public health journal publishing original research and case studies on issues of information, planning, production, management, and governance of the health workforce, and their links with health care delivery and health outcomes, particularly as related to global health. It was established in 1997 as the \"Human Resources Development Journal\" published by the Health Manpower Development Institute of the Ministry of Public Health of Thailand. Since 2003, it is published by BioMed Central in collaboration with the World Health Organization (WHO).\n\nThe journal is abstracted and indexed in PubMed, Social Sciences Citation Index, Current contents, Scopus, CINAHL and 10 other indexing services. The journal's impact factor as of 2016 is 2.416.\n\nThe journal occasionally publishes themed collections. In 2007, the journal issued a call for papers jointly with 17 other public health journals under the theme \"Towards a scaling-up of training and education for health workers\". Twenty-two articles were published in \"Human Resources for Health\" on this special theme between July 2008 and November 2009. In 2013, the journal issued a call for papers on the theme \"Right Time, Right Place: Improving access to health service through effective retention and distribution of health workers.\"\n\nIn 2016, the journal published a supplementary collection of research evidence of the relevance and effectiveness of the WHO's Global Code of Practice on the International Recruitment of Health Personnel.\n"}
{"id": "1364854", "url": "https://en.wikipedia.org/wiki?curid=1364854", "title": "Index of HIV/AIDS-related articles", "text": "Index of HIV/AIDS-related articles\n\nThis is a list of AIDS-related topics, many of which were originally taken from the public domain U.S. Department of Health Glossary of HIV/AIDS-Related Terms, 4th Edition. \n\nAACTG –\nacquired immunity –\nacquired immunodeficiency syndrome (AIDS) –\nACT UP/Golden Gate –\nactive immunity –\nacupuncture –\nacute HIV infection –\nAcute HIV Infection and Early Diseases Research Program (AIEDRP) –\nADAP –\nADC –\nadenopathy –\nadherence –\nadjuvant –\nadministration –\nAdult AIDS Clinical Trials Group (AACTG) –\nadverse drug reaction –\naerosolized –\nAETC –\nagammaglobulinemia –\nAgency for Healthcare Research and Quality (AHRQ) –\nAHRQ –\nAIDS –\nAIDS Arms –\nAIDS dementia complex (ADC) –\nAIDS Drug Assistance Programs (ADAP) –\nAIDS education and training centers (AETC) –\nAIDS orphan –\nAIDS research advisory committee (ARAC) –\nAIDS service organization (ASO) –\nThe AIDS Show –\nAIDS Vaccine 200 –\nAIDS Vaccine Advocacy Coalition –\nAIDS wasting syndrome –\nAIDS-related cancer –\nAIDS-related complex (ARC) –\nalkaline phosphatase –\nalopecia –\nalpha interferon (INFa) –\nalternative medicine –\nalveolar –\namebiasis –\namino acids –\nanaphylactic shock –\nanemia –\nanergy –\nangiogenesis –\nangiomatosis –\nanorexia –\nantenatal –\nantibiotic –\nantibodies –\nantibody-dependent cell-mediated cytotoxicity (ADCC) –\nantibody-mediated immunity –\nantifungal medication –\nantigen –\nantigen presentation –\nantigen-presenting cell (APC) –\nantineoplastic –\nantiprotozoal –\nantiretroviral drugs –\nantisense drugs –\nantitoxins –\nAntiviral drug –\naphasia –\naphthous ulcer –\napoptosis –\napproved drugs –\nARC –\nArmenicum –\nART –\narthralgia –\nASO –\naspergillosis –\nassembly and budding –\nasymptomatic –\nataxia –\nattenuated –\nautoantibody –\nautoimmunization –\nautoinoculation –\nautologous –\navascular necrosis (AVN) –\nAVN\n\nB-cell lymphoma –\nB cells –\nB lymphocytes (B cells) –\nbactericidal –\nbacteriostatic –\nbacterium –\nbaculovirus –\nbaseline –\nbasophil –\nbDNA test –\nbeta-2 microglobulin (β2M) –\nbilirubin –\nbioavailability –\nbiological response modifiers (BRMs) –\nbiopsy –\nbiotechnology –\nblinded study –\nblips –\nblood–brain barrier –\nbody fat redistribution (BFR) syndrome –\nbody fluids – \nbone marrow –\nbone marrow suppression –\nbooster –\nbranched DNA assay –\nbreakthrough infection –\nBroadway Cares/Equity Fights AIDS –\nbronchoscopy –\nbudding –\nbuffalo hump –\nbugchasing and giftgiving – \nBurkitt's lymphoma\n\nC-T scan (computed tomography scan) –\ncachexia –\nCanadian Foundation for AIDS Research –\ncandida –\ncandidiasis –\ncarcinogen –\ncat scan –\nCCR5 –\nCD4 (T4) or CD4 + cells –\nCDC National Prevention Information Network (CDC-NPIN) –\ncell lines –\ncell-mediated immunity (CMI) –\ncellular immunity –\nCenters for Disease Control and Prevention (CDC) –\nCenters for Medicare and Medicaid Services (CMS) – \ncentral nervous system –\ncerebrum –\ncerebrospinal fluid (CSF) –\ncervical cancer –\ncervical dysplasia –\ncervical intraepithelial neoplasia (CIN1, CIN2, CIN3) –\ncervix –\nchancroid –\nchemokines –\nchemoprophylaxis –\nchemotherapy –\nChlamydia –\nchronic idiopathic demyelinating polyneuropathy (CIPD) –\nCircumoral paresthesia –\nclade –\nclinical endpoint –\nclinical latency –\nclinical practice guidelines –\nclinical trial –\nclinicaltrials.gov –\ncloning –\nCMS –\nCMV –\nCNS –\nco-receptors –\ncoccidioidomycosis –\ncodon –\ncofactors –\ncognitive impairment –\ncohort –\ncolitis –\ncombination therapy –\ncommunity planning –\nCommunity Programs for Clinical Research on AIDS (CPCRA) –\ncommunity-based clinical trial (CBCT) –\ncommunity-based organization (CBO) –\ncompassionate use –\ncomplement –\ncomplement cascade –\ncomplementary and alternative therapy –\ncomplete blood count (CBC) –\ncomputed tomography scan (C-T scan) –\nconcomitant drugs –\ncondyloma –\ncondyloma acuminatum –\ncontagious –\ncontraindication –\ncontrolled trials –\ncore –\ncore protein –\ncorrelates of immunity/correlates of protection –\ncreatinine –\ncross-resistance –\ncryotherapy –\ncryptococcal meningitis –\ncryptococcosis –\nCryptococcus neoformans –\ncryptosporidiosis –\nCryptosporidium –\nCSF –\nCTL –\ncutaneous –\nCXCR4 –\ncytokines –\ncytomegalovirus (CMV) –\nCytomegalovirus retinitis –\ncytopenia –\ncytotoxic –\ncytotoxic T lymphocyte (CTL)\n\nDAIDS –\ndata safety and monitoring board (DSMB) –\ndeletion –\ndementia –\ndemyelination –\ndendrite –\ndendritic cells –\ndeoxyribonucleic acid (DNA) –\nDepartment of Health and Human Services (DHHS/HHS or DHHS) –\ndesensitization –\ndiabetes mellitus (DM) –\ndiagnosis –\ndiarrhea –\ndiplopia –\ndissemination –\ndivision of acquired immunodeficiency syndrome (DAIDS) –\nDNA –\nDomain (biology) –\ndose-ranging study –\ndose-response relationship –\ndouble-blind study –\ndrug resistance –\ndrug-drug interaction –\nDSMB –\nDuffy antigen system –\ndysplasia –\ndyspnea\n\nefficacy –\nempirical –\nencephalitis –\nend-stage disease –\nendemic –\nendogenous –\nendoscopy –\nendotoxin –\nendpoint –\nenteric –\nenteritis –\nentry inhibitors –\nEnv –\nenvelope –\nenzyme –\nenzyme-linked immunosorbent assay (ELISA) –\neosinophil –\neosinophilic folliculitis –\nepidemic –\nepidemiological surveillance –\nepidemiology –\nepithelium –\nepitope –\nEpstein-Barr virus (EBV) –\nerythema –\nerythema multiforme –\nerythrocytes –\netiology –\nexogenous –\nexotoxin –\nexpanded access –\nexperimental drug –\nexpression system\n\nfat redistribution –\nFDA\nFDC –\nfloaters –\nfollicle –\nfollicular dendritic cells (FDCs) –\nFood and Drug Administration (United States)\nfunctional antibody –\nfungus –\nfusin –\nfusion inhibitor –\nfusion mechanism –\nfusion peptide\n\nGAG –\ngamma globulin –\ngamma interferon –\nganglion –\nGART –\ngastrointestinal (GI) –\ngene –\ngene therapy –\ngenetic engineering –\ngenital ulcer disease –\ngenital warts –\ngenitourinary tract –\ngenome –\ngenotypic assay –\ngerminal centers –\ngiardiasis –\nglobulins –\nglycoprotein –\ngonorrhea –\ngp120 (gp120) –\ngp160 (gp160) –\ngp41 (gp41) –\ngranulocyte –\ngranulocyte macrophage-colony stimulating factor (GM-CSF) –\ngranulocyte-colony stimulating factor (G-CSF) –\ngranulocytopenia\n\nHAART –\nhairy leukoplakia –\nhalf-life –\nHAM/TSP –\nHealth Care Financing Administration (HCFA) –\nHealth Resources and Services Administration (HRSA) –\nHELLP syndrome –\nhelper T cells –\nhelper/suppressor ratio (of T cells) –\nhematocrit –\nhematotoxic –\nhemoglobin –\nhemolysis –\nhemophilia –\nhepatic –\nhepatic steatosis –\nhepatitis –\nhepatitis C and HIV coinfection –\nhepatomegaly –\nherpes simplex virus 1 (HSV-1) –\nherpes simplex virus 2 (HSV-2) –\nherpes varicella zoster virus (VZV) –\nherpes viruses –\nhighly active antiretroviral therapy (HAART) –\nhistocompatibility testing –\nhistoplasmosis –\nHIV disease –\nHIV prevention trials network (HPTN) –\nHIV set point –\nHIV vaccine trials network (HVTN) –\nHIV-1 –\nHIV-2 –\nHIV-associated dementia –\nHIV-related tuberculosis –\nHLA –\nHodgkin's disease –\nholistic medicine –\nhomology (biology) –\nhormone –\nhost –\nhost factors –\nHPTN –\nHPV –\nHRSA –\nHTLV-I –\nHTLV-I-associated myelopathy/tropical spastic paraparesis (HAM/TSP) –\nHTLV-II –\nhuman growth hormone (HGH) –\nhuman immunodeficiency virus type 1 (HIV-1) –\nhuman immunodeficiency virus type 2 (HIV-2) –\nhuman leukocyte antigens (HLA) –\nhuman papilloma virus (HPV) –\nhuman T cell lymphotropic virus type I (HTLV-I) –\nhuman T cell lymphotropic virus type II (HTLV-II) –\nhumoral immunity –\nHVTN –\nhydroxyurea –\nhypergammaglobulinemia –\nhyperglycemia –\nhyperlipidemia –\nhyperplasia –\nhyperthermia –\nhypogonadism –\nhypothesis –\nhypoxia\n\nidiopathic –\nidiopathic thrombocytopenia purpura –\nIHS –\nimmune complex –\nimmune deficiency/immunodeficiency –\nimmune response –\nimmune system –\nimmune thrombocytopenic purpura –\nimmunity –\nimmunization –\nimmunocompetent –\nimmunocompromised –\nimmunodeficiency –\nimmunogen –\nimmunogenicity –\nimmunoglobulin (Ig) –\nimmunoglobulin A (IgA) –\nimmunoglobulin D (IGD) –\nimmunoglobulin E (IGE) –\nimmunoglobulin G (IGG) –\nimmunoglobulin M (IGM) –\nimmunomodulator –\nimmunostimulant –\nimmunosuppression –\nimmunotherapy –\nimmunotoxin –\nin vitro –\nin vivo –\nincidence –\nIncubation period –\nIND –\nIndian Health Service (IHS) –\ninfection –\ninfectious –\ninformed consent –\ninfusion –\ninoculation –\ninstitutional review board (IRB) –\nintegrase –\nintegrase inhibitors –\ninteraction –\ninterferon –\ninterleukin-1 (IL-1) –\ninterleukin-2 (IL-2) –\ninterleukin-4 (IL-4) –\ninterleukin-12 (IL-12) –\ninterleukins –\nInternational Center for Research on Women – \nintramuscular (IM) –\nintravenous –\nintravenous immunoglobulin (IVIG) –\nintravitreal –\nInvestigational New Drug (IND) –\nIRB –\nITP –\nIVIG\n\njaundice –\nJC virus\n\nKaposi's sarcoma (KS) –\nKarnofsky score –\nkiller T cells –\nKSHV –\nKupffer cells\n\nLangerhans cells –\nLAS –\nlentivirus –\nlesion –\nleukocytes –\nleukocytosis –\nleukopenia –\nleukoplakia –\nLFT –\nLIP –\nlipid –\nlipodystrophy –\nliposomes –\nlive vector vaccine –\nliver function test (LFT) –\nlong terminal repeat sequence (LTR) –\nlong-term nonprogressors –\nLTR –\nlumbar –\nlumbar puncture –\nlymph –\nlymph nodes –\nlymphadenopathy syndrome (LAS) –\nlymphatic vessels –\nlymphocyte –\nlymphoid interstitial pneumonitis (LIP) –\nlymphoid organs –\nlymphoid tissue –\nlymphokine-activated killer cells (LAK) –\nlymphokines –\nlymphoma –\nlymphopenia –\nlymphoproliferative response –\nlysis\n\nMAC –\nmacrophage –\nmacrophage-tropic virus –\nmagnetic resonance imaging (MRI) –\nMAI –\nmaintenance therapy –\nmajor histocompatibility complex (MHC) –\nmalabsorption syndrome –\nmalaise –\nmalignant –\nmast cell –\nMedlinePlus –\nmega-HAART –\nmemory T cells –\nmeninges –\nmeningitis –\nmessenger RNA –\nmetabolism –\nmetastasis –\nMHC –\nmicrobes –\nmicrobicide –\nMicrosporidiosis –\nmitochondria –\nmitochondrial toxicity –\nmolecule –\nmolluscum contagiosum –\nmonocyte –\nmononeuritis multiplex (MM) –\nmonovalent vaccine –\nmorbidity –\nMRI –\nmucocutaneous –\nmucosa –\nmucosal immunity –\nmucous membrane –\nMulticenter AIDS Cohort Study –\nmulti-drug rescue therapy –\nmultiple drug-resistant tuberculosis (MDR-TB) –\nmutation –\nmyalgia –\nmycobacterium –\nmycobacterium avium complex (MAC) –\nmycosis –\nmyelin –\nmyelopathy –\nmyelosuppression –\nmyelotoxic –\nmyocardial –\nmyopathy\n\nNAT –\nNational Cancer Institute (NCI) –\nNational Institute of Allergy and Infectious Diseases (NIAID) –\nNational Institute of Child Health and Human Development (NICHD) –\nNational Institutes of Health (NIH) –\nNational Library of Medicine (NLM) –\nNational Prevention Information Network (NPIN) –\nnatural history study –\nnatural killer cells (NK cells) –\nNCI –\nNew Drug Application –\nnebulized –\nNef –\nneoplasm –\nnephrotoxic –\nneuralgia –\nneurological complications of AIDS –\nneuropathy –\nneutralization –\nneutralizing antibody –\nneutralizing domain –\nneutropenia –\nneutrophil –\nNew Drug Application (NDA) –\nNew York Cares –\nNIAID –\nNICHD –\nnight sweat –\nNIH –\nNK cell –\nNLM –\nNNRTI –\nnon-Hodgkin's lymphoma (NHL) –\nnon-nucleoside reverse transcriptase inhibitors (NNRTI) –\nnon-steroidal anti-inflammatory drugs (NSAID) –\nNRTI –\nnucleic acid –\nnucleic acid test –\nnucleocapsid –\nnucleoli –\nnucleoside –\nnucleoside analog –\nnucleoside reverse transcriptase inhibitors (NRTI) –\nnucleotide –\nnucleotide analogs –\nnucleus –\nnull cell\n\nocular –\noff-label use –\noncology –\nopen-label trial –\nopportunistic infections –\noral hairy leukoplakia (OHL) –\norganelle –\noropharyngeal –\norphan drugs –\nosteonecrosis –\nosteopenia\n\nP24 –\npackage insert –\npalliative –\npalliative care –\npancreas –\npancreatitis –\npancytopenia –\npandemic –\npap smear –\npapilloma –\nparallel track –\nparasite –\nparenteral –\nparesthesia –\npassive immunity –\npassive immunotherapy –\npathogen –\npathogenesis –\nPBMC –\nPCP –\nPCR –\nPediatric AIDS Clinical Trial Group (PACTG) –\npelvic inflammatory disease –\npeptide –\nperianal –\nperinatal –\nperinatal transmission –\nperipheral neuritis –\nperipheral neuropathy –\npersistent generalized lymphadenopathy –\nPGL –\nphagocyte –\nphagocytosis –\npharmacokinetics –\nphase I trials –\nphase II trials –\nphase III trials –\nphase IV trials –\nphotosensitivity –\nPHS –\npituitary gland –\nplacebo –\nplacebo controlled study –\nplacebo effect –\nplasma –\nplasma cells –\nplatelets –\nPML –\nPneumocystis jiroveci pneumonia (formerly Pneumocystis carinii or PCP) –\nPOL –\npolymerase –\nPolymerase chain reaction (PCR) –\npolyneuritis –\npolypeptide –\npolyvalent vaccine –\npost-exposure prophylaxis (PEP) –\nPPD test –\npre-conception counseling –\npreclinical –\nprecursor cells –\nprevalence –\nprimary HIV infection –\nprimary isolate –\nprimaquine –\nproctitis –\nprodrome –\nprodrug –\nprogressive multifocal leukoencephalopathy (PML) –\nprophylactic drug –\nprophylaxis –\nprotease –\nprotease inhibitors –\nprotease-sparing regimen –\nproteins –\nprotocol –\nprotozoa –\nprovirus –\npruritus –\npseudo-Cushing's syndrome –\npseudovirion –\nPUBMED –\npulmonary –\npurified protein derivative (PPD)\n\nradiology –\nrandomized trial –\nrebound –\nreceptor (immunology) –\nrecombinant –\nrecombinant DNA –\nrecombinant DNA technology –\nregulatory genes –\nregulatory T cells –\nremission –\nrenal –\nrescue therapy –\nresistance –\nretina –\nretinal detachment –\nretinitis –\nretrovirus –\nREV –\nreverse transcriptase –\nribonucleic acid (RNA) –\nribosome –\nRNA –\nroute of administration –\nRT-PCR –\nRTI –\nRyan White C.A.R.E. act\n\nsafe sex –\nsafer sex –\nsalmonella –\nsalvage therapy –\nSAMHSA –\nsarcoma –\nseborrheic dermatitis –\nsecondary prophylaxis –\nsepsis –\nseroconversion –\nserologic test –\nseroprevalence –\nserosorting –\nserostatus –\nserum –\nserum glutamic oxaloacetic transaminase (SGOT) –\nserum glutamic pyruvate transaminase (SGPT) –\nsexually transmitted disease (STD) –\nshingles –\nSHIV –\nside effects –\nsimian immunodeficiency virus (SIV) –\nsinusitis –\nsocial integration\nSIT –\nSIV –\nSpecial Projects of National Significance (SPNS) –\nspinal tap –\nspleen –\nsplenomegaly –\nsputum analysis –\nstandard of care –\nstaphylococcus –\nSTD –\nstem cells (FDCs) –\nsteroid –\nStevens–Johnson syndrome –\nSTI –\nstomatitis –\nstrain –\nstratification –\nstructured intermittent therapy (SIT) –\nstructured treatment interruption (STI) –\nstudy endpoint –\nsubarachnoid space –\nsubclinical infection –\nsubcutaneous (SQ) –\nSubstance Abuse and Mental Health Services Administration (SAMHSA) –\nsubunit HIV vaccine –\nsulfa drug –\nsulfonamides –\nsuperantigen –\nsuppressor T cell –\nsurrogate marker –\nsurveillance –\nsusceptible –\nsymptoms –\nsyncytium –\nsyndrome –\nsynergy –\nsynergistic –\nsynthesis –\nsyphilis –\nsystemic\n\nT cells (T lymphocytes) –\nT lymphocyte proliferation assay –\nT lymphocytes –\nT suppressor cells –\nT4 cell –\nT4 cells (T-helper cells) –\nT8 cells –\nTanner staging –\nTAT –\nTB –\ntemplate –\nTeachAIDS –\nteratogenicity –\ntestosterone –\ntherapeutic HIV vaccine –\nthrombocytopenia –\nthrush –\nthymosin –\nthymus –\ntissue –\ntiter –\ntoxicity –\ntoxoplasmic encephalitis –\ntoxoplasmosis –\ntransaminase –\ntranscription –\ntransfusion –\ntranslation –\ntransmission –\ntransplacental –\ntreatment IND –\ntriglycerides –\ntuberculin skin test (TST) –\ntuberculosis (TB) –\ntumor necrosis factor (TNF)\n\nV3 loop –\nvaccination –\nvaccine –\nvaccinia –\nvaginal candidiasis –\nvalley fever –\nvariable region –\nvaricella zoster virus (VZV) –\nvector –\nvertical transmission –\nviral burden –\nviral core –\nviral culture –\nviral envelope –\nviral load –\nviremia –\nviricide –\nvirion –\nvirology –\nvirus –\nvisceral\n\nwasting syndrome –\nWestern blot –\nwhite blood cells –\nwild-type virus –\nwindow period –\nWomen's Interagency HIV Study (WIHS) –\nWorld AIDS Day –\nWorld AIDS Vaccine Day\n\nyeast infection – Youth Against AIDS\n\nzinc finger inhibitor –\nzinc fingers\n"}
{"id": "219736", "url": "https://en.wikipedia.org/wiki?curid=219736", "title": "Indoor air quality", "text": "Indoor air quality\n\nIndoor air quality (IAQ) is the air quality within and around buildings and structures. IAQ is known to affect the health, comfort and well-being of building occupants. Poor indoor air quality has been linked to Sick Building Syndrome, reduced productivity and impaired learning in schools.\n\nIAQ can be affected by gases (including carbon monoxide, radon, volatile organic compounds), particulates, microbial contaminants (mold, bacteria), or any mass or energy stressor that can induce adverse health conditions. Source control, filtration and the use of ventilation to dilute contaminants are the primary methods for improving indoor air quality in most buildings. Residential units can further improve indoor air quality by routine cleaning of carpets and area rugs.\n\nDetermination of IAQ involves the collection of air samples, monitoring human exposure to pollutants, collection of samples on building surfaces, and computer modelling of air flow inside buildings.\n\nIAQ is part of indoor environmental quality (IEQ), which includes IAQ as well as other physical and psychological aspects of life indoors (e.g., lighting, visual quality, acoustics, and thermal comfort).\n\nIndoor air pollution in developing nations is a major health hazard. A major source of indoor air pollution in developing countries is the burning of biomass (e.g. wood, charcoal, dung, or crop residue) for heating and cooking. The resulting exposure to high levels of particulate matter resulted in between 1.5 million and 2 million deaths in 2000.\n\nSecond-hand smoke is tobacco smoke which affects people other than the 'active' smoker. Second-hand tobacco smoke includes both a gaseous and a particulate phase, with particular hazards arising from levels of carbon monoxide (as indicated below) and very small particulates (fine particular matter at especially PM2.5 size, and PM10) which get into the bronchioles and alveoles in the lung. The only certain method to improve indoor air quality as regards second-hand smoke is the implementation of comprehensive smoke-free laws.\n\nRadon is an invisible, radioactive atomic gas that results from the radioactive decay of radium, which may be found in rock formations beneath buildings or in certain building materials themselves. Radon is probably the most pervasive serious hazard for indoor air in the United States and Europe, probably responsible for tens of thousands of deaths from lung cancer each year. There are relatively simple test kits for do-it-yourself radon gas testing, but if a home is for sale the testing must be done by a licensed person in some U.S. states. Radon gas enters buildings as a soil gas and is a heavy gas and thus will tend to accumulate at the lowest level. Radon may also be introduced into a building through drinking water particularly from bathroom showers. Building materials can be a rare source of radon, but little testing is carried out for stone, rock or tile products brought into building sites; radon accumulation is greatest for well insulated homes. The half life for radon is 3.8 days, indicating that once the source is removed, the hazard will be greatly reduced within a few weeks. Radon mitigation methods include sealing concrete slab floors, basement foundations, water drainage systems, or by increasing ventilation. They are usually cost effective and can greatly reduce or even eliminate the contamination and the associated health risks.\n\nRadon is measured in picocuries per liter of air (pCi/L), a measurement of radioactivity. In the United States, the average indoor radon level is about 1.3 pCi/L. The average outdoor level is about 0.4 pCi/L. The U.S. Surgeon General and EPA recommend fixing homes with radon levels at or above 4 pCi/L. EPA also recommends that people think about fixing their homes for radon levels between 2 pCi/L and 4 pCi/L.\n\nThese biological chemicals can arise from a host of means, but there are two common classes: (a) moisture induced growth of mold colonies and (b) natural substances released into the air such as animal dander and plant pollen. Mold is always associated with moisture, and its growth can be inhibited by keeping humidity levels below 50%. Moisture buildup inside buildings may arise from water penetrating compromised areas of the building envelope or skin, from plumbing leaks, from condensation due to improper ventilation, or from ground moisture penetrating a building part. Even something as simple as drying clothes indoors on radiators can increase the risk of exposure to (amongst other things) Aspergillus - a highly dangerous mould that can be fatal for asthma sufferers and the elderly. In areas where cellulosic materials (paper and wood, including drywall) become moist and fail to dry within 48 hours, mold mildew can propagate and release allergenic spores into the air.\n\nIn many cases, if materials have failed to dry out several days after the suspected water event, mold growth is suspected within wall cavities even if it is not immediately visible. Through a mold investigation, which may include destructive inspection, one should be able to determine the presence or absence of mold. In a situation where there is visible mold and the indoor air quality may have been compromised, mold remediation may be needed. Mold testing and inspections should be carried out by an independent investigator to avoid any conflict of interest and to insure accurate results; free mold testing offered by remediation companies is not recommended.\n\nThere are some varieties of mold that contain toxic compounds (mycotoxins). However, exposure to hazardous levels of mycotoxin via inhalation is not possible in most cases, as toxins are produced by the fungal body and are not at significant levels in the released spores. The primary hazard of mold growth, as it relates to indoor air quality, comes from the allergenic properties of the spore cell wall. More serious than most allergenic properties is the ability of mold to trigger episodes in persons that already have asthma, a serious respiratory disease.\n\nOne of the most acutely toxic indoor air contaminants is carbon monoxide (CO), a colourless, odourless gas that is a byproduct of incomplete combustion of fossil fuels. Common sources of carbon monoxide are tobacco smoke, space heaters using fossil fuels, defective central heating furnaces and automobile exhaust. By depriving the brain of oxygen, high levels of carbon monoxide can lead to nausea, unconsciousness and death. According to the American Conference of Governmental Industrial Hygienists (ACGIH), the time-weighted average (TWA) limit for carbon monoxide (630-08-0) is 25 ppm.\n\nIndoor levels of CO are systematically improving due to increasing implementation of smoke-free laws.\n\nVolatile organic compounds (VOCs) are emitted as gases from certain solids or liquids. VOCs include a variety of chemicals, some of which may have short- and long-term adverse health effects. Concentrations of many VOCs are consistently higher indoors (up to ten times higher) than outdoors. VOCs are emitted by a wide array of products numbering in the thousands. Examples include: paints and lacquers, paint strippers, cleaning supplies, pesticides, building materials and furnishings, office equipment such as copiers and printers, correction fluids and carbonless copy paper, graphics and craft materials including glues and adhesives, permanent markers, and photographic solutions.\n\nChlorinated drinking water releases chloroform when hot water is used in the home. Benzene is emitted from fuel stored in attached garages. Overheated cooking oils emit acrolein and formaldehyde. A meta-analysis of 77 surveys of VOCs in homes in the US found the top ten riskiest indoor air VOCs were acrolein, formaldehyde, benzene, hexachlorobutadiene, acetaldehyde, 1,3-butadiene, benzyl chloride, 1,4-dichlorobenzene, carbon tetrachloride, acrylonitrile, and vinyl chloride. These compounds exceeded health standards in most homes.\n\nOrganic chemicals are widely used as ingredients in household products. Paints, varnishes, and wax all contain organic solvents, as do many cleaning, disinfecting, cosmetic, degreasing, and hobby products. Fuels are made up of organic chemicals. All of these products can release organic compounds during usage, and, to some degree, when they are stored. Testing emissions from building materials used indoors has become increasingly common for floor coverings, paints, and many other important indoor building materials and finishes.\n\nSeveral initiatives envisage to reduce indoor air contamination by limiting VOC emissions from products. There are regulations in France and in Germany, and numerous voluntary ecolabels and rating systems containing low VOC emissions criteria such as EMICODE, M1, Blue Angel and Indoor Air Comfort in Europe, as well as California Standard CDPH Section 01350 and several others in the USA. These initiatives changed the marketplace where an increasing number of low-emitting products has become available during the last decades.\n\nAt least 18 Microbial VOCs (MVOCs) have been characterised including 1-octen-3-ol, 3-methylfuran, 2-pentanol, 2-hexanone, 2-heptanone, 3-octanone, 3-octanol, 2-octen-1-ol, 1-octene, 2-pentanone, 2-nonanone, borneol, geosmin, 1-butanol, 3-methyl-1-butanol, 3-methyl-2-butanol, and thujopsene. The first of these compounds is called mushroom alcohol. The last four are products of \"Stachybotrys chartarum\", which has been linked with sick building syndrome.\n\nLegionellosis or Legionnaire's Disease is caused by a waterborne bacterium \"Legionella\" that grows best in slow-moving or still, warm water. The primary route of exposure is through the creation of an aerosol effect, most commonly from evaporative cooling towers or showerheads. A common source of Legionella in commercial buildings is from poorly placed or maintained evaporative cooling towers, which often release water in an aerosol which may enter nearby ventilation intakes. Outbreaks in medical facilities and nursing homes, where patients are immuno-suppressed and immuno-weak, are the most commonly reported cases of Legionellosis. More than one case has involved outdoor fountains in public attractions. The presence of Legionella in commercial building water supplies is highly under-reported, as healthy people require heavy exposure to acquire infection.\n\nLegionella testing typically involves collecting water samples and surface swabs from evaporative cooling basins, shower heads, faucets/taps, and other locations where warm water collects. The samples are then cultured and colony forming units (cfu) of Legionella are quantified as cfu/Liter.\n\nLegionella is a parasite of protozoans such as amoeba, and thus requires conditions suitable for both organisms. The bacterium forms a biofilm which is resistant to chemical and antimicrobial treatments, including chlorine. Remediation for Legionella outbreaks in commercial buildings vary, but often include very hot water flushes (160 °F; 70 °C), sterilisation of standing water in evaporative cooling basins, replacement of shower heads, and in some cases flushes of heavy metal salts. Preventative measures include adjusting normal hot water levels to allow for 120 °F (50 °C) at the tap, evaluating facility design layout, removing faucet aerators, and periodic testing in suspect areas.\n\nThere are many bacteria of health significance found in indoor air and on indoor surfaces. The role of microbes in the indoor environment is increasingly studied using modern gene-based analysis of environmental samples. Currently efforts are under way to link microbial ecologists and indoor air scientists to forge new methods for analysis and to better interpret the results.\n\n\"There are approximately ten times as many bacterial cells in the human flora as there are human cells in the body, with large numbers of bacteria on the skin and as gut flora.\"\nA large fraction of the bacteria found in indoor air and dust are shed from humans. Among the most important bacteria known to occur in indoor air are Mycobacterium tuberculosis, Staphylococcus aureus, Streptococcus pneumoniae.\n\nMany common building materials used before 1975 contain asbestos, such as some floor tiles, ceiling tiles, shingles, fireproofing, heating systems, pipe wrap, taping muds, mastics, and other insulation materials. Normally, significant releases of asbestos fiber do not occur unless the building materials are disturbed, such as by cutting, sanding, drilling, or building remodelling. Removal of asbestos-containing materials is not always optimal because the fibers can be spread into the air during the removal process. A management program for intact asbestos-containing materials is often recommended instead.\n\nWhen asbestos-containing material is damaged or disintegrates, microscopic fibers are dispersed into the air. Inhalation of asbestos fibers over long exposure times is associated with increased incidence of lung cancer, in particular the specific form mesothelioma. The risk of lung cancer from inhaling asbestos fibers is significantly greater to smokers, however there is no confirmed connection to damage caused by asbestosis . The symptoms of the disease do not usually appear until about 20 to 30 years after the first exposure to asbestos.\n\nAsbestos is found in older homes and buildings, but occurs most commonly in schools, hospitals and industrial settings. Although all asbestos is hazardous, products that are friable, eg. sprayed coatings and insulation, pose a significantly higher hazard as they are more likely to release fibers to the air. The US Federal Government and some states have set standards for acceptable levels of asbestos fibers in indoor air. There are particularly stringent regulations applicable to schools.\n\nCarbon dioxide (CO) is a relatively easy to measure surrogate for indoor pollutants emitted by humans, and correlates with human metabolic activity. Carbon dioxide at levels that are unusually high indoors may cause occupants to grow drowsy, to get headaches, or to function at lower activity levels. Outdoor CO levels are usually 350-450 ppm whereas the maximum indoor CO level considered acceptable is 1000 ppm. Humans are the main indoor source of carbon dioxide in most buildings. Indoor CO levels are an indicator of the adequacy of outdoor air ventilation relative to indoor occupant density and metabolic activity.\n\nTo eliminate most complaints, the total indoor CO level should be reduced to a difference of less than 600 ppm above outdoor levels. The National Institute for Occupational Safety and Health (NIOSH) considers that indoor air concentrations of carbon dioxide that exceed 1,000 ppm are a marker suggesting inadequate ventilation. The UK standards for schools say that carbon dioxide in all teaching and learning spaces, when measured at seated head height and averaged over the whole day should not exceed 1,500 ppm. The whole day refers to normal school hours (i.e. 9:00am to 3:30pm) and includes unoccupied periods such as lunch breaks. In Hong Kong, the EPD established indoor air quality objectives for office buildings and public places in which a carbon dioxide level below 1,000 ppm is considered to be good. European standards limit carbon dioxide to 3,500 ppm. OSHA limits carbon dioxide concentration in the workplace to 5,000 ppm for prolonged periods, and 35,000 ppm for 15 minutes. These higher limits are concerned with avoiding loss of consciousness (fainting), and do not address impaired cognitive performance and energy, which begin to occur at lower concentrations of carbon dioxide.\n\nCarbon dioxide concentrations increase as a result of human occupancy, but lag in time behind cumulative occupancy and intake of fresh air. The lower the air exchange rate, the slower the buildup of carbon dioxide to quasi \"steady state\" concentrations on which the NIOSH and UK guidance are based. Therefore, measurements of carbon dioxide for purposes of assessing the adequacy of ventilation need to be made after an extended period of steady occupancy and ventilation - in schools at least 2 hours, and in offices at least 3 hours - for concentrations to be a reasonable indicator of ventilation adequacy. Portable instruments used to measure carbon dioxide should be calibrated frequently, and outdoor measurements used for calculations should be made close in time to indoor measurements. Corrections for temperature effects on measurements made outdoors may also be necessary.\nCarbon dioxide concentrations in closed or confined rooms can increase to 1,000 ppm within 45 minutes of enclosure. For example, in a sized office, atmospheric carbon dioxide increased from 500 ppm to over 1,000 ppm within 45 minutes of ventilation cessation and closure of windows and doors\n\nOzone is produced by ultraviolet light from the Sun hitting the Earth's atmosphere (especially in the ozone layer), lightning, certain high-voltage electric devices (such as air ionizers), and as a by-product of other types of pollution.\n\nOzone exists in greater concentrations at altitudes commonly flown by passenger jets. Reactions between ozone and onboard substances, including skin oils and cosmetics, can produce toxic chemicals as by-products. Ozone itself is also irritating to lung tissue and harmful to human health. Larger jets have ozone filters to reduce the cabin concentration to safer and more comfortable levels.\n\nOutdoor air used for ventilation may have sufficient ozone to react with common indoor pollutants as well as skin oils and other common indoor air chemicals or surfaces. Particular concern is warranted when using \"green\" cleaning products based on citrus or terpene extracts, because these chemicals react very quickly with ozone to form toxic and irritating chemicals as well as fine and ultrafine particles. Ventilation with outdoor air containing elevated ozone concentrations may complicate remediation attempts.\n\nOzone is on the list of six criteria air pollutant list. The Clean Air Act of 1990 required the United States Environmental Protection Agency to set National Ambient Air Quality Standards (NAAQS) for six common indoor air pollutants harmful to human health. There are also multiple other organizations that have put forth air standards such as Occupational Safety and Health Administration (OSHA), National Institute for Occupational Safety and Health (NIOSH), and the World Health Organization (WHO). The OSHA standard for Ozone concentration within a space is 0.1 ppm . While the NAAQS and the EPA standard for ozone concentration is limited to 0.07 ppm. . The type of ozone being regulated is ground-level ozone that is within the breathing range of most building occupants\n\nAtmospheric particulate matter, also known as particulates, can be found indoors and can affect the health of occupants. Authorities have established standards for the maximum concentration of particulates to ensure indoor air quality.\n\nIn 2015, experimental studies reported the detection of significant episodic (situational) cognitive impairment from impurities in the air breathed by test subjects who were not informed about changes in the air quality. Researchers at the Harvard University and SUNY Upstate Medical University and Syracuse University measured the cognitive performance of 24 participants in three different controlled laboratory atmospheres that simulated those found in \"conventional\" and \"green\" buildings, as well as green buildings with enhanced ventilation. Performance was evaluated objectively using the widely used Strategic Management Simulation software simulation tool, which is a well-validated assessment test for executive decision-making in an unconstrained situation allowing initiative and improvisation. Significant deficits were observed in the performance scores achieved in increasing concentrations of either volatile organic compounds (VOCs) or carbon dioxide, while keeping other factors constant. The highest impurity levels reached are not uncommon in some classroom or office environments.\n\nHouseplants together with the medium in which they are grown can reduce components of indoor air pollution, particularly volatile organic compounds (VOC) such as benzene, toluene, and xylene. Plants remove CO and release oxygen and water, although the quantitative impact for house plants is small. Most of the effect is attributed to the growing medium alone, but even this effect has finite limits associated with the type and quantity of medium and the flow of air through the medium. The effect of house plants on VOC concentrations was investigated in one study, done in a static chamber, by NASA for possible use in space colonies. The results showed that the removal of the challenge chemicals was roughly equivalent to that provided by the ventilation that occurred in a very energy efficient dwelling with a very low ventilation rate, an air exchange rate of about 1/10 per hour. Therefore, air leakage in most homes, and in non-residential buildings too, will generally remove the chemicals faster than the researchers reported for the plants tested by NASA. The most effective household plants reportedly included aloe vera, English ivy, and Boston fern for removing chemicals and biological compounds.\n\nPlants also appear to reduce airborne microbes and molds, and to increase humidity. However, the increased humidity can itself lead to increased levels of mold and even VOCs.\n\nWhen carbon dioxide concentrations are elevated indoors relative to outdoor concentrations, it is only an indicator that ventilation is inadequate to remove metabolic products associated with human occupancy. Plants require carbon dioxide to grow and release oxygen when they consume carbon dioxide. A study published in the journal \"Environmental Science & Technology\" considered uptake rates of ketones and aldehydes by the peace lily (\"Spathiphyllum clevelandii\") and golden pothos (\"Epipremnum aureum\") Akira Tani and C. Nicholas Hewitt found \"Longer-term fumigation results revealed that the total uptake amounts were 30−100 times as much as the amounts dissolved in the leaf, suggesting that volatile organic carbons are metabolized in the leaf and/or translocated through the petiole.\" It is worth noting the researchers sealed the plants in Teflon bags. \"No VOC loss was detected from the bag when the plants were absent. However, when the plants were in the bag, the levels of aldehydes and ketones both decreased slowly but continuously, indicating removal by the plants.\" Studies done in sealed bags do not faithfully reproduce the conditions in the indoor environments of interest. Dynamic conditions with outdoor air ventilation and the processes related to the surfaces of the building itself and its contents as well as the occupants need to be studied.\n\nWhile results do indicate house plants may be effective at removing some VOCs from air supplies, a review of studies between 1989 and 2006 on the performance of houseplants as air cleaners, presented at the Healthy Buildings 2009 conference in Syracuse, New York, concluded \"...indoor plants have little, if any, benefit for removing indoor air of VOC in residential and commercial buildings.\"\n\nSince high humidity is associated with increased mold growth, allergic responses, and respiratory responses, the presence of additional moisture from houseplants may not be desirable in all indoor settings.\n\nEnvironmentally sustainable design concepts also include aspects related to the commercial and residential heating, ventilation and air-conditioning (HVAC) industry. Among several considerations, one of the topics attended to is the issue of indoor air quality throughout the design and construction stages of a building's life.\n\nOne technique to reduce energy consumption while maintaining adequate air quality, is demand-controlled ventilation. Instead of setting throughput at a fixed air replacement rate, carbon dioxide sensors are used to control the rate dynamically, based on the emissions of actual building occupants.\n\nFor the past several years, there have been many debates among indoor air quality specialists about the proper definition of indoor air quality and specifically what constitutes \"acceptable\" indoor air quality.\n\nOne way of quantitatively ensuring the health of indoor air is by the frequency of effective turnover of interior air by replacement with outside air. In the UK, for example, classrooms are required to have 2.5 outdoor air changes per hour. In halls, gym, dining, and physiotherapy spaces, the ventilation should be sufficient to limit carbon dioxide to 1,500 ppm. In the USA, and according to ASHRAE Standards, ventilation in classrooms is based on the amount of outdoor air per occupant plus the amount of outdoor air per unit of floor area, not air changes per hour. Since carbon dioxide indoors comes from occupants and outdoor air, the adequacy of ventilation per occupant is indicated by the concentration indoors minus the concentration outdoors. The value of 615 ppm above the outdoor concentration indicates approximately 15 cubic feet per minute of outdoor air per adult occupant doing sedentary office work where outdoor air contains 385 ppm, the current global average atmospheric CO concentration. In classrooms, the requirements in the ASHRAE standard 62.1, Ventilation for Acceptable Indoor Air Quality, would typically result in about 3 air changes per hour, depending on the occupant density. Of course the occupants are not the only source of pollutants, so outdoor air ventilation may need to be higher when unusual or strong sources of pollution exist indoors. When outdoor air is polluted, then bringing in more outdoor air can actually worsen the overall quality of the indoor air and exacerbate some occupant symptoms related to outdoor air pollution. Generally, outdoor country air is better than indoor city air. Exhaust gas leakages can occur from furnace metal exhaust pipes that lead to the chimney when there are leaks in the pipe and the pipe gas flow area diameter has been reduced.\n\nThe use of air filters can trap some of the air pollutants. The Department of Energy's Energy Efficiency and Renewable Energy section suggests that \"[Air] Filtration should have a Minimum Efficiency Reporting Value (MERV) of 13 as determined by ASHRAE 52.2-1999.\" Air filters are used to reduce the amount of dust that reaches the wet coils. Dust can serve as food to grow molds on the wet coils and ducts and can reduce the efficiency of the coils.\n\nMoisture management and humidity control requires operating HVAC systems as designed. Moisture management and humidity control may conflict with efforts to try to optimize the operation to conserve energy. For example, moisture management and humidity control requires systems to be set to supply make-up air at lower temperatures (design levels), instead of the higher temperatures sometimes used to conserve energy in cooling-dominated climate conditions. However, for most of the US and many parts of Europe and Japan, during the majority of hours of the year, outdoor air temperatures are cool enough that the air does not need further cooling to provide thermal comfort indoors. However, high humidity outdoors creates the need for careful attention to humidity levels indoors. High humidities give rise to mold growth and moisture indoors is associated with a higher prevalence of occupant respiratory problems.\n\nThe \"dew point temperature\" is an absolute measure of the moisture in air. Some facilities are being designed with the design dew points in the lower 50s °F, and some in the upper and lower 40s °F. Some facilities are being designed using desiccant wheels with gas-fired heaters to dry out the wheel enough to get the required dew points. On those systems, after the moisture is removed from the make-up air, a cooling coil is used to lower the temperature to the desired level.\n\nCommercial buildings, and sometimes residential, are often kept under slightly positive air pressure relative to the outdoors to reduce infiltration. Limiting infiltration helps with moisture management and humidity control.\n\nDilution of indoor pollutants with outdoor air is effective to the extent that outdoor air is free of harmful pollutants. Ozone in outdoor air occurs indoors at reduced concentrations because ozone is highly reactive with many chemicals found indoors. The products of the reactions between ozone and many common indoor pollutants include organic compounds that may be more odorous, irritating, or toxic than those from which they are formed. These products of ozone chemistry include formaldehyde, higher molecular weight aldehydes, acidic aerosols, and fine and ultrafine particles, among others. The higher the outdoor ventilation rate, the higher the indoor ozone concentration and the more likely the reactions will occur, but even at low levels, the reactions will take place. This suggests that ozone should be removed from ventilation air, especially in areas where outdoor ozone levels are frequently high. Recent research has shown that mortality and morbidity increase in the general population during periods of higher outdoor ozone and that the threshold for this effect is around 20 parts per billion (ppb).\n\nIt is common to assume that buildings are simply inanimate physical entities, relatively stable over time. This implies that there is little interaction between the triad of the building, what is in it (occupants and contents), and what is around it (the larger environment). We commonly see the overwhelming majority of the mass of material in a building as relatively unchanged physical material over time. In fact, the true nature of buildings can be viewed as the result of a complex set of dynamic interactions among their physical, chemical, and biological dimensions. Buildings can be described and understood as complex systems. Research applying the approaches ecologists use to the understanding of ecosystems can help increase our understanding. “Building ecology “ is proposed here as the application of those approaches to the built environment considering the dynamic system of buildings, their occupants, and the larger environment.\n\nBuildings constantly evolve as a result of the changes in the environment around them as well as the occupants, materials, and activities within them. The various surfaces and the air inside a building are constantly interacting, and this interaction results in changes in each. For example, we may see a window as changing slightly over time as it becomes dirty, then is cleaned, accumulates dirt again, is cleaned again, and so on through its life. In fact, the “dirt” we see may be evolving as a result of the interactions among the moisture, chemicals, and biological materials found there.\n\nBuildings are designed or intended to respond actively to some of these changes in and around them with heating, cooling, ventilating, air cleaning or illuminating systems. We clean, sanitize, and maintain surfaces to enhance their appearance, performance, or longevity. In other cases, such changes subtly or even dramatically alter buildings in ways that may be important to their own integrity or their impact on building occupants through the evolution of the physical, chemical, and biological processes that define them at any time. We may find it useful to combine the tools of the physical sciences with those of the biological sciences and, especially, some of the approaches used by scientists studying ecosystems, in order to gain an enhanced understanding of the environments in which we spend the majority of our time, our buildings.\n\nBuilding ecology was first described by Hal Levin in an article in the April 1981 issue of Progressive Architecture magazine.\n\nThe topic of IAQ has become popular due to the greater awareness of health problems caused by mold and triggers to asthma and allergies. In the US, awareness has also been increased by the involvement of the United States Environmental Protection Agency, who have developed an \"IAQ Tools for Schools\" program to help improve the indoor environmental conditions in educational institutions (see external link below). The National Institute for Occupational Safety and Health conducts Health Hazard Evaluations (HHEs) in workplaces at the request of employees, authorised representative of employees, or employers, to determine whether any substance normally found in the place of employment has potentially toxic effects, including indoor air quality.\n\nA variety of scientists work in the field of indoor air quality including chemists, physicists, mechanical engineers, biologists, bacteriologists and computer scientists. Some of these professionals are certified by organisations such as the American Industrial Hygiene Association, the American Indoor Air Quality Council and the Indoor Environmental Air Quality Council.\n\nOn the international level, the International Society of Indoor Air Quality and Climate (ISIAQ), formed in 1991, organises two major conferences, the Indoor Air and the Healthy Buildings series. ISIAQ's journal \"Indoor Air\" is published 6 times a year and contains peer-reviewed scientific papers with an emphasis on interdisciplinary studies including exposure measurements, modeling, and health outcomes.\n\n\n\n"}
{"id": "1335881", "url": "https://en.wikipedia.org/wiki?curid=1335881", "title": "James Mourilyan Tanner", "text": "James Mourilyan Tanner\n\nJames Mourilyan Tanner DSc, MRCP, FRCPsych, FRCP (1 August 1920 – 11 August 2010) was a British paediatric endocrinologist who was best known for his development of the Tanner scale, which measures the stages of sexual development during puberty. He was a professor emeritus of the Institute of Child Health at the University of London.\n\nTanner was born on 1 August 1920 in Camberley, Surrey, United Kingdom and was educated at Marlborough College and University College of the South West of England. His family travelled widely while he was a youth because his father, a soldier in the British Army, was stationed in various locations. Tanner was a top-ranked hurdler who might well have participated in the 1940 Summer Olympics which were to be held in London, but were cancelled after the outbreak of World War II. He decided to become a doctor and not follow his father into the military after his brother was killed early in the war. He attended St Mary's Hospital, London, under a scholarship in which he instructed fellow students in physical education. He went to the United States to complete his medical studies as part of a group of British students funded by a grant from the Rockefeller Foundation. He met his first wife, fellow physician Bernice Alture, while at the University of Pennsylvania School of Medicine and performed his internship at Johns Hopkins Hospital.\n\nTanner oversaw a study initiated by the British government at an orphanage in Harpenden starting in 1948. While the study had originally been planned to study the effects of malnutrition on children, Tanner charted and photographed the growth of the children in the study over a period of several years, developing the Tanner Scale, which measures sexual maturation in adolescents based on characteristics that can be objectively measured, including size of the genitals and the quantity of pubic hair. The data gathered led to the development of the modern growth chart, used by paediatricians around the world to monitor the pattern of growth in children through adolescence, with separate curves measuring the growth trajectory for boys and girls identified as maturing early, normal or late. Based on his research, Tanner noted that 90% of an individual child's adult height is based on genetic factors, but that the environment is the key factor when thousands of children are studied. By studying the growth characteristics of large populations, Tanner concluded that community-wide data on adult height was an indicator of how a society fosters its youths.\n\nTanner did early research on the use of human growth hormone to address children whose growth was significantly delayed and was responsible for selecting the small handful of children in the UK who would be treated with the limited supply of HGH extracted from human cadavers. After a number of patients worldwide died in 1985 due to an infectious brain disease spread by the HGH treatments, Tanner immediately stopped the therapy, but had patients who insisted that they were willing to take the risk to address their child's delayed growth. Treatments resumed in the 1990s following the introduction of genetically engineered human growth hormone.\n\nTanner died at age 90 on 11 August 2010 in Wellington, Somerset, due to a stroke and prostate cancer. He was survived by his second wife, Gunilla, as well as by a daughter, Helen Phillips, a stepdaughter, a stepson and three granddaughters.\n\nTanner authored and co-authored numerous publications and contributions to publications, some of which are listed below.\n"}
{"id": "34854989", "url": "https://en.wikipedia.org/wiki?curid=34854989", "title": "Joseph Berger (neurologist)", "text": "Joseph Berger (neurologist)\n\nJoseph R. Berger is an American internist and neurologist who is known for his research interests in progressive multifocal leukoencephalopathy (PML), the neurological complications of HIV/AIDS, multiple sclerosis, and other inflammatory disorders of the brain. Particularly, he contributed research on why PML occurs more frequently in AIDS than in other immunosuppressive conditions.\n\nHe has also made substantial contributions to the understanding of the spectrum of neurological complications that accompany HIV infection occurring as a consequence of the direct effects of the HIV on the central and peripheral nervous systems and those that result from the accompanying immunosuppression of AIDS. Berger is the discoverer of the value of the anabolic steroid oxandrolone in the treatment of AIDS wasting and AIDS myopathy. He is the recipient of the 2015 Pioneer in NeuroVirology award of the International Society for NeuroVirology.\n\nIn 1981, Berger joined the faculty of the University of Miami School of Medicine, serving in the departments of both neurology and internal medicine. At that institution, he held the Whigham-Berger Endowed Chair for the study of the neurological complications of HIV/AIDS. He is a fellow of the American Academy of Neurology, the American Neurological Association, and the American College of Physicians.\n\nFrom 1995 through 2014, he was chairman of the Department of Neurology at the University of Kentucky College of Medicine, where he held the Ruth L. Works Professorship and was director of the Multiple Sclerosis Clinic and the Neuro-AIDS Program.\n\nIn 2014, he joined the faculty of the Perelman School of Medicine, University of Pennsylvania, as professor of neurology and chief of the Multiple Sclerosis Division.\n\nBerger was a \"summa cum laude\" graduate of the Pennsylvania State University – Jefferson Medical College Five-Year Accelerated Medical Program. He completed his residency in internal medicine at Georgetown University Hospital and his neurology residency at the University of Miami School of Medicine.\n\nBerger is the case-report editor of the \"Journal of NeuroVirology\" and serves or has served on other editorial boards. He co-founded the International Neuroscience of HIV meeting with Dr. Robert Levy, and has served in numerous administrative capacities for the American Neurological Association and the American Academy of Neurology.\n\nBerger has published more than 210 refereed papers, more than 100 chapters, and has co-edited three textbooks,\n\n"}
{"id": "28796806", "url": "https://en.wikipedia.org/wiki?curid=28796806", "title": "Lebensreform", "text": "Lebensreform\n\nLebensreform (\"life reform\") was a social movement in late 19th-century and early 20th-century Germany and Switzerland that propagated a back-to-nature lifestyle, emphasizing among others health food/raw food/organic food, nudism, sexual liberation, alternative medicine, and religious reform and at the same time abstention from alcohol, tobacco, drugs, and vaccines.\n\nImportant \"Lebensreform\" proponents were Sebastian Kneipp, Louis Kuhne, Rudolf Steiner, Karl Wilhelm Diefenbach, Fidus (Hugo Höppener), Gustav Gräser, and Adolf Just. Some practitioners of \"Lebensreform\" such as Bill Pester, Benedict Lust, and Arnold Ehret emigrated to California in the late 19th (Lust) or first half of the 20th century and directly influenced the later hippie movement. One group, called the \"Nature Boys\", settled in the California desert. eden ahbez, a member of this group, wrote a hit song called \"Nature Boy\" (recorded in 1947 by Nat King Cole), popularizing the homegrown back-to-nature movement to mainstream America. Eventually, a few of these Nature Boys, including Gypsy Boots, made their way to Northern California in 1967, just in time for the Summer of Love in San Francisco.\n\nOne noticeable legacy of \"Lebensreform\" in Germany today are the \"Reformhaus\" (\"reform house\") retail stores that sell naturopathic medicine and organic food.\n\nThe Lebensreform movement in Germany originally was a politically diverse movement. There were hundreds of groups across Germany dedicated to some or all of the concepts associated with Lebensreform: ecology and organic farming, vegetarianism, naturism (\"freie Körperkultur or FKK\"), and abstinence from alcohol and tobacco. Dozens of magazines, books, and pamphlets were published on these topics. Some groups were made of socialists, some were apolitical, and some were rightwing and nationalist in outlook.\n\nOne outstanding prophet of Lebensreform was the painter Karl Wilhelm Diefenbach (1861-1913), a pacifist and tolstoyan anarchist who founded the community Himmelhof near Vienna. Among his disciples were three painters: Hugo Höppener (Fidus), Frantischek Kupka and Gusto Graeser. In 1900 Graeser became the cofounder and inspiring pioneer of the community Monte Verità near Ascona, Switzerland. Monte Verità attracted lots of artists from all of Europe, during World War I conscientious objectors from Germany and France. Gusto Graeser, thinker and poet, greatly influenced the German Youth Movement and such writers as Hermann Hesse and Gerhart Hauptmann. He was the model for the master figures in the books of Hermann Hesse. Richard Ungewitter and Heinrich Pudor were also well known advocates of a strain of Lebensreform that emphasized nudism and was explicitly anti-Semitic, which eventually became Freikörperkultur movement. The Freikörperkultur movement eventually broadened and came to include socialists with no strains of racism like Adolf Koch, who for example organized factory workers to go on nudist hikes.\n\nContemporary environmental movements, the organic food movement, many fad diets and \"back to nature\" movements, as well as \"folk movements\", have their roots in the Lebensreform movement's emphasis on the goodness of nature, the harms to society, people, and to nature caused by industrialization, the importance of the whole person, body and mind, and the goodness of \"the old ways\".\n\nAnother stream based on völkisch Romanticism gradually became part of Nazi ideology by the 1930s, known as blood and soil. As early as 1907, Richard Ungewitter published a pamphlet called \"Nudity and Culture\" (which sold 100,000 copies), arguing that the practices he recommended would be \"the means by which the German race would regenerate itself and ultimately prevail over its neighbours and the diabolical Jews, who were intent on injecting putrefying agents into the nation's blood and soil\".\n\nThe extremists promoting rightwing ideology eventually became popular among Nazi Party officials and their supporters, including Heinrich Himmler and Rudolph Höss, who belonged to the right-wing farming organization the Artaman League. When other groups were being banned or disbanded due to political conflict during the 1930s, the extreme nationalist ideology became connected with Naziism. The German Life Reform League broke apart into political factions during this time. The Nationalist physician Artur Fedor Fuchs began the League for Free Body Culture (FKK), giving public lectures on the healing powers of the sun in the \"Nordic sky\", which \"alone strengthened and healed the warrior nation\". Ancient forest living, and habits presumed to have been followed by the ancient tribes of Germany, were beneficial to regenerating the Aryan people, according to Fuchs' philosophy. Hans Sùren, a prominent former military officer, published \"Man and the Sun\" (1924), which sold 240,000 copies; by 1941 it was reissued in 68 editions. Sùren promoted the Aryan master race concept of physically strong, militarized men who would be the \"salvation\" of the German people.\n\nRecently, Germany has been experiencing a growth of rightwing extremist organizations with ecological connections, including organic farming. Since the 1990s, a number of rightwing farmers have set up organic farming operations in Mecklenburg. The politically far-right environmental-interest magazine \"Umwelt und Aktiv\" (Environment and Active) is believed to receive support from the far-right nationalist National Democratic Party of Germany (NPD). German publications \"Der Spiegel\" and \"Süddeutsche Zeitung\" have also covered the link between far-right extremists and certain organic farming projects in Germany, and it has received government and academic attention as well. Speculation is that such rightwing projects may be attempts to revive the Nazi-era Artaman League, to soften the image of the NPD, or to pull supporters away from the leftwing Alliance '90/The Greens (Green Party) of Germany, which is Europe's most successful environmentalist political party.\n\n\n\n"}
{"id": "41579179", "url": "https://en.wikipedia.org/wiki?curid=41579179", "title": "Medical Respite Care", "text": "Medical Respite Care\n\nMedical respite care, also referred to as recuperative care, is acute and post-acute medical care for homeless persons who are too ill or frail to recover from a physical illness or injury on the streets but are not ill enough to be in a hospital. Unlike “respite” for caregivers, “medical respite” is short-term residential care that allows homeless individuals the opportunity to rest in a safe environment while accessing medical care and other supportive services. Medical respite programs provide hospitals with an alternative to discharging homeless patients to the streets or to unequipped shelters when patients would otherwise be discharged to their homes for self-care and recuperation. In addition to providing post-acute care and clinical oversight, medical respite programs seek to improve transitional care for this population and end the cycle of homelessness by supporting patients in access benefits and housing.\n\nAs of 2014, over 70 medical respite programs have been established across the United States and a number are in development. Medical respite programs are housed in a number of different facility types including homeless shelters, motel rooms, nursing facilities, assisted living facilities and stand-alone facilities. The largest facility is based out of Boston, Massachusetts (United States), called the Barbara McIinnis House, which has 104 beds for men and women in need of a safe place to recuperate after leaving a hospital. The national average length of stay in medical respite programs is 40 days (30 days median).\n\nStudies and discussion about medical respite care include works on an individual and program level. A study out of Chicago looking at the impact of medical respite care on future hospitalizations found that patients who accessed medical respite care required fewer hospital stays (3.7 vs. 8.3 days) in the 12-months after program participation than those discharged from the hospital to the street or shelter. Another study out of Boston found similar results with homeless patients requiring 50% fewer hospital readmissions in the 90-days following medical respite program participation than those released to their own care (the street or shelter). Medical respite care has been discussed in the American Medical New Ethics Forum.\n\nMedical respite care is listed as a strategy in the federal plan to prevent and end homelessness. The Center for Medicare and Medicaid Innovation is currently conducting a national demonstration program to assess the impact of medical respite care. The demonstration is supported by the Affordable Care Act as an effort to improve health outcomes and health care quality while reducing health care spending for this population.\n\nThe National Health Care for the Homeless Council maintains a Respite Care Providers' Network of over 700 providers, consumers, and advocates who seek to improve access to medical respite care for homeless individuals across the country.\n"}
{"id": "51538744", "url": "https://en.wikipedia.org/wiki?curid=51538744", "title": "Mercedes Chacón Porras", "text": "Mercedes Chacón Porras\n\nMercedes Chacón Porras (1896-1963) was the first obstetrical nurse in Costa Rica and spread health care to rural communities throughout the country. In 2002, she was one of the inaugural women inducted into La Galería de las Mujeres de Costa Rica and the first national health center named for a woman bears her name.\n\nMercedes Chacón Porras was born on 11 September 1896 in Costa Rica. In 1925, Chacón became the first obstetrical nurse of Costa Rica and worked toward providing prenatal care and preventing maternal and infant deaths. She was one of the few professional women working in the health field in the country and strove to bring health services to rural populations within their own communities.\n\nChacón died on 18 April 1963 and was posthumously inducted into La Galería de las Mujeres de Costa Rica in 2002. A clinic in Aserrí, Costa Rica was named in her honor, breaking the custom of naming national health centers after men.\n\n"}
{"id": "13603816", "url": "https://en.wikipedia.org/wiki?curid=13603816", "title": "National Accreditation Board for Hospitals &amp; Healthcare Providers", "text": "National Accreditation Board for Hospitals &amp; Healthcare Providers\n\nNABH (National Accreditation Board for Hospitals & Healthcare Providers) is a constituent board of Quality Council of India Certification, set up to establish and operate accreditation programme for healthcare organizations. NABH was established in 2006.\n\nOrganisations like the Quality Council of India (QCI) and its National Accreditation Board for Hospitals & Healthcare Providers have designed an exhaustive healthcare standard for hospitals and healthcare providers. This standard consists of stringent 600 plus objective elements for the hospital to achieve in order to get the NABH accreditation. These standards are divided between patient centered standards and organization centred standards.\n\nTo comply with these standard elements, the hospital will need to have a process-driven approach in all aspects of hospital activities – from registration, admission, pre-surgery, peri-surgery and post-surgery protocols, discharge from the hospital to follow up with the hospital after discharge. Not only the clinical aspects but the governance aspects are to process driven based on clear and transparent policies and protocols. In a nutshell, NABH aims at streamlining the entire operations of a hospital.\n\nNABH is equivalent to JCI and other International standards including HAS: Haute Authorite de Sante, Australian Council on Healthcare Standards, the Japan Council for Quality in Health Care, and the National Committee for Quality Assurance in the United States. Its standards have been accredited by ISQUA the apex body accrediting the accreditators hence making NABH accreditation at par with the worlds most leading hospital accreditation.\n\nThe official website of QCI should be referred for application and implementation of healthcare standards. The Quality Council of India works under the guidance of Ministry of Commerce.\n\nHistory\n\nNABH accreditation system was established in 2006 as a constituent of Quality Council of India (QCI). The first edition of standards was released in 2006 and after that the standards has been revised every 3 years. Currently the 4th edition of NABH standards, released in December 2015 is in use.\n\nThe first hospital to be accredited by NABH is 'Malabar Institute of Medical Sciences (MIMS), Kerala' which is a 650-bed multispeciality hospital and was accredited in 2007 and till date more than 350 hospitals in India has achieved accreditation by NABH. In public hospitals, Gandhinagar General hospital was the first to get NABH accreditation in 2009.\n\nStandards\n\nThe NABH standards 4th edition standards are documented in 10 chapters, which are as follows\n\n\n"}
{"id": "24762111", "url": "https://en.wikipedia.org/wiki?curid=24762111", "title": "National Outbreak Reporting System", "text": "National Outbreak Reporting System\n\nThe National Outbreak Reporting System (NORS) is an electronic, web-accessible system designed to improve the quality, quantity, and availability of data for waterborne, foodborne, enteric person-to-person, and enteric zoonotic (animal-to-person) disease outbreaks in the United States.\n\nNORS launched in 2009 for use by staff working within public health departments in individual states, territories, and the Freely Associated States (composed of the Republic of the Marshall Islands, the Federated States of Micronesia and the Republic of Palau; formerly parts of the U.S.-administered Trust Territories of the Pacific Islands). Health departments are responsible for determining which staff members have access to NORS.\n\nNORS replaced the electronic Foodborne Outbreak Reporting System (eFORS) - the primary tool for reporting foodborne disease outbreaks to the U.S. Centers for Disease Control and Prevention (CDC) since 2001. NORS also replaced the paper-based reporting system used during 1971-2008 to report waterborne disease outbreaks to the Waterborne Disease and Outbreak Reporting System (WBDOSS). The transition to electronic waterborne disease outbreak reporting is in large part a response to the Council of State and Territorial Epidemiologists (CSTE) position statement titled \"Improving Detection, Investigation, and Reporting of Waterborne Disease Outbreaks.\"\n\nSeparate sections in NORS for enteric person-to-person and animal-to-person disease outbreak reports are intended to enhance the information available to quantify, describe and understand these types of outbreaks at a national level.\n\nWaterborne Disease and Outbreak Reporting System (WBDOSS)\n\n"}
{"id": "31955888", "url": "https://en.wikipedia.org/wiki?curid=31955888", "title": "Oni Akerele", "text": "Oni Akerele\n\nJohn Oni Akerele (died 1983) was a Nigerian doctor, Nigeria's first indigenous surgeon.\n\nWhile living in London, in 1941 he married Dorothy Jackson, who was of African, European and Native American descent, and they set up home in Kilburn, in the north of London.\nTheir house became a meeting place for Africans such as Nnamdi Azikiwe, the first President of Nigeria, and Jomo Kenyatta of Kenya.\nWhile in London, in 1945 he was one of the founders of the pan-Yoruba cultural society \"Egbe Omo Oduduwa\", and was the first president. Members included Obafemi Awolowo, Secretary, Akintola Williams, Saburi Biobaku, Ayo Rosiji and others.\n\nAkerele returned to Nigeria after independence in 1960, and became medical officer to the Western Region in Ibadan.\nDuring the Nigerian civil war (1967–1970) they moved to Lagos, where Akerela set up a private practice. He died in 1983. Dorothy lived on to the age of 93, dying in April 2007.\n"}
{"id": "37518081", "url": "https://en.wikipedia.org/wiki?curid=37518081", "title": "P. and S. v. Poland", "text": "P. and S. v. Poland\n\nP. and S. v. Poland is a decision by the European Court of Human Rights in which the court ruled that the state of Poland had improperly hindered a 14-year-old girl in Lublin, P., from her right to an abortion. The other plaintiff in the case was S., her mother, born in 1974.\n\nP. had become pregnant in 2008. Polish law allows abortion if the pregnancy is the consequence of a criminal act. In accordance with the law, on 20 May 2008, P. received a certificate from the public prosecutor attesting that she could get an abortion because she was fourteen, and sexual intercourse with minors below the age of fifteen is a crime. P. and S. went to two hospitals in Lublin to have an abortion performed, but the hospitals refused. A gynecologist at one of the hospitals brought her to see a Roman Catholic priest without asking her permission, and the priest urged her not to have an abortion. Following an argument with S., the gynecologist refused to perform the abortion. Hospital officials issued a press release about the case, following which P.'s situation was nationally debated. After her case became publicly known, P. was harassed by anti-abortion activists.\n\nP. and S. then went to a hospital in Warsaw. Doctors there expressed reluctance to perform the procedure, stating that they were under pressure not to do so. P. and S. were then taken in for police questioning, and S. accused of attempting to force P. to have an abortion. P. was then placed in a juvenile shelter, and authorities began proceedings to take custody of the girl away from S. After a complaint by S. to the Ministry of Health, P. was allowed to have an abortion in Gdańsk.\n\nThe European Court of Human Rights ruled that Poland had violated Article 3 of the European Convention on Human Rights, the \"prohibition of inhuman or degrading treatment\". The court stated that P.'s difficulties increased due to \"the lack of a clear legal framework, procrastination of medical staff and also as result of harassment\". The decision went on to note that \"[t]he court was particularly struck that the authorities started criminal proceedings for illicit sexual relations against the adolescent who, according to the prosecutor and medical reports, should have been considered the victim of sexual abuse\". Poland was ordered to pay €15,000 to P. and €30,000 to S., and €16,000 to each for court costs.\n\nFollowing the ruling, Amnesty International urged Poland to \"take urgent steps to ensure women and girls have full access to sexual and reproductive health\". \"The Irish Times\" stated that the decision had implications for Ireland, which had a pending case regarding a failure to provide a legal framework for abortion. \n\n\n"}
{"id": "38500797", "url": "https://en.wikipedia.org/wiki?curid=38500797", "title": "Para-cycling", "text": "Para-cycling\n\nPara-cycling (or Paracycling) is the sport of cycling adapted for cyclists who have various disabilities. It is governed by the Union Cycliste Internationale (UCI). The sport consists of seven different events which include road and track races. The world's elite para-cyclists compete at Worlds Championships, the Paralympic Games and the World Cup.\n\nPara-cycling originated in the 1980s, starting with visually impaired riders who competed on a tandem with a sighted partner. It entered the Summer Paralympic Games in 1984, where it consisted of only road races for riders with cerebral palsy. By 1996 track cycling was included and a variety of disabilities in various functional categories. Handcycling was included in the 2000 Paralympics in Sydney Australia as an exhibition event.\n\nPara-cycling events consist of the following three road races and four track events:\n\n\n\nClassification of riders consists of four broad groups; visual impairment, cerebral palsy, mobility impairment and handcycling. These are subdivided into 14 functional categories for men and women. Riders are placed in the appropriate category according to their functional ability.\n"}
{"id": "7026790", "url": "https://en.wikipedia.org/wiki?curid=7026790", "title": "Plutonium in the environment", "text": "Plutonium in the environment\n\nSince the mid-20th century, plutonium in the environment has been primarily produced by human activity. The first plants to produce plutonium for use in cold war atomic bombs were at the Hanford nuclear site, in Washington, and Mayak nuclear plant, in Russia. Over a period of four decades, “both released more than 200 million curies of radioactive isotopes into the surrounding environment -- twice the amount expelled in the Chernobyl disaster in each instance”.\n\nThe majority of plutonium isotopes are short-lived on a geological timescale, though it has been argued that traces of the long-lived Pu isotope, still exist in nature. This isotope has been found in lunar soil, meteorites, and in the Oklo natural reactor. However, one paper on marine sediments for plutonium in marine sediments, atomic bomb fallout is responsible for 66% of the Pu and 59% Pu found in the English Channel, while nuclear reprocessing is responsible for the majority of the Pu and Pu present in the Earth's oceans (nuclear weapons testing is only responsible for 6.5 and 16.5% of these isotopes respectively).\n\nRichland, Washington was the first city established to support plutonium production at the nearby Hanford nuclear site, to power the American nuclear weapons arsenals. Ozersk, Russia supported plutonium production to power the Soviet nuclear arsenals at the Mayak nuclear plant. These were the first two cities in the world to produce plutonium for use in cold war atomic bombs.\n\nIn the 2013 book on a history of these two blighted cities, \"Plutopia: Nuclear Families, Atomic Cities, and the Great Soviet and American Plutonium Disasters\" (Oxford), Kate Brown explores the health of affected citizens in both the United States and Russia, and the “slow-motion disasters” that still threaten the environments where the plants are located. According to Brown, the plants at Hanford and Mayak, over a period of four decades, “both released more than 200 million curies of radioactive isotopes into the surrounding environment -- twice the amount expelled in the Chernobyl disaster in each instance”.\n\nMost of this radioactive contamination over the years at Hanford and Mayak were part of normal operations, but unforeseen accidents did occur and plant management kept this secret, as the pollution continued unabated. Even today, as pollution threats to health and the environment persist, the government keeps knowledge about the associated risks from the public.\n\nAbout 3.5 tons of plutonium have been released into the environment by atomic bomb tests. While this might sound like a large amount it has only resulted in a very small dose to the majority of the humans on the earth. Overall the health effects of fission products are far greater than the effects of the actinides released by a nuclear bomb detonation. The plutonium from the fuel of the bomb is converted into a high-fired oxide that is carried high into the air. It slowly fall to earth as global fallout and is not soluble, and as a result it is difficult for this plutonium to be incorporated into an organism if ingested. Much of this plutonium is absorbed into sediments of lakes, rivers and oceans. However, about 66% of the plutonium from a bomb explosion is formed by the neutron capture of uranium-238; this plutonium is not converted by the bomb into a high fired oxide as it is formed more slowly. This formed plutonium is more soluble and more harmful as fallout.\n\nSome plutonium can be deposited close to the point of detonation. The glassy trinitite formed by the Trinity bomb has been examined to determine what actinides and other radioisotopes it contained. A recent paper reports the levels of long lived radioisotopes in the trinitite. Eu and Eu was mainly formed by the neutron activation of the europium in the soil, and the level of radioactivity for these isotopes is highest where the neutron dose to the soil was larger. Some of the Co was generated by activation of the cobalt in the soil, but some was also generated by the activation of the cobalt in the steel (100 foot) tower on which the bomb stood. This Co from the tower would have been scattered over the site reducing the difference in the soil levels. Ba and Am were created by the neutron activation of barium and plutonium inside the bomb. The barium was present in the form of the nitrate in the chemical explosives used while the plutonium was the fissile fuel used.\n\nAs the Pu/Pu ratio only changed slightly during the Trinity detonation, it has been commented that this isotope ratio for the majority of atomic bombs (in Japan the Pu/Pu ratio in soil is normally in the range 0.17 to 0.19) is very different than from the bomb dropped upon Nagasaki.\n\nPlutonium has also been released into the environment in \"safety trials\". In these experiments, nuclear bombs have been subjected to simulated accidents or detonated with an abnormal initiation of their chemical explosives. An abnormal implosion will result in a compression of the plutonium pit, which is less uniform and smaller than the designed compression in the device. In these experiments where no or very little nuclear fission occurs, plutonium metal has been scattered around the test sites. While some of these tests have been done underground, other such tests were conducted in open air. A paper on the radioisotopes left on an island by the French nuclear bombs tests of the 20th century has been printed by the International Atomic Energy Agency and a section of this report deals with plutonium contamination resulting from such tests.\n\nOther related trials were conducted at Maralinga, South Australia where both normal bomb detonations and \"safety trials\" have been conducted. While the activity from the fission products has decayed away almost totally (as of 2006) the plutonium remains active.\n\nPlutonium can also be introduced into the environment via the reentry of artificial satellites containing atomic batteries. There have been several such incidents, the most prominent being the Apollo 13 mission. The Apollo Lunar Surface Experiment Package carried on the Lunar Module re-entered the atmosphere over the South Pacific. Many atomic batteries have been of the Radioisotope thermoelectric generator (RTG) type. The Plutonium-238 used in RTGs has a half-life of 88 years, as opposed to the plutonium-239 used in nuclear weapons and reactors, which has a half-life of 24,100 years. In April 1964 a SNAP-9A failed to achieve orbit and disintegrated, dispersing roughly of plutonium-238 over all continents. Most plutonium fell in the southern hemisphere. Estimated 6300GBq or 2100 man-Sv of radiation was released and led to NASA's development of solar photovoltaic energy technology.\n\nChain reactions do not occur inside RTGs, so a nuclear meltdown is impossible. In fact, some RTGs are designed so that fission does not occur at all; rather, forms of radioactive decay which cannot trigger other radioactive decays are used instead. As a result, the fuel in an RTG is consumed much more slowly and much less power is produced. RTGs are still a potential source of radioactive contamination: if the container holding the fuel leaks, the radioactive material will contaminate the environment. The main concern is that if an accident were to occur during launch or a subsequent passage of a spacecraft close to Earth, harmful material could be released into the atmosphere. However, this event is extremely unlikely with current RTG cask designs.\n\nIn order to minimise the risk of the radioactive material being released, the fuel is typically stored in individual modular units with their own heat shielding. They are surrounded by a layer of iridium metal and encased in high-strength graphite blocks. These two materials are corrosion and heat-resistant. Surrounding the graphite blocks is an aeroshell, designed to protect the entire assembly against the heat of reentering the Earth's atmosphere. The plutonium fuel is also stored in a ceramic form that is heat-resistant, minimising the risk of vaporization and aerosolization. The ceramic is also highly insoluble.\n\nThe US Department of Energy has conducted seawater tests and determined that the graphite casing, which was designed to withstand reentry, is stable and no release of plutonium should occur. Subsequent investigations have found no increase in the natural background radiation in the area. The Apollo 13 accident represents an extreme scenario due to the high re-entry velocities of the craft returning from cislunar space. This accident has served to validate the design of later-generation RTGs as highly safe.\n\nPlutonium has been released into the environment in aqueous solution from nuclear reprocessing and uranium enrichment plants. The chemistry of this plutonium is different from that of the metal oxides formed from nuclear bomb detonations.\n\nOne example of a site where plutonium entered the soil is Rocky Flats where in the recent past XANES (X-ray spectroscopy) has been used to determine the chemical nature of the plutonium in the soil. The XANES was used to determine the oxidation state of the plutonium, while EXAFS was used to investigate the structure of the plutonium compound present in the soil and concrete.\n\nBecause plutonium oxide is very involatile, most of the plutonium in the reactor was not released during the fire. However that which was released can be measured. V.I. Yoschenko \"et al.\" reported that grass and forest fires can make the caesium, strontium and plutonium become mobile in the air again.\n\nThe ongoing crisis at this site includes Spent Fuel Pools on the upper floors, exposed to the elements with complex MOX and plutonium products. The Japanese Government Taskforce has asked for submissions to the International Research Institute for Nuclear Decommissioning in regards to the ongoing Contaminated Water Issues.\n\nThere have been 18 incidences of theft or loss of highly enriched uranium (HEU) and plutonium confirmed by the IAEA.\n\nOne case exists of a German man who attempted to poison his ex-wife with plutonium stolen from WAK (Wiederaufbereitungsanlage Karlsruhe), a small scale reprocessing plant where he worked. He did not steal a large amount of plutonium, just rags used for wiping surfaces and a small amount of liquid waste. The man was sent to prison for his crime. At least two other people were contaminated by the plutonium. Two flats in Rhineland-Palatinate were also contaminated. These were later cleaned at a cost of two million euro.\n\nPlutonium like other actinides readily forms a dioxide plutonyl core (PuO). In the environment, this plutonyl core readily complexes with carbonate as well as other oxygen moieties (OH, NO, NO, and SO) to form charged complexes which can be readily mobile with low affinities to soil.\n\n\nPuO formed from neutralizing highly acidic nitric acid solutions tends to form polymeric PuO which is resistant to complexation. Plutonium also readily shifts valences between the +3, +4, +5 and +6 states. It is common for some fraction of plutonium in solution to exist in all of these states in equilibrium.\n\nPlutonium is known to bind to soil particles very strongly (see above for an X-ray spectroscopic study of plutonium in soil and concrete). While caesium has very different chemistry to the actinides, it is well known that both caesium and many of the actinides bind strongly to the minerals in soil. Hence it has been possible to use Cs labeled soil to study the migration of Pu and Cs is soils. It has been shown that colloidal transport processes control the migration of Cs (and will control the migration of Pu) in the soil at the Waste Isolation Pilot Plant according to R.D. Whicker and S.A. Ibrahim.\n\nMary Neu (at Los Alamos in the USA) has done some work which suggests that bacteria can accumulate plutonium because the iron transport systems used by the bacteria also function as plutonium transport systems.\n\nPlutonium ingested by or injected into humans is transported in the transferrin based iron(III) transport system and then is stored in the liver in the iron store (ferritin), after an exposure to plutonium it is important to rapidly inject the subject with a chelating agent such as calcium complex of DTPA. This antidote is useful for a single exposure such as that which would occur if a glove box worker were to cut his or her hand with a plutonium-contaminated object. The calcium complex has faster metal binding kinetics than the zinc complex but if the calcium complex is used for a long time it tends to remove important minerals from the person. The zinc complex is less able to cause these effects.\n\nPlutonium that is inhaled by humans lodges in the lungs and is slowly translocated to the lymph nodes. Inhaled plutonium has been shown to lead to lung cancer in experimental animals.\n"}
{"id": "49509083", "url": "https://en.wikipedia.org/wiki?curid=49509083", "title": "President's Malaria Initiative", "text": "President's Malaria Initiative\n\nThe President's Malaria Initiative (PMI) is a U.S. Government initiative to control and eliminate malaria, one of the leading global causes of premature death and disability. The initiative was originally launched by U.S. president George W. Bush in 2005, and has been continued by each successive U.S. president.\n\nPMI was originally created with a mission to \"reduce malaria-related mortality by 50 percent across 15 high-burden countries in sub-Saharan Africa\". PMI has since expanded to 24 malaria-endemic countries in sub-Saharan Africa and 3 additional countries in the Greater Mekong Subregion of Southeast Asia, where it seeks to further reduce malaria burden and assist countries in achieving malaria elimination. \n\nPMI works closely with national malaria programs and global partners including the World Health Organization, Roll Back Malaria, and Global Fund. Global malaria efforts, led largely part by PMI, have cut malaria mortality by over 60%, saved nearly 7 million lives, and prevented more than 1 billion malaria cases between 2000 and 2015. PMI currently supports malaria prevention and control for over 500 million at-risk people in Africa.\n\nThe \"U.S. Leadership Against HIV/AIDS, Tuberculosis, and Malaria Act of 2003\" originally authorized the U.S. Government to provide 5 years of malaria funding to bilateral partners and the Global Fund. PMI was subsequently launched by President George W. Bush in 2005. In 2008, PMI was reauthorized for another 5 years of funding by the \"Lantos-Hyde Act,\" which also called for development of a comprehensive U.S. Global Malaria Strategy, the latest version of which is the U.S. Global Malaria Strategy 2015-2020. PMI served as a major component of the Global Health Initiative, a six-year, $63-billion effort proposed by President Obama in May 2009.\n\nThe US Government, including through PMI, is currently the largest international source of financing for malaria. PMI's global budget for FY2017 was $723 million.\nPMI is interagency initiative overseen by the U.S. Global Malaria Coordinator in consultation with an Interagency Advisory Group composed of representatives from USAID, CDC, the Department of State, the Department of Defense, the National Security Council, and Office of Management and Budget. The initiative is led by USAID and implemented together with CDC. In addition to US-based staff at USAID and CDC headquarters, PMI maintains resident advisors from both agencies in each focus country.\n\nPMI currently provides direct support to 24 \"focus\" countries and 3 additional country programs in the Great Mekong Subregion. At the time of its launch in 2005, PMI provided support to just three countries: Angola, Tanzania, and Uganda. Four additional countries (Malawi, Mozambique, Rwanda, and Senegal) were added the following year. By 2007, PMI had added Benin, Ethiopia, Ghana, Kenya, Liberia, Madagascar, Mali, and Zambia—bringing the total number of focus countries to the originally envisioned total of 15 high-burden nations. \n\nIn 2010, PMI added the Democratic Republic of the Congo, Nigeria, Guinea, Zimbabwe, and the Mekong Subregion. \n\nIn 2017, with additional funding from Congress, PMI expanded to 5 more countries: Burkina Faso, Cameroon, Cote d'Ivoire, Niger, and Sierra Leone.\n\nPMI is estimated to have prevented 185 million malaria cases and nearly 1 million deaths between 2005 and 2017. Globally, malaria mortality fell by more than 60% between 2000 and 2015. The presence of a PMI program in a country has also been associated with a significant reduction in all-cause under-5 child mortality.\n\n\n"}
{"id": "52144340", "url": "https://en.wikipedia.org/wiki?curid=52144340", "title": "Quahog Parasite Unknown", "text": "Quahog Parasite Unknown\n\nThe quahog parasite unknown, or QPX, is a parasite in the protist kingdom. It affects hard clams, or quahogs, both cultured and wild.\n\nParasites similar to QPX were first observed in New Brunswick, Canada, in 1959. Outbreaks have also occurred in Nova Scotia, Prince Edward Island, New York, New Jersey, Massachusetts, and Virginia, always only in quahog clams. The life stages of thalli, endospores, and sporangia have been observed.\n\nQPX was originally considered a chytrid, but has now been provisionally assigned to the phylum Labyrinthulomycota in either the families Thraustochytriidae or Labyrinthulidae, based on the organism having a \"uninucleate biflagellate zoospore stage, a loose multilaminar cell wall, and particularly an intracellular sagenogen-like structure\". However, much about it is still unknown. QPX-like organisms also may not be all of the same species.\n\nSymptoms of QPX include chipping of the shells, mantle swelling, stunted shell growth and the development of nodules.\n"}
{"id": "26926602", "url": "https://en.wikipedia.org/wiki?curid=26926602", "title": "Robert McCarrison", "text": "Robert McCarrison\n\nMajor-General Sir Robert McCarrison, CIE, FRCP (15 March 1878 – 18 May 1960) was a Northern Ireland physician and nutritionist in the Indian Medical Service, who was made a Companion of the Indian Empire (CIE) in 1923, received a knighthood in July 1933, and was appointed as Honourable Physician to the King in 1935.\n\nMcCarrison was born in Portadown, in County Armagh, Northern Ireland. He qualified in Medicine at Queen's College, Belfast in 1900. He joined the Indian Medical Service and was posted as Medical Officer to Indian troops guarding the mountainous Northern Frontiers. He was promoted to Captain in January 1904, to Major in July 1912, Lieutenant-Colonel in January 1918, Colonel from 1929, and to Major-General in July 1933. He retired from the Indian Medical Service on 19 August 1935. McCarrison's research in India on the cause of goitre won widespread recognition and in 1913 he was promoted to do research. In 1928 he became Director of Nutritional Research in India, where he remained until his retirement from the Indian Medical Service in 1935, when he returned to England, settling at Oxford.\n\nMcCarrison carried out the very first experiments to demonstrate the effect of nutrition on the epidemiology of disease.\n\nMcCarrison is credited with being the first to experimentally demonstrate the effect of deficient dietaries upon animal tissues and organs. He also carried out human experiments aimed at identifying the cause of goitre, and included himself as one of the experimental subjects. Much of McCarrison's work was pioneering. His 1921 book \"Studies in Deficiency Disease\" was considered notable at the time, being published at a time when knowledge of vitamins and their role in nutrition was crystallizing. McCarrison himself noted that prior to publication of his studies on the pathogenesis of deficiency disease \"no systemic \"post-mortem\" examination of animals fed on food deficient in vitamin B had ever been made; the histopathological effects of such food on the various systems of the body were wholly unknown; above all, its effects on the gastro-intestinal tract and the organs of digestion and assimilation, and the significance of these effects for clinical medicine, were wholly unsuspected\".\n\nAt age 23, McCarrison went to India, where he spent 30 years on nutritional problems. He attained the rank of major-general in the Indian Medical Service, and founded the Nutritional Research Laboratories in Coonoor. After retiring from the Indian Medical Service in 1935, he gave a series of Cantor lectures at the Royal Society of Arts, about the influence of diet on health. This comprised three lectures delivered on successive Mondays at the Society. The first lecture focused on the processes of nutrition; the second, on food essentials and their relationship to bodily structure and function; the third on disease prevention and physique improvement by attention to diet. The lectures were subsequently published in book form under the title \"Nutrition and Health\", and at the time of the third edition in 1962, were still not seen as \"dated\", with the advances of the preceding 25 years largely filling the details of the principles previously recognised by McCarrison.\n\n\"McCarrison's work on goitre, cretinism, and thyroid, begun in the western Himalayas in 1902, generated scores of scientific publications during the following thirty-five years\", While McCarrison's work is often considered the start of serious studies of goitre and cretinism in South Asia, it was preceded by that of Commissioner David Scott at Rangur in north-east India around 1825, and was investigated by Mountford Bramley at Kathmandu in 1832.\n\nIn 1918, McCarrison founded the \"Beri-Beri Enquiry Unit\" in a single room laboratory at the Pasteur Institute in Conoor, India. He was invalided to Britain from 1920–1922, and in 1923 the enquiry was axed on financial grounds. It was restored two years later as the \"Deficiency Disease Inquiry\", which McCarrison headed from 1925-1929. Around 1928-29, this developed further into the Nutrition Research Laboratories (NRL. Renamed the National Institute of Nutrition in 1969), with McCarrison as its first Director, until his retirement in 1935. In 1926, as head of the \"Deficiency Diseases Inquiry\", McCarrison submitted written and oral evidence on malnutrition to the \"Royal Commission on Agriculture in India\". The primary objective of McCarrison's submission was to indicate the significance of malnutrition \"as a cause of physical inefficiency and ill-health among the massess in India\"; the relationship between nutrition and agriculture; and \"the necessity for closer co-ordination of nutritional, medical, veterinary and agricultural research\" in India. McCarrison's submission had impact. \"A decade later, when the Commission's chairman, Lord Linlithgow, became Viceroy of India he showed a personal interest in nutrition, pushing it to the top of the research agenda. In 1936 a Nutrition Advisory Committee was established and roughly a tenth of IRFA's annual grants went to fund nutrition research at Coonoor and Calcutta\".\n\nAfter the Second World War, from 1945 to 1955, McCarrison served as director of postgraduate medical education at Oxford University.\n\nIn 1906 he married Helen Stella Johnston, to whom he was still married at the time of his death.\n\n\nIn 1966, a group of doctors, dentists and veterinarians, interested in the promotion of nutrition and health, founded the McCarrison Society in honour of his efforts, with a Scottish group established in 1981 due to both travel logistics and differing needs in the Scottish population.\n\nThe Society aims \"to assemble scientific knowledge on nutrition and health that is free from economic and political pressures with the object of securing the physical and mental health of future generations\". The Society meetings sometimes raise questions with elusive answers, with speakers presenting material based on scanty, often anectdotal data, inviting criticism that it is \"a gathering of cranks\". However, \"one answer to that criticism is that speakers at MCarrison meetings tend to be rather well qualified. But the main point is that the society has a way of asking questions about the environment - what are we doing to it and what it is doing to us - that are of profound importance\".\n\nThe Society's website summarises McCarrison's work thus:\n\nHis researches were extensive; they included work on the newly discovered vitamins and on the contrasting disease patterns in the Indian subcontinent. He demonstrated how many common diseases increasingly prevalent in industrial societies were caused simply by diets made defective by extensive food processing, often with the use of chemical additives. He deplored the universal consumption in Britain and America of refined white flour, instead of halite flour, and the substitution of canned, preserved and artificially sweetened products for fresh natural food.\n\nMcCarrison's work was widely published in the medical press. He was honoured for his discoveries, but completely ignored by government and the medical profession at a time when medical thought was absorbed in the study of disease rather than on prevention and the promotion of health.\n\nThe following is a selection of works published by McCarrison. To avoid duplication, this does not include works cited, which are to be found in the References section.\n\nThe following works discuss aspects of the life and work of Robert McCarrison.\n\na. The bulk of McCarrison's work appears to have been published in the \"British Medical Journal\" (BMJ), although he did publish in other journals, such as \"JAMA\" and \"The Lancet\", amongst others. Some publications are also found in the \"Proceedings of the Royal Society of Medicine\". Free access to publications \"BMJ\" and the \"Proceedings\" is to be found in the external links section. Some of McCarrison's publications listed are from those journals, but links were not located at time of listing. They should however, be available at these websites, along with other publications by or about McCarrison from those two journals which have not been located or listed.\n\nb. This letter is by the \"nominal overseer\" of McCarrison's last salaried post. It contains particularly insightful commentary on the contribution of McCarrison at a time of significant change in the existing university and medical institutions of the UK.\n\nc. The author of this obituary letter on McCarrison is identified only as \"N.C.P.\", which are also the initials of N.C. Penrose, author of a 1951 letter defending the legacy of McCarrison's earlier works.\n\nd. A book review of the 1953 edition is cited in this article, hence the listing. However, there have been other publications of this book both before and since. A publication from 1944 (\"Nutrition and National Health\") is to be found via web searches comprising the same lecture and essay collection. And publications in 1961 and 1982, under \"Nutrition and Health\", are also to be found. A new edition was produced in 2010, and may found at Lulu, a Print on Demand / Self-Publishing service.\n"}
{"id": "37706541", "url": "https://en.wikipedia.org/wiki?curid=37706541", "title": "Ruben Papian", "text": "Ruben Papian\n\nRuben Papian (born June 6, 1962 in Yerevan, Armenia) is an esotericist and para-scientist specializing in subjects such as metaphysics and parapsychology. He is best known as an energy healer and a developer and teacher of unique self-improvement methods.\n\nRuben Papian was born in Yerevan, Armenia. As a very young boy, Ruben heard stories about the existence of UFO’s and life outside our planet. It was a shock for him. After this, his affection towards paranormal sciences and exploration began to grow. This made him different from other children. Not only because of his interests, but also because he was a fast learner and could communicate and socialize with people who were much older than him. This influenced his further growth.\n\nIn Armenia, Ruben attended the Yerevan State University of Architecture and Construction. In addition to this he was also interested in painting and music. His musical career began when he was 12 years old. Ruben is the founder, leader and singer of a student rock band called Oleess that projects progressive ideas.\n\nA turning point of his life was when his mother was diagnosed with a serious illness. Ruben could not do anything to help her – at the time he was only 18. One day an energy healer came to their family house to help cure the disease. Ruben saw him standing in front of her waving his hands. “I’ve never seen anything like that before. He was treating my mother with no medicine or medical equipment. The only thing he had were – his hands”.\n\nWhen the energy healer finished, Ruben expressed a wish to learn everything about the method he was using. The healer gave him a book called “Caucasian Yoga” by Count Stefan Colonna Walewski. It was hand-written in Russian and was the first step in Ruben’s self-tutoring. With this book came an understanding of human energy and a glance at the possibilities that he had within himself.\n\n“When I was 16, I started noticing human pain. I don’t know how to explain it, but I knew if this or that person was sick. I could even see the exact place of the pain.” \nWith “Caucasian Yoga” he started learning energy healing and this profession played an important role in his later life.\n\nIn 1987 Ruben was invited to go to Moscow. His energy healing abilities were highly appreciated by Soviet Union State Department officials. During the time he spent in Moscow, his energy method increased in both quality and efficiency in the area of anatomy, the nervous system and mind functions. He came to the conclusion that the main key to solving health problems lay in the mind. He developed a method called “Mental Correction and Communication”.\n\nIn 1988 he was invited to come to Yugoslavia to solve a certain health problem. After a few visits, in 1990 he decided to move to Belgrade, Yugoslavia with his family and formed a “Center for Alternative Healing” where he performed personal and group treatments using his method “Mental Correction and Communication”. By 1993 his knowledge had become enriched and he began to understand human complexity. It led to the formation of the association for personal harmonic development “The Golden Step”.\n\nIn 1994 the Ministry of Education, Culture and Science in the Netherlands involved him in a project called “The theory and methodology of finding and developing the talents of gifted children”. \n\nFrom 1998 to 2005 the name Ruben Papian became well-known worldwide. \nIn 2005 Ruben developed “The Golden Step” into the first “Institute of Esotery and Parapsychology Ruben Papian” in Belgrade, Yugoslavia. The Institute offered educational programs such as Energy Therapy Healing, Mental Correction and Communication and Harmonic Personal Development.\n\nIn 2004 in the Netherlands Ruben developed a construction called “The Energy Pyramid”. Ever since he started researching cosmic energies, he had become interested in pyramids, the way they function and affect the human organism. In a short time he developed an energy flow concept and understood the basis of the mystical powers of those large monuments that could be found anywhere in the world.\n\nIn 2008 Ruben produced an Armenian movie called “Welcome Papa”.\n\nSince 2010 he has been Senior Advisor of the International competition. Challenge:Future is an international youth think tank and competition that connects corporate and global challenges with the power of youth-driven innovation based on sustainability principles. It’s a place where you can put your creativity to the test and collaborate with others to prove yourself and win amazing awards.\n\nAt the very start of 2011, the “Institute of Esotery and Parapsychology Ruben Papian” in Belgrade, Serbia became the “SFERA movement”. Thanks to his great success and to the people who were interested in his unique training methods, Ruben opened another “SFERA movement” in Kazakhstan, Almaty in December 2011.\n\nIn 2011 he wrote his first book, \"How to Wish\". This book is in the first part of a transformational series called “The Books of Essence”. The book was published in June 2013.\n\n"}
{"id": "36775513", "url": "https://en.wikipedia.org/wiki?curid=36775513", "title": "Saal Greenstein syndrome", "text": "Saal Greenstein syndrome\n\nSaal Greenstein syndrome is a very rare autosomal recessive genetic disorder characterized by stunted growth, short limbs, microcephaly, and an anomalous cleavage of the anterior chamber of the eye. The disorder is similar to Robinow syndrome except for anterior chamber anomalies and, in one case, hydrocephalus.\n"}
{"id": "1393392", "url": "https://en.wikipedia.org/wiki?curid=1393392", "title": "Savage Dragon", "text": "Savage Dragon\n\nSavage Dragon is an ongoing American comic book series created by Erik Larsen, published by Image Comics and taking place in the Image Universe. The comic features the adventures of a superheroic police officer named the Dragon. The character first appeared as Dragon in \"Graphic Fantasy\" #1 (June 1982) and first appeared as the \"Savage Dragon\" in \"Megaton\" #3 (February 1986).\n\nThe Dragon is a large, finned, green-skinned humanoid whose powers include super-strength and an advanced healing factor. He is also an amnesiac: his earliest memory is awakening in a burning field in Chicago, Illinois. Thus, for most of the series, the origins of his powers and appearance are a mystery to readers. At the beginning of the series, he becomes a police officer and battles the mutant criminal \"superfreaks\" that terrorize Chicago.\n\n\"Savage Dragon\" is one of only two Image Comics titles that debuted during the company's 1992 launch that continues to be published well into the late 2010s, and the only one of the two that for most of its run, has been written and drawn almost entirely by its creator (with the exception of one issue), for which Larsen has been lauded. \"Savage Dragon\" is the longest running American full-color comic book to feature a single artist/writer. The character was also adapted into an animated series, which ran for two seasons (26 episodes) on the USA Network beginning in 1995.\n\nSavage Dragon was listed by \"Wizard\" as the 116th-greatest comic book characters of all time. IGN also listed Savage Dragon as the 95th-greatest comic book hero of all time stating that he has the trappings of a great comic book hero.\n\nLike many of Erik Larsen's characters, the Savage Dragon was created by Larsen while he was a child in elementary school. In his youth, Larsen drew the Dragon in homemade comic books. The original Dragon, inspired by elements from Captain Marvel, Batman, Speed Racer and later The Incredible Hulk, differs greatly from the modern incarnation. After launching \"Savage Dragon\" in a professionally published comic book, Larsen returned to the original and reworked his designs into the characters William Jonson, a police officer ally of the Dragon, and Flash Mercury, the \"Spectacular Dragon\".\n\nMuch later, a greatly redesigned \"Savage Dragon\" was featured in two issues of \"Graphic Fantasy\", a self-published title with a small print run, published by Larsen and two friends. In this incarnation, the Dragon was a widower and a retired member of a government-sponsored superhero team. Subsequently, the Dragon made another appearance in the third issue of Gary Carlson's \"Megaton\" anthology in its \"Vanguard\" strip, which Larsen had been drawing. In these appearances, the character of the Dragon remained basically the same as it had been in \"Graphic Fantasy\", with a few details modified (such as the inclusion of his wife, who was dead in his previous incarnation). Both the \"Graphic Fantasy\" and \"Megaton\" issues containing the Dragon have since been reprinted in high-quality editions.\n\nIn 1992, when Larsen left Marvel to co-found Image Comics, he reworked the character for the new publication venture. This time, the Dragon was a massively muscled green amnesiac, who joined the Chicago police department after being discovered in a burning field. Initially debuting in a three-issue mini-series, the \"Savage Dragon\" comic book met with enough success to justify a monthly series, launched in 1993. To this day, Larsen continues to write and illustrate the series entirely by himself, and has maintained a reasonably consistent monthly schedule (save for occasional lapses) in comparison with the other original Image Comics titles. Larsen has occasionally produced ancillary mini-series, and sometimes allowed other creators to produce stories featuring the Dragon or other characters from the series.\n\nAccording to Larsen, the series is aimed at \"older Marvel readers who are about ready to throw in the towel on comics altogether. It's the missing link between Marvel and Vertigo. More mature than Marvel; less pretentious than Vertigo. The kind of comics [he wants] to read. [The] book is really self-indulgent.\"\n\nFor the initial mini-series and the first 38 issues of the ongoing series, the Dragon was a full officer of the Chicago Police Department, and partnered with officer Alex Wilde. Dragon and Wilde would later have a casual sexual relationship. He received the name of \"Dragon\" (due to his fin and green skin) from Nurse Ann Stevens, who would later become a supporting character in \"Mighty Man\".\n\nThe Dragon was found in a burning field by Lt. Frank Darling. At the time, Chicago was being terrorized by villainous \"superfreaks\" (Larsen's collective term for superpowered characters), namely the criminal gang called the Vicious Circle, led by the mysterious Overlord. Realizing that the Dragon's superhuman powers would be a terrific boon to the police in battling the Vicious Circle, Darling asks the Dragon to join the police. At first, the Dragon refuses and takes a job in the warehouse of Darling's cousin. After a number of serious incidents, including the murder of the superhero Mighty Man and the brutal mauling of SuperPatriot, Darling takes drastic action. He pays Vicious Circle members to threaten his cousin in the hope that it will prompt Dragon to re-consider his offer. Although this achieves Darling's desired result, the two criminals, Skullface and Hardware, kill Darling's cousin and detonate a bomb in his warehouse. The Dragon joins the police, but Darling is now under the thumb of the Vicious Circle, causing him to steer the Dragon away from Vicious Circle activities.\n\nLater, the Dragon gains a girlfriend, Debbie Harris, only to see her shot dead in his apartment by her jealous ex-boyfriend Arnold Dimple. The Dragon falls into a deep depression as a result. Dimple returns to plague the Dragon on several occasions as the Fiend, who makes a deal with the Devil to gain supernatural powers.\n\nAs well as being kept away from Vicious Circle activities, the Dragon was loaned out to other police forces across the country to help them in dealing with superpowered criminals. While on loan to the NYPD, he first met the Teenage Mutant Ninja Turtles, whom he assisted multiple times in later comics. Also during his time in New York, a large prison break occurred and a number of powerful and dangerous criminals were killed. This is the first time the Chicago PD lost a star witness against Overlord; Hardware, who intended to give evidence against the criminal, was shot dead.\n\nThough Captain Darling's Freak Force program failed, the Dragon carried on a lasting relationship with one of its former members: Rapture, a former prostitute with electrical powers, who would later have his child. Meanwhile, Overlord's second-in-command Cyberface broke away from the Vicious Circle to form a rival organization. Cyberface was later arrested but, like Hardware before him, he was killed before he was able to testify. Ultimately Cyberface was resurrected and later led the Vicious Circle under the control of Horde, another recurring villain.\n\nLater, the Dragon made his first attempt to arrest the Overlord, who easily defeated him and left him impaled upon a church spire. The Dragon was believed to be dead but regenerated from his wounds afterwards. This is not the only time the Dragon was missing and presumed dead; it becomes both a recurring theme and running joke in the series. During his recovery, Dragon was attacked by a person under the mental control of a strange worm. Under the domination of this creature, the Dragon went on a rampage during which many innocent bystanders are injured or killed. He was finally stopped by the vigilante Mace, and the worms were traced to Horde. The rampage resulted in a massive negative backlash against the Chicago Police Department, and the Dragon's biggest naysayer, R. Richard Richards, took this opportunity to attack the Dragon with a robotic weapon dubbed \"Dragon Slayer\". Later, the Dragon encountered the She-Dragon, a young superpowered woman who modeled herself after him.\n\nFollowing an attack on the police station and the murder of Cyberface (who is later resurrected), the Dragon led a SWAT team to finally take down the Overlord. The battle was harsh, and every member of the SWAT team perished except for the Dragon, who was skinned alive. Even in his weakened state, the Dragon finally unmasked the Overlord as mafia boss Antonio Seghetti, who subsequently falls to his death.\n\nAfter aiding the Teenage Mutant Ninja Turtles for a second time, the Dragon narrowly survived another attack by the Fiend, which left him nearly crippled after his bones healed incorrectly. To make matters worse, Chicago was in the midst of a brutal gang war that arose as a result of the Overlord's death. The Vicious Circle, once kept tightly organized by the Overlord, had since separated into several factions that were battling for criminal supremacy. The Dragon was found by a friendly cabbie and Mighty Man, who used his super-strength to re-set the Dragon's bones. After recuperating from this ordeal, the Dragon fought another prison break, this time in a maximum security facility torn open by a newly-resurrected Cyberface. This battle marked the end of the gang war, and Cyberface assumed command of the Vicious Circle.\n\nThis victory was followed by difficult times for the Dragon. After a number of crossovers with other Image Comics characters including WildStar and The Maxx, the Dragon encountered Spawn and ultimately was sent to Hell by the Fiend. The Fiend can possess living bodies, and his powers are fuelled by the capacity for hate of those possessed. His last victim was Debbie Harris' mother, who was unaware that the demon possessing her was the spirit of her daughter's murderer. While in Hell, a fist-fight occurred between God and the Devil. As God finally overcomes the Devil, he warned his defeated opponent: \"Don't fuck with God.\" Just as the amnesiac Dragon begins to ask about his origins, God returned him to Earth.\n\nAfterward, things grow steadily worse for the Dragon. He was unable to save ill fellow officer Phil Dirt with a blood transfusion. Meanwhile, Rapture (pregnant with the Dragon's child) suffered internal damage when the baby kicked—the unborn child having inherited its father's strength—and Rapture entered premature labour. The Dragon was not able to reach the hospital in time, and the baby appeared to have died. However, in truth, the infant was taken by the Covenant of the Sword, a shadowy organization bent on world takeover.\n\nAfter a crossover with Hellboy, the Dragon was caught up in the \"Mars Attacks\" (Image) and \"Mars Attacks/Savage Dragon\" event, in which he was responsible for destroying the Martians' bases on Mars using a Martian growth ray. This resulted in their retreat and possible extinction. While he was gone, the Vicious Circle had taken control of the city. Returning home to a devastated Chicago, the Dragon was captured and publicly crucified by the Circle. The Dragon survived and defeated most of the villains, but the Dragon's new superior, Captain Mendoza, suspended him for having been missing for so long. During his suspension, the Dragon spent a few months as a bounty hunter and helped rebuild the city after the Martian invasion.\n\nBehind the scenes during this period, Rob Liefeld departed from Image Comics. The \"Mars Attacks Image\" event and the \"Shattered Image\" crossover were used as a way to phase out characters created by Liefeld from the collective \"Image Universe\", including Youngblood. In the pages of the \"Savage Dragon\", Larsen has the Dragon approached by the United States government to form a superhuman task-force to replace Youngblood. After negotiations, the team is dubbed the Special Operations Strikeforce, or S.O.S. This team includes much of the super-powered supporting cast of the book, including Jennifer Murphy, a super-strong, invulnerable single mother first introduced in \"\" mini-series. Despite being the founding member of the team, the Dragon spends little time as a member.\n\nLater, on a dying parallel Earth, a murderous despot named Darklord begins to swap parts of his Earth with parts from the Dragon's. The Dragon leads a team of S.O.S. members, including Jennifer Murphy and his former girlfriend Rapture, to this world to stop Darklord. Rapture is killed by Darklord, and the Dragon and Jennifer are separated from the rest of the team. While the remaining members of S.O.S. manage to stop the transfer and escape back to their own Earth, the Dragon and Jennifer are forced to find their own way off of the dying planet. While they make their escape, Dragon attempts to find this Earth's Rapture, only to find that world's Debbie Harris instead.\n\nThe threesome is lost in space for some months, and Dragon is once again presumed dead, eventually landing on Godworld, where Debbie dies but is revived as an angel. Dragon and Jennifer are caught in a battle between Thor and Hercules, and then sent back to Earth by All-God; Debbie does not return with them. Following this, Dragon fights a Dr. Doom-like armored dictator before returning to Chicago on leave and striking up a casual sexual relationship with his former partner Alex Wilde.\n\nIn giant-sized issue 50, many of the series subplots are resolved, and in a climactic battle among most of the series cast, the Dragon is killed by the mystic Abner Cadaver; however, the wizard is murdered midway through this by William Jonson, and the Dragon is bonded with him.\n\nThe series changed its title to \"Savage She-Dragon\" for five issues, featuring her as the main character during an attack by The God Squad to retrieve the various super-freaks that were descendants of gods. This led to the S.O.S. returning to Godworld and its accidental destruction by S.O.S. member and former Deadly Duo member Kid Avenger. During this time, William Jonson realizes he and the Dragon are sharing bodies, and shortly thereafter Dragon finds he has the ability to take over Jonson's body, so they become a masked superhero. While he is helping She-Dragon, Jonson's fiancé, Rita Medermade, is kidnapped by Jonson's brother Ralph and they both encounter an individual wearing the Overlord armor. While rescuing her, Jonson is shot, Ralph is killed by Overlord, and Dragon is given full possession of his body.\n\nAbner Cadaver returns—made up of parts of dead God Squad characters, Darklord, and Dragon's arm—and engages in battle with Fon~Ti, the mystical being who was once Horde. After Fon~Ti’s victory, he separates the Dragon from Jonson and returns the Dragon to his normal body. Having admitted their love, Jennifer and Dragon begin to date. After a fight with Impostor, posing as Rapture, Dragon proposes to Jennifer, and their wedding follows in the next issue, in which Jennifer is apparently killed by the new Overlord. In truth, she was replaced with Impostor beforehand by the Covenant of the Sword. Though he had only been semi-active before, the Dragon officially resigns from the S.O.S. and became the legal guardian of Jennifer's daughter Angel. In the following issue, the Overlord subplot is tied up after the Dragon defeats his new team. The Dragon kills Overlord, and he is revealed as supporting character Vic Nixon, who had worn the armor to spy on Rita; the armor then corrupted him. After this, the Overlord armor is destroyed.\n\nFollowing the resolution of the new Overlord plot, the series spent most of its issues wrapping up all the remaining subplots. This was preparation for the eventual revamp in issue #75, with the Dragon as a single parent looking after Angel and eventually losing a custody battle for her because of his dangerous lifestyle. The Dragon dated a television producer named Marcy Howard, resumed his casual affair with Alex Wilde, and dated Ann Stevens before she is murdered, while a number of super-powered children and adults were kidnapped by the Covenant of the Sword.\n\nAfter losing custody of Angel and Ann's murder, the Dragon and Mighty Man (now former Freak Force member Dart) began searching for the missing SuperPatriot. This led them to the Covenant of the Sword, which had in its possession SuperPatriot, Jennifer, and the Dragon's child. The Dragon and Mighty Man are captured but eventually rescued in a large battle similar to the one in issue #50 in which a number of characters are killed.\n\nIt was revealed that the Covenant was formed by Damian Darklord, a time traveler who was the enemy of a vigilante named Super-Tough. This man became Darklord and started life as Damian, the son of Liberty, SuperPatriot’s daughter who was raped during the \"Mars Attacks\" event. Damian also built and detonated the \"Nega Bomb\" made up of super-powered individuals that de-powered every non-natural \"freak\" in the world. The Dragon then kills him.\n\nWith issue #76, the series changed into a Jack Kirby-inspired post-apocalyptic/dystopian story. The Dragon is stuck in a new reality he created by killing the infant Damian Darklord, which prevented him from going back in time, and with most of the mutated and monstrous populace of this world trying to kill him. The Dragon finds his house to be a crater and believes Jennifer and Angel are dead. The Dragon has encounters with WildStar (Image Comics) and Madman and finds out that during his time possessed, without Mace to stop him, he went on a much longer rampage, killing Alex Wilde. The Dragon also discovers that Cyberface is now president of America and has SuperPatriot under his control. The Dragon organizes a group of old enemies and allies to defeat Cyberface. After fulfilling a commitment to Rex Dexter—who helped him overthrow Cyberface—by saving his daughter, the Dragon returns a hero and finds his way back to Chicago and is reunited with Jennifer and Angel, who had in fact survived.\n\nThe Dragon then finds his old world had survived as well as the Savage World. His counterpart from Darkworld, this Dragon, was defeated, but the Dragon's old Earth was destroyed by a world-devouring Galactus-like being named Universo, despite the best efforts of the Dragon and his son, Malcolm, who are left floating in space after its destruction. The Dragon is able to save Alex Wilde from that world. After this, the Dragon marries Jennifer and lives with her, Angel, and Angel’s new \"pet\", Mr. Glum, who is secretly plotting to kill Dragon.\n\nTo coincide with the 2004 U.S. presidential election, Larsen created a corrupt politician Ronald Winston Urass, who engineers a successful write-in campaign to elect the Dragon president of the United States. However, once his criminal intents and relationship to the criminal Dread Knight are exposed, the Supreme Court disallows these votes. This leads a vengeful Urass to attack the Dragon using the armor of his father, Dread Knight, who was an old foe of SuperPatriot's.\n\nBehind the scenes, Erik Larsen was made publisher of Image Comics, causing a nearly year-long publishing gap between issues #121 and #122 of the series. The title resumed regular publication in January 2006, with the first story involving a vengeful scientist from Iraq sending an almost unstoppable robot to kill the president.\n\nMr. Glum's plans for world domination were realized using the power of the God Gun (a weapon able to grant three wishes to its user). Glum fires the gun and asserts his control of the planet while the Dragon is incapacitated in a hospital, having lost his rapid healing abilities. Glum was, at the time, on the run with the Dragon's stepdaughter Angel after he caused her to grow to more than 100 feet tall, and she accidentally destroyed her house and crippled her mother. The two become partners and Angel adopts a murderous, merciless personality, while Glum set the people of Earth to work with the impossible task of making the planet look like his face (as his old world did).\n\nThe Dragon is revived with his healing abilities restored and is able to defy Glum's control because of a loophole in his wish that means he cannot control extraterrestrials. The Dragon is unable to get close enough to Glum due to the various robots and villains Glum has under his control. However, the intervention of a number of characters from the comic series \"Wanted\", who had come to steal the God Gun, allows Dragon to destroy the weapon, negating Glum's wish.\n\nDuring the story, Vanguard's spaceship is destroyed, freeing Universo who was imprisoned on it. He begins to suck the energy from Earth once more. Universo and its herald are killed by Solar Man, a Superman-like hero who became murderous and was wished out of existence using the God Gun, a wish undone by the Dragon's destruction of the weapon. She-Dragon also returns from Dimension X with the Angel from the Dragon's original world of origin. They are being pursued by the Darkworld Dragon and a new villainess Battleaxe.\n\nAfter Angel and Malcolm's return to the \"new world\", Savage Dragon is left to face a new array of troubles. With Jennifer having disappeared and presumed dead, two superstrong kids ill-equipped to face the return to normalcy after months spent in isolation (Angel has learning deficits and Malcolm is nearly illiterate), and no income to care for his family, Savage Dragon returns to the police force.\n\nMeanwhile, a new Overlord takes over the Vicious Circle, resuming his attacks over the city, and Savage, hospitalized after a fight, is ambushed and killed by a new \"freak\" with the power to steal the memories and the lifeforce of his enemies. Due to the huge amount of lifeforce held by Dragon and his powerful immune system, the freak absorbs all of his memories and physical characteristic, becoming essentially a new iteration of the Dragon. The \"Impostor Dragon\" has the remains of his former body packed in a preservative solution by Rex, and resumes his normal life.\n\nEven this new lease at life appears to be short-lived, as the New Overlord, after trying to bargain with Savage Dragon for his allegiance, literally blows his head and torso away: the \"Impostor Dragon\", brought in the Vicious Circle laboratories for analysis, revives himself as a crazed, unstoppable, deformed powerhouse with conflicting memories, bent on nourishing himself on the superpowered Angel and Malcolm.\n\nStill knowing nothing about the actions of the \"Impostor Dragon\", Angel and Malcolm seek a way to revive the body of Savage Dragon, despite being faced by Rex with the prospect of creating nothing more than a soulless being or a mind-addled monstrosity, due to the brain matter lost during the attack. They set off to ask Nurse Stevens for the last blood sample of Dragon, hoping to use its regenerative abilities to speed up the recovery and the resurrection of the Savage Dragon corpse. The Vicious Circle, however, overpowers them, stealing the blood sample to create an army of Dragon clones.\n\nAs a last resort, after being faced by the \"Impostor Dragon\" who attacks Rex and is frozen in the preservative solution, Rex and Malcolm agree to transfuse part of Malcolm's blood into the Dragon corpse. The Dragon revives but has no memories of his former life.\n\nConcerned about the new, harder attitude of the Dragon, the New Overlord sends the Dark Dragon after the Savage Dragon. Showing a callous disregard for human life, the Savage Dragon ultimately reveals to have regained every shred of his past memory as Kurr the Emperor (see above), and after beating up the Dark Dragon, he eats his brains, killing him for his defiance.\n\nHe then proceeds to alienate from himself Malcolm, planning vengeance over the Vicious Circle, now using Dragon's blood to empower his members. The New Overlord decides to strike a truce with the police department as seen in #159. He lends the help of all the superfreaks in his command to stop Kurr. As the last attempt fails, Kurr sheds his facade, proclaiming his identity and retelling his origins (see below), for the first time in-universe speaking, to Malcolm and Angel. Battling his way through several enemies, including Vanguard, an unnamed Shapeshifter taking She-Dragon's appearance, Glum, the \"original\" Angel, and other friends and foes from his past, Kurr cleanses Earth of human life using a special venom.\n\nAfter he battles and kills Malcolm, the Impostor Dragon wakes up, this time with Savage Dragon's personality fully in charge, and avenges his offspring and world by killing the Kurr-Dragon. Damian Overlord proceeds to restore his original look and body, giving Savage Dragon the opportunity to greet his species and leave the cleansed Earth in their care.\n\nDistraught by the consequences of Kurr's actions, he pleads with Damian Overlord for the power to travel back in time and kill Kurr before he unleashes the potion, thus creating another divergent timeline where his family is still alive. Damian grants his wish, mercilessly killing him shortly thereafter as \"Savage Dragon is a dangerous wildcard for the world\". Despite a red herring implying Damian transplanted Savage's personality into WildStar's body, in the \"restored\" timeline Kurr's alien son, along with a \"mysterious gentleman\", takes away Virus' corpse (as he's now calling the Impostor Dragon), taking it on to his spaceship, where Virus and Kurr are used to return Savage Dragon to life. Savage Dragon decides to keep his resurrection hidden to Earthlings, and to make amends with his species, offers to help them to find a suitable planet.\n\nAfter the Dragon Wars, Malcolm Dragon has taken Savage Dragon's role, along with his sister Angel, acting as protectors of the city. A schism in the superfreaks has brought Overlord working with the police department, with a part of the freaks still engaging in villainy, and Malcolm to keep them in check.\n\nSavage Dragon's origin was revealed in the \"Image Comics 10th Anniversary\" hardcover book, which was released on November 30, 2005. The collection featured stories by the four remaining Image founders (Erik Larsen, Todd McFarlane, Marc Silvestri, and Jim Valentino) returning to the characters they first created for the company. Larsen's story revealed that the Dragon used to be an evil tyrant named Emperor Kurr, who led a nomadic race of space aliens who spent thousands of years traveling through space, searching for a suitable new homeworld. After Kurr had chosen Earth, he decided to go against his people's peaceful ways and slaughter all humans. Two scientists named Rech and Weiko conspired against him, giving him brain damage that erased his memory, and implanted within his memories five days' worth of satellite television broadcasts from Earth. Kurr was then sent to live on Earth, while his race moved on to search for a new planet elsewhere.\n\n\n\nIn 1995, the Savage Dragon appeared in \"The Savage Dragon\", an animated television series as part of the Cartoon Express on the USA Network. Produced by Universal Cartoon Studios, it ran for 26 episodes from 1995 to 1996 and featured numerous supporting characters from the comic book series, including She-Dragon, Horde, Barbaric, Mako and Overlord. The Dragon was voiced by Jim Cummings. Additional voices were provided by Mark Hamill, Michael Dorn, Jennifer Hale, René Auberjonois, Frank Welker, Dawnn Lewis, Paul Eiding, Peter Cullen, Rob Paulsen, Robert Ito and Tony Jay.\n\nEpisode 21 of \"The Savage Dragon\", \"Endgame\", served as the second part of a four-part crossover with three other shows in USA's \"Action Extreme Team\" programming block: \"Street Fighter\", \"\", and \"Wing Commander Academy\".\n\nSavage Dragon was listed by \"Wizard\" as the 116th-greatest comic book characters of all time. IGN also listed Savage Dragon as the 95th-greatest comic book hero of all time.\n\n"}
{"id": "40773141", "url": "https://en.wikipedia.org/wiki?curid=40773141", "title": "Seven ill years", "text": "Seven ill years\n\nThe seven ill years was a period of national famine in Scotland in the 1690s. It resulted from an economic slump created by French protectionism and changes in the Scottish cattle trade, followed by four years of failed harvests (1695, 1696 and 1698–99). The result was severe famine and depopulation, particularly in the north. The famines of the 1690s were seen as particularly severe, partly because famine had become relatively rare in the second half of the seventeenth century, with only one year of dearth (in 1674). The shortages of the 1690s would be the last of their kind.\n\nDuring this period, starvation probably killed 5–15 per cent of the Scottish population, but in areas like Aberdeenshire death rates reached 25 per cent. The system of the Old Scottish Poor Law was overwhelmed by the scale of the crisis, although provision in the urban centres of the burghs was probably better than in the countryside. It led to migration between parishes and emigration to England, Europe, the Americas and particularly Ireland. The crisis resulted in the setting up of the Bank of Scotland and the Company of Scotland Trading to Africa and the Indies. The eventual failure of the Company in the Darién scheme increased the pressure for political union with England, which occurred in 1707.\n\nBefore the seventeenth century, with difficult terrain, poor roads and methods of transport, there was little trade between different areas of Scotland. Most settlements depended for subsistence on what was produced locally, often with very little in reserve in bad years. Most farming was based on the lowland fermtoun or highland baile, settlements of a handful of families that jointly farmed an area notionally suitable for two or three plough teams. These were allocated in run rigs, of \"runs\" (furrows) and \"rigs\" (ridges), to tenant farmers. Those with property rights included husbandmen, lesser landholders and free tenants. Below them were the cottars, who often shared rights to common pasture, occupied small portions of land and participated in joint farming as hired labour. Farms also might have grassmen, who had rights only to grazing. There were also large numbers of casual wage labourers who carried out basic agricultural work. Labourers on fixed incomes, along with pensioners, were particularly vulnerable to the impact of famine, but it also affected those with land, who could not save enough seed for future planting and feed their families. Even pastoral farmers were affected as the price of animal feed became unaffordable.\n\nThe closing decade of the seventeenth century saw the generally favourable economic conditions that had dominated since the Restoration of the monarchy in 1660, come to an end. There was a slump in trade with the Baltic and France from 1689–91, caused by French protectionism and changes in the Scottish cattle trade. These were followed by four years of failed harvests (1695, 1696 and 1698–99). The period is named after the Biblical famine in Egypt predicted by Joseph in the Book of Genesis. The famine was evident for five years nationally and was present for less time in some regions. However, there is evidence that the harvest failures from 1685 followed years of relatively poor harvests from the 1680s and that the impact of poor harvests did not entirely subside until after 1700. The 1690s marked the lowest point of the Little Ice Age, of colder and wetter weather. This reduced the altitude at which crops could be grown and shortened the growing season by up to two months in extreme years, as it did in the 1690s. The massive eruptions of volcanoes at Hekla in Iceland (1693) and Serua (1693) and Aboina (1694) in Indonesia may also have polluted the atmosphere and filtered out significant amounts of sunlight.\n\nThe results of the climatic conditions were inflation, severe famine and depopulation, particularly in the north of the country. The price of oatmeal, the stable Scottish cereal crop, peaked in Aberdeen in 1698, which was particularly badly hit because of its reliance on the Baltic trade, at 166.7 per cent of average prices for 1690–94. Individuals were reduced to eating grass, nettles and rotten meat in order to survive. There is considerable eye-witness material indicating that large numbers of people died from starvation. In 1698 local tacksmen claimed that during the period 1695–97 \"many people were starved to death for want, both in town and country\" and in 1698 reports reached Edinburgh of people found dead on the roads throughout the country. Overall deaths from starvation were 5 to 15 per cent, but in areas like Aberdeenshire they reached 25 per cent. The young, the old and widows were particularly vulnerable.\n\nThe famines led to a rapid increase in the number of paupers and vagrants taking to the roads to find work, charity and food. In 1698, Andrew Fletcher of Saltoun (1655–1716) estimated that perhaps one-sixth of the population of Scotland, about 200,000 people, had left their homes to beg for food and charity, a doubling of the 100,000 vagrants that he estimated travelled the country during non-crisis years. Much of this movement was within large parishes, which allowed families to continue to receive the poor relief that was officially confined to local residents. However, many of these families later moved further afield to major urban centres and to other countries, particularly England and Ireland. So many poor beggars arrived in Edinburgh in search of relief in December 1696 that the town council had to erect a \"refugee camp\" in Greyfriars kirkyard to house all of them. Other towns reacted by enforcing severe punishments for beggars.\n\nThe system of the Old Scottish Poor Law was overwhelmed by the scale of the crisis. In the countryside, where the majority of the population lived, it relied on funds raised and distributed by the kirk session, usually led by the parish minister and reliant on the generosity of local landholders, particularly the local laird. The role of the minister was undermined by the results of the change of regime in the Glorious Revolution in Scotland, which meant that many episcopalian ministers had been ejected from their livings and had not been replaced by the time of the famines. In the urban settlements of the burghs there were more mechanisms that could be used to provide for the poor. In addition to the kirk sessions and general sessions of the church, there were guilds, trades' societies and town councils. Town councils also had the ability to intervene in local grain markets in an attempt to maintain low prices in times of scarcity. The impact of the famine may have been exacerbated in urban centres as the influx of new starving populations brought outbreaks of disease such as smallpox, which are evident from parish registers for the period.\n\nThese problems were not confined to Scotland; the years 1695-97 saw catastrophic famine in present-day Estonia, Finland, Latvia, Norway and Sweden plus an estimated two million deaths in France and Northern Italy. Its historical significance and impact is partly due to the fact famine had become relatively rare in the second half of the seventeenth century, with only 1674 being one of dearth and these were to be the last of their kind.\n\nThe conditions resulted in limited migration between estates and parishes in Scotland; emigration to England was limited by English Poor Laws preventing distribution of relief to strangers, while continental Europe had the same issues. It may have been a factor in emigration to the American colonies and the West Indies by volunteers as indentured servants, which became the most significant form of transatlantic emigration from Scotland in this period. From 1650 to 1700, approximately 7,000 Scots emigrated to America, 10–20,000 to Europe and England and 60–100,000 to Ireland. An estimated 20,000 migrated to Ireland from 1696-1698; these numbers were part of a continuation of the Ulster Plantation, with cheap confiscated land available in the north after the Williamite War of the early 1690s.\n\nTo tackle the desperate economic situation, in 1695 the Scottish Parliament passed Acts allowing the consolidation of run rigs and the division of common land which drove the agricultural improvements of the eighteenth century. These changes made Scottish farming highly productive and ensured people could be fed in extreme conditions, even with the population growth.\n\nOther changes included the creation of the Bank of Scotland, while the Company of Scotland Trading to Africa and the Indies received a charter to raise capital through public subscription.< The Company invested in the Darién scheme, an ambitious plan funded almost entirely by Scottish investors to build a colony on the Isthmus of Panama for trade with East Asia. The scheme was a disaster, with the colonists abandoning their project in 1700; only 1,000 of 3,000 survived and only one ship managed to return to Scotland. The losses of £150,000 put a severe strain on the Scottish commercial system and was a key driver of the 1707 Acts of Union creating the Kingdom of Great Britain.\n\n"}
{"id": "2970018", "url": "https://en.wikipedia.org/wiki?curid=2970018", "title": "Sexuality of William Shakespeare", "text": "Sexuality of William Shakespeare\n\nThe sexuality of William Shakespeare has been the subject of recurring debate. It is known from public records that he married Anne Hathaway and that they had three children; scholars have analysed their relationship through these documents, and particularly through the bequests to her in Shakespeare's will. Some have speculated Shakespeare had affairs with other women, based on contemporaries' written anecdotes of such affairs and sometimes on the \"Dark Lady\" figure in his sonnets. Some scholars have argued he was bisexual, based on analysis of the sonnets: many, including Sonnet 18 \"Shall I compare thee to a summer's day\", are love poems addressed to a man, the \"Fair Youth\", and contain puns relating to homosexuality.\n\nAt the age of 18, Shakespeare married the 26-year-old Anne Hathaway. The consistory court of the Diocese of Worcester issued a marriage licence on 27 November 1582. Two of Hathaway's neighbours posted bonds the next day as surety that there were no impediments to the marriage. The couple may have arranged the ceremony in some haste, since the Worcester chancellor allowed the marriage banns to be read once instead of the usual three times. Hathaway's pregnancy could have been the reason for this. Six months after the marriage, she gave birth to a daughter, Susanna. Twins, son Hamnet and daughter Judith, followed almost two years later.\n\nStephen Greenblatt argues that Shakespeare probably initially loved Hathaway, supporting this by referring to the theory that a passage in one of his sonnets (Sonnet 145) plays off Anne Hathaway's name, saying she saved his life (writing \"I hate from hate away she threw/And saved my life, saying 'not you.'\"). Nevertheless, after only three years of marriage Shakespeare left his family and moved to London. Greenblatt suggests that this may imply that he felt trapped by Hathaway. Other evidence to support this belief is that he and Anne were buried in separate (but adjoining) graves and, as has often been noted, Shakespeare's will makes no specific bequest to his wife aside from \"the second best bed with the furniture\". This may seem like a slight, but many historians contend that the second best bed was typically the marital bed, while the best bed was reserved for guests. The poem \"Anne Hathaway\" by Carol Ann Duffy endorses this view of the second best bed, having Anne say: \"The bed we loved in was a spinning world of forests, castles, torchlight, clifftops, seas where we would dive for pearls.\" On the other hand, \"In the other bed, the best, our guests dozed on, dribbling their prose\". A bed missing from an inventory of Anne's brother's possessions (removed in contravention of their father's will) allows the explanation that the item was an heirloom from the Hathaway family, that had to be returned. The law at the time also stated that the widow of a man was automatically entitled to a third of his estate, so Shakespeare did not need to mention specific bequests in the will.\n\nWhile in London, Shakespeare may have had affairs with different women. One anecdote along these lines is provided by a lawyer named John Manningham, who wrote in his diary that Shakespeare had a brief affair with a woman during a performance of \"Richard III.\"\n\nUpon a time when Burbage played Richard the Third there was a citizen grew so far in liking with him, that before she went from the play she appointed him to come that night unto her by the name of Richard the Third. Shakespeare, overhearing their conclusion, went before, was entertained and at his game ere Burbage came. Then, message being brought that Richard the Third was at the door, Shakespeare caused return to be made that William the Conqueror was before Richard the Third.\n\nThe Burbage referred to is Richard Burbage, the star of Shakespeare's company, who is known to have played the title role in \"Richard III\". While this is one of the few surviving contemporary anecdotes about Shakespeare—it was made in March 1602, a month after Manningham had seen the play—some scholars are sceptical of its validity. Still, the anecdote suggests that at least one of Shakespeare's contemporaries (Manningham) believed that Shakespeare was attracted to women, even if he was not 'averse to an occasional infidelity to his marriage vows'. Indeed, its significance has been developed to affording Shakespeare a preference for \"promiscuous women of little beauty and no breeding\" in his honest acknowledgement that well-born women are beyond his reach.\n\nA less certain reference to an affair is a passage in the poem \"Willobie His Avisa\", by Henry Willobie, which refers to Shakespeare's \"The Rape of Lucrece\" in the line \"Shake-speare paints poor Lucrece' rape\". Later in the poem there is a section in which \"H.W.\" (Henry Willobie) and \"W.S.\" discuss Willobie's love for \"Avisa\" in a verse conversation. This is introduced with a short explanatory passage:\n\nW.S., who not long before had tried the courtesy of the like passion, and was now newly recovered ... he [Willobie] determined to see whether it would sort to a happier end for this new actor, than it did for the old player.\n\nThe fact that W.S. is referred to as a \"player\", and is mentioned after a complimentary comment on Shakespeare's poetry has led several scholars to conclude that Willobie is describing a conversation with Shakespeare about love affairs. \"W.S.\" goes on to give Willobie advice about how to win over women.\n\nOther possible evidence of other affairs are that twenty-six of Shakespeare's \"Sonnets\" are love poems addressed to a married woman (the so-called 'Dark Lady').\n\nShakespeare's sonnets are cited as evidence of his bisexuality. The poems were initially published, perhaps without his approval, in 1609. One hundred twenty-six of them appear to be love poems addressed to a young man known as the 'Fair Lord' or 'Fair Youth'; this is often assumed to be the same person as the 'Mr W.H.' to whom the sonnets are dedicated. The identity of this figure (if he is indeed based on a real person) is unclear; the most popular candidates are Shakespeare's patrons, Henry Wriothesley, 3rd Earl of Southampton and William Herbert, 3rd Earl of Pembroke, both of whom were considered handsome in their youth.\n\nThe only explicit references to sexual acts or physical lust occur in the Dark Lady sonnets, which unambiguously state that the poet and the Lady are lovers. Nevertheless, there are numerous passages in the sonnets addressed to the Fair Lord that have been read as expressing desire for a younger man. In Sonnet 13, he is called \"dear my love\", and Sonnet 15 announces that the poet is at \"war with Time for love of you.\" Sonnet 18 asks \"Shall I compare thee to a summer's day? / Thou art more lovely and more temperate\", and in Sonnet 20 the narrator calls the younger man the \"master-mistress of my passion\". The poems refer to sleepless nights, anguish and jealousy caused by the youth. In addition, there is considerable emphasis on the young man's beauty: in Sonnet 20, the narrator theorises that the youth was originally a woman with whom Mother Nature had fallen in love and, to resolve the dilemma of lesbianism, added a penis (\"pricked thee out for women's pleasure\"), an addition the narrator describes as \"to my purpose nothing\". The line can be read literally as a denial of sexual interest. However, given the homoerotic tone of the rest of the sonnet, it could also be meant to appear disingenuous, mimicking the common sentiment of would-be seducers: 'it's \"you\" I want, not your body’. In Sonnet 20, the narrator tells the youth to sleep with women, but to love only him: \"mine be thy love and thy love's use their treasure\".\n\nIn some sonnets addressed to the youth, such as Sonnet 52, the erotic punning is particularly intense: \"So is the time that keeps you as my chest, Or as the wardrobe which the robe doth hide, To make some special instant special blest, By new unfolding his imprisoned pride.\" In Elizabethan bawdy, 'pride' is a euphemism for penis, especially an erect one.\n\nOthers have countered that these passages could be referring to intense platonic friendship, rather than sexual love. In the preface to his 1961 Pelican edition, (at which time, in Britain, proven male homosexuality still carried a prison sentence, dismissal from the professions and huge public stigma), Douglas Bush writes, Since modern readers are unused to such ardor in masculine friendship and are likely to leap at the notion of homosexuality (a notion sufficiently refuted by the sonnets themselves), we may remember that such an ideal, often exalted above the love of women, could exist in real life, from Montaigne to Sir Thomas Browne, and was conspicuous in Renaissance literature. Richard Dutton writes that the Shakespearean scholar A. L. Rowse never accepted that the Bard was homosexual to any extent at all, writing that \"Shakespeare’s interest in the youth is not at all sexual\". Dutton comments:Rowse’s conviction on this point remained unshaken to his death, which is odd, not least because he himself was widely understood to be homosexual and wrote openly about writers like Marlowe and Wilde. But Shakespeare for him was always unimpeachably heterosexual.\n\nAnother explanation is that the poems are not autobiographical but fiction, another of Shakespeare's \"dramatic characterization[s]\", so that the narrator of the sonnets should not be presumed to be Shakespeare himself.\n\nIn 1640, John Benson published a second edition of the sonnets in which he changed most of the pronouns from masculine to feminine so that readers would believe nearly all of the sonnets were addressed to the Dark Lady. Benson's modified version soon became the best-known text, and it was not until 1780 that Edmond Malone re-published the sonnets in their original forms.\n\nThe question of the sexual orientation of the sonnets' author was openly articulated in 1780, when George Steevens, upon reading Shakespeare's description of a young man as his \"master-mistress\" remarked, \"it is impossible to read this fulsome panegyrick, addressed to a male object, without an equal mixture of disgust and indignation\". Other English scholars, dismayed at the possibility that their national hero might have been a \"sodomite\", concurred with Samuel Taylor Coleridge's comment, around 1800, that Shakespeare's love was \"pure\" and in his sonnets there is \"not even an allusion to that very worst of all possible vices\". Robert Browning, writing of Wordsworth's assertion that \"with this key [the Sonnets] Shakespeare unlocked his heart\", famously replied in his poem \"House\", \"If so, the less Shakespeare he!\" The controversy continued in the 20th century. By 1944, the Variorum edition of the sonnets contained an appendix with the conflicting views of nearly forty commentators. In the year after \"the law in Britain decriminalized homosexual acts between consenting males over twenty-one\", the historian G. P. V. Akrigg published the first extended study of the Earl of Southampton, \"who he had no doubt was the 'fair youth' of the sonnets.\" Akrigg wrote, \"One is forced to suspect that some element of homosexuality lay at the root of the trouble . . . The love which he felt for Southampton may well have been the most intense emotion of his life.\"\n\nLiterary theorist Stephen Greenblatt, in writing about sexuality within Southampton’s world, \"assumes that something went on – 'whether they only stared longingly at one another or embraced, kissed passionately, went to bed together'\".\n\nStanley Wells also addressed the topic in \"Looking for sex in Shakespeare\" (2004), arguing that a balance had yet to be drawn between the deniers of any possible homoerotic expression in the sonnets and more recent, liberal commentators who have \"swung too far in the opposite direction\" and allowed their own sensibilities to influence their understanding. One element that complicates the question of Shakespeare's sexuality is that same-sex friendships in the Renaissance were often characterized by shows of affection (e.g., bed sharing, confessions of love) that contemporary readers associate with modern-day sexual relationships.\n\nA recent notable scholarly dispute on the matter occurred in the letters pages of the \"Times Literary Supplement\" in 2014.\n\n"}
{"id": "49073394", "url": "https://en.wikipedia.org/wiki?curid=49073394", "title": "Smoke-free multi-unit housing", "text": "Smoke-free multi-unit housing\n\nSmoke-Free Multi-Unit Housing refers to a ban on smoking tobacco products in multiple‐unit or multi‐unit housing (MUH) complexes, which are defined as a public or private building, or portion thereof, containing two or more dwelling or other housing units including, but not limited to, a building with live/work units, apartment buildings, condominiums, senior citizen residences, nursing homes, housekeeping room/units, residential or single room occupancy hotels, and other multiple unit residential dwellings, group housing, or boarding facilities. According to recent estimates, within the United States, roughly 80 million (1 in 4) residents live in multi-unit housing complexes and more than 1 in 3 renters are exposed to secondhand smoke.\n\nThe first smoke-free multi-unit housing ordinance in the U.S. occurred in Belmont, California, due to the advocacy efforts of a group of low-income senior citizen residents who were frustrated by the drifting secondhand smoke from their neighbors. In November 2006, the Belmont City Council voted unanimously to pursue a comprehensive ordinance that would prohibit smoking almost anywhere in the city, except single-family detached homes. An ordinance making smoke-free all multi-unit housing, as well as many outdoor areas, was adopted in October 2007 and sparked the interest of city officials from around the nation and the world.\n\nSecondhand smoke is a major cause of disease and premature death, including lung cancer, heart disease, and respiratory problems in nonsmoking adults. According to the U.S. Surgeon General, there is no safe level of secondhand smoke exposure. Children exposed to secondhand smoke are at increased risk of Sudden Infant Death Syndrome (SIDS) and are more susceptible to respiratory infections, asthma, and ear infections. One study showed that children who live in homes in which no one smokes inside have a 45% increase in cotinine levels if they live in multi-unit housing compared with detached homes, due to seepage through walls and shared ventilation systems.\n\nSecondhand smoke exposure in multi-unit housing is a serious health threat because secondhand smoke drifts into housing units from neighboring units, balconies, patios, and common areas. The most effective way to address this problem and protect tenants from secondhand smoke is to pass a strong policy making, at a minimum, all units and indoor common areas in a building smoke-free.\n\nIn addition to banning smoking in multi-unit housing residences such as apartment buildings and condos, smoke-free housing laws usually change terms of tenancy for rental units, making it a lease violation to smoke in a nonsmoking unit. These lease changes are automatic for new leases and upon renewal for existing leases. Declaring secondhand smoke as a nuisance is another option for city and county governments.\n\nCommunities with rent control laws have differing options in passing a smoke-free multi-unit housing policy as landlords are restricted in changing terms of tenancy without the consent of the tenant. One option is to prohibit smoking in new tenancies and even some existing tenancies. In May 2014, the City of Berkeley was the first rent control city in California to adopt a smoke-free multi-unit housing law with a city enforcement mechanism in place that covers all newly initiated leases while encouraging those with existing leases to sign a new non-smoking lease addendum on a voluntarily basis. With this law, all residents of multi-unit housing including condos and rent-controlled units are covered.\n\nAfter Belmont passed its smoke-free multi-unit housing policy, other cities began to follow suit. As of April 2018, 40 jurisdictions in California have enacted municipal laws at the city or county level that prohibit smoking in 100% of private units of all specified types of multi-unit housing. These laws typically apply to both privately-owned and publicly-owned multi-unit buildings. Such laws apply to all existing and future buildings, and do not permit current residents to continue smoking in the building (that is, no “grandfathering” clause). This includes: Alameda, Albany, Belmont, Belvedere, Berkeley, Brisbane, Burlingame, Compton, Cotati, Culver City, Daly City, El Cerrito, El Monte, Foster City, Huntington Park, Los Gatos, Manhattan Beach, Mill Valley, Novato, Palo Alto, Pasadena, Petaluma, Richmond, San Anselmo, San Bruno, San Mateo city, San Mateo County, San Rafael, Santa Clara County, Santa Rosa, Saratoga, Sebastopol, Sonoma city, Sonoma County, South San Francisco, Sunnyvale, Tiburon, Union City, Walnut Creek, and Windsor.\n\nIn addition, 24 jurisdictions in California have municipal laws at the city or county level that do not prohibit smoking in all units of all multi-unit residential buildings in the community, but restrict smoking in private units of some specified types of multi-unit buildings. These laws typically apply to both privately-owned and publicly-owned multi-unit housing. This includes: Baldwin Park, Beverly Hills, Burbank, Calabasas, Contra Costa County, Corte Madera, Dublin, Fairfax, Glendale, Lafayette, Larkspur, Loma Linda, Marin County, Moorpark, Oakley, Pinole, Pleasant Hill, Pleasanton, Redwood City, Rohnert Park, Santa Monica, Sausalito, South Pasadena, and Temecula.\n\n"}
{"id": "198796", "url": "https://en.wikipedia.org/wiki?curid=198796", "title": "Spanish flu", "text": "Spanish flu\n\nThe 1918 influenza pandemic (January 1918 – December 1920; colloquially known as Spanish flu) was an unusually deadly influenza pandemic, the first of the two pandemics involving H1N1 influenza virus. It infected 500 million people around the world, including people on remote Pacific islands and in the Arctic, and resulted in the deaths of 50 to 100 million (three to five percent of the world's population), making it one of the deadliest natural disasters in human history.\n\nInfectious disease already limited life expectancy in the early 20th century. But in the first year of the pandemic, life expectancy in the United States dropped by about 12 years. Most influenza outbreaks disproportionately kill juvenile, elderly, or already weakened patients; in contrast, the 1918 pandemic predominantly killed previously healthy young adults.\n\nScientists offer several possible explanations for the high mortality rate of the 1918 influenza pandemic. Some research suggests that the specific variant of the virus had an unusually aggressive nature. One group of researchers recovered the virus from the bodies of frozen victims, and found that transfection in animals caused a rapidly progressive respiratory failure and death through a cytokine storm (overreaction of the body's immune system). It was postulated that the strong immune reactions of young adults ravaged the body, whereas the weaker immune systems of children and middle-aged adults resulted in fewer deaths among those groups.\n\nMore recent investigations, based mainly on original medical reports from the period of the pandemic, found that the viral infection itself was not more aggressive than any previous influenza, but that the special circumstances of the epidemic (malnourishment, overcrowded medical camps and hospitals, poor hygiene) promoted bacterial superinfection that killed most of the victims, typically after a somewhat prolonged death bed.\n\nHistorical and epidemiological data are inadequate to identify the pandemic's geographic origin. It was implicated in the outbreak of encephalitis lethargica in the 1920s.\n\nTo maintain morale, wartime censors minimized early reports of illness and mortality in Germany, the United Kingdom, France, and the United States. Papers were free to report the epidemic's effects in neutral Spain (such as the grave illness of King Alfonso XIII). This created a false impression of Spain as especially hard hit, thereby giving rise to the pandemic's nickname, \"Spanish Flu\".\n\nHistorian Alfred W. Crosby recorded that the flu originated in the U.S. state of Kansas, and popular writer John Barry echoed Crosby in describing Haskell County, as the point of origin. But already in late 1917, there had been a first wave of epidemic in at least 14 US military camps.\n\nInvestigative work in 1999 by a British team, led by virologist John Oxford of St Bartholomew's Hospital and the Royal London Hospital, identified the major troop staging and hospital camp in Étaples, France, as being the center of the Spanish flu. In late 1917, military pathologists reported the onset of a new disease with high mortality that they later recognized as the flu. The overcrowded camp and hospital — which treated thousands of victims of chemical attacks and other casualties of war — was an ideal site for the spreading of a respiratory virus; 100,000 soldiers were in transit every day. It also was home to a live piggery, and poultry were regularly brought in for food supplies from surrounding villages. Oxford and his team postulated that a significant precursor virus, harbored in birds, mutated so it could migrate to pigs that were kept near the front.\n\nEarlier hypotheses of the epidemic's origin have varied. Some hypothesized the flu originated in East Asia, a common area for transmission of disease from animals to humans because of dense living conditions. Claude Hannoun, the leading expert on the 1918 flu for the Pasteur Institute, asserted the former virus was likely to have come from China, mutating in the United States near Boston and spreading to Brest, France, Europe's battlefields, Europe, and the world via Allied soldiers and sailors as the main spreaders. He considered several other hypotheses of origin, such as Spain, Kansas (United States), and Brest, as being possible, but not likely.\n\nPolitical scientist Andrew Price-Smith published data from the Austrian archives suggesting the influenza had earlier origins, beginning in Austria in early 1917.\n\nIn 2014, historian Mark Humphries of the Memorial University of Newfoundland in St. John's stated that newly unearthed records confirmed that one of the side stories of the war, the mobilization of 96,000 Chinese laborers to work behind the British and French lines on World War I's western front, might have been the source of the pandemic. In the report, Humphries found archival evidence that a respiratory illness that struck northern China in November 1917 was identified a year later by Chinese health officials as identical to the \"Spanish\" flu. A report published in 2016 in the Journal of the Chinese Medical Association found no evidence that the 1918 virus was imported to Europe via Chinese and Southeast Asian soldiers and workers. It found evidence that the virus had been circulating in the European armies for months and possibly years before the 1918 pandemic.\n\nWhen an infected person sneezes or coughs, more than half a million virus particles can be spread to those close by. The close quarters and massive troop movements of World War I hastened the pandemic, and probably both increased transmission and augmented mutation; the war may also have increased the lethality of the virus. Some speculate the soldiers' immune systems were weakened by malnourishment, as well as the stresses of combat and chemical attacks, increasing their susceptibility.\n\nA large factor in the worldwide occurrence of this flu was increased travel. Modern transportation systems made it easier for soldiers, sailors, and civilian travelers to spread the disease.\n\nIn the United States, the disease was first observed in Haskell County, Kansas, in January 1918, prompting local doctor Loring Miner to warn the U.S. Public Health Service's academic journal. On 4 March 1918, company cook Albert Gitchell reported sick at Fort Riley, an American military facility that at the time was training American troops during World War I, making him the first recorded victim of the flu. Within days, 522 men at the camp had reported sick. By 11 March 1918, the virus had reached Queens, New York. Failure to take preventive measures in March/April was later criticised.\n\nIn August 1918, a more virulent strain appeared simultaneously in Brest, France; in Freetown, Sierra Leone; and in the U.S. in Boston, Massachusetts. The Spanish flu also spread through Ireland, carried there by returning Irish soldiers. The Allies of World War I came to call it the Spanish flu, primarily because the pandemic received greater press attention after it moved from France to Spain in November 1918. Spain was not involved in the war and had not imposed wartime censorship.\n\nThe global mortality rate from the 1918/1919 pandemic is not known, but an estimated 10% to 20% of those who were infected died. With about a third of the world population infected, this case-fatality ratio means 3% to 6% of the entire global population died. Influenza may have killed as many as 25 million people in its first 25 weeks. Older estimates say it killed 40–50 million people, while current estimates say 50–100 million people worldwide were killed.\n\nThis pandemic has been described as \"the greatest medical holocaust in history\" and may have killed more people than the Black Death. It is said that this flu killed more people in 24 weeks than AIDS killed in 24 years, and more in a year than the Black Death killed in a century, although the Black Death killed a much higher percentage of the world's smaller population at the time.\n\nThe disease killed in every area of the globe. As many as 17 million people died in India, about 5% of the population. The death toll in India's British-ruled districts alone was 13.88 million.\n\nIn Japan, of the 23 million people who were affected, 390,000 died. In the Dutch East Indies (now Indonesia), 1.5 million were assumed to have died among 30 million inhabitants. In Tahiti 13% of the population died during one month. Similarly, in Samoa 22% of the population of 38,000 died within two months.\n\nIn Iran, the mortality was very high: according to an estimate, between 902,400 and 2,431,000, or 8.0% to 21.7% of the total population died.\n\nIn the U.S., about 28% of the population became infected, and 500,000 to 675,000 died. Native American tribes were particularly hard hit. In the Four Corners area alone, 3,293 deaths were registered among Native Americans. Entire Inuit and Alaskan Native village communities died in Alaska. In Canada 50,000 died.\nIn Brazil, 300,000 died, including president Rodrigues Alves. In Britain, as many as 250,000 died; in France, more than 400,000.\nIn West Africa the influenza epidemic killed at least 100,000 people in Ghana. Tafari Makonnen (the future Haile Selassie, Emperor of Ethiopia) was one of the first Ethiopians who contracted influenza but survived. Many of his subjects did not; estimates for fatalities in the capital city, Addis Ababa, range from 5,000 to 10,000, or higher. In British Somaliland, one official estimated that 7% of the native population died.\n\nThis huge death toll was caused by an extremely high infection rate of up to 50% and the extreme severity of the symptoms, suspected to be caused by cytokine storms. Symptoms in 1918 were so unusual that initially influenza was misdiagnosed as dengue, cholera, or typhoid. One observer wrote, \"One of the most striking of the complications was hemorrhage from mucous membranes, especially from the nose, stomach, and intestine. Bleeding from the ears and petechial hemorrhages in the skin also occurred\". The majority of deaths were from bacterial pneumonia, a common secondary infection associated with influenza. The virus also killed people directly, by causing massive hemorrhages and edema in the lung.\n\nThe unusually severe disease killed up to 20% of those infected, as opposed to the usual flu epidemic mortality rate of 0.1%.\n\nThe pandemic mostly killed young adults. In 1918–1919, 99% of pandemic influenza deaths in the U.S. occurred in people under 65, and nearly half in young adults 20 to 40 years old. In 1920, the mortality rate among people under 65 had decreased sixfold to half the mortality rate of people over 65, but still 92% of deaths occurred in people under 65. This is unusual, since influenza is normally most deadly to weak individuals, such as infants (under age two), the very old (over age 70), and the immunocompromised. In 1918, older adults may have had partial protection caused by exposure to the 1889–1890 flu pandemic, known as the Russian flu.\nAccording to historian John M. Barry, the most vulnerable of all – \"those most likely, of the most likely\", to die – were pregnant women. He reported that in thirteen studies of hospitalized women in the pandemic, the death rate ranged from 23% to 71%.\nOf the pregnant women who survived childbirth, over one-quarter (26%) lost the child.\n\nAnother oddity was that the outbreak was widespread in the summer and autumn (in the Northern Hemisphere); influenza is usually worse in winter.\n\nModern analysis has shown the virus to be particularly deadly because it triggers a cytokine storm, which ravages the stronger immune system of young adults.\n\nIn fast-progressing cases, mortality was primarily from pneumonia, by virus-induced pulmonary consolidation. Slower-progressing cases featured secondary bacterial pneumonias, and there may have been neural involvement that led to mental disorders in some cases. Some deaths resulted from malnourishment.\n\nA study – conducted by He et al. – used a mechanistic modelling approach to study the three waves of the 1918 influenza pandemic. They tried to study the factors that underlie variability in temporal patterns, and the patterns of mortality and morbidity. Their analysis suggests that temporal variations in transmission rate provide the best explanation, and the variation in transmission required to generate these three waves is within biologically plausible values.\n\nAnother study by He et al. used a simple epidemic model, to incorporate three factors, including school opening and closing, temperature changes over the course of the outbreak, and human behavioral changes in response to the outbreak, to infer the cause of the three waves of the 1918 influenza pandemic. Their modelling results showed that all three factors are important but human behavioral responses showed the largest effects.\n\nThe second wave of the 1918 pandemic was much deadlier than the first. The first wave had resembled typical flu epidemics; those most at risk were the sick and elderly, while younger, healthier people recovered easily. But by August, when the second wave began in France, Sierra Leone, and the United States, the virus had mutated to a much deadlier form. As the PBS \"American Experience\": Influenza 1918 episode says, October 1918 was the deadliest month of the whole pandemic.\n\nThis increased severity has been attributed to the circumstances of the First World War. In civilian life, natural selection favors a mild strain. Those who get very ill stay home, and those mildly ill continue with their lives, preferentially spreading the mild strain. In the trenches, natural selection was reversed. Soldiers with a mild strain stayed where they were, while the severely ill were sent on crowded trains to crowded field hospitals, spreading the deadlier virus. The second wave began and the flu quickly spread around the world again. Consequently, during modern pandemics, health officials pay attention when the virus reaches places with social upheaval (looking for deadlier strains of the virus).\n\nThe fact that most of those who recovered from first-wave infections had become immune showed that it must have been the same strain of flu. This was most dramatically illustrated in Copenhagen, which escaped with a combined mortality rate of just 0.29% (0.02% in the first wave and 0.27% in the second wave) because of exposure to the less-lethal first wave. For the rest of the population, the second wave was far more deadly; the most vulnerable people were those like the soldiers in the trenches – young previously healthy adults.\n\nEven in areas where mortality was low, so many adults were incapacitated that much of everyday life was hampered. Some communities closed all stores or required customers to leave orders outside. There were reports that health-care workers could not tend the sick nor the gravediggers bury the dead because they too were ill. Mass graves were dug by steam shovel and bodies buried without coffins in many places.\n\nSeveral Pacific island territories were particularly hard-hit. The pandemic reached them from New Zealand, which was too slow to implement measures to prevent ships carrying the flu from leaving its ports. From New Zealand, the flu reached Tonga (killing 8% of the population), Nauru (16%) and Fiji (5%, 9,000 people).\n\nWorst affected was Western Samoa, formerly German Samoa, which had been occupied by New Zealand in 1914. 90% of the population was infected; 30% of adult men, 22% of adult women and 10% of children died. By contrast, Governor John Martin Poyer prevented the flu from reaching American Samoa by imposing a blockade. The disease spread fastest through the higher social classes among the indigenous peoples, because of the custom of gathering oral tradition from chiefs on their deathbeds; many community elders were infected through this process.\n\nIn New Zealand, 8,573 deaths were attributed to the 1918 pandemic influenza, resulting in a total population fatality rate of 0.74%. Māori were 10 times as likely to die as pākehā (Europeans), because of their poorer and more crowded housing, and rural population. \n\nIn Ireland, the Spanish Flu accounted for 10% of the total deaths in 1918.\n\nData analysis revealed 6,520 recorded deaths in Savannah-Chatham County, Georgia (population = 83,252) for the three-year period from January 1, 1917, to December 31, 1919. Of these deaths, influenza was specifically listed as the cause of death in 316 cases, representing 4.85 percent of all causes of death for the total time period.\n\nIn Japan, 257,363 deaths were attributed to influenza by July 1919, giving an estimated 0.425% mortality rate, much lower than nearly all other Asian countries for which data are available. The Japanese government severely restricted sea travel to and from the home islands when the pandemic struck.\n\nIn the Pacific, American Samoa and the French colony of New Caledonia also succeeded in preventing even a single death from influenza through effective quarantines. In Australia, nearly 12,000 perished.\n\nBy the end of the pandemic, the isolated island of Marajó, in Brazil's Amazon River Delta had not reported an outbreak.\n\nSaint Helena also reported no deaths.\n\nIn a 2009 paper published in the journal \"Clinical Infectious Diseases\", Karen Starko proposed that aspirin poisoning contributed substantially to the fatalities. She based this on the reported symptoms in those dying from the flu, as reported in the post mortem reports still available, and also the timing of the big \"death spike\" in October 1918. This occurred shortly after the Surgeon General of the United States Army and the \"Journal of the American Medical Association\" both recommended very large doses of 8 to 31 grams of aspirin per day as part of treatment. These levels will produce hyperventilation in 33% of patients, as well as lung edema in 3% of patients. Starko also notes that many early deaths showed \"wet,\" sometimes hemorrhagic lungs, whereas late deaths showed bacterial pneumonia. She suggests that the wave of aspirin poisonings was due to a \"perfect storm\" of events: Bayer's patent on aspirin expired, so many companies rushed in to make a profit and greatly increased the supply; this coincided with the Spanish flu; and the symptoms of aspirin poisoning were not known at the time.\n\nAs an explanation for the universally high mortality rate, this hypothesis was questioned in a letter to the journal published in April 2010 by Andrew Noymer and Daisy Carreon of the University of California, Irvine, and Niall Johnson of the Australian Commission on Safety and Quality in Health Care. They questioned the universal applicability of the aspirin theory, given the high mortality rate in countries such as India, where there was little or no access to aspirin at the time compared to the rate where aspirin was plentiful. They concluded that \"the salicylate [aspirin] poisoning hypothesis [was] difficult to sustain as the primary explanation for the unusual virulence of the 1918–1919 inﬂuenza pandemic\". In response, Starko said there was anecdotal evidence of aspirin use in India and argued that even if aspirin over-prescription had not contributed to the high Indian mortality rate, it could still have been a factor for high rates in areas where other exacerbating factors present in India played less of a role.\n\nAfter the lethal second wave struck in late 1918, new cases dropped abruptly – almost to nothing after the peak in the second wave. In Philadelphia, for example, 4,597 people died in the week ending 16 October, but by 11 November, influenza had almost disappeared from the city. One explanation for the rapid decline of the lethality of the disease is that doctors got better at preventing and treating the pneumonia that developed after the victims had contracted the virus; but John Barry stated in his book that researchers have found no evidence to support this.\n\nAnother theory holds that the 1918 virus mutated extremely rapidly to a less lethal strain. This is a common occurrence with influenza viruses: there is a tendency for pathogenic viruses to become less lethal with time, as the hosts of more dangerous strains tend to die out (see also \"Deadly Second Wave\", above).\n\nA 2006 study in the \"Journal of Political Economy\" found that \"cohorts in utero during the pandemic displayed reduced educational attainment, increased rates of physical disability, lower income, lower socioeconomic status, and higher transfer payments compared with other birth cohorts.\" A 2018 study found that the pandemic reduced educational attainment in populations.\n\nAcademic Andrew Price-Smith has made the argument that the virus helped tip the balance of power in the later days of the war towards the Allied cause. He provides data that the viral waves hit the Central Powers before they hit the Allied powers, and that both morbidity and mortality in Germany and Austria were considerably higher than in Britain and France.\n\nIn the United States, Britain and other countries, despite the relatively high morbidity and mortality rates that resulted from the epidemic in 1918–1919, the Spanish flu began to fade from public awareness over the decades until the arrival of news about bird flu and other pandemics in the 1990s and 2000s. This has led some historians to label the Spanish flu a \"forgotten pandemic\".\n\nVarious theories of why the Spanish flu was \"forgotten\" include the rapid pace of the pandemic, which killed most of its victims in the United States, for example, within a period of less than nine months, resulting in limited media coverage. The general population was familiar with patterns of pandemic disease in the late 19th and early 20th centuries: typhoid, yellow fever, diphtheria, and cholera all occurred near the same time. These outbreaks probably lessened the significance of the influenza pandemic for the public. In some areas, the flu was not reported on, the only mention being that of advertisements for medicines claiming to cure it.\n\nIn addition, the outbreak coincided with the deaths and media focus on the First World War. Another explanation involves the age group affected by the disease. The majority of fatalities, from both the war and the epidemic, were among young adults. The deaths caused by the flu may have been overlooked due to the large numbers of deaths of young men in the war or as a result of injuries. When people read the obituaries, they saw the war or postwar deaths and the deaths from the influenza side by side. Particularly in Europe, where the war's toll was extremely high, the flu may not have had a great, separate, psychological impact, or may have seemed a mere extension of the war's tragedies.\n\nThe duration of the pandemic and the war could have also played a role. The disease would usually only affect a certain area for a month before leaving, while the war, which most had initially expected to end quickly, had lasted for four years by the time the pandemic struck. This left little time for the disease to have a significant impact on the economy.\n\nRegarding global economic effects, many businesses in the entertainment and service industries suffered losses in revenue, while the health care industry reported profit gains.\nHistorian Nancy Bristow has argued that the pandemic, when combined with the increasing number of women attending college, contributed to the success of women in the field of nursing. This was due in part to the failure of medical doctors, who were predominantly men, to contain and prevent the illness. Nursing staff, who were predominantly women, felt more inclined to celebrate the success of their patient care and less inclined to identify the spread of the disease with their own work.\n\nIn Spain, sources from the period explicitly linked the Spanish flu to the cultural figure of Don Juan. The nickname for the flu, the \"Naples Soldier\", was adopted from Federico Romero and Guillermo Fernández Shaw's operetta, \"The Song of Forgetting\" (\"La canción del olvido\"), the protagonist of which is a stock Don Juan type. Federico Romero, one of the librettists, quipped that the play's most popular musical number, \"Naples Soldier\", was as catchy as the flu. Davis has argued the Spanish flu–Don Juan connection served a cognitive function, allowing Spaniards to make sense of their epidemic experience by interpreting it through a familiar template, namely the Don Juan story.\n\nThe origin of the Spanish flu pandemic, and the relationship between the near-simultaneous outbreaks in humans and swine, have been controversial. One hypothesis is that the virus strain originated at Fort Riley, Kansas, in viruses in poultry and swine which the fort bred for food; the soldiers were then sent from Fort Riley around the world, where they spread the disease. Similarities between a reconstruction of the virus and avian viruses, combined with the human pandemic preceding the first reports of influenza in swine, led researchers to conclude the influenza virus jumped directly from birds to humans, and swine caught the disease from humans.\n\nOthers have disagreed, and more recent research has suggested the strain may have originated in a nonhuman, mammalian species. An estimated date for its appearance in mammalian hosts has been put at the period 1882–1913. This ancestor virus diverged about 1913–1915 into two clades (or biological groups), which gave rise to the classical swine and human H1N1 influenza lineages. The last common ancestor of human strains dates to between February 1917 and April 1918. Because pigs are more readily infected with avian influenza viruses than are humans, they were suggested as the original recipients of the virus, passing the virus to humans sometime between 1913 and 1918.\n\nAn effort to recreate the 1918 flu strain (a subtype of avian strain H1N1) was a collaboration among the Armed Forces Institute of Pathology, the USDA ARS Southeast Poultry Research Laboratory and Mount Sinai School of Medicine in New York City. The effort resulted in the announcement (on 5 October 2005) that the group had successfully determined the virus's genetic sequence, using historic tissue samples recovered by pathologist Johan Hultin from a female flu victim buried in the Alaskan permafrost and samples preserved from American soldiers.\n\nOn 18 January 2007, Kobasa et al. (2007) reported that monkeys (\"Macaca fascicularis\") infected with the recreated flu strain exhibited classic symptoms of the 1918 pandemic, and died from a cytokine storm—an overreaction of the immune system. This may explain why the 1918 flu had its surprising effect on younger, healthier people, as a person with a stronger immune system would potentially have a stronger overreaction.\n\nOn 16 September 2008, the body of British politician and diplomat Sir Mark Sykes was exhumed to study the RNA of the flu virus in efforts to understand the genetic structure of modern H5N1 bird flu. Sykes had been buried in 1919 in a lead coffin which scientists hoped had helped preserve the virus. The coffin was found to be split because of the weight of soil over it, and the cadaver was badly decomposed. Nonetheless, samples of lung and brain tissue were taken through the split, with the coffin remaining \"in situ\" in the grave during this process.\n\nIn December 2008, research by Yoshihiro Kawaoka of the University of Wisconsin linked the presence of three specific genes (termed PA, PB1, and PB2) and a nucleoprotein derived from 1918 flu samples to the ability of the flu virus to invade the lungs and cause pneumonia. The combination triggered similar symptoms in animal testing.\n\nIn June 2010, a team at the Mount Sinai School of Medicine reported the 2009 flu pandemic vaccine provided some cross-protection against the 1918 flu pandemic strain.\n\nOne of the few things known for certain about the influenza in 1918 and for some years after was that it was, out of the laboratory, exclusively a disease of human beings.\n\nIn 2013, the AIR Worldwide Research and Modeling Group \"characterized the historic 1918 pandemic and estimated the effects of a similar pandemic occurring today using the AIR Pandemic Flu Model\". In the model, \"a modern day \"Spanish flu\" event would result in additional life insurance losses of between USD 15.3–27.8 billion in the United States alone\", with 188,000–337,000 deaths in the United States.\n\n\n"}
{"id": "1051772", "url": "https://en.wikipedia.org/wiki?curid=1051772", "title": "Staphylococcal enteritis", "text": "Staphylococcal enteritis\n\nStaphylococcal enteritis is an inflammation that is usually caused by eating or drinking substances contaminated with staph enterotoxin. The toxin, not the bacterium, settles in the small intestine and causes inflammation and swelling. This in turn can cause abdominal pain, cramping, dehydration, diarrhea and fever.\n\n\"Staphylococcus aureus\" is a Gram-positive, facultative anaerobe, coccal (round shaped) bacteria that appears in grape-like clusters that can thrive in high salt and low water activity habitats. \"S. aureus\" bacteria can live on the skin which is one of the primary modes of transmission. \"S. aureus\" can cause a range of illnesses from minor skin infections to Staphylococcus aureus food poisoning enteritis. Since humans are the primary source, cross-contamination is the most common way the microorganism is introduced into foods. Foods at high risks are those prepared in large quantities. \nStaphylococcus aureus is a true food poisoning organism. It produces a heat stable enterotoxin when allowed to grow for several hours in foods such as cream-filled baked goods, poultry meat, gravies, eggs, meat salads, puddings and vegetables. It is important to note that the toxins may be present in dangerous amounts in foods that have no signs of spoilage, such as a bad smell, any off color, odor, or textural or flavor change.\n\nEnteritis is the inflammation of the small intestine. It is generally caused by eating or drinking substances that are contaminated with bacteria or viruses. The bacterium and/or toxin settles in the small intestine and cause inflammation and swelling. This in turn can cause abdominal pain, cramping, diarrhea, fever, and dehydration. There are other types of enteritis, the types include: bacterial gastroenteritis, \"Campylobacter\" enteritis, \"E. coli\" enteritis, radiation enteritis, \"Salmonella\" enteritis and \"Shigella\" enteritis.\n\nCommon symptoms of \"Staphylococcus aureus\" food poisoning include: a rapid onset which is usually 1–6 hours, nausea, explosive vomiting for up to 24 hours, abdominal cramps/pain, headache, weakness, diarrhea and usually a subnormal body temperature. Symptoms usually start one to six hours after eating and last less than 12 hours. The duration of some cases may take two or more days to fully resolve.\n\n\"S. aureus\" is an enterotoxin producer. Enterotoxins are chromosomally encoded exotoxins that are produced and secreted from several bacterial organisms. It is a heat stable toxin and is resistant to digestive protease. It is the ingestion of the toxin that causes the inflammation and swelling of the intestine.\n\nFor the detection of \"Staphylococcus aureus\" food poisoning which can lead to staphylococcal enteritis a stool culture may be required. A stool culture is used to detect the presence of disease-causing bacteria (pathogenic) and help diagnose an infection of the digestive tract. In the case of staphylococcal enteritis, it is conducted to see if the stool is positive for a pathogenic bacterium.\n\nStaphylococcal enteritis may be avoided by using proper hygiene and sanitation with food preparation. This includes thoroughly cooking all meats. If food is to be stored longer than two hours, keep hot foods hot (over 140 °F) and cold foods cold (40 °F or under). Ensure to refrigerate leftovers promptly and store cooked food in a wide, shallow container and refrigerate as soon as possible. Sanitation is very important. Keep kitchens and food-serving areas clean and sanitized. Finally, as most staphylococcal food poisoning are the result of food handling, hand washing is critical. Food handlers should use hand sanitizers with alcohol or thorough hand washing with soap and water.\n\nTips for hand washing:\n\n1. Wash hands with warm, soapy water before and after handling raw foods.\n\n2. Always wash your hands after using the bathroom, after changing a baby's diaper, after touching pets or other animals, and after sneezing or coughing\n\n3. Properly dress or glove.\n\nTreatment is supportive and based upon symptoms, with fluid and electrolyte replacement as the primary goal. Dehydration caused by diarrhea and vomiting is the most common complication. To prevent dehydration, it is important to take frequent sips of a rehydration drink (like water) or try to drink a cup of water or rehydration drink for each large, loose stool.\n\nDietary management of enteritis consists of starting with a clear liquid diet until vomiting and diarrhea end and then slowly introduce solid foods. It is also important to avoid foods that are high in fiber or are possibly difficult to digest.\n\n"}
{"id": "27150634", "url": "https://en.wikipedia.org/wiki?curid=27150634", "title": "Tobacco in the American Colonies", "text": "Tobacco in the American Colonies\n\nTobacco cultivation and exports formed an essential component of the American colonial economy. During the Civil War, they were distinct from other cash crops in terms of agricultural demands, trade, slave labor, and plantation culture. Many influential American revolutionaries, including Thomas Jefferson and George Washington, owned tobacco plantations, and were financially devastated by debt to British tobacco merchants shortly before the American Revolution.\n\nAmerican tobacco planters, including Jefferson and George Washington, financed their plantations with sizeable loans from London. When tobacco prices dropped precipitously in the 1750s, many plantations struggled to remain financially solvent. Severe debt threatened to unravel colonial power structures and destroy planters’ personal reputations. At his Mount Vernon plantation, Washington saw his liabilities swell to nearly £2000 by the late 1760s. Jefferson, on the verge of losing his own farm, aggressively espoused various conspiracy theories. Though never verified, Jefferson accused London merchants of unfairly depressing tobacco prices and forcing Virginia farmers to take on unsustainable debt loads. In 1786, he remarked:\nThe inability to pay what one owed was not just a financial failing, but a moral one. Planters whose operations collapsed were condemned as “sorry farmers” – unable to produce good crops and inept at managing their land, slaves, and assets. Washington excused his situation thusly:\nIn conjunction with a global financial crisis and growing animosity toward British rule, tobacco interests helped unite disparate colonial players and produced some of the most vocal revolutionaries behind the call for American independence. A spirit of rebellion arose from their claims that insurmountable debts prevented the exercise of basic human freedoms.\n\nJohn Rolfe, a colonist from Jamestown, was the first colonist to grow tobacco in America. He arrived in Virginia with tobacco seeds procured on an earlier voyage to Trinidad, and in 1612 he harvested his inaugural crop for sale on the European market. Rolfe’s tobacco operation was an instant boom for American exports.\n\nAs the English increasingly used tobacco products, tobacco in the American colonies became significant economic force, especially in the tidewater region surrounding the Chesapeake Bay. Vast plantations were built along the rivers of Virginia, and social/economic systems developed to grow and distribute this cash crop. In 1713, the General Assembly (under the leadership of Governor Alexander Spotswood) passed a Tobacco Act requiring the inspection of all tobacco intended for export or for use as legal tender. In 1730, the Virginia House of Burgesses standardized and improved quality of tobacco exported by establishing the Tobacco Inspection Act of 1730, which required inspectors to grade tobacco at 40 specified locations. Some elements of this system included the importation and employment of slaves to grow crops. Planters filled large hogsheads with tobacco and conveyed them to inspection warehouses.\n\nThe tobacco economy in the colonies was embedded in a cycle of leaf demand, slave labor demand, and global commerce that gave rise to the Chesapeake Consignment System and Tobacco Lords. American tobacco farmers would sell their crop on consignment to merchants in London, which required them to take out loans for farm expenses from London guarantors in exchange for tobacco delivery and sale. Further contracts were negotiated with wholesalers in Charleston or New Orleans to ship the tobacco to London merchants. The loan was then repaid with profits from their sales. \n\nAmerican planters responded to increased European demand by expanding the size and output of their plantations. The number of man-hours needed to sustain larger operations increased, which forced planters to acquire and accommodate additional slave labor. Furthermore, they had to secure larger initial loans from London, which increased pressure to produce a profitable crop and made them more financially vulnerable to natural disasters.\n\nThe slave population in the Chesapeake increased significantly during the 18th century due to demand for cheap tobacco labor and a dwindling influx of indentured servants willing to migrate from England. In this century, it is estimated that the Chesapeake African slave population increased from 100,000 to 1 million – a majority of the enslaved workforce and about 40% of the total population. Slaves were not imported to the Chesapeake after 1775, but slave populations continued to increase through 1790 because most were forced by their masters to produce large numbers of offspring.\n\nBefore the slave boom, Chesapeake tobacco plantations were characterized by a “culture of assimilation”, where white planters worked alongside their black slaves and racial boundaries were less distinct. As slaveholding increased, intense racial contrasts emerged and all-black labor units supervised by white planters came to replace mixed-race units. Unwritten race-based sumptuary laws, which would later become Jim Crow laws, became common social fixtures in Northern and Southern colonies.\n\nFor the many farmers who seized opportunity in the profitable tobacco enterprise, financial and personal anxiety mounted amidst stiff competition and falling prices. Some historians believe that these anxieties were redirected onto subordinates in the field, which exacerbated already strained racial relations. Planters pushed slaves to their physical limits to ensure a superior crop. Slaves, meanwhile, realized that the quality of a crop depended on their effort and began “foot dragging”, or collectively slowing their pace in protest of the planters' extreme demands. Farmers racialized foot dragging, portraying it as an inherent personality trait of slaves. William Strickland, a wealthy colonial tobacco planter, remarked:\nTensions between slaves and planters occasionally escalated enough to bring work in the field to a standstill. When this occurred, masters often punished insubordinate slaves with physical violence such as lashings and whippings until they resumed their tasks.\n\nIn the Chesapeake and North Carolina, tobacco constituted a major percentage of the total agricultural output. In the Deep South (mainly Georgia and South Carolina), cotton and rice plantations dominated. Stark diversity in the geographic and social landscapes of these two regions contributed to differences in their respective slave cultures.\n\nThe Chesapeake had few urban centers relative to the South. Instead, multiple markets were established along tributaries. This facilitated the persistence of smaller tobacco farms because the cost of moving tobacco to market was kept reasonable. In the south, all economic activity fed through a few heavily centralized markets, which favored large plantations that could bear the higher transportation costs. Differences in plantation size also owed significantly to the different demands of tobacco farming versus cotton and rice. Cotton and rice were cash crops, and cultivation was geared towards maximizing volume. Diminishing returns take effect on harvest quality past a certain threshold of labor investment. Tobacco, however, was considered to be more artisanal and craft-like, with limitless opportunity to improve the yield and quality. Thus, the most profitable cotton and rice operations were large and factory-like, while tobacco profits hinged on skilled, careful, and efficient labor units.\n\nBecause of the diminished need for trained labor, families of slaves on cotton and rice plantations would often remain together, bought and sold as complete packages. Individual life expectancies were generally shorter, because their skill set was less refined and workers were easily replaced if killed. Cotton and rice plantation owners employed a management technique called “tasking”, in which each slave would receive around one-half acre of land to tend individually with minimal supervision. The weight of the yield from each slave’s plot was interpreted as a direct reflection of the quality of his work.\n\nIn contrast, tobacco planters desired skilled male slaves, while women were mainly responsible for breeding and raising children. Family members were often estranged when women and children left to seek other work. Individual life expectancies for tobacco slaves were generally longer because their unique skills, honed over the course of many years in the field, proved indispensable to a planter’s success. Tobacco planters favored a technique called “ganging”, where groups of eight to twelve slaves worked fields simultaneously under the supervision of a white superior or a tenured slave. The hardest working slaves, called “pace-setters”, were spread amongst the different groups as an example for those around them. Unlike tasking, ganging was amenable to supervision and quality control, and lacked an inherent measure of individual effort.\n\nSome contemporary scholars argue that the Chesapeake was a more hospitable environment for slaves. It was more common in the Chesapeake for a slave to work alongside his master, an arrangement unheard of in the strict vertical hierarchies of massive Southern plantations. Whites and blacks were more deeply divided in the Deep South, and tasking allowed slave owners to arbitrarily replace individuals who did not meet expectations. Others argue that it is disingenuous to romanticize one incarnation of slavery over another and that neither environment was “hospitable” despite these differences.\n\nA culture of expertise surrounded tobacco planting. Unlike cotton or rice, cultivating tobacco was seen as an art form, and buyers understood that behind every crop of good tobacco was a meticulous planter with exceptional skills. Tobacco shipments were “branded” with a signature unique to its planter before they were sent overseas, and guarantors regarded brands as a seal of approval from the planter himself. One planter proclaimed of his branded tobacco, “it was made on the plantation where I live and therefore as I saw to the whole management of it my self \"(sic)\", I can with authority recommend it to be exceedingly good.” Even though not necessarily participating in the manual labor, planters took great financial stake in their final product.\n\nFurthermore, local reputation and social status varied with the quality of one’s leaf. In his book \"Tobacco Culture\", author T.H. Breen writes “quite literally, the quality of a man’s tobacco often served as the measure of the man.” Proficient planters, held in high regard by their peers, often exercised significant political clout in colonial governments. Farmers often spent excess profits on expensive luxury goods from London to indicate to others that their tobacco was selling well. Notably, Thomas Jefferson’s Monticello estate was styled after the dwellings of wealthy European aristocrat.\n\nAmerican tobacco planters, including Jefferson and George Washington, financed their plantations with sizeable loans from London. When tobacco prices dropped precipitously in the 1750s, many plantations struggled to remain financially solvent. Severe debt threatened to unravel colonial power structures and destroy planters’ personal reputations. At his Mount Vernon plantation, Washington saw his liabilities swell to nearly £2000 by the late 1760s. Jefferson, on the verge of losing his own farm, aggressively espoused various conspiracy theories. Though never verified, Jefferson accused London merchants of unfairly depressing tobacco prices and forcing Virginia farmers to take on unsustainable debt loads. In 1786, he remarked:\n\nThe inability to pay what one owed was not just a financial failing, but a moral one. Planters whose operations collapsed were condemned as “sorry farmers” – unable to produce good crops and inept at managing their land, slaves, and assets. Washington excused his situation thusly:\n\nIn conjunction with a global financial crisis and growing animosity toward British rule, tobacco interests helped unite disparate colonial players and produced some of the most vocal revolutionaries behind the call for American independence. A spirit of rebellion arose from their claims that insurmountable debts prevented the exercise of basic human freedoms.\n\n\n"}
{"id": "22973679", "url": "https://en.wikipedia.org/wiki?curid=22973679", "title": "Traditional Chinese veterinary medicine", "text": "Traditional Chinese veterinary medicine\n\nTraditional Chinese veterinary medicine (TCVM) is the ancient veterinary treatment of animals based on the same theories as traditional Chinese medicine (TCM). TCM and TCVM have developed over a period of over 3,500 years and are practiced all over the world. In Western cultures such as the U.S., TCVM has rapidly grown as an adjunct therapeutic modality for animals that do not respond favorably to typical Western veterinary treatments.\n\nChinese philosophical truths based on Taoism are the underpinnings that influence the practice of TCVM. The fundamental truth for health in TCVM is balance—balance within yourself, balance with others, balance with your diet, and balance with nature.\n\nTCVM practices include four major fundamental branches: Chinese food therapy, acupuncture, herbal therapy,and Tui na (\"twee-na\")\n\nIts counterpart TCM includes other such treatments as herbal medicine (中药), acupuncture, dietary therapy, and both tui-na and shiatsu massage. Qigong and Taijiquan are also closely associated with TCM.\n\nTCVM has evolved simultaneously with the evolution of TCM. TCVM originated thousands of years ago through meticulous observation of nature, the cosmos, and the human body. Major contributing theories that apply to the practice of both TCM and TCVM include: the Yin-yang theory, the five-element theory, the human body Channel system, Zang-Fu organ physiology, six confirmations, four layers, etc.\n\nFood therapy is the art and science of combining foods based on their inherent energetic properties. Unlike Western medicine, food is an integral component of treating and preventing disease in TCVM. The Eastern world is focused on the effect food has on the body after it is eaten. Each food item is described as having energetic properties such as warming, cooling, or flavors that act on the body in certain predictable yet different ways. Various food combinations may be used to maintain and support the balance of yin and yang thereby maintaining optimal health. When disease occurs, certain food combinations may be employed to return the body to a balanced state. Food therapy is one of the five fundamental branches of TCVM and a powerful component of the TCVM treatment regime.\n\nAcupuncture is an ancient form of medicine using small filiform needles placed at predetermined points on the body. The goal of acupuncture is to move Qi—the force that makes us alive. Western medicine has no equivocal term to describe Qi. Qi flows throughout the body along meridians, or paths that interconnect the external surface of the body with the internal organs. When needles are placed in points, Qi moves freely. As Qi moves freely, the body maintains its balance, or homeostasis.\n\nHerbal therapy is the use of therapeutic medicines derived from plants, animals, and substances occurring in the natural environment. Herbs are used to move Qi as well as tonify Yin and Yang. Yin and yang are equal yet opposing forces that occur in all naturally occurring phenomena. For instance, Yin corresponds to nighttime, cold, or resting of the body. Yang, on the other hand, corresponds to daytime, heat, and activity of the body. Whenever Yin or Yang becomes deficient or excessive, the balance of the body is lost, and disease results. Herbs are used to restore this natural balance. The Western equivalent to Chinese herbs is pharmaceutical drugs, such as antibiotics and anti-inflammatory medicines. Both western drugs and Chinese herbs are prescribed based on a medical diagnosis. Lately, Western herbals have become popular in the United States. However, distinct differences exist between Western and Chinese herbs. Western herbs are used in a singular form to treat symptoms of disease without a medical diagnosis. Chinese herbs are often a formula or mixture of herbs prescribed according to a medical diagnosis. Generally, in treating a patient, acupuncture is used in conjunction with herbal medicine.\n\nTui-Na is medical manipulation with the hands much like the modern versions of Western chiropractic and massage therapy. Various techniques are employed to massage the meridians and enhance the flow of Qi throughout the body. Certified Tui-Na practitioners often teach pet owners several techniques to use at home to enhance the treatment of disease.\n\nQi-Gong is the combination of exercise and meditation in which the flow of Qi is improved. It also is a way to balance the yin and yang of the body. This branch of Traditional Chinese Medicine does not apply to animals.\n\n"}
{"id": "33504166", "url": "https://en.wikipedia.org/wiki?curid=33504166", "title": "Water privatization in Albania", "text": "Water privatization in Albania\n\nWater privatization in Albania was initiated by the Albanian government in the early 2000s with the support of the World Bank and German development cooperation. The stated objective was to improve the quality and efficiency of urban water supply and sanitation. At the time, many households received water only for a few hours every day, utilities were overstaffed, water tariffs were low and many customers did not pay their water bills. There was no single municipal wastewater treatment plant in the country of 3 million, which is among Europe's poorest countries. In 2002-03 three contracts were signed with foreign private operators covering six secondary cities. Water privatization never covered more than a fifth of the country’s population. The contracts expired or were terminated early five years later with few tangible improvements in service quality.\n\nMuch of the water and sewerage infrastructure in Albania was built between the 1950s and early 70s with help from the People’s Republic of China. When Chinese aid ended in 1978 after the two communist governments fell out with each other, the infrastructure deteriorated with little or no maintenance. The responsibility for water supply rested with the central government with no participation by local governments and communities. With the fall of communism in the 1992 elections, the provision of water supply and sanitation services was assigned to 52 state-owned regional water enterprises in an effort to empower local government. Typically, the service area of a regional water enterprise comprises several municipalities. The mayors of Albania's 373 municipalities (Albanian: \"bashki\" or \"komunë\") nominate the members of the management councils of the regional water company which serves their territory.\n\nHowever, all important decisions about investments and staffing actually continued to be taken by the central government, so that local governments felt that they had no actual responsibility for water supply. Revenues were insufficient to cover even operating expenses, and electricity bills or even salaries went unpaid unless the central government provided subsidies. Investments picked up with Western aid after 1992, but service quality continued to remain poor.\n\nAbout 70% of all water produced was non-revenue water and only 30% was billed. Only 70% of these bills were actually paid, so that ultimately only 21% of the water produced was actually paid for. Furthermore, the regional water and sewer companies had about three times more staff per connection than in other Eastern European and Central Asian utilities. Low revenues and high costs led to an average operating cost recovery rate of only 60%. On all these counts, the performance of Albanian water companies was much lower than the performance of utilities in other former communist countries ten years after the beginning of the transition process. Concerning service quality, on average water was available only 3–4 hours per day. Certain areas received water only once in three days, which was partly due to intermittent power supply for pumps. There was no wastewater treatment. Sewers were often clogged causing seepage and cross-contamination with drinking water. Many covers for manholes were missing so that they filled with rubbish.\n\nThe reform strategy for the urban water and sanitation sector included three main elements: decentralization, private sector participation and increased cost recovery. The reforms were decided and implemented by governments under socialist Prime Ministers that ruled from 1997 to 2005. The reform process was supported by German development cooperation and the World Bank with financing and technical assistance. The government also decided that 6 companies would enter into public-private partnerships with foreign companies through 3 contracts. Water privatization thus never covered more than a fifth of the country’s population. The water supply for the capital Tirana was not privatized.\n\nIn 1998 the government instructed 18 of the 52 regional water enterprises to transform themselves into joint stock companies whose shares were held by the central government. However, in 2000 the government passed the \"Law on Organization and Functioning of Local Governments, No. 8652\" which gave the exclusive responsibility for water supply and sanitation to the municipalities. Thus the government sent what appears to be contradictory signals: keeping the shares of joint stock companies in the hands of central government, while passing the responsibility for the sector to the municipalities.\n\nIt is thus perhaps not surprising that the transformation of regional water companies to joint stock companies was slow: as of 2003 only 10 had completed the transformation and the by-laws necessary for the implementation of the local government law were not yet issued. The continued strong role of central government is shown by the fact that in the privatization process the central government, and not local governments, selected the private companies and signed the contracts with them.\n\nThe first private sector contract, a 30-year concession for Elbasan, took effect in April 2002. It was awarded to Berlinwasser International. It was supported by German development cooperation, which was to finance 70% of investment while the remainder was to be financed by the private concessionnaire. The contract had been negotiated between Berlinwasser and the Albanian government since 1999, when it had been expected the contract would be signed in 2000.\n\nThe second contract, a 4-year management contract for the Kavajë district, took effect in early 2003. The contract was meant to “prepare the ground for more substantial private sector participation at a later stage.” It was awarded to Aquamundo and was also financed by German development cooperation. Aquamundo was initially a joint venture owned by ABB, Bilfinger Berger and , the utility that serves the German city of Mannheim. However, according to other sources Aquamundo was two third-owned by the Saudi Arabian Amiantit Company, through its subsidiary AmiWater, when it signed the contract. According to the company website, Aquamundo has only been part of Amiantit Company since 2004.\n\nThe objectives were to introduce continuous water supply, reduce water losses and increase bill collection. Furthermore, the contract included the construction and operation of the first wastewater treatment plant in Albania.\n\nThe third contract, a 5-year management contract for the districts of Durrës, Fier, Lezhë and Sarandë, took effect in June 2003. It was financed by the World Bank. The objectives of this contract were to increase the continuity of water supply, to improve water quality, to increase bill collection and cost recovery. It was signed with Berlinwasser International, but Aquamundo was involved as a subcontractor.\n\nThere is little public information available about the impact of the privatization in Elbasan and Kavajë. However, the World Bank has published detailed information on the impact of the four cities concession in the completion report for the project that financed the management contract.\n\nService quality. The continuity of supply in Fier and Sarandë increased significantly, but it remained unchanged at a low level of 2–3 hours per day in Durrës and equally unchanged at a high level of 20 hours per day in Lezhë. Water quality compliance improved markedly in Lehzë and Sarandë; it had already been good in the other two cities.\n\nCost recovery. Financial indicators for the four utilities had been below the Albanian average at the beginning of the management contract, although the Albanian average was already below the average of other formerly communist countries. From this dismal starting point the collection efficiency and cost recovery improved somewhat, but remained far from satisfactory: Collection efficiency was 56-81% and operating cost recovery 40-60% at the beginning of the contract. The objective of 79% collection efficiency was reached in only one city, while the objective of operation cost recovery was not reached in any city despite tariff increases. Residential water tariffs almost doubled in two cities and almost tripled in the other two between 2002 and 2008. They were 15-20 Lek per cubic meter in 2002 (11-15 Euro Cent) and stood at 35-43 Lek (29-36 Euro Cent) in 2008. In order to protect the poor from tariff increases, the Government supported the four municipalities to test a free basic water policy. Low-income metered households were to be provided 20 liters per capita per day free of charge beginning in 2004. However, the policy was difficult to implement, because metering is a precondition for free basic water and only about 20% of residential customers were metered. Without free basic water, a tariff of 40 Lek per cubic meter corresponded to about 3% of the income of a poor household in 2006.\n\nSupervisory Boards of the utilities retained ultimate authority for key decisions such as staffing. This limited the control of the private operator over key decisions, making it more difficult to achieve the objectives.\n\nThe Elbasan concession with Berlinwasser was terminated early in 2007 in mutual agreement, while the management contracts expired in 2007 and 2008 without being renewed. The responsibility for water supply and sanitation reverted to the municipal utilities.\n\n\n"}
