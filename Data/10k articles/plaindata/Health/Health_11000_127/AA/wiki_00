{"id": "38095452", "url": "https://en.wikipedia.org/wiki?curid=38095452", "title": "Abortion in Luxembourg", "text": "Abortion in Luxembourg\n\nAbortion in Luxembourg was liberalized on 15 November 1978. \nBefore the end of 12 weeks after conception (14 weeks after the last menstrual period), a woman who determines herself to be \"in distress\" can obtain an abortion after two consultations with a doctor, one medical and one psycho-social, and a waiting period of at least three days. An abortion at later stages can only be obtained when two doctors certify there is a danger to the mother or fetus. Under-age patients must be accompanied by a trusted adult to the meetings and the procedure itself. Abortions may be performed in hospitals, clinics, and a doctor's surgery.\n\nBefore reforms passed in 2012, only a doctor could determine if a woman was \"in distress\". Abortions in the first twelve weeks were only permitted in the event of a physical or mental health threat to the mother, a serious risk that the child would be born with a serious disease or serious defects, or a pregnancy resulting from rape. Under-age patients needed to obtain parental consent for an abortion, and abortions could only be performed in hospitals and clinics.\n\nMany doctors in Luxembourg opt out of providing abortion services as conscientious objectors. Doctors who choose not to conduct an abortion, or are incapable of doing so, are required to refer the patient to another medical practitioner under the 2012 law.\n"}
{"id": "462243", "url": "https://en.wikipedia.org/wiki?curid=462243", "title": "Agnodice", "text": "Agnodice\n\nAgnodice or Agnodike (, c. 4th century BCE) is a legendary figure credited as the first female midwife or physician in ancient Athens. Her story is told by the Roman author Gaius Julius Hyginus in his \"Fabulae\". Agnodice is not generally believed to be a historical figure, but her story has been frequently deployed as a precedent for women practising midwifery or medicine.\n\nAccording to Hyginus, Agnodice studied medicine under Herophilus, and worked as a physician in her home city of Athens disguised as a man, because women at the time were forbidden from practising medicine. As her popularity with female patients grew, rival physicians accused her of seducing the women of Athens. She was tried, and revealed her sex to the jury by lifting her tunic. Accused of illegally practising medicine as a woman, she was defended by the women of Athens who praised her for her effective treatments. She was acquitted, and the law against female physicians in Athens was revoked.\n\nHyginus wrote that Agnodice lived in ancient Athens, where at the time women were forbidden from studying medicine. In order to learn medicine, she disguised herself as a man, cutting her hair short, and studied under Herophilus in Alexandria. Having trained as a physician, Agnodice tried to assist women in labour, who were ashamed of, or blatantly refused to consult male practitioners. In one case, Agnodice therefore revealed her sex and was permitted to treat the woman. Other doctors, growing jealous of Agnodice's success, accused her of seducing her patients. On trial before the Areopagus, Agnodice once again lifted her clothes, revealing that she was a woman. She was then charged with breaking the law which forbade women from practising medicine, but was defended by the wives of important Athenians whom she had treated. In response to this, the law was changed to allow women to practise medicine.\n\nHyginus describes Agnodice as an \"obstetrix\". It is difficult to know how to translate this into English. Sarah Pomeroy has rendered it as \"obstetrician\", arguing that midwives existed in Athens in Agnodice's day but that Agnodice was distinguished by her formal education in medicine. However, Helen King notes that there was no \"formal licensing system\" for medics in the ancient world, and that it is anachronistic to divide ancient healers into the distinct categories of \"midwife\" and \"obstetrician\".\n\nModern scholars generally doubt that Agnodice was a real historical figure. Problems with accepting Agnodice as historical include questions over her date, and the implausibility of Hyginus' claim that there were no \"obstetrices\" in Athens before Agnodice, when literary and epigraphic evidence shows that midwives were known. Hyginus claims that Agnodice was taught medicine by Herophilus – generally identified with Herophilus of Chalcedon, an ancient physician known for his work on gynaecology who was credited with the discovery of the ovaries. If this is the case, Agnodice would have lived in the late fourth or early third century BC.\n\nThe context of Agnodice’s story and similar stories could be interpreted as belonging to various different contexts, including either Greco-Roman, ancient Mediterranean, Western folk, or world ethnography. The context depends on what’s being studied, whether it be the related literatures, or other visual artistic artifacts outside the literary canon. Scholars warn against an ethnographic reading so might we not view Agnodice’s gestures as universal. \n\nThose who believe in the historicity of Agnodice have come to two separate conclusions explaining the lack of midwives in Athens before her. The first theory is that there were no midwives prior to Agnodice; alternatively, it has been proposed that there were earlier midwives but they had been forbidden by law from practising. This second theory has been elaborated over time, with Kate Hurd-Mead, in 1938, being the first to propose that women had been forbidden from practising medicine because they had been accused of performing abortions.\n\nAgnodice's story, widely recognized as fictional, is also widely accepted as being first written in ancient Greece. Herophilus, Agnodice's teacher, is regarded as a real historical figure who lived during the third century BC. The original text has not been preserved, but passed down in Latin by an unknown Greek scribe during the second century AD. Though even this Latin version isn't preserved, we know of it through a summary concerning it, written a few hundred years later. The summary surfaced during the Renaissance when bits of the manuscript were used to support book bindings. Since then, later versions of the tale have been told and popularized. \n\nThe story of Agnodice has been invoked since the sixteenth century to provide precedents for a range of gender options within the medical profession. While some later users of the story focused on the midwifery claims in the opening line, for example arguing that men were midwives before women were, or that women were midwives first, others have concentrated on what Agnodice is supposed to have learned from Herophilus, which was medicine rather than midwifery. Thus she was used both in the peak of men-midwifery in the eighteenth century and in women's struggle to enter the medical profession in the nineteenth century. Elizabeth Cellier, the seventeenth century \"Popish midwife\", positioned herself as a modern Agnodice.\n\nHowever, others have taken the story of Agnodice as a negative example: Augustus Gardner, for instance, in 1851 delivered a lecture arguing that \"literally, no improvement was made\" in the \"many centuries\" where midwifery was a women's profession, comparing Agnodice to the 19th century abortionist Madame Restell.\n\n"}
{"id": "1105247", "url": "https://en.wikipedia.org/wiki?curid=1105247", "title": "Alarm clock", "text": "Alarm clock\n\nAn alarm clock (alarm for short) is a clock that is designed to alert an individual or group of individuals at specified time. The primary function of these clocks is to awaken people from their night's sleep or short naps; they are sometimes used for other reminders as well. Most use sound; some use light or vibration. Some have sensors to identify when a person is in a light stage of sleep, in order to avoid waking someone who is deeply asleep, which causes tiredness, even if the person has had adequate sleep. To stop the sound or light, a button or handle on the clock is pressed; most clocks automatically stop the alarm if left unattended long enough. A classic analog alarm clock has an extra hand or inset dial that is used to specify the time at which to activate the alarm. Alarm clocks are also found on mobile phones, watches, and computers.\n\nMany alarm clocks have radio receivers that can be set to start playing at specified times, and are known as \"clock radios\". Some alarm clocks can set multiple alarms, a useful feature for couples who have different waking up schedules. A \"progressive alarm clock\", still new in the market, can have different alarms for different times (see Next-Generation Alarms) and even play music of your choice. Most modern televisions, mobile phones and digital watches have alarm clock functions to turn on or make sounds at a specific time.\n\nTraditional mechanical alarm clocks have one or two bells that ring by means of a mainspring that powers a gear to propel a hammer back and forth between the two bells or between the interior sides of a single bell. In some models, the back encasement of the clock itself acts as the bell. In an electric bell-style alarm clock, the bell is rung by an electromagnetic circuit and armature that turns the circuit on and off repeatedly.\n\nDigital alarm clocks can make other noises. Simple battery-powered alarm clocks make a loud buzzing or beeping sound to wake a sleeper, while novelty alarm clocks can speak, laugh, sing, or play sounds from nature.\n\nThe ancient Greek philosopher Plato (428–348 BC) was said to possess a large water clock with an unspecified alarm signal similar to the sound of a water organ; he used it at night, possibly for signaling the beginning of his lectures at dawn (Athenaeus 4.174c). The Hellenistic engineer and inventor Ctesibius (fl. 285–222 BC) fitted his clepsydras with dial and pointer for indicating the time, and added elaborate \"alarm systems, which could be made to drop pebbles on a gong, or blow trumpets (by forcing bell-jars down into water and taking the compressed air through a beating reed) at pre-set times\" (Vitruv 11.11).\n\nThe late Roman statesman Cassiodorus (c. 485–585) advocated in his rulebook for monastic life the water clock as a useful alarm for the 'soldiers of Christ' (Cassiod. Inst. 30.4 f.). The Christian rhetorician Procopius described in detail prior to 529 a complex public striking clock in his home town Gaza which featured an hourly gong and figures moving mechanically day and night.\n\nIn China, a striking clock was devised by the Buddhist monk and inventor Yi Xing (683–727). The Chinese engineers Zhang Sixun and Su Song integrated striking clock mechanisms in astronomical clocks in the 10th and 11th centuries, respectively. A striking clock outside of China was the water-powered clock tower near the Umayyad Mosque in Damascus, Syria, which struck once every hour. It was constructed by the Arab engineer al-Kaysarani in 1154. In 1235, an early monumental water-powered alarm clock that \"announced the appointed hours of prayer and the time both by day and by night\" was completed in the entrance hall of the Mustansiriya Madrasah in Baghdad.\n\nFrom the 14th century, some clock towers in Western Europe were also capable of chiming at a fixed time every day; the earliest of these was described by the Florentine writer Dante Alighieri in 1319. The most famous original striking clock tower still standing is possibly the one in St Mark's Clocktower in St Mark's Square, Venice. The St Mark's Clock was assembled in 1493, by the famous clockmaker Gian Carlo Rainieri from Reggio Emilia, where his father Gian Paolo Rainieri had already constructed another famous device in 1481. In 1497, Simone Campanato moulded the great bell (h. 1,56 m., diameter m. 1,27), which was put on the top of the tower where it was alternatively beaten by the \"Due Mori\" (\"Two Moors\"), two bronze statues (h. 2,60) handling a hammer.\n\nUser-settable mechanical alarm clocks date back at least to 15th-century Europe. These early alarm clocks had a ring of holes in the clock dial and were set by placing a pin in the appropriate hole.\n\nThe first American alarm clock was created by Levi Hutchins, of New Hampshire in the United States, in 1787. This device he made only for himself however, and it only rang at 4 AM, in order to wake him for his job. The French inventor Antoine Redier was the first to patent an adjustable mechanical alarm clock, in 1847.\n\nAlarm clocks, like almost all other consumer goods in the United States, ceased production in the spring of 1942, as the factories which made them were converted over to war work during World War II, but they were one of the first consumer items to resume manufacture for civilian use, in November 1944. By that time, a critical shortage of alarm clocks had developed due to older clocks wearing out or breaking down. Workers were late for, or missed completely, their scheduled shifts in jobs critical to the war effort. In a pooling arrangement overseen by the Office of Price Administration, several clock companies were allowed to start producing new clocks, some of which were continuations of pre-war designs, and some of which were new designs, thus becoming among the first \"postwar\" consumer goods to be made, before the war had even ended. The price of these \"emergency\" clocks was, however, still strictly regulated by the Office of Price Administration.\n\nThe first radio alarm clock was invented by James F. Reynolds, in the 1940s and another design was also invented by Paul L. Schroth Sr.\n\nA clock radio is an alarm clock and radio receiver integrated in one device. The clock may turn on the radio at a designated time to wake the user, and usually includes a buzzer alarm. Typically, clock radios are placed on the bedside stand. Some models offer dual alarm for awakening at different times and \"snooze\", usually a large button on the top that silences the alarm and sets it to resume sounding a few minutes later. Some clock radios also have a \"sleep\" timer, which turns the radio on for a set amount of time (usually around one hour). This is useful for people who like to fall asleep while listening to the radio.\n\nNewer clock radios are available with other music sources such as iPod, iPhone, and/or audio CD. When the alarm is triggered, it can play a set radio station or the music from a selected music source to awaken the sleeper. Some models come with a dock for iPod/iPhone that also charges the device while it is docked. They can play AM/FM radio, iPod/iPhone or CD like a typical music player as well (without being triggered by the alarm function). A few popular models offer \"nature sounds\" like rain, forest, wind, sea, waterfall etc., in place of the buzzer.\n\nClock radios are powered by AC power from the wall socket. In the event of a power interruption, older electronic digital models used to reset the time to midnight (00:00) and lose alarm settings. This would cause failure to trigger the alarm even if the power is restored. Many newer clock radios feature a battery backup to maintain the time and alarm settings. Some advanced radio clocks (not to be confused with clocks with AM/FM radios) have a feature which sets the time automatically using signals from atomic clock-synced time signal radio stations such as WWV, making the clock accurate and immune to time reset due to power interruptions.\n\nAlarm clock software programs have been developed for personal computers. A computer acting as an alarm clock through a website may allow a virtually unlimited number of alarm times (i.e. Personal information manager) and personalized tones.\nMany modern mobile phones feature built-in alarm clocks that do not need the phone to be switched on for the alarm to ring off. Some of these mobile phones feature the ability for the user to set the alarm's ringtone, and in some cases music can be downloaded to the phone and then chosen to play for waking.\n\nScientific studies on sleep having shown that sleep stage at awakening is an important factor in amplifying sleep inertia. Alarm clocks involving \"sleep stage monitoring\" appeared on the market in 2005. The alarm clocks use sensing technologies such as EEG electrodes and accelerometers to wake people from sleep.Dawn simulators are another technology meant to mediate these effects.\n\nSleepers can become accustomed to the sound of their alarm clock if it has been used for a period of time, making it less effective. Due to progressive alarm clocks complex waking procedure, they can deter this adaptation due to the body needing to adapt to more stimuli than just a simple sound alert.\n\nThe deaf and hard of hearing are often unable to perceive auditory alarms when asleep. They may use specialized alarms, including alarms with flashing lights instead of or in addition to noise. Alarms which can connect to vibrating devices (small ones inserted into pillows, or larger ones placed under bedposts to shake the bed) also exist.\n\nTime switches can be used to turn on anything that will awaken a sleeper, and can therefore be used as alarms. Lights, bells, and radio and TV sets can easily be used. More elaborate devices have also been used, such as machines that automatically prepare tea or coffee. A sound is produced when the drink is ready, so the sleeper awakes to find the freshly brewed drink waiting.\n\n\n"}
{"id": "16024353", "url": "https://en.wikipedia.org/wiki?curid=16024353", "title": "Amniotic fluid index", "text": "Amniotic fluid index\n\nAmniotic fluid index (AFI) is a quantitative estimate of amniotic fluid and an indicator of fetal well-being. It is a part of the biophysical profile.\n\nLeaking or rupture of membranes may be caused by a gush of fluid or a slow constant trickle of fluid. This is due to a tear in the membrane. Premature rupture of membranes can also result in low amniotic fluid levels.\nPlacental problems may cause low amniotic fluid. If the placenta is not providing enough blood and nutrients to the baby, then the baby may stop recycling fluid.\nBirth defects may occur if the fetus has problems with the development of the kidneys or urinary tract, which could cause little urine production, and it can lead to low levels of amniotic fluid.\nMaternal complications may cause low amniotic fluid. Some factors such as hypertension, diabetes, dehydration, preeclampsia, and chronic hypoxia in a woman can have an effect on amniotic fluid levels.\n"}
{"id": "55967427", "url": "https://en.wikipedia.org/wiki?curid=55967427", "title": "Apple Maggot Quarantine Area", "text": "Apple Maggot Quarantine Area\n\nThe Apple Maggot Quarantine Area is a permanent quarantine area established by the U.S. state of Washington. The quarantine was authorized under Washington state law and the area's boundaries are periodically reset by the state's Department of Agriculture. The quarantine was declared in the early 1980s to arrest the spread of the apple maggot into a portion of eastern Washington.\n\nThe apple maggot, which is not indigenous to the Pacific Northwest, was discovered to have arrived in Washington in 1980. The quarantine was declared thereafter and is designed to protect Washington's core apple growing regions from infestation. The Washington State Department of Transportation installed 70 signs along highways around the state in 1985 to warn of the quarantine.\n\nAuthority for the quarantine is codified under Title 17 of the Revised Code of Washington.\n\nWashington exported $718 million worth of apples in 2016, making apples the state's seventh largest export, and the apple has been declared the official state fruit. Almost two-thirds of all apples grown in the United States are produced in Washington. According to the Washington Apple Commission, the quality standards for Washington apples \"are more stringent than grading standards used in any other growing region in the world\". A mandatory inspection program requires apples, all of which are hand-picked, to meet this set of standards that, in some criteria factors, exceed those set by the United States Department of Agriculture. \n\nThe state's Department of Agriculture has said that the apple maggot threatens \"Washington's iconic apple industry, as well as many of our other fruit crops\". The establishment of reproducing populations of the apple maggot within Washington would have a devastating impact on the state's apple industry resulting from the potential loss of export markets.\n\nEach year, the Washington state Department of Agriculture deploys apple maggot traps to a selection of sites in the state with between 5,500 to 8,500 traps deployed annually. The traps are yellow paneled, adhesive traps baited with ammonium carbonate lures. The area surrounding locations which successfully trap apple maggots may be further studied by analyzing fruit in the area for the presence of apple maggot larvae and, ultimately, placed in the quarantine zone. In 2011, for instance, the trapping of 35 apple maggots at 23 locations in Chelan County resulted in a recommendation to extend the quarantine zone to the western part of that county.\n\nThe states of Oregon, California, Idaho, and Utah, all areas of the eastern United States, and all \"foreign countries where apple maggot is established\" have also been placed under quarantine by Washington. In addition to these areas, as of 2017, all or portions of the state's counties of Chelan, Clallam, Clark, Cowlitz, Grays Harbor, Island, Jefferson, King, Kitsap, Klickitat, Lewis, Lincoln, Mason, Pacific, Pierce, Snohomish, Spokane, Skagit, Skamania, Thurston, Wahkiakum, Whatcom, and Yakima, are also quarantined. \n\nWashington State University's Tree Fruit Research and Extension Center has cited the fact that \"apple maggots have never been found in commercially packed fruit in the state\" as evidence of the quarantine's efficacy.\n\nThere is a prohibition on transporting homegrown or foraged fruit from the quarantine zone into the pest free zone, except for fruit that has first been processed through canning, jarring, juicing, or drying. In addition, any yard waste from the quarantine zone must be disposed of within the zone and cannot be transported across its boundaries. Store-bought fruit is exempt from the quarantine as it is already subject to inspection by state authorities.\n\nIn addition, under state law pest control officials can order property owners to spray with pesticides trees in which the apple maggot has been observed.\n\nApple Maggot Quarantine Area, also known was A.M.Q.A., was the name of a metal band from Seattle active from 1985 to 1989.\n\n\n"}
{"id": "3937909", "url": "https://en.wikipedia.org/wiki?curid=3937909", "title": "Body fat percentage", "text": "Body fat percentage\n\nThe body fat percentage (BFP) of a human or other living being is the total mass of fat divided by total body mass, multiplied by 100; body fat includes essential body fat and storage body fat. Essential body fat is necessary to maintain life and reproductive functions. The percentage of essential body fat for women is greater than that for men, due to the demands of childbearing and other hormonal functions. Storage body fat consists of fat accumulation in adipose tissue, part of which protects internal organs in the chest and abdomen. The minimum recommended total body fat percentage exceeds the essential fat percentage value reported above. A number of methods are available for determining body fat percentage, such as measurement with calipers or through the use of bioelectrical impedance analysis.\n\nThe body fat percentage is a measure of fitness level, since it is the only body measurement which directly calculates a person's relative body composition without regard to height or weight. The widely used body mass index (BMI) provides a measure that allows the comparison of the adiposity of individuals of different heights and weights. While BMI largely increases as adiposity increases, due to differences in body composition, other indicators of body fat give more accurate results; for example, individuals with greater muscle mass or larger bones will have higher BMIs. As such, BMI is a useful indicator of overall fitness for a large group of people, but a poor tool for determining the health of an individual.\n\nEpidemiologically, the percentage of body fat in an individual varies according to sex and age. Various theoretical approaches exist on the relationships between body fat percentage, health, athletic capacity, etc. Different authorities have consequently developed different recommendations for ideal body fat percentages.\n\nThis graph from the National Health and Nutrition Examination Survey in the United States charts the average body fat percentages of Americans from samples from 1999–2004:\n\nIn males, mean percentage body fat ranged from 22.9% at age 16–19 years to 30.9% at age 60–79 years. In females, mean percentage body fat ranged from 32.0% at age 8–11 years to 42.4% at age 60–79 years.\n\nThe table below from the American Council on Exercise shows how average percentages differ according to the specified groups and categories:\nEssential fat is the level at which physical and physiological health would be negatively affected, and below which death is certain. Controversy exists as to whether a particular body fat percentage is better for one's health; athletic performance may also be affected. The leanest athletes typically compete at levels of about 6-13% for men or 14–20% for women. Bodybuilders may compete at essential body fat range, in fact certified personal trainers will suggest them to keep that extremely low level of body fat only for the contest time. However it is unclear that such levels are ever actually attained since (a) the means to measure such levels are, as noted below, lacking in principle and inaccurate, and (b) 4–6% is generally considered a physiological minimum for human males.\n\nIrrespective of the location from which they are obtained, the fat cells in humans are composed almost entirely of pure triglycerides with an average density of about 0.9 kilograms per litre. Most modern body composition laboratories today use the value of 1.1 kilograms per litre for the density of the “fat free mass”, a theoretical tissue composed of 72% water (density = 0.993), 21% protein (density = 1.340) and 7% mineral (density = 3.000) by weight.\n\nWith a well engineered weighing system, body density can be determined with great accuracy by completely submerging a person in water and calculating the volume of the displaced water from the weight of the displaced water. A correction is made for the buoyancy of air in the lungs and other gases in the body spaces. If there were no errors whatsoever in measuring body density, the uncertainty in fat estimation would be about ± 3.8% of the body weight, primarily because of normal variability in body constituents.\n\nWhole-body air displacement plethysmography (ADP) is a recognised and scientifically validated densitometric method to measure human body fat percentage. ADP uses the same principles as the gold-standard method of underwater weighing, but representing a densitometric method that is based on air displacement rather than on water immersion. Air-displacement plethysmography offers several advantages over established reference methods, including a quick, comfortable, automated, noninvasive, and safe measurement process, and accommodation of various subject types (e.g., children, obese, elderly, and disabled persons). However, its accuracy declines at the extremes of body fat percentages, tending to slightly understate the percent body fat in overweight and obese persons (by 1.68–2.94% depending on the method of calculation), and to overstate to a much larger degree the percent body fat in very lean subjects (by an average of 6.8%, with up to a 13% overstatement of the reported body percentage of one individual — i.e. 2% body fat by DXA but 15% by ADP).\n\nA beam of infra-red light is transmitted into a biceps. The light is reflected from the underlying muscle and absorbed by the fatileur . The method is safe, noninvasive, rapid and easy to use.\n\nDual energy X-ray absorptiometry, or DXA (formerly DEXA), is a newer method for estimating body fat percentage, and determining body composition and bone mineral density.\n\nX-rays of two different energies are used to scan the body, one of which is absorbed more strongly by fat than the other. A computer can subtract one image from the other, and the difference indicates the amount of fat relative to other tissues at each point. A sum over the entire image enables calculation of the overall body composition.\n\nThere are several more complicated procedures that more accurately determine body fat percentage. Some, referred to as multicompartment models, can include DXA measurement of bone, plus independent measures of body water (using the dilution principle with isotopically labeled water) and body volume (either by water displacement or air plethysmography). Various other components may be independently measured, such as total body potassium.\n\nIn-vivo neutron activation can quantify all the elements of the body and use mathematical relations among the measured elements in the different components of the body (fat, water, protein, etc.) to develop simultaneous equations to estimate total body composition, including body fat.\n\nPrior to the adoption of DXA, the most accurate method of estimating body fat percentage was to measure that person's average density (total mass divided by total volume) and apply a formula to convert that to body fat percentage.\n\nSince fat tissue has a lower density than muscles and bones, it is possible\nto estimate the fat content. This estimate is distorted by the fact that muscles and bones have different densities: for a person with a more-than-average amount of bone mass, the estimate will be too low. However, this method gives highly reproducible results for individual persons (± 1%), unlike the methods discussed below, which can have an uncertainty of 10%, or more. The body fat percentage is commonly calculated from one of two formulas (ρ represents density in g/cm):\n\nThe bioelectrical impedance analysis (BIA) method is a lower-cost (from less than one to several hundred US dollars in 2006) but less accurate way to estimate body fat percentage. The general principle behind BIA: two or more conductors are attached to a person's body and a small electric current is sent through the body. The resistance between the conductors will provide a measure of body fat between a pair of electrodes, since the resistance to electricity varies between adipose, muscular and skeletal tissue. Fat-free mass (muscle) is a good conductor as it contains a large amount of water (approximately 73%) and electrolytes, while fat is anhydrous and a poor conductor of electric current. Factors that affect the accuracy and precision of this method include instrumentation, subject factors, technician skill, and the prediction equation formulated to estimate the fat-free mass.\n\nEach (bare) foot may be placed on an electrode, with the current sent up one leg, across the abdomen and down the other leg. (For convenience, an instrument which must be stepped on will also measure weight.) Alternatively, an electrode may be held in each hand; calculation of fat percentage uses the weight, so that must be measured with scales and entered by the user. The two methods may give different percentages, without being inconsistent, as they measure fat in different parts of the body. More sophisticated instruments for domestic use are available with electrodes for both feet and hands.\n\nThere is little scope for technician error as such, but factors such as eating, drinking and exercising must be controlled since hydration level is an important source of error in determining the flow of the electric current to estimate body fat. The instructions for use of instruments typically recommended not making measurements soon after drinking or eating or exercising, or when dehydrated. Instruments require details such as sex and age to be entered, and use formulae taking these into account; for example, men and women store fat differently around the abdomen and thigh region.\n\nDifferent BIA analysers may vary. Population-specific equations are available for some instruments, which are only reliable for specific ethnic groups, populations, and conditions. Population-specific equations may not be appropriate for individuals outside of specific groups.\n\nThere exist various anthropometric methods for estimating body fat. The term \"anthropometric\" refers to measurements made of various parameters of the human body, such as circumferences of various body parts or thicknesses of skinfolds. Most of these methods are based on a statistical model. Some measurements are selected, and are applied to a population sample. For each individual in the sample, the method's measurements are recorded, and that individual's body density is also recorded, being determined by, for instance, under-water weighing, in combination with a multi-compartment body density model. From this data, a formula relating the body measurements to density is developed.\n\nBecause most anthropometric formulas such as the Durnin-Womersley skinfold method, the Jackson-Pollock skinfold method, and the US Navy circumference method, actually estimate body density, not body fat percentage, the body fat percentage is obtained by applying a second formula, such as the Siri or Brozek described in the above section on density. Consequently, the body fat percentage calculated from skin folds or other anthropometric methods carries the cumulative error from the application of two separate statistical models.\n\nThese methods are therefore inferior to a direct measurement of body density and the application of just one formula to estimate body fat percentage. One way to regard these methods is that they trade accuracy for convenience, since it is much more convenient to take a few body measurements than to submerge individuals in water.\n\nThe chief problem with all statistically derived formulas is that in order to be widely applicable, they must be based on a broad sample of individuals. Yet, that breadth makes them inherently inaccurate. The ideal statistical estimation method for an individual is based on a sample of similar individuals. For instance, a skinfold based body density formula developed from a sample of male collegiate rowers is likely to be much more accurate for estimating the body density of a male collegiate rower than a method developed using a sample of the general population, because the sample is narrowed down by age, sex, physical fitness level, type of sport, and lifestyle factors. On the other hand, such a formula is unsuitable for general use.\n\nThe skinfold estimation methods are based on a \"skinfold test\", also known as a \"pinch test\", whereby a pinch of skin is precisely measured by calipers, also known as a Plicometer, at several standardized points on the body to determine the subcutaneous fat layer thickness. These measurements are converted to an estimated body fat percentage by an equation. Some formulas require as few as three measurements, others as many as seven. The accuracy of these estimates is more dependent on a person's unique body fat distribution than on the number of sites measured. As well, it is of utmost importance to test in a precise location with a fixed pressure. Although it may not give an accurate reading of real body fat percentage, it is a reliable measure of body composition change over a period of time, provided the test is carried out by the same person with the same technique.\n\nSkinfold-based body fat estimation is sensitive to the type of caliper used, and technique. This method also only measures one type of fat: subcutaneous adipose tissue (fat under the skin). Two individuals might have nearly identical measurements at all of the skin fold sites, yet differ greatly in their body fat levels due to differences in other body fat deposits such as visceral adipose tissue: fat in the abdominal cavity. Some models partially address this problem by including age as a variable in the statistics and the resulting formula. Older individuals are found to have a lower body density for the same skinfold measurements, which is assumed to signify a higher body fat percentage. However, older, highly athletic individuals might not fit this assumption, causing the formulas to underestimate their body density.\n\nUltrasound is used extensively to measure tissue structure and has proven to be an accurate technique to measure subcutaneous fat thickness. A-mode and B-mode ultrasound systems are now used and both rely on using tabulated values of tissue sound speed and automated signal analysis to determine fat thickness. By making thickness measurements at multiple sites on the body you can calculate the estimated body fat percentage. Ultrasound techniques can also be used to directly measure muscle thickness and quantify intramuscular fat. Ultrasound equipment is expensive, and not cost-effective solely for body fat measurement, but where equipment is available, as in hospitals, the extra cost for the capability to measure body fat is minimal.\n\nThere also exist formulas for estimating body fat percentage from an individual's weight and girth measurements. For example, the U.S. Navy circumference method compares abdomen or waist and hips measurements to neck measurement and height and other sites claim to estimate one's body fat percentage by a conversion from the body mass index. In the U.S. Navy the method is known as the \"rope and choke.\" There is limited information, however, on the validity of the \"rope and choke\" method because of its universal acceptance as inaccurate and easily falsified.\n\nThe U.S. Army and U.S. Marine Corps also rely on the height and circumference method. For males, they measure the neck and waist just above the navel. Females are measured around the hips, waist, and neck. These measurements are then looked up in published tables, with the individual's height as an additional parameter. This method is used because it is a cheap and convenient way to implement a body fat test throughout an entire service.\n\nMethods using circumference have little acceptance outside the Department of Defense due to their negative reputation in comparison to other methods. The method's accuracy becomes an issue when comparing people with different body compositions, those with larger necks artificially generate lower body fat percentage calculations than those with smaller necks.\n\nBody fat can be estimated from body mass index (BMI), a person's mass in kilograms divided by the square of the height in meters; if weight is measured in pounds and height in inches, the result can be converted to BMI by multiplying by 703. There are a number of proposed formulae that relate body fat to BMI. These formulae are based on work by researchers published in peer-reviewed journals, but their correlation with body fat are only estimates; body fat cannot be deduced accurately from BMI.\n\nBody fat may be estimated from the body mass index by formulae derived by Deurenberg and co-workers. When making calculations, the relationship between densitometrically determined body fat percentage (BF%) and BMI must take age and sex into account. Internal and external cross-validation of the prediction formulas showed that they gave valid estimates of body fat in males and females at all ages. In obese subjects, however, the prediction formulas slightly overestimated the BF%. The prediction error is comparable to the prediction error obtained with other methods of estimating BF%, such as skinfold thickness measurements and bioelectrical impedance. The formula for children is different; the relationship between BMI and BF% in children was found to differ from that in adults due to the height-related increase in BMI in children aged 15 years and younger.\n\nHowever – contrary to the aforementioned internal and external cross-validation –, these formulae definitely proved unusable at least for adults and are presented here illustratively only.\n\nStill, the following formula designed for adults proved to be much more accurate at least for adults:\n\nOther indices may be used; the body adiposity index was said by its developers to give a direct estimate of body fat percentage, but statistical studies found this not to be so.\n\n"}
{"id": "9072912", "url": "https://en.wikipedia.org/wiki?curid=9072912", "title": "California Division of Occupational Safety and Health", "text": "California Division of Occupational Safety and Health\n\nThe Division of Occupational Safety and Health of California (DOSH, but more commonly known as Cal/OSHA) is an agency of the Government of California established by the California Occupational Safety & Health Act of 1973. Administered by the California Department of Industrial Relations, Cal/OSHA's mission is to protect public health and safety through research and regulation related to hazards on the job in California workplaces as well as on elevators, amusement rides, and ski lifts, and related to the use of pressure vessels such as boilers and tanks. Cal/OSHA requires that qualifying organizations create illness and injury prevention programs meant to help identify and eliminate dangers before accidents and illnesses occur.\n\nAs of December 22, 2015, Cal/OSHA employed 195 field enforcement officers, 25 of whom received bilingual pay for using a second language at least 10% of the time on the job. The organization offers training materials and paid training time to staff interested in learning other languages and encourages bilingual applicants to apply.\n\n\n"}
{"id": "34208897", "url": "https://en.wikipedia.org/wiki?curid=34208897", "title": "Cryptotia", "text": "Cryptotia\n\nCryptotia is the condition where an ear appears to have its upper portion buried underneath the side of the head. The condition also involves underdeveloped scapha and antihelical crura. Cryptotia is also known as buried ear or hidden ear.\n\nCryptotia is often treated through surgery which involves releasing the ear from its buried position, reshaping the cartilage and using local tissue to resurface the released cartilage.\n\n"}
{"id": "32059473", "url": "https://en.wikipedia.org/wiki?curid=32059473", "title": "DKH", "text": "DKH\n\nDegrees of carbonate hardness (dKH or °KH; the K is from the German \"Karbonathärte\") is a unit of water hardness, specifically for temporary or carbonate hardness. Carbonate hardness is a measure of the concentration of carbonates such as calcium carbonate (CaCO) and magnesium carbonate (MgCO) per volume of water. Specifically, 1 dKH is defined as 17.86 milligrams (mg) of calcium carbonate per litre of water, i.e. 17.86 ppm. Since a mole of calcium carbonate weighs 100.09 grams, 1 dKH is equivalent to 0.17832 mmol per litre. \n\ndKH are the same as °fH, degrees of French hardness.\n\n\n"}
{"id": "8521738", "url": "https://en.wikipedia.org/wiki?curid=8521738", "title": "Depression and Bipolar Support Alliance", "text": "Depression and Bipolar Support Alliance\n\nThe Depression and Bipolar Support Alliance (DBSA), formerly the National Depressive and Manic Depressive Association (NDMDA), is a non-profit organization providing support groups for people with depression or bipolar disorder as well as their friends and family. DBSA's scope, also includes outreach, education and advocacy regarding depression and bipolar disorder. DBSA employs a small staff and operates with the guidance of a Scientific Advisory Board.\n\nDBSA sponsors online and \"face to face\" support groups. A nonrandomized study found participants in such groups reported their coping skills, medication compliance, and acceptance of their illness correlated with participation. Member hospitalization decreased by 49% (from 82% to 33%). Following an initial meeting, members were found to be 6.8 times more likely to attend subsequent meetings if accompanied by a member the first time.\n\nDBSA is a not-for-profit 501(c)(3) organization that answers more than 3,000 calls per month on their toll-free information and referral line and receives over 21 million hits per year on their combined websites. Each month, DBSA distributes nearly 20,000 educational materials free of charge to anyone requesting information about mood disorders. DBSA reaches nearly five million people through their educational materials and programs, exhibit materials, and media activities. \n\n\n"}
{"id": "23977696", "url": "https://en.wikipedia.org/wiki?curid=23977696", "title": "Duct (industrial exhaust)", "text": "Duct (industrial exhaust)\n\nIndustrial exhaust ducts are pipe systems that connect hoods to industrial chimneys through other components of exhaust systems like fans, collectors, etc. Ducts are low-pressure pneumatic conveyors to convey dust, particles, shavings, fumes, or chemical hazardous components from air in the vicinity to a shop floor or any other specific locations like tanks, sanding machines, or laboratory hoods. Ducts can be fabricated from a variety of materials including carbon steel, stainless steel, PVC, and fiberglass. They can be fabricated through rolling (preferable for ducts of 12\" or more in diameter) or extruded (for ducts up to 18\").\n\nHVAC systems do not include this category of industrial application, namely exhaust systems. A distinction from HVAC system ducts is that the fluid (air) conveyed through the duct system may not be homogeneous. An industrial exhaust duct system is primarily a pneumatic conveying system and is basically governed by laws of flow of fluids.\n\nThe conveying fluid that flows through the duct system is air. Air transports materials from the hood to a destination. It is also instrumental in capturing the material into the flow system. Air is a compressible fluid, but for engineering calculations, air is considered as incompressible as a simplification, without any significant errors.\n\nProcess design of exhaust system will include\nThe goal is to keep contaminants out using minimum airflow. It is estimated that increase in an inch wg of static pressure can add a few thousands of dollars to the operation cost per annum.\n\n"}
{"id": "19674646", "url": "https://en.wikipedia.org/wiki?curid=19674646", "title": "Ernst Wynder", "text": "Ernst Wynder\n\nErnst Ludwig Wynder, M.D. (April 30, 1922 – July 14, 1999) was an American epidemiology and public health researcher who studied the health effects of smoking tobacco. His 1950 coauthored publication of \"Tobacco Smoking as a Possible Etiologic Factor in Bronchiogenic Carcinoma: A Study of 684 Proved Cases\" appeared in the Journal of the American Medical Association. It was one of the first major scientific publications identifying smoking as a contributory cause of lung cancer.\n\nWynder was born in Herford, Westphalia in 1922 to Jewish parents (a cousin of Robert Weinberg). In 1938 his family escaped Nazi rule and fled to the United States, where Wynder enrolled at New York University. During World War II, he attained citizenship and joined the U.S. Army, where, as a German-speaker, he was assigned to a psychological warfare unit to monitor German newscasts. After the war, he attended medical school at Washington University in St. Louis. In 1950, he received both a Bachelor of Science and a medical degree. Aside from his credentials as a physician, Wynder was a researcher, educator, and activist. He devoted his career to the study and prevention of cancer and chronic disease, including the publication of hundreds of scientific papers. Through the 1950s and 1960s, he worked at Sloan-Kettering Institute for Cancer Research. In 1969, he founded the American Health Foundation. In 1972, he founded the academic journal \"Preventive Medicine\" and served as the founding editor. Wynder died from thyroid cancer on July 14, 1999.\n\nWynder began collaborating with his coauthor on the article, Evarts Ambrose Graham, as a medical student at Washington University in St. Louis in 1947. The previous summer he had conducted epidemiological studies of smoking behavior among 146 lung cancer patients in New York City. The project was funded by the American Cancer Society. Now, with Graham, Wynder collected extensive data on 604 patients with lung cancer at hospitals across the United States. Departing from a tradition of using anecdotal evidence (e.g., clinical interviews) to develop explanations of disease causation, Wynder and Graham applied rudimentary statistical methods to their study. They divided patients into crude categories of \"moderate\" or \"heavy\" smokers, based on retrospective interviews of each patient's smoking behavior over a twenty-year period. They also measured and controlled for important confounding factors (e.g., age, types of tobacco use, inhalation level). Most importantly, with regard to an ability to demonstrate causation, Wynder and Graham also studied a control group of cancer-free individuals in hospitals. They systematically compared the lung cancer patients to the control group.\n\nOn May 27, 1950 the Journal of the American Medical Association published the resulting scientific report. Incidence among men and women matched patterns of smoking behavior in men and women; 4) \"the enormous increase in the sale of cigarettes in this country approximately parallels the increase in [lung cancer].\" As further scientific evidence of smoking's role in causing lung cancer began to mount in the United States and Great Britain, Wynder and Graham investigated the biological plausibility of the association between smoking and lung disease. In 1950, they initiated a study of the impact of cigarette tar condensate from tobacco smoke on mice skin. After a year of exposure to tar, 44 percent of the mice developed cancers. Wynder also discovered specific carcinogens in tar (e.g., benzopyrenes, arsenic), but was unable to identify the contributions of these chemicals to cancer.\n\nWynder's studies of tobacco smoke were timely and important. Whereas laboratory studies of tobacco tar had been conducted elsewhere, Wynder's findings supported the growing epidemiological data. \"The production of tumors in lab animals offered a powerful indicator that something in cigarette smoke could account for the epidemiological findings,\" writes Allan M. Brandt, a historian of medicine.\n\nWynder published nearly 800 papers during his lifetime. Wynder's work appeared in 139 periodicals and one book. More than half of his articles were published in ten prestigious mainline journals, such as \"Cancer\", the flagship journal of the American Cancer Society. The dominant themes were lung and breast cancer, but there were also in-depth studies of the epidemiology of cancer of the bladder, larynx, colon and rectum, stomach, ovary, prostate, pancreas, and kidney, as well as numerous experimental studies. Many of these papers were the first or most comprehensive studies ever published, especially the massive 1960 coauthored study of the epidemiology of breast cancer.\n\n\n"}
{"id": "22581", "url": "https://en.wikipedia.org/wiki?curid=22581", "title": "Estrogen", "text": "Estrogen\n\nEstrogen, or oestrogen, is the primary female sex hormone. It is responsible for the development and regulation of the female reproductive system and secondary sex characteristics. There are three major endogenous estrogens in females that have estrogenic hormonal activity: estrone, estradiol, and estriol. The estrane steroid estradiol is the most potent and prevalent of these.\n\nEstrogens are synthesized in all vertebrates as well as some insects. Their presence in both vertebrates and insects suggests that estrogenic sex hormones have an ancient evolutionary history. The three major naturally occurring forms of estrogen in females are estrone (E1), estradiol (E2), and estriol (E3). Another type of estrogen called estetrol (E4) is produced only during pregnancy. Quantitatively, estrogens circulate at lower levels than androgens in both men and women. While estrogen levels are significantly lower in males compared to females, estrogens nevertheless also have important physiological roles in males.\n\nLike all steroid hormones, estrogens readily diffuse across the cell membrane. Once inside the cell, they bind to and activate estrogen receptors (ERs) which in turn modulate the expression of many genes. Additionally, estrogens bind to and activate rapid-signaling membrane estrogen receptors (mERs), such as GPER (GPR30).\n\nIn addition to their role as natural hormones, estrogens are used as medications, for instance in menopausal hormone therapy and hormonal birth control; for information on estrogens as medications, see the estrogen (medication) article.\n\nThe four major naturally occurring estrogens in women are estrone (E1), estradiol (E2), estriol (E3), and estetrol (E4). Estradiol is the predominant estrogen during reproductive years both in terms of absolute serum levels as well as in terms of estrogenic activity. During menopause, estrone is the predominant circulating estrogen and during pregnancy estriol is the predominant circulating estrogen in terms of serum levels. Given by subcutaneous injection in mice, estradiol is about 10-fold more potent than estrone and about 100-fold more potent than estriol. Thus, estradiol is the most important estrogen in non-pregnant females who are between the menarche and menopause stages of life. However, during pregnancy this role shifts to estriol, and in postmenopausal women estrone becomes the primary form of estrogen in the body. Another type of estrogen called estetrol (E4) is produced only during pregnancy. All of the different forms of estrogen are synthesized from androgens, specifically testosterone and androstenedione, by the enzyme aromatase.\n\nMinor endogenous estrogens, the biosyntheses of which do not involve aromatase, include 27-hydroxycholesterol, dehydroepiandrosterone (DHEA), 7-oxo-DHEA, 7α-hydroxy-DHEA, 16α-hydroxy-DHEA, 7β-hydroxyepiandrosterone, androstenedione (A4), androstenediol (A5), 3α-androstanediol, and 3β-androstanediol. Some estrogen metabolites, such as the catechol estrogens 2-hydroxyestradiol, 2-hydroxyestrone, 4-hydroxyestradiol, and 4-hydroxyestrone, as well as 16α-hydroxyestrone, are also estrogens with varying degrees of activity. The biological importance of these minor estrogens is not entirely clear.\n\nThe actions of estrogen are mediated by the estrogen receptor (ER), a dimeric nuclear protein that binds to DNA and controls gene expression. Like other steroid hormones, estrogen enters passively into the cell where it binds to and activates the estrogen receptor. The estrogen:ER complex binds to specific DNA sequences called a hormone response element to activate the transcription of target genes (in a study using an estrogen-dependent breast cancer cell line as model, 89 such genes were identified). Since estrogen enters all cells, its actions are dependent on the presence of the ER in the cell. The ER is expressed in specific tissues including the ovary, uterus and breast. The metabolic effects of estrogen in postmenopausal women has been linked to the genetic polymorphism of the ER.\n\nWhile estrogens are present in both men and women, they are usually present at significantly higher levels in women of reproductive age. They promote the development of female secondary sexual characteristics, such as breasts, and are also involved in the thickening of the endometrium and other aspects of regulating the menstrual cycle. In males, estrogen regulates certain functions of the reproductive system important to the maturation of sperm<ref name=\"titleScience News Online (12/6/97): Estrogens Emerging Manly Alter Ego\"></ref> and may be necessary for a healthy libido.\n\n\nEstrogens are responsible for the development of female secondary sexual characteristics during puberty, including breast development, widening of the hips, and female fat distribution. Conversely, androgens are responsible for pubic and body hair growth, as well as acne and axillary odor.\n\nEstrogen, in conjunction with growth hormone (GH) and its secretory product insulin-like growth factor 1 (IGF-1), is critical in mediating breast development during puberty, as well as breast maturation during pregnancy in preparation of lactation and breastfeeding. Estrogen is primarily and directly responsible for inducing the ductal component of breast development, as well as for causing fat deposition and connective tissue growth. It is also indirectly involved in the lobuloalveolar component, by increasing progesterone receptor expression in the breasts and by inducing the secretion of prolactin. Allowed for by estrogen, progesterone and prolactin work together to complete lobuloalveolar development during pregnancy.\n\nAndrogens such as testosterone powerfully oppose estrogen action in the breasts, such as by reducing estrogen receptor expression in them.\n\nEstrogens are responsible for maturation and maintenance of the vagina and uterus, and are also involved in ovarian function, such as maturation of ovarian follicles. In addition, estrogens play an important role in regulation of gonadotropin secretion. For these reasons, estrogens are required for female fertility.\n\nEstrogens are involved in libido (sex drive) in both women and men.\n\nVerbal memory scores are frequently used as one measure of higher level cognition. These scores vary in direct proportion to estrogen levels throughout the menstrual cycle, pregnancy, and menopause. Furthermore, estrogens when administered shortly after natural or surgical menopause prevents decreases in verbal memory. In contrast, estrogens have little effect on verbal memory if first administered years after menopause. Estrogens also have positive influences on other measures of cognitive function. However the effect of estrogens on cognition is not uniformly favorable and is dependent on the timing of the dose and the type of cognitive skill being measured.\n\nThe protective effects of estrogens on cognition may be mediated by estrogens anti-inflammatory effects in the brain. Studies have also shown that the Met allele gene and level of estrogen mediates the efficiency of prefrontal cortex dependent working memory tasks.\n\nEstrogen is considered to play a significant role in women's mental health. Sudden estrogen withdrawal, fluctuating estrogen, and periods of sustained low estrogen levels correlate with significant mood lowering. Clinical recovery from postpartum, perimenopause, and postmenopause depression has been shown to be effective after levels of estrogen were stabilized and/or restored.\n\nCompulsions in male lab mice, such as those in obsessive-compulsive disorder (OCD), may be caused by low estrogen levels. When estrogen levels were raised through the increased activity of the enzyme aromatase in male lab mice, OCD rituals were dramatically decreased. Hypothalamic protein levels in the gene COMT are enhanced by increasing estrogen levels which are believed to return mice that displayed OCD rituals to normal activity. Aromatase deficiency is ultimately suspected which is involved in the synthesis of estrogen in humans and has therapeutic implications in humans having obsessive-compulsive disorder.\n\nLocal application of estrogen in the rat hippocampus has been shown to inhibit the re-uptake of serotonin. Contrarily, local application of estrogen has been shown to block the ability of fluvoxamine to slow serotonin clearance, suggesting that the same pathways which are involved in SSRI efficacy may also be affected by components of local estrogen signaling pathways.\n\nStudies have also found that fathers had lower levels of cortisol and testosterone but higher levels of estrogen (estradiol) compared to non-fathers.\n\nEstrogen may play a role in suppressing binge eating. Hormone replacement therapy using estrogen may be a possible treatment for binge eating behaviors in females. Estrogen replacement has been shown to suppress binge eating behaviors in female mice. The mechanism by which estrogen replacement inhibits binge-like eating involves the replacement of serotonin (5-HT) neurons. Women exhibiting binge eating behaviors are found to have increased brain uptake of neuron 5-HT, and therefore less of the neurotransmitter serotonin in the cerebrospinal fluid. Estrogen works to activate 5-HT neurons, leading to suppression of binge like eating behaviors.\n\nIt is also suggested that there is an interaction between hormone levels and eating at different points in the female menstrual cycle. Research has predicted increased emotional eating during hormonal flux, which is characterized by high progesterone and estradiol levels that occur during the mid-luteal phase. It is hypothesized that these changes occur due to brain changes across the menstrual cycle that are likely a genomic effect of hormones. These effects produce menstrual cycle changes, which result in hormone release leading to behavioral changes, notably binge and emotional eating. These occur especially prominently among women who are genetically vulnerable to binge eating phenotypes.\n\nBinge eating is associated with decreased estradiol and increased progesterone. Klump et al. Progesterone may moderate the effects of low estradiol (such as during dysregulated eating behavior), but that this may only be true in women who have had clinically diagnosed binge episodes (BEs). Dysregulated eating is more strongly associated with such ovarian hormones in women with BEs than in women without BEs.\n\nThe implantation of 17β-estradiol pellets in ovariectomized mice significantly reduced binge eating behaviors and injections of GLP-1 in ovariectomized mice decreased binge-eating behaviors.\n\nThe associations between binge eating, menstrual-cycle phase and ovarian hormones correlated.\n\nIn rodents, estrogens (which are locally aromatized from androgens in the brain) play an important role in psychosexual differentiation, for example, by masculinizing territorial behavior; the same is not true in humans. In humans, the masculinizing effects of prenatal androgens on behavior (and other tissues, with the possible exception of effects on bone) appear to act exclusively through the androgen receptor. Consequently, the utility of rodent models for studying human psychosexual differentiation has been questioned.\n\nEstrogens are responsible for both the pubertal growth spurt, which causes an acceleration in linear growth, and epiphyseal closure, which limits height and limb length, in both females and males. In addition, estrogens are responsible for bone maturation and maintenance of bone mineral density throughout life. Due to hypoestrogenism, the risk of osteoporosis increases during menopause.\n\nWomen suffer less from heart disease due to vasculo-protective action of estrogen which helps in preventing atherosclerosis. It also helps in maintaining the delicate balance between fighting infections and protecting arteries from damage thus lowering the risk of cardiovascular disease.\n\nEstrogen has anti-inflammatory properties and helps in mobilization of polymorphonuclear white blood cells or neutrophils.\n\nEstrogens are implicated in various estrogen-dependent conditions, such as ER-positive breast cancer, as well as a number of genetic conditions involving estrogen signaling or metabolism, such as estrogen insensitivity syndrome, aromatase deficiency, and aromatase excess syndrome.\n\nEstrogens, in females, are produced primarily by the ovaries, and during pregnancy, the placenta. Follicle-stimulating hormone (FSH) stimulates the ovarian production of estrogens by the granulosa cells of the ovarian follicles and corpora lutea. Some estrogens are also produced in smaller amounts by other tissues such as the liver, pancreas, bone, adrenal glands, skin, brain, adipose tissue, and the breasts. These secondary sources of estrogens are especially important in postmenopausal women.\nThe pathway of estrogen biosynthesis in extragonadal tissues is different. These tissues are not able to synthesize C19 steroids, and therefore depend on C19 supplies from other tissues and the level of aromatase.\n\nIn females, synthesis of estrogens starts in theca interna cells in the ovary, by the synthesis of androstenedione from cholesterol. Androstenedione is a substance of weak androgenic activity which serves predominantly as a precursor for more potent androgens such as testosterone as well as estrogen. This compound crosses the basal membrane into the surrounding granulosa cells, where it is converted either immediately into estrone, or into testosterone and then estradiol in an additional step. The conversion of androstenedione to testosterone is catalyzed by 17β-hydroxysteroid dehydrogenase (17β-HSD), whereas the conversion of androstenedione and testosterone into estrone and estradiol, respectively is catalyzed by aromatase, enzymes which are both expressed in granulosa cells. In contrast, granulosa cells lack 17α-hydroxylase and 17,20-lyase, whereas theca cells express these enzymes and 17β-HSD but lack aromatase. Hence, both granulosa and theca cells are essential for the production of estrogen in the ovaries.\n\nEstrogen levels vary through the menstrual cycle, with levels highest near the end of the follicular phase just before ovulation.\n\nNote that in males, estrogen is also produced by the Sertoli cells when FSH binds to their FSH receptors.\n\nEstrogens are plasma protein bound to albumin and/or sex hormone-binding globulin in the circulation.\n\nEstrogens are metabolized via hydroxylation by cytochrome P450 enzymes such as CYP1A1 and CYP3A4 and via conjugation by estrogen sulfotransferases (sulfation) and UDP-glucuronyltransferases (glucuronidation). In addition, estradiol is dehydrogenated by 17β-hydroxysteroid dehydrogenase into the much less potent estrogen estrone. These reactions occur primarily in the liver, but also in other tissues.\nEstrogens are excreted primarily by the kidneys as conjugates via the urine.\n\nEstrogens are used as medications, mainly in hormonal contraception and hormone replacement therapy.\n\nThe estrogen steroid hormones are estrane steroids.\n\nIn 1929, Adolf Butenandt and Edward Adelbert Doisy independently isolated and purified estrone, the first estrogen to be discovered. Then, estriol and estradiol were discovered in 1930 and 1933, respectively. Shortly following their discovery, estrogens, both natural and synthetic, were introduced for medical use. Examples include estriol glucuronide (Emmenin, Progynon), estradiol benzoate, conjugated estrogens (Premarin), diethylstilbestrol, and ethinylestradiol.\n\nThe word estrogen derives from Ancient Greek. It is derived from \"oestros\" (a periodic state of sexual activity in female mammals), and genos(generating). It was first published in the early 1920s and referenced as \"oestrin\". With the years, American English adapted the spelling of estrogen to fit with its phonetic pronunciation. Nevertheless, both estrogen and oestrogen are used nowadays, yet some still wish to maintain its original spelling as it reflects the origin of the word.\n\nThe name \"estrogen\" is derived from the Greek (\"oistros\"), literally meaning \"verve or inspiration\" but figuratively sexual passion or desire, and the suffix \"-gen\", meaning \"producer of\".\n\nA range of synthetic and natural substances that possess estrogenic activity have been identified in the environment and are referred to xenoestrogens.\n\n\nEstrogens are among the wide range of endocrine-disrupting compounds (EDCs) because they have high estrogenic potency. When an EDC makes its way into the environment, it may cause male reproductive dysfunction to wildlife. The estrogen excreted from farm animals makes its way into fresh water systems. During the germination period of reproduction the fish are exposed to low levels of estrogen which may cause reproductive dysfunction to male fish.\n\nSome hair shampoos on the market include estrogens and placental extracts; others contain phytoestrogens. In 1998, there were case reports of four prepubescent African-American girls developing breasts after exposure to these shampoos. In 1993, the FDA determined that not all over-the-counter topically applied hormone-containing drug products for human use are generally recognized as safe and effective and are misbranded. An accompanying proposed rule deals with cosmetics, concluding that any use of natural estrogens in a cosmetic product makes the product an unapproved new drug and that any cosmetic using the term \"hormone\" in the text of its labeling or in its ingredient statement makes an implied drug claim, subjecting such a product to regulatory action.\n\nIn addition to being considered misbranded drugs, products claiming to contain placental extract may also be deemed to be misbranded cosmetics if the extract has been prepared from placentas from which the hormones and other biologically active substances have been removed and the extracted substance consists principally of protein. The FDA recommends that this substance be identified by a name other than \"placental extract\" and describing its composition more accurately because consumers associate the name \"placental extract\" with a therapeutic use of some biological activity.\n\n\n"}
{"id": "16818407", "url": "https://en.wikipedia.org/wiki?curid=16818407", "title": "Evidence-based nursing", "text": "Evidence-based nursing\n\nEvidence-based nursing (EBN) is an approach to making quality decisions and providing nursing care based upon personal clinical expertise in combination with the most current, relevant research available on the topic. This approach is using evidence-based practice (EBP) as a foundation. EBN implements the most up to date methods of providing care, which have been proven through appraisal of high quality studies and statistically significant research findings. The goal of EBN is to improve the health and safety of patients while also providing care in a cost-effective manner to improve the outcomes for both the patient and the healthcare system. EBN is a process founded on the collection, interpretation, appraisal, and integration of valid, clinically significant, and applicable research. The evidence used to change practice or make a clinical decision can be separated into seven levels of evidence that differ in type of study and level of quality. To properly implement EBN, the knowledge of the nurse, the patient's preferences, and multiple studies of evidence must all be collaborated and utilized in order to produce an appropriate solution to the task at hand. These skills are taught in modern nursing education and also as a part of professional training.\n\nA spirit of inquiry refers to an attitude in which questions are encouraged to be asked about existing practices. Cultivating a spirit of inquiry allows healthcare providers to feel comfortable with questioning current methods of practice and challenging these practices to create improvements and change. A culture that fosters this should have a philosophy that incorporates EBP, access to tools that can enhance EBP, and administrative support and leadership that values EBP.\n\n    Key Elements to Foster EBP \n\nPICOT formatted questions address the patient population (P), issue of interest or intervention (I), comparison group (C), outcome (O), and time frame (T). Asking questions in this format assists in generating a search that produces the most relevant, quality information related to a topic, while also decreasing the amount of time needed to produce these search results. \n\nTo begin the search for evidence, use each keyword from the PICOT question that was formed. Once results have been found on the intervention or treatment, the research can be rated to determine which provides the strongest level of evidence. There are seven levels of evidence, with a level I being of the strongest quality and a level VII being of the weakest quality:\nThe strongest levels of evidence, systematic reviews and meta-analyses, summarize evidence related to a specific topic by finding and assessing studies that specifically relate to the question being asked. Meta-analyses are systematic reviews that also use quantitative measures such as statistics to summarize the results of the studies analyzed.\n\n    Pyramid framework. Thinking of the information resources used to obtain evidence as a pyramid can help determine what the most valid and least biased evidence is. The top of the pyramid is just that. This is where decision support can be found, which is found within the medical record. The middle of the pyramid is the reviews of the evidence. This includes systematic reviews, practice guidelines, topic summaries, and article synopses. The bottom of the pyramid is the original studies. The bottom is also considered the foundation of the pyramid and where evidence begins. This includes research articles. Those who look for evidence here need special knowledge and skills to not only find the evidence itself but how to evaluate its worthiness.\nTo begin the critical appraisal process, three questions need to asked to determine the relevance of evidence and if evidence applies to population being cared for. The three questions are: \nAfter asking these three questions, evidence appraisal continues by creating an evidence synthesis. This synthesis compares multiple studies to see if they are in agreement with each other.\n\nAfter appraising the evidence, it is necessary to integrate it with the provider's expertise and patient's preferences. The patient is encouraged to practice autonomy and participate in the decision-making process. Therefore, even if the study had successful outcomes, the patient may refuse to receive a treatment. Assessment findings and patient history may reveal further contraindications to a certain evidence-based treatment. Lastly, availability of healthcare resources may limit the implementation of a treatment even if it is found to be effective in a study.\n\nThe next step in the evidence-based practice process is to evaluate whether the treatment was effective in terms of patient outcomes. It is important to evaluate the outcomes in a real-world clinical setting to determine the impact of the evidence-based change on healthcare quality.\n\nThe last step is to share the information especially if positive outcomes are achieved. By sharing the results of evidence-based practice process, others may benefit. Some methods to disseminate the information include presentations at conferences, rounds within one's own institution, and journal publications.\n\nOne method of research for evidence-based practice in nursing is 'qualitative research': \"The word implies a entity and meanings that are not experimentally examined or measured in terms of quantity, amount, frequency, or intensity.\" \nWith qualitative research, researchers learn about patient experiences through discussions and interviews. The point of qualitative research is to provide beneficial descriptions that allow insight into patient experiences. \n\"Hierarchies if research evidence traditionally categorize evidence from weakest to strongest, with an emphasis on support for the effectiveness of interventions. That this perspective tends to dominate the evidence-based practice literature makes the merit of qualitative research unclear;\" Some people view qualitative research as less beneficial and effective, with its lack of numbers, the fact that it is \"feeling-based\" research, makes the opponents associate it with bias. Nevertheless, the ability to empathetically understand an individual's experience (whether it be with cancer, pressure ulcers, trauma, etc.), can benefit not only other patients, but the health care workers providing care.\n\nFor qualitative research to be reliable, the testing must be unbiased. To achieve this, researchers must use random and non-random samples to obtain concise information about the topic being studied. If available, a control group should be in use, if possible with the qualitative studies that are done. Evidence should be gathered from every available subject within the sample to create balance and dissolve any bias. There should also be several researchers doing the interviewing to obtain different perspectives about the subject. Researchers must also obtain negative information as well as the positive information gathered to support the data. This will help to show the researchers were unbiased and were not trying to hide negative results from readers, and actually makes it possible to objectively understand the phenomenon under investigation. The inclusion of this negative information will strengthen the researchers' initial study, and may actually work in favor to support the hypothesis. Any data that has been gathered must be appropriately documented. If the data collected was obtained from interviews or observation, it must all be included. \nDates, times and gender of the sample may be needed, providing background on subjects, such as breast cancer in women over thirty-five. Any pertinent information pertaining to the sample must be included for the reader to judge the study as worthy.\n\nIn addition, the current evidence-based practice (EBP) movement in healthcare emphasizes that clinical decision making should be based on the \"best evidence\" available, preferably the findings of randomized clinical trials. Within this context qualitative research findings are considered to have little value and the old debate in nursing has been re-ignited related as to whether qualitative versus quantitative research findings provides the best empirical evidence for nursing practice. \nIn response to this crisis qualitative scholars have been called upon by leaders in the field to clarify for outsiders what qualitative research is and to be more explicit in pointing out the utility of qualitative research findings. \nIn addition, attention to \"quality\" in qualitative research has been identified as an area worthy of renewed focus. Within this paper two key problems related to addressing these issues are reviewed: disagreement not only among \"outsiders\" but also some nursing scholars related to the definition of \"qualitative research\", and a lack of consensus related how to best address \"rigor\" in this type of inquiry.\n\nBased on this review a set of standard requirements for qualitative research published in nursing journals is proposed that reflects a uniform definition of qualitative research and an enlarged yet clearly articulated conceptualization of quality. The approach suggested provides a framework for developing and evaluating qualitative research that would have both defensible scholarly merit and heuristic value. This will help solidify the argument in favor of incorporating qualitative research findings as part of the empirical \"evidence\" upon which evidence-based nursing is founded.\n\nBoth legal and ethical issues are important in considering patient-based research. The American Nurses Association (ANA) has set up five basic rights for patient protection:\n\n\nThese rights apply to both researchers and participants. Informed consent is one area that nurses must be familiar with in order to complete research. Informed consent is \"the legal principle that governs the patient's ability to accept or reject individual medical interventions designed to diagnose or treat an illness\". Informed consent can only be obtained before the procedure and after potential risks have been explained to the participant. When dealing with the ethical portion of evidence-based practice, the Institutional Review Boards (IRB) review research projects to assess that ethical standards are being followed. The institutional review board is responsible for protecting subjects from risk and loss of personal rights and dignity. The IRB also come into play when deciding on which populations can be included in research. Vulnerable groups such as children, pregnant women, physically disabled or elderly maybe excluded from the process. Nurses must notify the IRB of any ethical or legal violations.\n\nIt is important to be up to date on all the appropriate state laws and regulations regarding vulnerable populations. This may mean consulting with lawyers, clinicians, ethicists, as well as the affiliated IRB. It is imperative that researchers act as advocates for these vulnerable persons that cannot do so for themselves.\n\nThe use of evidence-based practice depends a great deal on the nursing student's proficiency at understanding and critiquing the research articles and the associated literature that will be presented to them in the clinical setting. According to, Blythe Royal, author of \"Promoting Research Utilization in nursing: The Role of the Individual, Organization, and Environment\", a large amount of the preparation requirements of nursing students consists of creating care plans for patients, covering in depth processes of pathophysiology, and retaining the complex information of pharmacology. These are indeed very important for the future of patient care, but their knowledge must consist of more when they begin to practice. Evidence-based nursing in an attempt to facilitate the management of the growing literature and technology accessible to healthcare providers that can potentially improve patient care and their outcomes. Nancy Dickenson-Hazard states, \"Nurses have the capacity to serve as caregivers and change agents in creating and implementing community and population-focused health systems.\" There is also a need to overcome the barriers to encourage the use of research by new graduates in an attempt to ensure familiarity with the process. This will help nurses to feel more confident and be more willing to engage in evidence-based nursing. A survey that was established by the Honor Society of Nursing and completed by registered nurses proved that 69% have only a low to moderate knowledge of EBP and half of those that responded did not feel sure of the steps in the process. Many responded, \"lack of time during their shift is the primary challenge to researching and applying EBP.\" There is always and will always be a desire to improve the care of our patients. The ever-increasing cost of healthcare and the need for more accuracy in the field proves a cycle in need of evidence-based healthcare. The necessity to overcome the current issues is to gain knowledge from a variety of literature not just the basics. There is a definite need for nurses, and all practitioners, to have an open mind when dealing with the modern inventions of the future because these could potentially improve the health of patients.\nThere are many barriers to promoting evidence-based practice. The first of which would be the practitioner's ability to critically appraise research. This includes having a considerable amount of research evaluation skills, access to journals, and clinic/hospital support to spend time on EBN. Time, workload pressures, and competing priorities can impede research and development. The causes of these barriers include nurses' and other professional practitioners' lack of knowledge of research methods, lack of support from professional colleagues and organizations, and lack of confidence and authority in the research arena.\nAnother barrier is that the practice environment can be resistant to changing tried and true conventional methods of practice. This can be caused because of reluctance to believe results of research study over safe, traditional practices, cost of adopting new practices, or gaining momentum to rewrite existing protocols. It is important to show nurses who may be resistant to changes in nursing practice the benefits that nurses, their patients, and their institutions can reap from the implementation of evidence-based nursing practice, which is to provide better nursing care. Values, resources and evidence are the three factors that influence decision-making with regard to health care. All registered nurses and health care professionals should be taught to read and critically interpret research and know where to find articles which relate to their field of care. In addition, nurses need to be more aware of how to assess the information and determine its applicability to their practice.\n\nAnother barrier to implementing EBN into practice is lack of continuing education programs. Practices do not have the means to provide workshops to teach new skills due to lack of funding, staff, and time; therefore, the research may be tossed dismissed. If this occurs, valuable treatments may never be utilized in patient care. Not only will the patients suffer but the staff will not have the opportunity to learn a new skill. Also, the practitioners may not be willing to implement change regardless of the benefits to patient care.\n\nAnother barrier to introducing newly learned methods for improving treatments or patients' health is the fear of \"stepping on one's toes\". New nurses might feel it is not their place to suggest or even tell a superior nurse that newer, more efficient methods and/or practices are available.\n\nEven if clinicians do act consistently it is possible that their decisions are consistently biased. People put different values on gains and losses. Tversky and Kahneman gave people the two identical problems (with the same probabilities of life and death outcomes - see fig 1) but framed the outcome choices as either lives saved or as deaths.10 Most people wanted to avoid taking risks with gains which could be safeguarded, but would take risks with losses which might be avoided; this is a framing effect. If people are given identical options but different words are used to emphasize a gain rather than a loss, then a different response is given by a large proportion of the population under study. Such a change in response appears to be inconsistent.\n\nThe Iowa Model is used to promote quality of care. It is a guideline for nurses in their decision making process. The decision making can include clinical and administration practices. These practices affect patient outcomes. The model is based on problem-solving steps at are a part of the scientific process. Recognition for applicability and ease of use. Key components of using the Iowa Model: \n\n\n"}
{"id": "10782137", "url": "https://en.wikipedia.org/wiki?curid=10782137", "title": "Florida Mental Health Act", "text": "Florida Mental Health Act\n\nThe Florida Mental Health Act of 1971 (Florida Statute 394.451-394.47891 [2009 rev.]), commonly known as the \"Baker Act,\" allows the involuntary institutionalization and examination of an individual.\n\nThe Baker Act allows for involuntary examination (what some call emergency or involuntary commitment). It can be initiated by judges, law enforcement officials, physicians, or mental health professionals. There must be evidence that the person:\n\n\nExaminations may last up to 72 hours after a person is deemed medically stable and occur in over 100 Florida Department of Children and Families-designated receiving facilities statewide.\n\nThere are many possible outcomes following examination of the patient. This includes the release of the individual to the community (or other community placement), a petition for involuntary inpatient placement (what some call civil commitment), involuntary outpatient placement (what some call outpatient commitment or assisted treatment orders), or voluntary treatment (if the person is competent to consent to voluntary treatment and consents to voluntary treatment). The involuntary outpatient placement language in the Baker Act took effect as part of the Baker Act reform in 2005.\n\nThe legislation was nicknamed \"Baker Act\" after Florida Democratic state representative from Miami, Maxine Baker, who served from 1963 to 1972. She had a strong interest in mental health issues, served as chair of the House Committee on Mental Health, and was the sponsor of the bill.\n\nThe nickname has led to the term \"Baker Act\" as a transitive verb, and \"Baker Acted\" as a passive-voice verb, for invoking the Act to force an individual's commitment. Although the Baker Act is a statute only for the state of Florida, use of \"Baker Acting\" as a verb has become prevalent as a slang term for involuntary commitment in other regions of the United States.\n\nSpecific criteria must be met in order to initiate involuntary examination. Among those criteria are the following elements, that \"by themselves\", do \"not\" qualify an individual as having met or meeting the criteria:\n\nReason to believe that the person has a mental illness; refusal of voluntary examination; the person is unable to determine whether examination is necessary. Criteria are not met simply because a person has mental illness, appears to have mental problems, takes psychiatric medication, or has an emotional outburst. Criteria are not met simply because a person refuses voluntary examination. Criteria are not met if there are family members or friends that will help prevent any potential and present threat of substantial harm.\n\nThe decisive criterion, as stated in the statute, mentions a substantial likelihood that without care or treatment the person will cause serious bodily harm in the near future. (\"Substantial\" means ample, considerable, firm or strong.)\n\nTo further clarify this point of substantial likelihood, there must be evidence of recent behavior to justify the substantial likelihood of serious bodily harm in the near future. Moments in the past, when an individual may have considered harming themselves or another, do not qualify the individual as meeting the criteria. (\"Near\" means close, short, or draws near.)\n\nAn editorial in the \"Tampa Bay Times\" wrote that crisis stabilization is a Band-Aid solution to emotional problems\" and the Act should be reformed to allow public defenders to have access to the patient's medical records and ongoing counseling and outpatient mental health treatment should be provided to the patient.\n\n\n\n"}
{"id": "23817539", "url": "https://en.wikipedia.org/wiki?curid=23817539", "title": "Food power", "text": "Food power\n\nIn international politics, food power is the use of agriculture as a means of political control whereby one nation or group of nations offers or withholds commodities from another nation or group of nations in order to manipulate behavior. Its potential use as a weapon was recognised after OPEC’s earlier use of oil as a political weapon. Food has a major influence on political actions of a nation. In response to acts of food power, a nation usually acts in the interest of its citizens to provide food.\n\nFood power is an integral part of the politics of food. The idea of food power is used in embargoes, employment, and food politics. In order for a nation to utilize food power effectively, the nation must effectively apply and display scarcity, supply concentration, demand dispersion, and action independence. The four main nations that export enough agriculture to be able to exert food power are the United States, Canada, Australia, and New Zealand. On the smaller scale, particularly in some African countries, food power has been used as a weapon by opposing sides in internal wars and conflicts against their own people.\n\nThere are four nations in the world that export enough agriculture to exert this hypothetical food power: the United States, Canada, Australia, and New Zealand. Forced to rely on these nations in times of shortage, food-importing countries may face food crises if needed supplies are withheld. But while political leaders in food-importing countries have expressed misgivings over their dependence, food-exporting nations generally do not withhold food, as agricultural producers in these nations press their governments to continue to export.\n\nFood politics are the political aspects of the production, control, regulation, inspection and distribution of food. The politics can be affected by the ethical, cultural, medical and environmental disputes concerning proper farming, agricultural and retailing methods and regulations. Food power is an integral part of the politics of food.\n\n“Food is a weapon”, stated Earl Butz, the United States Secretary of Agriculture, in 1974. OPEC's use of oil as a political weapon brought on the possibility for America to use food as a tool against other states and to further the US's goals.\nThere are alternative uses of food power as well. An importer can refuse to continue import unless political concessions are made. This would have the same effects that an exporter refusing to export would have. An example of this would be American reduction of the Cuban sugar quota. In simple terms, the demand concentration (one importer being the dominant buyer) and supply dispersion (several exporters competing to sell the same product) an importer can try to use this exchange politically to their favor; this is especially effective if the exporter has little else so export (low action independence).\n\nFood security and food power are not the same thing. However, they are often directly related. Food security is when all people of a region at all times have enough food for an active, healthy life. Food power is related when a government, company, leader, country etc. takes this security away in order to get something in return. Many countries employ the exploit of food power to threaten another country's food security. A country's welfare correlates directly with the welfare of its people therefore each country wants to have an appropriate supply of food for its citizens. This want, however, can easily be used as leverage in the politics of food, demonstrating food power.\n\nAn embargo is not the same as Food Power, however, food power can be used in an embargo. In fact, embargoes that do not involve food in their list of restricted items often fail. For example, on August 20, 1914 the Allied Powers began an embargo on important items that were normally shipped to Germany. However, the embargo was not complete nor effective until food was added to the list of restricted materials. Food has the real power. After food was introduced the blockade began to strangle Germany's economy because they were dependent on imports for food. Because the Allied Powers used the power of food in their embargo, Germany was forced to resort to desperate measures and eventually failed despite them.\n\nIn the early 1980s, the United States posed a grain embargo upon the Soviet Union. This was an attempt by the U.S. utilize food power, however, it was not confirmed. The Soviets thus imported grain from different suppliers, leading to an increase in grain imports during that time period, only at a higher cost. Another unsuccessful embargo food power attempt was imposed by the UN Security Council in 1990 upon Iraq.\n\nAnother example of an embargo is the United States embargo against Cuba. This is still an ongoing embargo, and, due to the declining situation and health of Cuba's people, the embargo has been subject to much protest.\n\nFood power can only be used effectively if certain structural conditions apply:\n\nThe four conditions listed above MUST be simultaneously present in order to turn an economic asset food into a political instrument. This does not necessarily mean that the asset will be used whenever the four conditions above are present. Such a decision would be considered only if there were further conditions, for example, the nature of a given conflict and judgment, goals, alternative means, and judgment of utility.\n\nThere are several uses for employing economic weapons against one country or another. One use for using economic weapons would concern the seller/buyer bargaining on the conditions of a business contract. This would include price, transportation, timetable for consignment and payment, etc. Although this is an example of the successful application of food power, it is not a political objective. Another use concerns the economic objectives other than these relating to the transaction of goods; to the general economic policy of the buyer. This would be balance of payments, general problems, such as inflation or taxation and land holding. What distinguishes this from the first is the fact that there is no link between the conditions laid down and the transfer of product. The conditions refer to the economic realm of life. A political use would be one concerning the buyer’s foreign and defense policies. Many believe there is a moral threshold between economy and politics, making the use of economic means for political gains questionable. Examples of the use of economic weapons for political aims are boycotts against certain countries as well as the buying of votes in the UN. A fourth purpose pertains to the basic assumption of the third category: the governments no longer accept each other as legitimate. The economic goals are no longer seen as a means of influencing an opposite government but rather to stimulate opposition and achieve the overthrow or capitulation of the government.\n\nDuring the time the United States was the most dominant in all areas like military, energy, exports, etc. Food Power was not really thought about. However, since some of those powers have since diminished, the power of food has come to the surface. In the realm of food, The United States remains at the top, unchallenged. The United States has the position of being the largest producer and exporter of food. While others nations, predominantly developing nations but even some of the richest oil-exporting nations, are beginning to have food shortages and becoming more and more dependent on imported food from the United States, giving it more and more power. This allows the United States to expect friendly behavior from the countries that import American food. It is also likely that the United States would have some form of influence over these countries. Even some of the poorest OPEC countries have become dependent on U.S. wheat. Therefore, there is a possibility that the United States could restrict its food exports for political purposes. The United States could use this Food power as a means of exerting pressure on OPEC countries. Food power will be most effective in times of food shortage or famine because this is when those countries that have some dependence on the United States are most desperate.\n\nThe U.S. frequently uses its economic power in order to punish other countries. One of the ways the U.S. does this is by holding back on exporting food. Reasons for the punishment of another country vary; however, they can be broken down into two main groups: Foreign containment objective and market development/humanitarian objectives. The foreign containment objective tends to punish those countries who are threatening to the U.S. An example of such a threat would be countries under other forms of government. More examples related to the containment objective would be no aid to communist countries, socialist governments, countries who support radical regimes, regimes with an inadequate democracy who are too weak to be anti-communist (effectively), and countries who will not accept U.S. agreements. An example of market development and humanitarian objectives would fall under a category of countries that are trying to compete with the U.S. economically. The U.S. will execute foreign aid punishments to countries trying to nationalize property of U.S. companies, countries who want to take over functions by U.S. companies, and countries trying to initiate nationalistic economic policies.\n\nThe U.S. has modified its stance since the 1970s, when the State Department and the CIA issued reports exploring the potential of food embargoes. Congressional Bill H.R. 5426, the Trade Sanctions Reform and Export Enhancement Act of 2000, removed agricultural export sanctions applied to Libya, Sudan, and North Korea (agricultural trade with Cuba remained under some restrictions) and gave Congress veto power over unilateral presidential actions in this regard.\n\nFood politics in Africa differs from the cases in North America and Europe in that there is a case of small scale food power in Africa, particularly in Sudan. Some experts say that the cases of famine and food insecurity in Africa are due to inconsistent output of food production and the downward spiral of the interaction between population growth and environmental sustainability. But upon closer inspection, it is revealed that nature is not the only catalyst for Africa’s numerous food insecurity issues.\n\nFamine is shaped by generally two theories. The first is FAD, Food Availability Decline. This is the result of a drought, a war, or some other drastic change to the agricultural system. This is the natural cause for famine. The other theory deals primarily with the population’s ability to access or become entitled to food. In this case, food power makes itself known on a small scale, as opposing political forces in Sudan compete for the votes of the people by instigating or encouraging the famine.\n\nFor example, Sudan’s famine in the 1980s was completely intentional, and was only a pawn for a varied collection of different elites to improve their political and economic statuses. These political parties weren’t the only beneficiaries, though. Merchants were also known to hoard grain and buy livestock at inappropriately low prices when the famines shifted the terms of trade. Western Sudanese merchants during the famine of 1987 were described as heartless because they refused to sell grain to needy villages in Darfur at reasonable prices. Ergo, the Sudanese Famine was another example of food power in which food was and used as a policy, and which completely ignored the needs of the people and fostered the political and power-hungry intentions of opposite warring forces in the country.\n\nThe famine in Sudan in 1998 was a humanitarian disaster caused mainly by human rights abuses, as well as drought and the failure of the international community to react to the famine risk with adequate speed. The worst affected area was Bahr El Ghazal in southwestern Sudan. In this region over 70,000 people died during the famine.\n\n\nPaarlberg, Robert. \"Food Politics.\" Oxford Companion to Politics (2008). Mywire. University of Oxford, 1 Jan. 2008. Web. 2 Nov. 2009. <http://www.mywire.com/a/Oxford-Companion-Politics-World/Food-Politics/9577797/?&pbl=105>\n\n\n"}
{"id": "52105377", "url": "https://en.wikipedia.org/wiki?curid=52105377", "title": "Gladys Block", "text": "Gladys Block\n\nGladys Block is a nutrition researcher who worked at the National Cancer Institute.\n\nFrom July 1991 onward, Block worked at the University of California, Berkeley as a professor (and subsequently professor emerita) of Community Health and Human Development in the School of Public Health.\n\nIn 1992, Block's review of 15 epidemiological studies on cancer rates and intake of Vitamin C was mentioned in the \"New York Times\".\n\nBlock has been cited in media coverage of the debate around the efficacy of dietary multivitamin supplements in combating health risks including the risk of cancer, obesity, diabetes, heart disease, and hypertension. Others taking a similar position as Block (in favor of dietary supplements) include Harvard professor Walter Willett (designer of the Harvard FFQ), researcher Bruce N. Ames, and Michael Jacobson of the Center for Science in the Public Interest. Those on the other side include Marion Nestle, Joan Gussow, Catherine Wotecki, Walter Mertz, and Edgar Miller.\n\nBlock has led research on the variety in people's diet and its effects on people's nutrient consumption and health status. She has been cited on the subject in the \"New York Times\".\n"}
{"id": "4450529", "url": "https://en.wikipedia.org/wiki?curid=4450529", "title": "Health effects from noise", "text": "Health effects from noise\n\nNoise health effects are the physical and psychological health consequences of regular exposure, to consistent elevated sound levels. Elevated workplace or environmental noise can cause hearing impairment, hypertension, ischemic heart disease, annoyance, and sleep disturbance. Changes in the immune system and birth defects have been also attributed to noise exposure.\n\nAlthough presbycusis occur naturally with age, in many countries the cumulative impact of noise is sufficient to impair the hearing of a large fraction of the population over the course of a lifetime. Noise exposure has been known to induce tinnitus, hypertension, vasoconstriction, and other cardiovascular adverse effects. Chronic noise exposure has been associated with sleep disturbances and increased incidence of diabetes. Adverse cardiovascular effects occur from chronic exposure to noise due to the sympathetic nervous system's inability to habituate. The sympathetic nervous system maintains lighter stages of sleep when the body is exposed to noise, which does not allow blood pressure to follow the normal rise and fall cycle of an undisturbed circadian rhythm.\n\nStress from time spent around elevated noise levels has been linked with increased workplace accident rates and aggression and other anti-social behaviors. The most significant sources are vehicles, aircraft, prolonged exposure to loud music, and industrial noise.\n\nThere are an attributed 10 000 annual deaths as a result of noise in the European Economic Area.\n\nNoise-induced hearing loss is a permanent shift in pure-tone thresholds, resulting in sensorineural hearing loss. The severity of a threshold shift is dependent on duration and severity of noise exposure. Noise-induced threshold shifts are seen as a notch on an audiogram from 3000–6000 Hz, but most often at 4000 Hz.\n\nNoise has been associated with important cardiovascular health problems, particularly hypertension. Noise levels of 50 dB(A) at night may also increase the risk of myocardial infarction by chronically elevating cortisol production.\n\nRoadway noise levels are sufficient to constrict arterial blood flow and lead to elevated blood pressure. Vasoconstriction can result from elevated adrenaline levels or through medical stress reactions.\n\nCausal relationships have been discovered between noise and psychological effects such as annoyance, psychiatric disorders, and effects on psychosocial well-being. Exposure to intense levels of noise can cause personality changes and violent reactions. Noise has also been shown to be a factor that attributed to violent reactions. The psychological impacts of noise also include an addiction to loud music. This was researched in a study where non-professional musicians were found to have loudness addictions more often than non-musician control subjects.\n\nPsychological health effects from noise include depression and anxiety. Individuals who have hearing loss, including noise induced hearing loss, may have their symptoms alleviated with the use of hearing aids. Individuals who do not seek treatment for their loss are 50% more likely to have depression than their aided peers. These psychological effects can lead to detriments in physical care in the form of reduced self-care, work-tolerance, and increased isolation.\n\nAuditory stimuli can serve as psychological triggers for individuals with post traumatic stress disorder (PTSD).\n\nResearch commissioned by Rockwool, a multi-national insulation manufacturer headquartered in Denmark, reveals that in the UK one third (33%) of victims of domestic disturbances claim loud parties have left them unable to sleep or made them stressed in the last two years. Around one in eleven (9%) of those affected by domestic disturbances claims it has left them continually disturbed and stressed. More than 1.8 million people claim noisy neighbours have made their life a misery and they cannot enjoy their own homes. The impact of noise on health is potentially a significant problem across the UK given that more than 17.5 million Britons (38%) have been disturbed by the inhabitants of neighbouring properties in the last two years. For almost one in ten (7%) Britons this is a regular occurrence.\n\nThe extent of the problem of noise pollution for public health is reinforced by figures collated by Rockwool from local authority responses to a Freedom of Information Act (FOI) request. This research reveals in the period April 2008 - 2009 UK councils received 315,838 complaints about noise pollution from private residences. This resulted in environmental health officers across the UK serving 8,069 noise abatement notices, or citations under the terms of the Anti-Social Behaviour (Scotland) Act.\n\nWestminster City Council has received more complaints per head of population than any other district in the UK with 9,814 grievances about noise, which equates to 42.32 complaints per thousand residents. Eight of the top 10 councils ranked by complaints per 1,000 residents are located in London.\n\nSudden Impulse noises are typically perceived as more bothersome than noise from traffic of equal volume. Annoyance effects of noise are minimally affected by demographics, but fear of the noise source and sensitivity to noise both strongly affect the 'annoyance' of a noise. Sound levels as low as 40 dB(A) can generate noise complaints and the lower threshold for noise producing sleep disturbance is 45 dB(A) or lower.\n\nOther factors that affect the 'annoyance level' of sound include beliefs about noise prevention and the importance of the noise source, and annoyance at the cause (i.e. non-noise related factors) of the noise. Many of the interpretations of the level of annoyance and the relationship between noise levels and resulting health symptoms could be influenced by the quality of interpersonal relationships at the workplace, as well as the stress level generated by the work itself. Evidence for impact on annoyance of long-term noise versus recent changes is equivocal.\n\nApproximately 35% to 40% of office workers find noise levels from 55 to 60 dB(A) extremely irritating. The noise standard in Germany for mentally stressful tasks is set at 55 dB(A), however, if the noise source is continuous, the threshold level for tolerability among office workers is lower than 55 dB(A).\n\nThe U.S. Environmental Protection Agency authored a pamphlet in 1978 that suggested a correlation between low-birthweight (using the World Health Organization definition of less than and high sound levels, and also high rates of birth defects in places where expectant mothers are exposed to elevated sound levels, such as typical airport environs. Specific birth abnormalities included harelip, cleft palate, and defects in the spine.\n\nAccording to Lester W. Sontag of The Fels Research Institute (as presented in the same EPA study): “There is ample evidence that environment has a role in shaping the physique, behavior, and function of animals, including man, from conception and not merely from birth. The fetus is capable of perceiving sounds and responding to them by motor activity and cardiac rate change.\" The effects of noise exposure are highest when it occurs between 15 and 60 days after conception, a period in which major internal organs and the central nervous system are formed.\n\nLater developmental effects occur as vasoconstriction in the mother reduces blood flow and therefore oxygen and nutrition to the fetus. Low birth weights and noise were also associated with lower levels of certain hormones in the mother. These hormones are thought to affect fetal growth and to be good indicators of protein production. The difference between the hormone levels of pregnant mothers in noisy versus quiet areas increased as birth approached.\n\nIn a 2000 publication, a review of studies on birthweight and noise exposure note that while some older studies suggest that when women are exposed to >65 dB aircraft noise a small decrease in birthweight occurs, in a more recent study of 200 Taiwanese women including noise dosimetry measurements of individual noise exposure, the authors found no significant association between noise exposure and birth weight after adjusting for relevant confounders, e.g. social class, maternal weight gain during pregnancy, etc.\n\nWhen young children are regularly exposed to levels of noise that interfere with speech, they may develop speech or reading difficulties, because auditory processing functions are compromised. Children continue to develop their speech perception abilities until they reach their teens. Evidence has shown that when children learn in noisier classrooms, they have more difficulties understanding speech than those who learn in quieter settings.\n\nIn a study conducted by Cornell University in 1993, children exposed to noise in learning environments experienced trouble with word discrimination, as well as various cognitive developmental delays. In particular, the writing learning impairment dysgraphia is commonly associated with environmental stressors in the classroom.\n\nHigh noise levels have also been known to damage the physical health of small children. Children from noisy residences often have a heart rate that is significantly higher (by 2 beats/min on average) than those of children from quieter homes.\n\nEnvironmental noise regulations usually specify a maximum outdoor noise level of 60 to 65 dB(A), while occupational safety organizations recommend that the maximum exposure to noise is 40 hours per week at 85 to 90 dB(A). For every additional 3 dB(A), the maximum exposure time is reduced by a factor 2, e.g. 20 hours per week at 88 dB(A). Sometimes, a factor of two per additional 5 dB(A) is used, however, these occupational regulations are acknowledged by the health literature as inadequate to protect against hearing loss and other health effects. In an effort to prevent noise-induced hearing loss, many programs and initiative have been created, like the Buy Quiet program, which encourages employers to purchase quieter tools and equipment, and the Safe-In-Sound Award, which recognizes organizations with successful hearing loss prevention strategies.\n\nWith regard to indoor noise pollution in residences, the U.S. Environmental Protection Agency (EPA) has not set any restrictions on limits to the level of noise. Rather, it has provided a list of recommended levels in its \"Model Community Noise Control Ordinance\", which was published in 1975. For instance, the recommended noise level for indoor residences is less than or equal to 45 dB.\n\nNoise pollution control in residences is not funded by the federal government in part because of the disagreements in establishing causal links between sounds and health risks, since the effect of noise is often psychological and also, because it leaves no singular tangible trace of damage on the human body. For instance, hearing loss could be attributed to a variety of factors including age, rather than solely due to excessive exposure to noise. A state or local government is able to regulate indoor residential noise, however, such as when excessive noise from within a home causes disturbances to nearby residences.\n\nWhile people are often educated on the effects of noise exposure in humans, there are also different noise exposure effects in animals as well. An example of this would be in canines, and the noise exposure levels occurring within kennels. Canines experience this noise exposure whether it be a long stay at an animal shelter, or a weekend stay at a boarding facility.\n\nOrganizations like NIOSH and OSHA have different regulations when it comes to the noise exposure levels in industrial workers. Currently there are no regulations related to the noise exposure in canines even with such damaging effects related to their health. Health risks dogs are exposed to include ear damage and behavioral changes.\n\nThe average noise exposure in a kennel is greater than 100 dB SPL. According to OSHA these levels would yield in the use of hearing protection for the workers of those kennels due to the risk of noise induced hearing loss. The anatomical structures of the human and canine ear are very similar, so it is thought that these levels will negatively impact the hearing of canines in kennels. The ABR can be used to estimate the hearing threshold of canines, and can be used to show either a temporary threshold shift or permanent threshold shift after being exposed to excessive sound levels.\n\nBehavioral effects to excessive noise exposure include hiding, urinating, defecating, panting, pacing, drooling, disregard to commands, trembling, and barking. These behavioral patterns pose a much greater problem to canines than meets the eye. All of these behavioral patterns are characteristics that result in a longer stay at the kennels before being adopted. A longer stay at the shelter results in a longer duration of noise exposure and therefore more likely to show either a temporary or permanent threshold shift in the canine’s hearing.\n\nThese excessive noise levels are not only harming the canines' physical and psychological state, but the workers' and potential adoptive families' physical and psychological state as well. The workers' psychological state could affect the care provided to the canines. These loud noise exposures also have the potential to reduce the amount of time that potential adoptive families spend in the facility. This can result in less dogs being adopted and more time being exposed to excessive sound levels.\n\nTo reduce the level of noise exposure poses a little more difficulty because the majority of the noise is coming from the canines (barking), but structural changes can be made to the facilities in order to reduce the noise. Structural changes could include how many dogs are put in one area, more absorbing material rather than metal cages and cement walls and floors, and possibly in the future use of hearing protection devices (HPD) for the canines. All of these structural changes would also benefit the humans involved as well as the use of HPD’s (ear plugs).\n\n\n"}
{"id": "3276299", "url": "https://en.wikipedia.org/wiki?curid=3276299", "title": "Husayn Al-Khalidi", "text": "Husayn Al-Khalidi\n\nHusayn Fakhri al-Khalidi (, , 1895 – 6 February 1962) was mayor of Jerusalem from 1934 to 1937.\n\nOn 23 June 1935 Khalidi founded the Reform Party and was subsequently the party's representative to the Arab Higher Committee.\nOn 1 October 1937, amid the 1936–39 Arab revolt in Palestine, the British Mandate administration outlawed the AHC and several Arab political parties and arrested a number of Arab political leaders. The Reform Party was dissolved and Khalidi was one of the leaders arrested. He was removed as mayor of Jerusalem and deported to the Seychelles, together with four other Arab nationalist political leaders. He was released in December 1938 to enable him to take part in the London Conference in February 1939, and was among those rejecting the British Government's White Paper of 1939.\n\nKhalidi returned to Palestine in 1943 and joined the reformed Arab Higher Committee in 1945, becoming its secretary in 1946. He was a member of the short-lived All-Palestine Government established under Egypt's patronage in Gaza in September 1948. He published a book of his memoirs in the same year, while exiled in Beirut. He prospered under Jordanian rule, he was custodian and supervisor of the Haram al-Sharif in 1951, became a cabinet minister (for Foreign Affairs) and briefly prime minister in 1957. In 1958, he wrote a book in English entitled \"Arab Exodus\", though it has never been published.\n\nKhalidi died on 6 February 1962. He was the brother of Ismail Khalidi and the uncle of Rashid Khalidi and Raja Khalidi.\n\n\n"}
{"id": "43141237", "url": "https://en.wikipedia.org/wiki?curid=43141237", "title": "Independent Living Fund", "text": "Independent Living Fund\n\nThe Independent Living Fund was set up in 1988 to fund support for disabled people with high support needs in the United Kingdom, enabling them to live in the community rather than move into residential care.\n\nIt is run as a non-departmental public body with an office in Nottingham and about 120 staff. It provides support to 19,000 disabled people with the highest levels of need at a cost of about £320 million. It operates as an independent discretionary trust funded by the Department for Work and Pensions and is managed by a board of trustees. Its aim is to combat social exclusion on the grounds of disability. The money is generally used to enable disabled people to live in their own homes and to pay for care, and in particular to employ personal assistants. Many of the beneficiaries would otherwise have to move to residential care homes.\n\nIn December 2010 the Government announced the closure of the Fund to new applicants, and in December 2012, following a consultation on the future of the Fund, it was announced that the Fund would be closed permanently from April 2015. The Government claimed that Local Authorities could meet the same outcomes as the ILF and proposed transfer for existing ILF recipients to their Local Authorities.\n\nIn May 2014 The Court of Appeal, in the case of \"Bracking and others v Secretary of State for Work and Pensions\" found that the Department for Work and Pensions' decision to close the Fund was not lawful, overturning the High Court decision of April 2013. It decided that the Department had not complied with the Public Sector Equality Duties imposed by section 149 of the Equality Act 2010. The Court agreed that documents which the Minister, Esther McVey, had seen in the run up to her decision proved that \"the Minister did not receive a sufficient understanding of the true threat to independent living for ILF users posed by the proposal to close the fund\". Lord Justice McCombe said ‘there is simply not the evidence … to demonstrate to the court that a focussed regard was had to the potentially very grave impact upon individuals in this group of disabled persons, within the context of a consideration of the statutory requirements for disabled people as a whole'.\n\nThe Government has announced that it will not appeal against this decision so the Fund will continue for the time being. Its future was the subject of a Westminster Hall debate on 18 June 2014. The Department has carried out a new equality impact assessment to justify the closure.\n\n"}
{"id": "33965855", "url": "https://en.wikipedia.org/wiki?curid=33965855", "title": "Infoveillance", "text": "Infoveillance\n\nInfoveillance is the type of syndromic surveillance that utilizes the online contents. The term was coined by Gunther Eysenbach in 2004 for the first time along with Infodemiology \nThe work of Gunther Eysenbach, which utilized the Google Search queries, had led to the birth of Google Flu. Other than Google search engines have also been used.\n\nLater other researchers utilized other social media such as Twitter to find the disease outbreak patterns. The infoveillance detects disease outbreaks quicker than traditional public health surveillance systems with the minimal cost involved, revealing the promising results for the future surveillance methodologies.\n\nGoogle uses the query information to detect the flu trends and it compares the results to the countries' official surveillance data.\nThe primary research behind the Google Flu Trend is found here. In light of evidence showing that Google Flu Trends was occasionally over-estimating flu rates, researchers have also proposed a series of more advanced and better-performing approaches to flu modelling from Google search queries.\n\nGoogle uses the query information to detect the dengue trendsand it compares the results to the countries' official surveillance data.\nThe primary research behind the Google Dengue Trend is found here.\n\nFlu Detector was developed by Vasileios Lampos et al. at the University of Bristol. It is an application of Machine Learning that firstly uses Feature Selection to automatically extract flu-related terms from Twitter content and then uses those terms to compute a flu-score for several UK regions based on geolocated tweets. The primary research behind the Flu Detector is found here; a generalised scheme able to track other events as well is proposed here.\n\nA new, totally revamped (in terms of models and online data) version of the Flu Detector has been recently launched.\n\nMood of the Nation was developed by Vasileios Lampos et al. at the University of Bristol. It performs mood analysis on tweets geo-located in various regions of the United Kingdom computing on a daily basis scores for four types of emotion: anger, fear, joy and sadness. \n\n\n"}
{"id": "13853292", "url": "https://en.wikipedia.org/wiki?curid=13853292", "title": "Jonathan Gruber (economist)", "text": "Jonathan Gruber (economist)\n\nJonathan Holmes Gruber (born September 30, 1965) is an American professor of economics at the Massachusetts Institute of Technology, where he has taught since 1992. He is also the director of the Health Care Program at the National Bureau of Economic Research, where he is a research associate. An associate editor of both the \"Journal of Public Economics\" and the \"Journal of Health Economics\", Gruber has been heavily involved in crafting public health policy.\n\nHe has been described as a key architect of both the 2006 Massachusetts health care reform, sometimes referred to as \"Romneycare\", and the 2010 Patient Protection and Affordable Care Act, sometimes referred to as the \"ACA\" and \"Obamacare\". He became the focus of a media and political firestorm in late 2014 when videos surfaced in which he made controversial statements about the legislative process, marketing strategies, and public perception surrounding the passage of the ACA.\n\nGruber was born on September 30, 1965, the son of Martin Jay Gruber and Ellie Gruber. His father is Professor Emeritus of Finance at the New York University Stern School of Business, having taught there for more than 40 years. Jonathan Gruber was raised in the New York suburb of Ridgewood, New Jersey. He completed his BS in economics from the Massachusetts Institute of Technology in 1987 and his PhD in economics from Harvard University in 1992, with a thesis titled \"Changes in the Structure of Employer-Provided Health Insurance\".\n\nGruber began his career as an assistant professor of economics at MIT in 1992. He is also a research associate at the National Bureau of Economic Research. Gruber's research has focused on public finance and health economics.\n\nDuring the 1997–98 academic year, Gruber was on leave as Deputy Assistant Secretary for Economic Policy at the United States Department of the Treasury.\n\nFrom 2003-06 he was one of the architects of Massachusetts health care reform, also known as \"Romneycare\". In 2006 he became an inaugural member of the Health Connector Board, the main implementing body for that effort. The same year, he was named the 19th most powerful person in health care in the United States by \"Modern Healthcare\" magazine.\n\nDuring the 2008 election he was a consultant to the Clinton, Edwards and Obama presidential campaigns.\n\nGruber was ousted from the Massachusetts Health Connector in February 2015.\n\nFrom 2009-10, Gruber served as a technical consultant to the Obama Administration and worked with both the administration and U.S. Congress to help craft the Patient Protection and Affordable Care Act, often referred to as the ACA or \"Obamacare\". The Act was signed into law in March 2010, and Gruber has been described as an \"architect\", \"writer\", and \"consultant\" of the legislation. He was widely interviewed and quoted during the legislation's roll-out.\n\nIn 2010 and 2011, Gruber was involved in crafting and advocating for the Single-Payer and Unified Health System bill in Vermont, which passed in May 2011.\n\nThe bill established Green Mountain Care, which aimed to be the first-ever state-level single-payer health care system in the United States by the time it was to have kicked in fully in 2017. Green Mountain Care was cancelled in December 2014 by Governor Peter Shumlin saying its projected costs were becoming too high.\n\nGruber has published more than 140 research articles (the majority of which were for NBER) and has edited six research volumes.\n\nHe is a co-editor of the \"Journal of Public Economics\", an associate editor of the \"Journal of Health Economics\", and the author of \"Public Finance and Public Policy\". In 2011, he wrote \"Health Care Reform: What It Is, Why It's Necessary, How It Works\", delineating the Affordable Care Act, and illustrated by Nathan Schreiber.\n\nGruber's published works include:\n\nIn 2006, Gruber received the American Society of Health Economists Inaugural Medal for the best health economist in the nation aged 40 and under. He was elected a member of the Institute of Medicine in 2005. In 2009 he was elected to the Executive Committee of the American Economic Association.\n\nIn 2011 he was named “One of the Top 25 Most Innovative and Practical Thinkers of Our Time” by \"Slate\" Magazine. In both 2006 and 2012 he was rated as one of the top 100 most powerful people in health care in the United States by \"Modern Healthcare\" Magazine.\n\nIn January 2010, after news emerged that Gruber was under a $297,000 contract with the U.S. Department of Health and Human Services, while at the same time promoting the Obama administration's health care reform policies, some commentators suggested a conflict of interest. Paul Krugman in \"The New York Times\" argued that, although Gruber didn't always disclose his HHS connections, the times when he didn't were no big deal. In response to Krugman's contention, \"Salon\"'s Glenn Greenwald wrote, \"What will make it impossible to effectively call out wrongdoing by future corrupt administrations (by which Krugman seems to mean: Republican administrations) is the willingness of some people to tolerate and defend corruption when done by 'their side.'\"\n\nOne heavily scrutinized part of the ACA reads that subsidies should be given to healthcare recipients who are enrolled \"through an Exchange established by the State\". Some have read this to mean that subsidies can be given only in states that have chosen to create their own healthcare exchanges, and do not use the federal exchange, while the Obama administration says that the wording applies to all states. This dispute was part of a series of lawsuits referred to collectively as \"King v. Burwell\". In July 2014, two separate recordings of Gruber, both from January 2012, surfaced in which he seemed to contradict the administration's position. In one, Gruber states, in response to an audience question, that \"if you’re a state and you don’t set up an exchange, that means your citizens don't get their tax credits\", while in the other he says, \"if your governor doesn't set up an exchange, you're losing hundreds of millions of dollars of tax credits to be delivered to your citizens\". When these recordings emerged, Gruber called these statements mistaken, describing them as \"just a speak-o—you know, like a typo\".\n\nIn November 2014, a series of videos emerged of Gruber speaking about the ACA at different events, from 2010 to 2013, in ways that proved to be controversial; the controversy became known in the press as \"Grubergate\". In the first, most widely publicized video, taken at a panel discussion about the ACA at the University of Pennsylvania in October 2013, Gruber said the bill was deliberately written \"in a tortured way\" to disguise the fact that it creates a system by which \"healthy people pay in and sick people get money\". He said this obfuscation was needed due to \"the stupidity of the American voter\" in ensuring the bill's passage. Gruber said the bill's inherent \"lack of transparency is a huge political advantage\" in selling it. The comments caused significant controversy.\n\nIn two subsequent videos, Gruber was shown talking about the decision (which he attributed to John Kerry) to have the bill tax insurance companies instead of patients (the so-called \"Cadillac tax\"), which he called fundamentally the same thing economically but more palatable politically. In one video, he stated that \"the American people are too stupid to understand the difference\" between the two approaches, while in the other he said that the switch worked due to \"the lack of economic understanding of the American voter\".\n\nIn another video, taken in 2010, Gruber expressed doubts that the ACA would significantly reduce health care costs, although he noted that lowering costs played a major part in the way the legislation had been promoted. In another video, taken in 2011, Gruber again talks about manipulation behind the \"Cadillac tax\", this time also stating that the tax is designed so that, though it begins by affecting only 8% of insurance plans, it will \"over the next 20 years\" come to apply to nearly all employer-provided health plans. Journalist Jake Tapper noted that Gruber's description of the \"Cadillac tax\" directly contradicted a promise that Obama had made before the bill was passed.\n\nAfter the first of these videos came out, Gruber apologized and conceded he \"spoke inappropriately\".\n\nSome defenders of the ACA, such as Jonathan Cohn, called Gruber's statements about Americans \"wrong and inappropriate\" while maintaining that the trickery of which Gruber spoke was standard procedure in passing legislation in Washington, D.C., and thus not a cause for scandal. Opponents of the Act, on the other hand, were harsher in their criticism: \"National Review Online\" editor and conservative commentator Rich Lowry said the videos were emblematic of \"the progressive mind, which values complexity over simplicity, favors indirect taxes and impositions on the American public so their costs can be hidden, and has a dim view of the average American\", while commentator Charles Krauthammer called the first video \"the ultimate vindication of the charge that Obamacare was sold on a pack of lies.\"\n\nConservative S.E. Cupp wrote that the videos showed \"willful ignorance\" on Gruber's part in thinking that the Act was successfully marketed to voters, stating that \"the law has never cracked a 51% favorability rating\" and that, in the first elections after the ACA passed, Republicans, who had opposed it, retook the House of Representatives and gained control of 11 additional state governorships.\n\nNancy Pelosi, then-Speaker of the House, who successfully shepherded the legislation through the House of Representatives, without a single GOP vote and despite some opposition from pro-life Democrats, stated in a press conference after the Gruber controversy, \"So I don't know who he is. He didn't help write our bill\", a comment PolitiFact described as \"inaccurate\".\n\nIn the wake of the controversy, Jonathan Gruber was called to testify before members of United States Congress. He gave testimony on December 9, 2014, in which he apologized for his remarks, which he called \"glib, thoughtless, and sometimes downright insulting\". \"The Wall Street Journal\", in an editorial, called Gruber's apology unpersuasive, saying that \"his response to substantive questions suggested that he is mainly sorry for getting caught on tape\".\n\nOn December 17, 2014, Vermont Governor Peter Shumlin cancelled the Vermont health care reform plan, on which Gruber had served as a consultant. Although budgetary concerns were cited as the reason for the cancellation, some called Gruber's involvement with the plan a factor as well.\n\nAccording to VPR, Vermont state auditor Doug Hoffer is auditing Gruber's contracts for Vermont health care reform, which Gruber \"helped Vermont design\".\n\nThe extent of Gruber's contributions to both Massachusetts and federal health care reform has been the source of significant controversy. In 2014, the Obama administration claimed that Gruber did not have a major role in creating the ACA.\n\nAccording to emails released by the U.S. House Oversight Committee to the \"Wall Street Journal\", Gruber met and consulted with various Obama administration officials in charge of writing and developing the law, including Peter Orszag, who was director of the Office of Management and Budget (OMB), Jason Furman, an economic adviser to the president, Ezekiel Emanuel, who was then a special adviser for health policy at OMB, Jeanne Lambrew, a top Obama administration health adviser who worked at HHS and the White House, and Lawrence Summers, then a top economic adviser in the administration. In July 2009, he was invited to meet personally with Obama.\n\nDuring his December 2014 congressional hearing, in both his written and oral testimony, Gruber downplayed his own influence on the Massachusetts and national health care plans, stating: \"I did not draft Governor Romney’s health care plan, and I was not the 'architect' of President Obama’s health care plan.\" The newspaper \"The Hill\" called this a contradiction of various statements that Gruber had previously made, claiming that at \"numerous speeches, lectures and TV interviews in the past four years, Gruber has been introduced as the 'architect' of the Massachusetts law and/or Obamacare\".\n\n"}
{"id": "12612736", "url": "https://en.wikipedia.org/wiki?curid=12612736", "title": "Lactivism", "text": "Lactivism\n\nLactivism (a portmanteau of \"lactation\" and \"activism\") is the doctrine or practice of vigorous action or involvement as a means of achieving a breastfeeding culture, sometimes by demonstrations, protests, etc. of breastfeeding. Supporters, referred to as \"lactivists\", seek to protest the violation of International Code of Marketing of Breast-milk Substitutes by formula companies and industry. \n\nOne form that lactivism takes is the staging of a \"nurse-in\" (a play on \"sit-in\"), which involves women gathering in public to nurse their children, usually to protest incidents in which a nursing mother was asked to cover up or leave a location because she was nursing.\n\nDuring nurse-ins, nursing mothers often wear clothing with the International Breastfeeding Symbol on it, to show their solidarity.\n\nAnother form of lactivism is acting as support for mothers that wish to nurse. Lactivists provide information and share resources on successful nursing.\n\nMany lactivists choose to breastfeed their children over bottle feeding, seeing this as the natural way to provide nutrition. It is claimed that breastfeeding provides a bonding experience superior to that or bottle feeding. Lactivists may also argue that bottle feeding is costlier than breastfeeding as it requires a multitude of items, and the money saved from breastfeeding can be spent on other useful items for the child. Multiple health organizations recommend breast milk as the primary source of nutrition for babies, including the American Academy of Pediatrics, the American Medical Association, and the World Health Organization.\n\n\n"}
{"id": "9025294", "url": "https://en.wikipedia.org/wiki?curid=9025294", "title": "List of UN numbers 2901 to 3000", "text": "List of UN numbers 2901 to 3000\n\nThe UN numbers from UN2901 to UN3000 as assigned by the United Nations Committee of Experts on the Transport of Dangerous Goods.\n\n"}
{"id": "4673346", "url": "https://en.wikipedia.org/wiki?curid=4673346", "title": "Mall walking", "text": "Mall walking\n\nMall walking is a form of exercise in which people walk or jog through the usually long corridors of shopping malls. Many malls open early so that people may mall walk; stores and other such facilities generally do not open at this time, though vending machine concessions are available. Many choose to mall walk as the indoor climate is comfortable and there is easy access to amenities, such as benches, toilets, and water fountains. Clean and level surfaces also provide a safe walking environment.\n\nMall walking is undertaken individually, in groups, or as part of an organized mall walking program. Mall walking in the United States is especially popular amongst senior citizens. Many mall walkers cite the camaraderie of walking in groups.\n\nMany malls actively encourage mall walking with special clubs and benefits. It is seen by the mall owners as beneficial for several reasons:\n\nDespite the advantages that mall walking provides those that partake in the activity and the advantages they perceive mall owners receiving, there are some burdens placed upon mall owners:\n\n"}
{"id": "2421755", "url": "https://en.wikipedia.org/wiki?curid=2421755", "title": "Mater Private Hospital", "text": "Mater Private Hospital\n\nThe Mater Private Hospital is a private Catholic hospital company in Ireland. Founded in 1986, its Dublin site shares a campus on Eccles Street, Dublin 7, with its sister public hospital, the Mater Misercordiae Hospital. Its mission statement is \"\"to continue the healing mission of Christ by providing the highest quality healthcare in an independent tertiary acute care facility, complementary to the services provided by the Mater Misericordiae Hospital\".\"\n\nThe Mater Private group also owns the Mater Private Hospital Cork, two cancer treatment centres in Limerick and Liverpool, and out-patient clinics in Limerick, Drogheda, Mitchelstown, Mallow, Mullingar, Navan and Sligo.\n\nThe group was sold to Infravia Capital Partners for about €500 million in 2018.\n\nThe Mater Private Hospital in Dublin is built on the site of No 7 Eccles Street, the home of the main character (Leopold Bloom) in James Joyce's \"Ulysses.\" In Joyce's youth, No 7 Eccles Street was the actual home of his contemporary, JF Byrne.\n\nThe Dublin hospital provides a variety of services and procedures including: orthopaedic surgery, cardio-thoracic surgery, plastic surgery, general surgery, dermatology, dietetics, gynaecology, a sleep laboratory, oncology, chemotherapy, radiotherapy, rheumatology, cardiology, paediatric surgery, aviation medicine, ear, nose and throat surgery, ophthalmology, intensive care medicine and neurosurgery.\n\nThe company is 50% owned by London-based private equity firm CapVest. Patients may be self-paying, covered by private health insurance, or funded under the state's National Treatment Purchase Fund (NTPF). In 2010, the hospital received €23 million in NTPF funds, the largest payment to any single institution. In 2011 it was announced that the NTPF programme would be wound down.\n\nIn 2002, the Dublin hospital received Joint Commission accreditation.\n\n"}
{"id": "3575266", "url": "https://en.wikipedia.org/wiki?curid=3575266", "title": "National Council Licensure Examination", "text": "National Council Licensure Examination\n\nNCLEX (National Council Licensure Examination) is a nationwide examination for the licensing of nurses in the United States and Canada since 1994 and 2015, respectively. There are two types, the NCLEX-RN and the NCLEX-PN. After graduation from a school of nursing, one takes the NCLEX exam to receive his or her nursing license. A nursing license gives an individual the permission to practice nursing, granted by the state where he or she met the requirements.\n\nNCLEX examinations are developed and owned by the National Council of State Boards of Nursing, Inc. (NCSBN). The NCSBN administers these examinations on behalf of its member boards which consist of the boards of nursing in the 50 states, the District of Columbia, and four U.S. territories, American Samoa, Guam, Northern Mariana Islands and the Virgin Islands.\n\nTo ensure public protection, each board of nursing requires a candidate for licensure to pass the appropriate NCLEX examination, NCLEX-RN for registered nurses and the NCLEX-PN for vocational or practical nurses. NCLEX examinations are designed to test the knowledge, skills and abilities essential for the safe and effective practice of nursing at the entry-level.\n\nNCLEX examinations are provided in a computerized adaptive testing (CAT) format and are presently administered by Pearson VUE in their network of Pearson Professional Centers (PPC). With computerized exams such as this, the computer selects which question you are asked based on how you answered the previous question. The NCLEX covers a wide range of material. The individual will be scored by their ability to think critically about decisions involving nursing care.\n\nThe governing body responsible for making changes to the NCLEX is the National Council of State Boards of Nursing, the NCSBN. They make changes by analyzing the current nursing practices. They do this by surveying approximately 12,000 recently licensed nurses about different nursing activities which appear on the NCLEX. The NCSBN analyzes these nursing activities based on how frequent the activity may occur, how it could impact the client’s safety, and the location of these activities. The NCSBN conducts these analyses every three years, then makes any needed changes to the exam. Changes were made in 2013 and are expected every three years after that date.\n\nIn 2015, NCLEX was adopted in Canada, with changes made to address measuring units, drug names, and other terminology differences between the United States and Canada. Additionally, the NCLEX is available in Canadian French for French-speaking Canadians.\n\nNCLEX-RN (National Council Licensure Examination-Registered Nurse). All boards of nursing in states and territories of the United States require candidates to pass this exam for licensure as a registered nurse (RN). As of 2015, 10 provincial/territorial RN regulators in Canada have chosen the NCLEX-RN and the National Council of State Boards of Nursing (NCSBN) as the provider of the Canadian RN entry-to-practice exam.\n\nThe NCLEX-RN uses the five-step nursing process. Each of the questions will fall into one of the five steps: assessment, diagnosis, planning, implementation, and evaluation.\n\nNCLEX-PN (National Council Licensure Examination-Practical Nurse). All US state and territorial boards of nursing require a passing result on the exam for licensure as a licensed practical nurse (LPN) or licensed vocational nurse (LVN).\n\nThe majority of test items are written at the cognition level of application or higher, but the exam may include items at all cognitive levels. Examples of cognitive level are memorization or recall, knowledge, analysis and application.\n\nThe exam's content is based on client needs: \n\nThe exam's content is based on client needs:\n\nThe Physiological Integrity category contains the majority of the questions on the exam, about 43-67 percent. This portion of the NCLEX deals with adult medical and surgical care, pediatrics, and gerontology, which is the study of the elderly and the effects of aging. Some of the questions may deal with conditions that nurses treat on a regular basis such as, diabetes, cardiovascular disorders, neurological disorders, renal diseases, and respiratory diseases. In addition, questions on traumatic injuries, immunological disorders, skin disorders and infectious diseases could be asked. There are different topics on the NCLEX pertaining to the pediatric client. These topics may include growth and development, birth abnormalities, child abuse, common infectious diseases of children, and usual childhood traumas such as burn injuries and fractures.\n\nThis category makes up approximately 21-33 percent of the NCLEX questions. Questions in this category cover safety issues in patient care, particularly the administration of medicine to patients, safety measures to prevent further injuries and infections, isolation precautions, safety for pediatric patients, and special safety precautions for patients with psychiatric problems.\n\nThis portion of the exam may also include questions pertaining to laboratory tests, test results, and unique nursing procedures that may be associated with test results; ethical and legal nursing problems; nursing management; and issues related to giving patients the best care. NCLEX questions on these topics are randomly spread throughout the exam.\n\nThe Health Promotion and Maintenance category makes up about 12 percent of the NCLEX examination. Questions under this category deal with birth control measures, pregnancy, labor and delivery; care for a newborn infant, growth and development, and diseases that can spread easily like sexually transmitted infections. If a patient is pregnant, it is very important that the nurse be able to act as a teacher or counselor for the patient. This makes it necessary to understand all components of a patient’s pregnancy. Knowledge of a proper diet, development of the fetus, signs and symptoms of pregnancy complications and certain pregnancy related procedures will be helpful for this section of the exam.\n\nLike the section on Health Promotion and Maintenance, the Psychosocial Integrity category constitutes approximately 12 percent of the NCLEX questions. Questions in this category pertain to patients with psychiatric problems and their unique issues. In addition, this material may cover coping mechanisms for different situations. Other situations covered in this section are about psychosocial problems that fall short of psychiatric illness. Questions could cover information on the following disorders: depression, schizophrenia, organic mental disorders, eating disorders, personality disorders, and anxiety disorders. Also included in this section may be questions about crisis intervention, substance abuse, and therapy through communication.\n\nMost of the questions of the NCLEX exam are worded multiple choice questions. In recent years, however, the NCSBN has added \"new format questions\" which do not involve simple multiple choice selection. Examples of the new formats include identifying and selecting a particular area of a drawn body part; selecting multiple correct answers via check boxes; free response mathematical questions usually involving medication calculations; and ordering the steps of a medical or nursing procedure.\n\nQuestions on the NCLEX exam are of three different types or levels: Level 1, Level 2, and Level 3. Level 1 questions are the most basic questions and make up less than 10 percent of the total questions. Level 1 questions test the individual’s knowledge and understanding. These questions require the individual to recall specific facts and information. Level 2 questions require an additional level of thinking in order to answer the question. In these types of questions, the individual will be required to know specific information and then use it to interpret or analyze the question. Level 2 questions are analysis and application type questions. Level 3 questions are the most complex type of question on the NCLEX. These questions require the individual to judge, evaluate, and combine information. The individual will have to apply the rules, facts, and processes they know and then make decisions about what is best for the patient’s care based on the situation. What makes level 3 questions difficult is the likely existence of more than one correct answer forcing the individual to decide which answer is the best choice. Level 2 and Level 3 questions make up about 95 percent of the questions on the NCLEX exam. However, it is possible for the exam to have no Level 1 question.\n\nThe NCLEX exam is taken on a computer at a Pearson Professional Center. Pearson Professional Centers are testing centers for certifications and licenses all over the world. There are numerous testing centers in each state of the U.S. and centers can be found in 175 countries. The NCLEX exam is at least 90 percent multiple-choice questions. The remaining questions require an individual to fill in the blank, choose all of the correct answers from a list of options, put a number of steps in the correct sequence, or identify a correct area on a picture. Some of these alternative format questions ask information about a chart, graph, or audio clip. The questions can also use pictures as the answer choices instead of words. Each question will appear one at a time on a computer screen. Questions will not be repeated; however, questions based on a similar situation could be asked.\n\nEach individual will take a different form of the exam. Since each question depends on how the previous question is answered, an individual can be given between 75 and 265 questions. Only 60 out of the first 75 questions on the exam will count. The 15 that do not count are “trial” questions, and these will be used on future examinations. The “trial” questions are not identified as such, therefore, it is best to answer every question. If the individual continues to get questions from the same category, it could mean that the NCSBN is testing those types of questions, or it could mean that the individual keeps getting those types of questions incorrect. The computer will continue to randomly generate questions from that category until the individual has met the requirements of the test plan.\n\nEach individual will have a maximum of six hours to complete the exam but there is no minimum time limit. There is a mandatory 10-minute break about 2 ½ hours after the start of the exam and another optional break after about 4 hours of testing. It is acceptable to take breaks any time during the exam, however, test-takers will lose the additional break time from the total test time.\n\nA certain number of correctly answered questions is not required to pass the exam. An individual’ s score will not be compared to other scores to determine if he or she passes. The NCLEX is graded by comparing the responses to a pre-established standard. Those individuals who meet or exceed the standard pass the exam, those who do not fail.\n\n\n\n"}
{"id": "14407895", "url": "https://en.wikipedia.org/wiki?curid=14407895", "title": "National Health and Nutrition Examination Survey", "text": "National Health and Nutrition Examination Survey\n\nThe National Health and Nutrition Examination Survey (NHANES) is a survey research program conducted by the National Center for Health Statistics (NCHS) to assess the health and nutritional status of adults and children in the United States, and to track changes over time. The survey combines interviews, physical examinations and laboratory tests. \n\nThe NHANES interview includes demographic, socioeconomic, dietary, and health-related questions. The examination component consists of medical, dental, and physiological measurements, as well as laboratory tests administered by medical personnel.\n\nThe very first NHANES was conducted in 1971, and in 1999 the surveys became an annual event; the first report on the topic was published in 2001.\n\nNHANES findings are used to determine the prevalence of major diseases and risk factors for diseases. Information is used to assess nutritional status and its association with health promotion and disease prevention. NHANES findings are also the basis for national standards for such measurements as height, weight, and blood pressure. NHANES data from are used in epidemiological studies and health sciences research, which help develop sound public health policy, direct and design health programs and services, and expand health knowledge.\n\n"}
{"id": "2605020", "url": "https://en.wikipedia.org/wiki?curid=2605020", "title": "New Earth (Doctor Who)", "text": "New Earth (Doctor Who)\n\n\"New Earth\" is the first episode of the second series of the British science fiction television series \"Doctor Who\". It was first broadcast on BBC One on 15 April 2006.\n\nThe episode is set five billion years in the future on the planet New Earth, a planet humanity settled on following the destruction of the Earth in the 2005 episode \"The End of the World\". In the episode, the alien time traveller the Tenth Doctor (David Tennant), his travelling companion Rose Tyler (Billie Piper), and their old enemy Lady Cassandra (Zoë Wanamaker) uncover many artificially-grown humans having been infected with every disease in a hospital by a group of humanoid cat nuns as a way of finding cures for the diseases.\n\nThe Tenth Doctor takes Rose to the farthest point he's ever taken her, to the year 5,000,000,023, in the M87 galaxy. After the destruction of the Earth, humanity settled onto a world they named \"New Earth\". The Doctor is summoned to Ward 26 in a hospital in New New York through his psychic paper. In the Ward, the Doctor meets several humanoid feline nuns of the Sisters of Plenitude who are overseeing the patients. The patients catch the attention of the Doctor because they all have incurable maladies but are somehow being cured by the Sisters. The Doctor recognises the Face of Boe, who sent the message the Doctor received. Meanwhile, Rose is separated from the Doctor and brought to the basement, where she is escorted by Chip to meet Lady Cassandra. Chip has been using the hospital facility to care for Cassandra, but she is suspicious of the methods used in the hospital and needs Rose's help to investigate. Rose is tricked into stepping into a psychograft, a machine that allows Cassandra to implant her mind into Rose's body possessing her. Examining her new appearance, Cassandra is initially disgusted by Rose's \"Chav\" outfit but soon decides she is attractive enough. She is able to access Rose's thoughts and learns of the Doctor's new form.\n\nThe Doctor is suspicious of Cassandra/Rose's actions after she kisses him and displays knowledge of advanced computer systems. He and Cassandra/Rose discover that the hospital houses thousands of pods containing artificially grown humans in what is supposedly the hospital's intensive care unit. The artificial humans are forcibly infected with every disease in the galaxy so that the Sisters can discover the cures. The Doctor confronts the Sisters over their atrocity, and they insist it was necessary to deal with the influx of settlers and the diseases they brought with them. They also insist that they are simply flesh due to their origins, without any actual life. The Doctor believes that Rose's current actions are a result of being a test subject and orders her affliction to be reversed, but Cassandra/Rose uses a perfume gas hidden in her cleavage to knock the Doctor out, locking him in a pod. Cassandra/Rose then approaches the head Sister and demands payment in exchange for keeping the human test subjects secret. The Sisters refuse, and Cassandra/Rose releases the Doctor and some of the humans as a distraction. The infected humans release others from their pods and soon a zombie-like attack begins, with those infected trying to attack others in the hospital.\n\nA quarantine is ordered, and the Doctor, Cassandra/Rose, and the remaining Sisters try to flee the lower levels. Cassandra is able to jump her mind between other bodies, including one of the infected humans, and learns that the infected humans feel a strong sense of loneliness of not being able to touch or be touched. Eventually, the Doctor and Cassandra/Rose reach Ward 26 and grab all the intravenous medical solutions, emptying them into a disinfectant shower. They are able to spray the mixture onto a group of the infected humans, who within moments become cured of their diseases. The Doctor encourages them to go and spread the cure to the other infected people, and soon the attack is over. The police arrest the surviving Sisters, while the Face of Boe tells the Doctor that the message for him can wait until they meet for the third and final time.\n\nThe Doctor orders Cassandra out of Rose's body. Cassandra doesn't want to die, and Chip volunteers to accept her consciousness. Chip's cloned body begins to fail, and Cassandra finally accepts her impending true death. The Doctor decides to do one last thing for Cassandra and takes her back to see herself on the last night someone had called her beautiful. Cassandra/Chip approaches the Lady Cassandra at a party and tells that she is beautiful before collapsing and dying in the younger Cassandra's arms. As Cassandra finally dies, the Doctor and Rose silently leave in the TARDIS.\n\nRussell T Davies said of the episode \"I promised Billie [Piper] an episode in which she'd be funny. So episode one of the new series is very much based around comedy for Billie.\"\n\nThe exterior scenes on New Earth were shot at Worm's Head on the Gower Peninsula on 26 September 2005. The hospital basement scenes were recorded at Tredegar House in Newport. The location for the pods containing the human specimens was a disused paper mill previously used as the base of the Nestene Consciousness in \"Rose\". The hospital scenes were filmed inside the Wales Millennium Centre. When the Doctor asks about the shop and points to where he would put it, he points to the location of the centre's own Portmeirion shop. The nightclub the Doctor and Rose take Cassandra (as Chip) to at the end was filmed at the restaurant Ba Orient in Cardiff Bay. As it was filmed during the day, the building was covered with black drapes. The exterior shots of the lift car as Rose descends to the basement are reused footage from \"Rose\". Cassandra's face and body was put in during post-production by The Mill.\n\nThe producer's and director's credits have been amended slightly since \"The Christmas Invasion\", so that now the credit is in lower case and the name of the crewmember is in capitals. This was the result of a suggestion from a \"Doctor Who Magazine\" editor, who felt the previous arrangement had made the job seem more important than the crewmember.\n\nThis episode is set twenty-three years after the events of the 2005 episode \"The End of the World\", and thirty years prior to the events of the 2007 episode \"Gridlock\". Originally, Davies intended the Face of Boe to impart his message upon the Doctor in this episode; when he discovered that a third series was definitely to occur, Davies quickly decided to delay Boe's message for a year.\n\nAccording to Russell T Davies on the episode commentary, Cassandra's earlier self bases Chip on the man who had praised her beauty at the party — Chip himself. Where the \"pattern\" for Chip comes from in the first instance is thus unclear, creating an ontological paradox.\n\nAlso in the commentary, Tennant noted that the TARDIS has moved since \"The Christmas Invasion\". He speculates that there might have been many off-screen adventures, or (observing that it no longer seems like Christmas in the introduction) perhaps that the Doctor \"lived there for a bit\".\n\nAdjoa Andoh returned to \"Doctor Who\" in five episodes of Series 3 and the final two episodes of Series 4, as Francine Jones, mother of Martha Jones. She also played Nurse Albertine in the audio play \"Year of the Pig\".\n\nCassandra uses the UK slang term chav, although she is unable to mimic Rose's accent properly, instead making attempts at Cockney rhyming slang. Rose refers to Cassandra as \"Michael Jackson\" as she did in \"The End of the World\". She refers to Chip as \"Gollum\".\n\nOvernight ratings for the episode peaked at 8.3 million viewers in the UK, with a final rating of 8.62 million, making it the ninth most watched programme of the week. The episode achieved an audience Appreciation Index of 85. This is the first \"Doctor Who\" episode to have an accompanying TARDISODE.\n\nThe Canadian English-language premiere of Series 2 on CBC, consisting of this episode, took place on 9 October 2006. It concluded with an extended version of the \"Tooth and Claw\" trailer from the BBC broadcast; the revised closing theme was not heard in the broadcast and it was also the first episode to be broadcast without a specially taped introduction featuring one of the lead actors. The episode had previously aired on 29 August 2006 in translation on the French-language broadcaster Ztélé, under the title \"Une nouvelle Terre\".\n\nThis episode was released together with \"The Christmas Invasion\" as a basic DVD with no special features on 1 May 2006, and as part of a second series boxset on 20 November 2006. *Copies of the DVD from the complete Series 2 set distributed to Netflix customers contained an error: at the 32-minute mark, the playback switched abruptly to a scene from \"\". Netflix has pulled the disc from their inventory while they work out the issue with the BBC; this only seems to have affected Netflix copies.\n\nIGN's rated the episode 7.2 out of 10, concluding, \"Although this was an entertaining episode, it did not have the dramatic impact of the previous episode. Overall, \"New Earth\" featured more than a few interesting moments, such as the scenes with the Doctor and the Face of Boe, and Billie Piper's performance as the Casandra-possessed Rose was hilarious; but the zombie attack felt quite out of place for a \"Doctor Who\" episode\". Nick Setchfield of \"SFX\" questioned whether the \"brash, colourful and occasionally howl-out-loud funny\" tone was appropriate enough to start the series, but he praised the concept of the cat nuns as well as their prosthetics, Tennant's performance, and the ending that \"alchemises the broad strokes comedy into something genuinely moving\". Writing for \"The A.V. Club\" in 2014, Alasdair Wilkins gave \"New Earth\" the grade of \"C+\". He noted that, likely due to production difficulties, it \"too often feels like it is missing vital context\" and suffered from unconvincing special effects. Furthermore, he criticised the story for being \"caught between two irreconcilable tones\" and featuring a \"baffling\" ending that wished to redeem Cassandra. Nevertheless, he found Tennants performance to be impressive though not as coherent as he eventually will be, and he praised Piper despite the fact that the story lacked Rose's character.\n\n\n"}
{"id": "10196194", "url": "https://en.wikipedia.org/wiki?curid=10196194", "title": "Novartis Foundation", "text": "Novartis Foundation\n\nThe Novartis Foundation (formerly known as the Novartis Foundation for Sustainable Development) is a non-profit organization and part of the corporate responsibility portfolio of Novartis in Basel, Switzerland. The foundation conducts projects to improve health, mostly in sub-Saharan Africa and in south-east Asia.\n\nThe Novartis Foundation has been one of the leading organizations in the private sector for international development for the last 35 years. The humanitarian engagement of the Novartis Foundation goes back to the 1960s, when the Basel-based companies Ciba, Geigy, Sandoz, Durand & Huguenin, Hoffmann-La Roche and Lonza founded the Basel Foundation for Developing Countries. The Basel Foundation, for example, supported the field laboratory of the Swiss Tropical Institute (now known as the Ifakara Health Institute) located in Ifakara, which still works closely with the Novartis Foundation.\n\nToday, the Novartis Foundation focuses its work on the fight against leprosy and malaria, as well as on access to healthcare projects. The foundation acts as facilitator between the private sector, the state and civil society.\n\nThe Novartis Foundation supports access to healthcare in sub-Saharan Africa and on the Indian subcontinent. The aim is to improve access to primary healthcare and to strengthen the local healthcare systems.\n\nThe foundation fosters health policy among the private sector, non-governmental organizations, research institutions and state organizations. The foundation organizes an international symposium in Basel every year.\n\nThe Novartis Foundation was a scientific and educational charity, formed in 1949 by the Swiss company Ciba, now Novartis, and dissolved in 2008. It was the direct successor to the Ciba Foundation, and the changed name (Novartis Foundation) reflected the new name of Ciba, after merging with Sandoz. The Foundation was the brainchild of Robert Käppeli, Managing Director (and later President) of Ciba. The purpose of the institution was to promote collaboration in the medical sciences by the organisation of symposia which would allow experts of different fields to share ideas. Symposia took place both at their London premises and also in locations across the globe. Later these discussions were written up by in-house editors and published by John Wiley & Sons, with whom the foundation had a long-standing relationship.\n\nNovartis, though it provided financial support for the foundation, was not (in later years) represented on the Board of Trustees and occupied only a minority of seats on the executive council. The company withdrew their financial support from the foundation in February 2008. The trustees chose to undergo a merger with the Academy of Medical Sciences, which occurred on 31 July 2008 prior to the dissolution of the foundation later that year\nThe foundation had its headquarters at 41 Portland Place in central London, UK. The headquarters was refurbished and reopened by the Academy of Medical Sciences in 2010.\n\n"}
{"id": "41520240", "url": "https://en.wikipedia.org/wiki?curid=41520240", "title": "Nursing literature", "text": "Nursing literature\n\nNursing literature refers to articles in journals and texts in books devoted to the field of nursing.\n\nUnder the influence of Florence Nightingale, nursing became a scientific field of study and an independent discipline in healthcare. On March 6, 1886, the first nursing journal, \"The Nightingale\" was published, becoming the first nursing journal. In 1900, the \"American Journal of Nursing\" began publication, becoming the first nursing journal to be owned and operated by nurses. It remains the oldest nursing journal still in circulation.\n\nIn 1952, the first journal dedicated to nursing research, \"Nursing Research\" was published.\n\nAs the profession grew, new journals began to be published, including journals dedicated to various nursing specialties.\n\nNursing journals remain a primary method in which the nursing community shares information and disseminates research findings. These journals are most often peer-reviewed and contain editorials and reports of original research, including randomized controlled trials, observational studies, systematic reviews, meta-analyses, and qualitative research. Some journals also include case reports and case studies.\n\nWith the advent of evidence-based nursing, the number of journals blossomed.\n\nMost journal articles are indexed in National Library of Medicine's PubMed database as well as various other databases, including CINAHL.\n\nNightingale wrote extensively during her years as a nurse. Her most important work was Notes on Nursing in which she provided instructions for caregivers, including nurses, on how to provide care to the wounded and sick, as well as health promotion topics. Although not officially a textbook for nursing, it is considered the first scientific writing about nursing care.\n\nThe first scholarly textbook for nursing is generally accepted as \"Text-Book of the Principles and Practice of Nursing\" by Bertha Harmer, a Canadian nurse and early nurse educator. Virginia Henderson is regarded as one of the earliest nurse educators to expand the scholarly writings of nursing into textbooks for use in schools and colleges of nursing.\n\n"}
{"id": "3837120", "url": "https://en.wikipedia.org/wiki?curid=3837120", "title": "Nursing pin", "text": "Nursing pin\n\nA nursing pin is a type of badge, usually made of metal such as gold or silver, which is worn by nurses to identify the nursing school from which they graduated. They are traditionally presented to the newly graduated nurses by the faculty at a pinning ceremony as a symbolic welcome into the profession. Most pins have a symbolic meaning, often representing the history of the nursing program for that school of nursing.\nThe ancestor of the nursing pin is the Maltese cross. Some significant historical contributors to the foundation of hospital standards involved in using the Maltese cross were the Knights Hospitaller and Order of Saint Lazarus, pioneers of communicable disease care, such as leprosy, syphilis, and other chronic skin diseases during their period, and established one of a few hospitals in the territories of their reign. As the Renaissance period progressed, the use of the symbol has evolved into family coat of arms, then given to those who were providers of exclusive services. Such pins were then awarded to nurses who were needed by society during periods of spread of uncontrolled illnesses during the early period, and to recognize them as nurses who are educated, trained and experienced in the said field.\n\nModern designs of nurses' pins have evolved through time. The Maltese cross, in some nursing educational institutions, has not been incorporated in their pins. Instead, their own seal or logo, such as that of their nursing school, nursing organization or university affiliation is used. The pin is still worn as part of nurses' uniforms today, in such cases, before or even after they graduate from their respective nursing schools and work for medical institutions, such as hospitals and health and wellness centers.\n\nPins vary widely in shape and imagery, generally about the proportions of a woman's brooch (less than 10 cm diameter). A common graphic is an old pattern oil lamp. These lamps or candles were the only lighting available before kerosene became available early in the twentieth century. There are a selection of lamps in the Florence Nightingale museum, thought to have been used in the Scutari hospital in the area known geographically as the Balkans (then British Moldavia, now southern Ukraine), during the war with Russia. American Poet Henry Wadsworth Longfellow wrote a poem \"Saint Philomena\" dedicated to the work of Florence in 1857. In this verses, Longfellow characterised Florence as \"The lady with the lamp\". The poem was used in fundraising for the wounded veterans of the empire. The image of the lamp used by the emerging modern nursing profession took hold.\n\nAnother common graphic found on nursing pins is the symbol we associate with the international association of the red crescent and red cross, namely the red cross itself. In times past, young women who adopted the profession of nursing were accepted as nurses, particularly in overseas service roles, such as military and mission work, when they joined the red cross society. Volunteers usually had to supply their own uniforms, equipment and generally had to undertake charitable works in order to raise funds for their own passage to the area of identified need. Red cross nurses are honoured in the 1916 song Rose of no man's land but were by no means the only volunteers. Nurses were also drawn from organisations like the ancient order of deaconesses and quaker ambulance units. The situation changed during the great war, in which the contribution of nursing to the war effort was recognised in several urgent recruitment drives. As nurses were granted access to postings, commissions and pensions, amateur involvement declined.\n\nAnother symbol previously used was the sword entwined by double winged serpents. This sword of caduceus was mistakenly used by the United States medical forces in place of the wand of Asclepius (one serpent without wings on a stick), a long-standing symbol of medical doctors and physicians.\n\nOther common symbols include\n\n"}
{"id": "4901146", "url": "https://en.wikipedia.org/wiki?curid=4901146", "title": "Opium production in Afghanistan", "text": "Opium production in Afghanistan\n\nAfghanistan has been the world's leading illicit opium producer since 1992 (excluding the year 2001). Afghanistan's opium poppy harvest produces more than 90% of illicit heroin globally, and more than 95% of the European supply. More land is used for opium in Afghanistan than is used for coca cultivation in Latin America. In 2007, 93% of the non-pharmaceutical-grade opiates on the world market originated in Afghanistan. This amounts to an export value of about US$4 billion, with a quarter being earned by opium farmers and the rest going to district officials, insurgents, warlords, and drug traffickers.\nIn the seven years (1994–2000) prior to a Taliban opium ban, the Afghan farmers' share of gross income from opium was divided among 200,000 families. As of 2017, opium production provides about 400,000 jobs in Afghanistan, more than the Afghan National Security Forces. In addition to opium, Afghanistan is also the world's leading producer of hashish.. Almost 85% of the villages in the country's south cultivate opium poppies. The drug economy provides regular and somewhat reliable income to rural people in this extremely unstable country.The drug sector has been estimated to be worth between $4.1 billion and $6.6 billion, which would amount to about 20% to 32% of the country's gross domestic product in 2017.\n\nAfghanistan first began producing opium in significant quantities in the mid-1950s, to supply its neighbour Iran after poppy cultivation was banned there. Afghanistan and Pakistan increased production and became major suppliers of opiates to Western Europe and North America in the mid-1970s, when political instability combined with a prolonged drought disrupted supplies from the Golden Triangle.\n\nAs the Afghan government began to lose control of provinces during the Soviet invasion of 1979–80, warlords flourished. With that lack of control, opium production also expanded, as regional commanders searched for ways to generate money to purchase weapons, according to the United Nations. (At this time the United States was pursuing an \"arms-length\" supporting strategy of the Afghan freedom-fighters or Mujahideen, the main purpose of which was to cripple the Soviet Union slowly into withdrawal through attrition rather than effect a quick and decisive overthrow).\n\nAs explained by Zbigniew Brzezinski:\n\nIt was alleged by the Soviets on multiple occasions that US Central Intelligence Agency (CIA) agents were helping smuggle opium out of Afghanistan, either into the West, in order to raise money for the Afghan resistance, or into the Soviet Union, in order to weaken it through drug addiction. According to Alfred McCoy, the CIA supported various Afghan drug lords, for instance Gulbuddin Hekmatyar and others such as Haji Ayub Afridi.\n\nAnother factor was the eradication effort inside Pakistan (whose Inter-Services Intelligence were coincidentally supporters of the Mujahideen). The Pakistani government, US Agency for International Development (USAID) and other groups were involved in attempting to eliminate poppy cultivation from certain areas of the North-West Frontier Province (now Khyber Pakhtunkhwa) bordering Afghanistan. The opium industry shifted from Pakistan into Afghanistan during the 1980s.\n\nWhen the Soviet Army was forced to withdraw in 1989, a power vacuum was created. Various Mujahideen factions started fighting against each other for power. With the discontinuation of Western support, they resorted ever more to poppy cultivation to finance their military existence.\n\nDuring the Taliban rule, Afghanistan saw a bumper opium crop of in 1999.\n\nIn July 2000, Taliban leader Mullah Mohammed Omar, collaborating with the UN to eradicate heroin production in Afghanistan, declared that growing poppies was un-Islamic, resulting in one of the world's most successful anti-drug campaigns. The Taliban enforced a ban on poppy farming via threats, forced eradication, and public punishment of transgressors. The result was a 99% reduction in the area of opium poppy farming in Taliban-controlled areas, roughly three quarters of the world's supply of heroin at the time. The ban was effective only briefly due to the deposition of the Taliban in 2002.\n\nHowever, some people (Martin, An Intimate War, 2014), suggest that certain parties benefited from the price increase during the ban. Some, even believe it was a form of market manipulation on the part of certain drug lords. Dried opium, unlike most agricultural products, can easily be stored for long periods without refrigeration or other expensive equipment. With huge stashes of opium stored in secret hideaways, the Taliban and other groups that were involved in the drug trade were in theory able to make huge personal profits during the price spikes after the 2000 ban and the chaos following the September 11 attacks.\n\nBy November 2001, and with the start of the Afghan War, the collapse of the economy and the scarcity of other sources of revenue forced many of the country's farmers to resort to growing opium for export ( in 2004 according to the UN Office on Drugs and Crime).\n\nIn December 2001, a number of prominent Afghans met in Bonn, Germany, under UN auspices to develop a plan to reestablish the State of Afghanistan, including provisions for a new constitution and national elections. As part of that agreement, the United Kingdom (UK) was designated the lead country in addressing counter-narcotics issues in Afghanistan. Afghanistan subsequently implemented its new constitution and held national elections. On December 7, 2004, Hamid Karzai was formally sworn in as president of a democratic Afghanistan.\"\n\nTwo of the following three growing seasons saw record levels of opium poppy cultivation. Corrupt officials may have undermined the government's enforcement efforts. Afghan farmers claimed that \"government officials take bribes for turning a blind eye to the drug trade while punishing poor opium growers.\"\n\nAnother obstacle to getting rid of poppy cultivation in Afghanistan is the reluctant collaboration between US forces and Afghan warlords in hunting drug traffickers. In the absence of the Taliban, the warlords largely control the opium trade but are also highly useful to US forces in scouting, providing local intelligence, keeping their own territories clean from Al-Qaeda and Taliban insurgents, and even taking part in military operations.\n\nWhile US and allied efforts to combat the drug trade have been stepped up, the effort is hampered by the fact that many suspected drug traffickers are now top officials in the Karzai government. Estimates made in 2006 by the UN Office on Drugs and Crime (UNODC) estimate that 52% of the nation's GDP, amounting to US$2.7 billion annually, is generated by the drug trade. The rise in production has been linked to the deteriorating security situation, as production is markedly lower in areas with stable security. By some, the extermination of the poppy crops is not seen as a viable option because the sale of poppies constitutes the livelihood of Afghanistan's rural farmers. Some 3.3 million Afghans are involved in producing opium. Opium is more profitable than wheat and destroying opium fields could possibly lead to discontent or unrest among the indigent population. Some poppy eradication programs have, however, proven effective, especially in the north of Afghanistan. The opium poppy eradication program of Balkh Governor Ustad Atta Mohammad Noor between 2005 and 2007 successfully reduced poppy cultivation in Balkh Province from in 2005 to zero by 2007.\n\nThe Afghanistan Opium Risk Assessment 2013, issued by UNODC, suggests that the Taliban has, since 2008, been supporting farmers growing poppy, as a source of income for the insurgency.\n\nFormer US State Department Principal Deputy Assistant Secretary for the Bureau of International Narcotics and Law Enforcement Affairs Thomas Schweich, in a \"New York Times\" article dated July 27, 2007, asserts that opium production is protected by the government of Hamid Karzai as well as by the Taliban, as all parties to political conflict in Afghanistan, as well as criminals, benefit from opium production, and, in Schweich's opinion, the US military turns a blind eye to opium production as not being central to its anti-terrorism mission. In March 2010, NATO rejected Russian proposals for Afghan poppy spraying, citing concerns over income of Afghan people. There have also been allegations of US and European involvement in Afghanistan's drug trafficking with links to Taliban.\n\nOn October 28, 2010, agents of Russia's Federal Service for the Control of Narcotics joined Afghan and US anti-drug forces in an operation to destroy a major drug production site near Jalalabad. In the operation, of high quality heroin and of opium, with a street value of US$250 million, and a large amount of technical equipment was destroyed. This was the first anti-drug operation to include Russian agents. According to Viktor Ivanov, Director of Russia's Federal Service for the Control of Narcotics, this marks an advance in relations between Moscow and Washington. Hamid Karzai called the operation a violation of Afghan sovereignty and international law.\n\nAs had been the case in Indochina during the Vietnam War, the US invasion has in fact been causal in a massive increase in opium production, the aforementioned eradication efforts being largely window dressing. A SIGAR report showed a threefold increase in area under cultivation between 2002 and 2014. A December 2014 UNAIDS study showed an increase of 7% in one year alone.\n\nThe facts of an apparently non-significant resultant change to opium production is corroborated in a report by BBC, dated to 20 July 2015:\n\nApproximately 40,000 foreign troops attempted to manage \"security\" in Afghanistan, principally of 32,000 regular soldiers from 37 NATO forces: the International Security Assistance Force. 8,000 US and other special operations forces, mainly privately contracted soldiers of fortune, make up the balance. There is significant resistance, both from the ideological and theocratic Taliban, especially in southern Afghanistan, and independent local warlords and drug organizations. Antonio Maria Costa, Executive Director of UNODC, described the situation: \"There is no rule of law in most of the southern parts of Afghanistan—the bullets rule.\"\n\nThe following areas of Afghanistan play a role in the drug trafficking:\n\nAccording to the US Department of Labor's 2014 \"List of Goods Produced by Child Labor or Forced Labor\", opium production is one of the sectors that rely on child labor in Afghanistan. Poppies being the source of the crude drug, children are still recruited to harvest these flowers in the country's farming fields.\n\nAccording to European Union (EU) agencies, Afghanistan has been Europe's main heroin supplier for more than 10 years. Heroin enters Europe primarily by two major land routes: the long-standing 'Balkan route' through Turkey; and, since the mid-1990s, the 'northern route', which leaves northern Afghanistan through Central Asia and on to Russia (and is sometimes colloquially referred to as the 'silk route'). There is an estimated 1.5 million (1.3–1.7 million) opioid users in the EU, with an average prevalence of 4 to 5 per 1,000. In 2005, there were around 7,000 acute drug deaths, with opioids being present in the blood of 70% of the deceased. There was a minimum of 49,000 seizures resulting in the interception of an estimated of heroin. Countries reporting the largest number of seizures (in descending order): UK (2005), Spain, Germany, Greece, and France. Countries reporting the largest quantities of heroin seized in 2005 (in descending order): Turkey, UK, Italy, France, the Netherlands.\n\nPresently with the resurgence of high output production of opium and heroin in post-Taliban Afghanistan, there is an ongoing heroin addiction epidemic in Russia which is claiming 30,000 lives each year, mostly among young people. There were two and half million heroin addicts in Russia by 2009.\n\nThe International Council on Security and Development (ICOS) has proposed legalizing opium production for medical purposes. Opium can be manufactured into codeine and morphine, which are both legal pain-killers. The Governor of Afghanistan's Helmand Province, Hayatullah Hayat is a proponent of eventually legalizing opium production to create morphine.\n\nOthers have argued that legalizing opium production would neither solve the problem nor would it be workable in practice. They argue that illegal diversion of the crop could only be minimized if the Afghans had the necessary resources, institutional capacity and control mechanisms in place to ensure that they were the sole purchaser of opiate raw materials. For them, there is currently no infrastructure in place to set up and administer such a scheme. They reason that in the absence of an effective control system, traffickers would be free to continue to exploit the market and there would be a high risk that licit cultivation would be used for illegal purposes and that the Afghan government would be in direct competition with the traffickers, thereby driving up the price of opium, and attracting more farmers to cultivate. The Afghan government has ruled out licit cultivation as a means of tackling the illegal drug trade: however in Turkey in the 1970s, legalizing opium production, with US support brought illicit trafficking under control within four years. Afghan villages have strong local control systems based around the village shura, which with the support of the Afghan government and its international allies, could provide the basis for an effective control system. This idea is developed in the recent Senlis Council report \"Poppy for Medicine\" which proposes a technical model for the implementation of poppy licensing and the legal control of cultivation and production of Afghan morphine.\n\nSome believe that there is also little evidence to show that Afghan opium would be economically competitive in a global market place. Australia, France, India, Spain, and Turkey currently dominate the export market for licit opiates. Due to the high cost of production in countries where cultivation is undertaken on small landholdings, such as India and Turkey, licit production requires market support (the production costs for the equivalent of 1 kg of morphine in 1999 was US$56 in Australia, US$159.77 in India and US$250 in Turkey). The current cost of production of one kilogram of morphine equivalent in Afghanistan is approximately US$450. However, a poppy for medicine project in Afghanistan could provide a cheap pain relief option for pain sufferers who find morphine prices extremely elevated.\n\nThe price of illicit opium far exceeds that of licit, (in India, in 2000, the price for licit opium was US$13–29 per kilo, but for illicit US$155–206). Although there are many complex reasons behind the decision to grow poppy, one of them is the current economic dependence of poppy farmers on the illicit trade. Whilst traffickers continue to be free to exploit the illicit market, legalization would not change this. Demand for illicit opiates would not disappear even if Afghan opium were used for licit purposes and a vacuum would open that traffickers could exploit. However, currently 100% of Afghan opium is diverted to the illegal opium trade and funds in some cases terrorist activities. Despite eradication efforts since the international intervention in 2001, poppy cultivation and illicit opium production has increased, as UNODC figures show. A licensing system would bring farmers and villages into a supportive relationship with the Afghan government, instead of alienating the population by destroying their livelihood, and provide the economic diversification that could help cultivators break ties with the illicit opium trade.\n\nThe International Narcotics Control Board states that an over production in licit opiates since 2000 has led to stockpiles in producing countries 'that could cover demand for two years'. Thus, some say Afghan opium would contribute to an already oversupplied market and would potentially cause the supply and demand imbalance that the UN control system was designed. However, the World Health Organization points out that there is an acute global shortage of poppy-based medicines such as morphine and codeine. This is largely due to chronic underprescription (especially in countries where morphine is extremely highly priced). The International Narcotics Control Board which regulates opium supply throughout the world enforces the 1961 Single Convention on Narcotic Drugs: this law provides that countries can only demand the raw poppy materials corresponding to the use of opium-based medicines over the last two years and thus limits countries who have low levels of prescription in terms of the amounts they can demand. As such, 77% of the world's opium supplies are being used by only six countries, leaving the rest of the world lacking in essential medicines such as morphine and codeine. A second-tier supply system, that complements the current UN control system by supplying opium-based medicines to countries currently not receiving the poppy-based pain relief medicines needed, would maintain the balance established by the UN system and provide a market to Afghan-made poppy-based medicines.\n\nAfghanistan has seen a high rate of opium addiction among refugees returning from Iran and Pakistan. Zalmai Afzali, spokesman for the Ministry of Counter-Narcotics in Afghanistan reports an increase in the total number of drug users by over half a million, to 1.5 million, between 2005 and 2010.\n\nThe 2004 United Nations Development Programme ranked Afghanistan number 173 of 177 countries, using a human development index, with Afghanistan near or at the bottom of virtually every development indicator including nutrition, infant mortality, life expectancy, and literacy. Several factors encourage opium production, the greatest being economic: the high rate of return on investment from opium poppy cultivation has driven an agricultural shift in Afghanistan from growing traditional crops to growing opium poppy.\n\nOpium cultivation on this scale is not traditional, and in the area controlled by the Helmand Valley Authority in the 1950s the crop was largely suppressed.\n\n\"Despite the fact that only 12 percent of its land is arable, agriculture is a way of life for 70 percent of Afghans and is the country's primary source of income. During good years, Afghanistan produced enough food to feed its people as well as supply a surplus for export. Its traditional agricultural products include wheat, corn, barley, rice, cotton, fruit, nuts, and grapes. However, its agricultural economy has suffered considerably [...] Afghanistan's largest and fastest cash crop is opium.\"\n\nPoppy Cultivation and the Opium Trade have been said to have had a more significant impact on the civilians in Afghanistan than the impact of wheat farming and livestock trading. As farmers in Afghanistan were once heavily reliant on wheat farming to make sufficient income, the development of poppy cultivation has given many of these farmers a boost in capital, even though opium may be a more dangerous product to distribute. In addition, as the demand for Opium has elevated, women have more opportunity to work in the same setting as their male counterpart.\n\nAfghanistan's rugged terrain encourages local autonomy, which, in some cases, means local leadership committed to an opium economy. The terrain makes surveillance and enforcement difficult.\n\nAccording to the United Nations Office on Drugs and Crime (UNODC) \"2007 Afghanistan Opium Survey\", Afghanistan produced approximately 8,200 metric tonnes of opium – nearly double the estimate of global annual consumption. In an April 25, 2007 op-ed in the \"Washington Post\", Antonio Maria Costa, Executive Director of UNODC, asked \"Does opium defy the laws of economics? Historically, no. In 2001, prices surged tenfold from 2000, to a record high, after the Taliban all but eliminated opium poppy cultivation across the Afghan territory under its control. So why, with last year's bumper crop, is the opposite not occurring? Early estimates suggest that opium cultivation is likely to increase again this year. That should be an added incentive to sell.\n\nHe speculated, \"So where is it? I fear there may be a more sinister explanation for why the bottom has not fallen out of the opium market: major traffickers are withholding significant amounts.\n\n\"Drug traffickers have a symbiotic relationship with insurgents and terrorist groups such as the Taliban and al-Qaeda. Instability makes opium cultivation possible; opium buys protection and pays for weapons and foot soldiers, and these in turn create an environment in which drug lords, insurgents and terrorists can operate with impunity.\n\n\"Opium is the glue that holds this murky relationship together. If profits fall, these sinister forces have the most to lose. I suspect that the big traffickers are hoarding surplus opium as a hedge against future price shocks and as a source of funding for future terrorist attacks, in Afghanistan or elsewhere.\"\n\nDue to globalization and the development of trade, traditional ways of sustaining life for villagers has been forced to change. Before, people relied on wheat farming and livestock, whereas today, poppy cultivation is the most prominent economic activity. This can be attributed to higher profits from poppy cultivation and lack of opportunity for other farming practices due to land scarcity and more accessible loans from money providers for this activity.\n\nWar, economic instability, and poverty caused changes in the way villagers maintained their villages. Competition for scarce land and resources resulted in unsustainable practices, causing soil erosion and therefore making the land less productive. The cultivation of poppy, however, generated greater profits than wheat farming for the farming villagers due to the higher yielding possibilities with less land (poppies require less irrigation than wheat), and greater demand for the profitable drug trade of the highly valued opium, prepared from poppies. Many emigrants to places such as Pakistan and Iran witnessed the profitability of poppy cultivation in land development, through association with local landowners and businessmen, and were inspired to bring about the same economic improvement in their own lives and villages. Also, opium trade proved to be more cost-efficient than livestock trade, since large amounts of opium are easier to transport than livestock. Local shopkeepers used capital, which was acquired from buying opium resins from farmers and selling them to dealers at the Tajikistan-Afghanistan border, to invest in their own small shops, generating more income. Poor villagers saw this as a good investment opportunity, as it meant more efficient farming of one product with the possibility of creating economic stability in their villages.\n\nAside from the obvious threat of addiction, opium production is changing the dynamic of many Afghan villages. Wealth distribution, for example, has changed significantly as the opium economy has created a \"new rich\" in which young men have control. This newfound wealth for the young men of Afghanistan is troubling to many of the village leaders as before they were revered for their wisdom, and now are given little if any respect. It has also been noted that relationships among fathers and sons, neighbours, and family in general, are drastically changing as leadership roles in the economy continue to shift. As the young men have increased contact with the outer world, they have become aware of different methods of performing traditional tasks, which have created tensions between the young men and the white beards. Also, there has been a shift from the level of co-operation, trust, and reciprocity within villages to a move of self-interest, all of which have been adversely affected by the war.\n\nWhile the Taliban were considered a threat both to the human rights of Afghans, and to other areas of the world by providing a sanctuary for transnational terrorists, they also demonstrated an ability to strictly enforce a moratorium on opium production. Since their overthrow in 2001, stopping their enforcement with methods including beheading, opium poppy cultivation has been steadily increasing for over the past two decades. There is evidence that the Taliban ban carried the seeds of its own lack of sustainability, due to a many-fold increase in the burden of opium-related debt (locking many households into dependence on future opium poppy cultivation), forcing asset sales to make ends meet, etc. It also appears that the opium ban weakened the Taliban politically. Thus the sustainability of the ban beyond the first year was highly doubtful, even if the\nTaliban had not been overthrown in late 2001.\n\n\"Even though the Karzai government made opium poppy cultivation and trafficking illegal in 2002, many farmers, driven by poverty, continue to cultivate opium poppy to provide for their families. Indeed, poverty is the primary reason given by Afghan farmers for choosing to cultivate opium poppy.\" With a farm gate price of approximately $125 per kilogram for\ndry opium, an Afghan farmer can make 17 times more profit growing opium poppy ($4,622 per hectare), than by growing wheat ($266 per hectare). \"Opium poppy is also drought resistant, easy to transport and store, and, unlike many crops, requires no refrigeration and does not spoil.\" With Afghanistan's limited irrigation, in which qanats (karez) still play a big role, transportation and other agricultural infrastructure, growing alternative crops is not only less profitable, but more difficult.\n\nIn 2006, opium production in the province increased over 162 percent and now accounts for 42 percent of Afghan's total opium output. According to the UNODC, the opium situation in the southern provinces is \"out of control.\"\n\nThe Department of State (DoS), the U.S. Agency for International Development (USAID), the Department of Defense (DoD), and the Department of Justice (DoJ) are the primary organizations involved in carrying out this counternarcotics strategy for the US. The role of the CIA has not been mentioned. UNODC's executive director believes these measures are insufficient: \"What can be done? Since NATO forces are wary of making enemies out of opium farmers by being associated with eradication, and since the Afghan government is opposed to spraying poppy fields, rounding up the major traffickers may be the best available option for disrupting Afghanistan's lucrative opium market.\"\n\nBoth demand and supply reduction are important. \"the consuming countries need to get serious about curbing drug addiction. If there was less demand for heroin, the bottom really would fall out of the opium market.\" Farmers economically dependent on opium must have viable alternatives that give sustainable income. On the supply side, identifying the most-wanted traffickers and subjecting them to international arrest warrants with extradition, asset seizure, and travel bans could help. While it is not easy to destroy opium storage and heroin production laboratories, it is far easier to destroy drugs at the source than in transit.\n\nThere is an important nexus between drugs and hawala (informal money transfer system) in Afghanistan. The UN analysis is based on interviews with a sample of 54 hawala dealers in the main centers of hawala activity of Afghanistan as well as during a visit to Peshawar, Pakistan. In addition, interviews were conducted with users of the hawala system (drug dealers, businessmen, traders, international aid workers), regulators (government officials, central bank personnel), and formal\nservice providers (bankers, accountants). In addition to hawala, they found protection payments and connections, by which the drug industry has major linkages with local administration as well as high levels of the national government.\n\nSee informal money transfer systems to support clandestine activity, including terrorism, drug trade, and intelligence collection.\n\nDifferent localities studied by the UNODC give different views of the laundering of drug funds. It is difficult to get a solid sense of the overall economy. In Faizabad, for example, indicated that during certain times of the year close to 100% of the liquidity of the hawala system in the province is derived from drugs, whereas in Herat, the Northern Alliance stronghold, it was estimated that only 30% of the hawala market's overall transaction volume is directly linked to drugs. Analysis of data gathered in places like Herat was complicated by confirmed links between drug money and legitimate imports. The southern region (Helmand and Kandahar provinces) is also a key centre for money laundering in Afghanistan (about 60% of the funds are drug related and 80–90% of the hawala dealers in Kandahar [the former Taliban stronghold] and Helmand are involved in money transfers related to narcotics).\n\nHelmand has emerged as a key facilitator of the opium trade, both between provinces and exports, while overall estimates of the local hawala markets' drug-related component are of a similar order of magnitude to those in Kandahar. This finding adds weight to the notion that the major trading centers in these two neighboring provinces should be treated as essentially one market. Bearing this in mind, the study calculated that Helmand could account for roughly US$800 million of Afghanistan's drug-related hawala business and that Herat is the second largest contributor, with in the range of US$\n300–500 million of drug money laundered annually.\n\nFurthermore, Dubai appears to be a central clearing house for international hawala activities. In addition, various cities in Pakistan, notably Peshawar, Quetta, and Karachi, are major transaction centers. It appears that even in the case of drug shipments to Iran, payments for them come into Afghanistan from Pakistan ... the hawala system has been key to the deepening and widening of the \"informal economy\" in Afghanistan, where there is anonymity and the opportunity to launder money.\n\nHawala, however, also contributes positively to the regional economy. It has been central to the survival of Afghanistan's financial system through war. According to Maimbo (2003), \"integral to processes of early development and vital for the continued delivery of funds to the provinces.\" \"The hawala system also plays an important role in currency exchange. It participates in the Central Bank's regular foreign currency auctions, and was instrumental in the successful introduction of a new currency for Afghanistan in 2002–2003.\"\n\nWhile Herat is not the highest-volume area of opium trade, Herat, and the other Iranian border areas of Farah, and Nimroz, have some of the highest prices, presumably due to demand from the Iranian market. \"Opium prices are especially high in Iran, where law enforcement is strict and where a large share of the opiate consumption market is still for opium rather than heroin. Not surprisingly, it appears that very significant profits can be made by crossing the Iranian border or by entering Central Asian countries like Tajikistan.\" According to UNODC estimates bulk of Afghanistan's opium production goes to Iran either for consumption or for on-ward export to other countries in the region and Europe. Iran currently has the largest prevalence of opiate consumption in its population globally. Iran also accounts for 84% of total opiate seizures by law enforcement agencies in the world, interdicting tens of thousands of tons of opiates annually. The Iranian government has gone through several phases in dealing with its drug problem.\n\nFirst, during the 1880s, its approach was supply-sided: \"Law-and-order policies with zero tolerance led to the arrest of tens of thousands of addicts and the execution of thousands of narcotics traffickers.\" \"There are an estimated 68,000 Iranians imprisoned for drug trafficking and another 32,000 for drug addiction (out of a total prison population of 170,000, based on 2001 statistics)\"\n\nBeehner said \"Tehran also has spent millions of dollars and deployed thousands of troops to secure its porous 1,000-mile border with Afghanistan and Pakistan... a few hundred Iranian drug police die each year in battles with smugglers. Referring to the head of the UNODC office in Iran, Roberto Arbitrio, Beehner quoted Arbitrio in an interview with \"The Times.\" \"You have drug groups like guerrilla forces, [who] ... shoot with rocket launchers, heavy machine guns, and Kalashnikovs.\"\n\nA second-phase strategy came under then-President Mohammad Khatami, focused more on prevention and treatment. Drug traffic is considered a security problem, and much of it is associated with Baluchi tribesmen, who recognize traditional tribal rather than national borders. Current (2007) reports cite Iranian concern with ethnic guerillas on the borders, possibly supported by the CIA.\n\nIranian drug strategy changed again under President Mahmoud Ahmadinejad, who took office in 2005. Iran's drug policy has been reconsidered and shifted back toward supply interdiction and boosting border security. It is unclear if this is connected to more wide-ranging concerns with border security, perhaps in relation to Baluchi guerillas in Iran.\n\nIran has alleged that certain drugs are manufactured in Afghanistan under guidance of western powers and solely sent to Iran for consumption such as certain compounds of heroin, Crack cocaine and CNS stimulants. Iran has also alleged that large quantities of Acetic anhydride and Hydrochloric acid are brought to Afghanistan from Europe to be used in manufacturing of drugs as Afghanistan does not have the chemical industry to produce the compounds locally.\n\nSamii's 2003 paper described Iran's \"primary approach to the narcotics threat [as] interdiction. Iran shares a 936 kilometer border with Afghanistan and a 909 kilometer border with Pakistan, and the terrain in the two eastern provinces—Sistan va Baluchistan and Khorasan—is very rough. The Iranian government has set up static defenses along this border. This includes concrete dams, berms, trenches, and minefields\".\n\nAs per UN drug report of 2011, Iran accounts for highest rate of opium and heroin seizure rates in the world, intercepting 89% of all seized opium in the world. Within a span of thirty years, 3700 Iranian police officers have been killed and tens of thousands more injured in counter narcotics operations mostly on Afghan and Pakistan borders.\n\nGiven the fact that a third of the combined legal and illegal Afghan economy is based on the illegal opium industry, counter-narcotics policy is currently one of the most important elements of domestic politics. Despite law enforcement measures with a dominant focus on crop eradication programs, Afghan opium production has doubled in just two years. This has shown that currently there is no correlation between poppy crop eradication and the level of poppy cultivation or opium production. The reason for this is the underlying economic nature of the opium problem. Poverty and structural unemployment are the main reason for 3.3 million Afghans' full dependence on poppies.\n\nPoppy crop eradication could even have damaging side-effects for Afghanistan's process of stabilization and reconstruction. Director of policy research for the Senlis Council, Jorrit Kamminga, says:\n\nHe is referring to US-inspired aerial fumigation campaigns, planned for spring 2008 but never initiated. So far, crop eradication is done manually or mechanically from the ground. Chemical spraying could further destabilize rural areas and risk losing support for NATO's stabilization mission.\n\nSince the Taliban allegedly makes Afghanistan's opium business easy, offering credit, seeds and fertilizer to farmers to grow the drugs that fuel the Taliban insurgency, the US authorities are determined to change that momentum by offering similar incentives to steer farmers away from the drug trade and toward alternative, legitimate crops, like grapes, wheat and saffron.\n\nThe United States Department of State issued a press release that stated the arrest of Baz Mohammed \"demonstrated a strengthening collaboration between the United States and the newly democratic Afghanistan.\"\n\n\n"}
{"id": "36717847", "url": "https://en.wikipedia.org/wiki?curid=36717847", "title": "Parastremmatic dwarfism", "text": "Parastremmatic dwarfism\n\nParastremmatic dwarfism is a rare bone disease that features severe dwarfism, thoracic kyphosis (a type of scoliosis that affects the upper back), a distortion and twisting of the limbs, contractures of the large joints, malformations of the vertebrae and pelvis, and incontinence. The disease was first reported in 1970 by Leonard Langer and associates; they used the term \"parastremmatic\" from the Greek \"parastremma\", or \"distorted limbs\", to describe it. On X-rays, the disease is distinguished by a \"flocky\" or lace-like appearance to the bones. The disease is congenital, which means it is apparent at birth. It is caused by a mutation in the \"TRPV4\" gene, located on chromosome 12 in humans. The disease is inherited in an autosomal dominant manner.\n\nParastremmatic dwarfism is apparent at birth, with affected infants usually being described as \"stiff\", or as \"twisted dwarfs\" when the skeletal deformities and appearance of dwarfism further present themselves. Skeletal deformities usually develop in the sixth to twelfth month of an infant's life. The deformities may be attributed to osteomalacia, a lack of bone mineralization.\n\nParastremmatic dwarfism is caused by a missense mutation (where one amino acid is replaced by another in a gene sequence) in the \"TRPV4\" gene, located on the long arm of human chromosome 12, at 12q24.11. The mutation is in exon 11 of the gene, and is labelled R594H; this means that the codon (the code for an amino acid molecule) for arginine was erroneously substituted by a codon for histidine at position 594 in that exon. This same mutation in the \"TRVP4\" gene is known to cause the Kozlowski type of spondylometaphyseal dysplasia.\n\nParastremmatic dwarfism is inherited in an autosomal dominant manner, which means that the defective gene responsible for the disease is located on an autosome (chromosome 12 is an autosome), and one copy of the defective gene is sufficient to cause the disorder when inherited from a parent who also has the disorder.\n"}
{"id": "2574411", "url": "https://en.wikipedia.org/wiki?curid=2574411", "title": "Pneumonitis", "text": "Pneumonitis\n\nPneumonitis or pulmonitis is an inflammation of lung tissue due to factors other than microorganisms. Those can be radiation therapy of the chest , exposure to medications used during chemo-therapy, the inhalation of debris (e.g., animal dander), of food particles during vomiting, herbicides or fluorocarbons and some systemic diseases. \n\nIt is distinguished from pneumonia on the basis of causation as well as its manifestation since pneumonia can be described as pneumonitis combined with consolidation and exudation of lung tissue due to infection with microorganism.\n\nIt can be classified into acute interstitial pneumonitis, blood pneumonitis, lymphocytic interstitial pneumonitis, radiation pneumonitis, and uremic pneumonitis.\n\nChest X-ray\n\n"}
{"id": "1114036", "url": "https://en.wikipedia.org/wiki?curid=1114036", "title": "Polygonatum", "text": "Polygonatum\n\nPolygonatum , also known as King Solomon's-seal or Solomon's seal, is a genus of flowering plants. In the APG III classification system, it is placed in the family Asparagaceae, subfamily Nolinoideae (formerly the family Ruscaceae). It has also been classified in the former family Convallariaceae and, like many lilioid monocots, was formerly classified in the lily family, Liliaceae. The genus is distributed throughout the temperate Northern Hemisphere. Most of the approximately 63 species occur in Asia, with 20 endemic to China.\n\n\"Polygonatum\" comes from the ancient Greek for \"many knees\", referring to the multiple jointed rhizome. One explanation for the derivation of the common name \"Solomon's seal\" is that the roots bear depressions which resemble royal seals. Another is that the cut roots resemble Hebrew characters.\n\nThe fruits are red or black berries.\n\n, the World Checklist of Selected Plant Families accepts 74 species and hybrids:\n\nSeveral species are valued as ornamental plants, including:\nMany species have long been used as food in China. Leaves, stems, and rhizomes are used raw or cooked and served as a side dish with meat and rice. The rhizomes of two local species are eaten with chicken's or pig's feet during festivals. The rhizomes are used to make tea or soaked in wine or liquor to flavor the beverages. They are also fried with sugar and honey to make sweet snacks. The starchy rhizomes can be dried, ground, and added to flour to supplement food staples. The rhizome of \"P. sibiricum\" is pulped, boiled, strained, and thickened with barley flour to make a sweet liquid seasoning agent called \"tangxi\". At times, people in China have relied on \"P. megaphyllum\" as a famine food.\n\nThe shoots of some \"Polygonatum\" can be boiled and used like asparagus. \"P. cirrifolium\" and \"P. verticillatum\" are used as leafy vegetables in India. The American species \"P. biflorum\" has a starchy root that was eaten like the potato and used as flour for bread.\n\n\"P. sibirica\" is used for a tea called \"dungulle\" in Korea.\n\nThe traditional use of \"Polygonatum\" in the treatment of diabetes was first observed in 1930 by Hedwig Langecker. After experiments, she concluded that it was effective in fighting nutritional hyperglycemia, though not that caused by adrenaline release, probably due to its glucokinin content.\n\n\"P. verticillatum\" is used in Ayurveda as an aphrodisiac. It is also used to treat pain, fever, inflammation, allergy, and weakness.\n\nAn herbal remedy called \"rhizoma polygonati\" is a mix of \"Polygonatum\" species used in traditional Chinese medicine. It is supposed to strengthen various organs and enhance the \"qi\". Polygonatum is believed to be restorative to mental vitality, especially when the mind has been overworked, overstressed, or is in a state of exhaustion.\n"}
{"id": "18199358", "url": "https://en.wikipedia.org/wiki?curid=18199358", "title": "Prostitution in Malta", "text": "Prostitution in Malta\n\nProstitution in Malta is itself legal, but certain activities connected with it, such as running a brothel and loitering, are not. Certain offences are punishable by sentences of up to two years in prison. In March 2008, police and the Malta Ministry for Social Policy signed a memorandum of understanding to formalize a screening process for all arrested persons engaged in prostitution to determine whether they were victims of trafficking or other abuses. The law provides punishments of up to 6 years for involving minors in prostitution.\n\nPrime Minister Joseph Muscat promised to discuss legalising prostitution in the build up to the 2017 general election. Valletta’s Strait Street, known locally as the 'Gut', was the centre of prostitution from the 1830s to the 1970s. The Mello area of Gżira is known as a red-light district.\n\nProstitution has occurred in Malta for centuries. When the Knights Hospitaller came to the country in 1530, the port of Vittoriosa contained many brothels. As well as Maltese prostitutes, there were also some from Greece, Italy, Spain and North Africa. The French king’s geographer, Nicholas de Nicolai, was impressed by the number of prostitutes in the streets when he visited Vittoriosa in 1551, Prior to the Great Siege of Malta in 1565, arrangements were made to evacuate the country's prostitutes to Sicily.\n\nWhen the Knights moved from Vittoriosa to the new capital Valletta, the prostitutes followed. As the Knights took vows of chastity, the prostitutes with them was seen as a scandal. Foreign prostitutes were expelled and the Maltese prostitutes confined to one area of the city. At the time prostitutes wore a white shirt tied under their bust and a white cape.\n\nIn 1608, inquisitor Leonetto della Cordoba was charged with seeking out prostitutes and dismissed as an inquisitor. Prostitution was also common on Gozo.\n\nTowards the 17th century, there was harsh prejudice and laws towards those who were found guilty or speak openly of being involved in same-sex activity. English voyager and author William Lithgow, writing in March 1616, says a Spanish soldier and a Maltese teenage boy were publicly burnt to ashes for confessing to have practiced sodomy together. As a consequence, and fear to similar faith, about a hundred males involved in same-sex prostitution sailed to Sicily the following day.\n\nUnder a code introduced by Grand Master António Manoel de Vilhena in 1724, married men of means were fined if found guilty of use of the service of a prostitute, and expelled from the country on the third conviction. Lower class men were whipped and sentenced to hard labour on the third offence. The 1784 code of Emmanuel de Rohan-Polduc barred foreign prostitutes entering the country and placed restrictions on Maltese prostitutes. They were not allow to open their doors between sunrise and sunset and were not allowed to enter pubs or taverns. Compulsory medical examinations were introduced.\n\nFollowing the French occupation of Malta, prostitution rose. Compulsory medical examinations continued and the authorities opened hospitals in the monastery of Saint Scholastica and in Auberge de Bavière to treat soldiers with STIs.\n\nAfter the country come under control of the British, prostitution increased again due to the number of sailors and soldiers stationed there. Many married women became prostitutes with their husbands’ knowledge due to economic hardship.\n\nCompulsory medical examinations continued until 1859 when it was realised that previous Grand Master codes were not legally enforceable. The prostitutes therefore refused to undergo the examinations. As a result, the authorities, under the guidance of Governor John Le Marchant, decreed under Ordinance IV of 1861, that all prostitutes should be examined by a police doctor three times a month in an attempt to control the spread of STDs. If an infection was discovered, the prostitute was taken to hospital and kept there until cured. This regulation in Malta was a great influence on Britain introducing the first of the Contagious Diseases Acts in 1864 and its subsequent extension.. The frequency of examinations was increased to 4 times a month in 1920.\n\nAlthough there were regulations to control STIs, there were no prostitution laws until 1898. A new law was introduced prohibiting brothels, and not more than one prostitute could live in the same house unless they registered with the police. The law also forbade prostitutes to live on the ground floor, within 50 yards of a place of worship or adjacent to licensed premises. In 1904 there were 152 registered prostitutes, although many more were unregistered.\n\nMalta was known by British sailors as the 'place with the three Ps: pubs, priests and prostitutes'.\n\nMalta is a source and destination country for women and children subjected to sex trafficking. Women and children from Malta have also been subjected to sex trafficking within the country. Women from Southeast Asia working as domestic workers, Chinese nationals working in massage parlors, and women from Central and Eastern Europe, Russia, and Ukraine working in nightclubs represent populations vulnerable to exploitation.\n\nArticle 248A-G of the criminal code prohibits both sex and labour trafficking and prescribes penalties of four to 12 years imprisonment. The government has not obtained a conviction since early 2012. The government conducted three investigations and initiated prosecution of four defendants in one case, which remained pending at the close of 2016. These efforts were on par with 2015 when the government initiated investigation of two cases and prosecution of two defendants. Both the appeal of a 2012 conviction of a police officer for alleged collusion with a trafficker, and the prosecution of a 2004 case involving a police official, remained pending. There were no new investigations or prosecutions of government employees complicit in human trafficking offences.\n\nThe United States Department of State Office to Monitor and Combat Trafficking in Persons ranks Malta as a 'Tier 2' country.\n"}
{"id": "3598101", "url": "https://en.wikipedia.org/wiki?curid=3598101", "title": "Rubens Farias Jr.", "text": "Rubens Farias Jr.\n\nRubens was trained as an engineer. \n\nHe is not the first Brazilian to make the claim. He follows Zé Arigó, who died in a car crash in 1971, and a string of other claimants. Farias began claiming reincarnation as early as 1986. On a typical weekday, as many as 800 patients will line up outside the hall he uses (on weekends, it serves as a bar), waiting for treatment sessions which might be as short as 30 seconds. While in character as Dr. Fritz, he adopts a German accent and expressions such as \"Schnell!\" In some cases, patients get a homemade injection, reportedly a mixture of alcohol, iodine and turpentine. Medical hygiene is minimal.\n\nThe Regional Medical Council for the state of Rio de Janeiro labels Farias a \"charlatan\" taking advantage of the chaotic Brazilian public health system, and has sued to halt his activities.\n\n\n"}
{"id": "3791975", "url": "https://en.wikipedia.org/wiki?curid=3791975", "title": "Social role valorization", "text": "Social role valorization\n\nIn psychology, education and social work practice, social role valorization (SRV) is the name given to an analysis of human relationships and human services, formulated in 1983 by Wolf Wolfensberger, as the successor to his earlier formulation of the principle of normalization which is attributed to Nirje, Wolfensberger, and Bank-Mikkelsen worldwide (Lemay, 1995; Wolfensberger, 1972). The theory is based on the idea that society tends to identify groups of people as fundamentally 'different', and of less value than everyone else. It catalogs the methods of this 'devaluation' and analyzes its effects. It may be used by those seeking to counteract these methods and effects. A recent compilation of normalization and social role valorization was by Flynn and LeMay (1999); their work remains important today in Europe, New Zealand and Australia among other countries.\n\nAlthough normalization and the initial versions of SRV were described as an 'Ideology', the most recent formulation explicitly denies that SRV is about what \"should\" be done, and reinforces that SRV is intended to be a tool for analysis of the process and effects of Societal Devaluation. Wolfensberger's most recent (1999) definition of SRV is: \"the application of what science can tell us about the enablement, establishment, enhancement, maintenance, and/or defence of valued social roles for people\" (Susan Thomas and Wolf Wolfensberger in Flynn and Lemay 1999, p. 125). Susan Thomas, long time professional educator with Wolfensberger, continues to teach through the Institute at Syracuse University as of 2012. University students and training institute colleagues can be found worldwide with many internationally seeking collaborative projects with the Wolfensberger (e.g., now Rannveig Traustadottir, now Gender and Disability Chair at the University of Iceland).\n\nSocial role valorization (SRV) is a relationship theory of empirical knowledge for the design and rendering of formal and informal services and relationships to people with any need or condition, especially those who are devalued or are at risk. Social role valorization is intended to address the social and psychological wounds that are inflicted on vulnerable people because they are devalued, that so often come to define their lives and that in some instances wreak lifelong havoc on those who are close to them.\n\nSRV does not in itself propose a 'goal'. However a person who has a goal of improving the lives of devalued people may choose to use insights gained from SRV to cause change. They may do so by attempting to create or support socially valued roles for people in their society, because if a person holds valued social roles, a person is highly likely to receive from society those good things in life that are available or at least the opportunities for obtaining them. In other words, all sorts of good things that other people are able to convey are almost automatically apt to be accorded to a person who holds societally valued roles, at least within the resources and norms of his/her society.\n\nSocial role valorization identifies social devaluation as a critical human experience that has long-term effects on the individual. SRV is designed to raise consciousness about the fate of socially devalued persons. SRV holds that the human being is vulnerable to the regard of others for both the heights of edification and the depths of degradation.\n\nAn understanding of social role valorization can lead to ideas about how to improve the lives of people who are devalued by society. These can be seen to have two themes – firstly, removing devaluing features (for instance people being segregated from society in a building along with others perceived to belong to the same group), and secondly taking action that leads to people being valued. On one the approaches of SRV involves socially valued persons allying themselves with socially devalued persons. This alliance will unify people, broaden acceptance of differences, and encourage coexistence.\n\nSRV is a realistic if not pessimistic sense of human behaviour, holding that human beings are imperfect and capable of great evils even if they are occasionally saintly, heroic or kind.\n\nSocial role valorization is designed to address the social and psychological wounds that get inflicted on vulnerable people because they are devalued, that so often come to define their lives, and that in some instances wreak lifelong havoc on them and those who are close and committed to them.\n\nSRV is a description of how societally differentiated people are devalued, assigned low-value roles, and treated poorly, often to the extent of risk to their own lives. This poor treatment is given to members of any group that is given low value by powerful forces in society.\n\nSRV considers only those things that can be known from a scientific perspective. In itself it does not subscribe to a particular ideology – it does not say what should be done and it does not say what is morally correct.\n\nHowever, SRV does understand that human interaction is impossible without a moral code and so SRV can be used to suggest what is desirable given the spoken or unspoken moral code of a particular society or individual. Consequently, it is necessary to understand what sort of moral code and societal expectations might be around the implementation of any application of SRV. A consideration of the concepts of humanity and morality place SRV in an appropriate context.\n\nAny particular human society will have a set of written and unwritten rules about who is a member of that society and about how members of that society should act, and what treatment is due to non-members of that society. These rules are often set down in codes of law and in religious texts. Every society has such a moral code.\n\nSupport for SRV can be found throughout the human sciences. Biology, evolutionary biology, sociology, economics, psychology, and anthropology all lend strands to SRV. Even history and geography have ideas to contribute. Although SRV is not in itself a science, it is based on empirically produced disciplines.\n\nPsychology and philosophy tell us that there is considerable doubt about the common sense idea that we have total free will; what we do is often societally or physically caused by unconscious mechanisms.\n\nScience tells us that people do not often act as completely free-thinking individuals, but in fact occupy particular social strata and roles that organize and simplify their social communication. Particular people may be forced into a negative role which they do not desire.\n\nScience tells us that individuals and groups will place positive and negative values onto other individuals and groups. This assignation of value may lead to a process of devaluation.\n\nComplex societal forces mediate the exercise of power and social control in a society. These forces are often not well understood by individuals in that society.\n\nIndividuals in a society are very aware of similarities and differences between members of that society. This is societal differentiation.\n\nSuch difference groups may include people with the following differences from the valued norm:\n\nPsychology shows us that perception and interpretation are complex subjects, highly reliant on beliefs and prejudices. Human perception and interpretation is complicated and often not in accord with what 'common sense' tells us that it is.\n\nLearning and particularly imitation are the natural modes of behavior formation and are important in developing useful as well as damaging performances.\n\nImage and image transfer are important subjects when considering how people interpret each other and their own surroundings.\n\nPerformance, reputation and grouping determine how people are seen and interpreted.\n\nSo, we may summarise: people who differ in any way from societal expectations or desirability, where this difference is negatively valued, will be badly treated by that society.\n\nPowerful groups in society will:\n\n\nSRV suggests that role messages are largely conveyed by image, whether of the individual or of their surroundings (including accompanying people). A person's potential roles may be limited or assigned by the company they keep, the surroundings in which they live, or the activities they engage in.\n\nSRV suggests that Role Occupancy is dependent on apparent competency in that role. So the availability of roles may be limited or assigned by the person's ability (or, more importantly, the lack of ability) to perform the necessary role requirements for the effective performance of that role.\n\nPeople cast into such negative roles will be denied the good things in life:\n\nThe good things in life:\n\nFurther, such groups will be damaged in the following ways:\n\n'Wounds' or bad things which happen to devalued persons:\n\n\nAdditional mental and behavioral response patterns that are evidence of disturbed interactions with the world, and that are engendered by certain wounds and wound clusters, are:\n\n\nThe coping mechanism is to avoid negative roles and outcomes:\n\nIn order to ensure that positive roles are available to persons who have been devalued by society, it is necessary to consider actions at multiple levels:\n\n\nSRV suggests that by these means, people who have been devalued by society may be rescued (or may rescue themselves) from the effects of devaluation, and may manage to live their lives occupying Valued Roles and become seen as valued by society. Other theories regarding \"mentally handicapped\" individuals include consciousness raising and implications for normalization from the women's movement, related self-advocacy movements in special education and rehabilitation, and now the new movement to community inclusion as represented at the United Nation's Convention on the Rights of Persons with Disabilities (2006).\n\nThis criticism appears unjust in that Wolfensberger is an early proponent of the rights of people with mental retardation to marry, while other professionals placed the same individuals in institutional abuse and confinement. His doctoral students hold leadership positions in gender and disability, and he is associated with liberals in his own academic department who support actions in that context to address entrenched societal discrimination.\nIt can be suggested that all constructed attempts to re-valorize the roles and raise the social status of marginalised individuals and groups are hollow as they are artificial, but of course, government is responsible to provide minimum wage laws, to increase worker benefits, to maintain entitlements, to provide quality housing and beneficial and affordable health care. \nIn other words, the person providing the re-valorization efforts such as a social worker or supported employment worker is paid to do his or her job, and is not helping the marginalised person out of genuine interpersonal motivation such as friendship, attraction or emotional attachment, and people are well aware of this monetary role in professions in human services. Therefore, any re-valorized role is viewed by those outside the relationship as non-genuine, unstable, though new evidence and theory (e.g., theories of social acceptance, versus deviance) suggests that beneficence and social acceptance are active and result in positive life outcomes. Thus, paid roles (sometimes preferred in modern life) would tend to negate the security-giving benefits that valued, familial and friendship roles would normally provide.\n\nSome criticism of social role valorization is said by its advocates to be because of misconceptions about it. Such misconceptions include:\n\nThe theory of social role valorization is best understood as referring primarily to extreme devaluation (such that few people care much about what happens to an individual or group, or even actively look for their eradication) not more subtle (but still damaging) devaluation such as occurs between different social classes or between genders.\n\nSocial role valorization (SRV), similar to normalization, is a foundational theory with roots in intellectual and developmental disabilities, often termed learning disabilities in Europe. It is a revolutionary concept which took roots in the deinstitutionalization and community integration movements of the 1970s and 1980s which aligned themselves with its broad concepts and goals more so than with the specifics of the theory, goals and formulations itself. SRV and normalization adherents, in contrast, are committed first to the specific theories and have tended to be reluctant to engage in academic theoretical discussions with related theorists (e.g., independent and supportive living; support and empowerment paradigms; user-and-family directed services; self-determination and choice theories). In addition, other giants in community development such as Gunnar Dybwad, advisors to Presidents in the US, Brandeis University professor, friend of the Center on Human Policy, and former Arc-US director, often are missed in contrasting theory formulations.\n\nSRV is supportive of the development of community paradigms (e.g., Schwartz, McKnight, O'Brien, Taylor, Racino, Wehman, Roberts, Towell, Lakin, Bruininks, Braddock, Hemp, Rogan, Anthony, Carling, Seekins, Condeluci & Gretz-Lasky) which were necessary to replace the institutional paradigms of the pre-expose era, however, with community paradigms taking over 20 years to become the mainstream academic publications. Today, new goals of integration, a basic principle of normalization, involve the integration of family studies to include families with a disability family member, integration of financing (e.g., housing and homes), long-term services and supports development (e.g., personal assistance, support aides for homes and families), and modernization to areas such as green and sustainability.\n\n\n"}
{"id": "36160963", "url": "https://en.wikipedia.org/wiki?curid=36160963", "title": "Sofia's Last Ambulance", "text": "Sofia's Last Ambulance\n\nSofia's Last Ambulance (a co-production of Germany, Bulgaria, and Croatia) is a feature-length observational documentary film by Bulgarian director Ilian Metev. The film premiered at the 51st Semaine de la Critique (International Critics' Week) at the 2012 Cannes Film Festival, where it won the inaugural France 4 Visionary Award (France 4 Prix Revelation). It was the second documentary ever to compete in the section's 51-year history.\n\n\"Sofia's Last Ambulance\" opens on an ordinary working day of Krassi, Mila and Plamen, the paramedic crew on one of Sofia's dangerously dwindling fleet of emergency ambulances. The medical infra-structure is in ruins and the ambulance services is one of the hardest hit. Soon the daily pressure on the team is revealed in a sequence of absurdities. Unusual for a work about medical services, patients remained tactfully outside of the frame and sensationalism was rigorously avoided. Camera work focused closely on the faces of the ambulance crew to capture changes in their state of mind in their persistent efforts to work despite lack of means, exhaustion and ineffective bureaucracy.\n\nResearch for \"Sofia's Last Ambulance\" started in 2008. During the research period, Metev met Dr Yordanov, who has been working in the emergency services for 23 years, and was fascinated by his humbleness and industry. Dr Yordanov and his two teammates were responsible for the most critical cases in the capital. The observational documentary was then shot over the period of two years, with the shooting crew consisting of Metev and sound recordist Tom Kirk planted in the back of the ambulance, trying to be as discrete and invisible as possible.\nThe film was a co-produced in association with German television channel WDR, German/French channel Arte, American equity fund Impact Partners, Bulgarian National Film Center, the Croatian Audiovisual Centre and the German Film und Medienstiftung NRW. Sales agents are Berlin-based Films Boutique.\n\n\n\"Sofia's Last Ambulance\" premiered at the 51st International Critics' Week in Cannes. The AFP wrote that \"after the screening filmmakers and protagonists were in tears. Number of spectators also.\" Jay Weissberg of \"Variety\" described the film as \"rigidly constructed and deeply human\" and Julien Gester of \"Liberation\" called it a \"fine and strong investigation of a state of crisis.\"\n\nAt the premiere of the film in Sofia, the Bulgarian health minister Desislava Atanasova admitted that \"Sofia's Last Ambulance reflects the reality of things\" and pronounced that since the film, two new emergency response units have been opened up in the capital to speed up response times; ambulance crews' wages were to be increased by 18%. Protagonist and emergency doctor Krassimir Yordanov criticized that these reforms were insufficient to address the true cause of the problems: chronically low wages that makes medical professionals leave in droves. Despite 25-years experience in the job, his monthly pay is \"less than the weekly pay of any colleague in other European Union countries\".\n\n"}
{"id": "1957373", "url": "https://en.wikipedia.org/wiki?curid=1957373", "title": "Southern Regional Testing Agency", "text": "Southern Regional Testing Agency\n\nSouthern Regional Testing Agency (SRTA) is one of five examination agencies for dentistry in the United States. Some of the other examination agencies are, Western Regional Examining Board, Central Regional Dental Testing Service, Northeast Regional Board of Dental Examiners. These were organized to better standardize clinical exams for licensure.\n\nMember states that originally helped create the exam are: Arkansas, Kentucky, South Carolina, Tennessee, Virginia\n\nOther states that accept the exam for licensure: [[Alabama}}, [[Colorado]], [[Connecticut]], [[Ohio]], [[Illinois]], [[Kansas]], [[Nebraska]], [[Utah]], [[New Hampshire]], [[North Dakota]], [[Maine]], [[Wyoming]], [[Vermont]], [[West Virginia]], [[Missouri]], [[Massachusetts]].\n\n\n[[Category:Dental examinations]]\n[[Category:Standardized tests in the United States]]"}
{"id": "14176515", "url": "https://en.wikipedia.org/wiki?curid=14176515", "title": "Standard of living in China", "text": "Standard of living in China\n\nrising from around forty-four years in 1949 to sixty-eight years in 1985. In addition, the percentage of the Chinese population estimated to be living in absolute poverty fell from between 200-270 million in 1978 to 70 million in 2017.\n\nUntil the end of the 1970s, the fruits of economic growth were largely negated by population increases, which prevented significant advances in the per capita availability of food, clothing, and housing beyond levels achieved in the 1950s.\n\nIn 1978, the Communist Party of China, under the leadership of Deng Xiaoping, began to introduce market reforms, including decollectivizing agriculture, allowing foreign investment and individual entrepreneurship. After thirty years of austerity and marginal sufficiency, Chinese consumers suddenly were able to buy more than enough to eat from a growing variety of food items. Stylish clothing, modern furniture, and a wide array of electrical appliances also became part of the normal expectations of ordinary Chinese families.\n\nFollowing the economic reforms introduced by the government in the late 1970s, consumption and individual incomes rose significantly, with the real per capita consumption of peasants rising at an annual rate of 6.7% from 1975 to 1986, while for urbanites over the same period, the corresponding figure was 5.5%. The improvements in the standard of living were demonstrated by a boom in rural and urban housing, together with a considerable increase in the ownership of televisions and other appliances.\n\nWhile food production rose substantially after 1949, population increases were nearly as great until the 1980s. Production of grain, the source of about 75 percent of the calories in the Chinese diet, grew at an average rate of 2.7 percent a year between 1952 and 1979, while population growth averaged almost 2 percent a year. Total grain output per capita grew from 288 kilograms a year in 1952 to 319 kilograms in 1978, an increase of only 11 percent in 26 years. In 1984, however, a remarkably good harvest produced 396 kilograms of grain per capita, an increase of 24 percent in only 6 years. In 1985 grain output fell below the peak level of 1984, to 365 kilograms per person, and recovered only partially in 1986 to 369 kilograms per capita.\n\nIn the 1970s before the reform period, clothing purchases were restricted by rationing. Cotton cloth consumption was limited to between four and six meters a year per person. In the 1980s one of the most visible signs of the economic \"revolution\" was the appearance in Chinese cities of large quantities of relatively modern, varied, colorful clothes, a sharp contrast to the monotone image of blue and gray suits that typified Chinese dress in earlier years. Cloth consumption increased from eight meters per person in 1978 to almost twelve meters in 1985, and rationing was ended in the early 1980s. Production of synthetic fibers more than tripled during this period; in 1985 synthetics constituted 40 percent of the cloth purchased. Consumers also tripled their purchases of woolen fabrics in these years and bought growing numbers of garments made of silk, leather, or down. In 1987 Chinese department stores and street markets carried clothing in a large variety of styles, colors, quality, and prices. Many people displayed their new affluence with relatively expensive and stylish clothes, while those with more modest tastes or meager incomes still could adequately outfit themselves at very low cost.\n\nAs with food supplies and clothing, the availability of housewares went through several stages. Simple, inexpensive household items, like thermoses, cooking pans, and clocks were stocked in department stores and other retail outlets all over China from the 1950s on. Relatively expensive consumer durables became available more gradually. In the 1960s production and sales of bicycles, sewing machines, wristwatches, and transistor radios grew to the point that these items became common household possessions, followed in the late 1970s by television sets and cameras. In the 1980s supplies of furniture and electrical appliances increased along with family incomes. Household survey data indicated that by 1985 most urban families owned two bicycles, at least one sofa, a writing desk, a wardrobe, a sewing machine, an electric fan, a radio, and a television. Virtually all urban adults owned wristwatches, half of all families had washing machines, 10 percent had refrigerators, and over 18 percent owned color televisions. Rural households on average owned about half the number of consumer durables owned by urban dwellers. Most farm families had 1 bicycle, about half had a radio, 43 percent owned a sewing machine, 12 percent had a television set, and about half the rural adults owned wristwatches.\n\nHousing construction lagged behind urban population growth. A 1978 survey of housing conditions in 192 cities found that their combined population had increased by 83 percent between 1949 and 1978, but housing floor space had only grown by 46.7 percent. In 1978 there were only 3.6 square meters of living space per inhabitant in these cities, a reduction of 0.9 square meter since 1949. To remedy this problem, construction of modern urban housing became a top priority in the late 1970s, and by the mid-1980s new high-rise apartment blocks and the tall cranes used in their construction were ubiquitous features of large cities. Some apartments in the new buildings had their own lavatories, kitchens, and balconies, but others shared communal facilities. Nearly all were of much higher quality than older houses, many of which were built of mud bricks and lacked plumbing.\n\nBy 1981 living space in urban housing had increased to 5.3 square meters per person, and by 1985 the figure was 6.7 square meters. Despite this progress, scarcity of housing continued to be a major problem in the cities, and many young married couples had to live with parents or make do with a single room.\nHousing conditions in rural areas varied widely. During the 1960s and 1970s, thousands of production brigades built sturdy, sanitary houses and apartments and in many cases entire new villages. With the introduction of the responsibility system and the more than doubling of rural incomes in the early 1980s, another wave of housing construction took place as farm families moved quickly to invest in their major personal assets - their homes - which for the most part were privately owned. Many farm family houses lacked running water, but virtually all had electricity and were considerably more spacious than urban dwellings. In 1980 farm homes averaged 9.4 square meters of living space per person, and by 1985 the figure had risen to 14.7 square meters. Despite extensive construction of new housing, in poorer regions some farm families still lived in traditional dwellings, such as mud-brick and thatch houses or, in some regions, cave houses. Many of the nomadic herders in Inner Mongolia, Xinjiang, and Xizang (Tibet) autonomous regions still lived in tents or felt yurts. In the Yangtze River Valley and in south China, some fishing and boat transportation communities continued to live on their vessels.\n\nSince the 1990s there has been an increasing number of apartment built in China which remain empty. By 2010 approximately 65 million apartments, capable of housing some 250 million people, were unoccupied, due to there being too expensive for the majority of Chinese to purchase or rent. At the same time many millions of urban Chinese remained living in slums. But, as the urbanization rate in China remains high (approx. 20 million Chinese move from rural areas each year) this problem is not severe and many so-called \"ghost cities\" become inhabited. As for 2012, there is 35 sq.meters per person in average and construction rate exceeds 1.5 sq. meters per year which allows total living area to exceed 50 sq. meters per capital as soon as in the year 2020.\n\nIncome differences in China since the 1950s have been much smaller than in most other countries. There was never any attempt, however, at complete equalization, and a wide range of income levels remained. Income differences grew even wider in the 1980s as the economic reform policies opened up new income opportunities. More than two-thirds of all urban workers were employed in state-owned units, which used an eight-grade wage system. The pay for each grade differed from one industry to another, but generally workers in the most senior grades earned about three times as much as beginning workers, senior managers could earn half again as much as senior workers, and engineers could earn twice as much as senior workers. In 1985 the average annual income of people employed in state-owned units was ¥1,213. An important component of workers' pay was made up of bonuses and subsidies. In 1985 bonuses contributed 13 percent of the incomes of workers in state-owned units; subsidies for transportation, food, and clothing added another 15 percent. One of the most important subsidies - one that did not appear in the income figures - was for housing, nearly all of which was owned and allocated by the work unit and rented to unit members at prices well below real value. In 1985 urban consumers spent just over 1 percent of their incomes on housing.\n\nThe \"Chinese Customer Report 2010\" states three groups of spending tiers of income: big spenders (which spend 21% of the income), medium spenders (which spend 36% of the income) and small spenders (which spend 43% of the income).\n\nThe 27 percent of the urban labor force that was employed in collectively owned enterprises earned less on average than workers in state-owned units. The income of workers in collectively owned enterprises consisted of a share of the profit earned by the enterprise. Most such enterprises were small, had little capital, and did not earn large profits. Many were engaged in traditional services, handicrafts, or small-scale, part-time assembly work. In 1985 workers in urban collective units earned an average annual income of ¥968. In the more open commercial environment of the 1980s, a small but significant number of people earned incomes much larger than those in regular state-owned and collectively owned units. Employees of enterprises run by overseas Chinese, for instance, earned an average of ¥2,437 in 1985, over twice the average income of workers in state-owned units.\n\nThe small but dynamic domestic private sector also produced some lucrative opportunities. Private, part-time schools, which appeared in large numbers in the mid-1980s, offered moonlighting work to university professors, who could double or triple their modest incomes if they were from prestigious institutions and taught desirable subjects, such as English, Japanese, or electronics. Small-scale entrepreneurs could earn considerably more in the free markets than the average income. Business people who served as a liaison between foreign firms and the domestic economy could earn incomes many times higher than those of the best-paid employees of state-owned units. A handful of millionaire businessmen could be found in the biggest cities. These people had owned firms before 1949, cooperated with the government in the 1950s in return for stock in their firms, and then lost their incomes in the political turmoil of the Cultural Revolution. In the late 1970s and early 1980s, when these businessmen were politically rehabilitated, their incomes were returned with the accrued interest, and some suddenly found themselves quite wealthy. Although the number of people earning incomes far beyond the normal wage scale was tiny relative to the population, they were important symbols of the rewards of economic reform and received a great deal of media attention. In 1985 most of these people worked in enterprises classified as \"units of other ownership\" (private rather than state- or collectively owned enterprises). These enterprises employed only 440,000 people out of the total urban labor force of 128 million in 1985 and paid average annual salaries of ¥1,373, only slightly higher than the overall urban national average.\n\nIn China, as in other countries, an important determinant of the affluence of a household was the dependency ratio - the number of nonworkers supported by each worker. In 1985 the average cost of living for one person in urban areas was ¥732 a year, and the average state enterprise worker, even with food allowance and other benefits added to the basic wage, had difficulty supporting one other person. Two average wage earners, however, could easily support one dependent. Families with several workers and few or no dependents had substantial surplus earnings, which they saved or used to buy nonessential goods. An important positive influence on the per capita consumption levels of urban families was a decline in the number of dependents per urban worker, from 2.4 in 1964 to 0.7 in 1985. In farm families the dependency ratio fell from 1.5 in 1978 to 0.7 in 1985. Farm incomes rose rapidly in the 1980s under the stimulus of the responsibility system but on average remained considerably lower than urban incomes. Household surveys found that in 1985 average net per capita income for rural residents was ¥398, less than half the average per capita urban income, which was ¥821. The value of goods farmers produced and consumed themselves accounted for 31 percent of rural income in 1985. The largest component of income in kind was food, 58 percent of which was self-produced.\n\nFarm family members on average consumed much less of most major kinds of goods than urban residents. For instance, a household survey found in 1985 that the average urban dweller consumed 148 kilograms of vegetables, 20 kilograms of meat, 2.6 kilograms of sugar, and 8 kilograms of liquor. At the same time, a survey of rural households found that the average rural resident consumed 131 kilograms of vegetables, 11 kilograms of meat, 1.5 kilograms of sugar, and 4 kilograms of liquor. Differences of a similar nature existed for consumer durables.\n\nAnother indication of the gap between urban and rural income levels was the difference in personal savings accounts, which in 1985 averaged ¥277 per capita for urban residents but only ¥85 per capita for the rural population. There was great variation in rural income levels among different provincial-level units, counties, towns, villages, and individual families. While the average net per capita income for rural residents in 1985 was ¥398, provincial-level averages ranged from a high of ¥805 for farm families living in Shanghai to a low of ¥255 for the rural population of Gansu Province.\n\nThe fundamental influence on rural prosperity was geography. Soil type and quality, rainfall, temperature range, drainage, and availability of water determined the kinds and quantities of crops that could be grown. Equally important geographic factors were access to transportation routes and proximity to urban areas.\n\nThe highest agricultural incomes were earned by suburban units that were able to sell produce and sideline products in the nearby cities. Under the responsibility system, household incomes depended on the number of workers in each household and the household's success in holding down production costs and in supplying goods and services to local markets. Most of the rural families with the highest incomes - the \"10,000-yuan households\" - were \"specialized households\" that concentrated family efforts on supplying a particular service or good. Many of these families owned their own equipment, such as trucks or specialized buildings, and operated essentially as private concerns. An increasingly important influence on rural incomes in the mid-1980s was the expansion of nonagricultural rural enterprises, often referred to as \"township enterprises.\" These were factories, construction teams, and processing operations, most of which were owned by collectives, primarily villages, towns, and townships. Some were owned by voluntary groups of families. Township enterprises were considered by the government to be the main source of employment for rural workers who were leaving agriculture because of rising productivity under the responsibility system. By the end of 1986, township enterprises employed 21 percent of the rural labor force. The movement of rural labor into township enterprises helped to increase average rural incomes because of the higher productivity in nonagricultural jobs. In 1986 industrial workers in rural areas produced an average annual value of ¥4,300 per person, compared with about ¥1,000 per farmer in the same year.\n\nThe change in farm production from primarily collective to primarily household operations is reflected in household survey data on the sources of rural incomes. Before the 1980s farmers received income in the form of shares of the profits earned by their production teams plus supplementary income from household sideline activities. In 1978 two-thirds of the net income of farm families came from the collective, and only 27 percent was derived from household production. With the shift to the responsibility system these ratios were reversed. By 1982 the collective provided only 21 percent of farm income, while household production provided 69 percent. In 1985 the collective share of farm income had fallen to just over 8 percent, and the family production share had risen to 81 percent.\n\nPerhaps the most serious gaps in living standards between rural and urban areas were in education and health care. Primary schools existed in most rural localities, and 80 percent of the country's primary-school teachers worked in rural schools. Secondary schools were less widely distributed; only 57 percent of the total number of secondary-school teachers served in rural schools. Most rural schools were less well equipped, and their staffs less adequately trained than their urban counterparts. Health care had been greatly improved in rural areas in the 1960s and 1970s through sanitation campaigns and the introduction of large numbers of barefoot doctors, midwives, and health workers. Most modern hospitals, fully trained doctors, and modern medical equipment, however, were located in urban areas and were not easily accessible to rural families. In 1985 two-thirds of all hospital beds and medical staff personnel were located in urban hospitals. The economic reforms affected rural education and health care positively in places where farm communities used their higher incomes to improve schools and hospitals and negatively in localities where the reduced role of the collective resulted in deterioration of collective services.\n\n\n"}
{"id": "14682851", "url": "https://en.wikipedia.org/wiki?curid=14682851", "title": "Suruhanu", "text": "Suruhanu\n\nSuruhånu or Suruhåna are people who function as herbal healers in some Pacific Island cultures. Such people exist on the island of Guam and are a result of Pre-colonial times where people known as \"makahna\" were believed to mediate between the physical and spiritual worlds. It comes from the Spanish word \"cirujano\" or \"surgeon\", here taking the general meaning of healer.\n"}
{"id": "48120438", "url": "https://en.wikipedia.org/wiki?curid=48120438", "title": "University of Medicine, Taunggyi", "text": "University of Medicine, Taunggyi\n\nThe University of Medicine, Taunggyi (, ) located in Taunggyi, Shan State is one of universities of medicine in Myanmar. The university offers an M.B.,B.S. degree program. The university was established in 2015.\n\nThe university started its first enrollment in December 2015 and accepted 200 students from Shan State and Kayah State.\n\nAnd effective practical experiments are carried out in latter 4 subjects.\n\n\n"}
{"id": "11805693", "url": "https://en.wikipedia.org/wiki?curid=11805693", "title": "Vaginal delivery", "text": "Vaginal delivery\n\nA vaginal delivery is the birth of offspring (babies in humans) in mammals through the vagina. It is the natural method of birth for all mammals except monotremes, which lay eggs into the external environment. The average length of a hospital stay for a normal vaginal delivery is 36–48 hours or with an episiotomy (a surgical cut to widen the vaginal canal) 48–60 hours, whereas a C-section is 72–108 hours. Different types of vaginal deliveries have different terms:\n\n\nNote: Use of the term IVD for instrumental vaginal delivery is best avoided because of its duplicate meanings.\n\n"}
{"id": "50695592", "url": "https://en.wikipedia.org/wiki?curid=50695592", "title": "Victor Gomoiu", "text": "Victor Gomoiu\n\nVictor Gomoiu (April 18, 1882 – February 6, 1960) was a Romanian surgeon, anatomist, folklorist and medical historian, who served as Minister of Health and Social Protection in 1940. Noted before 1910 for his work in descriptive surgery and pathology, focusing on the treatment of tuberculosis, genital diseases and tumors, he soon became one of the main contributors to medical historiography and bibliography. He founded several hospitals and edited medical journals, setting up a collection of medical instruments which became the basis of a national museum in Craiova. He became a professor at the University of Bucharest, an expert for the League of Nations, and, after distinguished service in World War I, a recipient of the Legion of Honor; additionally, he served for 22 years as president of the International Society for the History of Medicine, of which his wife Viorica was also an active member.\n\nA protegé of Queen Helen and administrator of her Brâncovenesc Hospital, Gomoiu fell out with King Carol II, and was arrested in 1934 for protesting against his rule. He returned to serve in two consecutive far-right governments, but, during World War II, emerged as a protector of the Romanian Jews, denouncing the policy of deportations to Transnistria. Despite this stance and his international profile, Gomoiu was arrested by the postwar communist regime, and spent time in confinement at Sighet and Aiud. He had been posthumously rehabilitated by the 1980s, but his work was only fully recovered after the Romanian Revolution of 1989.\n\nBorn in Vânju Mare, Mehedinți County, he was the first child of Romanian Orthodox priest Gheorghe and his wife Ana. He attended primary school in his native village, followed by Traian High School in Turnu Severin from 1893 to 1900. Between 1900 and 1905, he studied at the medical faculty of the University of Bucharest. Meanwhile, he rose steadily through the hospital ranks, from extern at Colțea Hospital in 1903 to intern there in 1905 to apprentice doctor at Bucharest's central military hospital in 1910. Gomoiu was a disciple of anatomist Thoma Ionescu. Alongside Dimitrie Gerota, Ernest Juvara and Victor Papilian, he continued Ionescu's work in descriptive anatomy as well as, in some instances, physical anthropology.\n\nIn 1906, Gomoiu published in Bucharest the first volume of his \"Istoricul Societăței Studenților în Medicină\" (\"History of the Medical Students' Society\"), with a plate by Ary Murnu; also that year, his study on eye disease among the rural population saw print at Târgu Jiu. Affiliated with the left-wing agrarian current, or Poporanism, he established in that city the literary magazine \"Șezătoarea Satului\" (\"Village Sitting\"), joining an editorial office which also included George Coșbuc and G. Dumitrescu Bumbești-Jiu. He took his first trip outside the country in 1908, visiting states from Austria-Hungary to Great Britain.\n\nGomoiu published steadily, and also lectured at the Medical Students' Society and the Surgical Society. Topics included meningoencephalitis, cerebral atrophy, facial nerve paralysis, fibrous tissue neoplasm, lipoma, the anatomy of the endothelium, corneal transplantation, skin grafting, dental implants, hysterectomy, various types of cysts and \"rare tumors\", and talus bone expulsion. These works were taken up in Eraclie Sterian's magazine, \"Spitalul\", of which Gomoiu was co-editor, or published as brochures. His doctoral thesis, on facial anaplasia, was awarded a \"magna cum laude\" in 1909, and published the same year. It was followed in 1910 by Gomoiu's introduction to inguinal hernia surgery, his reviews of surgery as applied to genital tuberculosis, vaginal hydrocele, urethrocele, and varicocele, and a work on the physiological role of cholesterol. A winner of the Manoah Hillel scholarship, that year and the next also saw his first contributions as a medical bibliographer and librarian, with catalogues of entries for the Bucharest University graduation papers in medicine. For his service in the Romanian Army, Gomoiu was concentrated in Medgidia.\n\nGomoiu soon lost his father to pancreatic cancer and found it hard to provide for himself, accepting jobs for which he was overqualified. In March 1911, recommended by Francisc Rainer, he began working as a surgical docent and became director of the Techirghiol tuberculosis sanatorium. He modernized the institution, systematizing records, constructing a laboratory, planting a grove of cluster pines, and furnishing a small facility for the study of regional climatology and radioactivity. He also began experimenting with thalassotherapy, light therapy, and the use of medicinal clay. This inaugurated a ten-year practice at various hospitals, during which Gomoiu patented various new surgical techniques. In November, after a disagreement with medical inspector Gheorghe Proca, who suggested that the sanatorium was unhygienic, Gomoiu handed in his resignation.\n\nIn 1913, a second-class surgeon at Filantropia Hospital, Gomoiu published a piece on \"the radical treatment of vaginal hydrocele\" in the French journal \"Lyon Chirurgical\", and his opening lesson on \"small surgery\" (\"Mica chirurgie\"). That year, he also performed his military obligation by accompanying the ambulatory health service sent to the Ottoman Empire during the Second Balkan War and performing surgery within the unit. In parallel, he studied craniometry, publishing a study of 24 craniums in \"Revista Științelor Medicale\", then as a booklet, and following up in 1915 with \"Cercetări asupra perimetrului cranian\" (\"Researching the Cranial Perimeter\"). The same years saw his many conferences at the Surgical Society printed in several editions, alongside separate studies of skin cancer, the sympathetic nervous system in the abdomen, gas gangrene of the thorax, and gastrostomy techniques. In 1916, he and Ionescu together discovered the link between stellate ganglion removal and sympathectomy.\n\nFor his work as a military physician during the Romanian Campaign of World War I, Gomoiu was decorated with the Order of the Crown (1917), the Order of the Star of Romania (1918), and the Queen Marie Cross (1919). He subsequently served terms as head of the Union of Reserve Officers, and, in 1920–1921, was curator (or \"efor\") of Bucharest's civilian hospitals. The author of \"Hommage a la France et aux médecins français\" (\"A Homage to France and French Physicians\", 1918), Gomoiu was made a chevalier of the Legion of Honor in 1922. Between 1919 and 1942, he was a surgeon at the Oradea war hospital and at two hospitals in Bucharest, also working at Brâncovenesc Hospital. Meanwhile, he held various leadership roles in medical societies and administrative bodies, and, in 1921, became a professor at Bucharest University.\nHis work now included tracts in social medicine, the history of medicine and medical education. In 1923, he published the volume \"Din istoria medicinei și învățământului medical în România\" (\"Briefs on the History of Medicine and Medical History in Romania\"), followed in 1927 by \"Preoțimea în slujba operelor de ocrotire și medicină socială\" (\"Priesthood in Service of Medical Care and Social Medicine\"). The former essay, reissued in 1940 as \"Biserica și medicina\" (\"Church and Medical Science\"), showed Gomoiu as a deist, philosophically inspired by Isaac Newton and Giovanni Battista Morgagni. The work, which suggested that priests could work as \"doctors of the soul\", earned him a special prize from the Ministry of Health, led at the time by the priest Ioan Lupaș.\n\nGomoiu also issued \"Istoricul presei medicale din România\" (\"A History of Romania's Medical Press\", 1925), and the second volume of \"Istoricul Societăței Studenților\" (1926). His first contacts with the International Society for the History of Medicine (ISHM) came in 1927 and 1928, when he sent in presentations on the first physicians active in the Danubian Principalities and the roots of Romanian ethnomedicine. In late 1927, on a visit to northern Europe, Gomoiu was impressed by Danish education. His article covering Danish libraries, and in particular the one Nikolaj Tower, saw print in \"Cuvântul\" daily and was also taken up in \"Școala Noastră\".\n\nGomoiu also became a trusted supporter of King Ferdinand I, managing the charity set up by his daughter, Princess Ileana. He was one of the specialists who assisted Ferdinand during his losing battle with colorectal cancer. In 1927, under Ileana's patronage, he set up the Sfânta Elena Hospital, in the working-class suburb of Bariera Vergului, Bucharest. He personally oversaw the pledge drive, collecting private donations and public money from the National Bank, the Ministry of Health and Căile Ferate Române, offering free medical services to the donors. Gomoiu also designed much of the building, modifying sketches by the architect Gheorghe Șimotta. In the end, the hospital developed into a regional model, being cited as such in League of Nations reports.\n\nTogether with his friend Mihai Cănciulescu, Gomoiu edited \"Acta Medica Romana\" magazine from 1928 to 1948. There, the two led a sustained campaign for the establishment of a university at Craiova, and also contributed to the establishment of regional hospitals in Vânju Mare, Turnu Severin, and Mangalia. Considered a founder of medical history and museography in Romania, Gomoiu collected old publications, diplomas, decrees, instruments and medical or pharmaceutical apparatus. He founded the ISHN-affiliated Romanian Medical History Society, which held monthly meetings from 1929 to 1948 and was also placed under Princess Ileana's patronage. With his wife Viorica, herself a physician, Gomoiu organized and hosted the ISHM's September 1932 congress in Bucharest.\n\nFor a while in 1930, Gomoiu served as secretary general in the Ministry of Health. In this capacity, he attended a conference on social hygiene in the French industrial hub of Tergnier, meeting with the organizer, Raoul Dautry. He also represented Romania on the League of Nations committee for physical education, inspecting the military school at Joinville-le-Pont. After losing his government office, he returned to the ISHM and, in 1933, was elected its Vice President.\nGomoiu also served as private physician to Queen Helen, estranged wife of the new king, Carol II. Around 1933, she also appointed him to lead her charity, \"Așezămintele Brâncovenești\". During this perod of his wife, Gomoiu emerged as \"one of the best known critics of [Carol's] \"camarilla\"\". In March–April 1934, Gomoiu created a stir by publishing a manifesto against Carol and his circle of politicians. He was briefly arrested on charges of \"lèse-majesté\", alongside far-right politicians suspected of having conspired with the Iron Guard, which had just assassinated Prime Minister Ion G. Duca. \n\nGomoiu was also investigated for an alleged plot to assassinate Carol, but he rejected the charges, and insisted that he only wanted Queen Helen to be allowed back in the country. His account was backed by the Union of Reserve Officers, which staged a public protest; its influence, insiders speculated, explained by Gomoiu was treated leniently in court. In May 1936, Gomoiu was called upon by the Iron Guard to be a defense witness for Viorel Trifa, Alecu Cantacuzino, and other Guardista accused of conspiracy against the state.\n\nGomoiu was president of the ISHM from 1936 to 1940, having successfully defeated with Maxime Laignel Lavastine, who became his bitter adversary. He had by then established inside the international body a Cantacuzène Commission, named after (and presided upon by) Ion Cantacuzino. It tasked with researching and inventorying European medical folklore—although this subject was of marginal interest to Cantacuzino himself. Gomoiu also returned to his anatomical research, publishing in 1938 a definitive monograph of the connective tissue (\"Țesutul conjunctiv\"), co-authored by his student V. Plătăreanu. Also that year, the two also presented a report on \"the cross in Romanian medical folklore\" to the ISHM Congress in Zagreb; with Al. Raicovicianu, Gomoiu also published the bibliographic corpus \"Histoire du folklore médical en Roumanie\" (\"A History of Medical Folklore in Romania\").\n\nBy that moment in history, Carol had established his National Renaissance Front dictatorship, and, in 1940, appointed Ion Gigurtu to lead a government that included some Iron Guard members. Gomoiu also joined, serving as Gigurtu's Health Minister from July 4 to September 4. In this capacity, and also as a member of the Crown Council, he was marginally involved in the major international crisis which saw the cession of Romanian land to the Soviet Union and the Axis Powers. On the night of August 29–30, he was among a majority of ministers who voted to peacefully cede the regions of Northern Transylvania to Regency Hungary. Gomoiu kept his ministerial office during the first government of Ion Antonescu, from September 4 to 14, until the establishment of the National Legionary State and Carol's flight from the country. Reportedly, he resented Antonescu's alliance with the Iron Guard, and avoided politics altogether.\n\nIn October 1942, at the height of Antonescu's alliance with Nazi Germany, Gomoiu's friend Barbu Lăzăreanu was arrested with other Jews and scheduled to be deported to Transnistria Governorate, but was spared thanks to Gomoiu's appeal to Queen Helen, who intervened on Lăzăreanu's behalf. As a Swiss journalist reported at the time, Gomoiu, \"a man so nice that he could not imagine that the Jews are so persecuted\", personally visited the Jewish detainees and convinced himself of their mistreatment, before contacting the queen. The latter insisted that she would leave the country, and endanger Antonescu's legitimacy, if the deportations would continue.\n\nUpon the end of World War II and a 6-year hiatus, Gomoiu was finally replaced as head of the ISHM by Laignel Lavastine. Shortly after the establishment of a communist regime in December 1947, Gomoiu was removed from teaching. He was arrested, together with tens of others former dignitaries, on the night of May 5, 1950, and detained with them in the basement of the Ministry of the Interior, Palace Square. Incarcerated at Sighet prison from 1950 to 1953, where he was held in solitary confinement, he was transported to Bucharest in order to participate in a 1954 international congress on medical history. Released in 1954, he refused a position in the communized Health Ministry offered to him in 1956, viewing it is a form of collaborationism. Although some sources claim that he lived the rest of his days in Aiud prison, he is known to have died in Bucharest in 1960, \"almost forgotten by everyone.\" He was buried in Plot 33 of Bellu cemetery.\n\nIn 1963, his holdings and the minutes of his Medical History Society were donated to the University of Craiova by his widow Viorica, and form the basis for a museum of medical and pharmaceutical history. This was inaugurated within the medical faculty in 1974 and set up in its own building between 1979 and 1982. In recognition of Gomoiu's local contribution, an amphitheater was named after him. The Romanian Post also issued, in 1981, a series of stamps honoring the Medical History Society, with a postmark bearing Gomoiu's portrait. In 1990, following the Romanian Revolution, the institution in Bariera Vergului, now a children's hospital, was renamed in honor of its late founder. Two years later, the high school in Vânju Mare became \"Victor Gomoiu Theoretical High School\". His memoirs, recovered from the secret archives of the Securitate, were only published in 2006.\n\n"}
{"id": "5956526", "url": "https://en.wikipedia.org/wiki?curid=5956526", "title": "Water stagnation", "text": "Water stagnation\n\nWater stagnation occurs when water stops flowing. Stagnant water can be a major environmental hazard.\n\nMalaria and dengue are among the main dangers of stagnant water, which can become a breeding ground for the mosquitoes that transmit these diseases.\n\nStagnant water can be dangerous for drinking because it provides a better incubator than running water for many kinds of bacteria and parasites. Stagnant water is often contaminated with human and animal feces, particularly in deserts or other areas of low rain.\n\nStagnant water may be classified into the following basic, although overlapping, types:\n\n\nTo avoid ground and surface water stagnation, drainage of surface and subsoil is advised. Areas with a shallow water table are more susceptible to ground water stagnation due to the lower availability of natural soil drainage.\n\nSome plants prefer flowing water, while others, such as lotuses, prefer stagnant water.\n\nVarious anaerobic bacteria are commonly found in stagnant water . For this reason, pools of stagnant water have historically been used in processing hemp and some other fiber crops, as well as linden bark used for making bast shoes. Several weeks of soaking makes bast fibers easily separable due to bacterial and fermentative processes known as retting.\n\n\nStagnant water is the favorite breeding ground for a number of insects.\n\n\n"}
{"id": "51477426", "url": "https://en.wikipedia.org/wiki?curid=51477426", "title": "Winifred Heston", "text": "Winifred Heston\n\nWinifred Heston, M.D., (27 April 1872 – 1 June 1922) was a Presbyterian medical missionary who worked in India with the Foreign Missionary Society of the Presbyterian Church in the U.S.A. Heston attended medical school at Laura Memorial Women’s Medical College of Cincinnati and was an associate physician at the General Hospital in Miraj, India, from 1903 to 1907. She performed over five hundred surgical operations during her service in Miraj.\n\nHeston was born in Ionia, Michigan on April 27, 1872, to Alonzo Heston and Mary Elizabeth Heston (née Brown). Heston had one half-sister, Jessie B. Coulter (née Clark), a daughter of her mother’s from a previous marriage to Henry N. Clark. Heston spent her early life in Charlotte, Michigan, with her mother and half-sister.\n\nHeston served as an associate physician at the General Hospital in Miraj, India, from 1903 to 1907. During Heston's first period of missionary work in India, her sister, Jessie B. Coulter (née Clark), died following a long illness. This was very difficult for Heston, since she was so far away from her sister, who was still living in Michigan, when it happened. The loss made Heston reluctant to return to the United States, since she knew her sister would no longer be there when she arrived in Michigan.\n\nHeston returned to the United States in 1908. She sailed from India on March 15, 1908 and arrived in New York on May 22, 1908. During her voyage home from India, Heston became romantically involved with a British officer who had also been working in the Maharashtra State in India during the time Heston was there. He was aboard the same ship Heston took when she left India in 1908, both of them traveling through Italy on their trip back to their respective home countries.\n\nHeston and other passengers on the ship, including other missionaries and Italian military officers, visited Naples, Italy, after their ship arrived in Europe. During this time, Heston wrote in letters to friends at home that she had become close to the officer, who was a major in the British army. Heston had encountered the officer before, during her time in India, when he brought her back to the Presbyterian mission after she had fallen off her horse.\n\nAfter they parted ways in Italy, Heston received a letter from the officer, claiming that he would come to visit her if she gave him any encouragement. Heston indicated in a letter that she planned to invite him to visit her in the United States.\n\nIn a letter to her friend in 1908, Heston suggested that she planned to marry the officer. She feared that this would prevent her from returning to India to do missionary work. Ultimately, Heston never married, and returned to India for a second mission in 1910.\n\nAfter returning home, Heston compiled a collection of her personal letters into the novel \"A Bluestocking in India: Her Medical Wards and Messages Home,\" which was published by the Fleming H. Revell Company in 1910.\n\nIn 1909, Heston took a government position as an eye doctor, serving the Native American population in Arizona. Suffering from poor health after her time in India, she only spent one year working there. After leaving Arizona, she spent a brief period of time living in California, but had to return home due to her illness.\n\nShe returned home to Michigan for a short time, then sailed to Bombay again on December 17, 1910. From 1910 to 1915, Heston worked at a hospital for women and children in Jhelum, India under the United Presbyterian Board. In 1915, Heston sailed back to the United States via China and Japan.\n\nHeston died on June 1, 1922, in East Jordan, Michigan, of an accidental morphine overdose. She was 50 years old.\n\nHeston graduated from Alma College, a Presbyterian university in Michigan, in 1896, and from the Laura Memorial Woman's Medical College of Cincinnati, in 1901, with the degrees of M.D. and M.A. She worked for one year as an intern at the Presbyterian Hospital in Cincinnati before accepting service with the Foreign Mission Society of the Presbyterian Church.\n\nHeston sailed to Bombay, India, from New York, New York, leaving the United States on October 14, 1902. She was accompanied on her voyage by two other Christian missionaries, who left their ten-year-old daughter behind in America when they left for India. Heston described their parting as tearful, and was very sad to leave New York herself. She arrived in Bombay on November 20, 1902, and began preparing for missionary work.\n\nHeston went on her first medical mission to India in 1902, and remained in India until she returned to the United States in 1908. After a period of time working in the United States, she went back to India for another mission in 1910, and remained for five years before returning to the United States in 1915.\n\nAfter arriving in Bombay, Heston began to learn the local Marathi language, which the Presbyterian board required missionaries in Western India to study during the first year of their service in India. Heston, however, took the Marathi proficiency exam after only six months of study and began working actively in the community before the end of her first year in India.\n\nAfter finishing her studies, Heston became an associate physician at the General Hospital in Miraj, India, in the Maharashtra State, which is known today as the Mary Wanless Hospital/Miraj Medical Center. In 1903, the hospital was under the direction of William J. Wanless, M.D., a missionary who, like Heston, had traveled to India with the Presbyterian board.\n\nHeston served as an associate physician in Miraj from the beginning of her missionary work in 1903 until she returned to the United States in 1908. During her time in Miraj, Heston performed over five hundred surgical operations.\n\nHeston returned to the United States for two years between her periods of missionary service. She sailed from Bombay on March 15, 1908, and arrived in New York on May 22, 1908. She sailed to New York via Italy, stopping to visit Venice and Naples with other missionaries and military officers aboard her ship.\n\nHeston had felt ill and tired throughout much of her later years in India, which she felt may have been linked to her grief after the death of her half-sister in 1904 and the loss of another missionary working at the General Hospital in Miraj. Upon her return to New York, she was advised by a nerve specialist to take a \"rest cure\" and remain on bed rest for at least four weeks.\n\nIn 1908 and 1909, Heston lived with her mother in Michigan and compiled letters she had sent while abroad to create her novel \"A Bluestocking in India: Her Medical Wards and Messages Home,\" which was published by the Fleming H. Revell Company in 1910.\n\nIn October 1909, Heston took a government position in Arizona as an eye specialist. She served the Native American community there until leaving for California in 1910. Due to her poor health, Heston only spent a brief period in California before returning home to Michigan.\n\nIn 1910, Heston returned to India to continue her missionary work. Before leaving India after her first period of missionary work in 1908, she had been informed that the Presbyterian board planned to open a hospital for women and children in Jhelum, India, which should be ready for work in less than two years.\n\nIn 1910, Heston took charge of that hospital and worked there until 1915, completing more surgical operations than she had during her previous service.\n\nDr. Heston is known for her significant surgical service as a female surgeon in India, her leadership as founding director of the mission hospital in Jhelum Cantonment, and her book \"A Bluestocking in India: Her Medical Wards and Messages Home,\".\n\nIn 1915, Heston returned to Michigan, sailing from India via Japan and California. She lived in East Jordan, Charlevoix, Michigan, until her death in 1922.\n\nHeston died on June 1, 1922, in East Jordan, Michigan, of an accidental morphine overdose. The overdose may have been connected to Heston's long illness. She was advised to take a \"rest cure\" after returning from her first mission to India in 1908, due to poor health during her time abroad, and was troubled by her illness during her time in United States, when she was unable to remain in Arizona or California for long periods of time due to her health issues. She was 50 years old at the time of her death.\n\n"}
{"id": "49462871", "url": "https://en.wikipedia.org/wiki?curid=49462871", "title": "Wolfgang J. Lutz", "text": "Wolfgang J. Lutz\n\nWolfgang J. Lutz (May 27, 1913 – 19 September 2010) was an Austrian inventor, physician and author of Leben ohne Brot. He showed how, with little recourse to surgery or drugs, fundamental improvement could be made to health through low carbohydrate nutrition; Lutz demonstrated, inter alia, a probable way of preventing the huge and mounting toll exacted by obesity and diabetes. To honour this contribution, Lutz was made a Freeman of the City of London in 2007. His book with Christian Allan: Life without Bread: How a low-carbohydrate diet can save your life is still in print after 16 years. Recently a biography has been published: My Life without Bread: Dr Lutz at 90, which includes a complete list of his publications, also: Uncle Wolfi's Secret, which explores the work of Dr Lutz in everyday language.\n\nBorn in 1913 in Upper Austria, Dr Lutz read medicine at Innsbruck and Vienna. His notable career in scientific research included inventing a prototype spacesuit and developing resuscitation techniques to prevent death from freezing, which brought Lutz the award of Habilitation, a great distinction in the scientific world, together with a post doctoral degree in internal and aviation medicine from the University of Vienna, After World War II, Wolfgang Lutz became a practicing physician. As a consultant in internal medicine, Wolfgang Lutz turned his attention to the dramatic escalation of degenerative disease. His wide-ranging and penetrating gaze swept from our Ice-Age origins to the modern world and his approach to medicine changed.\n\nTaking as his basic thesis that the pattern of our hormonal secretion is still tuned to the largely animal food diet of that distant epoch, Lutz surmised that too large an intake of carbohydrate might disturb the intrinsic harmony of the endocrine system and hence our health, ultimately leading to disease. This caused him, as early as the 1950s, to instigate a diet for long-term use that he felt to be low enough in carbohydrate to be compatible with our genetic inheritance and so restore the missing harmony.\n\nThe body’s primary response to an increase in dietary carbohydrate is to increase insulin production. Wolfgang Lutz demonstrated that his obese patients often suffered from an overproduction of insulin and identified a see-sawing of compensatory hormonal measures: typically, an increase in insulin, thyroid and adrenal hormones, and a decrease in the growth hormone. Sex hormones were also affected. Lutz was the first to describe how these disturbances in hormonal regulation and their very varied repercussions underlay many of the diseases of civilisation.\n\nIn the early 1960s, Wolfgang Lutz conducted ground-breaking hen-feeding trials which showed that, in hens, a reduction in carbohydrate - not of fat - reduced the incidence of arteriosclerosis. (Hens like humans had moved from a largely animal to a largely carbohydrate diet and suffered similar changes in their arterial walls in old age.) Reassured by this, together with the relief from pain and inflammation he experienced with his own osteoarthritic hips and the positive results from his growing clinical experience, Lutz was to spend the next forty or so years observing on a wide range of ailments both the immediate results and, when possible, the effect of following his diet for many years. As it went to the very root of the problem, the simple expedient of sufficient carbohydrate restriction (with no limitation put on protein or fat intake, nor on calories except as a short-term measure for extreme obesity) proved a remarkable therapeutic tool.\n\nDr Lutz was to find that his low carbohydrate diet was effective with both childhood obesity and with hyperinsulinism - a hormonal pathway to both common obesity and, through exhaustion of supply, to Type II diabetes: he found that sufficient carbohydrate restriction could prevent the vascular complications of adult onset diabetes. Carefully implemented and occasionally with temporary support from drugs, Lutz further demonstrated the benefit of his diet to a wide range of medical conditions from early multiple sclerosis to heart failure, from morbus Crohn and ulcerative colitis to osteoarthritis; he showed low carbohydrate nutrition could lower cholesterol levels, normalise high and low levels of blood iron and calcium and ease many problems of reproduction. Wolfgang Lutz also found that his low carbohydrate diet brought patients many general improvements amongst which were improved immune function, a calmer nervous system, better digestion, enhanced skin and tissue quality, and a positive effect on overall health. His main book Leben ohne Brot reached its 16th edition in 2007 after being in continuous print for forty years.\n\nDr Lutz died in Austria in 2010, at 97 years of age.\n\nDr Wolfgang Lutz had five children. In 1997 Dr Lutz registered with the B M A in order to be able to work in the U K. He and his 3rd wife Helen Paula lived for 6 months a year in London and spent the other six in Graz, Austria. Wolfgang Lutz was a member of the Athenaeum Club.\n\n"}
