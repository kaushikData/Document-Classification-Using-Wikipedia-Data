{"id": "5367777", "url": "https://en.wikipedia.org/wiki?curid=5367777", "title": "Abu Sa'id al-Afif", "text": "Abu Sa'id al-Afif\n\nAbu Sa'id al-Afif was a Samaritan physician in fifteenth century Cairo.\n"}
{"id": "13441945", "url": "https://en.wikipedia.org/wiki?curid=13441945", "title": "Bend Over Boyfriend", "text": "Bend Over Boyfriend\n\nBend Over Boyfriend (BOB) is a series of sex education videos covering the practice of a woman penetrating a man's anus with a strap-on dildo (known as pegging). The first of the two videos, which was released in 1998, became the best-selling video to date for Good Vibrations, a sex-toy business. The video was also featured on \"The Daily Show\". The videos promote the idea, as \"Eye Weekly\" puts it, that \"fucking your boyfriend in the ass is fun\".\n\nThe videos star sexologist Carol Queen, who discusses pegging and also demonstrates the practice with her lover. The videos also contain footage of other couples engaging in the practice. The porn star Chloe appears in the second video; as she is best known as an anal queen, her use of a strap-on dildo is a \"role reversal\".\n\n\"Bend Over Boyfriend\" (1998) and \"Bend Over Boyfriend 2\" (1999) were created, produced, and directed by lesbian couple Shar Rednour and Jackie Strano, owners and founders of SIR Video Productions. The movies feature real life couples. BOB was co-produced with Nan Kinney of Fatale Media and was nominated for Best Specialty Release at the 1999 AVN Awards.\n\nDan Savage, who popularized the term pegging, originally offered \"bob\" (short for \"Bend over Boyfriend\") as one of two alternatives for the term. Dan Savage was the guest on \"The Colbert Report\" on November 29, 2010. During the interview, Savage educates Colbert on the practice of pegging.\n\nSome reviewers, such as \"Eye Weekly\", said the tapes are instructional to a fault, saying the presentation \"made anal sex seem more distasteful rather than more attractive\". Queen herself said she'd been told the first video was \"like watching a driving-instruction video\" and the subtitle of \"Bend Over Boyfriend 2: Less Talkin', More Rockin\"' attempts to address this concern.\n\nTristan Taormino, writing for the \"Village Voice\", credits the video as an archetype for a substantial cultural shift: \"The roles of active initiator and penetrator are no longer solely the domain of men, nor are the qualities of receptivity and passivity for girls only. Nowhere is this more apparent than in what I identify as the Bend Over Boyfriend Archetype.\" Taormino also went on to add that the video makers were resistant to visualizing or showing close-ups of the male buttocks in this video.\n\n\n \n"}
{"id": "58093928", "url": "https://en.wikipedia.org/wiki?curid=58093928", "title": "Bicyclic phosphate", "text": "Bicyclic phosphate\n\nBicyclic phosphate is a class of bicyclic organophosphate compound that are used as flame retardants, stabilizers and antioxidants. They are also used in spectroscopic studies.\n\nSome bicyclic phosphates, such as TBPS, TBPO and IPTBO, are highly toxic. They have toxicity comparable to nerve agents. However, they are not acetylcholinesterase inhibitors. They act as GABA receptor antagonists and have potent convulsant effects.\n\n"}
{"id": "58293866", "url": "https://en.wikipedia.org/wiki?curid=58293866", "title": "Bon Secours Health System (USA)", "text": "Bon Secours Health System (USA)\n\nBon Secours Health System (USA) is a $3.8 billion not-for-profit Marriottsville, Maryland-based Catholic health system that owns, manages, or joint ventures 19 acute care hospitals, one psychiatric hospital, five nursing care facilities, four assisted living facilities and 14 home care and hospice programs in seven US states.\n\n\n\n\n\n\n"}
{"id": "17408506", "url": "https://en.wikipedia.org/wiki?curid=17408506", "title": "Carole Caplin", "text": "Carole Caplin\n\nCarole Caplin (born 8 January 1962) was the style adviser to Cherie Blair and a fitness adviser to Tony Blair, when he was the British prime minister. She was controversial because of her relationship with the convicted conman Peter Foster.\n\nCaplin and her elder sister were brought up by her mother, Sylvia, of Jewish descent, who was a ballet dancer with the Festival Ballet until a car crash ended her dancing career. Her mother divorced her father, a furrier, when Carole was a toddler. Caplin was educated at Glendower, a private school in South Kensington, Lillsden School for Girls, a boarding school in Kent, and Hurlingham and Chelsea Secondary School.\n\nShe appeared as a child actor in the film \"Accident\" (1967), and in television advertisements. In 1980 she became a member of the burlesque pop band Shock.\n\nAccording to \"The Observer\", during the 1980s Caplin worked for the telemarketing company Programmes Ltd, and became involved in the related Exegesis alternative therapy programme. Later Caplin set up a series of health and well-being companies.\n\nCaplin has written a number of health and well-being books, and appeared in several television programmes, including presenting her own Channel 4 programme \"The Carole Caplin Treatment\".\n\nIn 2002, Caplin hit the newspaper headlines in the scandal referred to as \"Cheriegate\" because of her involvement with Peter Foster, an Australian with criminal convictions, who assisted the Prime Minister's wife, Cherie Blair, in the purchase of two flats in Bristol. Cherie Blair tried to distance herself from Foster and briefed the press office at 10 Downing Street to make a public statement claiming that Foster was not involved with the deal. She was caught out when Foster provided evidence that she had lied. She then made a public apology, tearfully reading a prepared statement blaming her \"misfortune\" on the pressures of running a family and being a mother. She again tried to distance herself from Foster, but it was later revealed that she and Tony Blair had agreed to be godparents to the yet-to-be born child of Carole Caplin (Caplin later miscarried).\n\nIn 2010 Caplin started libel proceedings against the \"Daily Mail\" for a newspaper article that suggested that Caplin might have been considering selling the story of her time with the Blairs and to \"blow the lid on Tony and Cherie Blair’s sex secrets\". It was announced on 1 November 2011 that Caplin has accepted \"substantial\" damages from the newspaper for the false claims the \"Mail\" had made.\n\nOn 1 November 2011 Caplin announced that the Metropolitan Police had told her that her mobile phone was probably hacked on the instructions of the \"News of the World\". Caplin's spokesman stated \"Dating from 2002, Ms Caplin's is one of the earliest cases so far discovered and the police investigation has yet to uncover all the available evidence. Once she is able to establish the extent of this invasion of her privacy, Ms Caplin will decide what further action to take.\"\n\nAlastair Campbell, Tony Blair's former communications director, told the Leveson inquiry that it was \"at least possible\" that press stories about Cherie Blair had been obtained by hacking Caplin's phone, and he had apologised to Caplin that he had earlier accused her of tipping off newspapers.\n"}
{"id": "3913137", "url": "https://en.wikipedia.org/wiki?curid=3913137", "title": "Churchill Livingstone", "text": "Churchill Livingstone\n\nChurchill Livingstone is an academic publisher. It is an imprint of Elsevier, but used to be owned by Harcourt and Pearson being an imprint of Longman.\n\nIt was formed in 1971 from the merger of E & S Livingstone (Edinburgh, Scotland) and J & A Churchill (London, England). It is now integrated as an imprint in Elsevier's health science division.\n\nIn the past it published a number of classic medical texts, including Sir William Osler's textbook \"The Principles and Practice of Medicine' Gray's Anatomy, and Myles' Textbook for Midwives. In the 1980s in addition to new texts in all areas of clinical medicine it published an extensive list of medical and nursing textbooks in low-cost editions for low-income countries supported by the UK-funded Educational Low Priced Book Scheme (ELBS)\n"}
{"id": "32027375", "url": "https://en.wikipedia.org/wiki?curid=32027375", "title": "Coding (therapy)", "text": "Coding (therapy)\n\nCoding is a catch-all term for various Russian alternative therapeutic methods used to treat addictions, in which the therapist attempts to scare patients into abstinence from a substance they are addicted to by convincing them that they will be harmed or killed if they use it again. Each method involves the therapist pretending to insert a \"code\" into patients' brains that will ostensibly provoke a strong adverse reaction should it come into contact with the addictive substance. The methods use a combination of theatrics, hypnosis, placebos, and drugs with temporary adverse effects to instill the erroneous beliefs. Therapists may pretend to \"code\" patients for a fixed length of time, such as five years.\n\nIn the case of alcohol addiction, the procedure may be carried out with a drug that temporarily affects the respiratory system when mixed with alcohol, administered under hypnosis. The therapist gives patients the drug, then allows them a small amount of alcohol, which triggers an adverse reaction and makes them erroneously believe that the therapy has had a long-term effect. Another method involves the therapist giving patients hypnotic suggestions during a head massage, with the message that alcohol will cause blindness or paralysis.\n\nIn one method, the therapist numbs patients' mouths with local anaesthetic, then places electrodes with a very weak current into their mouths. This is to make patients believe that the \"nerve points\" in their mouth are being \"manipulated\" and that it is no longer safe for them to drink alcohol. A further method involves the therapist using a special helmet to persuade patients that the therapist's suggestions are controlling their minds. Typically, therapists will also make patients sign a disclaimer, supposedly absolving the therapist of any responsibility should the patient use the addictive substance and suffer ill effects or die.\n\n"}
{"id": "13019166", "url": "https://en.wikipedia.org/wiki?curid=13019166", "title": "Commission Internationale Permanente pour l'Epreuve des Armes à Feu Portatives", "text": "Commission Internationale Permanente pour l'Epreuve des Armes à Feu Portatives\n\nThe Commission internationale permanente pour l'épreuve des armes à feu portatives (\"Permanent International Commission for the Proof of Small Arms\" – commonly abbreviated as C.I.P.) is an international organisation which sets standards for safety testing of firearms. (The word \"portatives\" (\"portable\") in the name refers to the fact the C.I.P. tests small arms almost exclusively; it is ordinarily omitted from the English translation of the name.) As of 2015, its members are the national governments of 14 countries, of which 11 are European Union member states. The C.I.P. safeguards that all firearms and ammunition sold to civilian purchasers in member states are safe for the users.\n\nTo achieve this, all such firearms are first proof tested at C.I.P. accredited Proof Houses. The same applies for cartridges; at regular intervals, cartridges are tested against the C.I.P. pressure specifications at the ammunition manufacturing plants and at C.I.P. accredited Proof Houses.\n\nPrior to firing cartridges in the firearm to be proofed, it is checked for its essential mechanical dimensions such all measures and tolerances in the chamber are verified. A visual inspection of the barrel is also performed.\nIf the firearm passes these first steps, the standard proof takes place. The proof consist of firing two overloaded cartridges producing 25% more chamber pressure than the C.I.P maximum pressure limit for the same cartridge in its commercial version. For pistol, revolver and rimfire cartridges the standard proof is performed with overloaded cartridges that produce 30% more chamber pressure than the C.I.P maximum pressure limit for the same cartridge in its commercial version. Voluntarily testing beyond the C.I.P. maximum pressure limit is also possible for consumers who intend to use their firearms under extreme conditions (hot climates, long series of shots, etc.). A proof mark is stamped in every successfully tested firearm. The C.I.P. does not test any further aspects regarding the correct functioning of the tested firearm. For example aspects like projectile velocity, accuracy or the correct cycling of cartridges etc. are not part of the proofing process.\n\nPrimarily oriented towards the proof houses and manufacturers, the C.I.P. independently assesses, approves and publicizes manufacturer's data such as ammunition and chamber dimension specifications, maximum allowed chamber pressures, caliber nomenclature, etc. All this C.I.P. established data can be accessed by everyone.\n\nTechnical procedures describing how to perform proofing are also established by the C.I.P. and updates to the various test methods are issued in the form of \"decisions\". These decisions can also easily be obtained by everyone involved.\n\nThe C.I.P. formally distributes established data and decisions to the member states through diplomatic channels for ratification in each member state and publishing in their official journals. After official publication C.I.P. established data and decisions obtain(s) indisputable legal status in all C.I.P. member states.\n\nGovernmental organizations, like military and police forces and other firearms bearing public power agencies, from the C.I.P. member states are legally exempted from having to comply with C.I.P. rulings. This does not automatically imply that all firearms and ammunitions used by governmental organizations in C.I.P. member states are not C.I.P. compliant, since those organizations often choose to self-impose the relevant C.I.P. standards for their service firearms and ammunition.\n\nFirearm safety tests were made compulsory at the beginning of the 16th century, for instance in Styria (Austria) by decree of Maximilian I of Habsburg on the 12th of September 1501, a little later in London (England), and in the 17th century in Liège (Belgium). At that time, proofing was executed by \"proofers\" at public places. All firearms of reputable brands were proofed this way. Proof testing is compulsory in Belgium since the decree of Maximilian Henry of Bavaria dated May 10, 1672. The Liège Proof House was created at this occasion. Progressively, national proof houses were set up in other countries and proof marks were introduced.\n\nIn 1914, the director of the Liège Proof House in Liège, Mr. Joseph Fraikin (director from 1908 to 1946), was the originator of the creation of the Permanent International Commission for Firearms Testing.\n\nThe C.I.P. has progressively established a set of uniform rules for the proofing of firearms and ammunition to ensure the reciprocal recognition of the proof marks of each member states.\n\nA convention between 8 member states was signed in 1969, ratified and converted into law in each signing state, so that the rules can be enforced to assure that every firearm and cartridge on the market has successfully passed the compulsory proofing and approval.\n\nIn 2014, The C.I.P. celebrated the centenary of its foundation July 15, 1914.\nIt was created just a few days before the First World War (August 1st, 1914)\n\nThe current (2015) C.I.P. member states are:\n\nMost recent member state:<br>\nThe United Arab Emirates became a member state on 9 April 2008. Local companies like Caracal International L.L.C. and ADCOM Manufacturing will benefit of a local proof house.\n\nFormer C.I.P. member state:\nThe Permanent International Commission, confirming that the Socialist Federal Republic of Yugoslavia is no longer in existence, declared during the XXII Plenary Session that the proof marks of the Proof House at Kragujevac would no longer be recognised by the C.I.P. Member States with effect from 30 September 1992.\n\nThe C.I.P. Convention has the following major precepts:\n\nThe main aims of the C.I.P. are as follows:\n\nThe C.I.P. is an organisation whose members are state authorities but the operations of C.I.P. and its decisions are fully delegated to professional people active in the firearms industry. This includes all the proof house directors and their collaborators, ammunition manufacturers, machine manufacturers, gunsmiths, ballistic specialists and so on. Two sub-commissions exist within the commission itself. The first technical sub-commission deals with the definition of measuring methods and determine the acceptable values while the second regulatory sub-commission defines and express the conditions for new uniform rules. Working parties within these sub-commissions are also created each time a subject needs to be discussed and experts on the subject are invited to participate in relevant meetings. They meet as often as considered necessary at various places to work on the subject they have been assigned to and report to their sub-commissions. After that, the C.I.P. votes in Plenary Sessions on submitted sub-commission proposals, resulting in decisions and the publishing of them. This implies that all decisions made by C.I.P., although enforced by law after publication, are the result of a cautious consensus between sensible and knowledgeable people in this field.\n\nSmall arms manufacturers and importers within the C.I.P. member countries are obliged to request one of the accredited Proof Houses to perform the proofing of all arms they manufacture or import. No small arm can be put on the market in any of the C.I.P. member states without prior successful proofing in an accredited proof house, as regulated by the C.I.P. decisions.\n\nAfter the proof test and if successful, two or three proof marks are always applied to the main (highly stressed) parts of the arm, namely the barrel, the chamber (when not part of the barrel) and the locking mechanism. \n\nThese 3 essential parts are also weighed and their weight is recorded in a database together with the serial number.\n\nThen a serial number indicating the year of proofing is also marked on these parts. In case a firearm was voluntary successfully tested at a higher than the normally required proof-test pressure superior proof marks are applied on the relevant parts.\n\nOnly after that is the arm released to the manufacturer or importer to sell or to deliver it, if already sold.\n\nThe C.I.P. also enforces the approval of all ammunition a manufacturer or importer intends to sell in any of the C.I.P. member states. The ammunition manufacturing plants are obliged to test their products during production against the C.I.P. pressure specifications. A compliance report must be issued for each production lot and archived for later verification if needed. The cartridge boxes must also be stamped with a C.I.P. approved number to allow quality/safety traceability according to ISO 9000 principles in case of quality problem though C.I.P. predates the creation of ISO 9000.\n\nSince the very beginning, the C.I.P.’s concern has only been related to arms/ammunition safety from the user's point of view. Thus the C.I.P. is only interested in chamber pressures and not interested in the velocity achieved by the projectiles. As a result, the compulsory ammunition safety control tests by the manufacturers themselves and their approval by the proof houses are only pressure related. The dimensional checking of the ammunition, as described in the C.I.P. Decisions, Texts and Tables, is left to the manufacturers themselves. Headspace is not checked, even on rimless cartridges with taper. The view is that in the very unlikely case (according to the current quality standards) the cartridge is too long, once pressed by the bolt, the pressure will rise too high causing rejection. If it is too short, firing will fail also causing rejection.\n\nThe manufacturers do make velocity measurements, however. These measurements are made during production for quality control with respect to the user's performance expectations of the product for its purpose.\n\nOne exception is arising due to the market introduction of lead free shotshell ammunition loaded with steel or alloy (e.g., bismuth alloy) pellets instead of more traditional lead-based pellets. Due to environmental regulations, hunters in Europe are required to use lead loaded ammunition carefully. For instance, in France, they cannot fire in the vicinity of a pond. In fact, the laws are so complex that some hunters in Europe prefer not to risk getting into trouble for firing lead pellets in the wrong places, so they opt for steel or alloy pellets in all situations. This makes it necessary for manufacturers to market new types of lead free shotgun ammunition loaded with steel pellets. The Vickers hardness test VH1, of the pellet alloy must not exceed a certain level. Many variations in steel and alloy quality exist, but even so, harder metals, especially steel, are known to wear a barrel excessively over time if the shot column velocity and momentum (velocity multiplied by mass) are too great. This leads to potentially harmful situations for the user. \n\nFor the above reasons, the measurement of pellet velocity and momentum is also a C.I.P. imposed obligation for manufacture of shotshell gauges 12, 16 and 20, in both standard and high performance versions. The pellet's velocity must be below 425 m/s, 390 m/s and 390 m/s, respectively, for the standard versions.\n\nAlthough the same approval rules do not apply to hand loaders, given that their products cannot be legally sold in C.I.P. member states, in the interests of safety most Proof Houses afford those parties opportunity to batch test their ammunition to ensure that the associated chamber pressures, velocities and momentum are within acceptable standards. By so doing it reduces the potential for weapons being damaged, thereby injuring the user or innocent bystanders. Previous tests of this nature in the past have indicated the poor standards adopted by some of such parties and the lack of uniformity between rounds of ammunition.\n\nThe NATO military alliance uses a NATO specific recognized class of procedures to control the safety and quality of firearms ammunition called NATO EPVAT testing. The civilian organisations C.I.P. and SAAMI use less comprehensive test procedures than NATO, but NATO test centres have the advantage that only a few NATO chamberings are in military use. The C.I.P. and SAAMI proof houses must be capable of testing hundreds of different chamberings requiring lots of different test barrels, etc. \nFor all other small arms ammunition for use in \"non-NATO Chamber\" weapons, NATO has chosen to conform to the procedures as defined by the current C.I.P. legislation.\n\nThe C.I.P. Decisions are updated, modified and published every one or two years in the form of a Comprehensive Edition of Adopted C.I.P. Decisions, Texts and Tables in the form of CD-ROM containing Portable Document Format documents. Part of the Decisions, Texts and Tables are also available on-line on the C.I.P. website.\n\nOfficial C.I.P. decisions regarding pressure are specified in the unit bar. Though the bar is not a SI unit like the pascal, nor a cgs unit, it is accepted for use with the SI by the US National Institute of Standards and Technology. The bar is widely used in descriptions of pressure because it is only about 1.3% smaller than \"standard\" atmospheric pressure, and is legally recognized in countries of the European Union.\nConversion between the units bar and the MPa is however easy since 10 bar = 1 MPa.\n\nIf there are any contradictions between new decisions and preceding decisions adopted at Plenary Session meetings, the most recent decisions prevail. If there are any contradictions between English or German language translations and the French original text, the latter prevails.\n\nThe C.I.P.’s Head Office is established in Brussels at the Royal Military Academy.\n\nThe American equivalent of C.I.P. is the Sporting Arms and Ammunition Manufacturers' Institute (SAAMI) although operating differently. SAAMI is a manufacturer's association. In contrast to C.I.P.’s decisions the recommendations of SAAMI do not have the force of law.\n\nThese two main ammunition standards organisations are cooperating in an effort to unify their rules, though they are still hard at work resolving differences between their rules. The most critical issue is the technical method used the measure chamber pressures causing differences in measured chamber pressures.\n\nTo a lesser extent there are also some geometric dimensioning and tolerancing differences in some chamberings known as the Delta L problem. The possibility of chambering and/or feeding problems in a firearm caused by the Delta L problem can not be compared with SAAMI's \"Unsafe Arms and Ammunition Combinations\" which details situations where a smaller cartridge may fit in a firearm designed for a larger cartridge, but would be unsafe to use. Such \"unsafe combinations\" do not exist under C.I.P. rules where all chamberings are accurately described without ambiguity.\n\nThe C.I.P. almost exclusively uses one type of Piezoelectric sensor (called a \"channel sensor\") made by the Swiss company Kistler that require drilling of the cartridge case before firing the proofing cartridge in a specially made test barrel. SAAMI uses another type of Piezoelectric sensor (called a \"conformal transducer\") that conforms to the contours of individual chambers and that therefore does not require prior drilling of the cartridge case. These are mostly made by the US company, PCB Piezotronics. Conformal Piezo transducers are more expensive to use because every different chamber wall shape requires a separate transducer whose piston matches that wall contour at the pressure sampling hole location. The channel sensor type is more economical to own because each sensor may be moved between all chambers that have the same size sample hole, of which there are only two. \n\nFor shotshell ammunition, the technical variations are easier to solve since only one type of Piezoelectric sensor (called \"tangential sensor\") is available from the PCB Piezotronics and Kistler International companies to be used without drilling and which does not vary between SAAMI standards and C.I.P. rules.\n\nUnder C.I.P. proof test standards a drilled case is used and the piezo measuring device (transducer) is positioned at a predefined distance from the breech face when the length of the cartridge case permits that, including limits. When the length of the cartridge case is too short or too long, pressure measurement will take place at a cartridge specific location defined at a shorter or longer distance from the breech face and depending on the dimensions of the case.\n\nUnder SAAMI proof test procedures, for bottlenecked cases the centre of the transducer is located behind the shoulder of the case for large diameter () transducers and for small diameter () transducers. For straight cases the centre of the transducer is located one-half of the transducer diameter plus behind the base of the seated bullet. Small transducers are used when the case diameter at the point of measurement is less than .\n\nThe difference in the location of the pressure measurement gives different results than the SAAMI standard.\n\nIn order to solve the problems of conflicting industry standards, efforts are currently made to produce a notion regarding \"reference cartridges\" similar to the system used by NATO armies (NATO EPVAT testing). In this system every manufacturer has set aside a batch (also named \"lot\") of ammunition they consider to be of very good quality and representative of what they need to produce later. It is planned that these batches be sent to the C.I.P. proof houses and to SAAMI approved centers where \"reference firings\" should be performed. \n\nThe system is not in place due to two critical issues. One is the number of cartridges (more than 500) to be referenced which makes the operation excessively costly and lengthy. A second issue is the United States ITAR regulations which makes it very complex administratively to move ammunition back and forth from the United States to Europe, and vice versa.\n\nThe testing and proofing of firearms and ammunition in the C.I.P. member states is performed at these C.I.P. accredited Proof Houses:\n\n\nThe following companies provide equipment to C.I.P. facilities to perform this type of testing:\n\n\n\n\n"}
{"id": "37629962", "url": "https://en.wikipedia.org/wiki?curid=37629962", "title": "Contraceptive trials in Puerto Rico", "text": "Contraceptive trials in Puerto Rico\n\nThe first large-scale human trial of the birth control pill was carried out in Puerto Rico in the 1950s. Between conceptualization and legalization of the first birth control drug in the United States in 1960, there were many developments and trials of test drugs. One such trial happened in Puerto Rico in the 1950s. Before the drug was approved as safe in the U.S., many Puerto Rican women were tested on. The trials were conducted by Gregory Pincus and John Rock in 1955. These trials are a major component in the history of the development of female oral contraceptives, in between initial small trial testing on the east coast and the release of the drug for public consumption.\n\nThe first human trial of the female oral contraceptive was conducted by Gregory Pincus and John Rock in Massachusetts on a test group of 50 women. The trial was described as a fertility study to avoid state legal interruption of the trial. Massachusetts at the time had strong legislation against birth control. In the 1950s in Massachusetts it was a felony to \"exhibit, sell, prescribe, provide, or give out information\" on birth control. Rather than distributing birth control, women were receiving hysterectomies to avoid continuing to get pregnant and have birth. Pincus and Rock felt confident that the combined oral contraceptive pill they had developed was ready for consumers in the United States. Once the Food and Drug Administration approved, the drug could potentially be released in the U.S., but they could not get the approval of the FDA without a larger clinical trial. In 1955 they developed a larger clinical trial of the drug, and tested it on women in Puerto Rico. The pharmaceutical company G. D. Searle & Company created the pills for the trial.\nAfter the trials in Puerto Rico, the drug was approved in the U.S. in 1957 for consumer use as a medication to treat severe menstrual side-effects. The drug was approved as a female oral contraceptive, the first in the U.S., in May 1960. G.D. Searle and company profited greatly from widespread sales of the product, although the company was initially extremely hesitant to be associated with the trials in any way.\n\nThe drug used in this trial was known as Enovid. The drug was a combination of estrogen and progesterone, the same hormones used in modern combined female oral contraceptive pills.\n\nThe drug used in this trial was a much higher dosage than oral contraceptive pills prescribed today. The original dose was 10 milligrams, but this dose was dropped to 5 milligrams after severe side effects were emerging.\n\nThe women who volunteered as subjects for the trial were Puerto Rican women searching for an effective method of birth control. Many were not fluent in English, and many were illiterate. The researchers believed that this would be beneficial to their study, as it would reveal whether or not these pills could be used by anyone around the world.\nFor people to participate, they had to be under forty years old, have two children minimum, fertile, and be in good health. Also, the women had to agree to give birth should they get pregnant during the trial.\n\nThe Puerto Rican women did not know they were experimental subjects. Contraceptives were illegal in the United States but not in the occupied territory so experiments were not regulated in the Island as it was in the mainland. The experimental dosages were many times higher than the legal dose today. Puerto Rican women were poor and many illiterate. This made it easier for researchers to conduct the experiment without the subjects understanding the risks. This avoided fear and reluctancy from the subjects. The effects of high doses of estrogen birth-control are understood today but the effects on Puerto Rican women have not been studied nor accounted for.\n\nSide effects of this high dose pill were similar to that of modern-day oral contraceptives, only more severe; these included nausea, bloating, weight gain, depression, loss of libido, severe mood changes, etc. Doctors did include patients in details of the study.\n\nBlood clotting also became a major problem with women participating in the trial, and is the currently suspect cause of death for the three deaths that occurred in the subjects while the trials were being conducted. However, it took over a decade for official recognition that there was a link between blood clotting and the use of the drug, leading to multiple deaths within the trial itself.\n\nThree deaths occurred among patients who were taking the birth control drug during these trials. However, at the time of occurrence these deaths were not reported in the U.S. to be linked to the trials. Despite strong circumstantial evidence that the pill was causing these unexpected deaths, it was not reported, and those conducting the trial considered the deaths to be merely coincidental. The estrogen in the Pill was making the women susceptible to blood clotting.\n\nAfter the drug came into the American public, controversy over the ethical standards of the trial in Puerto Rico arose. Language barriers inhibited the Puerto Rican women from gaining access to answers about side effects and potential risks. The women were informed that they were being given a pill, free of \ncharge, to prevent potential pregnancy. They were not fully informed that this was a clinical trial, or of the risks involved. Autopsies were never conducted on the bodies of the women that died during the trial, causing worry that drugs manufacturers were overlooking serious issues in order to quickly gain access to sales in the U.S.\n\nThere are many people who believe that \"The Pill\" at its current dosage is still a drug which poses a health threat to women.\nAlice Wolfson, a young activist who spoke at the Nelson Pill Hearings in the 1970s said \"It must be admitted that women make superb guinea pigs. They don't cost anything, they feed themselves, they clean their own cages, pay for their own pills, and remunerate the clinical observer.\" \n\nAlice Wolfson is among the many advocates that critiqued and condemned the contraceptive trials conducted on Puerto Rican women. Not only were advocates challenging the bigoted and hateful outlooks of both liberal and conservatives within the United States, but also the systematic inferiorization of women through colonial, racial and gendered structures.\n\nFeminist scholar and activist, Antonia Darder analyzed the various degrading policies that were enforced following World War II. As explained, women were seen as the means towards the advancement of imperialistic interests held by philanthropists and foreign policy makers. Notoriously, it was the exploitation of poor and working-class women’s sexuality and reproduction in which forged the crude occupation of the United States in Puerto Rico. Furthermore, feminist Catherine MacKinnon scrutinized the hierarchy of power between men and women as a key component in their encroached subjection. Such disparities within Puerto Rico constrained their advancement and rendered them as inferior citizens.\n\nIn addition, native Puerto Rican women were constantly targeted and discriminated based on derogatory stereotypes. Considered incapable of socio-economic achievement, they were often deemed as prostitutes, welfare abusers and incompetent mothers.\n\nThis stigma enforced the idea that low socio-economic communities had the moral obligation to limit and restrict the growth of families with inadequate capability to sustain themselves. This ideology was cultivated by the fears and biases of white pro-birth control groups in the United States who wanted to prevent abusive dependency on social welfare services by poor familial units.\n\nAmong those culpable in supporting this race-suicide discourse as explained by political activist, Angela Yvonne Davis, were white pro-birth control women like Margaret Sanger. Her public statement in support for the implementation of forced contraceptive trials in Puerto Rico is a direct example of the negative rhetoric that harmed minority women. As she argued, “morons, mental defectives, epileptics, illiterates, paupers, unemployables, criminals and prostitutes” should be forcibly sterilized or given contraception to limit their reproductive capabilities.\n\nAs Kimberlé Williams Crenshaw would argue through the theory of intersectionality, Sanger exclusively includes women in her hateful remarks since women are also victims of multiple conditions and societal strains at the same time. Due to this hateful discourse, minority women from Puerto Rico were coerced to undergo clinical treatments. In her film, La Operación, Ana Maria Garcia provides these women a platform to denounce the practices. Some women as seen in the film, were inadequately advised on procedures, and others argued that they did not have other choices due to the constant coercion.\n\nThrough a gendered perspective, it is evident that women are exclusively targeted due to their innate attributes such as their ability to reproduce. By forcibly restricting and removing their capabilities, women are actively being denied their fundamental right to parenthood. Not only is this hindering the progression of minority women, but also an attempt in annihilating “inferior” and “other” groups.\n"}
{"id": "42611255", "url": "https://en.wikipedia.org/wiki?curid=42611255", "title": "Cycle for Survival", "text": "Cycle for Survival\n\nCycle for Survival, owned and operated by Memorial Sloan Kettering Cancer Center (MSK), is leading a nationwide (USA) movement to beat rare cancers. Since its inception in 2007, Cycle for Survival — with support from its founding partner Equinox Fitness — has raised more than $180 million as of 2018. Cycle for Survival directly allocates 100% of all donations to rare cancer research led by MSK  within six months of the events.\n\nCycle for Survival was founded by Jennifer Goodman Linn and her husband, David Linn. In 2004, Jen was diagnosed with MFH sarcoma, a rare cancer, and began treatment at Memorial Sloan Kettering Cancer Center (MSK). After going into remission, she and Dave wanted to fight back and support the doctors and researchers at MSK. \n\nIn 2007, they held the first-ever event, originally named “Spin4Survival,” in Equinox Columbus Circle to raise money for rare cancer research. Despite Jen’s cancer returning, they held two successful events and in 2009, MSK became the owner and operator and Equinox became the founding partner of what it is known today as Cycle for Survival. Jen lost her battle to cancer in 2011 at the age of 40. After her passing, MSK dedicated a lab to recognize her critical role in the advancement of rare cancer research, named “The Jennifer Goodman Linn Laboratory of New Drug Development in Sarcoma and Rare Cancers.”\n\nAt the heart of the movement is a series of indoor team cycling events that take place across the country. In 2018, Cycle for Survival events took place in 16 cities over the USA with more than 34,000 participants.\n\nCycle for Survival’s signature events are indoor team cycling rides that take place across the country, primarily at Equinox clubs. Cancer survivors, patients, caregivers, Memorial Sloan Kettering doctors, researchers and their supporters ride together on stationary bikes to fundraise for rare cancer research. Equinox cycling instructors lead all rides. In 2018, more than 34,000 people participated in Cycle for Survival events that were held in 16 cities in the United States. That same year, over $39 million was raised and directly allocated to rare cancer research at MSK.\n\nCycle for Survival held Times Square Takeover from 2013 - 2017 to kick off event registration each September.\n\nCorporate sponsors help the events continue to grow and gain further support. Equinox, the founding partner of Cycle for Survival, dedicates significant time and resources to help raise awareness and funding. Additional sponsors of Cycle for Survival include official apparel sponsor, New Balance; official hydration sponsor, Smartwater; and official timepiece and timekeeper, TAG Heuer.\n\nThe National Institute of Health defines a \"rare cancer\" as one with fewer than 200,000 affected individuals within the United States. Approximately 50% of people with cancer are battling a cancer that is considered \"rare.\" Rare cancers include brain, ovarian, pediatric and pancreatic cancers, lymphoma and leukemia, and many other types of cancers. \n\nAll donations gained through Cycle for Survival fund promising research and clinical trials at Memorial Sloan Kettering.\n\nCycle for Survival has been featured in a variety of local and national broadcast, digital, and print coverage including: CNN, Refinery29, Shape Magazine, USA Today, ABC News, Good Morning America, Fast Company, and New York Post. \n\nIn 2018, Cycle for Survival was named P2P Forum’s Program of the Year during their annual conference held in Miami, FL. It was also recognized as the fastest-growing peer-to-peer fundraising program from 2014-2016.\n\n"}
{"id": "8207", "url": "https://en.wikipedia.org/wiki?curid=8207", "title": "Dilation and curettage", "text": "Dilation and curettage\n\nDilation (or dilatation) and curettage (D&C) refers to the dilation (widening/opening) of the cervix and surgical removal of part of the lining of the uterus and/or contents of the uterus by scraping and scooping (curettage). It is a therapeutic gynecological procedure as well as the most often used method of first trimester miscarriage or abortion.\n\nD&C normally refers to a procedure involving a curette, also called \"sharp curettage\". However, some sources use the term D&C to refer more generally to any procedure that involves the processes of dilation and removal of uterine contents, which includes the more common \"suction curettage\" procedures of manual and electric vacuum aspiration.\n\n The woman is typically put under monitored anesthesia care (MAC) before the procedure begins. The first step in a D&C is to dilate the cervix. This can be done with Hegar dilators. A curette, a metal rod with a handle on one end and a sharp loop on the other, is then inserted into the uterus through the dilated cervix. The curette is used to gently scrape the lining of the uterus and remove the tissue in the uterus. This tissue is examined for completeness (in the case of abortion or miscarriage treatment) or by pathology for abnormalities (in the case of treatment for abnormal bleeding).\n\nD&Cs are commonly performed for the diagnosis of gynecological conditions leading to 'abnormal uterine bleeding'; to resolve abnormal uterine bleeding (too much, too often or too heavy a menstrual flow); to remove the excess uterine lining in women who have conditions such as polycystic ovary syndrome (which cause a prolonged buildup of tissue with no natural period to remove it); to remove tissue in the uterus that may be causing abnormal vaginal bleeding, including postpartum retained placenta; to remove retained tissue (also known as retained POC or retained products of conception) in the case of a missed or incomplete miscarriage (in which some of the tissue remains in the uterus and the cervix stays open. This may increase a woman's risk of infection and continued bleeding); and as a method of abortion. In contrast, D&C remains 'standard care' for missed and incomplete miscarriage in many countries despite the existence of alternatives currently used for abortions.\n\nBecause medicinal and non-invasive methods of abortion now exist, and because D&C requires heavy sedation or general anesthesia and has higher risks of complication, the procedure has been declining as a method of abortion. The World Health Organization recommends D&C as a method of surgical abortion only when manual vacuum aspiration is unavailable. Most D&Cs are now carried out for miscarriage management and other indications such as diagnosis.\n\nHysteroscopy is a valid alternative to D&C for many surgical indications from diagnosis of uterine pathology to the removal of fibroids and even retained products of conception. It poses less risk because the doctor has a view inside the uterus during surgery, unlike with blind D&C.\n\nMedical management of miscarriage and medical abortion using drugs such as misoprostol and mifepristone are safe, non-invasive and cheaper alternatives to D&C.\n\nComplications may arise from either the introduction or spreading of infection, adverse reaction to general anesthesia required during the surgery or from instrumentation itself, if the procedure is performed blindly (without the use of any imaging technique such as ultrasound or hysteroscopy).\n\nOne risk of sharp curettage is uterine perforation. Although normally no treatment is required for uterine perforation, a laparoscopy may be done to verify that bleeding has stopped on its own. Infection of the uterus or fallopian tubes is also a possible complication, especially if the woman has an untreated sexually transmitted infection.\n\nAnother risk is intrauterine adhesions, or Asherman's syndrome. One study found that in women who had one or two sharp curettage procedures for miscarriage, 14-16% developed some adhesions. Women who underwent three sharp curettage procedures for miscarriage had a 32% risk of developing adhesions. The risk of Asherman's syndrome was found to be 30.9% in women who had D&C following a missed miscarriage, and 25% in those who had a D&C 1–4 weeks postpartum. Untreated Asherman's syndrome, especially if severe, also increases the risk of complications in future pregnancies, such as ectopic pregnancy, miscarriage, and abnormal placentation (e.g.placenta previa and placenta accreta). According to recent case reports, use of vacuum aspiration can also lead to intrauterine adhesions. Yet, in terms of long-term reproductive outcome after miscarriage, a review in 2013 came to the conclusion that there were no studies reporting a link to D&C, while similar pregnancy outcomes were reported subsequent to surgical management (including D&C), medical management or conservative management (that is, watchful waiting). After miscarriage, there is an association between surgical intervention in the uterus and the development of intrauterine adhesions, and between intrauterine adhesions and adverse pregnancy outcomes, but there is still no clear evidence of any method of prevention of adverse pregnancy outcomes related to intrauterine adhesions.\n\n\n"}
{"id": "1723800", "url": "https://en.wikipedia.org/wiki?curid=1723800", "title": "Donald Leake", "text": "Donald Leake\n\nDonald Lewis Leake (November 6, 1931 – December 31, 1997) was an oral surgeon, and inventor of the alloplastic tray, a method for reconstruction of jaws without the need for bone grafts. He gained his D.M.D. from Harvard University in 1962, and an M.D. from Stanford University in 1969. In 1970, Leake was employed at Harvard Medical School as an oral surgeon, and since 1971, Leake had been a Professor of Oral and Maxillofacial Surgery at UCLA.\n\nLeake is also a noted oboist, having studied with Henri de Busscher, and in 1956 gained Premier Prix avec Distinction in Oboe, and Premier Prix avec la Plus Grande Distinction in Chamber Music from the Conservatoire Royal de Musique in Brussels. He received an M.A. in music history in 1957, and continued his musical career in parallel with his dental one.\n"}
{"id": "11051234", "url": "https://en.wikipedia.org/wiki?curid=11051234", "title": "Drug classification: making a hash of it?", "text": "Drug classification: making a hash of it?\n\nDrug classification: making a hash of it? is the title of a 2006 report written by the UK Science and Technology Select Committee and submitted to the British House of Commons. The report suggested that the current system of recreational drug classification in the UK was arbitrary and unscientific, suggesting a more scientific measure of harm be used for classifying drugs. The report also strongly criticised the decision to place fresh psychedelic mushrooms in Class A, the same category as cocaine and heroin.\n\n\nDrug classification: making a hash of it? formed part of a major inquiry, launched in November 2005, into the Government’s \nhandling of scientific advice, risk and evidence in policy-making. The report was the second of three reports into different areas of policy: the first report (\"\"Watching the Directives: Scientific Advice on the EU Physical Agents (Electromagnetic Fields) Directive\") examined the EU Physical Agents (Electromagnetic Fields) Directive; the third (\"Identity Card Technologies: Scientific Advice, Risk and Evidence\"\") examined the government's ID cards proposal.\n\nA legal loophole meant that fresh magic mushrooms were not treated as controlled drugs, providing that they had not been 'prepared' (dried, packaged, cooked, etc.). The government made them a controlled substance by means of a clarification to the law, rather than as a reclassification decision, and there was thus no obligation to consult the Advisory Council on the Misuse of Drugs (ACMD). The government consulted the ACMD, but there was not the full consultation process there ordinarily would be.\n\nThe working practices (primarily excessive secrecy and a resulting lack of transparency) of the Council were criticised:\n\nIt was recommended that future meetings be made open to the public to strengthen public confidence in the Council. The Chairman was specifically criticised for showing little interest in improving the Council's approach with regards to transparency. The Council was also criticised for undertaking decisions in relation to methylamphetamine (see also: #Ecstasy and amphetamines) for apparently political reasons.\n\nThe report made several recommendations relating to the operations and composition of the ACMD, on the basis that it holds a critical role as the only body which the Home Office is legally obligated to consult before undertaking decisions relating to drugs policy. The report remarked that it was \"perturbing\" that the Chairman of the ACMD and the Home Secretary hold contradictory views on drugs classification, and also suggested that the term of the Chairman of the ACMD be limited to five years.\n\nWith regards to what the more general approach in relation to the ACMD should be, the report recommended that provision be made for departments other than the Home Office to benefit from the advice of the ACMD, as \"the current levels of co-ordination appear to be entirely inadequate\"; that the ACMD should more proactively give scientific advice in relation to drugs policy to the Department for Education and Skills and to the Department for Health; that the composition and workings of the ACMD be independently reviewed every five years; and that the Chairman of the Council always be accompanied by another Council member in meetings with ministers (although it was emphasised that it did not recommend this because it believed that the current Chairman had acted improperly).\n\nThe report stated that changes to drugs policy and especially to the classification of individual drugs must be accompanied by an adequate information campaign. It noted that the government of the time was beginning to understand the implications of muddying the water regarding drugs classification, and quoted Charles Clarke (then-home secretary) in his implicit criticism of his predecessors' actions:\nIt agreed with Clarke and cited the widespread confusion today over the legal status of cannabis as evidence of a failure by previous governments to adequately educate the public on drugs policy changes.\n\nThe report found that there was no evidence to support the gateway theory, which holds that the use of legal drugs such as tobacco and alcohol can lead to the subsequent misuse of illegal drugs and that the use of \"soft drugs\" such as cannabis can lead to the abuse of harder drugs such as heroin:\nBlakemore remarked that whilst the attitude to cannabis use in the Netherlands is more relaxed than it is in Britain, there is a little less than it is in Britain, hard drug use is about one third of the rate in this country (thus debunking the gateway theory).\n\nThe government's decision to outlaw magic mushrooms and classify them as a Class A controlled drug by means other than a reclassification meant that the ACMD was not properly consulted as would otherwise have been required by law. The report criticised this and criticised the Chairman of the Council for allowing this and the Council generally for not speaking out at the time.\n\nThe report criticised the Council for having not reviewed the Class A status of MDMA (Ecstasy) in light of its \"widespread usage amongst certain groups\". The decision of the Council to not review the classification of Methamphetamine because of the signal that reclassification might send to potential users was heavily criticised, with the report remarking that \"[to invoke this nonscientific judgement call as the primary justification for its position [regarding amphetamine] has muddied the water with respect to its role.\"\n\nIn a report recently published in the \"Lancet Journal\", researchers have introduced an alternative method for drug classification in the UK. This new system uses a \"nine category matrix of harm, with an expert Delphic procedure, to assess the harms of a range of illicit drugs in an evidence-based fashion.\"\n\nThe categories of harm included 3 main categories and 3 subcategories for each: \n\n\nThe researchers used the proposed classification system to test illegal and some legal substances including alcohol and tobacco among others. The new classification system suggested that heroin, cocaine, alcohol, benzodiazepines, amphetamine, and tobacco have a high or a very high risk of harm, whilst cannabis, LSD, and Ecstasy were all below the two legal drugs.\n\n"}
{"id": "13924093", "url": "https://en.wikipedia.org/wiki?curid=13924093", "title": "Environmental epidemiology", "text": "Environmental epidemiology\n\nEnvironmental epidemiology is a branch of epidemiology concerned with determining how environmental exposures impact human health. This field seeks to understand how various external risk factors may predispose to or protect against disease, illness, injury, developmental abnormalities, or death. These factors may be naturally occurring or may be introduced into environments where people live, work, and play. \n\nEnvironmental exposures can be broadly categorized into those that are proximate (e.g., directly leading to a health condition), including chemicals, physical agents, and microbiological pathogens, and those that are distal, such as socioeconomic conditions, climate change, and other broad-scale environmental changes. Proximate exposures occur through air, food, water, and skin contact. Distal exposures cause adverse health conditions directly by altering proximate exposures, and indirectly through changes in ecosystems and other support systems for human health.\n\nEnvironmental epidemiology research can inform risk assessments; development of standards and other risk management activities; and estimates of the co-benefits and co-harms of policies designed to reduce global environment change, including policies implemented in other sectors (e.g. food and water) that can affect human health.\n\nVulnerability is the summation of all risk and protective factors that ultimately determine whether an individual or subpopulation experiences adverse health outcomes when an exposure to an environmental agent occurs. Sensitivity is an individual’s or subpopulation’s increased responsiveness, primarily for biological reasons, to that exposure. Biological sensitivity may be related to developmental stage, pre-existing medical conditions, acquired factors, and genetic factors. Socioeconomic factors also play a critical role in altering vulnerability and sensitivity to environmentally mediated factors by increasing the likelihood of exposure to harmful agents, interacting with biological factors that mediate risk, and/or leading to differences in the ability to prepare for or cope with exposures or early phases of illness. Populations living in certain regions may be at increased risk due to location and the environmental characteristics of a region.\n\n\n"}
{"id": "3433583", "url": "https://en.wikipedia.org/wiki?curid=3433583", "title": "Folk healer", "text": "Folk healer\n\nA folk healer is an unlicensed person who practices the art of healing using traditional practices, herbal remedies and even the power of suggestion. A folk healer may be a highly trained person who pursues their specialties, learning by study, observation and imitation. In some cultures a healer might be considered to be a person who has inherited the \"gift\" of healing from his or her parent. The ability to set bones or the power to stop bleeding may be thought of as hereditary powers.\n\nGranny women are purported to be healers and midwives in Southern Appalachia and the Ozarks, claimed by a few academics as practicing from the 1880s to the 1930s. They are theorized to be usually elder women in the community and may have been the only practitioners of health care in the poor rural areas of Southern Appalachia. They are often thought to not have expected or received payment, and were respected as authorities on herbal healing and childbirth. They are mentioned by John C. Campbell in \"The Southern Highlander and His Homeland\":\n\nWhite witch and good witch are qualifying terms in English used to distinguish practitioners of folk magic for benevolent purposes (i.e. white magic) from practitioners of malevolent witchcraft or black magic. Related terms are \"cunning-folk\", \"witch doctor\", and the French \"devins-guérisseurs\", \"seer-healers\".\n\nDuring the witch trials of Early Modern Europe, many practitioners of folk magic who did not see themselves as witches, but as healers or seers, were convicted of witchcraft (Éva Pócs' \"sorcerer witches\"): many English \"witches\" convicted of consorting with demons seem to have been cunning folk whose fairy familiars had been demonised, and over half the accused witches in Hungary seem to have been healers.\n\nSome of the healers and diviners historically accused of witchcraft have considered themselves mediators between the mundane and spiritual worlds, roughly equivalent to shamans. Such people described their contacts with fairies, spirits, or the dead, often involving out-of-body experiences and travelling through the realms of an \"other-world\". Beliefs of this nature are implied in the folklore of much of Europe, and were explicitly described by accused witches in central and southern Europe. Repeated themes include participation in processions of the dead or large feasts, often presided over by a female divinity who teaches magic and gives prophecies; and participation in battles against evil spirits, \"vampires\", or \"witches\" to win fertility and prosperity for the community.\n\n\n\n"}
{"id": "8938711", "url": "https://en.wikipedia.org/wiki?curid=8938711", "title": "Gene-for-gene relationship", "text": "Gene-for-gene relationship\n\nThe gene-for-gene relationship was discovered by the late Harold Henry Flor who was working with rust (\"Melampsora lini\") of flax (\"Linum usitatissimum\"). Flor showed that the inheritance of both resistance in the host and parasite ability to cause disease is controlled by pairs of matching genes. One is a plant gene called the resistance (\"R\") gene. The other is a parasite gene called the avirulence (\"Avr\") gene. Plants producing a specific R gene product are resistant towards a pathogen that produces the corresponding \"Avr\" gene product. Gene-for-gene relationships are a widespread and very important aspect of plant disease resistance. An example can be seen with \"Lactuca serriola\".\n\nClayton Oscar Person was the first scientist to study plant pathosystem ratios rather than genetics ratios in host-parasite systems. In doing so, he discovered the differential interaction that is common to all gene-for-gene relationships and that is now known as the Person differential interaction.\n\nThere are several different classes of R Genes. The major classes are the NBS-LRR genes and the cell surface pattern recognition receptors (PRR). The protein products of the NBS-LRR R genes contain a nucleotide binding site (NBS) and a leucine rich repeat (LRR). The protein products of the PRRs contain extracellular, juxtamembrane, transmembrane and intracellular non-RD kinase domains.\n\nWithin the NBS-LRR class of R genes are two subclasses:\n\n\nThe protein products encoded by this class of resistance gene are located within the plant cell cytoplasm.\n\nThe PRR class of R genes includes the rice XA21 resistance gene that recognizes the ax21 peptide and the Arabidopsis FLS2 peptide that recognizes the flg22 peptide from flagellin.\n\nThere are other classes of R genes, such as the extracellular LRR class of R genes; examples include rice Xa21D for resistance against \"Xanthomonas\" and the \"cf\" genes of tomato that confer resistance against \"Cladosporium fulvum\".\n\nThe \"Pseudomonas\" tomato resistance gene (Pto) belongs to a class of its own. It encodes a Ser/Thr kinase but has no LRR. It requires the presence of a linked NBS-LRR gene, \"prf\", for activity.\n\nR gene specificity (recognising certain Avr gene products) is believed to be conferred by the leucine rich repeats. LRRs are multiple, serial repeats of a motif of roughly 24 amino acids in length, with leucines or other hydrophobic residues at regular intervals. Some may also contain regularly spaced prolines and arginines.\n\nLRRs are involved in protein-protein interactions, and the greatest variation amongst resistance genes occurs in the LRR domain. LRR swapping experiments between resistance genes in flax rust resulted in the specificity of the resistance gene for the avirulence gene changing.\n\nMost resistance genes are autosomal dominant but there are some, most notably the \"mlo\" gene in barley, in which monogenic resistance is conferred by recessive alleles. \"mlo\" protects barley against nearly all pathovars of \"powdery mildew\".\n\nThe term “avirulence gene” remains useful as a broad term that indicates a gene that encodes any determinant of the specificity of the interaction with the host. Thus, this term can encompass\nsome conserved microbial signatures (also called pathogen or microbe associated molecular patterns (PAMPs or MAMPs)) and pathogen effectors (e.g. bacterial type III effectors and oomycete effectors) as well as any genes that control variation in the activity of those molecules.\n\nThere is no common structure between avirulence gene products. Because there would be no evolutionary advantage to a pathogen keeping a protein that only serves to have it recognised by the plant, it is believed that the products of Avr genes play an important role in virulence in genetically susceptible hosts.\n\n\"Example:\" AvrPto is a small triple-helix protein that, like several other effectors, is targeted to the plasma membrane by N-myristoylation. AvrPto is an inhibitor of PRR kinase domains. PRRs signal plants to induce immunity when PAMPs are detected. The ability to target receptor kinases is required for the virulence function of AvrPto in plants. However, Pto is a resistant gene that can detect AvrPto and induce immunity as well. AvrPto is an ancient effector that is conserved in many P. syringae strains, whereas Pto R gene is only found in a few wild tomato species. This suggests recent evolution of the Pto R gene and the pressure to evolve to target AvrPto, turning a virulence effector to an avirulence effector.\n\nUnlike the MAMP or PAMP class of avr genes that are recognized by the host PRRs, the targets of bacterial effector avr proteins appear to be proteins involved in plant innate immunity signaling, as homologues of Avr genes in animal pathogens have been shown to do this. For example, the AvrBs3 family of proteins possess DNA binding domains, nuclear localisation signals and acidic activation domains and are believed to function by altering host cell transcription.\n\nIn only some cases is there direct interaction between the R gene product and the Avr gene product. For example, both FLS2 and XA21 interact with the microbial peptides. In contrast, for the NBS-LRR class of R genes, direct interaction has not been shown for most of the R/avr pairs. This lack of evidence for a direct interaction led to the formation of the guard hypothesis for the NBS-LRR class of R genes.\n\nThis model proposes that the R proteins interact, or guard, a protein known as the guardee which is the target of the Avr protein. When it detects interference with the guardee protein, it activates resistance.\n\nSeveral experiments support this hypothesis, e.g. the Rpm1 gene in \"Arabidopsis thaliana\" is able to respond to two completely unrelated avirulence factors from \"Pseudomonas syringae\". The guardee protein is RIN4, which is hyperphosphorylated by the Avr proteins. Another high profile study that supports the guard hypothesis shows that the RPS5 pair uses PBS1, a protein kinase as a guardee against AvrPphB.\n\nYeast two-hybrid studies of the tomato Pto/Prf/AvrPto interaction showed that the Avirulence protein, AvrPto, interacted directly with Pto despite Pto not having an LRR. This makes Pto the guardee protein, which is protected by the NBS-LRR protein Prf. However, Pto is a resistance gene alone, which is an argument against the guard hypothesis.\n\n"}
{"id": "15423087", "url": "https://en.wikipedia.org/wiki?curid=15423087", "title": "George Stuart Fullerton", "text": "George Stuart Fullerton\n\nGeorge Stuart Fullerton (1859–1925) was an American philosopher and psychologist. Fullerton was born at Fatehgarh, India, the son of the Rev. Robert Stuart Fullerton. He came to this country as a youth.\n\nHe graduated in 1879 from the University of Pennsylvania and in 1884 from Yale Divinity School; and returned to Pennsylvania to be an instructor, adjunct professor, and dean of the department of philosophy, dean of the college, and vice provost of the university. In 1904 he was appointed professor of philosophy at Columbia University, and served as head of the department.\n\nHe was the host of the first annual meeting of the American Psychological Association in 1892 at the University of Pennsylvania, and the APA's fifth president, in 1896.\n\nIn 1884 he married Miss Rebekah Daingerfield Smith of Alexandria, Va., who died in 1892. Five years later he married Julia Winslow Dickerson of Philadelphia, his widow. There were no children.\n\nIn 1914, while he was exchange professor at the University of Vienna, World War I broke out. He was Lecturing at Munich (Germany) when Interned. Fullerton was imprisoned as a civilian enemy national. He remained imprisoned for four years, until the end of the war, and conditions were so harsh that he returned to the U.S. with his health permanently damaged. (Scottish psychologist Henry J. Watt suffered a similar fate.) Nearly an invalid for the last decade of his life, Fullerton committed suicide at the age of 66.\n\nFullerton's philosophy was realist. His writings include: \n\n\n"}
{"id": "3963096", "url": "https://en.wikipedia.org/wiki?curid=3963096", "title": "Greystone Park Psychiatric Hospital", "text": "Greystone Park Psychiatric Hospital\n\nGreystone Park Psychiatric Hospital (also known as Greystone Psychiatric Park, Greystone Psychiatric Hospital, or simply Greystone and formerly known as the State Asylum for the Insane at Morristown, New Jersey State Hospital, Morris Plains, and Morris Plains State Hospital) referred to both the former psychiatric hospital and the historic building that it occupied in Morris Plains, New Jersey. Built in 1876, the facility was built to alleviate overcrowding at the state's only other \"lunatic asylum\" located in Trenton, New Jersey. Originally built to accommodate 350 people, the facility, having been expanded several times, reached a high of over 7700 patients resulting in unprecedented overcrowding conditions. In 2008, the facility was ordered to be closed as a result of deteriorating conditions and overcrowding. A new facility was built on the large Greystone campus nearby and bears the same name as the aging facility. Despite considerable public opposition and media attention, demolition of the main Kirkbride building began in April 2014 and was completed by October 2015.\n\nThe idea for such a facility was conceived in the early 1870s at the persistent lobbying of Dorothea Dix, a nurse who was an advocate for better health care for people with mental illnesses. At that time in history, New Jersey's state-funded mental health facilities were exceedingly overcrowded and sub-par compared to neighboring states that had more facilities and room to house patients. Greystone was built, all of it, in part to relieve the only – and severely overcrowded – \"lunatic asylum\" in the state, which was located in Trenton, New Jersey. Because of her efforts, the New Jersey Legislature appropriated $2.5 million to obtain about of land for New Jersey’s second \"lunatic asylum\". Great care was taken to select a location central to the majority of New Jersey's population. After visiting approximately 42 different locations, officials approved purchase of a portion of a few farms and lots, on August 29, 1871, near Morristown and a short distance from the Morris and Essex Railroad. The plots of land contained fertile soil, rock quarries for mining stone, a sand pit for building materials and reservoirs for water and ice access. The new asylum, when completed, would hold approximately 600 patients, with the large main building to be completed in sections as usage detailed. The plan of the main building was drafted to allow for a total of 40 wards split into two wings, one wing for each sex. There was to be no communication between wards. The corridors served a purpose other than just separating wards: they provided for fire protection, so that a fire would be unable to spread past a single section of the building. Upper floors in the center section contained apartments for employees, and the third story contained the amusement room and chapel for patients. Samuel Sloan was named architect of the main building and its smaller supporting buildings. Sloan chose to follow the Kirkbride Plan, a list of ideals pertaining to hospital design created by Thomas Story Kirkbride. There would be a center section for administrative purposes, then a wing on each side with three wards on a floor. Each ward would be set back from the previous one to allow patients to take in the beautiful grounds from their wards. Each ward was designed to accommodate 20 patients, with a dining room, exercise room and activity room. The wards were furnished with the highest quality materials such as wool rugs, pianos and fresh flowers.\n\nPatients worked on the farms growing and raising food and performed hard labor tasks in the clearing away of building debris, excavating for roads, and sodding grounds. The plan of the institution called for carriage drives ending at all doorways, and a central road leading up to the front entrance flanked by trees on both sides. Grounds on both sides of the wings would provide for simultaneous exercise of both sexes while keeping them separate. An industrial building opened in 1914, allowing for more jobs for patients than just manual labor jobs in farming or groundworks. It was a widely popular belief that putting the insane to work in certain circumstances was beneficial both to the patient and the institution. Those who were chronically ill, restless in the day and night, were thought to be aided in their general well-being by working out some of the oversupply of blood to the brain. Within the walls of the new building, male patients were able to make brooms, rugs, brushes, carpets, and do printing and bookmaking.\n\nBy 1895, the State Lunatic Asylum was operating at 325 patients over capacity. The overcrowding was a major health and cleanliness issue, resulting in a small outbreak of typhoid fever, eventually blamed on the water supply. The passing of years brought no relief for a bursting hospital, occupied with 1,189 patients bedded down in an institution meant to hold only 800 every night. Cots were placed in activity rooms, exercise halls and hallways in order to try to find sleeping arrangements for all. \"From a sanitary point of view these cots are an abomination,\" declared the board of managers. Cots were set up and taken down on a daily basis on the hallways, and were not able to be cleaned between uses. Patients often soiled themselves during the night, and the cots were simply handed out again the following evening.\n\nThe asylum scrambled to create more housing. By 1901, the new dormitory building was completed and quickly filled, slightly easing crowding issues. Patients were once again able to be grouped according to disease classification and had access to exercise and activity rooms again. The new dormitory building would gain infirmaries and operating rooms in the coming years, as well as a bowling alley which was extremely popular among patients and staff during the winter months when outdoor exercise was not an option. By 1903, the hospital had crossed over the 1,500-patient mark, continuing its steady climb. Once again, the numbers were an issue.\n\nA state-of-the-art electroconvulsive therapy room was installed in the main building, and the women’s wing of the dormitory received a hydrotherapy room. Medical Director Britton D. Evans described this new treatment in his report in 1906, writing, \"It is well recognized that the application of water at varying degrees of temperature and pressure exerts influences of a valuable therapeutic character upon the entire human economy and aids the recuperative powers of the body.\" Female patients were able to receive treatment for their afflictions through use of douches, massages, and hot air cabinets. A hydrotherapeutic treatment room for male patients was opened the following year.\n\nBy 1911, the newly renamed State Asylum at Morris Plains held 2,672 patients, and cots were once again placed in corridors and activity rooms. A photographic department was established and began documenting patients in hopes of cataloging facial expressions and characteristics which go with certain mental disorders. A dental clinic opened for treatment of teeth ailments. A tuberculosis pavilion was finished and occupied the following year, as well as a new larger fire department house, and enlargements to the greenhouse and piggery. In 1916, women began participating in sewing and arts and crafts on the top floor of the Industrial Building, and a small patient library was founded with 184 volumes of books. Annexes to the Dormitory building opened in 1917 to provide more space for housing. The next few years saw much progress in the department of building construction. The Voorhees Cottage and Knight Cottage were opened as homes for nurses, as well as cottages for senior physicians and the superintendent. The Psychiatric Clinic Reception Building opened in 1923 and all operating rooms, laboratories and x-ray equipment were moved to the new building. A Social Service Department was instituted, in charge of letting patients out for \"trial\" visits to help them assimilate back into the real world. Parts of the hospital are set aside of \"War Risk Patients\" or veterans from World War I suffering from various mental diseases, including the yet-to-be-named post-traumatic stress disorder (PTSD).\n\nThe hospital was given with its modern-day name, Greystone Park Psychiatric Center, in 1924. The new reception building, dubbed the Curry Building after Medical Superintendent Marcus Curry, opened in 1927, as well as a new fire station, power plant, greenhouse, and auxiliary buildings. The Men's Occupational Therapy Building opened that same year, allowing for patients to take on new duties in service to the hospital such as tailoring and woodworking. 1929 and 1930 proved to very trying times for Greystone. In the two-year span, three fires severely handicapped the institution’s ability to treat the mentally ill. The most devastating of the three fires, on November 26, 1930, was ruled to have originated from faulty electrical wiring on the sixth floor of the center section. Some patients were tied to trees with fireman’s ropes to prevent escape after evacuation. The fourth floor north wards were destroyed as well as the central tower. Once rebuilt, the fourth floor in the north wards never matched the rest of the hospital in construction and style again. The state of New Jersey opened the Marlboro Psychiatric Hospital in 1931, and patients were transferred over the next few years down to the new hospital to help with overcrowding issues. However, Greystone officials were faced with a new problem: patients transferred to Marlboro had to pass a series of tests, and often the most able-bodied patients were removed from the campus, leaving older or more seriously ill patients behind. A change in the population began, and there was a shortage of patients capable of work or occupational therapy. Some of this need was filled by working men brought in by the state through the WPA program and other similar programs starting around 1935.\n\nThe 1970s and 1980s saw a redirection in mental health towards deinstitutionalization. States around the country decided that mental health patients were better off living in the home with their families and being treated by the community than staying in removed surroundings in a hospital for a long-term stay. Two factors caused this sudden change. New psychological drugs were able to control patients much more effectively than previous methods ever could, and suddenly dangerous patients were capable of existing in the community in a less harmful state. Secondly, laws were passed in the 1970s forbidding patients to work unless paid fairly, which meant at least minimum wage. Suddenly hospital costs skyrocketed, as patients were no longer able to work in order to defray fees.\n\nDue to the landmark Doe vs. Klein case in 1974, Greystone Park Psychiatric Hospital was forced to build community homes for patients to provide halfway house type living situations, and adequate staffing and patient care was required of the institution. Twenty \"independent living\" cottages opened in 1982 and by 1988 all patients had been moved out of living in the main Kirkbride building, and the wings were basically abandoned. Now only the center section was used for administrative purposes. Students of Drew University led an effort to try to get Greystone Park Psychiatric Center listed on the National Register of Historic Places, but were turned down. The Register claimed that the study submitted focused too much on the Kirkbride building, and that they wanted to see the entire hospital system submitted as a National Historic District. However, one student did manage to get the gas house placed on the Register.\n\nGreystone had dark years in the 1990s. Patient escapes became commonplace, including some that involved criminals and sex offenders. Staff were accused of abuse and rape, and some female residents became pregnant. Buildings were falling apart and lacking in basic creature comforts. Greystone was in danger of losing its accreditation from the Joint Commission on Accreditation of Healthcare Organizations. If this had happened, the hospital would have lost approximately $35 million annually from Medicaid and Medicare. A Senate task force was appointed to conduct a six-month probe on how to improve conditions, and the hospital was able to pass.\n\nIn 1997, the original tuberculosis pavilion was demolished, along with the morgue, a large garage, the print and tailor shops, and several employee dormitories and cottages. A new era for Greystone had begun, and the state was realizing it did not include many of its decaying antiquated buildings. The State of New Jersey released a report in 1999 stating the behemoth Kirkbride building was \"not suitable for long-term future use.\" The report went on to say that a new smaller building should be built and the hospital consolidated under this structure, and that while older structures should be razed, the main building should be saved due to historical significance. Governor Christine Todd Whitman ordered the now 550-bed facility closed within the next three years in 2000.\n\nMorris County purchased approximately of the Greystone Park Psychiatric Center property in 2001 for one dollar, with the stipulation that it would clean up asbestos and other environmental hazards on the site within its decaying buildings. When this land was sold, a law was also passed that Greystone land cannot be used for any purpose other than \"recreation and conservation, historic preservation or farmland preservation.\" This meant no commercial development and no condos or townhomes.\n\nThe major effort to clean up the larger decaying buildings which still stood, and were viewed as eyesores, began in 2005 with the demolition of the dormitory. Ground was broken on the new hospital building, located up the hill across the street from the Ellis complex. The entire Curry Complex, including the Medical Clinic Building, the Curry Reception Building and the Employee Cafeteria came down in 2007 and 2008. The trio of buildings known as the Ellis Complex were cleared to make way for a parking lot.\n\nOn July 16, 2008, after countless unexplained delays, patients were moved into the new hospital building. Administration and other departments followed suit. Today, almost all hospital services have relocated to the new complex. Morris County has installed skating rinks and a ball field on its 300-acre share, and plans to incorporate a dog park where the Curry Complex once stood, as well as an athletic complex for disabled athletes. The Central Avenue Complex is planned to become a mall for nonprofit charitable agencies.\n\nOn September 8, 2005, the New Jersey Health Care Facilities Financing Authority closed a $186,565,000 bond issue on behalf of the State of New Jersey Department of Human Services for the completion of a new, Greystone Park Psychiatric Hospital, still with a shortage of about 75 beds.\n\nThe original Second Empire Victorian style building was . At the base of this building was the alleged largest continuous foundation in the United States from the time it was built until it was surpassed by the Pentagon when it was constructed in 1943. However, many other Kirkbride asylum buildings (such as the Athens Lunatic Asylum in Ohio) also lay a claim to this fame and it has not been verified which one is true. The building has a characteristic linear arrangement, which was designed to the specifications of the Kirkbride Plan. The main building has a center section that was used for administrative purposes with three wings radiating out from the center, each about long. They were set back from the previous one so that patients could enjoy the beauty of the outside surroundings. This was a central concept, along with moral treatment, that was the hallmark of the Kirkbride Plan for treating the mentally ill. The building form itself was meant to promote treatment and have a curative effect.\n\nEach ward was initially set up to accommodate 20 patients. Each was furnished with a dining room, exercise room, and parlor. Most wards had wool rugs that ran the full length of the corridors. Other amenities included Victorian stuffed furniture, pianos, pictures, curtains and fresh flowers. Though not all wards were created equally. Wards that housed the most excitable patients were sparsely furnished – presumably for their own safety – with sturdy oak furniture.\n\nDuring the time that Greystone was built, the predominant philosophy in psychology was that the mentally ill could be cured or treated, but only if they were in an environment designed to deal with them. A major proponent of this philosophy was Thomas Story Kirkbride, who participated in the design phase of the main building at Greystone, though the two main designers were architect Samuel Sloan and Trenton State Asylum Superintendent Horace Buttolph (a friend of Kirkbride's). The building was constructed and furnished according to Kirkbride's philosophy, which proposed housing no more than 250 patients in a three-story building. The rooms were to be light and airy with only two patients to a room. To reduce the likelihood of fires, Greystone and other Kirkbride asylums were constructed using stone, brick, slate and iron, using as little wood as possible. A street on the Greystone Park campus bears Buttolph's name.\n\nThe Greystone campus itself was once a self-contained community that included staff housing, a post office, fire and police stations, a working farm, and vocational and recreational facilities. It also had its own gas and water utilities and a gneiss quarry, which was the source of the Greystone building material. Below the building, a series of tunnels and rails connect the many sections.\n\nBy the 2000s, many of the buildings were vacant and needed major repairs. Preservationists had been working for several years to guarantee the survival of this complex of buildings and Morris County had been negotiating with the State of New Jersey to take over vacant structures for non-profit agencies. Citizens of Morris County and surrounding areas formed the Preserve Greystone society to save the buildings.\n\nIn the summer of 2008, the Curry building, as well as the surrounding vacant buildings, were demolished. In August 2013, state officials from the New Jersey Department of the Treasury announced plans to demolish the main Kirkbride building. In response to the community preservation group, Preserve Greystone, the Department worked with a consultant who found that redevelopment of the building would be too costly. The following year the state announced the awarding of a $34.4 million demolition bid to Northstar Contracting Group to take down the Kirkbride Building as well as other structures of the old hospital. Governor Chris Christie announced that the state was not considering a bid by Alma Realty to restore the property at no cost to the state. The plans for the demolition included the designation of an area on the property to memorialize the Kirkbride Building. State officials announced the demolition was scheduled to begin on April 6, 2015 and that work to clean up the site had already begun. Preserve Graystone filed an appeal to halt the demolition which the state court declined to hear.\n\nGround was ceremonially broken on November 16, 2005, for the new psychiatric hospital on the Greystone campus. The new hospital is two-thirds the size of the Kirkbride building and can house about 450 patients, with another 100 patients living in hospital-run cottages on the grounds around the main building. The remaining property, including the historic Kirkbride building, was turned over to the state's treasurer in October 2007 as excess property with the intention that it would be sold. Nevertheless, despite considerable public opposition and media attention, the main Kirkbride building was demolished in a process that began in April 2014 and was\ncompleted by October 2015.\n\nOn July 16, 2008, the patients were transferred to the new, state-of-the-art building housing the new 450-bed facility.\n\n\nThe Kirkbride building has been used as a filming location for multiple shows and films, including \"Marvin's Room\" as well as \"Mayfield Psychiatric Hospital\" in two episodes of the FOX series \"House, M.D.\".\n\n\n\n\n"}
{"id": "46478160", "url": "https://en.wikipedia.org/wiki?curid=46478160", "title": "Gross National Well-being", "text": "Gross National Well-being\n\nGross National Wellness or Well-being (GNW) is a socioeconomic development and measurement framework. The GNW / GNH Index consists of 7 dimensions: economic, environmental, physical, mental, work, social, and political. Most wellness areas include both subjective results (via survey) and objective data.\n\nThe GNW Index is also known as the first GNH Index or Gross National Happiness Index, not to be confused with Bhutan's GNH Index. Both econometric frameworks are different in authorship, creation dates, and geographic scope. The GNW / GNH index is a global development measurement framework published in 2005 by the International Institute of Management in the United States. \nThe Gross National Happiness phrase was coined in 1972 by Sicco Mansholt, one of the founders of the European Union and the fourth President of the European Commission, and was later popularized by Bhutan in the late 1990s. However, no GNH Index existed until 2005.\n\nThe GNH philosophy suggested that the ideal purpose of governments is to promote happiness. The philosophy remained difficult to implement due to the subjective nature of happiness and the lack of exact quantitative definition of GNH and the lack of a practical model to measure the impact of economic policies on the subjective well-being of the citizens.\n\nThe GNW Index paper proposed the first GNH Index as a solution to help with the implementation of the GHN philosophy and was designed to transform the first generation abstract subjective political mission statement into a second generation implementation holistic (objective and subjective) concept and by treating happiness as a socioeconomic development metric that word provide an alternative to the traditional GDP indicator, the new metric would integrates subjective and objective socioeconomic development policy framework and measurement indicators.\n\nThe GNW Index is a secular econometric model that tracks 7 subjective and objective development areas with no religious measurement components. On the other hand, Bhutan's GNH Index is a local development framework and measurement index, published by the Centre for Bhutan Studies in 2012 based on 2011 Index function designed by Alkire-Foster at Oxford University. The Bhutan's GNH Index is customized to the country's Buddhist cultural and spiritual values, it tracks 9 subjective happiness areas including spiritual measurement such as prayers recitation and other Karma indicators. The concepts and issues at the heart of Bhutanese approach are similar to the secular GNH Index.\n\nIn 2006, a policy white paper providing recommendations for implementing the GNW Index metric was published by the International Institute of Management. The paper is widely referenced by academic and policy maker citing the GNW / GNH index as a potential model for local socioeconomic development and measurement.\n\nThe subjective survey part of the GNW measurement system is structured into seven areas or dimensions.\nEach area or dimension satisfaction rating is scaled from 0–10: 0 being very dissatisfied, 5 being neutral, and 10 is very satisfied.\n\n\nThe survey also asks four qualitative questions to identify key causes of happiness and unhappiness:\n\n\nOne major criticism is that the use of subjective surveys can lead to unreliable conclusions.\n"}
{"id": "53368676", "url": "https://en.wikipedia.org/wiki?curid=53368676", "title": "Gynecologic cancer disparities in the United States", "text": "Gynecologic cancer disparities in the United States\n\nGynecologic cancer disparities in the United States refer to differences in incidence, prevalence, and mortality from gynecologic cancers between population groups. The five main types of gynecologic cancer include cervical cancer, ovarian cancer, endometrial cancer, vaginal cancer, and vulvar cancer. For patients with these and other gynecologic malignancies within the United States, disparities across the care continuum by socioeconomic status and racial/ethnic background have been previously identified and studied. The causes behind these disparities are multifaceted and a complex interplay of systemic differences in health as well as individual patient factors such as cultural, educational, and economic barriers.\nSince the development of the Papanicolou smear or Pap smear in 1941, cervical cancer has been highly preventable. The implementation of Pap smear screening programs has resulted in a steady decline in incidence and mortality rates from cervical cancer since the mid-1970s. Even with this technology, the American Cancer Society still estimates that within the U.S., about 12,820 new cases of invasive cervical cancer will be diagnosed and 4,210 women will die of cervical cancer by the end of 2017.\n\nDespite an overall decline in incidence and mortality rates from cervical cancer for women across the United States, significant disparities have been documented amongst racial and ethnic minorities and socioeconomically marginalized populations. Within the United States, Hispanic women have the highest incidence of cervical cancer, and African Americans have the highest mortality.\n\nDisparities amongst different minority groups have been attributed to different Pap smear screening practices. African Americans, American Indians, and non-white Hispanics have been found to be diagnosed at later stages than white women, which has been suggested as a potential contributing reason for their worse survival outcomes. One 2001 study in California found that Asian women were the least likely ethnic/racial group to have ever had a Pap test. This study also described varied trends existing within different Asian American subpopulations, identifying how Vietnamese women had the lowest screening rates (62.3%) and Filipino women had the highest screening rates (81.1%). It has also been discovered that foreign-born women in the U.S. have lower screening rates than those born in the U.S.\n\nNot only does there exist disparity in screening, but there also exists post-screening disparities in follow-up practices. Adherence to follow-up after abnormal Pap tests varies across minority groups. The National Breast and Cervical Cancer Early Detection Program, a national initiative focused on increasing access to cervical and breast cancer screening for underserved women followed more than 10,000 participants who had two or more abnormal Pap test results. They found 56% of these patients did not follow-up with a recommended cervical examination, and 27.7% of this group received no follow-up examination whatsoever. Within this study, African Americans had the highest rate of no follow-up.\n\nAcross all racial/ethnic groups in the U.S., increased poverty and decreased education levels have been associated with higher mortality.\n\nHuman papilloma virus (HPV) is consistently present in almost all cervical cancer cases across the world and is the main etiologic factor in cervical cancer. The U.S. Advisory Committee on Immunization Practice advises that females receive the full series of three doses of quadrivalent HPV vaccine at 11–12 years of age. For females aged 13–26 years who have not been previously vaccinated, catch-up vaccination is recommended.\n\nDespite these national recommendations, the rate of HPV vaccination in the U.S. remains low. One study of 409 females aged 13–26 found that only 5% of participants had received one or more HPV vaccine dosages. Since parents have an critical role in deciding the vaccination of their young daughters, studies have found that parenting beliefs and attitudes are important to HPV vaccine practices of girls throughout the U.S.\n\nNon-adherence to screening and vaccination have been found to be influenced by cultural and personal beliefs and conditions. Interviews with females of ethnic minorities, specifically Chinese and Hispanics, have revealed that the implications of sexual activity that come with Pap smears impact females decisions to get screened. Some women revealed that they avoid screening to prevent others from thinking that they are sexually active or promiscuous due to embarrassment or concern about being discovered.\n\nReceiving a recommendation by one's physician is strongly correlated with patients seeking out to be screened by a Pap smear. Across different racial and ethnic groups, having a regular doctor increases the likelihood of a patient undergoing regular Pap smearing. Additional barriers such as long wait times, lack of transportation, inability to take off work, lack of family support or available child care options can often impact patients' abilities to seek out and receive appropriate preventative measures and treatment.\n\nUnderstanding cervical cancer and its link to human papillomavirus (HPV) is closely related to agreeing to undergo Pap smear screening or get vaccinated against HPV across population types. Cervical cancer patients who have never had a Pap test were more likely to have previously not been aware that they were capable of developing cervical cancer.\n\nThere have been documented racial and ethnic disparities in clinical treatment for cervical cancer. Research has shown that African Americans are more likely than whites to go untreated. They are also less likely to receive clinical staging or be treated with surgery or combined therapy.\n\nWhile ovarian cancer accounts for only 3% of cancers for women in the U.S., it is the fifth leading cause of cancer-related deaths for this population. This cancer is known as the \"silent killer\" and is disproportionately lethal because of lack of effective screening and early detection strategies resulting from the absence of disease-specific symptoms. If diagnosed in an early stage (stage I) while the tumor is confined to the ovaries, ovarian cancer is highly treatable with a five-year survival rate over 90%. However the majority of ovarian cancer patients are diagnosed with stage III and stage IV cancer, which are associated with poor prognosis, even with aggressive therapy.\n\nEven with poor existing screening methods, around 20% of women with ovarian cancer are still effectively caught and diagnosed at early stages in the U.S. Research has revealed that not having private health insurance coverage decreases a woman's chance of being diagnosed with early stage ovarian cancer. African American women are less likely to be diagnosed at an early stage of ovarian cancer as compared to white women due to lower rates of private health insurance coverage. As a result, African American women have been found to be at higher risk of presenting with advanced, late-stage aggressive ovarian cancer for which current treatment standards can only palliate symptoms.\n\nCertain genetic components have been found to increase the susceptibility of carriers to develop ovarian cancer. Possession of specific mutations of the \"BRACA1\" and \"BRACA2\" genes impose a lifetime risk of developing ovarian cancer as high as 20-65%, compared to the 1.4-2.5% risk for a woman from the general population with no affected relatives. Hereditary nonpolyposis colorectal cancer, also known as Lynch syndrome, is also associated with elevated lifetime risk of developing ovarian cancer, at about 10-12%.\n\nGenetic screenings are strongly advised for high-risk women who possess a family history of ovarian cancer or any of the aforementioned genetic alterations or who have been diagnosed with early onset colorectal, breast, uterine, or endometrial cancer. Within the U.S., African American women are less likely to undergo genetic counseling or testing as compared to Caucasian women. A national study of 25,364 people revealed that more Caucasian women report having heard about genetic testing for cancer risk as compared to African American, Asian, or Hispanic women, indicating the need for more culturally competent approaches to improve awareness of these screening methods.\n\nIn the U.S. and the rest of the developed world, surgery is the treatment standard for all stages of ovarian cancer. For later stages, adjuvant chemotherapy has been shown to improve patient survival. Lymphadenectomy and lymph node chemotherapy have also been demonstrated to improve survival for ovarian cancer patients of all stages.\n\nThe U.S. is the only country that has reported significant ovarian cancer treatment disparities. Within the U.S., African American patients have the highest risk of receiving delayed treatment, non-standard treatment, or no treatment at all. A multi-institutional study of 47,390 patients revealed that uninsured and Medicaid-insured patients to be at higher risk of receiving non-standard treatment compared to privately insured patients. Patients at community cancer hospitals compared to teaching hospitals were also at higher likelihood for receiving non-standard care. Overall, even with treatment guidelines made by many different organizations, several ovarian cancer patients are not receiving appropriate treatment, especially older and minority women without private insurance.\n\nEndometrial cancer incidence is rising in the U.S across all racial/ethnic groups. The highest increases in incidence rates for endometrial cancer have been observed in African American and Asian women, who tend to present with more aggressive subtypes of endometrial cancer. The overall racial disparity in survival from endometrial cancer between African Americans and whites is greater than in any other type of cancer.\n\nAfrican American women are less likely than white women to receive primary surgery for endometrial cancer. Their associated mortality rate from endometrial cancer has been found to be 84% higher than white women.\n\nIt has been suggested that variance at the molecular level might underlie racial disparities in survival outcome. High expression of the mutant p53 tumor suppressor protein has been found to be associated with poor survival rates for endometrial cancer, and this malignant over-expression has been discovered to occur twice as frequently in blacks than in whites.\n\nVulvar cancer is the fourth most common gynecologic cancer with approximately 940 deaths from this disease in the United States each year. If caught early without associated nodal involvement, vulvar cancer patients can be treated with a survival rate of 90%.\n\nAfrican American women have been shown to have better survival outcomes compared to whites for vulvar cancer even though they present with cancer at a significantly younger age. This has been explained by African American's higher rate of human papilloma virus HPV infection. Research reveals that African American women have a higher frequency of HPV-associated vulvar cancers than white women. HPV-positive vulvar cancer is associated with early age onset, less overall aggressive behavior, and better patient prognosis.\n\nVaginal cancer is a rare cancer type that accounts for less than 1-2% of all gynecologic malignancies.\n\nPatients who are uninsured or with Medicaid are more likely to be diagnosed with advanced stage vaginal cancer than those with private insurance. Patients diagnosed at more advanced stages of vaginal cancer tend to have poorer survival outcomes. Studies have revealed that African Americans have a higher likelihood of being diagnosed with advanced stage vaginal cancer and are less likely to survive than their white counterparts.\n\nFor early stage vaginal cancer patients, surgery helps reduce mortality risk. One study revealed how a significantly lower proportion of African Americans with early stage vaginal cancer underwent surgery as compared to whites, which could partially explain differences in survival rates between these groups.\n"}
{"id": "16540346", "url": "https://en.wikipedia.org/wiki?curid=16540346", "title": "Health in Morocco", "text": "Health in Morocco\n\nMorocco became an independent country in 1956. At that time there were only 400 private practitioners and 300 public health physicians in the entire country. By 1992, the government had thoroughly improved their health care service and quality. Health care was made available to over 70% of the population. Programs and courses to teach health and hygiene have been introduced to inform parents and children on how to correctly care for their own and their families' health. \n\nThe first health care policy in Morocco was devised in 1959, with majority of the free healthcare services and management focused on the general public. The State provides funding and administration. The Ministry of Health runs the National Institutes and Laboratories, Basic Care Health Network and the Hospital Network. The Defence Department owns and runs its own hospitals, and local governments run city health services. \n\nThe healthcare system is made up of AMO (Mandatory Health Insurance). AMO is split into two sections: La CNSS (private) and La CNOPS (public). There is also RAMED, a health insurance program designed to support the low socioeconomic population from financial tragedy due to health related issues. \n\nThe Moroccan health care system has four layers, the first being \"primary healthcare\". This includes clinics, health centres and local hospitals for public healthcare, and infirmaries and medical offices for private healthcare. The second section includes provincial and prefectural hospitals for public health, and specialised clinics and offices for private health. The third area includes hospitals in all major cities, and the fourth includes university hospitals. These centres have the most advanced equipment.\n\nAccording to the United States government, Morocco has inadequate numbers of physicians (0.5 per 1,000 people) and hospital beds (1.0 per 1,000 people), and poor access to water (82 percent of the population) and sanitation (75 percent of the population). The health care system includes 122 hospitals, 2,400 health centres, and 4 university clinics, but they are poorly maintained and lack adequate capacity to meet the demand for medical care. Only 24,000 beds are available for 6 million patients seeking care each year, including 3 million emergency cases. The health budget corresponds to 5 percent of the gross domestic product and 5.5 percent of the central government's budget.\n\nIn 2001 the principal causes of mortality in the urban population were circulatory system diseases (20.4 percent); perinatal diseases (9.3 percent); cancer (8.5 percent); endocrinological, nutritional, and metabolic diseases (7.6 percent); respiratory system diseases (6.9 percent); and infectious and parasitic diseases (4.7 percent).\n\nIn 2004 the minister of health announced that the country had eradicated a variety of childhood diseases, specifically diphtheria, polio, tetanus, and malaria, but other diseases continue to pose challenges. According to estimates for 2013, 21,000 people or approximately 0.16 percent of the population between the ages of 15 and 49 was infected with human immunodeficiency virus/acquired immune deficiency syndrome (HIV/AIDS).\n\nUNAIDS (Joint United Nations Programme on HIV/AIDS) have stated that around 270,000 people in the Middle East are currently living with HIV. Research from between 2001 and 2012 has shown that the number of adults and children living with HIV had increased significantly, by 73%. The predominant cause of HIV transmissions is the lack of knowledge and education to help prevent the spread. Treatment services are also lacking significantly in the Middle East to help treat the infection before passing in on. Research has shown that particularly in Morocco, 89% of HIV infections are amongst men having sexual intercourse with other men, female sex workers and people who share contaminated needles. New research is revealing that Morocco's newest HIV infections are amongst females, with three quarters receiving it from their husbands.\n\nAdolescent girls are at a greater risk of becoming obese.\n\nObesity is linked to a greater availability of food, particularly from the West, and an increasingly sedentary lifestyle in urban areas. A woman who has a low level of schooling or no education in urban areas is significantly more likely to be obese. The general public is not aware of the medical conditions that result from obesity. Rather, female fatness is embraced, as it \"is viewed as a sign of social status and is a cultural symbol of beauty, fertility, and prosperity\". Being thin is a sign of sickness or poverty.\n\nBy 2001, 60% of births were taking place in both public and private health facilities, while the rest happened at home. Maternal mortality was 227 per 100,000 live births, and neonatal mortality was 27 per 1000 live births. A national population and family health survey showed that in 2003 the most common barriers in accessibility to emergency care were financial, for 74% of women; the distance to a health facility, for 60%; and transport, for 46%. \n\nIn 2007 the Ministry of Health recognised the problem of maternal and child mortality. This led the ministry to implement the Maternal Mortality Strategy action plan of 2008–12, whose aim was to reduce the maternal mortality rate (MMR) from 227 to 50 deaths per 100,000 births. There were three points of improvement to help them try and achieve their goal. The first was to reduce any barriers preventing women from accessing emergency services. The second was to enhance the health care quality and the third was to improve governance. The Ministry of Health also began the maternal mortality surveillance system. This allowed them to collect and analyse data in 2009 which discovered that the goal of reducing the MMR to 50 would not be achievable by 2015. Because of this information, a new action plan for 2012-16 was introduced to reinforce management and target specific actions for rural and disadvantaged areas.\n\nThe 2010 maternal mortality rate per 100,000 births in Morocco was 110. This is compared with 124 in 2008 and 383.8 in 1990. The under 5 mortality rate is 39 per 1,000 births, and the neonatal mortality as a percentage of under 5s mortality is 54. In Morocco the number of midwives per 1,000 live births is 5 and the lifetime risk of death for pregnant women is 1 in 360.\n\nOver the last 20 years nutrition has significantly changed with rapid changes due to demographic characteristics of the region, speedy urbanisation and social development of steady and significant economic growth. Morocco and the Middle East have the highest amount of excessive dietary energy intake. With a low rate of 4% of poverty prevalence and 19% of child malnutrition, Morocco has an 8% rate of child malnutrition. All these changes have significantly contributed to the dietary and physical activity of individuals living in the Middle East, reflecting changes with nutrition and the prevalence of these changes.\n\n\n"}
{"id": "9629215", "url": "https://en.wikipedia.org/wiki?curid=9629215", "title": "Hugh Mercer Apothecary", "text": "Hugh Mercer Apothecary\n\nHugh Mercer Apothecary was a pharmacy founded by Hugh Mercer in the mid 18th century. Mercer was a doctor who fled Scotland after the Battle of Culloden. He travelled to Pennsylvania, where he met Colonel George Washington during the French and Indian War and later moved to Fredericksburg, Virginia on Washington's advice to practice medicine and operate an Apothecary.\n\nThe building that housed the apothecary has been restored by Preservation Virginia (formerly known as the Association for the Preservation of Virginia Antiquities) to demonstrate 18th Century medical treatments. It also includes a small exhibit on Mercer's life and contributions to the American Revolutionary War.\n\nIn mid-2012, Preservation Virginia signed an agreement passing ownership to the \"Washington Heritage Museums\" group beginning in 2013.\n\nThe museum is located at 1020 Caroline Street in Fredericksburg, Virginia.\n\n"}
{"id": "34838102", "url": "https://en.wikipedia.org/wiki?curid=34838102", "title": "Indian Red Cross Society", "text": "Indian Red Cross Society\n\nThe Junior Red Cross Society (JRC) is a voluntary humanitarian organization to protect human life and health based in India. It is part of the International Red Cross and Red Crescent Movement, and so shares the Fundamental Principles of the International Red Cross and Red Crescent Movement. The society's mission is providing relief in times of disasters/emergencies and promoting health & care of vulnerable people and communities. It has a network of over 700 branches throughout India. The Society uses the Red Cross as an emblem in common with other international Red Cross societies. Volunteering has been at the very heart of the Indian Red Cross Society since its inception in 1920, with the Society having \"Youth\" and \"Junior\" volunteering programs. The Society is closely associated with the St John Ambulance in India.\n\nDuring the First World War relief services for affected soldiers in India was provided by a branch of the \"Joint War Committee\", a collaboration between the St. John Ambulance Association and the British Red Cross. On 3 March 1920 a bill was introduced to the Indian Legislative Council by Sir Claude Hill (a member of the Viceroy's Executive Council who was also Chairman of the Joint War Committee in India) to constitute the Indian Red Cross Society, independent of the British Red Cross. The Bill was passed as the \"Indian Red Cross Society Act, 1920\" on 17 March 1920, and became Parliament Act XV of 1920 with the assent of the Governor General on the 20 March 1920.\n\nOn 7 June 1920 fifty members were formally nominated to constitute the Indian Red Cross Society from members of the Indian branch of the Joint War Committee. The first Managing Body was elected from among them with Sir William Malcolm Hailey as Chairman.\n\nPoW parcels, supplied by the Indian Red Cross Society during WW2 contained:\n\n\nIn 1947 some of the IRCS assets were provided to found the Pakistan Red Crescent Society.\n\nThe act governing the IRCS was last amended by \"The Indian Red Cross Society (Amendment) Bill, 1992\".\n\n\n"}
{"id": "2293587", "url": "https://en.wikipedia.org/wiki?curid=2293587", "title": "International Pharmaceutical Federation", "text": "International Pharmaceutical Federation\n\nThe International Pharmaceutical Federation or Fédération Internationale Pharmaceutique, abbreviated as FIP, is an international federation of national organisations that represent pharmacists and pharmaceutical scientists. It was founded in 1912 and is based in The Hague in the Netherlands.\n\nThe International Pharmaceutical Federation (FIP) is the global federation of national associations of pharmacists and pharmaceutical scientists. It gathers 137 member organisations and represents three million practitioners and scientists around the world. It is a nongovernmental organisation (NGO) in official relations with the World Health Organization. The mission of FIP is to \"improve global health by advancing pharmacy practice and science to enable better discovery, development, access to and safe use of appropriate, cost-effective, quality medicines worldwide.\"\n\nThe Federation was founded on 25 September 1912 in The Hague, the Netherlands. It was the outcome of the series of international pharmaceutical congresses held in the nineteenth century, more specifically the congress held in Brussels in 1885. Following an initiative of the Royal Dutch Pharmaceutical Society in 1909, the 10th international pharmaceutical congress in 1910 in Brussels resolved to establish an international pharmaceutical federation in The Hague. The first president was Prof. Dr, Léopold of Itallie, professor at Leiden University. The first secretary-general was Dr. J.J. Hofman, pharmacist in The Hague.\n\nFIP consists of two boards: the Board of Pharmaceutical Practice and the Board of Pharmaceutical Sciences.\n\nThe FIP Board of Pharmaceutical Practice, which embodies pharmacists, has eight sections, each focusing on specific areas of pharmacy, developing and enhancing professional practice through shared experience. The Sections represent the following areas of pharmacy practice:\n\n\nThe Board of Pharmaceutical Sciences (BPS) is in place within FIP to provide a forum for pharmaceutical scientists to communicate, network, and further develop their expertise and knowledge in their areas of interest. This is accomplished through member participation in special interest groups that focus on specific aspects of pharmaceutical science and research. Targeted specifically to this group is the Pharmaceutical Sciences World Congress, which is held every 4 years in a different location around the world. The most recent was in Melbourne, Australia in 2014.\n\nSpecial interest groups have been formed on the following areas:\n\n\nRole of Board of Pharmaceutical Sciences\nThe role of this Board is to handle all scientific aspects of FIP's activities. To fulfill this task the BPS has developed a Strategic plan with a clear mission, namely to establish and maintain itself as the leading forum for representation of pharmaceutical science throughout the world. The main approaches to accomplish this mission are:\n\n\nThe Foundation's objectives are to promote the education of, and research by pharmacists and pharmaceutical scientists within the general fields of design, manufacture, distribution and use of medicines for humans and/or animals. In order to achieve its objectives the Foundation may undertake any of the following activities:\n\nMaking awards in recognition of excellence; \nMaking grants to support education or research; \nGranting Fellowships to permit a period of research at an approved institution;\nAwarding Scholarships to permit short periods of international travel in order to study the practice of pharmacy or pharmaceutical science in another country or in other countries; \nAll other charitable activities which do not conflict with the aforementioned objectives or the general objectives of the International Pharmaceutical Federation/Fédération Internationale Pharmaceutique (FIP).\n\nThe FIP Foundation for Education and Research was set up in 1993 with a programme of grants and awards. In addition to the Awards in Recognition of Excellence, the FIP Foundation also makes available FIP Development Grants to young pharmacists in training or research, FIP International Travel Scholarships and FIP Fellowships. In 1997 it introduced the Young Poster Presenter's Awards, which are given to a number of people who have submitted abstracts for the FIP Congress, which have been screened and approved by either the scientific or professional secretary.\n\nDonations and other forms of sponsorship are an essential ingredient to the success of the Awards programme and to the FIP Foundation and has set up a FIP Foundation Supporter's Club. It has developed a series of benefit, both individual and corporate, which will attract potential donors/sponsors. There are six categories - Ribbon, Bronze, Silver, Gold, Platinum and Diamond.\n\n\n\n"}
{"id": "48651882", "url": "https://en.wikipedia.org/wiki?curid=48651882", "title": "Keith Martin (heavy person)", "text": "Keith Martin (heavy person)\n\nKeith Martin (1970 – March 2014), one of the World's heaviest living people, was famous at one point for being the UK’s heaviest man, weighing approximately 980 lbs at his peak. Keith Martin was given a gastric bypass operation by the NHS, and had lost over 50% of his body weight.\n\nKeith Martin’s mother had died of pneumonia when he was only 16. Martin had used junk food as a comfort from this traumatic life event, which was the cause of his extreme weight gain.\n\nMartin (much like his mother) had developed pneumonia, and died as a result from it. \n\n"}
{"id": "10414425", "url": "https://en.wikipedia.org/wiki?curid=10414425", "title": "Kenya Cardiac Society", "text": "Kenya Cardiac Society\n\nThe Kenya Cardiac Society (KCS) is a non-governmental, non-profit organization found in Kenya with the aim to promote cardiac health and cardiac-related activities.\n\nFounded by the late Prof. Hillary Ojiambo and Prof. Peter Odhiambo, and eight members of the 1980 Kenyatta National Hospital Cardiac team, the society has since grown and is now a member of the World Heart Federation with more than 60 members.\n\nKCS is best known for its collaborative program with Mater Hospital and the Heart Walk held every September.\n\n"}
{"id": "6427165", "url": "https://en.wikipedia.org/wiki?curid=6427165", "title": "List of United Nations Security Council Resolutions 1701 to 1800", "text": "List of United Nations Security Council Resolutions 1701 to 1800\n\nThis is a list of United Nations Security Council Resolutions 1701 to 1800 adopted between 11 August 2006 and 20 February 2008.\n"}
{"id": "42093961", "url": "https://en.wikipedia.org/wiki?curid=42093961", "title": "Marihuana for Medical Purposes Regulations", "text": "Marihuana for Medical Purposes Regulations\n\nThe Marihuana for Medical Purposes Regulations (MMPR) was a set of Canadian regulations enacted in July 2013 concerning the production, distribution and use of medical cannabis (also known as \"marihuana\"). Portions of the law become effective on October 1, 2013, March 31, 2014 and March 31, 2015. The law was struck down as unconstitutional by the Federal Courts due to the inability for patients to grow their own medicine. The new act put forward is the Access to Cannabis for Medical Purposes Regulations (ACMPR).\n\nThe MMPR program replaces the Marihuana Medical Access Regulations (MMAR), which were enacted in July 2001. Prior to a federal injunction, the MMAR program was to end on March 31, 2014. The MMAR program was intended to clearly define the circumstances and the manner in which access to marihuana for medical purposes would be permitted. It contained three main components: authorizations to possess dried marihuana; licences to produce marihuana, which include Personal-Use Production Licences and Designated-Person Production Licences; and access to supply of marihuana seeds or dried marihuana.\n\nThe MMPR was introduced in response to concerns from stakeholders that the MMAR was open to abuse. The MMPR treats marihuana as much as possible like any other narcotic used for medical purposes by creating conditions for a new, commercial industry that is responsible for its production and distribution. According to Health Canada, the regulations \"will provide access to quality-controlled marihuana for medical purposes, produced under secure and sanitary conditions, to those Canadians who need it, while strengthening the safety of Canadian communities. In addition, the new regulations will also enable more choices of marihuana strains and licensed, commercial suppliers.\"\n\nUnder the MMPR, Health Canada maintains a list of authorized licensed producers of medical marihuana. While the MMPR originally only contemplated the sale of dried marihuana, recent amendments allow patients to turn their marihuana into products such as edibles and cannabis oil.\n\nThe transition from the MMAR to the MMPR program represents a substantial change in direction for the supply and acquisition of medical marihuana in Canada. It has not gone without controversy. The MMAR DPL/PPL Coalition Against Repeal is a coalition of over 6,000 members fighting for the preservation of the MMAR. An exemption was granted by a Federal Court Judge in British Columbia and permits clients who had a valid authorization to possess and/or a production license as of March 21, 2014 to continue to grow until the outcome of a Constitutional Challenge Trial that started in February 2015. In August 2016, Health Canada announced the Access to Cannabis for Medical Purposes Regulations (ACMPR) to replace MMPR. The new program incorporates the MMPR with a new personal cultivation regime similar to the former Marihuana Medical Access Regulations (MMAR). \n"}
{"id": "49985241", "url": "https://en.wikipedia.org/wiki?curid=49985241", "title": "Medical Research Future Fund", "text": "Medical Research Future Fund\n\nThe Medical Research Future Fund (MRFF) is a research fund established in Australia by the Abbott Government. It is managed by the Future Fund, with interest generated going to medical research.\n\nIn the Australian federal budget, 2014 Treasurer Joe Hockey announced the Liberal-National Abbott Government's commitment to build a $20 billion Medical Research Future Fund, in addition to existing funding through the National Health and Medical Research Council. Hockey predicted that the fund would, \"within six years, be the biggest medical research endowment fund in the world\" and announced that \"all the savings from the introduction of a $7 Medicare co-contribution, modest changes to the Pharmaceutical Benefits Scheme and other responsible changes in this Health Budget\" would be directed to the fund until it reaches $20 billion.\n\nThe Senate blocked passage of the medical co-payment, but approved the establishment of the Medical Research Future Fund in August 2015, with funding to be found through reduced health spending and the Health and Hospitals Fund, until a balance of $20bn is reached in 2020. The Fund is managed by the Future Fund, with interest generated going to medical research, beginning with $10 million in 2015, growing to $390m over the following three years.\n\nAnnouncing the Fund proposal to Parliament on 13 May, 2014, Joe Hockey said:\n\n\n"}
{"id": "2407129", "url": "https://en.wikipedia.org/wiki?curid=2407129", "title": "Medical education", "text": "Medical education\n\nMedical education is education related to the practice of being a medical practitioner; either the initial training to become a physician (i.e., medical school and internship), or additional training thereafter (e.g., residency, fellowship and continuing medical education).\n\nMedical education and training varies considerably across the world. Various teaching methodologies have been utilised in medical education, which is an active area of educational research.\n\nEntry-level medical education programs are tertiary-level courses undertaken at a medical school. Depending on jurisdiction and university, these may be either undergraduate-entry (most of Europe, Asia, South America and Oceania), or graduate-entry programs (mainly Australia, North America). Some jurisdictions and universities provide both undergraduate entry programs and graduate entry programs (Australia, South Korea).\n\nIn general, initial training is taken at medical school. Traditionally initial medical education is divided between \"preclinical\" and \"clinical\" studies. The former consists of the basic sciences such as anatomy, physiology, biochemistry, pharmacology, pathology. The latter consists of teaching in the various areas of clinical medicine such as internal medicine, pediatrics, obstetrics and gynecology, psychiatry, general practice and surgery. However, medical programs are using systems-based curricula in which learning is integrated, and several institutions do this. In the United States, until quite recently, the requirements for the M.D. degree did not include even one course in human nutrition. Today, this omission has been rectified, at least to the extent that one such course is required.\n\nThere has been a proliferation of programmes that combine medical training with research (M.D./Ph.D.) or management programmes (M.D./ MBA), although this has been criticised because extended interruption to clinical study has been shown to have a detrimental effect on ultimate clinical knowledge.\n\nFollowing completion of entry-level training, newly graduated doctors are often required to undertake a period of supervised practice before full registration is granted; this is most often of one-year duration and may be referred to as an \"internship\" or \"provisional registration\" or \"residency\".\n\nFurther training in a particular field of medicine may be undertaken. In the U.S., further specialized training, completed after residency is referred to as \"fellowship\". In some jurisdictions, this is commenced immediately following completion of entry-level training, while other jurisdictions require junior doctors to undertake generalist (unstreamed) training for a number of years before commencing specialisation.\n\nEducation theory itself is becoming an integral part of postgraduate medical training. Formal qualifications in education are also becoming the norm for medical educators, such that there has been a rapid increase in the number of available graduate programs in medical education.\n\nIn most countries, continuing medical education (CME) courses are required for continued licensing. CME requirements vary by state and by country. In the USA, accreditation is overseen by the Accreditation Council for Continuing Medical Education (ACCME). Physicians often attend dedicated lectures, grand rounds, conferences, and performance improvement activities in order to fulfill their requirements. Additionally, physicians are increasingly opting to pursue further graduate-level training in the formal study of medical education as a pathway for continuing professional development.\n\nMedical education is increasingly utilizing online teaching, usually within learning management systems (LMSs) or virtual learning environments (VLEs). Additionally, several medical schools have incorporated the use of blended learning combining the use of video and in-person exercises. A landmark scoping review published in 2018 demonstrated that online teaching modalities are becoming increasingly prevalent in medical education, with associated high student satisfaction and improvement on knowledge tests. However, the use of evidence-based multimedia design principles in the development of online lectures was seldom reported, despite their known effectiveness in medical student contexts.\n\nResearch areas into online medical education include practical applications, including simulated patients and virtual medical records. When compared to no intervention, simulation in medical education\ntraining is associated with positive effects on knowledge, skills, and behaviors and moderate effects for patient outcomes.\n\nAt present, in the United Kingdom, a typical medicine course at university is 5 years or 4 years if the student already holds a degree. Among some institutions and for some students, it may be 6 years (including the selection of an intercalated BSc—taking one year—at some point after the pre-clinical studies). All programs culminate in the Bachelor of Medicine and Surgery degree (abbreviated MBChB, MBBS, MBBCh, BM, etc.). This is followed by 2 clinical foundation years afterward, namely F1 and F2, similar to internship training. Students register with the UK General Medical Council at the end of F1. At the end of F2, they may pursue further years of study. The system in Australia is very similar, with registration by the Australian Medical Council (AMC).\n\nIn the US and Canada, a potential medical student must first complete an undergraduate degree in any subject before applying to a graduate medical school to pursue an (M.D. or D.O.) program. U.S. medical schools are almost all four-year programs. Some students opt for the research-focused M.D./Ph.D. dual degree program, which is usually completed in 7–10 years. There are certain courses that are pre-requisite for being accepted to medical school, such as general chemistry, organic chemistry, physics, mathematics, biology, English, labwork, etc. The specific requirements vary by school.\n\nIn Australia, there are two pathways to a medical degree. Students can choose to take a five- or six-year undergraduate medical degree Bachelor of Medicine/Bachelor of Surgery (MBBS or BMed) as a first tertiary degree directly after secondary school graduation, or first complete a bachelor's degree (in general three years, usually in the medical sciences) and then apply for a four-year graduate entry Bachelor of Medicine/Bachelor of Surgery (MBBS) program. \n\nSee:\n\n\nAs medical professional stakeholders in the field of health care (i.e. entities integrally involved in the health care system and affected by reform), the practice of medicine (i.e. diagnosing, treating, and monitoring disease) is directly affected by the ongoing changes in both national and local health policy and economics.\n\nThere is a growing call for health professional training programs to not only adopt more rigorous health policy education and leadership training, but to apply a broader lens to the concept of teaching and implementing health policy through health equity and social disparities that largely affect health and patient outcomes. Increased mortality and morbidity rates occur from birth to age 75, attributed to \"medical care\" (insurance access, quality of care), \"individual behavior\" (smoking, diet, exercise, drugs, risky behavior), \"socioeconomic and demographic factors\" (poverty, inequality, racial disparities, segregation), and \"physical environment\" (housing, education, transportation, urban planning). A country’s health care delivery system reflects its “underlying values, tolerances, expectations, and cultures of the societies they serve”, and medical professionals stand in a unique position to influence opinion and policy of patients, healthcare administrators, & lawmakers.\n\nOne 2010 survey of U.S. medical school deans of education regarding health policy education initiatives found that of the 160 accredited M.D. and D.O schools surveyed, 58% responded to report that while 94% of them had \"some form\" of policy education, 74% required that education and only 24% had courses directly on the topic of health policy. 58% reported room for improvement, while 52% were currently in the processing of adapting their policy curriculums. Still, the average amount of time spent with health policy instruction was only 14 hours (SD 12 hours) over the four years of medical school training.\n\nIn order to truly integrate health policy matters into physician and medical education, training should begin as early as possible – ideally during medical school or premedical coursework – to build “foundational knowledge and analytical skills” continued during residency and reinforced throughout clinical practice, like any other core skill or competency. This source further recommends adopting a national standardized core health policy curriculum for medical schools and residencies in order to introduce a core foundation in this much needed area, focusing on four main domains of health care: (1) \"systems and principles\" (e.g. financing; payment; models of management; information technology; physician workforce), (2) \"quality and safety\" (e.g. quality improvement indicators, measures, and outcomes; patient safety), (3) \"value and equity\" (e.g. medical economics, medical decision making, comparative effectiveness, health disparities), and (4) \"politics and law\" (e.g. history and consequences of major legislations; adverse events, medical errors, and malpractice).\n\nHowever limitations to implementing these health policy courses mainly include perceived time constraints from scheduling conflicts, the need for an interdisciplinary faculty team, and lack of research / funding to determine what curriculum design may best suit the program goals. Resistance in one pilot program was seen from program directors who did not see the relevance of the elective course and who were bounded by program training requirements limited by scheduling conflicts and inadequate time for non-clinical activities. But for students in one medical school study, those taught higher-intensity curriculum (vs lower-intensity) were “three to four times as likely to perceive themselves as appropriately trained in components of health care systems”, and felt it did not take away from getting poorer training in other areas. Additionally, recruiting and retaining a diverse set of multidisciplinary instructors and policy or economic experts with sufficient knowledge and training may be limited at community-based programs or schools without health policy or public health departments or graduate programs. Remedies may include having online courses, off-site trips to the capitol or health foundations, or dedicated externships, but these have interactive, cost, and time constraints as well. Despite these limitations, several programs in both medical school and residency training have been pioneered.\n\nLastly, more national support and research will be needed to not only establish these programs, but to evaluate how to both standardize and innovate the curriculum in a way that is flexible with the changing health care and policy landscape. In the United States, this will involve coordination with the ACGME (Accrediting Council for Graduate Medical Education), a private NPO that sets educational and training standards for U.S. residencies and fellowships that determines funding and ability to operate.\n\n\n"}
{"id": "797848", "url": "https://en.wikipedia.org/wiki?curid=797848", "title": "Medical savings account", "text": "Medical savings account\n\nA medical savings account (MSA) is an account into which tax-deferred amounts from income can be deposited. The amounts are often called contributions and may be made by a worker, an employer, or both, depending on a country's laws.\n\nThe money in such accounts is to be used to pay for medical expenses. Withdrawals from the account often called distributions, if made for that reason, may or may not be subject to income tax. Withdrawals without adequate documentation of use for medical expenses are subject to penalties.\n\nIn December 1994, the China began a pilot study of medical savings accounts in the cities of Zhenjiang and Jiujiang. China has planned to expand the program.\n\nMedisave (Chinese: 保健储蓄) was introduced in April 1984 as a national medical savings system in Singapore. It allows Singaporeans to put aside part of their income into a Medisave account to meet future personal or immediate family's hospitalization, day surgery and for certain outpatient expenses.\n\nUnder this system, Singaporean employees contributes 6–8% (depending on age group) of their monthly salaries to a personal Medisave account. The savings can be withdrawn to pay the hospital bills of the account holder and immediate family members.\n\nThe United States has two medical savings account programs:\n\n"}
{"id": "40715397", "url": "https://en.wikipedia.org/wiki?curid=40715397", "title": "Motor disorder", "text": "Motor disorder\n\nMotor disorders are disorders of the nervous system that cause abnormal and involuntary movements. They can result from damage to the motor system.\n\nMotor disorders are defined in the fifth edition of the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM-5) – published in 2013 to replace the fourth text revision (DSM-IV-TR) – as a new sub-category of neurodevelopmental disorders. The DSM-5 motor disorders include developmental coordination disorder, stereotypic movement disorder, and the tic disorders including Tourette syndrome.\n\nMotor disorders are malfunctions of the nervous system that cause involuntary or uncontrollable movements or actions of the body. These disorders can cause lack of intended movement or an excess of involuntary movement. Symptoms of motor disorders include tremors, jerks, twitches, spasms, contractions, or gait problems.\n\nTremor is the uncontrollable shaking of an arm or a leg. Twitches or jerks of body parts may occur due to a startling sound or unexpected, sudden pain. Spasms and contractions are temporary abnormal resting positions of hands or feet. Spasms are temporary while contractions could be permanent. Gait problems are problems with the way one walks or runs. This can mean an unsteady pace or dragging of the feet along with other possible irregularities.\n\nPathological changes of certain areas of the brain are the main causes of most motor disorders. Causes of motor disorders by genetic mutation usually affect the cerebrum. The way humans move requires many parts of the brain to work together to perform a complex process. The brain must send signals to the muscles instructing them to perform a certain action. There are constant signals being sent to and from the brain and the muscles that regulate the details of the movement such as speed and direction, so when a certain part of the brain malfunctions, the signals can be incorrect or uncontrollable causing involuntary or uncontrollable actions or movements.\n"}
{"id": "8223772", "url": "https://en.wikipedia.org/wiki?curid=8223772", "title": "NASU Institute of Cryobiology and Cryomedicine Issues", "text": "NASU Institute of Cryobiology and Cryomedicine Issues\n\nThe Institute for Problems of Cryobiology and Cryomedicine in Kharkiv is one of the institutes of the National Academy of Science of Ukraine, and is the largest institute devoted to cryobiology research in the world. Established in 1972, the focus of the research is on cryoinjury, cryosurgery, cryopreservation, lyophilization and hypothermia. The Institute publishes the peer-reviewed scientific journal \"Problems of Cryobiology and Cryomedicine\".\n\n\n\n"}
{"id": "26229805", "url": "https://en.wikipedia.org/wiki?curid=26229805", "title": "Pakistan Nursing Council", "text": "Pakistan Nursing Council\n\nThe Pakistan Nursing Council (PNC) is a regulatory body established in 1948 by the Pakistan Nursing Council Act (1952, 1973). PNC is empowered to license nurses, midwives, lady health visitors (LHVs) and nursing auxiliaries to practice throughout the country.\n\nNursing in Pakistan\n\nPNC official website\n"}
{"id": "192605", "url": "https://en.wikipedia.org/wiki?curid=192605", "title": "Pharmacist", "text": "Pharmacist\n\nPharmacists, also known as chemists (Commonwealth English) or druggists (North American and, archaically, Commonwealth English), are health professionals who practice in pharmacy, the field of health sciences focusing on safe and effective medication use. A pharmacist is a member of the health care team directly involved with patient care. Pharmacists undergo university-level education to understand the biochemical mechanisms and actions of drugs, drug uses, therapeutic roles, side effects, potential drug interactions, and monitoring parameters. This is mated to anatomy, physiology, and pathophysiology. Pharmacists interpret and communicate this specialized knowledge to patients, physicians, and other health care providers.\n\nAmong other licensing requirements, different countries require pharmacists to hold either a Bachelor of Pharmacy, Master of Pharmacy, or Doctor of Pharmacy degree.\n\nThe most common pharmacist positions are that of a \"community pharmacist\" (also referred to as a \"retail pharmacist\", \"first-line pharmacist\" or \"dispensing chemist\"), or a \"hospital pharmacist\", where they instruct and counsel on the proper use and adverse effects of medically prescribed drugs and medicines. In most countries, the profession is subject to professional regulation. Depending on the legal scope of practice, pharmacists may contribute to prescribing (also referred to as \"pharmacist prescriber\") and administering certain medications (e.g., immunizations) in some jurisdictions. Pharmacists may also practice in a variety of other settings, including industry, wholesaling, research, academia, military, and government.\n\nHistorically, the fundamental role of pharmacists as a healthcare practitioner was to check and distribute drugs to doctors for medication that had been prescribed to patients. In more modern times, pharmacists advise patients and health care providers on the selection, dosages, interactions, and side effects of medications, and act as a learned intermediary between a prescriber and a patient. Pharmacists monitor the health and progress of patients to ensure the safe and effective use of medication. Pharmacists may practice compounding; however, many medicines are now produced by pharmaceutical companies in a standard dosage and drug delivery form. In some jurisdictions, pharmacists have prescriptive authority to either independently prescribe under their own authority or in collaboration with a primary care physician through an agreed upon protocol called a collaborative practice agreement.\n\nIncreased numbers of drug therapies, ageing but more knowledgeable and demanding populations, and deficiencies in other areas of the health care system seem to be driving increased demand for the clinical counselling skills of the pharmacist. One of the most important roles that pharmacists are currently taking on is one of pharmaceutical care. Pharmaceutical care involves taking direct responsibility for patients and their disease states, medications, and management of each to improve outcomes. Pharmaceutical care has many benefits that may include but are not limited to: decreased medication errors; increased patient compliance in medication regimen; better chronic disease state management, including hypertension and other cardiovascular disease risk factors; strong pharmacist–patient relationship; and decreased long-term costs of medical care.\n\nPharmacists are often the first point-of-contact for patients with health inquiries. Thus pharmacists have a significant role in assessing medication management in patients, and in referring patients to physicians. These roles may include, but are not limited to:\n\nThe role of pharmacy education, pharmacist licensing, and continuing education vary from country to country and between regions/localities within countries. In most countries, pharmacists must obtain a university degree at a pharmacy school or related institution, and/or satisfy other national/local credentialing requirements. In many contexts, students must first complete pre-professional (undergraduate) coursework, followed by about four years of professional academic studies to obtain a degree in pharmacy (such as Doctorate of Pharmacy). Pharmacists are educated in pharmacology, pharmacognosy, chemistry, organic chemistry, biochemistry, pharmaceutical chemistry, microbiology, pharmacy practice (including drug interactions, medicine monitoring, medication management), pharmaceutics, pharmacy law, physiology, anatomy, pharmacokinetics, pharmacodynamics, drug delivery, pharmaceutical care, nephrology, hepatology, and compounding of medications. Additional curriculum may cover diagnosis with emphasis on laboratory tests, disease state management, therapeutics and prescribing (selecting the most appropriate medication for a given patient).\n\nOn graduation, pharmacists are licensed, either nationally or regionally, to dispense medication of various types in the areas they have trained for. Some may undergo further specialized training, such as in cardiology or oncology.\n\nSpecialties include:\n\nThe Ministry of Education and Ministry of Health oversee pharmacy school accreditation in Armenia. Pharmacists are expected to have competency in the WHO Model List of Essential Medicines (EML), the use of Standard Treatment Guidelines, drug information, clinical pharmacy, and medicine supply management. There are currently no laws requiring pharmacists to be registered, but all pharmacies must have a license to conduct business. According to a World Health Organization (WHO) report from 2010, there are 0.53 licensed pharmacists and 7.82 licensed pharmacies per 10,000 people in Armenia. Pharmacists are able to substitute for generic equivalents at point of dispensing.\n\nThe Australian Pharmacy Council is the independent accreditation agency for Australian pharmacists. It conducts examinations on behalf of the Pharmacy Board of Australia towards eligibility for registration. The Australian College of Pharmacy provides continuing education programs for pharmacists.\n\nWages for pharmacists in Australia appear to have stagnated. The award wages for a pharmacist is $812 a week. Pharmacist graduates are the lowest paid university graduates most years. Most pharmacists do earn above the award wage; the average male pharmacist earns $65,000, a female pharmacist averages $56,500. Over recent years, wages have stagnated, and even gone backwards. There are more graduates expected in the next few years making it even harder to get a job. Job security and increase in wages with regards to CPI could be unlikely. This is due to the large numbers of pharmacy graduates in recent years, and government desire to lower PBS costs. Contract and casual work is becoming more common. A contract pharmacist is self-employed and often called a locum; these pharmacists may be hired for one shift or for a longer period of time. There are accounts of underemployment and unemployment emerging recently.\n\nThe Canadian Pharmacists Association (CPhA) is the national professional organization for pharmacists in Canada. Specific requirements for practice vary across provinces, but generally include a Bachelor of Science in Pharmacy from a recognized university, successful completion of a national board examination through the Pharmacy Examining Board of Canada, and practical experience through an apprenticeship/internship program.\n\nThe vast majority (80%) of Canada's licensed pharmacists work in community pharmacies, another 15 percent in hospital or institutional pharmacies, and the remainder work in situations that may not legally require licensed pharmacists such as associations, pharmaceutical companies, and consulting firms. The wages for pharmacists, at about CAD $95,000, have been said to be slightly better than Australia but not as good as in the USA. This likely depends on what parts of Canada and or the USA are compared. Wages being significantly higher in Canada than the prospect for most developing countries, recruitment of pharmacists from South Africa and other countries with acute health workforce shortages to work in private franchise chains is subject to controversy.\n\nA pharmacist must be registered with the College of Pharmacists of British Columbia to practice in this province. A Bachelor of Science in Pharmaceutical Sciences is the minimum requirement to practice as a pharmacist in BC. The University of British Columbia is the only institution in the province that trains pharmacists. Professional associations include the College of Pharmacists of British Columbia and the British Columbia Pharmacy Association.\nThe University of Alberta is the only institution in the province awarding pharmacy degrees, offering both Bachelor of Pharmacy and Doctor of Pharmacy programs. Pharmacists must be registered with the Alberta College of Pharmacists in order to practice in Alberta.\n\nThe Ontario College of Pharmacists grants licenses to practise as a Pharmacist in the province of Ontario. International graduates of pharmacy must successfully complete the Pharmacist Evaluating Exam and Pharmacist Qualifying Exam along with a Studentship and Internship to be registered as a Pharmacist in Ontario. Canadian graduates of the pharmacy programme can sit the qualifying exam directly without the evaluating exam.\n\nIn Germany, the education and training is divided into three sections, each ending with a state examination:\nAfter the third state examination a person must become licensed as an RPh (\"registered pharmacist\") for a licence to practice pharmacy. \nToday, many pharmacists work as employees in public pharmacies. They will be paid according to the labour agreement of Adexa and employer associations.\n\nIn ancient Japan, the men who fulfilled roles similar to pharmacists were respected. The place of pharmacists in society was settled in the Taihō Code (701) and re-stated in the Yōrō Code (718). Ranked positions in the pre-Heian Imperial court were established; and this organizational structure remained largely intact until the Meiji Restoration (1868). In this highly stable hierarchy, the pharmacists — and even pharmacist assistants — were assigned status superior to all others in health-related fields such as physicians and acupuncturists. In the Imperial household, the pharmacist was even ranked above the two personal physicians of the Emperor.\n\nAs of 1997, 46 universities of pharmacy in Japan graduated about 8000 students annually. Contemporary practice of clinical pharmacists in Japan (as evaluated in September 2000) focuses on dispensing of drugs, consultation with patients, supplying drug information, advising on prescription changes and amending prescriptions. These practices have been linked to decreases in the average number of drugs in prescriptions, drug costs and incidence of adverse drug events.\n\nTraining to become a registered pharmacist in Nigeria involves a five-year course after six years of secondary/high school or four years after eight years of secondary/high school (i.e. after 2 years of Advanced-level studies in accredited Universities). The degree awarded by most pharmacy schools is a Bachelor of Pharmacy Degree (B.Pharm.) However, in the near future, all schools will offer a 6-year first Degree course leading to the award of a Pharm.D (Doctor of Pharmacy Degree). The University of Benin has started the Pharm.D programme with other pharmacy schools planning to start soon. The Pharmacy Degree in Nigeria is unclassified i.e. awarded without first class, second class upper, etc., however graduates could be awarded Pass with Distinctions in specific fields such as Pharmaceutics, Pharmacology, medicinal chemistry etc. Pharmacy Graduates are required to undergo 1 year of Tutelage under the supervision of an already Registered Pharmacist(a preceptor) in a recognized and designated Institution before they can become Registered Pharmacists. The Profession is Regulated by a Government Statutory body called the Pharmacists Council of Nigeria. The West African Post Graduate College of Pharmacy runs post-registration courses on advanced-level practice in various fields of pharmacy. It is a college jointly funded by a number of Countries in the West Africa sub-region. There are thousands of Nigerian-trained pharmacists registered and practicing in countries such as the US, the UK, Canada etc., due to the relatively poor public sector salaries in Nigeria.\n\nIn Pakistan, the Pharm.D. (Doctor of Pharmacy) degree is a graduate-level professional doctorate degree. Twenty-one universities are registered with the Pharmacy Council of Pakistan for imparting Pharmacy courses. In 2004 the Higher Education Commission of Pakistan and the Pharmacy Council of Pakistan revised the syllabus and changed the 4-year B.Pharmacy (Bachelor of Pharmacy) Program to a 5-year Pharm.D. (Doctor of Pharmacy) program. All 21 universities have started the 5-year Pharm.D Program. In 2011 the Pharmacy Council of Pakistan approved the awarding of a Doctor of Pharmacy degree, a five-year programme at the Department of Pharmacy, University of Peshawar.\n\nPolish pharmacists have to complete a 5-and-a-half-years Master of Pharmacy Programme at medical university and obtain the Right to Practice as a Pharmacist in Poland from District Pharmaceutical Council. The Programme includes 6-months pharmacy training. The Polish name for the Master of Pharmacy Degree (M. Pharm.) is \"magister farmacji\" (mgr farm). Not only pharmacists, but also pharmaceutical technicians are allowed to dispense prescription medicines, except for narcotics, psychotropics and very potent medicines. Pharmacists approve prescriptions fulfilled by pharmaceutical technicians subsequently. Pharmaceutical technicians have to complete 2-years post-secondary occupational school and 2-years pharmacy training afterwards. Pharmacists are eligible to prescribe medicines in exceptional circumstances. All Polish pharmacies are obliged to produce compound medicines. Most pharmacists in Poland are pharmacy managers and are responsible for pharmacy marketing in addition to traditional activities. To become a pharmacy manager in Poland, a pharmacist is expected to have at least 5-years professional experience. All pharmacists in Poland have to maintain an adequate knowledge level by participating in various university- and industry-based courses and arrangements or by undergoing postgraduate specialization.\n\nIn Sweden, the national board of health and welfare regulates the practice of all legislated health care professionals, and is also responsible for registration of pharmacists in the country. The education to become a licensed pharmacist is regulated by the European Union, and states that minimum educational requirements are five years of university studies in a pharmacy program, of which six months must be a pharmacy internship. To be admitted to pharmacy studies, students must complete a minimum of three years of gymnasium, similar to high school (school for about 15–20-year-old students) program in natural science after elementary school (6–16-year-olds). Only three universities in the whole of Sweden offer a pharmacy education, Uppsala University, where the Faculty of Pharmacy is located, the University of Gothenburg, and Umeå University. In Sweden, pharmacists are called \"Apotekare\". At pharmacies in Sweden, pharmacists work together with another class of legislated health care professionals called \"Receptarier\", in English so-called \"prescriptionists\", who have completed studies equal to a bachelor of science in pharmacy, i.e., three years of university. Prescriptionists also have dispensing rights in Sweden, Norway, Finland and Iceland. The majority of the staff in a pharmacy are \"Apotekstekniker\" or \"pharmacy technicians\" with a 3 semesters education at a vocational college.\n\nIn Switzerland, the federal office of public health regulates pharmacy practice. Four Swiss universities offer a major in pharmaceutical studies, the University of Basel, the University of Geneva, the University of Lausanne and the ETH Zurich. To major in pharmaceutical studies takes at least five years. Students spend their last year as interns in a pharmacy combined with courses at the university, with focus on the validation of prescriptions and the manufacturing of pharmaceutical formulations. Since all public health professions are regulated by the government it is also necessary to acquire a federal diploma in order to work in a pharmacy. It is not unusual for pharmaceutical studies majors to work in other fields such as the pharmaceutical industry or in hospitals. Pharmacists work alongside \"pharma assistants\", an apprenticeship that takes three years to complete. Pharmacists can further specialise in various fields, which is organized by PharmaSuisse the pharmacists association of Switzerland.\n\nIn Tanzania, pharmacy practice is regulated by the national Pharmacy Board, which is also responsible for registration of pharmacists in the country. By international standards, the density of pharmacists is very low, with a mean of 0.18 per 10,000 population. The majority of pharmacists are found in urban areas, with some underserved regions having only 2 pharmacists per region. According to 2007–2009 data, the largest group of pharmacists was employed in the public sector (44%). Those working in private retail pharmacies were 23%, and the rest were mostly working for private wholesalers, pharmaceutical manufacturers, in academia/teaching, or with faith-based or non-governmental facilities. The salaries of pharmacists varied significantly depending on the place of work. Those who worked in the academia were the highest paid followed by those who worked in the multilateral non-governmental organizations. The public sector including public retail pharmacies and faith based organizations paid much less. The Ministry of Health salary scale for medical doctors was considerably higher than that of pharmacists despite having a difference of only one year of training.\n\nIn the United Kingdom, most pharmacists working in the National Health Service practice in hospital pharmacy or community pharmacy. Pharmacists can undertake additional training to allow them to prescribe medicines for specific conditions. The Royal Commission on the National Health Service in 1979 reported that there were nearly 3,000 pharmacists employed in the hospital and community health service in the UK at that time. They were enthusiastic about the idea that pharmacists might develop their role of giving advice to the public.\n\nIn British English (and to some extent Australian English), the professional title known as \"pharmacist\" is also known as \"dispensing chemist\" or, more commonly, \"chemist\". A dispensing chemist usually operates from a pharmacy or chemist's shop, and is allowed to fulfil medical prescriptions and sell over-the-counter drugs and other health-related goods.\n\nThe new professional role for pharmacist as prescriber has been recognized in the UK since May 2006, called the \"Pharmacist Independent Prescriber\". Once qualified, a pharmacist independent prescriber can prescribe any licensed medicine for any medical condition within their competence. This includes controlled drugs except schedule 1 and prescribing certain drugs for the treatment of addiction (cocaine, heroin and dipipanone).\n\nPharmacists, pharmacy technicians and pharmacy premises in the United Kingdom are regulated by the General Pharmaceutical Council (GPhC) for England, Scotland and Wales and by the Pharmaceutical Society of Northern Ireland for Northern Ireland. The role of regulatory and professional body on the mainland was previously carried out by the Royal Pharmaceutical Society of Great Britain, which remained as a professional body after handing over the regulatory role to the GPhC in 2010.\n\nThe following criteria must be met for qualification as a pharmacist in the United Kingdom (the Northern Irish body and the GPhC operate separately but have broadly similar registration requirements):\n\nIn 2014 the United States Bureau of Labor Statistics revealed that there were 297,100 American pharmacist jobs. By 2024 that number is projected to grow by 3%. The majority (65%) of those pharmacists work in retail settings, mostly as salaried employees but some as self-employed owners. About 22% work in hospitals, and the rest mainly in mail-order or Internet pharmacies, pharmaceutical wholesalers, practises of physicians, and the Federal Government.\n\nAll graduating pharmacists must now obtain the Doctor of Pharmacy (Pharm.D.) degree before they are eligible to sit for the North American Pharmacist Licensure Examination (NAPLEX) to enter into pharmacy practice.\n\nThe Accreditation Council for Pharmacy Education (ACPE) was founded in 1932 as the accrediting body for schools of pharmacy in the United States. The mission of ACPE is “To assure and advance excellence in education for the profession of pharmacy.” \nACPE is recognized for the accreditation of professional degree programs by the United States Department of Education (USDE) and the Council for Higher Education Accreditation (CHEA). Since 1975, ACPE has also been the accrediting body for continuing pharmacy education. The ACPE board of directors are appointed by the American Association of Colleges of Pharmacy (AACP), the American Pharmacists Association (APhA), the National Association of Boards of Pharmacy (NABP) (three appointments each), and the American Council on Education (one appointment). To obtain licensure in the United States, applicants for the North American Pharmacist Licensure Examination (NAPLEX) must graduate from an ACPE accredited school of pharmacy. ACPE publishes standards that schools of pharmacy must comply with to gain accreditation.\nA Pharmacy school pursuing accreditation must first apply and be granted Pre-candidate status. These schools have met all the requirements for accreditation, but have not yet enrolled any students. This status indicates that the school of pharmacy has developed its program in accordance with the ACPE standards and guidelines. Once a school has enrolled students, but has not yet had a graduating class, they may be granted Candidate status. The expectations of a Candidate program are that they continue to mature in accordance with stated plans. The graduates of a Candidate program are the same as those of fully accredited programs. Full accreditation is granted to a program once they have demonstrated they comply with the standards set forth by ACPE.\nThe customary review cycle for established accredited programs is six years, whereas for programs achieving their initial accreditation this cycle is two years. These are comprehensive on-site evaluations of the programs. Additional evaluations may be conducted at the discretion of ACPE in the interim between comprehensive evaluations.\n\nAcceptance into a doctorate of pharmacy program depends upon completing specific prerequisites or obtaining a transferable bachelor's degree. Pharmacy school is four years of graduate school (accelerated Pharmacy Schools go January to January and are only 3 years), which include at least one year of practical experience. Graduates receive a Doctorate of Pharmacy (PharmD) upon graduation. Most schools require students to take a Pharmacy College Admissions Test PCAT and complete 90 credit hours of university coursework in the sciences, mathematics, composition, and humanities before entry into the PharmD program. Due to the large admittance requirements and highly competitive nature of the field, most pharmacy students complete a bachelor's degree before entry to pharmacy school.\n\nPossible prerequisites:\n\nBesides taking classes, additional requirements before graduating may include a certain number of hours for community service, e.g., working in hospitals, clinics, and retail.\n\nEstimated timeline: 4 years undergraduate + 4 years doctorate + 1–2 years residency + 1–3 years fellowship = 8–13 years\n\nA doctorate of pharmacy (except non-traditional, i.e. transferring a license from another country) is the only degree accepted by the National Associate of Boards of Pharmacy NABP to be eligible to \"sit\" for the North American Pharmacist Licensure Examination (NAPLEX). Previously the United States had a 5-year bachelor's degree in pharmacy. For BS Pharmacy graduates currently licensed in US, there are 10 Universities offering non-traditional doctorate degree programs via part-time, weekend or on-line programs. These are programs fully accredited by Accreditation Council for Pharmacy Education (ACPE) but only available to current BS Pharmacy graduates with a license to practice pharmacy. Some institutions still offer 6 year accelerated PharmD programs (similar to 6 year MD programs), though in both cases the issuance of a doctoral degree in less than 8 years is controversial.\n\nThe current Pharm.D. degree curriculum is considerably different from that of the prior BS in pharmacy. It now includes extensive didactic clinical preparation, a full year of hands-on practice experience in a wider array of healthcare settings, and a greater emphasis on clinical pharmacy practice pertaining to pharmacotherapy optimization. Legal requirements in the US to becoming a pharmacist include: graduating from an accredited PharmD program, conducting a specified number of internship hours under a licensed pharmacist (i.e. 1800 hours in some states), passing the NAPLEX, and passing a Multi-state Pharmacy Jurisprudence Exam MPJE. Arkansas, California, and Virginia have their own exams instead of the MPJE and pharmacists must pass the Arkansas Jurisprudence Exam, California Jurisprudence Exam, and Virginia Law Exam, respectively.\n\nResidency is an option for post-graduates that is typically 1–2 years in length. A residency gives licensed pharmacists decades of clinical experience in an extremely condensed timeframe of only a few short years. In order for new graduates to remain competitive, employers generally favor residency trained applicants for clinical positions. The profession is moving toward resident-trained pharmacists who wish to provide direct patient care clinical services. In 1990, the American Association of Colleges of Pharmacy (AACP) required the new professional degree. Graduates from a PharmD program may also elect to do a fellowship that is geared toward research. Fellowships can varying in length but last 1–3 years depending on the program and usually require 1 year of residency at minimum.\n\nAmerican pharmacists can become certified in recognized specialty practice areas by passing an examination administered by one of several credentialing boards.\n\n\nCalifornia pharmacists can apply for Advanced Practice Pharmacist (APh) licenses from the California State Board of Pharmacy. Senate Bill 493, written by Senator Ed Hernandez, established a section on the Advanced Practice Pharmacist and outlines the definition, scope of practice, qualifications, and regulations of those holding this license. \n\nAn APh can:\n\n\nQualifications: \n\nTo qualify for an advanced practice pharmacist license in California, the following requirements must be met\n\n\nThe APh applying for renewal must complete 10 hours of continuing education in 1 or more areas relevant to their clinical practice.\n\nThe \"American Pharmacy Journal of Education\" in 2014 reported the average salary around $112,160.\n\nAccording to the 2010 \"Pharmacy Compensation Survey\":\n\nAccording to the US Bureau of Labor Statistics – \"Occupational Outlook Handbook, 2016–17 Edition\", Median annual wages of wage and salary pharmacists in May 2015 were $121,500.\n\nSchool students must take a national exam to enter a university of pharmacy or the pharmacy department of a university of medicine and pharmacy. About 5–7% of students can pass the exam. There are 3 aspects to the exam. These are on math, chemistry, and physics or biology. After being trained in the university students receive a 5-year bachelor's degree in pharmacy. Or they are university pharmacists (university pharmacist to discriminate between college pharmacist or vocational pharmacist in some countries of the world these pharmacist are call pharmacist assistants). An alternative method of obtaining a bachelor's degree is as follows. School pupils study in a college of pharmacy or a vocational school of pharmacy. After attending the school or college they go to work. And with two years of practice they could take an exam to enter university of pharmacy or the pharmacy department of a university of medicine and pharmacy. This exam is easier than the national one. Passing the exam they continue studying to gain 3-year bachelor's degrees or 4-year bachelor's degrees. This degree is considered equivalent to a 5-year bachelor's degree.\n\n\n\n"}
{"id": "9629921", "url": "https://en.wikipedia.org/wiki?curid=9629921", "title": "Philip Morris USA Inc. v. Williams", "text": "Philip Morris USA Inc. v. Williams\n\nPhilip Morris USA v. Williams, 549 U.S. 346 (2007), 556 U.S. 178 (2009), was a decision by the Supreme Court of the United States, which held that the due process clause of the Fourteenth Amendment limits punitive damages, and ordered a lower court to reconsider its damages awards on that basis.\n\nMayola Williams, the widow of Jesse D. Williams, who died of smoking-related lung cancer in 1997, sued Philip Morris USA, a cigarette manufacturer, for fraud based on Philip Morris advertisements and sponsored studies that made cigarettes seem less dangerous than they actually were. At trial in 1999, the jury found for Williams and awarded her $821,485.50 in compensatory damages and $79.5 million in punitive damages. At that time, the verdict was the largest against a tobacco company. The trial court found that the compensatory damages exceeded the state cap and the punitive damages were \"grossly excessive\". It reduced the respective amounts to $521,485.50 and $32 million.\n\nOn appeal, the Oregon Court of Appeals reversed and reinstated the $79.5 million judgment. Following the \"guideposts\" established in \"BMW of North America, Inc. v. Gore\", the Court of Appeals examined whether the punitive damages were appropriate based on (1) the degree of reprehensibility of the conduct, (2) the disparity between the actual harm and the punitive damages, and (3) the difference between the punitive damages and civil penalties allowed in similar cases. While determining the reprehensibility of Philip Morris's actions, the court considered the length of the misinformation campaign and the number of people it had reached, concluding that its actions were so reprehensible that they justified punitive damages 97 times greater than the actual damages. The Oregon Supreme Court denied review.\n\nThe Supreme Court of the United States then granted \"certiorari\", and in the 2007 decision vacated the Court of Appeals' judgment, remanding the case to the Oregon Court of Appeals for that court to reconsider the amount of the punitive damages award in light of \"State Farm v. Campbell\".\n\nThe Court of Appeals again reinstated the $79.5 million judgment. On appeal, the Oregon Supreme Court affirmed, also holding that the courts can consider evidence of similar conduct to other people in Oregon–even those not party to the lawsuit–when awarding punitive damages. Philip Morris then appealed again to the U.S. Supreme Court in 2008, arguing that the Oregon Supreme Court ignored the guidance the U.S. Supreme Court had given as to punitive damages. In March 2009, the U.S. Supreme Court in essence affirmed the lower court decision when it withdrew their writ of \"certiorari\".\n\nPhilip Morris then paid Williams $61 million, as under Oregon law the state collects 60% of all punitive awards and places those funds into a compensation fund for crime victims. After Philip Morris paid Williams, it then fought the state over paying the remaining amount in punitive damages to the state, claiming that the tobacco settlement signed by Oregon in 1998 prevented Oregon from collecting. The Oregon Supreme Court again disagreed with Philip Morris in December 2011 and ruled that they had to pay the remaining punitive damages, which after interest then totaled $99 million.\n\n"}
{"id": "1945645", "url": "https://en.wikipedia.org/wiki?curid=1945645", "title": "Practice-based research network", "text": "Practice-based research network\n\nA practice-based research network (PBRN) is a group of practices devoted principally to the care of patients and affiliated for the purpose of examining the health care processes that occur in practices. PBRNs are characterized by an organizational framework that transcends a single practice or study. They provide a \"laboratory\" for studying broad populations of patients and care providers in community-based settings.\n\nBefore there were research institutes or networks of practices, there were individual practitioners who studied their patients' problems with scientific rigor. Among these were five general practitioners who have been recognized for their seminal work during the past 125 years. They are James Mackenzie, Will Pickles, John Fry, F.J.A. Huygen and Curtis G. Hames. Each of these pioneers demonstrated that important new knowledge could be discovered by practicing family physicians. And this is far from an accepted principle in the United States. These doctors all wondered about their patients' problems and they developed a means of gathering and recording data on their patients.\n\nEach of these research pioneers provide inspiration for the development of practice-based, primary care research networks because each demonstrated that important new knowledge could be discovered by the practicing family doctor. They each wondered about their patients, developed means of gathering and recording data, and found collaborators and support from their staff and local communities. Unfortunately, they practiced in an era that was over-committed to specialism. Research focused on molecular mechanisms of disease. The rush to specialization by the medical community and the linking of research to specialists resulted in decades of neglect of primary care and virtually no recognition of the need to investigate care in the primary care setting.\nInstead, the common wisdom viewed primary care practices as relatively boring places that could be potential sites of application of the fruits of research done elsewhere in research laboratories, hospitals and institutes.\n\nAmong the early regional networks started in the 1970s were the Family Medicine Information System in Colorado (FMIS) and the Cooperative Information Project. These regional networks learned from each other and succeeded in conducting studies focused on what was happening in primary care. They attracted funding from medical schools, national philanthropic foundations and federal programs such as Health for Underserved Rural Areas. As the 1970s closed, these early networks enjoyed sufficient success to stimulate debate about the next steps in the context of the microcomputer's development. Among them was a small group convened by Gene Farley in Denver in 1978 to consider establishing a national sentinel practice system. It was this idea that lead to the Ambulatory Sentinel Practice Network and provided in retrospect what appears to have been a nidus for the establishment of primary care PBRNs in the United States.\n\nPBRNs are feasible and that represent a useful infrastructure for the scientific discovery of family practice and primary care. Experience to date points out the great advantages enjoyed by those with enduring, core financial support—such as the Dutch with their early national commitment to primary care and their willingness to invest in primary care research. It is also obvious that these networks require collaboration, cooperation and a spirit of sharing and trust.\n\nThese networks are now at once both a place and a concept. As a place, they are a laboratory for surveillance and research. As a concept, they express the still unmet need for practicing primary care clinicians to accept responsibility to improve frontline clinical care by understanding what is happening in their practices. Successes to date have been sufficient to incite the Institute of Medicine's 1994 committee studying the future of primary care to recommend support to stabilize and expand practice-based primary care research networks.\n\n\n"}
{"id": "30534283", "url": "https://en.wikipedia.org/wiki?curid=30534283", "title": "Prisoner of Her Past", "text": "Prisoner of Her Past\n\nPrisoner of Her Past is a 2010 documentary film, produced by Kartemquin Films, that follows the journey of \"Chicago Tribune\" music critic Howard Reich as he travels to Europe to discover why his elderly mother, Sonia Reich, believes people are trying to kill her.\n\nInspired by conversations with young trauma survivors in post-Katrina New Orleans, Howard Reich begins to discover a secret that his mother, Sonia, had kept hidden for over 60 years. For most of her adult life, Sonia Reich was a well adjusted and self-sufficient woman, but now in her eighties, Sonia is suffering from late-onset Post Traumatic Stress Disorder.\n\nIn order to understand his mother's past, Howard Reich travels to Eastern Europe to discover that Sonia spent her adolescence fleeing the Nazis during World War II. Meeting some of Sonia's distant relatives and childhood friends, Howard begins to unravel what his mother has always refused to speak about. Having lost most of her family to the Holocaust, Sonia spent five years as a \"jungle child\", starving and constantly on the run. Now as Sonia tries to forget her past, Howard attempts to ease her pain and confront the horrors that haunted her.\n\n\"Prisoner of Her Past\" was directed by Gordon Quinn, a founder of Kartemquin Films. The film was produced by Joanna Rudnick and \"Chicago Tribune\" journalist, Howard Reich, with Associate Producer, Zak Piper. The film was a co-production of Kartemquin Films and the \"Chicago Tribune\". Prisoner of Her Past was the February 2010 winner of the Accolade Competition's Best of Show Award.\n\n"}
{"id": "6842369", "url": "https://en.wikipedia.org/wiki?curid=6842369", "title": "Proof test", "text": "Proof test\n\nA proof test is a form of stress test to demonstrate the fitness of a load-bearing structure. An individual proof test may apply only to the unit tested, or to its design in general for mass-produced items. Such a structure is often subjected to loads above that expected in actual use, demonstrating safety and design margin. Proof testing is nominally a nondestructive test, particularly if both design margins and test levels are well-chosen. However, unit failures are by definition considered to have been destroyed for their originally-intended use and load levels.\n\nProof tests may be performed before a new design or unit is allowed to enter service, or perform additional uses, or to verify that an existing unit is still functional as intended.\n\nCranes and derricks are proof tested when called on for potentially dangerous load levels or high-valued cargoes. Similarly, items which are smaller and more common (rope and cable, slings, shackles and eyes) are nevertheless in the load path and a failure risk if not tested. Testing generally involves lifting weight or drawing tension equal to or greater than design levels.\n\nAn overspeed proof test involves physically running the machine at high speed up to the test speed. This may be done during manufacture as an initial proof test. Physical overspeed tests may be periodically undertaken on some machines to verify operation of the overspeed protection systems.\n\nOperation at speeds above the normal operating speed can greatly increase stress levels in rotating parts. Failing flywheels, rotors, etc. may present a shrapnel risk in case of a failure.\n\nHistorically, swords would be proof tested by impact before issuance- the \"British test\".\n\nVessels which may be a failure risk, such as utility-scale water towers, chemical-handling equipment, or very-high-pressure storage tanks, may be proof tested. Rocket stage tankage, being high-valued and often the vehicle's primary structure, are proof-tested when redesigned, and may be tested at the unit level. Testing involves exposure to higher gauge pressures than design levels, or in some cases, pulling harder vacuum.\n\nA firearm's chamber and barrel become pressure vessels for brief periods. In firearm terminology, a proof test is a test wherein a deliberately over-pressured round is fired from a firearm in order to verify that the firearm is not defective and will not explode on firing. The firearm is inspected after the test, and if it is found to be in sound condition, then it is marked with a \"proof mark\" to indicate that it has been \"proofed\" (not \"proven\"). In many jurisdictions a proof test and valid proof mark are required for the sale of firearms.\n\nA \"proof round\" is an ammunition assembly designed to be used in proof testing; this can use a fixed cartridge, a semi-fixed cartridge, or separately loaded projectile, charge and primer. A \"proof shot\" is a special projectile used in a proof round or other projectile weapons, electromagnetic guns for example. Small arms proof rounds resemble normal cartridges, though they will typically bear special markings to prevent them from being confused for standard cartridges. Large calibre arms, such as artillery, will in general use an inert solid projectile (the proof shot); although water, sand or iron (powder) filled versions can be found for testing recoil systems.\n\nFor both small arms and heavy weapons, the gun is fired remotely and then examined; if undamaged, it is assumed to be safe for normal use and a proof mark is added to the barrel. In the case of revolvers or other multi-chamber firearms, each chamber must be proof tested before the firearm may be marked. Examination of the firearm may be as simple as visually inspecting it (defective components may fail in a spectacular manner, resulting in an explosion of the firearm) or may involve more in-depth examination, at the option of the tester.\n\nBecause proof testing may or may not result in the destruction of the test specimen, it falls on the border between destructive testing and nondestructive testing.\n\nA proof mark is a mark specific to the manufacturer, importer, or testing facility that is performing the test. It generally takes the form of a stamp that makes an impression in the metal. Since proof marks are unique and nearly universal, they are often used to identify the origins of firearms that lack normal manufacturer's markings, such as military weapons, which are often produced by large numbers of different manufacturers.\n\nA small arms proof round is loaded to a higher than normal service pressure, stressing both the gun barrel and breech during firing. This can be due to a heavy projectile fired using the standard propelling charge, the standard projectile fired with a different propellant type or weight, or combinations of charge and bullet weight to give the required proofing pressure. Minimum proof testing pressures are specified by the owner of the cartridge specification, such as C.I.P. or SAAMI for most commercial cartridges or NATO EPVAT testing for appropriate military cartridges.\n\nAn example proofing round for the .50 BMG (12.7 × 99 mm) is the \"Cartridge, Caliber .50, Test, High Pressure, M1\". This uses the standard weight .50 BMG M1 round propellant (240 grs of WC860), but a bullet weighing 999 grs (+/- 11 grs). The M1 proof round gives a proofing pressure of ~65,000 psi, 11,000 psi (~17%) above the standard service pressure.\n\nIn C.I.P. member states every civil firearm has to be professionally proofed in accredited Proof Houses before it can be sold to consumers. The proofsigns can allow to identify special periods of times in which they were used. Some of the acctually used signs are:\nThe standard proof test consist of firing two overloaded cartridges that produce 25% more chamber pressure than the C.I.P. specified maximum pressure limit for the same cartridge in its commercial version. The standard proof of pistol, revolver and rimfire cartridges is performed with overloaded cartridges that produce 30% more chamber pressure than the C.I.P maximum pressure limit for the same cartridge in its commercial version. There are only two overloaded firings to avoid excessive stress to the arm, especially the barrel which is the main part suffering this overload beside the chamber (when not part of the barrel) and the locking mechanism. After the test, the arm is disassembled by the proof house technicians for nondestructive testing looking for Magnetic flux leakage through fluoroscopic lamp in a dark room. Many manufacturers, including Glock Ges.m.b.H., package the casings from a firearm's proof ammunition in a sealed envelope accompanying the firearm so that authorities in C.I.P.-signatory states and civilian purchasers in other countries can conduct an independent examination if they desire.\n\nBefore the year 2006 the standard test consisted of firing two overloaded cartridges producing 30% more chamber pressure then the C.I.P. specified maximum chamber gas pressure limit for the same cartridge in its commercial version.\n\nVoluntarily testing beyond the current legally required standard test benchmark is often also possible for consumers who intend the use their firearms under extreme conditions (hot climates, long strings of shots, etc.). In case a firearm passes such a proof-test a pass mark termed superior proof mark is stamped in every successfully tested firearm.\n\nUnder SAAMI proof test procedures, for bottlenecked cases the centre of the transducer is located .175\" behind the shoulder of the case for large diameter (.250\") transducers and .150\" for small diameter (.194\") transducers. For straight cases the centre of the transducer is located one-half of the transducer diameter plus .005\" behind the base of the seated bullet. Small transducers are used when the case diameter at the point of measurement is less than .35\".\n\nUnder C.I.P. proof test standards a drilled case is used and the piezo measuring device (transducer) will be positioned at a distance of 25 mm from the breech face when the length of the cartridge case permits that, including limits. When the length of the cartridge case is too short, pressure measurement will take place at a cartridge specific defined shorter distance from the breech face depending on the dimensions of the case.\n\nThe difference in the location of the pressure measurement gives different results than the C.I.P. standard.\n\nThe test of a large-caliber weapon system primarily covers the strength of the barrel, breech and recoil systems. The proof shot has to resemble the resistance to motion (bore/rifling friction, shot start pressures, etc.) and profile to the propellant gases that the actual service projectile will give. For this reason, proof shots for APFSDS rounds have fin units and all must have profiles behind the obturator the same as the shot they are emulating. Crack analysis is often undertaken on large-caliber weapons after testing has been carried out.\n\nThe proof shot is normally a high-drag projectile since its job is over once it has left the muzzle of the gun. A high-drag projectile is advantageous for two reasons; first, it reduces the impact velocity when fired against an earth or sand backstop, and second, it reduces the range if no backstop is used. Excessive range can be a very problematic when firing any large-caliber round; safety traces can often exceed the bylaw areas of the firing range, so range reduction is imperative. This is even more of a problem when high velocity, low drag rounds such as APDS or APFSDS are used.\n\nAlthough proof shots are used in the service proof of barrels before use, the vast majority are used in propellant charge design. Proof shot emulating APFSDS rounds are also used in stabilizing-fin SoD trials, which is often combined with a charge design trial.\n\nWhen running a charge development, or Strength of Design (SoD) trial, the charge mass and service pressure will gradually be worked up to the required proofing pressure of the weapon system. Readings will be taken of chamber pressure by copper crusher, or piezo electric gauges and velocity by Doppler radar (in-bore or aeroballistic), or photocell counter chronographs. In addition strain and temperature readings may also be recorded. If required, high speed photography (synchroballistic photography, high speed digital stills, head on cine, or flight follower) may also be used.\n\nReproof is a further test of a gun after its original proof, which may necessary when changes are made or due to inadequacy of the original proof.\n\nVehicle systems or entire vehicles may be proof-tested. As failure of an aircraft structure or substructure may be catastrophic, demonstration of designs or of in-service units is performed via proof testing. Failure of sail rigging is no longer as catastrophic, but may still lead to damage, injury and loss of vehicle functions.\n\nThe leak testing is the proceedings to verify and measure the pneumatic tightness of the produced components. This phase of the industrial process is called leak test or leakage detection\n\n\n"}
{"id": "53828642", "url": "https://en.wikipedia.org/wiki?curid=53828642", "title": "Randolph Blake", "text": "Randolph Blake\n\nRandolph Blake is an American psychologist, currently the Centennial Professor at Vanderbilt University and an Elected Fellow of the American Academy of Arts and Sciences and National Academy of Sciences.\n"}
{"id": "22454779", "url": "https://en.wikipedia.org/wiki?curid=22454779", "title": "Sheldon Friel", "text": "Sheldon Friel\n\nErnest Sheldon Friel (1888 – 2 February 1970), was an Irish dentist who was the first specialist orthodontist to practise in the United Kingdom of Great Britain and Ireland, and the second in Europe, going on to become the first Professor of Orthodontics in Europe. His obituary in \"The Journal of the Irish Dental Association\" described him as the most distinguished dentist that Ireland had ever produced.\n\nFriel studied at Trinity College, Dublin, graduating in 1908 and receiving a master's degree in dental science in 1909. During this period he also undertook specialist orthodontic studies under the father of modern orthodontics, Edward Angle, in the United States. In 1909 he established an orthodontic practice in Dublin, the first in the British Isles. In 1910 he was appointed as Lecturer in Orthodontics at Trinity, receiving a Doctor of Science degree in 1928. In 1941 the college created the first professorship in orthodontics in Europe and appointed Friel to the position. For many years following this he was the only professor of orthodontics in the British Isles.\n\nFriel was a pioneer in the use of stainless steel, rather than the previously preferred gold, for the manufacture of orthodontic devices. Other research interests were muscle testing and training, the relation of function to the size and form of jaws, the migration of teeth and occlusion.\n\nFriel was a founder member of the British Society for the Study of Orthodontics and was prominent in the society in its early years, acting as its president in 1924. He was president of the Irish Dental Association in 1932, of the European Orthodontic Society from 1935 to 1937, and of the Odontological Section of the Royal Society of Medicine in 1949.\n\nIn 1945 Friel undertook a campaign in the profession for the greater specialisation of orthodontics in Britain at a time when much treatment was undertaken by non-specialist dentists.\n\nIn 1948 Friel was awarded a Fellowship of the Royal College of Surgeons of England, and in 1951 of the Royal College of Surgeons of Edinburgh. He received the Villain Prize in orthodontics from the Fédération Dentaire Internationale in 1957, and in 1960 he became the first person outside North America to receive the Ketcham Award from the American Board of Orthodontics.\n\nThree years after Friel's death his family provided funding to the European Orthodontic Society for the annual Sheldon Friel Memorial Lecture.\n"}
{"id": "4280556", "url": "https://en.wikipedia.org/wiki?curid=4280556", "title": "Sickle cell trait", "text": "Sickle cell trait\n\nSickle cell trait describes a condition in which a person has one abnormal allele of the hemoglobin beta gene (is heterozygous), but does not display the severe symptoms of sickle-cell disease that occur in a person who has two copies of that allele (is homozygous). Those who are heterozygous for the sickle cell allele produce both normal and abnormal hemoglobin (the two alleles are codominant with respect to the actual concentration of hemoglobin in the circulating cells).\n\nSickle cell disease is a blood disorder wherein there is a single amino acid substitution in the hemoglobin protein of the red blood cells, which causes these cells to assume a sickle shape, especially when under low oxygen tension. Sickling and sickle cell disease also confer some resistance to malaria parasitization of red blood cells, so that individuals with sickle-cell trait (heterozygotes) have a selective advantage in environments where malaria is present.\n\nSickle cell trait is a hemoglobin genotype AS and is generally regarded as a benign condition. However, individuals with sickle cell trait may have rare complications. For example, in November 2010, Dr. Jeffery K. Taubenberger of the National Institutes of Health discovered the earliest proof of sickle-cell disease while looking for the virus of the 1918 flu during the autopsy of an African-American soldier. Taubenberger's autopsy results showed that the soldier suffered a sickle-cell crisis that contributed to his death even though he had only one copy of the gene. There have been calls to reclassify sickle cell trait as a disease state, based on its malignant clinical presentations. Significance may be greater during exercise.\n\nNormally, a person inherits two copies of the gene that produces beta-globin, a protein needed to produce normal hemoglobin (hemoglobin A, genotype AA). A person with sickle cell trait inherits one normal allele and one abnormal allele encoding hemoglobin S (hemoglobin genotype AS).\n\nThe sickle cell trait can be used to demonstrate the concepts of co-dominance and incomplete dominance. An individual with the sickle cell trait shows incomplete dominance when the shape of the red blood cell is considered. This is because the sickling happens only at low oxygen concentrations. With regards to the actual concentration of hemoglobin in the circulating cells, the alleles demonstrate co-dominance as both 'normal' and mutant forms co-exist in the blood stream. Unlike the sickle-cell trait, sickle-cell disease is passed on in a recessive manner.\n\nWhole genome sequence analysis has identified a single origin of the sickle trait, with one haplotype ancestral to all sickle-cell variants. This haplotype is thought to have originated in the Sahara during the Holocene Wet Phase around 7,300 years ago. Sickle cell variants descended from this ancestral haplotype comprise five haplotypes named after toponyms or ethnolinguistic groups (the Arabian/Indian, Benin, Cameroon, Central African Republic/Bantu, and Senegal variants), and another designation earmarked for atypical sickle-cell haplotypes. Their clinical importance is because some are associated with higher HbF levels (e.g., Senegal and Saudi-Asian variants tend to have milder disease).\n\nSickle cell trait prevalence is highest in West Africa, where it is found in 25% of the population. The trait also has a high prevalence in South and Central Americans, especially those in Panama. However, it also very infrequently appears in Mediterranean countries such as Italy, Greece, and Spain, where it most likely expanded via the selective pressure of malaria, a disease that was endemic to the region.\n\nIn some cases, athletes with sickle cell trait do not achieve the same level of performance as elite athletes with normal hemoglobin AA. Athletes with sickle cell trait and their instructors must be aware of the dangers of the condition during anaerobic exertion especially in hot and dehydrated conditions. In rare cases, exercise-induced dehydration or exhaustion may cause healthy red blood cells to turn sickle-shaped, which can cause death during sporting activities.\n\nWhile more research is necessary on the topic, the correlation found between individuals with sickle cell trait and an increased risk of sudden death appears to be related to microcirculatory disorders, during exercise. In recent years the NCAA has partnered with the ACSM and issued a joint statement, warning athletes about both the prevalence and the potential risk factors of sickle cell trait. The NCAA has also recently encouraged athletes to become aware of their sickle cell trait status, as the trait itself does not typically result in symptoms under normal conditions but can become dangerous during extreme physical activity similar to the daily training that athletes undergo.\n\nNormal hemoglobin (and hemoglobin S in the presence of oxygen) contains a deformability characteristic that allows erythrocytes to essentially squeeze their way into smaller vessels, including those involved in microcirculation to the capillaries within muscle tissue as well as blood supply embedded within organ tissues. When hemoglobin S is deprived of oxygen, it can polymerize, which is what is proposed to cause the \"sickled\" cells. The sickled erythrocytes present a decreased deformability when compared to normal erythrocytes, leading to distress in circulation into the smaller vessels involved in microcirculation, particularly, in this case, the capillaries embedded in muscle tissue.\n\nThe resulting microvasculatory distress in capillaries specific to muscle tissue can cause acute rhabdomyolysis and necrosis within the muscle cells. The inflammation and leakage of intracellular material resulting from muscle cell necrosis releases a particular protein, myoglobin, into the blood stream. While necessary in muscle tissue to bind iron and oxygen, myoglobin circulating through the bloodstream can break down into smaller compounds that damage kidney cells, leading to various complications, such as those seen in sickle cell trait athletes during high levels of physical exertion.\n\nBecause of the link between deformability and sickled cells, deformability can be used to evaluate the amount of sickled cells in the blood. Deformability of the erythrocytes that cause the microcirculatory distress can be demonstrated through various other hemorheological characteristics. In order to determine the deformability of erythrocytes multiple factors including blood and plasma viscosity and hematocrit (a calculation of the percent of red blood cells present in the blood) are measured.\n\nAlpha-thalassemia, like sickle cell trait, is typically inherited in areas with increased exposure to malaria. It manifests itself as a decreased expression of alpha-globin chains, causing an imbalance and excess of beta-globin chains, and can occasionally result in anemic symptoms. The abnormal hemoglobin can cause the body to destroy red blood cells, essentially causing anemia.\n\nIn endurance-trained individuals with sickle cell trait the presence of alpha-thalassemia has been shown to act protectively against microvasculatory distress before, during, and after exercise.\n\nBecause of the microcirculatory distress, a telltale sign or symptom of a potential sickling collapse is cramping. Specifically to sickle cell trait, cramping occurs in the lower extremities and back in athletes undergoing intense physical activity or exertion. In comparison to heat cramps, sickling cramps are less intense in terms of pain and have a weakness and fatigue associated with them, as opposed to tightly contracted muscles that lock up during heat cramps.\n\nA sickling collapse comes on slowly, following cramps, weakness, general body aches and fatigue. Individuals with known positive sickle cell trait status experiencing significant muscle weakness or fatigue during exercise should take extra time to recover and hydrate before returning to activity in order to prevent further symptoms.\n\nA collapse can be prevented by taking steps to ensure sufficient oxygen levels in the blood. Among these preventative measures are proper hydration and gradual acclimation to conditions such as heat, humidity, and decreased air pressure due to higher altitude. Gradual progression of exertion levels also helps athletes' bodies adjust and compensate, gaining fitness slowly over the course of several weeks.\n\nSickle cell trait provides a survival advantage, against malaria fatality, over people with normal hemoglobin in regions where malaria is endemic. The trait is known to cause significantly fewer deaths due to malaria, especially when \"Plasmodium falciparum\" is the causative organism. This is a prime example of natural selection, evidenced by the fact that the geographical distribution of the gene for hemoglobin S and the distribution of malaria in Africa virtually overlap. Because of the unique survival advantage, people with the trait become increasingly numerous as the number of malaria-infected people increases. Conversely, people who have normal hemoglobin tend to succumb to the complications of malaria.\nAlthough the precise mechanism for this phenomenon is not known, several factors are believed to be responsible.\n\nThe sickle cell trait was found to be 50% protective against mild clinical malaria, 75% protective against admission to the hospital for malaria, and almost 90% protective against severe or complicated malaria.\n\n\n\nThere have been reports of pulmonary venous thromboembolism in pregnant women with sickle cell trait, or men during prolonged airflight, and mild strokes and abnormalities on PET scans in children with the trait.\n\nSickle cell trait appears to worsen the complications seen in diabetes mellitus type 2 (retinopathy, nephropathy and proteinuria) and provoke hyperosmolar diabetic coma nephropathy, especially in male patients.\n\n"}
{"id": "32282668", "url": "https://en.wikipedia.org/wiki?curid=32282668", "title": "Suicide in Pakistan", "text": "Suicide in Pakistan\n\nSuicide in Pakistan has been a long-term social issue and is a common cause of unnatural death. Incidents of suicide are often reported in the press and newspapers throughout the country as well as by several non-governmental organisations. However, diagnosing and covering suicide cases has generally been difficult in the local culture due to a number of social stigmas and legal issues that bind the problem; given that suicide is prohibited in Islam, there are various obstacles which come along in openly discussing the phenomenon in Pakistan, a predominantly Muslim country. Suicide is considered a criminal offence, with punitive laws imposed in place for attempted suicide. National suicide statistics are not compiled on a formal level nor officially reported to the World Health Organization, thus leaving any obtained data to be neglected and underreported. While suicide patterns have traditionally been low, there has been a slow but steep increase in the past few years.\n\nOne analysis of suicide reports, based over a period of two years, showed over 300 suicidal deaths in Pakistan from 35 different cities. The findings showed that men outnumber women by 2:1 and that the majority of men who commit suicide tend to be unmarried; the trend for women, however, is the opposite. Research also indicated that the majority of subjects were under the age of 30 and that \"domestic problems\" are the main reason stated for suicide. These include unemployment, health issues, poverty, homelessness, family disputes, depression and a range of social pressures. Hanging, use of insecticides and firearms are the most common methods for carrying out suicide in Pakistan.\n"}
{"id": "56203942", "url": "https://en.wikipedia.org/wiki?curid=56203942", "title": "Tara Flynn", "text": "Tara Flynn\n\nTara Flynn is an Irish actor and writer, best known for her comedy work.\n\nFlynn has written three satirical books: \"You're Grand: The Irishwoman's Secret Guide to Life\", \"Giving Out Yards: The Art of Complaint, Irish Style\" and \"Rage-In: Trolls and Tribulations of Modern Life\" \n\nShe was a founding member of comedy singing group 'The Nualas'.\n\nShe is a voice artist and was the voice of Molly in RTE's 'The Morbegs'.\n\nShe uses satire for activism, as in YouTube sketches such as 'Racist B&B', 'Armagayddon' and 'The Case for Mammy / Daddy Marriage'.\n\nIn 2015, as part of Amnesty International Ireland's 'She is not a Criminal' campaign, she spoke publicly for the first time about traveling to the Netherlands for an abortion (abortion was illegal in Ireland at the time). She has since been a vocal campaigner for reproductive rights and the repeal of Ireland's 8th amendment.\n\nIn 2017, Flynn provided the voiceover on TV3's remake of \"Blind Date\". She took over the role first done by Graham Sidmore in the original 1980s show.\n\n"}
{"id": "58058911", "url": "https://en.wikipedia.org/wiki?curid=58058911", "title": "Vladimír Plaček", "text": "Vladimír Plaček\n\nVladimír Plaček (29 May 1965 – 2 August 2018) was a Czech physician and politician affiliated with the Czech Social Democratic Party.\n\nPlaček graduated from the faculty of medicine at Masaryk University in 1990, and earned another degree from the University of Ostrava in 2008. He served on the Senate from 2012 until his death on 2 August 2018, aged 53.\n"}
{"id": "16064221", "url": "https://en.wikipedia.org/wiki?curid=16064221", "title": "Why Survive? Being Old in America", "text": "Why Survive? Being Old in America\n\nWhy Survive? Being Old In America was written by Robert Neil Butler and published by Harper & Row in 1975, it won the 1976 Pulitzer Prize for General Non-Fiction. The book discusses a range of problems faced by older people in American society stemming from poverty, the failures of the Social Security system, and social isolation, and argues for the necessity of comprehensive reform and developing of a strategy for dealing with an aging population.\n"}
{"id": "41989740", "url": "https://en.wikipedia.org/wiki?curid=41989740", "title": "Yeast Metabolome Database", "text": "Yeast Metabolome Database\n\nThe Yeast Metabolome Database (YMDB) is a comprehensive, high-quality, freely accessible, online database of small molecule metabolites found in or produced by Saccharomyces cerevisiae (Baker’s yeast). The YMDB was designed to facilitate yeast metabolomics research, specifically in the areas of general fermentation as well as wine, beer and fermented food analysis. YMDB supports the identification and characterization of yeast metabolites using NMR spectroscopy, GC-MS spectrometry and Liquid chromatography–mass spectrometry (LC-MS spectrometry). The YMDB contains two kinds of data: 1) chemical data and 2) molecular biology/biochemistry data. The chemical data includes 2027 metabolite structures with detailed metabolite descriptions along with nearly 4000 NMR, GC-MS and LC/MS spectra. \n\nThe biochemical data includes 1104 protein (and DNA) sequences and more than 900 biochemical reactions (Fig. 1) that are linked to these metabolite entries. Each metabolite entry in the YMDB contains more than 80 data fields with 2/3 of the information being devoted to chemical data and the other 1/3 devoted to enzymatic or biochemical data. Many data fields are hyperlinked to other databases (KEGG, PubChem, MetaCyc, ChEBI, Protein Data Bank, UniProt, and GenBank) and a variety of structure and pathway viewing applets. The YMDB database supports extensive text, sequence, spectral, chemical structure and relational query searches.\n\nAll data in YMDB is non-proprietary or is derived from a non-proprietary source. It is freely accessible and available to anyone. In addition, nearly every data item is fully traceable and explicitly referenced to the original source. YMDB data is available through a public web interface and downloads.\n\nUsers may search through the YMDB using a variety of database-specific tools. The simple text query supports general text queries of the textual component of the database. By selecting either metabolites or proteins in the “search for” field it is possible to restrict the search and the returned results to only those data associated with metabolites or with proteins. YMDB’s browse tool generates a tabular synopsis of YMDB's content (Fig. 2). This browser view allows users to casually scroll through the database or re-sort its contents. Clicking on a given MetaboCard button brings up the full data content for the corresponding metabolite (Fig. 3). Under the Search link users will find a number of search options listed in a pull-down menu. The Chem Query option allows users to draw (using MarvinSketch applet or a ChemSketch applet) or to type (SMILES string) a chemical compound and to search the YMDB for chemicals similar or identical to the query compound. The Advanced Search option supports a more sophisticated text search of the text portion of YMDB. The Sequence Search button allows users to conduct BLAST (protein) sequence searches of all sequences contained in YMDB. Both single and multiple sequence (i.e. whole proteome) BLAST queries are supported. YMDB also supports a Data Extractor option that allows specific data fields or combinations of data fields to be searched and/or extracted. Spectral searches of YMDB’s reference compound NMR and MS spectral data are also supported through its MS, MS/MS, GC-MS and NMR Spectra Search links. Users may download YMDB’s complete textual data, chemical structures and sequence data by clicking on the Download button.\n\n\n"}
{"id": "50806991", "url": "https://en.wikipedia.org/wiki?curid=50806991", "title": "Zimbabwe at the 1980 Summer Paralympics", "text": "Zimbabwe at the 1980 Summer Paralympics\n\nZimbabwe competed at the 1980 Summer Paralympics in Arnhem, Netherlands. 5 competitors from Zimbabwe won 12 medals, 8 silver and 4 bronze, and finished 34th in the medal table.\n\n"}
{"id": "30818631", "url": "https://en.wikipedia.org/wiki?curid=30818631", "title": "Újpest Water Tower", "text": "Újpest Water Tower\n\nThe Újpest Water Tower () is one of many water towers in Budapest.\n\nThe Újpest Water Tower played an important role in World War II. Explosives were stored within the tower, possibly reserved for its later destruction. In December 1944, Hungarian partisans ambushed the Arrow Cross guards and seized the ammunition, thus preventing the tower from being destroyed. Had it been destroyed, the entire area would have been left without water. \n"}
