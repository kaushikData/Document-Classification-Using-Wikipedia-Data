{"id": "2862940", "url": "https://en.wikipedia.org/wiki?curid=2862940", "title": "Action on Smoking and Health", "text": "Action on Smoking and Health\n\nAction on Smoking and Health (ASH) is the name of a number of autonomous pressure groups (charities) that seek to publicise the risks associated with tobacco smoking and campaign for greater restrictions on cigarette and tobacco sales.\n\nIn the US, ASH was formed in 1967 by John F. Banzhaf III, and a distinguished body of physicians, attorneys and other prominent citizens who saw the need for an organization to represent nonsmokers’ rights. Over the years, ASH has taken the lead on a variety of initiatives to counter the deaths and economic burden imposed by the tobacco industry.\n\nASH has a long history of advocacy, education and legal initiatives in the fight against tobacco. ASH has fought for health in courts, before legislative bodies and regulatory agencies, as well as international agencies such as the United Nations and the World Health Organization.\nASH’s work and the work of its allies has spanned more than 40 years. Since the release of the original Surgeon General Report on smoking in January 1964, the global initiative for the prevention of tobacco-related damages has made enormous progress—and ASH has played a major role in achieving this progress.\n\nASH’s actions have led to significant progress, including:\n\nIn the United Kingdom, ASH is a registered charity established in 1971, that aims to eliminate the harm caused by tobacco. It works to raise awareness of the health risks of tobacco, and also campaigns for policy measures. It provides the secretariat of the All-Party Parliamentary Group on smoking and health.\n\nASH was established in 1971 by the Royal College of Physicians following the refusal of the UK Government to act on the College's demand for laws to reduce tobacco use. Former health minister, John Dunwoody, became its first director. Its present-day board of trustees reflects its continued support from the medical establishment as it is composed largely of doctors and scientists.\n\nASH was awarded a WHO World No Tobacco Day award in May 2011 and the 2012 Luther L Terry Award for \"Outstanding Organization\" by the American Cancer Society in December 2011.\n\nIts current Chief Executive, appointed in 2003, is Deborah Arnott. She was appointed Honorary Associate Professor in the Division of Epidemiology and Public Health University of Nottingham in 2011 and won the 2007 Alwyn Smith Prize awarded annually by the UK Faculty of Public Health to the person judged to have made the most outstanding contribution to the health of the public.\n\nASH is a charity describing itself as a \"campaigning public health charity that works to eliminate the harm caused by tobacco\".\n\nIts funding for its core campaigning programme comes from the British Heart Foundation (BHF) and Cancer Research UK (CRUK). It has also received funding from the Department of Health under its Section 64 grant programme, which is earmarked for specific projects to further the department’s public health objectives, and cannot be used to lobby the government.\n\nASH uses funding from the BHF and CRUK to influence policy on a variety of issues including taxation and smuggling, health inequalities, harm reduction, and smoking and young people. It also works to raise awareness of the methods used by the tobacco industry to influence public health policies. ASH coordinates the Smokefree Action Coalition (SFAC), the umbrella group for organisations working to reduce the harm caused by tobacco, which was set up to campaign for comprehensive smoke-free legislation.\n\nIn February 2006, ASH won its campaign for legislation which created comprehensive smoke-free indoor workplace regulation, introduced in England on 1 July 2007. The smoke-free regulations included all pubs, bars and private members' clubs, as well as cafés, restaurants, and enclosed workplaces. A similar smoke-free law had already come into force in Scotland in March 2006, and Northern Ireland and Wales followed in April 2007. Campaigning after this point focussed on the need for a new government strategy on tobacco control.\n\nIn 2008, ten years after the publication of \"Smoking Kills\", a white paper on tobacco and the first comprehensive strategy to tackle the issue, ASH published \"Beyond Smoking Kills\" which provided a review of progress on the control of tobacco. The report called for a number of measures including a tobacco display ban, prohibition of the sale of tobacco from vending machines and standardised tobacco packaging.\n\nThe Health Act 2009 provides for removal of vending machines for tobacco products (implemented in October 2011) and for the prohibition of the display of tobacco products at the point of sale in England, Wales and Northern Ireland. In March 2011, the Government committed to implement the point of sale legislation in England in large shops from April 2012 and in smaller shops from April 2015. It also committed to a public consultation on standardised packaging in early 2012. ASH, and the SFAC, actively campaigned for the introduction of standardised packaging, which was included in the Children and Families Act 2014 and was passed into law in March 2015. The charity described it as the \"most important public health reform of this Parliament.\"\n\nIn 2015, ASH published \"Smoking Still Kills\" which called for a new government tobacco control strategy, and made a number of recommendations including an annual levy on tobacco companies to fund measures to help smokers quit and prevent youth uptake. At the launch of the report, Parliamentary Under Secretary of State for Public Health Jane Ellison committed to a new tobacco control strategy. Christopher Snowdon, a research fellow at the Institute of Economic Affairs, which had received funding from tobacco firms, noted the influence of the charity saying that the \"manifesto of this tiny pressure group is, in effect, the manifesto of whichever party is in power.\"\n\nASH is also a member of the World Health Organization's Framework Convention Alliance on Tobacco Control.\n\nASH covers the whole of the UK and encourages supporters to get involved in the organisation's work, or just lend financial support. ASH Northern Ireland, ASH Scotland and ASH Wales are separate organisations.\n\nASH Scotland is an independent Scottish charity which aims to take action to reduce the harm caused by tobacco. First founded under the auspices of the Royal College of Physicians of Edinburgh in 1973, ASH Scotland became a wholly separate charity in 1993.\n\nThe organisation seeks to improve health and quality of life by limiting the number of young people taking up smoking, reducing the number of adult smokers, protecting people from second-hand smoke and tackling the inequality resulting from tobacco use. This involves campaigning for change in the law, providing information to politicians, healthcare professionals and the public, and running programmes designed to help people be tobacco-free.\n\nFollowing ASH Scotland campaigns, Scotland was the first part of the UK to introduce smoke-free public places legislation and the first part of the UK (and the third country globally) to declare a tobacco-free date (2034) as part of the Scottish Government's tobacco control strategy 'Creating a tobacco-free generation'.\n\nASH Wales is a smoking cessation and health charity that began in 1976 as an autonomous branch of ASH UK, and later granted independent charity status in 2007. Its aim is to reduce the prevalence of smoking across Wales by identifying and addressing influential factors, increasing public awareness, and improving the quality and reach of cessation services. ASH Wales engages in a variety of projects including campaigning for tobacco-control public-health policy, research, training, educational workshops, advocacy, and support.\n\nFrom 2012 onward ASH Wales campaigned for all 22 local authorities in Wales to introduce smoke-free policies in their children’s playgrounds. To date, 20 out of 22 local authorities have implemented voluntary bans in their local playgrounds, with another currently in the process of implementing a ban.\n\nASH Wales played an instrumental role in the Welsh Government’s decision to enforce a ban on smoking in cars with children. Smoking in a private vehicle when someone under the age of 18 is present became illegal in England and Wales on 1 October 2015.\n\nThe Filter is the youth project of ASH Wales which delivers quit smoking support and prevention for children and young people aged 11–25. The Filter provides workshops and quit smoking programmes delivered by smoking cessation advisors.\n\nThe Filter Project was launched in 2013 as a result of funding from the Big Lottery Fund. Since then The Filter has delivered its workshops and cessation support to more than 6,000 people across Wales. From 2015 The Filter became part of an Erasmus+ funded partnership bringing together organisations from 5 different EU countries with the aim of reducing tobacco consumption across all of the nations. This partnership will examine the potential of The Filter to work on a transnational basis.\n\nThe Wales Tobacco or Health Network (WTHN) is a professional network led by ASH Wales for individuals in Wales with an interest in tobacco and its impact on public health. It focuses on smoking and tobacco control but also on wider issues of health and well being such as the links between wealth and health inequality.\n\nThe network contains both individuals and organisations with members from many sectors, including academia, the tobacco control community, education, government, healthcare, local government, the media, the NHS, public health, and the private and voluntary sectors.\n\nThe Wales Tobacco Control Alliance (WTCA) is a network managed by ASH Wales to enable all third sector and professional organisations involved with tackling tobacco in Wales to inform and influence policy development and implementation. The WTCA came together to campaign for a comprehensive Tobacco Control Strategy for Wales and now work to monitor this plan and reduce the harm caused by tobacco use more generally. Since 2008 over 30 organisations have joined the WTCA. This includes other charities like Cancer Research UK, the British Heart Foundation, along with professional bodies such as the Royal College of Physicians and the British Medical Association.\n\nFollowing a campaign by the WTCA the Welsh Government published its Tobacco Control Action Plan in February 2012 which set out a comprehensive strategy containing ambitions to reduce adult smoking prevalence to 16% by 2020.\n\nIn New Zealand, ASH was formed in 1983. In 2011, the New Zealand Government set a target of making NZ smokefree by 2025.\n\n\n"}
{"id": "37659806", "url": "https://en.wikipedia.org/wiki?curid=37659806", "title": "Bio Products Laboratory", "text": "Bio Products Laboratory\n\nThe Bio Products Laboratory (BPL) is a company involved in the manufacture of human blood plasma products, located in Elstree in the United Kingdom. It is owned by the Creat Group, a Chinese investment firm. Before August 2016, it had been owned by Bain Capital (80%) and the UK Government (20%) via holding company Plasma Resources UK Ltd. BPL is run as a commercial business and supplies plasma derived products to the National Health Service in the UK as well as to markets in 45 countries.\n\nThe Blood Products Laboratory was established in 1954 as part of the Lister Institute of Preventive Medicine by the Medical Research Council. Lister purchased the Elstree site in 1902 and operated on the site until 1978.\n\nDuring this time, Professor R. A.Kekwick, working at the Lister Institute undertook experimental and production work with A.S. McFarlane. The two scientists devised a process to clarify outdated blood plasma to render it suitable for transfusion. Laboratory testing was undertaken in the historic Queensbury Lodge, the site of Joseph Lister's laboratory.\n\nIn 1943, Kekwick was appointed Head of the Lister's Biophysics Division, Kekiwick established the Blood Filtration Unit and he and his team worked on methods of freeze-drying plasma and then of separating out proteins in blood plasma. These early products were used tomeet the needs of the Armed Services and civilian establishments. In 1948 the Blood Filtration Unit came under the joint management of the Medical Research Council (MRC) and the Lister Institute, and the name was changed to the Blood Products Research Unit and it occupied the newly built laboratories (or ‘Building 25’). The aim of the Unit was directed towards the preparation of plasma fractions for clinical use\n\nDuring the 1940s, Brinkhous and McFarlane discovered that transfusions using whole blood or plasma provided a means of FVIII replacement. Applications using this early discover were limited due to naturally low concentrations of this anti-haemophilic factor in blood and plasma and volume constraints in the circulatory system.\n\nIn 1954, the Government wished to establish a site for increased production of blood products. This followed on from the importance of blood in therapeutic medicine, the need for blood products during the Second World War (particularly the use of albumin) and the formation on 26 September 1946 of the National Blood Transfusion Service. It had also been discovered that a second form of haemophilia (Haemophilia B) existed, which was treatable with blood protein called Factor IX. An agreement was reached between the Government, MRC and the Lister Institute and the Blood Products Laboratory was established with funding from the Ministry of Health. Enlarged facilities for plasma fractionation and freeze-drying were established.\n\nDuring the 1970s and 1980s it became apparent that Factor VIII products produced at the BPL site (and other products from other companies) had infected haemophiliacs with life-threatening viruses.\n\nIn 1991 it was renamed the Bio Products Laboratory to reflect the internal market in the National Health Service and in 1993 it became part of the National Blood Authority. BPL began cross-charging NHS hospitals for its products and limited competition in the international blood plasma market was permitted.\n\nIn 1998 the BPL began sourcing its plasma from the United States due to concerns over vCJD in the UK. In 2002 the Department of Health (DoH) formed DCI Biologicals Inc to purchase US company Life Resources Inc to supply all of the BPL's plasma.\n\nBPL became an operating division within new Special Health Authority, NHS Blood and Transplant, in 2005. This placed BPL alongside the National Blood Service and the organ transplant division, a strategic partnership to safeguard blood, tissues and blood products.\n\nOn 31 December 2010 the BPL was vested into a limited company, Bio Products Laboratory Ltd, and ownership transferred to the DoH, with BPL Ltd and DCI Biologicals Inc brought under the same DoH holding company, Plasma Resources UK Ltd.\n\nOn 18 July 2013 it was announced by Business Secretary Vince Cable that Bain Capital had bought 80% of Plasma Resources UK (PRUK) from the DoH for £230m, which included both BPL and DCI Biologicals. The company was subsequently renamed BPL Holdings, with the original BPL site now called BPL Therapeutics and DCI named BPL Plasma. In July 2016, Bain Capital sold BPL Holdings to Creat, a Chinese-based investment company who part own a Chinese plasma fractionator. In 2018, Creat announced plans to integrate BPL with the German plasma products manufacturer Biotest.\n\n\n"}
{"id": "55213580", "url": "https://en.wikipedia.org/wiki?curid=55213580", "title": "British HIV Association", "text": "British HIV Association\n\nThe British HIV Association (BHIVA) is an organisation of healthcare professionals interested in the treatment and care of people with HIV.\n\nThe current BHIVA Chair is Professor Chloe Orkin.\n\nThe aims of BHIVA are, to advance:\n\n\nBHIVA holds two national conferences per year, the BHIVA National Conference in April and the BHIVA Autumn Conference.\n\nBHIVA produce guidelines which are accredited by the UK National Institute for Health and Care Excellence (NICE).\n\n"}
{"id": "20965483", "url": "https://en.wikipedia.org/wiki?curid=20965483", "title": "Bullous keratopathy", "text": "Bullous keratopathy\n\nBullous keratopathy is a pathological condition in which small vesicles, or \"bullae\", are formed in the cornea due to endothelial dysfunction.\n\nIn a healthy cornea, endothelial cells keeps the tissue from excess fluid absorption, pumping it back into the aqueous humor. When affected by some reason, such as Fuchs' dystrophy or a trauma during cataract removal, endothelial cells suffer mortality or damage. The corneal endothelial cells normally do not undergo mitotic cell division, and cell loss results in permanent loss of function. When endothelial cell counts drop too low, the pump starts failing to function and fluid moves anterior into the stroma and epithelium. The excess fluid precipitates swelling of the cornea. As fluid accumulates between the basal epithelium cells, blister like formations form (bullae) and they undergo painful ruptures releasing their fluid content to the surface. These characteristic malformations disrupt vision and create pain sensations.\n\nDisease begins with vesicles that coalesce. There is severe progressing edema and rupture may occur in 24 hours or less.\nBullous keratopathy\n\nTreatment can include hyperosmotic eye drops to reduce swelling (5% sodium chloride), bandage contact lenses to reduce discomfort, glaucoma medications to reduce the flow of fluid into the cornea, and surgical procedures to replace the damaged tissue. The most common types of surgical treatment are Descemet's stripping automated endothelial keratoplasty (DSAEK) and Descemet's membrane endothelial keratoplasty (DMEK).\n\nKeratopathy is common in older people. Keratopathy occurs after cataract surgery, its incidence has decreased since the advent of intraoperative viscoelastic agents that protect the endothelium.\n"}
{"id": "46504486", "url": "https://en.wikipedia.org/wiki?curid=46504486", "title": "Capital punishment in Sudan", "text": "Capital punishment in Sudan\n\nCapital punishment in Sudan is legal under Article 27 of the Sudanese Criminal Act 1991. The Act is based on Sharia law which prescribes both the death penalty and corporal punishment, such as amputation. Sudan has moderate execution rates, ranking 8th overall in 2014 when compared to other countries that still continue the practice, after at least 29 executions were reported (although it is expected that over 100 occurred).\n\nEven though Sudan's legal systems have been drawn from various other jurisdictions, capital punishment has always existed in the country.\n\nDuring the last 100 years there have been a number of changes to Sudanese law. In the early 1900s until 1974 the death penalty was active in a legal system based on Indian criminal law, which in itself was influenced by Anglo-Saxon law. In 1974, during President Gaafar Nimeiry's time in office, large scale amendments to the penal code were carried out which included some elements of civil law. However, the civil law amendments were never integrated into the Sudanese penal code which caused a number limitations for the courts. After this failure the previous Indian influenced penal law was reinstated. The basis of the legal system continued its yoyo pattern when in 1983 the Nimeiry regime sought to promote the Muslim Brotherhood's version of Sharia law. Nimeiry's office revised a number of national laws to reflect this, including the penal code, only to have it repealed two years later and the 1974 criminal code restored once more. In 1991 the 1974 penal code was replaced for a second time by the 1991 Criminal Code which is still in use today. By this time President Omar Al-Bashir had come to power after a 1989 coup, led by the fundamentalist National Islamic Front (NIF). The reformations made by the Al-Bashir government helped to promote Islamisation in the country.\n\nThough the identifier \"criminal code\" was chosen over \"penal code\" due to the fact the new laws included provisions which would promote care and rehabilitation, the government had no plans to follow growing international opinion against the death penalty and, to the contrary, further entrenched the practice. Rather than begin to draw back, the scope of the application of the penalty has expanded since the introduction of the code. \nIn the most recent periodic report of the government of Sudan to the African Commission on Human and Peoples' Rights it states that Sudan sees no reason to abolish the death sentence.\n\n\nArticle (27)(1) of the 1991 Act states that:\n\n\"execution is either by hanging or stoning or in the same manner as the commitment of murder by the perpetrator, and may be as a hudud punishment or in retribution or approximation, and may be with crucifixion\n\nGenerally, however, the punishment is executed by hanging.\n\nFor a person charged with a capital crime in Sudan there are a number of procedural guarantees they should receive:\n\nThese guarantees are only available at trial stage meaning that during the investigation period individuals may be dangerously exposed, particularly because torture (though illegal under Sudanese law) has been documented on numerous occasions.\n\nThe following cases demonstrate the kinds of actions that have led to recent episodes of capital punishment in the country. \nAlthough Sudan is a signatory to the U.N Convention on the Rights of the Child until an amendment made in 2010, Sudan was still one of the few remaining countries whose death penalty extended to juveniles. One of the last juveniles to be killed by death penalty was Abdulrahman Zakaria Mohammed in May 2009. He had been found guilty of murder and robbery. The decision was decided based on two factors, as confirmed by the UN Special Rapporteur on independence of judges and lawyers; firstly, the prohibition of the death penalty for children did not extend to hudud offences, and secondly the Court believed that because the definition of 'adult' in the Criminal Act was \"any person whose puberty has been established by definite natural features and who has completed 15 years of age and whoever obtains 18 years of age shall be deemed an adult even if the features of puberty do not exist\". Using this definition of adult, the Court determined that Abdulrahman could be treated as an adult, even though he was only 17 at the time he was arrested. Also in 2009, four children between the ages of 15 to 17 were sentenced to death after being found guilty of armed robbery. \nIn 2007 two young women in their early 20s were sentenced to death by stoning for committing adultery under Article 146 (a) of the Criminal Act. The woman did not have legal representation nor assistance to help defend themselves.\n\nCriticism of capital punishment in Sudan usually centers on two rights protections: the protection to the right to life and the protection against cruel, inhuman or degrading treatment or punishment. These rights are both recognized in the Universal Declaration of Human Rights and the African Charter on Human and Peoples Rights.\n\nThere are a number of human rights violations that occur because of Sudanese law. For example, Article 126 (2) of the 1991 Criminal Act, which stipulates religious crimes that may result in capital sentencing, is a violation of the right to freedom of conscience and religious creed.\n\nAlso, though the procedural guarantees are consistent with international standards, they are limited in practice and the lack of access to bail is evidence of this. Sima Samar, the Special Rapporteur for Human Rights in Sudan has noted in the past that the lack of sufficient guarantees of a fair trial for the accused facing the death penalty demonstrates serious doubts about compliance.\n\n"}
{"id": "593481", "url": "https://en.wikipedia.org/wiki?curid=593481", "title": "Catalepsy", "text": "Catalepsy\n\nCatalepsy (from Greek κατάληψις \"seizing, grasping\") is a nervous condition characterized by muscular rigidity and fixity of posture regardless of external stimuli, as well as decreased sensitivity to pain.\n\nSymptoms include: rigid body, rigid limbs, limbs staying in same position when moved (waxy flexibility), no response, loss of muscle control, and slowing down of bodily functions, such as breathing.\n\nCatalepsy is a symptom of certain nervous disorders or conditions such as Parkinson's disease and epilepsy. It is also a characteristic symptom of cocaine withdrawal, as well as one of the features of catatonia. It can be caused by schizophrenia treatment with anti-psychotics, such as haloperidol, and by the anesthetic ketamine. Protein kinase A has been suggested as a mediator of cataleptic behavior.\n\nSt. Teresa of Avila experienced a prolonged bout of catalepsy that began in 1539. This episode was precipitated by the stress she was suffering at the Carmelite Convent of the Incarnation. Her legs became rigid, leaving her an invalid for three years. Teresa endured intermittent attacks of catalepsy from then on.\n\nIn the arts, catalepsy is often used for dramatic effect, sometimes as a plot device.\n\nIn Alexandre Dumas, père's novel \"The Count of Monte Cristo\", the Abbé Faria has fits of catalepsy from time to time, before eventually dying from one.\n\nIn Eugène Sue's \"The Mysteries of Paris\", the villain Jacques Ferrand experiences a fit described as cataleptic in his final confrontation with Rodolphe, blinded by lamplight and hallucinating with visions of his fantasized Cecily.\n\nIn George Eliot's \"Silas Marner\", the main character Silas Marner frequently has cataleptic fits and seizures. It is not mentioned if they are caused by any of the aforementioned factors.\n\nIn Arthur Conan Doyle's \"The Adventure of the Resident Patient\", a man feigns catalepsy to gain access to a neurologist's rooms; the doctor attempts to treat him with amyl nitrite.\n\nIn Ford Madox Ford's \"The Good Soldier\", the protagonist Dowell experiences catalepsy following the death of his wife.\n\nIn Robert A. Heinlein's \"Stranger in a Strange Land\", the main character Valentine Michael Smith is believed to have catalepsy when he is returned to Earth.\n\nIn Edgar Allan Poe's \"The Premature Burial\", the narrator develops catalepsy. He fears being mistakenly declared dead and buried alive, and goes to great lengths to prevent this. In another of Poe's short stories, \"The Fall of the House of Usher\", Madeline Usher has catalepsy, and is buried alive by her unstable brother Roderick. Catalepsy is also depicted in \"Berenice\", thus becoming one of the recurrent themes in Poe's fiction.\n\nIn Poppy Z. Brite's \"Exquisite Corpse\", the main character—Comptom, a serial killer (recreation of Jeffery Dahmer's life story) facing a lifetime sentence—uses shamanistic techniques to induce catalepsy, and, convincingly appearing deceased, is able to escape prison.\n\nIn Émile Zola's short story \"La Mort d'Olivier Becaille\" (\"The Death of Olivier Becaille\"), the title character is buried alive and notes that \"I must have fallen into one of those cataleptic states that I had read of\".\n\nIn Sax Rohmer's Fu Manchu novels, Dr. Fu-Manchu has a serum that induces a state of catalepsy so extreme as to be indistinguishable from death.\n\nIn Charles Dickens's novel \"Bleak House\", Mrs. Snagsby has violent spasms before becoming cataleptic and being carried upstairs like a grand piano.\n\nIn Hegel's \"Lectures on the History of Philosophy: Greek Philosophy to Plato\", Hegel describes Socrates as having catalepsy caused by magnetic somnambulism when in deep meditation.\n\nIn Charles Williams's novel \"Many Dimensions\", Sir Giles Tumulty says to Lord Arglay, the Chief Justice of England: \"You are a louse-brained catalept, Arglay.\"\n\nIn Philip K. Dick's novel \"Now Wait for Last Year\", Kathy Sweetscent becomes immobilized by withdrawal from JJ-180, an alien (and highly addictive) drug. \"My God, Kathy thought as she stood gazing down at the record by her feet. I can't free myself; I'm going to remain here, and they'll find me like this and know something's terribly wrong. This is catalepsy!\"\n\nIn the second chapter of Álvares de Azevedo's \"Noite na Taverna\", character Solfieri rescues a woman who has catalepsy from inside a coffin.\n\nIn Sam Taylor's \"Kiki\" (1931), Mary Pickford feigns a case of catalepsy to keep from being removed from the apartment of the man she secretly loves.\n\nIn the soap opera \"La Traición\", the main character, Hugo De Medina, has catalepsy. Later in the telenovela, it is revealed that his daughter, Aurora, has the same illness.\n\nIn \"Chavo del Ocho\", the main character, El Chavo, would have cataleptic-like seizures if frightened, where he would curl as if sitting down in a chair and become stiff. However, he could be healed by being splashed with water.\n\nIn the 1965 Roman Polanski film \"Repulsion\", Catherine Deneuve's character shows signs of the condition through her erratic and unexplainable behavior.\n\nIn two \"\" episodes, \"Statistical Probabilities\" and \"\", the character Sarina Douglas, a genetically-enhanced human woman, exhibits cataleptic symptoms. In \"Chrysalis\", Dr. Bashir promises to do everything he can to cure her of the disorder, and is ultimately successful.\n\nIn \"The Premature Burial (film)\" based on the short story by Edgar Allan Poe, the protagonist is buried alive during a cataleptic episode, as his lack of response to external stimuli causes his family and doctors to believe him to be dead.\n\nIn \"The Fisher King\" (1991), Robin Williams' character Parry has this condition after witnessing the brutal murder of his wife.\n\nIn \"Isle of the Dead\" (1945), Katherine Emery's character suffers from a multitude of illness' that render her almost incapable of caring for herself. Of these many illness' she is subject to catatonic trances which inevitably lead to her demise.\n\nIn a second-season episode (\"Halloween\" - 1993) of Doctor Quinn, Medicine Woman, several residents of the town believe they have seen a dead man, only to have him disappear before they return with Dr. Quinn, who thinks they are playing Halloween pranks on her. Dr Quinn eventually sees the man have a seizure and diagnoses him with catalepsy.\n\n"}
{"id": "45468600", "url": "https://en.wikipedia.org/wiki?curid=45468600", "title": "Charles Basch", "text": "Charles Basch\n\nCharles Basch is the Richard March Hoe Professor of Health and Education at Teachers College, Columbia University, New York City, New York. He teaches courses related to epidemiology, planning and evaluation. Before coming to Teachers College, he was Assistant Professor of Community Health Education at Russell Sage College in Troy, New York.\n\nHe earned his B.S. and M.S. in community health education at the State University of New York at Brockport and his Ph.D. in health education at Southern Illinois University Carbondale, where he studied under four of the field's most prominent leaders, Robert S. Gold, David F. Duncan, Elena Sliepcevich, and Robert Russell.\n\nBasch's main scholarly interests are improving understanding of (1) health-related decision making, (2) dissemination and implementation of effective health-related programs and policies, and (3) the influence of health factors on educational outcomes in urban minority youth. In particular, he has documented a link between childhood health and learning in school. His research identifies seven factors (poor vision, asthma, teen pregnancy, aggression and violence, physical inactivity, ADHD, and insufficient breakfast) that can and do lead to health disparities and contribute to poorer academic achievement. He notes that students will perform and learn better every day if they are \"well-rested and well-nourished\". During his 25 years at Teachers College, he has directed approximately $15 million of grant-funded research and program development (primarily supported by the National Institutes of Health), and he continues to do so. His work has yielded over 100 scholarly publications.\n\n\n"}
{"id": "46213861", "url": "https://en.wikipedia.org/wiki?curid=46213861", "title": "Childbirth in Iraq", "text": "Childbirth in Iraq\n\nChildbirth in Iraq is marked by a fertility rate of 4.0 births per woman, a contested but high maternal mortality rate and a moderately high infant mortality rate.\n\nIn 2015 Iraq's fertility rate was reported by the World Health Organization at 4.0 births per woman.\n\nMaternal mortality is a much debated figure in Iraq. In 2010 the CIA World Factbook reported maternal mortality at 63 deaths/100,000 births. Iraq's Ministry of Health and the WHO reported in 2011 the maternal mortality rate at 84 death per 100,000 births. That would categorize Iraq as one of the 68 countries that account for 97% of the maternal and child deaths globally. In 2013 the two organizations were divided on the issue with the WHO reporting maternal mortality at 64 deaths per 100,000 and Ministry of Health reporting 25.\n\nIn 2014 total infant mortality in Iraq was reported 37.53 deaths/1,000 live births: male: 41.57 deaths/1,000 live births and female: 33.28 deaths/1,000 live births.\n\nIn 2013, the World Health Organization reported the contraception use rate at 53% for the population of Iraq, up from 32.9% in 2010.\n\nIn 2009, the United Nations reported that in Iraq abortion was only permitted to preserve a women’s life. It was not allowed in the case of rape or incest, to preserve a women’s physical or mental health, for economic or social reasons, or on request.\n\nThere are three types of pregnancy care providers in Iraq; midwives, obstetricians, and traditional birth attendants. Midwives practice in hospitals and in their home or the home of their client. They are educated in hospital based programs, but there is interest in expanding midwifery education to the university level. Once licensed, a midwife receives a plaque with her license number that she displays outside the door of her home. This lets potential clients know that she has the appropriate credentials. Midwives do not have prescribing privileges but may obtain certain medications from a physician if they are working outside of a hospital. Obstetricians are university educated and work in hospitals. Traditional birth attendants work only in clients homes \n\nIn 2006: 84% of women had at least one prenatal visit with skilled personnel.\nOf the women who received antenatal care:\n63% had a urine sample,\n66% had a blood test, and\n76% had their blood pressure taken.\nA client's weight was taken less than the other measurements.\n\nIn 2011, 74% of recorded births in Iraq took place in a hospital or birth center, 79% of urban births and 67% of rural births.\n\nIn 2011, 89% of births in Iraq were attended by a skilled birth attendant. Sixty percent were attended by a public or private doctor and 28% were attended by a nurse-midwife or certified midwife. Traditional birth attendants, called jiddas, attended 10% of the births. For hospital births, no family members are allowed to accompany the women into the hospital. For a home birth, a women's mother or sister is often present \n\nWomen in Iraq generally expect that there will be pain with labor and delivery. An absence of pain is often interpreted as a poor progress in labor. Epidurals are not commonly used in public hospitals in Iraq.\n\nIn 2006, 20% of recorded births in Iraq were via Caesarean section. The rate was higher in private hospitals and the likelihood increased with a woman's age and education level \n\nA recent report found that only 20% of newborns in Iraq are exclusively fed breast milk for the first six months. There is often pressures to switch to formula feeding, though this can be unsafe in a country such as Iraq where clean drinking water is not always available.\n\nFemale circumcision is controversial in Iraq. While it is not widespread throughout the country, it is still common practice in Iraqi Kurdistan. The decision to perform female circumcision is often made by the mother or grandmother on religious, social, or purity grounds. Negative consequences to the child's health include bleeding, sepsis, shock, psychological disorders, obstetrical complications, and urogenital problems. In 2010 the United Nations released a report that placed the prevalence of female genital mutilation at 78% of women in Kurdistan. A more recent survey of 1,508 women in Kurdistan recorded a prevalence of 23% of women, with the mean age at which it performed being 4.6 years old. Traditionally the procedure is performed at home by a midwife, traditional birth attendant, or relative. In 2011 a law was passed which made female circumcision illegal in Iraqi Kurdistan\n\n"}
{"id": "41926463", "url": "https://en.wikipedia.org/wiki?curid=41926463", "title": "Controlled Oral Word Association Test", "text": "Controlled Oral Word Association Test\n\nControlled Oral Word Association Test, abbreviated COWA or COWAT, is a verbal fluency test that measures spontaneous production of words belonging to the same category or beginning with some designated letter. \n\nThe test was first called the \"Verbal Associative Fluency Test\", and then was changed to the \"Controlled Word Association Test\".\n\nThe participant is usually asked to name words beginning with a letter, excluding proper nouns, for one minute and this procedure is repeated three times. The most commons letters used are FAS because of their frequency in the English language. The examiner must quickly write down the words provided by the participant on a piece of paper. The whole examination usually takes 5–10 minutes.\n"}
{"id": "34504565", "url": "https://en.wikipedia.org/wiki?curid=34504565", "title": "Crowding", "text": "Crowding\n\nCrowding is a perceptual phenomenon where the recognition of objects (or graphemes) presented away from the fovea is impaired by the presence of other neighbouring objects (sometimes called \"flankers\"). It has been suggested that crowding occurs due to mandatory integration of the crowded objects by a texture-processing neural mechanism.\n\nCrowding deficits have been specifically found in neuropsychiatric disorders such as schizophrenia and autism and may have profound clinical implications in these disorders.\n\nIf objects remain within your visual field over time, then priming (psychology) begins to occur and the objects become less cluttered.\n"}
{"id": "12787266", "url": "https://en.wikipedia.org/wiki?curid=12787266", "title": "Dokha", "text": "Dokha\n\nDokha (Arabic: دوخة, literal translation \"dizziness\" or \"vertigo\") is an Arabian tobacco product, consisting of dried and finely shredded tobacco flakes mixed with herbs and spices. It originated in Iran during the 15th century. Unlike hookah tobacco (also called \"shisha\" or \"mu'assel\"), dokha is not cured with molasses. Users smoke the tobacco blend in small quantities using a pipe called a midwakh. Because the midwakh pipe is used almost exclusively for smoking dokha, the terms are often used interchangeably. \n\nDokha has a higher concentration of nicotine compared to other forms of tobacco, and can cause brief periods of euphoria, relaxation or lightheadedness in some users. As using the midwakh also reportedly leaves less lingering smells, and requires less tobacco to be used at a time, it can be used discreetly, which has made it popular among student populations and young adults.\n\nThe product is popular in the United Arab Emirates (UAE), Oman, Qatar, Saudi Arabia, Bahrain, Jordan, and other Middle Eastern countries. It has reportedly spread to Europe and other regions via immigration, tourism and trade. Scientific research on the health effects of dokha use is lacking, but officials have concerns over the use of the product as a touted cigarette alternative, and preliminary studies have quantified dokha's high nicotine and tar concentration, as well as toxins present in its smoke. Notable concern in the UAE over the spreading popularity of dokha among teenagers and young adults has led to multiple tobacco control efforts to curb its use.\n\nDokha tobacco and its derivatives have been cultivated and used in Middle Eastern countries for approximately 500 years. It originated in Iran during the 15th century, as use spread among sailors in the Caspian Sea, which lead to it's eventual spread throughout all of the Middle East during the following centuries. Traditionally, dokha consists of dried and ground tobacco leaves, blended with herbs, spices, dried flowers and fruits. Depending on local traditions, bark and leaves of native plants were also used.\n\nModern dokha maintains many of the characteristics of its traditional forms, consisting of tobacco and spices without any preservatives, pesticides, herbicides or additives that are commonly used in mass-produced tobacco products. \n\nUnlike most tobaccos, dokha is not fire cured and cut, but dried in the arid desert region from whence it was harvested. It is finely ground to preserve the strength, freshness and flavor of the tobacco. Due to the lesser degree of processing, dokha tobacco appears essentially unaltered, maintaining the green color of the natural plant. The tobacco is then blended with other spices and herbs to create the final product. In many countries where dokha is used, there are a number of available tobacco strengths (typically described in Arabic as \"hot\", \"warm\" or \"cold\"), which indicate the harshness of a particular blend.\n\nDokha is regulated by most countries in the same manner as they would other tobacco products. \nThe UAE passed \"Federal Law No. 15 regarding Tobacco Control\" in December 2009, making the legal age to purchase tobacco (including dokha) 18 years old. The law also made smoking in cars (with children under 12 present), houses of worship, educational campuses and health/fitness centers, illegal. This law was expanded in 2012 by adopting GSO standards that require tobacco packaging warning messages. \n\nIn October 2015, the Dubai Municipality issued warnings to 40 dokha shops to obtain certificates of conformity from the UAE Authority for Standardization and Meteorology . The shops were required to discontinue the practices of allowing customers to sample dokha in the shop and cleaning their midwakh pipes for them in order to obtain these certificates. Despite these efforts, there were still concerns from local leaders and health officials over shopkeepers illegally selling dokha and midwakh pipes to underage customers, and teenage use of tobacco continued to rise.\n\nAn excise tax was introduced on October 1, 2017 on tobacco products in an effort to discourage their consumption. There was confusion among dokha users and retailers as to whether all dokha products, or only specific dokha brands, were subject to the excise tax. A poll the following year showed that one in four smokers said that the new tax changed their habit.\n\nIn May 2018, new regulations were approved by the UAE's National Tobacco Control Programme by the Ministry of Health and Prevention. Intended to be in place by the end of the year, the regulations set purchase restrictions specifically on dokha products. They also ban the practice of bottling and refilling larger quantities at home or in shops, which has been the local custom, and require dokha product packaging to include pictorial warnings (the same way other types of tobacco products were required to have per the 2012 law).\n\nDokha is almost exclusively smoked out of an elongated pipe called a midwakh (alternatively spelled 'medwakh'). The traditional midwakh has no filter, but more recent variations contain a removable, stem-mounted filter. A small container called a chanta is sometimes used to store and dispense the tobacco. Approximately 0.5-1 grams of dokha tobacco is smoked at a time, and is usually smoked in about two inhalations. One study estimates that the typical daily user of dokha consumes approximately 6 grams, or 12 smoking sessions. \n\nA preliminary study found dokha has significantly more nicotine than other tobacco products such as shisha or cigarettes. Nicotine produces various pharmacologic and psycho-dynamic effects in the brain within seconds, which generally last for 30 seconds to several minutes, depending on the user's nicotine tolerance. These include euphoria, increased alertness and a sense of relaxation and dokha is known for a strong production of these effects, which allows it to quickly satisfy nicotine cravings. \n\nUsers sometimes describe the sensation as 'dizziness', which is where dokha's name (meaning 'dizziness' or 'vertigo' in Arabic) is presumed to be derived. Dokha does not traditionally contain other psychoactive substances, such as cannabis or hashish. \n\nWhile dokha is not a relatively new alternative tobacco product, it's use has had a noted increase in the Middle East, particularly in the UAE, and especially among males aged 20-39, during the 2000s and 2010s. Experts speculate this may be due to tobacco control efforts' exclusive focus on cigarette use, coupled with the fact that dokha and midwakh usage in these countries has become the second-most popular form of tobacco, after cigarettes. \n\nCulminating in legislative efforts in 2009 and 2018, there has also been particular concern in the UAE that teenagers may be getting easier access to dokha tobacco when they are unable to obtain cigarettes, and that dokha has quickly become popular among young adults. Dokha's reported lack of lingering smells (compared to other forms of smoked tobacco) and the relatively smaller amount of material smoked in a given session, make it a convenient form of discreetly and quickly satisfying nicotine cravings, which has made dokha popular among underage smokers. One study assessing the prevalence of dokha smoking among secondary school students in the UAE found that 39% had ever smoked tobacco products, 36% had ever smoked dokha specifically, and 25% of them were now current users of dokha, which is very high compared to other forms of smoking.\n\nDokha use has seen some emergence in the Western world, and some health officials speculate this may be due to immigration, globalized commerce, and internet sales, but such a trend has not been definitively studied or proven. Retail companies specifically catering to dokha smokers can now be found in the United Kingdom, and more tobacco shops in the UK are stocking dokha and midwakh accessories to fill a gap in the market, which some company representatives claim is driven by increased immigration from Middle Eastern countries. There have been some reports that dokha may be spreading in popularity in India due to one successful startup company offering the product. \n\nPersonal accounts from users and marketing materials from dokha retailers claim that the relatively smaller amount of material smoked in a midwakh, or the lack of some additives in dokha, make it a less risky form of tobacco. Health professionals consider this a myth, that dokha is likely just as or more dangerous than other forms of smoking, and that more research is needed to investigate the adverse effects, as there is little comparative study between dokha and other tobacco products.\n\nA February 2018 study called for further research into the harmful effects of dokha smoke after it found that three different types of dokha tested from the Middle East and North Africa region contained toxic metals comprising \"22 irritants, 3 known carcinogens, 5 central nervous system depressants, in addition to several other compounds with miscellaneous effects\".\n\nIn September 2018, a University of Sharjah study compared the nicotine and tar levels in dokha to other tobacco products, which found dokha had significantly higher levels of both. Nicotine in dokha was measured at 23.83-52.8 mg/g compared to 0.8-20.52 mg/g in shisha, and 0.5-19.5 mg/g in cigarettes. Tar in dokha was measured at 21.6-45.02 mg/g compared to 1.68-11.87 mg/g in shisha and 5-27 mg/g in cigarettes.\n\nFew studies have been performed on the acute effects specific to dokha use, but one uncontrolled study among male UAE medical university students assessed the following:\n\n\nAs dokha consists of tobacco and other plant material, health officials suspect the health effects from prolonged use are similar or identical to that of other tobacco products, but as of 2018 there have been no clinical studies to identify the long-term risks specific to it.\n\nOne study concluded that oral lesions are a possible chronic side effect of irritation from the midwakh pipe.\n\nSome of the health risks of chronic tobacco smoking in general, that have been identified, are:\n\n\n"}
{"id": "25869952", "url": "https://en.wikipedia.org/wiki?curid=25869952", "title": "Emergency Medical Services for Children", "text": "Emergency Medical Services for Children\n\nThe Emergency Medical Services for Children (EMSC) program is a US federal government health initiative. It is administered by the U.S. Department of Health and Human Services’ Health Resources and Services Administration (HRSA), and the Maternal and Child Health Bureau (MCHB). Its aim is to reduce child and youth disability and death due to severe illness or injury by increasing awareness among health professionals, provider and planners and the general public of the special (physiological and psychological) needs of children receiving emergency medical care.\n\nIn the Korean and Vietnam wars, medical experience demonstrated that survival rates improved dramatically when patients were stabilized in the field and transported immediately to a well-equipped emergency facility. During the 1960s, civilian medical and surgical communities recognized the possibility of applying this principle to an EMS system.\n\nIn 1973, Congress passed the Emergency Medical Services Systems Act of 1973. Managed by the HRSA, it provided funding for more comprehensive state and local government EMS systems. Between 1975 and 1979, state EMS systems dramatically improved outcomes of adult patients but not those of pediatric patients. In 1979, Calvin C.J. Sia, MD, then-president of the Hawaii Medical Association, requested that the members of the American Academy of Pediatrics (AAP) develop EMS programs designed to decrease disability and death in children. Dr. Sia was joined by José B. Lee, then-executive officer of the Hawaii Medical Association Emergency Medical Services Program in requesting that U.S. Senator Daniel K. Inouye introduce legislation to establish, implement and fund a national initiative designed to address emergency medical services for children systems development. Soon after, Senator Daniel Inouye (D-HI) responded to this request by introducing a legislative vehicle in the United States Senate. His staff assistant and chief of staff Patrick DeLeon's daughter was hospitalized with meningitis. The girl's treatment demonstrated the shortcomings of an average emergency department when treating a critically ill child. Senators Orrin Hatch(R-UT) and Lowell Weicker(R-CT) also gave their support. In 1984, Congress enacted legislation (Public Law 98-555) authorizing the use of federal funds for emergency medical services for children (EMSC). By this law, and through the administration of the MCHB, the EMSC program obtained funds to improve the pediatric capabilities of existing emergency medical services systems. In 1985, Congress designated initial funding for the EMSC program and in 1986, the first federal grants were utilized in Alabama, California, New York, and Oregon.\n\nThe federal EMSC program is designed to ensure that all children and adolescents receive appropriate care in a health emergency. Since 1985, the EMSC program has provided grants to all states, and the District of Columbia, five U.S. territories, and three Freely Associated States. Additional EMSC program funding has been used to establish national resource centers and a pediatric emergency care research network.\n\nTo measure the effectiveness of federal grant programs, the HRSA requires grantees to report on specific performance measures related to their grant funded activities. The measures are part of the Government Performance Results Act (GPRA). In order to receive or continue to receive Program funds, all EMSC grantees must provide data on measures 71 to 80:\n\nThe program works with a variety of national and professional organizations to identify and address the key issues affecting EMS, including but not limited to: managed care, disaster preparedness, children with special health care needs, mental health, family-centered care, and cultural diversity. The program develops national task forces and publishes comprehensive reports drawing attention to many of these issues.\n\nIn 2013, the American Academy of Pediatrics, the American College of Emergency Physicians, the Emergency Nurses Association, and the EMSC cooperated in a quality improvement project. Approximately 5,000 EDs were offered an assessment of their department's readiness, based on six topic areas published in the 2009 Guidelines for the Care of Children in the Emergency Department (or National Guidelines). The assessment was conducted over a period of seven months. The response rate of EDs was over eighty percent. Assessments were completed by August 2013. Upon completion of their assessment, each emergency department was given a pediatric readiness score, a gap analysis and access to an on-line toolkit to assist in quality improvement initiatives.\n\nIn collaboration with the Emergency Nurses Association and the Society of Trauma Nurses, the EMSC developed the Inter Facility Transfer Tool Kit for the Pediatric Patient. The toolkit includes an algorithm for developing transfer processes; talking points; example guidelines, agreements, and memorandums of understanding; and case presentations.\n\nThe American College of Surgeons Committee on Trauma, the National Association of EMS Physicians, the American College of Emergency Physicians (ACEP), and the EMSC Partnership for Children Stakeholder Group collaborated to revise the recommended equipment list for ambulances. This revised document was to be used to evaluate the availability of pediatric equipment and supplies for basic and advanced life support.\n\nDuke University and the AAP convened a multidisciplinary panel provide recommendations to improve pediatric medication safety in the emergency department.\n\nThe George Washington University School of Public Health and Health Services Department of Health Policy and the NRC published an issue brief entitled \"The Application of the Emergency Medical Treatment and Labor Act (EMTALA) to Hospital Inpatients\".\n\nThe Federal Interagency Committee on EMS and the EMSCNRC conducted a gap analysis of EMS related research. The analysis included over 270 articles. Its aim was to provide an evidence base for decision makers.\n\nThe EMSCNRC has collaborated with the Pediatric Emergency Care Applied Research Network (PECARN), the first federally funded pediatric emergency medicine research network.\n\n"}
{"id": "52936021", "url": "https://en.wikipedia.org/wiki?curid=52936021", "title": "Federación Latinoamericana de Hipnosis Clínica", "text": "Federación Latinoamericana de Hipnosis Clínica\n\nThe Federación Latinoamericana de Hipnosis Clínica (“Latin American Association for Clinical Hypnosis”) was a Latin American professional association for clinical hypnosis.\n\nThe association was founded in the 1950s following Milton H. Erickson′s hypnotherapy with the aim of networking and professional training as well as raising public awareness for the benefits of hypnosis. Amongst their founding members were Isaac Gubel′s Sociedad Argentina de Hipnoterapia. The association included, among others, two Argentinian, four Brazilian, one Chilean, two Colombian, one Spanish, one Peruvian, one Uruguayan and five Verenzolan associations for clinical hypnosis.\n\nThe association held regular meetings in various countries of the continent. Its publication organ, the \"Revista Latino-Americana de Hipnosis Clínica\", was published under the editorial direction of Isaac Gubel from November 1959. Other publications were the \"Acta hipnológica latinoamericana\" and the \"Hipnología\".\n\nThe organization is not to be confused with the Confederación Latinoamericana de Hipnosis Clínica y Experimental.\n"}
{"id": "15121650", "url": "https://en.wikipedia.org/wiki?curid=15121650", "title": "Fistula Foundation", "text": "Fistula Foundation\n\nThe Fistula Foundation is a not-for-profit 501(c)(3) organization focused on treatment of obstetric fistula, funding more repair surgeries than any other organization. The organization is dedicated to providing obstetric fistula treatment worldwide, and does this by channeling funds toward fistula surgeon training, equipment and facility upgrades that make fistula treatment as safe as possible, and by funding the full cost of obstetric fistula repair surgery for poor women who would otherwise not be able to access treatment. Fistula Foundation has been recognized by several organizations for its transparency and efficiency, earning a top \"A\" rating from Charity Watch and a four star rating from Charity Navigator for 12 years in a row. Fistula Foundation has also been selected as one of 20 charities recommended by Princeton Professor Peter Singer's organization, The Life You Can Save.\n\nThe Fistula Foundation was founded in 2000. It is headquartered in San Jose, California. Since its inception, it has raised more than $55 million from donors from more than 60 countries. Until 2008, the Foundation supported only the work of Hamlin Fistula Ethiopia, founded by Dr. Catherine Hamlin and her husband Reginald Hamlin. Since 2009, the Foundation has extended its reach, having funded grantee partners in a total of 31 countries across Africa and Asia. The organization funds sites in more than 20 countries.\n\nThe primary focus of Fistula Foundation is treatment, either directly through fistula repair surgeries, or indirectly through training of surgeons and the provision and equipping of medical facilities. Countries where the Foundation has supported projects include Afghanistan, Angola, Bangladesh, Benin, Burundi, Cameroon, Chad, Democratic Republic of the Congo, Ethiopia, Guinea-Bissau, Guinea, Kenya, Liberia, Madagascar, Malawi, Mauritania, Mozambique, Nepal, Niger, Nigeria, Pakistan, Rwanda, Senegal, Somalia, Somaliland, Sudan, South Sudan, Tanzania, Uganda, Zambia and Zimbabwe.\n\nFistula Foundation also funds surgeon training, growing the pool of skilled fistula surgeons with the ability to perform what can be a very complex surgery. The organization funds the FIGO Fistula Training Initiative, which works to build the capacity of fistula surgeons in accredited training centers using the FIGO Global Competency-Based Fistula Surgery Training Manual. The manual is the only global competency-based standard for fistula surgeon training, and was authored by a former Foundation Board Chair, Dr. Sohier Elneil.\n\nFistula Foundation is run by CEO Kate Grant, who joined the organization in 2005 as its first chief executive. Under her leadership, the Foundation has grown from supporting one facility in one country to a global organization that has since funded treatment across 31 countries. During her tenure the Foundation more than quadrupled its revenue and has supported more than 10 times the number of fistula treatment surgeries it supports. In 2014, Ms. Grant was the recipient of the prestigious American Marketing Association Foundation \"Nonprofit Marketer of the Year Award.\"\n\nThe Foundation has a seven-member Board of Directors; the chair is Bill Mann. Fistula Foundation meets all Better Business Bureau Standards of Charity Accountability and has received the top 4-Star Rating from Charity Navigator for the last twelve years, placing it in the top 1% of charities nationwide.\n\nThe Foundation is a partner of the United Nations Population Fund’s Campaign to End Fistula. Other partners include Women and Health Alliance (WAHA), Direct Relief, the International Federation of Gynaecology and Obstetrics (FIGO) and the International Society of Obstetric Fistula Surgeons (ISOFS). The Foundation was a primary funder of the Global Fistula Treatment Map. \n\nFistula Foundation has received funding and supplies from Johnson & Johnson. The company has partnered with Fistula Foundation for the last decade, providing more than $1 million in support.\n\nFistula Foundation also works in Kenya to run the Action on Fistula program, an initiative designed to treat women, train more fistula surgeons and build a lasting national network of treatment partners, funded by Astellas Pharma EMEA. Since its launch in 2014, the program has treated over 2,700 women, added six facilities to a nationwide fistula treatment network, certified six new Kenyan fistula surgeons at FIGO global competency level, and reached more than 500,000 community members through outreach events designed to educate communities about obstetric fistula, how to identify it and where to receive treatment. \n\nThe Foundation was a primary sponsor of the documentary film \"A Walk to Beautiful\" which won the Best Feature-Length Documentary of 2007 from the International Documentary Association as well as an Emmy for best long form documentary in 2008. The film tells the story of five Ethiopian women treated by Dr. Hamlin and her staff at the Addis Ababa Fistula Hospital. PBS's \"NOVA\" is the other major sponsor of the documentary.\n\nMore recently, the Foundation has been mentioned several times by Nicholas D. Kristof in the \"New York Times\" and is a featured NGO partner of the Half the Sky Movement, a movement surrounding the PBS documentary film release of the book that Kristof authored with wife Sheryl WuDunn: \"Half the Sky: Turning Oppression into Opportunity for Women Worldwide\". This campaign includes the popular Facebook-based game, Half the Game. Thanks to generous support from Johnson & Johnson, players of this game can help fund fistula treatment in the real world, through online actions in the game.\n\nComedian Louis C.K. won $50,000 for the Fistula Foundation in May 2016 on the \"Jeopardy!\" \"Power Players\" edition. The Foundation continues to generate high profile attention through Grant's articles for \"The Huffington Pos\"t, as well as in major international publications, such as Ms. Grant's 2016 contribution to \"The Guardian\". The Foundation was also featured in Kenyan television (CitizenTV, NTV) for celebrating the grand opening of the Gynocare Women's & Fistula Center, a hospital funded by Foundation's donors.\n\n"}
{"id": "5547816", "url": "https://en.wikipedia.org/wiki?curid=5547816", "title": "Franciscan Sisters of Mary", "text": "Franciscan Sisters of Mary\n\nThe Franciscan Sisters of Mary is a Roman Catholic religious congregation of religious sisters based in St. Louis, Missouri, which was formed in 1987 from the merger of two related congregations. The congregations founded hospitals throughout the Midwestern United States, which the current congregation still operates.\n\nThe congregation has its origins in St. Louis in the work of Mother Mary Odilia Berger who had emigrated from Germany in 1872 with four companions. The original congregation was the Sisters of St. Mary (S.S.M.). They received their name because their residence shared a door with St. Mary of Victories Church in downtown St. Louis.\n\nAnna Katherine (later Mother Odilia) Berger was born in Regen in the Kingdom of Bavaria. In 1858 she joined the Poor Franciscan Sisters of the Holy Family of Pirmasens, Germany, founded by the Blessed Paul Joseph Nardini and was sent to beg in Paris.\n\nIn Paris she co-founded the Sisters Servants of the Sacred Heart in 1866 with the Abbé Peter-Victor Braun, but had to flee Paris when the city was besieged during the Franco-Prussian War. Berger spent several years in Elberfeld in the Rhineland, where she tried to start a new community with the same goals. Frustrated in this goal by the government of the \"Kulturkampf\", she and four of her companions emigrated to St. Louis in 1872. In 1874 they founded the Sisters of St. Mary under the Rule of the Franciscan Third Order Regular.\n\nIn 1877 the congregation borrowed what was then the enormous sum of $16,000 in order to open St. Mary's Infirmary in St. Louis. In 1878 Berger sent a third of the members of the congregation to Canton, Mississippi, and Memphis, Tennessee, during a Yellow fever outbreak in those cities. Five young sisters were to die as a result.\n\nIn 1894 Mother Mary Augustine Giesen led six other Sisters to Maryville, Missouri, from St. Louis. After settling there, they eventually chose to separate from the founding congregation and they formed the Sisters of St. Francis of Maryville.\n\nThe new congregation focused on health care in the more rural areas of Missouri. They established the first full-fledged hospital in the town. They later expanded to the Oklahoma Territory, where they established the first hospital.\n\nThe two congregations continued to grow in their numbers and work. With the reduced numbers of both congregations by the late 20th century, however, in May 1985 the members of both congregations voted to merge into a new one. In August 1987 the sisters came together to form the Franciscan Sisters of Mary. In 2010 the 80-year-old convent was vacated at St. Mary's Hospital in the Richmond Heights suburb of St. Louis, as the sisters moved to smaller quarters or a retirement home.\n\nTwenty hospitals and two nursing homes founded by the congregation are now operated as SSM Health Care (SSMHC) in Illinois, Missouri, Oklahoma and Wisconsin.\n\n"}
{"id": "709031", "url": "https://en.wikipedia.org/wiki?curid=709031", "title": "Graz School", "text": "Graz School\n\nThe Graz School (also Meinong's School) of experimental psychology and object theory was headed by Alexius Meinong, who was professor and Chair of Philosophy at the University of Graz where he founded the Graz psychological institute (in 1894).\n\nAmong his pupils were Stephan Witasek, Vittorio Benussi, R. Ameseder, Konrad Zindler, Wilhelm Maria Frankl, Eduard Martinak, Ernst Mally and F. Weber.\n\nAlso his earlier students, Christian von Ehrenfels (founder of \"Gestalt\" psychology), Alois Höfler, Adalbert Meingast, and Anton Oelzelt-Newin, can be considered part of this school.\n\nThe Graz School was part of the wider movement of Austrian realism.\n\n"}
{"id": "24443937", "url": "https://en.wikipedia.org/wiki?curid=24443937", "title": "Healthcare in Iceland", "text": "Healthcare in Iceland\n\nHealthcare in Iceland is universal. The healthcare system is largely paid for by taxes (85%) and to some extent by service fees (15%) and is administrated by the Ministry of Welfare. A considerable portion of government spending is assigned to health care. There is almost no private health insurance in Iceland and no private hospitals.\n\nHealthcare providers in Iceland fall into one of the following legally defined categories of healthcare providers:\n\n\nHealth care system in Iceland relies on general taxation, instead of local funding. This is affected by the Nordic welfare state model, in which public service is heavily funded through taxation to support the general public, in order for the population to have equal access to health care and welfare system. Although local authorities have limited influence over the national health care system, Iceland has recently adapted to similar structures to other Nordic countries, implementing decentralized structure by dividing the country into seven local health care regions. The health care regions were implemented to promote cooperations between institutions, and to provide quality care through regional provisions. However, this has not affected the financial responsibility of the central government. Although health care is usually funded through taxation, some out-of-pocket expenses are still required, such as service fees. Iceland does not operate its health care system based on financial need, but some disadvantaged groups, including disabled and elders, generally receive discounts on personal health expenses.\n\nAs of recently, out-of-pocket expenditure has increased significantly, resulted in approximately 76% increase in private expenditure from 1995 to 2010. By 2011, Iceland's out-of-pocket payments have become an important financial source for the universal health care system, which made up 18.2% of total health expenditures. The general population, however, still showed overwhelming support for governmental funding and providing the health care system at the same time. Through a research survey conducted in 2013 focused on Icelandic adults, in which 94% of the respondents want the government to spend more on public health care, and 81% of the respondents prefer and supports primary health care to be provided by the government. Although the government aimed to provide easy and accessible health care to all population regardless of income and social status, there are still some problems faced due to benefits given to disadvantaged groups. Some people without additional help face postponement or even cancellation to medical treatment.\n\nHealth centers that provide primary health care are located throughout the country, while some runs along smaller institutes and hospitals, all are funded and administered by central government. In accordance with the 1973 Health Care Act, which established universal primary health care and increase the amount of health personnel and institutes in the country, all patients are required to register and access through a primary care center and a general practitioner of their choice. Specialist services are provided mainly by general practitioners, privately operated or publicly funded.\n\nThere are a total of 6 regional hospitals and 16 health institutions throughout the country, funded through fixed global budgets. The main hospital is located in Reykjavik. Most hospital professionals and doctors are salaried employees, and are paid through hospital budgets. Doctors can also see private patients outside of the hospitals if they receive 80 percent of less.\n\nLong-term care can be accessed through institutions or at home. These includes personal assistance and domestic care, including nursing homes or child care. These services are provided by either private institutes or public services, and are funded through national budgets. Part-time and home-based child care are payable but subsidized, priority are given to special interest groups.\n\nIceland does not have its own specialist medical training system, so Icelandic doctors typically spend 8 or 10 years working abroad before returning to the country. They often use the relationship established in training for ongoing support.\n\nThe country is divided into 7 healthcare districts which correspond to the 8 regions of Iceland with the exception of the Northwestern Region and the Northeastern Region which are a single healthcare district.\n\n\nThere are two hospitals in Iceland, both of which are general and specialised.\n\n\n"}
{"id": "2465061", "url": "https://en.wikipedia.org/wiki?curid=2465061", "title": "Heinrich Khunrath", "text": "Heinrich Khunrath\n\nHeinrich Khunrath (c. 1560 – 9 September 1605), or Dr. Henricus Khunrath as he was also called, was a German physician, hermetic philosopher, and alchemist. Frances Yates considered him to be a link between the philosophy of John Dee and Rosicrucianism.\n\nKhunrath was born in Dresden, Saxony, the son of the merchant Sebastian Kunrat and his wife Anna in the year 1560. He was the younger brother of the Leipzig physician Conrad Khunrath. In the winter of 1570, he may have enrolled at the University of Leipzig under the name of Henricus Conrad Lips. The uncertainties surrounding his life stem from his supposed use of multiple names. It is certain that in May 1588, he matriculated at the University of Basel, Switzerland, earning his \"Medicinæ Doctor\" degree on 3 September 1588, after a defense of twenty-eight doctoral theses.\n\nKhunrath, a disciple of Paracelsus, practiced medicine in Dresden, Magdeburg, and Hamburg and may have held a professorial position in Leipzig. He travelled widely after 1588, including a stay at the Imperial court in Prague, home to the mystically inclined Habsburg emperor Rudolf II. Before reaching Prague he had met John Dee at Bremen on 27 May 1589, when Dee was on his way back to England from Bohemia. Khunrath praised Dee in his later works. During his court stay Khunrath met the alchemist Edward Kelley who had remained behind after he and Dee had parted company (Kelley was arrested on 30 April 1591 as an alleged imposter). In September 1591, Khunrath was appointed court physician to Count Rosemberk in Trebona. He probably met Johann Thölde while at Trebona, one of the suggested authors of the \"Basilius Valentinus\" treatises on alchemy.\n\nKhunrath's brushes with John Dee and Thölde and Paracelsian beliefs led him to develop a Christianized natural magic, seeking to find the secret \"prima materia\" that would lead man into eternal wisdom. The Christianized view that Khunrath took was framed around his commitment to Lutheran theology. He also held that experience and observation were essential to practical alchemical research, as would a natural philosopher.\n\nHis most famous work on alchemy is the \"Amphitheatrum Sapientiae Aeternae\" (Amphitheater of Eternal Wisdom), a work on the mystical aspects of that art, which contains the oft-seen engraving entitled \"The First Stage of the Great Work\", better-known as the \"Alchemist's Laboratory\". The book was first published at Hamburg in 1595, with four circular elaborate, hand-colored, engraved plates heightened with gold and silver which Khunrath designed and were engraved by Paullus van der Doort. The book was then made more widely available in an expanded edition with the addition of other plates published posthumously in Hanau in 1609. \"Amphitheatrum Sapientiae Aeternae\" is an alchemical classic, combining both Christianity and magic. In it, Khunrath showed himself to be an adept of spiritual alchemy and illustrated the many-staged and intricate path to spiritual perfection. Khunrath's work was important in Lutheran circles. John Warwick Montgomery has pointed out that Johann Arndt (1555–1621), who was the influential writer of Lutheran books of pietiesm and devotion, composed a commentary on \"Amphitheatrum\". Some of the ideas in his works are Kabbalistic in nature and foreshadow Rosicrucianism.\n\nKhunrath may have encountered some opposition to his alchemical work because most of his publications on alchemy were published widely after his death. He died in either Dresden or Leipzig on 9 September 1605. The tension between spirituality and experiment in \"Amphitheatrum Sapientiae Aeternae\" brought about its condemnation by the Sorbonne in 1625.\n\n\n\n"}
{"id": "18768921", "url": "https://en.wikipedia.org/wiki?curid=18768921", "title": "Hydrolethalus syndrome", "text": "Hydrolethalus syndrome\n\nHydrolethalus syndrome (HLS), less commonly referred to as Salonen-Herva-Norio syndrome, is a rare genetic disorder that causes improper fetal development, resulting in birth defects and, most commonly, stillbirth.\n\nHLS is associated with HYLS1 mutations. The gene encoding HYLS1 is responsible for proper cilial development within the human body. Cilia are microscopic projections that allow sensory input and signalling output within cells, as well as cell motility. Dysfunction results in a range of abnormalities that are often the result of improper cell signalling. A variant form, HLS2, with additional mutations to the \"KIF7\" gene, is less common. \"KIF7\" also ensures correct cilia formation and function, specifically cilia stability and length.\n\nHydrolethalus syndrome (HLS) was first mistakenly identified in Finland, during a study on Meckel syndrome. Like HLS, Meckel syndrome presents with severe physiological abnormalities, namely disruptions to the central nervous system and the presence of extra fingers or toes (polydactyly). HLS can be distinguished from Meckel syndrome by analysing kidney function, which is dysfunctional in Meckel syndrome as a result of cyst formation.\n\nHLS presents itself as various, lethal developmental abnormalities, which often result in either premature stillbirth or death shortly after birth. Rare cases of children born with HLS surviving for several months have been noted. A characteristic abnormality of HLS is an absence of brain tissue and midline structures, with the presence of excess brain fluid (hydrocephalus) as a result of abnormal development of the central nervous system. Other common defects include incomplete lung development, heart defects, a cleft lip or palate, polydactyly, and an abnormally small jaw. Stillbirth and an excess of amniotic fluid (polyhydramnios) are common during pregnancy with a HLS-affected foetus, with cases of up to 8 litres cited compared to the normal 1 litre. Less common symptoms such as abnormally small eyes and a broad nose are also possible.\n\nHLS is caused by a genetic missense mutation of the \"HYLS1\" gene, encoding for Hydrolethalus syndrome protein 1, on chromosome 11; a single base change to the amino acid sequence for \"HYLS1\" in exon 6 involves the replacement of aspartic acid 211 with glycine (D211G) in the polypeptide chain. Exon 6 is the only protein coding exon in \"HYLS1\"; proper functioning of exons 1-5 ensures regulation and expression of the entire protein.\nHLS is an autosomal recessive syndrome; development is only possible if both parents carry the defective gene, and in that instance, the risk of the foetus developing the syndrome is 25%. HLS is a member of the Finnish disease heritage, with incidences more common in Finland than the rest of the world; roughly 1 in 20,000 developing foetuses are affected in Finland. Rare cases in other regions have also been documented, often with less severe phenotypes as a result of allele variability across countries, allowing survival of affected offspring for up to several months. Individuals of Finnish descent are advised to undergo genetic testing before attempting to conceive.\n\nPrior to the discovery of HLS, the \"HYLS1\" gene was unknown, and similar genes within humans have not been identified. Orthologs, genes in other species with common ancestral heritage, have been examined to explain the pathophysiology of HLS; a similar gene within the roundworm, \"Caenorhabditis elegans\", is responsible for the formation of cilia. Current hypotheses place a dysfunction of cilia as the main cause of HLS defects arising from the \"HYLS1\" mutation in humans.\nDifferences between wild type and mutant \"HYLS1\" have been clearly observed; the wild type form is localised to the cytoplasm, while the mutant form is localised to the nucleus and forms small clusters, suggesting that the mutant gene disrupts cellular localisation. The protein encoded by the \"HYLS1\" mutant form is unable to carry out essential targeting of centrioles to the plasma membrane, disrupting ciliary function, which results in ciliopathy. As cilia are located in almost all cells throughout the body, cilial dysfunction causes developmental defects in a range of organs and thus the phenotype of HLS can vary greatly, though brain malformation and polydactyly are most commonly observed.\n\nCurrently, no environmental factors are known to increase the likelihood of HLS development or progression; HLS is caused only by genetic abnormalities.\n\nThe pathophysiology of HLS is abnormal cilia development arising from the inability of the mutated \"HYLS1\" gene to correctly target centrioles to the plasma membrane. Specifically, transition fibres within the transition zone, at the base of the axoneme and adjoining to the plasma membrane, lack proper development. As these structures form the cilial gate, improper development results in a loss of selectivity for protein entry into the ciliary compartment.\n\nHLS can be readily diagnosed during pregnancy through the use of ultrasound, which will often reveal hydrocephaly and an abnormal structure of the brain.\nPrecise examination via ultrasound or at birth is necessary to rule out Meckel syndrome, Trisomy 13, or Smith-Lemli-Opitz syndrome, which present with similar physiological defects. HLS can be detected at the end of the first trimester, approximately 13 weeks gestation.\n\nNo cure or treatment option for individuals with HLS currently exist. Due to the severity of the foetal defects and the poor prognosis for those with HLS, the pregnancy is often terminated. Certain prevention can only be achieved by avoiding conception if genetic testing indicates both prospective parents as carriers of the defective \"HYLS1\" gene.\n\nMutations in \"KIF7\" have also been noted in patients that present a similar phenotype to HLS and the characteristic \"HYLS1\" A to G transformation; homozygous deletion of the \"KIF7\" gene causes a variant form of HLS, HLS2. \"KIF7\" encodes a structural factor vital to cilial transport, and is also implicated in other developmental disorders, such as Joubert syndrome (JS).\nAdditionally, mutations in \"HYLS1\" are no longer explicitly connected to HLS in humans. Homozygous mutations removing the stop codon in exon 4 of \"HYLS1\" result in a different genomic sequence disruption to the missense mutation of HLS, and phenotypically present as JS. The ‘molar tooth sign’ of the brain, an anomaly in which cerebellar volume is reduced but cerebellar shape is retained, resembles the molar tooth and is used to identify JS. JS presents with mutations in more than 30 genes, whilst the \"HYLS1\" mutation is the sole cause of HLS, but is also present in the HLS2 variant form with the mutated \"KIF7\" gene.\n\n•HYLS1\n"}
{"id": "38270856", "url": "https://en.wikipedia.org/wiki?curid=38270856", "title": "Hyeminseo", "text": "Hyeminseo\n\nHyeminseo () was the medical authority of the Joseon Dynasty in Korea. The officers were in charge of the treatment of commoners and medicine.\n\nIn 1392, the year of the foundation of Joseon, the organ was established to succeed the Hyemingoguk (), the former medical institution of Goryeo. In 1414, its name became Hyeminguk (), and then finally changed to the name Hyeminseo in 1466 under the reign of Sejo of Joseon. It was abolished in 1882.\n\nThe officers were in charge of producing medicines, teaching disciplines, researching Korean medicine. Generally, four people were put to as the disciplines. Bureaucrats of Hyeminseo were also appointed through the \"gwageo\" recruitment examination.\n\nHyeminseo aimed to benefit the people but its coverage was limited to commoners living in Hanyang (now Seoul). There was another medical authority called Hwalinseo (). Collectively, the two were referred to as Yanguisa ().\n\n"}
{"id": "18796901", "url": "https://en.wikipedia.org/wiki?curid=18796901", "title": "Hyperprothrombinemia", "text": "Hyperprothrombinemia\n\nHyperprothrombinemia is a state of high of prothrombin levels in the blood which leads to hypercoagulability. An example of a genetic cause includes the mutation prothrombin G20210A.\n\n"}
{"id": "42139218", "url": "https://en.wikipedia.org/wiki?curid=42139218", "title": "ISO 45001", "text": "ISO 45001\n\nISO 45001 is an ISO standard for management systems of occupational health and safety (OH&S), published in March 2018. The goal of ISO 45001 is the reduction of occupational injuries and diseases.\n\nThe standard is based on OHSAS 18001, conventions and guidelines of the International Labour Organization including ILO OSH 2001, and national standards. It includes elements that are additional to BS OHSAS 18001 (see below: \"ISO 45001 changes compared to OHSAS 18001:2007\") which it is replacing over a three-year migration period from 2018 to 2021. \n\nISO 45001 also follows the High Level Structure of other ISO standards like ISO 9001:2015 and ISO 14001:2015 which makes integration of these standards much easier. \n\nISO 45001 was proposed at the ISO in October 2013. The committee ISO/PC 283, created in 2013, had direct responsibility for the standardization process. At least 70 countries contributed to the drafting process. Preparation and committee work lasted until December 2015. From 2015 to 2017, a first draft failed to gain sufficient approval from ISO members and was revised in a second draft, which was approved and refined into a final draft. In the final vote the standard garnered 62 votes in favour, nine abstentions and four votes against from France, India, Spain, and Turkey. The standard was published on 12 March 2018.\n\nISO 45001 is set to replace OHSAS 18001 over three years following its publication. It uses the management system standard structure guideline Annex SL to allow for simplified integration with other management system standards, such as ISO 9001 and ISO 14001. The International Accreditation Forum has published requirements for migration from OHSAS 18001 to ISO 45001.\n\nISO/IEC TS 17021-10:2018 is a technical specification setting out competence requirements for auditing and certification of ISO 45001.\n\nISO 45001 was adopted as a national standard by Albania, Argentina, Austria, Belgium, Brazil, Bulgaria, Chile, Costa Rica, Croatia, Denmark, Estonia, Finland, Germany, Greece, Hungary, Ireland, Italy, Malaysia, Netherlands, Norway, Poland, Romania, Serbia, Singapore, Slovenia, Sweden, Switzerland, Turkey, the United Kingdom, and Uruguay. Adoption as a national standard is under consideration in Australia.\n\n\n<div class=\"references-small\">\nn-[1]\n\n"}
{"id": "13971089", "url": "https://en.wikipedia.org/wiki?curid=13971089", "title": "Instituto Nacional de Medicina Legal", "text": "Instituto Nacional de Medicina Legal\n\nThe Instituto Nacional de Medicina Legal, I.P. (National Legal Medicine Institute) is a Portuguese government-owned organization under direct supervision of the Portuguese Ministry of the Justice, which provides forensic science services to the police forces and government agencies of Portugal. The national headquarters of the Instituto Nacional de Medicina Legal are in Coimbra. Its main general branches are located in Coimbra, Lisbon and Porto, and are linked with the legal medicine departments at the University of Coimbra, University of Lisbon and University of Porto.\n\nThe institute has laboratories throughout the country, and provides scene-of-crime and forensic investigation staff. Its principal functions are to provide forensic pathology and related scientific services, clinical forensic medicine services, teaching and research.\n\n"}
{"id": "12796320", "url": "https://en.wikipedia.org/wiki?curid=12796320", "title": "International Society for Bipolar Disorders", "text": "International Society for Bipolar Disorders\n\nThe International Society for Bipolar Disorders (ISBD) is a non-profit organization based in Pittsburgh, Pennsylvania, where it was founded June 17, 1999. The society focuses on research and education in bipolar disorders.\n\nThe society has a membership consisting of mental health professionals and patients and their family members representing 50 countries. The mission of the society is to advance the treatment of all aspects of bipolar disorder, thereby improving patient outcomes and quality of life, through fostering international collaboration in education and research. The society hosts biennial professional meetings and offers educational programs. The official journal of the society is \"Bipolar Disorders\" and a subscription is included with membership.\n\nThe ISBD was founded at the 3rd International Conference on Bipolar Disorder, in Pittsburgh, Pennsylvania in June 1999 by David J. Kupfer and Thomas Detre (University of Pittsburgh Medical Center). In September 1999, the official peer-reviewed society journal, \"Bipolar Disorders\", published its first issue.\n\nThe ISBD held its first meeting in Sydney, Australia in February 2004 with over 400 participants in attendance. The society held its second meeting in August 2006 in Edinburgh, Scotland with over 600 attendees. , the society has over 800 members in 50 countries with an elected board representing 15 countries. The president is Willem Nolen.\n\nThe society supports the following educational initiatives:\n\nThe society organizes biennial meetings that provides updates on topics such as epidemiology, pharmacotherapy, psychotherapies, genetics, neurobiology, imaging research, and bipolar disorder in special populations.\n"}
{"id": "57157259", "url": "https://en.wikipedia.org/wiki?curid=57157259", "title": "Japanese Medical Marijuana Association", "text": "Japanese Medical Marijuana Association\n\nThe Japanese Medical Marijuana Association (, \"Iryō taima o kangaeru kai\") was founded in 1999 and seeks to improve access to medical cannabis. Its status under Japanese law is Specified Nonprofit Corporation (特定非営利活動法人). Due to the illegality of cannabis in Japan, the organization has investigated leveraging legal medical cannabis in Guam for Japanese patients.\n\nIn 2014, JMMA president Koichi Maeda met with Guamanian senator Tina Muña-Barnes regarding Guam's medical cannabis program. In 2017, Maeda returned and met with governor Eddie Calvo. Maeda's intent was to develop Guam as a destination for Japanese people seeking cannabis remedies, and for the JMMA to promote cannabis medical tourism to Guam.\n\nJapan's strict laws prevent Japanese citizens from using cannabis even when outside of Japan. However, Maeda stated that Japanese citizens with incurable diseases would be exempt from this law.\n\n"}
{"id": "9182699", "url": "https://en.wikipedia.org/wiki?curid=9182699", "title": "Kumugwe", "text": "Kumugwe\n\nKumugwe (also Komokwa or Goomokwey) (pronounced \"koo-moo-gwee\") is a figure in the mythology of Pacific Northwest peoples. Known as \"Copper-Maker\", he is the god of the undersea world revered by the Kwakwaka'wakw and Nuxalk indigenous nations. He has a house under the sea filled with riches, and his name means \"wealthy one\". He is sometimes identified as one and the same as Qaniqilak, the spirit of the summer fishing season, and is then regarded as the adversary of Tseiqami otherwise known as Thunderbird, the guiding spirit of the Winter Hamatsa Dance season.\n\nKumugwe is master of the seals. The posts and beams of his house are living sea lions. Sometimes he appears on the surface of the sea, but his head is so big that it looks like an island. He is responsible for the rising and ebbing of the tides, as well as the riches these tides deposit on beaches, and those claimed by the vagaries of sea weather, both material and human lives. One terrific story recounts how he eats human eyes as if they were crab apples. Kumugwe has the power to see into the future, heal the sick and injured, and bestow powers on those whom he favors.\n\nMany heroes went on quests to reach his undersea abode; those who made it were rewarded with riches and spirit magic. His world is guarded by the octopus. Sometimes Kumugwe himself is conceived of in octopus form. Kumugwe would teach the hero who entered his abode the ways of the sea, and give him gifts of blankets, coppers, songs, masks, and regalia. These items of mystical regalia are called Tlugwe (or Tlokwe) in Kwak'wala. \n\nOne of Kumugwe's epithets is \"Copper Maker.\" He has a wife named Tlakwakilayokwa, which means \"Born to Be Copper Maker's Woman.\" She is also sometimes named Kominaga. \n\nMasks of Kumugwe often show him with sea creature attributes, such as rounded fish eyes, and rows of gills at the corners of his mouth, not to mention fins encircling his head, the suction cups of an octopus, fish and aquatic birds which frame or sit upon his head. His most important totemic animals are loons, seals, sea lions, octopuses, orcas, and sculpins.\n\n"}
{"id": "268062", "url": "https://en.wikipedia.org/wiki?curid=268062", "title": "Lac de Serre-Ponçon", "text": "Lac de Serre-Ponçon\n\nLake Serre-Ponçon (; Vivaro-Alpine: \"Lac de Sèrra Ponçon\") is a reservoir in the departments of Hautes-Alpes and Alpes-de-Haute-Provence, Provence-Alpes-Côte d'Azur region, in southeast France, one of the largest in Western Europe. The lake gathers the waters of the Durance and the Ubaye rivers, flowing down through the Hautes-Alpes and the Alpes du Sud to the Rhône River. The waters are dammed by the , a high earth core dam.\n\nAs well as water control, sixteen hydroelectric plants use the water (with additional water control supporting), and the lake provides irrigation to of land.\n\nThe lake was created to control water flow after disastrous floods caused severe damage and loss of life in 1843 and 1856. First proposed in 1895, construction started in 1955 and was completed by 1961.\n\nDuring construction of the lake, approximately of material was moved. The dam was constructed and the valley slowly became a lake, flooding some villages in the process. This flooding is the subject of Jean Giono's movie \"Girl and the River\" (1958), starring Guy Béart.\n\nAccording to the official website of the Muséoscope, the \"museum of the largest dam in Europe made of compacted soil\", Lac de Serre-Ponçon includes a hydroelectric power plant with a 380 MW generator. In addition to the power plant on the lake itself, the dam provides the reservoir and overall water management to facilitate an additional 15 hydroelectric plants along the Durance and Verdon rivers in south-eastern France, with total capacity of 2,000 MW.\n\nNeighboring communes:\n\n\n"}
{"id": "149132", "url": "https://en.wikipedia.org/wiki?curid=149132", "title": "Leighton Moss RSPB reserve", "text": "Leighton Moss RSPB reserve\n\nLeighton Moss RSPB reserve is a nature reserve in Lancashire, England, which has been in the care of the Royal Society for the Protection of Birds since 1964. It is situated at Silverdale near Carnforth, on the edge of Morecambe Bay and in the Arnside and Silverdale Area of Outstanding Natural Beauty. \n\nLeighton Moss contains the largest area of reed beds in north-west England. The site provides habitats for many species of wildlife, including bitterns and red deer. As a wetland of international importance, it was designated a Ramsar site in 1985. It is a Site of Special Scientific Interest, a Special Protection Area, and an Important Bird Area.\n\nThe RSPB reserve also protects an area of Morecambe Bay, where a saltmarsh provides a habitat for birds such as avocets.\n\nIn 1822 the moss came into the possession of Richard Gillow, grandson of the Lancaster furniture manufacturer Robert Gillow. Using steam technology, Gillow drained the moss for agriculture. Although the soil is of good quality, by 1918 the land was flooded again, as drainage appeared to have become uneconomic. The area was used for duck shooting.\n\nThe RSPB initially leased the moss and then purchased it from the Leighton Hall estate.\n\nThe reserve is entered through the visitor centre (a converted farmhouse) containing a shop and a tea-room. The centre also contains an education room.\n\nThere are seven observation hides, which were renewed in 2012 with funding from the Heritage Lottery Fund. One is named after comedian Eric Morecambe. There are also nature trails.\n\nThe reed beds are managed to prevent them drying out and also to prevent saline intrusion from the coast. Despite such control of ecological succession, the breeding bittern population (measured by \"booming\" males) has been in decline. This may be related to the reed beds being relatively mature. \n\nIn 2015 there was controversy about a plan to cull \"excess\" numbers of deer, which were blamed for damaging the reeds.\n\nIn 2013 Leighton Moss hosted the BBC's \"Autumnwatch\" programme. The programme returned in 2014.\n\nThe reserve and visitor centre are open daily all year round (except Christmas Day) from 9 am to dusk and the visitor centre from 9.30 am – 5 pm (4.30 pm November–January inclusive). Entrance is free for RSPB members, and half price for those who come by public transport, bicycle or on foot. Silverdale railway station is just a few minutes' walk away. The reserve is on a proposed cycle way around Morecambe Bay.\n\n"}
{"id": "9023090", "url": "https://en.wikipedia.org/wiki?curid=9023090", "title": "Lists of UN numbers", "text": "Lists of UN numbers\n\nThe UN numbers range from UN0001 to about UN3600 and are assigned by the United Nations Committee of Experts on the Transport of Dangerous Goods.100793049071\n\n\n\n\n\n"}
{"id": "42369757", "url": "https://en.wikipedia.org/wiki?curid=42369757", "title": "Macroom Oatmeal", "text": "Macroom Oatmeal\n\nMacroom Oatmeal is a traditional stone-ground Irish oatmeal produced in Macroom, County Cork, Ireland, at Walton's Mill, the last surviving stone mill in Ireland. It was taken aboard Slow Food's Ark of Taste in 2011, one of only seven Irish foods ever selected for the ark.\n\nThe mill has been operated continuously by the same family since the 1700s. Donal Creedon, great-great-great-great-grandson of founder Richard Walton, now operates the mill. Michelin star-winning chef Myrtle Allen developed the Macroom Biscuit recipe which appears on the package.\n\nMacroom oatmeal is stone-ground, then kiln-toasted.\n\nSaveur Magazine called it \"different from anyone else's in Ireland, full of flavor when simply cooked and immensely satisfying in its grainy texture.\" Food writer John Thorne said it \"may well be the best oatmeal I've ever eaten.\" Fodor's Ireland mentions Macroom Oatmeal. Darina Allen of Ballymaloe House, where Macroom Oatmeal is served for breakfast, said that Macroom Oatmeal has \"a cult following both at home and abroad.\" James Beard 2010 Cookbook of the Year \"The Country Cooking of Ireland\" says \"(t)he best oatmeal for Stirabout...is Macroom, milled by Donal Creedon in the town of that name in County Cork.\"\n"}
{"id": "58823163", "url": "https://en.wikipedia.org/wiki?curid=58823163", "title": "Michele Barry", "text": "Michele Barry\n\nMichele Barry is Director of the Stanford University Center for Innovation in Global Health, and in 2018 was awarded the Elizabeth Blackwell Medal by the American Medical Women's Association.\n\nA qualified physician and Fellow of the American College of Physicians, Barry has been Director of the Center for Innovation in Global Health at Stanford University since 2009, and is also Senior Associate Dean for Global Health at Stanford\".\" In 2011 she also became a Fellow of the American Society of Tropical Medicine and Hygiene, of which she was also a past president. She was elected to the National Academy of Medicine.\n\nPrior to her appointment at Stanford, Barry was a Professor of medicine at Yale University and had worked at the university for 28 years. She is an advocate for women's rights in the medicine profession, and during her time at Yale, she wrote the first policy for maternity leave in the Department of Medicine. She created the Women Leaders in Global Health conference in response to the underrepresentation of women in leadership positions in global health.\n\nShe is Director of the Yale/Stanford Johnson & Johnson Global Health Scholars Program, which sends physicians to low resource settings in overseas countries, to improve health infrastructure.\n\nHer research interests are in the fields of global health, tropical medicine, and emerging infectious diseases. She has written on the potential for pandemic disease in fragile states and areas of unrest and civil war, published in the journal Daedalus, which she sees as an important but underrepresented research area. Her research approach is transdisciplinary, taking into account the local context of global health issues such as infectious disease. In her work she highlights how areas of global unrest are often centres of emerging disease, and the complexities of the situation and of solutions.\n\nIn 2018 Barry was awarded the Elizabeth Blackwell Medal, a prize awarded annually by the American Medical Women's Association, to a woman physician for her outstanding contribution to the cause of women in medicine.\n\nIn 2010, she received the Ben Kean Medal, awarded to a clinician or educator for their dedication to clinical tropical medicine.\n\nBarry is married to Mark Cullen, also a doctor, and has two daughters.\n\n"}
{"id": "9569750", "url": "https://en.wikipedia.org/wiki?curid=9569750", "title": "Ninazu", "text": "Ninazu\n\nNinazu in Sumerian mythology was a god of the underworld, and of healing. He was the son of Enlil and Ninlil or, in alternative traditions, of Ereshkigal and Gugalana, and was the father of Ningiszida. In the text Enki and Ninhursag he was described as the consort of Ninsutu, one of the deities born to relieve the illness of Enki.\n\nNinazu was the patron deity of the city of Eshnunna until he was superseded by Tispak. His sanctuaries were the E-sikul and E-kurma. Unlike his close relative Nergal, he was generally benevolent.\n\nMichael Jordan, \"Encyclopedia of Gods,\" Kyle Cathie Limited, 2002\n\n"}
{"id": "430716", "url": "https://en.wikipedia.org/wiki?curid=430716", "title": "Nursing home care", "text": "Nursing home care\n\nNursing homes, also known as convalescent homes, are a type of residential care that provide around-the-clock nursing care for elderly or disabled people. Twenty-four-hour nursing care is available. Nursing homes will provide short-term rehabilitative stays following a surgery, illness or injury which may require physical therapy, occupational therapy or speech-language therapy. Nursing homes offer other services such as planned activities and daily housekeeping services. Nursing homes may also be referred to as convalescent care, skilled nursing or a long-term facility. Nursing homes may offer memory care services or have a separate area specified for memory care.\n\nStarting in the 17th century, the concept of poorhouses (also referred to as almshouses) were brought to America by English settlers. All orphans, mentally ill and the poor elderly were placed into these living commons. These poorhouses gave a place where they could be given shelter and daily meals. Poorhouses continued to exist into the early 20th century despite the criticism they faced. Much of the criticism stemmed from the conditions of the poorhouses. The Great Depression overwhelmed the poorhouses as there were a lot of people that needed help and care but not enough space and funding in the poorhouses. Due to Muck Raking in the 1930s the less than favorable living conditions of the poorhouses were exposed to the public. Poorhouses were then replaced with a different type of residential living for the elderly. These new residential living homes were called board-and-care homes or also known as convalescent homes. These board-and-care homes would provide basic levels of care and meals in a private setting for a specific fee. Board-and-care homes proved to be a success and by World War 2, the new way of nursing homes began to take shape. As the times continued to change, the government identified the issue of people spending extensive amounts of time in hospitals. To combat these long stays in short-term settings, board-and-care homes began to convert into something more public and permanent that was state and federally funded. From this, by 1965 nursing homes were a solid fixture. Nursing homes were a permanent residence where the elderly and disabled (poor elderly and disabled specifically) could receive any necessary medical care and receive daily meals. Though nursing homes in the beginning were not perfect, they were a huge step above almshouses and poorhouses in regards to following laws and maintaining cleanliness. From the 1950s through the 1970s the dynamics of nursing homes began changing significantly. Medicare and Medicaid began to make up much of the money that would filter through the homes and the 1965 amendment laws enforced nursing homes to comply with safety codes and required registered nurses to be on hand at all times. Later in 1987, the Nursing Reform Act was introduced to begin defining the different types of nursing home services and later added the Residents' Bill of Rights. Today nursing homes are very different across the board. Some nursing homes still resemble a hospital while others look more like a home. Nursing home residents can pay for their care out of pocket, others may receive medicare for a short time and some may use long-term insurance plans. Across the spectrum, most nursing homes will accept medicaid as a source of payment.\n\nIn most jurisdictions, nursing homes are required to provide enough staff to adequately care for residents. In the U.S., for instance, nursing homes must have at least one registered nurse RN available for at least 8 straight hours a day throughout the week, and at least one licensed practical nurse on duty 24 hours a day.\n\nNursing homes require that an RN be present to assess residents and to monitor their outcomes. The RN's job duties include implementing care plans, administering medications, recording and maintaining accurate reports for each resident, monitoring and recording medical changes and providing direction to the nursing assistant and licensed practical nurses or licensed vocational nurses. To be allowed to work as a Registered Nurse, one must complete a nursing program at one of several educational levels, including associate and bachelor degree programs, hospital-based diploma programs and master's degree programs. Licensed practical nurses complete a state-approved one-year program. Both registered nurses and licensed practical nurses must pass a national licensing exam before they can begin working. The LPN or LVN monitors residents’ well-being and administers treatments and medications, such as dressing wounds and dispensing prescribed drugs as directed by the Registered Nurse. \n\nA nursing assistant provides basic care to patients while working directly under an LPN/LVN or RN. These basic care activities, also referred to as activities of daily living, can include assisting with bathing and dressing residents, helping residents with meals, either serving them or with feeding, transferring to and from the bed or wheelchair, making and cleaning beds, assisting with toileting, and answering call lights. Training to become a nursing assistant is offered at some high schools, as well as at vocational-technical schools, community colleges, and nursing homes. These programs are typically three months to one year in length depending on the program. Nursing assistants are then listed on the state healthcare registry. Nursing assistants' titles can range from facility to facility, the job titles include Certified Nursing Assistants (CNA's), nursing aides, caregivers, patient care associates, patient care techs and care assistants\n\nDepending on the size of the nursing home, a nursing home may have either a nursing home administrator or an executive director. Some nursing homes may have both but their job duties are similar and can include overseeing staff, supplying medical supplies and financial matters. The nursing home administrators/ executive director's career requires at least a bachelor's degree and some advanced positions may require a master’s degree. There are certain classes that are commonly taken in this path of study, these classes include nursing home administrative practices, aging and long term care, gerontology and aging, and health behavior. You may also find human resources employees in a nursing home. This job requires at least a bachelor's degree and usually preferred related work experience. These employees are in charge of all aspects of hiring new employees. Human resources job duties vary but can also include coordinating payroll, organizing orientation programs for new employees, interviewing, disciplinary actions, and ensuring compliance with federal and state laws. Nursing homes are usually licensed and heavily regulated under governing legislation. Compliance with the federal and state legislatures are reviewed regularly for adherence to strict standards of building codes, care plans, behavior and altercations between residents, nutrition and dietary services, medical services, nursing and personal care, religious and spiritual practices, pets, and recreational programs.\n\nHousekeepers are an important part of up keeping nursing homes. Housekeepers play a huge part in ensuring that nursing homes are kept clean and free of disease causing agents. Housekeepers have a long list of duties which include cleaning floors, changing linens, disinfecting bathrooms, changing towels, washing clothes, emptying garbage cans, sanitizing rooms, replenishing supplies, dusting and polishing furniture, vacuuming, and keeping windows and woodwork clean. These duties can be  different from facility to facility but will overall include basic cleaning. Housekeeping does not require any licensure or schooling, but some housekeeping jobs may prefer prior job experience.\n\nRecreational staff usually include an activity director and possibly activity assistants depending on the size of the nursing home. The activity director job requires an associate degree or a bachelor's degree and allows for further certifications through the National Council for Therapeutic Recreation. Activities are planned that aim to meet each residents emotional, intellectual, physical, social, spiritual, and vocational needs. The transition from being independent to having to depend on others and be away from home is oftentimes very difficult, which is why activities are important to combat depression and anxiety. Some of the different activities that may be offered include hosting birthday parties, celebrating holidays, book clubs, musical events, outdoor activities, discussion and social groups, exercise, arts and crafts, pet therapy, religious services and community outings. Volunteer involvement is also an important part of nursing home activities given that volunteers can act as a link between the nursing home and the outside community.\n\nOne of the many services offered in a nursing home is occupational therapy. Occupational therapy may be necessary following an injury or illness in order to regain skills and to receive support during any physical or cognitive changes. Occupational therapy will focus on activities of daily living such as bathing, dressing, grooming. Occupational therapy also assists with instrumental activities of daily living which include home and financial management, rest and sleep, education, work, play, leisure, and social participation. Occupational therapists work to allow the person to safely and comfortably reintegrate into society by practicing public dining, transferring to different surfaces (chairs, beds, couches etc.), and will assess the need for any home modifications or safety equipment to ensure a proper and safe transition. When a cognitive and/or perceptual deficit is presented, therapists will work with the person by teaching strategies to maximize memory, sequencing and attention span length. \n\nAnother important service found in a nursing home is physical therapy. Physical therapy may be necessary following an injury, illness or surgery. Physical therapy works with the person to help them regain strength, endurance, flexibility, balance and range of motion. Physical therapy is also used as a way of preventing injuries and accidents by focusing on restoring mobility, increasing fitness levels, reducing pain and overall reaching a certain point of independence. There are many conditions that can benefit from receiving physical therapy in a nursing home, these conditions include arthritis, pain associated with cancer, dementia, Alzheimer's, stroke and incontinence.\n\nSpeech-language pathology is another service found in a nursing home. Speech language pathologists specialize in working with those who have a difficult time with language and/or speech, usually following an injury or an underlying diagnoses. The SLP will evaluate the persons speech. If the person is having trouble with speech, this points to an issue with coordinating the movements and muscles used to produce speech. While trouble with language points to the person having difficulty with understanding what they are hearing and seeing. The SLP will also look at difficulty with swallowing food and will evaluate the person in order to figure out which part of the swallowing process is not working. Some of the many speech disorders worked with by the SLP are; Phonology meaning the speech patterns used, Apraxia meaning difficulty with coordinating the movements needed to make sounds, Receptive Language meaning difficulty understanding language, Fluency meaning stuttering, Expressive Language meaning difficulty using language and many other disorders. \n\nLong-term care facilities exist under three major types: privately owned, non-profit/charitable, and municipal. Regardless of their ownership, aspects of funding, admission criteria, and cost to the individuals are all regulated by their respective provincial governments. As medical care is publicly funded in Canada, all long-term care facilities receive funding from provincial governments for the health care component of the residence – the nurses and personal support workers. Residents pay daily rates for 'room and board' (accommodation and food) that are determined by the type of room chosen, either shared or private. Provincial governments manage waiting lists for long-term care facilities. People who cannot afford to pay the monthly fees receive subsidies, and no one is refused due to inability to pay.\n\nIn the United Kingdom, care homes and care homes with nursing are regulated by different organisations in England, Scotland, Wales and Northern Ireland. To enter a care home, a candidate patient needs an assessment of needs and of their financial condition from their local council. The candidate may also have an assessment by a nurse, should the patient require nursing care. The cost of a care home is means tested in England.\n\nCare homes for adults in England are regulated by Care Quality Commission, which replaced the Commission for Social Care Inspection, and each care home is inspected at least every three years. In Wales the Care Standards Inspectorate for Wales has responsibility for oversight, In Scotland Social Care and Social Work Improvement Scotland otherwise known as the Care Inspectorate, and in Northern Ireland the Regulation and Quality Improvement Authority in Northern Ireland.\n\nIn 2002, nursing homes became known as care homes with nursing, and residential homes became known as care homes.\n\nAs of April 2009 in England, the lower capital limit is £13,500. At this level, all income from pensions, savings, benefits and other sources, except a \"personal expenses allowance\" (currently £21.90), goes towards paying the care home fees. The local council pays the remaining contribution provided the room occupied is not more expensive than the local council's normal rate.\nThe NHS has full responsibility for funding the whole placement if the resident is in a care home with nursing that meets the criteria for NHS continuing Health Care. This is identified by a multidisciplinary assessment process.\n\nIn May 2010, the Coalition Government announced the formation of an independent commission on the funding of long-term care, which was due to report within a 12-month time frame on the financing of care for an Ageing population. It delivered its recommendations on Monday 4 July 2011. The Care Quality Commission have themselves implemented a re-registration process, completed in October 2010, which will result in a new form of regulation being outlined in April 2011.\n\nIn the United States, there are three main types of nursing facilities (NFs).\n\nAn intermediate care facility (ICF) is a health care facility for individuals who are disabled, elderly, or non-acutely ill, usually providing less intensive care than that offered at a hospital or skilled nursing facility. Typically an ICF is privately paid by the individual or by the individual's family. An individual's private health insurance and/or a third party service like a hospice company may cover the cost. Board and Care Homes are special facilities designed to provide those who require assisted living services both living quarters and proper care. Often referred to as residential care homes, these facilities can either be located in a small residential home or a large modern facility. In fact, a large majority of board and care homes are designed to room less than 6 people. Board and care homes are typically staffed by licensed professionals, including nurses, doctors and other medical professionals. These facilities are highly regulated in order to ensure that the best possible care is being provided for the residents. Board and care homes offer residents 24 hour assistance, making them a highly popular choice for those in need of regular assistance.\n\nAssisted living residences or assisted living facilities (ALFs) are housing facilities for people with disabilities. These facilities provide supervision or assistance with activities of daily living (ADLs); ALFs are an eldercare alternative on the continuum of care for people, for whom independent living is not appropriate but who do not need the 24-hour medical care provided by a nursing home and are too young to live in a retirement home. Assisted living is a philosophy of care and services promoting independence and dignity.\n\nA skilled nursing facility (SNF) is a nursing home certified to participate in, and be reimbursed by Medicare. Medicare is the federal program primarily for the aged (65+) who contributed to Social Security and Medicare while they were employed. Medicaid is the federal program implemented with each state to provide health care and related services to those who are below the poverty line. Each state defines poverty and, therefore, Medicaid eligibility. Those eligible for Medicaid may be low-income parents, children, including State Children's Health Insurance Programs (SCHIPs) and maternal-child wellness and food programs. seniors, and people with disabilities.\n\nThe Centers for Medicare and Medicaid Services is the component of the U.S. Department of Health and Human Services (DHHS) that oversees Medicare and Medicaid. A large portion of Medicare and Medicaid dollars is used each year to cover nursing home care and services for the elderly and disabled. State governments oversee the licensing of nursing homes. In addition, states have a contract with CMS to monitor those nursing homes that want to be eligible to provide care to Medicare and Medicaid beneficiaries. Congress established minimum requirements for nursing homes that want to provide services under Medicare and Medicaid. These requirements are broadly outlined in the Social Security Act, which also entrusts the Secretary of Health and Human Services with the responsibility of monitoring and enforcing these requirements. CMS is also charged with the responsibility of working out the details of the law and how it will be implemented, which it does by writing regulations and manuals.\n"}
{"id": "16286341", "url": "https://en.wikipedia.org/wiki?curid=16286341", "title": "Odontis", "text": "Odontis\n\nOdontis was an English dental company started by Professor Paul Sharpe, in association with King's College London. The company was focused on a technology of treating dental problems by using stem cells.\n\nThe idea was to use stem cells to grow new teeth that could replace missing teeth. The new tooth would be alive and nearly identical to the one that is missing.\n\nThe technology, if proved successful, would have huge potential as it will enable the maintenance of healthy teeth virtually throughout an entire lifetime. The new teeth of the patient will be exactly the same as his own. This will make it possible to avoid many problems that can be faced with artificial implants.\n\nThe technology would also bring new business opportunities for dentists and the companies in the field.\n\nIn 2004 the company claimed to have achieved the first promising results in an experiment with a mouse. The scientists have successfully implanted stem cells into a gum of a mouse and managed to grow a new tooth. Statements were made that the technology for growing new teeth would be available to the public in the near future, and as a result, an award of five hundred thousand pounds was made; however since the claim, nothing further has emerged.\n"}
{"id": "13748138", "url": "https://en.wikipedia.org/wiki?curid=13748138", "title": "Operating room management", "text": "Operating room management\n\nOperating room management is the science of how to run an Operating Room Suite. Operational operating room management focuses on maximizing operational efficiency at the facility, i.e. to maximize the number of surgical cases that can be done on a given day while minimizing the required resources and related costs. For example, what is the number of required anaesthetists or the scrub nurses that are needed next week to accommodate the expected workload or how can we minimize the cost of drugs used in the Operating Room? Strategic operating room management deals with long-term decision-making. For example, is it profitable to add two additional rooms to the existing facility? Typically, operating room management in profit-oriented health-care systems (e.g. United States) emphasizes strategic thinking whereas in countries with publicly funded health care (e.g. the UK), the focus is on operational decisions.\n\nThe act of coordinating and running all parts of a surgical suite to accomplish a defined set of goals. An emerging field, operating room management is increasingly studied as how to best: \n1) ensure patient safety and optimal patient outcome, \n2) provide surgeons with appropriate access to the OR so that patients can have operations in a timely manner,\n3) maximize the efficiency of operating room utilization, staff, and materials,\n4) decrease patient delays,\n5) enhance satisfaction among patients, staff, and physicians.\n\nThis management science as applied to the surgical suite is gaining more attention because of increasing market pressures on hospitals from competitors (e.g., other surgical suites including office based surgery) and from payers seeking lower prices. The surgical suite is often considered a profitable hospital unit. As such, surgical suites also comprise an important fraction of hospital budget spending. Holding patient safety constant, the opportunity to increase financial gain through modifying the use of already existing resources is a prime target for managerial analysis. Incremental improvements in operating room utilization and operating room efficiency can have major impacts on hospital staff and finances. Some hospital administrators perceive efficiency in the operating room as throughput, completing the most surgical cases within budget. Later in this article we will provide examples of tools a manager may use to analyze efficiency.\n\nThe management of a surgical suite must take into account all cooperating team members. The operating environment consists of interaction between surgeons, anesthesiologists, nurses, technicians, and patients.\n\nOverhead costs include, but are not limited to, the space, technology and devices, pharmaceuticals and staffing. Hospital administrators have consequently focused their attention towards maximizing OR profitability, and thereby hospital profitability, through contribution margins. This focus, in addition to the boom in demand for elective surgery, has led to a rapid growth of OR facilities. Historically, nurses have been chiefly responsible for the daily functioning of the surgical suite. Increasingly, facilities are hiring a physician medical director for the OR, as represented by a surgeon, anesthesiologist, or both. In some instances, all three branches of surgery, anesthesia, and nursing will be represented in the daily OR management infrastructure. By working collegially, these three fields can mobilize all resources necessary to maximize OR productivity. Because medical needs and regulatory requirements are constantly changing, the concept of appointing a medical director in the OR, an operating room manager, has gained acceptance.\n\nClinicians typically focus on operational decisions on the day of surgery (short term) such as moving cases from one OR to another, assigning and relieving staff, prioritizing urgent cases, and scheduling add-on case. On the other hand, upper management typically focuses on strategic decision making (long term) such as whether to open a new cancer center, or whether to align the hospital with a regional health care system.\n\nThe decisions made by OR management should have a clear and definitive purpose in order to maintain consistency. In order of priority, governing principles of OR managers are to: (1) ensure patient safety and the highest quality of care; (2) provide surgeons with appropriate access to the OR; (3) maximize the efficiency of operating room utilization, staff, and materials to reduce costs; (4) decrease patient delays; and (5) enhance satisfaction among patients, staff, and physicians. If OR management is properly performed ahead of time, all that doctors and nurses have to think about on the day of surgery is the patient. If management is poor, then the medical and nursing staff may waste efforts and resources to rush cases or juggle schedules, thus compromising attention to patient safety.\n\nOR utilization is a measure of the use of an operating room that is properly staffed with people needed to successfully deliver a surgical procedure to a patient.\n\nBlock Utilization is a measure of the use of operating room time by a surgeon or group of surgeons to whom time has been allocated.\n\n\"Raw utilization\" is the total hours of elective cases performed within OR time divided by the hours of allocated block time.\n\nRaw Utilization = total hours of cases performed ÷ total hours of OR time allocated\n\n\"Adjusted utilization\" uses the total hours of elective cases performed within OR block time, including \"credit\" for the turnover times necessary to set up and clean up ORs.\n\nAdjusted Utilization = [total hours of cases + \"credit time\"] ÷ total hours of OR time allocated\n\nFactors affecting utilization rates include: \nthe accuracy of estimated case times, \ncancellation rate, \nnumber of add-ons available to fill gaps, \nlongest cases go first, \nthe time of day as utilization typically is highest in the morning and lowest in the evening, outpatient centers have lower utilization, and other constraints (i.e., surgeon can only use room 12, or start at 11 am).\n\nImprovements in operating room efficiency can have a major impact on hospital staff and finances as well as operating room management.\n\nOperating room (OR) efficiency is a measure of how well time and resources are used for their intended purposes. One way to analyze efficiency is to chart \"under-utilized\" and \"over-utilized\" time spent on a given day in the operating room. If the cases in an operating room finish earlier than scheduled, time is \"under-utilized\". Likewise, if the cases in an operating room run \"late\" or past its allotted operating room time then this produces \"over-utilized time\".\n\nThe terms \"operating room utilization\" and \"operating room productivity\" are also often used when discussing operating room management of a surgical suite.\n\nAn operating room manager must select criteria, key performance indicators, or a dashboard of measurements, to assess overall functioning of a surgical suite. An example of an analytic tool used to rate surgical suites is reflected below. This scoring system was created in order to quantify the efficiency levels of surgical suites. Its economical efficacy has yet to be validated by formal studies. In addition, it was developed in the US and contains scoring elements that are applicable for an American surgical suite. It is therefore unlikely to be useful for operating room managers outside the US.\n\nOR efficiency measurements\nThe above objective criteria can be computed from data commonly available in hospital administrative data systems.\n\nNothing is more important than to first allocate the right amount of OR time to each service on each day of the week for their case scheduling. This is not the same as the block time! To illustrate this imagine that two cases each lasting 2 hours are scheduled into OR #1 with OR nurses and an anesthesiologist scheduled to work an 8 hr day. The matching of workload to staffing has been so poor that little can be done the day of surgery to increase the efficiency of use of the staff. Neither awakening patients more quickly nor reducing the turnover time, for example, will compensate for the poor initial choice of staffing for OR #1 and/or how the cases were scheduled into OR #1.\n\nOptimal allocation of OR time should be based on historical use by a particular service (i.e., unit of OR allocation such as surgeon, group, department, or specialty) and then using computer software to minimize the amount of underutilized time and the more expensive overutilized time. Under-utilized hours reflect how early the room finishes. In the example above, if staff were scheduled to work from 7:00 am to 3:00 pm and instead the room finished at 11 am, then there would be 4 hours of underutilized time. The excess staffing cost would be 50% (4 hours/8 hours). On the other hand, if 9 hours of cases are performed in an OR with staff scheduled to work 8 hours then the excess staffing cost is 25%. Over-utilized hours are the hours that ORs run longer than the regularly scheduled OR hours, or 1 hr in this example. 1hr/8hr=12.5% which is then multiplied by the additional cost of staying late, which often is assumed to be a factor of two (related to monetary overtime cost paid to staff, as well as recruitment and retention costs related to unhappy staff because they have to stay late unpredictably).\nOR suites can reasonably aim to achieve a staffing cost that is within 10% of optimal (i.e., workload is perfectly matched to staffing).\n\nIf the key is to allocate appropriate time to each service based on historical OR use, how do you deal with rooms consistently running late on the day of surgery? The answer: make the allocated time, into which cases are being scheduled, longer. For example, if a surgeon does 12 hours worth of cases every day he is in the OR, don’t plan 8 hours of staffing (7am-3pm) and have everyone frustrated by having to stay late (overtime). Rather, schedule his cases into 12 hours of allocated time (7am-7pm). That way, anesthesia and nursing staff know they will be there 12 hours when they arrive to work and overtime costs (financial and morale) will be reduced. The common response to this approach is, “No one wants to be there till 7 pm.” The answer to that is, “You are there now till 7 pm so why not make scheduled OR time 12 hr long and have a more predictable work day duration.” Thus, optimizing staffing costs is finding balance between overtime and finishing early.\n\nThere may be concern about a nurse manager's ability to flex the staff enough to avoid excess staffing costs. It can be difficult from a human resources standpoint to match scheduled cases with staffing perfectly, such that staff still get the hours and shifts they need. For example, if Dr Smith needs a 12-hour block, the manager needs to find staff who want to work a 12-hour shift (or part-timers in some combination). Staffing is not only an OR efficiency issue, but a staff satisfaction issue. It can be a challenge at a time when recruiting and retaining nurses are growing concerns.\n\nStart-time tardiness is the mean tardiness of start times for elective cases per OR per day. Reducing the time patients have to wait for their surgery once they arrive to the hospital (especially if the preceding case runs late) is another important goal for the OR manager. If a case is supposed to start at 10:00 am (patient enters OR), but the case starts at 10:30 am instead, then there are 30 minutes of tardiness. In computing this metric, no credit is given if the 10:00 am case starts early (for example at 9:45 am).\n\nThe tardiness of start of scheduled cases should total less than 45 mins per eight-hour OR day in well functioning OR suites. Facilities with long work days will have greater tardiness because the longer the day, the more uncertainty about case start times. Having patients’ medical records ready to go with all needed documents is essential for on time starts.\n\nCancellation rates vary among facilities, depending partly on the types of patients receiving care, ranging from 4.6% for outpatients, to 13% -18% at VA medical centers. Recently published data from the UK estimate that 1 in 10 patients presenting for inpatient surgery have experienced a previous cancellation for their procedure, and that 1 in 7 patients being operated on had their procedure cancelled during a 1 week period in March 2017 in the UK National Health Service (NHS). Many cancellations are due to non-medical problems such as a full ICU, surgeon unavailability, or bad weather. OR cancellation rates can be monitored statistically. Well functioning OR suites should have cancellation rates less than 5%. Monitoring the cancellations correctly is calculated by taking the ratio of the number of cancellations to the number of scheduled cases.\n\nPACU admission delays can be expressed as a % of workdays with at least one delay of 10 mins or greater in PACU admission because PACU is full. It is important to adjust PACU nurse staffing around the times of OR admissions. Algorithms exist that use the number of available nursing hours to find the staffing solution with the fewest number of understaffed days.\n\nAn OR suite that puts up with excessive surgical times can schedule itself efficiently but still lose its financial shirt if many surgeons are slow, use too many instruments, or expensive implants, etc. These are all measured by the contribution margin per OR hr. The contribution margin per hour of OR time is the hospital revenue generated by a surgical case, less all the hospitalization variable labor and supply costs. Variable costs, such as implants, vary directly with the volume of cases performed.\n\nThis is because fee-for-service hospitals have a positive contribution margin for almost all elective cases mostly due to a large percentage of OR costs being fixed. For USA hospitals not on a fixed annual budget, contribution margin per OR hour averages one to two thousand USD per OR hour.\n\nTurnover time is the time from when one patient exits an OR until the next patient enters the same OR. Turnover times include cleanup times and setup times, but not delays between cases. Based on data collected at 31 USA hospitals, turnover times at the best performing OR suites average less than 25 mins. Cost reduction from reducing turnover times (because OR workload is less) can only be achieved if OR allocations and staffing are reduced. Despite this, turnover time receives lots of attention from OR managers because it is a key satisfier for surgeons.\n\nSometimes the OR suite reduces turnover times (by providing more staff to clean the room for example) but new problems arise (not enough time for sterilizing instruments for the new case, can’t bring patient to PACU because no beds) that were “hidden” by long turnover times.\n\nTimes between cases that are longer than a defined interval (e.g., 1 hr because to follow surgeon is unavailable) should be considered delays, not turnovers.\n\nPrediction bias in case duration are expressed as estimates per 8 hr of OR time. Prediction error equals the actual duration of the new case minus the estimated duration of the new case. Bias indicates whether the estimate is consistently too high or consistently too low, and precision reflects the magnitudes of the errors of the estimates. Efficient OR suites should aim to have bias in case duration estimates per 8 hr of OR time that is less than 15 minutes. A reason for bias can be surgeons’ consistently shortening their case duration estimates because they have too little OR time allocated and need to “fit” their list of cases into the OR time they do have. In contrast, other OR suites may have surgeons that purposely overestimate case durations to keep control/access of their allocated OR time so that if a new case appears their OR time was not given away.\n\nRemember that lack of historical case duration data for scheduled procedures is an important cause of inaccuracy in predicting case duration. In general, half of the cases scheduled in your OR suite tomorrow will have less than five previous cases of the same procedure type and same surgeon during the preceding year.\n\nIt would be nice to have no uncertainty in case duration prediction. But, it is present. The problem is looking for a single number that is correct most of the time. You won't get accurate estimates by using historical case duration data. Rather, from the historical data you'll get an assessment of the uncertainty.\n\nTimes between cases that are longer than a defined interval. (note: late arrival of a surgeon should be considered delays, not turnovers.)\n\n\"Operating room productivity\" is the quantity and quality of output (typically surgical cases) from the surgical suite in contrast to the amount of input required (such as physicians and nurses and equipment for example). Many institutions believe that productivity (output/input) can be accomplished without sacrificing convenience (rapid access to open OR time such that a surgeon can book a case without having to wait) but these two aspects are not separable.\n\nTypically, the greater the \"operating room utilization\", the less the convenience (able to book cases when desired) as defined by surgeons and patients. This is because as utilization goes up there is less available open staffed OR time available on short notice. In other words, the greater the access and convenience, the lower is \"operating room utilization\" (because of the need for extra capacity), at least as perceived by hospitals and anesthesiologists. This high level of customer service of being able to book cases on short notice is one reason ambulatory surgery centers typically have lower OR utilization than big city hospitals. The outpatient surgery center usually has reduced overhead when compared to a big city hospital, and therefore can financially get away with lower OR use.\n\nManagement of the operating room suite must acknowledge that people are the primary resource. Although management science theory may tend to hold constant the preferences and bias of the individuals working in and utilizing the surgery suite, management of the surgical suite with regards to case scheduling is strongly influenced by personal, political, and economic relationships within an institution.\n\nTo best align management goals with institutional objectives the OR director needs to identify the primary customer of the surgical suite. An OR can be completely balanced or it can be biased to one or more its constituents. The main people to consider are surgeons, anesthesiologists, nurses, the hospital (upper management), and of course the patient.\n\nA first step is to determine whose preferences or workload dominates the surgical suite. If surgeons are in large demand with small supply, then that may outweigh other interests. For example, a private facility may have surgeons who can pull their patients to another hospital if made to wait. As another example, in a private surgeon-owned surgery center, management may be directed as maintaining a particular partner's workload and the incentives are to schedule his/her cases with priority.\n\nThe same supply/demand balance applies to anesthesia. The situation may exist where a specific surgery group will only work with its contracted anesthesia group. In this case, a manager may have to wait until the contracted anesthesiologist is ready for the case, even if this means idle OR time. This can be avoided in institutions where one group has exclusive rights and controls anesthesia privilege over all the ORs. This arrangement is seen commonly because it eliminates factions and streamlines anesthesia placement for cases, either elective or emergency.\n\nHospital (Upper Management) run ORs are identified by those facilities where the hospital executives acting as agents for government authorities determine staffing and workload. Examples include hospitals in public health care systems like in European countries or the VA United States Department of Veteran Affairs in the USA.\n\nIn other surgical suites, in contrast, management decisions have patients as the first priority. Facilities performing elective cosmetic procedures for cash reimbursement are an example. Due to the patient being able to choose where they have plastic surgery, patients expect special circumstances such as first-rate customer service. Additionally, if a patient is one hour late for surgery the patient will most likely still be able to undergo surgery. This concept is in contrast to a large academic hospital, for example, where a patient who misses their check-in window for elective surgery is often removed from the surgery schedule to make room for re-shuffled elective and emergency cases.\n\nOnce the manager has identified the critical few customers and the necessary many customers, then the next step is to determine their preferences and incentives. Surgeons will favor early block surgery times, rapid turnover, low cancellation rates, and on time starts. The hospital (upper management) will want the most surgical output with the least associated cost. Patients will likely favor reduced waiting times for surgery start. Finally, nurse managers and anesthesiologists will be inclined to high operating room utilization, minimal overtime, the flexibility to move cases around, and reserve capacity in the ORs.\n\nMuch like economic Game Theory, agents in the OR will position their interests in a nature as to maximize their returns. It is up to the OR manager to weigh the contributions of each agent and provide enough OR time and resources to maximize the output of the surgical suite in its entirety.\n\nThis discussion addresses capitalistic healthcare markets. A discussion of socialized medicine would include several other factors which influence the supply and demand for surgical care. Analysis of operating room management within socialized medicine is becoming increasingly frequent in the medical literature, but is beyond the scope of this article.\n\nA manager must select benchmarks in order to analyze changes from baseline operations. Upgrades to existing operating infrastructures should be demonstrated as efficiency gained compared to baseline practices. Management criteria must therefore include preoperative, intraoperative, and immediate postoperative system analysis.\n\n\"Waiting time\" and \"operating room scheduling\" are the two key preoperative determinates.\n\nWaiting time prior to operation The time from surgical scheduling to check-in for the procedure is defined, for these purposes, as “preoperative wait time.”\n\nUse of a surgical suite depends greatly on, and increases as, the average length of time patients wait for surgery increases. As waiting time increases, more surgical dates (blocks) can be evaluated for a good match between a case's duration and the open times in the blocks. In some communities, competition among surgeons and hospitals may not allow the average length of time that patients have to wait for surgery to be as long as 2 weeks. An OR suite then cannot expect block time utilization from elective cases to exceed 90%, assuming that enough block time is allocated for a surgeon to complete all of the elective cases in the block time.\n\nFor these purposes, wait time can be equated to the price of an object. The price for an object increases if demand increases and/or supply reduces for that object. Hence, “preoperative wait time” will increase as demand for surgery increases and/or surgical supply (operating room availability) reduces or fails to grow proportionally to surgical demand.\n\nBy accurately gauging a patient population and an operative facility’s capacity, an effective manager can minimize the wait for elective and imminent procedures while covering all emergency cases and without overextending the operative team.\n\nCase scheduling or correctly selecting the day on which to do each elective case so as to best fill the allocated hours is most important, much more so than, for example, correcting errors in predicting how long elective or add-on cases would last, reducing variability in turnover or delays between cases, or day-to-day variation in hours of add-on cases.\n\nPoor scheduling is often the cause of lost OR time. To more efficiently operate a surgical setting, managers may consider centralizing all scheduling to the operating room suite itself. Ideally, holding patient and surgeon preferences constant, an operating facility can identify cases and appropriately place them into predetermined time slots, or blocks.\n\nTo examine scheduling challenges, consider three possible surgical scenarios: elective (e.g. cosmetic procedures, stable situations not increasing in severity), imminent (e.g. inflamed gall bladder removal, potential for worsening harm if situations not surgically corrected,) and emergency surgeries (e.g. burst appendix, situations in which death or disability is possible or likely). The majority of operative time is a combination of elective and imminent surgeries. Albeit a smaller percentage, emergency surgical cases must always be handled promptly in order to ensure patient safety. Emergency surgeries are often unforeseeable and present a scheduling challenge as a result. Therefore, from a management perspective, one must use the elective and imminent surgical cases as a guideline for pre-determining operative schedules, while allowing flexibility for the emergency situations that indubitably arise.\n\nThe historical approach for scheduling operating room time is via analysis of previous surgical information. For example, to estimate how much time a cholecystectomy will require, the management determines how long previous cholecystectomy operations took the participating surgeon. Limiting this approach is the number of prior recorded cases and the surgeon’s familiarity with the procedure. Previously recorded information serves to set a precedent for turnover rates. By allowing surgeons to operate efficiently based on their previous timetables, a manager allows all parties involved to work more efficiently.\n\nNothing is more important than to first allocate the right amount of OR time to each service on each day of the week so that rarely do services fill their allocated OR time and have another case to schedule. This allocation is based on historical use by surgeon and then using computer to minimize ratio of underutilized time and over-utilized time (which is more expensive).\n\nA prevailing school of thought is for managers to allocate operating room time based on the principles of safety, access and operating room efficiency, in respective order of importance. Part of a manager’s job is to clearly communicate these factors to all parties involved in care delivery.\n\nThere are times when a departmental manager must realize a departure from this practice and intervene to save profitability margins. For instance, an anesthesia practice group may negotiate extra funds from their employer (university, hospital, multi-specialty medical groups) to compensate for underutilized operating room time. In this instance, an anesthesia manager may use predetermined formulas to estimate excess labor costs they incur that are not offset by proper operating room utilization. A manager, whether departmental of administrative, that uses proactive applications can eliminate inefficiencies within their operating systems.\n\nManagers need to evaluate: 1) operating room leadership; 2) departmental leadership within the operating room; 3) interpersonal conflicts amongst the operating team; 4) physical layout and location of the operating room in relation to other integral departments; 5) operating room communication systems; and 6) patient turnover.\n\nOnly then can options such as providing rewards and incentives for improved operating room efficiency, assessing logistical and system design, delegating responsibility, and implementing teamwork initiatives be instituted to produce more favorable outcomes for both the provider and the patient.\n\nGenerally, an institution or private surgery center will have an agreed upon leader, generally dubbed the “Operating Room Manager.” The reporting structure is typically to a VP of surgical services. A manager may have the business and academic ability to operate a facility, but without the cooperation of staff and practitioners, most reform efforts will be futile.\n\nAn OR manager must be in compliance with several internal and external governing bodies. Depending on the institution, a given manager may have to work closely with committees ranging from patient safety and medical staff safety boards to an auxiliary OR committee. The Joint Commission on Accreditation of Healthcare Organizations (JCAHO) and the Centers for Medicare and Medicaid Services (CMS) puts forth an external, universal regulatory standard for hospitals and ORs. An OR manager must maintain compliance with this spectrum of policies in order to maintain both patient safety as well as hospital accreditation.\nOne of many notable policies put forth by JHACO [Joint Commission] is the universal protocol, implemented to ensure patient safety. This protocol requires that three sequential events must be completed prior to surgical incision in order to reduce iatrogenic errors and postoperative complications. The three checkpoints are (1) preoperative verification of procedure and background information, (2) marking of the operative site with a marker and surgeon’s initials, and (3) an official timeout for an audible confirmation of patient identity and the procedure to be completed. These regulations have proven to reduce avoidable complications of intraoperative mistakes and resultant postoperative morbidities and mortalities.\n\nThis topic compartmentalizes each member of a surgical suite team to his/her department (e.g. surgery, anesthesiology, environmental services, housekeeping, etc.). The principle behind departmental leadership is the delegation of responsibility. An operating room manager must rely upon departments to uphold their respective regulations in addition to acting in the best interest of the overall institution. This interest directly relates to operating room utilization and operating room productivity. Therefore, a surgical chief must be an active member of scheduling block time for surgery in order to avoid persistent over or underutilization of resources.\n\nThe majority of accidents in technical professions have human error as causal elements. More critically, these errors tend to involve interpersonal issues: communications, leadership, conflict, flawed decision making, etc. A questionnaire circulated to operating room staff and professionals identified communication problems as an overwhelming barrier to operating room performance. This problem is a constant theme within healthcare and can disrupt an operating room and detract from operating room efficiency. It is imperative that a manager optimize personal issues and act quickly to correct them.\n\nAn effective manager must analyze the layout of each operating room individually and as a whole. The mass of new technologies and equipment, such as Endoscopic surgical procedures, in today's operating room is increasing. Crowding may adversely affect the abilities of the surgical team. Managers must act to appropriately modify pre-existing operating room space or by identifying key design issues during the conception and building of new facilities. Larger cases where more materials and instruments are used should be appropriately scheduled into rooms that can accommodate them.\n\nLikewise, the surgical suite ideally is placed in close proximity to support functions such as radiology, pathology, and intensive care. Creating unnecessary distance between these entities compromises both operating room efficiency and patient safety.\n\nSurgical Suite Communication Systems and Patient Turnover\n\nCurrent technologies provide managers with tools to reduce patient turnover rate. Standard practices include passive status displays (whiteboards or screens in the surgical suites) and active displays (text pager notifications). These communication tools streamline interdisciplinary planning for real time decision-making. A recent study suggests going further and implementing a system of command displays (text suggestions of how to act) or even patient tracking systems such as with RFID tags. This communication is essential to know when to expect patients to arrive to the holding area prior to entering the OR, or to the recovery room after surgery.\n\nReduction in turnover time (patient exists operating room until next patient enters operating room) requires all individuals in the surgical suite to work together. The day-to-day management of operating room efficiency is integral to the maximization of both qualitative (improved professional satisfaction) and quantitative (completion of more cases and reduced staffing costs) returns.\n\nSurgical Care Improvement Project (SCIP)\n\nSCIP is a national partnership of organizations [www.medqic.org/scip] that are dedicated to reducing postoperative complications.\n\nThe project focuses on four broad areas in which the incidence and cost of complications are high: (1) Surgical site infections, (2) Perioperative myocardial infarctions (heart attacks), (3) Venous thromboembolism, and (4) Postoperative pneumonia.\n\nAn operating room manager must consider the preoperative, intraoperative and postoperative factors which reflect in patient safety and hospital efficiency. Ideally, a manager is approachable, intelligent, and an effective leader who communicates well with hospital staff. The above techniques and principles highlight many of the ways in which a manager can successfully direct a surgical suite to maximize its benefit to the patients, staff and hospital.\n\n1. One possible solution to intrapersonal conflict within the operating theatre is medical simulation training. Large institutions are adapting simulator practices to teach everything from communication skills to proper clinical management of crises situations. By identifying interpersonal barriers in a closed environment, a manager can work with all parties involved to address and resolve these problems. Such interventions will reduce intraoperative error as a result of personal conflicts and serve to increase efficiency.\n\n2. Ultimately, a manager may improve hospital functioning by providing rewards and incentives for improved efficiency, assessing logistical and system design, delegating responsibility, and implementing teamwork initiatives. These topics are beyond the scope of this article.\n\n3. Those seeking to learn more about operating room management may find Dr. Franklin Dexter’s website of help: \n\n4. Interested persons may also explore topics in administrative structure and supply chain management.\n"}
{"id": "56392968", "url": "https://en.wikipedia.org/wiki?curid=56392968", "title": "Prue Barron", "text": "Prue Barron\n\nPrudence Barron MBE FRCSEd (16 September 1917 – 10 October 2014) was a surgeon at the Royal Hospital for Sick Children, Edinburgh and geriatrician.\n\nPrudence Halton was born in Poona, Maharashtra, in India on 16 September 1917. Her father, Colonel Frederick Halton, who in peacetime was a solicitor and later the coroner for Cumberland, had been stationed on the North West Frontier during the Third Anglo-Afghan War. Educated as a boarder at Cheltenham Ladies’ College from the age of 12, she became a prefect and then head of house. Her mother encouraged her to apply to the London School of Medicine for Women and she was accepted in 1936, carrying out her undergraduate clinical training at the Royal Free Hospital.\n\nShe graduated with an MB, BS in 1942 and worked in house officer posts at the Cumberland Infirmary in Carlisle. She then took up the position of clinical assistant to Gertrude Herzfeld, the first practising woman surgeon in Scotland, at the Royal Hospital for Sick Children in Edinburgh. In July 1945 became a Fellow of the Royal College of Surgeons of Edinburgh.\n\nShe returned to Cumberland Infirmary as assistant surgical resident for a year, before becoming surgical resident at Birmingham Children’s Hospital, where she assisted in the first paediatric open heart surgery to be performed at the hospital. Barron was invited back to Edinburgh by Herzfeld, and was appointed senior surgical registrar at Bruntsfield Hospital in October 1947. She supplemented her salary by demonstrating anatomy to medical students at the University of Edinburgh.\nWhen the youngest of her three children was old enough, she returned part-time to her medical career, initially working as the medical officer at Crawford’s biscuit factory in Edinburgh and later as a general practitioner in a practice on Leith Walk, Edinburgh. In 1967 she was appointed medical officer for geriatrics at Queensberry House and Lodge in the Canongate, Edinburgh, where she was known for her kindness, sensitivity, and compassion, and was also acknowledged as an extremely capable clinician. She was appointed geriatric associate specialist at the Royal Victoria, Corstorphine, and Eastern General hospitals.\n\nIn 1975 she was appointed a Member of the Order of the British Empire (MBE) for services to geriatrics. When St Columba’s Hospice for palliative care opened in 1977, Barron worked on a voluntary basis, covering weekends and many nights, subsequently as a member of the executive committee until 1993. In addition she worked as a volunteer marriage guidance councillor, and volunteered in the Leith Hospital Samaritan Society. She was chair of the local Medical Women’s Federation and in her retirement chair of the Cruse bereavement counselling service.\n\nShe met a fellow surgeon Arthur F M Barron while they worked together as anatomy demonstrators. They married in Carlisle Cathedral in July 1950. He became consultant surgeon to Leith Hospital. He died suddenly in 1971 following a stroke.\n\nBarron underwent successful open heart valve replacement surgery at the age of 92. She died in Edinburgh on 10 October 2014.\n"}
{"id": "17371187", "url": "https://en.wikipedia.org/wiki?curid=17371187", "title": "Public Health Engineering Department (Sikkim)", "text": "Public Health Engineering Department (Sikkim)\n\nPublic Health Engineering Department (PHED) is a department of the Government of Sikkim that looks after several civic utilities of the Indian state of Sikkim, including water supply to urban areas such as the capital Gangtok.\n"}
{"id": "1270907", "url": "https://en.wikipedia.org/wiki?curid=1270907", "title": "Quad helix", "text": "Quad helix\n\nA quad helix (or quadhelix) is an orthodontic appliance for the upper teeth that is cemented in the mouth. It is attached to the molars by 2 bands and has two or four active helix springs that widen the arch of the mouth to make room for crowded teeth, or correct a posterior cross-bite, where lower teeth are buccal (outer) than upper teeth. It is usually made from 38 mil stainless steel wire and is primarily indicated in mixed dentition, cleft patients and those that have performed the act of thumbsucking. A variety of this appliance is inserted into attachments that are welded to the bands. In this way the orthodontist can adjust the appliance without removing the bands.\n\nThe precursor to the quad-helix was the coffin spring. Similar devices known as tri-helices and bi-helices were later developed, with three and two helix springs, respectively.\n\nThe expander works by gently pushing the teeth outwards to eventually widen the upper arch. A quad helix expander is usually given to those who have a narrow top jaw, a cross bite and/or crowded teeth. \n"}
{"id": "8142784", "url": "https://en.wikipedia.org/wiki?curid=8142784", "title": "Red wine headache", "text": "Red wine headache\n\nRed wine headache (\"RWH\") is a headache often accompanied by nausea and flushing that occurs after consuming red wine in susceptible individuals. White wine headaches have been less-commonly reported.\n\nMany wines contain a warning label about sulfites, and some people believe that sulfites are the cause of RWH and other allergic and pseudoallergic reactions. However, this may not be the case. Dried fruit and processed foods like lunch meat have more sulfites than red wine. Reactions to sulfites are not considered a \"true allergy\" and reactions more commonly occur in persons with asthma and may manifest themselves in difficulty breathing or skin reactions, rather than headache. \n\nSome wines may be exempt from including a sulfite warning. Wines that have under 10mg/l of sulfites do not need to be labeled that they contain sulfites. This includes added and natural sulfites, like sulfites that come from the soil, or those produced by yeasts during alcoholic fermentation. Wines labeled \"100% Organic\", \"Organic\", \"Made With Organic Grapes\", \"Made With Organic and Non-Organic Grapes\" or without organic certification may contain sulfites, and must disclose this on the label. This also means that the so called \"Natural\" wine can also contain sulfites. Different rules might apply in different continents.\n\nHistamine is present in a variety of fermented products such as wine, aged cheeses, and sauerkraut. Red wine has 20–200% more histamine than white wine, and those who react to it may be deficient in the enzyme diamine oxidase. Experts believe that in some individuals, alcohol consumption may lead to elevated plasma histamine levels even in the absence of histamines in the beverage consumed. A study of 16 people with an intolerance to red wine found no difference in reactions to low and high histamine wines. Other biogenic amines may also have an effect. Taking an antihistamine an hour before drinking may reduce the reaction to histamine and the resulting symptoms.\n\nRWH could be caused by the release of prostaglandins which some people are not able to metabolize. Prostaglandins are substances that can contribute to pain and swelling. Ibuprofen, paracetamol and aspirin are prostaglandin inhibitors. Aspirin and ibuprofen were shown to be effective at blocking both early and late stages of the RWH, and paracetamol was effective in blocking the early stage. However, paracetamol and NSAIDs like ibuprofen must not be taken with alcohol as the combination can cause liver damage.\n"}
{"id": "35954442", "url": "https://en.wikipedia.org/wiki?curid=35954442", "title": "Selenium in biology", "text": "Selenium in biology\n\nAlthough it is toxic in large doses, selenium is an essential micronutrient for animals. In plants, it sometimes occurs in toxic amounts as forage, e.g. locoweed. Selenium is a component of the amino acids selenocysteine and selenomethionine. In humans, selenium is a trace element nutrient that functions as cofactor for glutathione peroxidases and certain forms of thioredoxin reductase. Selenium-containing proteins are produced from inorganic selenium via the intermediacy of selenophosphate (PSeO).\n\nSelenium is an essential micronutrient in mammals, but is also recognized as toxic in excess. Selenium exerts its biological functions through selenoproteins, which contain the amino acid selenocysteine. Twenty-five selenoproteins are encoded in the human genome.\n\nThe glutathione peroxidase family of enzymes (abbreviated GSH-Px) catalyze reduction of hydrogen peroxide and organic hydroperoxides:\n\nThe two H atoms are donated by thiols in a process that begins with oxidation of a selenol side chain in GSH-Px. The organoselenium compound ebselen is a drug used to supplement the action of GSH-Px. It functions as a catalyst for the destruction of hydrogen peroxide.\n\nA related selenium-containing enzyme in some plants and in animals (thioredoxin reductase) generates reduced thioredoxin, a dithiol that serves as an electron source for peroxidases and also the important reducing enzyme ribonucleotide reductase that makes DNA precursors from RNA precursors.\n\nSelenium also plays a role in the functioning of the thyroid gland. It participates as a cofactor for the three thyroid hormone deiodinases. These enzymes activate and then deactivate various thyroid hormones and their metabolites. It may inhibit Hashimotos's disease, an auto-immune disease in which the body's own thyroid cells are attacked by the immune system. A reduction of 21% on TPO antibodies was reported with the dietary intake of 0.2 mg of selenium.\n\nSome microorganisms ulitize selenium in formate dehydrogenase. Formate is produced in large amounts in the hepatic (liver cells) mitochondria of embryonic cells and in cancer cells by the folate cycle.\n\nFormate is reversibly oxidized by the enzyme formate dehydrogenase:\n\nThioredoxin reductase uses a cysteine-selenocysteine pair to reduce the disulphide in thioredoxin. The selenocysteine is arranged in an unusual Sec-His-Glu catalytic triad, which tunes its pKa.\n\nCertain species of plants are considered indicators of high selenium content of the soil, since they require high levels of selenium to thrive. The main selenium indicator plants are \"Astragalus\" species (including some locoweeds), prince's plume (\"Stanleya\" sp.), woody asters (\"Xylorhiza\" sp.), and false goldenweed (\"Oonopsis\" sp.)\n\nThe substance loosely called selenium sulfide (with the approximate formula SeS) is the active ingredient in some anti-dandruff shampoos. The selenium compound kills the scalp fungus \"Malassezia\", which causes shedding of dry skin fragments. The ingredient is also used in body lotions to treat Tinea versicolor due to infection by a different species of \"Malassezia\" fungus.\n\nSelenium may be measured in blood, plasma, serum or urine to monitor excessive environmental or occupational exposure, confirm a diagnosis of poisoning in hospitalized victims or to assist in a forensic investigation in a case of fatal overdosage. Some analytical techniques are capable of distinguishing organic from inorganic forms of the element. Both organic and inorganic forms of selenium are largely converted to monosaccharide conjugates (selenosugars) in the body prior to being eliminated in the urine. Cancer patients receiving daily oral doses of selenothionine may achieve very high plasma and urine selenium concentrations.\n\nAlthough selenium is an essential trace element, it is toxic if taken in excess. Exceeding the Tolerable Upper Intake Level of 400 micrograms per day can lead to selenosis. This 400 microgram (µg) Tolerable Upper Intake Level is based primarily on a 1986 study of five Chinese patients who exhibited overt signs of selenosis and a follow up study on the same five people in 1992. The 1992 study actually found the maximum safe dietary Se intake to be approximately 800 micrograms per day (15 micrograms per kilogram body weight), but suggested 400 micrograms per day to not only avoid toxicity, but also to avoid creating an imbalance of nutrients in the diet and to account for data from other countries. In China, people who ingested corn grown in extremely selenium-rich stony coal (carbonaceous shale) have suffered from selenium toxicity. This coal was shown to have selenium content as high as 9.1%, the highest concentration in coal ever recorded in literature.\n\nSymptoms of selenosis include a garlic odor on the breath, gastrointestinal disorders, hair loss, sloughing of nails, fatigue, irritability, and neurological damage. Extreme cases of selenosis can result in cirrhosis of the liver, pulmonary edema, and death. Elemental selenium and most metallic selenides have relatively low toxicities because of their low bioavailability. By contrast, selenates and selenites are very toxic, having an oxidant mode of action similar to that of arsenic trioxide. The chronic toxic dose of selenite for humans is about 2400 to 3000 micrograms of selenium per day for a long time. Hydrogen selenide is an extremely toxic, corrosive gas. Selenium also occurs in organic compounds, such as dimethyl selenide, selenomethionine, selenocysteine and methylselenocysteine, all of which have high bioavailability and are toxic in large doses.\n\nSelenium poisoning of water systems may result whenever new agricultural runoff courses through normally dry, undeveloped lands. This process leaches natural soluble selenium compounds (such as selenates) into the water, which may then be concentrated in new \"wetlands\" as the water evaporates. High selenium levels produced in this fashion have been found to have caused certain congenital disorders in wetland birds.\nIn fish and other wildlife, low levels of selenium cause deficiency while high levels cause toxicity. For example, in salmon, the optimal concentration of selenium in the fish tissue (whole body) is about 1 microgram selenium per gram of tissue (dry weight). At levels much below that concentration, young salmon die from selenium deficiency; much above that level they die from toxic excess.\n\nSelenium deficiency can occur in patients with severely compromised intestinal function, those undergoing total parenteral nutrition, and in those of advanced age (over 90). Also, people dependent on food grown from selenium-deficient soil are at risk. Although New Zealand has low levels of selenium in its soil, adverse health effects have not been detected.\n\nSelenium deficiency as defined by low (<60% of normal) selenoenzyme activity levels in brain and endocrine tissues only occurs when a low selenium status is linked with an additional stress, such as high exposures to mercury or as a result of increased oxidant stress due to vitamin E deficiency.\n\nSelenium interacts other nutrients, such as iodide and vitamin E. The interaction is observed in the etiology of many deficiency diseases in animals and pure selenium deficiency is rare. The effect of selenium deficiency on health remains uncertain, particularly in relation to Kashin-Beck disease.\n\nThe U.S. Institute of Medicine (IOM) updated Estimated Average Requirements (EARs) and Recommended Dietary Allowances (RDAs) for selenium in 2000. If there is not sufficient information to establish EARs and RDAs, an estimate designated Adequate Intake (AI) is used instead. The current EAR for selenium for people ages 14 and up is 45 μg/day. The RDA is 55 μg/day. RDAs are higher than EARs so as to identify amounts that will cover people with higher than average requirements. RDA for pregnancy is 60 μg/day. RDA for lactation is 70 μg/day. For children ages 1–13 years the RDA increases with age from 20 to 40 μg/day. As for safety, the IOM sets Tolerable upper intake levels (ULs) for vitamins and minerals when evidence is sufficient. In the case of selenium the UL is 400 μg/day. Collectively the EARs, RDAs, AIs and ULs are referred to as Dietary Reference Intakes (DRIs).\n\nThe European Food Safety Authority (EFSA) refers to the collective set of information as Dietary Reference Values, with Population Reference Intake (PRI) instead of RDA, and Average Requirement instead of EAR. AI and UL defined the same as in United States. For women and men ages 15 and older the AI is set at 70 μg/day. AI for pregnancy is 70 μg/day, for lactation 85 μg/day. For children ages 1–14 years the AIs increase with age from 15 to 55 μg/day. These AIs are higher than the U.S. RDAs. The European Food Safety Authority reviewed the same safety question and set its UL at 300 μg/day, which is lower than the U.S. value.\n\nFor U.S. food and dietary supplement labeling purposes the amount in a serving is expressed as a percent of Daily Value (%DV). For selenium labeling purposes 100% of the Daily Value was 70 μg, but as of May 27, 2016 it was revised to 55 μg. A table of the old and new adult Daily Values is provided at Reference Daily Intake. Food and supplement companies have until January 1, 2020 to comply with the change.\n\nIn the United States, selenium deficiency is not common. A federal survey of food consumption determined that for women and men over the age of 19, average consumption from foods and beverages was 89 and 125 μg/day, respectively. For women and men of all ages fewer than 3% consumed less than the EAR.\n\nDietary selenium comes from nuts, cereals, meat, mushrooms, fish, and eggs. Brazil nuts are the richest ordinary dietary source and could cause selenium toxicity if consumed regularly – though the actual concentration of selenium (as with any plant-based food sources, such as another selenium-accumulating \"paradise nut\" Lecythis, belonging to the same family Lecythidaceae) is soil-dependent and may vary significantly by geographic location. In descending order of concentration, high levels are also found in kidney, tuna, crab, and lobster.\n\nThe human body's content of selenium is believed to be in the 13–20 milligram range.\n\n\"Although an inverse association between selenium exposure and the risk of some types of cancer was found in some observational studies, this cannot be taken as evidence of a causal relation, and these results should be interpreted with caution... Conflicting results including inverse, null and direct associations have been reported for some cancer types... RCTs assessing the effects of selenium supplementation on cancer risk have yielded inconsistent results... To date, no convincing evidence suggests that selenium supplements can prevent cancer in humans.\"\n\nAIDS appears to involve a slow and progressive decline in levels of selenium in the body. Whether this decline in selenium levels is a direct result of the replication of HIV or related more generally to the overall malabsorption of nutrients by AIDS patients remains debated. Observational studies have found an association between decreased selenium levels and poorer outcomes in patients with HIV, though these studies were mostly done prior to the currently effective treatments with highly active antiretroviral therapy (HAART). Currently there is inadequate evidence to recommend routine selenium supplementation for HIV patients, and further research is recommended.\n\nSelenium supplementation has no effect on overall mortality.\n\nAs with other types of supplementation, there is no good evidence selenium supplementation helps in the treatment of tuberculosis.\n\nA meta-analysis of four RCTs concluded that there is no support for selenium supplementation for prevention of type 2 diabetes mellitus in Caucasians.\n\nAbnormally high or low levels of dietary selenium can have an adverse effect on sperm quality, with a consequent lowering of fertility.\n\nSelenium is incorporated into several prokaryotic selenoprotein families in bacteria, archaea, and eukaryotes as selenocysteine, where selenoprotein peroxiredoxins protect bacterial and eukaryotic cells against oxidative damage. Selenoprotein families of GSH-Px and the deiodinases of eukaryotic cells seem to have a bacterial phylogenetic origin. The selenocysteine-containing form occurs in species as diverse as green algae, diatoms, sea urchin, fish and chicken. Selenium enzymes are involved in utilization of the small reducing molecules glutathione and thioredoxin.\n\nTrace elements involved in GSH-Px and superoxide dismutase enzymes activities, i.e. selenium, vanadium, magnesium, copper, and zinc, may have been lacking in some terrestrial mineral-deficient areas. Marine organisms retained and sometimes expanded their seleno-proteomes, whereas the seleno-proteomes of some terrestrial organisms were reduced or completely lost. These findings suggest that aquatic life supports selenium utilization, whereas terrestrial habitats lead to reduced use of this trace element. Marine fishes and vertebrate thyroid glands have the highest concentration of selenium and iodine. From about 500 Mya, freshwater and terrestrial plants slowly optimized the production of \"new\" endogenous antioxidants such as ascorbic acid (Vitamin C), polyphenols (including flavonoids), tocopherols, etc. A few of these appeared more recently, in the last 50–200 million years, in fruits and flowers of angiosperm plants. In fact, the angiosperms (the dominant type of plant today) and most of their antioxidant pigments evolved during the late Jurassic period.\n\nAbout 200 Mya, new selenoproteins were developed as mammalian GSH-Px enzymes.\n\n\n"}
{"id": "39894443", "url": "https://en.wikipedia.org/wiki?curid=39894443", "title": "Senji Yamaguchi", "text": "Senji Yamaguchi\n\nYamaguchi was born in 1930 to a poor family in Nagasaki. In 1945, he was employed as an under-age weapons maker. On August 9, 1945, he suffered keloid scars while working at the weapon factory when the United States dropped a nuclear bomb, which destroyed nearly everything in Nagasaki.\n\nYamaguchi has only served in two anti-nuclear organizations, one being the Anti-nuclear arms movement in 1955 and heading the Japan Confederation of A- and H-Bomb Sufferers Organizations between the years of 1981 and 2010. He even once was granted permission to be involved in the 1982 United Nations meeting. In his last years, he was hospitalized and died of an illness on July 6, 2013 in Unzen, Nagasaki.\n\n"}
{"id": "217773", "url": "https://en.wikipedia.org/wiki?curid=217773", "title": "Septic tank", "text": "Septic tank\n\nA septic tank is an underground chamber made of concrete, fiberglass or plastic through which domestic wastewater (sewage) flows for basic treatment. Settling and anaerobic processes reduce solids and organics, but the treatment efficiency is only moderate (referred to as \"primary treatment\"). Septic tank systems are a type of simple onsite sewage facility (OSSF). They can be used in areas that are not connected to a sewerage system, such as rural areas. The treated liquid effluent is commonly disposed in a septic drain field which provides further treatment. However, groundwater pollution may occur and can be a problem.\n\nThe term \"septic\" refers to the anaerobic bacterial environment that develops in the tank which decomposes or mineralizes the waste discharged into the tank. Septic tanks can be coupled with other onsite wastewater treatment units such as biofilters or aerobic systems involving artificially forced aeration.\n\nThe rate of accumulation of sludge—also called septage or fecal sludge—is faster than the rate of decomposition. Therefore, the accumulated fecal sludge must be periodically removed which is commonly done with a vacuum truck.\n\nA septic tank consists of one or more concrete or plastic tanks of between 4000 and 7500 liters (1,000 and 2,000 gallons); one end is connected to an inlet wastewater pipe and the other to a septic drain field. Generally these pipe connections are made with a T pipe, allowing liquid to enter and exit without disturbing any crust on the surface. Today, the design of the tank usually incorporates two chambers, each equipped with a manhole cover, and separated by a dividing wall with openings located about midway between the floor and roof of the tank.\n\nWastewater enters the first chamber of the tank, allowing solids to settle and scum to float. The settled solids are anaerobically digested, reducing the volume of solids. The liquid component flows through the dividing wall into the second chamber, where further settlement takes place. The excess liquid, now in a relatively clear condition, then drains from the outlet into the septic drain field, also referred to as a leach field, drain field or seepage field, depending upon locality. A percolation test is required prior to installation to ensure the porosity of the soil is adequate to serve as a drain field.\n\nThe remaining impurities are trapped and eliminated in the soil, with the excess water eliminated through percolation into the soil, through evaporation, and by uptake through the root system of plants and eventual transpiration or entering groundwater or surface water. A piping network, often laid in a stone-filled trench (see weeping tile), distributes the wastewater throughout the field with multiple drainage holes in the network. The size of the drain field is proportional to the volume of wastewater and inversely proportional to the porosity of the drainage field. The entire septic system can operate by gravity alone or, where topographic considerations require, with inclusion of a lift pump. Certain septic tank designs include siphons or other devices to increase the volume and velocity of outflow to the drainage field. These help to fill the drainage pipe more evenly and extend the drainage field life by preventing premature clogging or bioclogging.\n\nAn Imhoff tank is a two-stage septic system where the sludge is digested in a separate tank. This avoids mixing digested sludge with incoming sewage. Also, some septic tank designs have a second stage where the effluent from the anaerobic first stage is aerated before it drains into the seepage field.\n\nA properly designed and normally operating septic system is odor-free and, besides periodic inspection and emptying of the septic tank, should last for decades with minimal maintenance.\n\nA well designed and maintained concrete, fiberglass, or plastic tank should last about 50 years.\n\nWaste that is not decomposed by the anaerobic digestion must eventually be removed from the septic tank. Otherwise the septic tank fills up and wastewater containing undecomposed material discharges directly to the drainage field. Not only is this detrimental for the environment but, if the sludge overflows the septic tank into the leach field, it may clog the leach field piping or decrease the soil porosity itself, requiring expensive repairs.\n\nWhen a septic tank is emptied, the accumulated sludge (septage, also known as fecal sludge) is pumped out of the tank by a vacuum truck. How often the septic tank must be emptied depends on the volume of the tank relative to the input of solids, the amount of indigestible solids, and the ambient temperature (because anaerobic digestion occurs more efficiently at higher temperatures), as well as usage, system characteristics and the requirements of the relevant authority. Some health authorities require tanks to be emptied at prescribed intervals, while others leave it up to the decision of an inspector. Some systems require pumping every few years or sooner, while others may be able to go 10–20 years between pumpings. An older system with an undersize tank that is being used by a large family will require much more frequent pumping than a new system used by only a few people. Anaerobic decomposition is rapidly restarted when the tank is refilled.\n\nServices for de-sludging tend to empty a septic tank completely, i.e. take out all septage, while the actual requirement is removal of settled solids, it's left purposefully incomplete so as to leave at least some of the microbial populations in place to continue the anaerobic degradation processes that take place in a septic tank. An empty tank may be damaged by hydrostatic pressure causing the tank to partially \"float\" out of the ground, especially in flood situations or very wet ground conditions.\n\nLike any system, a septic system requires maintenance. The maintenance of a septic system is often the responsibility of the resident or property owner. Some forms of abuse or neglect include the following:\n\n\n\nSeptic tank additives have been promoted by some manufacturers with the aim to improve the effluent quality from septic tanks, reduce sludge build-up and to reduce odors. However, these additives—which are commonly based on \"effective microorganisms\"—are usually costly in the longer term and fail to live up to expectations. It has been estimated that in the U.S. more than 1,200 septic system additives were available on the market in 2011. However, very little peer-reviewed and replicated field research exists regarding the efficacy of these biological septic tank additives.\n\nWhile a properly maintained and located septic tank does not pose any more environmental problems than centralized municipal sewage treatment, certain problems can arise with septic tanks in unsuitable locations. Since septic systems require large drainfields, they are not suitable for densely built areas.\n\nSome constituents of wastewater, especially sulfates, under the anaerobic conditions of septic tanks, are reduced to hydrogen sulfide, a pungent and toxic gas. Methane may also be released. Nitrates and organic nitrogen compounds can be reduced to ammonia. Because of the anaerobic conditions, fermentation processes take place, which may generate carbon dioxide and/or methane.\n\nSeptic tanks by themselves are ineffective at removing nitrogen compounds that have potential to cause algal blooms in waterways into which affected water from a septic system finds its way. This can be remedied by using a nitrogen-reducing technology, or by simply ensuring that the leach field is properly sited to prevent direct entry of effluent into bodies of water.\n\nThe fermentation processes cause the contents of a septic tank to be anaerobic with a low redox potential, which keeps phosphates in a soluble and, thus, mobilized form. Phosphates discharged from a septic tank into the environment can trigger prolific plant growth including algal blooms, which can also include blooms of potentially toxic cyanobacteria.\n\nThe soil's capacity to retain phosphorus is usually large enough to handle the load through a normal residential septic tank. An exception occurs when septic drain fields are located in sandy or coarser soils on property adjoining a water body. Because of limited particle surface area, these soils can become saturated with phosphates. Phosphates will progress beyond the treatment area, posing a threat of eutrophication to surface waters.\n\nIn areas with high population density, groundwater pollution beyond acceptable limits may occur. Some small towns are experiencing the costs of building very expensive centralized wastewater treatment systems because of this problem, owing to the high cost of extended collection systems. To reduce residential development which might increase the demand to construct an expensive centralized sewerage system, building moratoriums and limits on the subdivision of property are often imposed. Ensuring existing septic tanks are functioning properly can also be helpful for a limited time, but becomes less effective as a primary remediation strategy as population density increases.\n\nIn areas adjacent to water bodies with fish or shellfish intended for human consumption, improperly maintained and failing septic systems contribute to pollution levels that can force harvest restrictions and/or commercial or recreational harvest closures.\n\nIn the United States, the 2007 American Housing Survey indicated that about 20 percent of all households rely on septic tanks, and that the overwhelming majority of systems are located in rural (50%) and suburban (47%) areas. Indianapolis is one example of a large city where many of the city's neighborhoods still rely on separate septic systems. In Europe, septic systems are generally limited to rural areas.\n\nIn the European Union the EN 12566 standard provides the general requirements for packaged and site assembled treatment plants used for domestic wastewater treatment.\n\nPart 1 (EN 12566-1) is for septic tanks which are prefabricated or factory manufactured and made of polyethylene, glass reinforced polyester, polypropylene, PVC-U, steel or concrete. Part 4 (EN 12566-4) regulates septic tanks that are assembled in situ from prefabricated kits, generally of concrete construction. Certified septic tanks of both types must pass a standardized hydraulic test to assess their ability to retain suspended solids within the system. Additionally, their structural adequacy in relevant ground conditions is assessed in terms of water-tightness, treatment efficiency, and structural behaviour.\n\nIn France, about 4 million households (or 20% of the population) are using on-site wastewater disposal systems (\"l’assainissement non collectif\"), including septic tanks (\"fosse septique\"). The legal framework for regulating the construction and maintenance of septic systems was introduced in 1992 and updated in 2009 and 2012 with the intent to establish the technical requirements applicable to individual sewerage systems. Septic tanks in France are subject to inspection by SPANC (\"Service Public d’Assainissement Non Collectif\"), a professional body appointed by the respective local authorities to enforce wastewater collection laws, at least once in four years. Following the introduction of EN 12566, the discharge of effluent directly into ditches or watercourses is prohibited, unless the effluent meets prescribed standards.\n\nAccording to the Census of Ireland 2011, 27.5% of Irish households (i.e. about 440,000 households), with the majority in rural areas, use an individual septic tank.\n\nFollowing a European Court of Justice judgment made against Ireland in 2009 that deemed the country non-compliant with the Waste Framework Directive in relation to domestic wastewaters disposed of in the countryside, the Water Services (Amendment) Act 2012 was passed in order to regulate wastewater discharges from domestic sources that are not connected to the public sewer network and to provide arrangements for registration and inspection of existing individual domestic wastewater treatment systems.\n\nAdditionally, a code of practice has been developed by the Environmental Protection Agency to regulate the planning and construction of new septic tanks, secondary treatment systems, septic drain fields and filter systems. Direct discharge of septic tank effluent into groundwater is prohibited in Ireland, while the indirect discharge via unsaturated subsoil into groundwater, e.g. by means of a septic drain field, or the direct discharge into surface water is permissible in accordance with a Water Pollution Act license. Registered septic tanks must be desludged by an authorized contractor at least once a year; the removed fecal sludge is disposed of, either to a managed municipal wastewater treatment facility or to agriculture provided that nutrient management regulations are met.\n\nSince 2015, only certain property owners in England and Wales with septic tanks or small packaged sewage treatment systems need to register their systems, and either apply for a permit or qualify for an exemption with the Environment Agency. Permits need to be granted to systems that discharge more than a certain volume of effluent in a given time or that discharge effluent directly into sensitive areas (e.g., some groundwater protection zones). In general, permits are not granted for new septic tanks that discharge directly into surface waters.\n\nIn Northern Ireland, the Department of the Environment must give permission for all wastewater discharges where it is proposed that the discharge will go to a waterway or soil infiltration system. The discharge consent will outline conditions relating to the quality and quantity of the discharge in order to ensure the receiving waterway or the underground aquifer can absorb the discharge.\n\nThe Water Environment Regulations 2011 regulate the registration of septic tank systems in Scotland. Proof of registration is required when new properties are being developed or existing properties change ownership.\n\nIn Australia, septic tank design and installation requirements are regulated by State Governments, through Departments of Health and Environmental Protection Agencies. Regulation may include Codes of Practice and Legislation. Regulatory requirements for the design and installation of septic tanks commonly references Australian Standards (1547 and 1546). Capacity requirements for septic tanks may be outlined within Codes of Practice, and can vary between states.\n\nIn many council districts (e.g. Sunshine Coast) septic systems have been banned and need to be replaced with much more expensive small scale sewage treatment systems that actively pump air into the tank producing an aerobic environment. Septic systems need to be replaced with any new building applications, regardless of how well the old system performed.\n\nAccording to the US Environmental Protection Agency, in the United States it is the home owners' responsibility to maintain their septic systems. Anyone who disregards this requirement will eventually be faced with costly repairs when solids escape the tank and clog the clarified liquid effluent disposal system.\n\nIn Washington, for example, a \"shellfish protection district\" or \"clean water district\" is a geographic service area designated by a county to protect water quality and tideland resources. The district provides a mechanism to generate local funds for water quality services to control non-point sources of pollution, such as septic system maintenance. The district also serves as an educational resource, calling attention to the pollution sources that threaten shellfish growing waters.\n\n\n"}
{"id": "6273051", "url": "https://en.wikipedia.org/wiki?curid=6273051", "title": "Southern bread riots", "text": "Southern bread riots\n\nThe Southern bread riots were events of civil unrest in the Confederacy during the American Civil War, perpetrated mostly by women in March and April 1863. During these riots, which occurred in cities throughout the South, women and men violently invaded and looted various shops and stores.\n\nThe riots were triggered by the women's lack of money, provisions, and food. All were the result of multiple factors:\n\nAs in the French Revolution, citizens, mostly women, began to protest the exorbitant price of bread. The protesters believed a negligent government and speculators were to blame. To show their displeasure, many protesters turned to violence. In Richmond; Columbus, Georgia, Macon, Atlanta, and Augusta armed mobs attacked stores and warehouses. In North Carolina, mobs destroyed grocery and dry goods stores.\n\nFood riots were occurring before the arrival of Union troops because the Confederate army was suffering the same food shortages and was taking food stocks for its own needs. Additionally, as the cost of war for the Confederate government exceeded the tax revenue, legislation was enacted that exacerbated the situation by devaluing the Confederate currency and inflating prices of goods.\n\nOn April 2, 1863, in the Confederate capital of Richmond, Virginia, about 5,000 people, mostly poor women, broke into shops and began seizing food, clothing, shoes, and even jewelry before the Militia arrived to restore order. Tens of thousands of dollars worth of items were stolen. No one died and few were injured. The riot was organized and instigated by Mary Jackson, a huckster and the mother of a soldier.\n\nPresident Jefferson Davis pleaded with the women and even threw them money from his pockets, asking them to disperse, saying \"You say you are hungry and have no money; here, this is all I have\". The mayor read the Riot Act; the governor called out the militia, and it restored order.\n\n"}
{"id": "23609694", "url": "https://en.wikipedia.org/wiki?curid=23609694", "title": "Spirangle", "text": "Spirangle\n\nIn geometry, a spirangle is a figure related to a spiral. Spirangles are similar to spirals in that they expand from a center point as they grow larger, but they are made out of straight line segments, instead of curves. Spirangle vectographs are used in vision therapy to promote stereopsis and help resolve problems with hand–eye coordination.\n\nA two-dimensional spirangle is an open figure consisting of a line bent into angles similar to a corresponding polygon. The spirangle can start at a center point, or a distance from the center, and has some number of turns around the center point.\n\nThree-dimensional spirangles have layers that slant upward, progressively gaining height from the previous segment. This is similar to staircases in large buildings that turn at the top of each flight. The segments also may progressively lose an amount of length and resemble a pyramid.\n\nOphthalmology – vectograms\n\nElectronics – printed inductors\n\nArchitecture – ‘spiral’ staircases\n\nJewelry – earrings, pendants\n\nSearch Algorithms - efficient scanning of a region of interest (crime scenes, astronomical regions, etc.)\n\n\n\n"}
{"id": "53830", "url": "https://en.wikipedia.org/wiki?curid=53830", "title": "St. Elizabeths Hospital", "text": "St. Elizabeths Hospital\n\nSt. Elizabeths Hospital opened in 1855 as the first federally operated psychiatric hospital in the United States. Housing over 8,000 patients at its peak in the 1950s, the hospital at one point had a fully functioning medical–surgical unit, a school of nursing, and accredited internships and psychiatric residencies. Its campus was designated a National Historic Landmark in 1990.\n\nSt. Elizabeths is in southeast Washington, D.C. Since 2010, hospital functions have been limited to a portion of the east campus operated by the District of Columbia Department of Mental Health. The remainder of the east campus is slated for redevelopment by the District of Columbia, which owns the site. The west campus is owned by the federal government and is being redeveloped for use as headquarters for the U.S. Department of Homeland Security and its child agencies.\n\nThe hospital was created in August 1852 when the United States Congress appropriated $100,000 for the construction of a mental hospital in Washington, D.C.; to provide care for indigent, mentally ill residents of the District of Columbia, as well as for the insane of the U.S. Army and U.S. Navy. As early as the 1830s, local residents including Dr. Thomas Miller, a local doctor and president of the D.C. Board of Health, had been petitioning Congress for a facility to care for the mentally ill in the City of Washington. Their efforts were given a significant boost when Dorothea Dix (1802–1877), a pioneering advocate for people living with mental illnesses, helped convince legislators of the need for the hospital. In 1852 she wrote the legislation that established the hospital. Dix, who was on friendly terms with President Millard Fillmore, was asked to assist the secretary of the interior in getting the hospital started. Her first recommendation resulted in the appointment of Dr. Charles H. Nichols as the hospital's first superintendent. After his appointment in the fall of 1852, Nichols and Dix began formulating a plan for the design and operation of the hospital as well as finding an appropriate location for it, based upon guidelines created by Thomas Story Kirkbride. His 1854 manual recommended specifics such as site, ventilation, number of patients, and the need for a rural location proximate to a city. He also recommended that the location have good soil for farming and gardens for the patients.\nDr. Nichols oversaw the design and building of St. Elizabeths, which began in 1853. It was built in three phases, the west wing first, then the east wing, and finally the center portion. The center portion was built to house all administrative operations as well as the superintendents' residential quarters. All three sections of the hospital were together under one roof, in keeping with Kirkbride's design. Two other buildings, the West Lodge (1856–98) for men and the East Lodge for women were built to house and care for African American patients.\n\nSoon after the hospital opened to patients in January 1855, it became known officially as the Government Hospital for the Insane. During the Civil War the West Lodge, originally built for male African American patients, was used as a general hospital by the U.S. Navy. The unfinished east wing of the main building was used by the U.S. Army as a general hospital for sick and wounded soldiers. The Army hospital officially took the name of St. Elizabeths Army Medical Hospital to differentiate it from the mental hospital in the west wing of the same building. The name St. Elizabeths was derived from the colonial-era name for the tract of land on which the hospital was built.\nAfter the Civil War and the closing of the Army's hospital, the St. Elizabeths name was used unofficially and intermittently until 1916, when Congress passed legislation changing the name from the Government Hospital for the Insane to St. Elizabeths Hospital, inexplicably omitting the possessive apostrophe. Also it transferred hospital to the United States Department of Interior.\n\nIn the late 19th century the hospital temporarily housed animals that were brought back from expeditions for the Smithsonian Institution, because of lack of housing for the animals at the yet-to-be-built National Zoo.\n\nBy 1940 St. Elizabeths Hospital was transferred to Federal Security Agency, after abolition of Service hospital was transferred to Department of Health, Education, and Welfare. At its peak, the St. Elizabeths campus housed 8,000 patients and employed 4,000 people. Beginning in the 1950s, however, large institutions such as St. Elizabeths were being criticized for hindering the treatment of patients. Community-based health care, as specified in the passage of the 1963 Community Mental Health Act, led to deinstitutionalization. The act provided for local outpatient facilities and drug therapy as a more effective means of allowing patients to live near-normal lives. The first community-based center for mental health was established at St. Elizabeths in 1969. The patient population of St. Elizabeths steadily declined.\n\nBy the 1960s and 1970s, the hospital was transferred to the National Institute of Mental Health, the National Institutes of Health and the Department of Health and Human Services.\n\nBy 1996 only 850 patients remained at the hospital, and years of neglect had become apparent; equipment and medicine shortages occurred frequently, and the heating system was broken for weeks at a time. By 2002 all remaining patients on the Federal western campus were transferred to other facilities. Although it continues to operate, it does so on a far smaller scale than it once did. As of January 31, 2009, the current patient census was 404 in-patients.\n\nIn recent years approximately half of St. Elizabeths patients are civilly committed to the hospital for treatment; the other half are forensic (criminal) patients. Forensic patients are those who are adjudicated to be criminally insane (not guilty by reason of insanity) or considered incompetent to stand trial. Civil patients are those who are admitted owing to an acute need for psychiatric care. Civil patients can be voluntarily or involuntarily committed for treatment.\n\nA new civil and forensic hospital was built on the East Campus by the District of Columbia Department of Mental Health and opened in the spring of 2010, housing approximately 297 patients. Until the new hospital opened, civil patients were cared for in various buildings on the East Campus; forensic patients were housed in the John Howard Pavilion. In the new facility, civil and forensic patients live in separate units of the same building. The new hospital also houses a library, an auditorium, multiple computer laboratories, and a small museum in the lobby.\n\nIn 2007 the U.S. Department of Justice and the District of Columbia reached a settlement over allegations that the civil rights of patients housed at St. Elizabeths were violated by the District. On August 28, 2014, the Department of Justice found that St. Elizabeths had \"significantly improved the care and treatment of persons confined to Saint Elizabeths Hospital\" and asked a federal court to dismiss the injunction. In January 2015, DC Auditors dismissed the settlement agreement and officially ended oversight of St. Elizabeths Hospital.\n\nAfter several decades in decline, it was decided that the large campus could no longer be adequately maintained. In 1987 hospital functions on the eastern campus were transferred from the United States Department of Health and Human Services to the District of Columbia government by St. Elizabeths Hospital and District of Columbia Mental Health Services Act of 1984, with the federal government retaining ownership of the western campus. Several commercial redevelopment opportunities were proposed by the D.C. government and consultants, including relocating the University of the District of Columbia to the campus or developing office and retail space. However, the tremendous cost of bringing the facilities up to code (estimated at $50–$100 million) kept developers away.\n\nWith little interest in developing the site privately, the federal government stepped in. Control of the western campus—home of the oldest building on the campus, the Center Building—was transferred to the General Services Administration in 2004. GSA improved security around the campus, shored up roofs, and covered the windows with plywood in an attempt to preserve the campus until a tenant could be found.\n\nAfter three years of searching for an occupant, the Department of Homeland Security (DHS) announced on March 20, 2007, that it would spend approximately US$4.1 billion to move its headquarters and most of its Washington-based offices to a new facility on the site, beginning with the United States Coast Guard in 2010. DHS, whose operations are scattered around dozens of buildings in the Washington, D.C., area, hopes to consolidate at least 60 of its facilities at St. Elizabeths and to save $64 million per year in rental costs. DHS also hopes to improve employee morale and unity by having a central location from which to operate.\n\nThe plans to locate DHS to St. Elizabeths have been met with criticism, however. Historic preservationists argue that the move will destroy dozens of historic buildings located on the campus and that other alternatives should be considered. Community activists have also expressed concern that the planned high-security facility will not interact with the surrounding community and do little to revitalize the economically depressed area. In 2007 the District of Columbia reached a deal with the Department of Justice and agreed to fix widespread health and safety hazards in the hospital.\n\nA ceremonial groundbreaking for the DHS consolidated headquarters took place at St. Elizabeths on September 11, 2009. The event was attended by Senator Joseph Lieberman, DHS Secretary Janet Napolitano, D.C. Delegate Eleanor Holmes Norton, DC Mayor Adrian Fenty, and acting GSA administrator Paul Prouty.\n\nThe relocated U.S. Coast Guard Headquarters Building was forecast to open in May 2013, and a ceremony was held in July 2013 at the site before it is to be officially opened. Along U.S. Coast Guard Headquarters Building, several former hospital buildings (Atkins Hall, cafeteria) had been rehabilitated.\n\nBy 2015, construction began in Center Building. Initially, this building has been stated for renovation, but internal structures (floors and ceilings) appeared to be beyond repair. Whole Center Building was rehabilitated by removing old internal structures and building new structures in latter place, while retaining the historic facades.\n\nThe St. Elizabeth's East Campus is a planned development for mixed use rental property development.\n\nWell-known patients of St. Elizabeths have included would-be presidential assassins Richard Lawrence (who attempted to kill Andrew Jackson) and John Hinckley Jr., who shot Ronald Reagan, as well as the assassin of James Garfield, Charles J. Guiteau (until his execution). Other notable residents were Mary Fuller, James Swann, Ezra Pound, and William Chester Minor.\n\nThe poet Ezra Pound was kept in St. Elizabeths on the charge of treason for 13 years (1946–58). Despite his being sane, and proving it by publication of two volumes of poetry and several translations, he was deemed unfit to stand trial by reason of insanity. In 1958 the treason charges were dropped, but Dr. Overholser discharged him as \"incurably insane.\"\n\nAccording to Kelly Patricia O'Meara, St. Elizabeths is believed to have treated over 125,000 patients, though an exact number is not known because of poor record keeping. Additionally, she believes that thousands of patients are buried in unmarked graves across the campus, although records for the individuals buried in the graves have been lost. She believes that the incinerator on site also brings up a few questions as to what may have happened to the bodies. The General Services Administration, current owner of the property, considered using ground penetrating radar to attempt to locate unmarked graves but has yet to do so.\n\nMore than 15,000 known autopsies were performed at St. Elizabeths from 1884 through 1982, and a collection of over 1,400 brains preserved in formaldehyde, 5,000 photographs of brains, and 100,000 slides of brain tissue was maintained by the hospital until the collection was transferred to a museum in 1986, according to O'Meara. In addition to the mental health patients buried on the campus, several hundred American Civil War soldiers are interred at St. Elizabeths.\n\nSeveral important therapeutic techniques were pioneered at St. Elizabeths, and it served as a model for later institutions. Walter Freeman, onetime laboratory director, was inspired by St. Elizabeths to pioneer the transorbital lobotomy. During American involvement in World War II, the Office of Strategic Services (OSS, predecessor to the CIA) used facilities and staff at St. Elizabeths hospital to test \"truth serums\". OSS unsuccessfully tested a mescaline and scopolamine cocktail as a truth drug on two volunteers at St. Elizabeths Hospital. Separate tests of THC as a truth serum were equally unsuccessful. In 1963 Dr. Luther D. Robinson, the first African American superintendent of St. Elizabeths, founded the mental health program for the deaf and was throughout his career a leading authority on treating deaf patients with mental disorders.\n\nThe campus of St. Elizabeths sits on bluffs overlooking the confluence of the Potomac and Anacostia Rivers in the southeast quadrant of Washington, D.C. It is divided by Martin Luther King Jr. Avenue between the east campus (owned by the D.C. government) and the west campus (owned by the federal government). It has many important buildings, foremost among them the Center Building, designed according to the principles of the Kirkbride Plan by Thomas U. Walter (1804–87), who is better known as the primary architect of the expansion of the U.S. Capitol that was begun in 1851.\n\nMuch of St. Elizabeths' campus has now fallen into disuse and is in serious disrepair. It was named in 2002 one of the nation's 11 Most Endangered Places by the National Trust for Historic Preservation. Access to many areas of the campus, including the abandoned western campus (which houses the Center Building), is restricted.\n\n\n\n"}
{"id": "22225212", "url": "https://en.wikipedia.org/wiki?curid=22225212", "title": "Steve Romeo", "text": "Steve Romeo\n\nSteve Romeo, Jr. (June 1, 1971 – March 7, 2012) was an American ski mountaineer living in Jackson, Wyoming. Romeo was a prominent figure in the backcountry ski community of Jackson Hole, Wyo. He founded and ran the popular ski blog \"Tetonat.com\" which covered backcountry skiing throughout the Tetons as well as extensive gear reviews. Romeo was killed on March 7, 2012 in a large slab avalanche on Ranger Peak in the northern part of the Teton Range of Wyoming. Some criticized Romeo's skiing as being somewhat reckless, yet most of the ski community saw Romeo as a preeminent American ski mountaineer who constantly pushed the boundaries of skiing in the Tetons. Others saw him as another self-promoting eastern transplant. Together with Cary Smith, Pete Swenson and Chris Kroger, he finished ninth in the relay event of the 2006 World Championship of Ski Mountaineering. He was also known as \"Randosteve\", \"Randomeo\", \"Randobewan Skinobee\", \"Skeve\", \"Ex-Steve\", \"Stevester\", and \"Stelvester Stallone\".\n\nRomeo was originally from Manchester, Connecticut, and following graduation from Marist College in 1993, he moved to Jackson Hole to work as a lift operator at Jackson Hole Mountain Resort. Romeo started the backcountry ski blog TetonAT.com in 2006. The site had a daily audience of over 10,000 visitors.\n\nThe popularity of TetonAT, coupled with Romeo's relatively high profile within the ski community, led Romeo to eventually gain sponsorships with the following industry leaders: Black Diamond, Dynafit, Arc'Teryx, Ortovox, GU, Nuun, and Mountain Khakis. Romeo skied across the globe, including notable stops throughout Europe, South America, New Zealand, Alaska, and Antarctica.\n\nOn March 7, 2012, Steve Romeo and ski partner Chris Onufer left Colter Bay and crossed Jackson Lake over three miles of ice to the base of Ranger Peak in the northern Teton Range. Their tracks continued up the mountains toward Ranger Peak with their final intended destination probably being an unskied chute located in the Waterfalls Canyon area. It is impossible to know exactly what Romeo and Onufer's plans were for the day as they had not informed anyone of specific intended routes. \"They chose to go up a known avalanche path ascending into an avalanche starting zone,\" noted Jenny Lake Park Ranger Rich Baerwald. Romeo and Onufer's skin tracks went up most of the mountain before disappearing in the avalanche slide path. This is likely where Romeo and Onufer triggered the avalanche, as search and rescue workers discovered the tell-tale signs of an avalanche trigger point as well as a three foot avalanche crown. Park rangers estimated that the avalanche gained speeds of up to 80 miles an hour. The avalanche debris could be seen from a distance of 14 miles, giving some measure of the size of the slide and its destructive power.\n\nJohn Onufer, Chris's father, initially recognized that something was wrong when his son never showed up to meet him at the Jackson Hole Airport after flying in on the day of the avalanche. John Onufer contacted officials who quickly located the pair's car at Colter Bay. Romeo and Onufer's bodies were quickly located the day after the avalanche, as their bodies were not entirely buried in the avalanche debris that stretched for over a mile. The cause of death for both men was determined to be blunt force trauma by the Teton County Coroner.\n\nThough the avalanche danger was listed as moderate on the day of the avalanche by the Bridger-Teton Avalanche center, the risk of a slide was increased by wind blowing loose snow onto leeward faces and loading certain aspects with additional snow, creating dangerous windslabs in certain areas. The avalanche that killed Romeo and Onufer was on a slope that had been adversely affected by windblown snow.\n\nSome within the Jackson Hole ski community wondered if various avalanche safety equipment devices, such as an 'avalanche airbag' could have saved the two from death in the avalanche, but park rangers stated that the avalanche was unsurvivable and that no equipment could have saved them. \"One piece of equipment wasn't going to have any effect on injuries,\" noted Buffalo Fork Ranger Rick Guerrieri. \"Their best tool they had with them, they weren't using the most. That was their brain.\" Although Romeo may have agreed with Guerrieri's statement, many members of the skiing community felt it was hurtful and in poor taste. As one of Romeo's ski partners, Reed Finlay, reflected, \"Even experts make mistakes. If you're a kid, it's a good lesson.\" \n\nRomeo's website TetonAT.com posted a memorial entry to Romeo and Onufer following their deaths, but has remained otherwise silent. The page continues to carry the sponsorship of many ski industry leaders.\n\nRomeo is survived by his parents, Elaine and Stephen Sr. Romeo, who live in Connecticut. Following the death of Steve, Elaine and Stephen Sr. went to Jackson Hole for a memorial, and they noted the amount of support from the community as a whole, pointing to Steve's impact in the area.\n\n"}
{"id": "46318138", "url": "https://en.wikipedia.org/wiki?curid=46318138", "title": "Tadashi Kanehisa", "text": "Tadashi Kanehisa\n\nKanehisa was born to a wealthy family in Shodon, a village in southwestern Kakeroma Island of the Amami Islands. Unlike his half-brothers and sisters, he was grown up by his grandparents. His grandfather Minesato (嶺佐登) was an important source of his folkloristic studies in his later life.\n\nHe studied English literature at Kyushu Imperial University. Being disappointed with it, he spent about five years pursuing folkloristic studies in his hometown Shodon. He then worked for the Nagasaki Prefectural Government while teaching linguistics at Kwassui Women's College. He published his folkloristic work at the \"Nantō\" (Southern Islands) edited by Eikichi Kazari, and the \"Tabi to Densetsu\" (Travels and Legends). He won fame for his paper \"Amori Onagu\" (天降り女人) (1943), where he proposed a couple of novel theories on Amami's swan maiden motif, a conundrum originally posed by Shomu Nobori. His work was highly commended by Kunio Yanagita, the father of Japanese folkloristics. His main source of information was a group of young men from Amami who had been drafted into the armament industry in Nagasaki. His informants were all killed by the U.S. atomic bombing on Nagasaki in 1945. He himself gradually lost his eyesight after the bombing.\n\nAfter World War II, he returned to Shodon and soon moved to Naze (part of modern-day Amami City), the center of Amami Ōshima. His blindness kept him from using his talent for prestigious jobs. He ran a private-tutoring school for the English language during daytime while continuing folkloristic and linguistic research at night. His decades of work resulted in the book titled \"Amami ni ikiru Nihon kodai bunka\" (Ancient Japanese Culture Still Alive in Amami). Its publication was done with the help from linguist Shirō Hattori.\n\nBeing a linguist himself, he worked as an informant of the Shodon dialect, which is part of the Southern Amami Ōshima dialect group of the Japonic languages. He worked with Yukio Uemura, Shirō Hattori and Samuel Martin. He was praised as an ideal informant by Hattori. His primarily linguistic work include the \"Amami hōgen on'in no sandai tokushoku\" (Three features of the Amami dialect phonology) and the \"Amami ni ikiru kotengo\" (Literary language still alive in Amami). He spent his final years in Kagoshima. He died in 1997, leaving an uncompleted dictionary of the Amami dialect.\n\n"}
{"id": "17596651", "url": "https://en.wikipedia.org/wiki?curid=17596651", "title": "Ventilated cigarette", "text": "Ventilated cigarette\n\nVentilated cigarettes (labeled in certain jurisdictions as \"Light\" or \"Mild\" cigarettes) are considered to have a milder flavor than regular cigarettes. These cigarette brands may be listed as having lower levels of tar (\"low-tar\"), nicotine, or other chemicals as \"inhaled\" by a \"smoking machine\". However, the scientific evidence is that switching from regular to light or low-tar cigarettes does not reduce the health risks of smoking or lower the smoker's exposure to the nicotine, tar, and carcinogens present in cigarette smoke.\n\nThe filter design, which may include perforated holes, is one of the main differences between light and regular cigarettes. When attached to a smoking machine, the small holes in the sides of the filter dilute the tobacco smoke with clean air. In ultra-light cigarettes, the filter's perforations are even larger, and on the smoking machine, they produce an even smaller smoke-to-air ratio. However, smokers react to the reduced resistance by inhaling more deeply, and tend to cover the holes with their fingers and mouth. None of these ventilation techniques reduce harm to smokers, and some may increase it; they are designed to give better readings in a smoking-machine test while minimally reducing what human smokers inhale.\n\nSmokers and adolescents generally falsely believe that \"light\" cigarettes are less harmful and less addictive. Usage of descriptors such as \"light\" or \"mild\" has thus been banned in the European Union, Australia, Malaysia, Philippines, the United States, and other countries. Tobacco manufacturers use color-coding to allow consumers to differentiate between regular and light brands, using lighter colors and silver for \"light\" cigarettes. Standardized plain dark brown packaging reduces this misperception.\n\nThe 1950s gave birth to numerous scientific studies that proved the link between cigarettes and cancer (see Wynder and Graham, 1950; Doll and Hill, 1952, 1954; Hammond and Horn, 1958). In response to these studies and their perceived threat to the tobacco industry's future profitability, tobacco companies experimented with new modifications to the cigarette design. By altering the cigarette design, tobacco companies hoped to create a \"safer\" cigarette that would better appeal to their increasingly health-conscious consumers. The addition of filters was one of the industry's first design modifications, and filters would become essential to the later development of light and low-tar products. Claiming that filtered cigarettes literally \"filtered out\" much of the harmful tar and carcinogenic particles found in regular cigarettes, tobacco companies promoted \"relative product safety\" in order to convince smokers to continue smoking. Because filtered cigarettes were depicted as relatively safer and less harmful, smokers who were concerned about tobacco's negative health impacts were led to believe that by switching to filtered cigarettes, they would minimize smoking's detrimental impact on their health. As a result, millions of smokers switched to filtered cigarettes instead of quitting altogether. By 1960, filtered cigarettes had become the leading tobacco product.\n\nIn addition to promoting the filtered cigarette as the answer to smokers' health concerns, the tobacco industry also poured resources into developing a cigarette that would produce lower machine-measured tar and nicotine yields when tested by the Federal Trade Commission (FTC). This endeavor resulted in the introduction and heavy promotion of \"light\" cigarettes during the 1970s. The newly designed light cigarette employed a special filter perforated with small holes; these perforated filters allegedly offset the concentration of inhaled harmful smoke with clean air. Most important to the tobacco industry, however, was that light cigarettes produced lower tar and nicotine levels when tested with the FTC's smoking machines.\n\nBy 1997, the advertising of light cigarettes constituted fifty percent of the tobacco industry's advertising spending. Through heavy marketing, the tobacco industry succeeded in leading its consumer base to believe that light products were safer than regular brands, and thus, that these products were the rational choice for smokers who cared about their health. As a result of these implicit and widespread health claims, the popularity of light and low-tar cigarettes grew considerably. In fact, the market share of light cigarettes grew from 2.0 percent in 1967 to 83.5 percent of the tobacco market in 2005.\n\nPackages of light, mild, and low-tar cigarettes are often labeled as being \"lower tar and nicotine\" and also list tar and nicotine levels that are lower than those found on the packages of regular cigarettes. The lower tar and nicotine numbers found on cigarette packages represent the levels produced when machine \"smoked\" by a smoking machine test method. Developed by the FTC in 1967, the smoking machine test method was created to determine the yield of a cigarette by \"smoking\" it in a standardized fashion by machine; this test method is also known as the International Organization for Standardization (ISO) machine-smoking method. While the FTC has always recognized that the smoking machine cannot accurately replicate human smoking and that no two human smokers smoke in the same way, the FTC did not initially recognize the tobacco industry's ability to design cigarettes that yielded low levels of tar and nicotine when machine-smoked, but yielded much higher levels when smoked by a human being.\n\nLight cigarettes essentially fool smoking machines through several techniques. A light cigarette's filter perforated by tiny holes, for instance, is uncovered when smoked by machine, and consequently, the cigarette smoke is heavily diluted with air and causes the machines to report low levels of nicotine and tar. When smoked by human smokers, in contrast, this filter is usually covered by smokers' lips and fingers. Consequently, the filter holes are closed and the light cigarette actually becomes equivalent to a regular cigarette. Some tobacco manufacturers also increased the length of the paper wrap which covers the cigarette filter; this modification serves to decrease the number of \"puffs\" available to the machine test and limits the amount of tobacco that is machine \"smoked\". In reality, however, the tobacco found under this paper wrap which is not \"smoked\" by machine is still available to and smoked by the human smoker.\n\nThe human act of \"compensating\" is perhaps the most important area in which the ISO machine-smoking method yields misleading results. Unlike machines, human smokers are often heavily addicted to the nicotine in cigarettes, and consequently, smokers alter their smoking behaviors in order to consume the amount of nicotine required to satisfy their cravings. Compensatory behavior most often occurs when a smoker switches from regular cigarettes to light cigarettes. Numerous scientific studies reveal that the smoker compensates for the lower concentration of nicotine by actively changing his or her smoking habits. Smokers adjust their smoking techniques by smoking their cigarettes \"more intensively\". More intensive smoking is achieved by taking larger, more rapid, and more frequent puffs, by inhaling more deeply, by smoking more cigarettes per day, and/or by reflexively blocking the cigarette's filter. Due to these compensatory smoking behaviors, smokers of light cigarettes inhale significantly more nicotine and tar than what is measured by the ISO machine-smoking method.\n\nAccording to the 2004 Surgeon General's report, \"Smoking cigarettes with lower machine-measured yields of tar and nicotine provides no clear benefit to health.\" The tobacco industry's own internal documents also reveal that cigarette manufacturers are aware of the difference between machine-measured levels of nicotine and tar, and those actually inhaled by smokers. The industry is also aware of the compensatory behaviors that smokers engage in when smoking light cigarettes.\n\nA recent small-scale study led by nicotine researcher Neal Benowitz found that smokers who were switched to cigarettes with tobacco that contained progressively less nicotine did not compensate by smoking more cigarettes, although a significant minority of the smokers in the research withdrew from the study citing a dislike of the taste of the reduced-nicotine cigarettes. These results differ greatly from those obtained in earlier studies by Benowitz and others, where filter-based nicotine reduction was found to result in compensatory smoking behaviours. According to a USCF article on the study, Benowitz wanted to simulate a societal scenario in which the nicotine content of cigarettes would be progressively regulated downward.\n\nAccording to a 2013 \"Washington Post\" article, the US FDA has backed low-nicotine cigarette research as it weighs its new regulatory power. That new power includes the power to regulate the level of nicotine in cigarettes and was given to the FDA by the 2009 Tobacco Control Act.\n\nIn June 2009, the United States Senate passed anti-smoking legislation described by USA Today as \"the most sweeping tobacco-control measure ever passed by Congress\". This legislation directly impacted the marketing and consumption of light tobacco products. In addition to giving the FDA regulatory power over all tobacco products, the bill severely restricted the tobacco industry's previous marketing strategies, many of which relied on making implicit health claims about their products. According to the bill, cigarette manufacturers are also forbidden from using product descriptors such as \"light\", \"low-tar\", and \"mild\".\n\nCritics of the legislation question whether it will have a significant impact on today's pervasive tobacco market in the United States. For one, the bill does not specify acceptable words for differentiating light cigarettes from other cigarettes. Cigarette manufacturers quickly responded to this loophole by strategically color-coding their products so that Camel Lights, for example, is now Camel Blue. Nik Modi, a tobacco industry analyst, concedes that prohibiting terms like \"light\" and \"low-tar\" will hardly affect the tobacco market because smokers have already \"become acclimated to color-coding.\"\n\nThe 2001 Directive on Tobacco Products, which banned the use of terms such as \"light\", \"mild\" and \"low-tar\" with regards to tobacco products, was the first major piece of legislation from the European Commission regarding tobacco control. This came into effect on 30 September 2003 for members of the European Union. A study on the United Kingdom found that while legislation had a minor impact in challenging misleading perceptions of ventilated cigarettes among smokers in the short term, by 2005 the change in belief had changed no more than in the United States, which at the time did not have any regulation regarding \"light\" descriptors of ventilated cigarettes.\n\n\n\n"}
{"id": "22464547", "url": "https://en.wikipedia.org/wiki?curid=22464547", "title": "Zygmunt Zimowski", "text": "Zygmunt Zimowski\n\nZygmunt Zimowski (7 April 1949 – 13 July 2016) was a Polish prelate of the Roman Catholic Church. Archbishop Zimowski had served until his death in July 2016 as President of the Pontifical Council for the Pastoral Care of Health Care Workers, having been head of that office since his appointment by Pope Benedict XVI on 18 April 2009. He previously served as bishop of Radom from 2002 until 2009.\n\nZimowski was born in Kupienin, Poland, located in the Roman Catholic Diocese of Tarnów. He was ordained a priest on 27 May 1973, and incardinated in Tarnów. He received a Licentiate in Dogmatic Theology from the Catholic University of Lublin. He continued his studies and subsequently received his Doctorate in Dogmatic Theology from the Faculty of Theology at the Leopold-Franzens University of Innsbruck. On 1 February 1983 he entered the service of the Congregation for the Doctrine of the Faith, where he remained until elevated to the episcopate. He was appointed Chaplain of His Holiness on 14 April 1988 and Prelate of Honour on 10 July 1999.\n\nHe was Postulator of some processes of beatification and canonization. He taught ecclesiology at the Catholic University of Lublin and at the Cardinal Stefan Wyszyński University in Warsaw and is the author of 120 publications, 40 pastoral letters and some books and several articles.\n\nHe participated in the preparation of the Catechism of the Catholic Church and worked with the Polish section of Radio Vatican.\n\nOn 28 March 2002, Zimowski was appointed Bishop of the Roman Catholic Diocese of Radom, and was consecrated in the Cathedral of Radom on 25 May 2002 by the Cardinal Prefect of the Congregation for the Doctrine of the Faith, Joseph Ratzinger, later Pope Benedict XVI. In the Polish Bishops' Conference, he held the following positions: President of the Episcopal Commission for the Doctrine of the Faith, Member of the Permanent Council, Delegate for the Pastoral Care of Migrants Poles, Member of the Ecumenical Commission and the Group for Contacts with the Polish Ecumenical Council, Member of the group of Bishops for the Pastoral Care for Radio Maria, and Member of the Polish Society of Mariology.\n\nHe remained Bishop of Radom until his appointment as the President of the Pontifical Council for the Pastoral Care of Health Care Workers in 2009. He was at the same time raised to the dignity of Archbishop \"ad personam\". In addition to his native Polish, Archbishop Zimowski speaks Italian, German, English, French and Russian.\n\nIn January 2011 Archbishop Zimowski said that \"Leprosy, in fact, after the upgrading of effective pharmacological therapies, witnessed a notable reduction of the lethal infection, but continues to cause suffering, diminution and social exclusion. Flourishing around it are ignorance, inequality and discrimination that, in turn, fuel its diffusion\". He noted that from a statistical point of view, the countries that are most affected are in Asia, South America and Africa. India has the greatest number of affected people, followed by Brazil. Numerous cases are recorded also in Angola, Bangladesh, the Central African Republic, the Democratic Republic of the Congo, Indonesia, Madagascar, Mozambique, Nepal and Tanzania. He said that \"Hansen's disease is an 'ancient' illness, but, because of this, no less devastating physically and also morally,\" Archbishop Zimowski reflected. \"In all ages and civilizations, the fate of the leprosy sufferer is marginalization, being deprived of any type of social life, condemned to seeing his body disintegrate until death comes.\"\n\nOn 4 May 2011, Pope Benedict appointed him a member of the Congregation for the Causes of Saints.\n\nOn 18 May 2011, in a speech to the annual assembly of the World Health Organization in Geneva, Switzerland, he said that the world seemed \"stalled in the status quo where the rich people have higher levels of coverage, while most of the poor people miss out, and [even] those who do have access often incur high, sometimes catastrophic costs in paying for services and medicine.\" He raised objections to needle-exchange programs and called for increased funding for poor nations.\n\nOn 2 April 2012, World Autism Awareness Day, Archbishop Zimowski said that \"The Church needs to address the alienation often surrounding those living with autism, especially children and young people, by coming to the aid of those affected\". He added: \"The church sees as impelling the task of placing herself at the side of these people – children and young people in particular – and their families, if not to break down these barriers of silence then at least to share in solidarity and prayer in their journey of suffering\".\n\nIn May 2012 Archbishop Zimowski, as head of the Holy See delegation to the 65th World Health Assembly, reaffirmed the Holy See's support for Resolution WHA64.9 on \"sustainable health financing structures and universal coverage,\" which urges member states to aim for affordable universal health care coverage and access for all citizens on the basis of equity and solidarity. Zimowski said \"more countries, especially those with emerging economies, are moving towards universal coverage,\" thanks also to \"good policies that promote equity. ... Therefore my delegation strongly believes that in the endeavor to promote universal coverage, fundamental values such as equity, human rights and social justice need to become explicit policy objectives\". The archbishop made an appeal for high-income countries to show greater solidarity toward poorer nations in order to overcome funding shortfalls in health.\n\nOn 28 July 2012, Archbishop Zimowski was named a Member of the Congregation for Bishops by Pope Benedict XVI.\n\nZimowski died in Poland on 13 July 2016, while convalescing following treatment for pancreatic cancer.\n"}
