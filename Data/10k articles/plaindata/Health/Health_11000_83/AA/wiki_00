{"id": "30075572", "url": "https://en.wikipedia.org/wiki?curid=30075572", "title": "AIDS Service Center NYC", "text": "AIDS Service Center NYC\n\nAlliance for Positive Change - formerly known as AIDS Service Center NYC - is a community organization that helps New Yorkers living with HIV and other chronic illnesses. Founded in 1990 by CEO Sharen Duke, ASCNYC provides direct services to over 1,800 New Yorkers per year, while its peer education programs and community outreach initiatives reach an additional 18,000. In 2017, the organization formally changed its name to The Alliance for Positive Change. This change came as the nonprofit expanded to help more New Yorkers with substance use and mental health issues, and program participants with chronic illnesses such as hepatitis, diabetes, and heart disease.\n\nThe Alliance for Positive Change transforms lives of New Yorkers living with HIV/AIDS and other chronic illnesses. It helps people access medical care, manage and overcome addiction, escape homelessness, get back to work, and find community. By addressing the underlying issues that contribute to poor health, the Alliance’s individualized, full-service approach and harm reduction philosophy help New Yorkers lead healthier, more self-sufficient lives.\n\nBased in midtown New York, ASCNYC partnered with the Keith Haring Foundation to open the Keith Haring ASC Harlem Center in 2010 and opened CASA Washington Heights to serve New York's Washington heights community in 2011.\n\nASCNYC partners with New York hospitals, such as Mount Sinai Hospital, New York, Beth Israel Medical Center, New York-Presbyterian Hospital and St. Luke's-Roosevelt Hospital Center for care coordination and case management for patients with HIV/AIDS. ASCNYC is a member of the Federation of Protestant Welfare Agencies.\n\nIn 2009, singer John Legend gave ASCNYC permission to remix his song \"If You're Out There\" to create a music video promoting HIV/AIDS awareness and testing. The video was launched at ASCNYC's annual Safer Sex in the City fundraiser.\n\nAlliance programs and services promote the well-being, empowerment, and stability of persons living with HIV/AIDS and other chronic illnesses. Program highlights include: \n"}
{"id": "34032561", "url": "https://en.wikipedia.org/wiki?curid=34032561", "title": "Abu Dhabi Medical Congress", "text": "Abu Dhabi Medical Congress\n\nAbu Dhabi Medical Congress, popularly known as Abu Dhabi Med, is a medical healthcare exhibition and conference held annually at Abu Dhabi, United Arab Emirates. It is the only event in the world that brings Emergency services, Patient Safety, Primary Healthcare and Rehabilitation businesses, organizations and professionals together under-one-roof for scientific and commercial exchange.\nDuring the event, international and local companies to showcase their latest products and innovations within the Emergency, Primary Healthcare, Patient Safety, Rehabilitation and Dentistry sectors. The Congress also serves as a platform for scientific exchange via the accompanying multi-track conference programme dedicated to these healthcare areas.It is organised by Informa Exhibitions which also organises Arab Health.The Abu Dhabi Medical Congress is the fastest growing event of its kind.\n\nIt is held annually at the Abu Dhabi National Exhibition Centre (ADNEC) and the event attracts more than 5000 professionals working in the Primary Healthcare, Emergency, Patient Safety, Rehabilitation and Pharma sectors across the Middle East. In 2011 the Abu Dhabi Medical Exhibition & Congress occupied over 5,000 square meters with 120 exhibitors from 24 countries showcasing their products and services at the event. Exhibitors showcase ambulances, defibrillators, immobilization devices, mobile surgical equipment, rapid infusion systems, pharmaceuticals, diagnostics, disposables, dietary management systems, autoclaves, bandages & dressings, clinical waste management, dental equipment & supplies, disinfectants.\n\nAlongside the exhibition runs a congress programme to discuss current goals, review tools for implementation, and meet the challenges of new and emerging healthcare dilemmas in the region. Ten different CME accredited congresses with a panel of more than 250 international speakers analyse the current best approaches for each sector involved in the congress.\n\nThe Emergency Congress & Exhibition co-locates with four other vertical events at the Abu Dhabi Medical Congress. It brings together regional and international emergency service professionals along with product manufacturers and distributor.\n\nThe Primary Healthcare Congress is a business-to-business forum for the Middle East's primary Healthcare sector. It covers a range of products and services including pharmaceuticals, healthcare management software, clinical research, diagnostics. The congress also hosts three conferences from current trends in pharma, through to bone & joint and family medicine.\n\nThe Patient Safety Congress is an interactive platform for patient safety and infection control.\n\nThe Rehabilitation Exhibition & Congress is a platform which showcases all products and services related to rehabilitation including mobility aids and physiotherapy equipment. The show vertical also include a three-day conference for rehabilitation specialists.\n\nThe event demonstrates the latest technologies from companies specialized in dental, sterilization, patient safety and infection control equipment to a body of senior dentists.\n\nIt is a three-day conference focused on the role of nurses in the management of various diseases and patient cases, and highlight the importance of nursing research in the field of acute and critical care.\n\n"}
{"id": "54677520", "url": "https://en.wikipedia.org/wiki?curid=54677520", "title": "Accelerated Access Review", "text": "Accelerated Access Review\n\nThe Accelerated Access Review was an initiative commissioned by the government of the United Kingdom, working with the Department of Health. The Accelerated Access Review aimed to speed up access to innovative drugs, devices and diagnostics for NHS patients. The Accelerated Access Review was commissioned by the government in November 2014, and produced its final report in October 2016.\n\n"}
{"id": "5111982", "url": "https://en.wikipedia.org/wiki?curid=5111982", "title": "Agricultural chemistry", "text": "Agricultural chemistry\n\nAgricultural chemistry is the study of both chemistry and biochemistry which are important in agricultural production, the processing of raw products into foods and beverages, and in environmental monitoring and remediation. These studies emphasize the relationships between plants, animals and bacteria and their environment.\nThe science of chemical compositions and changes involved in the production, protection, and use of crops and livestock. As a basic science, it embraces, in addition to test-tube chemistry, all the life processes through which humans obtain food and fiber for themselves and feed for their animals. As an applied science or technology, it is directed toward control of those processes to increase yields, improve quality, and reduce costs. One important branch of it, chemurgy, is concerned chiefly with utilization of agricultural products as chemical raw materials. Etc.\n\nThe goals of agricultural chemistry are to expand understanding of the causes and effects of biochemical reactions related to plant and animal growth, to reveal opportunities for controlling those reactions, and to develop chemical products that will provide the desired assistance or control. Every scientific discipline that contributes to agricultural progress depends in some way on chemistry. Hence agricultural chemistry is not a distinct discipline, but a common thread that ties together genetics, physiology, microbiology, entomology, and numerous other sciences that impinge on agriculture.\n\nChemical materials developed to assist in the production of food, feed, and fiber include scores of herbicides, insecticides, fungicides, and other pesticides, plant growth regulators, fertilizers, and animal feed supplements. Chief among these groups from the commercial point of view are manufactured fertilizers, synthetic pesticides (including herbicides), and supplements for feeds. The latter include both nutritional supplements (for example, mineral nutrients) and medicinal compounds for the prevention or control of disease.\n\nAgricultural chemistry often aims at preserving or increasing the fertility of soil, maintaining or improving the agricultural yield, and improving the quality of the crop.\n\nWhen agriculture is considered with ecology, the sustainablility of an operation is considered. Modern agrochemical industry has gained a reputation for maximising profits while violating sustainable and ecologically viable agricultural principles. Eutrophication, the prevalence of genetically modified crops and the increasing concentration of chemicals in the food chain (e.g. persistent organic pollutants) are only a few consequences of naive industrial agriculture.\n\n\n"}
{"id": "44190098", "url": "https://en.wikipedia.org/wiki?curid=44190098", "title": "Bagolini Striated Glasses Test", "text": "Bagolini Striated Glasses Test\n\nBagolini striated glasses test, or BSGT, is a subjective clinical test to detect the presence or extent of binocular functions and is generally performed by an Optometrist(O.D) or orthoptist or ophthalmologist (medical/surgical eye doctor, M.D. or D.O.). It is mainly used in strabismus clinics. Through this test, suppression, microtropia, diplopia and manifest deviations can be noted. However this test should always be used in conjunction with other clinical tests, such as Worth 4 dot test, Cover test, Prism cover test and Maddox rod to come to a diagnosis.\n\nTo perform the test you will need\n\nAlternatively, trial frames and lenses or a lorgnette can be used. \nIn some cases, the use of prisms is necessary to measure a deviation and test for the presence of binocular functions.\n\nBagolini striated glasses are glasses of no dioptric power that have many narrow striations running parallel in one meridian. These glasses cause the fixation light to appear as an elongated streak perpendicular to the striations. The lenses are usually placed at 135 degrees in front of the one eye and at 45 degrees in front of the other. Each eye receives a similar, fusible image, with the exception of the line, allowing simultaneous perception to be observed. With both eyes, the patient should see a cross. This test is minimally dissociative for the assessment of retinal correspondence.\n\nApart from testing binocular functions, Bagolini striated glasses can measure cyclotropia . The principle of the test is similar to that of double Maddox rod test. The glasses are placed in the trial frames with the striations vertical, giving rise to two horizontal line images when viewing a spotlight. If the patient has a vertical deviation, the lines will be seen one above the other. If there is little or no vertical separation, vertical prism can be used to separate the lines. The patient is asked if one or both lines are tilted. The lines can be straightened subjectively by rotating the glasses in the trial frame and the degree of cyclotropia recorded.\n\nThe BSGT is used for patients with strabismus to test for suppression, normal retinal correspondence or abnormal retinal correspondence, particularly in cases of manifest strabismus.\nThe Bagolini Striated Glasses Test is the test most likely to allow the demonstration of fusion in patients who fuse intermittently. Harmonious anomalous retinal correspondence is found more frequently when using Bagolini Striated Glasses Test than with the Worth 4 dot test or the synoptophore.\n\nThe BSGT is performed under normal lighting conditions. The Bagolini glasses can either be used in trial frames or are set up in reversible lorgnette frames which are placed over the patients glasses who wear refractive correction. The examiner shines a torch light, directing it towards the centre bridge of the Bagolini glasses i.e. the patients nose (light is at patients eye level) from distance (6 m) or near (33 cm). The patient can also be tested in alternate positions of gaze (upgaze or downgaze). The test is usually performed at near.\n\nThe number and type of questions asked are contingent on whether the patient has binocularity present and the consequent responses to the testing questions. The patient is firstly asked about the number of lights visible and the position and number of lines seen.\n\nThe patient is asked to describe or draw what they have seen \nWhen asking the patient to describe what they see, the clinician can prompt them by asking:\n\n\nResults are recorded by drawing the cross as the patient sees it, alongside an interpretation of the results.\n\nFor example:\n\nWhen interpreting results, the line associated with each eye is the line perpendicular to the lens in front of that eye. If the lens in front of the right eye is at 135 degrees, then the line on the results representing the right eye will be at 45 degrees.\n\nOne light: If the patient sees one light, that means that either they have fused the two images from each eye together, or are suppressing of one of the images.\n\nTwo lights: If the patient sees two lights, this is indicative of diplopia as the patient has an image from each eye but is unable to fuse the two.\n\nOne line: If only one line is seen, this means one eye is suppressing. The eye that is suppressing is the eye which the corresponding line is not seen.\n\nTwo lines: If the patient sees two lines, this means that there is no suppression of either eye.\n\nDisappearing line: The patient may report that they see one line, then the lines switch and they can only see the other line. This is the case in an alternating deviation, where there is always one eye suppressing, however the fixing eye is switching.\n\nBroken line: If a line has a break in it, this means that there is a scotoma somewhere on the retina.\n\nIn a patient with normal binocular functions, the expected results would be a cross with the light where the two lines intersect.\n\nIn a patient with microtropia, the patient may see one light and two lines, with one of the lines having a small break in it. This is due to foveal suppression.\n\nIn a patient with an unsuppressed esotropia, the patient will see two lights with one line through each light. The line corresponding to the right eye will be on the right side, meaning the images are uncrossed.\n\nIn a patient with an unsuppressed exotropia, the patient will see two lights with one line through each light. The line corresponding to the right eye will be on the left side of the results, meaning the images are crossed.\n\nIn a patient with an unsuppressed vertical deviation, one line will appear higher than the other. If the image of the right eye is higher than that of the left, this means the right eye is lower than the left. This could be either a right hypotropia or a left hypertropia.\n\nIf the patient has a known deviation, but they report a cross as seen in a patient with normal binocular functions, this indicates the presence of harmonious abnormal retinal correspondence.\n\nIf the patient reports that they see two lines, however only one of these lines crosses through the fixation light, this indicates the presence of inharmonious abnormal retinal correspondence.\n\nThis test merely detects the presence of a deviation, but does not identify which eye is the deviated eye.\n\nAdvantages\n\nDisadvantages\n\n"}
{"id": "29324283", "url": "https://en.wikipedia.org/wiki?curid=29324283", "title": "Banana wine", "text": "Banana wine\n\nBanana wine is a fruit wine made exclusively from bananas.\n\nIt is different from banana beer, which has a long tradition and great cultural significance in East Africa. Blocker et al. (2001) wrote a chapter on \"Banana Wine\" in the book \"Alcohol and temperance in modern history: an international encyclopedia\", though this is slightly confusing, as they define what is traditionally referred to as banana beer as being banana wine. The data they present on \"Production Techniques\" and \"Social Practices and Rituals\" relates to the latter and not to what is commonly known as banana wine.\n\nIn Tanzania, banana wine is made commercially by fermenting peeled, mashed, ripe bananas. Water (to dilute the rather thick banana mash), wine yeast and sugar is added to the \"banana mash\".\n\nThe traditional banana beer processing (as described in the banana beer page and in Blocker et al. (2001)) is different from commercial banana wine processing. For example, the process of making banana wine used by Banana Investment Ltd. is as follows:\n\n\nIn commercial production, ‘Cavendish’ bananas are used, while in informal production, a variety of cultivars, including both cooking and beer East African Highland bananas, ‘Pisang awak’, ‘Gros Michel’ and Apple bananas are used. Commercially produced banana wine is a clear, slightly sparkling alcoholic beverage with a longer shelf-life than banana beer, which is spoiled easily and therefore not stored for long periods. Depending on the strain of yeast and amount of sugar added, the sweetness and alcohol level in the final product is variable.\n\nProduction of banana wine is mostly at a small-scale level, though attempts have been made to bring it up to industrialized production, and there are commercial producers of banana wine (i.e. Arusha-based Banana Investment Ltd).\n\nSince the early 2000s, attempts have been made to expand banana wine production to other countries where the crop is prevalent. The Philippines government has sought to expand a local banana wine industry, while India has produced both award-winning banana wines and research into expanding production.\n\n"}
{"id": "13853951", "url": "https://en.wikipedia.org/wiki?curid=13853951", "title": "BioWatch", "text": "BioWatch\n\nBioWatch is a United States federal government program to detect the release of pathogens into the air as part of a terrorist attack on major American cities. Reportedly operating in Philadelphia, New York City, Washington, DC, San Diego, Boston, Chicago, San Francisco, Atlanta, St. Louis, Houston, Los Angeles and 21 other cities, the BioWatch program was created in 2001 in response to the increased threat of bioterrorism sparked by the 2001 anthrax attacks, and was announced in President George W. Bush's State of the Union Address of 2003.\n\nThe program, described as \"the nation's first early warning network of sensors to detect biological attack\" operates via a system of filters located within existing Environmental Protection Agency air filters that monitor air quality. Results from these filters are analyzed by the Centers for Disease Control and Prevention, who pass any significant results to the Federal Bureau of Investigation.\n\nAs of mid-2012, the system had generated a large number of false alarms, with more than 50 such cases documented between 2003 and 2008. State and local health officials have never ordered evacuations or distributed emergency medicines in response to a positive reading from the system.\n\nThe 2001 anthrax attacks in the United States, also known as Amerithrax from its FBI case name, occurred over the course of several weeks beginning on September 18, 2001. Letters containing anthrax spores were mailed to several news media offices and two Democratic U.S. Senators, killing five people and infecting 17 others. As a response, the US increased countermeasure research funding and funding into the public health sector. Before the BioWatch program, the quickest method of detecting the presence of an infectious material was through the diagnosis of infected patients, however the most effective treatment takes place prior to infection or in its early stages. While the Central Intelligence Agency maintains that the use of bioterrorism in the United States is unlikely, the Biowatch program was created in 2001 in conjunction with the FBI, EPA, United States Department of Homeland Security and the US Laboratory Response Network for Bioterrorism, and was tested by the Centers for Disease Control and Prevention and Association of Public Health Laboratories. According to the DHS, the BioWatch program helps to provide \"early warning of a mass pathogen release.\" The original 31 city program cost $60 million to implement, with a proposed expansion in 2005 to cost $118 million.\n\nTo remedy this, another program was created in 2003 that was meant to shorten the detection time to 6 hours and that could detect more than the six pathogens. After 11 years and $200 million spent on testing and development, however, the program was cancelled in 2014 because the new devices could not be made to work. For now, the 36-hour detection program continues, with maintenance costs of $80 million per year. The undersecretary for the science and technology at the Department of Homeland Security stated to Congress in February 2016 that his team was in an \"exploratory process\" phase for addressing the program's shortcomings, and that a solution was hoped for in 3–8 years.\n\n\nThe BioWatch system has received a mix of responses since coming online, many that result in waste of resources and a lowering public confidence in the system. A Congressional report in 2003 recorded that there was concern that the BioWatch filters would fail to detect indoor or underground releases, and also that the existence of BioWatch filters in some cities would direct terrorists to attack other cities without such protection. The report also highlighted the risk of the filters themselves being detected and destroyed. The report also states that, as EPA filters are located based on different policies than what would provide optimum locations for counter-bioterrorism sensors, the BioWatch filters may not be optimally located. Furthermore, the BioWatch system may miss releases that take place within the gaps in coverage. The House of Representatives also concluded that models used to predict the spread of an infectious agent after release and detection may be inaccurate.\n\nThe Congressional Report also raises concerns as to whether BioWatch can detect pathogens in large, polluted cities, as well as issues relating to the BioWatch filter reporting harmful pathogens that are actually within safe background levels, and thus would throw up more positive hits than actual investigation warrants. There are also concerns that the BioWatch filters kill whatever pathogen has set them off, thus removing the possibility of further tests being undertaken. Finally, concerns were raised in the Congressional Report regarding the sensitivity of the filters, and the fact that each filter would be exposed to different environmental conditions and thus a standardized detection rate would be near impossible to achieve. The complicated response that would be required should the BioWatch filter detect a pathogen would also be difficult to implement and put strain on local health authorities. Funding, policy and evaluation of effectiveness were all other areas of concern\n\nIn June 2013, Mike Walter, the manager of the Office of Health Affairs BioWatch Program, made a few remarks during his testimony to the House Committee on Energy and Commerce's Subcommittee on Oversight and Investigations. Walter said the benefits of the BioWatch Program give public health decision makers more time and more options to mitigate a bioterrorist event. He said that early detection is critical to the successful treatment of affected populations and provides public health decision makers more time – and thereby more options – in responding to, mitigating, and recovering from a bioterrorist event. If a bioagent is detected and assessed to be the result of an act of bioterrorism and/or a threat to public health, prophylactic treatment can be started prior to the widespread onset of symptoms resulting in more lives saved. He also talked about the federal, state and local partnership, tools for preparedness and is developing robust quality assurance, as well as assessing new technologies to shorten decision time in relation to bioagent detection.\n\n"}
{"id": "56062749", "url": "https://en.wikipedia.org/wiki?curid=56062749", "title": "Cannabis in Azerbaijan", "text": "Cannabis in Azerbaijan\n\nCannabis in Azerbaijan is illegal but is cultivated illicitly, and has a long history as a medical remedy in the nation.\n\nAcademic Farid Alakbarov has written on cannabis medicines found in medieval Azerbaijani texts, including treatments for uterine tumors, hemorrhoids, and hysteria.\n\nPer a 2011 report, cannabis is cultivated, mostly in southern Azerbaijan, \"to a modest extent\".\n"}
{"id": "47308680", "url": "https://en.wikipedia.org/wiki?curid=47308680", "title": "Cannabis in Palau", "text": "Cannabis in Palau\n\nCannabis in Palau is illegal, but reports indicate the drug is widely produced and consumed on the island nation. Palau is a former Trust Territory of the Pacific Islands of the United States which gained independence in 1994, and has a population under 20,000. \n\nReports by the World Health Organization and UNODC have been called into question for the accuracy of their claims that Palau has the highest cannabis usage rates in the world. Despite controversy over the numbers, usage appears high, and a 2005 academic paper states the Palau police ignore public consumption.\n\nA 2011 WHO report, as well as the 2012 UN World Drug Report stated that Palau has the world's highest adult cannabis consumption rate, at 24.2% annually. However, critics have questioned these results, noting that the numbers were based on a survey conducted at the island's only public highschool, which had then been extrapolated to the entire nation. However, academics have noted that while the numbers may not be reliable, Palau does have prevalent cannabis use.\n\nA 1989 American congressional hearing noted that Palau was exporting some 300 pounds of cannabis per week.\n\nAn International Monetary Fund report noted that Palauan marijuana farmers produced for local consumption, and also exported cannabis to Guam and the Federated States of Micronesia.\n\nBy the 1980s, cannabis had become the most valuable export crop of Palau.\n\nIn the early 1980s, a joint US effort removed 3,347 cannabis plants, which had been used to produce \"sinsemilla\", from the island of Peleliu.\n\nIn 2006, a law requiring that all elected officials be tested for illicit drugs was passed by the Senate of Palau.\n"}
{"id": "818329", "url": "https://en.wikipedia.org/wiki?curid=818329", "title": "Co-counselling", "text": "Co-counselling\n\nCo-counselling (spelled co-counseling in American English) is a grassroots method of personal change based on reciprocal peer counselling. It uses simple methods. Time is shared equally and the essential requirement of the person taking their turn in the role of counsellor is to do their best to listen and give their full attention to the other person. It is not a discussion; the aim is to support the person in the client role to work through their own issues in a mainly self-directed way.\n\nCo-counselling was originally formulated in the early 1950s by the American Harvey Jackins and originated in a schism in the Dianetics movement (itself in part derived from schisms in General Semantics and Cybernetics). Jackins founded the Re-evaluation Counseling (RC) Communities, with headquarters in Seattle, Washington, United States. His son, Tim Jackins, is currently the international leader of Re-evaluation Counseling and its main affiliates.\n\nThere are a number of smaller, separate, independent organizations that have resulted from breakaways from, or re-workings of, Re-evaluation Counseling. The principal one of these is Co-Counseling International (CCI).\n\nThe main activity in co-counselling involves participants arranging to meet regularly in pairs to give each other peer-to-peer counselling, in turn taking the role of counsellor and client, with equal amounts of time allocated to each. Co-counselling functions by giving people an opportunity to work on whatever issues they choose with the accepting support of another person, with whom they have no actual relationship. The person in the role of counsellor acts as a facilitator to the client, sometimes as a third-party observer and sometimes as a second-party confidant. While co-counselling is sometimes practiced outside a formal organisation, formal co-counselling organisations have developed leadership and support structures, including trainings and retreats.\n\nSafety (in the sense of being very low risk) and the sense that a co-counselling session is a safe space is important to the methods. There are strict rules of confidentiality. In most circumstances, the counsellor may not talk about a client's session without explicit and specific permission by the client. This is stricter than in other practices where practitioners discuss clients with supervisors, colleagues and sometimes with all sorts of other people. The peer relationship makes a considerable contribution to a sense of trust.\n\nThe nature of the co-counselling session opens up the possibility for people to get in touch with emotions that they would avoid in any other circumstance. A belief in the value of working with emotions has become a core focus of the approach. Co-counselling training emphasizes methods for accessing and working with emotions, and co-counsellors aim to develop and improve emotional competence through the practice. Evidence as to the actual effectiveness of this method is undemonstrated.\n\nTo get involved in co-counselling, it is usually first necessary to complete a Fundamentals course. The training involves learning how to carry out the roles of client and counsellor. Trainers may be counsellors or simply experienced members of the community. It also covers the guidelines or rules affecting co-counselling for the particular organization. Differences in approach mean that each organization normally requires completion of one of its own courses as a prerequisite for membership, even if someone has already completed a course with another organization.\n\nThe original theory of co-counselling centres on the concept of distress patterns. These are patterns of behaviour, that is, behaviour that tends to be repeated in a particular type of circumstance, that are irrational, unhelpful or compulsive. The theory is that these patterns are driven by the accumulated consequences in the mind of (not currently) conscious memories of past events in which the person was unable to express or discharge the emotion appropriate to the event. Co-counselling enables release from the patterns by allowing \"emotional discharge\" of the past hurt experiences. Such cathartic discharge includes crying, warm perspiration, trembling, yawning, laughing and relaxed, non-repetitive talking. In day-to-day life, these \"discharging\" actions may be limited by social norms, such as, for example, taboos around crying, which are widespread in many cultures.\n\nHaving temporary, undivided, supportive attention from another person often gives rise to strong feelings towards that person; your counsellor often becomes your best friend for life. Sometimes people \"fall in love\" with each other. This is similar to the phenomenon of transference, particularly when one of the partners is felt to have more authority because, for instance, they are more experienced, are teachers of co-counselling, or have authority roles within the organisation. The organisations differ in the ways that they handle this. The inability to trust and feel in real relationships is sometimes exacerbated by the intimacy of co-counselling relationship, making transference a possibility. But participants are strongly encouraged and supported to counsel through these feelings, often leading to profound changes in their perspectives and abilities around closeness. For the most part, co-counselling relationships become life-long, therapeutic partnerships that enable the participant to have healthier relationships in general.\n\nMany co-counsellors take the view, often quite strongly, that co-counselling is not psychotherapy. In the beginning, this was because Re-evaluation Counseling decided not to draw on any discipline of psychotherapy for its theory and practice, although RC did incorporate some ideas from psycho-analysis such as \"unconscious promptings\" which Jackins adapted and relabeled \"restimulation\". A similar view is taken by some non-RC co-counsellors who regard psychotherapy as involving specialist techniques used by a therapist on a client and is therefore not peer and the client has little or no control over the process.\n\nOthers consider that co-counselling is psychotherapeutic, in that it enables change or therapy to take place in the psyche, soul affect or being of an individual. Co-counselling takes a positive view of the person (i.e. we are all essentially good), considers the mind and body as an integrated whole and acknowledges the value of catharsis; it is regarded as an approach within humanistic psychology, a view that would be rejected by some within RC. \n\nThe core organization structure of RC consists of classes and local communities set up by experienced co-counsellors, which are in turn organized by regions and country.\n\nThe term \"re-evaluation\" refers to the client's need to rethink their past distress experiences after the emotional hurt in those experiences have been discharged, and thereby regain (\"re-emerge\" with) their natural intellectual and emotional capacities. The RC organization and literature do not accept the description of its practice as psychotherapy, maintaining instead that the process of developing distress patterns that dissolve through emotional discharge in the context of appreciative attention is simply a natural process that does not imply either psychopathology on the part of the individual or the need for professional treatment. Re-evaluation Counseling regards other forms of \"mainstream counselling\" and psychotherapy in general as frequently inadequate attempts to bring about relief from distress using methods that do not focus on discharge and re-emergence.\n\nIn RC, the client and counsellor are expected to work co-operatively, participants are expected to provide non-judgmental active listening and to \"contradict\" the misinformation or other conditions thought to be associated with distress patterns. RC also engages techniques such as \"non-permissive\" counselling, in which the counsellor intervenes to \"interrupt\" client patterns without the consent of the client. The structure of RC is one of clearly defined leadership, to encourage clarity in the difficult struggles many people have to achieve breakthroughs against their distresses. RC encourages counsellors to think very hard about all possible ways to assist the client in discharging.\n\nRC approaches the issue of feelings between co-counsellors by having a strict \"no-socialising\" rule. RC co-counsellors are expected not to socialise or have social or sexual relationships with other co-counsellors unless these relationships pre-dated their becoming co-counsellors. RC specifically rejects the label \"transference\" for this phenomenon, as this is seen as part of a \"symptomatic\" method typical in psychology; the original theory of co-counselling (from RC) teaches that the best thing to do in these circumstances is repeatedly counsel on, and \"discharge\" about, such feelings. In addition, methods of \"getting attention out of distress\" are available which help with the difficulty of \"switching roles\" between counsellor and client. When taught correctly, counsellors are soon able to grasp the difference between counselling relationships and those from outside life. However, sometimes there is a marked pull to \"socialise\" or confuse the boundaries of the co-counselling relationship with other types of relationships. This is one reason why many consider a well-organised community of co-counsellors with clear rules to be essential in the successful practise of co-counselling.\n\nRe-evaluation Counseling places a high importance on the need to understand and adhere to a comprehensive theory about the nature of the universe and of human beings (known in general as the \"Benign Reality\"), the best ways of assisting the discharge process and of pro-liberation attitudes in co-counselling. RCers believe that, when taken together, these enable the counsellor to keep a clear picture of the client's \"re-emergence\" and are therefore very effective. People disagreeing with the theoretical perspective are asked to think and discharge on the points at issue before actively challenging such perspectives. The main aim is to provide a safe, stable and supportive atmosphere within which people can client skillfully and also lead \"re-emergent lives\" where they are not dependent in a therapeutic sense, but instead become more energetic and effective (a state known as \"zestfulness\" in RC).\n\nCo-Counselling International (CCI) was started in 1974 as a breakaway from Re-evaluation Counseling by John Heron, who was at the time director of the Human Potential Research Project, University of Surrey UK, and Tom Sargent and Dency Sargent from Hartford, Connecticut, United States. Unlike other breakaways from RC, which involved changes of leadership but otherwise continued to practice in similar ways to RC, the CCI break was ideological, and CCI developed in significantly different ways. The differences are in practice, theory and organisation.\n\nIn practice, the client in CCI co-counselling is wholly in charge of the session. In other words, client and counsellor do not work co-operatively. The counsellor only intervenes in accordance with one of three levels of \"contract\"—free attention, normal and intensive—which are defined in CCI's principles. The only requirement of the counsellor is that they give \"free attention\" (that is, full supportive attention) to the client. The other two contracts constitute invitations to the counsellor to make interventions from within those permitted if they feel it is appropriate. The intensive contract can be similar to the RC way of working, although the counsellor is still not permitted to intervene as flexibly as in RC.\n\nThe original theory of co-counselling is taught in the CCI fundamentals training courses, and participants learn techniques for releasing, or \"discharging\", emotions. However, the theory is not seen as a constraint within CCI, and co-counsellors draw on the whole range of psychotherapeutic theory and methods including analytical, cognitive-behavioural and transpersonal as well as humanistic approaches. The principal constraint is that the client must be able to work self-directedly.\n\nOrganisationally, CCI is a peer network with no core structure. Local and national networks have a variety of organisation. Classes and activities are organised by individuals or groups acting self-directedly. John Heron's status within the network has always been as an equal member, although inevitably as a founder member and activist for some 15 years and the person who developed much of the thinking behind CCI, there was a certain amount of transference on him. Heron now lives in New Zealand and is involved with the CCI network there.\n\nCCI approaches the issue of personal relationships between co-counsellors as a matter for raising awareness. CCI co-counsellors may and do have the whole range of personal relationships with other co-counsellors. However, new co-counsellors are encouraged not to develop new non-co-counselling relationships with other co-counsellors until they have more experience and experienced co-counsellors will often have people with whom they only have a co-counselling relationship. Teachers of co-counselling are strongly discouraged from having sexual relationships with people they have taught.\n\nThe existence of other co-counselling organisations is generally not mentioned in RC, and RC co-counsellors are often not aware of their existence.\n\nAmongst those within RC who know about it, CCI is often seen as an \"attack organisation\" and was specifically condemned as such in many private and public conversations by Jackins, who claimed that Heron had started it against a specific agreement not to, and in breach of RC guidelines he had previously agreed to. In turn, Heron and many of his supporters claimed that RC was authoritarian and cult-like, and later, that Jackins engaged in sexual abuse of clients. RC supporters parried that CCI fostered a sexually-liberal atmosphere that blurred the boundaries of co-counselling and relationships. \n\nThe history of co-counselling including its origins with RC is normally taught on CCI Fundamentals courses. CCI, by its nature, has no corporate opinion about RC, and individual CCI co-counsellors have their own views. Most CCI co-counsellors have a benevolent view toward RC, regarding it as a different, alternative approach to co-counselling. Membership of RC is not a bar to membership of CCI, and a few people manage to do both despite the RC ban.\n\n\n\n\n"}
{"id": "1245460", "url": "https://en.wikipedia.org/wiki?curid=1245460", "title": "Composite Health Care System", "text": "Composite Health Care System\n\nThe Composite Health Care System (CHCS) is a medical informatics system designed by Science Applications International Corporation (SAIC) and used by all United States and OCONUS military health care centers. In 1988, SAIC won a competition for the original $1.02 billion contract to design, develop, and implement CHCS.\n\nCHCS is module based: modules include RAD (radiology), LAB (Laboratory), PHR (Pharmacy), PAS (Patient Appointing & Scheduling), MCP (Managed Care Program; used to support TRICARE enrollees by enrolling them to Primary Care Managers), PAD (Patient Administration): MRT (Medical Records Tracking), MSA (Medical Service Accounting) medical billing, WAM (Workload Assignment Module), DTS (Dietetics), CLN (CLinical: Nursing, Physician, and Allied Health), DAA (Database Administration), ADM (Ambulatory Data Module) Medical Coding of outpatient visits, and TOOLS (FileMan). \n\nCurrently all appointments are booked in CHCS, except for Walk-Ins and Telephone Consults, which can now be booked in AHLTA. CHCS is a text based BBS/ANSI like display accessed via DEC VT320 terminal emulation. CHCS supports outpatient Order Entry (LAB, RAD, PHR, Consults (ancillary procedures), one-time and scheduled/multiple appointment consults. CHCS can also support Inpatient charting and Order Entry with multi-paging with a page for each ward the patient is transferred, but this feature is not fielded/enabled at many medical centers. Instead Clinicomp's Essentris product is deployed at all MHS hospitals and has replaced the use of CHCS Inpatient module for nurse charting. An interface solution to allow Essentris Orders to be transferred into CHCS order entry is being deployed.\n\nArmed Forces Health Longitudinal Technology Application (commonly referred to as AHLTA) is the clinical documentation engine for the Physicians to write their notes, put in orders, document procedures performed and provide the basis of medical coding information. This information is then sent into CHCS and its subsystems (ADM - ambulatory data module) provide the official repository of the medical coding information and handle the transmission of those encounters via the Comprehensive Ambulatory Patient Encounter Record (CAPER) interface. The clinical data is brought into the M2 DataMart for use in research, operational metrics, trend analysis, and many other business intelligence processes/products. AHLTA information is also contained in a Central Data Repository (CDR). This CDR contains information from AHLTA, CHCS, and AHLTA-Theater. The AHLTA CDR is a comprehensive full scale world-wide EHR repository.\n\nCHCS shares its original codebase with the VA's VistA system. Since its inception it has been customized for supporting the Military and their family members.\n\nSecurity in CHCS works by a number of mechanisms and includes the concept of least privilege. You are assigned the minimum needed for your work duties. This limits your access to sensitive data both protected by the Privacy Act 1974 and PHI protected under HIPAA. \n\nAdHoc reports can be written using the FileMan tools and can be quite powerful if the files are designed with that in mind. Many CHCS files are now more easily accessed with MUMPS routinues that can make more efficient use of the internal data structures. More information about FileMan can be found at www.hardhats.org. CHCS, which now runs on InterSystems Caché with the MUMPS globals being converted into Caché objects and the MUMPS routines accessing them, now can be accessed with .NET tools to query the Caché database. Many facilities have developed special queries of CHCS or new tools to facilitate workflow and processes. One such tool is an intranet web application to facilitate printing of lab specimen labels to special printers with formats not possible with the regular CHCS print devices and label printing methods.\n\nCITPO (now known as Defense Health Information Management Systems (DHIMS)) began the implementation of AHLTA, the DoD's Electronic Health Record(EHR) system, in January 2004. The system links the 481 Military Treatment Facilities (MTF) worldwide as well as service members deployed abroad to the EHR, ultimately supporting 9.2 million MHS beneficiaries. The introduction of AHLTA, previously known as the Composite Health Care System II, ushered in a significant new era in health care for the MHS and the nation. AHLTA Version 3.3.3.X with client update 9.1 currently fielded to physician and clinic staff workstations. DHIMS also manages the AHLTA-Theater program that provides EHR capabilities to deployed users with important store and forward capabilities when communications are unavailable.\n\nAHLTA and a significant portion of CHCS are slated to be replaced by a VA/DoD interagency iEHR program. The iEHR will bring together the strong Health IT resources of both the VA and the DoD to acquire the next generation EHR capabilities for both departments.\n\nAs with all large hospital information systems, there are occasions that despite training and best intentions, duplicate patient records are created. CHCS has a function to merge patients, but not to unmerge. AHLTA also has merges performed on patients in its Oracle database and successful attempts are made to un-merge patients and their associated medical/encounter data where diligent research has determined that mistakes were made with the identification of patients and to split off encounter records from patients that are blended into the single AHLTA record. Master Patient Indexing is a feature of the AHLTA Clinical Data Repository (CDR). Over 100 CHCS host systems, DEERS (Defense Enrollment Eligibility Reporting System), and AHLTA Theater (the version being used in Iraq and other areas) all contributed patients into the CDR when it was created from 25 month data pulls back in 2004. Each CHCS patient registration links into AHLTA, some link to existing patients, but others are newly created. Complexity with patient names and methods of identifying them with other demographics can lead to duplication, both in a local CHCS system and in the central AHLTA CDR. There is currently a DHIMS contract working on improving the processes and automating the routines to resolve duplicate patients and prevent their creation in future.\n"}
{"id": "26322806", "url": "https://en.wikipedia.org/wiki?curid=26322806", "title": "Continuous adsorption-regeneration", "text": "Continuous adsorption-regeneration\n\nElectrochemical regeneration of activated carbon adsorbents such as granular activated carbon present an alternative to thermal regeneration or land filling at the end of useful adsorbent life. Continuous adsorption-electrochemical regeneration encompasses the adsorption and regeneration steps, typically separated in the bulk of industrial processes due to long adsorption equilibrium times (ranging from hours to months), into one continuous system. This is possible using a non-porous, electrically conducting carbon derivative called Nyex. The non-porosity of Nyex allows it to achieve its full adsorptive capacity within a few minutes and its electrical conductivity allows it to form part of the electrode in an electrochemical cell. As a result of its properties Nyex can undergo quick adsorption and fast electrochemical regeneration in a combined adsorption-electrochemical regeneration cell achieving 100% regeneration efficiency.\n\nThe adsorption regeneration process is divided into three key elements which occur in different parts of the cell. All three occur continuously and simultaneously, with parameters such as charge passed, rate of effluent in/outflow and air inlet rate varied according to pollutant type and concentration.\n\nPolluted effluent is added into the bottom of the cell and mixed with the adsorbent in the adsorption zone 1.1 where adsorption of the pollutants onto the surface of the adsorbent occurs. Mixing between the adsorbent and the polluted effluent is promoted by air spargers at the base of the cell which also facilitate the migration of the adsorbent upwards and into the cell's sedimentation zone.\n\nThe adsorbent is separated from the now treated effluent in the sedimentation zone where the density of the adsorbent allows separation by gravitational sedimentation. The treated effluent is allowed to overflow out of the cell.\n\nThe adsorbent, loaded with adsorbed pollutant on its surface sediments and forms a bed in the regeneration zone in the cell. The mass of the Nyex causes the bed to travel down the regeneration column slowly and eventually pass back into the cell. During the journey down the regeneration column, a DC current is passed across the electrochemical cell of which the adsorbent forms the anode. The applied current causes the pollutants adsorbed on the surface of the Nyex to be electrochemically oxidised regenerating the adsorbent surface restoring its full adsorptive capacity completing the adsorption-regeneration cycle.\n\nThis technology is currently being incorporated into a variety of industries for applications in effluent treatment areas such as:\n"}
{"id": "21625730", "url": "https://en.wikipedia.org/wiki?curid=21625730", "title": "Delayed pressure urticaria", "text": "Delayed pressure urticaria\n\nDelayed pressure urticaria is known as one of the more painful subsets of physical urticaria due to formed hives being deep-seated and appearing after 4–6 hours.\n\nDue to the delayed appearance of wheals, plausible causes are hard to establish; the natural course and/or clinical pattern is variable and inconclusive.\n\nIt was noted that although antihistamines and anti-inflammatory drugs such as, colchicine, sulphasalazine, dapsone, and topical steroid are advocated for in the treatment of DPU, most if not all are unsatisfactory in relieving symptoms. Even a second generation antihistamine, ketotifen, was unable to efficiently and satisfactorily relieve symptoms of DPU\n"}
{"id": "15063531", "url": "https://en.wikipedia.org/wiki?curid=15063531", "title": "Dyson Airblade", "text": "Dyson Airblade\n\nThe Dyson Airblade is an electric hand dryer made by the Wiltshire, UK based company Dyson, found in public bathrooms across the United Kingdom. It was introduced in the UK in 2006 and in the United States in the latter part of 2007.\n\nInstead of using a wide jet of heated air, Dyson Airblade uses a thin layer of unheated air travelling at around as a squeegee to remove water, rather than using heat to evaporate the water. The Dyson Airblade is claimed by its manufacturer to dry hands in 10 seconds and to use less electricity than conventional hand dryers.\n\nThe first commercially available high-speed, horizontal-wiping air dryer was the Mitsubishi Jet Towel, invented in 1993 and available in the United States since 2005. There are several technical differences among electric hand dryers, such as airspeed, water containment, energy efficiency, use of heat, type of filter, motor lifespan and power usage.\n\nThe same technology is used by Dyson in the Air Multiplier fan to create a cooling air stream for personal comfort.\n\nThe Dyson Airblade is 69% more energy-efficient than conventional hand-dryers and 97% more cost effective than paper towels. The Airblade is cheaper to operate because it does not require hot air which greatly increases electricity consumption. The Airblade is also cheaper to operate due to decreased drying times. The Airblade V can dry off hands in 12 seconds, versus 25 for a traditional hand dryer.\n\nA comparative test found that both paper towels and the Airblade dried hands quickly, achieving around 90% dryness in about ten seconds, supporting Dyson's claim of approximately ten seconds of drying time. A conventional warm air dryer took about forty-seven seconds.\n\nIn the United States, Dyson worked with the NSF to become the only certified hand dryer under Protocol P335 for Hygienic Commercial Hand Dryers. The Royal Society of Public Health has given the Dyson Airblade hand dryer its first hygiene accreditation.\n\nA paper was presented at the 17th European Congress of Clinical Microbiology and Infectious Diseases, Munich, Germany in 2007 by the University of Bradford and Dyson showing that for a set drying time of 10 seconds, the Airblade led to significantly less bacterial transfer than with the other driers (\"p\" < 0.05). When the latter were used for longer (30–35 s) the trend was for the Airblade to still perform better; however, these results did not reach statistical significance (\"p\" > 0.05). In addition the study showed that rubbing hands whilst using the driers counteracted the reduction in overall bacterial numbers at all anatomical sites.\n\nHygiene associated with the product has been questioned in research by the University of Westminster Trade Group, London and sponsored by the paper towel industry the European Tissue Symposium, which suggests that use increases the amount of bacteria on the fingertips by about 42%; paper towels reduced the number of bacteria by 50 to 75%, while warm air dryers increased bacteria by 194%. The report found that \"the manufacturer’s claim that the tested JAD [Airblade] is 'the most hygienic hand dryer' is confirmed ... assuming that the term 'hand dryer' refers to electric devices only because its performance in terms of the numbers of all types of bacteria remaining on the hands of users compared to paper towels was significantly worse.\"\n\nIn early 2013, three new models of the Dyson Airblade were introduced: the Airblade Mk. 2, the Airblade V, and the Airblade Tap. The Mk. 2 uses a similar design as the original model, but has increased jet air speed from , and new soundproofing makes the new model quieter than the old one. The Airblade V is a hands-under hand dryer that complies with the Americans With Disabilities Act.\n\nThe Airblade Tap is a non-contact bathroom faucet that both washes and dries hands. It eliminates the need to move to a separate area to dry hands, and therefore eliminates any water dripped on the floor. All three hand dryers use a new Digital Slim Motor, the Dyson V4.\n\nOn December 5, 2012, a lawsuit by competitor Excel Dryer was filed against Dyson, claiming that Dyson's advertising comparing the Airblade to the Excel Dryer XLerator were deceptive. Dyson's advertisements stated the XLerator produces twice as much carbon dioxide, is worse for the environment, and costs more to operate than the Airblade. Excel Dryer charged that Dyson was falsifying its comparisons by submitting a 20-second dry time for the XLerator to the Materials Systems Laboratory at the Massachusetts Institute of Technology, rather than Excel Dryer's tested 12-second dry time, thus inflating energy consumption figures in the Airblade's favor.\n\nIn 2014, a paper was published in the \"Journal of Hospital Infection\" (2014;88:199-206), showing that high-speed hand dryers such as the Dyson Airblade can spread large numbers of a harmless test bacteria through the air in the vicinity. The Dyson company challenged the study with its own criticism of the methods and conclusions.\n\n"}
{"id": "199433", "url": "https://en.wikipedia.org/wiki?curid=199433", "title": "Early Warning and Response System", "text": "Early Warning and Response System\n\nThe Early Warning and Response System (EWRS) for communicable diseases in the European Union was created by the European Commission to \"ensure a rapid and effective response by the EU to events (including emergencies) related to communicable diseases.\"\n\n"}
{"id": "17476149", "url": "https://en.wikipedia.org/wiki?curid=17476149", "title": "Emotional self-regulation", "text": "Emotional self-regulation\n\nEmotional self-regulation or emotion regulation is the ability to respond to the ongoing demands of experience with the range of emotions in a manner that is socially tolerable and sufficiently flexible to permit spontaneous reactions as well as the ability to delay spontaneous reactions as needed. It can also be defined as extrinsic and intrinsic processes responsible for monitoring, evaluating, and modifying emotional reactions. Emotional self-regulation belongs to the broader set of emotion-regulation processes, which includes both the regulation of one's own feelings and the regulation of other people's feelings.\n\nEmotional regulation is a complex process that involves initiating, inhibiting, or modulating one's state or behavior in a given situationfor example the subjective experience (feelings), cognitive responses (thoughts), emotion-related physiological responses (for example heart rate or hormonal activity), and emotion-related behavior (bodily actions or expressions). Functionally, emotional regulation can also refer to processes such as the tendency to focus one's attention to a task and the ability to suppress inappropriate behavior under instruction. Emotional regulation is a highly significant function in human life.\n\nEvery day, people are continually exposed to a wide variety of potentially arousing stimuli. Inappropriate, extreme or unchecked emotional reactions to such stimuli could impede functional fit within society; therefore, people must engage in some form of emotion regulation almost all of the time. Generally speaking, emotional dysregulation has been defined as difficulties in controlling the influence of emotional arousal on the organization and quality of thoughts, actions, and interactions. Individuals who are emotionally dysregulated exhibit patterns of responding in which there is a mismatch between their goals, responses, and/or modes of expression, and the demands of the social environment. For example, there is a significant association between emotion dysregulation and symptoms of depression, anxiety, eating pathology, and substance abuse. Higher levels of emotion regulation are likely to be related to both high levels of social competence and the expression of socially appropriate emotions.\n\nThe process model of emotion regulation is based upon the modal model of emotion. The modal model of emotion suggests that the emotion generation process occurs in a particular sequence over time. This sequence occurs as follows:\nBecause an emotional response (4.) can cause changes to a situation (1.), this model involves a feedback loop from (4.) Response to (1.) Situation. This feedback loop suggests that the emotion generation process can occur recursively, is ongoing, and dynamic.\n\nThe process model contends that each of these four points in the emotion generation process can be subjected to regulation. From this conceptualization, the process model posits five different families of emotion regulation that correspond to the regulation of a particular point in the emotion generation process. They occur in the following order:\nThe process model also divides these emotion regulation strategies into two categories: antecedent-focused and response-focused. Antecedent-focused strategies (i.e., situation selection, situation modification, attentional deployment, and cognitive change) occur before an emotional response is fully generated. Response-focused strategies (i.e., response modulation) occur after an emotional response is fully generated.\n\nSituation selection involves choosing to avoid or approach an emotionally relevant situation. If a person selects to avoid or disengage from an emotionally relevant situation, he or she is decreasing the likelihood of experiencing an emotion. Alternatively, if a person selects to approach or engage with an emotionally relevant situation, he or she is increasing the likelihood of experiencing an emotion.\n\nTypical examples of situation selection may be seen interpersonally, such as when a parent removes his or her child from an emotionally unpleasant situation. Use of situation selection may also be seen in psychopathology. For example, avoidance of social situations to regulate emotions is particularly pronounced for those with social anxiety disorder and avoidant personality disorder.\n\nEffective situation selection is not always an easy task. For instance, humans display difficulties predicting their emotional responses to future events. Therefore, they may have trouble making accurate and appropriate decisions about which emotionally relevant situations to approach or to avoid.\n\nSituation modification involves efforts to modify a situation so as to change its emotional impact. Situation modification refers specifically to altering one's external, physical environment. Altering one's \"internal\" environment to regulate emotion is called cognitive change.\n\nExamples of situation modification may include injecting humor into a speech to elicit laughter or extending the physical distance between oneself and another person.\n\nAttentional deployment involves directing one's attention towards or away from an emotional situation.\n\nDistraction, an example of attentional deployment, is an early selection strategy, which involves diverting one's attention away from an emotional stimulus and towards other content. Distraction has been shown to reduce the intensity of painful and emotional experiences, to decrease facial responding and neural activation in the amygdala associated with emotion, as well as to alleviate emotional distress. As opposed to reappraisal, individuals show a relative preference to engage in distraction when facing stimuli of high negative emotional intensity. This is because distraction easily filters out high-intensity emotional content, which would otherwise be relatively difficult to appraise and process.\n\nRumination, an example of attentional deployment, is defined as the passive and repetitive focusing of one's attention on one's symptoms of distress and the causes and consequences of these symptoms. Rumination is generally considered to be a maladaptive emotion regulation strategy, as it tends to exacerbate emotional distress. It has also been implicated in a host of disorders including major depression.\n\nWorry, an example of attentional deployment, involves directing attention to thoughts and images concerned with potentially negative events in the future. By focusing on these events, worrying serves to aid in the downregulation of intense negative emotion and physiological activity. While worry may sometimes involve problem solving, incessant worry is generally considered maladaptive, being a common feature of anxiety disorders, particularly generalized anxiety disorder.\n\nThought suppression, an example of attentional deployment, involves efforts to redirect one's attention from specific thoughts and mental images to other content so as to modify one's emotional state. Although thought suppression may provide temporary relief from undesirable thoughts, it may ironically end up spurring the production of even more unwanted thoughts. This strategy is generally considered maladaptive, being most associated with obsessive-compulsive disorder.\n\nCognitive change involves changing how one appraises a situation so as to alter its emotional meaning.\n\nReappraisal, an example of cognitive change, is a late selection strategy, which involves reinterpreting the meaning of an event so as to alter its emotional impact. For example, this might involve reinterpreting an event by broadening one's perspective to see \"the bigger picture.\" Reappraisal has been shown to effectively reduce physiological, subjective, and neural emotional responding. As opposed to distraction, individuals show a relative preference to engage in reappraisal when facing stimuli of low negative emotional intensity because these stimuli are relatively easy to appraise and process.\n\nReappraisal is generally considered to be an adaptive emotion-regulation strategy. Compared to suppression, which is correlated negatively with many psychological disorders, reappraisal can be associated with better interpersonal outcomes, and can be positively related to wellbeing. However, some researchers argue that context is important when evaluating the adaptiveness of a strategy, suggesting that in some contexts reappraisal may be maladaptive.\n\nDistancing, an example of cognitive change, involves taking on an independent, third-person perspective when evaluating an emotional event. Distancing has been shown to be an adaptive form of self-reflection, facilitating the emotional processing of negatively valenced stimuli, reducing emotional and cardiovascular reactivity to negative stimuli, and increasing problem-solving behavior.\n\nHumor, an example of cognitive change, has been shown to be an effective emotion regulation strategy. Specifically, positive, good-natured humor has been shown to effectively upregulate positive emotion and downregulate negative emotion. On the other hand, negative, mean-spirited humor is less effective in this regard.\n\nResponse modulation involves attempts to directly influence experiential, behavioral, and physiological response systems.\n\nExpressive suppression, an example of response modulation, involves inhibiting emotional expressions. It has been shown to effectively reduce facial expressivity, subjective feelings of positive emotion, heart rate, and sympathetic activation. However, the research is mixed regarding whether this strategy is effective for downregulating negative emotion. Research has also shown that expressive suppression may have negative social consequences, correlating with reduced personal connections and greater difficulties forming relationships.\n\nExpressive suppression is generally considered to be a maladaptive emotion-regulation strategy. Compared to reappraisal, it is correlated positively with many psychological disorders, associated with worse interpersonal outcomes, is negatively related to wellbeing, and requires the mobilization of a relatively substantial amount of cognitive resources. However, some researchers argue that context is important when evaluating the adaptiveness of a strategy, suggesting that in some contexts suppression may be adaptive.\n\nDrug use, an example of response modulation, can be a way to alter emotion-associated physiological responses. For example, alcohol can produce sedative and anxiolytic effects and beta blockers can affect sympathetic activation.\n\nExercise, an example of response modulation, can be used to downregulate the physiological and experiential effects of negative emotions. Regular physical activity has also been shown to reduce emotional distress and improve emotional control.\n\nSleep plays a role in emotion regulation, although stress and worry can also interfere with sleep. Studies have shown that sleep, specifically REM sleep, down-regulates reactivity of the amygdala, a brain structure known to be involved in the processing of emotions, in response to previous emotional experiences. On the flip side, sleep deprivation is associated with greater emotional reactivity or overreaction to negative and stressful stimuli. This is a result of both increased amygdala activity and a disconnect between the amygdala and the prefrontal cortex, which regulates the amygdala through inhibition, together resulting in an overactive emotional brain. Due to the subsequent lack of emotional control, sleep deprivation may be associated with depression, impulsivity, and mood swings. Additionally, there is some evidence that sleep deprivation may reduce emotional reactivity to positive stimuli and events and impair emotion recognition in others.\n\nEmotion-regulation strategies are taught, and emotion-regulation problems are treated, in a variety of approaches to counseling and psychotherapy, including cognitive behavioral therapy (CBT), dialectical behavior therapy (DBT), emotion-focused therapy (EFT), and mindfulness-based cognitive therapy (MBCT).\n\nFor example, a relevant mnemonic formulated in DBT is \"ABC PLEASE\":\n\n\nIntrinsic emotion-regulation efforts during infancy are believed to be guided primarily by innate physiological response systems. These systems usually manifest as an approach towards and an avoidance of pleasant or unpleasant stimuli. At three months, infants can engage in self-soothing behaviors like sucking and can reflexively respond to and signal feelings of distress. For instance, infants have been observed attempting to suppress anger or sadness by knitting their brow or compressing their lips. Between three and six months, basic motor functioning and attentional mechanisms begin to play a role in emotion regulation, allowing infants to more effectively approach or avoid emotionally relevant situations. Infants may also engage in self-distraction and help-seeking behaviors for regulatory purposes. At one year, infants are able to navigate their surroundings more actively and respond to emotional stimuli with greater flexibility due to improved motor skills. They also begin to appreciate their caregivers' abilities to provide them regulatory support. For instance, infants generally have difficulties regulating fear. As a result, they often find ways to express fear in ways that attract the comfort and attention of caregivers.\n\nExtrinsic emotion-regulation efforts by caregivers, including situation selection, modification, and distraction, are particularly important for infants. The emotion regulation strategies employed by caregivers to attenuate distress or to upregulate positive affect in infants can impact the infants' emotional and behavioral development, teaching them particular strategies and methods of regulation. The type of attachment style between caregiver and infant can therefore play a meaningful role in the regulatory strategies infants may learn to use.\n\nRecent evidence supports the idea that maternal singing has a positive effect on affect regulation in infants. Singing play-songs, such as \"The Wheels on the Bus\" or \"She'll Be Comin' Round the Mountain\" have a visible affect-regulatory consequence of prolonged positive affect and even alleviation of distress. In addition to proven facilitation of social bonding, when combined with movement and/or rhythmic touch, maternal singing for affect regulation has possible applications for infants in the NICU and for adult caregivers with serious personality or adjustment difficulties.\n\nBy the end of the first year, toddlers begin to adopt new strategies to decrease negative arousal. These strategies can include rocking themselves, chewing on objects, or moving away from things that upset them. At two years, toddlers become more capable of actively employing emotion regulation strategies. They can apply certain emotion regulation tactics to influence various emotional states. Additionally, maturation of brain functioning and language and motor skills permits toddlers to manage their emotional responses and levels of arousal more effectively.\n\nExtrinsic emotion regulation remains important to emotional development in toddlerhood. Toddlers can learn ways from their caregivers to control their emotions and behaviors. For example, caregivers help teach self-regulation methods by distracting children from unpleasant events (like a vaccination shot) or helping them understand frightening events.\n\nEmotion-regulation knowledge becomes more substantial during childhood. For example, children aged six to ten begin to understand display rules. They come to appreciate the contexts in which certain emotional expressions are socially most appropriate and therefore ought to be regulated. For example, children may understand that upon receiving a gift they should display a smile, irrespective of their actual feelings about the gift. During childhood, there is also a trend towards the use of more cognitive emotion regulation strategies, taking the place of more basic distraction, approach, and avoidance tactics.\n\nRegarding the development of emotion dysregulation in children, one robust finding suggests that children who are frequently exposed to negative emotion at home will be more likely to display, and have difficulties regulating, high levels of negative emotion.\n\nAdolescents show a marked increase in their capacities to regulate their emotions, and emotion-regulation decision making becomes more complex, depending on multiple factors. In particular, the significance of interpersonal outcomes increases for adolescents. When regulating their emotions, adolescents are therefore likely to take into account their social context. For instance, adolescents show a tendency to display more emotion if they expect a sympathetic response from their peers.\n\nAdditionally, spontaneous use of cognitive emotion-regulation strategies increases during adolescence, which is evidenced both by self-report data and neural markers.\n\nSocial losses increase and health tends to decrease as people age. As people get older their motivation to seek emotional meaning in life through social ties tends to increase. Autonomic responsiveness decreases with age, and emotion-regulation skill tends to increase.\n\nAs people age, their affectthe way they react to emotionschanges, either positively or negatively. Studies show that positive affect increases as a person grows from adolescence to their mid 70s. Negative affect, on the other hand, decreases until the mid 70s. Studies also show that emotions differ in adulthood, particularly affect (positive or negative). Although some studies found that affect decreases with age, some have concluded that adults in their middle age experience more positive affect and less negative affect than younger adults. Positive affect was also higher for men than women while the negative affect was higher for women than it was for men and also for single people. A reason that older peoplemiddle adulthoodmight have less negative affect is because they have overcome, \"the trials and vicissitudes of youth, they may increasingly experience a more pleasant balance of affect, at least up until their mid-70s\". Positive affect might rise during middle age but towards the later years of lifethe 70sit begins to decline while negative affect also does the same. This might be due to failing health, reaching the end of their lives and the death of friends and relatives.\n\nIn addition to baseline levels of positive and negative affect, studies have found individual differences in the time-course of emotional responses to stimuli. The temporal dynamics of emotional regulation, also known as affective chronometry, include two key variables in the emotional response process: rise time to peak emotional response, and recovery time to baseline levels of emotion. Studies of affective chronometry typically separate positive and negative affect into distinct categories, as previous research has shown (despite some correlation) the ability of humans to experience changes in these categories independently of one another. Affective chronometry research has been conducted on clinical populations with anxiety, mood, and personality disorders, but is also utilized as a measurement to test the effectiveness of different therapeutic techniques (including mindfulness training) on emotional dysregulation.\n\nThe development of functional magnetic resonance imaging has allowed for the study of emotion regulation on a biological level. Specifically, research over the last decade strongly suggests that there is a neural basis. Sufficient evidence has correlated emotion regulation to particular patterns of prefrontal activation. These regions include the orbital prefrontal cortex, the ventromedial prefrontal cortex, and the dorsolateral prefrontal cortex. Two additional brain structures that have been found to contribute are the amygdala and the anterior cingulate cortex. Each of these structures are involved in various facets of emotion regulation and irregularities in one or more regions and/or interconnections among them are affiliated with failures of emotion regulation. An implication to these findings is that individual differences in prefrontal activation predict the ability to perform various tasks in aspects of emotion regulation.\n\nPeople intuitively mimic facial expressions; it is a fundamental part of healthy functioning. Similarities across cultures in regards to nonverbal communication has prompted the debate that it is in fact a universal language. It can be argued that emotional regulation plays a key role in the ability to emit the correct responses in social situations. Humans have control over facial expressions both consciously and unconsciously: an intrinsic emotion program is generated as the result of a transaction with the world, which immediately results in an emotional response and usually a facial reaction. It is a well documented phenomenon that emotions have an effect on facial expression, but recent research has provided evidence that the opposite may also be true.\n\nThis notion would give rise to the belief that a person may not only control his emotion but in fact influence them as well. Emotional regulation focuses on providing the appropriate emotion in the appropriate circumstances. Some theories allude to the thought that each emotion serves a specific purpose in coordinating organismic needs with environmental demands (cole 1994). This skill, although apparent throughout all nationalities, has been shown to vary in successful application at different age groups. In experiments done comparing younger and older adults to the same unpleasant stimuli, older adults were able to regulate their emotional reactions in a way that seemed to avoid negative confrontation. These findings support the theory that with time people develop a better ability to regulate their emotions. This ability found in adults seems to better allow individuals to react in what would be considered a more appropriate manner in some social situations, permitting them to avoid adverse situations that could be seen as detrimental.\n\nIn solitary conditions, emotional regulation can include a minimization-miniaturization effect, in which common outward expressive patterns are replaced with toned down versions of expression. Unlike other situations, in which physical expression (and its regulation) serve a social purpose (i.e. conforming to display rules or revealing emotion to outsiders), solitary conditions require no reason for emotions to be outwardly expressed (although intense levels of emotion can bring out noticeable expression anyway). The idea behind this is that as people get older, they learn that the purpose of outward expression (to appeal to other people), is not necessary in situations in which there is no one to appeal to. As a result, the level of emotional expression can be lower in these solitary situations.\n\nAccording to Yu. V. Scherbatykh, emotional stress in situations like school examinations can be reduced by engaging in self-regulating activities prior to the task being performed. To study the influence of self-regulation on mental and physiological processes under exam stress, Shcerbatykh conducted a test with an experimental group of 28 students (of both sexes) and a control group of 102 students (also of both sexes).\n\nIn the moments before the examination, situational stress levels were raised in both groups from what they were in quiet states. In the experimental group, participants engaged in three self-regulating techniques (concentration on respiration, general body relaxation, and the creation of a mental image of successfully passing the examination). During the examination, the anxiety levels of the experimental group were lower than that of the control group. Also, the percent of unsatisfactory marks in the experimental group was 1.7 times less than in the control group. From this data, Scherbatykh concluded that the application of self-regulating actions before examinations helps to significantly reduce levels of emotional strain, which can help lead to better performance results.\n\nIdentification of our emotional self-regulating process can facilitate in the decision making process. Current literature on emotion regulation identifies that humans characteristically make efforts in controlling emotion experiences. There is then a possibility that our present state emotions can be altered by emotional regulation strategies resulting in the possibility that different regulation strategies could have different decision implications.\n\nWith a failure in emotional regulation there is a rise in psychosocial and emotional dysfunctions caused by traumatic experiences due to an inability to regulate emotions. These traumatic experiences typically happen in grade school and are sometimes associated with bullying. Children who can't properly self-regulate express their volatile emotions in a variety of ways, including screaming if they don't have their way, lashing out with their fists, or bullying other children. Such behaviors often elicit negative reactions from the social environment, which, in turn, can exacerbate or maintain the original regulation problems over time, a process termed cumulative continuity. These children are more likely to have conflict-based relationships with their teachers and other children. This can lead to more severe problems such as an impaired ability to adjust to school and predicts school dropout many years later. Children who fail to properly self-regulate grow as teenagers with more emerging problems. Their peers begin to notice this \"immaturity\", and these children are often excluded from social groups and teased and harassed by their peers. This \"immaturity\" certainly causes some teenagers to become social outcasts in their respective social groups, causing them to lash out in angry and potentially violent ways. Being teased or being an outcast during the teenage years is especially damaging and could lead to a dysfunctional future, which is why it is recommended to foster emotional self-regulation in children as early as possible.\n"}
{"id": "27545386", "url": "https://en.wikipedia.org/wiki?curid=27545386", "title": "Everest ER", "text": "Everest ER\n\nThe Everest ER is a seasonal tent-based medical clinic at the Everest base camp (17,600 ft/5350m) founded in 2003 by Dr. Luanne Freer, a volunteer physician for the nonprofit Himalayan Rescue Association (HRA) in Nepal and Associate Medical Director of Medcor, Inc.Volunteer doctors provide altitude-experienced health care and preventative education to the climbing community, their support staff and trekking-through public in base camp, using proceeds from this care to subsidize free/low cost health care for the Sherpa people of the Khumbu region of Nepal.\n\nStaffed by volunteer physicians from all over the world, the ER works to stabilize patients for evacuation and descent or, in many cases, to definitively treat the illness or injury. Ninety percent of Everest ER patients are climbers or their support staff; the remaining 10% are trekkers-through or media and just over half of the patients every year are native Nepali.\n\nEverest ER has struggled to remain fiscally solvent. The clinic has accumulated some donated clinic supplies and equipment, including new custom-made tents, and solar panels to enable power to the equipment with clean, quiet, renewable energy. The 501C-3 non-profit organization Himalayan Rescue Association - USA (HRA-USA) was created in 2005 to help fund the clinic, a corporate sponsor (Medcor, Inc.) created and continues to manage the website and production companies filmed documentaries about the clinic in 2004, 2006, and 2007, which increased exposure to potential sponsors. The Everest ER has been well received and relied upon by more teams in the subsequent seasons – in the first 9 seasons the clinic logged over 2500 patient visits.\n"}
{"id": "5091961", "url": "https://en.wikipedia.org/wiki?curid=5091961", "title": "Field trial", "text": "Field trial\n\nA field trial is a competitive event at which hunting dogs compete against one another. There are field trials for retrievers, pointing dogs and flushing dogs. Field trials are usually organized by kennel clubs or other gun dog organizations. Field trials are generally considered more competitive than hunt tests in that success at a field trial requires a higher level of training than success at a hunt test requires. For example, in Retriever Field Trials, dogs retrieve over longer distances with a more complex path than a Retriever Hunt Test would generally provide. Field trial dogs must be finished in their training in order to enter. Their purpose is also different, as they exist mainly for breeders, while hunting tests are made for hunters.\n\nThe term is confusing as it means different things to different breed organizations. Spaniel field trials demand that dogs compete against one another, whereas retriever field trials are more similar to hunt tests among other breeds. In most hunt tests, on the other hand, dogs are evaluated against a written standard and all of the dogs in the hunt test may qualify if they meet the standard. To further complicate the issue, various kennel organizations have differing definitions of field trial.\n\nField trials come in various grades including Open, Amateur, Sanctioned and non-sanctioned. An Open field trial permits entry from any handler or trainer while an Amateur trial only permits non-professional handlers/trainers. Sanctioned trials are ones that are held under the control of a national kennel club or organization, while the non-sanctioned can be organized by a local club.\n\nA field trial that is held under the auspices of the Kennel Club, the UK's governing body in respect of working gundogs, can be described as a competition to assess the work of gundogs in the field. By definition this means that all field trials are held on live, unhandled game that is shot for the purpose of that field trial. Game that has been handled in any way, whether it be live or dead game, may not be used for testing dogs in any part of a field trial. The only exception to this rule is where dead game may be used in the conduct of a water test at a field trial. The reason this exception exists it to acknowledge the fact that game will not necessarily be shot over water, although for dogs to qualify for titles in field trials will be required to demonstrate their ability to retrieve from water.\n\nGundog clubs and societies that are registered with the Kennel Club and which have been authorized to organize and run field trials may do so, provided that a license is issued to that club or society for every field trial. Field trials not licensed by the Kennel Club are liable to be deemed as unrecognized canine events.\n\nIn the US, retriever field trials are held under the auspices of the American Kennel club.\n\nField trials can consist of one or more stakes, which can be considered as separate competitions within a field trial. Such stakes can be run for any of the four sub-groups of gundogs recognized by the Kennel Club. The four sub-groups are;\n\n\nThis is a stake in which the dogs have the opportunity of gaining a qualification towards the title of Field Trial Champion (FTCh in the UK and Ireland, FC in the US) and towards entry in the Championships or Champion Stake for its breed.\n\nThis is open to all dogs of a specified breed or breeds without restriction as to the age of the dog, but which may be restricted by other conditions that are deemed necessary by the organizing club or society. Four placements plus a Reserve JAM and JAMs (Judges Award of Merit).\n\nThis stake is confined to dogs that not have gained the following awards:\n\n\nIn the U.S., this stake is for dogs that have not yet placed first or second in a Qualifying stake nor completed an Open or Amateur stake.\n\nConfined to dogs whelped not earlier than 1 January in the year preceding the date of the field trial. If a Puppy Stake is run in January then a dog that was a puppy in the previous year is deemed to still be a puppy.\n\nIn the U.S., this stake is for dogs at 6 months of age and no more than 2 years of age.\n\nThe judges at field trials are appointed by the Field Trial Secretary of the organising club or society, after having been instructed to do so by the committee of the club or society. It is considered an honour to be asked to judge at a field trial and the highest standard of judging is expected from appointed judges. The club or society running the trial must satisfy itself that the persons being invited to judge at a trial have practical experience of both field trials and sporting shooting. Judges may not shoot at a stake at which they are judging nor may they enter a dog for competition at that trial (except for retriever stakes where someone else may handle their dog in a stake other than the one the owner has been asked to judge).\n\nJudges are classified as either A or B \"Panel Judges and Non-panel (NP). However, an A Panel Judge must be present at all field trials. Judges are appointed to panels after recommendation from a Field Trial Secretary of a club or society which is approved to hold Open Stakes for the appropriate sub-group of gundogs for which he or she has judged within the past three years. The opinion of all previous A Panel judges with whom he or she has judged field trials over the previous three years will be sought by the Kennel Club's Field Trial Sub-Committee. The experience of the perspective Panel Judge over the last number of years is taken into account but this must include having judged at trials for at least two different clubs or societies and with at least five different A Panel co-judges.\n\nIn addition, judges appointed to the B Panel must have a minimum of three years judging experience and six stakes, with at least five A Panel Judges. For appointment to the A Panel, judges must have served at least three years as a B Panel Judge, judging at a minimum of six stakes of which three must have been Open Stakes and with at least five different A Panel Judges.\n\nIn the U.S. the American Kennel Club requires a minimum total of 8 points between the two judges for each stake. Judges for major stakes (Open, Amateur) must have at least 8 combined major judging points and judges of minor stakes (Derby, Qualifying) must have at least 8 combined points of any type.\n\nIt is the judges at field trials who decide whether or not awards are to be made. In tests where the dog and handler team are judged against a standard, in some instances it has been adjudged that none of the dogs reached the required standard and awards have been withheld. This is, however, an unusual occurrence. It is more common for awards to be limited to one or two places than not to be awarded.\n\nAn award is any placing in a stake decided by the judges which may be first, second, third or fourth position. The following can also be conferred at the discretion of judges:\n\n\nDogs competing in retriever or spaniel field trials must not wear a collar of any kind when under the order of the judges. Leads can be used when dogs are not under the order of the judges, but these must be removed prior to the dogs entering the competition line. Any dog that, in the opinion of the judges, does not reach the required standard for the breed will not receive an award. Judges will eliminate dogs from the trial if they have committed an \"eliminating fault.\" Where the judges eliminate a dog for hard mouth, the handler must be given the opportunity of examining the game in the presence of the judges. Their decision, however, is final and binding.\n\nIn general, all dogs must be steady to the shot and the fall of game and should have the ability to retrieve on command. Handlers at field trials must not send their dog on a retrieve until they have been instructed to do so by a judge. Because all field trials in the UK are conducted in live shooting environments, judges will have instructed their guns not to shoot directly over a dog when it is already out working on a retrieve. All wounded game is gathered and dispatched at the earliest possible opportunity and is normally retrieved before dead game. It is possible that game cannot be gathered by the dogs in competition and in such cases the judges would assign this task to picker-up appointed for this purpose.\n\nAs good marking is essential in a retrieving breed to avoid the disturbance of game in the vicinity, judges will give full credit to a dog that goes directly to the fall of the game and gets on with the job of locating and retrieving. A clean pick up is preferred but judges will normally not penalize too heavily dogs that set game down to get a better grip. They will, of course, make a distinction between this and dogs that are guilty of sloppy retrieving or that deliver short of the handler.\n\nWhilst dogs are required to be obedient and respond to its handler's signals, good game finding dogs will be scored higher than those dogs that need handled to the game. Usually the better dogs require less handling, appear to have an instinctive knowledge of direction and make a difficult find look simple. In the UK, Judges will call up dogs that are performing indifferently on a runner and another dog will be tried on it. The work of subsequent dogs on the runner will be assessed in the order in which they are tried. Missed game that is picked by the second or subsequent dog constitutes an \"eye wipe.\" All \"eye wipes\" will be treated on their merits but dogs that have had their \"eye wiped\" during the body of the stake will be discarded by the judges. Where a dog shows ability by acknowledging the fall of game and making a workmanlike job of the line to the fall, it should not be barred from the awards by failing to retrieve the game if that game is not collected by another dog, tried by the judges on the same game.\n\nAll retrieved game is examined by the judges for signs of \"hard mouth.\" Because hard mouthed dogs seldom give a visible sign of hardness by damaging the skin of game, the retrieved game should be placed in the palm of the hand, breast upwards and head forwards. Judges will examine the rib cage of the game, looking for any signs of the ribs being crushed by running the index finger and thumb along each side of the rib cage. If a judges suspects hard mouth, he or she would normally consult with their co-judge who will also examine the game. Where judges are in agreement that the damage has been caused by the dog crushing and not by the fall or the shot, the handler will be given the opportunity of inspecting the game in the presence of the judges. The decision of the judges is final and the dog will be eliminated from the trial.\n\nIn the United States, results of retriever field trials are published in a monthly magazine called Retriever News and in a website (www.retrieverresults.com).\n\nDefinitions of field trials differ based on the organizations around the world that sanction them. The above definition for trials in Great Britain, for example, is quite different from American Field sanctioned field trials for Pointers, English and Red Setters, German Shorthaired Pointers, Vizsla and Brittanys in the United States, Canada and Japan. The American Kennel Club also holds field trials with a different standard for awarding titles.\n\nField trials are competitions for a class of sporting dogs called pointing dogs that have been selectively bred for well over a hundred and fifty years specifically to search for and point upland game birds for hunters. Dogs detect the scent cone in the air given off by birds; they do not track foot scent. Field trials, first conducted in England in 1865 have been used to greatly aid with the selective breeding of dogs with desired characteristics thereby improving the various breeds of pointing dogs both for competition and for upland bird hunters to enjoy. On October 8, 1874 near Memphis TN, a solid black setter named “Knight” won the first ever field trial held in the United States. In 1900 the American Field published the first Field Dog Stud Book (FDSB), establishing the oldest purebred dog registry for sporting dogs. \n\nDogs are entered in field trial stakes for puppies, derbies, and adult dogs in Walking and Horseback Shooting Dog and All-Age categories. Dogs are drawn to run in braces but compete against all dogs entered in the stake. Handlers show their dogs to best advantage to two judges, each assigned to cover a dog and handler, switching in the middle of the stake so each judge has the opportunity to witness both dogs in the brace. Braces are generally from 20 minutes for puppies to 30 - 60 minutes for derbies and adult dogs. Championships are one hour or more and sometimes require a second series for dogs selected as the best from the first series to compete again. People are invited to judge based on their experience training and competing with their own dogs as well as their experience upland bird hunting. Dogs are judged on their genetic characteristics and their training. Each dog is judged on their ground effort (race) demonstrating their ability to intelligently search, using the wind to their advantage, and accurately locate and point game birds. Dogs must handle, always to the front, moving efficiently and attractively with high tail and head carriage, displaying confidence and boldness, wasting no time hunting unlikely cover. As derbies, they should show their potential to become finished, polished dogs. As adults, they must display perfect manners on birds being broke steady to wing and shot and honoring their bracemates’ points. Whether Shooting Dog or All-Age contender, a field trial dog’s performance both running and pointing, should always display “class” and excite the judges and gallery attendants. \n\nA field trial is hosted by a field trial club and run to a set of Minimum Requirements established by the American Field in order for the dog’s win to become part of their permanent record. American Field sanctioned trials — whether a day or two of various stakes or championships — are observed by a reporter invited by the host club. Along with the registered names, registration numbers, handlers and owners of the winning dogs, field trial reports are published in the American Field’s weekly publication so field trialers across the country have an opportunity to read about the dogs’ performances if they were unable to attend and watch the trial. Reports record the history of the sport. \n\nThe American Field’s weekly newspaper also announces field trials (open and amateur) in the USA, Canada and Japan. Dogs must qualify by winning field trial placements in order to compete in championships and be awarded Championship and Runner-Up Championship titles. There are primarily horseback Shooting Dog and All-Age stakes, Walking stakes (including grouse and woodcock trials, referred to as 'grouse' or 'cover dog' trials) held throughout the US and many Canadian provinces on various species of upland game birds. In many parts of the country, trials are now held on released or liberated game because wild birds no longer exist in those areas or because there are no available wild-bird grounds suitable or attainable to run field trials on. Enormous efforts by conservation groups supported by field trialers have been made to reverse this situation by land management efforts to restore the natural habitat for wild upland game birds.\n\nThe Amateur Field Trial Clubs of America (AFTCA) was established in 1917 specifically for amateur handlers to compete against one another.\n\n\"The familiar, capsule description of the all-age dog, attributed to old-time trainer Jim Advent, declares that he (or she) is a dedicated hunter of upland game birds which 'runs off — but not quite'. The all-age dog is a free spirit and fills up all the available country (plus a little) in a bold and sometimes reckless manner, yet ultimately acknowledges the control exerted by his handler and course to the front in such a pattern as to maintain periodic, suitable contact with the handler. The real intelligent and accomplished all-age dog exhibits the knack of \"showing\" at strategic, distant, forward points on the course during the progress of his heat. He may frequently pass from view, only to show again after a lapse of time, or to be discovered by handler or scout pointing game.\n\nAll-Age Standard reads as follows:\nIn any given All-Age Stake, it may be very difficult to place a dog which totally meets the exalted standard; therefore, out of necessity, there will frequently be a need to accept a dog whose qualities and character can only begin to approximate the standard. The standard, when applied, should examine the total performance of the dog with range being kept foremost in mind. Range is the “sine qua non” of an all-age dog and it should take precedence over and not be compromised for a short, practical, methodical, uninspiring performance, no matter how immaculate the bird work of the latter.\n\n“A Shooting Dog Stake is held for the purpose of promoting the ideal shooting dog, one that will find and handle correctly all game birds on the designated course.\n“The superior shooting dog is one that excites constant admiration for the quality of the performance and does nothing to displease or annoy. Without giving his handler any unnecessary effort, he will, in an artistic and polished manner, give him the most quality bird finds that are to be had on the ground covered.\n\nShooting Dog Standard reads as follows:\nIn any given Shooting Dog Stake, it may be very difficult to place a dog which totally meets the exalted standard. Therefore, out of necessity, there will frequently be a need to accept a dog whose qualities and character can only begin to approximate this standard. The standard when applied should seek out a dog which displays superior bird dog characteristics in the form of natural qualities such as pace, range, bird sense, nose, stamina and style. The contender sought after should render a balanced, biddable performance, search intelligently and exhibit bird finding ability with quality always superseding quantity, manifest accuracy of location, loftiness and intensity on point. Subservience to the handler and proper handling response without the benefit of scouting and excessive handling are the “sine qua non” of a shooting dog. Excessive range on the part of a shooting dog is not considered desirable. When considering bird work, the judges should be swayed not by the frequency of occurrence but rather the quality of the performance.\n\nExact definitions of field trial dogs and stakes and their interpretation have differed, no doubt, from the beginning of field trial history. There is much subjectivity based on individual understanding, experience and preference brought to the judicial saddle. One aspect of field trials generally agreed upon is the necessity of good, experienced judges of great integrity.\n\n1. They should be of strong moral character and integrity, and respected for these qualities in their hometown, business, and field trial community.\n\n2. They should be in good physical condition with the stamina to ride (or walk where horses cannot be used) for days on end and see all the entries in the stake through to their proper conclusion, and possess keen eyesight to see all the action as it transpires.\n\n3. They should be of even temperament, blessed with common sense, possess an alert, analytically decisive mind, and have sufficient conviction in their abilities to stand up for their decisions.\n\n4. They should be a good horseman (or women) and have full knowledge of the outdoors and an understanding of the behavior of game birds and dogs, and have background of practical bird-hunting experience.\n\n5. They should be familiar with the proper procedure of training and breaking bird dogs and must have successfully run dogs in field trials, and should have “broke” dogs of their own.\n\n6. They should have a thorough knowledge and understanding of the AFTCA's Guidelines to Field Trial Procedure and Judicial Practice.\n\n7. They should have experience running All-Age and/or Shooting Dogs to understand the difference between these types of performances and their different standards. This knowledge should be applied when decisions are rendered.\n\nA dog’s field trial wins are recorded with the FDSB (Field Dog Stud Book) and are a permanent part of their record shown on their pedigree. Field trials have always been and continue to be a critical tool for the continued successful breeding of superior bird dogs from which the upland game hunter has benefited.\n\n"}
{"id": "6934905", "url": "https://en.wikipedia.org/wiki?curid=6934905", "title": "Frank D. Costenbader", "text": "Frank D. Costenbader\n\nFrank D. Costenbader (1905 - 1978) was an American physician frequently credited as the world's first pediatric ophthalmologist.\n"}
{"id": "23167397", "url": "https://en.wikipedia.org/wiki?curid=23167397", "title": "GENCODE", "text": "GENCODE\n\nGENCODE is a scientific project in genome research and part of the ENCODE (ENCyclopedia Of DNA Elements) scale-up project.\n\nThe GENCODE consortium was initially formed as part of the pilot phase of the ENCODE project to identify and map all protein-coding genes within the ENCODE regions (approx. 1% of Human genome). Given the initial success of the project, GENCODE now aims to build an “Encyclopedia of genes and genes variants” by identifying all gene features in the human and mouse genome using a combination of computational analysis, manual annotation, and experimental validation, and annotating all evidence-based gene features in the entire human genome at a high accuracy.\n\nThe result will be a set of annotations including all protein-coding loci with alternatively transcribed variants, non-coding loci with transcript evidence, and pseudogenes.\n\nGENCODE is currently progressing towards its goals in Phase 2 of the project, which are:\nThe most recent release of the Human geneset annotations is Gencode 20, with a freeze date of April 2014. This release utilises the latest GRCh38 human reference genome assembly, and corresponds to Ensembl release 76.\nThe latest release for the mouse geneset annotations is Gencode M3, also with a freeze date of April 2014.\n\nSince September 2009, GENCODE has been the human gene set used by the Ensembl project and each new GENCODE release corresponds to an Ensembl release.\n\n2003 September\nThe National Human Genome Research Institute (NHGRI) launched a public research consortium named ENCODE, the Encyclopedia Of DNA Elements, in September 2003, to carry out a project to identify all functional elements in the human genome sequence. The project was designed with three phases - Pilot, Technology development and Production phase.\nThe pilot stage of the ENCODE project aimed to investigate in great depth, computationally and experimentally, 44 regions totaling 30 Mb of sequence representing approximately 1% of the human genome. As part of this stage, the GENCODE consortium was formed to identify and map all protein-coding genes within the ENCODE regions. It was envisaged that the results of the first two phases will be used to determine the best path forward for analysing the remaining 99% of the human genome in a cost-effective and comprehensive production phase.\n\n2005 April\nThe first release of the annotation of the 44 ENCODE regions was frozen on 29 April 2005 and was used in the first ENCODE Genome Annotation Assessment Project (E-GASP) workshop. GENCODE Release 1 contained 416 known loci, 26 novel (coding DNA sequence) CDS loci, 82 novel transcript loci, 78 putative loci, 104 processed pseudogenes and 66 unprocessed pseudogenes.\n\n2005 October\nA second version (release 02) was frozen on 14 October 2005, containing updates following discoveries from experimental validations using RACE and RT-PCR techniques. GENCODE Release 2 contained 411 known loci, 30 novel CDS loci, 81 novel transcript loci, 83 putative loci, 104 processed pseudogenes and 66 unprocessed pseudogenes.\n\n2007 June\nThe conclusions from the pilot project were published in June 2007. The findings highlighted the success of the pilot project to create a feasible platform and new technologies to characterise functional elements in the human genome, which paves the way for opening research into genome-wide studies.\n\n2007 October\nAfter a successful pilot phase on 1% of the genome, the Wellcome Trust Sanger Institute was awarded a grant from the US National Human Genome Research Institute (NHGRI) to carry out a scale-up of the GENCODE project for integrated annotation of gene features.\nThis new funding was part of NHGRI's endeavour to scale-up the ENCODE Project to a production phase on the entire genome along with additional pilot-scale studies.\n\n2012 September\nIn September 2012, The GENCODE consortium published a major paper discussing the results from a major release – GENCODE Release 7, which was frozen in December 2011. The GENCODE 7 release used a combination of manual gene annotation from the Human and Vertebrate Analysis and Annotation (HAVANA) group and full new release (Ensembl release 62) of the automatic gene annotation from Ensembl. At the time of release, GENCODE Release 7 had the most comprehensive annotation of long noncoding RNA (lncRNA) loci publicly available with the predominant transcript form consisting of two exons.\n\n2013 - 2017\nHaving been involved in successfully delivering the definitive annotation of functional elements in the human genome, the GENCODE group were awarded a second grant in 2013 in order to continue their human genome annotation work and expand GENCODE to include annotation of the mouse genome. It is envisaged that the mouse annotation data will allow comparative studies between the human and mouse genomes, to improve annotation quality in both genomes.\n\nThe key participants of the GENCODE project have remained relatively consistent throughout its various phases, with the Wellcome Trust Sanger Institute now leading the overall efforts of the project.\n\nA summary of key participating institutions of each phase is listed below:\n\nSince its inception, GENCODE has released 20 versions of the Human gene set annotations (excluding minor updates).\n\nThe key summary statistics of the most recent GENCODE Human gene set annotation (Release 20, April 2014 freeze, Ensembl 76), which is the first version that utilises the latest version of the Human Genome Assembly (GRCh38), is shown below: \nRefer to the GENCODE Statistics README and GENCODE biotypes page for more details on the classification of the above gene set.\n\nThrough advancements in sequencing technologies (such as RT-PCR-seq), increased coverage from manual annotations (HAVANA group), and improvements to automatic annotation algorithms using Ensembl, the accuracy and completeness of GENCODE annotations have been continuously refined through its iteration of releases.\n\nA comparison of key statistics from 3 major GENCODE releases is shown below. It is evident that although the coverage, in terms of total number of genes discovered, is steady increasing, the number of protein-coding genes has actually decreased. This is mostly attributed to new experimental evidence obtained using Cap Analysis Gene Expression (CAGE) clusters, annotated PolyA sites, and peptide hits.\nThe general process to create an annotation for GENCODE involves manual curation, different computational analysis and targeted experimental approaches. Putative loci can be verified by wet-lab experiments and computational predictions are analysed manually.\nCurrently, to ensure a set of annotation covers the complete genome rather than just the regions that have been manually annotated, a merged data set is created using manual annotations from HAVANA, together with automatic annotations from the Ensembl automatically annotated gene set. This process also adds unique full-length CDS predictions from the Ensembl protein coding set into manually annotated genes, to provide the most complete and up-to-date annotation of the genome possible.\n\nEnsembl transcripts are products of the Ensembl automatic gene annotation system (a collection of gene annotation pipelines), termed the Ensembl gene build. All Ensembl transcripts are based on experimental evidence and thus the automated pipeline relies on the mRNAs and protein sequences deposited into public databases from the scientific community. Moreover, Protein levels 1 and 2 from UniProt, untranslated regions (UTRs), long intergenic noncoding RNA (lincRNA) genes (annotated using a combination of cDNA sequences and regulatory data from the Ensembl project), short non-coding RNAs (annotated using the Ensembl ncRNA pipelines) are included.\n\nThe main approach to manual gene annotation is to annotate transcripts aligned to the genome and take the genomic sequences as the reference rather than the cDNAs. The finished genomic sequence is analyzed using a modified Ensembl pipeline, and BLAST results of cDNAs/ESTs and proteins, along with various ab initio predictions, can be analyzed manually in the annotation browser tool Otterlace. Thus, more alternative spliced variants can be predicted compared with cDNA annotation. Moreover, genomic annotation produces a more comprehensive analysis of pseudogenes.\nThere are several analysis groups in the GENCODE consortium that run pipelines that aid the manual annotators in producing models in unannotated regions, and to identify potential missed or incorrect manual annotation, including completely missing loci, missing alternative isoforms, incorrect splice sites and incorrect biotypes. These are fed back to the manual annotators using the AnnoTrack tracking system. Some of these pipelines use data from other ENCODE subgroups including RNASeq data, histone modification and CAGE and Ditag data. RNAseq data is an important new source of evidence, but generating complete gene models from it is a difficult problem. As part of GENCODE, a competition was run to assess the quality of predictions produced by various RNAseq prediction pipelines (Refer to RGASP below). To confirm uncertain models, GENCODE also has an experimental validation pipeline using RNA sequencing and RACE \n\nDuring the merge process, all HAVANA and Ensembl transcripts models are compared, first by clustering overlapped coding exons on a same strand, and then by pairwise comparisons of each exon in a cluster of transcripts. The module used to merge the gene set is HavanaAdder. Additional steps are required prior to running the HavanaAdder code (e.g. Ensembl health-checking system and queries against CCDS gene set and Ensembl´s cDNA alignments). If annotation described in external data sets is missing from the manual set, then this is stored in the AnnoTrack system to be reviewed.\n\nFor GENCODE 7, transcript models are assigned a high or low level of support based on a new method developed to score the quality of transcripts. This method relies on mRNA and EST alignments supplied by UCSC and Ensembl. The mRNA and EST alignments are compared to the GENCODE transcripts, and the transcripts are scored according to the alignment over its full length. A summary of support levels for each chromosome in GENCODE Release 7 is shown in the figure on the right. The annotations are partitioned into those produced by the automated process, manual method and the merged annotations, where both processes result in the same annotation.\n\nAmplification, sequencing, mapping and validation exon–exon junction\n\nDouble-stranded cDNA of eight human tissues (brain, heart, kidney, testis, liver, spleen, lung, and skeletal muscle) were generated with a cDNA amplification, and the purified DNA was directly used to generate a sequencing library with the ‘‘Genomic DNA sample prep kit’’ (Illumina). This library was subsequently sequenced on an Illumina Genome Analyzer 2 platform. Then, reads (35 or 75 nt) were mapped on to the reference human genome (hg19) and the predicted spliced amplicons with Bowtie software. Only uniquely mapping reads with no mismatch were considered to validate a splice site (transcript). Splice junctions were validated if a minimum of 10 reads with the following characteristics spanned the predicted splice junctions. For 35- and 75-nt-long reads, it required at least 4 and 8 nt on each side of the breakpoints (i.e., on each targeted exon), respectively.\n\nComparison of RefSeq, UCSC, AceView, and GENCODE transcripts\n\nTranscripts belonging to four different data sets (GENCODE, RefSeq, UCSC, and AceView) were compared to assess to which extent these data sets overlap. Releases compared were GENCODE 7, RefSeq and UCSC Genes freeze July 2011, and AceView 2010 release. The overlaps between different data set combinations were graphically represented as three-way Venn diagrams using the Vennerable R package and edited manually.\n\nPhyloCSF analysis\n\nPhyloCSF was used to identify potential novel coding genes in RNA-seq transcript models based on evolutionary signatures. For each transcript model generated from the Illumina HBM data using either Exonerate or Scripture, a mammalian alignment was generated by extracting the alignment of each exon from UCSC’s vertebrate alignments (which includes 33 placental mammals).\n\nAPPRIS (CNIO)\n\nAPPRIS is a system that deploys a range of computational methods to provide value to the annotations of the human genome. APPRIS also selects one of the CDS for each gene as the principal isoform. Moreover, it defines the principal variant by combining protein structural and functional information and information from the conservation of related species. The APPRIS server has been used in the context of the scale up of the ENCODE project to annotate the Human genome but APPRIS is being used for other species (e.g. mouse, rat and zebrafish). The pipeline is made up of separate modules that combine protein structure and function information and evolutionary evidence. Each module has been implemented as a separate web service.\n\nThe current GENCODE Human gene set version (GENCODE Release 20) includes annotation files (in GTF and GFF3 formats), FASTA files and METADATA files associated with the GENCODE annotation on all genomic regions (reference-chromosomes/patches/scaffolds/haplotypes). The annotation data is referred on reference chromosomes and stored in separated files which include: Gene annotation, PolyA features annotated by HAVANA, (Retrotransposed) pseudogenes predicted by the Yale & UCSC pipelines, but not by HAVANA, long non-coding RNAs, and tRNA structures predicted by tRNA-Scan.\nSome examples of the lines in the GTF format are shown below:\n\nThe columns within the GENCODE GTF file formats are described below.\n\nFormat description of GENCODE GTF file. TAB-separated standard GTF columns\n\nDescription of key-value pairs in 9th column of the GENCODE GTF file (format: key \"value\")\nEach gene in the GENCODE data set are classified into three levels according to their type of annotation:\n\nLevel 1 (verified loci):\nIncludes transcripts that have been manually annotated and experimentally validated by RT-PCR-seq, and pseudogenes that have been validated by three different methodologies.\n\nLevel 2 (manually annotated loci):\nHighlights transcripts that have been manually annotated by HAVANA only, and also includes transcripts that have been merged with models produced by the Ensembl automatic pipeline.\n\nLevel 3 (automatically annotated loci):\nIndicates transcripts and pseudogene predictions resulting from Ensembl’s automated annotation pipeline.\n\nGenes & transcripts are assigned the status ‘‘known,’’ ‘‘novel,’’ or ‘‘putative’’ depending on their presence in other major databases and the evidence used to build their component transcripts.\n\nKnown:\nRepresented in the HUGO Gene Nomenclature Committee (HGNC) database and RefSeq.\n\nNovel: \nNot currently represented in HGNC or RefSeq databases, but are well supported by either locus specific transcript evidence or evidence from a paralogous or orthologous locus.\n\nPutative:\nNot currently represented in HGNC or RefSeq databases, but are supported by shorter, more sparse transcript evidence.\n\nAlso, the GENCODE website contains a Genome Browser for human and mouse where you can reach any genomic region by giving the chromosome number and start-end position (e.g. 22:30,700,000..30,900,000), as well as by ENS transcript id (with/without version) , ENS gene id (with/without version) and gene name. The browser is powered by Biodalliance.\n\nThe definition of a \"gene\" has never been a trivial issue, with numerous definitions and notions proposed throughout the years since the discovery of the human genome. First, genes were conceived in the 1900s as discrete units of heredity, then it was thought as the blueprint for protein synthesis, and in more recent times, it was being defined as genetic code that is transcribed into RNA. Although the definition of a gene has evolved greatly over the last century, it has remained a challenging and controversial subject for many researchers. With the advent of the ENCODE/GENCODE project, even more problematic aspects of the definition have been uncovered, including alternative splicing (where a series of exons are separated by introns), intergenic transcriptions, and the complex patterns of dispersed regulation, together with non-genic conservation and the abundance of noncoding RNA genes. As GENCODE endeavours to build an encyclopaedia of genes and gene variants, these problems presented a mounting challenge for the GENCODE project to come up with an updated notion of a gene.\n\nPseudogenes have DNA sequences which are similar to functional protein-coding genes, however their transcripts are usually identified with a frameshift or deletion, and are generally annotated as a byproduct of protein-coding gene annotation in most genetic databases. However, recent analysis of retrotransposed pseudogenes have found some retransposed pseudogenes to be expressed and functional and to have major biological/regulatory impacts on human biology. To deal with the unknowns and complexities of pseudogenes, GENCODE has created a pseudogene ontology using a combination of automated, manual, and experimental methods to associate a variety of biological properties—such as sequence features, evolution, and potential biological functions to pseudogenes.\n\nThe Encyclopedia Of DNA Elements (ENCODE) is a public research consortium launched by the National Human Genome Research Institute (NHGRI), in September 2003 (Pilot phase). The goal of ENCODE is to build a comprehensive parts list of functional elements in the human genome, including elements that act at the protein and RNA levels, and regulatory elements that control cells and circumstances in which a gene is active. \nData analysis during the pilot phase (2003 - 2007) was coordinated by the Ensembl group, a joint project of EBI and the Wellcome Trust Sanger Institute. During the initial pilot and technology development phases of the project, 44 regions—approximately 1% of the human genome—were targeted for analysis using a variety of experimental and computational methods.\nAll data produced by ENCODE investigators and the results of ENCODE analysis projects from 2003 to 2012 are hosted in the UCSC Genome browser and database. ENCODE results from 2013 and later are freely available for download and analysis from the ENCODE Project Portal. To annotate all evidence-based gene features (genes, transcripts, coding sequences, etc.) in the entire human genome at a high accuracy, ENCODE consortium create the subproject GENCODE.\n\nThe Human Genome Project was an international research effort to determine the sequence of the human genome and identify the genes that it contains. The Project was coordinated by the National Institutes of Health and the U.S. Department of Energy. Additional contributors included universities across the United States and international partners in the United Kingdom, France, Germany, Japan, and China. The Human Genome Project formally began in 1990 and was completed in 2003, 2 years ahead of its original schedule.\nFollowing the release of the completed human genome sequence in April 2003, the scientific community intensified its efforts to mine the data for clues about how the body works in health and in disease. A basic requirement for this understanding of human biology is the ability to identify and characterize sequence-based functional elements through experimentation and computational analysis. In September 2003, the NHGRI introduced the ENCODE project to facilitate the identification and analysis of the complete set of functional elements in the human genome sequence.\n\nEnsembl is part of the GENCODE project, and it has played a critical role to provide automatic annotation on the human reference genome assembly and to merge this annotation with manual annotation from the HAVANA team. The gene set provided by Ensembl for human is the GENCODE gene set \n\nA key research area of the GENCODE project was to investigate the biological significance of long non-coding RNAs (lncRNA). To better understand the lncRNA expression in Humans, a sub project was created by GENCODE to develop custom microarray platforms capable of quantifying the transcripts in the GENCODE lncRNA annotation. A number of designs have been created using the Agilent Technologies eArray system, and these designs are available in a standard custom Agilent format.\n\nThe RNA-seq Genome Annotation Assessment Project (RGASP) project is designed to assess the effectiveness of various computational methods for high quality RNA-sequence data analysis. The primary goals of RGASP are to provide an unbiased evaluation for RNA-seq alignment, transcript characterisation (discovery, reconstruction and quantification) software, and to determine the feasibility of automated genome annotations based on transcriptome sequencing.\n\nRGASP is organised in a consortium framework modelled after the EGASP (ENCODE Genome Annotation Assessment Project) gene prediction workshop, and two rounds of workshops have been conducted to address different aspects of RNA-seq analysis as well as changing sequencing technologies and formats. One of the main discoveries from rounds 1 & 2 of the project was the importance of read alignment on the quality of gene predictions produced. Hence, a third round of RGASP workshop is currently being conducted (in 2014) to focus primarily on read mapping to the genome.\n\n\n"}
{"id": "1843625", "url": "https://en.wikipedia.org/wiki?curid=1843625", "title": "GNC (store)", "text": "GNC (store)\n\nGNC Holdings Inc. (General Nutrition Centers) is a Pittsburgh, Pennsylvania-based American company selling health and nutrition related products, including vitamins, supplements, minerals, herbs, sports nutrition, diet, and energy products.\n\nIn 1935, David Shakarian opened a small health food store, Lackzoom, in downtown Pittsburgh. He only made US$35 on his first day, but was able to open a second store within six months. A year later, Shakarian suffered from what appeared to be a fatal blow when the Ohio River flooded into downtown on St. Patrick's Day. Both of his stores were wiped out. However, he quickly rebuilt both stores, and opened five more by 1941. The company officially registered as a corporation on September 1, 1936 Shakarian moved into the mail order business during WWII. He said that customers sent him a check and asked him to mail their product as they could not drive to his store due to the gas rationing which happened during WWII. During the health food craze of the 1960s, Shakarian expanded his chain outside Pittsburgh for the first time, and in the process changed its name to General Nutrition Center. He continued to run the chain until his death in 1984. Shakarian took GNC public (listed on the NYSE) in the 1980s. Overexpansion and his death in 1984 resulted in a highly leveraged GNC. The Shakarian family decided to sell GNC shortly after his death. The family brought in a \"turn around\" executive, Jerry Horn, with instructions to \"stop the bleeding\" and position GNC to be sold. \n\nIn 1990 the company considered relocating but a public/private effort retained GNC headquarters in Downtown Pittsburgh. GNC was taken private and sold to The Thomas Lee Company, a PE investment/management fund in the late 1980s. Thomas Lee ran GNC and took it public prior to selling the company to Royal Dutch Numico and Numico acquired GNC in 1999; it sold GNC to Apollo Management in 2003. Ontario Teachers' Pension Plan and Ares Management bought GNC in 2007. GNC went public in 2011.\n\nIn 2018, Harbin Pharmaceutical Group Holding Co., a company controlled by the Chinese government, agreed to acquire an approximately 40% stake in GNC.\n\nGNC stores typically stock a wide range of weight loss, bodybuilding, nutritional supplements, vitamins, natural remedies, and health and beauty products, in both its owned brands as well as third-party brands. The stores also sell health and fitness books and magazines.\n\nGNC has more than 6,000 stores in the U.S., including 1,100 store-within-a-store locations within Rite Aid, as well as locations in 49 other countries. In addition, GNC LiveWell currently has 41 Stores located in Brisbane, Sydney, and Melbourne in Australia.\n\nGNC retail stores are a combination of corporate-owned and franchised stores; 950 of the 5,000 domestic US stores are franchises, commonly located within urban shopping malls and shopping zones. In addition to the GNC.com website, GNC's products are sold on drugstore.com.\n\nIn 1998, GNC was accused of purposely running its franchisees out of business in order to \"retake\" the stores into corporate control. An April 30, 2003 article states that the GNC corporate company was sued by numerous franchise owners. The complaint is that the parent company was allowing their corporate owned stores to sell products for less than the franchise stores are allowed to sell them for. The suit also claimed that GNC charged high \"reset fees\" to franchisees when there is new signage that needs to be changed in the store or an image facelift that must be done by GNC corporate. A similar lawsuit was filed again in an article written on October 20, 2004.\n\nIn February 2015, New York Attorney General Eric Schneiderman sent cease and desist letters to GNC and other major retailers due to concerning laboratory tests regarding the accuracy of the claimed contents of supplements. GNC shortly afterwards removed some stock from sales while working with the Attorney General. In September 2016, GNC, the New York Office of the Attorney General, and other supplement retailers ultimately came to an agreement and retailers are now accomplishing more robust testing of supplements to ensure accurate labeling.\n\nIn October 2015, the Attorney General of Oregon filed a lawsuit against GNC alleging that the company knowingly sold products containing the ingredients picamilon and BMPEA, which are banned by the FDA.\n\nOn February 2, 2017, GNC threatened to sue the Fox Broadcasting Company for \"significant economic and reputational damages, lost opportunities, and consequential damages\", after an advertisement for the chain was blocked from airing during Super Bowl LI. Despite repeated approvals by Fox, the network stated that the ad had been vetoed by the National Football League because of GNC's placement on an NFLPA blacklist for selling products that contain substances banned by the NFL. The letter of intent claimed that Fox had not informed them of any such rules when they purchased the ad time, and cited that the purchase induced them to \"spend millions of dollars in production costs and in the development of a national, coordinated marketing and rebranding campaign\" around the commercial. The NFL itself does not prohibit ads for health stores unless they contain references to specific prohibited products; the GNC ad only contained motivational themes and no references to its products.\n\n"}
{"id": "56527", "url": "https://en.wikipedia.org/wiki?curid=56527", "title": "Galactose", "text": "Galactose\n\nGalactose (, \"galacto-\" + \"-ose\", \"milk sugar\"), sometimes abbreviated Gal, is a monosaccharide sugar that is about as sweet as glucose, and about 30% as sweet as sucrose. It is a C-4 epimer of glucose.\n\nGalactan is a polymeric form of galactose found in hemicellulose, and forming the core of the galactans, a class of natural polymeric carbohydrates.\n\nThe word \"galactose\" was coined by Charles Weissman in the mid 19th century and is derived from Greek \"galaktos\" (milk) and the generic chemical suffix for sugars \"-ose\". The etymology is comparable to that of the word \"lactose\" in that both contain roots meaning \"milk sugar\". Lactose is a disaccharide of galactose plus glucose.\n\nGalactose exists in both open-chain and cyclic form. The open-chain form has a carbonyl at the end of the chain.\n\nFour isomers are cyclic, two of them with a pyranose (six-membered) ring, two with a furanose (five-membered) ring. Galactofuranose occurs in bacteria, fungi and protozoa, and is recognized by a putative chordate immune lectin intelectin through its exocyclic 1,2-diol. In the cyclic form there are two anomers, named alpha and beta, since the transition from the open-chain form to the cyclic form involves the creation of a new stereocenter at the site of the open-chain carbonyl. In the beta form, the alcohol group is in the equatorial position, whereas in the alpha form, the alcohol group is in the axial position.\n\nGalactose is a monosaccharide. When combined with glucose (monosaccharide), through a condensation reaction, the result is the disaccharide lactose. The hydrolysis of lactose to glucose and galactose is catalyzed by the enzymes lactase and β-galactosidase. The latter is produced by the \"lac\" operon in \"Escherichia coli\".\n\nIn nature, lactose is found primarily in milk and milk products. Consequently, various food products made with dairy-derived ingredients can contain lactose. Galactose metabolism, which converts galactose into glucose, is carried out by the three principal enzymes in a mechanism known as the Leloir pathway. The enzymes are listed in the order of the metabolic pathway: galactokinase (GALK), galactose-1-phosphate uridyltransferase (GALT), and UDP-galactose-4’-epimerase (GALE).\n\nIn human lactation, glucose is changed into galactose via hexoneogenesis to enable the mammary glands to secrete lactose. However, most lactose in breast milk is synthesized from galactose taken up from the blood, and only 35±6% is made from galactose from \"de novo\" synthesis.\n\nGlucose is the primary metabolic fuel for humans. It is more stable than galactose and is less susceptible to the formation of nonspecific glycoconjugates, molecules with at least one sugar attached to a protein or lipid. Many speculate that it is for this reason that a pathway for rapid conversion from galactose to glucose has been highly conserved among many species.\n\nThe main pathway of galactose metabolism is the Leloir pathway; humans and other species, however, have been noted to contain several alternate pathways, such as the De Ley Doudoroff pathway. The Leloir pathway consists of the latter stage of a two-part process that converts β-D-galactose to UDP-glucose. The initial stage is the conversion of β-D-galactose to α-D-galactose by the enzyme, mutarotase (GALM). The Leloir pathway then carries out the conversion of α-D-galactose to UDP-glucose via three principal enzymes: Galactokinase (GALK) phosphorylates α-D-galactose to galactose-1-phosphate, or Gal-1-P; Galactose-1-phosphate uridyltransferase (GALT) transfers a UMP group from UDP-glucose to Gal-1-P to form UDP-galactose; and finally, UDP galactose-4’-epimerase (GALE) interconverts UDP-galactose and UDP-glucose, thereby completing the pathway.\n\nGalactosemia is an inability to properly break down galactose due to a genetically inherited mutation in one of the enzymes in the Leloir pathway. As a result, the consumption of even small quantities is harmful to galactosemics.\n\nGalactose is found in dairy products, avocados, sugar beets, other gums and mucilages. It is also synthesized by the body, where it forms part of glycolipids and glycoproteins in several tissues; and is a by-product from the third-generation ethanol production process (from macroalgae).\n\nChronic systemic exposure of mice, rats, and \"Drosophila\" to D-galactose causes the acceleration of senescence (aging). It has been reported that high dose exposure of D-galactose (120 mg/Kg) can cause reduced sperm concentration and sperm motility in rodent and has been extensively used as an aging model.\nTwo studies have suggested a possible link between galactose in milk and ovarian cancer. Other studies show no correlation, even in the presence of defective galactose metabolism. More recently, pooled analysis done by the Harvard School of Public Health showed no specific correlation between lactose-containing foods and ovarian cancer, and showed statistically insignificant increases in risk for consumption of lactose at 30 g/d. More research is necessary to ascertain possible risks.\n\nSome ongoing studies suggest galactose may have a role in treatment of focal segmental glomerulosclerosis (a kidney disease resulting in kidney failure and proteinuria). This effect is likely to be a result of binding of galactose to FSGS factor.\n\nGalactose is a component of the antigens present on blood cells that determine blood type within the ABO blood group system. In O and A antigens, there are two monomers of galactose on the antigens, whereas in the B antigens there are three monomers of galactose.\n\nA disaccharide composed of two units of galactose, galactose-alpha-1,3-galactose (alpha-gal), has been recognized as a potential allergen present in mammal meat. Alpha-gal allergy may be triggered by lone star tick bites.\n\nIn 1855, E. O. Erdmann noted that hydrolysis of lactose produced a substance besides glucose. Galactose was first isolated and studied by Louis Pasteur in 1856. He called it \"lactose\". In 1860, Berthelot renamed it \"galactose\" or \"glucose lactique\". In 1894, Emil Fischer and Robert Morrell determined the configuration of galactose.\n\n"}
{"id": "48128792", "url": "https://en.wikipedia.org/wiki?curid=48128792", "title": "Great Smoky Mountains Study", "text": "Great Smoky Mountains Study\n\nThe Great Smoky Mountains Study is a longitudinal study led by William Copeland (professor) from Duke University Medical Center that started in 1993 and ended in 2003. It followed 1,420 children from western North Carolina. Participants were interviewed at up to nine points in time - first aged 9 to 16, and again at ages 19–21.\n\nFour years into the study, about one quarter of the families saw a dramatic and unexpected increase in income. They were members of the Eastern Band of Cherokee Indians, and a casino had just been built on the reservation. From that point on every tribal citizen earned a share of the profits (about $4,000/yr per person). The study showed that among these children, instances of behavioral and emotional disorders decreased, and conscientiousness and agreeableness increased. Randall Akee remarked that \"It would be almost impossible to replicate this kind of longitudinal study”.\n"}
{"id": "45369161", "url": "https://en.wikipedia.org/wiki?curid=45369161", "title": "Grotta del Ninfeo", "text": "Grotta del Ninfeo\n\nThe Grotta del Ninfeo is an artificial cavity in the rock of Temenite Hill (named after the Greek \"temenos\", \"sacred precinct\") located in the Archaeological park of Neapolis in Syracuse.\n\nThe grotta is located near the highest part of the little rocky relief, on a rectangular terrace which verges on the Greek theatre and opens at the centre of a stone wall where a closed portico in the form of an \"L\" was once found. At the entrance there were statues dedicated to the Muses, three of which (dated to the 2nd century BC) are still preserved and are on display at the Museo archeologico regionale Paolo Orsi. The fountain is dedicated to the Ancient Greek cult of the nymphs, nature goddesses. The name nymphaeum for a monumental, decorated fountain derives from this.\n\nThe Syracusan nymphaeum is thought to have been the ancient location of the \"Mouseion\" (the sanctuary of the Muses), seat of the artistic guild, where the Syracusan actors gathered before descending into the theatre to put on comedies and tragedies in the time of Epicharmus and Aeschylus.\n\nRegarding the Grotta del Ninfeo, the Syracusan Giuseppe Politi wrote in the nineteenth century:\nThe grotto has a vaulted ceiling and inside it there is a rectangular tub in which the water collects before cascading from a cavity located at the bottom of the rock wall. Next to the entrance, there are some votive aedicula which were used for hero cults (\"Pinakes\"). To the east of the Grotta del Ninfeo, the last watermill from the Spanish period remains visible even today. It took water from the grotta and redirected it into the theatre after using it to mill grain. From nymphaeum, one continues to the Via dei Sepolcri and from there to the summit of the hill, where there are other Graeco-Roman monuments. \n\nThe water that flows into the Grotta derives from two separate aqueducts, both of Greek date; one is called the \"Acquedotto del Ninfeo\" (Nymphaeum Aqueduct) after the Grotta, while the other is the Galermi Aqueduct.\n\nDuring one of his trips to Syracuse in the second half of the 1700s, the painter Jean-Pierre Houël depicted the Grotta del Ninfeo as he found it. The gouache shows a much deeper grotta than today, with water descending towards the theatre, where the mills were installed. In the grotta, some women are busy making cloth.\n\n"}
{"id": "19227131", "url": "https://en.wikipedia.org/wiki?curid=19227131", "title": "HIV/AIDS in Egypt", "text": "HIV/AIDS in Egypt\n\nWith less than 1 percent of the population estimated to be HIV-positive, Egypt is a low-HIV-prevalence country. However, between the years 2006 and 2011, HIV prevalence rates in Egypt increased tenfold. Until 2011, the average number of new cases of HIV in Egypt was 400 per year. But, in 2012 and 2013 it increased to about 600 new cases and in 2014 it reached 880 new cases per year. According to UNAIDS 2016 statistics, there are about 11,000 people currently living with HIV in Egypt. However, unsafe behaviors among most-at-risk populations and limited condom usage among the general population place Egypt at risk of a broader epidemic.\n\nAmong officially reported cases, heterosexual intercourse is the primary mode of transmission of HIV (49.1 percent), followed by homosexual intercourse (22.9 percent), renal dialysis (12 percent), and blood transfusion (6.2 percent), according to the National Aids Program (NAP) in an official report issued in January 2008. Males are four times more likely to have HIV than females, but this may be due to more men being tested than women. Other people likely to be exposed to HIV in Egypt include street children, prisoners, and refugees. A United States Agency for International Development (USAID) funded Biological-Behavioral Surveillance Survey was conducted by the Ministry of Health and Population (MOHP) to explore HIV prevalence rates among most-at-risk groups. The survey targeted street children, female sex workers (FSWs), men who have sex with men (MSM), and injecting drug users (IDUs). The study identified an infection rate of 6.9 percent and 7.7 percent in MSM and intravenous drug users respectively. These statistics fuel some of the hypotheses that there is a concentrated HIV epidemic occurring in Egypt among high-risk groups, but due to social stigma and lack of prevalence data, it is not acknowledged. Nonetheless, over time, the Egyptian government has made efforts to improve the lives of people with HIV and AIDS in the country.\n\nEgypt reported its first case of HIV/AIDS in 1986. This was about the same time that other countries in the Middle East and North Africa region also started seeing their first cases of HIV. In 1987, one year after the discovery of the disease in Egypt, the National Aids Program (NAP) in Egypt was formed. By March 1993, there were 359 people infected with HIV. In 1990, the NAP tested over 135,000 blood bags and only four were HIV positive. Still, many of the early cases came from infected blood products or dialysis. In 1993, approximately 60 kidney dialysis patients became infected with HIV, while in 1997 about 20 people became HIV positive from infected blood transfusions.\n\nIn the early 90's several studies suggested that there was overall a very low, presence of HIV in the MENA region. By the end of 1996 only 27,000 people in the region died of HIV related causes while in Europe and sub-Saharan Africa that number was 170,000 and 4.6 million respectively. But, over time, research revealed that there were more HIV cases in the region than accounted for. Still, the HIV prevalence rate in MENA is less than that of Tuberculosis and Diabetes. In 2009, the United Nations Development Program placed the MENA region in the lowest category for antiretroviral therapy (ART) access in the years 2003-2006, but access has improved over time. Even though great progress has been made in the HIV continuum and the general understanding of the disease globally, progress in the MENA region has been limited due to lack of data and surrounding controversy. While it is estimated that only two percent of people with HIV are from the MENA area, the region has one of the fastest growing epidemics. Initially, many people were unconcerned about the disease due to its stigmatization, allowing the HIV epidemic to become more of an issue as time progressed. This is especially true in the MENA region where people thought, and some still do, that HIV only effects marginalized groups such as MSM and IDUs. Thus, those who didn't identify with these groups dismissed HIV as an insignificant issue.\n\nIn Egypt, HIV is most prevalent in high risk groups including street children, female sex workers (FSWs), men who have sex with men (MSM), and injecting drug users (IDUs). Globally, the average percentage of HIV infections through blood transfusions/products is only 5 percent. However, in Egypt, about 24 percent of all its known HIV cases are from infected blood products. There's also been five outbreaks in renal dialysis because of unsterile equipment. While the MOHP established an infection control program in 2003, controlling these infections is still challenging due to lack of training, proper equipment, and the fragile Egyptian health care system. In regards to intravenous drug use, between 16 percent and 41 percent of recreational drug users in Egypt use injected drugs, and about half of those have shared or reused syringes. One study explored sexual relations within the Egyptian population to determine prominence of HIV transmission and found that of the 74 percent in the study that were sexually active, 15 percent had more than three partners in the last month and 58 percent had never used a condom. About 26 percent of all HIV cases in Egypt occur in MSM and studies conducted by the NAP revealed very low rates of condom usage, along with multiple sexual partners among the MSM population. Additionally, many of the transmission cases are due to disease and to foreigners visiting or citizens living outside of the country, fueling some people's beliefs that HIV is a western disease. Although HIV prevention is not as comprehensive in Egypt as other parts of the world, the conservative religious beliefs in the country, both of the Muslim majority and the Coptic minority, provide their own form of protection. For instance, they frown upon promiscuity, homosexuality, and sex before marriage. These religious norms, along with widespread male circumcision, have resulted in decreased HIV transmission rates. However, over-reliance on the protection created by religious and cultural values has made HIV stigma and denial a problem. The protection that these values provide is counterbalanced by the stigma and discrimination that accompany those who defy these boundaries, leading to less HIV testing and treatment. Thus, the overall net impact on prevention is modest.\n\nEgypt still faces several challenges in maintaining low prevalence of HIV/AIDS. There is a general reluctance on the part of the government and civil society to discuss issues related to marginalized groups such as MSM, FSWs, and IDUs. The conservative nature of Egyptian society stigmatizes these high-risk groups, making HIV surveillance studies in Egypt more difficult. The General Penalties Laws in Egypt criminalize commercial sex work and intravenous drug use, as many other countries do. However, there are also other laws that criminalize homosexual activity, stating that it is inappropriate social conduct and an insult to religion. In some parts of Egyptian society, it is considered immoral to have HIV. Additionally, the mortality of people with HIV only seemed to justify the conservative society's view of homosexuality and promiscuity as sinful actions. These views further the cloud of stigma and shame associated with having HIV in Egypt and prevent people from utilizing the HIV testing services.\n\nIn addition, there a lack of effective STI/HIV/AIDS education programs and other preventive measures, such as peer education, outreach work, and behavior change communications among at-risk groups. This stems from the lack of overall knowledge about the disease. According to recent studies, there is an imminent need for improved education of healthcare workers about HIV/AIDS in Egypt. Specifically, a 2016 study performed at Tanta University Hospital in Tanta, Egypt revealed that there were high levels of discrimination and stigma against people living with HIV among health care workers. Overall, of the 310 studied participants, 40 percent said that they would be worried about providing care to HIV patients. About 21.3 percent said they would be worried about touching cloths of patients with HIV, 27.4 percent said they'd be scared to get blood samples from people with HIV, and 26.4 percent said they'd be worried to dress HIV patients' wounds. Additionally, 34.8 percent of the physicians studied and 65.8 percent of the nurses believed that irresponsible behavior led to patients' HIV infections.\n\nA collaboration between UNAIDS, the Egyptian Ministry of Health, and numerous Egyptian universities was established to help better train medical personnel to deal with the disease, as a way to fight the present stigma and misconceptions. Additionally, the lack of knowledge about the disease among Egyptian youth has the potential of greatly broadening the epidemic. In 2010, there were over 1,500 Egyptian youth (ages 15–24) with HIV. While only 11% of HIV cases in Egypt are among the youth, the early average age of sexual initiation, and increasing tendencies of premarital sex could augment these rates.\n\nBecause of the stigma around the disease, many people in Egypt are afraid to get tested for HIV. In the years before 2004, the majority of HIV cases recorded in Egypt were due to mandated testing, such as for blood donors, foreigners staying in the country for more than six months, and citizens applying for permits to work overseas. Even though voluntary testing was available, people were discouraged from utilizing these services because of the requirement that those who tested positive be identified and reported to the MOHP. According to UNAIDS statistics, about 6,500 people know of their HIV positive status, which is 57 percent of those who are infected. In 2005, the MOHP, with the help of Family Health International (An Egyptian organization funded by U.S. Agency for International Development), established a system of voluntary confidential counseling and testing (VCCT) for anonymous testing, which encouraged more people to find out their HIV status. Moreover, many people who get diagnosed with Tuberculosis get tested for HIV. More specifically, in 2010 about half of the TB patients got tested for HIV. Currently, less than 1 percent of adult TB patients are HIV-positive. However, continued monitoring is necessary because an increase in the incidence of HIV-TB co-infection could add to the complexity of fighting both diseases in Egypt.\n\nBy the end of 2006, according to UNAIDS, 22 percent of HIV-infected women and men were receiving antiretroviral therapy (ART). In 2014, about 1,323 people received ART treatment. In 2016, that number increased to 3,100 people, which is about 27 percent of the infected population. In 2010, a qualitative study was conducted to gather data about ART adherence and limitations. They interviewed 27 HIV positive Egyptian women who had been receiving ART for at least three months. The results showed that there were five key factors that served as obstacles to adherence to treatment, which were \"fear of stigma, financial constraints, characteristics of ART, social support, and reliance on faith.\"\n\nThe NAP is the official governmental body responsible for HIV/AIDS prevention. Its goal is to maintain the low prevalence of HIV/AIDS and improve health care services for those infected or affected by the disease. It performs blood screening, provides free Antiretorviral Therapy (ART) for those infected, encourages HIV testing, and provides support for those with HIV and their families. The organization also aims to raise awareness about HIV in the general public and among high risk groups, using mass media as one of the means of doing so. Additionally, they established anonymous hotlines, distributed condoms, and partnered with various non-governmental organizations (NGOs). The NAP formed the National Strategic Plan (2006–2010) to build on the successes of the previous five-year plan. It was designed to maintain the low prevalence of HIV/AIDS and improve health care services for those infected or affected by the disease. The plan's objectives included strengthening HIV/AIDS surveillance, expanding HIV/AIDS response, increasing awareness among the population, developing outreach and educational programs, growing the testing and counseling services, and improving the overall quality of life for people infected and affected by HIV.\n\nSince 2005, the Government of Egypt has become more actively involved in the fight against HIV/AIDS. The government established nine mobile VCCT (Voluntary Confidential Counseling and Testing) centers and 14 fixed centers around the country. With the help of Family Health International, it also conducted trainings for physicians and nurses on clinical management and nursing care, created self-care guides in Arabic and started to promote the use antiretroviral therapy. Additionally, the Ministry of Health has also been fighting the issue of lack of adherence to drug treatments by many HIV positive citizens. It started implementing case management programs that follow up with patients and provide psychological counseling and resources that will help the patients adhere to their specific treatments and deal with the stigma of the disease. These programs were established in numerous health centers that are associated with the Ministry of Health.\n\nIn 2006, Cairo was the site of a three-day, UNAIDS-supported workshop on HIV/AIDS and drug use in the region. The workshop included representatives of governments, non-governmental organizations (NGOs), and research programs from the Arab countries as well as from Afghanistan, Iran, and Pakistan. The Egyptian government worked with UNICEF to help prevent HIV/AIDS among youth and worked with the United Nations Office on Drugs and Crime to address HIV/AIDS among IDUs. Moreover, the Egyptian government, led by former First Lady Suzanne Mubarak, started a campaign to educate the public about HIV as a way to fight the spread of disease The government has worked to integrate HIV/AIDS into preparatory and secondary school curriculums.\n\nIn March 2008, Egypt negotiated a six-round grant with the Global Fund to Fight AIDS, Tuberculosis and Malaria with the goal of \"Reinforcing HIV/AIDS Prevention and Care Efforts in Egypt.\" The grant start date was April 1, 2008 and the end date was December 31, 2016. Throughout its duration, the project collected a cumulative amount of approximately $9 million. Some of the objectives of the project included: establishing a strong and supportive environment for the treatment and care of HIV, improving the current surveillance and monitoring data, preventing HIV transmission, including mother-to-child, reducing risk among the most impacted groups, and increasing access to treatment and other services for all people living with HIV in Egypt.\n\nOn Feb. 22, 2014, a government-sponsored public service announcement aired on an official Egyptian T.V. channel where Major General Ibrahim Abdul Atti, the chief of the Egyptian Army Medical Team, announced the military's new medical devices, C-FAST and CCD for the treatment of AIDS. The announcer made ambitious claims about the devices that the Egyptian military scientists were working on. He proclaimed that the C-FAST was a breakthrough minimally invasive device that could detect and diagnose diseases, such as HIV, with electromagnetism. At the same time, the announcement stated that another device called CCD was currently being tested in trials but had high success rates of curing AIDS through blood purification. A short video accompanied the announcement showing the supposed devices at work. However, even though many major networks and media in Egypt ran with this news, there was no scientific basis to these claims made by the military scientists. In June 2014, the military personnel went back on their claims, stating that these devices needed additional testing because their original trials did not have large enough sample sizes. Now, further research is still being conducted by military medical personnel into the treatment of HIV and the widely spread Hepatitis C virus.\n\n\n\nVideo and Photography Material related to HIV/AIDS in Egypt:\n"}
{"id": "35326416", "url": "https://en.wikipedia.org/wiki?curid=35326416", "title": "Health in Guyana", "text": "Health in Guyana\n\nCompared with other neighbouring countries, Guyana ranks poorly in regard to basic health indicators. Basic health services in the interior are primitive to non-existent, and some procedures are not available at all. Although Guyana's health profile falls short in comparison with many of its Caribbean neighbours, there has been remarkable progress since 1988, and the Ministry of Health is working to upgrade conditions, procedures, and facilities. Many Guyanese seek medical care in the United States, Trinidad and Tobago or Cuba.\n\nThe delivery of health services is provided at five different levels in the public sector:\n\nThis system is structured so that its proper functioning depends intimately on a process of referrals. Except for serious emergencies, patients are to be seen first at the lower levels, and those with problems that cannot be treated at those levels are referred to higher levels in the system. However, in practice, many patients by-pass the lower levels.\n\nThe health sector is currently unable to offer certain sophisticated tertiary services and specialised medical services, the technology for which is unaffordable in Guyana, or for which the required medical specialists are not available. Even with substantial improvements in the health sector, the need for overseas treatment for some services might remain. The Ministry of Health provides financial assistance to patients requiring such treatment, priority being given to children whose condition can be rehabilitated with significant improvements to their quality of life.\n\nThere are 10 hospitals belonging to the private sector and to public corporations, plus diagnostic facilities, clinics and dispensaries in those sectors. These ten hospitals provide for 548 beds. Eighteen clinics and dispensaries are owned by GUYSUCO.\n\nThe Ministry of Health and Labour is responsible for the funding of the National Referral Hospital in Georgetown, which has recently been made a public corporation managed by an independent Board. Region 6 is responsible for the management of the National Psychiatric Hospital. The Geriatric Hospital, previously administered by the Ministry of Labour, became the responsibility of the Ministry of Human Resources and Social Security of Guyana in December 1997.\n\nThe US State Department Consular Information Sheet warns \"Medical care is available for minor medical conditions. Emergency care and hospitalization for major medical illnesses or surgery is limited, because of a lack of appropriately trained specialists, below standard in-hospital care, and poor sanitation. Ambulance service is substandard and may not routinely be available for emergencies.\" Many Guyanese seek medical care in the United States, Trinidad and Tobago or Cuba.\n\nIn 2012, life expectancy at birth was estimated at 71.0 years.\n\nThe leading causes of mortality for all age groups are cerebrovascular diseases (11.6%); ischemic heart disease (9.9%); immunity disorders (7.1%); diseases of the respiratory system (6.8%); diseases of pulmonary circulation and other forms of heart disease (6.6%); endocrine and metabolic diseases (5.5%); diseases of other parts of the Digestive System (5.2%); violence (5.1%); certain condition originating in the prenatal period (4.3%); and hypertensive diseases (3.9%). The ten leading causes of morbidity for all age groups are, in decreasing order: malaria; acute respiratory infections; symptoms, signs and ill defined or unknown conditions; hypertension; accident and injuries; acute diarrhoeal disease; diabetes mellitus; worm infestation; rheumatic arthritis; and mental and nervous disorders.\n\nThis morbidity profile indicates that it can be improved substantially through enhanced preventive health care, better education on health issues, more widespread access to potable water and sanitation services, and increased access to basic health care of good quality. A number of non-governmental organisations, including Health and Educational Relief for Guyana (HERG, INC) and Guyana Medical Relief (GMR, INC) are currently working to address these issues by improving healthcare access and educational infrastructure.\n\nSuicide is a leading cause of death in Guyana. Guyana suffers from the highest suicide rate of any South American country. In 2008 it was estimated that at least 200 people commit suicide each year in Guyana, or 27.2 people for each 100,000 people each year.\n\nIn 2008 Guyana had a murder rate of 26 per 100,000.\n\nThe 2010 maternal mortality rate per 100,000 births for Guyana is 260. This is compared with 143.1 in 2008 and 162.3 in 1990. The under 5 mortality rate, per 1,000 births is 36 and the neonatal mortality as a percentage of under 5's mortality is 60. In Guyana the number of midwives per 1,000 live births is unavailable and the lifetime risk of death for pregnant women is 1 in 150.\n"}
{"id": "15985948", "url": "https://en.wikipedia.org/wiki?curid=15985948", "title": "Health in Malaysia", "text": "Health in Malaysia\n\nMalaysia is classified by The World Bank as upper middle income country and is attempting to achieve high-income status by 2020 and to move further up the value-added production chain by attracting investments in high technology, knowledge-based industries and services. Malaysia’s HDI value for 2015 was recorded at 0.789 and HDI rank no 59 out of 188 countries and territories on the United Nations Development Programme’s Human Development Index. In 2016, the population of Malaysia is 31,000 millions; Total expenditure on health per capita (Intl $, 2014) is 1040; Total expenditure on health as % of GDP (2014) was 4.2 Gross national income (GNI) per capita (2011 PPP$) was recorded at 24,620 \nMalaysia is classified as High Human Development (HDI) country with HDI of 0.789 in the year of 2015 while average annual income growth in the year 2015 is 0.85%. \n\nIn 2016, neonatal mortality rate for Malaysia was recorded at 4.4 deaths per 1,000 live births. Between 1967 and 2016, neonatal mortality rate of Malaysia was has shown a declinine at a moderating rate to shrink from 16.6 deaths per 1,000 live births in 1967 to 4.1 deaths per 1,000 live births in 2016. Infant mortality rate for Malaysia in 2016 was 7.1 deaths per 1,000 live births. Infant mortality rate fell gradually from 46.8 deaths per 1,000 live births in 1967 to 7.1 deaths per 1,000 live births in 2016. Under-5 mortality rate for Malaysia in the year 2015 was 7.45 deaths per thousand live births. It is shown that Under-5 mortality rate of Malaysia showed decreased from 70.31 deaths per thousand live births in 1966 to 7.45 deaths per thousand live births in 2015. Maternal mortality ratio for Malaysia at 2015 was 40 deaths per 100,000 live births. Maternal mortality ratio of Malaysia recorded a gradual decrease from 65 deaths per 100,000 live births in 1996 to 40 deaths per 100,000 live births in 2015. \n\nIn the year 2016, global average of life expectancy at birth for both sexes was 72.0 years. Life expectancy at birth for Malaysia in the year 2016 for both sexes was 75.3 years. Japan has the highest life expectancy at birth for both sexes in the year 2016 which is 84.2.\n\nDeath rate for Malaysia in 2016 was 4.9 per 1,000 people. Death rate of Malaysia has decreased from 8 per 1,000 people in 1967 to 4.9 per 1,000 people in 2016. A total of 162,201 deaths were recorded in the year 2016 and there is an increase of 4.1% as compared to 2015 with 155,786. \n\nDepartment of statistic Malaysia reported in the press release statistics on causes of death, Malaysia 2017 that the principle causes of death in the year 2016 was ischaemic disease (13.2 per cent), followed by pneumonia (12.5%), cerebrovascular diseases (6.9%), transport accidents (5.4%) and malignant neoplasm of trachea, bronchus & lung (2.2%). In 2016, the Ischemic heart disease was the principle cause of death for males. Deaths due to ischaemic heart diseases recorded the highest percentage for males (15.3%), followed by pneumonia of 11.5%, 7.5% for transport accidents, cerebrovascular diseases accounts for 6.4% and 2.4% malignant neoplasm of trachea, bronchus & lung. For women, the principle cause of death was pneumonia. Deaths due to pneumonia (14%) recorded the highest percentage for females in 2016, ischaemic heart diseases followed next at 9.9%, cerebrovascular diseases account for 7.6%, 3.8% for malignant neoplasm of breast and 2.2% for transport accident.\n\nThe under 5 mortality rate was 8.3 per 1000 live birth in the year of 2016. \nThe major cause of under 5 death in 2016 is due to certain conditions originating in the perinatal period and it is recorded at 35.0%, followed by 27.2% for congenital malformations, deformations & chromosomal abnormalities, pneumonia (3.8%), transport accidents (1.8%) and 1.1% accidental drowning & submersion. As much as 77.0% of infant deaths were due to five principal causes of death which include certain conditions originating in the perinatal period (41.9%); 30.5% congenital malformations, deformations & chromosomal abnormalities; 3.0% of pneumonia; chronic lower respiratory disease (0.9%); and meningitis (0.7%).\n\nThe main causes of maternal deaths was due to obstetric embolism, it is recorded at 23.0%, followed by complicating pregnancy, childbirth & the puerperium (18.2%), postpartum haemorrhage (11.5%), ectopic pregnancy (6.8%) and eclampsia (6.1%). However, the percentage of deaths due to obstetric embolism in 2016 recorded a decline from 27.4 to 23.0 per cent as compared to 2015. \n\nLeptospirosis is a water contract disease caused by bacteria of the genus Leptospirabacterial. It is a disease that affects both humans and animals. The number of leptospirosis cases had steadily increased from 2011 (2,268 cases with 55 death) to 2015 (8,291 cases with 78 death) and 5,284 cases with 52 death in 2016. Leptospirosis can have important health impact and is a burden to the nation if not well controlled. Addressing leptospisoris includes maintain a clean environment and by not swimming or wading in water that might be contaminated with animal urine, or eliminating contact with potentially infected animals.\n\nThe largest contribution to mortality is non communicable disease. 40 million people each year die from noncommunicable diseases (NCDs) and accounted for 70% of global deaths annually. From 1996 to 2011 the proportion of the population who are obese increased from 5% to 15%. In 2015, National Health Morbidity Survey (NHMS) revealed that the overall prevalence of two out of three major risk factors contributing to non-communicable disease (NCD) remained high for diabetes mellitus and hypercholesterolemia. The prevalence of hypertension has shown a decreased 2.4% in the study done nationwide. The current prevalence (Year 2017) of hypertension in Malaysia is 30.3%, which is lower than the prevalence in 2011 and 2006 with 32.7% and 32.2% respectively.The prevalence of hypercholesterolemia has increased to 47.7% in 2017 from 32.6% in 2011 \nRisk factors for noncommunicable diseases include tobacco use, reduced physical activity, alcohol abuse and unhealthy food consumption. Risk factors for noncommunicable diseases include tobacco use, reduced physical activity, alcohol abuse and unhealthy food consumption. Managing the risk factor as well as early detection of disease is the key to combat non communicable diseases besides than policy coherence across all levels of government at the national and international level.\n\nPrevalence of HIV as a share of population aged 15-49 in 2016, was 0.4 % and has fallen gradually from 0.7% in 1997 to 0.4% in 2016.\nIncidence of tuberculosis fluctuated substantially in recent years through 2002 - 2016 and in the year 2016, incidence of tuberculosis for Malaysia was 92 cases per 100,000 people.\n\nIn Malaysia, mass vaccination is practised in public schools. The vaccines may be administered by a school nurse or a team of other medical staff from outside the school. All the children in a given school year are vaccinated as a cohort. For example, children may receive the oral polio vaccine in Year One of primary school (about six or seven years of age), the BCG in Year Six, and the MMR in Form Three of secondary school. Therefore, most people have received their core vaccines by the time they finish secondary school.\n\n"}
{"id": "5143567", "url": "https://en.wikipedia.org/wiki?curid=5143567", "title": "Imago therapy", "text": "Imago therapy\n\nImago relationship therapy is a form of marriage therapy that takes a relationship approach rather than an individual approach to problem solving in a marriage . It was codeveloped by Dr. Harville Hendrix and Dr. Helen LaKelly Hunt, and documented in Hendrix's 1988 book, \"Getting the Love You Want, A Guide for Couples.\" Hendrix and Hunt selected the word \"imago,\" the Latin word for \"image,\" as a name for the \"unconscious image of the opposite sex that you had been forming since birth.\" In February 2012, the BBC aired a Wonderland documentary that included an imago relationship therapy workshop on the cruise ship \"MS Golden Iris\".\n\nImago therapy focuses on collaboratively healing childhood wounds couples share. According to Hendrix and Hunt, the human brain has a compelling non-negotiable drive to restore feelings of aliveness and wholeness with which people came into the world. It is believed by imago therapists that a person's brain constructs an image of characteristics from their primary caretakers including both their best and worst traits. The brain's unconscious drive is to repair damage done in childhood, needs not met, by finding a partner who can give us what our caretakers failed to provide. This is why traits of a future partner often reflect our parents' traits. Our unconscious drives towards this to seek healing and to resolve unresolved childhood wounds, in order to grow. In this way, wounds received by a person, from their parents, tend to be re-stimulated by new adult partners and potential partners. The re-stimulation triggers old, unresolved emotions. Both people in the relationship can learn how to heal one another, and appreciate each other for the person they are--and--it takes time. Couples must engage in a specific type of dialogue for Imago therapy to work. The conscious self may not be able to see and understand clearly the reflection of unresolved parental issues in his or her current marriage partner. Nonetheless, our unconscious connects with this person in its best (unconscious) effort to heal old wounds and allow love into your life again. \n\n"}
{"id": "53354244", "url": "https://en.wikipedia.org/wiki?curid=53354244", "title": "International Association of Dental Students", "text": "International Association of Dental Students\n\nThe International Association of Dental Students (IADS) is a non-governmental organization representing interests of dental students worldwide. It was founded in August 1951 in Copenhagen, Denmark and currently has more than 200,000 students from 60 countries of six world continents.\n\nIn February 1951, the national organization of French stomatology students invited some of their colleagues from other countries to attend their annual meeting in Paris, France where the Danish, Dutch and Swedish representatives proposed to establish international dental students' organization. Such proposal was unanimously welcomed.\n\nA committee consisting of representatives from Denmark, the Netherlands and the United Kingdom was formed to work out the basic principles on which to build the constitution of the association. This constitution was drafted and the first executive committee was elected; Leslie Sorling from Sweden was elected the first president.\n\nTwo international meetings take place each year to offer the opportunity for dental students delegates to come together to discuss their current issues and future strategies. One of these two meetings is called the Mid Year Meeting (MYM) and usually takes place by the end of each winter, while the other one is the Annual Congress (AC) which takes place by the end of each summer.\n"}
{"id": "52846005", "url": "https://en.wikipedia.org/wiki?curid=52846005", "title": "James Jamieson (dentist)", "text": "James Jamieson (dentist)\n\nDr James Dalgleish Hamilton Jamieson FRSE FDSE (1875-1966) was a Scottish dentist and author.\n\nHe was born on 10 September 1875 at 52 Rankeillor Street, a ground floor and basement flat in Edinburgh’s South Side, the son of James Jamieson (1841-1905), a surgeon, and his wife, Agnes Boyd. He was educated at George Watsons College. He then studied Dentistry at Edinburgh University graduating in 1899.\n\nHe practiced as a dental surgeon from 52 George Square in Edinburgh’s South Side 1899 to 1955, and also seemed to have lived at the same address. The building was demolished by Edinburgh University in the 1960s. The Royal College of Surgeons of Edinburgh awarded him an honorary doctorate in 1920.\nFrom 1930 until 1951 he lectured in Dental Disorders at Edinburgh University.\n\nIn 1938 he was elected a Fellow of the Royal Society of Edinburgh. His proposers were Francis Albert Eley Crew, Charles Henry O’Donoghue, Edwin Bramwell, and John Walton.\n\nHe died at New Malden in Surrey on 21 September 1966 aged 91. He was returned to Edinburgh for burial in the family plot in the south-east section of Grange Cemetery in Edinburgh.\n\nHe was married to Jessie Ann Fergusson Ireland (d.1949).\n\n"}
{"id": "5579978", "url": "https://en.wikipedia.org/wiki?curid=5579978", "title": "Jessore Medical College", "text": "Jessore Medical College\n\nJessore Medical College () is a government medical school in Bangladesh, established in 2010. It is located at Horinar Beel near Chanchra New Bus Terminal in Jessore District.\n\nIt provides 5 year MBBS degree and it offers all the opportunities of advanced medical science. One-year internship after graduation is compulsory for all graduates. The degree is recognized by the Bangladesh Medical and Dental Council.\n\nThe government felt the need for more medical colleges for medical education facilities. The government started establishing medical colleges at notable districts. As a result, Jessore Medical College was established in 2010. Jessore Medical College is continuing its hospital activity at Jessore 250 Beds General Hospital.\n\nIts main campus is situated at Horinar Beel near Chanchra New Bus Terminal in Jessore Sadar Upazila\n\nJessore Medical College is affiliated under Rajshahi University. The students receive MBBS degree from Rajshahi University after completion of their fifth year and passing the final Professional MBBS examination. The Professional examinations are held under the university and results are given thereby. Internal examinations are also taken on regular interval namely Card completions, term end and regular assessments.\n\nJessore Medical College admits 57 students into the MBBS degree programme yearly under the government medical admission test. JMC is under DGHS and curriculum by BMDC (Bangladesh Medical and Dental Council). Like other government medical colleges, to be admitted into Jessore Medical College need to be follow DGHS rules.\n\nThe admission test is conducted centrally by Director of Medical Education under DGHS (nearly 70,000 applicants sat for the medical college entrance examination in Bangladesh). The test comprises a written MCQ exam, which is held simultaneously in all government medical colleges on the same day throughout the country. Candidates are selected for admission based on national merit and district, whether they are sons or daughters of freedom fighters and to fill tribal quotas. For foreign students, admission is through the embassy of Bangladesh in their respective countries.\n\n\n"}
{"id": "55522412", "url": "https://en.wikipedia.org/wiki?curid=55522412", "title": "Kim Barrett", "text": "Kim Barrett\n\nKim E. Barrett is a research physiologist, specialising in digestive disorders such as inflammatory bowel disease. Her positions have included Professor of Medicine and Dean of Graduate Studies at UCSD; Editor-in-Chief of The Journal of Physiology and President of the American Physiological Society.\n\nKim achieved her PhD in Biological Chemistry and her BSc in Medicinal Chemistry, both from University College London in 1982 and 1979 respectively. \n\nIn 2015 she was awarded the Bayliss-Starling Prize Lecturer by The Physiological Society. \n\nHer key research activities have included Neuroimmunophysiology in the Gastrointestinal Tract, Intestinal Secretory Mechanisms and Bypassing the secretory defect in cystic fibrosis. \n"}
{"id": "11212161", "url": "https://en.wikipedia.org/wiki?curid=11212161", "title": "List of political parties in Middle Africa by country", "text": "List of political parties in Middle Africa by country\n"}
{"id": "11538870", "url": "https://en.wikipedia.org/wiki?curid=11538870", "title": "MECACAR", "text": "MECACAR\n\nOperation MECACAR (currently known as MECACAR New Millennium) is a multi-national immunization program launched in 1995 by the World Health Organization to coordinate polio vaccination efforts (currently it is also used to coordinated measles and rubella vaccination efforts). The name of the operation was derived from the names of the regions participating in the operation: Eastern Mediterranean, Caucasus, Central Asian Republics and Russia. Currently, 18 countries are participating and more than 60 million children have been vaccinated.\n\nThe operation was launched to \"maximize the geographic area covered and the number of children targeted simultaneously for mass vaccination with OPV\". It introduced \"National Immunization Days\", held at the same dates in bordering member countries; and also coordinated the efforts of different laboratories.\n\nAfter Europe was declared polio-free in 2002, MECACAR's objectives became maintaining polio-free status in the region and also achieve measles and rubella elimination.\nOn May 17, 2007, the MECACAR New Millennium declaration was signed. The event took place in Geneva.\n\n"}
{"id": "32592400", "url": "https://en.wikipedia.org/wiki?curid=32592400", "title": "Meldonium", "text": "Meldonium\n\nMeldonium (INN; trade name Mildronate, among others) is a limited-market pharmaceutical, developed in 1970 by Ivars Kalviņš at the USSR Latvia Institute of Organic Synthesis, and now manufactured by the Latvian pharmaceutical company Grindeks and several generic manufacturers. It is primarily distributed in Eastern European countries as an anti-ischemia medication.\n\nSince 1 January 2016, it has been on the World Anti-Doping Agency (WADA) list of substances banned from use by athletes. However, there are debates over its use as an athletic performance enhancer. Some athletes are known to have been using it before it was banned. It is currently unscheduled in the US.\n\nMeldonium may be used to treat coronary artery disease. These heart problems may sometimes lead to ischemia, a condition where too little blood flows to the organs in the body, especially the heart. Because this drug is thought to expand the arteries, it helps to increase the blood flow as well as increase the flow of oxygen throughout the body.\nMeldonium has also been found to induce anticonvulsant and antihypnotic effects involving alpha 2-adrenergic receptors as well as nitric oxide-dependent mechanisms. This, in summary, shows that meldonium given in acute doses could be beneficial for the treatment of seizures and alcohol intoxication. It is also used in cases of cerebral ischemia, ocular ischemic syndrome and other ocular disease caused by disturbed arterial circulation and may also have some effect on decreasing the severity of withdrawal symptoms caused by the cessation of chronic alcohol use.\n\nTo ensure a continuous guarantee of energy supply, the body oxidises considerable amounts of fat besides glucose. Carnitine transports activate long-chain fatty acids (FA) from the cytosol of the cell into the mitochondrion and is therefore essential for fatty acid oxidation (known as beta oxidation). Carnitine is mainly absorbed from the diet, but can be formed through biosynthesis. To produce carnitine, lysine residues are methylated to trimethyllysine. Four enzymes are involved in the conversion of trimethyllysine and its intermediate forms into the final product of carnitine. The last of these 4 enzymes is gamma-butyrobetaine dioxygenase (GBB), which hydroxylates butyrobetaine into carnitine.\n\nThe main cardioprotective effects are mediated by the inhibition of the enzyme GBB. By subsequently inhibiting carnitine biosynthesis, fatty acid transport is reduced and the accumulation of cytotoxic intermediate products of fatty acid beta-oxidation in ischemic tissues to produce energy is prevented, therefore blocking this highly oxygen-consuming process. Treatment with meldonium therefore shifts the myocardial energy metabolism from fatty acid oxidation to the more favorable oxidation of glucose, or glycolysis, under ischemic conditions. It also reduces the formation of Trimethylamine N-oxide, a product of carnitine breakdown and implicated in the pathogenesis of atherosclerosis and congestive heart failure.\n\nIn the mitochondria, the effects of the carnitine shuttle are reduced by meldonium, which competitively inhibits the SLC22A5 transporter. This results in reduced transportation and metabolism of long-chain fatty acids in the mitochondria (this burden is shifted more to peroxisomes). The final effect is a decreased risk of mitochondrial injury from fatty acid oxidation and a reduction of the production of acylcarnitines, which has been implicated in the development of insulin resistance. Because of its inhibitory effects on L-carnitine biosynthesis and its subsequent glycolytic effects as well as reduced acylcarnitine production, meldonium has been indicated for use in diabetic patients. In an animal models and a very small clinical trial, meldonium has been shown to reduce blood glucose concentrations, exhibit cardioprotective effects and prevent or reduce the severity of diabetic complications. Long term treatment has also been shown to attenuate the development of atherosclerosis in the heart.\n\nIts vasodilatory effects are stipulated to be due to the stimulation of the production of nitric oxide in the vascular endothelium. It is hypothesized that meldonium may increase the formation of the gamma-butyrobetaine esters, potent parasympathomimetics and may activate the eNOS enzyme which causes nitric oxide production via stimulation of the M3 muscarinic acetylcholine receptor or specific gamma-butyrobetaine ester receptors.\n\nMeldonium is believed to continually train the heart pharmacologically, even without physical activity, inducing preparation of cellular metabolism and membrane structures (specifically in myocardial mitochondria) to survive ischemic stress conditions. This is done by adapting myocardial cells to lower fatty acid inflow and by activating glycolysis; the heart eventually begins using glycolysis instead of beta oxidation during real life ischaemic conditions. This reduces oxidative stress on cells, formation of cytotoxic products of fatty acid oxidation and subsequent cellular damage. This has made meldonium a possible pharmacological agent for ischemic preconditioning.\n\nHow the central nervous system effects of meldonium is brought about is unclear. Studies have shown that meldonium increases cognition and mental performance in animal models of Alzheimer's disease by reducing amyloid beta deposition in the hippocampus.\n\nAlthough initial reports suggested meldonium is a non-competitive and non-hydroxylatable analogue of gamma-butyrobetaine; further studies have identified that meldonium is a substrate for gamma-butyrobetaine dioxygenase. X-ray crystallographic and \"in vitro\" biochemical studies suggest that meldonium binds to the substrate pocket of γ-butyrobetaine hydroxylase and acts as an alternative substrate, and therefore a competitive inhibitor. Normally, this enzyme's action on its substrates γ-butyrobetaine and 2-oxoglutarate gives, in the presence of the further substrate oxygen, the products L-carnitine, succinate, and carbon dioxide; in the presence of this alternate substrate, the reaction yields malonic acid semialdehyde, formaldehyde (akin to the action of histone demethylases), dimethylamine, and (1-methylimidazolidin-4-yl)acetic acid, \"an unexpected product with an additional carbon-carbon bond resulting from N-demethylation coupled to oxidative rearrangement, likely via an unusual radical mechanism.\" The unusual mechanism is thought likely to involve a Steven's type rearrangement.\n\nMeldonium's inhibition of γ-butyrobetaine hydroxylase gives a half maximal inhibitory concentration (IC) value of 62 micromolar, which other study authors have described as \"potent.\" Meldonium is an example of an inhibitor that acts as a non-peptidyl substrate mimic.\nThe chemical name of meldonium is 3-(2,2,2-trimethylhydraziniumyl) propionate. It is a structural analogue of γ-butyrobetaine, with an amino group replacing the C-4 methylene of γ-butyrobetaine. γ-Butyrobetaine is a precursor in the biosynthesis of carnitine.\nMeldonium is a white crystalline powder, with a melting point of .\n\nMeldonium was added to the World Anti-Doping Agency (WADA) list of banned substances effective 1 January 2016 because of evidence of its use by athletes with the intention of enhancing performance. It was on the 2015 WADA's list of drugs to be monitored. An alarmingly high prevalence of meldonium use by athletes in sport was demonstrated by the laboratory findings at the Baku 2015 European Games. 13 medallists or competition winners were taking meldonium at the time of the Baku Games. Meldonium use was detected in athletes competing in 15 of the 21 sports during the Games. Most of the athletes taking meldonium withheld the information of their use from anti-doping authorities by not declaring it on their doping control forms as they should have. Only 23 of the 662 (3.5%) athletes tested declared the personal use of meldonium. However, 66 of the total 762 (8.7%) of athlete urine samples analysed during the Games and during pre-competition tested positive for meldonium.\n\nWADA classes the drug as a metabolic modulator, just as it does insulin. Metabolic modulators are classified as S4 substances according to the WADA banned substances list. These substances have the ability to modify how some hormones accelerate or slow down different enzymatic reactions in the body. In this way, these modulators can block the body's conversion of testosterone into oestrogen, which is necessary for females. Based on the overall effects these drugs have, they have been banned since 2001 from men's competitions and 2005 for women's.\nOn April 13, 2016 it was reported that WADA had issued updated guidelines allowing less than 1 microgram per milliliter of meldonium for tests done before March 1, 2016. The agency cited that \"preliminary tests showed that it could take weeks or months for the drug to leave the body\".\n\nOn March 7, 2016, former world number one tennis player Maria Sharapova announced that she had failed a drug test in Australia due to the detection of meldonium. She said that she had been taking the drug for ten years for various health issues, and had not noticed that it had been banned. On June 8, 2016, she was suspended from playing tennis for two years by the International Tennis Federation (ITF). Earlier the same year (March 7), Russian ice dancer Ekaterina Bobrova announced that she had also tested positive for meldonium at the 2016 European Figure Skating Championships. Bobrova said she was shocked about the test result, because she had been made aware of meldonium's addition to the banned list, and had been careful to avoid products containing banned substances. In May 2016, Russian professional boxer Alexander Povetkin—a former two-time World Boxing Association (WBA) Heavyweight Champion—tested positive for meldonium. This was discovered just a week prior to his mandatory title match against World Boxing Council (WBC) Heavyweight Champion, Deontay Wilder. As a result, the match—scheduled to take place in Povetkin's native Russia—was postponed indefinitely by the WBC.\n\nOther athletes who are provisionally banned for using meldonium include Ethiopian-Swedish middle-distance runner Abeba Aregawi, Ethiopian long-distance runner Endeshaw Negesse, Russian cyclist Eduard Vorganov, and Ukrainian biathletes Olga Abramova and Artem Tyshchenko.\n\nThe Ice Hockey Federation of Russia replaced the Russia men's national under-18 ice hockey team with an under-17 team for the 2016 IIHF World U18 Championships after players on the original roster tested positive for meldonium.\n\nMore than 170 failed tests by athletes were identified in a relatively brief period after the ban on meldonium was imposed on January 1, 2016, almost all of which were from Eastern European countries, with much smaller numbers since. Many of the early cases were dropped when athletes claimed that they had ceased use in 2015, with the claim often consistent with the low concentrations of the drug in their samples. Notable athletes with positive samples include:\n\nIn addition it was reported that five Georgian wrestlers and a German wrestler had tested positive for the drug although no further names were released. On 25 March 2016 the Fédération Internationale de Sambo confirmed that four wrestlers under their governance (two from Russia and two from other countries) had recorded positive tests for the drug.\n\nA December 2015 study in the journal \"Drug Testing and Analysis\" argued that meldonium \"demonstrates an increase in endurance performance of athletes, improved rehabilitation after exercise, protection against stress, and enhanced activations of central nervous system (CNS) functions\". However the study itself presents no evidence for this claim, and focuses instead on describing two approaches for the reliable identification of meldonium. It is also believed that meldonium is opposing to steroids in the sense that instead of making the athlete emotionally unstable and readily irritable, it keeps them in an elevated state of mind and keeps their emotions in a happier state. When referring to central nervous system enhancements, it better activates the neurons in the CNS. This improves the messaging system throughout the body and, therefore, can decrease (improve) reaction time for an athlete.\n\nThe manufacturer, Grindeks, said in a statement that it did not believe meldonium’s use should be banned for athletes. It said the drug worked mainly by reducing damage to cells that can be caused by certain byproducts of carnitine. Meldonium “is used to prevent death of ischemic cells and not to increase performance of normal cells,” the statement said. “Meldonium cannot improve athletic performance, but it can stop tissue damage in the case of ischemia,” which is lack of blood flow to an area of the body.\n\nThe drug was invented in the mid-1970s at the Institute of Organic Synthesis of the Latvian SSR Academy of Sciences by Ivars Kalviņš. Kalviņš criticized the ban, saying that WADA had not presented scientific proof that the drug can be used for doping. According to him, meldonium does not enhance athletic performance in any way, and was rather used by athletes to prevent damage to the heart and muscles caused by lack of oxygen during high-intensity exercise. He contended that not allowing athletes to take care of their health was a violation of their human rights, and that the decision aimed to remove Eastern European athletes from competitions and his drug from the pharmaceutical market. Liene Kozlovska, the head of the anti-doping department of the Latvian sports medicine center, rejected claims that the ban is in violation of athletes' rights, saying that meldonium is dangerous in high doses, and should only be used under medical supervision to treat genuine health conditions. She also speculated that Russian athletes may not have received adequate warnings that the drug was banned – due to the suspension of the Russian Anti-Doping Agency in late 2015.\n\nForbes reported that anesthesiology professor Michael Joyner, at the Mayo Clinic in Rochester, Minnesota, who studies how humans respond to physical and mental stress during exercise and other activities, told them that \"Evidence is lacking for many compounds believed to enhance athletic performance. Its use has a sort of urban legend element and there is not much out there that is clearly that effective. I would be shocked if this stuff [meldonium] had an effect greater than caffeine or creatine (a natural substance that, when taken as a supplement, is thought to enhance muscle mass).” Ford Vox, a U.S.-based physician specializing in rehabilitation medicine and a journalist reported \"there's not much scientific support for its use as an athletic enhancer\".\n\nDon Catlin, a long-time anti-doping expert and the scientific director of the Banned Substances Control Group (BSCG) said “There’s really no evidence that there’s any performance enhancement from meldonium – Zero percent.”\n\nMeldonium, which is not approved by the FDA in the United States, is registered and prescribed in Latvia, Russia, Ukraine, Georgia, Kazakhstan, Azerbaijan, Belarus, Uzbekistan, Moldova, Lithuania and Kyrgyzstan.\n\nMeldonium is manufactured by Grindeks, a Latvian pharmaceutical company, with offices in thirteen Eastern European countries as a treatment for heart conditions. The company identifies it as one of their main products. It had sales of 65 million euros in 2013.\n"}
{"id": "26267037", "url": "https://en.wikipedia.org/wiki?curid=26267037", "title": "National Hospital (Niamey)", "text": "National Hospital (Niamey)\n\nThe National Hospital is a hospital in Niamey, Niger. It has 244 beds. The hospital was founded in 1922.\n\nThe hospital provides a wide range of services to residents of Niamey and the greater region. As of September, 2018 the National Hospital has two Otolaryngologists, two Ophthalmologists, five Radiologists, three Cardiologists, three Dermatologists, four Obsetricians/Gynecologists, five dentists and one psychiatrist.\n"}
{"id": "30993607", "url": "https://en.wikipedia.org/wiki?curid=30993607", "title": "National Malaria Eradication Program", "text": "National Malaria Eradication Program\n\nIn the United States, the National Malaria Eradication Program (NMEP) was launched on 1 July 1947. This federal programwith state and local participationhad succeeded in eradicating malaria in the United States by 1951.\n\nPrior to the establishment of the NMEP, malaria had been endemic across much of the United States. By the 1930s, it had become concentrated in 13 southeastern states. (For example, in the Tennessee River Valley it had a prevalence of about 30% in 1933.)\n\nA national malaria eradication effort was originally proposed by Louis Laval Williams. The NMEP was directed by the federal Communicable Disease Center (now the Centers for Disease Control and Prevention, or CDC) created in 1946 and based in Atlanta, Georgia. It was a cooperative undertaking by federal, state and local health agencies. The Program had evolved from the Office of Malaria Control in War Areas, which had been created in 1942 to suppress malaria near military bases in the United States during World War II. The CDC's first directorJustin M. Andrewswas also Georgia's chief malariologist.\n\nThe new agency was a branch of the U.S. Public Health Service and Atlanta was chosen as its headquarters because malaria was locally endemic. Offices were located on the sixth floor of the Volunteer Building on Peachtree Street. With an annual budget of about $1 million, some 59% of its personnel were engaged in mosquito abatement and habitat control. Among its 369 employees, the main jobs at CDC at this time were entomology and engineering. In 1946, there were only seven medical officers on duty and an early organization chart was drawn, somewhat fancifully, in the shape of a mosquito.\n\nDuring the CDC's first few years, more than 6,500,000 homes were sprayed with the insecticide DDT. DDT was applied to the interior surfaces of rural homes or entire premises in counties where malaria was reported to have been prevalent in recent years. In addition, wetland drainage, removal of mosquito breeding sites, and DDT spraying (occasionally from aircraft) were all pursued. In 1947, some 15,000 malaria cases were reported. By the end of 1949, over 4,650,000 housespray applications had been made and the United States was declared free of malaria as a significant public health problem. By 1950, only 2,000 cases were reported. By 1951, malaria was considered eliminated altogether from the country and the CDC gradually withdrew from active participation in the operational phases of the program, shifting its interest to surveillance. In 1952, CDC participation in eradication operations ceased altogether.\n\nA major international effort along the lines of the NMEPthe Global Malaria Eradication Programme (1955–1969), administered by the World Health Organizationwas unsuccessful.\n\n\n"}
{"id": "261773", "url": "https://en.wikipedia.org/wiki?curid=261773", "title": "Parenteral nutrition", "text": "Parenteral nutrition\n\nParenteral nutrition (PN) is the feeding of specialist nutritional products to a person intravenously, bypassing the usual process of eating and digestion. The products are made by specialist pharmaceutical compounding companies and is considered to be the highest risk pharmaceutical preparation available as the products cannot undergo any form of terminal sterilization. The person receives highly complex nutritional formulae that contain nutrients such as glucose, salts, amino acids, lipids and added vitamins and dietary minerals. It is called total parenteral nutrition (TPN) or total nutrient admixture (TNA) when no significant nutrition is obtained by other routes, and partial parenteral nutrition (PPN) when nutrition is also partially enteric. It may be called peripheral parenteral nutrition (PPN) when administered through vein access in a limb rather than through a central vein as central venous nutrition (CVN).\n\nTotal parenteral nutrition (TPN) is provided when the gastrointestinal tract is nonfunctional because of an interruption in its continuity (it is blocked, or has a leak - a fistula) or because its absorptive capacity is impaired. It has been used for comatose patients, although enteral feeding is usually preferable, and less prone to complications. Parenteral nutrition is used to prevent malnutrition in patients who are unable to obtain adequate nutrients by oral or enteral routes. The Society of Critical Care Medicine (SCCM) and American Society for Parenteral and Enteral Nutrition recommends waiting until hospital day number seven.\n\nAbsolute indications for TPN:\n\n\nTPN may be the only feasible option for providing nutrition to patients who do not have a functioning gastrointestinal tract or who have disorders requiring complete bowel rest, including bowel obstruction, short bowel syndrome, gastroschisis, prolonged diarrhea regardless of its cause, very severe Crohn's disease or ulcerative colitis, and certain pediatric GI disorders including congenital GI anomalies and necrotizing enterocolitis.\n\nThe benefit of TPN to cancer patients is largely debated, and studies to date have generally showed minimal long term benefit.\n\nShort-term PN may be used if a person's digestive system has shut down (for instance by peritonitis), and they are at a low enough weight to cause concerns about nutrition during an extended hospital stay. Long-term PN is occasionally used to treat people suffering the extended consequences of an accident, surgery, or digestive disorder. PN has extended the life of children born with nonexistent or severely deformed organs.\n\nApproximately 40,000 people use TPN at home in the United States, and because TPN requires anywhere from 10–16 hours to be administered, daily life can be affected. Although daily lifestyle can be changed, most patients agree that these changes are better than staying at the hospital. Many different types of pumps exist to limit the time the patient is “hooked-up”. Usually a backpack pump is used, allowing for mobility. The time required to be connected to the IV is dependent on the situation of each patient; some require once a day, or five days a week.\n\nIt is important for patients to avoid as much TPN related change as possible in their lifestyles. This allows for the best possible mental health situation; constantly being held down can lead to resentment and depression. Physical activity is also highly encouraged, but patients must avoid contact sports (equipment damage) and swimming (infection). Many teens find it difficult to live with TPN due to issues regarding body image and not being able to participate in activities and events.\n\nTPN fully bypasses the GI tract and normal methods of nutrient absorption. Possible complications, which may be significant, are listed below. Other than those listed below, other common complications of TPN include hypophosphatemia, hypokalemia, hyperglycemia, hypercapnia, decreased copper and zinc levels, elevated prothrombin time (if associated with liver injury), hyperchloremic metabolic acidosis and decreased gastrointestinal motility.\n\nTPN requires a chronic IV access for the solution to run through, and the most common complication is infection of this catheter. Infection is a common cause of death in these patients, with a mortality rate of approximately 15% per infection, and death usually results from septic shock. When using central venous access, the subclavian (or axillary) vein is preferred due to its ease of access and lowest infectious complications compared to the jugular and femoral vein insertions.\n\nChronic IV access leaves a foreign body in the vascular system, and blood clots on this IV line are common. Death can result from pulmonary embolism wherein a clot that starts on the IV line breaks off and travels to the lungs, blocking blood flow. \nPatients on TPN who have such clots occluding their catheter may receive a thrombolytic flush to dissolve the clots and prevent further complications.\n\nFatty liver is usually a more long term complication of TPN, though over a long enough course it is fairly common. The pathogenesis is due to using linoleic acid (an omega-6 fatty acid component of soybean oil) as a major source of calories. TPN-associated liver disease strikes up to 50% of patients within 5–7 years, correlated with a mortality rate of 2–50%. Onset of this liver disease is the major complication that leads TPN patients to requiring an intestinal transplant.\n\nIntralipid (Fresenius-Kabi), the US standard lipid emulsion for TPN nutrition, contains a 7:1 ratio of n-6/n-3 ratio of polyunsaturated fatty acids (PUFA). By contrast, Omegaven has a 1:8 ratio and showed promise in multiple clinical studies. Therefore n-3-rich fat may alter the course of parenteral nutrition associated liver disease.\n\nBecause patients are being fed intravenously, the subject does not physically eat, resulting in intense hunger pangs (pains). The brain uses signals from the mouth (taste and smell), the stomach/gastrointestinal tract (fullness) and blood (nutrient levels) to determine conscious feelings of hunger. In cases of TPN, the taste, smell and physical fullness requirements are not met, and so the patient experiences hunger, despite the fact that the body is being fully nourished.\n\nPatients who eat food despite the inability can experience a wide range of complications.\n\nTotal parenteral nutrition increases the risk of acute cholecystitis due to complete disuse of gastrointestinal tract, which may result in bile stasis in the gallbladder. Other potential hepatobiliary dysfunctions include steatosis, steatohepatitis, cholestasis, and cholelithiasis. Six percent of patients on TPN longer than 3 weeks and 100% of patients on TPN longer than 13 weeks develop biliary sludge. The formation of sludge is the result of stasis due to lack of enteric stimulation and is not due to changes in bile composition. Gallbladder sludge disappears after 4 weeks of normal oral diet. Administration of exogenous cholecystokinin (CCK) or stimulation of endogenous CCK by periodic pulse of large amounts of amino acids have been shown to help prevent sludge formation. These therapies are not routinely recommended. Such complications are suggested to be the main reason for mortality in people requiring long-term total parenteral nutrition, such as in short bowel syndrome. In newborn infants with short bowel syndrome with less than 10% of expected intestinal length, thereby being dependent upon total parenteral nutrition, 5 year survival is approximately 20%.\n\nInfants who are sustained on TPN without food by mouth for prolonged periods are at risk for developing gut atrophy.\n\nOther complications are either related to catheter insertion, or metabolic, including refeeding syndrome. Catheter complications include pneumothorax, accidental arterial puncture, and catheter-related sepsis. The complication rate at the time of insertion should be less than 5%. Catheter-related infections may be minimised by appropriate choice of catheter and insertion technique. Metabolic complications include the refeeding syndrome characterised by hypokalemia, hypophosphatemia and hypomagnesemia. Hyperglycemia is common at the start of therapy, but can be treated with insulin added to the TPN solution. Hypoglycaemia is likely to occur with abrupt cessation of TPN. Liver dysfunction can be limited to a reversible cholestatic jaundice and to fatty infiltration (demonstrated by elevated transaminases). Severe hepatic dysfunction is a rare complication. Overall, patients receiving TPN have a higher rate of infectious complications. This can be related to hyperglycemia.\n\nPregnancy can cause major complications when trying to properly dose the nutrient mixture. Because all of the baby’s nourishment comes from the mother’s blood stream, the doctor must properly calculate the dosage of nutrients to meet both recipients’ needs and have them in usable forms. Incorrect dosage can lead to many adverse, hard-to-guess effects, such as death, and varying degrees of deformation or other developmental problems.\n\nIt is recommended that parenteral nutrition administration begin after a period of natural nutrition so doctors can properly calculate the nutritional needs of the fetus. Otherwise, it should only be administered by a team of highly skilled doctors who can accurately assess the fetus’ needs.\n\nSolutions for total parenteral nutrition may be customized to individual patient requirements, or standardized solutions may be used. The use of standardized parenteral nutrition solutions is cost effective and may provide better control of serum electrolytes. \nIdeally each patient is assessed individually before commencing on parenteral nutrition, and a team consisting of specialised doctors, nurses, clinical pharmacists and registered dietitians evaluate the patient's individual data and decide what PN formula to use and at what infusion rate.\n\nFor energy only, intravenous sugar solutions with dextrose or glucose are generally used. This is not considered to be parenteral nutrition as it does not prevent malnutrition when used on its own. Standardized solutions may also differ between developers. Following are some examples of what compositions they may have. The solution for normal patients may be given both centrally and peripherally.\n\nPrepared solutions generally consist of water and electrolytes; glucose, amino acids, and lipids; essential vitamins, minerals and trace elements are added or given separately. Previously lipid emulsions were given separately but it is becoming more common for a \"three-in-one\" solution of glucose, proteins, and lipids to be administered.\n\nIndividual nutrient components may be added to more precisely adjust the body contents of it. That individual nutrient may, if possible, be infused individually, or it may be injected into a bag of nutrient solution or intravenous fluids (volume expander solution) that is given to the patient.\n\nAdministration of individual components may be more hazardous than administration of pre-mixed solutions such as those used in total parenteral nutrition, because the latter are generally already balanced in regard to e.g. osmolarity and ability to infuse peripherally. Incorrect IV administration of concentrated potassium can be lethal, but this is not a danger if the potassium is mixed in TPN solution and diluted.\n\nVitamins may be added to a bulk premixed nutrient immediately before administration, since the additional vitamins can promote spoilage of stored product. Vitamins can be added in two doses, one fat-soluble, the other water-soluble. There are also single-dose preparations with both fat- and water-soluble vitamins such as \"Cernevit\".\n\nMinerals and trace elements for parenteral nutrition are available in prepared mixtures, such as \"Addaven\".\n\nOnly a limited number of emulsifiers are commonly regarded as safe to use for parenteral administration, of which the most important is lecithin. Lecithin can be biodegraded and metabolized, since it is an integral part of biological membranes, making it virtually non-toxic. Other emulsifiers can only be excreted via the kidneys, creating a toxic load. The emulsifier of choice for most fat emulsions used for parenteral nutrition is a highly purified egg lecithin, due to its low toxicity and complete integration with cell membranes.\n\nUse of egg-derived emulsifiers is not recommended for people with an egg allergy due to the risk of reaction. In situations where there is no suitable emulsifying agent for a person at risk of developing essential fatty acid deficiency, cooking oils may be spread upon large portions of available skin for supplementation by transdermal absorption.\n\nAnother type of fat emulsion Omegaven is being used experimentally within the US primarily in the pediatric population. It is made of fish oil instead of the egg based formulas more widely in use. Research has shown use of Omegaven may reverse and prevent liver disease and cholestasis.\n\nDeveloped in the 1960s by Dr. Stanley J. Dudrick, who as a surgical resident in the University of Pennsylvania, working in the basic science laboratory of Dr. Jonathan Rhoads, was the first to successfully nourish initially Beagle puppies and subsequently newborn babies with catastrophic gastrointestinal malignancies. Dr. Dudrick collaborated with Dr. Willmore and Dr. Vars to complete the work necessary to make this nutritional technique safe and successful.\n\n"}
{"id": "7336482", "url": "https://en.wikipedia.org/wiki?curid=7336482", "title": "Perineology", "text": "Perineology\n\nPerineology is a speciality dealing with the functional troubles of the three axes (urological, gynaecological and coloproctological) of the female perineum. The perineologist takes a holistic approach, using defect-specific and mini-invasive treatments.\n\n\"The word perineology represents a neologism. Many specialties have split into subspecialties. From surgery and from gastroenterology derived proctology. The latter needs now an evolution, mainly for its functional aspects. The proctologist cannot restrict his competence to the posterior perineum, as the urologist and the gynaecologist, when evaluating the pelvic floor and its diseases, must take into account the posterior compartment. A unitary view of the pelvic organs function then creates a sort of superspecialty that must open new spaces to the research insuring to the patients more rational solutions. Perineology is then a medical branch of which we probably will hear talking more and more in the future.\" (\"G. Dodi, RICP 1990; 9: 113\" \n\n\n"}
{"id": "7987684", "url": "https://en.wikipedia.org/wiki?curid=7987684", "title": "Plutonium", "text": "Plutonium\n\nPlutonium is a radioactive chemical element with symbol Pu and atomic number 94. It is an actinide metal of silvery-gray appearance that tarnishes when exposed to air, and forms a dull coating when oxidized. The element normally exhibits six allotropes and four oxidation states. It reacts with carbon, halogens, nitrogen, silicon and hydrogen. When exposed to moist air, it forms oxides and hydrides that can expand the sample up to 70% in volume, which in turn flake off as a powder that is pyrophoric. It is radioactive and can accumulate in bones, which makes the handling of plutonium dangerous.\n\nPlutonium was first produced and isolated on December 14, 1940, by a deuteron bombardment of uranium-238 in the 1.5 metre (60 in) cyclotron at the University of California, Berkeley. First neptunium-238 (half-life 2.1 days) was synthesized which subsequently beta-decayed to form this new element with atomic number 94 and atomic weight 238 (half-life 87.7 years). Since uranium had been named after the planet Uranus and neptunium after the planet Neptune, element 94 was named after Pluto, which at the time was considered to be a planet as well. Wartime secrecy prevented its discovery being announced until 1948. Plutonium is the element with the highest atomic number to occur in nature. Trace quantities arise in natural uranium-238 deposits when U-238 captures neutrons emitted by decay of other U-238 atoms. Plutonium is much more common on Earth since 1945 as a product of neutron capture and beta decay, where some of the neutrons released by the fission process convert uranium-238 nuclei into plutonium-239.\n\nBoth plutonium-239 and plutonium-241 are fissile, meaning that they can sustain a nuclear chain reaction, leading to applications in nuclear weapons and nuclear reactors. Plutonium-240 exhibits a high rate of spontaneous fission, raising the neutron flux of any sample containing it. The presence of plutonium-240 limits a plutonium sample's usability for weapons or its quality as reactor fuel, and the percentage of plutonium-240 determines its grade (weapons-grade, fuel-grade, or reactor-grade). Plutonium-238 has a half-life of 88 years and emits alpha particles. It is a heat source in radioisotope thermoelectric generators, which are used to power some spacecraft. Plutonium isotopes are expensive and inconvenient to separate, so particular isotopes are usually manufactured in specialized reactors.\n\nProducing plutonium in useful quantities for the first time was a major part of the Manhattan Project during World War II that developed the first atomic bombs. The Fat Man bombs used in the Trinity nuclear test in July 1945, and in the bombing of Nagasaki in August 1945, had plutonium cores. Human radiation experiments studying plutonium were conducted without informed consent, and several criticality accidents, some lethal, occurred after the war. Disposal of plutonium waste from nuclear power plants and dismantled nuclear weapons built during the Cold War is a nuclear-proliferation and environmental concern. Other sources of plutonium in the environment are fallout from numerous above-ground nuclear tests, now banned.\n\nPlutonium, like most metals, has a bright silvery appearance at first, much like nickel, but it oxidizes very quickly to a dull gray, although yellow and olive green are also reported. At room temperature plutonium is in its α (\"alpha\") form. This, the most common structural form of the element (allotrope), is about as hard and brittle as gray cast iron unless it is alloyed with other metals to make it soft and ductile. Unlike most metals, it is not a good conductor of heat or electricity. It has a low melting point (640 °C) and an unusually high boiling point (3,228 °C).\n\nAlpha decay, the release of a high-energy helium nucleus, is the most common form of radioactive decay for plutonium. A 5 kg mass of Pu contains about atoms. With a half-life of 24,100 years, about of its atoms decay each second by emitting a 5.157 MeV alpha particle. This amounts to 9.68 watts of power. Heat produced by the deceleration of these alpha particles makes it warm to the touch.\n\nResistivity is a measure of how strongly a material opposes the flow of electric current. The resistivity of plutonium at room temperature is very high for a metal, and it gets even higher with lower temperatures, which is unusual for metals. This trend continues down to 100 K, below which resistivity rapidly decreases for fresh samples. Resistivity then begins to increase with time at around 20 K due to radiation damage, with the rate dictated by the isotopic composition of the sample.\n\nBecause of self-irradiation, a sample of plutonium fatigues throughout its crystal structure, meaning the ordered arrangement of its atoms becomes disrupted by radiation with time. Self-irradiation can also lead to annealing which counteracts some of the fatigue effects as temperature increases above 100 K.\n\nUnlike most materials, plutonium increases in density when it melts, by 2.5%, but the liquid metal exhibits a linear decrease in density with temperature. Near the melting point, the liquid plutonium has very high viscosity and surface tension compared to other metals.\n\nPlutonium normally has six allotropes and forms a seventh (zeta, ζ) at high temperature within a limited pressure range. These allotropes, which are different structural modifications or forms of an element, have very similar internal energies but significantly varying densities and crystal structures. This makes plutonium very sensitive to changes in temperature, pressure, or chemistry, and allows for dramatic volume changes following phase transitions from one allotropic form to another. The densities of the different allotropes vary from 16.00 g/cm to 19.86 g/cm.\n\nThe presence of these many allotropes makes machining plutonium very difficult, as it changes state very readily. For example, the α form exists at room temperature in unalloyed plutonium. It has machining characteristics similar to cast iron but changes to the plastic and malleable β (\"beta\") form at slightly higher temperatures. The reasons for the complicated phase diagram are not entirely understood. The α form has a low-symmetry monoclinic structure, hence its brittleness, strength, compressibility, and poor thermal conductivity.\n\nPlutonium in the δ (\"delta\") form normally exists in the 310 °C to 452 °C range but is stable at room temperature when alloyed with a small percentage of gallium, aluminium, or cerium, enhancing workability and allowing it to be welded. The δ form has more typical metallic character, and is roughly as strong and malleable as aluminium. In fission weapons, the explosive shock waves used to compress a plutonium core will also cause a transition from the usual δ phase plutonium to the denser α form, significantly helping to achieve supercriticality. The ε phase, the highest temperature solid allotrope, exhibits anomalously high atomic self-diffusion compared to other elements.\n\nPlutonium is a radioactive actinide metal whose isotope, plutonium-239, is one of the three primary fissile isotopes (uranium-233 and uranium-235 are the other two); plutonium-241 is also highly fissile. To be considered fissile, an isotope's atomic nucleus must be able to break apart or fission when struck by a slow moving neutron and to release enough additional neutrons to sustain the nuclear chain reaction by splitting further nuclei.\n\nPure plutonium-239 may have a multiplication factor (k) larger than one, which means that if the metal is present in sufficient quantity and with an appropriate geometry (e.g., a sphere of sufficient size), it can form a critical mass. During fission, a fraction of the nuclear binding energy, which holds a nucleus together, is released as a large amount of electromagnetic and kinetic energy (much of the latter being quickly converted to thermal energy). Fission of a kilogram of plutonium-239 can produce an explosion equivalent to . It is this energy that makes plutonium-239 useful in nuclear weapons and reactors.\n\nThe presence of the isotope plutonium-240 in a sample limits its nuclear bomb potential, as plutonium-240 has a relatively high spontaneous fission rate (~440 fissions per second per gram—over 1,000 neutrons per second per gram), raising the background neutron levels and thus increasing the risk of predetonation. Plutonium is identified as either weapons-grade, fuel-grade, or reactor-grade based on the percentage of plutonium-240 that it contains. Weapons-grade plutonium contains less than 7% plutonium-240. Fuel-grade plutonium contains from 7% to less than 19%, and power reactor-grade contains 19% or more plutonium-240. Supergrade plutonium, with less than 4% of plutonium-240, is used in U.S. Navy weapons stored in proximity to ship and submarine crews, due to its lower radioactivity. The isotope plutonium-238 is not fissile but can undergo nuclear fission easily with fast neutrons as well as alpha decay.\n\nTwenty radioactive isotopes of plutonium have been characterized. The longest-lived are plutonium-244, with a half-life of 80.8 million years, plutonium-242, with a half-life of 373,300 years, and plutonium-239, with a half-life of 24,110 years. All of the remaining radioactive isotopes have half-lives that are less than 7,000 years. This element also has eight metastable states, though all have half-lives less than one second.\n\nThe known isotopes of plutonium range in mass number from 228 to 247. The primary decay modes of isotopes with mass numbers lower than the most stable isotope, plutonium-244, are spontaneous fission and alpha emission, mostly forming uranium (92 protons) and neptunium (93 protons) isotopes as decay products (neglecting the wide range of daughter nuclei created by fission processes). The primary decay mode for isotopes with mass numbers higher than plutonium-244 is beta emission, mostly forming americium (95 protons) isotopes as decay products. Plutonium-241 is the parent isotope of the neptunium decay series, decaying to americium-241 via beta emission.\n\nPlutonium-238 and 239 are the most widely synthesized isotopes. Plutonium-239 is synthesized via the following reaction using uranium (U) and neutrons (n) via beta decay (β) with neptunium (Np) as an intermediate:\n\n</chem>\n\nNeutrons from the fission of uranium-235 are captured by uranium-238 nuclei to form uranium-239; a beta decay converts a neutron into a proton to form neptunium-239 (half-life 2.36 days) and another beta decay forms plutonium-239. Egon Bretscher working on the British Tube Alloys project predicted this reaction theoretically in 1940.\n\nPlutonium-238 is synthesized by bombarding uranium-238 with deuterons (D, the nuclei of heavy hydrogen) in the following reaction:\n\n\\ce\n"}
{"id": "36561323", "url": "https://en.wikipedia.org/wiki?curid=36561323", "title": "Pulp stone", "text": "Pulp stone\n\nPulp stones (also denticles or endoliths) are nodular, calcified masses appearing in either or both the coronal and root portion of the pulp organ in teeth. Pulp stones are not painful unless they impinge on nerves.\n\nThey are classified:\n"}
{"id": "8315690", "url": "https://en.wikipedia.org/wiki?curid=8315690", "title": "Qar (doctor)", "text": "Qar (doctor)\n\nQar was a doctor during the Sixth dynasty of Egypt, which lasted from about 2350 to 2180 BC. He was the royal physician.\n\nAdil Hussein discovered his tomb north of the pyramid of Sekhemkhet in 2001. He died at the age of fifty years and his mummified remains were discovered by archaeologists in December 2006 in his mastaba at Saqqara, Egypt. As were many other tombs in Saqqara, his tomb was re-used several times.\n\nBeside his mummy in the limestone sarcophagus, there were metal (bronze or copper) model tools that were entombed alongside his remains. In press reports following the discovery of the tomb and in several publications they are regarded as surgical instruments. It was stated that they might be the oldest surgical tools in the world. They are now preserved in Imhotep museum. However, these types of model tools are common in many Old Kingdom burials of officials with different functions. They are not surgical instruments. They are model tools.\n\nAlso 22 bronze statues were unearthed representing different deities in various shapes and sizes including Ptah, Horus-the- child (also known as Harpocrates) and Isis. A statuette of Imhotep the physician, the great engineer and builder of Djoser's pyramid complex, was also among the statuettes found by the team.\n\nHis mummy and findings from his tomb are preserved in the Imhotep Museum at Saqqara.\n"}
{"id": "17087685", "url": "https://en.wikipedia.org/wiki?curid=17087685", "title": "Slingshot (water vapor distillation system)", "text": "Slingshot (water vapor distillation system)\n\nSlingshot is a water purification device created by inventor Dean Kamen. Powered by a Stirling engine running on a combustible fuel source, it claims to be able to produce drinking water from almost any source by means of vapor compression distillation, requires no filters, and can operate using cow dung as fuel.\n\nThe name of the machine is a reference to the slingshot used by David to defeat Goliath.\n\nIn his TEDMED 2010 presentation, Kamen announced several goals for and characteristics of the machine:\n\nKamen came to develop the device on the basis of statistics that showed lack of access to clean water as a public health crisis. Statistics from the World Health Organization show that there are 900 million people worldwide without a readily available supply of drinking water and that some 3.5 million people die annually because of diseases resulting from the consumption of unsanitary water. Despite the fact that over two-thirds of the Earth's surface is covered with water, only 1% of it is potable.\n\nKamen sought to develop a technology that would transform the 97% of water that is undrinkable into water that can be used and consumed on the spot, readily and inexpensively. The device takes contaminated water and runs it through a vapor compression distiller that produces clean water, producing 250 gallons daily (~946 litres), enough for 100 people. The test devices have been used with \"anything that looks wet\", including polluted river water, saline ocean water and raw sewage. In a demonstration at a technology conference in October 2004, Kamen ran his own urine through the machine and drank the clean water that came out.\n\nKamen built two machines — a power generator that would output one kilowatt from \"anything that burns\", and the water distiller, which uses the electricity. In 2005, the power generator was tested for six months in a village in Bangladesh and generated enough electricity to light 70 energy-efficient light bulbs. The hand-made prototype cost each.\n\nBy the end of 2005, a team of 200 at DEKA had produced 30 units, each the size of a compact refrigerator. A pair of Slingshot devices ran successfully for a month in a village in Honduras during the summer of 2006. While the initial devices cost hundreds of thousands of dollars, Kamen hopes that increased economies of scale will allow production machines to be made available for $2,000 each.\n\nIn 2008, Kamen demonstrated the device on The Colbert Report.\n\nIn his TEDMED 2010 presentation, Kamen lamented throughout that when he asked for \"a few million dollars\" over a few months, no large global health organizations supported the development. Later in the presentation, he announced a partnership with The Coca-Cola Company.\n\nIn 2011, field tests of Slingshot in five towns in Ghana proved their effectiveness and durability.\n\nIn October 2012, Kamen and Coca Cola CEO Muhtar Kent announced at the Clinton Global Initiative that in collaboration with DEKA Research, Africare and Inter-American Development Bank, they will start bringing the Slingshot to rural parts of Latin America and Africa. The first initiative will be testing the Slingshot technology in health centers and schools in remote communities in Latin America in 2013.\n\nKamen hopes to send thousands of the units with local village entrepreneurs, in much the same way independent cell phone businesses have thrived and gradually changed the face of many impoverished areas around the globe. Future target price for the device is in the $1,000 to $2,000 range.\n\nAs of 2016, the product does not seem to be in commercial production or wide use. The systems appear to be distributed as a component of EKOCENTER kiosks, of which over 150 have been deployed worldwide.\n\n\n"}
{"id": "28690075", "url": "https://en.wikipedia.org/wiki?curid=28690075", "title": "Smoking in Indonesia", "text": "Smoking in Indonesia\n\nSmoking in Indonesia is common, as there are approximately 57 million smokers in Indonesia. Of Indonesian people, 63% of men and 5% of women reported being smokers, a total of 34% of the population. 88% of Indonesia smokers use clove-flavoured kreteks. Kretek manufacturers directly employ over 180,000 people in Indonesia and an additional 10 million indirectly. Indonesia is the fifth largest tobacco market in the world, and in 2008 over 165 billion cigarettes were sold in the country. Major tobacco companies dominating the market in Indonesia include Gudang Garam, Sampoerna (Philip Morris International), Djarum, Bentoel Group (British American Tobacco) and Nojorono Tobacco International. The WHO has ranked Indonesia third in the world for total number of smokers.\n\nAccording to an official spokesman of a special commission set up to protect children's rights (KPAI) and evolve regulations to prevent children getting addicted to smoking, \"The future of 80 million Indonesian children is at stake as the cigarette producers were intentionally aiming children as their future market through massive TV advertisements and sponsorships on activities in which teenagers involved the most.\"\n\nMore than 30% of Indonesian children reportedly smoke a cigarette before the age of 10. In 2010, a two-year-old boy from Sumatra, Ardi Rizal, made global headlines for having a 40-a-day cigarette habit.\n\nIn 2003, cigarette advertising and promotion in Indonesia was valued at $250 million. It is thus one of the most distinctive tobacco manufacturing hubs in the world. Smoking Kretek is said to be \"an ingrained part of Indonesian culture\". An all pervading scent of kretek smoke is distinctly discerned in Indonesia.\n\nKretek is credited as an invention by Nitisemito of Kudus, an industrial town in Central Java. They emerged in the late 19th century in Java. The practice was to roll, by hand, a compound of tobacco, cloves and cocoa in a dry corn husk wrap, which gives a honeyed flavour. It was Nitisemito who introduced cigarette papers in place of corn husk; following this simple innovation, a Kretek manufacturing factory was opened in Sumatra. The first brand of cigarette produced in this factory, \"Bal Tiga\" (three balls), became very popular, and as result, the economy of Kudus prospered. The inventor popularized his brand of cigarettes through a concerted media campaign, even establishing his own radio station for the purpose. He touted his habit of smoking kretek as the cure for his asthma. However, intense competition (25 manufactures are now reported in the city and its suburbs) combined with poor management resulted in his eventual financial failure, when he died in 1953. Another local brand, which became very popular in the 1980s, is the Gudang Garam brand of Kretek. Chinese businessmen who are credited with establishing this brand of Kretek from a modest beginning in the 1920s produced 40 billion cigarettes in the 1980s. Other business enterprises competing with this brand tried to discredit the brand by attributing use of cannabis in addition to cloves and tobacco. It has the distinction of being the largest single employer in Indonesia.\n\nKretek is very popular in rural areas as this type of cigarette is cheap. Kretek is known to burn slowly, and also self-extinguish. Evidence seems to suggest oral lesions may be less common than with other cigarette types. Due to this effect, cigarette smoking has largely replaced betel chewing.\n\nThe term \"Kretek\" is onomatopoeic, referring to the crackling sound that is produced when such cigarettes are burnt and inhaled.\n\nKretek cigarettes contain high concentration of tar and nicotine, approximately four times that of the strongest Marlboros. Some countries (such as the United States) have banned marketing flavoured cigarettes (including kreteks), as these are often seen as more appealing to the youth. The other harmful effect mentioned is from the clove oil used in making Kretek. The clove oil or eugenol is harmful to the lungs. The Indonesian Health Department reported in 2000 that 200,000 people are affected by cancer every year but eugenols exact relation to smoking has not been evaluated. Due to the popularity of Kretek, 5% of the national revenue is from this source, next only to the revenue from oil. Indonesia also records the highest growth of cigarette industry in the world, accounting for 4% of the world consumption.\n\nWhile cigarette smoking is declining throughout the world, in Indonesia, the industry continues to thrive. Indonesia has one of the highest smoking rates in the world and is currently one of the biggest producers of tobacco worldwide, with Malaysia and the United States being two of their important markets. There are hundreds of tobacco companies in the country, with Gudang Garam, Djarum, Sampoerna and Bentoel dominating the Indonesian market share.\n\nKretek was initially a habit of the lower classes of society. However, it has now become very popular among the \"middle class and intelligentsia, to the extent that it has become very \"de rigueur\" and a mark of Indonesian-ness.\"\n\nTobacco smoking in Indonesia is said to claim 300,000 lives every year. Even though the country has required \"no smoking\" signs in health care units, educational institutions and in public transportation system, there is no ban on smoking in government and private offices, restaurants and bars. Tax exemptions in the country provide an incentive to the manufacturers to advertise the sale of cigarettes as compared to other countries in the region, in spite of the World Bank suggesting higher tax rates. As a result, tobacco manufacturers almost run cigarette advertisements for free. All these factors, plus its low cost, have contributed to the extensive proliferation of cigarette smoking in the country among people of all ages. So much so, that even a two-year-old child picked up the habit of smoking two packs of cigarettes a day in his fishing village, where every one smokes. It was reported that the child's father initiated his son into this habit at the age of 18 months. However, press reports indicate that the child has been placed in rehabilitation by keeping him in a different environment under the care of a psychologist, and as a result the child has given up smoking. The government of Indonesia is now contemplating introducing regulations that would ban the advertising of cigarettes, smoking in public places and selling cigarettes to children.\n\n"}
{"id": "629218", "url": "https://en.wikipedia.org/wiki?curid=629218", "title": "Sodium hexametaphosphate", "text": "Sodium hexametaphosphate\n\nSodium hexametaphosphate (SHMP) is a hexamer of composition (NaPO). Sodium hexametaphosphate of commerce is typically a mixture of polymeric metaphosphates, of which the hexamer is one, and is usually the compound referred to by this name. It is more correctly termed sodium polymetaphosphate.\n\nSHMP is used as a sequestrant and has applications within a wide variety of industries, including as a food additive in which it is used under the E number E452i. Sodium carbonate is sometimes added to SHMP to raise the pH to 8.0–8.6, which produces a number of SHMP products used for water softening and detergents.\n\nA significant use for sodium hexametaphosphate is as a deflocculant in the production of clay-based ceramic particles. It is also used as a dispersing agent to break down clay and other soil types for soil texture assessment.\n\nIt is used as an active ingredient in toothpastes as an anti-staining and tartar prevention ingredient.\n\nAs a food additive, SHMP is used as an emulsifier. Artificial maple syrup, canned milk, cheese powders and dips, imitation cheese, whipped topping, packaged egg whites, roast beef, fish fillets, fruit jelly, frozen desserts, salad dressing, herring, breakfast cereal, ice cream, beer, and bottled beverages, among other foods, can contain SHMP.\n\nSHMP is prepared by heating monosodium orthophosphate to generate sodium acid pyrophosphate:\n\nSubsequently, the pyrophosphate is heated to give the corresponding sodium hexametaphosphate:\n\nfollowed by rapid cooling.\n\nSHMP hydrolyzes in aqueous solution, particularly under acidic conditions, to sodium trimetaphosphate and sodium orthophosphate.\n\nHexametaphosphoric acid was named (but misidentified) in 1849 by the German chemist (1828–1904). By 1956, chromatographic analysis of hydrolysates of Graham's salt (sodium polyphosphate) indicated the presence of cyclic anions containing more than four phosphate groups; these findings were confirmed in 1961. In 1963, the German chemists Erich Thilo and Ulrich Schülke succeeded in preparing sodium hexametaphosphate by heating anhydrous sodium trimetaphosphate.\n\n"}
{"id": "31176877", "url": "https://en.wikipedia.org/wiki?curid=31176877", "title": "The Himalaya Drug Company", "text": "The Himalaya Drug Company\n\nThe Himalaya Drug Company is a company established by M Manal in 1930 and based in Bangalore, India. It produces health care products under the name \"Himalaya Herbal Healthcare\" whose products include ayurvedic ingredients. It is spread across locations in India, the United States, the Middle East, Asia and Europe., while its products are sold in 92 countries across the world.\n\nThe company has more than 290 researchers that utilize ayurvedic herbs and minerals. An Hepatic drug, named \"Liv.52\", is its flagship product, first introduced in 1955. Liv.52 to date has now over 215 clinical trials backing it.\n\nHimalaya Global Holdings Ltd. (HGH), is the parent of The Himalaya Drug Company worldwide. It is also the global headquarters of all Himalaya subsidiaries.\n\nFounded by M Manal, the Himalaya Drug Company's history began in 1930. Manal, while in the forests of Burma, became interested in the root, \"Rauwolfia serpentina\", which helped pacify elephants. Becoming engrossed in the intriguing effects surrounding the root, Manal went on to studying various herbs, and producing tablets. According to Himalaya Wellness, Manal's motivation and \"vision was to bring the traditional science of Ayurveda to society in a contemporary form.\" Nonetheless, in 1934, Serpina, derived from Rauwolfia serpentina, became \"the world's first natural antihypertensive drug\". Another product soon became the Himalaya drug company's best selling medicine, Liv. 52. This product, created in 1955, is \"a liver formulation that ensures optimum liver function.\". In addition, the Himalaya Drug company soon introduced several other products, such as Cystone, Bonnisan and Rumalaya forte. In the 1930s, the company was based in Dehradun, but subsequently it advanced to Mumbai and extended across India. Then, in 1975, it established a factory. in Makali, Bangalore. Finally, in 1991, the company moved its research and development facility to Bangalore. Meraj Manal pioneered the growth of the company in the USA, first with a range of dietary supplements falling in line with the norms of the Dietary Supplement Health and Education Act of 1994 in 1996, and then personal care products in 1999, under the brand name Ayurvedic Concepts, that later bloomed into the exquisite Himalaya Herbals. Today, the company has offices across the globe, including India, USA, South Africa and other countries in Europe, the middle east, and Asia.\n\nAs of 2015, the company sold its products in 91 countries with about 50% of its revenue from outside India.\n\nHimalaya Herbal Healthcare has a very wide range of products, which include \"pharmaceuticals, personal care, baby care, well-being, nutrition and animal health products.\" The Neem Face Wash is one of their most popular and well known products. Mothercare products have been launched in 2016 with foray into extensive research and development in systems of ancient Ayurveda medicines of India. The company has a presence in 92 countries.\n\n\n"}
{"id": "36953510", "url": "https://en.wikipedia.org/wiki?curid=36953510", "title": "University of Montenegro Faculty of Applied Physiotherapy", "text": "University of Montenegro Faculty of Applied Physiotherapy\n\nThe University of Montenegro Faculty of Applied Physiotherapy (Montenegrin: Fakultet primijenjene fizioterapije \"Факултет примијењене физиотерапије\") is one of the educational institutions of the University of Montenegro. The building is located in Igalo, and the Faculty is the only physical therapy school in Montenegro and the region.\n\nIn 1976, the High School of Physiotherapy was founded in Igalo as a two-year post-secondary school.\n\nIn compliance with the new Law on Higher Education, the Post-secondary School of Physiotherapy was transformed into a Higher School of Physiotherapy in 2004 and one year later was renamed the Faculty of Applied Physiotherapy as an organizational unit of the University of Montenegro.\n"}
{"id": "28999793", "url": "https://en.wikipedia.org/wiki?curid=28999793", "title": "Vikenty Veresaev", "text": "Vikenty Veresaev\n\nVikenty Vikentyevich Smidovich (January 16, 1867 – June 3, 1945), better known by his pen name Vikenty Vikentyevich Veresaev, () was a Russian writer and medical doctor of Polish descent.\n\nVeresaev was born in Tula, where his father was a doctor. After graduating from the Tula gymnasium in 1884, he attended Saint Petersburg University, taking a master's degree in history in 1888. He then enrolled in University of Dorpat/Yuryev and successfully completed a course in medicine. \nHis first work to appear in print was a collection of poems in 1885. His first short story, \"The Puzzle\", was published in 1887. In 1890 he toured the coal mines of Donetsk with his brother, gathering material for a collection of sketches called \"The Underground Kingdom\", detailing the struggles and hardships of the exploited miners, which he published in 1892.\n\nDuring the 1890s, Veresaev joined a group known as the Legal Marxists, and he published works in such journals as \"New Word\", \"Inception\" and \"Life\". During this period he wrote a cycle of works concerning the intelligentsia’s frame of mind at the turn of the 20th century, including the novella \"Without a Road\" (1895), the short story \"The Craze\" (1898) and the novella \"At the Turning Point\" (1902). He also wrote about the difficult position of the Russian peasantry, such as in the short story \"Lizar\" (1899) which was praised by Vladimir Lenin. His short story \"On a Dead-end Road\" (1896) and the novella \"Two Ends\" (1899–1903) were devoted to the life of the workers.\n\nDuring the first decade of the 20th century Veresaev was a member of the Sreda (Wednesday) literary group and published his works in Maxim Gorky's Znanie collections. He published his most successful book, the semi-autobiographical \"Memoirs of a Physician\" in 1901, in which he sharply criticized the system of Russian medical education. In April 1901 he was dismissed from the hospital where he'd been working because of his political views, and was forbidden to live in Moscow or Saint Petersburg for a period of two years.\n\nIn 1904, at the outbreak of the Russo-Japanese War, he joined the army as a doctor. He told of his experiences in his book \"In the War\", published in 1906. In this work he showed the heroism of Russian soldiers and officers and, at the same time, the corruption of the tsarist army.\n\nVeresaev also wrote a long critical and philosophical work entitled \"Vital Life\", the first book of which (1910) was devoted to a comparative analysis of Fyodor Dostoevsky (\"Man Accursed\") and Leo Tolstoy (\"Long Live the Whole World!\"); the second book, \"Apollo and Dionysius\" (1915), was a critique of Friedrich Nietzsche's views. In 1911 Veresaev established the Pisately v Moskve Publishing House which he headed until 1918.\n\nAfter the 1917 Revolution, which he welcomed, he devoted much of his time to cultural development and education. He also completed his cycle of works about the intelligentsia, including the novels \"In a Blind Alley\" (1922- translated into English as \"The Deadlock\") and \"The Sisters\" (1933). He published his reminiscences \"In the Years of My Youth\" in 1927 and \"In My Student Years\" in 1929. He also translated works by ancient Greek and Roman authors, including Homer’s Hymns, Sappho, Archilochus and others. At the end of the 1930s he began to translate the Iliad (published in 1949) and the Odyssey (published in 1953).\n\nFor his outstanding achievements in the field of literature Veresaev was awarded the Stalin Prize in 1945. He was also awarded the Order of the Red Banner of Labour. He died in Moscow in June 1945.\n\n"}
{"id": "3601611", "url": "https://en.wikipedia.org/wiki?curid=3601611", "title": "Visual pollution", "text": "Visual pollution\n\nVisual pollution is an aesthetic issue and refers to the impacts of pollution that impair one's ability to enjoy a vista or view.\nVisual pollution disturbs the visual areas of people by creating harmful changes in the natural environment. Billboards, open storage of trash, antennas, electric wires, buildings, and automobiles are often considered visual pollution.\nAn overcrowding of an area causes visual pollution. Visual pollution is defined as the whole of irregular formations, which are mostly found in nature.\n\nEffects of exposure to visual pollution include: distraction, eye fatigue, decreases in opinion diversity, and loss of identity.\n\nLocal managers of urban areas sometimes lack control over what is built and assembled in public places. As businesses look for ways to increase the profits, cleanliness, architecture, logic and use of space in urban areas are suffering from visual clutter. Variations in the built environment are determined by the location of street furniture such as public transport stations, garbage cans, large panels and stalls. Insensitivity of local administration is another cause for visual pollution. For example, poorly planned buildings and transportation systems create visual pollution. High-rise buildings, if not planned properly or sufficiently, can bring adverse change to the visual and physical characteristics of a city, which may reduce said city's readability\n\nA frequent criticism of advertising is that there is too much of it. Billboards, for example, have been alleged to distract drivers, corrupt public taste, promote meaningless and wasteful consumerism and clutter the land. See highway beautification. However, with the introduction of new communication technologies the fragmentation and incentive nature of advertising methods will improve, reducing clutter. Thus, with the increase of mobile device usage, more money goes to advertising on social media websites and mobile apps. Vandalism, in the form of graffiti is defined as street markings, offensive, inappropriate, and tasteless messages made without the owner’s consent. Graffiti adds to visual clutter as it disturbs the view.\n\nIn the United States, there are several initiatives gradually taking place to prevent visual pollution. The Federal Highway Beautification Act of 1965 limits placement of billboards on Interstate highways and federally aided roads. It has dramatically reduced the amount of billboards placed on these roads. Another highway bill, the Intermodal Surface Transportation Efficiency Act (ISTEA) of 1991 has made transportation facilities sync with the needs of communities. This bill created a system of state and national scenic byways and provided funds for biking trails, historic preservation and scenic conservation.\n\nThe Dunn Foundation is an organization that increases public awareness of visual pollution and landscape appearance in America through educational programs. The foundation has designed an educationally interactive package for students from grades 3-12 on how to improve the visual environment in their communities. Another company working toward prevention of visual clutter is Scenic America; a non-profit organization that envisions a future movement toward ensuring that scenic conservation boosts the economy and decreases visual pollution. Businesses situated near an interstate can create problems of advertising through large billboards, however now an alternative solution for advertisers is gradually eliminating the problem. For example, logo signs that provide directional information for travelers without disfiguring the landscape are increasing and are a step toward decreasing visual pollution on highways in America. Thus, researchers believe that planners should help and encourage citizens to maintain their communities as citizens have the power to influence government, especially local and regional management where most issues regarding appearance and disclosed.\n\nIn September 2006, São Paulo passed the Cidade Limpa (Clean City Law), outlawing the use of all outdoor advertisements, including on billboards, transit, and in front of stores.\n\n\nChmielewski, Sz., Lee, D., Tompalski, P., Chmielewski, T., J., Wężyk, P. (2016) Measuring visual pollution by outdoor advertisements in an urban street using intervisibility analysis and public surveys. International Journal of Geographical Information, 30(4): 801-819. DOI: 10.1080/13658816.2015.1104316\n\n"}
{"id": "35677938", "url": "https://en.wikipedia.org/wiki?curid=35677938", "title": "Xinxiang Hygiene School", "text": "Xinxiang Hygiene School\n\nXinxiang Hygiene School is a sanitation college in the Chinese city of Xinxiang.\n"}
