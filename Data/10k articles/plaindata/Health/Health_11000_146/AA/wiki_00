{"id": "32192878", "url": "https://en.wikipedia.org/wiki?curid=32192878", "title": "ASAPROSAR", "text": "ASAPROSAR\n\nASAPROSAR (Asociación Salvadoreña Pro-Salud Rural - The Salvadoran Association for Rural Health) is a non-governmental organization that provides health, education, environment and economic development programs in El Salvador.\n\nASAPROSAR was founded in 1986 by Dr. Vicky Guzmán. The organization developed out of Dr. Guzmán's work providing health services and training to rural communities in her native El Salvador in the 1970s. Founded during the Salvadoran Civil War, ASAPROSAR continued Dr. Guzman's work providing health services to the rural poor. In the 1990s, ASAPROSAR developed a post conflict resolution program that sought to help reintegrate ex-combatants from the civil war into society.\n\nHeadquartered in Santa Ana, El Salvador, ASAPROSAR has over 200 local employees in the education, health and social work fields. ASAPROSAR also has staff and volunteers based in the United States. Today, ASAPROSAR serves more than 150,000 people in El Salvador.\n\n\n"}
{"id": "40671302", "url": "https://en.wikipedia.org/wiki?curid=40671302", "title": "Akanksha Infertility Clinic", "text": "Akanksha Infertility Clinic\n\nThe Akanksha Infertility Clinic is a women's health centre located in Anand, Gujarat, India, and\nheaded by Dr Nayna Patel. The clinic was founded in 1999, and was originally focused on In Vitro Fertilization. India declared commercial surrogacy legal in 2002; however the clinic did not begin to do surrogacy until 2004. Patel, who appeared on Oprah Winfrey's talk show in 2007, has produced more than 1000 surrogate babies as of October 2015.\n\nPatel states that \"we provide a legitimate service to those in need, whether it is the couple who desperately want a child or the woman who wishes to change her circumstances, to educate her children, build a house or pay off debts.”\n\nHow this works is a couple will go to the clinic, request a surrogate, and essentially rent her womb for the next nine months. The surrogate will be implanted with the sperm and egg, and hopefully after having a successful birth, will give up the child to its parents. The women are then paid. Dr. Patel pays her surrogates around 400,000 rupees ($6,500). Couples are charged an average of $25,000 to $30,000 per baby.\n\nOf the women who work as surrogates “nearly half described themselves as housewives and the rest were a mix of domestic, service, and manual laborers” . Most of them are married and have children of their own. They must live at the clinic, are heavily monitored and restricted, and are not allowed sex for the duration of their pregnancy. Their young children are allowed to stay with them, as a way to prevent to the women from getting attached to the baby they are carrying. During their required stay “residents are offered daily English classes and weekly lessons in computer use” and the director “arranges film screenings and gives out school backpacks and pencil boxes to surrogates’ children\".\n\nIn India, “surrogacy...is slated to add $2 billion to the nation's gross domestic product”. So the country gets money, the surrogates get the needed money, and a couple gets a baby.\n\nFor comparison, in USA, the cost is $150,000, in a handful of states where it is permitted. \nFor surrogates, the compensation outweighs the downside. A recent surrogate was the wife of an auto-rickshaw driver with three daughters of her own. she had to live in a hostel for nine months with 60 other surrogates so the clinic could monitor her health.\n\nAkanksha claims an implantation success rate of 44%, similar to other Indian clinics, compared with a US norm of 31%.\n\nWhile surrogacy is legal, it is highly unregulated. There is are laws in the progress of being made to attempt to aid the surrogate mothers. However it does “little to improve the life for women” and takes away their rights to decide whether they want an abortion or not. Another problem is that “lack of regulation could spark a price war for surrogacy”. This means that other countries could have surrogates willing to be paid a lower wage per baby carried. This leads to surrogate clinics basically competing against other clinics in other countries, creating a “race to the bottom.” If this happens then the protections for surrogate mothers could decrease; “with countries slowly under-cutting fees and legal protections for surrogates along the way”.\n\nThere are other cultural consequences as well. Women who are surrogates face the risk and consequences of being rejected from society or being discriminated against. There is another issue, the “dilemma of all rural surrogates: being suspected of adultery -a cause for shunning or worse”.\n\nThere was an issue of the citizenship of children, as many countries do not recognize surrogacy and these babies therefore have no legal standing \n\nA Japanese baby girl born to an Indian surrogate mother was in legal limbo after the couple who had intended to raise her divorced. The three-month-old baby had been unable to leave India after her birth because she holds neither an Indian nor a Japanese nationality. The issue was resolved after the Japanese Government issued a one-year visa to her on humanitarian grounds, after the Indian Government had granted the baby a travel certificate in September in line with a Supreme Court direction.\n\nIn October 2015 a letter was sent by Indian Council of Medical Research (ICMR). The letter bans foreign couples getting Indian surrogates. This sparked public outcry and protests. People are concerned about the affect the ban will have on the economy of Anand.\n\nThe surrogacy industry has played a role in transforming the economy of Anand in India and financially bettering the lives of thousands of poor families and the government’s recent move to ban the practice will wipe out incomes. “About 5,000 families in Anand are surviving on surrogacy,” says Dr Patel, whose clinic has been at the forefront of the country’s commercial surrogacy sector. “There are the surrogates, the nannies, the rickshaw drivers, the hoteliers who employ hundreds of peoples, the restaurants, the shops. There are so many people directly or indirectly surviving on surrogacy, so it’s going to be a huge economic impact as far as Anand is concerned.”\n\nIn 2008 a law - the Assisted Reproductive Technologies Bill (ART) - was introduced to protect surrogates, the children and the commissioning parents.\n\nDr Anup Gupta, the founder of Delhi IVF, a clinic that handles five to six cases a month said that \"The legislation will facilitate surrogacy\".\n\nDraft, Assisted Reproductive Technologies Bill, http://icmr.nic.in/guide/ART%20REGULATION%20Draft%20Bill1.pdf, MINISTRY OF HEALTH & FAMILY WELFARE\nGOVT. OF INDIA, NEW DELHI\n\n"}
{"id": "9987647", "url": "https://en.wikipedia.org/wiki?curid=9987647", "title": "An Encyclopedia of Claims, Frauds, and Hoaxes of the Occult and Supernatural", "text": "An Encyclopedia of Claims, Frauds, and Hoaxes of the Occult and Supernatural\n\nAn Encyclopedia of Claims, Frauds, and Hoaxes of the Occult and Supernatural is a 1995 book by James Randi with a foreword by Arthur C. Clarke. It serves as a reference for various pseudoscience and paranormal subjects.\n\nIn 2006 Randi made the work available free online.\n\n\n"}
{"id": "3166587", "url": "https://en.wikipedia.org/wiki?curid=3166587", "title": "Association of Mouth and Foot Painting Artists of the World", "text": "Association of Mouth and Foot Painting Artists of the World\n\nThe Association of Mouth and Foot Painting Artists of the World (AMFPA) is a for-profit international organization facilitating the sale of artwork produced by mouth and foot painting artists associated with the organization. None of the artists have proper use of their hands as a pre-condition to joining the association. It represents around 820 artists located in 76 countries, of whom 143 ( as of 2016) are full members, and receive a monthly fee from the organization from the date of their admission until their death. The other artists are students, who receive a monthly scholarship until such time as they are promoted.\n\nThe main product of the organization is Christmas cards designed by the member artists. These cards are sold every year in the months leading up to Christmas via direct mailing in 48 countries around the world. Other products include postcards, art prints and calendars.\n\nThe parent company in Liechtenstein acquires the reproduction rights of a given painting and distributes it internationally. The original works are also sold at exhibitions held throughout the world. Works produced by the members have been shown in the United Nations Office at Geneva and at the European Council in Strasbourg.\n\nAMFPA was founded in 1957 as the Vereinigung der Mund- und Fussmalenden Künstler in aller Welt, e. V. (VDMFK), in Liechtenstein. It was styled a \"self-help\" organization and had the scope to further the painting skills of any mouth or foot painter, to promote their artwork and to support them financially.\n\nThe first president of the association, Arnulf Erich Stegmann, was a prominent figure in the development of mouth and foot painting. Born in 1912 in Darmstadt, Germany, Stegmann lost the use of both arms from polio at the age of two. Regardless, his artistic talents were soon recognized and supported by his teachers. He was proficient with a variety of brushes and styles, using only his mouth. He was educated at the School of Higher Education for Book Trade and Graphics in Nuremberg and studied with the artists Erwin von Kormöndy and Hans Gerstacker. He made a living selling his art cards and prints at marketplaces. After the Second World War he established his own publishing company with the poignant name \"Dennoch\" (\"Anyway\").\n\nIn 1953/54 he organized the \"Lodge of Mouth and Foot Painting Artists\" as a type of artists' community. This developed into the international \"Association of Mouth and Foot Painting Artists\", with Stegmann elected president for life.\n\nThe association's stated objectives are:\n\nThe association is run as a \"democratic co-operative\". Any mouth and foot painter of unimpeachable reputation living anywhere in the world can become a member of the association, provided they are 18 years of age and their works are considered artistic by the Jury who then recommends them for membership to the Managing Board.\n\nThe management procedures are governed by the statutes, which require that a Delegates Convention or General Assembly of all members must be held at least once every three years.\n\nFor electoral purposes, the Association divides the world into four regions: Europe, Africa and the Middle East; the Americas; the Far East; Australasia and Oceania. Each region deputes at least one delegate for every five members.\n\nThe managing board members and the president are elected by the members of the association. With the exception of the legal representative, every managing board member has to be a recognized mouth or foot painter.\n\nThe Mouth and Foot Painting Artists (MFPA) is the British organization for mouth and foot painters, and is a member organization of AMFPA. It was established in 1973 following legislation which required that disabled people be in charge of the business activities of an organization representing them.\n\nDuring the last 50 years paintings and artworks of mouth- and footpainters haven\\ been shown in numerous museums and town halls around the world. International exhibitions were held, for instance, in the following venues:\n\nAMFPA has many customers and supporters from around the world who appreciate and understand the difficult lives and inspiring works of the artists. Among those prominent figures to have spoken in favour of, met or celebrated lives of AMFPA artists are the Pope, Pierce Brosnan, HRH Prince Harry, Queen Sofia of Spain, Heinz Fischer, former president of Austria, Ma Ying-Jeou, former president of Taiwan, Bertel Haarder, Danish Minister for culutre and church, Mauricio Macri, current president of Argentina, Arnold Schwarzenegger 38th Governor of California, Salman Kahn, Amitabh Bachchan, Honorable Mr Narendra Modi, Prime Minister of India, David Dimbleby, Seal, Keith Chesney, HRH Prince Charles, Al Gore 45th Vice President of the United States, Morgan Freeman, (the late) Sir Terry Wogan KBE, Frederick Forsythe CBE, Kathy Lee Gifford, Jonny Wilkinson MBE, Anton Du Beke, Susan Boyle, David Coulthard MBE, Sir Bradley Wiggins, Sir Geoffrey Boycott, Alesha Dixon, KT Tunstall, Aled Jones, Bennett Gartside, Sean Lock, Rula Lenska, Kathy Lee Gifford, Katie Couric, HRH Sophie, Countess of Wessex, Sir Harold Evans, Rt. Hon. Boris Johnson MP, Rt. Hon. William Hague MP, David Shepherd OBE, Lorraine Kelly, Rafael Nadal, Ram Nath Kovind President of India, Prince William Duke of Cambridge, Pau Gasol, Prokopis Pavlopoulos President of Greece\n\nThen years ago AMFPA has been the subject of several exposés in German, French, Swiss, Swedish, Norwegian, Polish, British, Canadian and Danish media, suggesting unethical behaviour within the organization. The coverage has spurred criticism from charity, consumer and handicap organizations. The criticism included:\n\n\nNo claims have been made suggesting any illegal activity by AMFPA. The criticism has been centred on what is perceived as bad ethics.\n\nThe AMFPA has in some news reports and court hearings responded to some of the claims, stating that AMFPA has never intentionally presented itself as a charitable organization, but instead has explicitly pointed its commercial nature out to consumers. AMFPA has also stated that 80% of the worldwide profits are distributed among the artists. AMFPA declined to present financial records to support this claim.\n\nAMFPA stated that it never introduced pressure sales tactics but made use of direct mailing many years before competitors and charity organisations introduced similar methods. AMFPA sees itself as a victim of an unfair and tendentious journalistic coverage lacking of true facts and suspecting bad ethics.\n\nIn June 2007 the company sued the Danish Broadcasting Corporation and Danish daily \"Ekstra Bladet\" for libel, following negative coverage during December 2005. On 10 October 2008, the High Court of Eastern Denmark ruled in favor of the accused journalists, stating that there was sufficient factual basis for statements like: \"Behind the scenes we found a well-oiled money making machine with economic puppeteers, who are scraping in money with arms and legs\"; \"People think they are supporting a charity, but in reality we are looking at a money making machine\"; and \"...only a measly 3% is going to the mouth and foot painting artists\". AMFPA did not appeal the decision.\n\n"}
{"id": "38348312", "url": "https://en.wikipedia.org/wiki?curid=38348312", "title": "Bioenhancer", "text": "Bioenhancer\n\nBioenhancers or bioavailability enhancers is a new chapter in medical science first scientifically established in 1979 after the discovery of world's first bioenhancer Piperine. It is a pocket friendly drug technology which reduces the destruction, wastage and elimination of several orally administered drugs inside the body.\n\nDefinition Bioenhancers are defined as substances that increase the bioavailability and bioefficacy of active substances with which they are combined without having any activity of their own at the dose used. Besides several classes of modern drugs like antibiotics, anti cancer drugs, cardiovascular drugs, anti inflammatory, central nervous drugs, etc., they also increase the bioavailability of vitamins and nutrients.\n\nIncreased Bioavailabiity means increased levels of drug in the blood stream available for drug action. Increased Bioefficecy means the increased effectiveness of the drug due to increased bioavailability and also due to other mechanisms.\nSignificance of Bioenhancers\nDue to an increased bioavailability, the dose and cost of active drug can be reduced, making the formulation cheaper and safer, better tolerated, having better efficacy, better compliance and having lesser risk of developing drug resistance as in case of antibiotics. As it benefits the dose economy,it is particularly of great value to poor ill diseased segment of society.For example, by reducing the required dose of expensive toxic Rifampicin by 60 percent,it correspondingly reduces the cost and side effects of Rifampicin while treating the dreaded disease Tuberculosis.\n\nHistory \nBioenhancers or bioavailability enhancers as a term and chapter did not exist in any modern scientific literature prior to 1979. The term bioavailability enhancers was first coined in 1979 at Indian Institute of Integrative medicine, Jammu, formerly RRL,Jammu, by Indian scientists (Dr. C. K. Atal, the Director of institute RRL Jammu proposed the hypothesis of increased bioavailability of drugs from a clue during research on traditional medicinal drugs). Subsequently, the concept of bioavailability enhancers was scientifically researched and scientifically established by him and his research team at RRL Jammu. The institute then discovered and scientifically validated Piperine as the world's first bioenhancer using Sparteine and Vasicine which became the world's first experimentally bioenhanced drugs. Dr.Atal also initiated the bioenhanced anti tubercular drug research project using Rifampicin which later resulted in development of world's first bioenhanced anti tubercular drug formulation. This DCGI approved formulation was officially released by Indian government at Anusandhan Bhawan Delhi on world tuberculosis day 2011, and also presented to Mr. Bill Gates, chairman of Microsoft same day at a function at Le Meridian in Delhi.\n\nAfter the discovery of bioenhancer Piperine in 1979, a new chapter was added in medical science. Since then it has generated global interest and research in the field and has led to discovery of many other new bioenhancers. Piperine remains the most potent and extensively researched bioenhancer till date. It is safe, effective, extremely economical and easily manufactured for commercial use.It is also a broad spectrum bioenhancer acting on several classes of modern drugs as noted elsewhere.\n\nClassification bioenhancers can be classified according to their source of origin, either plant based or animal based or else according to their site of action.\n\nBioenhancers so far almost exclusively discovered in plants, increase the bioavailability of other substances in different ways:\n\nReduced bioavailability of orally administered drugs by Destruction, elimination and wastage inside the body\n\n• After oral ingestion and absorption, drugs reach the blood stream where the drug needs to attain a certain desired drug level in the blood to cause desired drug action.\n• After oral ingestion and absorption, drugs while passing from the gut via the liver to blood stream are inadequately absorbed, wasted, eliminated and destroyed and therefore a reduced percentage of ingested dose reaches the blood stream resulting in lower drug levels in blood.\n• Therefore, more quantity of drug has to be ingested to compensate for the losses in order to achieve desired blood levels which in turn increase the cost and side effects of drugs.\n\nBillions of Dollars are wasted globally in various countries due to poor bioavailability of drugs, which is a huge financial burden on any nation, particularly poor developing countries.This is particularly relevant in serious and dreaded diseases on mankind like tuberculosis for which treatment is expensive, toxic and prolonged and for which an emergency situation has been declared by UN due to emergence of AIDS and development of serious drug resistance.\n\n'BENEFICIAL ROLE OF BIOENHANCERS'\n\nReduced dose- Bioenhancers prevent this wastage of ingested drugs inside the body and increase quantity of drug reaching the blood, therefore a reduced dosage of oral drug is sufficient to achieve the desired blood levels.\n\nReduced burden on raw material of country -This reduced dose needed for desired drug action means beneficial effect on raw materials consumption required to develop drugs which is a great savings for any country.\n\nEcological advantage- This also translates into ecological advantage in case of rare and expensive plant based drugs as less trees or plant have to be consumed to produce drugs, an example being the costly anti cancer drug Taxol derived from very slow growing Yew trees .\n\nReduced drug cost- This reduced dose in turn also reduces the cost of drugs.\n\nReduced adverse reactions- This reduced dose in turn also reduces the side effects of drugs.\n\nImproved compliance- Lesser side effects also improve drug tolerability, drug compliance and promote completion of treatment.\n\nReduced drug resistance- This improved tolerability and compliance in turn reduces risk of developing dangerous drug resistance.\n\nAdded hepatoprotective and gastroprotective actions of bioenhacer piperine reduces gastrointestinal side effects and hepatotoxicity of primary active drug which further makes formulation safer, better tolerated and again reduces drug toxicity and drug resistance.\n\nThis is a great advantage to poor patients, poor countries and for dreaded diseases of man.\n\nThe following examples of bioenhancers give an insight into the current pharmacological research and show how with pepper, curry, ginger and other herbal ingredients in food a lack of nutrients or insufficient effects of active agents can be prevented:\n\nPiperine, an ingredient of pepper, promotes intestinal absorption by activation of the γ-glutamyltranspeptidase and inhibits the degradation of many compounds, by inhibiting different enzymes: aryl hydrocarbon hydroxylase (AHH), ethylmorphine N-demethylase, Uridine diphosphate (UDP) glucuronyltransferase (UGT), P-glycoprotein and CYP3A4. Especially the latter two enzymes contribute significantly to the first-pass effect.\n\nPiperine acts as bioenhancer to vitamins (A, B1, B2, B6, C, D, E, K), amino acids (lysine, isoleucine, leucine, threonine, valine, tryptophan, phenylalanine, and methionine), minerals (iodine, calcium, iron, zinc, copper, selenium, magnesium, potassium, manganese), herbal compounds (including ginsenosides, Pycnogenol), and drugs (such as ibuprofen, diclofenac, rifampicin, ampicillin, tetracycline, vasicine, pyrazinamide, fexofenadine, resveratrol, epigallocatechin, curcumin).\n\nAllicin from garlic enhances the effect of the fungicide amphotericin B on yeast cells by affecting the transport of the fungicide into the yeast vacuole.\n\nCurcumin which inter alia is found in curry inhibits like piperine the enzyme CYP3A4 and affects the transport function of P-glycoprotein. In combination with curcumin an increased bioavailability of the active compounds celiprolol and midazolam was detected.\n\nGinger promotes due to the gingerols the intestinal absorption of many compounds (including drugs) and elements. In most cases, ginger acts synergistically with piperine.\n\nGlycyrrhizin, a saponin of the liquorice plant, promotes the action of numerous antibiotics and the antifungal agent clotrimazole.\n\nQuercetin, a flavonoid from fruits and leaves, acts like curcumin and piperine. It increases the bioavailability of the active agent paclitaxel used to treat cancer.\n\nThe bioenhancer technology is primarily targeted for toxic drugs, expensive drugs, scarce drugs,poorly bioavailable drugs or drugs which need to be given for prolonged periods. However it can also be used in any drugs influenced by bioenhancers. The discovery and characterization of bioenhancers has led to several patent applications. Piperine is marketed as bioenhancer in mono preparations and as a component of dietary supplements that contain different vitamins, curcumin, resveratrol or Coenzyme Q.\n\nSince bioenhancers can reduce the dosage and cost of expensive medication while making treatment safer, its application has for the first time been done in humans in treating tuberculosis for which the existing drugs are toxic and expensive and need to be administered over prolonged periods. In India where low treatment costs for medical care are essential, the drug Risorine is approved against tuberculosis. Besides the antibiotics rifampicin and isoniazid it contains piperine.\n"}
{"id": "1431131", "url": "https://en.wikipedia.org/wiki?curid=1431131", "title": "Bureau of Oceans and International Environmental and Scientific Affairs", "text": "Bureau of Oceans and International Environmental and Scientific Affairs\n\nThe Bureau of Oceans and International Environmental and Scientific Affairs (OES) is a bureau within the United States Department of State. It coordinates a portfolio of issues related to the world's oceans, environment, science and technology, and health.\n\nThe Bureau is headed by the Assistant Secretary of State for Oceans and International Environmental and Scientific Affairs. As of April 2014, it is headed by acting Assistant Secretary Judith Garber. \n\nThe Oceans and Fisheries Directorate has two offices dedicated to international oceans issues. The Office of Marine Conservation focuses on international fisheries matters and related problems and the Office of Oceans and Polar Affairs has primary responsibility for international ocean law and policy, marine pollution, marine mammals, polar affairs, maritime boundaries, and marine science. It is headed by Deputy Assistant Secretary David A. Balton.\n\nThe Environment Directorate deals with environmental issues including environmental aspects of international trade and safeguarding hazardous materials requiring multilateral agreements within the Office of Environmental Quality and Transboundary Affairs. The Office of Conservation and Water develops U.S. foreign policy approaches to conserving and managing the world ecosystems and to transboundary water issues. The Environment Directorate is headed by Deputy Assistant Secretary Daniel Reifsnyder. \n\nThe Health, Space and Science Directorate includes the Office of International Health Affairs which works with U.S. Government agencies to facilitate policy-making regarding international bioterrorism, infectious disease, surveillance and response, environmental health, and health in post-conflict situations. The Office of Space and Advanced Technology handles issues arising from our exploration of space to assure global security regarding this new frontier, and the Office of Science & Technology (S&T) Cooperation promotes the interests of the U.S. science and technology communities in the international policy arena, negotiates framework and other S&T agreements, manages the Department's Embassy Science fellows program, and takes a leading role in representing U.S. science and technology in multilateral international organizations, such as UNESCO and other UN organizations, APEC, OECD and others. The Health, Space and Science Directorate is headed by acting Deputy Assistant Secretary Jonathan Margolis.\n\n"}
{"id": "34474694", "url": "https://en.wikipedia.org/wiki?curid=34474694", "title": "CT Value", "text": "CT Value\n\nCT Values are an important part of calculating disinfectant dosage for the chlorination of drinking water. A CT value is the product of the concentration of a disinfectant (e.g. free chlorine) and the contact time with the water being disinfected. It is typically expressed in units of mg-min/L.\n\nThe goal of disinfection is the inactivation of microorganisms. This depends on: the microorganism, the disinfectant being used, the concentration of the disinfectant, the contact time, and the temperature and pH of the water.\n\nThe disinfection kinetics are conventionally calculated via the Chick-Watson model, named for the work of Harriette Chick and H.E. Watson. This model is expressed by the following equation:\n\nWhere:\n\nThe survival ratio is commonly expressed as an inactivation ratio (in %) or as the number of reductions in the order of magnitude of the microorganism concentration. For example, a situation where N=10 CFU/L and N=10 CFU/L would be reported as a 99.9% inactivation or \"3-log\" removal.\n\nIn water treatment practice, tables of the product C×t are used to calculate disinfection dosages. These tables express the required CT values to achieve a desired removal of microorganisms of interest in drinking water (e.g. \"Giardia lamblia\" cysts) for a given disinfectant under constant temperature and pH conditions. A portion of such a table is reproduced below.\n\nCT Values for the Inactivation of Giardia Cysts by Free Chlorine at 5 °C and pH ≈ 7.0:\n\nFull tables are much larger than this example and should be obtained from the regulatory agency for a particular jurisdiction.\n\n"}
{"id": "56205602", "url": "https://en.wikipedia.org/wiki?curid=56205602", "title": "Cannabis in the Gambia", "text": "Cannabis in the Gambia\n\nCannabis in the Gambia is illegal. It is known locally as yamba or tie and is the most used illegal drug in the country.\n"}
{"id": "50059840", "url": "https://en.wikipedia.org/wiki?curid=50059840", "title": "Capital punishment in Bangladesh", "text": "Capital punishment in Bangladesh\n\nCapital punishment in Bangladesh is a legal form of punishment for anyone who is over 16, however in practice will not apply to persons under 18. Crimes that are currently punishable by death in Bangladesh are set out in the \"Penal Code\" 1860. These include waging war against Bangladesh, abetting mutiny, giving false evidence upon which an innocent person suffers death, murder, assisted suicide of a child, attempted murder of a child and kidnapping. The \"Code of Criminal Procedure\" 1898 provides that \"he be hanged by the neck until he is dead.\" For murder cases, the Appellate Division requires trial courts to weigh aggravating and mitigating factors to determine whether the death penalty is warranted.\n\nThe Constitution of Bangladesh does not anywhere expressly recognise International Human Rights law, although some articles recognise international human rights. Article 25 of the Constitution recognises the United Nations Charter. Article 47 recognises international humanitarian law and provides that the Constitution will not limit the application of international treaties and the law of war.\n\nA person can receive the death penalty if they are found guilty of crimes against women and children. The \"Women and Children Repression Prevention Act\" 2000 provides that the death penalty can be imposed for murder or attempted murder involving burning, poison, or acid. Causing grievous bodily harm by burning, poison or acid, if the victims eyesight, hearing, face, breasts or reproductive organs are damaged. Therefore, criminals in Bangladesh can be sentenced for death for attempted crimes and causing grievous bodily harm.\n\nA number of offences (crimes not result in death) are punishable by death when committed by armed forces personnel. These offences include, providing aid to the enemy, cowardice and desertion and inducement to such and cowardly use of a flag of truce or any act calculated to imperil Bangladesh.\n\nBangladesh was created as a consequence of human rights abuses. When the Awami League won Pakistan’s first election in 1970, the Pakistani Army brutally suppressed the Bengali people in East Pakistan. More than three million people were left dead, millions of women were raped, tens of millions of people were forced into extremely dirty and unpleasant refugee camps in India. After India briefly invaded, Bangladesh was free from the brutality of Pakistani rule but faced a difficult task of rebuilding a country that was already desperately poor and prone to natural disasters. To this day, Amnesty International believes Bangladesh is still wracked with human rights violations.\n\nThe People’s Republic of Bangladesh has ratified some International Human Rights Treaties. However, the government has registered some declarations and reservations to particular articles of certain treaties. One reservation of particular importance is the reservation to Article 14 paragraph 1 of the Convention Against Torture (CAT). The reservation grounds were that Bangladesh would apply it “in consonance with the existing laws and legislation of the country.”\n\nBangladesh has not yet ratified or acceded to a number of International Human Rights Treaties. The International Covenant on Civil and Political Rights: 1976 was ratified in 2000. However, the Optional Protocol to the International Covenant on Economic, Social and Cultural Rights (ICESCR) and the Optional Protocol to the International Covenant on Civil and Political Rights (ICCPR) have not yet been ratified. The Second Protocol to the International Covenant on Civil and Political Rights, aiming at the abolition of the death penalty: 1991 has also not yet been ratified.\n\nThe Human Rights Council under the Universal Periodic Review reviewed Bangladesh in 2009. A strong recommendation was made for the abolition of the death penalty. The Bangladesh government in response to this said: “The death penalty is maintained in Bangladesh only as an exemplary punishment for heinous crimes such as throwing of acid, acts of terrorism, planned murder, trafficking of drugs, rape, abduction of women and children. Both the judiciary and administration deal with these cases of capital punishment with extreme caution and compassion, and such punishment is extended only in ultimate cases that relates to gross violation of human rights of the victims. Bangladesh has an extremely low rate of implementation of such death penalties.”\n\nThe fact that a very wide range of crimes are punishable by death is potentially conflicting with Bangladesh's International obligations. Allowing the death penalty for crimes such as kidnapping or drug trafficking is contrary to the ICCPR's mandate which states the death penalty should only be applied in the most serious of cases.\n\nThe Women and Children Repressive Prevention Act 2000 provides that the punishment required for a person who causes death for dowry is a mandatory death sentence. This therefore means there is no other alternative punishment available and the jury are deprived the ability to apply discretion to certain circumstances relating to the crime or the accused.\n\nThis case is an example of the potentially unjust outcomes that can result from mandatory death sentences. \nOn 12 July 2001, Shukar Ali, a 14 year old boy who was convicted of sexually assaulting a 7 year old girl which resulted in her death. At the time, the summer of 1999, Ali lived with his mother and elder sister in the slums of western Bangladesh’s Manikganj District. He was not in a financial position to afford legal assistance , so he was appointed a defence lawyer by the State. This was not standard practice, however in this case was necessary because of the severity of the punishment that Ali would face if found guilty. Ali was sentenced by the High Court Division to death by hanging under section 6 of an earlier version of the Women and Children Repressive Prevention Act, 1995. The court compelled they were compelled to make this decision regardless of his age. The court held \"no alternative punishment has been provided for the offence that the condemned prisoner has been charged and we are left with no other discretion but to maintain the sentence if we believe that the prosecution has been able to prove beyond reasonable doubt. This is a case, which may be taken as \"hard cases make bad laws\".\nOn appeal, the Appellate Division commuted Ali's death sentence to life imprisonment for \"until natural death\". This was the first time the Supreme Court of Bangladesh has ever overturned a decision. The criminal law in Bangladesh has advanced significantly since Ali was first imprisoned. A law was introduced prohibiting the death penalty and life imprisonment for children. However, children are still held to be criminally responsible at the age of nine.\n\nOn 16 May 2010, the High Court Division of the Supreme Court of Bangladesh declared that sections 6(2), 6(3), and 6(4) of the Women and Children Repressive Prevention (Special Provision) Act, 1995 unconstitutional. The court held that regardless of the offence, legislation may not provide that mandatory death sentences are the only available punishment. The judge held, “A provision of law which deprives the court to use of its beneficent discretion in a matter of life and death, without regard to the circumstances in which the offence was committed and, therefore without regard to the gravity of the offence cannot but be regarded as harsh, unfair and oppressive. The legislature cannot make relevant circumstances irrelevant, deprive the court of its legitimate jurisdiction to exercise its discretion not to impose death sentence in appropriate cases. Determination of appropriate measures of punishment is judicial and not executive functions [sic]. The court will enunciate the relevant facts to be considered and weight to be given to them having regard to the situation of the case. Therefore we have no hesitation in holding the view that these provisions are against the fundamental tenets of our Constitution, and therefore, ultra vires the Constitution and accordingly they are declared void.\"\n\nThe International Crimes Tribunal (Bangladesh) (ICT of Bangladesh) is a domestic war tribunal in Bangladesh, which was set up to investigate and prosecute suspects for the genocide committed in 1971 by the Pakistan Army during the Bangladesh Liberation War. The first person to be convicted in the Tribunal was Abul Kalam Azad, he had already left the country so he was not present for his own trial. He was sentenced to death in 2013. The United Nations offered its support in 2009 to make sure that similar mistakes made by other Crimes tribunals were not made in Bangladesh. The head of the United Nations in Bangladesh said \"this is the first time Bangladesh is conducting war crimes tribunals and it is important it understands how other countries have held them. There are some countries where mistakes were made and we don't want Bangladesh to repeat those mistakes.\" However, there has been a shift since the commencement of the trials because there is concern the International Crimes Tribunal are not carrying out their obligations under Bangladesh's international human rights obligations, International Criminal law, and the Bangladesh Constitution. Bangladesh is a State party to the ICCPR, therefore they have an obligation to meet the key provisions. Especially the provisions regarding fair trials and the rights of accused persons.\n"}
{"id": "36777018", "url": "https://en.wikipedia.org/wiki?curid=36777018", "title": "Causes of cancer", "text": "Causes of cancer\n\nCancer is a disease caused by genetic changes leading to uncontrolled cell growth and tumor formation. The basic cause of sporadic (non-familial) cancers is DNA damage and genomic instability. A minority of cancers are due to inherited genetic mutations. Most cancers are related to environmental, lifestyle, or behavioral exposures. Cancer is generally not contagious in humans, though it can be caused by oncoviruses and cancer bacteria. The term \"environmental\", as used by cancer researchers, refers to everything outside the body that interacts with humans. The environment is not limited to the biophysical environment (e.g. exposure to factors such as air pollution or sunlight), but also includes lifestyle and behavioral factors. Over one third of cancer deaths worldwide (and about 75-80% in the United States) are potentially avoidable by reducing exposure to known factors. Common environmental factors that contribute to cancer death include exposure to different chemical and physical agents (tobacco use accounts for 25–30% of cancer deaths), environmental pollutants, diet and obesity (30–35%), infections (15–20%), and radiation (both ionizing and non-ionizing, up to 10%). These factors act, at least partly, by altering the function of genes within cells. Typically many such genetic changes are required before cancer develops. Aging has been repeatedly and consistently regarded as an important aspect to consider when evaluating the risk factors for the development of particular cancers. Many molecular and cellular changes involved in the development of cancer accumulate during the aging process and eventually manifest as cancer.\n\nAlthough there are over 50 identifiable hereditary forms of cancer, less than 0.3% of the population are carriers of a cancer-related genetic mutation and these make up less than 3–10% of all cancer cases. The vast majority of cancers are non-hereditary (\"sporadic cancers\"). Hereditary cancers are primarily caused by an inherited genetic defect. A cancer syndrome or family cancer syndrome is a genetic disorder in which inherited genetic mutations in one or more genes predisposes the affected individuals to the development of cancers and may also cause the early onset of these cancers. Although cancer syndromes exhibit an increased risk of cancer, the risk varies. For some of these diseases, cancer is not the primary feature and is a rare consequence.\n\nMany of these syndromes are caused by mutations in tumor suppressor genes that regulate cell growth. Other common mutations alter the function of DNA repair genes, oncogenes and genes involved in the production of blood vessels. Certain inherited mutations in the genes \"BRCA1\" and \"BRCA2\" with a more than 75% risk of breast cancer and ovarian cancer. Some of the inherited genetic disorders that can cause colorectal cancer include familial adenomatous polyposis and hereditary non-polyposis colon cancer; however, these represent less than 5% of colon cancer cases. In many cases, genetic testing can be used to identify mutated genes or chromosomes that are passed through generations. \n\n\nParticular substances, known as carcinogens, have been linked to specific types of cancer. Common examples of non-radioactive carcinogens are inhaled asbestos, certain dioxins, and tobacco smoke. Although the public generally associates carcinogenicity with synthetic chemicals, it is equally likely to arise in both natural and synthetic substances. It is estimated that approximately 20,000 cancer deaths and 40,000 new cases of cancer each year in the U.S. are attributable to occupation. Every year, at least 200,000 people die worldwide from cancer related to their workplace. Millions of workers run the risk of developing cancers such as lung cancer and mesothelioma from inhaling asbestos fibers and tobacco smoke, or leukemia from exposure to benzene at their workplaces. Cancer related to one's occupation is believed to represent between 2–20% of all cases. Most cancer deaths caused by occupational risk factors occur in the developed world. Job stress does not appear to be a significant factor at least in lung, colorectal, breast and prostate cancers.\n\nTobacco smoking is associated with many forms of cancer, and causes 80% of lung cancer. Decades of research has demonstrated the link between tobacco use and cancer in the lung, larynx, head, neck, stomach, bladder, kidney, esophagus and pancreas. There is some evidence suggesting a small increased risk of developing myeloid leukemia, squamous cell sinonasal cancer, liver cancer, colorectal cancer, cancers of the gallbladder, the adrenal gland, the small intestine, and various childhood cancers. Tobacco smoke contains over fifty known carcinogens, including nitrosamines and polycyclic aromatic hydrocarbons. Tobacco is responsible for about one in three of all cancer deaths in the developed world, and about one in five worldwide. Lung cancer death rates in the United States have mirrored smoking patterns, with increases in smoking followed by dramatic increases in lung cancer death rates and, more recently, decreases in smoking rates since the 1950s followed by decreases in lung cancer death rates in men since 1990. However, the numbers of smokers worldwide is still rising, leading to what some organizations have described as the \"tobacco epidemic\".\n\nElectronic cigarettes or e-cigarettes are handheld electronic devices that simulate the feeling of tobacco smoking. Daily long-term use of high voltage (5.0 V) electronic cigarettes may generate formaldehyde-forming chemicals at a greater level than smoking, which was determined to be a lifetime cancer risk of approximately 5 to 15 times greater than smoking. However, the overall safety and long-term health effects of electronic cigarettes is still uncertain.\n\nSome substances cause cancer primarily through their physical, rather than chemical, effects on cells. A prominent example of this is prolonged exposure to asbestos, naturally occurring mineral fibers which are a major cause of mesothelioma, which is a cancer of the serous membrane, usually the serous membrane surrounding the lungs. Other substances in this category, including both naturally occurring and synthetic asbestos-like fibers such as wollastonite, attapulgite, glass wool, and rock wool, are believed to have similar effects. Non-fibrous particulate materials that cause cancer include powdered metallic cobalt and nickel, and crystalline silica (quartz, cristobalite, and tridymite). Usually, physical carcinogens must get inside the body (such as through inhaling tiny pieces) and require years of exposure to develop cancer. Common occupational carcinogens include:\n\nMany different lifestyle factors contribute to increasing cancer risk. Together, diet and obesity are related to approximately 30–35% of cancer deaths. Dietary recommendations for cancer prevention typically include an emphasis on vegetables, fruit, whole grains, and fish, and avoidance of processed meat, red meat, animal fats, and refined carbohydrates. The evidence to support these dietary changes is not definitive.\n\nAlcohol is an example of a chemical carcinogen. The World Health Organization has classified alcohol as a Group 1 carcinogen. In Western Europe 10% of cancers in males and 3% of cancers in females are attributed to alcohol. Worldwide, 3.6% of all cancer cases and 3.5% of cancer deaths are attributable to alcohol. In particular, alcohol use has been shown to increase the risk of developing cancers of the mouth, esophagus, pharynx, larynx, stomach, liver, ovaries, and colon. The main mechanism of cancer development involves increased exposure to acetaldehyde, a carcinogen and breakdown product of ethanol. Other mechanisms have been proposed, including alcohol-related nutritional deficiencies, changes in DNA methylation, and induction of oxidative stress in tissues.\n\nSome specific foods have been linked to specific cancers. Studies have shown that individuals that eat red or processed meat have a higher risk of developing breast cancer, prostate cancer, and pancreatic cancer. This may be partially explained by the presence of carcinogens in food cooked at high temperatures. Several risk factors for the development of colorectal cancer include high intake of fat, alcohol, red and processed meats, obesity, and lack of physical exercise. A high-salt diet is linked to gastric cancer. Aflatoxin B1, a frequent food contaminate, is associated with liver cancer. Betel nut chewing has been shown to cause oral cancers.\n\nThe relationship between diet and the development of particular cancers may partly explain differences in cancer incidence in different countries. For example, gastric cancer is more common in Japan due to the frequency of high-salt diets and colon cancer is more common in the United States due to the increased intake of processed and red meats. Immigrant communities tend to develop the cancer risk profile of their new country, often within one to two generations, suggesting a substantial link between diet and cancer.\n\nIn the United States, excess body weight is associated with the development of many types of cancer and is a factor in 14–20% of all cancer deaths. Every year, nearly 85,000 new cancer diagnoses in the United States are related to obesity. Individuals who underwent bariatric surgery for weight loss have reduced cancer incidence and mortality.\n\nThere is an associated between obesity and colon cancer, post-menopausal breast cancer, endometrial cancer, kidney cancer, and esophageal cancer. Obesity has also been linked with the development of liver cancer. The current understanding regarding the mechanism of cancer development in obesity relates to abnormal levels of metabolic proteins (including insulin-like growth factors) and sex hormones (estrogens, androgens and progestogens). Adipose tissue also creates an inflammatory environment which may contribute to the development of cancers.\n\nPhysical inactivity is believed to contribute to cancer risk not only through its effect on body weight but also through negative effects on immune system and endocrine system. More than half of the effect from diet is due to overnutrition rather than from eating too little healthy foods.\n\nSome hormones play a role in the development of cancer by promoting cell proliferation. Insulin-like growth factors and their binding proteins play a key role in cancer cell growth, differentiation and apoptosis, suggesting possible involvement in carcinogenesis.\n\nHormones are important agents in sex-related cancers such as cancer of the breast, endometrium, prostate, ovary, and testis, and also of thyroid cancer and bone cancer. For example, the daughters of women who have breast cancer have significantly higher levels of estrogen and progesterone than the daughters of women without breast cancer. These higher hormone levels may explain why these women have higher risk of breast cancer, even in the absence of a breast-cancer gene. Similarly, men of African ancestry have significantly higher levels of testosterone than men of European ancestry, and have a correspondingly much higher level of prostate cancer. Men of Asian ancestry, with the lowest levels of testosterone-activating androstanediol glucuronide, have the lowest levels of prostate cancer.\n\nOther factors are also relevant: obese people have higher levels of some hormones associated with cancer and a higher rate of those cancers. Women who take hormone replacement therapy have a higher risk of developing cancers associated with those hormones. On the other hand, people who exercise far more than average have lower levels of these hormones, and lower risk of cancer. Osteosarcoma may be promoted by growth hormones.\n\nSome treatments and prevention approaches leverage this cause by artificially reducing hormone levels, and thus discouraging hormone-sensitive cancers. Because steroid hormones are powerful drivers of gene expression in certain cancer cells, changing the levels or activity of certain hormones can cause certain cancers to cease growing or even undergo cell death. Perhaps the most familiar example of hormonal therapy in oncology is the use of the selective estrogen-receptor modulator tamoxifen for the treatment of breast cancer. Another class of hormonal agents, aromatase inhibitors, now have an expanding role in the treatment of breast cancer.\n\nWorldwide, approximately 18% of cancer cases are related to infectious diseases. This proportion varies in different regions of the world from a high of 25% in Africa to less than 10% in the developed world. Viruses are the usual infectious agents that cause cancer but bacteria and parasites also contribute. Infectious organisms that increase the risk of cancer are frequently a source of DNA damage or genomic instability.\n\nViral infection is a major risk factor for cervical and liver cancer. A virus that can cause cancer is called an \"oncovirus\". These include human papillomavirus (cervical carcinoma), Epstein–Barr virus (B-cell lymphoproliferative disease and nasopharyngeal carcinoma), Kaposi's sarcoma herpesvirus (Kaposi's sarcoma and primary effusion lymphomas), hepatitis B and hepatitis C viruses (hepatocellular carcinoma), and Human T-cell leukemia virus-1 (T-cell leukemias).\n\nIn Western developed countries, human papillomavirus (HPV), hepatitis B virus (HBV) and hepatitis C virus (HCV) are the most common oncoviruses. In the United States, HPV causes most cervical cancers, as well as some cancers of the vagina, vulva, penis, anus, rectum, throat, tongue and tonsils. Among high-risk HPV viruses, the HPV E6 and E7 oncoproteins inactivate tumor suppressor genes when infecting cells. In addition, the oncoproteins independently induce genomic instability in normal human cells, leading to an increased risk of cancer development. Individuals with chronic hepatitis B virus infection are more than 200 times more likely to develop liver cancer than uninfected individuals. Liver cirrhosis, whether from chronic viral hepatitis infection or alcohol abuse, is independently associated with the development of liver cancer, but the combination of cirrhosis and viral hepatitis presents the highest risk of liver cancer development.\n\nCertain bacterial infections also increase the risk of cancer, as seen in Helicobacter pylori-induced gastric carcinoma. The mechanism by which \"H. pylori\" causes cancer may involve chronic inflammation or the direct action of some of the bacteria's virulence factors. Parasitic infections strongly associated with cancer include \"Schistosoma haematobium\" (squamous cell carcinoma of the bladder) and the liver flukes, \"Opisthorchis viverrini\" and \"Clonorchis sinensis\" (cholangiocarcinoma). Inflammation triggered by the worm's eggs appears to be the cancer-causing mechanism. Certain parasitic infections can also increase the presence of carcinogenic compounds in the body, leading to the development of cancers. Tuberculosis infection, caused by the mycobacterium \"M. tuberculosis\", has also been linked with the development of lung cancer.\n\nThere is evidence that inflammation itself plays an important role in the development and progression of cancer. Chronic inflammation can lead to DNA damage over time and the accumulation of random genetic alterations in cancer cells. Inflammation can contribute to proliferation, survival, angiogensis and migration of cancer cells by influencing tumor microenvironment. Individuals with inflammatory bowel disease are at increased risk of developing colorectal cancers.\n\nUp to 10% of invasive cancers are related to radiation exposure, including both non-ionizing radiation and ionizing radiation. Unlike chemical or physical triggers for cancer, ionizing radiation hits molecules within cells randomly. If it happens to strike a chromosome, it can break the chromosome, result in an abnormal number of chromosomes, inactivate one or more genes in the part of the chromosome that it hit, delete parts of the DNA sequence, cause chromosome translocations, or cause other types of chromosome abnormalities. Major damage normally results in the cell dying, but smaller damage may leave a stable, partly functional cell that may be capable of proliferating and developing into cancer, especially if tumor suppressor genes were damaged by the radiation. Three independent stages appear to be involved in the creation of cancer with ionizing radiation: morphological changes to the cell, acquiring cellular immortality (losing normal, life-limiting cell regulatory processes), and adaptations that favor formation of a tumor. Even if the radiation particle does not strike the DNA directly, it triggers responses from cells that indirectly increase the likelihood of mutations.\n\nNot all types of electromagnetic radiation are carcinogenic. Low-energy waves on the electromagnetic spectrum including radio waves, microwaves, infrared radiation and visible light are thought not to be because they have insufficient energey to break chemical bonds. Non-ionizing radio frequency radiation from mobile phones, electric power transmission, and other similar sources have been described as a possible carcinogen by the World Health Organization's International Agency for Research on Cancer. However, studies have not found a consistent link between cell phone radiation and cancer risk.\n\nHigher-energy radiation, including ultraviolet radiation (present in sunlight), x-rays, and gamma radiation, generally is carcinogenic, if received in sufficient doses. Prolonged exposure to ultraviolet radiation from the sun can lead to melanoma and other skin malignancies. The vast majority of non-invasive cancers are non-melanoma skin cancers caused by non-ionizing ultraviolet radiation. Clear evidence establishes ultraviolet radiation, especially the non-ionizing medium wave UVB, as the cause of most non-melanoma skin cancers, which are the most common forms of cancer in the world.\n\nSources of ionizing radiation include medical imaging, and radon gas. Ionizing radiation is not a particularly strong mutagen. Medical use of ionizing radiation is a growing source of radiation-induced cancers. Ionizing radiation may be used to treat other cancers, but this may, in some cases, induce a second form of cancer. Radiation can cause cancer in most parts of the body, in all animals, and at any age, although radiation-induced solid tumors usually take 10–15 years, and can take up to 40 years, to become clinically manifest, and radiation-induced leukemias typically require 2–10 years to appear. Radiation-induced meningiomas are an uncommon complication of cranial irradiation. Some people, such as those with nevoid basal cell carcinoma syndrome or retinoblastoma, are more susceptible than average to developing cancer from radiation exposure. Children and adolescents are twice as likely to develop radiation-induced leukemia as adults; radiation exposure before birth has ten times the effect.\n\nIonizing radiation is also used in some kinds of medical imaging. In industrialized countries, medical imaging contributes almost as much radiation dose to the public as natural background radiation. Nuclear medicine techniques involve the injection of radioactive pharmaceuticals directly into the bloodstream. Radiotherapy deliberately deliver high doses of radiation to tumors and surrounding tissues as a form of disease treatment. It is estimated that 0.4% of cancers in 2007 in the United States are due to CTs performed in the past and that this may increase to as high as 1.5–2% with rates of CT usage during this same time period.\n\nResidential exposure to radon gas has similar cancer risks as passive smoking. Low-dose exposures, such as living near a nuclear power plant, are generally believed to have no or very little effect on cancer development. Radiation is a more potent source of cancer when it is combined with other cancer-causing agents, such as radon gas exposure plus smoking tobacco.\n\nThe development of donor-derived tumors from organ transplants is exceedingly rare. The main cause of organ transplant associated tumors seems to be malignant melanoma, that was undetected at the time of organ harvest. There have also been reports of Kaposi's sarcoma occurring after transplantation due to tumorous outgrowth of virus-infected donor cells.\n\nPhysical trauma resulting in cancer is relatively rare. Claims that breaking bones resulted in bone cancer, for example, have never been proven. Similarly, physical trauma is not accepted as a cause for cervical cancer, breast cancer, or brain cancer. One accepted source is frequent, long-term application of hot objects to the body. It is possible that repeated burns on the same part of the body, such as those produced by kanger and kairo heaters (charcoal hand warmers), may produce skin cancer, especially if carcinogenic chemicals are also present. Frequently drinking scalding hot tea may produce esophageal cancer. Generally, it is believed that the cancer arises, or a pre-existing cancer is encouraged, during the process of repairing the trauma, rather than the cancer being caused directly by the trauma. However, repeated injuries to the same tissues might promote excessive cell proliferation, which could then increase the odds of a cancerous mutation.\n\nIn the United States, approximately 3,500 pregnant women have a malignancy annually, and transplacental transmission of acute leukemia, lymphoma, melanoma and carcinoma from mother to fetus has been observed. Excepting the rare transmissions that occur with pregnancies and only a marginal few organ donors, cancer is generally not a transmissible disease. The main reason for this is tissue graft rejection caused by MHC incompatibility. In humans and other vertebrates, the immune system uses MHC antigens to differentiate between \"self\" and \"non-self\" cells because these antigens are different from person to person. When non-self antigens are encountered, the immune system reacts against the appropriate cell. Such reactions may protect against tumor cell engraftment by eliminating implanted cells.\n"}
{"id": "714646", "url": "https://en.wikipedia.org/wiki?curid=714646", "title": "Ciguatera fish poisoning", "text": "Ciguatera fish poisoning\n\nCiguatera fish poisoning, also known simply as ciguatera, is a foodborne illness caused by eating reef fish whose flesh is contaminated with certain toxins. Symptoms may include diarrhea, vomiting, numbness, itchiness, sensitivity to hot and cold, dizziness, and weakness. Onset of symptoms vary with the amount of toxin eaten from half an hour to up to two days. The diarrhea may last for up to four days. Some symptoms typically remain for a few weeks to months. Heart difficulties such as a slow heart rate and low blood pressure may occur.\nThe specific toxins involved are ciguatoxin and maitotoxin. They are originally made by a small marine organism, \"Gambierdiscus toxicus\", that grows on and around coral reefs in tropical and subtropical waters. These are eaten by herbivorous fish which in turn are eaten by larger carnivorous fish. The toxins become more concentrated as they move up the food chain. The fish most often implicated include barracuda, grouper, moray eel, amberjack, sea bass, and sturgeon. Diagnosis is based on a person's symptoms together with having recently eaten fish. If a number of those who eat the same fish develop symptoms the diagnosis becomes more likely. If some of the fish they had previously eaten is available this can also be tested to confirm the diagnosis.\nPreventive efforts include not eating reef fish, not eating high risk fish such as barracuda, and not eating fish liver, roe, or fish heads. Ciguatoxin has no taste or smell, and cannot be destroyed by conventional cooking. There is no specific treatment for ciguatera fish poisoning once it occurs. Mannitol may be considered but evidence supporting its use is not very good. Gabapentin or amitriptyline may be used to treat some of the symptoms.\nThe Center for Disease Control estimates that around 50,000 cases occur a year. Other estimates vary up to 500,000 cases per year. It is the most frequent seafood poisoning. It occurs most commonly in the Pacific Ocean, Indian Ocean, and the Caribbean Sea between the latitudes of 35°N and 35°S. The risk of the condition appears to be increasing due to coral reef deterioration and increasing trade in seafood. The risk of death from poisoning is less than 1 in 1,000. Descriptions of the condition date back to at least 1511. The current name came into use in 1787.\n\nHallmark symptoms of ciguatera in humans include gastrointestinal, cardiovascular, and neurological effects. Gastrointestinal symptoms include nausea, vomiting, and diarrhea, usually followed by neurological symptoms such as headaches, muscle aches, paresthesia, numbness of extremities, mouth and lips, reversal of hot and cold sensation, ataxia, vertigo, and hallucinations. Severe cases of ciguatera can also result in cold allodynia, which is a burning sensation on contact with cold. Neurological symptoms can persist and ciguatera poisoning is occasionally misdiagnosed as multiple sclerosis. Cardiovascular symptoms include bradycardia, tachycardia, hypotension, hypertension, orthostatic tachycardia, exercise intolerance, and rhythm disorders. Death from the condition can occur, but is very rare.\n\nDyspareunia and other ciguatera symptoms have developed in otherwise healthy males and females following sexual intercourse with partners suffering ciguatera poisoning, signifying that the toxin may be sexually transmitted. Diarrhea and facial rashes have been reported in breastfed infants of poisoned mothers, suggesting that ciguatera toxins migrate into breast milk.\n\nThe symptoms can last from weeks to years, and in extreme cases as long as 20 years, often leading to long-term disability. Most people do recover slowly over time.\n\n\"Gambierdiscus toxicus\" is the primary dinoflagellate responsible for the production of a number of similar polyether toxins, including ciguatoxin, maitotoxin, gambieric acid and scaritoxin, as well as the long-chain alcohol palytoxin. Other dinoflagellates that may cause ciguatera include \"Prorocentrum\" spp., \"Ostreopsis\" spp., \"Coolia monotis\", \"Thecadinium\" spp. and \"Amphidinium carterae\".\n\nDiagnosis is based on a person's symptoms together with having recently eaten fish. If a number of those who eat the same fish have symptoms the diagnosis becomes more likely. If some of the fish they had previously eaten is available this can also be tested to confirm the diagnosis. Other potential causes such as paralytic shellfish poisoning (PSP), neurotoxic shellfish poisoning (NSP), scombrotoxin fish poisoning, and pufferfish poisoning should be excluded.\n\nThere is no effective treatment or antidote for ciguatera poisoning. The mainstay of treatment is supportive care. There is some evidence that calcium channel blockers like nifedipine and verapamil are effective in treating some of the symptoms that remain after the initial sickness passes, such as poor circulation and shooting pains through the chest. These symptoms are due to vasoconstriction caused by maitotoxin. Ciguatoxin lowers the threshold for opening voltage-gated sodium channels in synapses of the nervous system. Opening a sodium channel causes depolarization, which could sequentially cause paralysis, heart contraction, and changing the senses of hot and cold. Some medications such as amitriptyline may reduce some symptoms, such as fatigue and paresthesia, although benefit does not occur in every case.\n\nMannitol was once used for poisoning after one study reported symptom reversal. Follow-up studies in animals and case reports in humans also found benefit from mannitol. However, a randomized, double-blind clinical trial found no difference between mannitol and normal saline. Despite this its use may still be considered.\n\nThe current estimated global incidence annually is 20,000 to 50,000 people, though a large number of cases are believed to go unreported.\nDue to the limited habitats of ciguatoxin-producing microorganisms, ciguatera is common only in subtropical and tropical waters, particularly the Pacific and Caribbean, and usually is associated with fish caught in tropical reef waters. Exportation of reef fish, as well as tourism, often account for cases that develop in other regions.\n\nCiguatoxin is found in over 400 species of reef fish. Avoiding consumption of all reef fish is the only sure way to avoid exposure. Imported fish served in restaurants may contain the toxin and produce illness which often goes unexplained by physicians unfamiliar with the symptoms of a tropical toxin. Ciguatoxin can also occur in farm-raised salmon. Furthermore, species substitution, labeling a reef fish as a non-reef fish at restaurants and retail, can complicate efforts by consumers to avoid ciguatera.\n\n\nCiguatera was first described by one of the surgeon's mates, William Anderson, on the crew of in 1774.\n\nResearchers, such as Ross M. Brown with his New Religion theory suggest that ciguatera outbreaks caused by warm climatic conditions in part propelled the migratory voyages of Polynesians between 1000 and 1400AD.\n\nIn Northern Australia, where ciguatera is a common problem, two different folk science methods are widely believed to detect whether fish harbor significant ciguatoxin. The first method is that flies are supposed not to land on contaminated fish. The second is that cats will either refuse to eat or vomit/display symptoms after eating contaminated fish. A third, less common testing method involves putting a silver coin under the scales of the suspect fish. If the coin turns black, according to the theory, it is contaminated.\n\nOn Grand Cayman and other islands the locals will test barracuda by placing a piece of the fish on the ground and allowing ants to crawl on it. If the ants do not avoid the flesh and will eat it, then the fish is deemed safe. \n\nIn Dominican Republic, another common belief is that during months whose names do not include the letter \"R\" (May through August), it is not recommended to eat certain kinds of fish, because they are more likely to be infected by the ciguatera toxin.\n\nThe validity of many of these tests has been scientifically rejected.\n\nLeaves of \"Heliotropium foertherianum\" (Boraginaceae) – also known as \"octopus bush\" – are used in many Pacific islands as a traditional medicine to treat ciguatera fish poisoning. Senescent octopus bush leaves contain rosmarinic acid and derivatives, which are known for their antiviral, antibacterial, antioxidant, and anti-inflammatory properties. Rosmarinic acid may remove the ciguatoxins from their sites of action, as well as being an anti-inflammatory.\n\nAn account of ciguatera poisoning from a linguistics researcher living on Malakula island, Vanuatu, indicates the local treatment: \"We had to go with what local people told us: avoid salt and any seafood. Eat sugary foods. And they gave us a tea made from the roots of ferns growing on tree trunks. I don't know if any of that helped, but after a few weeks, the symptoms faded away\".\n\nVarious Caribbean folk and ritualistic treatments originated in Cuba and nearby islands. The most common old-time remedy involves bed rest subsequent to a guanabana juice enema. In Puerto Rico, natives drink a tea made from mangrove buttons, purportedly high in B vitamins, to flush the toxic symptoms from the system. There has never been a funded study of these treatments. Other folk treatments range from directly porting and bleeding the gastrointestinal tract to \"cleansing\" the diseased with a dove during a Santería ritual.\n\n\n"}
{"id": "241717", "url": "https://en.wikipedia.org/wiki?curid=241717", "title": "Clinical trial", "text": "Clinical trial\n\nClinical trials are experiments or observations done in clinical research. Such prospective biomedical or behavioral research studies on human participants are designed to answer specific questions about biomedical or behavioral interventions, including new treatments (such as novel vaccines, drugs, dietary choices, dietary supplements, and medical devices) and known interventions that warrant further study and comparison. Clinical trials generate data on safety and efficacy. They are conducted only after they have received health authority/ethics committee approval in the country where approval of the therapy is sought. These authorities are responsible for vetting the risk/benefit ratio of the trial – their approval does not mean that the therapy is 'safe' or effective, only that the trial may be conducted.\n\nDepending on product type and development stage, investigators initially enroll volunteers or patients into small pilot studies, and subsequently conduct progressively larger scale comparative studies. Clinical trials can vary in size and cost, and they can involve a single research center or multiple centers, in one country or in multiple countries. Clinical study design aims to ensure the scientific validity and reproducibility of the results.\n\nCosts for clinical trials can range into the billions of dollars per approved drug. The sponsor may be a governmental organization or a pharmaceutical, biotechnology or medical device company. Certain functions necessary to the trial, such as monitoring and lab work, may be managed by an outsourced partner, such as a contract research organization or a central laboratory.\n\nOnly 10 percent of all drugs started in human clinical trials become an approved drug. \n\nSome clinical trials involve healthy subjects with no pre-existing medical conditions. Other clinical trials pertain to patients with specific health conditions who are willing to try an experimental treatment.\n\nWhen participants are healthy volunteers who receive financial incentives, the goals are different than when the participants are sick. During dosing periods, study subjects typically remain under supervision for one to 40 nights.\n\nUsually pilot experiments are conducted to gain insights for design of the clinical trial to follow.\n\nThere are two goals to testing medical treatments: to learn whether they work well enough, called \"efficacy\" or \"effectiveness\"; and to learn whether they are safe enough, called \"safety\". Neither is an absolute criterion; both safety and efficacy are evaluated relative to how the treatment is intended to be used, what other treatments are available, and the severity of the disease or condition. The benefits must outweigh the risks. For example, many drugs to treat cancer have severe side effects that would not be acceptable for an over-the-counter pain medication, yet the cancer drugs have been approved since they are used under a physician's care, and are used for a life-threatening condition.\n\nIn the US, the elderly constitute 14% of the population, while they consume over one-third of drugs. People over 55 (or a similar cutoff age) are often excluded from trials because their greater health issues and drug use complicate data interpretation, and because they have different physiological capacity than younger people. Children and people with unrelated medical conditions are also frequently excluded. Pregnant women are often excluded due to potential risks to the fetus.\n\nThe sponsor designs the trial in coordination with a panel of expert clinical investigators, including what alternative or existing treatments to compare to the new drug and what type(s) of patients might benefit. If the sponsor cannot obtain enough test subjects at one location investigators at other locations are recruited to join the study.\n\nDuring the trial, investigators recruit subjects with the predetermined characteristics, administer the treatment(s) and collect data on the subjects' health for a defined time period. Data include measurements such as vital signs, concentration of the study drug in the blood or tissues, changes to symptoms, and whether improvement or worsening of the condition targeted by the study drug occurs. The researchers send the data to the trial sponsor, who then analyzes the pooled data using statistical tests.\n\nExamples of clinical trial goals include assessing the safety and relative effectiveness of a medication or device:\n\nWhile most clinical trials test one alternative to the novel intervention, some expand to three or four and may include a placebo.\n\nExcept for small, single-location trials, the design and objectives are specified in a document called a clinical trial protocol. The protocol is the trial's \"operating manual\" and ensures that all researchers perform the trial in the same way on similar subjects and that the data is comparable across all subjects.\n\nAs a trial is designed to test hypotheses and rigorously monitor and assess outcomes, it can be seen as an application of the scientific method, specifically the experimental step.\n\nThe most common clinical trials evaluate new pharmaceutical products, medical devices (such as a new catheter), biologics, psychological therapies, or other interventions. Clinical trials may be required before a national regulatory authority approves marketing of the innovation.\n\nSimilarly to drugs, manufacturers of medical devices in the United States are required to conduct clinical trials for premarket approval. Device trials may compare a new device to an established therapy, or may compare similar devices to each other. An example of the former in the field of vascular surgery is the Open versus Endovascular Repair (OVER trial) for the treatment of abdominal aortic aneurysm, which compared the older open aortic repair technique to the newer endovascular aneurysm repair device. An example of the latter are clinical trials on mechanical devices used in the management of adult female urinary incontinence.\n\nSimilarly to drugs, medical or surgical procedures may be subjected to clinical trials, such as case-controlled studies for surgical interventions.\n\nThe concepts behind clinical trials are ancient. The Book of Daniel chapter 1, verses 12 through 15, for instance, describes a planned experiment with both baseline and follow-up observations of two groups who either partook of, or did not partake of, \"the King's meat\" over a trial period of ten days. Persian physician Avicenna, in \"The Canon of Medicine\" (1025) gave similar advice for determining the efficacy of medical drugs and substances.\n\nAlthough early medical experimentation was often performed, the use of a control group to provide an accurate comparison for the demonstration of the intervention's efficacy, was generally lacking. For instance, Lady Mary Wortley Montagu, who campaigned for the introduction of inoculation (then called variolation) to prevent smallpox, arranged for seven prisoners who had been sentenced to death to undergo variolation in exchange for their life. Although they survived and did not contract smallpox, there was no control group to assess whether this result was due to the inoculation or some other factor. Similar experiments performed by Edward Jenner over his smallpox vaccine were equally conceptually flawed.\n\nThe first proper clinical trial was conducted by the physician James Lind. The disease scurvy, now known to be caused by a Vitamin C deficiency, would often have terrible effects on the welfare of the crew of long distance ocean voyages. In 1740, the catastrophic result of Anson's circumnavigation attracted much attention in Europe; out of 1900 men, 1400 had died, most of them allegedly from having contracted scurvy. John Woodall, an English military surgeon of the British East India Company, had recommended the consumption of citrus fruit (it has an antiscorbutic effect) from the 17th century, but their use did not become widespread.\n\nLind conducted the first systematic clinical trial in 1747. He included a dietary supplement of an acidic quality in the experiment after two months at sea, when the ship was already afflicted with scurvy. He divided twelve scorbutic sailors into six groups of two. They all received the same diet but, in addition, group one was given a quart of cider daily, group two twenty-five drops of elixir of vitriol (sulfuric acid), group three six spoonfuls of vinegar, group four half a pint of seawater, group five received two oranges and one lemon, and the last group a spicy paste plus a drink of barley water. The treatment of group five stopped after six days when they ran out of fruit, but by that time one sailor was fit for duty while the other had almost recovered. Apart from that, only group one also showed some effect of its treatment.\n\nAfter 1750, the discipline began to take its modern shape. John Haygarth demonstrated the importance of a control group for the correct identification of the placebo effect in his celebrated study of the ineffective remedy called \"Perkin's tractors\". Further work in that direction was carried out by the eminent physician Sir William Gull, 1st Baronet in the 1860s.\n\nFrederick Akbar Mahomed (d. 1884), who worked at Guy's Hospital in London, made substantial contributions to the process of clinical trials, where \"he separated chronic nephritis with secondary hypertension from what we now term essential hypertension. He also founded the Collective Investigation Record for the British Medical Association; this organization collected data from physicians practicing outside the hospital setting and was the precursor of modern collaborative clinical trials.\"\n\nSir Ronald A. Fisher, while working for the Rothamsted experimental station in the field of agriculture, developed his \"Principles of experimental design\" in the 1920s as an accurate methodology for the proper design of experiments. Among his major ideas, was the importance of randomization – the random assignment of individuals to different groups for the experiment; replication – to reduce uncertainty, measurements should be repeated and experiments replicated to identify sources of variation; blocking – to arrange experimental units into groups of units that are similar to each other, and thus reducing irrelevant sources of variation; use of factorial experiments – efficient at evaluating the effects and possible interactions of several independent factors.\n\nThe British Medical Research Council officially recognized the importance of clinical trials from the 1930s. The Council established the \"Therapeutic Trials Committee\" to advise and assist in the arrangement of properly controlled clinical trials on new products that seem likely on experimental grounds to have value in the treatment of disease.\n\nThe first randomised curative trial was carried out at the MRC Tuberculosis Research Unit by Sir Geoffrey Marshall (1887–1982). The trial, carried out between 1946–1947, aimed to test the efficacy of the chemical streptomycin for curing pulmonary tuberculosis. The trial was both double-blind and placebo-controlled.\n\nThe methodology of clinical trials was further developed by Sir Austin Bradford Hill, who had been involved in the streptomycin trials. From the 1920s, Hill applied statistics to medicine, attending the lectures of renowned mathematician Karl Pearson, among others. He became famous for a landmark study carried out in collaboration with Richard Doll on the correlation between smoking and lung cancer. They carried out a case-control study in 1950, which compared lung cancer patients with matched control and also began a sustained long-term prospective study into the broader issue of smoking and health, which involved studying the smoking habits and health of over 30,000 doctors over a period of several years. His certificate for election to the Royal Society called him \"...the leader in the development in medicine of the precise experimental methods now used nationally and internationally in the evaluation of new therapeutic and prophylactic agents.\"\n\nInternational clinical trials day is celebrated on 20 May.\n\nOne way of classifying clinical trials is by the way the researchers behave.\n\n\nAnother way of classifying trials is by their purpose. The U.S. National Institutes of Health (NIH) organizes trials into five different types:\n\n\nA third classification is whether the trial design allows changes based on data accumulated during the trial.\n\n\nFinally, a common way of distinguishing trials is by phase, which in simple terms, relates to how close the drug is to being clinically proven both effective for its stated purpose and accepted by the regulatory authorities for use for that purpose.\n\nClinical trials involving new drugs are commonly classified into five phases. Each phase of the drug approval process is treated as a separate clinical trial. The drug-development process will normally proceed through all four phases over many years. If the drug successfully passes through phases 1, 2, and 3, it will usually be approved by the national regulatory authority for use in the general population. Before pharmaceutical companies start clinical trials on a drug, they will also have conducted extensive preclinical studies. Each phase has a different purpose and helps scientists answer a different question.\n\nA fundamental distinction in evidence-based practice is between observational studies and randomized controlled trials. Types of observational studies in epidemiology, such as the cohort study and the case-control study, provide less compelling evidence than the randomized controlled trial. In observational studies, the investigators retrospectively assess associations between the treatments given to participants and their health status, with potential for considerable errors in design and interpretation.\n\nA randomized controlled trial can provide compelling evidence that the study treatment causes an effect on human health.\n\nCurrently, some phase 2 and most phase 3 drug trials are designed as randomized, double-blind, and placebo-controlled.\n\nClinical studies having small numbers of subjects may be \"sponsored\" by single researchers or a small group of researchers, and are designed to test simple questions or feasibility to expand the research for a more comprehensive randomized controlled trial.\n\nIn many cases, giving a placebo to a person suffering from a disease may be unethical. To address this, it has become a common practice to conduct \"active comparator\" (also known as \"active control\") trials. In trials with an active control group, subjects are given either the experimental treatment or a previously approved treatment with known effectiveness.\n\nIn such studies, multiple experimental treatments are tested in a single trial. Genetic testing enables researchers to group patients according to their genetic profile, deliver drugs based on that profile to that group and compare the results. Multiple companies can participate, each bringing a different drug. The first such approach targets squamous cell cancer, which includes varying genetic disruptions from patient to patient. Amgen, AstraZeneca and Pfizer are involved, the first time they have worked together in a late-stage trial. Patients whose genomic profiles do not match any of the trial drugs receive a drug designed to stimulate the immune system to attack cancer.\n\nA clinical trial protocol is a document used to define and manage the trial. It is prepared by a panel of experts. All study investigators are expected to strictly observe the protocol.\n\nThe protocol describes the scientific rationale, objective(s), design, methodology, statistical considerations and organization of the planned trial. Details of the trial are provided in documents referenced in the protocol, such as an investigator's brochure.\n\nThe protocol contains a precise study plan to assure safety and health of the trial subjects and to provide an exact template for trial conduct by investigators. This allows data to be combined across all investigators/sites. The protocol also informs the study administrators (often a contract research organization).\n\nThe format and content of clinical trial protocols sponsored by pharmaceutical, biotechnology or medical device companies in the United States, European Union, or Japan have been standardized to follow Good Clinical Practice guidance issued by the International Conference on Harmonization of Technical Requirements for Registration of Pharmaceuticals for Human Use (ICH). Regulatory authorities in Canada and Australia also follow ICH guidelines. Journals such as \"Trials\", encourage investigators to publish their protocols.\n\nClinical trials recruit study subjects to sign a document representing their \"informed consent\". The document includes details such as its purpose, duration, required procedures, risks, potential benefits, key contacts and institutional requirements. The participant then decides whether to sign the document. The document is not a contract, as the participant can withdraw at any time without penalty.\n\nInformed consent is a legal process in which a recruit is instructed about key facts before deciding whether to participate. Researchers explain the details of the study in terms the subject can understand. The information is presented in the subject's native language. Generally, children cannot autonomously provide informed consent, but depending on their age and other factors, may be required to provide informed assent.\n\nThe number of subjects has a large impact on the ability to reliably detect and measure effects of the intervention. This is described as its \"power\". The larger the number of participants, the greater the statistical power and the greater the cost.\n\nThe statistical power estimates the ability of a trial to detect a difference of a particular size (or larger) between the treatment and control groups. For example, a trial of a lipid-lowering drug versus placebo with 100 patients in each group might have a power of 0.90 to detect a difference between placebo and trial groups receiving dosage of 10 mg/dL or more, but only 0.70 to detect a difference of 6 mg/dL.\n\nMerely giving a treatment can have nonspecific effects. These are controlled for by the inclusion of patients who receive only a placebo. Subjects are assigned randomly without informing them to which group they belonged. Many trials are doubled-blinded so that researchers do not know to which group a subject is assigned.\n\nAssigning a subject to a placebo group can pose an ethical problem if it violates his or her right to receive the best available treatment. The Declaration of Helsinki provides guidelines on this issue.\n\nClinical trials are only a small part of the research that goes into developing a new treatment. Potential drugs, for example, first have to be discovered, purified, characterized, and tested in labs (in cell and animal studies) before ever undergoing clinical trials. In all, about 1,000 potential drugs are tested before just one reaches the point of being tested in a clinical trial. For example, a new cancer drug has, on average, six years of research behind it before it even makes it to clinical trials. But the major holdup in making new cancer drugs available is the time it takes to complete clinical trials themselves. On average, about eight years pass from the time a cancer drug enters clinical trials until it receives approval from regulatory agencies for sale to the public. Drugs for other diseases have similar timelines.\n\nSome reasons a clinical trial might last several years:\n\nThe biggest barrier to completing studies is the shortage of people who take part. All drug and many device trials target a subset of the population, meaning not everyone can participate. Some drug trials require patients to have unusual combinations of disease characteristics. It is a challenge to find the appropriate patients and obtain their consent, especially when they may receive no direct benefit (because they are not paid, the study drug is not yet proven to work, or the patient may receive a placebo). In the case of cancer patients, fewer than 5% of adults with cancer will participate in drug trials. According to the Pharmaceutical Research and Manufacturers of America (PhRMA), about 400 cancer medicines were being tested in clinical trials in 2005. Not all of these will prove to be useful, but those that are may be delayed in getting approved because the number of participants is so low.\n\nFor clinical trials involving potential for seasonal influences (such as airborne allergies, seasonal affective disorder, influenza, and skin diseases), the study may be done during a limited part of the year (such as spring for pollen allergies), when the drug can be tested.\n\nClinical trials that do not involve a new drug usually have a much shorter duration. (Exceptions are epidemiological studies, such as the Nurses' Health Study).\n\nClinical trials designed by a local investigator, and (in the US) federally funded clinical trials, are almost always administered by the researcher who designed the study and applied for the grant. Small-scale device studies may be administered by the sponsoring company. Clinical trials of new drugs are usually administered by a contract research organization (CRO) hired by the sponsoring company. The sponsor provides the drug and medical oversight. A CRO is contracted to perform all the administrative work on a clinical trial. For phases 2, 3 and 4, the CRO recruits participating researchers, trains them, provides them with supplies, coordinates study administration and data collection, sets up meetings, monitors the sites for compliance with the clinical protocol, and ensures the sponsor receives data from every site. Specialist site management organizations can also be hired to coordinate with the CRO to ensure rapid IRB/IEC approval and faster site initiation and patient recruitment. Phase 1 clinical trials of new medicines are often conducted in a specialist clinical trial clinic, with dedicated pharmacologists, where the subjects can be observed by full-time staff. These clinics are often run by a CRO which specialises in these studies.\n\nAt a participating site, one or more research assistants (often nurses) do most of the work in conducting the clinical trial. The research assistant's job can include some or all of the following: providing the local institutional review board (IRB) with the documentation necessary to obtain its permission to conduct the study, assisting with study start-up, identifying eligible patients, obtaining consent from them or their families, administering study treatment(s), collecting and statistically analyzing data, maintaining and updating data files during followup, and communicating with the IRB, as well as the sponsor and CRO.\n\nJanet Yang uses the Interactional Justice Model to test the effects of willingness to talk with a doctor and clinical trial enrollment. Results found that potential clinical trial candidates were less likely to enroll in clinical trials if the patient is more willing to talk with their doctor. The reasoning behind this discovery may be patients are happy with their current care. Another reason for the negative relationship between perceived fairness and clinical trial enrollment is the lack of independence from the care provider. Results found that there is a positive relationship between a lack of willingness to talk with their doctor and clinical trial enrollment. Lack of willingness to talk about clinical trials with current care providers may be due to patients' independence from the doctor. Patients who are less likely to talk about clinical trials are more willing to use other sources of information to gain a better insight of alternative treatments. Clinical trial enrollment should be motivated to utilize websites and television advertising to inform the public about clinical trial enrollment.\n\nThe last decade has seen a proliferation of information technology use in the planning and conduct of clinical trials. Clinical trial management systems are often used by research sponsors or CROs to help plan and manage the operational aspects of a clinical trial, particularly with respect to investigational sites. Advanced analytics for identifying researchers and research sites with expertise in a given area utilize public and private information about ongoing research. Web-based electronic data capture (EDC) and clinical data management systems are used in a majority of clinical trials to collect case report data from sites, manage its quality and prepare it for analysis. Interactive voice response systems are used by sites to register the enrollment of patients using a phone and to allocate patients to a particular treatment arm (although phones are being increasingly replaced with web-based (IWRS) tools which are sometimes part of the EDC system). While patient-reported outcome were often paper based in the past, measurements are increasingly being collected using web portals or hand-held ePRO (or eDiary) devices, sometimes wireless. Statistical software is used to analyze the collected data and prepare them for regulatory submission. Access to many of these applications are increasingly aggregated in web-based clinical trial portals. In 2011, the FDA approved a phase 1 trial that used telemonitoring, also known as remote patient monitoring, to collect biometric data in patients' homes and transmit it electronically to the trial database. This technology provides many more data points and is far more convenient for patients, because they have fewer visits to trial sites.\n\nClinical trials are closely supervised by appropriate regulatory authorities. All studies involving a medical or therapeutic intervention on patients must be approved by a supervising ethics committee before permission is granted to run the trial. The local ethics committee has discretion on how it will supervise noninterventional studies (observational studies or those using already collected data). In the US, this body is called the Institutional Review Board (IRB); in the EU, they are called Ethics committees. Most IRBs are located at the local investigator's hospital or institution, but some sponsors allow the use of a central (independent/for profit) IRB for investigators who work at smaller institutions.\n\nTo be ethical, researchers must obtain the full and informed consent of participating human subjects. (One of the IRB's main functions is to ensure potential patients are adequately informed about the clinical trial.) If the patient is unable to consent for him/herself, researchers can seek consent from the patient's legally authorized representative. In California, the state has prioritized the individuals who can serve as the legally authorized representative.\n\nIn some US locations, the local IRB must certify researchers and their staff before they can conduct clinical trials. They must understand the federal patient privacy (HIPAA) law and good clinical practice. The International Conference of Harmonisation Guidelines for Good Clinical Practice is a set of standards used internationally for the conduct of clinical trials. The guidelines aim to ensure the \"rights, safety and well being of trial subjects are protected\".\n\nThe notion of informed consent of participating human subjects exists in many countries all over the world, but its precise definition may still vary.\n\nInformed consent is clearly a 'necessary' condition for ethical conduct but does not 'ensure' ethical conduct. In compassionate use trials the latter becomes a particularly difficult problem. The final objective is to serve the community of patients or future patients in a best-possible and most responsible way. See also Expanded access. However, it may be hard to turn this objective into a well-defined, quantified, objective function. In some cases this can be done, however, for instance, for questions of when to stop sequential treatments (see Odds algorithm), and then quantified methods may play an important role.\n\nAdditional ethical concerns are present when conducting clinical trials on children (pediatrics), and in emergency or epidemic situations.\n\nIn response to specific cases in which unfavorable data from pharmaceutical company-sponsored research were not published, the Pharmaceutical Research and Manufacturers of America published new guidelines urging companies to report all findings and limit the financial involvement in drug companies by researchers. The US Congress signed into law a bill which requires phase II and phase III clinical trials to be registered by the sponsor on the clinicaltrials.gov website compiled by the National Institutes of Health.\n\nDrug researchers not directly employed by pharmaceutical companies often seek grants from manufacturers, and manufacturers often look to academic researchers to conduct studies within networks of universities and their hospitals, e.g., for translational cancer research. Similarly, competition for tenured academic positions, government grants and prestige create conflicts of interest among academic scientists. According to one study, approximately 75% of articles retracted for misconduct-related reasons have no declared industry financial support. Seeding trials are particularly controversial.\n\nIn the United States, all clinical trials submitted to the FDA as part of a drug approval process are independently assessed by clinical experts within the Food and Drug Administration, including inspections of primary data collection at selected clinical trial sites.\n\nIn 2001, the editors of 12 major journals issued a joint editorial, published in each journal, on the control over clinical trials exerted by sponsors, particularly targeting the use of contracts which allow sponsors to review the studies prior to publication and withhold publication. They strengthened editorial restrictions to counter the effect. The editorial noted that contract research organizations had, by 2000, received 60% of the grants from pharmaceutical companies in the US. Researchers may be restricted from contributing to the trial design, accessing the raw data, and interpreting the results.\n\nResponsibility for the safety of the subjects in a clinical trial is shared between the sponsor, the local site investigators (if different from the sponsor), the various IRBs that supervise the study, and (in some cases, if the study involves a marketable drug or device), the regulatory agency for the country where the drug or device will be sold.\n\nFor safety reasons, many clinical trials of drugs are designed to exclude women of childbearing age, pregnant women, or women who become pregnant during the study. In some cases, the male partners of these women are also excluded or required to take birth control measures.\n\nThroughout the clinical trial, the sponsor is responsible for accurately informing the local site investigators of the true historical safety record of the drug, device or other medical treatments to be tested, and of any potential interactions of the study treatment(s) with already approved treatments. This allows the local investigators to make an informed judgment on whether to participate in the study or not. The sponsor is also responsible for monitoring the results of the study as they come in from the various sites as the trial proceeds. In larger clinical trials, a sponsor will use the services of a data monitoring committee (DMC, known in the US as a data safety monitoring board). This independent group of clinicians and statisticians meets periodically to review the unblinded data the sponsor has received so far. The DMC has the power to recommend termination of the study based on their review, for example if the study treatment is causing more deaths than the standard treatment, or seems to be causing unexpected and study-related serious adverse events. The sponsor is responsible for collecting adverse event reports from all site investigators in the study, and for informing all the investigators of the sponsor's judgment as to whether these adverse events were related or not related to the study treatment.\n\nThe sponsor and the local site investigators are jointly responsible for writing a site-specific informed consent that accurately informs the potential subjects of the true risks and potential benefits of participating in the study, while at the same time presenting the material as briefly as possible and in ordinary language. FDA regulations state that participating in clinical trials is voluntary, with the subject having the right not to participate or to end participation at any time.\n\nThe ethical principle of \"primum non nocere\" (\"first, do no harm\") guides the trial, and if an investigator believes the study treatment may be harming subjects in the study, the investigator can stop participating at any time. On the other hand, investigators often have a financial interest in recruiting subjects, and could act unethically to obtain and maintain their participation.\n\nThe local investigators are responsible for conducting the study according to the study protocol, and supervising the study staff throughout the duration of the study. The local investigator or his/her study staff are also responsible for ensuring the potential subjects in the study understand the risks and potential benefits of participating in the study. In other words, they (or their legally authorized representatives) must give truly informed consent.\n\nLocal investigators are responsible for reviewing all adverse event reports sent by the sponsor. These adverse event reports contain the opinion of both the investigator at the site where the adverse event occurred, and the sponsor, regarding the relationship of the adverse event to the study treatments. Local investigators also are responsible for making an independent judgment of these reports, and promptly informing the local IRB of all serious and study treatment-related adverse events.\n\nWhen a local investigator is the sponsor, there may not be formal adverse event reports, but study staff at all locations are responsible for informing the coordinating investigator of anything unexpected. The local investigator is responsible for being truthful to the local IRB in all communications relating to the study.\n\nApproval by an Institutional Review Board (IRB), or ethics board, is necessary before all but the most informal research can begin. In commercial clinical trials, the study protocol is not approved by an IRB before the sponsor recruits sites to conduct the trial. However, the study protocol and procedures have been tailored to fit generic IRB submission requirements. In this case, and where there is no independent sponsor, each local site investigator submits the study protocol, the consent(s), the data collection forms, and supporting documentation to the local IRB. Universities and most hospitals have in-house IRBs. Other researchers (such as in walk-in clinics) use independent IRBs.\n\nThe IRB scrutinizes the study for both medical safety and protection of the patients involved in the study, before it allows the researcher to begin the study. It may require changes in study procedures or in the explanations given to the patient. A required yearly \"continuing review\" report from the investigator updates the IRB on the progress of the study and any new safety information related to the study.\n\nIn the US, the FDA can audit the files of local site investigators after they have finished participating in a study, to see if they were correctly following study procedures. This audit may be random, or for cause (because the investigator is suspected of fraudulent data). Avoiding an audit is an incentive for investigators to follow study procedures.\n\nAlternatively, many American pharmaceutical companies have moved some clinical trials overseas. Benefits of conducting trials abroad include lower costs (in some countries) and the ability to run larger trials in shorter timeframes, whereas a potential disadvantage exists in lower-quality trial management. Different countries have different regulatory requirements and enforcement abilities. An estimated 40% of all clinical trials now take place in Asia, Eastern Europe, and Central and South America. \"There is no compulsory registration system for clinical trials in these countries and many do not follow European directives in their operations\", says Jacob Sijtsma of the Netherlands-based WEMOS, an advocacy health organisation tracking clinical trials in developing countries.\n\nBeginning in the 1980s, harmonization of clinical trial protocols was shown as feasible across countries of the European Union. At the same time, coordination between Europe, Japan and the United States led to a joint regulatory-industry initiative on international harmonization named after 1990 as the International Conference on Harmonisation of Technical Requirements for Registration of Pharmaceuticals for Human Use (ICH)\nCurrently, most clinical trial programs follow ICH guidelines, aimed at \"ensuring that good quality, safe and effective medicines are developed and registered in the most efficient and cost-effective manner. These activities are pursued in the interest of the consumer and public health, to prevent unnecessary duplication of clinical trials in humans and to minimize the use of animal testing without compromising the regulatory obligations of safety and effectiveness.\"\n\nAggregating safety data across clinical trials during drug development is important because trials are generally designed to focus on determining how well the drug works. The safety data collected and aggregated across multiple trials as the drug is developed allows the sponsor, investigators and regulatory agencies to monitor the aggregate safety profile of experimental medicines as they're developed. The value of assessing aggregate safety data is: a) decisions based on aggregate safety assessment during development of the medicine can be made throughout the medicine's development and b) it sets up the sponsor and regulators well for assessing the medicine's safety after the drug is approved.\n\nClinical trial costs vary depending on trial phase, type of trial, and disease studied. A study of clinical trials conducted in the United States from 2004 to 2012 found the average cost of phase I trials to be $1.4 million and $6.6 million, depending on the type of disease. Phase II trials ranged from $7 million to $20 million, and phase III trials from $11 million to $53 million.\n\nThe cost of a study depends on many factors, especially the number of sites conducting the study, the number of patients involved, and whether the study treatment is already approved for medical use.\n\nThe expenses incurred by a pharmaceutical company in administering a phase 3 or 4 clinical trial may include, among others:\nThese expenses are incurred over several years.\n\nIn the US, sponsors may receive a 50 percent tax credit for clinical trials conducted on drugs being developed for the treatment of orphan diseases. National health agencies, such as the US National Institutes of Health, offer grants to investigators who design clinical trials that attempt to answer research questions of interest to the agency. In these cases, the investigator who writes the grant and administers the study acts as the sponsor, and coordinates data collection from any other sites. These other sites may or may not be paid for participating in the study, depending on the amount of the grant and the amount of effort expected from them. Using internet resources can, in some cases, reduce the economic burden.\n\nInvestigators are often compensated for their work in clinical trials. These amounts can be small, just covering a partial salary for research assistants and the cost of any supplies (usually the case with national health agency studies), or be substantial and include 'overhead' that allows the investigator to pay the research staff during times between clinical trials.\n\nParticipants in phase 1 drug trials do not gain any direct health benefit from taking part. They are generally paid a fee for their time, with payments regulated and not related to any risk involved. In later phase trials, subjects may not be paid to ensure their motivation for participating with potential for a health benefit or contributing to medical knowledge. Small payments may be made for study-related expenses such as travel or as compensation for their time in providing follow-up information about their health after the trial treatment ends.\n\nPhase 0 and phase 1 drug trials seek healthy volunteers. Most other clinical trials seek patients who have a specific disease or medical condition. The diversity observed in society should be reflected in clinical trials through the appropriate inclusion of ethnic minority populations. Patient recruitment or participant recruitment plays a significant role in the activities and responsibilities of sites conducting clinical trials.\n\nAll volunteers being considered for a trial are required to undertake a medical screening. Requirements differ according to the trial needs, but typically volunteers would be screened in a medical laboratory for:\n\nDepending on the kind of participants required, sponsors of clinical trials, or contract research organizations working on their behalf, try to find sites with qualified personnel as well as access to patients who could participate in the trial. Working with those sites, they may use various recruitment strategies, including patient databases, newspaper and radio advertisements, flyers, posters in places the patients might go (such as doctor's offices), and personal recruitment of patients by investigators.\n\nVolunteers with specific conditions or diseases have additional online resources to help them locate clinical trials. For example, the Fox Trial Finder connects Parkinson's disease trials around the world to volunteers who have a specific set of criteria such as location, age, and symptoms. Other disease-specific services exist for volunteers to find trials related to their condition. Volunteers may search directly on ClinicalTrials.gov to locate trials using a registry run by the U.S. National Institutes of Health and National Library of Medicine.\n\nThe risk information seeking and processing (RISP) model analyzes social implications that affect attitudes and decision making pertaining to clinical trials. People who hold a higher stake or interest in the treatment provided in a clinical trial showed a greater likelihood of seeking information about clinical trials. Cancer patients reported more optimistic attitudes towards clinical trials than the general population. Having a more optimistic outlook on clinical trials also leads to greater likelihood of enrolling.\n\n\n"}
{"id": "1043902", "url": "https://en.wikipedia.org/wiki?curid=1043902", "title": "Fasciolosis", "text": "Fasciolosis\n\nFasciolosis is a parasitic worm infection caused by the common liver fluke \"Fasciola hepatica\" as well as by \"Fasciola gigantica\". The disease is a plant-borne trematode zoonosis, and is classified as a neglected tropical disease (NTD). It affects humans, but its main host is ruminants such as cattle and sheep. The disease progresses through four distinct phases; an initial incubation phase of between a few days up to three months with little or no symptoms; an invasive or acute phase which may manifest with: fever, malaise, abdominal pain, gastrointestinal symptoms, urticaria, anemia, jaundice, and respiratory symptoms. The disease later progresses to a latent phase with less symptoms and ultimately into a chronic or obstructive phase months to years later. In the chronic state the disease causes inflammation of the bile ducts, gall bladder and may cause gall stones as well as fibrosis. While chronic inflammation is connected to increased cancer rates, it is unclear whether fasciolosis is associated with increased cancer risk.\nUp to half of those infected display no symptoms, and diagnosis is difficult because the worm eggs are often missed in fecal examination. The methods of detection are through fecal examination, parasite-specific antibody detection, or radiological diagnosis, as well as laparotomy. In case of a suspected outbreak it may be useful to keep track of dietary history, which is also useful for exclusion of differential diagnoses. Fecal examination is generally not helpful because the worm eggs can seldom be detected in the chronic phase of the infection. Eggs appear in the feces first between 9–11 weeks post-infection. The cause of this is unknown, and it is also difficult to distinguish between the different species of fasciola as well distinguishing them from echinostomes and \"Fasciolopsis\". Most immunodiagnostic tests detect infection with very high sensitivity, and as concentration drops after treatment, it is a very good diagnostic method. Clinically it is not possible to differentiate from other liver and bile diseases. Radiological methods can detect lesions in both acute and chronic infection, while laparotomy will detect lesions and also occasionally eggs and live worms.\nBecause of the size of the parasite, as adult \"F. hepatica\": or adult \"F. gigantica:\" 25–75×12 mm, fasciolosis is a big concern. The amount of symptoms depend on how many worms and what stage the infection is in. The death rate is significant in both sheep and cattle, but generally low among humans. Treatment with triclabendazole has been highly effective against the adult worms as well as various developing stages. Praziquantel is not effective, and older drugs such as bithionol are moderately effective but also cause more side effects. Secondary bacterial infection causing cholangitis has also been a concern and can be treated with antibiotics, and toxaemia may be treated with prednisolone.\nHumans are infected by eating watergrown plants, primarily wild-grown watercress in Europe or morning glory in Asia. Infection may also occur by drinking contaminated water with floating young fasciola or when using utensils washed with contaminated water. Cultivated plants do not spread the disease in the same capacity. Human infection is rare, even if the infection rate is high among animals. Especially high rates of human infection have been found in Bolivia, Peru and Egypt, and this may be due to consumption of certain foods. No vaccine is available to protect people against \"Fasciola\" infection. Preventative measures are primarily treating and immunization of the livestock, which are required to host the live cycle of the worms. Veterinary vaccines are in development, and their use is being considered by a number of countries on account of the risk to human health and economic losses resulting from livestock infection. Other methods include using molluscicides to decrease the number of snails that act as vectors, but it is not practical. Educational methods to decrease consumption of wild watercress and other waterplants has been shown to work in areas with a high disease burden.\n\nFascioliasis occurs in Europe, Africa, the Americas as well as Oceania. Recently, worldwide losses in animal productivity due to fasciolosis were conservatively estimated at over US$3.2 billion per annum. Fasciolosis is now recognized as an emerging human disease: the World Health Organization (WHO) has estimated that 2.4 million people are infected with \"Fasciola\", and a further 180 million are at risk of infection.\n\n The course of fasciolosis in humans has 4 main phases:\nThis phase may develop months or years after initial infection. Adult flukes in the bile ducts cause inflammation and hyperplasia of the epithelium. The resulting cholangitis and cholecystitis, combined with the large body of the flukes, are sufficient to cause mechanical obstruction of the biliary duct. In this phase, biliary colic, epigastric pain, fatty food intolerance, nausea, jaundice, pruritus, right upper-quadrant abdominal tenderness, etc., are clinical manifestations indistinguishable from cholangitis, cholecystitis and cholelithiasis of other origins. Hepatic enlargement may be associated with an enlarged spleen or ascites. In case of obstruction, the gall bladder is usually enlarged and edematous with thickening of the wall (Ref: Hepatobiliary Fascioliasis:\nSonographic and CT Findings in 87 Patients During the InitialPhase and Long-Term Follow-Up. Adnan Kabaalioglu, Kagan Ceken, Emel Alimoglu, Rabin Saba, Metin Cubuk, Gokhan Arslan, Ali Apaydin. AJR 2007; 189:824–828). Fibrous adhesions of the gall bladder to adjacent organs are common. Lithiasis of the bile duct or gall bladder is frequent and the stones are usually small and multiple.\n\nClinical signs of fasciolosis are always closely associated with infectious dose (amount of ingested metacercariae). In sheep, as the most common definitive host, clinical presentation is divided into 4 types:\n\n\nIn blood, anemia, hypoalbuminemia, and eosinophilia may be observed in all types of fasciolosis. Elevation of liver enzyme activities, such a glutamate dehydrogenase (GLDH), gamma-glutamyl transferase (GGT), and lactate dehydrogenase (LDH), is detected in subacute or chronic fasciolosis from 12 to 15 weeks after ingestion of metacercariae. Economical effect of fasciolosis in sheep consists in sudden deaths of animals as well as in reduction of weight gain and wool production. In goats and cattle, the clinical manifestation is similar to sheep. However, acquired resistance to \"F. hepatica\" infection is well known in adult cattle. Calves are susceptible to disease but in excess of 1000 metacercariae are usually required to cause clinical fasciolosis. In this case the disease is similar to sheep and is characterized by weight loss, anemia, hypoalbuminemia and (after infection with 10,000 metacercariae) death. Importance of cattle fasciolosis consist in economic losses caused by condemnation of livers at slaughter and production losses especially due to reduced weight gain.\n\nIn sheep and sometimes cattle, the damaged liver tissue may become infected by the \"Clostridium\" bacteria \"C. novyi\" type B. The bacteria will release toxins into the bloodstream resulting in what is known as black disease. There is no cure and death follows quickly. As \"C. novyi\" is common in the environment, black disease is found wherever populations of liver flukes and sheep overlap.\n\nFasciolosis is caused by two digenetic trematodes \"F. hepatica\" and \"F. gigantica\". Adult flukes of both species are localized in the bile ducts of the liver or gallbladder. \"F. hepatica\" measures 2 to 3 cm and has a cosmopolitan distribution. \"F. gigantica\" measures 4 to 10 cm in length and the distribution of the species is limited to the tropics and has been recorded in Africa, the Middle East, Eastern Europe and south and eastern Asia. In domestic livestock in Japan, diploid (2n = 20), triploid (3n = 30) and chimeric flukes (2n/3n) have been described, many of which reproduce parthenogenetically. As a result of this unclear classification, flukes in Japan are normally referred to as \"Fasciola\" spp. Recent reports based on mitochondrial genes analysis has shown that Japanese \"Fasciola\" spp. is more closely related to \"F. gigantica\" than to \"F. hepatica\". In India, a species called \"F. jacksoni\" was described in elephants.\n\nHuman \"F. hepatica\" infection is determined by the presence of the intermediate snail hosts, domestic herbivorous animals, climatic conditions and the dietary habits of man. Sheep, goats and cattle are considered the predominant animal reservoirs. While other animals can be infected, they are usually not very important for human disease transmission. On the other hand, some authors have observed that donkeys and pigs contribute to disease transmission in Bolivia. Among wild animals, it has been demonstrated that the peridomestic rat (\"Rattus rattus\") may play an important role in the spread as well as in the transmission of the parasite in Corsica. In France, nutria (\"Myocastor coypus\") was confirmed as a wild reservoir host of \"F. hepatica\". Humans are infected by ingestion of aquatic plants that contain the infectious cercariae. Several species of aquatic vegetables are known as a vehicle of human infection. In Europe, \"Nasturtium officinale\" (common watercress), \"Nasturtium silvestris\", \"Rorippa amphibia\" (wild watercress), \"Taraxacum dens leonis\" (dandelion leaves), \"Valerianella olitoria\" (lamb's lettuce), and \"Mentha viridis\" (spearmint) were reported as a source of human infections. In the Northern Bolivian Altiplano, some authors suggested that several aquatic plants such as bero-bero (watercress), algas (algae), kjosco and tortora could act as a source of infection for humans. Because \"F. hepatica\" cercariae also encyst on water surface, humans can be infected by drinking of fresh untreated water containing cercariae. In addition, an experimental study suggested that humans consuming raw liver dishes from fresh livers infected with juvenile flukes could become infected.\n\nIntermediate hosts of \"F. hepatica\" are freshwater snails from family Lymnaeidae. Snails from family Planorbidae act as an intermediate host of \"F. hepatica\" very occasionally.\n\nThe development of infection in definitive host is divided into two phases: the parenchymal (migratory) phase and the biliary phase. The parenchymal phase begins when excysted juvenile flukes penetrate the intestinal wall. After the penetration of the intestine, flukes migrate within the abdominal cavity and penetrate the liver or other organs. \"F. hepatica\" has a strong predilection for the tissues of the liver. Occasionally, ectopic locations of flukes such as the lungs, diaphragm, intestinal wall, kidneys, and subcutaneous tissue can occur. During the migration of flukes, tissues are mechanically destroyed and inflammation appears around migratory tracks of flukes. The second phase (the biliary phase) begins when parasites enter the biliary ducts of the liver. In biliary ducts, flukes mature, feed on blood, and produce eggs. Hypertrophy of biliar ducts associated with obstruction of the lumen occurs as a result of tissue damage.\n\nMechanisms of resistance have been studied by several authors in different animal species. These studies may help to better understand the immune response to \"F. hepatica\" in host and are necessary in development of vaccine against the parasite. It has been established that cattle acquire resistance to challenge infection with \"F. hepatica\" and \"F. gigantica\" when they have been sensitized with primary patent or drug-abbreviated infection. Resistance to fasciolosis was also documented in rats. On the other hand, sheep and goats are not resistant to re-infection with \"F. hepatica\". However, there is evidence that two sheep breeds, in particular Indonesian thin tail sheep and Red maasai sheep, are resistant to \"F. gigantica\". No reports concerning the resistance in humans are available.\n\nMost immunodiagnostic tests will detect infection and have a sensitivity above 90% during all stages of the diseases. In addition antibody concentration quickly drops post treatment and no antibodies are present one year after treatment, which makes it a very good diagnostic method. In humans, diagnosis of fasciolosis is usually achieved parasitologically by findings the fluke eggs in stool, and immunologically by ELISA and Western blot. Coprological examinations of stool alone are generally not adequate because infected humans have important clinical presentations long before eggs are found in the stools.\n\nMoreover, in many human infections, the fluke eggs are often not found in the faeces, even after multiple faecal examinations. Furthermore, eggs of \"F. hepatica\", \"F. gigantica\" and \"Fasciolopsis buski\" are morphologically indistinguishable. Therefore, immunonological methods such ELISA and enzyme-linked immunoelectrotransfer blot, also called Western blot, are the most important methods in diagnosis of \"F. hepatica\" infection. These immunological tests are based on detection of species-specific antibodies from sera. The antigenic preparations used have been primarily derived from extracts of excretory/secretory products from adult worms, or with partially purified fractions. Recently, purified native and recombinant antigens have been used, e.g. recombinant \"F. hepatica\" cathepsin L-like protease.\n\nMethods based on antigen detection (circulating in serum or in faeces) are less frequent. In addition, biochemical and haematological examinations of human sera support the exact diagnosis (eosinophilia, elevation of liver enzymes). Ultrasonography and xray of the abdominal cavity, biopsy of liver, and gallbladder punctuate can also be used (ref: US-guided gallbladder aspiration:\na new diagnostic method for biliary fascioliasis. A. Kabaalioglu, A. Apaydin, T. Sindel, E. Lüleci. Eur. Radiol. 9, 880±882 (1999) . False fasciolosis (pseudofasciolosis) refers to the presence of eggs in the stool resulting not from an actual infection but from recent ingestion of infected livers containing eggs. This situation (with its potential for misdiagnosis) can be avoided by having the patient follow a liver-free diet several days before a repeat stool examination.\n\nIn animals, intravital diagnosis is based predominantly on faeces examinations and immunological methods. However, clinical signs, biochemical and haematological profile, season, climate conditions, epidemiology situation, and examinations of snails must be considered. Similarly to humans, faeces examinations are not reliable. Moreover, the fluke eggs are detectable in faeces 8–12 weeks post-infection. In spite of that fact, faecal examination is still the only used diagnostic tool in some countries. While coprological diagnosis of fasciolosis is possible from 8- to 12-week post-infection (WPI), \"F. hepatica\" specific-antibodies are recognized using ELISA or Western blot after 2-4 week post-infection. Therefore, these methods provide early detection of the infection.\n\nIn some areas special control programs are in place or have been planned. The types of control measures depend on the setting (such as epidemiologic, ecologic, and cultural factors). Strict control of the growth and sale of watercress and other edible water plants is important. Individual people can protect themselves by not eating raw watercress and other water plants, especially from endemic grazing areas. Travelers to areas with poor sanitation should avoid food and water that might be contaminated (tainted). Vegetables grown in fields, that might have been irrigated with polluted water, should be thoroughly cooked, as should viscera from potentially infected animals.\n\nSeveral drugs are effective for fascioliasis, both in humans and in domestic animals. The drug of choice in the treatment of fasciolosis is triclabendazole, a member of the benzimidazole family of anthelmintics. The drug works by preventing the polymerization of the molecule tubulin into the cytoskeletal structures, microtubules. Resistance of \"F. hepatica\" to triclabendazole has been recorded in Australia in 1995 and Ireland in 1998.\n\nPraziquantel treatment is ineffective.\nThere are case reports of nitazoxanide being successfully used in human fasciolosis treatment in Mexico. There are also reports of bithionol being used successfully.\n\nNitazoxanide has been found effective in trials, but is currently not recommended. The life cycle includes freshwater snails as an intermediate host of the parasite.\n\nHuman and animal fasciolosis occurs worldwide. While animal fasciolosis is distributed in countries with high cattle and sheep production, human fasciolosis occurs, excepting Western Europe, in developing countries. Fasciolosis occurs only in areas where suitable conditions for intermediate hosts exist.\n\nStudies carried out in recent years have shown human fasciolosis to be an important public health problem. Human fasciolosis has been reported from countries in Europe, America, Asia, Africa and Oceania. The incidence of human cases has been increasing in 51 countries of the five continents. A global analysis shows that the expected correlation between animal and human fasciolosis only appears at a basic level. High prevalences in humans are not necessarily found in areas where fasciolosis is a great veterinary problem. For instance, in South America, hyperendemics and mesoendemics are found in Bolivia and Peru where the veterinary problem is less important, while in countries such as Uruguay, Argentina and Chile, human fasciolosis is only sporadic or hypoendemic.\n\nIn Europe, human fasciolosis occur mainly in France, Spain, Portugal, and the former USSR. France is considered an important human endemic area. A total of 5863 cases of human fasciolosis were recorded from nine French hospitals from 1970 to 1982. Concerning the former Soviet Union, almost all reported cases were from the Tajik Republic. Several papers referred to human fasciolosis in Turkey. Recently, serological survey of human fasciolosis was performed in some parts of Turkey. The prevalence of the disease was serologically found to be 3.01% in Antalya Province, and between 0.9 and 6.1% in Isparta Province, Mediterranean region of Turkey. In other European countries, fasciolosis is sporadic and the occurrence of the disease is usually combined with travelling to endemic areas.\n\nIn North America, the disease is very sporadic. In Mexico, 53 cases have been reported. In Central America, fasciolosis is a human health problem in the Caribbean islands, especially in zones of Puerto Rico and Cuba. Pinar del Río Province and Villa Clara Province are Cuban regions where fasciolosis was hyperendemic. In South America, human fasciolosis is a serious problem in Bolivia, Peru, and Ecuador. These Andean countries are considered to be the area with the highest prevalence of human fasciolosis in the world. Well-known human hyperendemic areas are localized predominately in the high plain called altiplano. In the Northern Bolivian Altiplano, prevalences detected in some communities were up to 72% and 100% in coprological and serological surveys, respectively. In Peru, \"F. hepatica\" in humans occurs throughout the country. The highest prevalences were reported in Arequipa, Mantaro Valley, Cajamarca Valley, and Puno Region. In other South American countries like Argentina, Uruguay, Brazil, Venezuela and Colombia, human fasciolosis appear to be sporadic, despite the high prevalences of fasciolosis in cattle.\n\nIn Africa, human cases of fasciolosis, except in northern parts, have not been frequently reported. The highest prevalence was recorded in Egypt where the disease is distributed in communities living in the Nile Delta.\n\nIn Asia, the most human cases were reported in Iran, especially in Gīlān Province, on the Caspian Sea. It was mentioned that more than 10,000 human cases were detected in Iran. In eastern Asia, human fasciolosis appears to be sporadic. Few cases were documented in Japan, Koreas, Vietnam, and Thailand.\n\nIn Australia, human fasciolosis is very rare (only 12 cases documented). In New Zealand, \"F. hepatica\" has never been detected in humans.\n\nA number of drugs have been used in control fasciolosis in animals. Drugs differ in their efficacy, mode of action, price, and viability. Fasciolicides (drugs against Fasciola spp.) fall into five main chemical groups:\n\nTriclabendazole (Fasinex) is considered as the most common drug due to its high efficacy against adult as well as juvenile flukes. Triclabendazole is used in control of fasciolosis of livestock in many countries. Nevertheless, long-term veterinary use of triclabendazole has caused appearance of resistance in \"F. hepatica\". In animals, triclabendazole resistance was first described in Australia, later in Ireland and Scotland and more recently in the Netherlands. Considering this fact, scientists have started to work on the development of new drug. Recently, a new fasciolicide was successfully tested in naturally and experimentally infected cattle in Mexico. This new drug is called 'Compound Alpha' and is chemically very similar to triclabendazole.\n\nCountries where fasciolosis in livestock was repeatedly reported:\n\nOn September 8, 2007, Veterinary officials in South Cotabato, Philippines said that laboratory tests on samples from cows, carabaos, and horses in the province's 10 towns and lone city showed the level of infection at 89.5%, a sudden increase of positive cases among large livestock due to the erratic weather condition in the area. They must be treated forthwith to prevent complications with surra and hemorrhagic septicemia diseases. Surra already affected all barangays of the Surallah town.\n\n\n"}
{"id": "85305", "url": "https://en.wikipedia.org/wiki?curid=85305", "title": "Febris", "text": "Febris\n\nIn Roman mythology, Febris (\"fever\") was the goddess who embodied, but also protected people from fever and malaria. Febris had three temples in ancient Rome, of which one was located between the Palatine and Velabrum. She may have originated from the Roman god Februus. Among her characteristic attributes are \"shrewdness\" and \"honesty\", according to Seneca the Younger's \"Apocolocyntosis\".\n\n"}
{"id": "38108839", "url": "https://en.wikipedia.org/wiki?curid=38108839", "title": "Heads of International Research Organizations", "text": "Heads of International Research Organizations\n\nHeads of International Research Organizations (HIROs) is an organization composed of directors of International Research Organizations. It was established by Harold Varmus in 1998. Representatives from United States, Canada, China, EU, India, South Africa, and South Korea. The members include director of NIH, Wellcome Trust, Korea Health Industry Development Institute (KHIDI).\n"}
{"id": "23642805", "url": "https://en.wikipedia.org/wiki?curid=23642805", "title": "Health in Gabon", "text": "Health in Gabon\n\nMost of the health services of Gabon are public, but there are some private institutions, of which the best known is the hospital established in 1913 in Lambaréné by Albert Schweitzer. The hospital is now partially subsidized by the Gabonese government.\n\nGabon’s medical infrastructure is considered one of the best in West Africa. By 1985 there were 28 hospitals, 87 medical centers, and 312 infirmaries and dispensaries. As of 2004, there were an estimated 29 physicians per 100,000 people. \n\nApproximately 90% of the population had access to health care services. In 2000, 70% of the population had access to safe drinking water and 21% had adequate sanitation.\n\nThe 2014 CIA estimated average life expectancy in Gabon was 52.06 years.\n\nThe total fertility rate has decreased from 5.8 in 1960 to 4.20 children per mother during childbearing years in 2000.\n\nA comprehensive government health program treats such diseases as leprosy, sleeping sickness, malaria, filariasis, intestinal worms, and tuberculosis. Rates for immunization of children under the age of one were 97% for tuberculosis and 65% for polio. Immunization rates for DPT and measles were 37% and 56% respectively. Gabon has a domestic supply of pharmaceuticals from a large, modern factory in Libreville.\n\nThe 2010 maternal mortality rate per 100,000 births for Gabon is 260. This is compared with 493.5 in 2008 and 422.5 in 1990. The under 5 mortality rate, per 1,000 births is 71 and the neonatal mortality as a percentage of under 5's mortality is 36. In Gabon the number of midwives per 1,000 live births is 12 and the lifetime risk of death for pregnant women 1 in 110.\n\nTen percent of all births were low birth weight.\n\nThe HIV/AIDS prevalence is estimated to be 5.2% of the adult population (ages 15–49). As of 2009, approximately 46,000 people were living with HIV/AIDS. There were an estimated 2,400 deaths from AIDS in 2009 – down from 3,000 deaths in 2003.\n\nWorld Health Organization specialists and the government of Gabon took immediate action against the mid-1990s re-emergence of the Ebola virus.\n\n"}
{"id": "1465997", "url": "https://en.wikipedia.org/wiki?curid=1465997", "title": "Health psychology", "text": "Health psychology\n\nHealth psychology is the study of psychological and behavioral processes in health, illness, and healthcare. It is concerned with understanding how psychological, behavioral, and cultural factors contribute to physical health and illness. Psychological factors can affect health directly. For example, chronically occurring environmental stressors affecting the hypothalamic–pituitary–adrenal axis, cumulatively, can harm health. Behavioral factors can also affect a person's health. For example, certain behaviors can, over time, harm (smoking or consuming excessive amounts of alcohol) or enhance health (engaging in exercise). Health psychologists take a biopsychosocial approach. In other words, health psychologists understand health to be the product not only of biological processes (e.g., a virus, tumor, etc.) but also of psychological (e.g., thoughts and beliefs), behavioral (e.g., habits), and social processes (e.g., socioeconomic status and ethnicity).\n\nBy understanding psychological factors that influence health, and constructively applying that knowledge, health psychologists can improve health by working directly with individual patients or indirectly in large-scale public health programs. In addition, health psychologists can help train other healthcare professionals (e.g., physicians and nurses) to take advantage of the knowledge the discipline has generated, when treating patients. Health psychologists work in a variety of settings: alongside other medical professionals in hospitals and clinics, in public health departments working on large-scale behavior change and health promotion programs, and in universities and medical schools where they teach and conduct research.\n\nAlthough its early beginnings can be traced to the field of clinical psychology, four different divisions within health psychology and one related field, occupational health psychology (OHP), have developed over time. The four divisions include clinical health psychology, public health psychology, community health psychology, and critical health psychology. Professional organizations for the field of health psychology include Division 38 of the American Psychological Association (APA), the Division of Health Psychology of the British Psychological Society (BPS), and the European Health Psychology Society. Advanced credentialing in the US as a clinical health psychologist is provided through the American Board of Professional Psychology.\n\nRecent advances in psychological, medical, and physiological research have led to a new way of thinking about health and illness. This conceptualization, which has been labeled the biopsychosocial model, views health and illness as the product of a combination of factors including biological characteristics (e.g., genetic predisposition), behavioral factors (e.g., lifestyle, stress, health beliefs), and social conditions (e.g., cultural influences, family relationships, social support).\n\nPsychologists who strive to understand how biological, behavioral, and social factors influence health and illness are called health psychologists. Health psychologists use their knowledge of psychology and health to promote general well-being and understand physical illness. They are specially trained to help people deal with the psychological and emotional aspects of health and illness. Health psychologists work with many different health care professionals (e.g., physicians, dentists, nurses, physician's assistants, dietitians, social workers, pharmacists, physical and occupational therapists, and chaplains) to conduct research and provide clinical assessments and treatment services. Many health psychologists focus on prevention research and interventions designed to promote healthier lifestyles and try to find ways to encourage people to improve their health. For example, they may help people to lose weight or stop smoking. Health psychologists also use their skills to try to improve the healthcare system. For example, they may advise doctors about better ways to communicate with their patients. \nHealth psychologists work in many different settings including the UK's National Health Service (NHS), private practice, universities, communities, schools and organizations. While many health psychologists provide clinical services as part of their duties, others function in non-clinical roles, primarily involving teaching and research. Leading journals include \"Health Psychology\", the \"Journal of Health Psychology\", the \"British Journal of Health Psychology\", and \"Applied Psychology: Health and Well-Being\". Health psychologists can work with people on a one-to-one basis, in groups, as a family, or at a larger population level.\n\n\n\n\n\nHealth psychology, like other areas of applied psychology, is both a theoretical and applied field. Health psychologists employ diverse research methods. These methods include controlled randomized experiments, quasi-experiments, longitudinal studies, time-series designs, cross-sectional studies, case-control studies, qualitative research as well as action research. Health psychologists study a broad range of variables including cardiovascular disease, (cardiac psychology), smoking habits, the relation of religious beliefs to health, alcohol use, social support, living conditions, emotional state, social class, and more. Some health psychologists treat individuals with sleep problems, headaches, alcohol problems, etc. Other health psychologists work to empower community members by helping community members gain control over their health and improve quality of life of entire communities.\n\nPsychological factors in health had been studied since the early 20th century by disciplines such as psychosomatic medicine and later behavioral medicine, but these were primarily branches of medicine, not psychology. Health psychology began to emerge as a distinct discipline of psychology in the United States in the 1970s. In the mid-20th century there was a growing understanding in medicine of the effect of behavior on health. For example, the Alameda County Study, which began in the 1960s, showed that people who ate regular meals (e.g., breakfast), maintained a healthy weight, received adequate sleep, did not smoke, drank little alcohol, and exercised regularly were in better health and lived longer. In addition, psychologists and other scientists were discovering relationships between psychological processes and physiological ones. These discoveries include a better understanding of the impact of psychosocial stress on the cardiovascular and immune systems, and the early finding that the functioning of the immune system could be altered by learning.\n\nPsychologists have been working in medical settings for many years (in the UK sometimes the field was termed medical psychology). Medical psychology, however, was a relatively small field, primarily aimed at helping patients adjust to illness. In 1969, William Schofield prepared a report for the APA entitled \"The Role of Psychology in the Delivery of Health Services\". While there were exceptions, he found that the psychological research of the time frequently regarded mental health and physical health as separate, and devoted very little attention to psychology's impact upon physical health. One of the few psychologists working in this area at the time, Schofield proposed new forms of education and training for future psychologists. The APA, responding to his proposal, in 1973 established a task force to consider how psychologists could (a) help people to manage their health-related behaviors, (b) help patients manage their physical health problems, and (c) train healthcare staff to work more effectively with patients.\n\nLed by Joseph Matarazzo, in 1977, APA added a division devoted to health psychology. At the first divisional conference, Matarazzo delivered a speech that played an important role in defining health psychology. He defined the new field in this way, \"Health psychology is the aggregate of the specific educational, scientific and professional contributions of the discipline of psychology to the promotion and maintenance of health, the prevention and treatment of illness, the identification of diagnostic and etiologic correlates of health, illness and related dysfunction, and the analysis and improvement of the healthcare system and health policy formation.\" In the 1980s, similar organizations were established elsewhere. In 1986, the BPS established a Division of Health Psychology. The European Health Psychology Society was also established in 1986. Similar organizations were established in other countries, including Australia and Japan. Universities began to develop doctoral level training programs in health psychology. In the US, post-doctoral level health psychology training programs were established for individuals who completed a doctoral degree in clinical psychology.\n\nA number of relevant trends coincided with the emergence of health psychology, including:\n\nIn the UK, the BPS’s reconsideration of the role of the Medical Section prompted the emergence of health psychology as a distinct field. Marie Johnston and John Weinman argued in a letter to the \"BPS Bulletin\" that there was a great need for a Health Psychology Section. In December 1986 the section was established at the BPS London Conference, with Marie Johnston as chair. At the Annual BPS Conference in 1993 a review of \"Current Trends in Health Psychology\" was organized, and a definition of health psychology as \"the study of psychological and behavioural processes in health, illness and healthcare\" was proposed.\nThe Health Psychology Section became a Special Group in 1993 and was awarded divisional status within the UK in 1997. The awarding of divisional status meant that the individual training needs and professional practice of health psychologists were recognized, and members were able to obtain chartered status with the BPS. The BPS went on to regulate training and practice in health psychology until the regulation of professional standards and qualifications was taken over by statutory registration with the Health Professions Council in 2010.\n\nHealth psychologists conduct research to identify behaviors and experiences that promote health, give rise to illness, and influence the effectiveness of health care. They also recommend ways to improve health care policy. Health psychologists have worked on developing ways to reduce smoking and improve daily nutrition in order to promote health and prevent illness. They have also studied the association between illness and individual characteristics. For example, health psychology has found a relation between the personality characteristics of thrill seeking, impulsiveness, hostility/anger, emotional instability, and depression, on one hand, and high-risk driving, on the other.\n\nHealth psychology is also concerned with contextual factors, including economic, cultural, community, social, and lifestyle factors that influence health. The biopsychosocial model can help in understanding the relation between contextual factors and biology in affecting health. Physical addiction impedes smoking cessation. Some research suggests that seductive advertising also contributes to psychological dependency on tobacco, although other research has found no relationship between media exposure and smoking in youth. OHP research indicates that people in jobs that combine little decision latitude with a high psychological workload are at increased risk for cardiovascular disease. Other OHP research reveals a relation between unemployment and elevations in blood pressure. Epidemiologic research documents a relation between social class and cardiovascular disease.\n\nHealth psychologists also aim to change health behaviors for the dual purpose of helping people stay healthy and helping patients adhere to disease treatment regimens (also see health action process approach). Health psychologists employ cognitive behavior therapy and applied behavior analysis (also see behavior modification) for that purpose.\n\nHealth psychologists promote health through behavioral change, as mentioned above; however, they attempt to prevent illness in other ways as well. Health psychologists try to help people to lead a healthy life by developing and running programmes which can help people to make changes in their lives such as stopping smoking, reducing the amount of alcohol they consume, eating more healthily, and exercising regularly. Campaigns informed by health psychology have targeted tobacco use. Those least able to afford tobacco products consume them most. Tobacco provides individuals with a way of controlling aversive emotional states accompanying daily experiences of stress that characterize the lives of deprived and vulnerable individuals. Practitioners emphasize education and effective communication as a part of illness prevention because many people do not recognize, or minimize, the risk of illness present in their lives. Moreover, many individuals are often unable to apply their knowledge of health practices owing to everyday pressures and stresses. A common example of population-based attempts to motivate the smoking public to reduce its dependence on cigarettes is anti-smoking campaigns.\n\nHealth psychologists help to promote health and well-being by preventing illness. Some illnesses can be more effectively treated if caught early. Health psychologists have worked to understand why some people do not seek early screenings or immunizations, and have used that knowledge to develop ways to encourage people to have early health checks for illnesses such as cancer and heart disease. Health psychologists are also finding ways to help people to avoid risky behaviors (e.g., engaging in unprotected sex) and encourage health-enhancing behaviors (e.g., regular tooth brushing or hand washing).\n\nHealth psychologists also aim at educating health professionals, including physicians and nurses, in communicating effectively with patients in ways that overcome barriers to understanding, remembering, and implementing effective strategies for reducing exposures to risk factors and making health-enhancing behavior changes.\n\nThere is also evidence from OHP that stress-reduction interventions at the workplace can be effective. For example, Kompier and his colleagues have shown that a number of interventions aimed at reducing stress in bus drivers has had beneficial effects for employees and bus companies.\n\nHealth psychologists investigate how disease affects individuals' psychological well-being. An individual who becomes seriously ill or injured faces many different practical stressors. These stressors include problems meeting medical and other bills, problems obtaining proper care when home from the hospital, obstacles to caring for dependents, the experience of having one's sense of self-reliance compromised, gaining a new, unwanted identity as that of a sick person, and so on. These stressors can lead to depression, reduced self-esteem, etc.\n\nHealth psychology also concerns itself with bettering the lives of individuals with terminal illness. When there is little hope of recovery, health psychologist therapists can improve the quality of life of the patient by helping the patient recover at least some of his or her psychological well-being. Health psychologists are also concerned with providing therapeutic services for the bereaved.\n\nCritical health psychologists explore how health policy can influence inequities, inequalities and social injustice . These avenues of research expand the scope of health psychology beyond the level of individual health to an examination of the social and economic determinants of health both within and between regions and nations. The individualism of mainstream health psychology has been critiqued and deconstructed by critical health psychologists using qualitative methods that zero in on the health experience.\n\nLike psychologists in the other main psychology disciplines, health psychologists have advanced knowledge of research methods. Health psychologists apply this knowledge to conduct research on a variety of questions. For example, health psychologists carry out research to answer questions such as: \n\nHealth psychologists can also be responsible for training other health professionals on how to deliver interventions to help promote healthy eating, stopping smoking, weight loss, etc. Health psychologists also train other health professionals in communication skills such as how to break bad news or support behavior change for the purpose of improving adherence to treatment.\n\nHealth psychologists aid the process of communication between physicians and patients during medical consultations. There are many problems in this process, with patients showing a considerable lack of understanding of many medical terms, particularly anatomical terms (e.g., intestines). One area of research on this topic involves \"doctor-centered\" or \"patient-centered\" consultations. Doctor-centered consultations are generally directive, with the patient answering questions and playing less of a role in decision-making. Although this style is preferred by elderly people and others, many people dislike the sense of hierarchy or ignorance that it inspires. They prefer patient-centered consultations, which focus on the patient's needs, involve the doctor listening to the patient completely before making a decision, and involving the patient in the process of choosing treatment and finding a diagnosis.\n\nHealth psychologists engage in research and practice aimed at getting people to follow medical advice and adhere to their treatment regimens. Patients often forget to take their pills or consciously opt not to take their prescribed medications because of side effects. Failing to take prescribed medication is costly and wastes millions of usable medicines that could otherwise help other people. Estimated adherence rates are difficult to measure (see below); there is, however, evidence that adherence could be improved by tailoring treatment programs to individuals' daily lives. Additionally, traditional cognitive-behavioural therapies have been adapted for people suffering from chronic illnesses and comorbid psychological distress to include modules that encourage, support and reinforce adherence to medical advice as part of the larger treatment approach.\n\nHealth psychologists have identified a number of ways of measuring patients' adherence to medical regimens:\n\nHealth psychology attempts to find treatments to reduce or eliminate pain, as well as understand pain anomalies such as episodic analgesia, causalgia, neuralgia, and phantom limb pain. Although the task of measuring and describing pain has been problematic, the development of the McGill Pain Questionnaire has helped make progress in this area. Treatments for pain involve patient-administered analgesia, acupuncture (found to be effective in reducing pain for osteoarthritis of the knee), biofeedback, and cognitive behavior therapy.\n\nBelow are some examples of the types of positions held by health psychologists within applied settings such as the UK's NHS and private practice.\n\nIn the UK, health psychologists are registered by the Health Professions Council (HPC) and have trained to a level to be eligible for full membership of the Division of Health Psychology within the BPS. Registered health psychologists who are chartered with the BPS will have undertaken a minimum of six years of training and will have specialized in health psychology for a minimum of three years. Health psychologists in training must have completed BPS stage 1 training and be registered with the BPS Stage 2 training route or with a BPS-accredited university doctoral health psychology program. Once qualified, health psychologists can work in a range of settings, for example the NHS, universities, schools, private healthcare, and research and charitable organizations. A health psychologist in training might be working within applied settings while working towards registration and chartered status. A health psychologist will have demonstrated competencies in all of the following areas:\nAll qualified health psychologists must also engage in and record their continuing professional development (CPD) for psychology each year throughout their career.\n\n\n\n"}
{"id": "439973", "url": "https://en.wikipedia.org/wiki?curid=439973", "title": "Herbalism", "text": "Herbalism\n\nHerbalism (also herbal medicine) is the study of botany and use of plants intended for medicinal purposes. Plants have been the basis for medical treatments through much of human history, and such traditional medicine is still widely practiced today. Modern medicine makes use of many plant-derived compounds as the basis for evidence-based pharmaceutical drugs. Although herbalism may apply modern standards of effectiveness testing to herbs and medicines derived from natural sources, few high-quality clinical trials and standards for purity or dosage exist. The scope of herbal medicine is sometimes extended to include fungal and bee products, as well as minerals, shells and certain animal parts.\n\nHerbal medicine may also refer to phytomedicine, phytotherapy, or paraherbalism, which are alternative and pseudoscientific practices of using unrefined plant or animal extracts as supposed medicines or health-promoting agents. Phytotherapy differs from plant-derived medicines in standard pharmacology because it does not isolate or standardize biologically active compounds, but rather relies on the false belief that preserving various substances from a given source with less processing is safer or more effective — for which there is no evidence. Herbal dietary supplements most often fall under the phytotherapy category. \n\nArchaeological evidence indicates that the use of medicinal plants dates back to the Paleolithic age, approximately 60,000 years ago. Written evidence of herbal remedies dates back over 5,000 years to the Sumerians, who compiled lists of plants. Some ancient cultures wrote about plants and their medical uses in books called \"herbals\". In ancient Egypt, herbs are mentioned in Egyptian medical papyri, depicted in tomb illustrations, or on rare occasions found in medical jars containing trace amounts of herbs. Among the oldest, lengthiest, and most important medical papyri of ancient Egypt, the Ebers Papyrus dates from about 1550 BC, and covers more than 700 compounds, mainly of plant origin. The earliest known Greek herbals came from Theophrastus of Eresos who, in the 4th century BC, wrote in Greek \"Historia Plantarum\", from Diocles of Carystus who wrote during the 3rd century BC, and from Krateuas who wrote in the 1st century BC. Only a few fragments of these works have survived intact, but from what remains, scholars noted overlap with the Egyptian herbals. Seeds likely used for herbalism were found in archaeological sites of Bronze Age China dating from the Shang Dynasty (c. 1600–1046 BC). Over a hundred of the 224 compounds mentioned in the \"Huangdi Neijing\", an early Chinese medical text, are herbs. Herbs also commonly featured in the traditional medicine of ancient India, where the principal treatment for diseases was diet. \"De Materia Medica\", originally written in Greek by Pedanius Dioscorides (c. 40–90 AD) of Anazarbus, Cilicia, a Greek physician, pharmacologist and botanist, is one example of herbal writing which was used for 1500 years until the 1600s.\n\nThe World Health Organization (WHO) estimates that 80 percent of the population of some Asian and African countries presently use herbal medicine for some aspect of primary health care. Pharmaceuticals are prohibitively expensive for most of the world's population, half of whom lived on less than $2 U.S. per day in 2002. In comparison, herbal medicines can be grown from seed or gathered from nature for little or no cost.\n\nMany of the pharmaceuticals currently available to physicians have a long history of use as herbal remedies, including opium, aspirin, digitalis, and quinine. According to the World Health Organization, approximately 25% of modern drugs used in the United States have been derived from plants. At least 7,000 medical compounds in the modern pharmacopoeia are derived from plants. Among the 120 active compounds currently isolated from the higher plants and widely used in modern medicine today, 80% show a positive correlation between their modern therapeutic use and the traditional use of the plants from which they are derived.\n\nIn a 2010 global survey of the most common 1000 plant-derived compounds, 156 had clinical trials published. Preclinical studies (cell culture and animal studies) were reported for about one-half of the plant products, while 120 (12%) of the plants evaluated – although available in the Western market – had no rigorous studies of their properties, and five were toxic or allergenic, a finding that led the authors to conclude \"their use ought to be discouraged or forbidden.\" Nine plants evaluated in human clinical research included \"Althaea officinalis\" (marshmallow), \"Calendula officinalis\" (marigold), \"Centella asiatica\" (centella), \"Echinacea purpurea\" (echinacea), \"Passiflora incarnata\" (passionflower), \"Punica granatum\" (pomegranate), \"Vaccinium macrocarpon\" (cranberry), \"Vaccinium myrtillus\" (bilberry), and \"Valeriana officinalis\" (valerian), although generally there were inconsistent, often negative results, and the studies were of low quality.\n\nIn 2015, the Australian Government's Department of Health published the results of a review of alternative therapies that sought to determine if any were suitable for being covered by health insurance; Herbalism was one of 17 topics evaluated for which no clear evidence of effectiveness was found. Establishing guidelines to assess safety and efficacy of herbal products, the European Medicines Agency provides criteria for evaluating and grading the quality of clinical research in preparing monographs about herbal products. In the United States, the National Center for Complementary and Integrative Health of the National Institutes of Health funds clinical trials on herbal compounds, provides fact sheets evaluating the safety, potential effectiveness and side effects of many plant sources, and maintains a registry of clinical research conducted on herbal products.\n\nAccording to Cancer Research UK as of 2015, \"there is currently no strong evidence from studies in people that herbal remedies can treat, prevent or cure cancer\".\n\nThe use of herbal remedies is more prevalent in patients with chronic diseases such as cancer, diabetes, asthma and end-stage renal disease. Multiple factors such as gender, age, ethnicity, education and social class are also shown to have association with prevalence of herbal remedies use.\n\nA survey released in May 2004 by the National Center for Complementary and Integrative Health focused on who used complementary and alternative medicines (CAM), what was used, and why it was used. The survey was limited to adults, aged 18 years and over during 2002, living in the United States. According to this survey, herbal therapy, or use of natural products other than vitamins and minerals, was the most commonly used CAM therapy (18.9%) when all use of prayer was excluded.\n\nHerbal remedies are very common in Europe. In Germany, herbal medications are dispensed by apothecaries (e.g., Apotheke). Prescription drugs are sold alongside essential oils, herbal extracts, or herbal teas. Herbal remedies are seen by some as a treatment to be preferred to pure medical compounds that have been industrially produced.\n\nIn India the herbal remedy is so popular that the government of India has created a separate department—AYUSH—under the Ministry of Health & Family Welfare. The National Medicinal Plants Board was also established in 2000 by the Indian government in order to deal with the herbal medical system.\n\nThere are many forms in which herbs can be administered, the most common of which is in the form of a liquid that is drunk by the patient—either an herbal tea or a (possibly diluted) plant extract.\n\nSeveral methods of standardization may be determining the amount of herbs used. One is the ratio of raw materials to solvent. However different specimens of even the same plant species may vary in chemical content. For this reason, thin layer chromatography is sometimes used by growers to assess the content of their products before use. Another method is standardization on a signal chemical.\nHerbal teas, or tisanes, are the resultant liquid of extracting herbs into water, though they are made in a few different ways. Infusions are hot water extracts of herbs, such as chamomile or mint, through steeping. Decoctions are the long-term boiled extracts, usually of harder substances like roots or bark. Maceration is the cold infusion of plants with high mucilage-content, such as sage or thyme. To make macerates, plants are chopped and added to cold water. They are then left to stand for 7 to 12 hours (depending on herb used). For most macerates, 10 hours is used.\n\nTinctures are alcoholic extracts of herbs, which are generally stronger than herbal teas. Tinctures are usually obtained by combining 100% pure ethanol (or a mixture of 100% ethanol with water) with the herb. A completed tincture has an ethanol percentage of at least 25% (sometimes up to 90%). Herbal wine and elixirs are alcoholic extract of herbs, usually with an ethanol percentage of 12–38%. Extracts include liquid extracts, dry extracts, and nebulisates. Liquid extracts are liquids with a lower ethanol percentage than tinctures. They are usually made by vacuum distilling tinctures. Dry extracts are extracts of plant material that are evaporated into a dry mass. They can then be further refined to a capsule or tablet.\n\nThe exact composition of an herbal product is influenced by the method of extraction. A tea will be rich in polar components because water is a polar solvent. Oil on the other hand is a non-polar solvent and it will absorb non-polar compounds. Alcohol lies somewhere in between.\nMany herbs are applied topically to the skin in a variety of forms. Essential oil extracts can be applied to the skin, usually diluted in a carrier oil. Many essential oils can burn the skin or are simply too high dose used straight; diluting them in olive oil or another food grade oil such as almond oil can allow these to be used safely as a topical. Salves, oils, balms, creams and lotions are other forms of topical delivery mechanisms. Most topical applications are oil extractions of herbs. Taking a food grade oil and soaking herbs in it for anywhere from weeks to months allows certain phytochemicals to be extracted into the oil. This oil can then be made into salves, creams, lotions, or simply used as an oil for topical application. Many massage oils, antibacterial salves, and wound healing compounds are made this way.\n\nInhalation, as in aromatherapy, can be used as a treatment.\n\nA number of herbs are thought to be likely to cause adverse effects. Furthermore, \"adulteration, inappropriate formulation, or lack of understanding of plant and drug interactions have led to adverse reactions that are sometimes life threatening or lethal.\" Proper double-blind clinical trials are needed to determine the safety and efficacy of each plant before they can be recommended for medical use. Although many consumers believe that herbal medicines are safe because they are \"natural\", herbal medicines and synthetic drugs may interact, causing toxicity to the patient. Herbal remedies can also be dangerously contaminated, and herbal medicines without established efficacy, may unknowingly be used to replace medicines that do have corroborated efficacy.\n\nStandardization of purity and dosage is not mandated in the United States, but even products made to the same specification may differ as a result of biochemical variations within a species of plant. Plants have chemical defense mechanisms against predators that can have adverse or lethal effects on humans. Examples of highly toxic herbs include poison hemlock and nightshade. They are not marketed to the public as herbs, because the risks are well known, partly due to a long and colorful history in Europe, associated with \"sorcery\", \"magic\" and intrigue. Although not frequent, adverse reactions have been reported for herbs in widespread use. On occasion serious untoward outcomes have been linked to herb consumption. A case of major potassium depletion has been attributed to chronic licorice ingestion., and consequently professional herbalists avoid the use of licorice where they recognize that this may be a risk. Black cohosh has been implicated in a case of liver failure.\nFew studies are available on the safety of herbs for pregnant women, and one study found that use of complementary and alternative medicines are associated with a 30% lower ongoing pregnancy and live birth rate during fertility treatment. Examples of herbal treatments with likely cause-effect relationships with adverse events include aconite, which is often a legally restricted herb, ayurvedic remedies, broom, chaparral, Chinese herb mixtures, comfrey, herbs containing certain flavonoids, germander, guar gum, liquorice root, and pennyroyal. Examples of herbs where a high degree of confidence of a risk long term adverse effects can be asserted include ginseng, which is unpopular among herbalists for this reason, the endangered herb goldenseal, milk thistle, senna, against which herbalists generally advise and rarely use, aloe vera juice, buckthorn bark and berry, cascara sagrada bark, saw palmetto, valerian, kava, which is banned in the European Union, St. John's wort, Khat, Betel nut, the restricted herb Ephedra, and Guarana.\n\nThere is also concern with respect to the numerous well-established interactions of herbs and drugs. In consultation with a physician, usage of herbal remedies should be clarified, as some herbal remedies have the potential to cause adverse drug interactions when used in combination with various prescription and over-the-counter pharmaceuticals, just as a patient should inform a herbalist of their consumption of orthodox prescription and other medication.\n\nFor example, dangerously low blood pressure may result from the combination of an herbal remedy that lowers blood pressure together with prescription medicine that has the same effect. Some herbs may amplify the effects of anticoagulants.\nCertain herbs as well as common fruit interfere with cytochrome P450, an enzyme critical to much drug metabolism.\n\nIn a 2018 study, FDA identified active pharmaceutical additives in over 700 of analyzed dietary supplements sold as \"herbal\", \"natural\" or \"traditional\". The undisclosed additives included \"unapproved antidepressants and designer steroids\", as well as prescription drugs, such as sildenafil or sibutramine.\n\nA 2013 study found that one-third of herbal supplements sampled contained no trace of the herb listed on the label. The study found products adulterated with contaminants or fillers not listed on the label, including potential allergens such as soy, wheat, or black walnut. One bottle labeled as St. John's Wort was found to actually contain \"Alexandrian senna\", a laxative.\n\nResearchers at the University of Adelaide found in 2014 that almost 20 per cent of herbal remedies surveyed were not registered with the Therapeutic Goods Administration, despite this being a condition for their sale. They also found that nearly 60 per cent of products surveyed had ingredients that did not match what was on the label. Out of 121 products, only 15 had ingredients that matched their TGA listing and packaging.\n\nIn 2015, the New York Attorney General issued cease and desist letters to four major U.S. retailers (GNC, Target, Walgreens, and Walmart) who were accused of selling herbal supplements that were mislabeled and potentially dangerous. Twenty-four products were tested by DNA barcoding as part of the investigation, with all but five containing DNA that did not match the product labels.\n\nHerbalists must learn many skills, including the wildcrafting or cultivation of herbs, diagnosis and treatment of conditions or dispensing herbal medication, and preparations of herbal medications. Education of herbalists varies considerably in different areas of the world. Lay herbalists and traditional indigenous medicine people generally rely upon apprenticeship and recognition from their communities in lieu of formal schooling.\n\nIn some countries, formalized training and minimum education standards exist, although these are not necessarily uniform within or between countries. In Australia, for example, the self-regulated status of the profession (as of 2009) resulted in variable standards of training, and numerous loosely-formed associations setting different educational standards. One 2009 review concluded that regulation of herbalists in Australia was needed to reduce the risk of interaction of herbal medicines with prescription drugs, to implement clinical guidelines and prescription of herbal products, and to assure self-regulation for protection of public health and safety. In the United Kingdom, the training of herbalists is done by state funded universities offering Bachelor of Science degrees in herbal medicine.\n\nThe World Health Organization (WHO), the specialized agency of the United Nations (UN) that is concerned with international public health, published \"Quality control methods for medicinal plant materials\" in 1998 in order to support WHO Member States in establishing quality standards and specifications for herbal materials, within the overall context of quality assurance and control of herbal medicines.\n\nIn the European Union (EU), herbal medicines are regulated under the Committee on Herbal Medicinal Products.\n\nIn the United States, herbal remedies are regulated dietary supplements by the Food and Drug Administration (FDA) under current good manufacturing practice (cGMP) policy for dietary supplements. Manufacturers of products falling into this category are not required to prove the safety or efficacy of their product so long as they do not make 'medical' claims or imply uses other than as a 'dietary supplement', though the FDA may withdraw a product from sale should it prove harmful.\n\nCanadian regulations are described by the Natural and Non-prescription Health Products Directorate which requires an eight-digit Natural Product Number or Homeopathic Medicine Number on the label of licensed herbal medicines or dietary supplements.\n\nSome herbs, such as cannabis and coca, are outright banned in most countries though coca is legal in most of the South American countries where it is grown. The \"Cannabis\" plant is used as an herbal medicine, and as such is legal in some parts of the world. Since 2004, the sales of ephedra as a dietary supplement is prohibited in the United States by the FDA, and subject to Schedule III restrictions in the United Kingdom.\n\nHerbalism has been criticized as a potential \"minefield\" of unreliable product quality, safety hazards, and potential for misleading health advice. Globally, there are no standards across various herbal products to authenticate their contents, safety or efficacy, and there is generally an absence of high-quality scientific research on product composition or effectiveness for anti-disease activity. Presumed claims of therapeutic benefit from herbal products, without rigorous evidence of efficacy and safety, receive skeptical views by scientists.\n\nUnethical practices by some herbalists and manufacturers, which may include false advertising about health benefits on product labels or literature, and contamination or use of fillers during product preparation, may erode consumer confidence about services and products.\n\nParaherbalism or phytotherapy is the pseudoscientific use of extracts of plant or animal origin as supposed medicines or health-promoting agents. Phytotherapy differs from plant-derived medicines in standard pharmacology because it does not isolate and standardize the compounds from a given plant believed to be biologically active. It relies on the false belief that preserving the complexity of substances from a given plant with less processing is safer and potentially more effective, for which there is no evidence either condition applies.\n\nPhytochemical researcher Varro Eugene Tyler described paraherbalism as \"faulty or inferior herbalism based on pseudoscience\", using scientific terminology but lacking scientific evidence for safety and efficacy. Tyler listed ten fallacies that distinguished herbalism from paraherbalism, including claims that there is a conspiracy to suppress safe and effective herbs, herbs can not cause harm, that whole herbs are more effective than molecules isolated from the plants, herbs are superior to drugs, the doctrine of signatures (the belief that the shape of the plant indicates its function) is valid, dilution of substances increases their potency (a doctrine of the pseudoscience of homeopathy), astrological alignments are significant, animal testing is not appropriate to indicate human effects, anecdotal evidence is an effective means of proving a substance works and herbs were created by God to cure disease. Tyler suggests that none of these beliefs have any basis in fact.\n\nUp to 80% of the population in Africa uses traditional medicine as primary health care.\n\nNative Americans medicinally used about 2,500 of the approximately 20,000 plant species that are native to North America.\n\nSome researchers trained in both western and traditional Chinese medicine have attempted to deconstruct ancient medical texts in the light of modern science. One idea is that the yin-yang balance, at least with regard to herbs, corresponds to the pro-oxidant and anti-oxidant balance. This interpretation is supported by several investigations of the ORAC ratings of various yin and yang herbs.\n\nIn India, Ayurvedic medicine has quite complex formulas with 30 or more ingredients, including a sizable number of ingredients that have undergone \"alchemical processing\", chosen to balance dosha.\n\nIn Ladakh, Lahul-Spiti and Tibet, the Tibetan Medical System is prevalent, also called the 'Amichi Medical System'. Over 337 species of medicinal plants have been documented by C.P. Kala. Those are used by Amchis, the practitioners of this medical system.\n\nIn Tamil Nadu, Tamils have their own medicinal system now popularly called Siddha medicine. The Siddha system is entirely in the Tamil language. It contains roughly 300,000 verses covering diverse aspects of medicine. This work includes herbal, mineral and metallic compositions used as medicine. Ayurveda is in Sanskrit, but Sanskrit was not generally used as a mother tongue and hence its medicines are mostly taken from Siddha and other local traditions.\n\nIn Indonesia, especially among the Javanese, the jamu traditional herbal medicine is an age old tradition preserved for centuries. Jamu is thought to have originated in the Mataram Kingdom era, some 1300 years ago. The bas-reliefs on Borobudur depicts the image of people grinding herbs with stone mortar and pestle, a drink seller, a physician and masseuse treating their clients. All of these scenes might be interpreted as a traditional herbal medicine and health-related treatments in ancient Java. The Madhawapura inscription from Majapahit period mentioned a specific profession of herbs mixer and combiner (herbalist), called \"Acaraki\". The medicine book from Mataram dated from circa 1700 contains 3,000 entries of jamu herbal recipes, while Javanese classical literature Serat Centhini (1814) describes some jamu herbal concoction recipes.\n\nThough highly possible influenced by Indian Ayurveda system, Indonesia is a vast archipelago with numerous indigenous plants not to be found in India, which include plants similar to Australia beyond the Wallace Line. Indonesians might experimented and figure out the medicinal uses of these native herbal plants. Jamu may vary from region to region, and often not written down, especially in remote areas of the country. Although primarily herbal, materials acquired from animals, such as honey, royal jelly, milk and \"ayam kampung\" eggs are also often used in jamu.\n\nHerbalists tend to use extracts from parts of plants, such as the roots or leaves, believing that plants are subject to environmental pressures and therefore develop resistance to threats such as radiation, reactive oxygen species and microbial attack in order to survive, providing defensive phytochemicals of use in herbalism.\n\nIndigenous healers often claim to have learned by observing that sick animals change their food preferences to nibble at bitter herbs they would normally reject. Field biologists have provided corroborating evidence based on observation of diverse species, such as chickens, sheep, butterflies, and chimpanzee. The habit has been shown to be a physical means of purging intestinal parasites. Lowland gorillas take 90% of their diet from the fruits of \"Aframomum melegueta\", a relative of the ginger plant, that is a potent antimicrobial and apparently keeps shigellosis and similar infections at bay. Current research focuses on the possibility that this plant also protects gorillas from fibrosing cardiomyopathy, which has a devastating effect on captive animals.\n\nSick animals tend to forage plants rich in secondary metabolites, such as tannins and alkaloids. Because these phytochemicals often have antiviral, antibacterial, antifungal, and antihelminthic properties, a plausible case can be made for self-medication by animals in the wild.\n\n"}
{"id": "43398753", "url": "https://en.wikipedia.org/wiki?curid=43398753", "title": "Hittite cuisine", "text": "Hittite cuisine\n\nThe Hittites have left a good number of texts detailing preparation of food and many Hittite laws stipulate how certain food is to be prepared, cooked and served. \nThe main ingredients of Hittite cuisine were dairy products, meat, grain products and other natural products such as honey. \nHittites loved bread and had recipes for as many as 180 types of bread in different shapes and with varying ingredients. Food eaten in Anatolia is a continuation of the Hittite cuisine as stated in the book \"Hittite Cuisine\" published by Alpha Publishing (08-2008) in Turkey.\nSome cities have preserved the Hittite food traditions. Adana, a major city in South East Turkey (Adaniya in Hittite in the former Neo-Hittte, Luwian Kizzuwadna region) is famous for its kebabs and according to studies Hittite cuisine contained a strong element of meat skewer (Shish Kebab). \nVarious books are written in Turkish about the Hittite cuisine and the Hittite University in Çorum in Turkey has published articles about Hittite cuisine recently.\nHittite food recipes were generally similar to that of contemporary civilizations, especially in regard to meat and dairy dishes, but were unique with regard to the plants used in cooking, as Anatolia has its own unique vegetation.\nWine was consumed by the Hittites on regular basis and used for religious festivals and rituals. \n\n"}
{"id": "20361676", "url": "https://en.wikipedia.org/wiki?curid=20361676", "title": "Instituto Conmemorativo Gorgas de Estudios de la Salud", "text": "Instituto Conmemorativo Gorgas de Estudios de la Salud\n\nThe Instituto Conmemorativo Gorgas de Estudios de la Salud (The Gorgas Memorial Institute for Health Studies (GMI)) is a medical research institution that has been dedicated for more than 80 years on investigating diseases in the tropics and preventive medicine.\n\nThe institute was created in 1921 by Dr. Belisario Porras, to honor Dr. William Crawford Gorgas, who eradicated yellow fever in Panama. This achievement allowed the construction of the Panama Canal. Gorgas Memorial Laboratories was inaugurated in 1928 on Arosemena Avenue. Its expertise in studying the diseases of the tropics originated from the necessity to eradicate yellow fever and control malaria in the cities of Panama and Colon with the construction of the Panama Canal.\n\nThis triumph, led by Dr. William C. Gorgas in the first years of the 20th century, was achieved by one of the largest and most successful community-level public health interventions ever recorded in the history of medicine. Since then, many emerging and reemerging diseases have been studied at GMI and physicians and scientists of many nationalities working there have made significant contributions to medicine in the tropics. These collaborations and lines of investigation have continued up to the present.\n\nGMI is known for its high quality laboratories, including those of parasitology, immunology, genomics, entomology, water and food chemistry, bacteriology, entomology and virology. Besides having an epidemiology and biostatistics department, it conducts research on health administration, chronic diseases and human reproduction. GMI has contributed to better the health of Panama and the Central American countries by acting as a reference laboratory to diagnose diseases like yellow fever, malaria, measles, arbovirus febrile illness, viral encephalitidies, influenza, dengue and hantavirus cardiopulmonary syndrome. Jorge Motta, MD, MPH, was the Director General from 2004 to 2008 and the present director is Dr. Nestor Sosa.\n\nMost recently GMI became a World Bank-Pan-American Health Organization reference laboratory for human immunodeficiency virus (HIV) for the Central American region. Its lengthy tradition of service in the region has permitted GMI to maintain and nurture close contacts and rapid communication with all the public health installations of Panama’s Ministry of Health, with the health installations of the Social Security System and with the main private hospitals of the country.\n\nIn 2006, GMI signed an MOU with the Department of Health and Human Services and was also awarded two grants, one to increase its virology diagnostic capacity and to strengthen the surveillance of influenza virus in Panama and Central America and the other to develop a Regional Training Center for community health care workers of the Central American Region.\n\nThe Regional Training Center is an educational facility dedicated to community health care workers and clinicians of Central America to prepare them to provide better primary and preventive health care to underserved rural and poor urban communities and indigenous populations. These health care providers are trained to provide the first line of response to health needs of their communities, especially in areas related of infectious diseases, pandemic illness response and the attainment of Millennium Development Health Goals.\n\nGMI's has research agreements and research projects with academic centers like the Johns Hopkins University, George Washington University, the University of South Florida, the University of New Mexico, and the Walter Reed Institute of Research. GMI has developed strong links with the epidemiology programs and the extended immunization programs of all the countries in Central America, with the World Health Organization (WHO), specifically with the Special Programme for Research and Training in Tropical Diseases (TDR) and influenza program, with the Center for Diseases Control of the United of America (CDC-USA) and (CDC-MERTU-G), with the Pan-American Health Organization (PAHO) and with institutions like the Smithsonian Tropical Research Institute (STRI).\n\nToday GMI is an autonomous public institution that works closely with the Ministry of Health. Its vision is to improve the health of Panama and Central America. Its mission is to develop health research in Panama, to fulfill the functions of a national public health laboratory and to provide education to health care workers of the region. GMI is evolving to become Panama’s national public health institute and will continue serving the Ministry of Health by providing the best evidence available to develop public health policy.\n\nA collection of the institute's papers are held at the National Library of Medicine in Bethesda, Maryland. \n\n"}
{"id": "34568954", "url": "https://en.wikipedia.org/wiki?curid=34568954", "title": "International Congress on Sleep Apnea", "text": "International Congress on Sleep Apnea\n\n\"The International Congress on Sleep Apnea in Odontology\" is the first international congress assembled to discuss this disorder. The congress is held annually in Madrid. The meeting consists of prestigious lecturers with high experience in the field of dental sleep medicine at the international level.\n\nThe next edition of the Congress will take place on February 17 and 18 in Madrid and will be attended by 24 speakers. They will give a talk about the latest innovations of Sleep Apnea.\n\nThe first National Congress on Sleep Apnea in Odontology was held in 2010, which led to scientific success and participation. On February 5 and 6, 300 attendees participated in the NH Eurobuilding Hotel where they had the opportunity to hear different presentations by specialists such as: Susanne Schwarting, W. Keith Thornton, Julio Cifuentes and other specialists from France, Italy, Germany, Brazil and Portugal.\n\nThe Second Congress Edition was held on February 18 and 19 2011. The event content was published by TV announcement and newspapers. The II Congress was attended by Roy Dookun (President of the British Society of Dental Sleep Medicine), José Castro Padial (President of the Spanish Sleep Society), Joâo Lopes Fonseca, and Susanne Schwarting amongst others.\n\n"}
{"id": "2579214", "url": "https://en.wikipedia.org/wiki?curid=2579214", "title": "Lady Stanley Institute for Trained Nurses", "text": "Lady Stanley Institute for Trained Nurses\n\nThe Lady Stanley Institute for Trained Nurses was the first nursing school in Ottawa, Ontario, located on Rideau Street. It was founded in 1891 by Constance Stanley, Baroness Stanley of Preston and later Countess of Derby. She was the wife of Frederick Arthur Stanley, 16th Earl of Derby, who served as Governor General of Canada from 1888-1893.\n\n"}
{"id": "31593529", "url": "https://en.wikipedia.org/wiki?curid=31593529", "title": "Lake Chad replenishment project", "text": "Lake Chad replenishment project\n\nThe Lake Chad replenishment project is a proposed major water diversion scheme that would involve damming the Ubangi River at Palambo in Central African Republic and channeling some of the water to Lake Chad through a navigable canal.\n\nThe canal was suggested by a Nigerian engineer before 1991, and would generate hydro-electricity at several points along its length. These would power new industrial townships, while the canal would replenish the lake. \nThe irrigation scheme for a 2,400 km canal from the Congo Basin to the lake, which has been steadily shrinking, was considered unlikely to materialize as late as 2005.\n\nThe members of the Lake Chad Basin International Commission are Chad, the Central African Republic, Nigeria, Cameroon and Niger. Concerned by shrinkage of the lake's area from in 1972 to in 2002, they met in January 2002 to discuss the project. Both the ADB and the Islamic Development Bank expressed interest in the project. However, the member states of the Congo-Ubangi-Sangha Basin International Commission, Congo-Kinshasa, Congo-Brazzaville and the Central African Republic expressed concern that the project would reduce the energy potential of the Inga hydroelectric dam, would affect navigation on the Ubangi and Congo rivers and would reduce fish catches on these rivers.\n"}
{"id": "12010057", "url": "https://en.wikipedia.org/wiki?curid=12010057", "title": "Let There Be Light (1946 film)", "text": "Let There Be Light (1946 film)\n\nLet There Be Light (1946) — known to the U.S. Army as PMF 5019 — is a documentary film directed by American filmmaker John Huston (1906–1987). It was the last in a series of four films directed by Huston while serving in the U.S. Army Signal Corps during World War II. Its portrayal of soldiers suffering from posttraumatic stress disorder led to \"Let There Be Light\" being suppressed by the U.S. government; it was not released until the 1980s.\n\nSeventy-five U.S. service members — recent combat veterans suffering from various \"nervous conditions\" including psychoneurosis, battle neurosis, conversion disorder, amnesia, severe stammering, and anxiety states — are followed in the course of their medical management. A series of scenes chronicles their entry into the military psychiatric hospital, treatment, and eventual recovery and discharge, all typically in a period of 6 to 8 weeks. Treatments depicted include narcosynthesis, hypnosis, group psychotherapy, music therapy, and work therapy. The highlighted cases are presented as marked therapeutic successes, accompanied by upbeat musical cues, although the narrator cautions after one dramatic recovery that \"the neurosis is not cured\". The patients, who explain themselves to the doctors on camera at some length, are treated soberly and with dignity, while the therapies are presented in an optimistic and flattering manner. The film ends with a number of the featured patients participating in a ceremony in which they are discharged, not just from the hospital, but from military service, and returned to civilian life.\n\nThe film was made as one of the early entries in the Army's Professional Medical Film series, which began in 1945. It was shot during spring 1945 at Edgewood State Hospital, Deer Park, Long Island, New York which between 1944 and 1946 was part of Mason General Hospital, a psychiatric hospital run by the United States War Department named for an Army doctor and general.\n\nThere are no personal credits in the film. Offscreen credits have been compiled by several sources. The film includes scoring by Dimitri Tiomkin. The cinematography has been credited to Stanley Cortez, John Doran, Lloyd Fromm, Joseph Jackman, and George Smith. The film's editors were William H. Reynolds and Gene Fowler Jr..\n\nIn 1948, the film was remade with professional actors and retitled \"Shades of Gray\" (PMF 5047).\n\nThe film was controversial in its portrayal of psychologically traumatized veterans of the war. \"Twenty percent of our army casualties\", the narrator says, \"suffered psychoneurotic symptoms: a sense of impending disaster, hopelessness, fear, and isolation.\" Apparently due to the potentially demoralizing effects the film might have on post-war recruitment, it was subsequently banned by the Army after its production, although some unofficial copies had been made. Military police once confiscated a print Huston was about to show friends at the Museum of Modern Art. The Army claimed it invaded the privacy of the soldiers involved, and the releases Huston had obtained were lost; the War Department refused to get new ones.\n\nThe film's eventual release in the 1980s by Secretary of the Army Clifford Alexander, Jr. was attributed to his friend Jack Valenti who worked to get the ban lifted. The film was screened in the \"Un Certain Regard\" section at the 1981 Cannes Film Festival. The copy of the film that was released was poor, with a garbled sound track that \"made it almost impossible to understand the whispers and mumbles of soldiers in some scenes.\n\nIn 2010, the film was selected for preservation in the United States National Film Registry by the Library of Congress as being \"culturally, historically, or aesthetically significant\". The National Film Preservation Foundation then funded restoration of the print and its soundtrack. The restored version was released in May, 2012.\n\nThe National Archives now sells and rents copies of the film and, as a federal government work, it is in the public domain.\n\n\n\n\n"}
{"id": "9024504", "url": "https://en.wikipedia.org/wiki?curid=9024504", "title": "List of UN numbers 1301 to 1400", "text": "List of UN numbers 1301 to 1400\n\nThe UN numbers from UN1301 to UN1400 as assigned by the United Nations Committee of Experts on the Transport of Dangerous Goods.\n\n"}
{"id": "412681", "url": "https://en.wikipedia.org/wiki?curid=412681", "title": "List of protective human features", "text": "List of protective human features\n\nThis is a list of human features that offer protection against disease.\n\n"}
{"id": "531365", "url": "https://en.wikipedia.org/wiki?curid=531365", "title": "London School of Hygiene &amp; Tropical Medicine", "text": "London School of Hygiene &amp; Tropical Medicine\n\nThe London School of Hygiene & Tropical Medicine (informally the LSHTM) is a public research university on Keppel Street, Bloomsbury, Camden, the constituent college of the University of London that specialises in public health and tropical medicine. On successful completion of their studies, its students gain a University of London degree.\n\nThe institution was founded in 1899 by Sir Patrick Manson, after a donation from the Indian Parsi philanthropist B.D. Petit. Since its foundation it has become one of the most highly placed institutions in global rankings in the fields of public health and infectious diseases.\n\nThe LSHTM's mission is to contribute to the improvement of health worldwide through the pursuit of excellence in research, postgraduate teaching and advanced training in national and international public health and tropical medicine, and through informing policy and practice in these areas. The annual income of the institution for 2016–17 was £177.7 million of which £121.9 million was from research grants and contracts, with an expenditure of £176.8 million. \n\nThe school was founded in 1899 by Sir Patrick Manson as the London School of Tropical Medicine after the Parsi philanthropist Bomanjee Dinshaw Petit made a donation of £6,666. \n\nIt was initially located at the Albert Dock Seamen's Hospital in the London Docklands. Just prior to this teaching in tropical medicine had been commenced in 1899 at the Extramural school at Edinburgh and even earlier at London's Livingstone College founded in 1893 by Charles F. Harford-Battersby (1865–1925). Before giving lectures at St George's Hospital, London, in 1895, Livingstone College afforded Manson his first opportunity to teach courses in tropical medicine. Manson's early career was as a physician in the Far East where he deduced the correct etiology of filariasis, a parasitic vector based disease, transmitted through the bite of a mosquito. On his return to London, he was appointed Medical Advisor to the Colonial Office. He strongly believed that doctors should be trained in tropical medicine to treat British colonial administrators and others working throughout Britain's tropical empire. He also encouraged and mentored Ronald Ross during this period to uncover the correct etiology of malaria, which Ross subsequently discovered in 1897, winning the Nobel Prize for his efforts. The original school was established as part of the Seamen's Hospital Society.\n\nIn 1902, the benefactor Petit wrote the following about the institution in a letter to Sir Francis Lovell (Dean of the School), quoted in \"The Times\". \nIn 1920 the school moved, with the Hospital for Tropical Diseases, to Endsleigh Gardens in central London, taking over a former hotel which had been used as a hospital for officers during the First World War.\nIn 1921 the Athlone Committee recommended the creation of an institute of state medicine, which built on a proposal by the Rockefeller Foundation to develop a London-based institution that would lead the world in the promotion of public health and tropical medicine. This enlarged school, now named the London School of Hygiene & Tropical Medicine was granted its Royal Charter in 1924.\n\nThe school moved to its present location in Gower Street in 1929.\n\nA competition to design a new school building to be sited in Gower Street, was held involving five architects, all experienced in laboratory design and construction. This was won in 1925 by Morley Horder and Verner Rees who located the main entrance in Keppel Street. This building was opened in 1929 by HRH the Prince of Wales. The purchase of the site and the cost of a new building was made possible through a gift of $2m from the Rockefeller Foundation.\n\nThe Faculty of Epidemiology and Population Health aims to be a methodological centre of excellence for research in national and global health issues, to expand the limits of epidemiological thinking & multi-disciplinary research to further understanding of health issues in their full complexity, to develop, refine and disseminate tools & methods for research design, data collection, analysis and evaluation, and to conduct rigorous research in national and global health. \n\nThe Faculty of Infectious and Tropical Diseases (ITD) was formed in August 1997 and encompasses all of the laboratory-based research in the School as well as that on the clinical and epidemiological aspects of infectious and tropical diseases. It is currently headed by Simon Croft, who is Professor of Parasitology. The Faculty is organised into four large research departments. The range of disciplines represented in the faculty is very broad and inter-disciplinary research is a feature of much of its activity. \n\nThe spectrum of diseases studied is wide and there are major research groups working on topics which include:\n\n\nThere is close interaction between scientists in different research teams. The Faculty has overseas links which provide a basis for field studies and international collaborations in developed and developing countries. Funding for research in the Faculty comes from around 45 funding organisations and agencies.\n\nThe Faculty of Public Health and Policy aims to improve global health through research, teaching and the provision of advice in the areas of health policy, health systems and services, and individual, social and environmental influences on health. Interests and activities embrace the health needs of people living in countries at all levels of development.\nThe School has the largest numbers of research active staff in the areas of epidemiology, public health and health services research in the UK. The Faculty of Public Health and Policy has over 220 members of staff, including epidemiologists, public health physicians, economists, policy analysts, anthropologists, sociologists, historians, psychologists, statisticians and mathematicians. The Faculty's research programmes, with an annual spend of over £7m, focus on public health problems of importance both globally and in the UK, and build on an extensive network of collaborations.\n\nThe research programmes exploit multidisciplinary and multi-method approaches, generate new knowledge for specific contexts and test transferability to different settings, and engage with policymakers and providers of health care to ensure research is relevant and translated into practice.\n\nThe Faculty hosts School Centres in the areas of History in Public Health, Research on Drugs and Health Behaviours, Spatial Analysis in Public Health, Global Change and Health, Health of Societies in Transition (ECOHOST), and Gender Violence and Health. In addition, staff participate in Centres based in other departments, notably the Malaria Centre and the Centre for the Mathematical Modelling of Infectious Disease.\n\nThe School is currently home to the following research centres:\n\nAll three Faculties offer a wide range of MSc courses and Research Degrees leading to a University of London degree of DrPH, MPhil and PhD. Courses are delivered both face-to-face in London and via distance learning in collaboration with the University of London International Programmes. The School also offers access to free online courses.\n\nThe LSHTM won the 2009 Gates Award for Global Health established by the Bill & Melinda Gates Foundation and received $1 million in prize money. The award recognises organisations that have made an outstanding contribution to improving global health.\n\nMore recently, a team of researchers led by Richard Hayes at the London School of Hygiene & Tropical Medicine, have been awarded $37 million to test an innovative combination of strategies to prevent HIV in African countries.\n\nThe Donald Reid Medal is awarded triennially by the LSHTM in recognition of distinguished contributions to epidemiology.\n\nIn 2015 and 2016, US News Best Global Universities Rankings ranked the LSHTM as 3rd in the world for social sciences and public health, ranking behind only Harvard and Johns Hopkins Universities. The School also ranked 29th in the world for clinical medicine, 20th for immunology and 39th for microbiology, contributing to an overall ranking of 114th in the world, 38th in Europe and 10th in the UK.\n\nIn the 2015 CWTS Leiden Ranking, the LSHTM has been ranked top university in Europe for research impact in all fields, ahead of Oxford and Cambridge. The School is also ranked 6th overall in the world for impact based on the top 1% of published papers in all fields, after MIT, Harvard, Caltech, Stanford and Berkeley, 3rd in the world for biomedical and health sciences, after only MIT and Caltech, and 5th in the world overall for collaborative research.\n\nIn 2008, the UK Research Assessment Exercise (RAE) confirmed the School as a world leading centre for research. The School has been ranked one of the top three research institutions in the UK in the Times Higher Education Table of Excellence, which is based on the 2008 Research Assessment Exercise.\n\n\n"}
{"id": "43281371", "url": "https://en.wikipedia.org/wiki?curid=43281371", "title": "Mechanophobia", "text": "Mechanophobia\n\nMechanophobia is the fear of machines, a type of specific phobia.\n\n"}
{"id": "370604", "url": "https://en.wikipedia.org/wiki?curid=370604", "title": "Medical license", "text": "Medical license\n\nA medical license is an occupational license that permits a person to legally practice medicine. Most nations require such a license, bestowed either by a specified government-approved professional association or a government agency. Licenses are not granted automatically to all people with medical degrees. A medical school graduate must receive a license to practice medicine to legally be called a physician. The process typically requires testing by a medical board. The medical license is the documentation of authority to practice medicine within a certain locality.\n\nCanada requires that applicants have graduated from a school registered in the World Directory of Medical Schools, and apply to sit the \"Medical Council of Canada Evaluating Examination\".\n\nChina issued the «Law on Licensed Physician» in 1995. The law requires all newly graduated medical students to sit the National Medical Licensing Examination (NMLE), regulated by the National Medical Examination Center (NMEC), and then register with the local regulatory body. Eligibility for the exam requires that students complete a one year internship after obtaining a primary medical qualification (i.e., Bachelor of Medicine). The two-part exam includes a Clinical Skill (CS) test and a General Written (GW) test. The CS test consists of many stations, and candidates must pass the CS test to take the GW test. The GW test consists of four papers, and candidates have 2.5 hours to complete each one over two days. The CS is held in July, followed by GW in September each year.\n\nThe Instituto Colombiano para el Fomento de la Educación Superior (ICFES) and the Ministry of Education regulate the medical schools that are licensed to offer medical degrees. After completing all the schools' requirements to obtain a medical degree, physicians must serve the \"obligatory social service\" (in rural areas, research, public health or special populations e.g., orphan children), which usually lasts one year. After completing the social service, a doctor obtains a \"medical registration\" at the governor's office (Gobernación) of the Department (province/state) where they served the obligatory term. This registration is the same as a license in other countries, and authorizes the physician to practice medicine anywhere in the national territory. However, to practice in other departments requires an inscription from that department. Unlike the US, there is no official licensing exam for medical graduates in Colombia, since this responsibility is delegated to medical schools that have permission to confer medical degrees.\n\nIn Germany, licensing of doctors (\"Approbation\") is the responsibility of the state governments. Licensed doctors are compulsory members of \"Ärztekammern\" (literally: \"Physician chambers\"), which are medical associations organized on state level. Criteria for licensing of doctors are regulated in the \"Approbationsordnung für Ärzte\", which is a piece of federal law.\n\nIn India, certification requires that a medical school graduate pass the final MBBS examination and undergo a one year internship in a hospital recognised by the Medical Council of India. Foreign medical graduates must take the Foreign Medical Graduates Examination (FMGE), conducted by the National Board of Examinations (NBE). They can practise medicine throughout the country after certifying themselves as per Indian Medical Council Act, 1956. Doctors registered with any one state medical council are automatically included in the Indian Medical Register and thereby entitled to practise medicine anywhere in India.\nThe MCI Ethics Committee observed in a meeting held on September 2, 2004 that, \"There is no necessity of registration in more than one state medical council because any doctor, who has registered with any state medical council is automatically registered in the Indian Medical Register and also by virtue of Section 27 of the IMC Act, 1956, a person, whose name is included in the IMR, can practise anywhere in India.\" The Registered Doctors with various State Medical Councils across India up to the year 2015 can be checked in the official website of INDIAN MEDICAL REGISTRY search www.mciindia.org by just typing the name of the doctor.\n\nThe term \"Medical License\" is US-centric terminology. In the UK and in other commonwealth countries the analogous instrument is called registration; i.e., being on the register or being/getting struck off (the register). The General Medical Council is the regulatory body for doctor's licensing in the UK. Currently, there are two types of basic registration: \"Provisional Registration\" and \"Full Registration\", and two types of specialty registration: \"Specialist Registration\" and \"GP registration\". In November 2009, the GMC introduced the \"licence to practise\", and it is required by law that to practise medicine in the UK, all doctors must be registered and hold a licence to practise. The registration information for all doctors holding or that have previously held a license in the UK is available online at the GMC website.\n\nIn the United States, medical licenses are usually granted by individual states. Only those with medical degrees from schools listed in the AVICENNA Directory for medicine or the FAIMER International Medical Education Directory are permitted to apply for medical licensure.\n\nThe federal government does not grant licenses. A physician practicing in a federal facility, federal prison, US Military, and/or an Indian Reservation may have a license from any state, not just the one they are residing in. The practice of \"tele-medicine\" has made it common for physicians to consult or interpret images and information from a distant location. Some states have special licensure for this. The licensure process for most physicians takes between three and six months, due to the extensive background checks, educational, training, and historical primary source verifications.\n\nThe enactment of U.S. state medical licensing laws in the late 1800s was for the primary purpose of reducing competition and allowing physicians to make more money.\nThe added benefit of public safety made restrictive licensure laws more appealing to both physicians and legislators. Infrequently mentioned in the literature, is that the “public safety” that is created by reducing the number of practitioners only extends to the patients who receive medical care. Thus, the overall effect is more expensive and higher-quality medical care for fewer patients.\n\nAn article from 2013 says of the road to licensing in Canada, \"The path through immigration, residency training, licensure and employment promises to remain a difficult road to navigate,\" and emphasizes that the current and future demand for healthcare. This emphasizes that there are a number of barriers that doctors face when it comes to practicing, yet there is a very high demand for doctors.\n\nBeyond the more general criticisms of occupational licensing that licensing increases costs and fails to improve quality, licensing in the medical profession specifically has been criticized as failing to enforce the standard practices they are charged with enforcing. In 1986, Inspector General at the US Health Department said that medical boards took \"strikingly few disciplinary actions\" for physician misconduct.\nThere have been a number of cases involving patient deaths where physicians only had their licenses removed years after multiple wrongful patient deaths had happened.\nAlso, it has been said that because hospitals have had more legal burden placed on them in recent decades, they have more of an incentive to require that their physicians be competent. Thus, the process whereby physicians are reviewed and licensed by the State medical board results in some duplicate evaluations. The physician is evaluated both in the licensure process and then again by the hospital for the purpose of credentialing and granting hospital privileges. State medical boards have increased the number of disciplinary actions against physicians since the 1980s.\n\n"}
{"id": "37333380", "url": "https://en.wikipedia.org/wiki?curid=37333380", "title": "Michael J. Ybarra", "text": "Michael J. Ybarra\n\nMichael Jay Ybarra (September 28, 1966 – June 30, 2012) was an American journalist, author and adventurer whose non-fiction work appeared in various national publications. In 2004, his book about McCarthyism, \"Washington Gone Crazy: Senator Pat McCarran and the Great American Communist Hunt\", won the D.B. Hardeman Prize. As the extreme sports correspondent for \"The Wall Street Journal,\" Ybarra wrote articles about outdoor adventure, providing the genre with a wider audience than it typically receives.\n\nBorn and raised in Los Angeles, Ybarra graduated from the University of California, Los Angeles, in 1990 with a B.A. in political science. It was during his undergraduate years at UCLA that he started writing professionally for the \"Los Angeles Times\", followed by the \"Chicago Tribune\". During his brief stint at the \"Chicago Tribune\", he interviewed future President Barack Obama. After graduating from UCLA, Ybarra moved to Washington, D.C., where he wrote for \"The Washington Post\". He left to return to school and graduated from the University of California, Berkeley, in 1992 with an M.A. in political science.\n\nYbarra had a 25-year career as a journalist and author. An article he wrote for \"The\" \"Washington Post\", \"Activists Attest to Romania's Idea of Democracy\", was entered into the \"Congressional Record\" at the request of Senator Ted Kennedy. His story about Hurricane Katrina for \"CIO Decisions\" magazine, \"The Long Road Back\", won a National Azbee Gold Award from the American Society of Business Publication Editors and a Bronze Tabbie Award for feature article. Ybarra reported on a wide variety of topics and people, including President Obama, Pulitzer Prize-winning author Michael Chabon, Patagonia founder and climber Yvon Chouinard, novelist Norman Mailer, historian Arthur Schlesinger, Jr., veteran climber Fred Beckey and television personality Bill Maher.\n\nIn the early 1990s, Ybarra began working for \"The\" \"Wall Street Journal\" as a staff reporter in its San Francisco bureau. It was during this period that he started researching and writing \"Washington Gone Crazy\". The book was published by Steerforth in 2004 to critical acclaim. Author, professor and CBS News commentator Douglas Brinkley wrote: \"Esteemed scholar Michael J. Ybarra's \"Washington Gone Crazy —\" based on extensive new archival research — offers a fair-minded, and ultimately devastating, portrait of Nevada's notorious Cold Warrior. A truly landmark study.\" It was a finalist for the Los Angeles Times Book Prize and was shortlisted for the Ambassador Book Award in American Studies, and \"The New York Times Book Review\" listed it among the 100 Notable Books of the Year. \"Washington Gone Crazy\" also won the D.B. Hardeman Prize for the best book on Congress from the Lyndon B. Johnson Foundation. Award committee member H. W. Brands, the Dickson, Allen, Anderson Centennial Professor of History at the University of Texas at Austin, said Ybarra's work was \"that rare book which has something really new to say on an old subject\". A digital version, featuring an introduction by Sam Tanenhaus, a former editor of \"The New York Times Book Review\", is slated to be released in 2015.\n\nWhile on a trip to Peru in 2004, Ybarra took his first climbing lessons. He subsequently became an avid climber and adventurer. Ybarra traveled widely, climbing, hiking and kayaking in such places as Nepal, Peru, Chile, Argentina, Switzerland, Italy, Thailand, Mexico, Canada, Alaska, Montana, Utah and the Sierra Nevada. From 2007 until his death in 2012, he chronicled his adventures for \"The\" \"Wall Street Journal\" as its extreme sports correspondent, publishing more than 30 pieces.\n\nYbarra was killed on June 30, 2012, in a climbing accident on the Sawtooth Ridge in Yosemite National Park. Mr. Ybarra’s sister, Suzanne, said the family had reported him missing on Sunday after he did not return from what was supposed to be a two-day solo climb. His sudden death at the age of 45 was widely covered by the American and British media. Upon Ybarra's death, \"The\" \"Wall Street Journal\" released the following statement: \"Michael Ybarra was an extraordinary journalist. In the best traditions of his profession he enlightened and engaged readers on a wide array of topics in clear, vivid prose. His passion for the outdoors was evident not only in his writing for the Leisure & Arts and Book sections — reviews and essays written with such verve you felt you were right beside him on a mountain face or in a kayak — but in the way he lived. We mourn his passing, and send our thoughts and prayers to his family.\"\n\nAs a writer, he left behind a large body of published work spanning more than two decades. A portion of Ybarra's personal collection of climbing books is housed at the California Institute of Technology in the Sherman Fairchild Library as \"The Michael J. Ybarra Memorial Collection.\" Bret Israel, Sunday Calendar editor of the \"Los Angeles Times\", established a scholarship at UCLA in Ybarra's memory for humanities students studying abroad. Ybarra's Pat McCarran memorabilia is available to the public at the Nevada Historical Society in Reno. His papers for \"Washington Gone Crazy\" are at the Hoover Institution at Stanford.\n\nBooks\n\nArticles\n"}
{"id": "18250110", "url": "https://en.wikipedia.org/wiki?curid=18250110", "title": "Mpedigree", "text": "Mpedigree\n\nmPedigree refers both to a mobile telephony shortcode platform that interconnects GSM mobile networks in a number of African and Asian countries to a central registry wherein pedigree information of product brands belonging to participant manufacturers are stored, as well as the organisation that was founded in 2007 to manage and promote this registry to organisations and governments in Africa and other parts of the world. The latter is named the mPedigree Network. In December 2015, the mPedigree Network rebranded to 'mPedigree', and begun to trade under that name and a new logo, based on a knight-of-chess motif.\n\nIn November 2008, the Nigerian National Agency for Drug Administration & Control (NAFDAC) reported to an industry publication that its Technical Committee was evaluating the security credentials of the mPedigree system for a possible roll-out in that country. NAFDAC and the Nigerian pharmaceutical companies formed a consortium in June 2009 to roll the service out for all medicines in Nigeria. By 2014, NAFDAC had renamed this initiative as MAS (Mobile Authentication Service), involving multiple partners, including mPedigree. \n\nIn 2011, the Kenyan drug safety regulator announced its support for the mobile telephony anti-counterfeiting system deployed in that country by mPedigree.\n\nIn 2017, the Kenyan agricultural regulator, KEPHIS, announced a partnership with mPedigree to enable the verification of seed quality using mobile phone technologies. \n\nManufacturers who sign on to the mPedigree scheme upload pedigree information of each pack of medicine into the central registry using standard mass serialisation methods such as those employed in the RFID-enabled e-pedigree system familiar in the United States and elsewhere.\n\nWhen consumers buy a product made by a manufacturer participating in the scheme, they are able to query the pedigree information stored in the registry by means of a free SMS message. An automatic response from the registry certifies whether the particular product is truly \"from source\" or not. The proponents of the scheme believe the system will be effective in the fight against counterfeit medicines in the region.\n\nIn May 2010 it was reported that Hewlett Packard (HP), Zain Telecommunications, and undisclosed pharmaceutical and other partners had signed up to the mPedigree program with plans to extend the service to multiple countries across Africa. Some West African companies were also reported as using the technology.\nThe platform has been in testing since 28 January 2008. Media reports in Ghana suggest that monitored trials conducted in the two major cities in the country, Accra and Kumasi, were largely successful. In a forum convened together with the US-based Partnership for Safe Medicines and the Ghana Food & Drugs Board, the Deputy Chief Executive of the Food & Drugs Board announced that the Ghanaian Authorities were investigating the introduction of the mPedigree platform as a national standard based on the outcomes of the trial.\n\nA new consortium, including mPedigree and other technology companies, was formed by Nigerian regulator NAFDAC to promote the use of mobile medicines authentication technologies in Nigeria, and in July 2014 a deadline for compliance was set for manufacturers of certain categories of medicines.\nOn 21 August 2014, the Pharmaceutical Society of Ghana announced that it had adopted the mPedigree initiative through its new PREVENT program, thus making the mPedigree solution an industry-wide standard in Ghana. The Pharmaceutical Society's member organization, the Pharmaceutical Manufacturers Association of Ghana, also announced its embrace of the solution, and mention was made that several member companies of the association had already implemented the mPedigree Goldkeys solution on medicines sold in Ghana. The Ministry of Health of Ghana and the Food & Drugs Authority endorsed the program.\nmPedigree's Goldkeys technology is also used in the protection of products from counterfeiting in other industries such as textiles and cosmetics.\nIn 2015, the Ugandan standards regulator, the UNBS, announced a partnership with mPedigree, USAID, and others to track seeds and other agro-inputs, and secure them against counterfeiting, using mPedigree's Goldkeys platform, under the KAKASA brand name. Channel 114 was dedicated by the Uganda telecom authorities for this purpose. \n\nMPedigree lists as its supporting partners: the World Economic Forum Technology Pioneers Program, Ashoka, Nokia, and a number of telecoms carriers and pharmaceutical regulators in Ghana, Nigeria, and India.\n\nIn April 2008, mPedigree announced that it had commissioned the first documentary on the fake drugs phenomenon produced within West Africa by a locally based production House. This documentary was debuted in partnership with the German overseas cultural establishment, the Goethe Institut, and later premiered on Ghanaian television networks, including the national broadcaster, GTV.\n\nIn November 2009, mPedigree lost out to Air Semiconductor in the finals of the 2009 Institution of Engineering Technology's Innovation Awards.\n\nOn 4 December 2008, the World Economic Forum announced that it has selected mPedigree as a 2009 Technology Pioneer. The World Economic Forum's Technology Pioneer Program alumni includes NanoSolar, Google, the Wikimedia Foundation (publishers of the Wikipedia), Mozilla, and Raindance Technologies.\n\nIn November 2010, mPedigree won the start-up category of the Global Security Challenge in London, becoming the first organisation in the Southern Hemisphere to win the award according to the organisers.\n\nIn February 2011, mPedigree won the 2011 Netexplorateur Grand Prix at UNESCO in Paris, for combating fake medicine in Africa through texting. \n\nIn August 2013, mPedigree's President, Bright Simons, was given a lifetime achievement award by the International Foundation for Africa Innovation, for his work in mobile innovation.\n\nAlso in August 2013, Bright Simons, was named on a list by MIT Technology Review of the World's 35 Top Innovators Under 35.\n\nIn 2016, Fastcompany placed mPedigree at number five (5) of the most innovative companies from Africa. \n\nIn 2016, Fortune Magazine ranked mPedigree at number 34 on its Change the World List, ahead of other well known companies such as Tesla and LinkedIn. \n"}
{"id": "56106288", "url": "https://en.wikipedia.org/wiki?curid=56106288", "title": "National Prize for Medicine", "text": "National Prize for Medicine\n\nThe National Prize for Medicine () was created in 2001 by the , the Association of Medical Faculties, the Association of Medical Scientific Societies, and the .\n\nIt is given to recognize the work of those doctors who have excelled among their peers in the area of clinical or public health and, in addition, have had a prominent role in teaching, academic administration, or research.\n\nThe prize consists of a diploma, a commemorative medal, and an amount of money that is contributed by the medical community.\n\nIt is awarded every two years.\n\n\n"}
{"id": "4780068", "url": "https://en.wikipedia.org/wiki?curid=4780068", "title": "Norman Riches", "text": "Norman Riches\n\nNorman Vaughan Hurry Riches (1883-1975) was a Welsh cricketer who played first-class cricket for Glamorgan from 1921 to 1934. \n\nThe son of C. H. Riches of Tredegarville, Cardiff, Norman Riches joined Abingdon School from Chard School in 1900. He was a first team member of the football and athletics team and played cricket for the Old Abingdonians.\n\nRiches worked as a dentist. He played cricket as an amateur for Glamorgan from 1901, initially as wicket keeper. His first major innings was against Monmouth at Swansea when he scored 183 in 1904. Apart from two matches for Welsh teams against the touring South Africans in 1912, he played no first-class cricket until Glamorgan's initial season in the County Championship in 1921, when he captained the team, turning 38 during the season. His obituary in \"Wisden\" expressed the opinion that he had \"the natural ability, the technique and the temperament\" to have become a Test player, but had lacked the opportunity.\n\nRiches continued to represent Glamorgan until 1934, and was captain again in 1929. He scored nine centuries in his career and in 1921 was the first Glamorgan batsman to pass a thousand runs in first-class cricket. He was vice-chairman, trustee and patron of the club from 1934 to 1950. Riches also played for Cardiff Cricket Club from 1934 to 1947.\n\nIn 1923 he played for the Gentlemen in the Gentlemen v Players match on 4 July. In 1926 he played for Wales against Ireland in Belfast, scoring 239 not out. As of late 2018 this remains the highest first-class score made in Ireland.\n\n\n"}
{"id": "33115969", "url": "https://en.wikipedia.org/wiki?curid=33115969", "title": "Nursing in Japan", "text": "Nursing in Japan\n\nNursing in Japan did not develop until the end of the nineteenth century. Initially introduced only in Tokyo in the late 1860s, small schools utilizing Western models were being opened by the late 1880s. In response to disaster relief, the Japanese Red Cross became an integral part of nursing development. By 1915, nurse registration had been established and public health nurses began working throughout the country. Nursing universities were established in the twentieth century and regulations were passed to develop standards for training and public health.\n\nCare of the sick in Japan was primarily done in the home by untrained family members until the end of the nineteenth century. Nursing first emerged in Tokyo in 1869, when the Tokyo Imperial University opened a small school for nurses. Little training was given in how to care for the sick, but students were instructed in hygiene and sanitary conditions for hospitals. In 1883, foreign missionaries opened two small nursing schools, based on Western models to give theoretical training to nurses. Two years later, a doctor opened a school in Kyoto and the Canadian Episcopal Mission began a school in Kobe. The Kyoto school was begun by Linda Richards, who was sent by the American Board of Missions to organize a training school at the Doshisha Hospital. The first class of four nurses graduated in 1888.\n\nIn 1887, the Japanese Red Cross (JRC) was founded and by 1890 had begun teaching and recruiting nurses for training. Though their nurses were still studying when the Sino Japanese War broke out, the JRC decided to send trainees to help with relief efforts. From 1894, JRC Nurses served in numerous conflicts helping with the wounded, including in the Boxer Rebellion (1900), the Russo-Japanese War (1904), World War I and the Japanese intervention in Siberia (1919). The JRC Nurses' training program required three years of study with the first year dedicated to theory, including courses on anatomy, bandaging, disinfection, hygiene, instruments, women’s health, obstetrics, as well as basic assistance of surgery and health treatment and the latter two years involved in practical training. Completion of the course required a final examination before diplomas were given and additional six months of training could qualify nurse candidates as head nurses. Because the JRC was under government control, their hospitals spread to all the major cities and a uniformity of training made the organization a leader in nursing development.\n\nNursing was not an established part of Japan's health care system until 1899 with the adoption of the \"Midwives Ordinance\". The \"Registered Nurse Ordinance\" was passed in 1915 which established a legal substantiation to registered nurses all over Japan. In the 1920s, the government began investigating the need to increase the educational requirements for nurses. Up to that time, job training was the only requirement and there was no prerequisite for a high school education to enter training at most hospitals. In 1927, St. Luke's International Hospital became the first college of nursing in the country and based its training program on the one offered at Yale University in New Haven, Connecticut. The program required students to be graduates of a Government High School, complete three years of standard training, and a fourth year of specialization.\n\nThe first nursing association in Japan was founded in 1929 by Take Hagiwara as the Nursing Association of the Japanese Empire. By 1933, the organization had around 1500 members from throughout Japan and joined the International Council of Nurses (ICN). During World War II the \"Public Health Nurse Ordinance\" (1941) and \"National Medical Care Act\" (1942) were passed and re-affirmed in 1948 with passage of the \"Public Health Nurses, Midwives and Nurses Act\". It established educational requirements, standards and licensure. In 1946, the Japanese Nursing Association was created, merging the Japanese Midwife Society, Japanese Public Health Nurses Association and the Nursing Association of the Japanese Empire into one umbrella organization.\n\nThere has been a continued effort to improve nursing in Japan. In 1952 the first university courses on nursing were introduced, 1957 requirements for assistant nurses were introduced, in 1965 regulations were passed for nurses working night-shifts, and throughout the 1990s several legislative acts expanded training and employment protections for nurses. In 1992, the \"Law for Securing Nursing Personnel\" created new university programs to address the aging population of Japan, establish a critical scientifically based approach to training rather than a pragmatic one, unify training and licensing requirements and overall improve the image of the field. In 2009, the \"Public Health Nurses, Midwives and Nurses Act\" was amended allowing those who had graduated from a 4-year college to be eligible to take the nursing examination, revising course requirements, and making newly graduated training mandatory for nursing personnel.\n\nJapan recognizes four types of nurses: Public Health Nurses, Midwives, Registered Nurses and Assistant Nurses.\n\nPublic health nursing is designed to help the public and is also driven by the public's needs. The goals of public health nurses are to monitor the spread of disease, keep vigilant watch for environmental hazards, educate the community on how to care for and treat themselves, and train for community disasters.\n\nMidwife nurses are independent of any organization. A midwife takes care of a pregnant woman during labor and postpartum. They assist the mother with breastfeeding, caring for the child, and related tasks.\n\nIndividuals who are assistant nurses follow orders from a registered nurse. They report back to the licensed nurse about a patient's condition. Assistant nurses are always supervised by a dentist, licensed registered nurse or physician.\n\nRequirements of nursing education in Japan are that candidates have completed twelve years of basic academic study and then three years of basic nursing education. Public health nurses and midwives require a minimum of one additional year of specialized study. After completing their studies, students must pass the national licensing examination and obtain a license from the Minister of Health, Labour, and Welfare in the case of nurses, or from the prefectural governor, for nurse assistants. Foreign nurses who wish to work in Japan are required to pass the licensing examination and obtain a Japanese nursing license.\n\nTo become a registered nurse in Japan, candidates must first obtain a high school degree and then either enroll in a nursing university for four years and earn a Bachelor of Science in Nursing (BSN); attend a junior nursing college for three years, earning an Associate of Science in Nursing (ASN); or study at a nursing training school for three years and obtain a diploma. The Ministry of Education, Culture, Sports, Science and Technology (MEXT) regulates the curriculum of the colleges and universities, while the Ministry of Health, Labour, and Welfare's Division of Nursing regulates nursing diploma programs. The two Ministries jointly establish core curriculum, though individual schools may vary on additional requirements. The basic course study must include courses on: anatomy, adult health, basic nursing, children’s health, disease and recovery studies, gerontological nursing, health support and social systems, home care nursing theory, maternity, mental health, nursing integration, psychiatric nursing, scientific thinking and the understanding of humans, life and society. Both theoretical study and clinical practice are required.\n\nUpon completion of studies a national examination administered by the Division of Nursing of the Ministry of Health, Labour, and Welfare is required. Licenses are issued for the nurse's lifetime and require no renewal or continuing education. For nurses who wish to become Public Health Nurses or Midwives, post-graduate studies are required. Colleges, junior colleges, nurse training schools or universities offer courses for the additional training which must be for a minimum of one year. Additionally master's degrees are offered at some universities. As of 2010, all nurses are required to complete postgraduate clinical training.\n\nThe certification of nurse specialists is not legally specified in Japan, though the practice is widely accepted. The Japanese Nursing Association (JNA) certifies nurses in three categories: Certified Nurse, Certified Nurse Administrator and Certified Nurse Specialist. All three levels of certification require that the nurse pass the national nursing examination as well as a certification test administered by the JNA. Certifications must be renewed every five years.\n\nCertified Nurses (CN) are required to take six months training in cancer and chemotherapy nursing, emergency care, hospice care, intensive care nursing, wound, ostomy, and continence nursing, and pain management nursing, after completion of their basic nursing licensing. As of July 2015, nearly 16,000 CNs were working in Japan in various specialties including cancer care, chronic care, dementia nursing, diabetes nursing, dialysis nursing, emergency care, heart care, infection control, infertility nursing, neonatal care, rehabilitative care, respiratory care, and other specialized fields.\n\nCertified Nurse Administrators (CNA) are required to complete a master’s program in management at a graduate school or university or a certification from a nurses training education program.\n\nCertified Nurse Specialists (CNS) are required to complete a master’s program for specialized fields, including Cancer Nursing, Child Health Nursing, Chronic Care Nursing, Community Health Nursing, Critical Care Nursing, Family Health Nursing, Gerontological Nursing, Home Care Nursing, Infection Control Nursing, Psychiatric/Mental Health Nursing or Women's Health Nursing, after obtaining their national licensing. In addition, certification requires a minimum of five years clinical experience.\n\nOther professional groups also provide certification for clinical specialties such as community health, diabetes, disaster nursing, emergency nursing, intractable illness, nursing administration, and psychiatric nursing. These organizations predominantly emerged in the 1990s. They include the Japan Visiting Nursing Foundation, which was founded in 1994 to create and improve home care services for the elderly; the Japanese Family Nursing Society, which emerged in 1994 to focus on the education, practices and development of theory for family nurse practitioners; the Japanese Nursing Diagnosis Association and the Japan Society of Nursing Diagnosis focus on nursing diagnosis. Additional professional organizations include the Federation of Nursing Colleges and Association of Nurses, the International Nursing Foundation of Japan, the Japanese Midwives Association, and the Japanese Society of Nursing Research.\n\nUntil 2015, nurses in Japan were required to work under the guidance of physicians. They were not allowed to diagnose conditions or prescribe medications without a doctor's directive. Socio-cultural custom giving doctors higher perceived social status and nurses the role of caretaker, led to nurses' lack of autonomy. In October 2015, the Act on Public Health Nurses, Midwives and Nurses was amended to allow nurses who had received specific training to act as nurse practitioners and intervene in certain situations without awaiting a physician's decision.\n\nThe training curricula requires completion of 315 study hours of common subjects and 15 to 72 study hours of subjects for specified categories of medicine. Participants must attend both lectures and participate in practical applications. Upon completion of the coursework, applicants must receive a certificate of completion. They may then perform specific medical interventions based upon those described in procedure manuals prepared by physicians.\n\nThere is currently a shortage of nurses in Japan, in part due to the expanding population of elderly. Other reasons for the deficit in nursing applicants are poor working conditions, an increase in assigned workloads, the low social status of nurses, and the cultural idea that married women quit their jobs for family responsibilities. On average, Japanese nurses will make around 280,000 yen a month. Until 2000, nurses made up about 4.5% of the women's work force in Japan with almost two-thirds having nursing diplomas and only one percent having a BSN degree. The majority of nurses were female with only around three percent of the field being male. The largest segment of nurses are in their 30s and 40s with the average age being 41 in 2016 and hospitals are the major employer (61%) of nursing staff, followed by private clinics (21%).\n\nAfter 1992, Nurse Centers were created in each prefecture by the \"Act on Assurance of Work Forces of Nurses and Other Medical Experts\". These Centers provide placement, job training and recertification, if desired. They monitor nurses who are unemployed and support those who may wish to re-enter the work force. The most common reason for nurses to leave the work force is to raise a family, though heavy responsibilities, irregular shift work, long working hours, night shift duty, and poor working conditions/treatment accounted for part of the turnover. Government programs to improve working environments have been on-going since 2011.\n\nOne of the older unions that relates to nursing is the Japanese Federation of Medical Workers Union, which was created in 1957. It is a union that includes physicians as well as nurses. This organization was involved with the creation of the \"Nursing Human Resource Law\".\n\n\n"}
{"id": "49579233", "url": "https://en.wikipedia.org/wiki?curid=49579233", "title": "Omashram", "text": "Omashram\n\nOmashram is a old-age home located in Vijaya Bank Layout, Bilekahalli, Bangalore, India. The old-age home was founded by Mohan Pai in 2001, who worked as an adviser for various government projects. After his retirement he decided to establish this home.\n"}
{"id": "56561342", "url": "https://en.wikipedia.org/wiki?curid=56561342", "title": "Ontario Health Coalition", "text": "Ontario Health Coalition\n\nThe Ontario Health Coalition (OHC) is an organization in Ontario that advocates publicly funded health care. The OHC authors and releases research reports related to health care provision issues and opposing privatization of health care. The organization is made up of an advocacy network of over 400 grassroots community organizations representing virtually all areas of the province that lobbies for its goals through rallies and lobbying.\n\nThe Ontario Health Coalition supports preserving Canada's Medicare system and the overall goal and policy of universal public health care.\n\nIn January 2018, the OHC released a report that due to underfunding, hospitals are operating above their capacity resulting in higher infection rates and waiting times.\n\nIn 2017, the OHC conducted a series of 14 public hearings across the province in order to gather personal testimony regarding hospital care. Earlier in the year, the organization conducted a cross-province tour against for-profit medical clinics conducting MRIs and other diagnostic tests as well as cataract and other minor surgical procedures claiming that this is s form of privatization that undermines the public health care system.\n\nThe Ontario Health Coalition has more than 400 member organizations as well as a network of Local Health Coalitions and individual members.\n\nThe Ontario Health Coalition is affiliated to the Canadian Health Coalition and provides provincial coordination of community-based health coalitions.\n\n"}
{"id": "17422441", "url": "https://en.wikipedia.org/wiki?curid=17422441", "title": "Peter Pronovost", "text": "Peter Pronovost\n\nPeter J. Pronovost is an intensive care specialist physician at Johns Hopkins Hospital in Baltimore, Maryland.\nHe is a Professor at the Johns Hopkins School of Medicine in the Departments of Anesthesiology and Critical Care Medicine, and Surgery, Professor of Healthcare Management at the Carey Business School, Professor of Health Policy and Management at the Johns Hopkins Bloomberg School of Public Health, and is Medical Director for the Center for Innovation in Quality Patient Care.\n\nHe introduced an intensive care checklist protocol that during an 18-month period saved 1500 lives and $100 million in the State of Michigan. According to Atul Gawande in The New Yorker, Pronovost's \"work has already saved more lives than that of any laboratory scientist in the past decade\". In 2008 \"Time\" named Pronovost one of the 100 most influential people in the world. That same year, Pronovost was awarded a MacArthur Fellowship.\n\nPronovost's book \"Safe Patients, Smart Hospitals: How One Doctor's Checklist Can Help Us Change Health Care from the Inside Out\" was released in February 2010.\n\nPronovost grew up in Waterbury, Connecticut. His parents were an elementary school teacher and a math professor. He received his B.S. from Fairfield University, M.D. from the Johns Hopkins School of Medicine, and Ph.D. from the Johns Hopkins Bloomberg School of Public Health. In his Ph.D. thesis at Johns Hopkins Bloomberg School of Public Health, he documented that in intensive-care units in Maryland, an intensive care specialist on the staff reduced death rates by a third.\n\nIn 2003 he founded the Quality and Safety Research Group. He has published over 200 articles and chapters on patient safety and advises the World Health Organization on improving patient safety measurement through WHO's World Alliance for Patient Safety.\n\nHe started studying hospital-acquired infections in 2001, concluding that a simple 5 item check-list protocol would greatly reduce infections when inserting a central venous catheter;\n\nDoctors should: \n\nIn the Keystone Initiative, a 2003 study by a collection of Michigan hospitals and health organizations, the median rate of infections at a typical ICU dropped from 2.7 per 1,000 patients to zero after three months. The Keystone Initiative published its results in the December, 2006 \"New England Journal of Medicine\". In the first three months of the project, the infection rate in Michigan’s ICUs decreased by sixty-six per cent. In the Initiative’s first eighteen months, they estimated that 1500 lives and $100 million were saved. These results were sustained for almost four years.\n\nSeveral reasons may explain why a simple checklist protocol is not more widely adapted:\n\nAccording to Pronovost,\n\nIn 2013, Pronovost co-founded Doctella, a startup that provides surgical checklists for patients to improve patient engagement, patient safety, and lead to better health outcomes.\n\nAlso in 2013, Pronovost advocated for a system of alcohol and drug testing for doctors in a Journal of the American Medical Association article.\n\nHe has participated in an online course, or MOOC, from Johns Hopkins provided via Coursera.\n\nIn January 2018, he announced that he would be taking a position at United HealthCare. Shortly after taking the position he was promoted to Chief Medical Officer. Within weeks of taking this position, his departure from the position and the company was confirmed, although no reason was given.\n\nIn 2008, he was named in \"Time\" magazine's 100 most influential people in the world, and was also named a MacArthur Fellow. In 2011, Pronovost was recognized for his outstanding professional achievement and commitment to service with election to membership in the Institute of Medicine, one of the highest honors in the fields of health and medicine. On March 28, 2013, he was named a Gilman Scholar at Johns Hopkins University.\n\nPeter Pronovost has two children, Ethan and Emma Pronovost. His wife, Marlene, is a pediatrician at Johns Hopkins.\n\n\n"}
{"id": "40369975", "url": "https://en.wikipedia.org/wiki?curid=40369975", "title": "Philippine Physician Licensure Examination", "text": "Philippine Physician Licensure Examination\n\nThe Philippine Physician Licensure Examination, also called Philippine Medical Boards, is the professional licensure examination for incoming physicians in the Philippines, exclusively administered twice a year by the Professional Regulation Commission.\n\nAccording to Article III, Section 9 of Republic Act 2382, also known as the \"Medical Act of 1959\", a board examinee must meet the following qualifications:\n\nAfter graduating from medical school, candidates who meet all the admission requirements usually enroll in special review classes held from May to July in medical schools, colleges, universities, and review centers.\n\nProgram schedule, content, and delivery differs from one review program to another. In these programs, lecturers, called medical board reviewers, are usually full-time professors and part-time professorial lecturers in medical schools and universities.\n\nThe review center with the highest number of enrollees is Topnotch Medical Board Prep. Other review centers in the country include Cracking D' Boards, Medprime and Brains Medical Boards Review Center. Only Cracking D' Boards holds review classes both in Cebu and Manila, with Medprime in Baguio City.\n\nThe Ateneo School of Medicine and Public Health, Ateneo de Zamboanga University, De La Salle University College of Medicine, Fatima College of Medicine, Pamantasan ng Lungsod ng Maynila, University of Santo Tomas, University of the East Ramon Magsaysay Memorial Medical Center, and University of the Philippines offer review classes for their respective graduates.\n\nDuring the entirety of the examination, the following topics are included, pursuant to Section 6:\n\n\nThe twelve subjects are separately graded, with each subject contributing 8.3% to the overall grade. The passing average is 75%, with no grade falling below 50% in any subject. The passing average is obtained using the Mean Passing Level of the entire batch of examinees, which is done using the Nedelsky Method, wherein an examinee's raw scores are transmuted based on the current Mean Passing Level.\n\n"}
{"id": "48676301", "url": "https://en.wikipedia.org/wiki?curid=48676301", "title": "Population informatics", "text": "Population informatics\n\nThe field of population informatics is the systematic study of populations via secondary analysis of massive data collections (termed \"big data\") about people. Scientists in the field refer to this massive data collection as the social genome, denoting the collective digital footprint of our society. Population informatics applies data science to social genome data to answer fundamental questions about human society and population health much like bioinformatics applies data science to human genome data to answer questions about individual health. It is an emerging research area at the intersection of SBEH (Social, Behavioral, Economic, & Health) sciences, computer science, and statistics in which quantitative methods and computational tools are used to answer fundamental questions about our society.\n\nThe term was first used in August 2012 when the Population Informatics Research Group was founded at the University of North Carolina at Chapel Hill. The term was first defined in a peer reviewed article in 2013 and further elaborated on in another article in 2014. The first Workshop on Population Informatics for Big Data was held at the ACM SIGKDD conference in Sydney, Australia, in August 2015.\n\nTo study social, behavioral, economic, and health sciences using the massive data collections, aka social genome data, about people. The primary goal of population informatics is to increase the understanding of social processes by developing and applying computationally intensive techniques to the social genome data.\n\nSome of the important sub-disciplines are :\n\nRecord Linkage, the task of finding records in a dataset that refer to the same entity across different data sources, is a major activity in the population informatics field because most of the digital traces about people are fragmented in many heterogeneous databases that need to be linked before analysis can be done.\n\nOnce relevant datasets are linked, the next task is usually to develop valid meaningful measures to answer the research question. Often developing measures involves iterating between inductive and deductive approaches with the data and research question until usable measures are developed because the data were collected for other purposes with no intended use to answer the question at hand. Developing meaningful and useful measures from existing data is a major challenge in many research projects. In computation fields, these measures are often called features.\n\nFinally, with the datasets linked and required measures developed, the analytic dataset is ready for analysis. Common analysis methods include traditional hypothesis driven research as well more inductive approaches such as data science and predictive analytics.\n\nComputational social science refers to the academic sub-disciplines concerned with computational approaches to the social sciences. This means that computers are used to model, simulate, and analyze social phenomena. Fields include computational economics and computational sociology. The seminal article on computational social science is by Lazer et al. 2009 which was a summary of a workshop held at Harvard with the same title. However, the article does not define the term computational social science precisely.\n\nIn general, computational social science is a broader field and encompasses population informatics. Besides population informatics, it also includes complex simulations of social phenomena. Often complex simulation models use results from population informatics to configure with real world parameters.\n\nData Science for Social Good (DSSG) is another similar field coming about. But again, DSSG is a bigger field applying data science to any social problem that includes study of human populations but also many problems that do not use any data about people.\n\nPopulation reconstruction is the multi-disciplinary field to reconstruct specific (historical) populations by linking data from diverse sources, leading to rich novel resources for study by social scientists.\n\nThe first Workshop on Population Informatics for Big Data was held at the ACM SIGKDD conference in Sydney, Australia, in 2015. The workshop brought together computer science researchers, as well as public health practitioners and researchers. This Wikipedia page started at the workshop.\n\nThe International Population Data Linkage Network (IPDLN) facilitates communication between centres that specialize in data linkage and users of the linked data. The producers and users alike are committed to the systematic application of data linkage to produce community benefit in the population and health-related domains.\n\nThree major challenges specific to population informatics are: \n\n\n"}
{"id": "9027784", "url": "https://en.wikipedia.org/wiki?curid=9027784", "title": "Prioritization", "text": "Prioritization\n\nPrioritization is the activity that arranges items or activities in order of importance relative to each other.\n\nIn the context of medical evaluation it is the establishment of the importance or the urgency of actions that are necessary to preserve the welfare of client or patient. In the clinical context, establishing priorities aids in the rationale and justification for the use of limited resources. Priority setting is influenced by time, money, and expertise. A risk priority number assessment is one way to establish priorities that may be difficult to establish in a health care setting.\n\nSoftware has been designed to assist professionals in establishing priorities in a specific business setting.\n\n"}
{"id": "32053787", "url": "https://en.wikipedia.org/wiki?curid=32053787", "title": "Project Happiness", "text": "Project Happiness\n\nProject Happiness is a 2011 documentary film created, narrated, and produced by Randy Taran and directed by John Sorenson. The documentary follows students on three continents as they search for the meaning of \"lasting happiness\".\n\n\"Project Happiness\" started as personal story. The film came into being after creator Randy Taran discovered that her daughter was stressed, saying \"I want to be happy, I just don't know how\". Randy, after speaking with experts, discovered that this situation was more widespread than she had known.\n\nDetermined to find a way for her and other parents to speak to their children about happiness, she decided to make a film to educate and initiate the conversation for youth, families and the communities to which they belong.\n\nThe film connects students from three continents – North America, Africa and Asia – and throughout their senior year, they students discuss amongst themselves with several notable individuals one central question: \"What brings lasting happiness?\" During the filming, the students involved conducted interviews with scientists, celebrities, and world political and spiritual leaders including Richard Gere, Dr. Richard Davidson, Adam Yauch, the late Nirmala Deshpande, Dr. A.P.J Abdul Kalam, George Lucas, and Tenzin Gyatso, the 14th Dalai Lama.\n\nThis film had a sneak preview at the University of Southern California and the Daily Trojan said of the film \"Project Happiness is a journey applicable not only to graduating high school students, but people of all ages.\" The film has been chosen as an Official Selection at the Seoul International Youth Film Festival in Seoul, South Korea as well as the WorldKids International Film Festival in Mumbai, India. Proceeds from the film go to the Project Happiness nonprofit organization.\n\n\n"}
{"id": "6191938", "url": "https://en.wikipedia.org/wiki?curid=6191938", "title": "Raymond Carhart", "text": "Raymond Carhart\n\nRaymond T Carhart was a Speech/Language Pathologist. As a founder and pioneer of the science, he is frequently referred to as the \"Father of Audiology.\"\nCarhart was born on March 28, 1912, in Mexico City. He studied at Dakota Wesleyan University (BA in Speech and Psychology, 1932), and at Northwestern University (MA, 1934, and PhD, 1936, in Speech Pathology, Experimental Phonetics and Psychology).\nHe remained at Northwestern until 1944, first as Instructor in Speech Re-education and later as Assistant (1940) and Associate (1943) Professor. He joined the US Army Medical Administrative Corps in 1944, working in Butler, Pennsylvania until 1946. He returned to Northwestern in 1947, where he remained until his death in 1975.\n\n\"Carhart notch effect\" is a decrease in the bone-conduction hearing at the 2000 Hz region of patients with otosclerosis first reported by and therefore named after Raymond Carhart.\n\n"}
{"id": "32028", "url": "https://en.wikipedia.org/wiki?curid=32028", "title": "Standard of living in the United States", "text": "Standard of living in the United States\n\nThe standard of living in the United States is high by the standards that most economists use, and for many decades throughout the 20th century, the United States was recognized as having the highest standard of living in the world. Per capita income is high but also less evenly distributed than in most other developed countries; as a result, the United States fares particularly well in measures of average material well being that do not place weight on equality aspects.\n\nIn the United Nations Human Development Index, which measures health, education, and per capita income levels, the United States is relatively high, currently ranking 8th. However, the Human Development Index is not considered a measure of living standards, but a measure of \"potential\" living standards were there no inequality: rather, the inequality-adjusted Human Development Index is considered the actual level of human development, taking inequality into account. On the inequality-adjusted HDI, the United States ranked 27th in 2014, tied with Poland.\n\nIn 2013, the \"Economist Intelligence Unit's\" Where-to-be-born Index, which takes into account material well-being as measured by GDP per capita, life expectancy, political stability, the quality of family life based on divorce rates, community life, crime and terrorism rates, gender equality, the quality of governance, climate, and unemployment rates, ranked the United States at 16th place, tied with Germany.\n\nThe OECD Better Life Index, which measures quality of life according to 11 factors, ranks the United States as 7th among 34 OECD countries.\n\nThe homeownership rate is relatively high compared to other post-industrial nations. In 2005, 69% of Americans resided in their own homes, roughly the same percentage as in the United Kingdom, Belgium, Israel and Canada. In 2007, Americans enjoyed more cars and radios per capita than any other nation and more televisions and personal computers per capita than any other nation with more than 200 million people.\n\nIn colonial America, the standard of living was high by 18th century standards. Americans could choose their diet from a diverse range of plants and animals from Europe and the Western Hemisphere, and this, combined with favorable weather conditions, ensured that Americans never had to deal with harvest failures. There was little exposure to epidemic diseases, and low wealth inequality, ensuring that even the poor were well-fed.\n\nHistorians have used height to measure living standards during this time as average adult heights can point to a population's net nutrition - the amount of nutrition people grew up with as compared to biological stress which can cause lower heights in adulthood, stemming from things like food deprivation, hard work, and disease. According to military records of American and European men, Americans were on average two to three inches taller than Europeans.\n\nAverage heights showed little change until the second quarter of the 19th century, with the Industrial Revolution. The growth of canals, steamboats, and railways, as well as the public school system, mass immigration, and urbanization, increased exposure to diseases. Food prices rose in the 1830s, and industrialization brought along with it growing wealth inequality and business depressions that further worsened the situations of the poor. As a result, average stature and life expectancy declined, and only rebounded from 1910 to 1950, as incomes rose, urban conditions became less crowded, and public health measures were put in place.\n\nFrom the 1930s up until 1980, the average American after-tax income adjusted for inflation tripled, which translated into higher living standards for the American population. Between 1949 and 1969, real median family income grew by 99.3%. From 1946 to 1978, the standard of living for the average family more than doubled. Average family income (in real terms) more than doubled from 1945 up until the 1970s, while unemployment steadily fell until it reached 4% in the 1960s. Between 1949-50 and 1965–66, median family income (in constant 2009 dollars) rose from $25,814 to $43,614, and from 1947 to 1960, consumer spending rose by a full 60%, and for the first time, as noted by Mary P. Ryan, \"the majority of Americans would enjoy something called discretionary income, earnings that were secure and substantial enough to permit them to enter sectors of the marketplace that were once reserved for the affluent.\" In 1960, Americans were, on average, the richest people in the world by a massive margin.\n\nDuring the 1960s, median family incomes increased by over 33%, while per capita expenditures on recreation and meals grew by over 40%. From 1959 to 1969, median family income (in 1984 dollars) increased from $19,300 to $26,700. By 1969, 79.6% of all households owned at least one car, 82.6% owned a refrigerator or freezer, 79% owned a black and white television set, 31.9% owned a color television set, and 70% owned a washing machine. Leisure time also increased. By 1970, it was estimated that the average workingman in America had 140 days off work each year. US work hours fell by 10.7% between 1950 and 1979, though the decline was still around half that of Western Europe.\n\nIn 1980, the American standard of living was the highest among the industrial countries, according to the OECD. Out of the 85 million households in the United States, 64% owned their own living quarters, 55% had at least two TV sets, and 51% had more than one vehicle. In terms of possession of telephones, TV sets, school enrollments, animal protein in diets, and energy consumption, the United States was far ahead of other industrialized countries. Wealthy and middle class and a majority of poor Americans had higher after-tax incomes than their counterparts almost anywhere else in the world. By 1985, the US per capita income was $11,727, one of the highest among industrialized countries. By the mid-1980s, 98% of all households had a telephone service, 77% a washing machine, 45% a freezer, and 43% a dishwasher.\n\nIn the 1990s, the average American standard of living was regarded as amongst the highest in the world, and middle class and poor Americans were still, on average, richer than their counterparts in almost all other countries, though the gap with some European countries had noticeably narrowed.\n\nIn 2006, median income was $43,318 per household ($26,000 per household member) with 42% of households having two income earners. Meanwhile, the median income of the average American age 25+ was roughly $32,000 ($39,000 if only counting those employed full-time between the ages of 25 to 64) in 2005. According to the CIA the gini index which measures income inequality (the higher the less equal the income distribution) was clocked at 45.0 in 2005, compared to 32.0 in the European Union and 28.3 in Germany.\n\nThe US has... a per capita GDP [PPP] of $42,000... The [recent] onrush of technology largely explains the gradual development of a \"two-tier labor market\"... Since 1975, practically all the gains in household income have gone to the top 20% of households... The rise in GDP in 2004 and 2005 was undergirded by substantial gains in labor productivity... Long-term problems include inadequate investment in economic infrastructure, rapidly rising medical and pension costs of an aging population, sizable trade and budget deficits, and stagnation of family income in the lower economic groups.\n\nIn 2014, median wealth in the United States was $44,900, which put the United States in 19th place, behind many other developed countries. In 2015, median wealth in the United States was 55,775.\nThe United States has one of the widest rich-poor gaps of any high-income nation today, and that gap continues to grow. Some prominent economists have warned that the widening rich-poor gap in the U.S. population is a problem that could undermine and destabilize the country's economy and standard of living. In 2006, Alan Greenspan wrote that \"The income gap between the rich and the rest of the US population has become so wide, and is growing so fast, that it might eventually threaten the stability of democratic capitalism itself\". In 2013, George Friedman, the head of Stratfor, wrote that the middle class' standard of living was declining, and that \"If we move to a system where half of the country is either stagnant or losing ground while the other half is surging, the social fabric of the United States is at risk, and with it the massive global power the United States has accumulated.\"\n\nIn 2015 a report was done that showed that 71 percent of all workers in America made less than $50,000 in 2014. For a family of four to live a middle class lifestyle, it was estimated that they would need $50,000 a year. For workers that make less than that, their standard of living is lacking. \nSince 1971, the middle income was above 50% of the population in the U.S. In 2015, the middle class income consisted of 49.9% of the population. The middle class continues to shrink and standard of living continues to decrease.\n\nStandard of living in the United States varies considerably with socio-economic status. The table below gives a summarization of prominent academic theories on the socio-economic stratification of the United States:\n\n\nGeneral:\n"}
{"id": "54021693", "url": "https://en.wikipedia.org/wiki?curid=54021693", "title": "Stromagen", "text": "Stromagen\n\nStromagen is a product that is made of stem cells taken from a patient’s bone marrow and grown in the laboratory. After a patient’s bone marrow is destroyed by treatment with whole body irradiation or chemotherapy, these cells are injected back into the patient to help rebuild bone marrow. Stromagen has been studied in the prevention of graft-versus-host disease during stem cell transplant in patients receiving treatment for cancer. Stromagen is used in cellular therapy. Also called autologous expanded mesenchymal stem cells OTI-010. Peripheral stem cell transplantation may allow doctors to give higher doses of chemotherapy and kill more tumor cells. It is not yet known whether Stromagen improves the success of stem cell transplantation in women with breast cancer.\n"}
{"id": "4693638", "url": "https://en.wikipedia.org/wiki?curid=4693638", "title": "Testicular microlithiasis", "text": "Testicular microlithiasis\n\nTesticular microlithiasis is an unusual condition diagnosed on testicular ultrasound. It is found in between 1.5 to 5% of normal males, and may be found in up to 20% of individuals with subfertility. It is an asymptomatic, non-progressive disease. The cause is unknown, but this condition has been associated with testicular cancer in a small group of individuals, cryptorchidism, mumps, infertility and intraepithelial germ cell neoplasia. Classic testicular microlithiasis is defined as five or more echogenic foci per view in either or both testes, and limited testicular microlithiasis defined as one or more echogenic foci that do not satisfy the criteria for classic testicular microlithiasis. In 80% of cases, both testicles are affected.\n\nTesticular microlithiasis is not associated with risk of testicular cancer in asymptomatic individuals with no risk factors for testicular germ cell tumor. However, a large meta-analysis has shown that in individuals with associated risk factors for testicular germ cell tumor, the increase in risk of concurrent diagnosis of testicular germ cell tumor, or testicular carcinoma-in-situ upon biopsy is approximately eight to ten-fold.\n\nThere is extensive controversy over whether testicular microlithiasis in individuals with testicular germ cell tumor, or risk factors for such, should undergo testicular biopsy to exclude the presence of testicular carcinoma-in-situ, also known as intratubular germ cell neoplasia of unclassified type. Additionally, whether the presence of testicular microlithiasis should influence decision for adjuvant chemotherapy or surveillance in individuals with testicular germ cell tumor remains unclear. A recent review in Nature Reviews Urology has comprehensively evaluated these topics.\n\nThere is no cure or treatment for testicular microlithiasis, however, patients may be monitored via ultrasound to make sure that other conditions do not develop. Emphasis on testicular examination is the recommended follow up for asymptomatic men incidentally identified with testicular microlithiasis. For men with risk factors for testicular germ cell tumor such as subfertility however, individualized discussion with their urologists is necessary.\n\n"}
{"id": "39848931", "url": "https://en.wikipedia.org/wiki?curid=39848931", "title": "Theiler's disease", "text": "Theiler's disease\n\nTheiler's disease, also known as idiopathic acute hepatitis disease (IAHD), serum-associated hepatitis, serum sickness, and postvaccinal hepatitis, is a viral hepatitis that affects horses. It is one of the most common cause of acute hepatitis and liver failure in the horse.\n\nThere is a rapid onset of clinical signs over the period of 2–7 days, beginning with anorexia, lethargy, and hyperbilirubinemia (icterus and discolored urine). Signs of hepatic encephalopathy (ataxia, blindness, aggression, and coma) and fever can also occur. Other signs include photodermatitis, hemorrhagic diathesis, dependent edema, and colic. The reason for colic is unknown, but is thought to be due to rapid decrease in the size of the liver, and the increased risk of gastric impaction. Rarely, weight loss can occur.\n\nThe most current theory is a result of a recent study that suggests it is caused by a pegivirus, referred to as Theiler's disease-associated virus (TDAV). Eight horses that had received prophylactic botulinum antitoxin and developed subsequent signs of Theiler's disease were subjected to a test for a viral infection based on RNA sequencing techniques. When TDAV was found, the original source of virus (the antitoxin) was injected into 4 additional healthy horses, with one displaying increased liver enzymes and all 4 having increased levels of TDAV, showing that the virus can be spread by inoculation. Measuring levels of virus in the originally infected horses has shown that the disease can become chronic, with some horses displaying low virus levels one year after initial infection. All horses that were initially negative remained so, suggesting that the virus is poorly transmitted horizontally.\n\nHowever, not all horses that tested positive for this virus showed clinical signs, so additional causative factors such as immune mediated hypersensitivity or co-infections with other agents may be required to produce disease.\n\nAt present this can only be made definitively by liver biopsy or post mortem examination. Given the isolation of a causative virus it should soon be possible to diagnose this by serology, polymerase chain reaction or viral culture. On necropsy, the liver will be small, flaccid, and \"dish-rag\" in appearance. It has a mottled and bile stained surface. On microscopy there is marked centrilobular to midzonal hepatocellular necrosis and a mild to moderate mononuclear infiltrate. Mild to moderate bile duct proliferation may also be present. On radiology, the liver may be shrunken and difficult to visualize on ultrasound. Ascites may be present.\n\nThe most characteristic feature are elevated levels of gamma glutamyl transferase (100–300 IU/L), aspartate transaminase (>1000 IU/L) and sorbitol dehydrogenase, with AST levels > 4000 IU/L indicating a poor prognosis. High levels of unconjugated and total bilirubin, and serum bile acids, can be seen. Moderate to severe acidosis, leukocytosis, polycythaemia, increased creatine kinase and hyperammonemia may be present, and hemolysis can occur at the end stage. The prothrombin time (PT) and partial thromboplastin time (PTT) is often prolonged. Subclinical horses may only show elevated liver enzymes without any other clinical signs. Horses are rarely hypoglycemic, but blood glucose monitoring is ideal to indicate which horses may be benefited by glucose treatment.\n\nThis is quite extensive and includes\n\n\nThere is currently no specific therapy. Intravenous fluids and treatment of the hepatic encephalopathy may help. Increasing dietary levels of branched chain amino acids and feeding low protein diets can help signs of hepatic encephalopathy, which is often accomplished by feeding small amounts of grain and/or beet pulp, and removing high-protein feedstuffs such as alfalfa hay. Grazing on non-legume grass may be acceptable if it is late summer or fall, although the horse should only be permitted to eat in the evening so as to avoid photosensitization. Due to the risk of gastric impaction, stomach size should be monitored.\n\nSedation is minimized and used only to control behavior that could lead to injury of the animal and to allow therapeutic procedures, and should preferably involve a sedative other than a benzodiazepine. Stressing the animal should be avoided if at all possible. Plasma transfusions may be needed if spontaneous bleeding occurs, to replace clotting factors. Antibiotics are sometimes prescribed to prevent bacterial translocation from the intestines. Antioxidants such as vitamin E, B-complex vitamins, and acetylcysteine may be given. High blood ammonia is often treated with oral neomycin, often in conjunction with lactulose, metronidazole and probiotics, to decrease production and absorption of ammonia from the gastrointestinal tract.\n\nThis depends on the degree of hepatocellular necrosis that has occurred. Decreases in the SDH and prothrombin time along with improvement in appetite are the best positive predictive indicators of recovery. GGT may remain elevated for weeks even if the horse is recovering. Horses that survive for greater than one week and that continue to eat usually recover. Cases with rapid progression of clinical signs, uncontrollable encephalopathy, haemorrhage or haemolysis have a poor prognosis. Horses that display clinical signs have a mortality rate of 50–90%.\n\nThis condition most commonly occurs after the administration of a horse origin biological agent such as equine-derived antiserum, and usually occurs 4–10 weeks after the event. Diseases that have been vaccinated against using equine-origin antiserum, resulting in subsequent Theiler's disease, include: African horse sickness, Eastern and Western Equine Encephalitis, \"Bacillus anthracis\", tetanus antitoxin, \"Clostridium perfringens\", \"Clostridium botulinum\", \"Streptococcus equi\" subspecies \"equi\", Equine influenza, Equine herpesvirus type 1, pregnant mare's serum, and plasma. Although it occurs sporadically, It appears to be spreadable within a premises, and there have been outbreaks occurring on farms involving multiple horses over several months. In the Northern hemisphere it is most common between August to November. It is seen almost exclusively in adult horses, and lactating broodmares given tetanus antitoxin post foaling may be more susceptible.\n\nThis disease was described in 1919 by Arnold Theiler, a South African veterinary surgeon, after vaccinating horses against African horse sickness using a live virus vaccine and equine antiserum. It was later described in the United States after vaccinating horses for Eastern Equine Encephalitis, again using live virus vaccines and equine-derived antiserum. It has since been reported throughout North America and Europe.\n"}
{"id": "12194086", "url": "https://en.wikipedia.org/wiki?curid=12194086", "title": "URGE: Unite for Reproductive &amp; Gender Equity", "text": "URGE: Unite for Reproductive &amp; Gender Equity\n\nURGE is a reproductive rights and justice non-profit organization in the United States based in Washington, D.C. It is youth-led, with a focus on pro-choice movements. URGE changed its name in July 2014 and was formerly called Choice USA. In a statement on its website, the group said the name change reflected work it was already doing outside of abortion rights advocacy. It described its mission as \"catalyzing the power of young people to fight for the ability of all people to build the families they want, access the healthcare they need, and to live and love in the way that's true to who they are.\"\n\nURGE was co-founded in 1992 by Gloria Steinem, an American feminist, activist, and writer. The organization's first projects analyzed the activities of the religious right in elections and promoted electoral participation by women, young people, and people of color.\n\nIn recent years, the organization has focused its efforts on mobilizing people under 30 in support of abortion rights, comprehensive sex education, and access to sexual health and wellness services.\n\n\n\n"}
{"id": "13911234", "url": "https://en.wikipedia.org/wiki?curid=13911234", "title": "Ultimate issue (law)", "text": "Ultimate issue (law)\n\nAn ultimate issue in criminal law is a legal issue at stake in the prosecution of a crime for which an expert witness is providing testimony.\n\nIf the issue is the defendant's mental state at the time of the offense, the ultimate issue would be the defendant's sanity or insanity during the commission of the crime. In the past, expert witnesses were allowed to give testimony on ultimate issues, such as the applicability of the insanity defense to a particular defendant. However, after the 1982 trial of John Hinckley, Jr., the federal rules of evidence were changed. Now in the United States, federal courts and some states have rules of evidence that specifically rule out legal conclusions drawn by expert witnesses in their testimony. However, a large amount of judicial discretion is allowed in how this rule is applied, resulting in an uneven application of rules across jurisdictions.\n\nThe Federal Rules do not say what falls within the definition of an \"ultimate issue.\" However, a long history of case law on the subject suggests that an expert witness runs afoul if he uses the same words (words with legal meaning) that will ultimately be presented to the jury. One court excluded a psychologist's evidence on the credibility of prosecution's witness on the grounds that it amounted to an \"ultimate opinion\", meaning this was an opinion that could only be properly reached by a jury.\n\nThe expert witness testimony is confined to giving an opinion on whether the defendant had a serious mental disorder at the time of the offense, and explaining the symptoms and characteristics of any diagnosis given, including other testimony regarding the defendant's mental status (\"mens Rea\") and motivation. The expert witness cannot make a statement addressing the issue of whether the legal test for insanity has been met. That is left to the judge and jury. The restriction of expert opinion on ultimate issues includes any testimony on the criminal elements, including testimony that would bear on the mental state of the defendant relevant to ultimate legal decisions to be decided by the triers of fact.\n\nThe Federal Rules of Evidence adopted in 1975 (and their state counterparts) expressly allowed expert testimony to include statements on ultimate issues if such statements will be helpful to the judge or jury. In 1984, Federal Rule of Evidence 704(b) was added following the trial of John Hinckley, Jr. for the attempted assassination of U.S. President Ronald Reagan. The changes were in part a result of the public backlash due to Hinckley's successful use of the insanity defense. These changes, in particular Rule 704(b), put limits on expert witness testimony. \n\nThe new rules of evidence restrict the testimony allowed on the ultimate issue. Rule 704(b) states that the mental health expert may testify to the defendant's mental disorder or defect and its symptoms, but may not offer a conclusion on an ultimate issue such as the sanity or insanity of the defendant. The expert witness must refrain from merely giving the jury a conclusion that pertains to the legal issues at hand and cannot testify to legal conclusions (ultimate issues), the rationale being that mental health professional are not attorneys. Judicial discretion remains in determining the limits of testimony as well, such that any testimony that \"wastes time' or is irrelevant can be barred. The rationale for this restriction was stated in the legislative history of the rule as the following:\n\nThe result is that large gray areas remain regarding exactly what testimony is allowed. For example, the Third Circuit Court of Appeals in \"United States v. Rutland\" ruled that testimony from \"an extraordinarily qualified handwriting expert\" was admissible on the \"ultimate issue of authorship of key documents\".\n\nAn example of how this change in the rules of evidence can affect trial testimony is demonstrated in an analysis of the 1979 trial of Jeffrey R. MacDonald, a physician, for the murder of his wife and children, if his trial occurred today. In that trial, an expert testified in support of the defense hypothesis that someone else committed the murders. Expert testimony that the defendant had a \"personality configuration inconsistent with the outrageous and senseless murders of [his] family\" was not allowed under the rules of evidence in effect at the time because it was considered confusing and misleading. However, under Rule 704(b) this character testimony would not be barred since testimony regarding \"personality configuration\" is general psychological evidence unrelated to any ultimate issues such as intent or malice aforethought. Also, an expert witness would not be in violation of 704(b) in use today if he gave testimony regarding the defendant's positive behaviors, such as acting like a loving father and husband, which might create the impression that he was not capable of committing such a crime, but is an opinion unrelated to guilt.\n\nRules of evidence are meant to screen what evidence the jury may consider to prevent testimony that is mere opinion from infringing upon the territory of jury decision-making. Rule 704(b) reversed the trend toward permitting the testimony of experts on the ultimate issue. Since so much faith is placed in the jury system, limiting what a jury can consider narrows the jury's options. As in the past, lay witnesses may testify to facts only.\n\nThe result of rule 704(b) is to prevent expert witnesses such as psychologists and psychiatrists from testimony regarding how the defendant's mental state affected an element of the crime or an element of the defense. It has been ruled that 704(b) bans expert opinions on mental states affecting other elements, not only on questions of insanity, but also on questions on all mental states forming an element of a crime or defense such as premeditation in a murder case or specific intent and mens rea.\n\nThe position under English law is different from that in the United States as there is no rule preventing an expert from giving an opinion on the 'ultimate issue' in England and Wales. This has been confirmed by the English Courts in both criminal and civil cases.\n\n\n"}
{"id": "47103857", "url": "https://en.wikipedia.org/wiki?curid=47103857", "title": "Watercress Wildlife Site", "text": "Watercress Wildlife Site\n\nWatercress Wildlife Site is a Local Nature Reserve in St Albans, Hertfordshire, England. It is owned by St Albans City Council and managed by the Watercress Wildlife Association, a registered charity. The boundaries of the site are the Alban Way, the River Ver and the houses of Riverside Road.\n\nUntil 1972 the site was one of the many commercial watercress beds in the area. It was then used partly as allotments, with fly tipping in some areas. In 1991 the council leased the site to the Watercress Wildlife Association, which cleared the site to become a nature reserve and gradually took over the allotments.\n\nThe site has a wide variety of wildlife, including water rails, kingfishers, little grebes and muntjac deer. \n\nThere is access from the junction of Riverside Road and Cornwall Road. Facilities include a hide, seating area and information board.\n\nThe Herts and Middlesex Wildlife Trust has a reserve at Lemsford Springs, Lemsford, which is also a former watercress bed.\n"}
