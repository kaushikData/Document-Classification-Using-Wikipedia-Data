{"id": "1116617", "url": "https://en.wikipedia.org/wiki?curid=1116617", "title": "2020 Vision Initiative", "text": "2020 Vision Initiative\n\nThe 2020 Vision Initiative in an initiative of the International Food Policy Research Institute (IFPRI). IFPRI launched the 2020 Vision Initiative in 1993; the primary goal of the initiative is to reach sustainable food security for all by 2020. The Initiative also supports the goals set at the World Food Summit in 1996, to halve the number of chronically undernourished people on the Earth by the year 2015.\n\nThe 2020 Vision Initiative has two primary objectives:\n\n\nIn May 2014, the next 2020 conference will be held in Addis Ababa, Ethiopia on the topic: Building Resilience for Food and Nutrition Security\n\nSeveral international conferences have been held to date:\n\n"}
{"id": "19788381", "url": "https://en.wikipedia.org/wiki?curid=19788381", "title": "3D Indiana", "text": "3D Indiana\n\n3D Indiana is a commercial Educational software for teaching and research on the human anatomy. The name is an acronym for Three-Dimensional Interactive Digital Anatomy. This software is based on the principles of \"volumetric anatomy\" which uses three intersecting coordinate planes to locate the organs of the human body based on mathematical calculations. This is in contrast to the traditional method of describing the location of the organs in relation to one another. The Gall bladder is traditionally described thus: 'It is situated on the right side of the body closely in contact with the inferior surface of the liver, along the right edge of the quadrate lobe in a shallow fossa extending from the right edge of the porta hepatis to the inferior lobe of the liver'.\n\nThis patent-pending software was designed by the Kalister Foundation led by Jerome Kalister, an alumnus of TD Medical College, Alapuzha, Kerala, India. A team of about fifteen professionals of the Foundation worked for nearly three years to create the software. It was formally unveiled at TD Medical College by Jerome Kalister on 13 October 2008 before an audience of more than a thousand students and staff of various medical colleges in Kerala.\n\nAccording to its creators, 3D Indiana is a virtual human body and its use would be complementary to the conventional mode of anatomy studies. Eventually this software may replace the human cadavers in anatomical studies. Without any additional programming, a researcher could elicit normal body responses from this virtual body. This gives the package the potential as a tool for doing clinical trials of drugs and chemicals in it.\nEvery named structure in the body is digitally recreated in detail and deployed in their true anatomical positions in the body. By clicking on any part of the body using a computer mouse, the user can get the name of the part displayed and can zoom in, rotate or isolate the part for further details.\n\nThe 3D Indiana package has been already endorsed by the Anatomical society of India. The Kalister Foundation is in discussion with the National Rural Health Mission for its endorsement of 3D Indiana as an educational software suitable for application in medical colleges.\n\n\n"}
{"id": "6211939", "url": "https://en.wikipedia.org/wiki?curid=6211939", "title": "4-Chloro-o-toluidine", "text": "4-Chloro-o-toluidine\n\n4-Chloro-\"o\"-toluidine (4-COT, 4-chloro-2-methylaniline) is the organic compound with the formula CHCHCl(NH). It is a colorless solid. The compound is produced as an intermediate to the pesticide chlordimeform and a precursor to some azo dyes. Production has declined after it was shown to be highly carcinogenic.\n\nIt is produced by the chlorination reaction of N-aceyltoluidine followed by deprotection and separation from the 6-chloro isomer. Production of 4-chloro-\"o\"-toluidine began in Germany in 1924. In Switzerland, 4-COT and its salts were produced between 1956 and 1976. Production and distribution ceased in 1979 in the US and in 1986 in Germany.\n\nIn nature, 4-COT is found in plants and animals as a metabolic product of chlordimeform.\n\nIn chronic feeding studies (mice of both sexes), 4-COT induces hemangiosarcomas and hemangioendotheliomas.\n\n4-COT becomes covalently bound to DNA of rats and mice livers.\n\nInhalation or skin contact with 4-COT produces acute toxic effects, initially appearing as macroscopic or microscopic haematuria. Further symptoms include dysuria, reduced bladder capacity and pain the lower abdomen. Haemorrhagic cystitis is the main symptom of acute toxicity, with methaemoglobinaemia was observed in 50% of poisoning cases.\n\nNo urinary bladder cancer was found in two of the earlier epidemiological reports of workers exposed to 4-COT in Switzerland and in the USA.\n\nStasik \"et al.\" obtained similar results in their previous mortality study carried out on a cohort of 335 male employees exposed to 4-COT at plants in Frankfurt.\n\nA subcohort of 116 subjects in the 4-COT cohort, engaged in the synthesis of 4-COT at the old production plant with presumably higher level of exposure to this monocyclic arylamine, was separated from the Frankfurt cohort of 335 men, for further research.\n\nStasik then conducted a retrospective study of the incidence of bladder cancer among workers restricted to this subcohort. His investigation revealed eight subjects in whom bladder carcinomas were diagnosed between 1967 and 1985. Two of them had already died. The standardized incidence rate for bladder carcinomas in the 4-COT subcohort was 73 times higher than expected.\n\nHistologically, all tumor cases were urothelial carcinomas.\n\nThe Deutsche Forschungsgemeinschaft (German Research Council) defined 4-COT as a human carcinogen (III A1). Besides Germany, 4-COT is listed as a carcinogen in Finland and Switzerland.\n\nFurther in 1990 the International Agency for Research on Cancer (IARC) classified 4-COT as a probable human carcinogen (2A).\n\nBoth assessments were based on the results of the subcohort incidence study.\n\nAlso in China an increased incidence of bladder cancer among farm workers exposed to chlordimeform has been reported in 1990.\n\nIn 1992 Popp, Norpoth \"et al.\" found seven persons suffering from bladder cancer among 49 workers involved in the synthesis of chlordimeform from 4-COT in another German plant.\n\nTen years later Stasik carried out a follow-up study of the same 4-COT subcohort studied by him previously. His re-investigations revealed a cluster of four new cases of bladder tumors in this group. So the total evidence of bladder cancer in the 4-COT subcohort increased to 12 cases, which makes 10% of all members of this particular group.\n"}
{"id": "16219820", "url": "https://en.wikipedia.org/wiki?curid=16219820", "title": "Act to Prevent Pollution from Ships", "text": "Act to Prevent Pollution from Ships\n\nThe Act to Prevent Pollution from Ships (APPS, 33 U.S.C. §§1905-1915) is a United States law that implements the provisions of MARPOL and the annexes to which the United States is a party. The most recent U.S. action concerning MARPOL occurred in April 2006, when the U.S. Senate approved Annex VI, which regulates air pollution (Treaty Doc. 108-7, Exec. Rept. 109-13). Following that approval, in March 2007, the House of Representatives approved legislation to implement the standards in Annex VI (H.R. 802), through regulations to be promulgated by Environmental Protection Agency in consultation with the U.S. Coast Guard.\n\nAPPS applies to all U.S.-flagged ships anywhere in the world and to all foreign-flagged vessels operating in navigable waters of the United States or while at port under U.S. jurisdiction. The Coast Guard has primary responsibility to prescribe and enforce regulations necessary to implement APPS in these waters. The regulatory mechanism established in APPS to implement MARPOL is separate and distinct from the Clean Water Act and other federal environmental laws.\n\nThe H.R. 6665 legislation was passed by the 96th U.S. Congressional session and signed by the 39th President of the United States Jimmy Carter on October 21, 1980.\n\n\n\n"}
{"id": "58713754", "url": "https://en.wikipedia.org/wiki?curid=58713754", "title": "Anurag Chauhan", "text": "Anurag Chauhan\n\nAnurag Chauhan (born 1994) is an Indian social worker and founder of Humans For Humanity, a non-governmental organization (NGO) headquartered in Dehradun, India. He is founder-director of Dehradun Literature Festival. He is known for his work towards menstrual hygiene.\n\nHe was awarded the \"Karmavir Chakra Award\" by the United Nations for social work in the year 2016. In July 2016, he was conferred the \"Bharat Nirman Award\" 2016 by Union Minister Dr. Najma Heptulla for entrepreneurship and excellence in social work at the India International Centre, New Delhi.\nIn 2015, Anurag started a project called WASH - Women, Sanitation, Hygiene, that works towards educating women about menstrual hygiene, providing them sanitary napkins and giving training to them for making bio-degradable sanitary napkins. Chauhan founded his NGO \"Humans For Humanity\" in 2014, after reading an article written about deaths caused due to lack of menstruation hygiene. His cause received support from actress Twinkle Khanna. Anurag runs awareness programs in many villages of Uttarakhand, Delhi, Rajasthan, Uttar Pradesh, Maharashtra and Karnataka, reportedly by Dainik Jagaran. \nChauhan acted in a film, based on Clean India Campaign, an initiative by PM Narendra Modi. In 2016, he launched the Dehradun Literature Festival, an annual literary fest in Dehradun.\n\nIn September, 2017, Chauhan started an online compaign #TheDoorChallenge to promote ethnic Indian attire among youngsters.\n\n"}
{"id": "7396206", "url": "https://en.wikipedia.org/wiki?curid=7396206", "title": "Barangay Health Volunteers", "text": "Barangay Health Volunteers\n\nThe Barangay Health Volunteer, also known as Barangay Health Worker, is a category of health care providers in the Philippines. They undergo a basic training program under an accredited government or non-government organization, and render primary care services in the community. They provide services such as first aid, maternal, neonatal, and child health, and community-based interventions including immunization clinics for barangays (local neighborhoods).\n\nWith the decentralization of healthcare through the 1991 Local Government Code, the responsibility of delivery of primary health services were transferred from the central government to locally elected provincial, city, and municipal governments. Health services were previously funded and managed by the Department of Health but were transferred to the local governments after the devolution of the healthcare system.\n\nBarangay Health Workers are accredited to function as such by the local health board in accordance with the guidelines promulgated by the Philippines Department of Health, as defined in Sec. 3 of Republic Act No. 7883. This act, also known as \"Barangay Health Workers' Benefits and Incentives Act of 1995\", recognizes the need for primary health care and organizes health workers to promote health empowerment.\n\nBarangay health workers are a type of community health workers and act as health advocates and educators within their communities. They live in the communities they serve and receive about five weeks of training, ranging from administering immunizations, weighing children, birthing services, etc. They provide information, education and motivation services for primary health care, maternal and child health, child rights, family planning and nutrition.\n\nOn average, each Volunteer is expected to work with around 20 families in their community. However the scarcity of trained individuals has narrowed down the number of volunteers, especially in some remote areas, where now one or two volunteers service an entire barangay.\n\nResearch by Fe Espino at the Research Institute for Tropical Medicine on dengue prevention in the Philippines shows how community trust of the BHV is vital to the success of behavior change programs. In 2010, the number of dengue cases in the Philippines rose from 37,101 in 2006 to 118,868. Dengue fever is caused by a virus transmitted by mosquitoes which are born in still water. Due to water shortages, households are forced to store water throughout the year. Espino’s research team engaged the local Barangay Health Workers (BHWs) to introduce a household water container management system to control dengue in 2 communities in \"Masagana City\" in Metro Manila.\n\nIn both village ‘A’ and ‘B’, BHWs were trained to teach households to inspect water containers for immature mosquitoes. An instructional guide was provided along with a container management checklist, collected during monthly visits. The team also provided a video of dengue control techniques. Village A, however, encountered many problems and there was a poor response to the program. In Village B participants reported not only that the visits made residents more aware of dengue control, but they were more inclined to take action. Although behaviour change results have not yet been reported, it appears the difference is that the BHWs in Village B were more active and more trusted by the community. This shows that when engaging change agents, it’s important to understand both how the community feels about them and how they feel about their community.\n\nDespite the efforts of barangay health volunteers, they are constrained within the political leadership of local government units. There is a perception that barangay health stations provide low-quality health services and have low-client satisfaction. With funding limitations, barangay health stations struggle with lack of medicines supplies, long wait times, declines in quality of facility infrastructure, and lack of proper training and staffing. The rural poor are the most susceptible to poor sanitation, malnutrition, and lack of hygiene efforts. These communities that depend heavily on barangay health services are affected by political, social, and economic decisions made by local authorities .\n\nVolunteers may often be limited in knowledge due to new advances in medicine and lack of proper training. Training is crucial for barangay health workers to improve their health knowledge and competency and provide the best quality care.\n\n"}
{"id": "2654847", "url": "https://en.wikipedia.org/wiki?curid=2654847", "title": "Biopharmaceutical", "text": "Biopharmaceutical\n\nA biopharmaceutical, also known as a biologic(al) medical product, biological, or biologic, is any pharmaceutical drug product manufactured in, extracted from, or semisynthesized from biological sources. Different from totally synthesized pharmaceuticals, they include vaccines, blood, blood components, allergenics, somatic cells, gene therapies, tissues, recombinant therapeutic protein, and living cells used in cell therapy. Biologics can be composed of sugars, proteins, or nucleic acids or complex combinations of these substances, or may be living cells or tissues. They (or their precursors or components) are isolated from living sources—human, animal, plant, fungal, or microbial.\n\nTerminology surrounding biopharmaceuticals varies between groups and entities, with different terms referring to different subsets of therapeutics within the general biopharmaceutical category. Some regulatory agencies use the terms \"biological medicinal products\" or \"therapeutic biological product\" to refer specifically to engineered macromolecular products like protein- and nucleic acid-based drugs, distinguishing them from products like blood, blood components, or vaccines, which are usually extracted directly from a biological source. Specialty drugs, a recent classification of pharmaceuticals, are high-cost drugs that are often biologics. The European Medicines Agency uses the term \"advanced therapy medicinal products\" (ATMPs) for medicines for human use that are \"based on genes, cells, or tissue engineering\", including gene therapy medicines, somatic-cell therapy medicines, tissue-engineered medicines, and combinations thereof. Within EMA contexts, the term \"advanced therapies\" refers specifically to ATMPs, although that term is rather nonspecific outside those contexts.\n\nGene-based and cellular biologics, for example, often are at the forefront of biomedical research, and may be used to treat a variety of medical conditions for which no other treatments are available.\n\nIn some jurisdictions, biologics are regulated via different pathways than other small molecule drugs and medical devices.\n\nThe term biopharmacology is sometimes used to describe the branch of pharmacology that studies biopharmaceuticals.\n\nSome of the oldest forms of biologics are extracted from the bodies of animals, and other humans especially. Important biologics include:\n\n\nSome biologics that were previously extracted from animals, such as insulin, are now more commonly produced by recombinant DNA.\n\nAs indicated the term \"biologics\" can be used to refer to a wide range of biological products in medicine. However, in most cases, the term \"biologics\" is used more restrictively for a class of therapeutics (either approved or in development) that are produced by means of biological processes involving recombinant DNA technology. These medications are usually one of three types:\n\nBiologics as a class of medications in this narrower sense have had a profound impact on many medical fields, primarily rheumatology and oncology, but also cardiology, dermatology, gastroenterology, neurology, and others. In most of these disciplines, biologics have added major therapeutic options for the treatment of many diseases, including some for which no effective therapies were available, and others where previously existing therapies were clearly inadequate. However, the advent of biologic therapeutics has also raised complex regulatory issues (see below), and significant pharmacoeconomic concerns, because the cost for biologic therapies has been dramatically higher than for conventional (pharmacological) medications. This factor has been particularly relevant since many biological medications are used for the treatment of chronic diseases, such as rheumatoid arthritis or inflammatory bowel disease, or for the treatment of otherwise untreatable cancer during the remainder of life. The cost of treatment with a typical monoclonal antibody therapy for relatively common indications is generally in the range of €7,000–14,000 per patient per year.\n\nOlder patients who receive biologic therapy for diseases such as rheumatoid arthritis, psoriatic arthritis, or ankylosing spondylitis are at increased risk for life-threatening infection, adverse cardiovascular events, and malignancy.\n\nThe first such substance approved for therapeutic use was biosynthetic \"human\" insulin made via recombinant DNA. Sometimes referred to as rHI, under the trade name Humulin, was developed by Genentech, but licensed to Eli Lilly and Company, who manufactured and marketed it starting in 1982.\n\nMajor kinds of biopharmaceuticals include:\n\nResearch and development investment in new medicines by the biopharmaceutical industry stood at $65.2 billion in 2008. A few examples of biologics made with recombinant DNA technology include:\n\nMany vaccines are grown in tissue cultures.\n\nViral gene therapy involves artificially manipulating a virus to include a desirable piece of genetic material.\n\nWith the expiration of numerous patents for blockbuster biologics between 2012 and 2019, the interest in biosimilar production, i.e., follow-on biologics, has increased. Compared to small molecules that consist of chemically identical active ingredients, biologics are vastly more complex and consist of a multitude of subspecies. Due to their heterogeneity and the high process sensitivity, originators and follow-on biosimilars will exhibit variability in specific variants over time, however the safety and clinical performance of both originator and biosimilar biopharmaceuticals must remain equivalent throughout their lifecycle. Process variations are monitored by modern analytical tools (e.g., liquid chromatography, immunoassays, mass spectrometry, etc.) and describe a unique design space for each biologic.\n\nThus, biosimilars require a different regulatory framework compared to small-molecule generics. Legislation in the 21st century has addressed this by recognizing an intermediate ground of testing for biosimilars. The filing pathway requires more testing than for small-molecule generics, but less testing than for registering completely new therapeutics.\n\nIn 2003, the European Medicines Agency introduced an adapted pathway for biosimilars, termed \"similar biological medicinal products\". This pathway is based on a thorough demonstration of \"comparability\" of the \"similar\" product to an existing approved product. Within the United States, the Patient Protection and Affordable Care Act of 2010 created an abbreviated approval pathway for biological products shown to be biosimilar to, or interchangeable with, an FDA-licensed reference biological product. A major hope linked to the introduction of biosimilars is a reduction of costs to the patients and the healthcare system.\n\nWhen a new biopharmaceutical is developed, the company will typically apply for a patent, which is a grant for exclusive manufacturing rights. This is the primary means by which the developer of the drug can recover the investment cost for development of the biopharmaceutical. The patent laws in the United States and Europe differ somewhat on the requirements for a patent, with the European requirements are perceived as more difficult to satisfy. The total number of patents granted for biopharmaceuticals has risen significantly since the 1970s. In 1978 the total patents granted was 30. This had climbed to 15,600 in 1995, and by 2001 there were 34,527 patent applications. In 2012 the US had the highest IP (Intellectual Property) generation within the biopharmaceutical industry, generating 37 percent of the total number of granted patents worldwide, however, there is still a large margin for growth and innovation within the industry. Revisions to the current IP system to ensure greater reliability for R&D (research and development) investments is a prominent topic of debate in the US as well. Blood products and other human derived biologics like breast milk, have highly regulated or very hard to access markets, therefore, customers generally face a supply shortage for these products due to their nature and often institutions housing these biologics, designated as 'banks', cannot distribute their product to customers effectively. Conversely, banks for reproductive cells are much more widespread and available due to the ease of which spermatozoa and egg cells are able to be used for fertility treatment.\n\nBiopharmaceuticals may be produced from microbial cells (e.g., recombinant \"E. coli\" or yeast cultures), mammalian cell lines (see cell culture) and plant cell cultures (see plant tissue culture) and moss plants in bioreactors of various configurations, including photo-bioreactors. Important issues of concern are cost of production (low-volume, high-purity products are desirable) and microbial contamination (by bacteria, viruses, mycoplasma). Alternative platforms of production which are being tested include whole plants (plant-made pharmaceuticals).\n\nA potentially controversial method of producing biopharmaceuticals involves transgenic organisms, particularly plants and animals that have been genetically modified to produce drugs. This production is a significant risk for the investor, due to production failure or scrutiny from regulatory bodies based on perceived risks and ethical issues. Biopharmaceutical crops also represent a risk of cross-contamination with non-engineered crops, or crops engineered for non-medical purposes.\n\nOne potential approach to this technology is the creation of a transgenic mammal that can produce the biopharmaceutical in its milk, blood, or urine. Once an animal is produced, typically using the pronuclear microinjection method, it becomes efficacious to use cloning technology to create additional offspring that carry the favorable modified genome. The first such drug manufactured from the milk of a genetically modified goat was ATryn, but marketing permission was blocked by the European Medicines Agency in February 2006. This decision was reversed in June 2006 and approval was given August 2006.\n\nIn the European Union, a biological medicinal product is one of the active substance(s) produced from or extracted from a biological (living) system, and requires, in addition to physico-chemical testing, biological testing for full characterisation. The characterisation of a biological medicinal product is a combination of testing the active substance and the final medicinal product together with the production process and its control. For example:\n\nIn the United States, biologics are licensed through the biologics license application (BLA), then submitted to and regulated by the FDA's Center for Biologics Evaluation and Research (CBER) whereas drugs are regulated by the Center for Drug Evaluation and Research. Approval may require several years of clinical trials, including trials with human volunteers. Even after the drug is released, it will still be monitored for performance and safety risks. The manufacture process must satisfy the FDA's \"Good Manufacturing Practices\", which are typically manufactured in a clean room environment with strict limits on the amount of airborne particles and other microbial contaminants that may alter the efficacy of the drug.\n\n\n"}
{"id": "43586140", "url": "https://en.wikipedia.org/wiki?curid=43586140", "title": "Black gill disease", "text": "Black gill disease\n\nBlack gill disease is a disease of crustaceans.\n\nIt has been observed in spiny lobsters (\"Panulirus ornatus\") in Vietnam, where it is caused by a species of \"Fusarium\".\n\nIt has been observed in shrimp, where the agent is microscopic protozoan \"Hyalophysa chattoni\" or a close relative, in Galveston Bay, Texas and other locations.\n\nThere are multiple sources known to cause black gill disease. Poor pond conditions can cause debris to build up in the gills turning them black. Certain kinds of bacteria and the fungus genus Fusarium are also known causes.\n\nWith extra care taken to the health of the shrimp, it is possible to prevent cases of black gill disease. The water should have 10-20 parts per thousand parts salinity and filtered. \n"}
{"id": "8299539", "url": "https://en.wikipedia.org/wiki?curid=8299539", "title": "Breaking point (psychology)", "text": "Breaking point (psychology)\n\nIn human psychology, the breaking point is a moment of stress in which a person breaks down or a situation becomes critical.\n\nThe intensity of environmental stress necessary to bring this about varies from individual to individual.\n\nGetting someone to confess to a crime during an interrogation – whether innocent or guilty – means the suspect has been broken. The key to breaking points in interrogation has been linked to changes in the victim's concept of self – changes which may be precipitated by a sense of helplessness, by lack of preparedness or an underlying sense of guilt, as well (paradoxically) as by an inability to acknowledge one's own vulnerabilities.\n\nPsychoanalysts like Ronald Fairbairn and Neville Symington considered that everybody has a potential breaking point in life, with vulnerability particularly intense at early developmental stages.\n\nSome psychoanalysts say that rigid personalities may be able to endure great stress before suddenly cracking open.\n\n\n"}
{"id": "38340278", "url": "https://en.wikipedia.org/wiki?curid=38340278", "title": "Capital punishment in Lebanon", "text": "Capital punishment in Lebanon\n\nCapital punishment is a legal penalty in Lebanon, though it has not been used since 2004.\n\nCapital crimes in Lebanon include murder; espionage; treason; terrorism; collaborating with Israeli forces and if the crime is especially heinous enough; rape; pedophilia; gang-robbery or gang-assault; arson against certain types of structures or sabotage of communications, transportation or industrial facilities causing death; aggravated assault; gang-assault involving torture; life-eligible crimes with recidivism; importing nuclear/toxic wastes; polluting rivers or waterways with harmful substances and some military offences (e.g. desertion). The methods prescribed by law are hanging and firing squad, although hanging has been the predominant method throughout Lebanese history. In the Lebanese Republic, the President has the sole authority to pardon an inmate and all execution orders must be ratified by him.\n"}
{"id": "33678934", "url": "https://en.wikipedia.org/wiki?curid=33678934", "title": "Capital punishment in Spain", "text": "Capital punishment in Spain\n\nThe 1978 Spanish Constitution bans capital punishment in Spain. Spain completely abolished capital punishment for all offenses, including during wartime conditions, in October 1995.\n\nThe last executions were carried out on September 27, 1975 when five members of ETA and Revolutionary Antifascist Patriotic Front (FRAP) were executed by firing squad for murder following a much-publicised trial in which a number of the convicted (including a pregnant woman) were given clemency by General Francisco Franco, and the sentences of the remaining five, due to the unavailability of executioners versed in the use of the garrote, were carried out by shooting. Strangulation by garotte had been portrayed as a draconian act by the publicity after its last use in 1974, when Salvador Puig Antich was executed in Barcelona and Heinz Chez in Tarragona.\n\nCapital punishment was common in the Spanish kingdom, and methods used included decapitation (especially for nobility). In 1820 Ferdinand VII replaced all other methods with the garrote, which was used mainly since then, including for the liberal freedom fighter Mariana de Pineda Muñoz and the assassin of six-time Prime Minister of Spain Antonio Cánovas del Castillo. According to a pamphlet published anonymously by Crown Prince Oscar Bernadotte, Spain was the most frequent executioner of the Western world in the early 1800s, followed by his native Sweden. The penalty was abolished by the Second Spanish Republic in 1932 but restored two years later in the midst of social and political turmoil for a few major offences, not including murder.\nCapital punishment in Francoist Spain was restored fully on decree in 1938. From 1940 to 1975, 165 judicial executions are reported to have been carried out, although precise numbers from the years following the Spanish Civil War are vague. Among the most relevant executed from this period there is Lluís Companys, President of the Generalitat of Catalonia.\n\nAs Franco's regime was consolidated, use of the death penalty became more scarce; between 1950 and 1959 some 58 Spaniards (including two women) were executed by garrote and nine by firing squad. In the 1960s, the total number of executions dropped to six; two in 1960, two in 1963 and two in 1966 (less than in neighbouring France, although several of the convictions were considered political). Due to criticism, a six-year stay followed, broken when Pedro Martínez Exposito was shot in 1972 for homicide and robbery. The next executions, of Salvador Puig Antich and Heinz Chez in 1974, were allegedly held on the same day to deliberately confuse public sentiments and equalize the execution of a political opponent - both were convicted of killing Guardia Civil members - with that of a common murderer. The last five death sentences were carried out simultaneously in Madrid, Barcelona and Burgos on September 27, 1975, prompting Swedish Prime Minister Olof Palme - amongst other harsh condemnations - to denounce the regime as \"devilish murderers\" the following day.\n\nThe imposition of the death penalty for terrorism followed its own logic during Franco's dictatorship. Sometimes it was not swiftly carried out, such as in the case of Andrés Ruiz Márquez \"(Coronel Montenegro)\", a member of a Spanish National Liberation Front (FELN) commando who had set up a string of small bombs in Madrid. He was arrested by the Spanish police in 1964 and condemned to death but saw his sentence commuted to life in prison.\n\n"}
{"id": "38256723", "url": "https://en.wikipedia.org/wiki?curid=38256723", "title": "Catastrophic injury", "text": "Catastrophic injury\n\nA catastrophic injury is a severe injury to the spine, spinal cord, or brain, and may also include skull or spinal fractures. This is a subset of the definition for the legal term \"catastrophic injury\", which is based on the definition used by the American Medical Association.\n\nThe National Center for Catastrophic Sport Injury Research in the United States classifies catastrophic injuries based on the three outcomes associated with them: fatality, those causing permanent severe functional disability, and those causing severe head or neck trauma with no permanent disability. A fatal injury may be a direct result of trauma sustained during an activity, or may occur indirectly. Indirect nonfatal catastrophic injury may occur as a result of systemic failure from exertion during an activity, such as from cardiovascular conditions, heat illness, exertional hyponatremia, or dehydration, or a complication to a nonfatal injury. Indirect fatalities are usually caused by cardiovascular conditions, such as hypertrophic cardiomyopathy and coronary artery disease.\n\nFatal injury may reveal an unknown \"underlying anatomical or physiological abnormality\". Individuals with certain anatomical anomalies should not participate in some activities. For example, contact sports are contraindicated for individuals with an anomalous odontoid process, as any violent impact may result in a catastrophic injury. This is because a malformed odontoid process may lead to instability between the atlas and axis (the C1 and C2 cervical vertebrae). Those with atlanto-occipital fusion should also avoid contact sports.\n\nParticipation in any sport or recreational activity may result in a catastrophic sports injury, particularly if unsupervised or if engaged with little or no protection. Direct fatalities in sport are rare, as most sport fatalities are indirect and associated with non-sport cardiovascular problems.\n\nIn the United States, American football has the greatest incidence of catastrophic injury per population, whereas cheerleading is associated with the greatest incidence of direct catastrophic injury at both the interscholastic and intercollegiate levels.\n\nCervical spine trauma is most common in sports and activities involving contact and collision, particularly American football, rugby, ice hockey, gymnastics, skiing, wrestling, and diving. A 2005 report by the National Center for Catastrophic Sport Injury Research in the United States stated that sports requiring attention for potential catastrophic injuries are American football, ice hockey, baseball, wrestling, gymnastics, and track and field.\n\nThe incidence of catastrophic injury is four times higher in college than in high school in the United States. Sport accounts for between 5% and 10% of all cervical spine and spinal cord injuries in the United States, and 15% in Australia. The incidence of catastrophic injury for all sports is low, less than 0.5 per 100,000 participants.\n\nA study in the province of Ontario in Canada based on epidemiological data from 1986, 1989, 1992, and 1995 states that the greatest incidence of catastrophic injuries occurred in snowmobiling, cycling, ice hockey, and skiing. Of the 2,154 reported catastrophic injuries, 1,756 were sustained by males and 368 by females. The only activity in the study in which female casualties outnumbered males was equestrianism. The study also stated that field and floor sports had a relatively low incidence of catastrophic injury, and that July had the highest incidence of injury. Drowning was the cause of 357 fatalities, and there were 640 head and 433 spine injuries.\n\nThe study found 79.2% of the injuries were preventable; from over 1,500 responses, 346 involved alcohol consumption, and 1,236 were not supervised. Most alcohol-related injuries were sustained in snowmobiling (124), fishing (41), diving (40), boating excluding canoeing (31), swimming (31), riding an all-terrain vehicle (24), and cycling (23). Other studies have concluded that alcohol consumption is a common risk factor \"associated with all types of exposure\" (that is, activities) for traumatic brain injury.\n\nThe American Academy of Pediatrics has classified sports based on the likelihood of collision and contact. It recommends against participation in boxing.\n\nThose classified as \"contact and collision\" sports include basketball, boxing, diving, field hockey, football, ice hockey, lacrosse, martial arts, rodeo, rugby, ski jumping, soccer, team handball, water polo, and wrestling.\n\nThose classified as \"limited contact\" include baseball, bicycling, cheerleading, whitewater canoeing and kayaking, fencing, floor hockey, flag football, gymnastics, handball, horseback riding, racquetball, skating (ice skating, inline skating, roller skating), skiing (cross-country skiing, downhill skiing, water skiing), skateboarding, snowboarding, softball, squash, ultimate frisbee, volleyball, and windsurfing or surfing, and the track and field events high jump and pole vaulting.\n\nSports classified as \"non-contact\" include archery, badminton, body building, bowling, flatwater canoeing and kayaking, curling, dancing, golf, orienteering, power lifting, race walking, riflery, rope jumping, rowing, running, sailing, scuba diving, swimming, table tennis, tennis, weightlifting and weight training, the track and field events discus, javelin, and shot put and all track events.\n\nFrom 1945 to 2005, there were 497 fatalities, of which 69% were a result of brain injury and 16% from spinal cord injury. Today, the most common catastrophic injury in American football is cervical spinal cord injury, which is also the \"second leading cause of death attributable to football\". The 84% reduction in head injuries and 74% reduction in fatalities is directly attributable to the implementation of NOCSAE standards for football helmets and rule changes for tackling.\n\nFootball has the highest incidence of cervical spinal cord injuries in the United States per population. From 1977 to 2001, the incidence of cervical spinal cord injury amongst high school, college, and professional participants was 0.52, 1.55, and 14 per 100,000 participants, respectively.\n\nFrom 1982 to 1988, 75% of direct fatalities and 40% of indirect fatalities in college sports were associated with football; for high school athletes, the rates were 75% and 33%, respectively. Indirect fatalities were usually caused by cardiac failure or heat exhaustion. Indirect fatalities in high school and college football have been attributed to heat stroke, heart-related conditions, viral meningitis, and even lightning strikes.\n\nThe most common mechanism for catastrophic cervical spinal cord injury in American football is axial loading or compression resultant from spear tackling, in which a player uses the crown of the helmet as the initial point of contact for striking another player. This form of tackling was banned in 1976 for high school and college football, resulting in a significant reduction in catastrophic injuries of this type. For example, incidence of quadriplegia decreased from 2.24 and 10.66 per 100,000 participants in high school and college football in 1976, to 1.30 and 2.66 per 100,000 participants in 1977. Since 1977, about 67% of all catastrophic injuries in football were the result of a player making a tackle.\n\nIn the paper \"Catastrophic Football Injuries: 1977-1998\" published in 2000 by the journal \"Neurosurgery\", Robert Cantu and Frederick Mueller recommend that \"players should use the shoulder for blocking and tackling\" instead of \"using the head as a battering ram\". The purpose of rules against spearing, ramming, and butting is to protect both the tackler and the opponent from head trauma or catastrophic injury. Mueller also suggests that coaches remove players from a game if they exhibit symptoms of concussion, such as dizziness, headaches, nausea, or sensitivity to light.\n\nBaseball has a high incidence of catastrophic injury, the most common being cranial injuries usually sustained during a collision between a baserunner diving head first and a fielder, resulting in an axial compression injury to the baserunner. Other causes included collisions, such as between a catcher and baserunner, or being struck by a pitched or thrown ball.\n\nIn the Ontario study, all catastrophic injuries recorded for recreational canoeing were fatal, and accounted for 4.3% of all sport and recreation fatalities in the province. Of the 27 cases, 24 fatalities resulted from drowning, and the others from cerebral contusions, cerebral lacerations, and skull fractures. Canoeing drowning fatalities are \"often correlated with alcohol consumption\", as it increases the probability of submersion and decreases the probability of recovery from submersion. They are often associated with young males inexperienced in canoeing.\n\nThe primary cause of increased incidence of catastrophic injuries to cheerleaders is the \"evolution of cheerleading to a gymnastic-like activity\". It is the leading cause of catastrophic injuries to females, representing over 65% of the catastrophic injuries occurring in high school and college female athletes in the United States.\n\nHigh-risk activities include the construction of pyramids, which result in several catastrophic injuries each year, the 'basket toss', and tumbling, all of which are usually performed over hard surfaces. Cheerleader pyramids are banned in Minnesota and North Dakota.\n\nOther causes include inadequate supervision, poorly trained coaches, and the equipment used.\n\nIn the Ontario study, fishing resulted in 126 catastrophic injuries, of which 117 were fatal, 110 from drowning. Of these, 119 events were associated with males, of which 112 were fatalities. Fishing had the highest rate of catastrophic injuries to all injuries for any activity in Ontario, as 2.54% of all fishing injuries were catastrophic.\n\nCatastrophic injuries in fishing may be related to equipment, fish, alcohol, or the environment. Equipment issues generally involve penetrative injuries from the use of hooks and harpoons, but may also be caused by the fishing rod, lure, sinker, or bait. Fish-related injuries result from mishandling, poisoning, and contamination from consumption. Environmental causes may include overexposure to solar radiation, lightning strikes, hypothermia during ice fishing, snakebites, and viral infection spread by mosquitoes.\n\nGymnastics has a relatively low incidence of catastrophic injury, that is the number of catastrophic injuries with respect to the number of participants. In the United States from 1982 to 2007, nineteen catastrophic injuries were reported from 147 million high school and 8 million college participants.\n\nClub-level injury surveillance data in Australia indicate no catastrophic injury to elite participants from 1983 to 1993. Elite gymnast catastrophic injuries to the spinal cord have been recorded in China, Japan, and the United States, the most notable being to Sang Lan and Julissa Gomez. There is an \"absence of research reporting rate data\" for catastrophic injury to club-level gymnasts in the United States.\nThe most common catastrophic injury occurring in ice hockey is cervical spinal cord injury, which most often occur at C5, C6, or C7. The most common cause is checking from behind. Such checking was banned from hockey in 1985, which has resulted in a decreased incidence of catastrophic spinal injuries and a reduction of head and neck injuries.\n\nIncreased standards for hockey helmets and the requirement that they be worn in competitive play has resulted in a decrease of serious head injury and fatalities. Although full facial protection (helmet with cage) did not reduce the incidence of catastrophic injuries or concussion compared to a standard helmet, it reduced the incidence of facial injuries and lacerations.\n\nPorters who carry loads on their heads are subjected to axial strains that exacerbate degenerative change in the cervical spine, and has an etiological role in spondylosis.\n\nIn a 1968 study, Laurence Levy recorded six catastrophic injuries to porters at Harare Central Hospital in Harare, Zimbabwe. Of these, one died instantaneously, and five became quadriplegic, one as a result of a herniated intervertebral disc and four from fractures or fracture-dislocations.\n\nFor rugby union, the incidence of catastrophic injury from 1952 to 2005 in England was 0.84 per 100,000 per year. In all other countries, from 1970 to 2007 the incidence was 4.6 per 100,000 per year. For rugby league, it was 2 per 100,000 per year. In rugby union in France, the incidence of catastrophic cervical spine injuries decreased from 2.1 per 100,000 in the 1996–1997 season to 1.4 per 100,000 in the 2005–2006 season, which has been attributed to rule changes regarding the scrum.\n\nThe most common causes are the scrum, the ruck or maul, and the tackle. Research from Australia states that injury prevention in youth rugby should focus on the scrum and the tackle, and that risk factors are level of play (age group) and player position. It also indicated that \"neck injuries in the scrum and to the front row are of great concern\".\n\nThe use of a scrum cap or other padded headgear does not reduce the incidence of concussion or other head or neck trauma.\n\nIn a survey of scientific literature from 1990 to 2004, 24 studies covering 10 countries indicated an increasing incidence of traumatic brain injury (TBI) and spinal cord injury amongst alpine skiers and snowboarders. The most common cause of death is head injuries, which can be mitigated by 22–60% by the use of helmets. The increased incidence coincides \"with the development and acceptance of acrobatic and high-speed activities\".\n\nMost deaths are attributed to massive head, neck, or thoracoabdominal injury, of which TBI accounted for between 50% and 88% and spinal cord injury between 1% and 13%. Ski fatalities occur between 0.050 and 0.196 per 100,000 participants. Head injuries represent 28.0% of all injuries in skiers and 33.5% for snowboarders.\n\nIn the Ontario study, snowmobiling had the highest incidence and prevalence of recreational catastrophic injuries of any activity (290 incidents, 120 fatalities). It had the second-highest incidence of catastrophic injury per participant (88.2 per 100,000), the greatest incidence per 100,000 population (0.706), and the greatest incidence of fatality per 100,000 population (0.292). It was also the activity in which alcohol consumption was most prevalent in catastrophic events (124), representing more than one third of all events for which alcohol was a factor. Other contributing factors include \"poor lighting, young age and inappropriate terrain\".\n\nThe majority of track and field-related fatalities in the United States is associated with pole vaulting. Other fatalities and catastrophic injuries in track and field occur by a participant or bystander being struck by a discus, shot put, or javelin.\n\nMost catastrophic injuries related to diving and swimming in the United States occur when an individual dives into shallow water. It is the cause of 2.6% of all cervical spine injury admissions, and are chiefly sustained by recreational divers. The most common cause is diving into shallow water, inexperience, inadequate supervision, and alcohol consumption.\n\nCatastrophic swimming injuries in the Ontario study were four times as prevalent in males than females. The incidence of catastrophic injury in competitive swimming is very low, and almost all such injuries occur in recreational and non-competitive swimming.\n\nFrom 1981 until 1999 in the United States, 35 catastrophic injuries related to wrestling were reported, one in college and the others in high school, an incidence of 1 per 100,000 per year. They were caused by three positions: defensive position during takedown (74%), down position (23%), and lying position (3%). Most occurred in the lower weight classes, and 80% were incurred during a match. In Iran from 1998 to 2005, the incidence of catastrophic injury was 1.99 per 100,000 participants per year.\n\nMost injuries were cervical fracture or major cervical ligament injuries. One of the athletes died, one third became tetraplegic, one paraplegic, and six others suffered residual neurologic deficit.\n\nCatastrophic wrestling injuries are preventable, and associated risk factors include incorrectly performing a manoeuvre, lack of supervision by the coach, and inappropriate injury management.\n\nIn the United Kingdom, the incidence of catastrophic injury per year for work-related situations is 0.9 per 100,000. The incidence is highest in agriculture (6.0 per 100,000) and construction (6.0 per 100,000), and lowest in the service sector (0.4).\n\nThe incidence is 3.7 per 100,000 for pedestrians, 2.9 per 100,000 for automobile occupants, and 190 per 100,000 for motorcyclists.\n\nVehicular accidents account for 43% of catastrophic spinal injury in the United States and 45% in Australia.\n\nIn the Ontario study, recreational catastrophic injuries were most prevalent in snowmobiling (290 incidents, 120 fatalities), bicycling (289 incidents, 67 fatalities), fishing (126 incidents, 117 fatalities), boating (excluding canoeing, 112 incidents, 72 fatalities), diving (105 incidents, 5 fatalities) and swimming (100 incidents, 86 fatalities). The greatest incidence per participant was recorded for diving (511.0 per 100,000), snowmobiling (88.2 per 100,000), parachuting (62.9 per 100,000), tobogganing or sledding ( 37.7 per 100,000), hang gliding (29.4 per 100,000), water polo (24.5 per 100,000), scuba diving (12.2 per 100,000), hunting (12.2 per 100,000), horseback riding (11.6 per 100,000), archery (11.1 per 100,000), and fishing (11.0 per 100,000). The greatest incidence per 100,000 population were recorded for snowmobiling (0.706), cycling (0.701), ice hockey (0.462), fishing (0.307), boating excluding canoeing (0.273), diving (0.256), swimming (0.243) and baseball (0.217). The greatest incidence of fatality per 100,000 population were recorded for snowmobiling (0.292), fishing (0.285), swimming (0.200), boating excluding canoeing (0.175), cycling (0.163), canoeing (0.066), riding an all-terrain vehicle (0.039), hunting (0.037), and horseback riding (0.024). Catastrophic cycling injuries were most prevalent in cities, particularly Toronto (64), Ottawa (21), and London (7). Drowning represented more than half of sport and recreation fatalities in the Ontario study.\n\nIn the United States, the Consumer Product Safety Commission (CPSC) recorded nearly 1,000 fatalities between 1967 and 1987 as a result of riding an all-terrain vehicle, more than half of which were individuals less than 16 years old. This led to a filing of an action per the Consumer Product Safety Act in 1987, which effectively ended the sale of three-wheeled ATVs. Since then, 35% of deaths were individuals less than 16 years old. The American Academy of Pediatrics and CPSC recommend that individuals less than 16 years old should not ride ATVs.\n\nThe types of acute catastrophic spinal injuries are those associated with unstable fractures and dislocations, intervertebral disc herniation, and transient quadriplegia. These most commonly affect the cervical spine, but also affect the thoracolumbar spine (the thoracic and lumbar vertebrae) and physis, or cause cervical cord neuropraxia and sometimes spinal cord injury without radiographic abnormality ().\n\nResponse to a non-fatal catastrophic spinal cord injury by the patient varies by \"social, economic, and educational background\".\n\nThe most common initial response is depression. About 6% of patients with a spinal cord injury commit suicide, usually in the years immediately after sustaining the injury. By ten years after an injury, the rate of suicide is similar to that of the general population.\n\nMany patients recover only partially from their injury, and must cope with paralysis or mental deficiency, usually requiring lifetime medical care.\n\nAbout 90% of patients who are single when injured are still single five years after the injury. There is a high incidence of divorce and separation after an injury, though this decreases beyond the first year after injury.\n\nMany catastrophic spinal cord injury patients improve their education. Immediately after injury, the average level of education is below that of the general population; fifteen years after injury, it is above that of the general population.\n\nSurvivors of catastrophic injury may also have catastrophic facial injuries, such as fractured facial bones, particularly those from events associated with ice hockey, cycling, and snowmobiling.\n\nNumerous secondary medical problems are associated with catastrophic spinal cord injury. These include cardiovascular complications, such as deep vein thrombosis, pulmonary embolism, orthostatic hypotension, bradycardia, autonomic dysreflexia, altered thermoregulation, and changes to cardiac function as a result of injury to the sympathetic nervous system.\n\nOther problems may include pulmonary and gastrointestinal problems, heterotopic ossification, osteoporosis, and other pathologic fractures. Pneumonia is a common cause of death among patients with spinal cord injuries.\n\nA skull fracture occurs when a bone in the skull breaks, and may penetrate the brain, tearing arteries, veins, or meninges, leading to the functional impairment of walking, communication, thinking, or feeling. Cerebral lacerations (tearing of brain tissue) or cerebral contusions (bruising of brain tissue) usually damage the cerebral cortex, resulting in permanent neurological deficits.\n\nA life care plan is established for the patient to address the patient's needs. It is an individualized document describing the services, support, equipment, and ancillary requirements for the patient that is updated to reflect changes in the patient's condition. It usually contains target outcomes, dates, and timelines.\n\nComponents of the life care plan may include:\n\n\nThis is in addition to information regarding surgical intervention and treatment, diagnostic testing, therapeutic interventions (speech therapy, rehabilitation, etc.), counselling, and dealing with complications. It may also include educational and vocational services.\n\nIn the United States, 2.55% of hospitalized catastrophic injury patients enroll in Medicaid to cover their medical bills. In \"Catastrophic Injuries in Sports and Recreation: Causes and Prevention : A Canadian Study\", Charles Tator states that the average case of non-fatal catastrophic injury costs about $7.5 million (Canadian dollars, normalized to 2006) in lost earnings, lifetime care, and rehabilitation services, and cost the economy of Ontario about $2.125 billion annually.\n\nOne paradigm used in injury prevention is the Haddon Matrix developed by William Haddon Jr. of the National Highway Safety Bureau in the late 1960s. The matrix was designed to categorize highway safety phenomena, and applied a public health model to traffic-related epidemiology. It consists of ten strategies that are implemented based on temporality, that is pre-event strategies (primary prevention), event strategies (secondary prevention), and post-event strategies (tertiary prevention). The purpose of injury prevention is to decrease the \"burden of injury to the individual and to society\", which includes mortality, morbidity, disability, and economic cost.\n\nThe ten strategies are:\n\n\nIn \"Catastrophic Head Injuries in High School and Collegiate Sports\", Frederick Mueller states that the frequency of catastrophic injuries may be reduced by:\n\n\nPreparation for a catastrophic injury event includes a written emergency plan, which should incorporate an evacuation, transportation and communication plan, as well as notifying hospital emergency departments about game and practice schedules for teams and clubs. Response to a catastrophic injury event should reduce its severity, such as via the administration of first aid. In \"Catastrophic Injuries in Sports and Recreation: Causes and Prevention : A Canadian Study\", Charles Tator states that effective injury prevention programs involve education, engineering, and rule enforcement. Education is intended to inform the participants of potential dangers of risky behaviour in the activity, and engineering \"involved modifying the environment to create safer surroundings\", such as maintaining playing fields or improving the design of equipment.\n\nSports organizations, leagues, and associations have integrated a catastrophic injury plan as part of their emergency action and emergency management plans, and have also changed rules to prevent or reduce the incidence of catastrophic injuries. Such plans include a notification system, which may be used to contact the family of the injured athlete, athletic coordinators, officials, legal and risk management offices, and institutional insurance carriers. It may also include the formation of a catastrophic injury team, which may include athletic directors, head athletic trainer, team physicians, legal counsel, and media relations.\n\nIn 1985, the National Collegiate Athletic Association created an insurance plan for member institutions to provide benefits for student athletes who sustain a catastrophic injury, in response to an increase in workers' compensation claims filed by students. This was designed to protect member institutions \"against the sudden and substantial costs of injury benefits\", typically obtained by the student via worker's compensation claims and litigation. The injured student receives benefits immediately and does not incur litigation costs, but retains the right to litigation in cases of negligence by the institution. In 2005, 25% of funds for insurance claim payouts were associated with cheerleading.\n\nThe National Federation of High School Associations instituted a medical plan for high school athletic associations and their member schools and districts. This allows a catastrophically injured student athlete to receive \"medical, rehabilitation, and work-loss benefits\" until death by waiving rights to litigation. The institution thereby need not invest the human and financial resources associated with litigation, in addition to a potential award to the plaintiff, and the student receives immediate and lifelong benefits.\n\nAthletic associations, organizations, and leagues update their rules based on research regarding catastrophic injuries. The amount of enforcement of the rules may explain variations in incidence of catastrophic injuries between jurisdictions.\n\nIn Canada, as of May 2012 the largest award to a plaintiff of a catastrophic brain injury was $18.4 million, and the largest award to a plaintiff of a catastrophic spinal cord injury was $12.33 million.\n\nIn South Africa, the largest malpractice settlement for the Medical Protection Society as of 2011 was for R17 million, awarded to a patient who suffered catastrophic neurological damage as a result of a surgical procedure.\n\n"}
{"id": "56810248", "url": "https://en.wikipedia.org/wiki?curid=56810248", "title": "Code of practice", "text": "Code of practice\n\nA Code of practice can be a document that complements occupational health and safety laws and regulations to provide detailed practical guidance on how to comply with legal obligations, and should be followed unless another solution with the same or better health and safety standard is in place, or may be a document for the same purpose published by a self-regulating body to be followed by member organisations.\n\nCodes of practice published by governments do not replace the occupational health and safety laws and regulations, and are generally issued in terms of those laws and regulations. They are intended help understand how to comply with the requirements of regulations. A workplace inspector can refer to a code of practice when issuing an improvement or prohibition notice, and they may be admissible in court proceedings. A court may use a code of practice to establish what is reasonably practicable action to manage a specific risk. Equivalent or better ways of achieving the required work health and safety may be possible, so compliance with codes of practice is not usually mandatory, providing that any alternative systems used provide a standard of health and safety equal to or better than those recommended by the code of practice.\n\nOrganisational codes of practice do not have the same authority under law, but serve a similar purpose. Member organisations generally undertake to comply with the codes of practice as a condition of membership and may lose membership if found to be in violation of the code.\n"}
{"id": "25386783", "url": "https://en.wikipedia.org/wiki?curid=25386783", "title": "Disability benefits", "text": "Disability benefits\n\nDisability benefits are funds provided from public or private sources to a person who is ill or who has a disability.\n\nIn the United Kingdom disability benefits are covered by Department for Work and Pensions, and include:\n\n\nIn the United States, disability benefits for most Americans are covered and paid for by the Social Security Administration (a government agency). There are two main programs administered by the SSA; Social Security Disability Insurance program (SSDI) and the Supplemental Security Income (SSI) program. There is also a specific program for children with disabilities.\n\nSocial Security Disability Insurance provides benefits to individuals who have worked and paid Social Security taxes. Insurance eligibility is dependent upon Quarters of Coverage (QCs), commonly called \"work credits\". These are allotted based on the earnings for each quarter the individual has worked. Work credits ensure coverage until they \"expire\" on the individual's Date Last Insured (DLI). Medical evidence must prove that the onset of disability was before their DLI to receive benefits. SSDI recipients become eligible for Medicare after two years of SSDI eligibility.\n\nSupplemental Security Income (SSI) provides benefits to low-income individuals who are disabled and unable to work, regardless of whether they have worked in the past. Individuals must meet income and resource requirements. SSI also provides benefits to children under 18 years old, who are disabled and whose parents or guardians have limited income. The monthly SSI payment is calculated based upon the Federal Benefit Rate (FBR), and the individual's income. Most SSI recipients are immediately eligible for Medicaid and Supplemental Nutrition Assistance Program (SNAP), though program requirements vary by state. \n\nSome individuals are eligible for both SSI and SSDI.\n\nIn Canada, there are a variety of public Disability Benefit Programs. The largest programs are the Canada Pension Plan and Quebec Pension Plan disability benefits, and provincial workers' compensation and social assistance programs. Some individuals, in addition, have private disability insurance coverage, purchased either individually, or through an employer. Different programs use different rules to decide whether or not someone is eligible for benefits.\n\nTo access Canada Pension Plan or the Quebec Pension Plan disability benefits, an individual needs to have a disability that is \"severe and prolonged\", and which prevents them from working on a regular basis. As of 2018, CPP disability benefits are a minimum of $485.20 a month. Individuals who have contributed more to CPP or QPP during their working career receive higher benefits. The average monthly CPP disability benefit was $971.23 in 2018 and the maximum monthly amount was $1,335.83. \n\nPeople receiving CPP disability benefits may earn up to $5,500 a year without losing their benefits. Benefits stop when an individual has the ability to work regularly, or is no longer disabled. When an the individual reaches the age of 65, CPP Disability Benefits are replaced by a Retirement Pension.\n\nEmployment Insurance is a benefit plan that offers temporary financial assistance to those individuals who cannot work due to sickness, injury, or quarantine. \n\nTo be eligible to receive EI sickness benefits:\n\n\nPeople are only eligible for these benefits if they are unable to work due to their sickness, injury, or quarantine, but would be able to work otherwise. To receive EI sickness benefit a medical certificate signed by the doctor is required.\n\nTo qualify for EI you must have a required amount of insurable employment hours, which are used to calculate your benefit period, these insurable employment hours must be accumulated throughout the qualifying period. \n\nThe qualifying period: \n\n\nIt is important to note that each individual’s case is different and requirements may vary from case to case. But a general way of calculating EI benefits is 55% of the average insurable weekly earnings. The maximum amount you can be eligible for as of January 1 2018 is $51,700. Typically EI sickness benefits can only be paid for up to 15 weeks, but can vary depending on how long the individual is unable to work. \n\nWeekly EI sick benefits are calculated based on income before its been deducted during the individuals “best weeks”. Best weeks are the weeks in which the individual earned the most amount of amount, including any tips and commissions, the best weeks are chosen out of the qualifying period. \n\nIn Canada areas with high rates of unemployment will use the best 14 weeks, and in areas with low unemployment rates will use the best 22 weeks. \n\nThe weekly amount is calculated: \n\n\nIf you are considered a low income family you may be eligible to receive the EI Family Supplement. An individual can be considered to be a part of this category if the yearly family net income is $25, 921 or less, has children, and if the individual or their spouse receives Canada child tax benefit. If both the individual and their spouse claims EI sickness benefits only one of them can be eligible for the family supplement. \n\nFor more information on Benefits and eligibility, please visit the Government of Canada website. \n"}
{"id": "56657636", "url": "https://en.wikipedia.org/wiki?curid=56657636", "title": "Dorothea Chalmers Smith", "text": "Dorothea Chalmers Smith\n\nDr Elizabeth \"Dorothea\" Chalmers Smith \"née\" Lyness (1874 – 1944) was a pioneer doctor and a militant Scottish suffragette. She was imprisoned for eight months for breaking and entering, and attempted arson, where she went on hunger strike.\n\nChalmers Smith graduated from medicine from the University of Glasgow in 1894, and worked at the Royal Samaritan Hospital for Women in Glasgow.\n\nChalmers Smith married Reverend William Chalmers Smith, minister of Calton Church, Glasgow in 1901. They had six children born between 1900 and 1911.\n\nChalmers Smith joined the Women's Social and Political Union (WSPU) in 1912, but her enthusiasm for extreme militancy was not welcomed by her husband, who believed adamantly that a woman's place was in the home.\nChalmers Smith, alongside artist Ethel Moorhead, attempted to set fire to a house at 6 Park Gardens in Glasgow on 23 July 1913. They were caught red-handed by multiple witnesses. In one room firefighters found matches, firelighters, six flasks of paraffin, candles, and a postcard bearing the words: 'A protest against Mrs Pankhurst's re-arrest'.\n\nThe case was tried in the High Court at Jail Square and hundreds of Suffragettes attended the trial. Chalmers Smith and Moorhead both conducted their own defence and refused to plead. Moorhead interrupted the Judge saying \"We do not want to hear any more. We refused to listen to you. Please sentence us.\"\n\nWhen both women were sentenced to eight-months imprisonment, the women rose from all sections of the court and protested, crying out \"Pitt Street, Pitt Street\" whilst others starting throwing apples at the Judge and counsel.\n\nBoth women went on hunger strike immediately. When they became physically weak they were released from prison under the Cat and Mouse Act, which was introduced in April 1913, and allowed for the re-arrest of prisoners once their health improved.\n\nDetectives were posted on the door of her house to make sure that she did not escape. She managed to escape on occasion by dressing up in her younger sister's school uniform.\n\nChalmers Smith and her husband divorced after the First World War, at a time that it was difficult for a Church of Scotland minister to do so. She left with her three daughters, but she was not allowed to see her three sons again.\n\nAfter the Great War, Chalmers Smith worked in the newly established child welfare clinics in Glasgow. She did pioneering work in child-care and raised her daughters to be doctors. She died in 1944, and her silver WSPU Hunger Strike medal was donated to the People's Palace by one of her daughters. These medals were first presented by the WSPU at a ceremony in August 1909.\n\nThe Suffrage Oak on Kelvinway was planted in 1918 to celebrate women’s first opportunity to vote in a general election and stands as a memorial to the likes of Helen Crawfurd, Dorothea Chalmers Smith, Jessie Stephen and Frances McPhun.\n\n"}
{"id": "53779427", "url": "https://en.wikipedia.org/wiki?curid=53779427", "title": "Family planning in Bangladesh", "text": "Family planning in Bangladesh\n\nFamily planning in Bangladesh in Bangladesh is carried out by government agencies and supported by non-government organisations. The Directorate General of Family Planning is the government agency responsible for family planning in Bangladesh. Marie Stopes Bangladesh is an international NGO that provides family planning services in Bangladesh.\n\nIn 1975 the population of Bangladesh was 76.3 million, and by 2001 the population had reached 130.5 million. Bangladesh has a fertility rate of 2.3, which, according to United Nations Population Fund, makes it a \"low fertility country\". Bangladesh has a high population density, with about 1000 people per square kilometre. Since independence Bangladesh has reduced its total fertility rate (TFR) to 2.1, which means that women have 2.1 children on average. At this TFR and without migration a country's population is neither growing nor shrinking. Recently, Bangladesh family planning programs are described as being weakened.\n\nIn 1950 family planning was introduced by medical volunteers and social workers. In 1965 the Government of Pakistan started family planning program in East Pakistan. In 1976 the government of Bangladesh declared rapid population growth rate as the nations number one problem. Bangladesh has experienced rapid population growth since its independence. This was a result of high fertility rate, increased life expectancy, and decreasing mortality rate. In 1975 the total fertility rate was 6.3 which by 2011 was reduced to 2.3 from the data collected by Bangladesh Demographic Health Survey 2011. The survey found most women have two or more children. It also found that the majority of women in Bangladesh would prefer to have two or less Children. Since 2011 the total fertility rate has remained at 2.3, according to the International Conference on Family Planning, family planning in Bangladesh has not made progress since then. Infant mortality fell from 160,300 in 2000 to 83,100 by 2015 according to \"The Lancet\". Bangladesh is ranked 7 worldwide in number of stillbirths. Bangladesh Demographic Health Survey 2014 found that 33 percent 15 to 19 year olds were pregnant. 66 percent of the population give birth before 19. Family Service is supported by UNFPA in Bangladesh.\n\nAccording to official government estimates in Bangladesh 65% of girls are married off before their 18th birthday. 60 percent of child brides have children by the time they are 19 and 10 percent of them have children by the time they are 15. Bangladesh's Penal Code places the age of consent at 14, through sex before marriage is frowned upon socially.\n\nAccording to Bangladesh government data 40 percent couple in the country do not use contraceptives. The most popular choice of contraceptives is birth control pill. The Ministry of Health and Family Welfare subsidizes contraceptives in Bangladesh. Reproductive health is not taught in schools and is not part of the national educational curriculum. Bangladesh employs women to provide family planning advice and contraceptives. Bangladesh has a high rate of illegal abortions and increased availability of contraceptives is expected to reduce that. Essential Drugs Company Ltd started manufacturing condoms in Bangladesh from 2010.\n"}
{"id": "429848", "url": "https://en.wikipedia.org/wiki?curid=429848", "title": "Food Standards Agency", "text": "Food Standards Agency\n\nThe Food Standards Agency is a non-ministerial government department of the Government of the United Kingdom. It is responsible for protecting public health in relation to food in England, Wales and Northern Ireland. It is led by a board appointed to act in the public interest. Its headquarters are in London, with offices in York, Wales and Northern Ireland. The agency had a national office in Scotland until April 2015 when it was replaced by Food Standards Scotland.\n\nThe Agency was created in 2001 based on a report by Professor James, issued after several high-profile outbreaks and deaths from foodborne illness. It was felt that it was inappropriate to have one government department, the Ministry of Agriculture, Fisheries and Food, responsible for both the health of the farming and food processing industries and for food safety.\n\nUniquely for a UK Government department, the Food Standards Act gave the Agency the statutory right to publish the advice it gives to Ministers - and as a signal of its independence it declared that it would invariably do so. From its inception, the Agency declared that it would take no decisions about food policy except in open Board meetings accessible to the public. Since 2003, these meetings have been webcast live, enabling consumers to see the decision-making process in action. Each Board meeting concludes with a Q&A session in which web viewers can question the Board or its Executive directly.\n\nIn 2006, the Wine Standards Board merged with the FSA to take over responsibility for enforcing the EU wine regime in the UK.\n\nFormerly an executive agency of the FSA, the Meat Hygiene Service merged with the FSA in April 2010 to form a new operations group. The operations group has responsibility for the delivery of official controls.\nCertain aspects of food labelling policy in England were transferred from the Food Standards Agency to the Department for Environment, Food and Rural Affairs (Defra) on 1 September 2010. In England, the Agency retains responsibility for food safety-related labelling issues, whereas the devolved Food Standards Agency offices in Wales and Northern Ireland are still responsible for all labelling and standards policy.\n\nNutrition policy, including nutrition labelling, in England and Wales was transferred from the Food Standards Agency to the Department of Health in England and to the Assembly Government in Wales on 1 October 2010. The Food Standards Agency offices in Scotland and Northern Ireland have retained their responsibilities for nutrition policy.\n\nPlans to create a new food standards body in Scotland were announced by Ministers in June 2012\nand in January 2015 this new body was established through primary legislation. Food Standards Scotland took over from the FSA on 1 April 2015 as the public body responsible for food safety, food standards, nutrition, food labelling and meat inspection in Scotland.\n\nSir John Krebs was the first Chair of the Food Standards Agency, until 2005. Dame Deirdre Hutton was Chair between 2005 and July 2009, followed by\nJeff Rooker until July 2013. Tim Bennett, the former Deputy Chair, was appointed as interim Chair whilst a permanent appointment was made. Heather Hancock was appointed the new Chair on 1 April 2016, for a three-year term. \n\nThe Agency is advised by a number of independent expert committees, including: the General Advisory Committee on Science, the Advisory Committee on the Microbiological Safety of Food, the Committee on Toxicity, the Advisory Committee on Novel Foods and Processes and the Social Science Research Committee.\n\nIn February 2005, the agency announced the discovery of the dye Sudan I in Worcester sauce, prompting a mass recall of over 400 products that used the sauce as a flavouring. \n\nOn 31 March 2006, it published its \"Survey of benzene levels in soft drinks\", which tested 150 products and found that four contained benzene levels above the World Health Organization (WHO) guidelines for drinking water. The Agency asked for these to be removed from sale.\n\nThe Food Standards Agency also imposed restrictions on the sheep trade because of the consequences of the 1986 Chernobyl catastrophe which were repealed in March 2012.\n\nThe FSA pushed for stricter rules on TV advertising to children of foods high in salt, sugar and fat and devised a nutritional profiling system to measure the balance of benefit and detriment in individual food products. In 2007, the UK TV regulator Ofcom introduced restrictions on advertising of products that scored poorly under the scheme.\n\nIn June 2002, and re-released in June 2006, the FSA conducted an advertising campaign on British television, highlighting the danger of food poisoning caused by barbecues. The advert, intended to shock viewers, shows sausages sizzling on a barbecue, looking to the viewer as if they are cooked. However, when a pair of tongs pick up one of these sausages, it falls apart, and reveals pink, uncooked meat in the middle. To emphasize the risk of diarrhoea and vomiting caused by food poisoning, the song \"When Will I See You Again\" by The Three Degrees is played in the background.\n\nIn 2005, Brenda Dean carried out an independent review of the Food Standards Agency. The report made 22 recommendations, all of which were accepted by the Food Standards Agency board. \n\nDean concluded:\n\nMy overwhelming impression, having undertaken this Review, is of an organisation that has been extremely conscious of the importance of fulfilling the very serious responsibilities of changing both the perception and the reality of food safety in the UK.\n\nIt has done well in taking forward the experiences, good and bad, of the previous regime, to begin building its own reputation.\n\nMost stakeholders agreed that the Agency has made significant progress towards improving food safety, gaining public confidence in food safety, and creating a modern culture in which it is the norm for procedures, information, consultation and decision-making to be in the public domain and to involve external stakeholders.\n\nThere was overwhelming support for the Agency’s policy of basing decisions on scientific evidence, and for this policy to be maintained and developed further. The vast majority of stakeholders believe the Agency to be independent and to act independently, with general recognition that decisions are based on scientific evidence.\n\nThere was general support for the Agency amongst all stakeholder groups, both in terms of the objectives of the Agency, and the way in which the Agency has approached and undertaken its responsibilities.\n\nOne principal criticism, identified in the report, was (Recommendation 20):\n\nIt is clear that many stakeholders believe the Agency has already made policy decisions on GM foods and organic foods and is not open to further debate. The Agency must address the perceptions of these stakeholders who have now formed views of the Agency founded on their belief that the basis upon which the Agency’s policy decisions were made was flawed.\n\nA food hygiene rating scheme has been deployed by the Food Safety Agency for all food businesses. Ratings are available at the business premises and online. Following a meeting in Cardiff, the FSA plans to make audit reports as widely available as possible for the public. According to Terence Collins, FSA’s Director of communication, the reason behind this decision is to make ratings simple and easily understood for every single business.\n\nApart from Scotland which is under a very simple Food Hygiene Information Scheme, the FSA’s Food Hygiene Rating Scheme will be tested throughout United Kingdom. As a result, ratings will range from 0 (improvement urgently needed) to 5 (very good), and may be displayed on a certificate. This information will also be made available online. Rating primary meat processing plants is the next step forward for the FSA, as meat audit are currently only available through Freedom of Information requests.\n\nThe local authority in Rutland is believed to the only one which has not accepted the scheme.\n\n\n\n"}
{"id": "51225665", "url": "https://en.wikipedia.org/wiki?curid=51225665", "title": "Georges Vicaire", "text": "Georges Vicaire\n\nGeorges Vicaire (8 December 1853 – 4 November 1921) was a French bibliophile and bibliographer. The son of (1802-1865), General Director of forests, and Marthe Vicaire Blais, Georges Vicaire was the father of Jean Vicaire and (1893–1976), an orientalist painter.\n\nGeorges Vicaire was responsible for special work on the preparation of the printed catalogs of the Bibliothèque de l'Arsenal, then was attached to the Bibliothèque Mazarine. In 1909, the Institut de France appointed curator of the , created by and located in Chantilly, next to the Musée Condé, which houses the very large Library of Henri d'Orléans, Duke of Aumale. He was also correspondent to the Vatican Library. He had hence access to funds from both institutions.\n\nVicaire is the author of bibliographies of Honoré de Balzac, José-Maria de Heredia, George Sand, Stendhal, Victor Hugo and gastronomic literature and a very important work in 8 volumes on the literature of the nineteenth century, \"Le Manuel de l'amateur de livres du XIX°siècle\" ; 8 volumes available online. \"This work, which will remain one of the monuments of the bibliography, has among other merits that of fending for the first time the issue long overlooked by first editions of the great romantic\" and earned its author in 1906, the Botta prize of the Académie française and twice, in 1900 and 1912, the Brunet prize awarded by the Académie des inscriptions et belles-lettres.\n\nFrom 1896 until his death, Georges Vicaire was director of the Bulletin du bibliophile with which he worked since 1890. From 1898 to 1902, he was secretary of the \"Amis de l'eau forte\" and in 1900, a member of the organizing committee of the retrospective section of book at the Exposition Universelle (1900) and a committee member of the International Congress of libraries. On 27 February 1901, he was elected a member of the \"Société des bibliophiles françois\", established in 1820. At seat XII, he succeeded Jean Hély d'Oissel, Félix-Sébastien Feuillet de Conches, Count Charpin-Feugerolles, Mme Standish-Noailles. In 1890, he had published to her attention, \"Rôti-cochon\" (\"roast-pig\") and was preparing for her an important and erudite study which was published in 1901 in the \"Almanach du bibliophile\" with which he collaborated since 1898.\n\nIn 1903, appeared Jeunesse de Balzac by Gabriel Hanotaux and Georges Vicaire. A new edition, augmented of the correspondence between Balzac and Madame de Berny, published shortly after the death of Georges Vicaire, of which Gabriel Hanotaux could write, in the afterword dated November 8, 1921: \"He did not have the satisfaction to see this book published and, after twenty-five years of cordial collaboration, I have the pain of losing at the time of realization, this incomparable friend. This book comes from him, it is him. I send it back to his memory. It will include on each page, the marks of his conscience, his flawless erudition and worship he professed for beautiful literature\".\n\nKnowledgeable about food and culinary arts, his copious annotations have generated exceptional interest for both the culinary art and bibliophily. His work \"Bibliographie gastronomique\" \"should be considered as the most important bibliographic contribution in this area\" (André-Louis Simon). Katherine Bitting states \"This work is considered the most erudite and valuable existing bibliography on culinary topics.\"\n\n\n"}
{"id": "36101926", "url": "https://en.wikipedia.org/wiki?curid=36101926", "title": "Gonadotropin-releasing hormone insensitivity", "text": "Gonadotropin-releasing hormone insensitivity\n\nGonadotropin-releasing hormone (GnRH) insensitivity is a rare autosomal recessive genetic and endocrine syndrome which is characterized by inactivating mutations of the gonadotropin-releasing hormone receptor (GnRHR) and thus an insensitivity of the receptor to gonadotropin-releasing hormone (GnRH), resulting in a partial or complete loss of the ability of the gonads to synthesize the sex hormones. The condition manifests itself as isolated hypogonadotropic hypogonadism (IHH), presenting with symptoms such as delayed, reduced, or absent puberty, low or complete lack of libido, and infertility, and is the predominant cause of IHH when it does not present alongside anosmia.\n\n"}
{"id": "49183716", "url": "https://en.wikipedia.org/wiki?curid=49183716", "title": "Haralampie Manchev", "text": "Haralampie Manchev\n\nHaralampie Manchev () (Kocani, March 3, 1898 – Skopje, January 14, 1974) was the first Macedonian medical research scientist who studying the child pathology, found some important specifics.\n\nManchev studied medicine in Vienna and graduated in Belgrade immediately after the First World War, but could not work in the hospital institution after the one-year medical internship. Got a place as outpatient doctor in dispensaries social diseases of the Hygiene Institute in Skopje, after a number of cases of malaria in all shapes, child malnutrition, infectious childhood diseases protracted convalescence.\n\nDuring the Second World War go to specialization in pediatric clinic in Sofia, where he met with Dr. Asparuh Panov, who showed his own material haematological changes in anemia of Kulej. Manchev started to investigate the incidence of Mediterranean anemia Kulej, where asking for malarial parasites found strange formation (leishmaniasis) in punktatite children with huge spleens and livers. Revealing leishmaniasis epidemic in Macedonia gave impetus to many researchers to detect leishmaniasis in other areas. More than 100 children were quickly diagnosed him and treated with specific chemotherapy with antiparasitic activity and clinical, a kind ex juvantibus.\n\nHe was associate professor of environmental theme of Kala-azar (KA). Dr. Haralmpie Manchev, who first described this parasitosis in children in Macedonia, a disease caused by leishmaniasis, the vector of the parasite from infected animals (dogs, ferrets and other tropical beasts) with gnat known to us as papatachi (ph. Flebotomus paptacei).\n\nHaralampie Manchev is the first head of the department at Children's Hospital in Skopje Temporal (1946), first director of the Children's Clinic (1947) and then worked as a doctor in the Special Clinic for lung diseases in children \"Kozle\". He was the first editor of a medical expert scientific journal Macedonian medical examination issued by the Macedonian Medical Association and the first president of the Association of pediatricians of Macedonia.\n\nManchev died after a long illness on 14 January 1974 in Skopje.\n"}
{"id": "51229322", "url": "https://en.wikipedia.org/wiki?curid=51229322", "title": "IPERGAY", "text": "IPERGAY\n\nIPERGAY was a French clinical trial of pre-exposure prophylaxis (PrEP) in sexually active gay men in a community setting. It demonstrated 86% effectiveness in preventing HIV transmission.\n\nThe study was published in December 2015 looking at an alternative strategy of \"on-demand\" PrEP where Truvada was taken 2–24 hours before sexual activity and only continued for 2 days afterwards. In a population of 400 gay men in France and Canada at high risk for HIV, this strategy led to an 86% drop in HIV infections over the average 9 month follow-up of the study. As of December 2015, non-continuous PrEP methods have not been endorsed by WHO or national guidelines.\n\n\n"}
{"id": "735136", "url": "https://en.wikipedia.org/wiki?curid=735136", "title": "Ibn Zuhr", "text": "Ibn Zuhr\n\nIbn Zuhr (; 1094–1162), traditionally known by his Latinized name of Avenzoar, was an Arab physician, surgeon, and poet. He was born at Seville in medieval Andalusia (present-day Spain), was a contemporary of Averroes and Ibn Tufail, and was the most well-regarded physician of his era. He was particularly known for his emphasis on a more rational, empiric basis of medicine. His major work, \"Al-Taysīr fil-Mudāwāt wal-Tadbīr\" (\"Book of Simplification Concerning Therapeutics and Diet\"), was translated into Latin and Hebrew and was influential to the progress of surgery. He also improved surgical and medical knowledge by keying out several diseases and their treatments.\n\nIbn Zuhr performed the first experimental tracheotomy on a goat. He is thought to have made the earliest description of bezoar stones as medicinal items.\n\nHis full name is Abū-Marwān ʻAbd al-Malik ibn Abī al-ʻAlāʼ Ibn Zuhr (). His name was Latinized as Avenzoar, Abumeron, Abhomeron, Alomehَn or Abhomjeron.\n\nAvenzoar was born in Seville in 1094, to the notable Banu Zuhr family who were members of the Arab tribe of Iyad. The family has since the early 10th century produced six consecutive generations of physicians, and included jurists, poets, viziers or courtiers, and midwives who served under rulers of Al-Andalus. Avenzoar started his education by studying religion and literature, as was the custom in medieval Muslim socialites. He later studied medicine with his father, Abu'l-Ala Zuhr (d.1131) at an early age. According to Avenzoar himself, his father introduced him to the works of Galen and Hippocrates, and asked him to swear the Hippocratic Oath while still a youth.\n\nAvenzoar started his medical career as court physician for the Almoravid dynasty. However, for some undisclosed reason, he later fell out of favour with the Almoravid ruler, 'Ali bin Yusuf bin Tashufin, and fled from Seville. He was however, apprehended and jailed in Marrakesh in 1140. This experience left a bad resentment in him as alluded from his writing. Later in 1147 when the Almohad dynasty conquered Seville, he returned and devoted himself to medical practice. He died in Seville in 1162.\n\nAccording to Leo Africanus, ibn Zuhr heard Averroes lecture, and learned physic from him. He was a great admirer of Galen, and in his writings he protests emphatically against quackery and the superstitious remedies of astrologers.\n\n\"The book of moderation,\" this was a treatise on general therapy written in his youth for the Almoravid prince Ibrahim Yusuf ibn Tashfin. The book is a summary of various different diseases, therapeutics and general hygiene. It is also noted for its advice regarding cosmetics and physical beauty. Ibn Zuhr even recommended plastic surgery to alter acquired features such as big noses, thick lips or crooked teeth.\n\nThe book of foods, as its name indicates, is a manual on foods and regimen which contains guidelines for a healthy life. Ibn Zuhr wrote the book shortly after he went out of jail for his new patron, Almohad leader Abd al-Mu'min. The book contains classification of different kinds of dishes and foods like bread, meat, beverages, fruits and sweats. When he talks about the meat, Ibn Zuhr mentions different kinds of animals' fleshes, even unusual ones like those of gazelles, lions and snakes, classifying them based on their taste, usefulness and digestibility. He also recommends specific foods for each season of the year. For example, during winter, digestion is accelerated, so the amount of food consumed should also be increased. Moreover, the food should also be warmer and drier, as temperatures are lower and humidity is higher.\n\nKitab al-Taysir seems to be the last book of Ibn Zuhr before his death. As mentioned in the introduction, the book was authored at the request of his friend, Averroes, to act as a compendium to his medical encyclopedia Colliget which focused more on general topics of medicine. The two books were later translated into Hebrew and Latin, where they used to be printed as a single book and remained popular as late as the 18th century.\n\nThe book, which contains 30 chapters, provides clinical descriptions and diagnosis of diseases starting from the head. Ibn Zuhr provided an accurate description of the esophageal, stomach and mediastinal cancers, as well as other lesions. He proposed feeding enemas to keep alive patients with stomach cancer. He was also the first to give pathological descriptions of inflammations like otitis media and pericarditis.\n\nIbn Zuhr is also credited with providing one of the earliest recorded evidence of the Scabies mite, which contributed to the scientific advancement of microbiology. In his Kitab al-Taysir, he wrote the following:\nThere are lice under the hand, ankle and foot like worms, and sores affecting the same areas. If the skin is removed, there appears from various parts of it, a very small animal which can hardly be seen.\n\nPerhaps Ibn Zuhr's greatest contribution to medicine was his application of experimental method by introducing animal testing. He is known to have performed medical procedures on animals before doing them on humans to know if they would work. Most notable was his approval and recommendation for the surgical procedure of tracheotomy, which was a controversial procedure at the time. In trying to sort out the controversy, Ibn Zuhr described the following medical experiment which he performed on a goat:\n\"Earlier on in my training when I read those opinions (controversies), I cut on the lung pipe of a goat after incising the skin and the covering sheath underneath. Then I completely cut off the substance of the pipe, an area just less than the size of a tirmisah (lupine seed). Then, I kept washing the wound with water and honey till it healed and it (the animal) totally recovered and lived for a long time.\"\n\nIbn Abi Usaibia mentions these other works of Ibn Zuhr:\n\nThe Jewish physician-philosopher Maimonides admired Ibn Zuhr, describing him as \"unique in his age and one of the great sages\". He frequently quoted him in his medical texts. Averroes praised him as the greatest physician since Galen. Both his daughter and granddaughter also became physicians, specializing in obstetrics.\n\n\n"}
{"id": "211644", "url": "https://en.wikipedia.org/wiki?curid=211644", "title": "Intestinal parasite infection", "text": "Intestinal parasite infection\n\nAn intestinal parasite infection is a condition in which a parasite infects the gastro-intestinal tract of humans and other animals. Such parasites can live anywhere in the body, but most prefer the intestinal wall. \n\nRoutes of exposure and infection include ingestion of undercooked meat, drinking infected water, fecal-oral transmission and skin absorption. \n\nSome types of helminths and protozoa are classified as intestinal parasites that cause infection—those that reside in the intestines. These infections can damage or sicken the host (humans or other animals). If the intestinal parasite infection is caused by helminths, the infection is called helminthiasis.\n\nSigns and symptoms depend on the type of infection. Intestinal parasites produce a variety of symptoms in those affected, most of which manifest themselves in gastrointestinal complications and general weakness. Gastrointestinal complications include diarrhea, nausea, dysentery, and abdominal pain. These symptoms negatively impact nutritional status, including decreased absorption of micronutrients, loss of appetite, weight loss, and intestinal blood loss that can often result in anemia. It may also cause physical and mental disabilities, delayed growth in children, and skin irritation around the anus and vulva.\n\nThe prevalence of intestinal parasites is the highest among children that are living in the poorest communities in developing nations. The most common causes of intestinal parasites are through consumption of contaminated water, infected soil, inadequate sanitation and hygiene, and improper hygiene. Specifically, lack of access to facilities for safe disposal of human waste can result in intestinal parasites and disease. Poor hygiene habits or lacking available hygiene resources, such as hand washing facilities, also negatively impact rates of disease. Parasitic contamination can also occur from eating raw vegetables and fruits, soil-eating behaviour, and lack of available safe water. \n\nParasites can get into the intestine by going through the mouth from uncooked or unwashed food, contaminated water or hands, or by skin contact with larva infected soil; they can also be transferred by the sexual act of anilingus in some cases.\nWhen the organisms are swallowed, they move into the intestine, where they can reproduce and cause symptoms. Children are particularly susceptible if they are not thoroughly cleaned after coming into contact with infected soil that is present in environments that they may frequently visit such as sandboxes and school playgrounds. People in developing countries are also at particular risk due to drinking water from sources that may be contaminated with parasites that colonize the gastrointestinal tract.\n\nDue to the wide variety of intestinal parasites, a description of the symptoms rarely is sufficient for diagnosis. Instead, medical personnel use one of two common tests: they search stool samples for the parasites, or apply an adhesive to the anus to search for eggs.\nMajor groups of parasites include protozoans (organisms having only one cell) and parasitic worms (helminths). Of these, protozoans, including cryptosporidium, microsporidia, and isospora, are most common in HIV-infected persons. Each of these parasites can infect the digestive tract, and sometimes two or more can cause infection at the same time.\n\nGood hygiene is necessary to avoid reinfection. The Rockefeller Foundation's hookworm campaign in Mexico in the 1920s was extremely effective at eliminating hookworm from humans with the use of anthelmintics. However, preventative measures were not adequately introduced to the people that were treated. Therefore, the rate of reinfection was extremely high and the project evaluated through any sort of scientific method was a marked failure. More education was needed to inform the people of the importance of wearing shoes, using latrines (better access to sanitation), and good hygiene.\n\nIntestinal parasite prevention methods are not isolated to specific geographical areas; however, many of the research-based interventions have primarily taken place in underdeveloped countries and regions, where sanitation is a large concern for spreading disease.Current best practice behaviors that prevent intestinal parasites include: using proper hand washing practices, using correctly-built latrines with ample ventilation, having a piped water source, and wearing shoes. Currently, in some parts of Ethiopia where disease prevalence is high, up to 80% of people in a population lack access to washing facilities. While this is high, 93% did have access to a latrine, but only 29.2% of those latrines had proper construction to decrease parasitic infections.Behavioral interventions have focused on promoting washing, sometimes with soap, in context of education at schools and child care facilities. In recent studies, the best interventions follow a multidisciplinary approach by:\nSpecific evidence-based interventions that may lower disease prevalence include:\n\n\nDrugs are frequently used to kill parasites in the host. In earlier times, turpentine was often used for this, but modern drugs do not poison intestinal worms directly. Rather, anthelmintic drugs now inhibit an enzyme that is necessary for the worm to make the substance that prevents the worm from being digested.\n\nFor example, tapeworms are usually treated with a medicine taken by mouth. The most commonly used medicine for tapeworms is praziquantel.\n"}
{"id": "33522732", "url": "https://en.wikipedia.org/wiki?curid=33522732", "title": "Kent Holtorf", "text": "Kent Holtorf\n\nKent Holtorf (born 1964) is an American physician and entrepreneur practicing in Los Angeles, California. He is a board examiner of the American Board of Anti-Aging Medicine (ABAAM), which is not recognized by established medical organizations. He is the founder and medical director of Holtorf Medical Group, a practice with five centers that offer treatment for conditions including fibromyalgia, adrenal fatigue (a non-existent condition), complex endocrine dysfunction, hypothyroidism, age management, chronic fatigue syndrome, low libido, chronic Lyme disease, migraines, PMS, perimenopause and menopause. His practice focuses on alternative therapies that are not recognised as effective. He has been criticized in the media for his controversial views on topics like bioidentical hormone replacement therapy and vaccines.\n\nHoltorf is a graduate of the University of California at Los Angeles. He is also a graduate of the St. Louis University School of Medicine, where he received his doctorate of medicine then returned to UCLA for residency training. He has maintained a clinical practice since 1994 and is a former medical director of the Fibromyalgia and Fatigue Centers, Inc. (FFC). Holtorf has published a number of endocrine reviews on complex topics in peer-reviewed journals on controversial diseases and treatments. He is a guest editor and peer-reviewer for a number of medical journals including \"Endocrine\", is the current AOL Health Expert in Endocrinology, and is a diplomate and board examiner of the American Board of Anti-Aging Medicine (ABAAM). He is a founding member of The Bioidentical Hormone Initiative (BHI), and a founder and director of the National Academy of Hypothyroidism (NAH). In 2001, Holtorf established the Holtorf Medical Group.\n\nHoltorf has been the subject of criticism online and in the media for several years for his promotion of controversial diagnostic methods. He has been an advocate of bioidentical hormones, which has been labeled as quack medicine. He published an extensive review on the safety and efficacy of bioidentical hormones in the peer-reviewed journal \"Post Graduate Medicine\". The review concluded, “Physiological data and clinical outcomes demonstrate that bioidentical hormones are associated with lower risks, including the risk of breast cancer and cardiovascular disease, and are more efficacious than their synthetic and animal derived counterparts. Until evidence is found to the contrary, bioidentical hormones remain the preferred method of HRT. Further randomized controlled trials are needed to delineate these differences more clearly.” The conclusions were contrary to mainstream opinions on the use of bioidentical hormones. Additionally, many argue that the extensive use of compounded bioidentical hormones is risky because they can be inconsistent and unstable and are not always subject to FDA oversight.\n\nHoltorf has also taken an unpopular stance that children are over vaccinated and that vaccines may be associated with autism. Televised appearances and interviews have put Holtorf's views front and center and invited criticism and debate. Among them, his 2009 appearance on \"Fox News\" in regards to the H1N1 vaccine, in which Holtorf plainly states he \"definitely would not\" administer the controversial vaccine to his own children, is one of the most highly deliberated. Holtorf likewise links high levels of vaccine adjuncts, such as mercury, to some cases of autism development in children during the interview and is questionably identified on the program as an infectious disease expert. This view is contrary to the position statements of agencies such as the Center for Disease Control and the Institute of Medicine, and societies such as the American Academy of Pediatrics, who state that there is no credible evidence that vaccines have any link to autism.\n\nHoltorf states that the standard thyroid tests which are typically relied upon by primary care and specialist physicians to diagnosis hypothyroidism (low thyroid) and determine dosage are insufficient because they focus on TSH levels as an indicator of thyroid function and miss a large percentage of people with low thyroid. This is discussed extensively on the website of his nonprofit organization the National Academy of Hypothyroidism. Instead, Holtorf advocates labs and diagnostics which look at all thyroid hormone levels, with a particular emphasis on free T3, triodothyronine, the active hormone both produced by the thyroid and converted from T4, levothyroxine, and reverse T3, a metabolite of T4 conversion usually created during times of stress or trauma. This is contrary to position statements by societies such as the American Thyroid Association and American Association of Clinical Endocrinologist. Holtorf condones treating hypothyroidism with compounded combinations of bioidentical thyroid hormones.\n\nChronic Fatigue Syndrome (CFS) and fibromyalgia are two separate disorders that share many overlapping symptoms and are often cross-diagnosed. FDA approved therapies for the treatment of fibromyalgia include Cymbalta (duloxetine hydrochloride), Lyrica (pregabalin), and Savella (milnacipran HCL); while there are no FDA approved medications for the treatment of chronic fatigue syndrome. Other medications that are commonly used include tryicylcic antidepressants, SSRI antidepressants, Nonsteroidal anti-inflammatory drugs (NSAIDs) and muscle relaxants. In contrast, Dr Holtorf advocates a controversial six step plan that involves the treatment of hormone imbalances, mitochondrial dysfunction, sleep disturbances, and chronic infections.\n\nThe Infectious Disease Society of America states that Lyme disease is easily treated with a few weeks of antibiotics and that chronic Lyme disease does not exist. Their position is that standard blood tests are an accurate means of determining the presence of Lyme disease.\n\nHoltorf maintains a controversial stance that weight loss is not an issue of diet and exercise, citing causes for the inability to lose weight as leptin resistance, undiagnosed hypothyroidism, environmental toxins, hypometabolism and dysfunctional weight set-point.\n\nLeptin resistance is described as a condition in which overweight individuals are unable to respond to the hormone’s signals appropriately, leading to a starvation response in the body as well as hypothyroid symptoms at the cellular level where they are more difficult to detect. Holtorf treats leptin resistance in patients with a class of medications that are typically reserved for controlling blood sugar levels in diabetics.\n\nA suppressed or \"wrecked\" metabolism is another cause of obesity commonly cited by Holtorf. Holtorf claims the metabolism, when subjected to repeated or overzealous dieting and exercise, will regulate itself by repressing thyroid hormone levels in the body, resulting in a hypothyroid state. Even the return to normal intake of food or levels of exercise will not be substantial enough to return the metabolism to its previous state. According to his website, holtorfmed.com, this leads to a permanently or chronically suppressed metabolism and Holtorf issues metabolic testing for patients exhibiting metabolism suppression, as well as labs denoting thyroid and other hormone levels.\n\nSet-Point malfunction is another theory proposed and supported by Holtorf, which suggests that the body is programmed to return to a set weight and that this point can be altered by numerous medications, resulting in weight gain. Holtorf prescribes naltrexone, an opioid receptor blocker, used most often to treat opiate addiction, and buproprion (Wellbutrin), a common antidepressant, to reduce the body's set-point.\n\n"}
{"id": "35139438", "url": "https://en.wikipedia.org/wiki?curid=35139438", "title": "Lake Tarnobrzeg", "text": "Lake Tarnobrzeg\n\nLake Tarnobrzeg, Machowski Reservoir or Lake Machów is an artificial lake created in a former sulfur mine in Machów, Tarnobrzeg, Poland.\n\nThe lake was opened in 2010 after 16 years of construction and landscaping. The re-cultivation work began in the old mine in 1994. The total cost of changing post the industrial area into lake totaled 1.5 billion PLN. The project was paid for by the State Treasury.\n\nIn 2011 the Tarnobrzeg City Council, together with the Mayor of Tarnobrzeg, interpellated with the Polish Ministry of the Interior and Administration to change the official name to Lake Tarnobrzeg.\n\n"}
{"id": "31914184", "url": "https://en.wikipedia.org/wiki?curid=31914184", "title": "List of rampage killers (Americas)", "text": "List of rampage killers (Americas)\n\nThis section of the list of rampage killers contains those cases that occurred in the Americas.\n\nThis section does not include school massacres; workplace killings; religious, political, or racial crimes; or mass murders that took place primarily in a domestic environment, like familicides, which are covered in their own categories. Cases where the primary motive for the murders was to facilitate or cover up another felony, like robbery, are also excluded.\n\nA rampage killer has been defined as follows:\nThis list should contain every case with at least one of the following features:\nW – A basic description of the weapons used in the murders\n"}
{"id": "12500545", "url": "https://en.wikipedia.org/wiki?curid=12500545", "title": "Lower Nihotupu Reservoir", "text": "Lower Nihotupu Reservoir\n\nThe Lower Nihotupu Reservoir (or Lower Nihotupu Dam) is one of five reservoirs in the Waitakere Ranges that supply water to Auckland. Built between 1945 and 1948, the reservoir covers an area of 52.9 hectares and has a capacity of 4.6 million cubic metres. The reservoir is managed by Water Care Services Limited, a council-owned company.\n\nThe dam is credited as one of the first applied examples of the soil mechanics science in New Zealand, and was soon followed by the creating of engineering geology as a major subject at the School of Engineering, Auckland.\n"}
{"id": "6175096", "url": "https://en.wikipedia.org/wiki?curid=6175096", "title": "Majewski's polydactyly syndrome", "text": "Majewski's polydactyly syndrome\n\nMajewski's polydactyly syndrome, also known as polydactyly with neonatal chondrodystrophy type I, short rib-polydactyly syndrome type II, and short rib-polydactyly syndrome, is a lethal form of neonatal dwarfism characterized by osteochondrodysplasia (skeletal abnormalities in the development of bone and cartilage) with a narrow thorax, polysyndactyly, disproportionately short tibiae, thorax dysplasia, hypoplastic lungs and respiratory insufficiency. Associated anomalies include protruding abdomen, brachydactyly, peculiar faces, hypoplastic epiglottis, cardiovascular defects, renal cysts, and also genital anomalies. Death occurs before or at birth.\n\nThe disease is inherited in an autosomal recessive pattern.\n\nIt was characterized in 1971.\n"}
{"id": "48528252", "url": "https://en.wikipedia.org/wiki?curid=48528252", "title": "Manchester Cancer Research Centre", "text": "Manchester Cancer Research Centre\n\nThe Manchester Cancer Research Centre (MCRC) was established in 2006 by the University of Manchester, Cancer Research UK and The Christie NHS Foundation Trust. It has since been expanded through the Manchester Academic Health Science Centre to include Central Manchester University Hospitals NHS Foundation Trust, Salford Royal NHS Foundation Trust, University Hospital of South Manchester NHS Foundation Trust, Manchester Mental Health and Social Care Trust and Salford Clinical Commissioning Group.\n\n"}
{"id": "357632", "url": "https://en.wikipedia.org/wiki?curid=357632", "title": "Mating", "text": "Mating\n\nIn biology, mating (or mateing in British English) is the pairing of either opposite-sex or hermaphroditic organisms, usually for the purposes of sexual reproduction. Some definitions limit the term to pairing between animals, while other definitions extend the term to mating in plants and fungi. \"Fertilization\" is the fusion of both sex cell or gamete. \"Copulation\" is the union of the sex organs of two sexually reproducing animals for insemination and subsequent internal fertilization. Mating may also lead to external fertilization, as seen in amphibians, fishes and plants. For the majority of species, mating is between two individuals of opposite sexes. However, for some hermaphroditic species, copulation is not required because the parent organism is capable of self-fertilization (autogamy); for example, banana slugs.\n\nThe term \"mating\" is also applied to related processes in bacteria, archaea and viruses. Mating in these cases involves the pairing of individuals, accompanied by the pairing of their homologous chromosomes and then exchange of genomic information leading to formation of recombinant progeny (see mating systems).\n\nFor animals, mating strategies include random mating, disassortative mating, assortative mating, or a mating pool. In some birds, it includes behaviors such as nest-building and feeding offspring. The human practice of mating and artificially inseminating domesticated animals is part of animal husbandry.\n\nIn some terrestrial arthropods, including insects representing basal (primitive) phylogenetic clades, the male deposits spermatozoa on the substrate, sometimes stored within a special structure. Courtship involves inducing the female to take up the sperm package into her genital opening without actual copulation. In groups such as dragonflies and many spiders, males extrude sperm into secondary copulatory structures removed from their genital opening, which are then used to inseminate the female (in dragonflies, it is a set of modified sternites on the second abdominal segment; in spiders, it is the male pedipalps). In advanced groups of insects, the male uses its aedeagus, a structure formed from the terminal segments of the abdomen, to deposit sperm directly (though sometimes in a capsule called a \"spermatophore\") into the female's reproductive tract.\n\nOther animals reproduce sexually with external fertilization, including many basal vertebrates. Vertebrates (such as reptiles, some fish, and most birds) reproduce with internal fertilization through cloacal copulation (see also hemipenis), while mammals copulate vaginally.\n\nLike in animals, mating in other Eukaryotes, such as plants and fungi, denotes . However, in vascular plants this is mostly achieved without physical contact between mating individuals (see pollination), and in some cases, e.g., in fungi no distinguishable male or female organs exist (see isogamy); however, mating types in some fungal species are somewhat analogous to sexual dimorphism in animals, and determine whether or not two individual isolates can mate. \"Yeasts\" are eukaryotic microorganisms classified in the kingdom Fungi, with 1,500 species currently described. In general, under high stress conditions like nutrient starvation, haploid cells will die; under the same conditions, however, diploid cells of \"Saccharomyces cerevisiae\" can undergo sporulation, entering sexual reproduction (meiosis) and produce a variety of haploid spores, which can go on to mate (conjugate) and reform the diploid.\n\nProtists are a large group of diverse eukaryotic microorganisms, mainly unicellular animals and plants, that do not form tissues. Eukaryotes emerged in evolution more than 1.5 billion years ago. The earliest eukaryotes were likely protists. Mating and sexual reproduction are widespread among extant eukaryotes including protists such as \"Paramecium\" and \"Chlamydomonas\". In many eukaryotic species, mating is promoted by sex pheromones including the protist \"Blepharisma japonicum.\" Based on a phylogenetic analysis, Dacks and Roger proposed that facultative sex was present in the common ancestor of all eukaryotes.\n\nHowever, to many biologists it seemed unlikely until recently, that mating and sex could be a primordial and fundamental characteristic of eukaryotes. A principal reason for this view was that mating and sex appeared to be lacking in certain pathogenic protists whose ancestors branched off early from the eukaryotic family tree. However, several of these protists are now known to be capable of, or to recently have had, the capability for meiosis and hence mating. To cite one example, the common intestinal parasite \"Giardia intestinalis\" was once considered to be a descendant of a protist lineage that predated the emergence of meiosis and sex. However, \"G. intestinalis\" was recently found to have a core set of genes that function in meiosis and that are widely present among sexual eukaryotes. These results suggested that \"G. intestinalis\" is capable of meiosis and thus mating and sexual reproduction. Furthermore, direct evidence for meiotic recombination, indicative of mating and sexual reproduction, was also found in \"G. intestinalis\". Other protists for which evidence of mating and sexual reproduction has recently been described are parasitic protozoa of the genus \"Leishmania\", \"Trichomonas vaginalis\", and acanthamoeba.\n\nProtists generally reproduce asexually under favorable environmental conditions, but tend to reproduce sexually under stressful conditions, such as starvation or heat shock.\n\n\n"}
{"id": "25989634", "url": "https://en.wikipedia.org/wiki?curid=25989634", "title": "Mohammed Bello Abubakar", "text": "Mohammed Bello Abubakar\n\nMuhammadu Bello Abubahkar Masaba Bida also known as Mohammed Bello Abubakar (28 January 1924-28 January 2017) was born in Nigeria. Masaba is known for having stirred up controversy in his hometown Bida, Niger State due to his extensive polygamy, and for being outspoken, he was uncharged under Sharia law and sent to prison in 2008 for refusing to divorce 82 of his wives. Islam limits the number of wives a Muslim man can have to four, mandating they must be all treated equally. He married 120 wives, divorced 10, and fathered 203 children. At the time of his death in 2017, some of his wives were believed to be pregnant. \n\nMasaba was as a teacher and Imam. He lived in an entire apartment block with his family. Masaba claimed that he never pursued his wives, and that he was sought by them due to his reputation as a healer. Most of his wives were younger than 30 years of age, and a few younger than his elder children. In interviews with Al Jazeera English, his wives claimed that he was a good husband and father. \n\nThe Quran states that a man may marry up to four wives mandating they must be all treated equally. Masaba claimed that when the Quran set a law, it must also set a punishment for offenders, and no punishment was given for this offense.\n\nDuring a prison interview Masaba told The Christian Science Monitor:\n\n\"If God permits me, I will marry more than 86 wives. A normal human being could not marry 86 – but I can only by the grace of God, I married 86 women and there is peace in the house – if there is peace, how can this be wrong?\"\n\nAfter the death pronouncement on him by the Islamic group, Jama'atu Nasiru-l Islam (JNI), the Bida Emirate Council and an assembly of Islamic leaders invited Masaba for interrogation. Deliberations were given in Etsu Nupe's palace Bida and the Etsu Nupe of Bida, Alhaji Yahya Abubakar read out a veredict saying that Masaba should divorce 82 of the 86 wives within 48 hours or leave the entire Nupe Kingdom as his safety could not be guaranteed within the kingdom. At the expiration of the ultimatum, Masaba refused to divorce any of his wives and denied ever promising this.\nIn 2008 Bello was arrested by Islamic authorities and tried before a Sharia court. Before his trial at the Sharia court, Police in Niger State gave him a clean bill, as the state command declared that nothing incriminating was found in his house. The leader of the police team, that arrested the Islamic cleric in Bida before 27 September 2008, Deputy Commissioner of Police, Mr John Olayemi declared:\n\n\"We found nothing incriminating in his house. There was no knife, no pistol or skull in his house when we went to invite him to the headquarters for a chat.\"Olayemi explained that the command of arresting Masaba acted on an instrument of Upper Sharia Court.\n\nIn October 6,2008, while in detention in Minna Prison, an Upper Sharia Court Judge in Minna, Alhaji Abdulmalik Imam, transferred Masaba's case to a Chief Magistrate's Court in Minna after admitting lacking jurisdiction. Masaba was still remanded in prison custody at the instance of the Sharia Court.\n\nThousands of protestors gathered to protest against his actions, and claimed that if he were released, they would not allow him to return to his home. His wives announced their outrage at his arrest. Due to his persistent refusal to divorce 82 of his wives during his trial ,he was sentenced to death. The sentence was lifted in early September 2008. Masaba still faced eviction from his home. The case was reported globally and throughout Nigeria, angering many Nigerian Muslims. \n\nFollowing the case, Masaba told the BBC:\n\n\"A man with ten wives would collapse and die, but my own power is given by Allah. That is why I have been able to control 86 of them,\" \n\nOn 12 November 2008, a Federal High Court sitting in Maitama, Abuja ordered the release of Masaba from detention in Minna Prison with immediate effect. The trial high court judge, Justice G.O. Kolawole attached no condition to his release. The judge also ordered the Inspector General of Police, Mr Mike Okiro, to ensure the protection of Masaba's fundamental rights to life, liberty and privacy, as enshrined in the 1999 constitution of Nigeria, through the Niger State Commissioner of Police. Masaba returned to his hometown, Bida, on 13 November 2008.\n\nIn July 2011, Dr. Muazu Babangida Aliyu, the governor of Niger State said \"though we have Sharia in place in the state, but we have no law to pin him down\". Niger State government's effort to prosecute Masaba , were unsuccessful because of legal lacuna. The Speaker of Niger State House of Assembly, Barrister Adamu Usman, disclosed that various attempts to prosecute Masaba ran into hitches because there was no provision in the law of the state to effect his prosecution.\n\nBarrister Adamu Usman said:\n\"As Attorney General then I personally appeared before Sharia court, Minna, as prosecutor to prosecute the man but later discovered that Sharia courts in Niger State cannot deal with the case. No provision made in Penal code C.P.C or Sharia administration of Justice law to deal with such cases.\"\n\nMasaba is frequently depicted by the media as \"the man with 86 wives.\" Contrary to some media reports, that Masaba divorced 82 out of his 86 wives, he refused to divorce any of his wives.\n\nRecently Masaba has reappeared in articles concerning an alleged plot to disenfranchise his family. Members of his family were prevented by thugs from registering to vote. Nine members of the Masaba family were injured by thugs whenever they attempted to register to vote.\n\nAfter a Federal High Court sitting in Abuja ordered the release of Masaba from detention, he had 18 more children, having a total of 138 . Masaba came into limelight with another super polygamist, Ziona Chana of India in 2011. As of May 2011, Masaba had 89 wives and 133 children while India's Ziona Chana had 39 wives, 94 children and 33 grandchildren.\n\nIn June 2012, Masaba had an interview with Jide Orintunsin where he debunked his rumoured death and said: \"Large number of wives? I only have 97 wives. I am still going to marry more. I will keep marrying them for as long I am alive. Whoever is fighting me because of my wives or love life. Such an individual has missed it. Left for me, I would have married maybe two wives, but what I am doing is divine. It is an assignment and I will keep marrying till the end of time. I just want to advise those fighting against the number of my wives to stop because such people are waging war against God, their creator.\"\n"}
{"id": "236300", "url": "https://en.wikipedia.org/wiki?curid=236300", "title": "Morning sickness", "text": "Morning sickness\n\nMorning sickness, also called nausea and vomiting of pregnancy (NVP), is a symptom of pregnancy that involves nausea or vomiting. Despite the name, nausea or vomiting can occur at any time during the day. Typically these symptoms occur between the 4th and 16th week of pregnancy. About 10% of women still have symptoms after the 20th week of pregnancy. A severe form of the condition is known as hyperemesis gravidarum and results in weight loss.\nThe cause of morning sickness is unknown but may be related to changing levels of the hormone human chorionic gonadotrophin. Some have proposed that it may be useful from an evolutionary point of view. Diagnosis should only occur after other possible causes have been ruled out. Abdominal pain, fever, or headaches are typically not present in morning sickness.\nTaking prenatal vitamins before pregnancy may decrease the risk. Specific treatment other than a bland diet may not be required for mild cases. If treatment is used the combination of doxylamine and pyridoxine is recommended initially. There is limited evidence that ginger may be useful. For severe cases that have not improved with other measures methylprednisolone may be tried. Tube feeding may be required in women who are losing weight.\nMorning sickness affects about 70-80% of all pregnant women to some extent. About 60% of women have vomiting. Hyperemesis gravidarum occurs in about 1.6% of pregnancies. Morning sickness can negatively affect quality of life, result in decreased ability to work while pregnant, and result in health care expenses. Generally mild to moderate cases have no effect on the baby. Most severe cases also have normal outcomes. Some women choose to have an abortion due to the severity of symptoms. Complications such as Wernicke encephalopathy or esophageal rupture may occur but are very rare.\n\nAbout 66% of women have both nausea and vomiting while 33% have just nausea.\n\nThe cause of morning sickness is unknown. While some have claimed it to be due to psychological reasons, this is not supported by evidence.\n\nNausea and vomiting may also occur with molar pregnancy.\n\n\nMorning sickness may be an evolved trait that protects the baby against toxins ingested by the mother. Evidence in support of this theory includes:\n\nWomen who have \"no\" morning sickness are more likely to miscarry. This may be because such women are more likely to ingest substances that are harmful to the fetus.\n\nIn addition to protecting the fetus, morning sickness may also protect the mother. A pregnant woman's immune system is suppressed during pregnancy, presumably to reduce the chances of rejecting tissues of her own offspring. Because of this, animal products containing parasites and harmful bacteria can be especially dangerous to pregnant women. There is evidence that morning sickness is often triggered by animal products including meat and fish.\n\nIf morning sickness is a defense mechanism against the ingestion of toxins, the prescribing of anti-nausea medication to pregnant women may have the undesired side effect of causing birth defects or miscarriages by encouraging harmful dietary choices.\n\nThere is a lack of good evidence to support the use of any particular intervention for morning sickness.\n\nA number of antiemetics are effective and safe in pregnancy including: pyridoxine/doxylamine, antihistamines (such as diphenhydramine), metoclopramide, and phenothiazines (such as promethazine). With respect to effectiveness it is unknown if one is superior to another. In the United States and Canada, the doxylamine-pyridoxine combination (as Diclegis in US and Diclectin in Canada) is the only approved pregnancy category \"A\" prescription treatment for nausea and vomiting of pregnancy.\n\nOndansetron may be beneficial, but there are some concerns regarding an association with cleft palate, and there is little high quality data. Metoclopramide is also used and relatively well tolerated. Evidence for the use of corticosteroids is weak.\n\nSome studies support the use of ginger, but overall the evidence is limited and inconsistent. Safety concerns have been raised regarding its anticoagulant properties.\n\nThalidomide was originally developed and prescribed as a cure for morning sickness in West Germany, but its use was discontinued when it was found to cause birth defects. The United States Food and Drug Administration never approved thalidomide for use as a cure for morning sickness.\n"}
{"id": "27143571", "url": "https://en.wikipedia.org/wiki?curid=27143571", "title": "National Surgical Quality Improvement Program", "text": "National Surgical Quality Improvement Program\n\nThe American College of Surgeons National Surgical Quality Improvement Program (ACS NSQIP) was started in the American Veterans Health Administration (VHA). In the mid-1980s the VHA was criticized for their high operative mortality. To that end, Congress passed Public Law 99-166 in December 1985 which mandated the VHA to report their outcomes in comparison to national averages and the information must be risk-adjusted to account for the severity of illness of the VHA surgical patient population. In 1991 the National VA Surgical Risk Study (NVASRS) began in 44 Veteran's Administration Medical Centers. By 31 December 1993 there was information for 500,000 non-cardiac surgical procedures. In 1994 NVASRS was expanded to all 128 HVA hospitals that performed surgery. The name was then changed to the National Surgical Quality Improvement Program.\n\nThe ACS NSQIP collects data on 135 variables, including preoperative risk factors, intraoperative variables, and 30-day postoperative mortality and morbidity outcomes for patients undergoing major surgical procedures in both the inpatient and outpatient setting.\n"}
{"id": "1183023", "url": "https://en.wikipedia.org/wiki?curid=1183023", "title": "Nicholas Green", "text": "Nicholas Green\n\nNicholas Green (September 9, 1987 – October 1, 1994) was an Anglo-American boy who was shot and killed in an attempted car robbery while vacationing with his family in Southern Italy. Robbers mistook their family car for a jeweller's. When Nicholas died, his parents chose to donate his organs. Five people received his major organs, and two received a cornea transplant. The incident is credited with generating a significant increase in the rate of organ donation in Italy.\n\nNicholas Green, his sister, Eleanor Green, and their parents, Margaret and Reginald Green, were having a holiday in Calabria, Southern Italy. On the night of September 29, 1994 his parents were driving on the A3 motorway between Salerno and Reggio Calabria. They stopped at an Autogrill, where two men started following their car, believing they were jewellers. The men pulled up alongside the Greens' vehicle and shouted something in Italian, which the Greens did not understand. Reginald Green accelerated, at which point the men fired shots into the rear of the car. He accelerated a second time, and once again the men shot into the back of the car. After the pursuers gave up Reginald stopped the car, and at this point he and Margaret realized that Nicholas had been shot in the head. They drove directly to the nearest town, but the hospital was not equipped to deal with Nicholas' injuries. The police took the family to Villa San Giovanni, where they transferred to a ferry which brought them across the Strait of Messina to the port of Messina. From there, the police took them to a specialist head injuries unit at a nearby hospital, where he was pronounced dead the next day.\nIn May 1996 the Greens had twins, a girl (Laura) and a boy (Martin). Since their loss, the Greens have been strong supporters of organ donation and they have been traveling throughout the world to spread the message of donation and tell their story.\n\nFollowing their decision of donating Nicholas' organs, Nicholas' parents were received by Italy's President (Oscar Luigi Scalfaro). They were awarded Italy's highest honour for civilians \"Medaglia d'Oro al Merito Civile\". After Nicholas' death, donation rates increased dramatically in Italy, a country where organ donations had been among the lowest in Europe. According to 2017 data, organ donations in Italy have more than tripled since. Many elementary schools as well as city locations/addresses all over the country were named after Nicholas.\n\nFollowing the shooting, Italian police arrested two men on November 2, 1994, Francesco Mesiano and Michele Iannello. They were tried in Catanzaro by a court consisting of three judges, and on January 17, 1997 they were found not guilty. Reginald Green had been unable to identify them, as the shooters had both been wearing masks, and it was dark. However, a year later, with no new evidence, an appellate court with a jury convicted the pair. Iannello was sentenced to life imprisonment and Mesiano was sentenced to 20 years. This decision was upheld by Italy's supreme court in 1999.\n\nAfter Nicholas' death, donation rates increased dramatically in Italy, a country where organ donations had been among the lowest in Europe. According to 2017 data, organ donations in Italy have more than tripled since. Nicholas' name continues to be associated with organ donation, and is acknowledged as the most famous organ donor in the world. The result of his parents' decision has been called \"The Nicholas Effect\" (l'Effetto Nicholas) and refers not only to organ donation but also to everything good that emerged from the tragedy.\n\nA memorial bell tower (The Children's Bell Tower) has been built in Bodega Bay in memory of Nicholas Green and all the children, using more than 140 bells sent to the Greens from individuals, families, schools, and churches all over Italy. The monument, set in Bodega Bay, where Nicholas and his family lived, has become a place of pilgrimage as well as a tourist attraction. The central bell, donated by the Marinelli Foundry, that has been making bells for the Papacy for more than 1000 years, was blessed by Pope John Paul II. It has the names of the seven recipients of Nicholas' organs inscribed on it. The monument is the work of San Francisco sculptor Bruce Hasson.\n\nAnother sculpture, called \"The Birds\", has been donated by the Greens to the Calabria Region and is located at the Regional Council Palace. It depicts seven birds (like Nicholas' organs that were donated and the number of the recipients) made of steel, floating in a sort of tower. This monument is also the work of Bruce Hasson. He used the steel of guns confiscated by the San Francisco Police Department.\n\nAn educational video has been made out of their story, called 'The Nicholas Effect'. It is currently shown in hospitals all around the United States and is used by procurement organizations, hospitals, churches, to spread a message of solidarity and the importance of donation. It tells the story of Nicholas, how his organs saved the lives of seven very sick Italians, and how this thing changed the attitude of a whole Country towards organ donation.\nSince Nicholas died, organ donation rates in Italy have more than tripled, bringing Italy from being at the bottom among European Countries in donation to one of the top of the list (currently Italy is second, after Spain, as far as organ donation rates).\n\nReginald Green wrote two books: the first called \"The Nicholas Effect\" (Il Dono di Nicholas, in Italiano) and the second called \"The Gift that Heals\" (Il Dono che Guarisce, in Italian), published jointly with UNOS (United Network for Organ Sharing) - the non-profit organization that manages the United States's organ transplant system under contract with the federal government.\nBoth books have been highly acclaimed by media and specialists of organ donation all around the world . They are used in nursing schools, hospitals, churches, since the books are considered a complete and useful work on organ donation. \nThe Greens also established an annual scholarship for primary and middle school children in the United States that is awarded to a distinguished student in each state. The award is managed by the NAGC (the National Association for Gifted Children).\n\nThe World Transplant Game Federation dedicated to Nicholas Green the ski race for transplanted children: it is the \"Nicholas Cup\". It has been held in Nendaz, Switzerland in 2001, Bormio in Northern Italy in 2004, Poland in 2005, Rovaniemi, Finland in 2008, Anzere, Switzerland in March 2012 and La Chapelle D'Abondance France in January 2014.\n\nIn 1998, a TV movie, \"Nicholas' Gift\", starring Jamie Lee Curtis and Alan Bates, was based on the event.\n\nSeveral schools, streets, gardens and squares in Italian cities have been named or renamed in honor of Nicholas Green. For the full list of places named for Nicholas Green in Italy and a map, visit https://nicholaseffect.org/places-named-for-nicholas-in-italy/\n\nThe Children's Bell Tower is located in Bodega Bay, off Route 1. GPS (N 38° 20.448 W 123° 03.126)\n"}
{"id": "47940049", "url": "https://en.wikipedia.org/wiki?curid=47940049", "title": "Nobukazu Kuriki", "text": "Nobukazu Kuriki\n\nKuriki was born in Imakane, Setana District, Hokkaido, Japan. He graduated from Hokkaido Hiyama Kita High School and Sapporo International University's Humanities and Sociology Department of Sociology.\n\nKuriki climbed the Himalayas at high altitude once or twice a year. He successfully climbed the 8000 meter peaks Cho Oyu in August 2007 and Dhaulagiri in May 2009. He tried to climb Mount Everest without oxygen while live streaming over the internet, climbing the Tibet side in September 2009, and the Nepal side in September 2010, but was not able to climb above 8,000 meters. In his third time climbing the Nepal side in August to October 2011, Kuriki was not able to reach 7,900 meters. During his fourth attempt in October 2012, he gave up due to the strong wind, and lost nine of his fingers to frostbite after spending two days in a snow hole at temperatures below -20°C. His 2015 attempt was prevented by the avalanche that struck Everest Base Camp that year, and his attempts in 2016 and 2017 were cut short by weather conditions.\n\nHe gave well-attended lectures across Japan on the theme of \"shared adventure\" and the value of perseverance, and attracted numerous social media followers with his online postings, including videos and photos of his climbs.\n\nKuriki successfully climbed the highest peaks of 6 continents (the Seven Summits) during his career, including Denali, Mount Aconcagua, Mount Elbrus, Mount Kilimanjaro, the Carstensz Pyramid, and Mount Vinson.\n\nHe was represented by the talent agency, Yoshimoto Creative Agency.\n\nIn May 2018, during his 8th attempt to climb Mount Everest, he died while descending from Camp Three after abandoning the attempt due to illness. He is survived by his father Toshio. \n\n"}
{"id": "8387592", "url": "https://en.wikipedia.org/wiki?curid=8387592", "title": "Nodding disease", "text": "Nodding disease\n\nNodding disease or nodding syndrome is a recent, little-known disease which emerged in Sudan in the 1960s. It is a mentally and physically disabling disease that only affects children, typically between the ages of 5 and 15. It is currently restricted to small regions in South Sudan, Tanzania, and northern Uganda. Prior to the South Sudan outbreaks and subsequent limited spread, the disease was first described in 1962 existing in secluded mountainous regions of Tanzania, although the connection between that disease and nodding syndrome was only made recently.\n\nChildren affected by nodding disease experience a complete and permanent stunting of growth. The growth of the brain is also stunted, leading to mental handicap. The disease is named for the characteristic, pathological nodding seizure, which often begins when the children begin to eat, or sometimes when they feel cold. These seizures are brief and halt after the children stop eating or when they feel warm again. Seizures in nodding disease span a wide range of severity. Neurotoxicologist Peter Spencer, who has investigated the disease, has stated that upon presentation with food, \"one or two [children] will start nodding very rapidly in a continuous, pendulous nod. A nearby child may suddenly go into a tonic–clonic seizure, while others will freeze.\" Severe seizures can cause the child to collapse, leading to further injury. Sub-clinical seizures have been identified in electroencephalograms, and MRI scans have shown brain atrophy and damage to the hippocampus and glia cells.\n\nIt has been found that no seizures occur when victims are given an unfamiliar or non-traditional food, such as chocolate.\n\nIt is currently not known what causes the disease, but it is believed to be connected to infestations of the parasitic worm \"Onchocerca volvulus\", which is prevalent in all outbreak areas, and a possible explanation involves the formation of antibodies against parasite antigen that are cross-reactive to leiomodin-1 in the hippocampus. \"O. volvulus\", a nematode, is carried by the black fly and causes river blindness. In 2004, most children suffering from nodding disease lived close to the Yei River, a hotbed for river blindness, and 93.7% of nodding disease sufferers were found to harbour the parasite — a far higher percentage than in children without the disease. A link between river blindness and normal cases of epilepsy, as well as retarded growth, had been proposed previously, although the evidence for this link is inconclusive. Of the connection between the worm and the disease, Scott Dowell, the lead investigator into the syndrome for the US Centers for Disease Control and Prevention (CDC), stated: \"We know that [\"Onchocerca volvulus\"] is involved in some way, but it is a little puzzling because [the worm] is fairly common in areas that do not have nodding disease\". Andrea Winkler, the first author of a 2008 Tanzanian study, has said of the connection: \"We could not establish any hint that \"Onchocerca volvulus\" is actually going into the brain, but what we cannot exclude is that there is an autoimmune mechanism going on.\" In the most severely affected region of Uganda, infection with microfilariae in epileptic or nodding children ranged from 70% to 100%.\n\nThe CDC is investigating a possible connection with wartime chemical exposure. The team is also investigating whether a deficiency in vitamin B (pyridoxine) could be a cause, noting the seizures of pyridoxine-dependent epilepsy and this common deficiency in disease sufferers. Older theories include a 2002 toxicology report that postulated a connection with tainted monkey meat, as well as the eating of agricultural seeds provided by relief agencies that were covered in toxic chemicals.\n\nDiagnosis is not very advanced and is based on the telltale nodding seizures of the victims. When stunted growth and mental disability are also present, probability of nodding syndrome is high. In the future, neurological scans may also be used in diagnosis. As there is no known cure for the disease, treatment has been directed at symptoms, and has included the use of anticonvulsants such as sodium valproate and phenobarbitol. Anti-malaria drugs have also been administered, to unknown effect.Most of the non communicable diseases are about lack of nutrients in the body, to this being that the nodding syndrome is non communicable without a clear cause, Moringa with 93 of the nutrients needed by the human body and selenim, are some foods that can help on boosting the immune system for adjunctive therapy (benefits of Moringa and benefits of selenium). These two can help in malnutrition, stroke, appetite some of the symptoms we see in nodding syndrome victims. , .\n\nNodding syndrome is debilitating both physically and mentally. In 2004, Peter Spencer stated: \"It is, by all reports, a progressive disorder and a fatal disorder, perhaps with a duration of about three years or more.\" While a few children are said to have recovered from it, many have died from the illness. Seizures can also cause children to collapse, potentially causing injury or death.\n\nWhile the majority of occurrences of the disease known as \"nodding syndrome\" have been relatively recent, it appears that the condition was first documented in 1962 in southern Tanzania. More recently, nodding syndrome had become most prevalent in South Sudan, where in 2003 approximately 300 cases were found in Mundri alone. By 2009, it had spread across the border to Uganda's Kitgum district, and the Ugandan ministry of health declared that more than 2000 children had the disease. As of the end of 2011, outbreaks were concentrated in Kitgum, Pader and Gulu. More than 1000 cases were diagnosed in the last half of that year.\n\nThere were further outbreaks in early 2012, in South Sudan, Uganda, and Tanzania.\n\nThe spread and manifestation of outbreaks may further be exacerbated due to the poor availability of health care in the region.\n\n"}
{"id": "53700734", "url": "https://en.wikipedia.org/wiki?curid=53700734", "title": "Pelvic lift", "text": "Pelvic lift\n\nPelvic lift (also known as pelvic tilt) is an exercise to strengthen the lower back, glute muscles, lower abdominal muscles, and maintain hip muscle balance. It does not require weights, although they can be placed on the stomach.\n\nThere are four steps in the exercise.\n\nThe pelvic floor is a “broad sling of muscles, ligaments and sheet-like tissues that stretch from your pubic bone at the front of your body, to the base of your spine at the back”.\n\nThe pelvic floor is resistant to stretch and weight as it bounces back. However, after carrying weight for long periods of time, it can become stretched. Additionally, weight on the pelvic floor can weaken its resistance and contribute to its loss of shape over time.\n\nPerforming this exercise routinely can strengthen glutes, abs, and lower back muscles. As a result, doctors may recommend pelvic lifts to reduce lower back pain, improve posture, and improve bladder control.\n"}
{"id": "1807772", "url": "https://en.wikipedia.org/wiki?curid=1807772", "title": "Pinhole glasses", "text": "Pinhole glasses\n\nPinhole glasses, also known as stenopeic glasses, are eyeglasses with a series of pinhole-sized perforations filling an opaque sheet of plastic in place of each lens. Similar to the workings of a pinhole camera, each perforation allows only a very narrow beam of light to enter the eye which reduces the size of the circle of confusion on the retina and increases depth of field. In eyes with refractive error, the result is often a sharper image. However, a second effect may appear at the common bridge between each two adjacent holes, whereby two different rays of light coming from the same object (but each passing through a different hole) are diffracted back toward the eye and onto different places on the retina. This leads to double vision (objects having doubled edges) around the rim of each hole the eye is not focussing on, which can make the overall image disturbing and tiring to look at for prolonged periods of time.\n\nUnlike conventional prescription glasses, pinhole glasses produce an image without the pincushion effect around the edges (which makes straight lines appear curved). While pinhole glasses are claimed to be useful for people who are both near- and far-sighted, they are not recommended for people with over 6 diopters of myopia. Additionally, pinhole glasses reduce brightness and peripheral vision, and thus should not be used for driving or when operating machinery.\n\nMerchants state that after prolonged use, the plastic grating should become easy to ignore. However, each time the user blinks, the horizontal lines of the grating will briefly appear to be thicker. This is because the eyelid moving over the pupil will reduce the amount of light falling onto the retina and thus will briefly remove the lateral inhibition effect which normally makes all the holes appear bigger (and the grating appear thinner). So, as long as the user keeps blinking, they will be constantly reminded of the dark grating covering their eyes.\n\nPinhole glasses have been marketed by various companies on the claim that—combined with certain eye exercises—they could permanently improve eyesight. However, no scientific evidence has been found to support these claims. Due to a lack of formal clinical studies to substantiate this type of claim by companies selling pinhole glasses, this type of claim is no longer allowed to be made in the United States under the terms of a legal settlement with the Federal Trade Commission.\n\nThe pinhole occluder, a device used by ophthalmologists and optometrists for diagnosis of refractive errors, works on the same principles, but is not intended for use outside of diagnosis.\n"}
{"id": "33746838", "url": "https://en.wikipedia.org/wiki?curid=33746838", "title": "Prospective payment system", "text": "Prospective payment system\n\nA prospective payment system (PPS) is a term used to refer to several payment methodologies for which means of determining insurance reimbursement is based on a predetermined payment regardless of the intensity of the actual service provided.\n\nIt includes a system for paying hospitals based on predetermined prices, from Medicare. Payments are typically based on codes provided on the insurance claim such as these:\n\n\nThe PPS was established by the Centers for Medicare and Medicaid Services (CMS), as a result of the Social Security Amendments Act of 1983, specifically to address expensive hospital care. Regardless of services provided, payment was of an established fee. The idea was to encourage hospitals to lower their prices for expensive hospital care. \n\nIn 2000, CMS changed the reimbursement system for outpatient care at Federally Qualified Health Centers (FQHCs) to include a prospective payment system for Medicaid and Medicare. Under this system, health centers receive a fixed, per-visit payment for any visit by a patient with Medicaid, regardless of the length or intensity of the visit. The per-visit rate for the Medicaid PPS is specific to the individual health center location. The rate is determined and updated by a financial accounting process conducted by State Medicaid agencies. The FQHC PPS rate for Medicare (previously called the All Inclusive Reimbursement Rate), in contrast, is fixed at the same level across different health centers. \n\nAside from FQHCs, other entities that provide outpatient services to Medicaid patients, that are also paid by a PPS methodology include:\n\n"}
{"id": "50411261", "url": "https://en.wikipedia.org/wiki?curid=50411261", "title": "Quiet Power: The Secret Strengths of Introverts", "text": "Quiet Power: The Secret Strengths of Introverts\n\nQuiet Power: The Secret Strengths of Introverts is a 2016 non-fiction book written by Susan Cain with Gregory Mone and Erica Moroz, and illustrated by Grant Snider.\n\n\"Quiet Power\" is an adaptation for children and teens, and for their educators and parents, of Cain's 2012 adult-audience book \".\"\n\nSusan Cain's 2012 book \"\" reached \"The New York Times\" best seller list and \"Time\" magazine's cover, and was the subject of one of the most-watched TED Talks. In 2015 Cain co-founded Quiet Revolution, a company that produces content, including online training courses for parents, about and for introverts. \"Quiet Power\" constitutes Cain's focus on introverted children and teens, especially in the context of schools, so that the next generation of introverts doesn't grow up feeling there is something wrong with them or repress their personality trait.\n\nCain's co-authors Erica Moroz and Gregory Mone are, respectively, a journalist and a writer of children's books; illustrator Grant Snider was discovered through his comics that were inspired by Cain's 2012 \"Quiet.\"\n\n\"Quiet Power\" discusses the distinction between introversion and shyness; deeper student engagement versus conventional expectations of class participation; speaking in front of groups; individual versus group work; introvert-friendly methods of structuring group work; and use of social media in education. The book focuses on shyness in addition to introversion, saying that shyness involves fear of social judgment. Cain says that while shyness may be something to overcome, introversion can be something to celebrate, adding that introspection tends to come with \"superpowers\" such as listening ability, empathy, deeper study, and longer focus. The book includes chapters on school, socializing, hobbies, and home, and incorporates firsthand accounts of introverted teens and of famous figures who have succeeded outside of their initial comfort zones.\n\nCain included new research in \"Quiet Power\" that was not present in the adult-audience \"Quiet,\" and recast it especially for 10- to 14-year-olds who would be less able than high schoolers to translate the workplace-oriented \"Quiet\" into their own world. The book also includes appendices for teachers and parents.\n\nSaying that adolescence is the hardest period in an introvert's life, Cain suggests that young introverts talk with others about their desired socializing style (to avoid misunderstandings), find activities about which they can be passionate (to motivate stepping outside their comfort zones), focus on their strengths (to remain true to themselves), and be open to extroverted people (as having complementary abilities).\n\nCain critiques schools' clustered desks, infatuation with group projects, and rewards for students who are quickest to speak. Cain instead favors recognition of deep focus and talent for listening with empathy and patience, noting that in the business world people don't read books together or write memos together. The Quiet Revolution (company) created a Quiet Schools Network to partner with educators to design techniques to develop the talents of introverted students, such as by beginning public speaking programs with lower-anxiety assignments and incrementally increasing challenges as the student progresses.\n\nCain encourages parents, first, to understand that introverts' nerve biologies react more strongly to stimulation, and that the reactions can be draining through no preference of their own. Also, Cain urges parents to help their children be \"intelligent consumers\" of social media with its constant personal evaluation, despite its enabling introverts to communicate \"without being at the party.\"\n\n\"Quiet Power\" started at #4 on \"The New York Times\" bestseller list (children's middle grade hardcover category).\n\n\n\"Further reading: (alphabetically)\"\n"}
{"id": "23605229", "url": "https://en.wikipedia.org/wiki?curid=23605229", "title": "RBM Partnership To End Malaria", "text": "RBM Partnership To End Malaria\n\nThe RBM Partnership To End Malaria (formerly Roll Back Malaria Partnership) is the largest global platform for coordinated action towards a world free from malaria.\n\nThe partnership includes organizations from malaria endemic countries, bilateral and multilateral development partners, organizations from the private sector, nongovernmental and community-based organizations, foundations, research and academic institutions.\n\nSince its inception in 1998, the RBM Partnership has played a role in global efforts that reduced malaria deaths by over 60% and saved 7 million lives.\n\nThe RBM Partnership Host is the United Nations Office for Project Services (UNOPS), an operational arm of the United Nations, supporting the implementation of its partners' peacebuilding, humanitarian, and development projects around the world. \n\n"}
{"id": "11519220", "url": "https://en.wikipedia.org/wiki?curid=11519220", "title": "Raúl Cuero", "text": "Raúl Cuero\n\nRaúl Gonzalo Cuero Rengifo (born in Buenaventura, Colombia) is an Colombian professor of microbiology. From 1988 through 2012 he was a professor at Prairie View A&M University researching biological resistance to ultraviolet light. The work was supported in part by NASA and led to at least one publication and patent. During this period, Colombian media portrayed Cuero as \"one of the greatest scientists in the world\" who was internationally acknowledged as one of the greatest Colombian inventors, stated he had over 100 publications in scientific journals, and claimed he had won a significant award from NASA. Since 2012, he has been the research director of International Park of Creativity, an organization of which he is the founder.\n\nIn 2013, an \"El Espectador\" investigation alleged Cuero's curriculum vitae mixed in trivial publications with his peer-reviewed work, listed publications that did not appear to exist, misstated his invention record and employment at NASA and possibly fabricated several awards and honors. This contradicted Cuero's reputation as a leading researcher. In a follow-up interview with the paper, Cuero clarified he had contracted with NASA, could not recall the origin of the award in question, stated that 11 of the 13 patents claimed on his CV were still going through the approval process, and confirmed he had five peer reviewed articles published in the past 14 years.\n\n"}
{"id": "43114158", "url": "https://en.wikipedia.org/wiki?curid=43114158", "title": "Roberts Rugh", "text": "Roberts Rugh\n\nRoberts Rugh, Ph.D. (16 April 1903 – 11 November 1978), radiation biologist and embryologist.\n\nRoberts Rugh was born to Arthur and Gertrude (Roberts) Rugh in Springfield, Ohio on April 16, 1903 and died on 11 November 1978 in Bethesda, Maryland.\nRugh married Harriette Sheldon on July 24, 1926 and the couple had two children, Mary Elizabeth (Rugh) Downs and William Arthur.\n\nRugh earned his A.B. (1926) from Oberlin College and his M.A. (1927) and Ph.D. (1935) from Columbia University.\n\nRoberts Rugh began his professional career as a faculty member at Lawrence College (1927-1928) and went on to teach at Hunter College (1929-1939) and New York University (1939-1948) before moving to Columbia University.\n\nAt Columbia, Rugh joined the Radiological Research Laboratory, College of Physicians and Surgeons. Here, he served as a Professor of Radiology (1948-1971) in addition to directing research on the effects of ionizing radiation (1948-1971) and serving as a senior medical consultant and lecturer (1971-1978). Rugh devoted many of his research pursuits in the field of embryology and published many papers and wrote several books on this topic.\nPhotograph shows Rugh at work.\n\n\nRugh also wrote a number of books, including: \n"}
{"id": "2424009", "url": "https://en.wikipedia.org/wiki?curid=2424009", "title": "Royal College of Physicians of Ireland", "text": "Royal College of Physicians of Ireland\n\nThe Royal College of Physicians of Ireland (RCPI), () is an Irish professional body dedicated to improving the practice of general medicine and related medical specialties, chiefly through the accreditation of physicians by examination.\n\nThe \"Royal\" in the title comes from the Royal Charters that were granted in 1667, by King Charles II of England, and in 1692, by King William III and Queen Mary II of England. It was known as the King and Queen's College of Physicians in Ireland until 1890 when, under charter of Queen Victoria, it adopted the present title.\n\nThe College was founded in 1654 by John Stearne, a professor and registrar of Trinity College, Dublin, for the purpose of regulating the practice of medicine in Ireland. Originally, it was called \"The Fraternity of Physicians of Trinity Hall\", as its first home was in a building called Trinity Hall, given to the Physicians by Trinity College.\n\nThe Royal Charter of 1692 made the Physicians independent of Trinity College but meant that they had to leave Trinity Hall. They then had no permanent home until the opening of Sir Patrick Dun's Hospital in 1812, when the College established its headquarters in some rooms in the hospital.\n\nIn 1860, the College purchased the premises of the Kildare Street Club in Kildare Street. The building was destroyed in a fire in November 1860 and subsequently rebuilt by the College to its own design. It opened in 1864 and has remained the College's home ever since.\n\nThe College Library dates its foundation to 1713 when Sir Patrick Dun bequeathed his personal, large library to the College. The Library has been known as \"Dun's Library\" ever since. The Dun's Library forms part of the College's Heritage Centre, with the archive, heritage items and genealogical research collections. The Heritage Centre holds one of the most important and extensive collections of printed, manuscript material and items relating to the history of medicine and medical education in Ireland.\n\nAmong the famous past presidents of the College were William Fetherstone Montgomery, Sir Patrick Dun (1681–93), Henry Marsh (1841), Robert James Graves (1843), William Stokes (1849), and Sir Dominic Corrigan (1859–1863). James Little (1837–1916), who was president from 1886 to 1888, had worked as a ship's surgeon early in his career. He survived the shipwreck of the SS \"Ava\" in 1858, which is recorded in his diary, now held in the college's archives. \n\nIn November 1974 Irish president Erskine Hamilton Childers made a speech to psychiatrists at the Royal College of Physicians about alternative treatments for mentally ill people. And means to be made available for people who were suffering from depression and anxiety and other such disorders Before he himself suddenly collapsed dead of heart failure in the very conference room of the building \n\n\nThe College offers the postgraduate Membership of the Royal College of Physicians of Ireland (MRCPI) qualification. There is a separate and distinct Membership of the Royal College of Physicians (MRCPUK) qualification which is run by the UK Royal Colleges of Physicians in Glasgow, Edinburgh and London.\n\nFor several years, the College has been successfully conducting its MRCPI examinations in its overseas centres (Malaysia, Oman, India, Saudi Arabia, and Bahrain) in addition to many centres in the Republic of Ireland.\n\nMembership is governed by the by-laws of the college. Every candidate wishing to obtain Membership of the Royal College of Physicians of Ireland must pass both parts of the Membership Examination (unless exemption has been granted) and attend a Membership Conferring Ceremony where he/she is conferred as a Member of the Royal College of Physicians of Ireland. Membership confers the right to use the post nominal MRCPI.\nFellowship is awarded by the College upon nomination by 2 existing Fellows (who should be in a good standing with the College) to doctors of consultant or equivalent status. In 1915 the College updated the regulations to allow women to become Fellows. The first woman to become a fellow was Mary Hearn in 1924. The benefits of this award include recognition of professional standing, access to Continuing Medical Education and Continuing Professional Development support, international collegiality and the opportunity to influence the future of the profession. Fellowship of the Royal College of Physicians of Ireland (FRCPI) is an international benchmark of professional excellence, reserved for doctors who have made substantial contributions to their specialty and whose published works and attainments meet the high expectations of the College.\n\n\n\n"}
{"id": "6848035", "url": "https://en.wikipedia.org/wiki?curid=6848035", "title": "Tawa Reservoir", "text": "Tawa Reservoir\n\nTawa Reservoir is a reservoir on the Tawa River in central India. It is located in Hoshangabad District of Madhya Pradesh state, above Baitul district. The reservoir was formed by the construction of the Tawa Dam, which began in 1958 and was completed in 1978. The dam provides for irrigation to several thousand hectares of farming land in Hoshangabad and Harda districts. It is also a big tourist attraction during the monsoon months. A cruise boat service has been started by the tourism department for visitors to the dam and reservoir. The dam was made by late Shri Vinay Kumar Diwan also known as Denva Ke Gandhi for his work for public welfare being public representative in the region for almost two decades serving as MLA.\n\nThe dam has brought prosperity to the Hoshangabad district.\n\nTawa Reservoir forms the western boundary of Satpura National Park and Bori Wildlife Sanctuary.\n\nIt is a small hydropower plant which was set up on the left bank to utilize the tailrace water for irrigation purpose.\n\nIt is a private sector hydro-electric generation power plant. The two units of 2 × 6.75 MW were set up by LNJ Bhilwara group. Generated power supplied to HEG Plant Mandideep via MPPTCL Power Line.\n\nThe power production in this plant was started in 1998.\n\nThe construction of project was completed in record time of 22 months and at a cost of about 65 crore. Early and efficient completion made possible by RSWI, Canada.\n\nIt is a canal head project.\n\nCatchments area spreads over approximately 6000 km.\n\nFull reservoir level (FRL) is .\n\nHead range 7 to 21 m and discharge varying from 25 to 54 Cumecs.\n\nTwo turbo generators 6.75 MW rated capacity (20% over load).\n\n"}
{"id": "3154336", "url": "https://en.wikipedia.org/wiki?curid=3154336", "title": "Thyroiditis", "text": "Thyroiditis\n\nThyroiditis is the inflammation of the thyroid gland. The thyroid gland is located on the front of the neck below the laryngeal prominence, and makes hormones that control metabolism.\n\nThyroiditis is a group of disorders that all cause thyroidal inflammation. Forms of the disease are Hashimoto's thyroiditis, the most common cause of hypothyroidism in the US, postpartum thyroiditis, subacute thyroiditis, silent thyroiditis, drug-induced thyroiditis, radiation-induced thyroiditis, acute thyroiditis, and Riedel's thyroiditis.\n\nEach different type of this disease has its own causes, clinical features, diagnoses, durations, resolutions, conditions and risks.\n\nThere are many different signs and symptoms for thyroiditis, none of which are exclusively limited to this disease. Many of the signs imitate symptoms of other diseases, so thyroiditis can sometimes be difficult to diagnose. Common hypothyroid symptoms manifest when thyroid cell damage is slow and chronic, and may include fatigue, weight gain, feeling \"fuzzy headed\", depression, dry skin, and constipation. Other, rarer symptoms include swelling of the legs, vague aches and pains, decreased concentration and so on. When conditions become more severe, depending on the type of thyroiditis, one may start to see puffiness around the eyes, slowing of the heart rate, a drop in body temperature, or even incipient heart failure. On the other hand, if the thyroid cell damage is acute, the thyroid hormone within the gland leaks out into the bloodstream causing symptoms of thyrotoxicosis, which is similar to those of hyperthyroidism. These symptoms include weight loss, irritability, anxiety, insomnia, fast heart rate, and fatigue. Elevated levels of thyroid hormone in the bloodstream cause both conditions, but thyrotoxicosis is the term used with thyroiditis since the thyroid gland is not overactive, as in the case of hyperthyroidism.\n\nThyroiditis is generally caused by an immune system attack on the thyroid, resulting in inflammation and damage to the thyroid cells. This disease is often considered a malfunction of the immune system, and can be associated with IgG4-related systemic disease, in which symptoms of autoimmune pancreatitis, retroperitoneal fibrosis and noninfectious aortitis also occur. Such is also the case in Riedel thyroiditis, an inflammation in which the thyroid tissue is replaced by fibrous tissue which can extend to neighbouring structures. Antibodies that attack the thyroid are what causes most types of thyroiditis. It can also be caused by an infection, like a virus or bacteria, which works in the same way as antibodies to cause inflammation in the glands, such as in the case of subacute granulomatous thyroiditis (de Quervain). Certain people make thyroid antibodies, and thyroiditis can be considered an autoimmune disease, because the body acts as if the thyroid gland is foreign tissue. Some drugs, such as interferon, lithium and amiodarone, can also cause thyroiditis because they have a tendency to damage thyroid cells.\n\nThe most common and helpful way to diagnose thyroiditis is first for a physician to palpate the thyroid gland during a physical examination. Laboratory tests allow doctors to evaluate the patient for elevated erythrocyte sedimentation rates, elevated thyroglobulin levels, and depressed radioactive iodine uptake (Mather, 2007). Blood tests also help to determine the kind of thyroiditis and to see how much thyroid stimulating hormone the pituitary gland is producing and what antibodies are present in the body. In some cases a biopsy may be needed to find out what is attacking the thyroid.\n\nTreatments for this disease depend on the type of thyroiditis that is diagnosed. For the most common type, which is known as Hashimoto's thyroiditis, the treatment is to immediately start hormone replacement. This prevents or corrects the hypothyroidism, and it also generally keeps the gland from getting bigger. However, Hashimoto's thyroiditis can initially present with excessive thyroid hormone being released from the thyroid gland (hyperthyroid). In this case the patient may only need bed rest and non-steroidal anti-inflammatory medications; however, some need steroids to reduce inflammation and to control palpitations. Also, doctors may prescribe beta blockers to lower the heart rate and reduce tremors, until the initial hyperthyroid period has resolved.\n\nMost types of thyroiditis are three to five times more likely to be found in women than in men. The average age of onset is between thirty and fifty years of age. This disease tends to be geographical and seasonal, and is most common in summer and fall.\n\nHashimoto's thyroiditis was first described by Japanese physician Hashimoto Hakaru working in Germany in 1912. Hashimoto's thyroiditis is also known as chronic lymphocytic thyroiditis, and patients with this disease often complain about difficulty swallowing. This condition may be so mild at first that the disease goes unnoticed for years. The first symptom that shows signs of Hashimoto's thyroiditis is a goiter on the front of the neck. Depending on the severity of the disease and how much it has progressed, doctors then decide what steps are taken for treatment.\n\n\n"}
{"id": "24285737", "url": "https://en.wikipedia.org/wiki?curid=24285737", "title": "Urban water management in Monterrey, Mexico", "text": "Urban water management in Monterrey, Mexico\n\nBeginning early in the 20th century, Monterrey, Mexico began a successful economic metamorphosis and growth pattern that remains an exception in Mexico. This all began with increased investments in irrigation that fueled a boom in agriculture and ranching for this northern Mexican city. The economic growth has fueled income disparity for the 3.86 million residents who live in the Monterrey Metro area (MMA). In addition, the rapid urbanization has taken a large toll on the water resources. In addressing many of this challenges, the city of Monterrey has become a model for sound and effective Integrated urban water management.\n\nThe challenges that Monterrey has confronted pertain to scarcity of surface water resources, poor water quality due to untreated industrial effluents, political cycles and term-limits which can limit long-term vision, and water disputes between urban and agricultural users. Monterrey has good groundwater \"well-fields\" that supply about 40% of the water demand for the city and generally are not over-exploited because of good connections to high-yield aquifer systems in the central parts of the \"Curvatura de Monterrey\". These wells are managed as storage reserves that can be used in time of drought, which is quite common in this region of Mexico.\n\nAlso unique to Monterrey is an arrangement made between farmers and the municipality, whereby the farmers grant the use of their water rights from the nearby Cuchillo reservoir and the municipal water utility SADM \"(Servicios de Agua y Drenaje de Monterrey)\" returns urban used and treated water to farmers for irrigation. This arrangement has benefited both parties since SADM supplements its water supply with high quality but internmitent supply from the Cuchillo reservoir and farmers receive a consistent and full of nutrients water for irrigation. The longer term outlook for the area is for urbanization to continue and water availability to decrease, therefore, new water management strategies will have to be created.\n\nDuring the first half of the 1900s, high investments in irrigation infrastructure had spurred agricultural development.\n\nReferred to as the \"Mexican Miracle\" from the 1940s through the 1970s, rapid economic and population growth transformed Monterrey into the second most important industrial city and second largest city in the country with a metropolitan population of 3.8 million. Monterrey's rapid urbanization was driven in part by the development of assembly plants (‘‘maquiladoras’’) and expanded significantly with the 1994 signing of the North American Free Trade Agreement (NAFTA). More specifically, the electronics industry became the largest industry in Monterrey and employs large volumes of industrial solvents in its productive process. These harmful chemicals are the most serious concern to surface and ground water in the Monterrey metro area §k§l§6Hola=D.\n\nA water shortage in the late 1970s forced rationing on 750,000 people, most of whom were poor and already experienced low access to water. Forced water rationing spawned water protests that escalated to larger organized mass rallies, blockades, seizure of water service trucks, taking over of government buildings, and the holding hostage of water delivery drivers. Most of these actions were led by poor women and resulted in presidential action with the creation of the \"Water for Everyone\" (Agua para Todos) program that ushered in a new era of government spending that promised to bring water to every resident by 1985.\n\nMonterrey is the capital city of the state of Nuevo León, and is situated approximately in the center of the state located in NE-Mexico and close to the Texas border. Monterrey has an elevation of above sea level and is located in a wide basin about across, surrounded to the north, west, and south by mountains. It has a semi-arid climate with a mean temperature of 75o F (24o C). However, most of the year temperatures are either warmer than 82o F (28o C), or cooler than 57o F (14o C). Monterrey's annual rainfall averages 584 mm (23 inches), with most of this total falling between June and October during the Atlantic hurricane season.\n\nIn 1995 the population of the San Juan watershed was 5m inhabitants, of which approximately 4m \nwere in Metro Monterrey (MAM) and the population is expected to increase to 8.4m inhabitants by 2020. The population of MAM is located within 360 km across nine municipalities (Apodaca, Garcia, Escobedo, Guadalupe, Juarez, Monterrey, San Nicolas, Santa Catarina and San Pedro). Taking discharge and aquifer recharge, current population and average hydrology into account, the watershed possesses a water availability of 484 m per inhabitant per year and would be reduced to 230 m per inhabitant per year by the year 2020. The watershed therefore ranks amongst the poorest regions in regards to per capita water availability with countries such as Syria, Israel, and Saudi Arabia. Per capita water use estimates, including domestic, commercial, municipal, and industrial supplies, approach 290 liters per day per inhabitant for MAM. More specifically, the MAM receives 60% of their water supply from surface water while the remaining 40% comes from an extensive network of groundwater wells.\n\nSurface water:\nThe San Juan River with a surface area of 20,212 km, accounts for 31.5% of the entire surface area of the State of Nuevo León and is the largest and most important river in supplying water to Monterrey.\n\nEl Cuchillo dam (1,123,000,000 m active capacity) was constructed 75 km upstream of the Gómez dam and began operations in 1993 primarily to supply water to Monterrey. The Marte R. Gómez (MRG) dam, constructed in 1936 just upstream of the San Juan's conﬂuence with the Río Bravo, serves as the Bajo Río San Juan (BRSJ) irrigation district's principal reservoir with 829,900,000 m active storage capacity. The José López Portillo ‘Cerro Prieto’, reservoir (ordinary storage capacity 393 mm) was built in the early 1980s in the adjacent Rio San Fernando watershed to supply the domestic and industrial water \ndemands of Monterrey Metro Area (MAM), and was the first case of inter-basin transfer of freshwater to \ncope with shortages in Mexico’s northeast.\n\nGroundwater:\nMonterrey groundwater is accounted for by 46 deep wells (700 to 1000 m), 74 wells (<100 m), three water tunnels (Cola de Caballo I and II, San Francisco), and two major springs. The wells are located in the ‘wellfields’ (area with many boreholes) and contribute 40% of the total water that consumed in Monterrey. The three most important ‘wellfields\" are the \"Metropolitan Area of Monterey Wellfield\", \"Buenos Aires Wellfield\", and \"Mina Wellfield\". The \"Buenos Aires Wellfield\" is the most important and contributes nearly half (46%) of the groundwater extracted (~ 1.5 m/s). It is located in a mountainous area of the \"Huasteca Canyon\" close to Monterrey. These ‘wellfields’ provide high quality water with a low cost of treatment.\nAccording to data gathered by researchers at the Autonomous University of Nuevo León in Mexico, a medium annual precipitation of 538 mm/year within the Buenos Aires wellfield´s catchment area is sufficient to recharge the aquifer while allowing for a discharge of around 1,600 L/s (400 gal.) that can safely be extracted at any given time. In 1998, the wellfield was operated at a mean discharge of 1,535 L/s. Due to higher extraction during most of the last 25 years however, dynamic levels in some of the wells have been observed to drop almost 100 meters over a period of several years indicating possible over-exploitation. While this does occur, the wellfields are quickly and completely recharged back to artesian conditions by hurricanes that have passed through in recent decades. Hurricanes do not appear in the hydrological balance that is based on 538 mm mean annual precipitation, therefore, long term aquifer reserves are considered to be significantly higher, implicating that extraction from the Buenos Aires wellfield can be considerably higher than 1,600 L/s without overexploiting the aquifer system.\n\nOther sources of water include man-made tunnels and natural springs (3.20% of total supply); water culture programs, reusable water from wastewater treatment plants and rehabilitation of groundwater wells that now provide access to aquifers.\n\nManagement of drainage infrastructure is the domain of SADM. Despite comparably low rainfall, Monterrey receives storms and hurricanes of great intensity during the months of May and July. Drainage has been under relative control during these storms. Flooding from storms is also a distinct possibility during September and October, therefore the government has sought to protect the citizens of Monterrey by building 160 km of drainage infrastructures including: 1) seven large storm water canals totaling 60 km; 2) three retention dams; 3) 47 smaller drainage branches totaling 70 km; 4) and 26 km of other municipal works.\n\nThe irrigation districts within the watersheds serving the MMA are the Bajo Río San Juan (BRSJ) irrigation district #26 (ID026) and the Bajo Río Bravo (BRB) irrigation district #25 (ID025). The farmers in these two irrigation districts receive water through a unique compensation arrangement that includes crop loss payments on the order of US$100 per hectare un-irrigable land due to the diversion of water to Monterrey plus an additional 60% of the diverted water to be returned to farmers as treated effluent via the Ayancual Creek, Pesquería River. While this has been a success, the Mexican irrigation sector will continue to face intense competition for water given: (a) low water productivity in agriculture leading decision-makers to allocate water to higher productivity uses particularly in cities; (b) priority accorded to the domestic use component of municipal water supply; (c) and Mexico's national interests in meeting its water sharing obligations with the United States.\n\nIn 1992, when the National Water Law (Ley de Aguas Nacionales) was enacted, management of water and irrigation systems became decentralized from the federal level to state and municipal levels. Irrigation districts, from that year on, became open to privatization and have since been responsible for maintaining themselves. Immediately, the lack of federal funding and resources to the irrigation districts around Monterrey caused problems such as lack of maintenance and management capacity. As the MMA continues to urbanize and demand for water supplies grow for both industrial and public use, irrigation districts 025 and 026 are seeing their irrigated lands contract.\n\nWater from the Río Bravo including the San Juan sub-basin are used as follows: 78% for agriculture, 12% for urban-public supply, 8% for industry, and 2% for Livestock. Monterrey has 99% coverage in water supply and 98% in sewer and close to 100% in wastewater treatment. Despite high coverage and efficiency rates, the city continues investing in expanding its capacity and improving its operations.\nRecent statistics show mean domestic water consumption for the city at about 12% of total discharge (Mexico average = 17%) or 10,400 liter per second (~2750 gallons) with lows in winter of 9,300 L/s (2,457 gallons) and high peaks in summer of 12,100 L/s (~3200 gallons). SADM estimated 2002 daily per capita domestic water consumption to be 130 L (32.5 gal.), down 18% from 1997 due to constant supply of 335 million m/year even though there has been a constant increase in population.\n\nThe fast pace of economic growth for the Monterrey Metro Area (MMA) has placed an increasing toll on water quality as industry (ex. Electronics) has discharged untreated industrial effluents and population has grown at a faster rate than the rest of Mexico. Consequently, availability of clean water resources has been impaired by contamination from industrial and residential sources along the Rio San Juan. Another river that first became polluted from industrial effluents and then completely dry from overuse is the Santa Catarina River.\n\nAdding to the problem, a municipal wastewater treatment plant (WWTP) operated by SADM in Montemorelos, 45 miles southeast of Monterrey, is unable to make the capital investment required to expand unit operations and \nprocesses and therefore cannot meet the current needs of a growing community resulting in a heavily \noverloaded plant producing effluent that does not meet discharge standards of 30 mg/l BOD and \nTotal suspended solids (TSS). In response, biological treatment technologies were deployed at the Montemorelos 1 WWTP without further significant capital increases. Positive results were observed after utilizing the biological treatment. Specifically, after 8 weeks of treatment, the Montemorelos 1 WWTP monthly average of influent BOD decreased 49% from 318 mg/l to 161 mg/l and influent TSS decreased 20% from 228 mg/l to 184 mg/l. Effluent BOD decreased 92% from 116 mg/l to 9 mg/l and effluent TSS decreased 80% from 58 mg/l to 12 mg/l.\n\nEvaporation and droughts have played a significant role in Monterrey's ongoing struggle to acquire adequate quantities of water. Because Monterrey is located in a semi-arid region where surface water is scarce and rainfall is infrequent, high temperatures stimulate high degree of water loss through evaporation from bodies of water and evapotranspiration from surrounding flora. In El Cuchillo, the largest reservoir in the area, water evaporation is equal to the amount extracted for drinking water at least five months of the year due to a large water surface and shallow depth of the reservoir. The impact of water loss through evaporation is very high as more than half of Monterrey's water supply comes from surface water.\n\nEl Cuchillo dam is the centerpiece of the basin's water management infrastructure and has become the ﬂashpoint of a multi-faceted water dispute between the states of Nuevo León and Tamaulipas as well as between urban and agricultural water interests in the basin. An article from a 1999 issue of the publication, Borderlines, does a good job of describing why there is conflict between the states of Nuevo León and Tamaulipas. Until the construction of the El Cuchillo project, the reservoir created by the Marte R. Gómez Dam, known in the U.S. as Sugar Lake, had provided a relatively clean source of drinking water to Reynosa, Tamaulipas and irrigation water to the 26th Irrigation District, which surrounds Sugar Lake. But since coming online, El Cuchillo has devastated northern Tamaulipas. As a result of the diversion upstream, water that once supported rural users downstream has virtually dried up. Approximately 300 fishing families who earned their living from Sugar Lake lost their livelihoods, as have some local merchants and motel owners. Likewise, farmers in the 26th Irrigation District have lost their crops over several seasons and affected crop lands are estimated as high as 70,000. As many as 20,000 families may have been affected. Also, Reynosa's drinking water now comes from the Rio Grande, which is extremely polluted. To date, the Mexican government denies any responsibility and blames the problems on the ongoing drought.\n\nIn response to the contamination of the San Juan River, the government of Nuevo León initiated a sanitation program in 1994 entitled Plan Monterrey IV, which included the construction of three large wastewater treatment plants and the discharge of municipal effluents and treated water to other Rio San Juan tributaries. The public perception has remained, however, that the San Juan River is still a polluted river.\n\nDisputes over water between agriculture and municipal needs have been mitigated to some degree as the Monterrey water utility, SADM, now returns treated effluent back to the farming districts. This solution seems to be working for both sectors; however, the program and strategy will have to be re-evaluated as water resources become more scarce.\n\nSADM has developed a program to replace micro-meters and valves on its secondary water network. One goal of the program was to replace 700,000 water meters by April 2003 while another goal was to increase water supply to the city by 2,500 L/s. Actions taken to achieve these stated goals included repairing leaks in the system, promoting water re-use in industry, extracting water from new wells, using new sources which contain sulfured water, reducing urban consumption by 5% and using technologies to avoid evaporation in dams.\n\nSADM (Servicios de Agua y Drenaje de Monterrey) is the water and sewer utility and supplies water in the Monterrey metro area (MMA). SADM is an autonomous public utility under the government of the state of Nuevo León and is the acting water authority in throughout the MMA.\n\nA particular type of Water User Association (WUA) called ‘‘módulos’’ propose operation and maintenance (O&M) plans for irrigation systems while also supporting farmers with procurement and marketing plans.\n\nNew SADM tariff agreements were signed in 2007 that became effective January 1, 2008. The first agreement maintained current rates for monthly domestic water consumption between 0–10 m. Another agreement enacted a 7.5% increase for all uses ranging from commercial, industrial, public and private institutions, and government dependencies. many more specifics of the 2007 Agreement can be located and downloaded at the SADM website concerning their tariff structures.\n\nIBWC (International Boundary and Water Commission) has responsibility for applying the boundary and water treaties between the United States and Mexico. The IBWC is an international body composed of the United States Section and the Mexican Section, each headed by an Engineer-Commissioner appointed by his/her respective president. The commissioners report to their respective federal authorities (State Department in the case of the US, and Secretario de Relaciones Exteriores in Mexico), but operationally work with state and local agencies on water management and allocation. Each Section is administered independently of the other. The IBWC is important here because the surface water of Monterrey is supplied by the El Cuchillo reservoir receiving water from the San Juan River, a major tributary of the Rio Grande. The Mexican Water Treaty signed in 1944 with the United States covers all shared water resources, principally the Río Bravo/Grande and the Colorado in the West.\n\n\n"}
{"id": "6900166", "url": "https://en.wikipedia.org/wiki?curid=6900166", "title": "Utility submeter", "text": "Utility submeter\n\nUtility submetering is a system that allows a landlord, property management firm, condominium association, homeowners association, or other multi-tenant property to bill tenants for individual measured utility usage. The approach makes use of individual water meters, gas meters, or electricity meters.\n\nSubmetering may also refer to the monitoring of the electrical consumption of individual equipment within a building, such as HVAC, indoor and outdoor lighting, refrigeration, kitchen equipment and more. In addition to the \"main load\" meter used by utilities to determine overall building consumption, submetering utilizes individual \"submeters\" that allow building and facility managers to have visibility into the energy use and performance of their equipment, creating opportunities for energy and capital expenditure savings.\n\nTypically a multi-tenant dwelling has either one master meter for the entire property or a meter for each building and the property is responsible for the entire utility bill. Submetering allows property owners who supply utilities to their tenants the ability to account for each tenant’s usage in measurable terms. By fairly billing each tenant for their portion, submetering promotes conservation and offsets the expense of bills generated from a master meter, maintenance and improvements for well water systems, lagoon, or septic systems. Submetering is legally allowable in most states and municipalities, but owners should consult a Utility Management Vendor for assistance with local and state compliance and regulations.\n\nTypical users of submetering are mobile home parks, apartment communities, condominium communities, townhouse communities, student housing communities, and commercial plazas. Usually, utility submetering is placed in situations where the local utility cannot or will not individually meter the utility in question. Municipal Utility companies are often reluctant to take on metering individual spaces for several reasons. One reason is that rental space tenants tend to be more transient and are more difficult to collect from. By billing only the owner, they can place liens on real property if not paid (as opposed to tenants they may not know exist or who have little to lose if they move without paying). Utilities also generally prefer not to have water meters beyond their easement (i.e., the property boundary), since leaks to a service line would be before the meter and could be of less concern to a property owner. Other reasons include difficulty in getting access to meters for reading, or electrical systems and plumbing not suitable for submetering.\n\nBefore submetering, many landlords either included the utility cost in the bulk price of the rent or lease, or divided the utility usage among the tenants in some way such as equally, by square footage via allocation methods often called RUBS (Ratio Utility Billing System) or some other means. Without a meter to measure individual usage, there is less incentive to identify building inefficiencies, since the other tenants or landlord may pay all or part of those costs. Submetering creates awareness of water and Energy conservation because landlords and tenants are equally aware of what they will pay for these inefficiencies if they are not attended to. Conservation also allows property owners to keep the cost of rent reasonable and fair for all units regardless of how much water or energy they consume. \n\nOn the other hand, submetering provides an opportunity for building owners to shift their rising electricity costs to tenants who lack ownership or control over thermal efficiency of the structure, its insulation, windows, and major energy consuming appliances. Landlords may attempt to deem their charges for electric service as \"additional rent\" making tenants subject to eviction for nonpayment of electric bills, which would not be possible if they were direct customers of the utility. The Ontario Energy Board in August 2009 nullified all landlord submetering and allowed future submetering only upon informed tenant consent, including provision of third party energy audits to tenants to enable them to judge the total cost of rent plus electricity.\n\nSome submetering products connect with software that provides consumption data. This data provides users with the information to locate leaks and high-consumption areas. Users can apply this data to implement conservation or renovation projects to lower usage & costs, meet government mandates, or participate in green building programs such as LEED and green globes.\n\nA submetering system typically includes a \"master meter\", which is owned by the utility supplying the water, electricity, or gas, with overall usage billed directly to the property owner. The property owner or manager then places their own private meters on individual tenant spaces to determine individual usage levels and bill each tenant for their share. In some cases, the landlord might add the usage cost to the regular rent or lease bill. In other cases, a third party might read, bill, and possibly even collect for the service. Some of these companies also install and maintain meters and reading systems.\n\nPanel or circuit submeters are used to measure resource use of the same system for added security, economic, reliability, and behavioral benefits. These provide important insights into resource consumption of building systems and equipment working in the same series. Submeters can measure use of a single panel, or multiple points within a panel system using single-point, multi-point, and branch circuit submeters.\n\nThe latest trend in submetering is Automatic Meter Reading, or AMR. This technology is used to get from meter reading to billing by an automated electronic means. This can be by handheld computers that collect data using touch wands, walk or drive-by radio, fixed network systems where the meter has a transmitter or transceiver that sends the data to a central location, or transmission via Wi-Fi, cellular, or Internet connections.\n\nAlthough not technically submetering, an alternate method of utility cost allocation called RUBS (Ratio Utility Billing Systems) is sometimes used to allocate costs to tenants when true submetering is not practical or not possible due to plumbing or wiring constraints. This method divides utility costs by square footage, number of occupants, or some other combination of cost ratios.\n\nSubmeters take many forms. For example, Central heating in apartment blocks in Belgium, Germany and Switzerland is sometimes submetered with liquid filled calibrated vials, known as heat cost allocators, attached to each of the heating radiators. The metering company visits the apartments about once a year and reads the liquid level and replaces the vials. Some apartment owners have replaced the vials with electronic submeters that transmit temperature readings via radio to a master unit in each apartment. The master unit in turn transmits collated readings to the utility company, thereby saving both labour costs and inconvenience to both tenant and landlord. The master unit displays a number representing the current total of \"heating value\".\n\nThe concept of submetering was effectively \"invented\" sometime in the 1920s, when many laws currently affecting submetering were written. However, submetering really did not take a hold in the property management world until the late 1980s, with the ever increasing costs associated with utilities and a society more aware of environmental conservation.\n\n\n\n"}
{"id": "1242271", "url": "https://en.wikipedia.org/wiki?curid=1242271", "title": "Women's Health Initiative", "text": "Women's Health Initiative\n\nThe Women's Health Initiative (WHI) was initiated by the U.S. National Institutes of Health (NIH) in 1991. The Women's Health Initiative, which consisted of three clinical trials (CT) and an observational study (OS), was conducted to address major health issues causing morbidity and mortality in postmenopausal women. In particular, randomized controlled trials were designed and funded that addressed cardiovascular disease, cancer, and osteoporosis. In its entirety, the WHI enrolled more than 160,000 postmenopausal women aged 50–79 years (at time of study enrollment) over 15 years, making it one of the largest U.S. prevention studies of its kind, with a budget of $625 million. A 2014 analysis calculated a net economic return on investment of $37.1 billion for the estrogen-plus-progestin arm of the study's hormone trial alone, providing a strong case for the continued use of this variety of large, publicly funded population study.\n\nIn the 1980s, it had become apparent that past biomedical research had focused disproportionately on white men, often neglecting prevention and treatment studies of diseases that are either unique to or more common in women and minorities. In 1985, the Public Health Service Task Force on Women's Health Issues issued recommendations that biomedical and behavioral research should be expanded to provide for the inclusion diseases and conditions identified among women of all age groups. In 1986, the NIH issued recommendations that women be included in all research studies. To further promote the study of women, in 1990, the NIH created the Office of Research on Women's Health.\n\nIn 1990, however, a report was published by the General Accounting Office (GAO), at the request of the Congressional Caucus on Women's Issues, which stated that this NIH policy was not being adequately applied to research grant applications. As a consequence, beginning in 1991, NIH strengthened the policy to require, rather than recommend, the inclusion of women in clinical research (when appropriate) in order to obtain funding.\n\nIt was these changes in societal attitudes and policy toward women's health research, in addition to the demonstration that such a large study was not only feasible, but could be done economically, that gave rise to the WHI.\n\nAmong postmenopausal women, cardiovascular disease, cancer, and osteoporosis are the leading causes of morbidity and mortality, as well as impaired quality of life. Among women in all age groups, cancer and cardiovascular disease are the leading causes of mortality. As the incidence of these diseases increases according to age, women over the age of 50 bear much of the disease burden.\n\nIt had been generally accepted that postmenopausal estrogen deficiency may play a role in these morbidities, and that dietary, behavioral, and drug interventions may forestall their development. However, these findings were identified on the basis of epidemiologic observational studies alone. Such interventions would require testing through clinical trials before they, along with their full range of risks and benefits, could be used as the basis for setting public health policy and creating prevention guidelines.\n\nHowever, concerns existed about the feasibility of such a complex clinical trial among participants in this demographic of older women, particularly with respect to sufficient recruitment and adherence to the dietary and hormone-treatment regimens.\n\nIn 1987, the NIH funded the Postmenopausal Estrogen/Progestin Intervention (PEPI). The trial followed 875 women who underwent treatment with estrogen, estrogen and progestin, or placebo, and — even quite early in the study — demonstrated both successful recruitment and participant retention/adherence in a hormone therapy (HT) setting. Many of the operational procedures from PEPI, including the study drug dosing, were retained in the larger WHI-HT clinical trial.\n\nIn 1984, the NIH provided funding for a feasibility study pertaining to diet adherence, conducted by the Women's Health Trial (WHT). The WHT, which commenced in 1986 and involved 303 women randomized into dietary intervention and control groups, yielded results demonstrating a high degree of adherence on the basis of both food-intake questionnaires and clinical laboratory findings. The WHT did not proceed with its full-scale trial, as it was not awarded further funding from the NIH on the basis of the potential inability of the study to test the hypothesis in a larger cohort of women. In 1990, however, interest in the impact of diet on cancer and cardiovascular disease in women was renewed, and a joint National Cancer Institute (NCI)-National Heart, Lung, and Blood Institute (NHLBI) workshop concluded that a full-scale dietary trial, with a focus on these two diseases, was warranted.\n\nOn April 19, 1991, Dr. Bernadine Healy, newly appointed as the first female director of the NIH, announced her plan for the Women's Health Initiative (WHI). Planning for the WHI CT/OS study began that year. In order to promote cross-institutional collaboration, and to prevent the loss of funding to other women's health-related studies, funding was requested and obtained directly from Congress in the form of a discrete line item, with a projected budget of $625 million over the life of the 15-year study.\n\nThe NIH awarded the role of Clinical Coordinating Center (CCC) to the Fred Hutchinson Cancer Research Center (FHCRC), located in Seattle, Washington. The CCC's responsibilities included the coordination of the 40 study clinics that would eventually recruit women nationwide, as well as ensuring their consistent adherence to the study design and guidelines.\n\nIn 1991, working groups were formed to determine the study plan for both the clinical trials (CT) and the observational study (OS). These groups included experts from diverse arenas of medicine, public health, and clinical trial design from both within and outside the NIH.\n\nGiven the complexity of the WHI study, both in terms of the number of interventions and outcomes studied, as well as the number and geographic distribution of participants and clinical centers, careful orchestration was required. To this end, the WHI maintained a carefully designed organizational structure, along with governance- and science-specific committees and communications channels for staff and investigators to resolve study-related questions and exchange information. As the study launched concurrently with the early stages of modern Internet connectivity, the study centers had to be supplied with computing and networking equipment to connect to the WHI network; WHI-hosted e-mail facilitated the efficient exchange of information among staff and scientists, as well as the transfer of study-related data.\n\nThe launch of the study was undertaken in two stages. At first, 16 \"vanguard\" study centers entered active operation, to evaluate the study protocol and procedures. Once this initial portion of the study was underway, the remaining 24 study centers entered the study around a year later, each assigned to one of the \"vanguard\" study centers for purposes of mentorship. Study centers were subdivided into four regions, each under the supervision of a regional center, to further facilitate communication and information exchange among study centers.\n\nThe WHI study recruited postmenopausal women in the 50-79 age range, and sought to be as inclusive as practical. The wide nature of the age range balanced the need to observe the effects of hormone therapy on younger women, while also attempting to capture physical and cognitive outcomes in older populations. In addition, a 20% minority enrollment rate was set for all components, to accurately represent the proportion of minorities within the study demographic (17% at the time of the 1990 U.S. Census). To achieve this, 10 of the 40 WHI clinical centers were designated as minority recruitment centers, with enhanced minority recruitment goals.\n\nEligibility and exclusion criteria also were defined, both study-wide and component-specific. Global inclusion criteria included postmenopausal women, between 50 and 79 years of age, who were willing and able to provide written consent, and who planned to reside in the study recruitment for a least three years after enrollment. Global exclusion criteria included medical conditions that would be predictive of a survival of less than three years, possessing characteristics or conditions that may diminish study adherence (e.g., substance abuse, mental illness, or cognitive impairment), or concurrent enrollment in another randomized controlled clinical trial.\n\nFor the CT, a partial factorial study design was utilized for the investigation of three overlapping interventions (dietary modification, hormone therapy, and calcium/vitamin D supplementation), as this would provide considerable cost efficiencies. Willing study-eligible women were asked to join either the hormone therapy (HT trial), the dietary modification (DM) trial, or both. After one year, willing and eligible CT participants were also asked to join the calcium/vitamin D trial (CaD).\n\nRecruitment goals for the HT, DM, and CaD components of the CT were 27,500, 48,000, and 45,000, respectively, each obtained on the basis of calculations of statistical power with regard to the outcomes of interest for each component.\n\nParticipants who either did not qualify for or declined to participate in the CT were, if eligible and willing to consent, enrolled in the observational study (OS), which had an enrollment goal of 100,000.\n\nThe WHI study was composed of four study components, to include three overlapping clinical trial (CT) interventions and one observational study (OS). Component enrollment and the primary findings are summarized in the following two tables, respectively, with additional detail following subsequently:\n\nThe design of the hormone therapy trial (HT) was approached with the hypothesis that estrogen therapy would result in a decrease in coronary heart disease and osteoporosis-related fractures. As such, the primary outcome of interest was coronary heart disease, as this is a major cause of morbidity and mortality among women, particularly those over age 65, and because, at the time, no clinical trial had been undertaken to prove the cardioprotective effects of HT. Due to the concern over the relationship between HT and elevated breast cancer risk, breast cancer was selected as the primary adverse outcome. Additional outcomes monitored included stroke, pulmonary embolism (PE), endometrial cancer, colorectal cancer, hip fracture, and death due to other causes.\n\nTwo regimens were selected, in addition to a placebo group. Women assigned to the intervention group who had previously undergone a hysterectomy were treated with unopposed estrogen, specifically conjugated estrogens (Premarin), manufactured by (Wyeth), at a dosage of 0.625 mg/day (\"E-alone,\" n = 5310; placebo, n = 5429). Women with an intact uterus were treated by a combined estrogen plus progestin regimen (\"E+P,\" n = 8506; placebo, n = 8102), specifically the aforementioned estrogen regimen with the addition of 2.5 mg/day of medroxyprogesterone acetate (MPA; Prempro, also manufactured by Wyeth). The addition of progestin has been linked to a marked reduction in the risk for the development of endometrial cancer in women receiving estrogen treatment who have not undergone a hysterectomy.\n\nIn addition to the global exclusion criteria, women were ineligible for the HT component if safety was a concern. Such concerns included a breast cancer diagnosis at any time in the past, other cancers (excluding non-melanoma skin cancer) diagnosed within the previous 10 years, or low hematocrit or platelet counts.\n\nThe HT component had originally been designed to include a follow-up period of nine years. However, interim monitoring of the combined estrogen/progestin treatment group indicated an increased risk of breast cancer, coronary heart disease, stroke, and pulmonary embolism, which outweighed the evidence indicating a benefit in preventing colorectal cancer and fractures. As a consequence, the HT study pills were stopped in July 2002, with an average follow-up period of 5.2 years. The unopposed estrogen trial was halted in February 2004, after an average follow-up period of 6.8 years, on the basis that unopposed estrogen did not appear to affect the risk of heart disease, the primary outcome, which was in contrast to the findings of previous observational studies. On the other hand, there were indications for an increased risk of stroke. Unopposed estrogen did reduce the risk for osteoporotic fractures and, unlike the estrogen/progestin treatment, showed a decrease in breast cancer risk.\n\nAs a consequence of the findings, which indicated that the incurred risks of HT outweigh the identified benefits, the study authors recommended that HT not be prescribed for the purpose of chronic disease prevention in postmenopausal women.\n\nThe hypothesized and observed risks of specific clinical outcomes are summarized in the following table. Of particular interest are the contrasts between several of the hypothesized risks and the observed attributable risks, which are instructive in demonstrating the distinct differences between the HT trial findings and those of previous observational studies.\n\nHazard Ratios (HR) and 95% confidence intervals (CIs) for various clinical outcomes in the E+P and E-alone trials\n\nOf all the WHI study findings, the HT findings could be argued to have yielded the farthest-reaching societal and economic impacts, and received substantial media attention. Large reductions in HT prescriptions ensued, resulting in a substantial loss of revenue in sales of this class of drugs, with a presumably commensurate savings to patients and insurers. More importantly, in subsequent years, studies have shown a decrease in breast cancer rates in postmenopausal women, attributed to the decline in use of HT.\nIn 2014, an analysis was conducted to determine the economic impact of the estrogen-plus-progestin trial findings, which calculated the net economic return on investment to be $37.1 billion, owing to a combination of averted health-related expenditures and increased number of quality-adjusted life years (QALYs).\n\nOf note, in 1996, based on observational studies and short-term trials, the United States Preventive Services Task Force (USPSTF) assigned a \"B\" grade to hormone replacement therapy for use in primary prevention of chronic conditions in postmenopausal women. A score of \"B\" carries an official message of, \"The USPSTF recommends the service. There is high certainty that the net benefit is moderate, or there is moderate certainty that the net benefit is moderate to substantial.\" In light of subsequent results from the Heart and Estrogen/progestin Replacement Study (HERS) and the WHI trials, the USPSTF downgraded the scoring to a \"D,\" which corresponds to a message of, \"The USPSTF recommends against the service. There is moderate or high certainty that the service has no net benefit or that the harms outweigh the benefits,\" and discourages health providers from offering the service or treatment. In 2017, the USPSTF again evaluated the use of HRT, and again assessed a \"D\" score. The publication of this most recent recommendation against the use of HRT for the treatment of chronic postmenopausal symptoms was accompanied by several companion editorials, lauding the WHI clinical trial's role in preventing patient harm due to HRT administration, noting also the risks inherent to smaller observational studies, which previously had yielded misleading, potentially harmful recommendations to medical practitioners.\n\nThe DM trial was conducted with the purpose of identifying the effects of a low-fat eating pattern; the primary outcome measures were the incidence of invasive breast and colorectal cancers, fatal and nonfatal coronary heart disease (CHD), stroke, and overall cardiovascular disease (CVD), calculated as a composite of CHD and stroke.\n\nWomen in the trial were randomly assigned to the dietary intervention group (40%; n = 19541) or the control group (60%; n = 29294). In addition to the global exclusion criteria, component-specific exclusion criteria included prior breast cancer, colorectal cancer, other cancers excluding nonmelanoma skin cancer in the past 10 years, adherence or retention concerns (e.g., a substance abuse history or dementia), or a baseline diet that included a fat intake accounting for less than 32% of total energy intake.\n\nParticipants in the intervention group underwent a regimen of trainings, group meetings, and consultations which encouraged low-fat eating habits, targeted to 20% of daily caloric intake, along with increasing the consumption of fruits, vegetables, and grains. Those assigned to the control group were not asked to adopt any specific dietary changes.\n\nThe mean follow-up for the DM intervention was 8.1 years. At study years 1 and 6, the dietary fat intake levels for the intervention group were 10.7% and 8.2% less than those of the control group, respectively. The results indicated that, despite some reduction in CVD risk factors (e.g., blood lipids and diastolic blood pressure), there was no significant reduction in the risk of CHD, stroke, or CVD, indicating that a more focused combination of diet and lifestyle interventions may be required to further improve CVD risk factors and reduce overall risk. In addition, no statistically significant reduction in breast cancer risk was identified, although the results approached significance and indicated that longer-term follow-up may yield a more definitive comparison. The trial also did not identify a reduction in colorectal cancer risk attributable to a low-fat dietary pattern.\n\nThe CaD trial component was designed to test the hypothesis that women taking a combination of calcium and vitamin D will experience a reduced risk of hip and other fractures, as well as breast and colorectal cancer.\n\nWomen participating in this intervention were randomly assigned to receive a regimen of 1000 mg calcium in combination with 400 International Units (IU) of vitamin D (n = 18176) or a placebo (n = 18106), and were followed for an average of 7 years, with monitoring for bone density, fractures, and pathologically confirmed cancers as the measures of outcomes. Women in the CaD trial were already participating in the HT trial, the DM trial, or both. In addition to the global exclusion criteria, component-specific exclusion criteria hypercalcemia, renal calculi, corticosteroid use, and calcitriol use.\n\nAmong the intervention cohort, a small but significant improvement in hip bone density was observed, although a significant reduction in hip fractures was not observed. However, subgroup analysis revealed a possible benefit to older women in terms of a reduced risk of hip fractures, attributable to calcium plus vitamin D supplementation.\n\nIt was also found that the intervention did not have an effect on the incidence of colorectal cancer, possibly owing to the long latency associated with colorectal cancers. Calcium plus vitamin D was not found to affect the incidence of breast cancer. Finally, an increased risk of kidney stones was observed among those taking calcium plus vitamin D.\n\nThe OS study recruited eligible postmenopausal women (n = 93676) who were either ineligible or unwilling to participate in the CT portion of the study, for the purpose of obtaining additional risk factor information, identifying risk-related biomarkers, and serving as a comparative observational assessment to the CT interventions.\n\nParticipants underwent an initial baseline screening, including the collection of physical measurements, blood specimens, an inventory of medications and supplements, and completion of questionnaires pertaining to medical history, family history, reproductive history, lifestyle and behavioral factors, and quality of life. In addition, more specific information was collected with regard to the participant's geographic residence history, passive (i.e., \"second-hand\") smoking exposure in childhood and adulthood, early life exposures, details of physical activity, weight and weight-cycling history, and occupational exposures. In addition to the baseline data collected, OS participants received annual questionnaire mailings to update selected exposures and outcomes, and were expected to make an additional clinic visit, to include an additional blood collection, about three years post-enrollment. It was planned that participants would be followed for an average of 9 years.\n\nThe major outcomes of interest for the OS were coronary heart disease, stroke, breast cancer, colorectal cancer, osteoporotic fractures, diabetes, and total mortality. Given the size and diversity of the cohort, taken together with the data and specimen collection being undertaken, it was expected that this cohort could yield insights into a variety of hypotheses, as well as generate new hypotheses with respect to disease etiology in women.\n\nThe WHI OS has and continues to yield many findings and new hypotheses, a small sampling of which are highlighted below:\n\nThe WHI study has received three extensions; these extensions are referred to as \"Extension Study 1\" (2005-2010), \"Extension Study 2\" (2010-2015), and the recently undertaken \"Extension Study 3\" (2015-2020). Participants from the first phase of the WHI study were consented and enrolled, with the intention of collecting additional longitudinal data from subjects involved in all of the original study components. The primary outcomes were the same, although greater emphasis was placed on the investigation of cardiovascular disease and aging. Extension Study 1 enrolled 115,403 of the original WHI participants, or 77% of those eligible from the first study phase. Extension Study 2 was able to enroll 93,540 participants, or 87% of those eligible from Extension Study 1. Preliminary estimates for Extension Study 3 participation, as of September 30, 2015, estimate that 36,115 of the Clinical Trial participants and 45,271 Observational Study participants remain active in the WHI study, for a total of 81,386 or 87% of those previously enrolled in Extension Study 2.\n\nA subsample of the Extension Study 2 participants (n = 7875), aged 63–99 and meeting other eligibility criteria, were consented into the Long Life Study (LLS), the purpose of which was to establish new baselines from which new studies in disease and aging can work. In-person visits were conducted to assess and collect physical and functional measurements, as well as blood to replenish the WHI biospecimen repository and determine current CBC parameters for these participants. The LLS completed its in-person visits and blood collections in May 2013.\n\nA large subset of the LLS participants (n ≈ 7400) were further enrolled in the Objective Physical Activity and Cardiovascular Health in Women (OPACH) study, the purpose of which was to assess physical activity in women capable of ambulation. These women were asked to maintain a week-long sleep log, wear an accelerometer for a week, and keep track of falls on a month basis for one year. The goal was to establish a stronger correlation between physical activity and cardiovascular disease and total mortality.\n\nUndertaken beginning in 2015, the COcoa Supplement and Multivitamin Outcomes Study (COSMOS) at Brigham and Women’s Hospital and the Fred Hutchinson Cancer Research Center (Seattle, WA) is a four-year clinical trial that will randomize 18,000 men and women across the U.S. The study will investigate whether taking daily supplements of cocoa flavanols (600 mg/day) or a common multivitamin reduces the risk for developing heart disease, stroke, and cancer.\n\nThe Women’s Health Initiative Strong and Healthy Study (WHISH), started in 2015 and expected to last four years, seeks to examine the impact of physical activity in older women on certain outcomes such as heart disease and metrics including maintaining an independent lifestyle. The study has enrolled nearly 50,000 participants as of October 2016, whose assigned interventions will include varying physical activity routines, which are monitored by mail and via phone, using an interactive voice response (IVR) system.\n\nPublic health investigators and biostatisticians can apply to use WHI study data in conjunction with their investigations. As of June 2013, nearly 450 Ancillary Studies have been proposed. Newly generated data from these Ancillary Studies must be submitted to the WHI, which in turn provides a richer data resource for subsequent studies.\n\nIn addition to the study data, data from genome-wide association studies (GWAS) conducted on participant DNA is available on the NIH-hosted Database of Genotypes and Phenotypes (dbGaP).\n\nRecent analysis during the post-intervention period following the estrogen-plus-progestin trial continues to reveal the strong association between estrogen- plus-progestin usage and breast cancer risk. Following the halt of the estrogen-plus-progestin trial, there was a sharp decrease in breast cancer risk in the early post-intervention period, though the hazard ratio remained greater than 1, followed by a sustained risk during the late post-intervention period that was significantly greater than 1. It is hypothesized that the initial decrease was due to the resulting change in the hormone environment, while the subsequent persistent increase in breast cancer incidence may be attributed to the persistence of oncogenic mutations and subsequent expansion of these mutation-harboring cell lineages.\n\nIn contrast, breast cancer risk was significantly lower for the estrogen-alone group compared to placebo during the post-intervention period. Specifically, the reduction of breast cancer incidence persisted throughout the early post-intervention phase, but was lost during the late post-intervention phase.\n\nRegarding endometrial cancer, although estrogen-plus-progestin use during the intervention period suggested a reduction in cancer incidence, the difference became statistically significant with additional follow-up from the extension period. These findings highlight the completely different long-term influences estrogen plus progestin have on endometrial cancer and breast cancer.\n\nAccording to a cumulative 18-year follow-up analysis published in 2017, it was found that, among 27,347 postmenopausal women who had originally participated in the WHI hormone therapy trials, interventions using estrogen-plus-progestin and estrogen-alone were not associated with increased or decreased risk of all-cause, cardiovascular, or total cancer mortality.\n\nOf note, mortality is a rather limited summary because it does not include non-fatal CVD and non-fatal cancer events that may have long term consequences on health and quality of life. Post-menopausal women considering initiation of HT and their clinicians should refer to previous WHI publications for a complete summary of risks for fatal and non-fatal events.\n\nThe Dietary Modification intervention has also yielded new findings, after nearly two decades of follow-up. During the dietary intervention period (median, 8.1 years), it was found that a low-fat dietary pattern led to a lower incidence of death after breast cancer (40 deaths versus 94 in the \"normal diet\" arm; HR, 0.65; 95% CI, 0.45 to 0.94, P = .02.). After a median 16.1 years of cumulative follow-up (inclusive of the intervention period), further analysis showed that this benefit persisted (234 deaths versus 443 in the \"normal diet\" arm; HR, 0.82; 95% CI, 0.70 to 0.96 with P = .01).\n\nAnother recent analysis of Dietary Modification intervention outcomes showed a 30% reduction in coronary heart disease (CHD) risk among women having normal blood pressure (n = 23,248) and partaking in a low-fat dietary pattern (122 versus 256 CHD events; HR, 0.70; 95% CI, 0.56 to 0.87 during the intervention period). Participants with existing cardiovascular disease at baseline (n = 1,656) were at higher risk of developing coronary heart disease, both during the intervention and extended follow-up periods (101 versus 116 CHD events, HR, 1.47; 95% CI, 1.12 to 1.93; and 36 versus 44, HR, 1.61 95% CI 1.02 to 2.55, respectively). The increased among women with prior CVD was likely due to post-randomization confounding, resulting in some difficulty in interpretation. Women in the diet intervention group were more likely to report changes in statin use (either cessation or initiation) post-randomization than women in the comparison group.\n\nThese types of analysis, conducted more than a decade after the halt of the intervention trials, serves further to demonstrate the long-term value and return on investment yielded by the WHI study.\n\nAs of September 2018, the WHI has reviewed 3,154 writing proposals, of which 1,725 have been published in scientific journals.\n\nAccording to a 2013 analysis of extramural clinical trials supported by the NHLBI, the components of the WHI study have been some of the most frequently cited in the literature, with the E+P trial ranking first among all NHLBI-sponsored clinical trials, alone averaging 812.5 citations annually (total average annual number of citations for the WHI study interventions, 1233.3). In addition, the WHI study component findings were found to reach publication in a timely manner, despite the study's negative trial findings (see NEJM Supplementary Appendix for detailed findings).\n\nIn 2015, the WHI study was awarded the 2015 Team Science Award from the Association for Clinical and Translational Science (ACTS), \"given in recognition of the WHI team’s success in the translation of research discoveries into clinical applications and, eventually, widespread clinical practice.\"\n\nIn April 2016, the American Association for Cancer Research (AACR), the oldest and largest research society of its kind, awarded the WHI study the 2016 Team Science Award in recognition of its more than 20 years of work, which ultimately \"singularly changed the face of women's medicine around the world.\"\n\nThe WHI trial was limited by low adherence, high attrition, inadequate power to detect risks for some outcomes, and evaluation of few regimens. Subsequent to publication of the WHI, controversy arose regarding the applicability of its findings to women just entering menopause. To be properly double blinded, the study required that women not be perimenopausal or have symptoms of menopause. As the average age of menopause is 51, this resulted in an older study population, with an average age of 63. Only 3.5% of the women were 50–54 years of age, the time when women usually decide whether to initiate hormonal therapy. Further analysis of WHI data, however, demonstrated that there is no gained preventive benefit in starting hormone therapy soon after menopause.\n\nMost fundamentally, the WHI did not address the major indication for MHT use, relief of symptoms. On the other hand, the stated goal of the HT component was to test the long-term cardiovascular-protective effects (rather than treatment of menopausal symptoms) of HT in postmenopausal women, which had been supported by previous observational studies in terms of how it reduces atherosclerotic diseases by lowering serum lipid levels and promoting vasodilation. In an expert consensus statement from The Endocrine Society, evidence from the WHI trial was weighted less than that of a randomized controlled trial according to the GRADE system criteria because of mitigating factors: large dropout rate; lack of adequate representation of applicable group of women (i.e. those initiating therapy at the time of menopause); and modifying influences from prior hormone use. However, the editor of one of the journals which published the results of the WHI called it a \"landmark\" study. The double blinding limited validity of study results due to its effects on patient exclusion criteria. The dominant majority of participants were Caucasian, and tended to be slightly overweight and former smokers, with the necessary health risks for which these demographics predispose. Furthermore, the focus of the WHI study was disease prevention. Most women take hormone therapy to treat symptoms of menopause rather than for disease prevention and therefore the risks and benefits of hormone therapy in the general population differ from the women included in the WHI. Despite these concerns, the original findings of the WHI trial have been accepted by reputable journals, and have withstood the scrutiny of subsequent reanalysis of the study data.\n\nAtherosclerosis Risk in Communities (ARIC) study - cohort study of 15,792 men and women in four U.S. communities, which began in 1987, and seeks to identify the underlying causes of atherosclerosis and the resulting clinical outcomes.\n\nCaerphilly Heart Disease Study - cohort study of 2,512 men, set up in a representative population sample drawn from a small town in South Wales, UK. Study has collected wide-ranging data and has focused on risk factors that predict vascular disease, diabetes, cognitive impairment and dementia — and the benefits of living a healthy lifestyle.(1979–present).\n\nFramingham Heart Study - long-term, ongoing cardiovascular study on the residents of Framingham, Massachusetts (1948–present).\n\nMulti-Ethnic Study of Atherosclerosis (MESA) - cohort study of approximately 6,000 men and women in six U.S. communities, which started in 2000, with the purpose of identifying the subclinical (i.e., asymptomatic) characteristics of cardiovascular disease, as well as risk factors that predict progression to a clinical disease state.\n\nNurses' Health Study - cohort (three cohorts: 1976 and 1989, with a third cohort currently under recruitment) study focusing on the health of female registered nurses.\n\n\n"}
{"id": "40856034", "url": "https://en.wikipedia.org/wiki?curid=40856034", "title": "XDT", "text": "XDT\n\nxDT (aka KVDT) is a family of data exchange formats that are used by physicians and health care administration in Germany. They were created by initiative of the \"Kassenärztliche Bundesvereinigung\" (National Association of Statutory Health Insurance Physicians - NASHIP).\n\nAs of October 2013 the following formats have been implemented:\n\n\n"}
