{"id": "32969077", "url": "https://en.wikipedia.org/wiki?curid=32969077", "title": "Abimbola Alao", "text": "Abimbola Alao\n\nAbimbola Gbemi Alao also known as Abi Alao, was born in Ibadan, Nigeria. She is a performance storyteller, author, children's book translator and researcher. She currently lives in England.\n\nAbimbola studied at the University of Ibadan, Nigeria, where she gained a BA (Hon) Classics in 1988 and an MA Classics in 1991. She later studied PGCE and MA in Creative Writing at the University of Plymouth.\n\nAbimbola is the author of \"Trickster Tales for Telling\" (2016), \"How to Enhance Your Storytelling With Music\" (2016),\"The Legendary Weaver: New Edition\", a young-adult fiction book (2003 and 2011), and \"The Goshen Principle: A Shelter in the Time of Storm\" (2010). She has also written numerous poems, short stories and plays. In 2008, her short play, 'Legal Stuff', won the BBC and Royal Court Theatre '24 Degrees' Writing Competition. In 2011-2012, she wrote a collection of fables for KidsOut World Stories; this project won the 2013 Talk Talk Digital Heroes award for the East of England. \nShe is a children's book translator and her work includes translation of the classics: 'Hansel and Gretel', 'The Little Red Hen and the Grain of Wheat' and several other books, published by Mantra Lingua publishers.\n\nAbimbola was a tutor at the Institute of Education, University of Plymouth, from 2003 to 2007 and was appointed as a lecturer in Creative Writing at the University of St Mark & St John (MARJON), Plymouth, in 2007. A recipient of Plymouth's 2017 Mayflower Scholarship, she is currently researching the influence of physical and cognitive non-pharmacological intervention on disease progression in people living with dementia.\n\nAbimbola is the lead provider of 'StoryWeavers for Dementia', a Special Study Unit (SSU) in Medical Humanities, at the Peninsula School of Medicine and Dentistry, Plymouth. The program, developed by Abimbola, explores non-pharmacological approach to dementia care, and offered to people who live with various forms of dementia. In 2015, Abimbola collaborated with the Alzheimer's Society to run a 12-week project with service users in memory cafes. This culminated in an anthology titled, 'Narrative Adventures from Plymouth Memory Cafes'. In January 2014, Stoke Damerel College in Plymouth participated in StoryWeavers for Dementia; the school won the Prime Minister's Dementia Friendly Award: Schools Category in May 2014.\n\nAbimbola was a regular contributor to the BBC Radio Devon 'Pause for thought', between 2004 and 2009. She also contributes to 'Saturday Thought', a weekly column in \"The Herald\".\n\n\nAbimbola performs Storytelling, Musicals and Poetry on stage. Her audience includes children, young adults and adults.\n\n\n\n"}
{"id": "15015085", "url": "https://en.wikipedia.org/wiki?curid=15015085", "title": "Aging of Japan", "text": "Aging of Japan\n\nThe aging of Japan is thought to outweigh all other nations, with Japan being purported to have the highest proportion of elderly citizens. Japan is experiencing a “super-aging” society both in rural and urban areas. According to 2014 estimates, 33.0% of the Japanese population is above the age of 60, 25.9% are aged 65 or above, 12.5% are aged 75 or above. People aged 65 and older in Japan make up a quarter of its total population, estimated to reach a third by 2050.\n\nJapan had a post war baby boom between 1947 and 1949. The law of 1948 led to easy access to abortions, followed by a prolonged period of low fertility, resulting in the aging population of Japan. The dramatic aging of Japanese society as a result of sub-replacement fertility rates and high life expectancy is expected to continue. Japan's population began to decline in 2011. In 2014, Japan's population was estimated at 127 million; this figure is expected to shrink to 107 million (16%) by 2040 and to 97 million (24%) by 2050 should the current demographic trend continue.\n\nJapanese citizens largely view Japan as comfortable and modern, resulting in no sense of a population crisis. The government of Japan has responded to concerns about the stress that demographic changes place on the economy and social services with policies intended to restore the fertility rate and make the elderly more active in society.\n\nThe number of Japanese people with ages 65 years or older nearly quadrupled in the last forty years, to 33 million in 2014, accounting for 26% of Japan's population. In the same period, the number of children (aged 14 and younger) decreased from 24.3% of the population in 1975 to 12.8% in 2014. The number of elderly people surpassed the number of children in 1997, and sales of adult diapers surpassed diapers for babies in 2014. This change in the demographic makeup of Japanese society, referred to as population aging (\"\", ), has taken place in a shorter span of time than in any other country.\n\nAccording to projections of the population with the current fertility rate, over 65s will account for 40% of the population by 2060, and the total population will fall by a third from 128 million in 2010 to 87 million in 2060. Economists at Tohoku University established a countdown to national extinction, which estimates that Japan will have only one remaining child in 4205. These predictions prompted a pledge by Prime Minister Shinzō Abe to halt population decline at 100 million.\n\nThe aging of the Japanese population is a result of one of the world's lowest fertility rates combined with the highest life expectancy.\n\nThe reason for Japan's growing aging population is because of high life expectancy. Japan's life expectancy in 2016 was 85 years. The life expectancy is 81.7 for males and 88.5 for females. Since Japan's overall population is shrinking due to low fertility rates, the aging population is rapidly increasing.\n\nFactors such as improved nutrition, advanced medical and pharmacological technologies reduced the prevalence of diseases, improving living conditions. Moreover, peace and prosperity following World War II was integral to the massive economic growth of post-war Japan, leading to longer lifespans. Proportion of health care spending has dramatically increased as Japan's older population spends time in hospitals and visits physicians. 2.9% people aged 75–79 were in a hospital and 13.4% visited physicians on any given day in 2011.\n\nLife expectancy at birth has increased rapidly from the end of World War II, when the average was 54 years for women and 50 for men, as a result of improvements in medicine and nutrition, and the percentage of the population aged 65 years and older has increased steadily from the 1950s. The advancement of life expectancy translated into a depressed mortality rate until the 1980s, but mortality has increased again to 10.1 per 1000 people in 2013, the highest since 1950.\n\nJapan's total fertility rate (the number of children born by each woman in her lifetime) has been below the replacement threshold of 2.1 since 1974 and reached a historic low of 1.26 in 2005. Experts believe that signs of a slight recovery reflect the expiration of a \"tempo effect,\" as fertility rates accommodate a major shift in the timing and number of children, rather than any positive change. As of 2016, the TFR was 1.41 children born/woman.\n\nA range of economic and cultural factors contributed to the decline in childbirth during the late 20th century: later and fewer marriages, higher education, urbanization, increase in nuclear family households (rather than extended family), poor work–life balance, increased participation of women in the workforce, a decline in wages and lifetime employment along with a high gender pay gap, small living spaces, and the high cost of raising a child.\n\nMany young people face economic insecurity due to a lack of regular employment. About 40% of Japan's labor force is non-regular, including part-time and temporary workers. Non-regular employees earn about 53 percent less than regular ones on a comparable monthly basis, according to the Labor Ministry. Young men in this group are less likely to consider marriage or to be married.\n\nAlthough most married couples have two or more children, a growing number of young people postpone or entirely reject marriage and parenthood. Conservative gender roles often mean that women are expected to stay home with the children, rather than work. Between 1980 and 2010, the percentage of the population who had never married increased from 22% to almost 30%, even as the population continued to age, and by 2035 one in four people will not marry during their childbearing years. The Japanese sociologist Masahiro Yamada coined the term for unmarried adults in their late 20s and 30s who continue to live with their parents.\n\nDemographic trends are altering relations within and across generations, creating new government responsibilities and changing many aspects of Japanese social life. The aging and decline of the working-age population has triggered concerns about the future of the nation's workforce, the potential for economic growth, and the solvency of the national pension and healthcare services.\n\nA smaller population could make the country's crowded metropolitan areas more livable, and the stagnation of economic output might still benefit a shrinking workforce. However, the low birthrate and high life expectancy has also inverted the standard population pyramid, forcing a narrowing base of young people to provide and care for a bulging older cohort even as they try to form families of their own. In 2014, the aged dependency ratio (the ratio of people over 65 to those age 15–65, indicating the ratio of the dependent elderly population to those of working age) was 40%, meaning two aged dependents for every five workers. This is expected to increase to 60% by 2036 and to nearly 80% by 2060.\n\nElderly Japanese have traditionally commended themselves to the care of their adult children, and government policies still encourage the creation of , where a married couple cares for both children and parents. In 2015, 177,600 people between the ages of 15 and 29 were caring directly for an older family member. However, the migration of young people into Japan's major cities, the entrance of women into the workforce, and the increasing cost of care for both young and old dependents have required new solutions, including nursing homes, adult daycare centers, and home health programs. Every year Japan closes 400 primary and secondary schools, converting some of them to care centers for the elderly.\n\nThere are special nursing homes in Japan that offer service and assistance to more than 30 residents. In 2008, it has been recorded that there were approximate 6,000 special nursing homes available that compensated 420,000 Japanese elders. With many nursing homes in Japan, the demand for more caregivers is high. In Japan, Family caregivers are preferred as the main caregiver, because it is a better support system if an elderly person is related to his/her caregiver. Therefore, it is possible that Japanese elderlies can perform activities of daily living (ADL's) with little assistance and live longer if his/her caregiver is a family caregiver.\n\nMany elderly people live alone and isolated, and every year thousands of deaths go unnoticed for days or even weeks, in a modern phenomenon known as .\n\nThe disposable income in Japan's older population has increased business in biomedical technologies research in cosmetics and regenerative medicine.\n\nThe Greater Tokyo Area is virtually the only locality in Japan to see population growth, mostly due to internal migration from other parts of the country. Between 2005 and 2010, 36 of Japan's 47 prefectures shrank by as much as 5%, and many rural and suburban areas are struggling with an epidemic of abandoned homes (8 million across Japan). Masuda Hiroya, a former Minister for Internal Affairs and Communications who heads the private think tank Japan Policy Council, estimated that about half the municipalities in Japan could disappear between now and 2040 as young people, especially young women, move from rural areas into Tokyo, Osaka, and Nagoya, where around half of Japan's population is already concentrated. The government is establishing a regional revitalization task force and focusing on developing regional hub cities, especially Sapporo, Sendai, Hiroshima, and Fukuoka.\n\nInternal migration and population decline have created a severe regional imbalance in electoral power, where the weight of a single vote depends on where it was cast. Some depopulated districts send three times as many representatives per voter to the National Diet as their growing urban counterparts. In 2014, the Supreme Court of Japan declared the disparities in voting power violate the Constitution, but the ruling Liberal Democratic Party, which relies on rural and older voters, has been slow to make the necessary realignment.\n\nThe increasing proportion of elderly people has a major impact on government spending and policies. As recently as the early- 1970s, the cost of public pensions, health care and welfare services for the aged amounted to only about 6% of Japan's national income. In 1992 that portion of the national budget was 18%, and it is expected that by 2025 28% of national income will be spent on social welfare. Because the incidence of chronic disease increases with age, the health care and pension systems are expected to come under severe strain. In the mid- 1980s the government began to reevaluate the relative burdens of government and the private sector in health care and pensions, and it established policies to control government costs in these programs.\n\nThe large share of elderly inflation averse voters may also hinder the political attractiveness of pursuing higher inflation consistent with the evidence that ageing may lead to lower inflation. With the increasing older population and decreasing young population, 38% percent of the population will be people aged 65 and older by 2065. This concludes that Japan has the highest amount of public debt in the world because of the low fertility rates and aging population. Japan's government has spent almost half of its tax revenue trying to recover from their debt. According to IMF, Japan has a 246.14 debt percentage of GDP making it the highest public debt.\n\nSince the 1980s, there has been an increase of older-age workers and a shortage of young workers in Japan's workforce, from employment practices to benefits to the participation of women. The U.S. Census Bureau estimated in 2002 that Japan would experience an 18% decrease of young workers in its workforce and 8% decrease in its consumer population by 2030. The Japanese labor market is already under pressure to meet demands for workers, with 125 jobs for every 100 job seekers at the end of 2015, as older generations retire and younger generations become smaller in quantity.\n\nJapan made a radical change in how its healthcare system is regulated by introducing long-term care insurance in 2000. The proportion of old Japanese citizens will soon level off, however; there is a decline in young population due to zero growth, death exceeding the births. For example, number of young people under the age of 19 in Japan will constitute only 13 percent in the year 2060, which used to be 40 percent in 1960.\n\nJapan's aging population is considered economically prosperous profiting the large corporations. Lawson Inc., a Japanese convenience store chain has salons for senior citizens that feature adult wipes and diapers, strong detergents to eliminate urine on bed mats, straw cups, gargling basins, and rice and water. The decline in the working population is impacting the national economy. It is causing a shrinkage of the nation's military. The government has focused on medical technologies such as regenerative medicines and cell therapy to recruit and retain more older population into the work force.\n\nMounting labor shortages in the 1980s and 90s led many Japanese companies to increase the mandatory retirement age from 55 to 60 or 65, and today many allow their employees to continue working after official retirement. The growing number of retirement age people has put strain on the national pension system. In 1986, the government increased the age at which pension benefits begin from 60 to 65, and shortfalls in the pension system have encouraged many people of retirement age to remain in the workforce and have driven some others into poverty.\n\nThe retirement age may go even higher in the future if Japan continues to have older age populations in its overall population. A study by the UN Population Division released in 2000 found that Japan would need to raise its retirement age to 77 (or allow net immigration of 17 million by 2050) to maintain its worker-to-retiree ratio. Consistent immigration into Japan may prevent further population decline, therefore, it is encouraged that Japan develops policies that will support large influx of young immigrants.\n\nLess desirable industries, such as agriculture and construction, are more threatened than others. The average farmer in Japan is 70 years old, and while about a third of construction workers are 55 or older, including many who expect to retire within the next ten years, only one in ten are younger than 30.\n\nThe decline in working-aged cohorts may lead to a shrinking economy if productivity does not increase faster than the rate of Japan's decreasing workforce. The OECD estimates that similar labor shortages in Austria, Germany, Greece, Italy, Spain, and Sweden will depress the European Union's economic growth by 0.4 percentage points annually from 2000 to 2025, after which shortages will cost the EU 0.9 percentage points in growth. In Japan labor shortages will lower growth by 0.7 percentage points annually until 2025, after which Japan will also experience a 0.9 percentage points loss in growth.\n\nThe Japanese government is addressing demographic problems by developing policies to encourage fertility and keep more of its population, especially women and elderly, engaged in the workforce. Incentives for family formation include expanded opportunities for childcare, new benefits for those who have children, and a state-sponsored dating service. Some policies have focused on engaging more women in the workplace, including longer maternity leave and legal protections against pregnancy discrimination, known in Japan as . However, \"Womenomics,\" the set of policies intended to bring more women into the workplace as part of Prime Minister Shinzō Abe's economic recovery plan, has struggled to overcome cultural barriers and entrenched stereotypes.\n\nThese policies could prove useful for bringing women back into the workforce after having children, but they can also encourage the women who opt not to have children to join the workforce. The Japanese government has introduced other policies to address the growing elderly population as well, especially in rural areas. Many young people end up moving to the city in search of work, leaving behind a growing elderly population and a smaller work force to take care of them. Because of this, Japan's national government has tried to improve welfare services such as long-term care facilities and other services that can help families at home such as day-care or in-home nursing assistance. The Gold Plan was introduced in 1990 to improve these services and attempted to reduce the burden of care placed on families, followed by long-term care insurance (LTCI) in 2000. These plans have been upgraded and revised over the years to provide more local welfare services and institutions in rural areas, yet the rapidly increasing elderly population makes these efforts difficult to maintain.\n\nA net decline in population due to a historically low birth rate has raised the issue of immigration, as a way to compensate for labor shortages. While public opinion polls tend to show low support for immigration, most people support an expansion in working-age migrants on a temporary basis to maintain Japan's economic status. Comparative reviews show that Japanese attitudes are broadly neutral and place Japanese acceptance of migrants in the middle of developed countries.\n\nHowever, immigration might save their economy due to the low percentage of the working-age population. Opening up more desired, favorable jobs will bring in immigrants who are in the working-age population. This will help better the economy and the elders will be taken care of by the influx of immigrants. Only two percent of the total population is made up of foreign residents which shows that there might not be much opportunities for foreigners to thrive on.\n\nImmigrants would have to increase by eight percent, in order for Japan's economy to be stable. Japan's government is first trying to increase tourism rates which increases their economy and brings in foreign workers. The government has also recruited international students which allow foreigners to begin work and potentially stay in Japan to help the economy. However, Japan is strict when accepting refugees into their country. Only 27 people out of 7,500 refugee applicants were granted into Japan in 2015. Though, Japan provides high levels of foreign and humanitarian aid. In 2016, there was a 44% increase in asylum seekers to Japan from Indonesia, Nepal, and the Philippines. Since Japan did not desire low-skilled workers to enter, many people went through the asylum route instead. This allowed immigrants to apply for the asylum and begin work six months after the application. However, it did not allow foreigners without valid visas to apply for work.\n\nJapan has focused its policies on the work-life balance with the goal of improving the conditions for increasing the birth rate.\nTo address these challenges, Japan has established goals to define the ideal work-life balance that would provide the environment for couples to have more children with the passing of the Child Care and Family Care Leave Law, which took effect in June 2010.\n\nThe law provides both mothers and fathers with an opportunity to take up to one year of leave after the birth of a child (with possibility to extend the leave for another 6 months if the child is not accepted to enter nursery school) and allows employees with preschool-age children the following allowances: up to five days of leave in the event of a child's injury or sickness, limits on the amount of overtime in excess of 24 hours per month based on an employee's request, limits on working late at night based on an employee's request, and opportunity for shorter working hours and flex time for employees.\n\nThe goals of the law would strive to achieve the following results in 10 years are categorized by the female employment rate (increase from 65% to 72%), percentage of employees working 60 hours or more per week (decrease from 11% to 6%), rate of use of annual paid leave (increase from 47% to 100%), rate of child care leave (increase from 72% to 80% for females and .6% to 10% for men), and hours spent by men on child care and housework in households with a child under six years of age (increase from 1 hour to 2.5 hours a day).\n\nJapan's population is aging faster than any other country on the planet. The population of those 65 years or older roughly doubled in 24 years, from 7.1% of the population in 1970 to 14.1% in 1994. The same increase took 61 years in Italy, 85 years in Sweden, and 115 years in France. Life expectancy for women in Japan is 87 years, five years more than that of the U.S. Men in Japan with a life expectancy of 81 years, have surpassed U.S. life expectancy by four years. Japan also has more centenarians than any other country (58,820 in 2014, or 42.76 per 100,000 people). Almost one in five of the world's centenarians live in Japan, and 87% of them are women.\n\nIn contrast to Japan, a more open immigration policy has allowed Australia, Canada, and the United States to grow their workforce despite low fertility rates. An expansion of immigration is often rejected as a solution to population decline by Japan's political leaders and people. Reasons include a fear of foreign crime, a desire to preserve cultural traditions, and a belief in the ethnic and racial homogeneity of the Japanese nation.\n\nHistorically, European countries have had the largest elderly populations by proportion as they became developed nations earlier and experienced the subsequent drop in fertility rates, but many Asian and Latin American countries are quickly catching up. As of 2015, 22 of the 25 oldest countries are located in Europe, but Japan is currently the oldest country in the world and its rapidly aging population displays a trend that other Asian countries such as South Korea, Hong Kong, and Taiwan are expected to follow by 2050. As recently developed nations continue to experience improved health care and lower fertility rates, the growth of the elderly population will continue to rise. In 1970-1975, only 19 countries had a fertility rate that can be considered below-replacement fertility and there were not any countries with exceedingly low fertility (<1.3 children); however, between 2000-2005, there were 65 countries with below-replacement fertility and 17 with exceedingly low fertility.\n\nWhile there has been a global trend of lower fertility and longer life expectancy, it is first evident in the more developed countries and occurs more rapidly in developing or recently developed countries. One of the most astounding aspects of Japan's elderly population, in particular, is that it is both fast-growing and has one of the highest life expectancies equating to a larger elderly population and an older one. According to the World Health Organization, Japanese people are able to live 75 years without any disabilities and fully healthy compared to other countries. Also, American women usually live to around 81 years and American men 76; but compared to Japan, women live to around 87 years and men to 80 years. There is demographic data that shows Japan is an older and more quickly aging society than United States. Japan, also, has reached the condition aging much faster than other developed countries, and they have the highest life expectancy rate among developed countries. They, also, have the highest proportion of the elderly population as well with the highest population decline of developed countries.\n\nJapan is leading the world in aging demographics, but the other countries of East Asia are following a similar trend. In South Korea, where the fertility rate often ranks among the lowest in the OECD (1.21 in 2014), the population is expected to peak in 2030. The smaller states of Singapore and Taiwan are also struggling to boost fertility rates from record lows and to manage aging populations. More than a third of the world's elderly (65 and older) live in East Asia and the Pacific, and many of the economic concerns raised first in Japan can be projected to the rest of the region. India's population is aging exactly like Japan, but with a 50-year lag. A study of the populations of India and Japan for the years 1950 to 2015 combined with median variant population estimates for the years 2016 to 2100 shows that India is 50 years behind Japan on the aging process.\n\n\nGeneral:\n\nInternational:\n\n"}
{"id": "35830787", "url": "https://en.wikipedia.org/wiki?curid=35830787", "title": "Alvin J. Siteman Cancer Center", "text": "Alvin J. Siteman Cancer Center\n\nThe Alvin J. Siteman Cancer Center at Barnes-Jewish Hospital and Washington University School of Medicine is a cancer treatment, research and education institution with six locations in the St. Louis area. Siteman is the only cancer center in Missouri and within 240 miles of St. Louis to be designated a Comprehensive Cancer Center by the National Cancer Institute (NCI). Siteman is also the only area member of the National Comprehensive Cancer Network, a nonprofit alliance of 28 cancer centers dedicated to improving the quality and effectiveness of cancer care.\n\nIn 2015, Siteman received the highest rating possible - exceptional - by the NCI for cancer research. At Siteman's review leading to the rating, researchers presented their findings in genomics, cancer imaging, cancer prevention and disparities, and the use of the body's immune system to fight cancer.\n\nIn 2018, Siteman was named a top 15 U.S. cancer center by U.S. News & World Report. The recognition is part of the overall ranking of its parent institutions, Barnes-Jewish Hospital, which is tied for No. 11 on the newsmagazine's “The Best Hospitals 2018-19 Honor Roll,” and Washington University School of Medicine, which is No. 8 on the newsmagazine's \"2019 Best Medical Schools: Research\" list.\n\nIn 2014, Siteman treated nearly 9,000 newly diagnosed cancer patients and every year provides continuing care to about 40,000 people, making it one of the largest cancer centers in the United States.\n\nSiteman’s main facility is at Washington University Medical Center in St. Louis’ Central West End neighborhood. Five other St. Louis-area sites offer specialized cancer care in suburban locations:\n\nIn 1999, Alvin J. and Ruth Siteman committed $35 million to the development of the Siteman Cancer Center at Washington University School of Medicine and Barnes-Jewish Hospital. The commitment was the largest gift ever received by Barnes-Jewish and Washington University in support of cancer research, patient care and services, education and community outreach.\n\nTimothy Eberlein, M.D., has been director of the center since its inception. John DiPersio, M.D., Ph.D., is deputy director.\n\nIn 2001, the NCI designated Siteman as a Cancer Center, which signaled that the institution had demonstrated significant scope and quality in its cancer research programs. The designation came with $850,000 per year in federal research grants. The NCI named Siteman a Comprehensive Cancer Center in 2005, recognizing its broad-based research, outreach and education activities, and awarded the center a five-year, $21 million support grant. The NCI renewed the designation in 2010 and awarded another five-year grant, totaling $23 million. The grants fund programs and specialized services that promote multidisciplinary research, as well as shared scientific resources and seed awards that enable investigators to develop and pursue new research opportunities.\n\nAlvin J. Siteman announced in 2010 that he would donate $1 million annually to an endowment fund at the center to advance cancer prevention, diagnosis and treatment programs that might not receive federal funding.\n\nMore than 350 Washington University research scientists and physicians provide inpatient and outpatient care at Siteman. The center also offers patient and family support services, including discussion and education groups.\n\nScientists and physicians affiliated with Siteman hold more than $145 million in cancer research and related training grants. The results of basic laboratory research are rapidly incorporated into treatment advances. This process is enhanced by patient access to more than 500 therapeutic clinical studies, including many collaborative efforts with other leading cancer centers throughout the country.\n\nIn 2013, three scientists affiliated with Siteman, Washington University School of Medicine and the McDonnell Genome Institute were included on the Thomson Reuters list of “Hottest Scientific Researchers of 2012”: Richard K. Wilson, Ph.D.; Elaine Mardis, Ph.D.; and Li Ding, Ph.D. The list recognized the 21 most-cited researchers of 2012. Robert Fulton, a fourth scientist from Washington University School of Medicine and the McDonnell Genome Institute, also made the list.\n\nResearchers affiliated with Siteman and/or Washington University School of Medicine have pioneered important advances in cancer research, prevention, education and treatment. Highlights and ongoing studies include these projects:\n\n2018 — Personalized brain cancer vaccines\n\n\n2017 — CAR-T cell therapy and using Zika virus to fight brain cancer\n\n\n2016 — Chemotherapy for brain tumors\n\n\n2015 — Melanoma vaccine and urine test for kidney cancer\n\n\n2014 — Breast cancer vaccine and cancer goggles\n\n\n2013 — Endometrial cancer and leukemia\n\n\n2012 — Leukemia, breast cancer research and cancer prevention\n\n\n2011 — Blood-related cancers\n\n\n2010 — Pediatric cancers\n\n\n2008 — Genetic sequencing\n\n\n2007 — Nanotechnology and radiation therapy\n\n\n2006 — Photoacoustic imaging\n\n\n2003 — Breast cancer\n\n\n2001 — Imaging and the immune system’s role in controlling cancer\n\n\n1998 — Biopsies\n\n\n1994 — Genetic screening test for thyroid cancer\n\n\n1979 — Bone marrow transplants\n\n\nMid-1970s — Imaging\n\n1954 — Growth factors and cancer\n\n\n1946 — Radiocarbon in cancer research\n\n\n1941 — Cyclotron\n\n\n1933 — Lung cancer surgery and the disease’s link to smoking\n\n\nSiteman and Washington University School of Medicine are actively engaged in many projects to prevent cancer in the St. Louis region and across the United States. These efforts include:\n\nIn addition to treatment and research programs, Siteman is involved with community outreach, education and screening. Efforts include:\n\n\nIn 2017, Siteman Cancer Center launched the Siteman Cancer Network, an affiliation with regional medical centers that is aimed at improving the health of individuals and communities through cancer research, treatment and prevention. Network members are Boone Hospital Center's Stewart Cancer Center in Columbia, Missouri and Phelps County Regional Medical Center's Delbert Day Cancer Institute in Rolla, Missouri.\n\n"}
{"id": "18284675", "url": "https://en.wikipedia.org/wiki?curid=18284675", "title": "Asahi Health", "text": "Asahi Health\n\nAsahi (or \"Asahi Health\") is a Finnish health exercise based on the eastern traditions of T'ai chi ch'uan, qigong, yiquan and yoga, with a western scientific viewpoint. Asahi is designed to suit everybody, regardless of physical condition or age. \n\nAsahi exercise is taught and performed in instructed groups, but Asahi can also be performed alone as a form of daily self-treatment. Asahi exercise is ideal for short breaks.\n\nAsahi was created in Finland 2004 by professional sports instructors and martial artists Timo Klemola, Ilpo Jalamo, Keijo Mikkonen and Yrjö Mähönen. They all had high regards towards classical body development techniques such as karate, T'ai chi ch'uan, yiquan and yoga, but these styles, as rewarding as they are, seemed to attract only a small marginal of the Finnish population. \n\nThese classical styles are quite complex and therefore may have a high starting level. They use concepts such as qi and prana, which may seem mystical to western people.\n\nThe purpose of Asahi was to get the best out of these techniques, put it in the most simplified form, make it overall scientific and turn it into an easily approachable form - a health exercise for everybody with no starting level at all. \n\nAsahi is designed to treat and prevent shoulder- and back problems, fractures due to falling down and stress-related psychosomatic problems.\n\nAsahi is a series of slow movements, completed in silence. It looks harmonious and beautiful, a bit like qigong.\n\nThe basic six principles of Asahi are:\n\n1. The linking of movement and breath\n2. Practicing vertically erect body alignment\n3. Whole body movement\n4. Listening to the slow motion\n5. Cultivating the mind with mental images\n6. The exercise as a continual, flowing experience\n\nThe Asahi movements are soft and performed in the rhythm of breathing. The series is simple and easy to learn. The movements have also a practical function, for example picking up a ball from the floor or improving one’s balance by standing on one foot. Advanced levels are designed for long-term trainees, yet they are equally simple to learn.\n\nAsahi can be practiced in major areas of Finland. Asahi Health Ltd has also been accepted as an Education Partner to Federation of International Sports, Aerobics and Fitness as the first Body Mind -product to be recognized and recommended by this organization.\n\n\n\n"}
{"id": "24928671", "url": "https://en.wikipedia.org/wiki?curid=24928671", "title": "Australasian Plant Pathology Society", "text": "Australasian Plant Pathology Society\n\nThe Australasian Plant Pathology Society (APPS) is a scientific association whose members study plant diseases. Its members are located in Australia, New Zealand and Papua New Guinea, and also the Indian, Pacific and Asian regions. The society was founded in 1969.\n\nAs part of their membership in APPS, members are also associate members of the International Society for Plant Pathology.\n\nThe 2013 APPS conference was held in Auckland, New Zealand. \n\nThe official journals of the society, \"Australasian Plant Pathology \" and \"Australasian Plant Disease Notes\", are published by Springer Science+Business Media.\n\n"}
{"id": "43569192", "url": "https://en.wikipedia.org/wiki?curid=43569192", "title": "Aversion to happiness", "text": "Aversion to happiness\n\nAversion to happiness, also called cherophobia or fear of happiness, is an attitude towards happiness in which individuals may deliberately avoid experiences that invoke positive emotions or happiness.\n\nOne of several reasons why cherophobia may develop is the belief that when one becomes happy, a negative event will soon occur that will taint that happiness, as if punishing that individual for satisfaction. This belief is thought to be more prevalent in Eastern cultures. In Western cultures, such as American culture, \"it is almost taken for granted that happiness is one of the most important values guiding people's lives\". Western cultures are more driven by an urge to maximize happiness and to minimize sadness. Failing to appear happy often gives cause for concern. The value placed on happiness echoes through Western positive psychology and through research on subjective well-being.. Fear of happiness is associated with fragility of happiness beliefs, suggesting that one of the causes of aversion to happiness may be the belief that happiness is unstable and fragile. Research shows that fear of happiness is associated with avoidant and anxious attachment styles.\n\nThere are four major reasons why cherophobes avoid happiness: \"believing that being happy will provoke bad things to happen; that happiness will make you a worse person; that expressing happiness is bad for you and others; and that pursuing happiness is bad for you and others\". For example, \"some people—in Western and Eastern cultures—are wary of happiness because they believe that bad things, such as unhappiness, suffering, and death, tend to happen to happy people.\"\n\nThese findings \"call into question the notion that happiness is the ultimate goal, a belief echoed in any number of articles and self-help publications about whether certain choices are likely to make you happy\". Also, \"in cultures that believe worldly happiness to be associated with sin, shallowness, and moral decline will actually feel less satisfied when their lives are (by other standards) going well\", so measures of personal happiness cannot simply be considered a yardstick for satisfaction with one's life, and attitudes such as aversion to happiness have important implications for measuring happiness across cultures and ranking nations on happiness scores.\n"}
{"id": "21380304", "url": "https://en.wikipedia.org/wiki?curid=21380304", "title": "Bailey Barton Burritt", "text": "Bailey Barton Burritt\n\nBailey Barton Burritt (31 May 1878 – 18 June 1954) was a United States public health and social welfare advocate known as \"the father of the family health movement.\" He was the chairman of the executive council of the Community Service Society.\n\nHe graduated from the University of Rochester in 1902 and Columbia University in 1903. He married Ruth Hogarth Dennis (1879–1960) on May 18, 1909.\n"}
{"id": "55778765", "url": "https://en.wikipedia.org/wiki?curid=55778765", "title": "Caetextia", "text": "Caetextia\n\nCaetextia (from the Latin word \"caecus\", meaning \"blind\" and \"contextus\", meaning \"context\") is a term and concept first coined by psychologists Joe Griffin and Ivan Tyrrell to describe a chronic disorder that manifests as a context blindness in people on the autism spectrum. It was specifically used to designate the most dominant manifestation of autistic behavior in higher-functioning individuals. Griffin and Tyrell also suggested that caetextia \"is a more accurate and descriptive term for this inability to see how one variable influences another, particularly at the higher end of the spectrum, than the label of 'Asperger's syndrome'\".\n\nThose who suffer from caetextia often experience elevated levels of frustration, anger, and anxiety when faced with a situation that requires giving attention to more than one interacting variable or factor at a time. This can be attributed to the inability to unconsciously draw upon the contextual information presented in a given situation as well as evaluate the significance of change with regards to the surrounding environment.\n\nCaetextia can also exist in a temporary form prompted by stress, anxiety, or depression.\n\nMany of the symptoms observed in patients with Asperger's can be attributed to caetextia. In order for someone to be considered contextually aware, they must be able to attach attention to and detach it from the interacting variables in a given situation. This implies active integration of sensory information gathered from the situation. It has been found that patients differ in their ability to perform these functions based on the dominant hemisphere of their brain.\n\nContext blindness has been speculated as having a relationship with other prominent neurocognitive theories of Autism Spectrum Disorder (ASD) such as theory of mind, empathizing-systemizing, and executive function.\n\n"}
{"id": "47233365", "url": "https://en.wikipedia.org/wiki?curid=47233365", "title": "Caraga candy poisonings", "text": "Caraga candy poisonings\n\nAlmost 2,000 people, mostly schoolchildren from the Caraga Region, experienced food poisoning after consuming durian, mangosteen, and mango flavored candies.\n\nMost of the victims of the food poisoning incident were schoolchildren within the Caraga Region. Victims reported of experiencing symptoms such as diarrhea, dizziness, and stomachache. The cases were reported by at least nine health facilities based in Surigao del Sur, Surigao del Norte and Agusan del Sur.\n\nThe first cases were reported in Cagwait, Surigao del Sur in the morning of July 10.\n\nPoisonings were reported in the following towns:\n\nActing Mayor Paolo Duterte of Davao City ordered an urgent investigation on July 10 regarding the matter to determine the exact cause of the candy poisoning incident.\n\nOn July 11, 2015, the Department of Health in the Caraga declared a food poisoning outbreak in the region. Hospitals across the Caraga Region were put into white alert in response to the poisoning incident.\n\nThe Food and Drug Administration (FDA) has traced the tainted candies' origin to two manufacturing facilities in Davao City. The FDA has linked two candy manufacturers to the poisoning incident based on labels found on the food products, one which is licensed with the food safety authority and the other manufacturer, Wendy's Durian Candies is not in the database of the FDA.\n\nJanet Aquino of Wendy's Durian Candies said the candies were apparently repacked when she saw the candies made by her company in news report. She noted that the candies' packages included a cut-up portions of the original label of the products.\n\nThe FDA has also conducted a Microbiological tests on the samples of the tainted candies and is suspecting that the candies were contaminated by E. Coli, Salmonella or staphylococcus based on the reported symptoms by victims of the food poisoning incident. In a press conference on June 16, 2015, announced that the candy samples were tested positive for \"staphylococcus aureus\".\n\nOne of the linked manufacturers to the poisoning incident was Wendy’s Durian Candies. Janet Aquino, whose family runs the manufacturing firm, admitted that her company made the candies linked to the poisonings. However she added that the repacking of the candies by the distributors might be the cause of the poisonings. The Davao City government has suspended the business permit of Wendy's Durian Candies until the business secure a clearance from the FDA. Wendy Aquino, owner of the business, has apologized for the incident in behalf of the company.\n\nNine men and women linked to the poisonings were arrested. The arrested were identified as vendors; Junnil Martinez, John Oben, Joel Pasa, Richard Rivera Jr, Martinez Bocaycay, Genelyn Pasa, Junnel Teriote, John Dequilla, Henryto Amogui and three more people whose names were not disclosed.\n\nPasa, 26, and Amoguis 21, from Davao City and Valencia, Bukidnon respectively, were seen selling the tainted durian, mango and mangosteen flavored candies at the Special Education Elementary School in Tandag. The same vendors were also believed to have sold the candies in Aras-Arasan in Cagwait and Carrascal.\n\nOne of those arrested is named John Dequilla, who had been client of Wendy's Durian Candies for at least two years. Janet Aquino, representing the candy manufacturer, said that Dequilla ordered 300 bags of 100-piece packs of candies in July 7 to be delivered in Tandag in Surigao del Sur. Aquino noted that it was the first time Dequilla asked for the candies to be delivered in Tandag.\n"}
{"id": "47646622", "url": "https://en.wikipedia.org/wiki?curid=47646622", "title": "Cathy Warwick (midwife)", "text": "Cathy Warwick (midwife)\n\n\"Not to be confused with Cathy Warwick the chess player.\"\n\nDame Catherine Lilian \"Cathy\" Warwick is a Scottish midwife, trade union leader, and abortion rights activist. She has been the Chief Executive of the Royal College of Midwives since 2008, and is also Chair of Trustees of BPAS, one of the UK's leading providers of abortion services.\n\nShe received a nursing degree from the University of Edinburgh in 1975, and completed a one-year midwifery course at Queen Charlotte's Hospital in 1976. She is an Honorary Professor of Midwifery at King's College London School of Midwifery. She was awarded a CBE for services to healthcare in the 2006 Birthday Honours and elevated to DBE in the 2018 New Year Honours.\n\nShe was ranked sixth in the Health Service Journal's list of Clinical Leaders in 2015. In October 2014, she led the first ever strike by midwives in the United Kingdom.\n"}
{"id": "33219341", "url": "https://en.wikipedia.org/wiki?curid=33219341", "title": "Center for Personalized Education for Physicians", "text": "Center for Personalized Education for Physicians\n\nThe Center for Personalized Education for Physicians (CPEP) is a non-profit organization, headquartered in Denver, Colorado, and it specializes in physician competency assessment and educational intervention. The organization was established in 1990 as a collaborative effort of seven Colorado healthcare organizations: the Colorado Alliance for CME, the Colorado Foundation for Medical Care, the Colorado Hospital Association, the Colorado Medical Society, the Colorado Physician Health Program, the Colorado Society of Osteopathic Medicine and the University of Colorado School of Medicine.\n\nCPEP provides assessment and education for physicians re-entering practice. Its approach is based on the idea that education should be directed by an evaluation of the individual's educational needs and that traditional continuing medical education conferences alone may not be effective in improving practice. This is consistent with the approach of remediation programs both in the United States and internationally. Physicians take part in CPEP programs for medical ethics education and training, to address performance evaluation issues and concerns, and to help them reinstate their medical licenses.\n\nCPEP collaborates with the University of Colorado Schoolof Medicine and is led by faculty and other physician consultants who are board certified in their respective specialties. CPEP is one of five programs nationwide that have been accepted as members of the Coalition for Physician Enhancement, the primary U.S. organization representing programs that provide physician assessment and education. \n\nCPEP receives no funding from medical licensure fees or state sources. Instead, the organization is supported by participant fees and donations from the Colorado medical community, including the COPIC Companies. \n\nAssessment Testing\n\nDoctors are referred to CPEP for competency assessments from different organizations, including hospitals, medical groups and state medical boards. The CPEP approach to physician competency evaluation and assessment has three major components: clinical competence assessment, educational intervention, and post-educational evaluation. \n\nThe assessment is individualized based on the physician’s practice and the concerns of the referring organization. The actual assessment includes structured clinical interviews, simulated patient encounters and written testing. This testing is overseen by a board-certified physician who acts as an associate medical director (AMD). This AMD then compiles a final report, and the physician receives recommendations for education based on their needs.\n\nProBE\n\nThe ProBE (Professional/Problem-Based Ethics) Program started in 1992 in New Jersey as collaboration between the New Jersey State Board of Medical Examiners and The Ethics Group, LLC. The program started as a way to provide educational intervention to physicians who were identified by the Board and had received ethical infractions. \nBy 1996, the ProBE Program had been endorsed by 45 licensing boards and sub-specialty boards throughout the United States. In 2007, CPEP acquired The Ethics Group, LLC, and began offering the program.\n\nThe ProBE Program provides education for healthcare professionals, and it focuses on ethics violations and unprofessional conduct secondary to boundary violations in the practice of healthcare. These violations can include financial irregularities, misrepresentation, sexual misconduct, disruptive behavior and substance abuse. The class is offered in Denver, Colorado and Newark, New Jersey in the United States, and Toronto, Ontario, Canada.\n\nOther Programs\n\nCPEP offers a Clinical Practice Reentry Program for physicians who wish to reenter the field after a voluntary absence to enhance a physician's practice, and/or restore a physician's clinical capabilities. This program evaluates the physician’s clinical skills, including structured clinical interviews and a one-day comprehensive evaluation. Physicians are then given a reentry plan, which includes supervised clinical experience to update skills and knowledge and a detailed reporting of progress. To enter this program, physicians must have left the medical field in good standing, and they must want to reenter in the same clinical practice for which they were trained.\n\nThe Patient Care Documentation Seminar teaches physicians how to identify basic documentation guidelines, understand the legal issues associated with poor documentation and overcome barriers to good documentation. Physicians can receive up to eight continuing medical education credits and up to two Experience Rating System points for taking the class.\n\nThe Personalized Implementation Program is the follow-up class to the Patient Care Documentation Seminar. Physicians submit three sets of charts to CPEP at two, four and six months, and they receive feedback via checklists from a medical consultant on their progress at two and four months. Physicians then contact CPEP for a telephone conference with a medical reviewer and receive a final report of their progress after the last chart is submitted.\n\n"}
{"id": "20480442", "url": "https://en.wikipedia.org/wiki?curid=20480442", "title": "Centre of Biological Research (Spain)", "text": "Centre of Biological Research (Spain)\n\nThe Centre of Biological Research (Spanish: Centro de Investigaciones Biológicas) is a leading research centre in Spain, specialising in molecular genetics. It belongs to the Spanish National Research Council (CSIC). \n\nCreated in 1958, the centre leads Spanish and European research in the fields of biology and biomedicine. Set up under the auspices of Nobel laureate Santiago Ramón y Cajal, its first director was Gregorio Marañon. Leading scientists associated with the centre include Mariano Barbacid.\n\nOriginally located in the centre of Madrid, its new facilities at the Complutense University of Madrid campus were inaugurated on 26 January 2004 by Her Royal Highness Infanta Cristina, Duchess of Palma de Mallorca.\n\nThe centre is divided into five departments corresponding to the scientific areas they specialise in: \n\nWith 90 staff scientists and some 500 pre-and postdoctoral research fellows, technical and administrative staff, it has a high output in leading English-and Spanish language scientific reviews.\n\n"}
{"id": "18216963", "url": "https://en.wikipedia.org/wiki?curid=18216963", "title": "Coronectomy", "text": "Coronectomy\n\nWhen extracting lower wisdom teeth, Coronectomy is a treatment option involving removing the crown of the lower wisdom tooth, whilst keeping the roots in place in healthy patients. This option is given to patients as an alternative to extraction when the wisdom teeth are in close association with the inferior alveolar nerve, and so used to prevent damage to the nerve which may occur during extraction.\n\nPrevents potential neuropathy\n\nThe risk of altered sensation is significantly lower than convention surgical removal of mandibular third molars with 8% of the cases affected temporarily and 3.6% of the cases got permanently affected. \n30% of the roots will migrate post-coronectomy, erupting away for the inferior alveolar canal. This makes extraction of the remaining roots safer.\n\nThere is a 5% chance of failure of coronectomy, the root will become mobilized during transection. In 5% of the cases, follicle remnants will form deep periodontal pockets which will lead to infection.\n\nCoronectomy should be considered if there are signs that the patient is at a high risk of nerve damage during extraction:\n\n\nThe patient should be aware of the potential risks of the procedure such as:\n\nA plain film radiograph allows the proximity of the tooth to the inferior alveolar canal to be assessed. The plain film can be assessed to identify the tooth as high risk If there is; loss of the lamina dura, darkening of the canal and grooving of the root. If the mandibular third molar is deemed to be high risk, a cone beam CT (CBCT) is taken in addition to the plain film. The justification of additional radiography can be justified by the surgeon as it allows them to gain further information regarding the tooth roots and the inferior alveolar canal should the roots be mobilised when transecting.\n\nVerbal consent must be attained by the surgeon prior to the procedure of a coronectomy. Additionally consent must be gained if removal of the roots is required due to mobilisation. The patient should be informed of early and late infection meaning the roots may need removing.\n\n\nIf the patient presents with dry socket, irrigate with chlorohexidine mouthwash and place resorbable dressing such as Alvogyl. If the patient has recurrent infection, consideration to remove the roots should be noted.\n\nIn a few cases the remaining roots may erupt which can minimise the morbidity of the inferior alveolar nerve, however the roots may be in close contact to the inferior alveolar nerve requiring surgical separation. \n"}
{"id": "5778583", "url": "https://en.wikipedia.org/wiki?curid=5778583", "title": "Culture and menstruation", "text": "Culture and menstruation\n\nCulture and menstruation is about cultural aspects surrounding how society views menstruation. A \"menstrual taboo\" is any social taboo concerned with menstruation. In some societies it involves menstruation being perceived as unclean or embarrassing, inhibiting even the mention of menstruation whether in public (in the media and advertising) or in private (among friends, in the household, or with men). Many traditional religions consider menstruation ritually unclean, although anthropologists point out that the concepts 'sacred' and 'unclean' may be intimately connected.\n\nDifferent cultures view menstruation in different ways. The basis of many conduct norms and communication about menstruation in western industrial societies is the belief that menstruation should remain hidden. By contrast, in many hunter-gatherer societies, particularly in Africa, menstrual observances are viewed in a positive light, without any connotation of uncleanness.\n\nThe word \"menstruation\" is etymologically related to \"moon\". The terms \"menstruation\" and \"menses\" are derived from the Latin \"mensis\" (month), which in turn relates to the Greek \"mene\" (moon) and to the roots of the English words \"month\" and \"moon\".\n\nAccording to the anthropologists Buckley and Gottlieb, cross-cultural study shows that, while taboos about menstruation are nearly universal, and while many of these involve notions of uncleanliness, numerous menstrual traditions \"bespeak quite different, even opposite, purposes and meanings.\" In some traditional societies, menstrual rituals are experienced by women as protective and empowering, offering women a space set apart from the male gaze and from unwanted sexual or domestic pressures and demands.\n\nAn instructive example is provided by the anthropologist Wynne Maggi, who describes the communal \"bashali\" (large menstrual house) of women in the Kalasha Valley (northwestern Pakistan) as their 'most holy place', respected by men, and serving as women's all-female organizing centre for establishing and maintaining gender solidarity and power. According to one body of cultural evolutionary scholarship, the idea that menstrual blood marks the body as periodically sacred was initially established by female coalitions in their own interests, although later, with the rise of cattle-ownership and patriarchal power, these same beliefs and taboos were harnessed by religious patriarchs to intensify women's oppression.\n\nMetaformic Theory, as proposed by cultural theorist Judy Grahn and others, places menstruation as a central organizing idea in the creation of culture and the formation of humans' earliest rituals.\n\nMenstruation in synchrony with the moon is widely assumed in myths and traditions as a ritual ideal. The idea that menstruation is—or ideally ought to be—in harmony with wider cosmic rhythms is one of the most tenacious ideas central to the myths and rituals of traditional communities across the world. One of the most thoroughgoing analyses of primitive mythology ever undertaken was that of the French anthropologist Claude Lévi-Strauss, who concluded that, taken together, the indigenous myths of North and South America expressed men's worry that, unless women's periods were carefully monitored and synchronised, the universe might descend into chaos.\n\nIn Aboriginal Australia, the supernatural being known as the 'Rainbow Snake' has been interpreted as, among other things, an indigenous way of conceptualising the ideal of synchronised tidal, lunar, menstrual and seasonal periodicities whose overall harmony (it is believed) confers spiritual power and fertility.\n\nTo many, such cultural associations appear persuasive in view of the fact that in humans, the menstrual cycle quite closely approximates the moon's 29.5-day synodic cycle, unlike in chimpanzees (~36 days) or bonobos (~40 days). Statistical information from hunter gatherers is lacking, but where large-scale western studies focus on women's peak reproductive years—removing outlier values—the cycle length gravitates around 29.1–29.5 days, while the figure for women in their thirties shortens toward 28 days. In no extant human population has statistically significant lunar phase-locking been demonstrated.\n\nIn some historic cultures, a menstruating woman was considered sacred and powerful, with increased psychic abilities, and strong enough to heal the sick. According to the Cherokee, menstrual blood was a source of feminine strength and had the power to destroy enemies. In Ancient Rome, Pliny the Elder wrote that a menstruating woman who uncovers her body can scare away hailstorms, whirlwinds and lightning. If she strips naked and walks around the field, caterpillars, worms and beetles fall off the ears of corn. Menstrual blood is viewed as especially dangerous to men's power. In Africa, menstrual blood is used in the most powerful magic charms in order to both purify and destroy.\nMayan mythology explains the origin of menstruation as a punishment for violating the social rules governing marital alliance. The menstrual blood turns into snakes and insects used in black sorcery, before the Maya moon goddess is reborn from it.\n\nWhere women's blood is considered sacred, the belief is that it should be ritually set apart. According to this logic, it is when sacred blood comes into contact with profane things that it becomes experienced as ritually dangerous or 'unclean'.\n\nMenstruating women having been believed to be dangerous.\n\nThe sociological theorist Emile Durkheim argued that human religion in its entirety emerged originally in connection with menstruation. His argument was that a certain kind of action – collective ritual action – could establish simultaneously totemism, law, exogamy and kinship in addition to distinctively human language and thought. Everything began, according to Durkheim, when a flow of blood periodically ruptured relations between the sexes. 'All blood is terrible', he observed, 'and all sorts of taboos are instituted to prevent contact with it'. During menstruation, females would exercise a 'type of repulsing action which keeps the other sex far from them'. This same blood was thought to run through the veins of women and animals alike, suggesting the blood's ultimate origin in 'totemic'—part-human, part-animal—ancestral beings. Once menstrual blood had been linked with the blood of the hunt, it became logically possible for a hunter to respect certain animals as if they were his kin, this being the essence of 'totemism'. Within the group's shared blood resided its 'god' or 'totem', 'from which it follows that the blood is a divine thing. When it runs out, the god is spilling over'.\n\nIn Buddhism (Theravada or Hinayana) menstruation is viewed as \"a natural physical excretion that women have to go through on a monthly basis, nothing more or less\". However, in certain branches of Japanese Buddhism, menstruating women are banned from attending temples.\nIn Nichiren Buddhism (Japan) menstruation is not considered a spiritual obstacle to religious practice, although a menstruating woman may choose not to bow, for comfort.\n\nMost Christian denominations do not follow any specific rituals or rules related to menstruation. Some denominations follow the rules laid out in the Holiness Code section of Leviticus, somewhat similar to the Jewish ritual of Niddah.\n\nSome church fathers defended the exclusion of women from ministry based on a notion of uncleanness. Others held that purity laws should be discarded as part of the Old Covenant.\n\nSome Christian denominations, including many authorities of the Eastern Orthodox Church and some parts of the Oriental Orthodox Church (also known as the Russian, Ukrainian, Greek, and Indian Orthodox Church), distinct from the Roman Catholic Church, advise women not to receive communion during their menstrual period.\n\nConservative/traditionalist members of the Orthodox Church observe the ancient practice of abstaining from Holy Communion during menstruation.\nThis is a fairly common practice throughout Greece and Russia and other historically Orthodox Christian countries. However, in most non-Orthodox countries—especially in Europe and North America—a sizable majority of women do not practice this ancient rule, although a minority of women still do. In fact, many Orthodox Christian women are unaware of the ancient practice of abstaining from Holy Communion due to menstruation, or merely view it as an \"old wives' tale\". Many Orthodox Christians in Non-Orthodox countries are advised to disregard this practice, as it is seen as an excuse to not participate in the sacrament of Communion and in fact, discourages laity involvement in the service of Divine Liturgy.\n\nIn Hinduism, menstruating women are traditionally considered ritually impure and given rules to follow. During menstruation, women are not allowed to “enter the kitchen and temples\", wear flowers, have sex, touch other males or females.” Women themselves are seen as impure and polluted, and are often isolated as untouchables, unable to return to their family, for the length of their period.\n\nIn 1991, the Kerala High Court restricted entry of women above the age of 10 and below the age of 50 from Sabarimala Shrine as they were of the menstruating age. On 28th September 2018, the Supreme Court of India lifted the ban on the entry of women. It said that discrimination against women on any grounds, even religious, is unconstitutional.\n\nIn Shaktism the Earth's menstruation is celebrated during the Ambubachi Mela, an annual fertility festival held in June, in Assam, India. During Ambubachi, the annual menstruation course of the goddess Kamakhya is worshipped in the Kamakhya Temple. The temple stays closed for three days and then reopens to receive pilgrims and worshippers. It is one of the most important pilgrimage sites in the world, attracting millions of visitors each year, particularly for Ambubachi Mela which draws upwards of 100,000 pilgrims per day during the 4-day festival.\n\nDuring menstrual periods, women are excused from performing prayers. They should not fast and left over fasts of Ramadan are to be completed during other days. During menses pilgrimages are allowed; however, circumambulation of the Kaaba is prohibited and is to be performed during other times. Respect for women on their period is valued. They are advised to not enter the praying place of mosque without any important purpose, but are encouraged to be present at muslims gatherings and festivals (Eids). After the period, a bath (Ghusl), which is also required of both partners after sex, is also required before prayer may continue.\nThe traditional Islamic interpretation of the Qur'an forbids intercourse, but not physical intimacy, during a woman's menstrual period. The Qur'an explicitly prohibits a menstruating woman from sexual intercourse. If a man is engaged in sexual intercourse with his wife and discovers that her period has started, he must immediately withdraw.\n\nScholars argue that menstruating women are in a state in which they are unable to maintain wudhu, and are therefore prohibited from touching the Arabic version of the Qur'an. Similarly, other biological and involuntary functions such as vomiting, bleeding, sexual intercourse, and going to the bathroom invalidate one's wudhu. On authority of Urwah:\nMenstruating women are also prohibited from engaging in tawaf during Hajj. When A'isha wept to Muhammad when she was not able to perform tawaf on her menses, Muhammad responded, \"This is a thing which Allah has ordained for the daughters of Adam. So do what all the pilgrims do with the exception of the Tawaf (Circumambulation) round the Ka'ba.\" \n\nIn Judaism, a woman during menstruation is called \"niddah\" and may be banned from certain actions. For example, the Jewish Torah prohibits sexual intercourse with a menstruating woman. The ritual exclusion of \"niddah\" applies to a woman while menstruating and for about a week thereafter, until she immerses herself in a mikvah (ritual bath) which is basically intended only for married women. During this time, a married couple must avoid sexual intercourse and physical intimacy. Orthodox Judaism forbids women and men from even touching or passing things to each other during this period. While Orthodox Jews follow this exclusion, many Jews in other branches of the religion do not.\n\nIn the Torah (Leviticus 15:19-30), a menstruating female is considered ritually unclean - \"anyone who touches her will be unclean until evening\" (New International Version). Touching a menstruating female, touching an object she had sat on or lain on, or having intercourse with her also makes a person ritually unclean. The extent to which these rules are observed in modern Judaism varies depending on the degree of conservatism/orthodoxy.\n\nBahá'u'lláh, the founder of the Bahá'í Faith, in the \"Kitáb-i-Aqdas\" abolished all forms of ritual impurity of people and things and stressed the importance of cleanliness and spiritual purity. Menstruating women are encouraged to pray and are not required to fast; they have the (voluntary) alternative of reciting a verse instead.\n\nWoman's menstrual blood is considered to be impure in several important Jain texts. The bleeding that occurs in menstruation is thought to kill micro-organisms in the body, making the female body less non-violent than the male body—although that idea does not have any scientific support. Jainism does not permit women to cook or attend temples while menstruating.\n\nIn Japan, the religion of Shinto did and still does play a part in their society. The Kami, the spirits they worshiped, would not grant wishes if you had traces of blood, dirt, or death on you. While menstruation is not entirely blood, the ancient Japanese did not know that. As a result, women who were menstruating were not allowed to visit any of the Kami shrines for the duration of their menstrual period. Even today, women are not allowed to enter Shinto shrines and temples during menstruation, and in some instances, women are completely banned from climbing the tops of sacred mountains due to their 'impurity'. Furthermore, the tradition is kept somewhat alive in the belief that the shedding of the endometrial lining is a kind of death. It is theorized that the Kami are the reason Japan is kept so clean and, in many houses, minimalistic.\n\nIn Sikhism, woman is given equal status to man and is regarded as pure as man is. The Sikh gurus teach that one cannot be pure by washing his body but purity of mind is the real pureness. They are not called pure, who sit down after merely washing their bodies. Guru Nānak, the founder of Sikhism, condemned the practice of treating women as impure while menstruating.\n\nIn Sikhism, the menstrual cycle is not considered a pollutant. Certainly, it can have a physical and physiological effect on the woman. Nonetheless, this is not considered a hindrance to her wanting to pray or accomplish her religious duties fully. The Guru makes it very clear that the menstrual cycle is a God-given process. The blood of a woman is required for the creation of any human being. The requirement of the mother's blood is fundamental for life. Thus, the menstrual cycle is certainly an essential and God-given biological process. In other faiths blood is considered a pollutant. However, the Guru rejects such ideas. Those who are impure from within are the truly impure ones.\n\nMeditating on God's name is of importance in Sikhism. Whether your clothes are blood stained or not (including clothes stained from menstrual blood) is not of spiritual importance. Thus, there are no restrictions placed on a woman during her menstruation. She is free to visit a gurdwara, take part in prayers and do Seva. In \"The Feminine Principle\" in the Sikh vision of the transcendent, Nikky Guninder Kaur-Singh writes:\n\nGuru Nānak, the founder of Sikhism, condemned the practice of treating women as impure while menstruating. In Sikhism, the menstrual cycle is not considered a pollutant. Certainly, it can have a physical and physiological effect on the woman. Nonetheless, this is not considered a hindrance to her wanting to pray or accomplish her religious duties fully. The Guru makes it very clear that the menstrual cycle is a God given process. (Guru Granth Sahib Ji, p. 1013).\n\nAcross the continent of Africa, a wide variety of menstruation-related customs have been recorded.\nA cloth torn from the traditional wrap (chitenge) is worn, part tied around the waist and part looped under the crutch, to catch menstrual fluid. Menarche (the first menstrual cycle at puberty) is traditionally treated as a sign that the girl is probably ready for sex and marriage, as well as for adult duties in the household. Initiation rites on menarche include instruction on sex and marital relations as well as on menstrual management. This is conducted by older women. It is taboo to talk about menstruation with men, or to learn from one's own mother. \nIn some portions of South Asia, there is a menstrual taboo, with it frequently being considered impure. Restrictions on movement, behaviour and eating are frequently placed. More than one-third of girls across South Asia do not go to school during menstruation. Some of that is due to lack of safe and comfortable toilets at school (lack of water, sanitation and hygiene in schools in developing countries).\nA small study in a rural area in Laos (Savannakhet) found that menstruation is considered taboo and shameful. This makes it difficult for sharing knowledge in schools and in homes. Also, there is a low level of menstrual hygiene management. This has a negative effects on the female's social opportunities in achieving a good health, move around freely and to go to school. Some menstruating women (16%) wear double-layer skirts (sinhs) while in the private sphere, compared to 54% who wear disposable pads.\n\nHindus in India tend to view menstruation, especially first menstruation or menarche, as a positive aspect of a girl's life. In South India, girls who experience their menstrual period for the first time are given presents and celebrations to mark the occasion.\n\nIn many traditional Hindu homes in India, girls and women face restrictive taboos relative to menstruation, such as being denied entry to the temple and the kitchen. In areas around the Jhabua district, the belief is that \"menstruation is a disease and not a normal biological process\", and therefore women who are menstruating are not allowed to sleep on beds, enter kitchens, touch male members of their family or eat spicy foods.\n\nIn a 2014 study conducted in India, the researchers found that as many as 42% of women who participated in the study did not know about sanitary pads or from where in their anatomy menstruation originated. \"Most of them were scared or worried on first menstruation.\"\n\nIn Bali, a woman is not allowed to enter the kitchen to perform her usual duties, nor is she allowed to have sex with her husband while menstruating. She is to sleep apart from the family and has to keep her clothes that she wears while menstruating away from any clothes that she could wear to the temple. One of the most important regulations is that a woman is not allowed to attend temple while menstruating.\n\nIn Sumba, women keep their cycles secret, which makes men see them as deceitful. Women from Sumba believe that because of their secrecy, they will always have control of the men. \"Men will never know how much we really can do to control these things. We have all kinds of secrets, and they should always believe that we can control even more than we really can\".\n\nWomen are supposed to avoid intercourse while menstruating. It is believed that sexually transmitted diseases are the results of women deceiving men and having intercourse while they are menstruating. Gonorrhea translates as \"disease you get from women\" in Sumba; it has become a social problem. When a man would get this disease, the only way they believed he could rid himself of painful sores was to pass it to a woman. The reasoning was that a woman's body can absorb infection and purge it during a cycle.\n\nHindus in Nepal traditionally keep women isolated during menstruation, when women who are menstruating are not allowed in the household for a period of 3 nights. This practise was banned by the Nepalese Supreme Court in 2005 but still continues. Chhaupadi is a social tradition associated with a menstrual taboo in the western part of Nepal. The tradition prohibits Hindu women and girls from participating in normal family activities while menstruating, as they are considered \"impure\". In some parts of western Nepal, the custom of \"chhaupadi\" requires menstruating girls and women to sleep in a hut called \"Chhau Goth\" some distance from the family home\n\nTwo-thirds of girls in Sri Lanka were unaware of menstruation before reaching puberty.\n\nThe Yurok in North America practiced menstrual seclusion. Yurok women used a small hut near the main house.\n\nA survey conducted in 1981 showed that a substantial majority of U.S. adults and adolescents believed that it is socially unacceptable to discuss menstruation, especially in mixed company. Many believed that it is unacceptable to discuss menstruation even within the family. Studies in the early 1980s showed that nearly all girls in the United States believed that girls should not talk about menstruation with boys, while more than one-third of girls did not believe it appropriate to discuss menstruation with their father.\n\nMenstruation education is frequently taught in combination with sex education in the US, although one study suggests that girls would prefer their mothers to be the primary source of information about menstruation and puberty. A Nigerian study showed the following breakdown in menstruation education: “parents of 56%, friends of 53%, books of 46%, teachers of 44%, internet of 45%, and health centers of 54” held the most influence in terms of menstruation education. Information about menstruation is often shared among friends and peers, which may promote a more positive outlook on puberty.\n\nThe quality of menstrual education in a society determines the accuracy of people's understanding of the process. This is in part due to the segregation of male and female peers during educational sessions. Failure to teach an accurate understanding of menstruation to students of all genders has social implications for gendered relationships and the objectification of women’s bodies. Discomfort arises when students do not have access to the same information, reinforcing the belief “that menstruation is gross and should be kept hidden”. Girls are encouraged to conceal the fact that they may be menstruating in order to be considered desirable. Sexual harassment and teasing about menstruation cause girls anxiety as they must struggle to ensure that they give no sign of menstruation.\n\nEffective educational programs are essential to providing children and adolescents with clear and accurate information about menstruation. Several education and sexual health experts have studied the key features necessary for such programs. Some experts maintain that schools are an appropriate place for menstrual education to take place because they are an institution that young people attend consistently. Schools are intended to expand students’ knowledge and thus serve as an appropriate site for conveying menstrual education.\n\nOther experts argue that programs led by peers or third-party agencies are more effective than those taught in the school classroom. This may be due to the use of small group interactions, the ability of these programs to target specific populations, or the possibility that many teenagers choose to participate voluntarily in these programs, rather than being mandated to attend school programs.\n\nOne common way that sanitary-product advertising avoids depicting menstruation is by pouring a blue, rather than red, liquid on the sanitary product to demonstrate its absorptivity. Further evidence of the taboo is the creation of a variety of euphemisms for menstruation, including \"Aunt Flo\", \"on the rag\", \"my friend\", or even \"the curse\".\n\nIn 2010, the \"Always\" tampon brand created the first feminine hygiene ad to ever feature a tiny red spot, representing blood. The ad was created by an intern who was working at Always' advertising agency, Leo Burnett. Originally the ad was created for the intern's personal portfolio, but then it caught the attention of the chief creative officer at Leo Burnett, and was subsequently published as an actual ad. There was some controversy when the ad was first released. In June 2016 the presence of red blood in a UK Bodyform commercial was greeted with approval in social media for its attempt to challenge the stereotypical menstruation ad, by showing women who struggle despite bleeding from cuts, blows and bruises they receive while playing various sports.\n\nMovies and television also reflect the taboo nature of menstruation. Typically menstruation as a topic is avoided, except for scenes involving menarche or the first period. For example, as Elizabeth Arveda Kissling explains in her article, \"On the Rag on Screen: Menarche in Film and Television\", the early 1991 movie \"My Girl\" contains a scene where the main character, Vada, experiences her first period. The explanation given to her by a female role model of what is happening to her is done off-camera and the subject is never mentioned again, save when Vada pushes Thomas across the porch telling him, \"Don't come back for five to seven days.\"\n\nIn the movie \"Carrie\", the title character has her first period in the school gym shower, and the other girls tease her by throwing tampons and sanitary pads at her. The gym teacher tries to calm Carrie down, and eventually must explain the concept of menstruation to Carrie (because Carrie's mother had never done so). When Carrie returns home, her fanatically religious mother yells at her and throws her into a closet because menstruation is apparently a sign of sin. Later in the movie, her classmates mock her menarche again by pouring pig's blood on her at the prom.\n\nIn \"Only Yesterday\", one of the girls is found to be going through menstruation and is later teased about it, especially when a group of boys tell the others not to touch a ball she had touched by saying, \"You'll catch her period\".\n\nIn the 2007 movie \"Superbad\", Seth discovers menstrual blood on his jeans after dancing with a woman. He reacts with disgust, as do other men in the scene.\n\nWith the recent FDA approval of menstrual suppression medications, researchers have begun to shift their focus to the attitudes of American women toward their periods. One study in particular found that 59% of the women they surveyed reported an interest in not menstruating every month. Of these, 1/3 said they were interested in not menstruating at all anymore.\n\nAnthropologists, Lock and Nguyen (2010), have noted that the heavy medicalization of the reproductive life-stages of women in the West, mimic power structures that are deemed, in other cultural practices, to function as a form of \"social control\". Medicalization of the stages of women's lives, such as birth and menstruation, has enlivened a feminist perspective that investigates the social implications of biomedicine’s practice. \"[C]ultural analysis of reproduction…attempts to show how women…exhibit resistance and create dominant alternative meanings about the body and reproduction to those dominant among the medical profession.\"\n\nMenstrual activism (otherwise known as radical menstruation, menstrual anarchy, or menarchy) is a movement that addresses menstrual taboos. Overcoming this taboo is a point of contention amongst feminists. The primary argument behind this movement is that if menstruation is normal, there is no reason why the topic should be avoided: \"After a while it becomes psychologically disorienting for women to look out at a world where their reality doesn't exist.\"\n\nMenstruation can be conceptualized as a stigmatized condition that both reflects and reinforces women’s perceived lower status in relation to men. Feminist scholars extend this theory to explain negative attitudes towards women's bodily functions. Such stigmatization occurs when menstrual blood is viewed as one of the \"abominations\" of the body and reflects a gendered identity among women, which leads to consequences for women's psychological and sexual\nwell-being.\n\nFeminists such as Chella Quint have spoken against the use of shaming in advertising for feminine hygiene products. She created a zine, Adventures in Menstruating, to \"help alter the visibility of menstruation, so that it's at least normal to talk about it. Because, right now, it's not\". Other menstrual activists include Rachel Kauder Nalebuff, who published \"My Little Red Book\"; filmmaker and academic Giovanna Chesler, who created the documentary \"Period: The End of Menstruation\"; and artist Ingrid Berthon-Moine, who exhibited a video and series of photographs at the Venice Biennale.\n\nBlood from female menstruation has been used in medicines. In Chinese Daoist alchemy, menstrual blood from females who had not had sexual intercourse was used to make a substance to prolongue an individual's life, called red lead (). The substance was taken by the Ming dynasty Jiajing Emperor and the abuses inflicted on the palace women to ensure the blood's purity led to the Renyin palace rebellion.\n\nMenstrual synchrony is an alleged process whereby women who begin living together in close proximity experience their menstrual cycle onsets (the onset of menstruation or menses) becoming more synchronized together in time than when previously living apart. A 2013 review concluded that menstrual synchrony likely does not exist.\n\n\n"}
{"id": "1677606", "url": "https://en.wikipedia.org/wiki?curid=1677606", "title": "Cyclic alternating pattern", "text": "Cyclic alternating pattern\n\nThe cyclic alternating pattern (abbreviated CAP) is a pattern of two, long-lasting alternate electroencephalogram (EEG) patterns that occur in sleep, as described by Terzano, et al, in 1985. It is a pattern of spontaneous cortical activity, which is ongoing and in the absence of sensory stimulation. It is the reorganization of the sleeping brain challenged by the modification of environmental conditions and it is characterized by periodic abnormal electrocortical activity that recurs with a frequency of up to one minute. It is considered \"the EEG marker of unstable sleep\". CAP does not occur during REM. In Lennox-Gastaut syndrome, CAP modulates the occurrence of clinical seizures and generalized epileptic discharges by means of a gate-control mechanism.\n\nAs noted at MedLink.com, CAP is a marker of sleep instability and it is found during non-rapid eye movement sleep. CAP is organized into sequences of successive cycles composed of two phases, A and B. Phase A involves phasic events, in other words, not continuous. Phase A subtypes of CAP allow adaptive adjustments of ongoing states to internal and external inputs. Phase B refers to background rhythm during CAP. Furthermore, CAP involves cerebral activities and is influenced by autonomic and motor functions. Interaction between CAP and neurovegetative fluctuations and motor events determine the pathophysiology of several sleep disorders and the effect of medication on continuous positive airway pressure (CPAP) treatment (CPAP is used to treat obstructive sleep apnea or OSA).\n\nCAP is a marker of NREM instability and is also the \"master clock\" that accompanies the stage transitions maintained in sleep phases, noted in both the EEG and by autonomic functions through regular fluctuations. CAP is decreased in narcolepsy, multiple system atrophy, in certain cases of drug administration, with CPAP treatment for OSA, and during night-time recovery sleep after prolonged sleep deprivation. There is a relationship present between CAP and arousals that allows for adjustements of vigilance during sleep. If there is a failure in this relationship during sleep, sleep disorders may develop.\n\nRechtschaffen and Kales have developed the standard criteria for sleep staging in 1968. In 1992, the AASM defined arousals as markers of sleep disruption, which is harmful for sleep. According to Boselli, et al, in 1998 it was noted that spontaneous arousals are natural in sleep and increase over life.\n"}
{"id": "52837196", "url": "https://en.wikipedia.org/wiki?curid=52837196", "title": "Death and state funeral of Akbar Hashemi Rafsanjani", "text": "Death and state funeral of Akbar Hashemi Rafsanjani\n\nOn 8 January 2017, Akbar Hashemi Rafsanjani, the fourth President of Iran and the country's Chairman of Expediency Discernment Council, died at the age of 82 after suffering a heart attack. He was transferred to a hospital in Tajrish, north Tehran without consciousness. Attempts at cardiopulmonary resuscitation for more than an hour trying to revive him were unsuccessful and he died at 19:30 local time (UTC+3:30).\n\nIranian government observed a national mourning period of 3 days. Rafsanjani's body lay in state at Jamaran Huseinieh, near where his house was located. Thousands of the people and officials from Iran and other countries visited his body at Jamaran. A state funeral was held on 10 January 2017 which was attended by millions of people and his body was buried at the Mausoleum of Ruhollah Khomeini hours later.\n\nRafsanjani's body lay in state at the Jamaran Huseinieh in north Tehran hours after his death from 9 to 10 January 2017. Approximately thousands mourners viewed his body over the two days. The crowds grew larger each day and thousands who queued on the final day could not be accommodated and were turned away. The ceremony was also attended by Rafsanjani's family, Iranian officials like President Hassan Rouhani and his cabinet, parliament members and its chairman Ali Larijani, Tehran Friday prayer Imam Mohammed Emami-Kashani, Chief of Staff for the Armed Forces Major General Mohammad Bagheri and Quds Forces commander Major General Qasem Soleimani, Ruhollah Khomeini's survivors (specially Hassan Khomeini), former parliament chairman and a close friend Ali Akbar Nateq-Nouri, former MP and presidential election rival Ahmad Tavakoli, former government members (Akbar Torkan, Mohsen Rafighdoost, Ahmad Madani, Abdullah Nouri, Manouchehr Mottaki etc.), public figures like cinema director Ebrahim Hatamikia, former national team and Persepolis head coach Ali Parvin, singer Majid Akhshabi and some foreign figures which was included Ibrahim al-Jafari, Ammar al-Hakim and country's ambassadors to Iran.\n\nHours after his death, his office announced that a state funeral will be held on 11 January in University of Tehran, with the place of burial being Mausoleum of Ruhollah Khomeini. It was previously announced he will be buried at Fatima Masumeh Shrine in Qom, but his family decided to change the place of burial.\n\nThousands of the people and government officials attended the ceremony and Ali Khamenei performed the ritual prayer for the deceased (Salat al-Mayyit) in his funeral. Some foreign leaders like Afghanistan's Chief Executive Abdullah Abdullah, Kuwait's Deputy Prime Minister Sabah Al-Khalid Al-Sabah, Turkeministan Deputy Prime Minister Raşit Meredow, Iraqi foreign minister Ibrahim al-Jaafari, Georgian foreign minister Mikheil Janelidze, Azerbaijan parliament chair Ogtay Asadov, Malian national assembly president Issaka Sidibé, British Ambassador Nicholas Hopton, Lebanon's Nabih Berri and Armenian parliament speaker Galust Sahakyan also attended the event. The truck carrying Rafsanjani's coffin topped with his trademark white turban inched down Enqelab Street, one of the capital's main thoroughfares. Rafsanjani was buried next to the former supreme leader Ruhollah Khomeini.\n\nAccording to Iranian TV and governor of Tehran, 2.5 million attended his funeral. It was the second largest funeral in Iran and the first in the last 25 years after funeral of Ruhollah Khomeini.\n\nThe Office of the Supreme Leader of Iran announced that a memorial service will be held in Beit Rahbari by Ayatollah Ali Khamenei on 11 January in memorial of Hashemi Rafsanjani. It was attended by the survivors of Rafsanjani and governmental and foreign officials. Another memorial service was also held in the same day by the Rafsanjani family in the mosque of Azad University central building. Another ceremonies was held in different cities like Qom and Rafsanjani on 12 and 13 January. A ceremony was also held at Imam Reza Shrine The 7th Day (Haftom) ceremony was also held at Mausoleum of Ruhollah Khomeini on 15 January which crowds of the people attending.\n\nMemorial services was held by Iran's embassy at Baghdad, Kabul, London, Beirut, Tokyo, Ankara and other cities.\n\nA memorial service in honour of Rafsanjani was held on 14 January 2017 in Najaf's Imam Ali shrine which was attended by key Shiite clerics.\n\n\nHis death is described as a \"blow\" to the reformist movement of Iran. He headed the Expediency Council, a body which is intended to resolve disputes between the parliament and a hardline watchdog body, the Guardian Council.\n\n\n\n\n\n\n\n\n\n\nThe funeral veered slightly off script when groups of mourners started shouting opposition slogans. The authorities were forced to raise the volume on the loudspeakers playing lamentation songs after some in the crowds took up cries of using name of former presidential candidate, Mir-Hossein Mousavi, who has been under house arrest since 2011. Some of the chants were aimed at Russia, Iran's ally in the Syrian conflict. Video clips on social media showed mourners shouting \"Death to Russia\" (which was also shouted during the 2009 Iranian presidential election protests after Russian President Dmitry Medvedev became the first foreign leader to congratulate Mahmoud Ahmadinejad on his re-election) and \"the Russian Embassy is the den of espionage,\" as they passed the embassy's complex in the heart of Tehran. People also called for the release of hunger strikers in Iranian prisons.\n\nState television, broadcasting the funeral live, airbrushed the protests, which were nevertheless allowed to proceed without police intervention.\n\n\n"}
{"id": "48614481", "url": "https://en.wikipedia.org/wiki?curid=48614481", "title": "Drainage Services Department", "text": "Drainage Services Department\n\nThe Drainage Services Department (DSD) is a department of the Hong Kong Government responsible for drainage and sewerage. Since 2007 it has been subordinate to the Development Bureau.\n\nThe department is responsible for stormwater drainage, sewage collection and treatment, and flood prevention.\n\nEnvironmental protection was one of the main concerns of former governor David Wilson. Wilson stressed the importance of better planning, increased control of pollution discharges, and large-scale investment in improved sewage disposal infrastructure. He stated that Hong Kong needed more treatment facilities and new outfalls constructed sufficiently far out to sea, and promoted a new department to help achieve this. The Drainage Services Department was established in 1989.\n\nThe Harbour Area Treatment Scheme (HATS) is a major sewage treatment infrastructure improvement scheme designed to improve the water quality of Victoria Harbour. Originally called the Strategic Sewage Disposal Scheme, the plan was drawn up in 1989 and construction of HATS Stage 1 commenced in 1994. It comprises a system of deep tunnels to convey sewage from eight Preliminary Treatment Works to the Stonecutters Island Sewage Treatment Works, which opened in 1997. The full Stage I system, which treats 75% of the sewage generated by the urban areas around the harbour, came online in December 2001. Construction of HATS Stage 2 commenced in 2008, and stage 2A was commissioned in 2015. HATS Stage 2B, comprising an underground biological treatment facility at Stonecutters Island, has been shelved as it is felt that the existing facility is sufficient at this time.\n\nThe department has built several significant bored tunnels designed to intercept water running down mountain slopes and divert it from urban areas in order to prevent flooding.\n\nThe largest of these is the Hong Kong West Drainage Tunnel, comprising an 11-kilometre long main tunnel and 8 km of adits. It stretches from Tai Hang in the east to an outfall just north of Cyberport. It was built at a cost of HK$3.4 billion. Construction commenced in November 2007 and the tunnel was commissioned on 22 August 2012.\n\nThe Lai Chi Kok Drainage Tunnel encircles Sham Shui Po and Lai Chi Kok. It is a 3.7-kilometre tunnel, stretching from Shek Kip Mei to an outfall near Stonecutters Island, built at a cost of $1.7 billion. Construction commenced in November 2008 and the tunnel was commissioned on 18 October 2012.\n\nThe Tsuen Wan Drainage Tunnel protects the Tsuen Wan New Town and Kwai Chung areas. The 5.1-kilometre tunnel begins at Wo Yi Hop, north of Kwai Chung, and curves around the north of Tsuen Wan proper. Past Chai Wan Kok, it parallels the Tuen Mun Highway a short distance and then empties into the Rambler Channel. Construction of the $1.5 billion tunnel commenced in 2007. It was commissioned on 28 March 2013.\n\nThe department operates two sludge transport vessels, called Clean Harbour 1 and Clean Harbour 2. These ships transport sludge from the Stonecutters Island Sewage Treatment Works to the sludge treatment facility in Tuen Mun.\n\nThe ships are equipped with gantry cranes capable of lifting sludge from the lorries directly into containers on board, and can lift 10 containers per hour. Each ship can carry 90 containers of sludge, a total of 1,200 tons of sludge. The vessels were built by Jinhui Shipbuilding of Zhongshan and commissioned in 2015.\n\n\n\n"}
{"id": "42551400", "url": "https://en.wikipedia.org/wiki?curid=42551400", "title": "E. Gail de Planque", "text": "E. Gail de Planque\n\nEileen Gail de Planque (also Eileen Gail de Planque Burke, best known as E. Gail de Planque; 1944 – September 8, 2010) was an American nuclear physicist. An expert on environmental radiation measurements, she was the first woman and first health physicist to become a Commissioner at the US government's Nuclear Regulatory Commission (NRC). Her technical areas of expertise included environmental radiation, nuclear facilities monitoring, personnel dosimetry, radiation shielding, radiation transport, and solid state dosimetry.\n\nBorn in New Jersey and raised in Maryland, Planque earned her bachelor's degree from Immaculata College (Mathematics, 1967), Master's degree from the Newark College of Engineering (Physics, 1973), and PhD from New York University (Environmental health science, 1983). From 1967 until 1982, she worked as a physicist for the Atomic Energy Commission. She joined the Environmental Measurements Laboratory, US Department of Energy as its deputy director in 1982, and was promoted to director five years later. From 1991-95, she was a member of the NRC. In 1997, Planque chaired a planning committee, Celebration of Women in Engineering, which developed conferences that encouraged women to choose careers in engineering and included the development of the website EngineerGirl.\n\nA Fellow of the American Nuclear Society and the American Association for the Advancement of Science, Planque was also a member of the National Academy of Engineering, Association of Women in Science, and the National Council on Radiation Protection and Measurements. She served as president of the ANS (1988–89), and Health Physics Society; as well as the co-chair of Committee for International Intercomparison of Environmental Dosimeters. In the late 1970s, Planque was a US expert delegate to the international committee for Development of an International Standard on Thermoluminescence Dosimetry.\n\nPlanque was married to Frank Burke. She lived in New York City, and Potomac, Maryland. Planque died in 2010.\n\n"}
{"id": "22922620", "url": "https://en.wikipedia.org/wiki?curid=22922620", "title": "Family Smoking Prevention and Tobacco Control Act", "text": "Family Smoking Prevention and Tobacco Control Act\n\nThe Family Smoking Prevention and Tobacco Control Act, (, ) is a federal statute in the United States that was signed into law by President Barack Obama on June 22, 2009. The Act gives the Food and Drug Administration the power to regulate the tobacco industry. A signature element of the law imposes new warnings and labels on tobacco packaging and their advertisements, with the goal of discouraging minors and young adults from smoking. The Act also bans flavored cigarettes, places limits on the advertising of tobacco products to minors and requires tobacco companies to seek FDA approval for new tobacco products.\n\nOn March 21, 2000, the Supreme Court in \"FDA v. Brown & Williamson Tobacco Corp.\", in a 5-4 decision, held that the Federal Food, Drug, and Cosmetic Act, particularly when considering \"Congress’ subsequent tobacco-specific legislation,\" that Congress had not given the FDA the authority to regulate tobacco products as customarily marketed. Thus the Family Smoking Prevention and Tobacco Control Act was introduced to respond to the decision, which had held that the Clinton administration's FDA had \"overreached\" its Congressionally delegated authority, thus giving the FDA the authority the Court determined it had lacked.\n\nThe bill passed the United States House of Representatives on April 2, 2009, by a vote of 298 to 112. The House bill had 178 cosponsors and the companion legislation in the Senate, had 57 cosponsors. On May 20, 2009, the Senate Committee on Health, Education, Labor, and Pensions ordered the Senate bill to be reported favorably with amendments on a 15-8 vote.\n\nThe Capitol Hill newspaper \"The Hill\" reported on May 25, 2009, that Senate Majority Leader Reid planned to move on the bill during the month of June 2009; however it noted that Senators Burr and Hagan of North Carolina were proposing alternative legislation.\n\nOn June 2, the Senate voted 84-11 to proceed to consideration of the House bill. On June 8, the Senate voted 61-30 on cloture on amendments to the Senate bill. The \"Senate bill requires that cigarette health warning labels be large enough to make up 50 percent of the front and rear panels of the package and that the word “warning” appear in capital letters.\"\nOn June 11, the Senate passed H.R. 1256 by a vote of 79-17, with 3 Senators not voting. Passage of the legislation came a week later than was originally scheduled. The Senate's version of the bill was approved by the House on June 12, by a bipartisan vote of 307-97.\n\nMedia accounts noted that the opposition in the Senate was largely from tobacco farming states, particularly Kentucky, North Carolina, South Carolina and Georgia, with the only Democrat in opposition being Kay Hagan, from North Carolina. Notable exceptions were Virginia Senators Jim Webb and Mark Warner who supported the measure, despite the state's connection to the tobacco industry.\n\nThe Family Smoking Prevention and Tobacco Control Act was signed into law on June 22, 2009, by President Barack Obama.\n\nThe bill makes no provisions that ban the import of the banned items for personal consumption, only for \"sale or distribution.\" (Division A Title II Section 201) \n\nPassing of the law was supported by the American Cancer Society, whose CEO noted in a press release that \"[t]his bill forces Big Tobacco to disclose the poisons in its products and has the power to finally break the dangerous chain of addiction for generations to come.\" The ACS press release also noted that the legislation would \"require cigarette companies to disclose all ingredients used in cigarettes and to stop using words like 'light' and 'ultra-light' to give the impression that some tobacco products have a lower health risk.\" The legislation also garnered support from the American Heart Association, whose CEO noted that the bill \"provides a tremendous opportunity to finally hold tobacco companies accountable and restrict efforts to addict more children and adults.\" \n\nThe law was criticized by some as ineffectual, with community health sciences professor Michael Siegel stating that it \"creates the appearance of regulation without allowing actual regulation.\" Critics argue that without the authority to eliminate nicotine completely, the reduction of nicotine levels in cigarettes may result in compensation by existing smokers, increasing their cigarette smoke inhalation to consume a level of nicotine which will satisfy their cravings. The Tobacco Control Act has been called \"the Marlboro Protection Act\" because it grandfathered in tobacco products marketed before 2007, while erecting nearly impassable financial and regulatory barriers for the introduction of competing products to the US market. These marketing restrictions enacted by the bill make it more difficult to promote safer smokeless alternatives to cigarettes. The restrictions have been disputed on the grounds of free speech, with some stating that the legislation violates the First Amendment to the United States Constitution.\n\nThe bill bans flavored cigarettes, including cloves, cinnamon, candy, and fruit flavors, with a special exception for menthol cigarettes. Because Philip Morris is the largest producer of cigarettes in the United States and the bill would have the effect of eliminating potential competition, the bill has been nicknamed the \"Marlboro Monopoly Act of 2009\". Philip Morris strongly supports FDA regulation. The exemption was reportedly influenced by the Congressional Black Caucus. The Tobacco Products Scientific Advisory Committee provisioned under the bill is to submit a recommendation on menthol cigarettes to the United States Secretary of Health and Human Services no later than one year after its establishment.\n\n\nIn June 2011, the FDA released nine new warning signs containing both graphic text and images that should be included on all cigarette packaging and advertisement by September 2012. The textual warnings state:\n\"WARNING: Cigarettes are addictive. \nWARNING: Tobacco smoke can harm your children.\nWARNING: Cigarettes cause fatal lung disease.\nWARNING: Cigarettes cause cancer.\nWARNING: Cigarettes cause strokes and heart disease.\nWARNING: Smoking during pregnancy can harm your baby.\nWARNING: Smoking can kill you.\nWARNING: Tobacco smoke causes fatal lung disease in nonsmokers.\nWARNING: Quitting smoking now greatly reduces serious risks to your health.\" \nEach warning is to be paired with one of the following colored images: a man exhaling cigarette smoke through a tracheotomy hole in his throat; a plume of cigarette smoke enveloping an infant receiving a kiss from his or her mother; a pair of diseased lungs next to a pair of healthy lungs; a diseased mouth afflicted with what appears to be cancerous lesions; a man breathing into an oxygen mask; a bare-chested male cadaver lying on a table, and featuring what appears to be post-autopsy chest staples down the middle of his torso; a woman weeping uncontrollably; or a man wearing a T-shirt that features a \"no smoking\" symbol and the words \"I Quit.\" Four tobacco companies responded to the mandate by filing a legal challenge in August. \n\nThe constitutionality of the provision requiring graphic warnings on cigarette packs has been questioned with tobacco companies and others saying that the new warnings violated the first amendment by going beyond being informational and require manufactures of a legal product to \"engage in anti-smoking advocacy\" on the government's behalf.R.J. Reynolds, Lorillard, Liggett Group and Commonwealth Brands, filed a lawsuit against the FDA in August 2011. It should be noted that Altria did not take any legal action. On November 7, 2011, US district judge Richard Leon granted a temporary injunction postponing the implementation of the new warnings, ruling that \"It is abundantly clear from viewing these images that the emotional response they were crafted to induce is calculated to provoke the viewer to quit, or never to start smoking - an objective wholly apart from disseminating purely factual and uncontroversial information.\" The Court of Appeals for the D.C. Circuit upheld the District Court’s opinion that the labels were unconstitutional, analyzing the labels under the Central Hudson standard. Before the D.C. Circuit issued its ruling, a divided panel for the Sixth Circuit Court of Appeals upheld the constitutionality of the Act in the case of Discount Tobacco City & Lottery v. FDA. On April 22, 2013, the Supreme Court declined review of 6th District's decision.\n\nOn 12 April 2010, Indonesia filed a formal complaint with the World Trade Organization stating the ban on kreteks (clove cigarettes) in America amounts to discrimination because menthol cigarettes are exempt from the new regulation. Trade Ministry Director General of International Trade Gusmardi Bustami has stated that the Indonesian government has asked the WTO panel to review US violations on trade regulations, including the General Agreement on Tariff and Trade (GATT) 1994, Technical Barriers to Trade (TBT) and Sanitary and Phytosanitary (SPS) Agreement. The TBT Agreement is of special importance as it defines clove cigarettes and menthol cigarettes as \"like products.\" Claims of discrimination are enhanced when noting that 99% of kreteks were imported from countries other than the United States (chiefly Indonesia), while menthol cigarettes are produced almost entirely by American tobacco manufacturers. Indonesia's case is further strengthened by comparing the number of young kretek smokers in America with the number of young menthol cigarette smokers. According to US health reports, 43% of young smokers smoke menthol cigarettes, which accounts for nearly 25% of the total cigarette consumption in the United States. Young smokers habituated to kreteks, however, account for less than 1% of cigarette consumption in the US, and <1% of the total cigarettes sold in the US. On 4 April 2012, the WTO ruled in favor of Indonesia's claim, though it is unclear how this will affect U.S. law.\n\n\n"}
{"id": "5974619", "url": "https://en.wikipedia.org/wiki?curid=5974619", "title": "George Albee", "text": "George Albee\n\nGeorge Wilson Albee (December 20, 1921 – July 8, 2006) was a pioneer in clinical psychology, who believed societal factors such as unemployment, racism, sexism, and all the myriad forms of exploitation of people by people were the major cause of mental illness. He was one of the leading figures in the development of community psychology.\n\nAlbee was born in St. Marys, Pennsylvania, he attended Bethany College and graduated in 1943. He was drafted into the Army Air Forces until the end of World War II.\n\nAfter leaving the forces he attended the University of Pittsburgh where he attained his Masters and Doctorate degrees. Having received his doctorate in 1949 he spent the next two years in a research appointment at Western Psychiatric Institute. From 1951 to 1953 Albee worked for the Central Office of the American Psychological Association (APA).\n\nIn 1953 Albee went to Finland for a year as a Fulbright scholar, before returning to the USA to become a Professor at Case Western Reserve University, a post he held for 16 years. In 1971 Albee left Case Western for a position at the University of Vermont. He remained here until his retirement in 1991. During that time, he married Constance Impallaria,and had 4 kids: Alec, Luke, Maud and Sarah.\n\nDuring his career Albee was the author of groundbreaking studies in the 50's and 60's, that showed societal factors such as poverty, racism, sexism and child abuse, were to a large degree responsible for mental illness. He believed the psychological profession needed to focus more on prevention, rather than one to one treatment. After his retirement Albee spent time travelling around the world giving lectures on psychology as well as writing a humor column for his local newspaper the \"Longboat Observer\".\n\nFrom 1969-70 Albee was the president of the APA. During his tenure he negotiated conflicts between the mainstream of psychology and the demands of Black and female psychologists.\n\nHe was the author of more than 200 articles and book chapters on community approaches to mental illness, as well as writing more than a dozen books.\n\nAlbee died in Longboat Key, Florida.\n\n\n"}
{"id": "41622061", "url": "https://en.wikipedia.org/wiki?curid=41622061", "title": "George Kellie", "text": "George Kellie\n\nDr George Kellie MD, FRSE (1770–1829) was a Scottish surgeon who, together with Alexander Monro \"secundus\" gave his name to the Monro-Kellie doctrine, a concept which relates intracranial pressure to the volume of intracranial contents and is a basic tenet of our understanding of the neuropathology of raised intracranial pressure. The doctrine states that since the skull is incompressible, and the volume inside the skull is fixed then any increase in volume of one of the cranial constituents must be compensated by a decrease in volume of another.\nPrevious research about George Kellie (1720–1779) may have been hampered by a widely cited incorrect year of birth, by the spelling of his name as Kellie or Kelly and by confusion with his father, also a surgeon in Leith, with the same name and subject to similar spelling variations.\n\nGeorge Kellie was born in Leith, the seaport for Edinburgh which was at that time the fifth largest town in Scotland. His parents George Kellie (1742–1805), originally from Dunbar, East Lothian, and Catherin [sic] McCall of Haddington, East Lothian had married in South Leith in August 1769 On his baptismal entry in the parish of Dunbar, East Lothian for 6 October 1742 George senior's surname is spelt Kellie, as is that of his father. In the South Leith parish records of his marriage to Catherin McCall in August 1764 and the record of the birth of his son, the spelling is given as 'Kelly'. George Kellie senior practised as a surgeon and while there is no record of his registration as a surgical apprentice in Wallis's extensive listing of British medical and surgical apprentices that listing showed that he trained three apprentices between 1771–75. The Street directories for Edinburgh and Leith for the years 1773–1805 show that ‘George Kelly’ senior practised as a surgeon in Tolbooth Wynd, Leith, the only Kelly or Kellie listed in Leith for that period. In 1774 he published a paper describing a case of extensive surgical emphysema which, after consulting with Alexander Monro secundus, he had successfully treated by inserting of a cannula into the thoracic cavity. George Kelly senior died at Leith on 3 April 1805, the spelling of his name on the death notice reverting to 'Kellie'.\nGeorge Kellie junior followed his father into a career as a surgeon in Leith after serving a five year apprenticeship to the Edinburgh surgeon James Arrott (1760–1818).\n\nAs Arrott had done before him Kellie joined the Royal Navy in 1790 as a surgeon. During this naval service he published papers in the form of letters to his father ‘Mr Kellie, surgeon, Leith’. A letter to \"Edinburgh Medical Commentaries\" dated 21 May 1794 show that he is now surgeon on HMS \"Iris\", a 32 gun, fifth rate frigate. In this letter he records experiments on himself, describing the effects of compressing the arm by tourniquet. In August 1796 he was posted to HMS \"Leopard\", a 50 gun fourth rate warship. In the next month he writes to the \"Annals of Medicine\" about the anatomy of the shark and the following year writes with more information about tourniquet compression. In a letter to the \"Annals\" in 1801 from a Mr Livingstone, Kellie is described as ‘physician to the English prisoners at Valencienne’, a reference to the town in the Pas de Calais in northern France where British prisoners of war were held during the Napoleonic War.\n\nWhen Kellie returned to surgical practice in Leith he maintained his military links by becoming Surgeon to the Royal Leith Volunteers. In 1802 he became a fellow of the Royal College of Surgeons of Edinburgh (RCSEd) and was elected a Burgess of the City of Edinburgh, a necessary prerequisite to practise as a surgeon-apothecary. On 12 September 1803 he graduated MD from the University of Edinburgh Medical School with a thesis entitled ‘de Electricitate animale’, by now obviously able to pay the graduation fee. On 21 November 1805 he married Ann Wight, daughter of Robert Wight of the Murrays near Ormiston in East Lothian, maintaining his family links with that region. He now published a series of papers on a diverse range of medical and surgical topics.\n\nIn the paper which was to give Kellie lasting eponymous fame he describes the post mortem appearances in the bodies of two individuals found dead after lying outside after a storm. He was asked by local magistrates to try to establish the cause of death. Kellie noted that the veins in the meninges and surface of the brain were congested and the associated arteries were relatively bloodless while the brain was otherwise normal. In concluding that the individuals died from exposure he quotes a similar case described by Samuel Quelmalz (1696–1758) where exposure results in a progression through weariness, lassitude, drowsiness, coma and death which he ascribes to disordered cerebral circulation. He concluded 'When the cavity of the cranium is encroached upon by depression of its walls compensation may be made at the expense of circulatory fluid within the head; less blood is admitted and circulated'. Kellie gave credit to two of his Edinburgh contemporaries for their contributions in the shaping of this concept, Alexander Monro \"secundus\" (' … my illustrious preceptor in anatomy, the second Monro') and John Abercrombie. Monro had stated that since the healthy cranial cavity is rigid and of constant volume and the brain 'is nearly incompressible, the quantity of blood within the head must remain the same'. Later in the paper Kellie described how Monro, aware of his interest, invited him jointly to examine the brains of executed criminals and sent him descriptions of autopsy findings in other similar cases. He gives Abercrombie particular credit when he writes 'the argument has already been taken up and illustrated by Dr Abercrombie, in his ingenious analysis of apoplexy … '. In 1818 Abercrombie indeed had ‘proposed a doctrine’ clearly setting out the hypothesis.\nAbercrombie was largely responsible for the doctrine becoming widely known and accepted around the world. His authoritative book \"Pathological and Practical Researches on Disease of the Brain and Spinal Cord\" first published in 1828 was a milestone in neuropathology which ran to three British, two American and French and German editions. In it Abercrombie linked the theories of Monro and Kellie and gave them full credit for the hypothesis\n\nAs Abercrombie had done before him, Kellie went on to test his theories with a series of animal experiments where he studied the cerebral circulation of sheep and of dogs immediately after exsanguination or death induced by cyanide. He found that in many instances while the tissues outwith the cranium were drained of blood, the brain was not affected in this way, retaining blood volume. He concluded that where the circulating blood volume was depleted, the volume circulating within the cranium remained constant, with the increase in arterial tone and consequent reduction in arterial blood volume being compensated by venous engorgement thus keeping the total blood volume constant. \nThe English physician Dr (later Sir) George Burrows (1801–1887) later tested the hypothesis with CSF included in the equation. He repeated Kellie’s experiments using animal exsanguination and concluded that a depletion of CSF volume was compensated by an increase in intracranial blood volume and vice versa, so validating the hypothesis.\nHarvey Cushing (1869–1939)and his researcher Lewis Weed (1886–1952) tested the theory in the light of increasing knowledge and Weed found that ' ... in every way Monro-Kellie doctrine must be considered essentially correct'. The development of techniques to measure cerebral blood flow (CBF) and intracranial pressure (ICP) have allowed more sophisticated testing of the doctrine and shown that the hypothesis formulated by Monro, Kellie and Abercrombie still holds good.\n\nKellie went on to achieve local distinction in his lifetime. He was elected a Fellow of the Royal Society of Edinburgh in December 1823. In 1827 he was elected President of the Edinburgh Medico-Chirurgical Society and was succeeded in that office by John Abercrombie.\nGeorge Kellie collapsed and died in Leith on 28 September 1829 while on his way home from visiting a patient.\n\nMacintyre I. A hotbed of medical innovation: George Kellie (1770–1829), his colleagues at Leith and the Monro–Kellie doctrine. \"J Med Biogr\" 2013;22(2): 93-100 https://doi.org/10.1177/0967772013479271\n"}
{"id": "16693514", "url": "https://en.wikipedia.org/wiki?curid=16693514", "title": "Got Mercury?", "text": "Got Mercury?\n\nGot Mercury? is a public awareness campaign about mercury levels in seafood. It is sponsored by the Sea Turtle Restoration Project (STRP) and its parent organization, the Turtle Island Restoration Network (TIRN). The name of the campaign is a snowclone of the successful Got Milk? advertising campaign.\n\nAlthough the STRP was founded to protect sea turtles in their natural habitats, the organization began the Got Mercury? campaign in 2002. The campaign advocates that supermarkets and restaurants post warning signs about mercury contamination in seafood, require them to regularly screen seafood for levels of mercury under one part per million and that species that contain the \"highest levels of mercury\" should be removed from the shelves. In 2004, the organization created an online mercury seafood calculator, one that was mimicked by the free market Center for Consumer Freedom not long thereafter.\n\nOn March 17, 2008, Got Mercury? issued a report entitled, \"Mercury in Seafood: No Fair Warning\", which included these findings:\n\nShortly after the release of the report, the National Fisheries Institute issued a press advisory urging reporters to disregard the report on the basis that it might cause public harm by leading individuals, including mothers and children, to consume less fish and lose the benefits from omega-3 fatty acids that can be important to early childhood development.\n\nIn January 2011, the group secretly tested samples of seafood bought from California retailers. The group tested swordfish, tuna, halibut, and salmon for traces of methylmercury. The results of the study showed that tuna and swordfish purchased from some supermarkets and sushi restaurants contained as much as three times the FDA limit for mercury contamination. Representatives of the seafood industry criticized the report, arguing that it might lead consumers to eat less seafood and thus be detrimental to public health. Pamela Tom, manager of the seafood extension program at the University of California at San Diego also noted that no cases of methylmercury poisoning have been found from fish documented with the Centers for Disease Control and Prevention.\n\nCurrently, the Turtle Island Restoration Network provides organizational support for the STRP, Got Mercury?, as well as the SPAWN. Between 1999 and 2008, the Turtle Island Restoration Network has received $93,000 from the Foundation for Deep Ecology, an organization founded by fashion executive Douglas Tompkins.\n\n\n"}
{"id": "52787440", "url": "https://en.wikipedia.org/wiki?curid=52787440", "title": "Haikou Nandu River Water Diversion Project", "text": "Haikou Nandu River Water Diversion Project\n\nHaikou Nandu River Water Diversion Project (海口南渡江引水工程) is a project to divert water from the Nandu River to parts of Haikou Prefecture, in particular, an agricultural area west of Haikou City where lychee are grown.\n\nThe project is ongoing in 2017 and includes a pumping station on the east bank of the Nandu River just south of the Longtang Dam. Tunnels are being bored from the west side of the Nandu westward to the areas where the water is needed. This involves underground blasting and the creation of numerous pits along the route for equipment access.\n"}
{"id": "42442982", "url": "https://en.wikipedia.org/wiki?curid=42442982", "title": "Health Insurance Fund", "text": "Health Insurance Fund\n\nHealth Insurance Fund (HIF) is an Australian, not-for-profit insurer. In 1954 it was brought into existence as the WA Government Employee’s Hospital and Medical Benefits Fund Incorporated. But has since undergone a series of name changes to better reflect the scope and services it provides.\n\nHIF has majority market share for health funds in Western Australia. Its business model boasts a strong environmental focus. Currently, it is the only certified carbon neutral health fund in Australia.\n\nHIF (Health Insurance Fund of Australia) began in 1954 as the Western Australian Government Railways Employees’ Hospital and Medical Fund. Within a few months this name was changed to the Government Employees’ Hospital and Medical Benefits Fund Incorporated.\nIn 1978, to comply with the Associations Incorporations Act 1895 (WA), HIF became the Health Insurance Fund of WA. In 2010, the fund changed its name to Health Insurance Fund Of Australia Limited to reflect its nationally expanding client base. Also in 2010, data published by the Private Health Insurance Administration Council (PHIAC) revealed HIF to be the fastest growing not-for-profit Australian health fund for that financial year.\n\nIn 2008, the Federal Government passed the Private Health Insurance Legislation Amendment Bill 2008 (Cth) (PHILA Act); seeking to amend the Private Health Insurance Act 2007 (Cth). This legislation governs the operation of all private health insurers. The PHILA Act required all insurers to qualify as a ‘company’ as stipulated by the Corporations Act 2001 (Cth). As a result of this, on December 1, 2009, the Western Australian Government passed legislation facilitating the transfer of HIF’s status from an incorporated association under the Associations Incorporations Act 1987 (WA) to an Australian public company.\n\nToday HIF is an Australian public company limited by guarantee and governed by the Corporations Act 2001 (Cth). HIF is registered with the federal regulator, the Australian Securities and Investments Commission (ASIC) and the Private Health Insurance Administration Council (PHIAC) as an open access, not for profit, private, health insurer.\n\nPrivate health insurance in Australia is heavily regulated. Prudential supervision is undertaken by PHIAC to ensure the company remains solvent. PHIAC publishes extensive statistics on the industry and annual financial statements for individual health funds. The pricing and features of health insurance products is regulated by the Department of Health and Ageing.\n\nHIF holds the title of Australia’s first carbon neutral health fund, as certified by the Carbon Reduction Institute (CRI). From their analysis, HIF was able to construct and implement strategies to reduce their carbon footprint. After achieving significant reductions the company sought to offset remaining emissions through the purchase of carbon abatement credits. \nHIF is involved with multiple charitable works. One of these is the Amanda Young Foundation: A not-for-profit charity dedicated to reducing deaths from Meningococcal Disease. HIF provides the Amanda Young Foundation with accommodation, resources, and administrative and accounting support.\n\nHIF is strongly involved with SIDS & Kids Western Australia. This charity’s mission is to save the lives of infants through education and research. HIF also provide support for those affected by the sudden and unexpected death of a child.\nHIF sponsor a number of community initiatives, including:\n\n\n\n"}
{"id": "26205474", "url": "https://en.wikipedia.org/wiki?curid=26205474", "title": "Heat trap", "text": "Heat trap\n\nHeat traps are valves or loops of pipe installed on the cold water inlet and hot water outlet pipes on water heaters. The heat traps allow cold water to flow into the water heater tank, but prevent unwanted convection and heated water to flow out of the tank. Newer water heaters have built-in heat traps.\n\nMany water-heating pieces of equipment have integral heat traps installed from the factory. For water-heating equipment that does not already have factory installed heat traps, they must be purchased then installed in the inlet and outlet connections.\n\nHeat traps are very simple and inexpensive. They are an effective way to prevent cooling of hot water in water heaters by thermosyphoning the hot water to a higher elevated portion of the piping system. Thermosyphoning is based on natural convection. Hot water rises and is then displaced by cold water beneath it. The heat trap stops this process, thus keeping the hot water inside the insulated storage tank.\n\n\n"}
{"id": "24038428", "url": "https://en.wikipedia.org/wiki?curid=24038428", "title": "Hudson–Stahli line", "text": "Hudson–Stahli line\n\nThe Hudson–Stahli line is a line of iron deposition lying roughly on the border between the middle and lower thirds of the cornea. It lies in the corneal epithelium. Usually it has about 0.5 mm in thickness and is 1–2 mm long. It is generally horizontal, with possible mild downward trend in the middle. It is present normally in people over the age of 50, but seems to dissipate to some degree by the age of 70.\n\nThe Hudson-Stahli line is not associated with any pathology calling for clinical intervention. Formation of the line may depend upon the rate of tear secretion.\n\nHowever, the Hudson-Stahli line can be enhanced in hydroxychloroquine toxicity.\n\n\n"}
{"id": "2634430", "url": "https://en.wikipedia.org/wiki?curid=2634430", "title": "International Food Policy Research Institute", "text": "International Food Policy Research Institute\n\nThe International Food Policy Research Institute (IFPRI) is an international agricultural research center founded in the early 1970s to improve the understanding of national agricultural and food policies to promote the adoption of innovations in agricultural technology. Additionally, IFPRI was meant to shed more light on the role of agricultural and rural development in the broader development pathway of a country. The mission of IFPRI is to provide research-based policy solutions that sustainably reduce poverty and end hunger and malnutrition.\n\nIFPRI carries out food policy research and disseminates it through hundreds of publications, bulletins, conferences, and other initiatives. IFPRI was organized as a District of Columbia non-profit, non-stock corporation on March 5, 1975, and its first research bulletin was produced in February 1976. IFPRI has offices in several developing countries, including China, Ethiopia, and India, and has research staff working in many more countries around the world. Most of the research takes place in developing countries in Central America, South America, Africa, and Asia.\n\nIFPRI is part of a network of international research institutes funded in part by the CGIAR, which in turn is funded by governments, private businesses and foundations, and the World Bank.\n\nIFPRI's institutional strategy rests on three pillars: research, capacity strengthening, and policy communication.\n\nResearch topics have included low crop and animal productivity, and environmental degradation, water management, fragile lands, property rights, collective action, sustainable intensification of agricultural production, the impact of climate change on poor farmers, the problems and opportunities of biotechnology, food security, micronutrient malnutrition, microfinance programs, urban food security, resource allocation within households, and school feeding in low-income countries.\n\nOne major area of research is gender and development, One study, conducted in Sub-Saharan Africa, looked at the relative productivity of plots of farm land controlled by men compared to plots controlled by women. They found that the majority of resources are devoted to plots controlled by men, but if resources were diverted to plots controlled by women productivity could increase by as much as 20%. In another study in Kenya, where women get almost no education, they determined that if women farmers were provided one year of primary education, maize production could increase by as much as 24%.\n\nStudies conducted in Egypt and Mozambique found that the education level of adult females in a household is more important than the education level of adult males to bring a household out of poverty. Increasing the education of mothers to completion of primary school decreased the percentage of households below the poverty line by 33.7%. Related studies in Bangladesh, Ethiopia, Indonesia and South Africa found that when women controlled the finances children benefited. The funds were more likely to be spent on children's clothes, education and general well being for both girls and boys.\n\nOne of the areas of research for the IFPRI is the effects of climate change on developing countries. Climate change describes a global change in the climate, but this does not mean that all areas of the globe will be affected equally or that they will all experience the same type of climate change. Some areas may become warmer while others may become colder. The IFPRI has conducted studies to model the effects of climate change on developing populations.\n\nIn 2011, IFPRI published the results of a study in The Republic of Yemen predicting the economic outcome of climate change in urban and rural Yemeni communities. The study predicted that the country's GDP would drop, but that agricultural GDP would increase. It predicted that flooding would cause farmers to lose some crops, but agriculture in general would benefit. The group expected to suffer the most would be rural non-farmers. In the long term, climate change was predicted to damage food security and cause a decrease in household GDP.\n\nIn December 2011, the IFPRI published a report sent to the United Nations Framework Convention on Climate Change (UNFCCC) highlighting the need for research into agricultural systems likely to be affected by climate change. They highlighted 12 that they suggested should be high research priority:\n\nIFPRI has done extensive research into areas related to malnutrition. They have conducted research all over the world on various issues that arise from or cause malnutrition. They have looked at HIV and Malaria and how malnutrition affects the epidemiology of these diseases. They have looked at the effects of childhood malnutrition on adult health. They have looked at the potential benefits of biotech crops on childhood nutrition, and the effects of vitamin supplements in general.\n\nA study in Ethiopia to test cost effectiveness of two different methods of treating malnutrition in children was done by Tekeste Asayehegn. In the study the compared two different methods of long term care for the malnourished children. In the first method children were brought to Therapeutic Feeding Centers where they remained as in-patients. The alternative method involved the supplies to treat malnourished children being sent to local clinics and healthcare facilities where the children were brought on a weekly or fortnight basis for treatment. The nutritional supplements were then sent home with the children. Volunteers checked on the patients at home and brought them to the facilities for treatment. This localized treatment program was found to cut the cost of treating a malnourished child in half.\n\nIn Uganda the IFPRI conducted a study on the relationship between malnutrition and the incidences of malaria. There were two variables in the study the first was evidence of malnutrition in the child and the second was whether or not the child was infected with HIV. The study indicated that there may be a correlation between malnutrition and increased risk of malaria. Both the HIV-negative and positive patients that were malnourished showed higher rates of malaria than the groups with better nutrition.\n\nIFPRI neither supports nor opposes genetically modified foods; however, they have released many publications on the potential impact of using transgenic crops. There are many types of transgenic crops. Some modify the plant's ability to produce natural pesticides while others affect the nutritional value of the crops themselves. In 2009 IFPRI released a publication that was an overview of the use of biotech crops between 1997 and 2007. Since the institute maintains a neutral standpoint on the subject, they chose the term \"biotech\" as being less inflammatory than \"genetically modified\" or \"transgenic\". The publication was a review of many studies conducted during the ten-year time period in several countries around the world.\n\nThey observed that many of the studies were inconclusive in terms of the economic value of a crop. For instance, the studies showed conclusively that the use of Bt cotton reduced the need for pesticide treatment and increased crop yield, but they did not show whether it increased profits for the small farms involved. They determined that the information provided to the consumer was important in these studies. Negative messages were very effective at dissuading use.\n\nOverall, the researchers determined that some strains of biotech crops were economically promising especially in countries like India and China. They were unwilling to make too strong a judgment on the data provided recommending better studies be conducted over the following ten years to obtain a more complete understanding of the economic effects of biotech crops in developing countries. This publication made no observations about potential environmental or health related issues involved with the crops. It simply dealt with potential profits and economic impact.\n\nIFPRI also analyzes agricultural market reforms, trade policy, World Trade Organization negotiations in the context of agriculture, institutional effectiveness, crop and income diversification, postharvest activity, and agroindustry.\n\nThe institute is involved in measuring the Millennium Development Goals project and supports governments in the formulation and implementation of development strategies.\n\nFurther work includes research on agricultural innovation systems and the role of capacity strengthening in agricultural development.\n\nIFPRI targets its policy and research products to many audiences, including developing-country policymakers, nongovernmental organizations (NGOs), and civil-society organizations, \"opinion leaders\", donors, advisers, and media.\n\nPublications by IFPRI include books, research reports, but also newsletters, briefs, and fact sheets, which are also available from IFPRI's Knowledge Repository. It is also involved in the collection of primary data and the compilation and processing of secondary data.\n\nThe Global Food Policy Report is one of IFPRI's flagship publications. To meet the needs of policy makers and researchers interested in food security and nutrition, this annual report offers an overview of recent food policy developments that have contributed to or hindered progress in reducing hunger and improving nutrition. It reviews what happened in food policy and why, examines key challenges and opportunities, shares new evidence and knowledge, updates key food policy indicators, and highlights emerging issues. The 2017 Report takes an in-depth look at how rapid urbanization is reshaping food systems and its impact on food security and nutrition for rural and urban populations, focusing on policies to improve rural-urban linkages.\n\nIn 1993 IFPRI introduced the 2020 Vision Initiative, which aims at coordinating and supporting a debate among national governments, nongovernmental organizations, the private sector, international development institutions, and other elements of civil society to reach food security for all by 2020.\n\nAs of 2006 IFPRI produces the Global Hunger Index (GHI) yearly measuring the progress and failure of individual countries and regions in the fight against hunger. The GHI is a collaboration of IFPRI, the Welthungerhilfe, and Concern Worldwide.\n\nIFPRI has produced the related Hunger Index for the States of India (ISHI) (2008) and the Sub-National Hunger Index for Ethiopia (2009).\n\nIFPRI is made up of the Office of the Director General, Eastern and Southern Africa Office, South Asia Office, West & Central Africa Office, Communications & Knowledge Management Division, the Finance and Administration Division, and 5 research divisions:\n\n\nIFPRI also leads two of CGIAR's Research Programs (CRPs): Policies, Institutions, and Markets (PIM) and Agriculture for Nutrition and Health (A4NH).\n\nIFPRI hosts several research networks:\n\nThe evaluation of policy-oriented research poses a lot of challenges including the difficulty to quantify the impact of knowledge and ideas in terms of reduced poverty and or increased income or the attribution of a change in these numbers to a specific study or research project.\n\nDespite these challenges, studies find that IFPRI research had spill-over effects for specific country-level research, but also in setting the global policy agenda, for example in the areas biodiversity (influencing the International Treaty on Plant Genetic Resources) and trade (with respect to the Doha Development Round of trade negotiations).\n\nAnother example of IFPRI's impact on policy formulation was the 2007–2008 world food price crisis. IFPRI was able to quickly pull together relevant research and its resulting recommendations were included in the United Nations' Comprehensive Framework for Action on food security.\n\nIFPRI leads a number of partnerships that engage different stakeholders to influence policies with an impact on poverty, hunger and food situation of poor people. The newest of these initiatives is Compact2025, a partnership that develops and disseminates evidence-based advice to politicians and other decision-makers aimed at ending hunger and undernutrition in the coming 10 years.\n\nCGIAR and its agencies, including IFPRI, have been criticized for their connections to Western governments and multinational agribusiness. Its research publications have also been cited by critics of genetically modified organisms in agriculture. IFPRI describes itself as \"neither an advocate nor an opponent of genetically modified crops\". In addition, many sources recognize CGIAR as having support of smallholders and poor farmers central to its mission.\n\n"}
{"id": "21874721", "url": "https://en.wikipedia.org/wiki?curid=21874721", "title": "Intracranial hypertension syndrome", "text": "Intracranial hypertension syndrome\n\nIntracranial hypertension syndrome is characterized by an elevated intracranial pressure, papilledema, and headache with occasional abducens nerve paresis, absence of a space-occupying lesion or ventricular enlargement, and normal cerebrospinal fluid chemical and hematological constituents.\n"}
{"id": "326481", "url": "https://en.wikipedia.org/wiki?curid=326481", "title": "Irritation", "text": "Irritation\n\nIrritation, in biology and physiology, is a state of inflammation or painful reaction to allergy or cell-lining damage. A stimulus or agent which induces the state of irritation is an irritant. Irritants are typically thought of as chemical agents (for example phenol and capsaicin) but mechanical, thermal (heat), and radiative stimuli (for example ultraviolet light or ionising radiations) can also be irritants. Irritation also has non-clinical usages referring to bothersome physical or psychological pain or discomfort.\n\nIrritation can also be induced by some allergic response due to exposure of some allergens for example contact dermatitis, irritation of mucosal membranes and pruritus. Mucosal membrane is the most common site of irritation because it contains secretory glands that release mucous which attracts the allergens due to its sticky nature.\n\nChronic irritation is a medical term signifying that afflictive health conditions have been present for a while. There are many disorders that can cause chronic irritation, the majority involve the skin, vagina, eyes and lungs.\n\nIn higher organisms, an allergic response may be the cause of irritation. An allergen is defined distinctly from an irritant, however, as allergy requires a specific interaction with the immune system and is thus dependent on the (possibly unique) sensitivity of the organism involved while an irritant, classically, acts in a non-specific manner.\n\nIt is a form of stress, but conversely, if one is stressed by unrelated matters, mild imperfections can cause more irritation than usual: one is irritable; see also sensitivity (human).\n\nIn more basic organisms, the status of pain is the perception of the being stimulated, which is not observable although it may be shared (see gate control theory of pain).\nIt is not proven that oysters can feel pain, but it is known that they react to irritants. When an irritating object becomes trapped within an oyster's shell, it deposits layers of calcium carbonate (CaCO), slowly increasing in size and producing a pearl. This is purely a defense mechanism, to trap a potentially threatening irritant such as a parasite inside its shell, or an attack from outside, injuring the mantle tissue. The oyster creates a pearl sac to seal off the irritation.\n\nIt has also been observed that an amoeba avoids being prodded with a pin, but there is not enough evidence to suggest how much it feels this. Irritation is apparently the only universal sense shared by even single-celled creatures.\n\nIt is postulated that most such beings also feel pain, but this is a projection – empathy. Some philosophers, notably René Descartes, denied it entirely, even for such higher mammals as dogs or primates like monkeys; Descartes considered intelligence a pre-requisite for the feeling of pain.\n\nModern office work with use of office equipment has raised concerns about possible adverse health effects. Since the 1970s, reports have linked mucosal, skin, and general symptoms to work with self-copying paper. Emission of various particulate and volatile substances has been suggested as specific causes. These symptoms have been related to Sick Building Syndrome, which involves symptoms such as irritation to the eyes, skin, and upper airways, headache and fatigue.\n\nThe eye is also a source of chronic irritation. Disorders like Sjögren's syndrome, where one does not make tears, can cause a dry eye sensation which feels very unpleasant. The condition is difficult to treat and is lifelong. Besides artificial tears, there is a drug called Restasis which may help.\n\nBlepharitis is dryness and itching on the upper eyelids. This condition is often seeing in young people and can lead to reddish dry eye and scaly eyebrows. To relieve the itching sensation, one may need to apply warm compresses and use topical corticosteroid creams.\n\nEczema is another cause of chronic irritation and affects millions of individuals. Eczema simply means a dry skin which is itchy. The condition usually starts at an early age and continues throughout life. The major complaint of people who suffer from eczema is an itchy dry skin. Sometimes, the itching will be associated with a skin rash. The affected areas are always dry, scaly, reddish and may ooze sometimes. Eczema cannot be cured, but its symptoms can be controlled. One should use moisturizers, use cold compresses and avoid frequent hot showers. There are over the counter corticosteroids creams which can be applied. Sometimes, an anti histamine has to be used to prevent the chronic itching sensations. There are also many individuals who have allergies to a whole host of substances like nuts, hair, dander, plants and fabrics. For these individuals, even the minimal exposure can lead to a full blown skin rash, itching, wheezing and coughing. Unfortunately, other than avoidance, there is no other cure. There are allergy shots which can help desensitize against an allergen but often the results are poor and the treatments are expensive. Most of these individuals with chronic irritation from allergens usually need to take anti histamines or use a bronchodilator to relieve symptoms.\n\nAnother common irritation disorder in females is intertrigo. This disorder is associated with chronic irritation under folds of skin. This is typically seen under large breasts, groins and folds of the abdomen in obese individuals. Candida quickly grows in warm moist areas of these folds and presents as a chronic itch. Over time, the skin becomes red and often oozes.\nPerspiration is also a chronic type of irritation which can be very annoying. Besides being socially unacceptable, sweat stain the clothes and can present with a foul odor. In some individuals, the warm moist areas often become easily infected. The best way to treat excess sweating is good hygiene, frequent change of clothes and use of deodorants/antiperspirants.\n\nOne of the most common areas of the body associated with irritation is the vagina. Many women complain of an itch, dryness, or discharge in the perineum at some point in their lives. There are several causes of vaginal irritation including fungal vaginitis (like candida) or trichomoniasis. Often, herpes simplex infection of the mouth or genitalia can be recurrent and prove to be extremely irritating.\nSometimes, the irritation can be of the chronic type and it can be so intense that it also causes painful intercourse. Aside from infections, chronic irritation of the vagina may be related to the use of contraceptives and condoms made from latex. The majority of contraceptives are made of synthetic chemicals which can induce allergies, rash and itching. Sometimes the lubricant used for intercourse may cause irritation.\nAnother cause of irritation in women is post menopausal vaginitis. The decline in the female sex hormones leads to development of dryness and itching in the vagina. This is often accompanied by painful sexual intercourse. Cracks and tears often develop on outer aspects of the labia which becomes red from chronic scratching. Post menopausal vaginitis can be treated with short term use of vaginal estrogen pessary and use of a moisturizer.\n\nIndividuals who smoke or are exposed to smog or other airborne pollutants can develop a condition known as COPD. In this disorder, there is constant irritation of the breathing tubes (trachea) and the small airways. The constant irritation results in excess production of mucus which makes breathing difficult. Frequently, these individuals wake up in the morning with copious amounts of foul smelling mucus and a cough which lasts all day. Wheeze and heavy phlegm are common findings. COPD is a lifelong disorder and there is no cure. Eventually most people develop recurrent pneumonia, lack any type of endurance, and are unable to work productively. One of the ways to avoid chronic bronchitis is to stop or not smoke.\n\nGastritis or stomach upset is a common irritating disorder affecting millions of people. Gastritis is basically inflammation of the stomach wall lining and has many causes. Smoking, excess alcohol consumption and the use of non-steroidal anti-inflammatory drugs (NSAIDs), such as ibuprofen, account for the majority of causes of gastritis. In some cases, gastritis may develop after surgery, a major burn, infection or emotional stress. The most common symptoms of gastritis include sharp abdominal pain which may radiate to the back. This may be associated with nausea, vomiting, abdominal bloating and a lack of appetite. When the condition is severe it may even result in loss of blood on the stools. The condition often comes and goes for years because most people continue to drink alcohol or use NSAIDs. Treatment includes the use of antacids or acid neutralizing drugs, antibiotics, and avoiding spicy food and alcohol.\n\n"}
{"id": "9268909", "url": "https://en.wikipedia.org/wiki?curid=9268909", "title": "Israel Journal of Psychiatry and Related Sciences", "text": "Israel Journal of Psychiatry and Related Sciences\n\nThe Israel Journal of Psychiatry and Related Sciences is a medical journal that publishes original articles dealing with the bio-psycho-social aspects of mobility, relocation, acculturation, ethnicity, stress situations in war and peace, victimology, and mental health in developing countries. According to the \"Journal Citation Reports\", the journal has a 2014 impact factor of 0.789.\n"}
{"id": "756399", "url": "https://en.wikipedia.org/wiki?curid=756399", "title": "Jaime Lusinchi", "text": "Jaime Lusinchi\n\nJaime Ramón Lusinchi (27 May 1924 – 21 May 2014) was a Venezuelan politician who was the President of Venezuela from 1984 to 1989. His term was characterized by an economic crisis, growth of the external debt, populist policies, currency depreciation, inflation and corruption that exacerbated the crisis of the political system established in 1958.\n\nAlthough accused of corruption after leaving office, Lusinchi was popular during his presidency, and was succeeded by a member of his own political party, Carlos Andrés Pérez.\n\nJaime Lusinchi was born in Clarines, Anzoategui, on 27 May 1924. His mother María Angelica Lusinchi, who was of Italian-Corsican descent, gave him her family name. Growing up without the presence of a father (who probably was an Italian immigrant), Lusinchi attended elementary school in his native Clarines and Puerto Píritu, and high school at the Federal School of Barcelona, Anzoátegui. In 1941 he began to study Medicine at the University of the Andes in Mérida, but soon moved to Caracas continuing his career at the Central University of Venezuela graduating in 1947. He married Gladys Castillo in 1941.\n\nIn 1937, at the age of 13, Lusinchi vinculated to the National Democratic Party, organization created by Rómulo Betancourt against the government of Eleazar López Contreras. In 1941, Lusinchi was present at the foundation of the social democratic party Acción Democrática.\n\nDuring his time at college, Lusinchi stood out as a political activist, was secretary of the School Medicine Council, vice president of the Venezuelan Association of Youth and vice president of the Student Federation of Venezuela - an organization with Marxist influences that became part of the \"19 October 1945\" revolutionary movement which overthrew the government of Isaías Medina Angarita. In 1948, he was elected president of the Municipal Council of Freites District and president of the Legislative Assembly of Anzoátegui, as well as regional secretary of Acción Democrática.\n\nAfter the overthrow of Venezuela's first democratically elected leader, Rómulo Gallegos, by a military-led coup on 24 November 1948, Lusinchi continued carrying out political activities whilst in hiding from the new military-dominated authorities. For a time he worked in a hospital belonging to the oil company Mene Grande in San Tomé (Anzoátegui state), however he soon moved to Caracas to avoid persecution by security forces who had already arrested him several times before.\n\nIn Caracas he was part of the clandestine organization of Acción Democrática which, in coordination with the leadership in exile, established an organised resistance to the military dictatorship. Lusinchi acquired responsibilities in the national secretariats of organization and propaganda, and was a member of the party's Political Bureau. In 1950 he was one of the organizers of the nationwide strike of oil workers. After the 1952 election fraud, which dissolved the Civilian-Military Junta and began the dictatorship of Marcos Pérez Jiménez, Lusinchi was again captured and imprisoned at the National Security facility.\n\nA month later he was transferred to the \"Cárcel Modelo\" (Model Prison) in Caracas, and was released shortly after that, beginning an exile of five years in Argentina, Chile and the United States. During his stay in Buenos Aires and Santiago de Chile, he undertook postgraduate study in Pediatrics. He resided in Santiago from 1953 and worked at Roberto del Río Hospital. In addition, he struck up friendships with prominent figures in local politics, such as the Christian Democrat Eduardo Frei Montalva and the democratic-socialist leader Salvador Allende.\n\nIn 1956 he moved to New York City, which was the focal point of Acción Democrática's leadership in exile, with Betancourt as the principal leader. In the aforementioned metropolis Lusinchi obtained a master's degree in pediatrics, at Lincoln Hospital and the Bellevue Hospital Center, joining the American Academy of Pediatrics. On 23 January 1958, democracy was restored in Venezuela. Therein after the fall of the Pérez Jiménez Government, Lusinchi returned from exile, and joined the National Executive Committee of Acción Democrática as secretary for International Affairs. In the 1959 General Elections he was elected deputy for Anzoátegui for the National Congress, being re-elected in 1963, 1968 and 1973.\n\nIn 1977, Lusinchi unsuccessfully ran for the presidency of Acción Democrática and in the 1978 elections was defeated by Luis Piñerúa Ordaz (who in turn lost against the candidate of COPEI, Luis Herrera Campins). After this, Lusinchi was elected senator for the 1979-1984 period. On March, 1981 he was elected General Secretary of Acción Democrática, and on 29 June 1982, he was nominated as a candidate for the 1983 elections.\n\nOn 4 December 1983, Lusinchi with 56% of the votes, won the presidency, and Acción Democrática obtained an absolute majority n the Congress. On 2 February 1984, he was sworn in as President of Venezuela for a five-year term.\n\nLusinchi started his presidency at the age of 59, promising to govern with fairness, transparency, social sensitivity and austerity in the use of public funds, while presenting himself as a moderate president.\n\nThe first three years of his presidency were characterized by efforts to achieve economy stability, the paying off of the foreign debts, the reduction of public spending, the implementation of social programs benefiting the people and the promotion of industrial growth. These goals were not accomplished. However, agriculture and the iron mining industry were developed during his administration, the country achieved positive growth rates at the end of 1984, with a growth rate of 6% in GDP, but the official rate of unemployment inherited from the previous government of Luis Herrera Campins was 20%.\n\nDuring this period, the government started negotiations to restructure interest payments and amortizations of the foreign debt, which in 1985 was 36 billion dollars (of which 28 billion was from the public sector), contracted with the international private banking and multilateral agencies. The first positive result of this effort was that Venezuela regained a credit-eligibility rating. In addition, Lusinchi took initiatives to increase oil prices via OPEC.\n\nHowever, Lusinchi was not successful at crucial goals for the development of the country. The oil market was too unstable due to price fluctuations and thus unpredictable, the oil prices were low, and the Venezuelan economy was too oil-dependent. This led to a dismal situation due to an excessively high government fiscal budget, depleting financial reserves for the payment of debt, an important pledge made during Lusinchi's presidential campaign.\n\n1985, was characterized by a relative social peace and the absence of labor disputes and strikes, in part due to the support of the government by the largest trade union of the country, the Confederation of Workers of Venezuela, which had traditionally been closely linked to Acción Democrática. During this year, Lusinchi welcomed John Paul II, the first Pope ever to visit Venezuela. But in the second half of his presidency, the social malaise grew, and the government was pressed to change the direction of its policies. In December 1986, the government decided to devalue the official exchange of the national currency bolivar by 93%, culminating with three years of depreciation of the national currency. Starting February, 1983, also introduced was a system of multiple currency changes. In 1987, Lusinchi finally stopped the economic program carried out from the beginning of his term in office, and gave up his attempts to pay off the external debt, control the fiscal deficit and restrain public spending.\n\nAfter that, Lusinchi decreed salary increases, price controls, emission of currency and compensatory bonds for subsidies. These measures tried to appease social tensions, that from 1987 on had appeared with more intensity. Among the consequences of this economic program were, more inflation and budget deficits.\n\nThe return to economic populism as in previous administrations safeguarded Lusinchi's popularity. However, there occurred currency devaluation, corruption, media criticism and unsatisfactory results from the Presidential Commission for State Reform (COPRE) which was established on 17 December 1984 and whose work encountered the same bureaucratic problems and administrative inefficiency, which it attempted to solve.\n\nDuring Lusinchi's presidency some repudable incidents also occurred, such as the Yumare massacre, in Yaracuy, on 8 May 1986 carried out by the DISIP (political police of Venezuela), executing nine members of the subversive group \"Punto Cero\"; and the massacre of El Amparo, in Apure State, on 29 October 1988, in which 14 fishermen were mistakenly assumed to be guerrillas and killed by the army.\n\nLusinchi supported the former minister and political leader Octavio Lepage in his bid to be AD's candidate for the 1988 elections, but Lepage was defeated in the internal elections of the party on October, 1987, by the former president Carlos Andrés Pérez. Pérez was elected for a new term after a gap as president in 1988. Lusinchi finished his term in office on 2 February 1989.\n\nIn January 1986, Pope John Paul II visited Venezuela. This was to be the first time ever that a Roman pontiff had visited that country specifically. As part of that very special event, thousands of people were mobilized to conduct many cultural and religious programs in several different cities, notably Puerto Ordaz, Maracaibo, Mérida and Caracas. To commemorate the place where the Pope conducted Mass while in Caracas, a housing complex was created years later that used the Pope's official title, John Paul II, as its own. Unfortunately that effort became tarnished by corruption and scandal.\n\nOn 13 August 1987, the Colombian navy corvette \"Caldas\" sailed into the Gulf of Venezuela, causing a crisis in Colombian-Venezuelan relations that almost led to armed conflict. The crisis was eventually resolved by dialogue between Lusinchi and Colombian President Virgilio Barco.\n\nAfter his presidency had ended, Lusinchi was appointed Senator for Life, as was permitted by the Venezuelan constitution of 1961. But From 27 March 1990, Lusinchi became the subject of a parliamentary inquiry looking at what was believed to be a corruption scandal of huge proportions that took place during his term in government. Accused of illegally influencing decisions at the currency exchange through the financial Regime of Preferential Currency Change (RECADI) and management of funds at the Foreign Affairs Ministry, as well as the purchase of 65 off-road vehicles that were to be used in the 1988 electoral campaign of Acción Democrática; the diversion of other funds from the National Institute for Racetracks (INH). He was also declared a suspect in the August 1993 sending of mail bombs meant to intimidate members of the Supreme Court.\n\nIn November 1991, the Venezuelan Congress issued a \"political and moral condemnation\" to be lodged against the former president for his part in economic mismanagement and administrative irregularities that took place during his term. Then, on 10 August 1993, the Supreme Court decided it had found evidence of actual criminality during its review of charges filed against Lusinchi by the Attorney General's Office, and started proceedings against him.\n\nOn 13 August Lusinchi was stripped of senatorial immunity, and prohibited from leaving of country. Lusinchi responded by flying to Miami. Next he left for Costa Rica where he met Blanca Ibáñez, his future wife. In July 1994, and again in February 1997, charges were filed against him by the courts. A trial was opened against the former president, ostensibly for his illegal use of funds belonging to the Department of Foreign Affairs and the National Institute for Racetracks (INH). But in October 1999, the Supreme Court reversed both decisions.\n\nAlthough an inquiry into the process of how that happened was later opened, by then the corruption charges against him had expired their legal term of placement. Again in June 2006 however, himself and seven former officials of his government, along with 38 other retired members of the Venezuelan security services DISIP were accused of in some way being guilty of events now known as the Yumare Massacre.\n\nLusinchi left Venezuela via Miami and lived in the city of San José, Costa Rica. till 2009, when returned to Caracas.\n\nLusinchi was married to Gladys Castillo in 1941–1988 (they had 1 son and 4 daughters) who served as First Lady of Venezuela from 1984, and then to Blanca Ibáñez in 1991–2014.\n\nLusinchi died on 21 May 2014 at the age of 89 after having been hospitalized for lung problems. He died about 5 weeks before ex-President Ramón José Velásquez died on 24 June 2014 of a natural causes.\n\n\n"}
{"id": "11610629", "url": "https://en.wikipedia.org/wiki?curid=11610629", "title": "Kathryn Adams Doty", "text": "Kathryn Adams Doty\n\nKathryn Elizabeth Doty (née Hohn; July 15, 1920 – October 14, 2016), also known by her stage name Kathryn Adams or as Kathryn Adams Doty, was an American actress.\n\nThe daughter of a Methodist minister, Dr. Chris G. Hohn, Doty was born in New Ulm, Minnesota. When she was 6, the family moved to Warrenton, Missouri, where her father was chaplain and executive secretary at an orphan's home. After she developed lung problems, she spent two years at a camp in Minnesota. As early as age 13, she took her father's place in the pulpit when he was sick. In a 1939 newspaper article, she recalled: \"It was quite a radical thing, in that small town, for a little girl to conduct the church services and preach the sermon, but the congregation understood and were very kind to me.\"\n\nDoty was a student at Hamline University in Saint Paul, Minnesota, (where she sang in the a cappella choir) and worked as a catalog clerk at the headquarters of Montgomery Ward when an opportunity for an acting career arose. She competed in 1939 in the national finals of the Jesse L. Lasky radio contest, \"Gateway to Hollywood\", received a contract, and remained in California to begin a film career under the name of Kathryn Adams.\n\nDoty debuted on film in \"5th Avenue Girl\" (1939). One of her most notable roles was as \"Mrs. Brown\", the young mother in Alfred Hitchcock's \"Saboteur\" (1942). She co-starred in \"Sky Raiders\" (1941), a film serial from Universal and had the leading lady role in three Western films in which Johnny Mack Brown starred.\n\nShe married fellow actor Hugh Beaumont in an Easter wedding, April 13, 1941, at Hollywood Congregational Church. They had three children: Hunter, Kristy, and Mark. After divorcing Beaumont in 1974, she married Fred Doty, and relocated to her native Minnesota. Fred Doty (1922 – 2011) died on January 8, 2011, aged 88.\n\nShe earned a master's degree in Educational Psychology and had a career as a psychologist, working at the Footlight's Child Guidance Clinic at Hollywood Presbyterian Medical Center and later in Minnesota after she moved back to her home state.\n\nAdams Doty wrote two novels: \"A Long Year of Silence\" and \"Wild Orphan\". \"A Long Year of Silence\", set in New Ulm, Minnesota, during World War I, was a finalist for the Minnesota Book Award and winner of the 2005 Midwest Book Award. A third book, \"Becoming the Mother of Me\", described her life growing up as a minister's daughter and her trip to Hollywood and her first marriage.\n\nWriting as Kathryn Doty, she published short stories in \"Pocket\", \"The Friend\" and various children's magazines.\n\nAdams died on October 14, 2016, aged 96.\n\n\n"}
{"id": "2251120", "url": "https://en.wikipedia.org/wiki?curid=2251120", "title": "Law of comparative judgment", "text": "Law of comparative judgment\n\nThe law of comparative judgment was conceived by L. L. Thurstone. In modern-day terminology, it is more aptly described as a model that is used to obtain measurements from any process of pairwise comparison. Examples of such processes are the comparison of perceived intensity of physical stimuli, such as the weights of objects, and comparisons of the extremity of an attitude expressed within statements, such as statements about capital punishment. The measurements represent how we perceive objects, rather than being measurements of actual physical properties. This kind of measurement is the focus of psychometrics and psychophysics.\n\nIn somewhat more technical terms, the law of comparative judgment is a mathematical representation of a discriminal process, which is any process in which a comparison is made between pairs of a collection of entities with respect to magnitudes of an attribute, trait, attitude, and so on. The theoretical basis for the model is closely related to item response theory and the theory underlying the Rasch model, which are used in psychology and education to analyse data from questionnaires and tests.\n\nThurstone published a paper on the law of comparative judgment in 1927. In this paper he introduced the underlying concept of a psychological continuum for a particular 'project in measurement' involving the comparison between a series of stimuli, such as weights and handwriting specimens, in pairs. He soon extended the domain of application of the law of comparative judgment to things that have no obvious physical counterpart, such as attitudes and values (Thurstone, 1929). For example, in one experiment, people compared statements about capital punishment to judge which of each pair expressed a stronger positive (or negative) attitude.\n\nThe essential idea behind Thurstone's process and model is that it can be used to scale a collection of stimuli based on simple comparisons between stimuli two at a time: that is, based on a series of \"pairwise\" comparisons. For example, suppose that someone wishes to measure the perceived weights of a series of five objects of varying masses. By having people compare the weights of the objects in pairs, data can be obtained and the law of comparative judgment applied to estimate scale values of the \"perceived\" weights. This is the perceptual counterpart to the physical weight of the objects. That is, the scale represents how heavy people perceive the objects to be based on the comparisons.\n\nAlthough Thurstone referred to it as a law, as stated above, in terms of modern psychometric theory the 'law' of comparative judgment is more aptly described as a measurement model. It represents a general theoretical model which, applied in a particular empirical context, constitutes a scientific hypothesis regarding the outcomes of comparisons between some collection of objects. If data agree with the model, it is possible to produce a scale from the data.\n\nThurstone showed that in terms of his conceptual framework, Weber's law and the so-called Weber-Fechner law, which are sometimes (and misleadingly) regarded as one and the same, are independent, in the sense that one may be applicable but not the other to a given collection of experimental data. In particular, Thurstone showed that if Fechner's law applies \"and\" the discriminal dispersions associated with stimuli are constant (as in Case 5 of the LCJ outlined below), then Weber's law will also be verified. He considered that the Weber-Fechner law and the LCJ both involve a linear measurement on a psychological continuum whereas Weber's law does not.\n\nWeber's law essentially states that how much people perceive physical stimulus intensity to change depends on that intensity. For example, if someone compares a light object of 1 kg with one slightly heavier, one notices a relatively small difference, perhaps when the second object is 1.2 kg. On the other hand, if someone compares a heavy object of 30 kg with a second, the second must be quite a bit larger for a person to notice the difference, perhaps when the second object is 36 kg. People tend to perceive differences that are \"proportional\" to the size rather than noticing a specific difference irrespective of the size. The same applies to brightness, pressure, warmth, loudness, and so on.\n\nThurstone stated Weber's law as follows: \"The stimulus increase which is correctly discriminated in any specified proportion of attempts (except 0 and 100 per cent) is a constant fraction of the stimulus magnitude\" (Thurstone, 1959, p. 61). He considered that Weber's law said nothing directly about sensation intensities at all. In terms of Thurstone's conceptual framework, the association posited between perceived stimulus intensity and the physical magnitude of the stimulus in the Weber-Fechner law will only hold when Weber's law holds \"and\" the just noticeable difference (JND) is treated as a unit of measurement. Importantly, this is not simply given a priori (Michell, 1997, p. 355), as is implied by purely mathematical derivations of the one law from the other. It is, rather, an empirical question whether measurements have been obtained; one which requires justification through the process of stating and testing a well-defined hypothesis in order to ascertain whether specific theoretical criteria for measurement have been satisfied. Some of the relevant criteria were articulated by Thurstone, in a preliminary fashion, including what he termed the \"additivity criterion\". Accordingly, from the point of view of Thurstone's approach, treating the JND as a unit is justifiable provided only that the discriminal dispersions are uniform for all stimuli considered in a given experimental context. Similar issues are associated with Stevens' power law.\n\nIn addition, Thurstone employed the approach to clarify other similarities and differences between Weber's law, the Weber-Fechner law, and the LCJ. An important clarification is that the LCJ does not \"necessarily\" involve a physical stimulus, whereas the other 'laws' do. Another key difference is that Weber's law and the LCJ involve proportions of comparisons in which one stimulus is judged greater than another whereas the so-called Weber-Fechner law does not.\n\nThe most general form of the LCJ is\n\nin which:\n\n\nThe \"discriminal dispersion\" of a stimulus \"i\" is the dispersion of fluctuations of the \"discriminal process\" for a uniform repeated stimulus, denoted formula_5, where formula_2 represents the \"mode\" of such values. Thurstone (1959, p. 20) used the term discriminal process to refer to the \"psychological values of psychophysics\"; that is, the values on a psychological continuum associated with a given stimulus.\n\nThurstone specified five particular cases of the 'law', or measurement model. An important case of the model is Case 5, in which the discriminal dispersions are specified to be uniform and uncorrelated. This form of the model can be represented as follows:\n\nwhere\n\nIn this case of the model, the difference formula_11 can be inferred directly from the proportion of instances in which \"j\" is judged greater than \"i\" if it is hypothesised that formula_3 is distributed according to some density function, such as the normal distribution or logistic function. In order to do so, it is necessary to let formula_13, which is in effect an arbitrary choice of the unit of measurement. Letting formula_14 be the proportion of occasions on which \"i\" is judged greater than \"j\", if, for example, formula_15 and it is hypothesised that formula_3 is normally distributed, then it would be inferred that formula_17.\n\nWhen a simple logistic function is employed instead of the normal density function, then the model has the structure of the Bradley-Terry-Luce model (BTL model) (Bradley & Terry, 1952; Luce, 1959). In turn, the Rasch model for dichotomous data (Rasch, 1960/1980) is identical to the BTL model after the person parameter of the Rasch model has been eliminated, as is achieved through statistical conditioning during the process of Conditional Maximum Likelihood estimation. With this in mind, the specification of uniform discriminal dispersions is equivalent to the requirement of parallel Item Characteristic Curves (ICCs) in the Rasch model. Accordingly, as shown by Andrich (1978), the Rasch model should, in principle, yield essentially the same results as those obtained from a Thurstone scale. Like the Rasch model, when applied in a given empirical context, Case 5 of the LCJ constitutes a mathematized hypothesis which embodies theoretical criteria for measurement.\n\nOne important application involving the law of comparative judgment is the widely used Analytic Hierarchy Process, a structured technique for helping people deal with complex decisions. It uses pairwise comparisons of tangible and intangible factors to construct ratio scales that are useful in making important decisions.\n\n\n"}
{"id": "11005395", "url": "https://en.wikipedia.org/wiki?curid=11005395", "title": "List of acupuncture points", "text": "List of acupuncture points\n\nThis article provides a comprehensive list of acupuncture points, locations on the body used in acupuncture, acupressure, and other treatment systems based on Traditional Chinese Medicine (TCM).\n\nMore than four hundred acupuncture points have been described, with the majority located on one of the main meridians, pathways which run throughout the body and according to Traditional Chinese Medicine (TCM) transport life energy (qi, 氣). TCM recognizes twenty meridians, cutaneous and subcutaneous in nature, which have branching sub-meridians believed to affect surrounding tissues. Twelve of these major meridians, commonly referred to as \"the primary meridians\", are bilateral and are associated with internal organs. The remaining eight meridians are designated as \"extraordinary\", and are also bilateral except for three, one that encircles the body near the waist, and two that run along the midline of the body. Only those two extraordinary meridians that run along the midline contain their own points, the remaining six comprise points from the aforementioned twelve primary meridians. There are also points that are not located on the fourteen major meridians but do lie in the complete nexus referred to as \"jing luo\" (經絡). Such outliers are often referred to as \"extra points\".\n\nAlthough many hypotheses have been proposed, the anatomical and physiological basis for acupuncture points and meridians remains elusive. Hypotheses include neural signaling, with possible involvement of opioid peptides, glutamate, and adenosine, and correspondence to responsive parts in the central nervous system; or mechanical signaling, with involvement of connective tissue (fascia), and mechanical wave activation of the calcium ion channel to beta-endorphin secretion. In practice, acupuncture points are located by a combination of anatomical landmarks, palpation, and feedback from the patient.\n\nTwelve Primary Meridians:\nEight Extraordinary Meridians 奇 經 八 脈 (奇 经 八 脉), qí jīng bā mài (qí jīng bā mò):\n\nIn east Asian countries practitioners commonly refer to acupuncture points by their traditional names. Some points have several names. When acupuncture was adopted in the western world, a standard nomenclature was developed to unambiguously identify the acupuncture points on meridians. This model achieved wide acceptance and today virtually every book on acupuncture refers to acupuncture points using it. The World Health Organization (WHO) published \"A Proposed Standard International Acupuncture Nomenclature Report\" in 1991, listing 361 classical acupuncture points organized according to the fourteen meridians, eight extra meridians, 48 extra points, and scalp acupuncture points, and published \"Standard Acupuncture Nomenclature\" in 1993, focused on the 361 classical acupuncture points. Each acupuncture point is identified by the meridian on which it is located and its number in the point sequence on that channel. For example, \"Lu-9\" identifies the 9th acupuncture point on the lung meridian, \"tài yuān\" (太渊) or \"gui xin\" (鬼心), two names used for this same point. The only glitch with this unique systemized method can be found on the urinary bladder meridian, where the outer line of 14 points found on the back near the spine are inserted in one of two ways; following the last point of the inner line along the spine (會陽) and resuming with the point found in the crease of the buttocks (承扶), or following the point in the center of the crease of the knee (委中) and resuming with the point just below that (合陽), found in the bifurcation of the gastrocnemius muscle. Although classification of the extra points often tries to utilize a similar shortcut method, where a numbered sequence along an assigned body part is used, there is no commonly agreed-upon system and therefore universal identification of these points relies on the original naming system of traditional Chinese characters.\n\nThe above figure and the tables below follow the standard numbering scheme to identify the acupuncture points of the main channels. For extra points the tables follow the numbering scheme found in \"A Manual of Acupuncture\".\n\nAbbreviated as LU, described in Chinese as 手太阴肺经穴 or 手太陰肺經 \"The Lung channel of Hand Taiyin\".\nAbbreviated as LI or CO (colon), described in Chinese as 手阳明大肠经穴 or 手陽明大腸經 \"The Large Intestine channel of Hand Yangming\".\nAbbreviated as ST, described in Chinese as 足阳明胃经穴 or 足陽明胃經 \"The Stomach channel of Foot Yangming\".\nAbbreviated as SP, described in Chinese as 足太阴睥经穴 or 足太陰脾經 \"The Spleen channel of Foot Taiyin\".\nAbbreviated as HE, HT or H, described in Chinese as 手少阴心经穴 or 手少陰心經 \"The Heart channel of Hand Shaoyin\".\nAbbreviated as SI, described in Chinese as 手太阳小肠经穴 or 手太陽小腸經 \"The Small Intestine channel of Hand Taiyang\". \nAbbreviated as BL or UB (urinary bladder), described in Chinese as 足太阳膀胱经穴 or 足太陽膀胱經 \"The Bladder channel of Foot Taiyang\".\n\nAn alternative numbering scheme for the \"appended part\" (beginning with Bl-41 in the list below), which places the outer line along the spine after Bl-35 (會陽) instead of Bl-40 (委中), will be noted in the Alternative names column.\n\nAbbreviated as KI or K, described in Chinese as 足少阴肾经穴 or 足少陰腎經 \"The Kidney channel of Foot Shaoyin\".\nAbbreviated as PC or P, described in Chinese as 手厥阴心包经穴 or 手厥陰心包經 \"The Pericardium channel of Hand Jueyin\".\nAlso known as San Jiao, triple-heater, triple-warmer or triple-energizer, abbreviated as TB or SJ and described in Chinese as 手少阳三焦经穴 or 手少陽三焦經 \"The Sanjiao channel of Hand Shaoyang\".\nAbbreviated as GB, described in Chinese as 足少阳胆经穴 or 足少陽膽經 \"The Gallbladder channel of Foot Shaoyang\".\nAbbreviated as LR or LV, described in Chinese as 足厥阴肝经穴 or 足厥陰肝經 \"The Liver channel of Foot Jueyin\".\nAlso known as Du, abbreviated as GV and described in Chinese as 督脉穴 or 督脈 \"The Governing Vessel\".\nAlso known as Ren, abbreviated as CV and described in Chinese as 任脉穴 or 任脈 \"The Conception Vessel\".\nThere is no agreed-on naming scheme for extra points on the body; this table follows the numbering scheme of Peter Deadman.\n"}
{"id": "44975261", "url": "https://en.wikipedia.org/wiki?curid=44975261", "title": "Medical Marijuana, Inc.", "text": "Medical Marijuana, Inc.\n\nMedical Marijuana, Inc. (traded over the counter as MJNA), is a holding company with subsidiaries that make and sell a range of hemp-based products.\n\nThe company came into being in 2009, when a company called Club Vivanet bought another company from Bruce Perlowin; the new company was named Medical Marijuana, Inc. and was based in Poway, California. The company appears to have been among the first to exploit the 2004 Ninth Circuit Court of Appeals decision, HIA vs DEA, which prevented the federal government from treating hemp as though it were marijuana, to market canabidiol-based products to the public.\n\nMichael Llamas was the initial CEO of MMI; he stepped down in 2012 when he was indicted for his role in a real estate Ponzi scheme.\n\nThe company operated at a loss for 2011 and 2012, and made money for the first time in 2013 on the basis of a single contract signed by one of its subsidiaries. In 2013, MMI and CannaVEST, an exchange-traded fund, each invested in a company called Kannalife Sciences Inc. Kannalife had been founded in 2010 by Dean Petkanas, former CFO of Stratton Oakmont, the penny-stock trading company depicted in \"The Wolf of Wall Street\", and Thoma Kikis. Kannalife was founded to commercialize inventions made at the NIH concerning methods to use cannabidiol as a neuroprotectant. As of 2016, Kannalife was working on novel analogs of CBD that are more drug-like than CBD.\n\nIn the fall of 2014, the company filed a lawsuit against Project CBD and Stewart Environmental Labs to dispute a report of \"significant levels of toxic solvents\" in the hemp oil offered by one of their subsidiaries. Stewart Environmental settled with the company but Project CBD filed an anti-SLAPP motion in May 2015.\n\nIn 2014, MMI reported that it was under investigation by the SEC; the Financial Industry Regulatory Authority warned investors that year about penny stock scams in the marijuana industry. In 2015 a report in \"Forbes\" laid out relationships among CannaVEST, money taken in by the real estate Ponzi scheme run by Llamas, Stuart Titus and the private equity firm General Hemp that he ran, and one of MMI's subsidiaries called PhytoSphere.\n\nIn 2015 the company hired Titus as CEO after having an interim CEO since Llamas' departure. At that time, the company did most of its business through a subsidiary called HempMedsPX, which marketed and sold products from other MMI subsidiaries. As of 2015 the company sourced the hemp oil used in its products from a facility in Denmark. Its then-most prominent product was called \"Real Scientific Hemp Oil\", sold at around $169 per 3 grams, and was marketed as a dietary supplement. It also sold a range of other consumer products, such as hemp-based shampoo.\n"}
{"id": "18250995", "url": "https://en.wikipedia.org/wiki?curid=18250995", "title": "Mental Health (Care and Treatment) (Scotland) Act 2003", "text": "Mental Health (Care and Treatment) (Scotland) Act 2003\n\nThe Mental Health (Care and Treatment) (Scotland) Act 2003, which came into effect on 5 October 2005, is an Act of the Scottish Parliament which enables medical professionals to detain and treat people against their will on grounds of mental disorder, with the Mental Health Tribunal for Scotland and the Mental Welfare Commission for Scotland providing safeguards against mistreatment.\n\nIt largely replaces the Mental Health (Scotland) Act 1984.\n\nThe act provides for short term detention certificates and emergency detention certificates.\n\nShort term certificates are referred to by the act as the 'preferred gateway' to detention, and lead, notionally, to up to 28 days' detention during which treatment may be administered against the will of the detainee, and can also lead to compulsory treatment orders, which have longer term implications for the detainee's liberty.\n\nDetainees can apply to the Mental Health Tribunal for revocation of short term certificates.\n\nEmergency certificates lead, notionally, to up to 72 hours' detention, and can also lead to detentions under short term certificates.\n\nEmergency certificates do not enable treatment against the will of detainees, except for urgent treatment, and there is no formal process of appeal against them.\n\nUnless a certificate is completed for someone who is already in a mental health hospital, both forms of detention are preceded by detention of up to 72 hours in what are called 'places of safety', while transport to hospital is arranged.\n\nAlso, short term detentions may be extended for periods of up to three 'working days', to facilitate applications to the Mental Health Tribunal for compulsory treatment orders.\n\nSaturdays, Sundays, and Scottish bank holidays are not counted as working days.\n\nThe law is based on a set of principles. These principles should be taken into account by anyone involved in a person's care and treatment.\n\nPatients should be given the information and support they need to take part in decisions about their care and treatment. To help service users get their views across, the Act puts in place the right to access independent advocacy services. It also puts in place advance statements as a way to help service users say what care and treatment they would and would not want to have. The Mental Health Commission in Scotland examines cases where a person's advance statement has been overridden.\n\nCarers should be involved in decision-making and should be given information they need to help them in their role. We will be developing guidance this year to help service providers and carers with the problem of patient confidentiality and sharing information.\n\nA patient's care plan should reflect their needs as an individual. A Mental Health Tribunal reviews care that looks for a compulsory treatment order that lasts longer than 2 years or the service users can request this if they wish to appeal a compulsory treatment order after 3months.\n\nThis should be reflected in a care plan. In addition the Act puts in place safeguards when consent to treatment has not been given.\n\nOn many occasions a patient's care & treatment becomes much to the opinion of any one person, with a psychiatric disorder (mentalis confusio), latest labels that of chemical imbalance or chemical disorder, perplex and confuse not only the patient, but those whom may be designated decision makers on a patient's behalf. Family members all too often are not given any information, nor the correct questions to ask.\n\nAll too often the system fails to accept a lack of science behind these labels. \"where is that chemical test for this chemical imbalance?\" Truth is that like the word illness: no such disease exists, nor any chemical as where is this chemical test; well paid professionals or populus of institutions together, with no clear facts and no willingness to discuss any way except that of psychiatry & adding of substance of those many same category as Class substances.\n\nImportant things about a person such as their age, gender, sexual orientation, religion, racial origin or membership of any ethnic group should be taken into account by people providing care and treatment.\n\nPeople providing care should also make sure that:\n\n"}
{"id": "1594236", "url": "https://en.wikipedia.org/wiki?curid=1594236", "title": "Nukla", "text": "Nukla\n\nNukla is a fictional character published by Dell Comics in the mid-1960s. He was created by writer Joe Gill and artist Sal Trapani (with uncredited assistance from others artists, including Dick Giordano). The character made his debut in \"Nukla\" #1 (October-December 1965).\n\nNukla is really Matthew Gibbs, a handsome blond CIA spy and pilot. While flying his U-2 spy plane over Communist China, he is fired on by the Chinese Red Army. Unable to evade the missiles, he and his aircraft are vaporised in the resulting nuclear explosion. For some unexplained reason, he is able to maintain his human consciousness in this atomized state and reform himself through sheer force of will with incredible nuclear powers. His secret known only to his section chief Jim Clarke, Nukla used his atomic abilities to fight the enemies of the United States, like supervillains Baron Von Zee and Captain Whale.\n\nNukla has nuclear-based powers, somewhat similar to those of Captain Atom. He can will himself into an invisible immaterial state and in said phantom form fire destructive bolts of pure \"radiation-free\" atomic energy from his hands and fly at the speed of light as well as quickly heal himself of any injuries received in his mortal flesh and blood form. He must be careful, though, not to deplete his energy and take time to recharge his \"nuclear batteries\" or he will not be able to transform, and extreme cold makes it impossible for him to dematerialize.\n\nHe is also able to dematerialize and rematerialize his U-2 when needed, flying it both to conserve his vast powers for when they are needed and also simply because he still enjoys being a pilot.\n\n\"Nukla\" ran for only four issues. Steve Ditko, artist of Captain Atom, did the artwork for the last issue. \n\n\n"}
{"id": "21689547", "url": "https://en.wikipedia.org/wiki?curid=21689547", "title": "Occupational fatality", "text": "Occupational fatality\n\nAn occupational fatality is a death that occurs while a person is at work or performing work related tasks. Occupational fatalities are also commonly called “occupational deaths” or “work-related deaths/fatalities” and can occur in any industry or occupation.\n\nCommon causes of occupational fatalities include falls, machine-related incidents, motor vehicle accidents, electrocution, falling objects, homicides and suicides. Oftentimes, occupational fatalities can be prevented.\n\nIn the United States in 2007, 42% of occupational fatalities occurred during a transportation incident, 16% occurred after a worker came into contact with an object or equipment, 15% occurred as a result of a fall, 15% occurred as a result of assault or other violent acts in the workplace, 12% were the result of chemical or environmental exposures (9%) and 3% were the result of fires or explosions. \nMany factors contribute to a fatal incident at work. Lack of appropriate employee training and failure to provide and enforce the use of safety equipment are frequent contributors to occupational fatalities. In some cases, employees do receive safety training, but language barriers prevent the employee from fully understanding the safety procedures. Incidents can also be the result of insufficient supervision of inexperienced employees or employees who have taken on a responsibility for which they are not properly trained. Poor worksite organization, staffing and scheduling issues, unworkable policies and practices and workplace culture can all play a role in occupational fatalities. An incident leading to an occupational fatality is generally not the fault of a single person, but the result of a combination of many human and environmental factors.\nIn distinction to \"risk factors\", which may be thought to imply a causal link between such factors and fatality, statistics such as those from the U.S. Bureau of Labor Statistics on the demographics of deaths at work do not imply that age and gender are in themselves causative factors of fatality, but simply show that fatalities occur more frequently among certain groups.\nAlthough all workers are at risk for occupational fatalities, elderly workers age 65 and older are roughly three times more likely to die at work.\n\nA large majority of occupational deaths occur among men. In one U.S. study, 93% of deaths on the job involved men, with a death rate approximately 11 times higher than women. The industries with the highest death rates are mining, agriculture, forestry, fishing, and construction, all of which employ more men than women. Deaths of members in the military is currently above 90% men.\n\nOccupational fatalities are preventable. Prevention of occupational fatalities depends on the understanding that worker safety is not only the responsibility of the worker, but is the primary responsibility of the employer. Employers must train all employees in the appropriate safety procedures and maintain a safe working environment so that fatalities are less likely to occur. An occupational fatality is not just the fault of the deceased worker; instead, it is the combination of unsafe work environments, insufficient safety training, and negligible employee supervision that contribute fatal incidents. As a result, it is imperative that an employer address all the potential [risk] factors at the workplace and educate all employees in safe work practices and risk awareness.\n\nIn order to perform adequate risk assessment of injuries that occur in the workplace, health and safety professionals use resources such as the Haddon Matrix. This model assesses the risks leading up to, during, and after a death in order to prevent future incidents of a similar nature. Employers and employees can learn how to identify risk factors in their work environment in order to avoid incidents that may result in death.\n\nThe regulatory organization for occupational injury control and prevention is the Occupational Safety and Health Administration (OSHA). Formed in 1970 as an agency of the United States Department of Labor under the Occupational Safety and Health Act, OSHA exists to prevent occupational injuries and deaths by creating and enforcing standards in the workplace. OSHA standards address employee training programs, safety equipment, employer record keeping and proper maintenance of the work environment. Failure to comply with the OSHA standards can result in workplace inspections and legal action including citations and fines. In very severe cases of employer misconduct, OSHA can “red flag” an operation and send the employer to legal court.\n\nTo regulate the millions of workplaces in the United States, OSHA requires that all employers maintain a record of occupational injuries, illnesses and fatalities. Occupational fatalities must be reported to OSHA within eight hours of the incident. Failure to do so can result in legal action against the employer. Employers are responsible for staying current on OSHA standards and enforcing them in their own workplace. State OSHA organizations exist in twenty-eight states and are required to have the same or more rigorous standards than the federal OSHA standards. In these states, employers must abide by their state’s regulations. It is not the responsibility of the employee to stay current on the OSHA standards.\n\nIn addition to OSHA, the National Institute for Occupational Safety and Health (NIOSH) was formed under the Occupational Safety and Health Act as a federal research agency to formulate industry recommendations for health and safety. NIOSH is part of the Centers for Disease Control and Prevention (CDC) in the United States Department of Health and Human Services (DHHS). NIOSH analyzes workplace injury and illness data from all fifty states as well as provides support for state-based projects in occupational health and safety.\n\nUnder NIOSH, the Fatality Assessment and Control Evaluation (FACE) Program tracks and investigates occupational fatalities in order to provide recommendations for prevention. A voluntary program for individual states created in 1989, FACE is active in California, Iowa, Kentucky, Massachusetts, Michigan, New Jersey, New York, Oregon, and Washington. The primary responsibilities of the state FACE programs are to track occupational fatalities in their state, investigate select fatalities, and provide recommendations for prevention. As part of the prevention efforts, FACE programs also produce extensive prevention education materials that are disseminated to employees, employers, unions, and state organizations.\n\nNationally, the Census of Fatal Occupational Injuries (CFOI), within the U.S. Department of Labor, compiles national fatality statistics. CFOI is the key, comprehensive system in the surveillance of occupational fatalities in the United States.\n\nMany other non-governmental organizations also work to prevent occupational fatalities. Trade associations and unions play an active role in protecting workers and disseminating prevention information. The National Safety Council also works to prevent occupational fatalities as well as provide resources to employers and employees.\n\n"}
{"id": "51149398", "url": "https://en.wikipedia.org/wiki?curid=51149398", "title": "Oil Mines Regulations-1984", "text": "Oil Mines Regulations-1984\n\nOil Mines Regulations-1984 (OMR 1984) replaces the Oil Mines Regulations-1933, with effect from October-1984 to deal with matters for the prevention of possible dangers in oil mines in India.\n\nOMR 1984 was Published in 1986 by Directorate General of Mines Safety, Ministry of Labour in Dhanbad, Jharkhand.\n\nShort Title; Extent; Application and; Definitions. (Reg 1-2)\nReturns, Notices and Plans. (Reg 3-9) \nQualifications; Appointment; General Management and; Duties of Pe\nns Employed in Mines for various functions. (Reg 10-23) \nReg 24- Derricks; 25- Derrick platforms and floors; 26- Ladders; 27- Safety belts and life lines; 28- Emergency escape device; 29- Weight indicator; 30- Escape exits; 31- Guardrails, handrails and covers; 32- Draw-works; 33- Cathead and cat line; 34- Tongs; 35- Safety chains or wire lines; 36- Casing lines; 37- Rigging equipment for material handling; 38- Storage of materials; 39- Construction and loading of pipe-racks; 40- Rigging-up and rig dismantling; 41- Mud tanks and mud pumps; 42- Blowout preventer assembly; 43- Control system for blowout preventers; 44- Testing of blowout preventer assembly; 45- Precautions against blowout; 46- Precautions after a blowout has occurred; 47- Drilling workover and other operations; 48- Precautions during drill stem test. \nWell completion, Testing and Activation (Reg 49-50)\n\nGroup Gathering Station and Emergency Plan (Reg 51-51A)\n\nPrecautions during acidizing operations; fracturing operations and; loading and unloading of petroleum tankers. (Reg 52-54)\nStorage Tank; Well servicing operations; Artificial lifting of oil; Temporary closure of producing well and; Plugging requirements of abandoned wells (Reg 55-59)\nApplication (Reg-60)\nApproval and design of the route and design of pipeline, their laying and, Emergency procedure. (Reg 61-64) \nStorage and use of flammable material; Precaution against noxious, flammable gases and, fire; Fire Fighting Equipment and; Contingency plan. (Reg 65-72)\nUse of certain machinery and equipment; Classification of Hazardous Area; Use of electrical equipment in hazardous area; General Provisions about construction and maintenance of machinery; Internal combustion Engines; Apparatus under pressure; Precautions regarding moving parts of machinery; Engine rooms and their exits and; Working and examination of machinery. (Reg 73-81) \nHousekeeping; General/Emergency lighting; Supply and use of protective equipments; Protection against noise, toxic dusts, gases and ionising radiation ; Communication; Protection against pollution of environment; Fencings and; General Safety. (Reg 82-98) \nSafety and health education, instructions and, inspections; Returns, notices, correspondence and Appeals. (Reg 99-106)\n\nOil spill\n"}
{"id": "1213987", "url": "https://en.wikipedia.org/wiki?curid=1213987", "title": "Pandora (novel)", "text": "Pandora (novel)\n\nPandora (1998) is a novel and a vampire in Anne Rice's \"Vampire Chronicles\". Her story is told in the book \"Pandora\", one of two novels in the \"New Tales of the Vampires\" series.\n\nPandora was born with the name Lydia in the Roman Republic in the year 15 BC to a Senatorial family. She is tall, with rippling brown hair and gold-brown eyes. Like many Patrician Roman females of the time Pandora was taught how to read and write and is well versed in epic poems, especially Ovid's works. She meets Marius for the first time when he is twenty-five and she is ten. Marius asks for Lydia's hand in marriage, but her father rejects Marius' offer. Five years later, Lydia sees Marius at a festival and begs her father to allow her to marry Marius. Her father again refuses.\n\nPandora's father holds a high rank as a Senator. But when a new emperor takes power, her family is betrayed by her own brother and killed. Only Pandora and her traitorous brother survive the massacre, and she is taken to Antioch (after changing her name) by a man who was very close to her father. There she meets Marius again, twenty years after their last encounter. Unbeknownst to her, Marius is now a vampire.\n\nShe eventually finds out what Marius has become, and also that he protects and hides the Queen and King of all Vampires. The vampire, Akabar, wants to steal the Queen's powerful and ancient blood. Marius and Pandora try to prevent him from carrying out his plan. To gain access to the Queen, Akabar uses Marius's love for Pandora against him and drains Pandora to the point of death. In order to save her, Marius is forced to make Pandora into a vampire and forced to let Akabar see the Queen, who then destroys Akabar. The pair stay together for the next two hundred years, taking care of the King and Queen of all vampires, before arguing and separating. Marius later characterized the breakup (of which he left her and she spent six months or more waiting for him to return) as being entirely his fault: He considers himself a teacher who longs to impart what he knows upon his pupils, but Pandora—being as free-spirited and highly educated as she was—had no patience to be his student. During their time together, against his objection, she did turn one of her beloved slaves into a vampire. As soon as he was turned he left the pair and was not seen again.\n\nThe next time they meet again is in a Dresden ballroom in the early to late-17th century. Marius tries in vain to make Pandora leave her companion and fledgling, Arjun, and come back to him. Pandora's relationship with Arjun is of great concern to Marius, who fears Pandora is being held against her will. While she outwardly denies this, Pandora overcomes her embarrassment and admits to David in her writing that she could not bring herself to leave Arjun, citing that his stronger will propelled them both through time.\n\nThe next and last time that they meet is in 1985, when she is among thirteen vampires who survived Akasha's killing spree and gathered at Maharet's house in the Sonoma compound to battle against Akasha. Pandora remains quiet and withdrawn throughout the whole ordeal, staring out the windows and saying little, rousing herself only once to say that Akasha is trying to justify deplorable \"reasons\" for a holocaust.\n\nLike many vampires, Pandora is a morose, despairing immortal who initially wanted immortality but soon regretted her choice and turns into a dark, indifferent cynic. Lestat thinks that Pandora was troubled in some deep, fundamental way even before she became a vampire, because she's the only vampire who doesn't receive visions of Maharet and Mekare in her dreams. During the confrontation in Sonoma, when Akasha directly asks Pandora to join with her or die, Pandora merely responds in a quiet, indifferent voice that she can't do what Akasha is asking of her, and stoically accepts the idea of being killed.\n\nEven after Akasha herself is destroyed and the thirteen vampires regroup in Armand's Night Island in Florida, Pandora still acts withdrawn from her fellow vampire kin, watching music videos all day long and completely ignoring Marius, who dotes on her lovingly. There is no sense of recovery or security in her as there is with the other vampires, and she departs from Night Island alone, still just as morose as ever.\n\nDavid Talbot encounters her in Paris shortly after the events of \"Memnoch the Devil\" and before the story of \"The Vampire Armand\". He asks her to write the story of her life, which she does in a cafe by writing in some notebooks he gave her. She recalls the details of her life before becoming a vampire and briefly discusses the period when she was with Marius. After she has finished, she writes that she plans to go to New Orleans to look for Marius and to look into the eyes of Lestat, and try to understand what it is he saw. She is last seen at the end of \"Blood and Gold\", alongside Marius.\n\nPandora is again seen in the novel \"Prince Lestat\" when she comes to confront Arjun of his burning fledglings and old ones in Mumbai after being told by \"The Voice\". There she meets Gremt Stryker Knollys, who confides in her that he is also searching for \"The Voice\". He also claims to be the founder of the Talamasca in the year 748, along with the vampire who created Marius and the ghost of a vampire that was just killed named Hesketh. Gremt is the spirit Pandora meets towards the end of her novel when the writer Cassiodorus dies.\n"}
{"id": "21311880", "url": "https://en.wikipedia.org/wiki?curid=21311880", "title": "Peanut Corporation of America", "text": "Peanut Corporation of America\n\nPeanut Corporation of America (PCA) was a peanut-processing business with headquarters in Lynchburg, Virginia, plants in other southern states, and distribution across the United States, now defunct as a result of one of the most massive and lethal food-borne contamination events in U.S. history. PCA was founded in 1977 and initially run by Hugh Parnell, father of Stewart Parnell, with him and two other sons. The company was sold in 1994-1995 with the senior Parnell retiring, and with Stewart Parnell and others remaining with the new company as consultants. In 2000, control of PCA returned to Stewart Parnell via a private sale. Over this history, PCA came to operate processing facilities in Blakely, Georgia, Suffolk, Virginia, and Plainview, Texas, providing peanut and peanut butter products primarily to the \"institutional food\" market (schools, prisons and nursing homes), to food manufacturers for use in cookies, snacks, ice cream, and dog treats, and to other low-end markets.\n\nPCA permanently halted its operations after it was found to be the source of a massive \"Salmonella\" outbreak in the U.S., during late 2008 and early 2009. By 2007, prior to closing its doors, PCA had grown to 90 employees and was doing $25 million in annual sales. It has been estimated to have been manufacturing roughly 2.5% of processed peanuts in the U.S. at that time. The 2008 contamination followed a long history of food quality issues. There had been concerns about sanitation at the company by private individuals since at least the mid-1980s, when the company was run by its founder, Stewart Parnell's father, Hugh Parnell. In addition, in the years just prior to its sale and Hugh Parnell's retirement, PCA was sued: by American Candy Company in 1990, and by Zachary Confections Inc. of Frankfort, Indiana in 1991, after discovery that PCA's peanut products exceeded the FDA tolerance level for aflatoxin, a mold-derived toxin common to peanuts. Moreover, as a result of the coming contamination event, investigations would show that some PCA processing was being done without FDA knowledge and oversight, and other food handling and processing areas had gone long periods without federal inspection.\n\nIn late 2008 and early 2009, as a result of the \"Salmonella\" contamination event, 9 people died and at least 714 people (half of them children) fell ill, all from food poisoning after eating products containing contaminated peanuts. This contamination triggered the most extensive food recall in U.S. history up to that time, involving 46 states, more than 360 companies, and more than 3,900 different products manufactured using PCA ingredients. The contamination and recall had immediate major ramifications for the market of this set of farm products, and further impact on public perceptions of food safety and on government regulation of the same. On February 13, 2009, Peanut Corporation of America ceased all manufacturing and business operations, and filed for Chapter 7 bankruptcy liquidation. As of February 2009, a federal criminal investigation was continuing, and at least a dozen civil lawsuits had been filed. In September 2015, Stewart Parnell was sentenced, after earlier conviction on more than 70 criminal charges—including felony charges that included knowingly shipping tainted food across state lines—to 28 years in prison for his role in the nationwide outbreak.\n\nHugh Parnell Sr. founded Parnell's Peanuts, in Gorman, Texas in 1977 selling to consumers, bakeries and manufacturers (candy, ice cream, and snacks). In 1990 the FDA found PCA distributing peanuts with unacceptable levels of aflatoxins, caused by mold that grows in nuts and seeds. In 1992 American Candy Company sued PCA for lost inventory that used PCA nuts with aflatoxins. The company was sold in 1994-1995, with the senior Parnell retiring, and with Stewart Parnell and others remaining with the new company as consultants. In 2000, control of PCA returned to Stewart Parnell via a private sale. Over this history, PCA came to operate processing facilities in Blakely, Georgia, Suffolk, Virginia, and Plainview, Texas, providing peanuts, peanut butter, peanut meal, and peanut paste to an institutional food market—to schools, prisons, and nursing homes—as well as to low-budget retail outlets such as dollar stores and to food manufacturers for use in cookies, snacks, ice cream, and dog treats. It has been estimated to have been manufacturing roughly 2.5 percent of processed peanuts in the U.S. at its height, with 90 employees and $25 million in annual sales in 2007. The company filed for Chapter 7 bankruptcy and permanently halted its processing and sales operations, after being found to be the source of a massive \"Salmonella\" outbreak in the United States beginning in 2008.\n\nPCA was sued in 1990 by American Candy Company after the FDA discovered that PCA's peanut butter exceeded the FDA tolerance level for aflatoxin, a mold-derived toxin common to peanut production; American Candy had turned the peanut butter into 8,000 unshipped cases of \"kisses\" for Wal-Mart. Another lawsuit was brought by Zachary Confections Inc. of Frankfort, Indiana, in 1991, after a 40,020-pound shipment of nuts from PCA was also found to have an unacceptably high level of aflatoxin.\n\nIn January 2006, Nestlé completed an onsite audit of PCA's Plainview plant, and gave it a \"Does Not Meet Standards\" score on nearly all 40 inspection areas. Months after, PCA hired Kenneth Kendrick as assistant plant manager at the Plainview plant.\n\nIn 2001, FDA inspectors also found that products from the Blakely plant were potentially exposed to insecticides, according to a report obtained by the Associated Press.\n\nAccording to Virginia state inspection records, the PCA blanching operations in Suffolk, Virginia, had some of the same food safety problems that would be found in the company's Georgia plant (see below). Inspection in 2008 found mold on \"totes\" holding peanuts, counted 43 mouse droppings on the floor, and saw a live bird walking and flying inside the warehouse.\n\nIn late 2008 and early 2009, nine people died and at least 714 people in 46 states, half of them children, fell ill due to food poisoning from eating products containing contaminated peanuts, according to the Centers for Disease Control and Prevention (CDC). Among persons with available information, 23% reported being hospitalized. The real numbers were believed to be much higher, since for every reported case of salmonellosis, on average, another 38 or so cases go unreported, according to the CDC. A combination of epidemiological analysis and laboratory testing by state officials in Minnesota and Connecticut, the Food and Drug Administration (FDA), and the CDC enabled the FDA to confirm that the sources of the outbreak of illnesses caused by \"Salmonella typhimurium\" were peanut butter, peanut paste, and peanut meal produced by the Peanut Corporation of America (PCA) at its Blakely, Georgia processing plant.\n\nOn February 7, 2009, Oregon officials confirmed the first case of salmonellosis in a dog that had eaten biscuits contaminated with the PCA-produced peanut products.\n\nThe company issued a statement categorically denying the allegations; in January 2009, it shut down production and laid off 50 employees at the Blakely plant.\n\nThis contamination event triggered the most extensive food recall ever in U.S. history. As of April 22, 2009, it involved at least 361 companies and 3,913 different products manufactured using PCA ingredients. The recall included everything produced at the Blakely plant since January 1, 2007, as well as everything ever produced at the Plainview, Texas plant. Products supplied for some school lunches were pulled, and the Federal Emergency Management Agency (FEMA) even recalled emergency meals sent after a massive ice storm. (Since the storm left many without power, the United States Postal Service went door-to-door in Kentucky to warn residents and hand out 600,000 flyers from FEMA.) Food banks nationwide had to discard thousands of pounds of food in time of high demand from millions of U.S. families in need.\n\nThe recall did not involve major-brand peanut butters, since PCA primarily served only low-budget and institutional providers, but many consumers reacted by avoiding peanut products altogether, driving down the sales of all brands of peanut butter by nearly 25%.\nThis caused great harm to the industry and farmers, already suffering from low prices due to the 2008 bumper crop and the deepening economic crisis. Early estimated losses to the U.S. peanut industry because of this outbreak would be on the order of $1 billion.\n\nFollowing initial reporting of the contamination's source, reporters and investigators began taking a careful look at the sites run by PCA. \"The Washington Post\" reported on February 14, 2009, the view of David Brooks, a buyer for a snack company that had visited PCA facilities in the mid-1980s (when PCA was under Hugh Parnell's control), that \"everybody in the peanut industry\" in the states involved (Georgia, Virginia, and Texas) knew of the serious sanitation issues associated with PCA; Brooks went on to state that PCA was \"a time bomb waiting to go off.\"\n\nFormer employees interviewed by the \"Chicago Tribune\" stated that conditions in the plant were \"filthy and nasty\", and that they would never eat the peanut butter or allow their children to eat it. One employee remembered seeing a family of baby mice in a tote of peanuts, and others recalled having to step over standing water inside the building after heavy rain. Another former employee told CBS News that he saw a rat dry-roasting in a peanut area. Another told ABC News that workers had no idea the company had positive \"Salmonella\" tests because \"that information is not for the average employee to see.\"\n\nFood and Drug Administration (FDA) inspectors reported, following a two-week inspection of the Blakely, Georgia, plant in January 2009, that the company had information that its peanut-butter products were tainted with \"Salmonella\", but shipped them anyway after \"retesting\" them. This occurred at least 12 times in 2007 and 2008. FDA inspectors also found mold growing on the plant's ceiling and walls, foot-long gaps in its roof, dead insects near peanuts, and holes in the plant big enough for rodents to enter. Inspectors found that the company also did not clean its equipment after finding contamination, and did not properly segregate raw and finished products. In 2007, the company shipped chopped peanuts on two occasions even after \"Salmonella\" was confirmed by private lab tests. The company had previously refused to divulge production test records until federal officials invoked the food safety provisions of a federal antiterrorism law (the 2002 Public Health Security and Bioterrorism Preparedness Response Act). As a result of this refusal and the incident in general, the Georgia State Senate passed a bill requiring peanut product manufacturers to report any contamination within 24 hours, failing which felony charges would result.\n\nOn February 6, 2009, the FDA reported that the company shipped tainted products under three conditions: (1) without retesting, (2) before the retest results came back from an outside company, and (3) after a second test showed no bacterial contamination. In all three cases, the initial positive result means that the product should have been destroyed. Food safety experts say \"Salmonella\" can live in pockets of peanut butter, so that one batch could test both negative and positive. In that case, it should have been destroyed, they said.\n\nDocuments released February 11 by the U.S. House Energy and Commerce Committee showed that the company shipped products to customers even before receiving results of \"Salmonella \"tests, and the company stopped using a private laboratory because too many tests done there showed contamination. A lab tester told the House panel that the company discovered \"Salmonella\" at its Blakely plant as far back as 2006.\n\nThe company had operated a plant in Gorman, where the company originally started in 1977. David Brooks, the snack food company buyer interviewed by the \"Washington Post\" after the \"Salmonella\" outbreak, said that he inspected this plant three times on behalf of his company in the mid-1980s to determine whether to buy peanuts from PCA. The plant failed his private inspection each time for what he called \"just filthy\" conditions, including dusty beams, leaky roofs, and birds flying through the building. The Gorman operations transferred to Plainview when Hale County officials issued $2 million in tax-free revenue bonds to help the company convert a long vacant Jimmy Dean sausage factory into a peanut plant. Local officials, including a county health inspector, toured the new plant and approved its opening, although the state said it never knew the plant existed. The plant was located along a major highway, across from a large Wal-Mart distribution center; it had four highly visible signs in the front and a billboard bearing a picture of a peanut. A state inspector who drove by the plant \"a few times\" on his way to other inspections never stopped because it was not on his list. State officials said the company was solely to blame for failing to obtain the food manufacturer's license when the Plainview plant opened.\n\nThe company's plant in Plainview opened in March 2005 and employed 30 people, but was never licensed in that state as a food manufacturing facility; the state had not done any inspections until the problems with the Georgia plant became news. The Texas plant blanched, dry- and oil-roasted, and chopped peanuts, then shipped them to food companies across the country. The plant had been certified for organic production in November 2005, based on what state officials later called incomplete information obtained by an inspector with the Texas Department of Agriculture. However, the company failed to apply for a Texas health certificate, which would have triggered a visit by state inspectors. State health officials were not aware the plant existed until the company released a list of its plants around the country.\n\nThe Texas inspection in January 2009 found some unsanitary conditions, such as unclean sections of a peanut-roasting line. It also reported that several internal company laboratory tests dating back to November had found no \"Salmonella\" or other contaminants. However, on February 10, 2009, company officials announced that the Texas plant had been shut down, after samples taken on February 4 tested positive for \"Salmonella\". Former workers at the Texas plant interviewed by the \"New York Times\" said that the facility was \"disgusting\". It said the plant shared many of the problems found in the plant in Georgia, including a badly leaking roof and rodent infestation. A former plant manager told \"Good Morning America\" that he had repeatedly complained to the company owner, Stewart Parnell, about unsanitary conditions, including \"water leaking off a roof and bird feces washing in\", but Parnell would not authorise money for necessary repairs.\n\nOn February 12, 2009 Texas health officials ordered an unprecedented recall of all products ever shipped from the Texas plant since it opened in 2005, after discovering that the plant's air-handling system was drawing in debris from a crawl space containing \"dead rodents, rodent excrement and bird feathers\" into production areas. State health officials said they issued the sweeping recall because they did not know how long the unsanitary conditions had existed at the plant.\n\nThe PCA's peanut blanching operation in Suffolk, Virginia, employed 13 workers and was shut down the day PCA filed for bankruptcy.\n\nTommy Irvin, commissioner of the Georgia Department of Agriculture (GDA), requested criminal investigation of the Georgia Bureau of Investigation (GBI) as the organ responsible for inspections contracted by the FDA. GDA and GBI officials had said they would consider pursuing manslaughter charges if federal authorities did not take up the case. On January 30, 2009, federal health officials announced that a criminal investigation had been launched by the U.S. Justice Department for possible prosecution under provisions of the 1938 Federal Food, Drug, and Cosmetic Act. On February 4, Georgia officials said they would not prosecute the company, because the two state laws under consideration (reckless conduct and adulteration of food) were only misdemeanors and would only allow for minor penalties. Vernon Keenan, director of the Georgia Bureau of Investigation, said: \"Any potential prosecution is most appropriately handled at the federal level\".\n\nOn February 9, 2009, the Federal Bureau of Investigation (FBI) announced that it had joined with the FDA's Office of Criminal Investigations (FDA-OCI) as part of a Criminal investigation of the company. Search warrants were executed on the Blakely plant, as well as PCA's corporate headquarters in Lynchburg. Following a raid by its agents, the Federal Agents sealed off the Blakely plant. On February 21, 2013, four former officials of the company were named in a 75-count indictment on charges related to \"Salmonella\"-tainted peanuts and peanut products. The former processing plant manager for Peanut Corporation, Samuel Lightsey, reached a plea agreement on May 8, 2014. Lightsey was then available to the government as a witness at the trial, scheduled to begin in July 2014.\n\nParnell and his brother were convicted in September 2014 of 71 criminal counts, including conspiracy, fraud and other federal charges. In July 2015, Federal authorities recommended a sentence of life imprisonment for Stewart Parnell. Both Daniel Kilgore and Samuel Lightsey (both former plant managers at PCA) pleaded guilty on their related charges and became government witnesses in the case, providing testimony during the 2014 trial, for consideration of limited sentencing.\n\nIn July 2015, federal authorities recommended a sentence of life imprisonment for Parnell. On September 21, 2015, Parnell was sentenced to 28 years in prison, the longest punishment ever handed out to a producer in a U.S. foodborne illness case. His brother Michael Parnell was sentenced to 20 years, and the plant's former quality assurance manager Mary Wilkerson was sentenced to five years. On October 1, 2015, the court sentenced Samuel Lightsey to three years in prison and Daniel Kilgore to six years in prison. (cooperating witnesses)\n\nU.S. District Judge W. Louis Sands stated during sentencing, \"We place faith that no one would intentionally ship products to market that are contaminated…. Consumers are at the mercy of food producers for the safety of the products. These acts [of the convicted PCA executives] were driven by profit and the protection of profit … thus greed.\"<br>Sands told Stewart Parnell that he had \"taken risks for years,\" that they were \"eventually discovered and traced back\" to his corporation, and that, unfortunately, \"thousands of people suffered and nine died\" from Parnell's knowing disregard for public health and safety.\n\nJudge Sands addressed Mary Wilkerson, Quality Assurance Manager for PCA, \"You were aware of what was going on and played a role in concealing the problem. That was not actually a minor role in this case\". The PCA case, according to Sands, was not about the \"condemnation of peanuts or the peanut industry, but of a few individuals.\"\n\nThe prosecution team asked the court to find that the Parnell brothers were flight risks and to deny them bail while they appeal their convictions. The prosecutors did not ask the same for Wilkerson. Judge Sands dismissed defense team allegations of prosecutorial misconduct and a \"less-than-unbiased jury.\" He also addressed defense objections to the victims' testimony, citing their constitutional rights. The judge then announced that the character witnesses and families of the two Parnell brothers hurt their argument that the two men would not be a flight risk by talking about Stewart Parnell's hobby of being a licensed pilot and flying all over the country, their family resources, and their many connections around the world. Judge Sands ordered that the two Parnell brothers be taken into custody of the U.S. Marshals while allowing bail for Wilkerson (stating that she did not pose the same flight risk without the same access to resources) until the Bureau of Prisons directs her to appear at a specified time and place to begin her sentence.\n\nOn February 13, 2009— less than 24 hours after the Texas recall—Peanut Corporation of America announced it was permanently halting operations and filing for Chapter 7 bankruptcy. Bankruptcy lawyer Andrew Goldstein said that the company had considered filing for Chapter 11, but decided to liquidate because all of its plants had been shut down and there was no way it could carry on business. Consumers Union criticised the move, saying that the bankruptcy filing would shield the company from liability suits, although in reality, the bankruptcy filing merely delays any claims against the company.\n\nParnell served on the U.S. Department of Agriculture's Peanut Standards Board, which sets quality and handling standards for peanuts. He was first appointed by Agriculture Secretary Mike Johanns to the position in 2005, and was reappointed for another term that would have expired in 2011, but on February 5, 2009, the USDA announced that the new Agriculture Secretary Tom Vilsack had removed Parnell from the board.\n\nOn February 5, 2009, the U.S. Department of Agriculture (USDA) announced that Peanut Corporation of America and a subsidiary, Tidewater Blanching LLC, were banned from all federal government contracts and subcontracts for one year, saying the company: \"lacks business integrity and business honesty, which seriously and directly hinders its ability to do business with the federal government.\"\n\nPeanut Corporation of America was founded and originally owned by Hugh Parnell, father of Stewart Parnell, but by the time of the contamination scandal had passed to Stewart Parnell as sole owner, and as president and CEO of the company.\n\nHugh Parnell started in the peanut business with Stewart Parnell and his two younger brothers in 1977; they took a struggling, $50,000-a-year peanut roasting operation and turned it into a $30 million business before selling the business in 1994-1995, after which Stewart Parnell continued on as a consultant until re-buying the Gorman, Texas plant in 2000. In 2001, he bought the Blakely, Georgia operation, when its operations consisted only of roasting and blanching peanuts. Parnell tripled revenue at the Blakely plant by 2004, turning its first profit in 15 years, with production regularly surpassing 2.5 million pounds of peanuts per month. However, the FDA did not know that the plant manufactured peanut butter until the 2008-2009 outbreak.\n\nThe Parnells ran PCA on a very tight budget. The company, under Hugh Parnell, who operated a bare-bones front office and used minimum-wage labor, a style that was continued by Stewart Parnell, who ran his newly acquired PCA from a converted garage behind Parnell's home in an upscale suburb outside of Lynchburg, Virginia, and continued to rely on minimum-wage labor.\n\nDespite more than 12 tests between 2007 and 2008 that showed \"Salmonella\" contamination in his company's products, Parnell wrote an email to company employees on January 12, 2009, that stated, \"We have never found any salmonella at all. No salmonella has been found anywhere in our products or in our plants.\" Parnell ordered products identified with \"Salmonella\" to be shipped and complained that tests discovering the contaminated food were \"costing us huge $$$$$.\" In a June 2008 email exchange, Parnell complained to a worker after being notified that \"Salmonella\" had been found in more products. \"I go thru this about once a week,\" he wrote. \"I will hold my breath ... again.\" After the company was identified as the source of the outbreak, Parnell pressed federal regulators to allow him to continue using peanuts from the tainted plant. He wrote that company executives \"desperately at least need to turn the raw peanuts on our floor into money.\"\n\nUnder Congressional subpoena, Parnell on February 11 appeared with his plant manager before a House Energy and Commerce subcommittee, but repeatedly refused to testify, citing their Fifth Amendment protection against self-incrimination. Among the questions they refused to answer was one from Rep. Greg Walden (R-Ore.): \"In this container, are products that have your ingredients in them, some of which are on the recall list, some of which are probably contaminated. It seems like from what we've read you were willing to send out that peanut base that went into these ingredients. I just wonder, would either of you be willing to take the lid off and eat any of these products now like the people on the panel ahead of you, their relatives, their loved ones did?\" Walden revealed an e-mail from Parnell, who, referring to products that had tested positive for Salmonella, wrote: \"Let's turn them loose.\"\n\nIn 2015, Food Republic produced and aired Food Crimes: \"P.B. & Jail.\" \n\nOn July 3, 2017, CNBC aired an episode of American Greed: \"From Peanuts to Sick Millions” [Documentary / Crime]. Season ll, Episode AG 141.\n\nA Food Safety Expert / Professor of food policy & regulatory compliance wrote a series of articles based on interviewing participants and being in the courtroom during the sentencing.\n\n"}
{"id": "544177", "url": "https://en.wikipedia.org/wiki?curid=544177", "title": "Plasmodium falciparum", "text": "Plasmodium falciparum\n\nPlasmodium falciparum is a unicellular protozoan parasite of humans, and the deadliest species of \"Plasmodium\" that cause malaria in humans. It is transmitted through the bite of a female \"Anopheles\" mosquito. It is responsible for roughly 50% of all malaria cases. It causes the disease's most dangerous form called falciparum malaria. It is therefore regarded as the deadliest parasite in humans, causing 435,000 deaths in 2017. It is also associated with the development of blood cancer (Burkitt's lymphoma) and is classified as Group 2A carcinogen.\n\nThe species originated from the malarial parasite \"Laverania\" found in gorillas, around 10,000 years ago. Alphonse Laveran was the first to identify the parasite in 1880, and named it \"Oscillaria malariae\". Ronald Ross discovered its transmission by mosquito in 1897. Giovanni Battista Grassi elucidated the complete transmission from a female anopheline mosquito to humans in 1898. In 1897, William H. Welch created the name \"Plasmodium falciparum\", which ICZN formally adopted in 1954. \"P. falciparum\" assumes several different forms during its life cycle. The human-infective stage are sporozoites from the salivary gland of a mosquito. The sporozoites grow and multiply in the liver to become merozoites. These merozoites invade the erythrocytes (RBCs) to form trophozoites, schizonts and gametocytes, during which the symptoms of malaria are produced. In the mosquito, the gametocytes undergo sexual reproduction to a zygote, which turns into ookinete. Ookinete forms oocyts from which sporozoites are formed.\n\nAs of the latest \"World Malaria Report\" of the World Health Organization, there were 219 million cases of malaria worldwide in 2017, up from 216 million cases in 2016. This resulted in an estimated 435,000 deaths. Almost every malarial death is caused by \"P. falciparum\", and 93% of death occurs in Africa. Children under five years of age are most affected, accounting for 61% of the total deaths. In Sub-Saharan Africa, over 75% of cases were due to \"P. falciparum\", whereas in most other malarial countries, other, less virulent plasmodial species predominate.\n\nFalciparum malaria was familiar to the ancient Greeks, who gave the general name \"pyretós\" \"fever\". Hippocrates (c. 460-370 BCE) gave several descriptions on tertian fever and quartan fever. It was prevalent throughout the ancient Egyptian and Roman civilizations. It was the Romans who named the disease \"malaria\"—\"mala\" for bad, and \"aria\" for air, as they believed that the disease was spread by contaminated air, or miasma. \n\nA German physician, Johann Friedrich Meckel, must have been the first to see \"P. falciparum\" but not knowing what it was. In 1847 he reported the presence of black pigment granules from the blood and spleen of a patient who died of malaria. The French Army physician Charles Louis Alphonse Laveran, while working at Bône Hospital (now Annaba in Algeria), correctly identified the parasite as a causative pathogen of malaria in 1880. He presented his discovery before the French Academy of Medicine in Paris, and published it in \"The Lancet\", in 1881. He gave the scientific name \"Oscillaria malariae\". But his discovery was received with skepticism mainly because by that time leading physicians such as Theodor Albrecht Edwin Klebs and Corrado Tommasi-Crudeli claimed that they had discovered a bacterium (which they called \"Bacillus malariae\") as the pathogen of malaria. Laveran's discovery was widely accepted only after five years when Camillo Golgi confirmed the parasite using better microscope and staining technique. Laveran was awarded the Nobel Prize in Physiology or Medicine in 1907 for his work. In 1900, the Italian zoologist Giovanni Battista Grassi categorized \"Plasmodium\" species based on the timing of fever in the patient; malignant tertian malaria was caused by \"Laverania malariae\" (now \"P. falciparum\"), benign tertian malaria by \"Haemamoeba vivax\" (now \"P. vivax\"), and quartan malaria by \"Haemamoeba malariae\" (now \"P. malariae\"). \n\nThe British physician Patrick Manson formulated the mosquito-malaria theory in 1894; until that time, malarial parasites were believed to be spread in air as miasma, a Greek word for pollution. His colleague Ronald Ross, a British Army surgeon, travelled to India to test the theory. Ross discovered in 1897 that malarial parasite lived in certain mosquitoes. The next year, he demonstrated that a malarial parasite of birds could be transmitted by mosquitoes from one bird to another. Around the same time, Grassi demonstrated that \"P. falciparum\" was transmitted in humans only by female anopheline mosquito (in his case \"Anopheles claviger\"). Ross, Manson and Grassi were nominated for the Nobel Prize in Physiology or Medicine in 1902. Under controversial circumstances, only Ronald Ross was selected for the award.\n\nThere was a long debate on the taxonomy. It was only in 1954 the International Commission on Zoological Nomenclature officially approved the binominal \"Plasmodium falciparum\". The valid genus \"Plasmodium\" was created by two Italian physicians Ettore Marchiafava and Angelo Celli in 1885. The species name was introduced by an American physician William Henry Welch in 1897. It is derived from the Latin \"falx\", meaning \"sickle\" and \"parum\" meaning \"like or equal to another\".\n\n\"P. falciparum\" is now generally accepted to have evolved from \"Laverania\" (a subgenus of \"Plasmodium\" found in apes) species present in gorilla in Western Africa. Genetic diversity indicates that the human protozoan emerged around 10,000 years ago. The closest relative of \"P. falciparum\" is \"P. praefalciparum\", a parasite of gorillas, as supported by mitochondrial, apicoplastic and nuclear DNA sequences. These two species are closely related to the chimpanzee parasite \"P. reichenowi\", which was previously thought to be the closest relative of \"P. falciparum\". \"P. falciparum\" was also once thought to originate from a parasite of birds.\n\nLevels of genetic polymorphism are extremely low within the \"P. falciparum\" genome compared to that of closely related, ape infecting species of \"Plasmodium\" (including \"P. praefalciparum\")\".\" This suggests that the origin of \"P. falciparum\" in humans is recent, as a single \"P. praefalciparum\" strain became capable of infecting humans. The genetic information of \"Plasmodium falciparum\" has signaled a recent expansion that coincides with the agricultural revolution. It is likely that the development of extensive agriculture increased mosquito population densities by giving rise to more breeding sites, which may have triggered the evolution and expansion of \"Plasmodium falciparum\".\n\n\"P. falciparum\" does not have a fixed structure but undergoes continuous change during the course of its life cycle. A sporozoite is spindle-shaped and 10-15 μm long. In the liver it grows into an ovoid schizont of 30-70 μm in diameter. Each schizont produces merozoites, each of which is roughly 1.5 μm in length and 1 μm in diameter. In the erythrocyte the merozoite form a ring-like structure, becoming a trophozoite. A trophozoites feed on the haemoglobin and forms a granular pigment called haemozoin. Unlike those of other \"Plasmodium\" species, the gametocytes of \"P. falciparum\" are elongated and crescent-shaped, by which they are sometimes identified. A mature gametocyte is 8-12 μm long and 3-6 μm wide. The ookinete is also elongated measuring about 18-24 μm. An oocyst is rounded and can grow up to 80 μm in diameter. Microscopic examination of a blood film reveals only early (ring-form) trophozoites and gametocytes that are in the peripheral blood. Mature trophozoites or schizonts in peripheral blood smears, as these are usually sequestered in the tissues. On occasion, faint, comma-shaped, red dots are seen on the erythrocyte surface. These dots are Maurer's cleft and are secretory organelles that produce proteins and enzymes essential for nutrient uptake and immune evasion processes.\n\nThe apical complex, which is actually a combination of organelles, is an important structure. It contains secretory organelles called rhoptries and micronemes, which are vital for mobility, adhesion, host cell invasion, and parasitophorous vacuole formation. As an apicomplexan, it harbours a plastid, an apicoplast, similar to plant chloroplasts, which they probably acquired by engulfing (or being invaded by) a eukaryotic alga and retaining the algal plastid as a distinctive organelle encased within four membranes. The apicoplast is involved in the synthesis of lipids and several other compounds and provides an attractive drug target. During the asexual blood stage of infection, an essential function of the apicoplast is to produce the isoprenoid precursors isopentenyl pyrophosphate (IPP) and dimethylallyl pyrophosphate (DMAPP) via the MEP (non-mevalonate) pathway .\n\nIn 1995 the Malaria Genome Project was set up to sequence the genome of \"P. falciparum\". The genome of its mitochondrion was reported in 1995, that of the nonphotosynthetic plastid known as the apicoplast in 1996, and the sequence of the first nuclear chromosome (chromosome 2) in 1998. The sequence of chromosome 3 was reported in 1999 and the entire genome was reported on 3 October 2002. The roughly 24-megabase genome is extremely AT-rich (about 80%) and is organised into 14 chromosomes. Just over 5,300 genes were described. Many genes involved in antigenic variation are located in the subtelomeric regions of the chromosomes. These are divided into the \"var\", \"rif\", and \"stevor\" families. Within the genome, there exist 59 \"var\", 149 \"rif\", and 28 \"stevor\" genes, along with multiple pseudogenes and truncations. It is estimated that 551, or roughly 10%, of the predicted nuclear-encoded proteins are targeted to the apicoplast, while 4.7% of the proteome is targeted to the mitochondria.\n\nHumans are the intermediate hosts in which asexual reproduction occurs, and female anopheline mosquitos are the definitive hosts harbouring the sexual reproduction stage.\n\nInfection in humans begins with the bite of an infected female \"Anopheles\" mosquito. Out of about 460 species of \"Anopheles\" mosquito, more than 70 species transmit falciparum malaria. \"Anopheles gambiae\" is one of the best known and most prevalent vectors, particularly in Africa.\n\nThe infective stage called sporozoites released from the salivary glands through the proboscis of the mosquito enter the bloodstream during feeding. The mosquito saliva contains antihemostatic and anti-inflammatory enzymes that disrupt blood clotting and inhibit the pain reaction. Typically, each infected bite contains 20-200 sporozoites. The immune system clears the sporozoites from the circulation within 30 minutes. But a few escape and quickly invade liver cells (hepatocytes). The sporozoites move in the blood stream by gliding, which is driven by motor made up of proteins actin and myosin beneath their plasma membrane.\n\nEntering the hepatocytes, the parasite loses its apical complex and surface coat, and transforms into a trophozoite. Within the parasitophorous vacuole of the hepatocyte, it undergoes 13-14 rounds of mitosis and meiosis which produce a syncytial cell (coenocyte) called a schizont. This process is called schizogony. A schizont contains tens of thousands of nuclei. From the surface of the schizont, tens of thousands of haploid (1n) daughter cells called merozoites emerge. The liver stage can produce up to 90,000 merozoites, which are eventually released into the bloodstream in parasite-filled vesicles called merosomes.\n\nMerozoites use the apicomplexan invasion organelles (apical complex, pellicle and surface coat) to recognize and enter the host erythrocyte (red blood cell). The parasite first binds to the erythrocyte in a random orientation. It then reorients such that the apical complex is in proximity to the erythrocyte membrane. The parasite forms a parasitophorous vacuole, to allow for its development inside the erythrocyte. This infection cycle occurs in a highly synchronous fashion, with roughly all of the parasites throughout the blood in the same stage of development. This precise clocking mechanism has been shown to be dependent on the human host's own circadian rhythm.\n\nWithin the erythrocyte, the parasite metabolism depends on the digestion of hemoglobin. The clinical symptoms of malaria such as fever, anemia, and neurological disorder are produced during the blood stage.\n\nThe parasite can also alter the morphology of the erythrocyte, causing knobs on the erythrocyte membrane. Infected erythrocytes are often sequestered in various human tissues or organs, such as the heart, liver and brain. This is caused by parasite-derived cell surface proteins being present on the erythrocyte membrane, and it is these proteins that bind to receptors on human cells. Sequestration in the brain causes cerebral malaria, a very severe form of the disease, which increases the victim's likelihood of death.\n\nAfter invading the erythrocyte, the parasite loses its specific invasion organelles (apical complex and surface coat) and de-differentiates into a round trophozoite located within a parasitophorous vacuole. The young trophozoite (or \"ring\" stage, because of its morphology on stained blood films) grows substantially before undergoing schizogony.\n\nAt the schizont stage, the parasite replicates its DNA multiple times and multiple mitotic divisions occur asynchronously. Each schizont forms 16-18 merozoites. The red blood cells are ruptured by the merozoites. The liberated merozoites invade fresh erythrocytes. A free merozoite is in the bloodstream for roughly 60 seconds before it enters another erythrocyte.\n\nThe duration of each blood stage is approximately 48 hours. This gives rise to the characteristic clinical manifestations of falciparum malaria, such as fever and chills, corresponding to the synchronous rupture of the infected erythrocytes.\n\nNot all of the merozoites divide into schizonts; some get differentiated into sexual forms, male and female gametocytes. These gametocytes take roughly 7–15 days to reach full maturity, through the process called gametocytogenesis. These gametocytes are taken up by a female \"Anopheles\" mosquito during a blood meal.\n\nThe time of appearance of the symptoms from infection (called incubation period) is shortest for \"P. falciparum\" among \"Plasmodium\" species. An average incubation period is 11 days, but may range from 9 to 30 days. In isolated cases, prolonged incubation period as long as 2, 3 or even 8 years have been recorded. Pregnancy and co-infection with HIV are important conditions for delayed symptoms. Parasites can be detected from blood samples by the 10th day after infection (pre-patent period).\n\nWithin the mosquito midgut, the female gamete maturation process entails slight morphological changes, becoming more enlarged and spherical. The male gametocyte undergoes a rapid nuclear division within 15 minutes, producing eight flagellated microgametes by a process called exflagellation. The flagellated microgamete fertilizes the female macrogamete to produce a diploid cell called a zygote. The zygote then develops into an ookinete. The ookinete is a motile cell, capable of invading other organs of the mosquito. It traverses the peritrophic membrane of the mosquito midgut and crosses the midgut epithelium. Once through the epithelium, the ookinete enters the basal lamina, and settles to an immotile oocyst. For several days, the oocyst undergoes 10 to 11 rounds of cell division to create a syncytial cell (sporoblast) containing thousands of nuclei. Meiosis takes place inside the sporoblast to produce over 3,000 haploid daughter cells called sporozoites on the surface of the mother cell. Immature sporozoites break through the oocyst wall into the haemolymph. They migrate to the mosquito salivary glands where they undergo further development and become infective to humans.\n\nA single anopheline mosquito can transmit hundreds of \"P. falciparum\" sporozoites in a single bite under experimental conditions. But in nature the number is generally less than 80. The sporozoites do not enter the blood stream directly and remain in the skin tissue for 2 to 3 hours. About 15–20% sporozoites enter the lymphatic system where they activate dendritic cells, which send them for destruction by T lymphocytes (CD8+ T cells). At 48 hours after infection, \"Plasmodium\"-specific CD8+ T cells can be detected in the lymph nodes connected to the skin cells. Most of the sporozites remaining in the skin tissue are subsequently killed by the innate immune system. The sporozoite glycoprotein specifically activates mast cells. The mast cells then produce signalling molecules such as TNFα and MIP-2, which activate cell eaters (professional phagocytes) such as neutrophils and macrophages.\n\nOnly a small number (0.5-5%) of sporozoites enter the blood stream into the liver. In the liver, the activated CD8+ T cells from the lymph bind the sporozoites through the circumsporozoite protein (CSP). Antigen presentation by dendritic cells in the skin tissue to T cells is also a crucial process. From this stage onward the parasites produce different proteins that help in suppressing communication of the immune cells. Even at the height of the infection when RBCs are ruptured, the immune signals are not strong enough to activate macrophages or natural killer cells.\n\nAlthough \"P. falciparum\" is easily recognized by human immune system while in the bloodstream, it evades immunity by producing over 2,000 cell membrane antigens The initial infective stage sporozoites produce circumsporozoite protein (CSP), which binds to hepatocytes. Binding to and entry into the hepatocytes is aided by another protein, thrombospondin-related anonymous protein (TRAP). TRAP and other secretory proteins (including sporozoite microneme protein essential for cell traversal 1, SPECT1 and SPECT2) from microneme allow the sporozoite to move through the blood, avoiding immune cells and penetrating hepatocytes.\n\nDuring erythrocyte invasion, merozoites release merozoite cap protein-1 (MCP1), apical membrane antigen 1 (AMA1), erythrocyte-binding antigens (EBA), myosin A tail domain interacting protein (MTIP), and merozoite surface proteins (MSPs). Of these MSPs, MSP1 and MSP2 are primarily responsible for avoiding immune cells. The virulence of \"P. falciparum\" is mediated by erythrocyte membrane proteins, which are produced by the schizonts and trophozoites inside the erythrocytes and are displayed on the erythrocyte membrane. PfEMP1 is the most important, capable of acting as both an antigen and an adhesion molecule.\n\nThe clinical symptoms of falciparum malaria are produced by the rupture of schizont and destruction of erythrocytes. Most of the patients experience fever (>92% of cases), chills (79%), headaches (70%), and sweating (64%). Dizziness, malaise, muscle pain, abdominal pain, nausea, vomiting, mild diarrhea, and dry cough are also generally associated. High heartrate, jaundice, pallor, orthostatic hypotension, enlarged liver, and enlarged spleen are also diagnosed.\n\n\"P. falciparum\" works via sequestration, a distinctive property not shared by few other \"Plasmodiae\". The mature schizonts change the surface properties of infected erythrocytes, causing them to stick to blood vessel walls (cytoadherence). This leads to obstruction of the microcirculation and results in dysfunction of multiple organs, such as the brain in cerebral malaria.\n\n\"P. falciparum\" is responsible for (almost) all severe human illnesses and deaths due to malaria, in a condition called complicated or severe malaria. Complicated malaria occurs more commonly in children under age 5, and sometimes in pregnant women (a condition specifically called pregnancy-associated malaria). Women become susceptible to severe malaria during their first pregnancy. Susceptibility to severe malaria is reduced in subsequent pregnancies due to increased antibody levels against variant surface antigens that appear on infected erythrocytes. But increased immunity in mother increases susceptibility to malaria in newborn babies.\n\n\"P. falciparum\" is found in all continents except Europe. According to the WHO \"World Malaria Report 2018\", 219 million people suffered from malaria in 2017, an increase from 216 million in 2016. 435,000 people died from it. The infection is most prevalent in Africa, where 92% of malaria deaths occr. Children under five years of age are most affected and 61% of malaria deaths occurred in this age group. 80% of the infection is found in Sub-Saharan Africa, 7% in the South-East Asia, and 2% in the Eastern Mediterranean. Nigeria has the highest incidence with 27% of the total global cases. Outside Africa, India has the highest incidence with 4.5% of the global burden. Europe is regarded as a malaria-free region. Historically, the parasite and its disease had been most well known in Europe. But medical programmes, such as insecticide spraying, drug therapy and environmental engineering since the early 20th century resulted in complete eradication in the 1970s. It is estimated that approximately 2.4 billion people are at constant risk of infection.\n\nIn 1640, Huan del Vego first employed the tincture of the cinchona bark for treating malaria; the native Indians of Peru and Ecuador had been using it even earlier for treating fevers. Thompson (1650) introduced this \"Jesuits' bark\" to England. Its first recorded use there was by John Metford of Northampton in 1656. Morton (1696) presented the first detailed description of the clinical picture of malaria and of its treatment with cinchona. Gize (1816) studied the extraction of crystalline quinine from the cinchona bark and Pelletier and Caventou (1820) in France extracted pure quinine alkaloids, which they named quinine and cinchonine. The total synthesis of quinine was achieved by American chemists R.B. Woodward and W.E. Doering in 1944. Woodward received the Nobel Prize in Chemistry in 1965.\n\nAttempts to make synthetic antimalarials began in 1891. Atabrine, developed in 1933, was used widely throughout the Pacific in World War II, but was unpopular because of its adeverse effects. In the late 1930s, the Germans developed chloroquine, which went into use in the North African campaigns. Creating a secret military project called Project 523, Mao Zedong encouraged Chinese scientists to find new antimalarials after seeing the casualties in the Vietnam War. Tu Youyou discovered artemisinin in the 1970s from sweet wormwood (\"Artemisia annua\"). This drug became known to Western scientists in the late 1980s and early 1990s and is now a standard treatment. Tu won the Nobel Prize in Physiology or Medicine in 2015.\n\nAccording to WHO guidelines 2010, artemisinin-based combination therapies (ACTs) are the recommended first-line antimalarial treatments for uncomplicated malaria caused by \"P. falciparum\". WHO recommends combinations such as artemether/lumefantrine, artesunate/amodiaquine, artesunate/mefloquine, artesunate/sulfadoxine-pyrimethamine, and dihydroartemisinin/piperaquine.\n\nThe choice of ACT is based on the level of resistance to the constituents in the combination. Artemisinin and its derivatives are not appropriate for monotherapy. As second-line antimalarial treatment, when initial treatment does not work, an alternative ACT known to be effective in the region is recommended, such as artesunate plus tetracycline or doxycycline or clindamycin, and quinine plus tetracycline or doxycycline or clindamycin. Any of these combinations is to be given for 7 days. For pregnant women, the recommended first-line treatment during the first trimester is quinine plus clindamycin for 7 days. Artesunate plus clindamycin for 7 days is indicated if this treatment fails. For travellers returning to nonendemic countries, atovaquone/proguanil, artemether/lumefantrineany and quinine plus doxycycline or clindamycin are recommended.\n\nFor adults, intravenous (IV) or intramuscular (IM) artesunate is recommended. Quinine is an acceptable alternative if parenteral artesunate is not available.\n\nFor children, especially in the malaria-endemic areas of Africa, artesunate IV or IM, quinine (IV infusion or divided IM injection), and artemether IM are recommended.\n\nParenteral antimalarials should be administered for a minimum of 24 hours, irrespective of the patient's ability to tolerate oral medication earlier. Thereafter, complete treatment is recommended including complete course of ACT or quinine plus clindamycin or doxycycline.\n\nRTS,S is the only candidate as malaria vaccine to have gone through clinical trials. Analysis of the results of the phase III trial (conducted between 2011 and 2016) revealed a rather low efficacy (20-39% depending on age, with up to 50% in 5–17-month aged babies), indicating that the vaccine will not lead to full protection and eradication.\n\nThe International Agency for Research on Cancer (IARC) has classified malaria due to \"P. falciparum\" as Group 2A carcinogen, meaning that the parasite is probably a cancer-causing agent in humans. Its association with a blood cell (lymphocyte) cancer called Burkitt's lymphoma is established. Burkit's lymphoma was discovered by Denis Burkitt in 1958 from African children, and he later speculated that the cancer was likely due to certain infectious diseases. In 1964, a virus, later called Eppstein-Barr virus (EBV) after the discoverers, was identified from the cancer cells. The virus was subsequently proved to be the direct cancer agent, and is now classified as Group 1 carcinogen. In 1989, it was realised that EBV requires other infections such as with malaria to cause lymphocyte transformation. It was reported that the incidence of Burkitt's lymphoma decreased with effective treatment of malaria over several years. The actual role played by \"P. falciparum\" remained unclear for the next two-and-half decades. EBV had been known to induce lymphocytes to become cancerous using its viral proteins (antigens such as EBNA-1, EBNA-2, LMP-1, and LMP2A). From 2014, it became clear that \"P. falciparum\" contributes to the development of the lymphoma. \"P. falciparum\"-infected erythrocytes directly bind to B lymphocytes through the CIDR1α domain of PfEMP1. This binding activates toll-like receptors (TLR7 and TLR10) causing continuous activation of lymphocytes to undergo proliferation and differentiation into plasma cells, thereby increasing the secretion of IgM and cytokines. This in turn activates an enzyme called activation-induced cytidine deaminase (AID), which tends to cause mutation in the DNA (by double-strand break) of an EBV-infected lymphocytes. The damaged DNA undergoes uncontrolled replication, thus making the cell cancerous.\n\nThe high mortality and morbidity caused by \"P. falciparum\" has placed great selective pressure on the human genome. Several genetic factors provide some resistance to \"Plasmodium\" infection, including sickle cell trait, thalassaemia traits, glucose-6-phosphate dehydrogenase deficiency, and the absence of Duffy antigens on red blood cells. The presence of \"P. falciparum\" in human populations has exerted selective pressure on the human genome. E. A. Beet, a doctor working in Southern Rhodesia (now Zimbabwe) had observed in 1948 that sickle-cell disease was related to lower rate of malaria infection. This suggestion was reiterated by J. B. S. Haldane in 1948, who suggested that thalassaemia could provide similar protection. This hypothesis has since been confirmed and extended to hemoglobin E, hemoglobin C and Hemoglobin S.\n\n\n\n"}
{"id": "31595228", "url": "https://en.wikipedia.org/wiki?curid=31595228", "title": "Psychological stress", "text": "Psychological stress\n\nIn psychology, stress is a feeling of strain and pressure. Stress is a type of psychological pain. Small amounts of stress may be desired, beneficial, and even healthy. Positive stress helps improve athletic performance. It also plays a factor in motivation, adaptation, and reaction to the environment. Excessive amounts of stress, however, may lead to bodily harm. Stress can increase the risk of strokes, heart attacks, ulcers, and mental illnesses such as depression.\n\nStress can be external and related to the environment, but may also be caused by internal perceptions that cause an individual to experience anxiety or other negative emotions surrounding a situation, such as pressure, discomfort, etc., which they then deem stressful.\n\nHumans experience stress, or perceive things as threatening, when they do not believe that their resources for coping with obstacles (stimuli, people, situations, etc.) are enough for what the circumstances demand. When people think the demands being placed on them exceed their ability to cope, they then perceive stress.\nA very much overlooked side of stress is its positive adaptations. Positive psychological stress can lead to motivation and challenge instead of anxiety. The effects of experiencing eustress, which is positive stress, versus distress, which is negative stress, are significant. While colloquially lumped together, the various types of stress should be treated as separate concepts.\n\nSelye proposed that there are four variations of stress. On one axis, there is good stress (eustress) and bad stress (distress). On the other is over-stress (hyperstress) and understress (hypostress). The goal is to balance these as much as possible. The ultimate goal would be to balance hyperstress and hypostress perfectly and have as much eustress as possible. It is extremely useful for a productive lifestyle because it makes working enjoyable instead of a chore, as seen with distress.\n\nEustress comes from the Greek root “eu” which means good as in euphoria. Eustress is when a person perceives a stressor as positive. Distress stems from the Latin root “dis” as in dissonance or disagreement. Distress is a threat to the quality of life. It is when a demand vastly exceeds a person’s capabilities.\n\nThere is likely a connection between stress and illness. Theories of the stress–illness link suggest that both acute and chronic stress can cause illness, and several studies found such a link. According to these theories, both kinds of stress can lead to changes in behavior and in physiology. Behavioral changes can be smoking and eating habits and physical activity. Physiological changes can be changes in sympathetic activation or hypothalamic pituitary adrenocorticoid activation, and immunological function. However, there is much variability in the link between stress and illness.\n\nStress can make the individual more susceptible to physical illnesses like the common cold. Stressful events, such as job changes, may result in insomnia, impaired sleeping, and health complaints. Research indicates the type of stressor (whether it is acute or chronic) and individual characteristics such as age and physical well-being before the onset of the stressor can combine to determine the effect of stress on an individual. An individual's personality characteristics (such as level of neuroticism), genetics, and childhood experiences with major stressors and traumas may also dictate their response to stressors.\n\nChronic stress and a lack of coping resources available or used by an individual can often lead to the development of psychological issues such as depression and anxiety (see below for further information). This is particularly true regarding chronic stressors. These are stressors that may not be as intense as an acute stressor like a natural disaster or a major accident, but they persist over longer periods of time. These types of stressors tend to have a more negative impact on health because they are sustained and thus require the body's physiological response to occur daily. This depletes the body's energy more quickly and usually occurs over long periods of time, especially when these microstressors cannot be avoided (i.e. stress of living in a dangerous neighborhood). See allostatic load for further discussion of the biological process by which chronic stress may affect the body. For example, studies have found that caregivers, particularly those of dementia patients, have higher levels of depression and slightly worse physical health than noncaregivers.\n\nStudies have also shown that perceived chronic stress and the hostility associated with Type A personalities are often associated with much higher risks of cardiovascular disease. This occurs because of the compromised immune system as well as the high levels of arousal in the sympathetic nervous system that occur as part of the body's physiological response to stressful events. However, it is possible for individuals to exhibit hardiness a term referring to the ability to be both chronically stressed and healthy. Chronic stress can be associated with psychological disorders such as delusions. Pathological anxiety and chronic stress lead to structural degeneration and impaired functioning of the hippocampus.\n\nIt has long been believed that negative affective states, such as feelings of anxiety and depression, could influence the pathogenesis of physical disease, which in turn, have direct effects on biological process that could result in increased risk of disease in the end. However, studies done by the University of Wisconsin-Madison and other places have shown this to be partly untrue; although stress seems to increase the risk of reported poor health, the \"perception\" that stress is harmful increases the risk even further. For example, when humans are under chronic stress, permanent changes in their physiological, emotional, and behavioral responses are most likely to occur. Such changes could lead to disease. Chronic stress results from stressful events that persist over a relatively long period of time, such as caring for a spouse with dementia, or results from brief focal events that continue to be experienced as overwhelming even long after they are over, such as experiencing a sexual assault.\n\nExperiments show that when healthy human individuals are exposed to acute laboratory stressors, they show an adaptive enhancement of some markers of natural immunity but a general suppression of functions of specific immunity. By comparison, when healthy human individuals are exposed to real-life chronic stress, this stress is associated with a biphasic immune response where partial suppression of cellular and humoral function coincides with low-grade, nonspecific inflammation.\n\nEven though psychological stress is often connected with illness or disease, most healthy individuals can still remain disease-free after confronting chronic stressful events. Also, people who do not believe that stress will affect their health do not have an increased risk of illness, disease, or death. This suggests that there are individual differences in vulnerability to the potential pathogenic effects of stress; individual differences in vulnerability arise due to both genetic and psychological factors. In addition, the age at which the stress is experienced can dictate its effect on health. Research suggests chronic stress at a young age can have lifelong impacts on the biological, psychological, and behavioral responses to stress later in life.\n\nAs stress has a physical effect on the body, some individuals may not distinguish this from other more serious illnesses.\nIf the symptom is unambiguous (e.g. a breast lump), individuals are motivated to seek care regardless if they are under stress.\nHowever, if the symptom is ambiguous (e.g. headache), they will not seek care attributing the symptom to stress if the stressor's onset is recent which began in the previous 3 weeks, and will seek care if the onset is not recent.\n\nIn animals, stress contributes to the initiation, growth, and metastasis of select tumors, but studies that try to link stress and cancer incidence in humans have had mixed results. This can be due to practical difficulties in designing and implementing adequate studies. Personal belief in stress as a risk factor for cancer was common in one UK study, though awareness of risk factors overall was found to be low.\n\nStress is a non-specific response. It is neutral, and what varies is the degree of response. It is all about the context of the individual and how they perceive the situation. Selye defined stress as “the nonspecific (that is, common) result of any demand upon the body, be the effect mental or somatic.” This includes the medical definition of stress as a physical demand and the colloquial definition of stress as a psychological demand. A stressor is inherently neutral meaning that the same stressor can cause either distress or eustress. It is individual differences and responses that induce either distress or eustress.\n\nA stressor is any event, experience, or environmental stimulus that causes stress in an individual. These events or experiences are perceived as threats or challenges to the individual and can be either physical or psychological. Researchers have found that stressors can make individuals more prone to both physical and psychological problems, including heart disease and anxiety.\n\nStressors are more likely to affect an individual's health when they are \"chronic, highly disruptive, or perceived as uncontrollable\". In psychology, researchers generally classify the different types of stressors into four categories: 1) crises/catastrophes, 2) major life events, 3) daily hassles/microstressors, and 4) ambient stressors.\n\nThis type of stressor is unforeseen and unpredictable and, as such, is completely out of the control of the individual. Examples of crises and catastrophes include: devastating natural disasters, such as major floods or earthquakes, wars, etc. Though rare in occurrence, this type of stressor typically causes a great deal of stress in a person's life. A study conducted by Stanford University found that after natural disasters, those affected experienced a significant increase in stress level. Combat stress is a widespread acute and chronic problem. With the rapid pace and the urgency of firing first, tragic episodes of accidentally killing friendly forces (“brother” killing “brother” or fratricide) may happen. Prevention requires stress reduction, emphasis on vehicle and other identification training, awareness of the tactical situation, and continual risk analysis by leaders at all echelons.\n\nCommon examples of major life events include: marriage, going to college, death of a loved one, birth of a child, moving houses, etc. These events, either positive or negative, can create a sense of uncertainty and fear, which will ultimately lead to stress. For instance, research has found the elevation of stress during the transition from high school to university, with college freshmen being about two times more likely to be stressed than final year students. Research has found major life events are somewhat rare to be major causes of stress, due to its rare occurrences.\n\nThe length of time since occurrence and whether or not it is a positive or negative event are factors in whether or not it causes stress and how much stress it causes. Researchers have found that events that have occurred within the past month generally are not linked to stress or illness, while chronic events that occurred more than several months ago are linked to stress and illness and personality change. Additionally, positive life events are typically not linked to stress and if so, generally only trivial stress while negative life events can be linked to stress and the health problems that accompany it. However, positive experiences and positive life changes can predict decreases in neuroticism.\n\nThis category includes daily annoyances and minor hassles. Examples include: making decisions, meeting deadlines at work or school, traffic jams, encounters with irritating personalities, etc. Often, this type of stressor includes conflicts with other people. Daily stressors, however, are different for each individual, as not everyone perceives a certain event as stressful. For example, most people find public speaking to be stressful, nevertheless, a seasoned politician most likely will not.\n\nDaily hassles are the most frequently occurring type of stressor in most adults. The high frequency of hassles causes this stressor to have the most physiological effect on an individual. Carolyn Aldwin, Ph.D., conducted a study at the Oregon State University that examined the perceived intensity of daily hassles on an individual's mortality. Aldwin's study concluded that there is a strong correlation between individuals who rate their hassles as very intense and a high level of mortality. One's perception of his/her daily stressors can have a modulating effect on the physiological impact of daily stressors.\n\nThere are three major psychological types of conflicts that can cause stress.\n\n\nTravel-related stress results from three main categories: lost time, surprises (an unforeseen event such as lost or delayed baggage) and routine breakers (inability to maintain daily habits).\n\nAs their name implies, these are global (as opposed to individual) low-grade stressors that are a part of the background environment. They are defined as stressors that are \"chronic, negatively valued, non-urgent, physically perceptible, and intractable to the efforts of individuals to change them\". Typical examples of ambient stressors are pollution, noise, crowding, and traffic. Unlike the other three types of stressor, ambient stressors can (but do not necessarily have to) negatively impact stress without conscious awareness. They are thus low on what Stokols called \"perceptual salience\".\n\nStudies conducted in military and combat fields show that some of the most potent stressors can be due to personal organizational problems in the unit or on the home front. Stress due to bad organizational practices is often connected to \"Toxic Leadership\", both in companies and in governmental organizations.\n\nStress management refers to a wide spectrum of techniques and psychotherapies aimed at controlling a person's levels of stress, especially chronic stress, usually for the purpose of improving everyday functioning. It involves controlling and reducing the tension that occurs in stressful situations by making emotional and physical changes.\n\nDecreasing stressful behaviors is a part of prevention, some of the common strategies and techniques are: Self-monitoring, tailoring, material reinforcement, social reinforcement, social support, self-contracting, contracting with significant other, shaping, reminders, self-help groups, professional help.\n\nAlthough many techniques have traditionally been developed to deal with the consequences of stress considerable research has also been conducted on the prevention of stress, a subject closely related to psychological resilience-building. A number of self-help approaches to stress-prevention and resilience-building have been developed, drawing mainly on the theory and practice of cognitive-behavioral therapy.\n\nBiofeedback may also play a role in stress management. A randomized study by Sutarto et al. assessed the effect of resonant breathing biofeedback (recognize and control involuntary heart rate variability) among manufacturing operators; depression, anxiety and stress significantly decreased.\n\nThe Lazarus and Folkman model suggests that external events create a form of pressure to achieve, engage in, or experience a stressful situation. Stress is not the external event itself, but rather an interpretation and response to the potential threat; this is when the coping process begins.\n\nThere are various ways individuals deal with perceived threats that may be stressful. However, people have a tendency to respond to threats with a predominant coping style, in which they dismiss feelings, or manipulate the stressful situation.\n\nThere are different classifications for coping, or defense mechanisms, however they all are variations on the same general idea: There are good/productive and negative/counterproductive ways to handle stress. Because stress is perceived, the following mechanisms do not necessarily deal with the actual situation that is causing an individual stress. However, they may be considered coping mechanisms if they allow the individual to cope better with the negative feelings/anxiety that they are experiencing due to the perceived stressful situation, as opposed to actually fixing the concrete obstacle causing the stress. The following mechanisms are adapted from the DSM-IV Adaptive Functioning Scale, APA, 1994.\n\nThese skills are what one could call as “facing the problem head on”, or at least dealing with the negative emotions experienced by stress in a constructive manner. (generally adaptive)\n\n\n\nThe final path model fitted well (CF1 = 1, RMSEA = 0.00) and showed that direct quality of life paths with β = -0.2, and indirect social support with β = -0.088 had the most effects on reduction of stress during pregnancy.\nOther adaptive coping mechanisms include anticipation, altruism, and self-observation.\n\nThese mechanisms cause the individual to have a diminished (or in some cases non-existent) awareness about their anxiety, threatening ideas, fears, etc., that come from being conscious of the perceived threat.\n\n\nOther inhibition coping mechanisms include undoing, dissociation, denial, projection, and rationalization. Although some people claim that inhibition coping mechanisms may eventually increase the stress level because the problem is not solved, detaching from the stressor can sometimes help people to temporarily release the stress and become more prepared to deal with problems later on.\n\nThese methods deal with stress by an individual literally taking action, or withdrawing.\n\n\nThere is an alternative method to coping with stress, in which one works to minimize their anxiety and stress in a preventative manner. If one works towards coping with stress daily, the feeling of stress and the ways in which one deals with it as the external event arises becomes less of a burden.\n\nSuggested strategies to improve stress management include:\n\n\nDepending on the situation, all of these coping mechanisms may be adaptive, or maladaptive.\n\nThe body responds to stress in many ways. Readjusting chemical levels is just one of them. Here are some examples of adjustments and changes that affect communication.\n\nIn terms of measuring the body's response to stress, psychologists tend to use Hans Selye's general adaptation syndrome. This model is also often referred to as the classic stress response, and it revolves around the concept of homeostasis. General adaptive syndrome occurs in three stages:\n\n\nThis physiological stress response involves high levels of sympathetic nervous system activation, often referred to as the \"fight or flight\" response. The response involves pupil dilation, release of endorphins, increased heart and respiration rates, cessation of digestive processes, secretion of adrenaline, arteriole dilation, and constriction of veins. This high level of arousal is often unnecessary to adequately cope with micro-stressors and daily hassles; yet, this is the response pattern seen in humans, which often leads to health issues commonly associated with high levels of stress.\n\nSleep allows people to rest and re-energize for another day filled with interactions and tasks. If someone is stressed it is extremely important for them to get enough sleep so that they can think clearly. Unfortunately, chemical changes in the body caused by stress can make sleep a difficult thing. Glucocorticoids are released by the body in response to stress which can disrupt sleep. Sleep comes in four stages and the deepest, most restful sleep can only be attained after having been asleep for an hour.\n\nWhen someone is stressed, many challenges can arise; a recognized challenge being communication difficulties. Here are some examples of how stress can hinder communication.\n\nThe cultures of the world generally fall into two categories; individualistic and collectivistic.\n\n\nThese cultural differences can affect how people communicate when they are stressed. For example, a member of an individualistic cultural would be hesitant to ask for pain medication for fear of being perceived as weak. A member of a collectivistic culture would not hesitate. They have been brought up in a cultural where everyone helps each other and is one functional unit whereas the member of the individualistic culture is not as comfortable asking others for aid.\n\nLanguage barriers can also diminish communication due to stress. All languages have their own way of using names, titles, and just interacting. These differences can make inter lingual communication relatively stressful. Not speaking the same languages, different ways of showing respect, and different use of body language can make things difficult. Being uncomfortable with the communication around a person can discourage them from communicating at all.\n\nDivorce, death, and remarriage are all disruptive events in a household. Although everyone involved is affected by events such as these, it can be most drastically seen in children. Due to their age, children have relatively undeveloped coping skills. For this reason a stressful event may cause some changes in their behavior. Falling in with a new crowd, developing some new and sometimes undesirable habits are just some of the changes stress may trigger in their lives.\n\nA particularly interesting response to stress is talking to an imaginary friend. A child may feel angry with a parent or their peers who they feel brought this change on them. They need someone to talk to but it definitely won’t be the person with whom they are angry. That’s when the imaginary friend comes in. They “talk” to this imaginary friend but in doing so they cut off communication with the real people around them.\n\nResearchers have long been interested in how an individual's level and types of social support impact the effect of stress on their health. Studies consistently show that social support can protect against physical and mental consequences of stress. This can occur through a variety of mechanisms. One model, known as the \"direct effects\" model, holds that social support has a direct, positive impact on health by increasing positive affect, promoting adaptive health behaviors, predictability and stability in life, and safeguarding against social, legal, and economic concerns that could negatively impact health. another model, the \"buffering effect\", says that social support exerts greatest influence on health in times of stress, either by helping individuals appraise situations in less threatening manners or coping with the actual stress. Researchers have found evidence to support both these pathways.\n\nSocial support is defined more specifically as psychological and material resources provided by a social network that are aimed at helping an individual cope with stress. Researchers generally distinguish among several types of social support: instrumental support – which refers to material aid (e.g., financial support or assistance in transportation to a physician's appointment), informational support (e.g., knowledge, education or advice in problem-solving), and emotional support (e.g., empathy, reassurance, etc.). Social support can reduce the rate of stress during pregnancy.\n\nSocial support from friends and the community can be very beneficial to helping someone communicate while stressed. Social support is giving a person the knowledge that they are part of a mutual network of caring, interested others, that enable them to lower levels of stress and be better able to cope with the stress that they undergo. The social and emotional support people provide for each other demonstrates that they are important and valued members of social networks.\n\nThe stress of a person can greatly affect those around them, especially in families. “Families can experience many conflicting emotions when placed in the position of providing protected care for a loved one. Compassion, protectiveness, and caring can be intermingled with feelings of helplessness and being trapped.\" Emotional support is crucial to helping families cope with the challenge of supporting their loved one (stressed person). This emotional support can be expressed through many communication methods.\n\nIn order to be able to effectively communicate with someone who is stressed, it is important to know how to interact with them in a way that can be beneficial for them. Therapeutic communication techniques can help with different types of communication. These techniques include but are not limited to listening, making open-ended comments, reducing distance, restating, seeking clarification, reflecting, and planning. Actively listening to someone when they are stressed can help them release frustrations and cope with their problems. Listening shows that you are interested in the person, and can have great therapeutic value. It is important to show that the stressed person's needs are above the caregiver's in order for the interaction to be therapeutic. It is important that you remain prepared mentally, emotionally, and physically to assist him or her. It is favorable to remain punctual and polite in the manner of relating to them, and that the best methods are used to promote their well-being and comfort.\n\n\n\nCommunication is an important stress-management skill. Although this seems like an easy skill, there is much more to communication than simply speaking. In fact, communication can cause problems such as misunderstandings when not used effectively. When miscommunication happen there tends to be more problems, anger and resentment then if communication were effective in the first place. There are certain things that need to be done to achieve effective communication.\n\nThe \"first guideline\" is to be clear about is what is wanted or needed when speaking with others.\n\nThis technique requires the individual’s recognition of distorted and exaggerated expectations and thoughts.\n\nAn easy way to meet this guideline is by reflecting the purpose of the conversation in the statement. By reflecting what the desired outcome of the conversation is, there is little room for miscommunication.\n\nThe \"second guideline\" for effective communication is to use assertive communication.\n\nAn assertive statement is non-judgmental, expresses feelings and opinions and reaffirms perceived rights.\nThe best way to use the assertive technique is with manipulating the following formula:\n\n\nWhen people are stressed, they cannot verbalize their feelings correctly. When the receiver in the conversation cannot understand the needs of the person, miscommunications happen and the person may feel victimized and blame others for not understanding. The third guideline is empathy which is defined as the ability to consider another person’s perspective and to communicate this perspective back to that person.\n\nThe \"final guideline\" to prevent misunderstandings when communicating while stressed is cognitive restructuring which facilitates assertive communication as it requires the person to identify their thoughts and feelings. Some ways to restructure cognitively is by stopping and understanding what the conversation holds.\n\nBreathing deeply as this will release any tension and promote relaxation which will allow you to reflect on the true emotions.\n\nReflecting on how you feel emotionally and how you feel immediately allow you to choose the right answer.\n\nChoosing the more realistic and helpful way of thinking allows the communication to be straight forward and upfront leaving little room for miscommunication.\n\nBy following the above techniques and guidelines, the chance of a miscommunication in a conversation will decrease. Once the ability to communicate with assertive techniques is worked into everyday life, the frequency of misunderstandings will decrease significantly.\n\nThe importance of understanding how to communicate assertively is critical for daily life. With the knowledge of how to properly communicate, whether stressed or not, the ability to communicate will become easier and result in less misunderstandings and frustrations which can contribute to one’s stress.\n\nLife events scales can be used to assess stressful things that people experience in their lives. One such scale is the Holmes and Rahe Stress Scale, also known as the Social Readjustment Rating Scale, or SRRS. Developed by psychiatrists Thomas Holmes and Richard Rahe in 1967, the scale lists 43 stressful events.\n\nTo calculate one's score, add up the number of \"life change units\" if an event occurred in the past year. A score of more than 300 means that individual is at risk for illness, a score between 150 and 299 means risk of illness is moderate, and a score under 150 means that individual only has a slight risk of illness.\n\nA modified version was made for non-adults. The scale is below.\n\nThe SSRS is used in psychiatry to weight the impact of life events.\n"}
{"id": "20764919", "url": "https://en.wikipedia.org/wiki?curid=20764919", "title": "Richard Clarke Cabot", "text": "Richard Clarke Cabot\n\nRichard Clarke Cabot (May 21, 1868 – May 7, 1939) was an American physician who advanced clinical hematology, was an innovator in teaching methods, and was a pioneer in social work.\n\nRichard Clarke Cabot was born May 21, 1868, in Brookline, Massachusetts, one of five sons of James Elliot Cabot and Elizabeth (Dwight) Cabot. James Cabot was a philosopher and Harvard University professor who also trained as a lawyer and biographer, and was a friend of Ralph Waldo Emerson.\n\nCabot studied philosophy at Harvard University before switching to medicine. Inspired by the beliefs of John Dewey, Cabot felt more drawn to action than contemplation, and he admired the work of Teddy Roosevelt and Jane Addams. After completing his studies in 1892, he turned down the role of the first bacteriologist at Massachusetts General Hospital to work in the hospital's much less prestigious outpatient department. At this time, outpatient wards dealt mostly with people who couldn't afford inpatient treatment, or for the treatment of incurable chronic conditions such tuberculosis or diabetes. This involved working populations who lived in unhealthy, overcrowded accommodation, often recent migrants.\n\nHe changed the way that the outpatient department was run, believing that economic, social, family and psychological conditions underpinned many of the conditions that patients presented with. He envisaged that social workers would work in a complementary relationship with doctors, the former concentrating on physiological health, and the latter on social health. In addition to this, he saw that social work could improve medicine by providing a critical perspective on it while working alongside it in an organisational setting. In 1905 Cabot created one of the first positions of professional social worker in the world, given to Garnet Pelton, and then to Ida Cannon. Although Clarke credited his approach as similar to that of Anne Cummins in London. The hospital refused to support the hiring of social workers, and Cabot had to pay their wages himself. Pelten developed tuberculosis herself soon after taking up the position and was forced to retire. Cannon stayed in the position for forty years and became Head of Social Work at the hospital. Cabot and Cannon pioneered many programs to improve the health of patients, including art classes for psychiatric patients, low-cost meals for patients and research on the social factors that increased a person's likelihood of developing tuberculosis.\n\nIn 1917 Cabot took up a position in the Medical Reserve Corps for a year. He returned briefly to Massachusetts General Hospital in 1918 and then left to take up the position of chair at Harvard's Department of Social Ethics in 1919. At this time, the hospital agreed to pay the wages of social workers, as up to this point, Cabot had paid the wages of thirteen social workers over the last 12 years. He went on to write about his experiences in his book \"Social Work\"\n\nHe is also credited with discovering Cabot rings, and for describing, along with his colleague, Locke, the eponymous Cabot-Locke murmur, a diastolic murmur occasionally heard in severe anemia, unrelated to heart valve abnormalities.\n\nCabot established a tradition of teaching conferences at Massachusetts General Hospital (MGH) that featured generating differential diagnoses, and founded the long-standing feature of Case Record of MGH in \"New England Journal of Medicine\".\n\nCabot's paternal grandfather, Samuel Cabot, Jr., became a sailor at age 19 and married Elizabeth Perkins, daughter of a successful Boston trader. Samuel Cabot III later took over the running of the firm.\n\nRichard married Ella Lyman, and both held Transcendentalist views. This philosophy, as well as his parents' commitment to philanthropy, had a strong influence of Richard. Around the end of the 19th Century, such ideals were out of favor, with the dominant beliefs at the time being social Darwinism.\n\n\n\n"}
{"id": "4292637", "url": "https://en.wikipedia.org/wiki?curid=4292637", "title": "Saskia Estupinan", "text": "Saskia Estupinan\n\nDr. Saskia Estupiñán, a native of Quito, Ecuador, is a leading figure in international public health and oral health research. Dr. Estupinan has worked extensively with international organizations and has advised agencies including NASA, Kellogg Foundation and the World Bank.\n\nA dentist and public health specialist who attended the Universidad Central in Quito and UCLA, Dr. Estupinan is best known for work with the World Health Organization and the Pan American Health Organization promoting the expansion of salt fluoridation.\n\nSaskia Estupiñán is a track and field Master's athlete, ranked 9th worldwide in the 80 meter hurdles among women in her age group.\n"}
{"id": "23964266", "url": "https://en.wikipedia.org/wiki?curid=23964266", "title": "Sertoli cell nodule", "text": "Sertoli cell nodule\n\nA Sertoli cell nodule, also Pick's adenoma, testicular tubular adenoma and tubular adenoma of the testis, is a benign proliferation of Sertoli cells that arises in association with cryptorchidism (undescended testis). They are not composed of a clonal cell population, i.e. neoplastic; thus, technically, they should not be called an \"adenoma\".\n\nSertoli cell nodules are unencapsulated nodules that consist of:\n\n\n"}
{"id": "239041", "url": "https://en.wikipedia.org/wiki?curid=239041", "title": "Stanford–Binet Intelligence Scales", "text": "Stanford–Binet Intelligence Scales\n\nThe Stanford–Binet Intelligence Scales (or more commonly the Stanford–Binet) is an individually administered intelligence test that was revised from the original Binet–Simon Scale by Lewis M. Terman, a psychologist at Stanford University. The Stanford–Binet Intelligence Scale is now in its fifth edition (SB5) and was released in 2003. It is a cognitive ability and intelligence test that is used to diagnose developmental or intellectual deficiencies in young children. The test measures five weighted factors and consists of both verbal and nonverbal subtests. The five factors being tested are knowledge, quantitative reasoning, visual-spatial processing, working memory, and fluid reasoning.\n\nThe development of the Stanford–Binet initiated the modern field of intelligence testing and was one of the first examples of an adaptive test. The test originated in France, then was revised in the United States. It was initially created by the French psychologist Alfred Binet, who, following the introduction of a law mandating universal education by the French government, began developing a method of identifying \"slow\" children, so that they could be placed in special education programs, instead of labelled \"sick\" and sent to the asylum. As Binet indicated, case studies might be more detailed and helpful, but the time required to test many people would be excessive. In 1916, at Stanford University, the psychologist Lewis Terman released a revised examination that became known as the \"Stanford–Binet test\".\n\nAs discussed by Fancher & Rutherford in 2012, the Stanford–Binet is a modified version of the Binet-Simon Intelligence scale. The Binet-Simon scale was created by the French psychologist Alfred Binet and his student Theodore Simon. Due to changing education laws of the time, Binet had been requested by a government commission to come up with a way to detect children with significantly below-average intelligence and mental retardation.\n\nTo create their test, Binet and Simon first created a baseline of intelligence. A wide range of children were tested on a broad spectrum of measures in an effort to discover a clear indicator of intelligence. Failing to find a single identifier of intelligence, Binet and Simon instead compared children in each category by age. The children’s highest levels of achievement were sorted by age and common levels of achievement considered the normal level for that age. Because this testing method merely compares a person's ability to the common ability level of others their age, the general practices of the test can easily be transferred to test different populations, even if the measures used are changed.\n\nOne of the first intelligence tests, the Binet-Simon test quickly gained support in the psychological community, many of whom further spread it to the public. Lewis M. Terman, a psychologist at Stanford University, was one of the first to create a version of the test for people in the United States, naming the localized version the Stanford–Binet Intelligence Scale. Terman used the test not only to help identify children with learning difficulties but also to find children and adults who had above average levels of intelligence. In creating his version, Terman also tested additional methods for his Stanford revision, publishing his first official version as The Measurement of Intelligence: An Explanation of and a Complete Guide for the Use of the Stanford Revision and Extension of the Binet-Simon Intelligence Scale (Fancher & Rutherford, 2012) (Becker, 2003).\n\nThe original tests in the 1905 form include:\n\n\nOne hindrance to widespread understanding of the test is its use of a variety of different measures. In an effort to simplify the information gained from the Binet-Simon test into a more comprehensible and easier to understand form, German psychologist William Stern created the now well known Intelligence Quotient (IQ). By comparing the age a child scored at to their biological age, a ratio is created to show the rate of their mental progress as IQ. Terman quickly grasped the idea for his Stanford revision with the adjustment of multiplying the ratios by 100 to make them easier to read.\n\nAs also discussed by Leslie, in 2000, Terman was another of the main forces in spreading intelligence testing in the United States (Becker, 2003). Terman quickly promoted the use of the Stanford–Binet for schools across the United States where it saw a high rate of acceptance. Terman’s work also had the attention of the U.S. government, who recruited him to apply the ideas from his Stanford–Binet test for military recruitment near the start of World War I. With over 1.7 million military recruits taking a version of the test and the acceptance of the test by the government, the Stanford–Binet saw an increase in awareness and acceptance (Fancher & Rutherford, 2012).\n\nGiven the perceived importance of intelligence and with new ways to measure intelligence, many influential individuals, including Terman, began promoting controversial ideas to increase the nation's overall intelligence. These ideas included things such as discouraging individuals with low IQ from having children and granting important positions based on high IQ scores. While there was significant opposition, many institutions proceeded to adjust students' education based on their IQ scores, often with a heavy influence on future career possibilities (Leslie, 2000).\n\nSince the first publication in 1916, there have been four additional revised editions of the Stanford–Binet Intelligence Scales, the first of which was developed by Lewis Terman. Over twenty years later, Maud Merrill was accepted into Stanford’s education program shortly before Terman became the head of the psychology department. She completed both her Masters Degree and Ph.D. under Terman and quickly became a colleague of his as they started the revisions of the second edition together. There were 3,200 examinees, aged one and a half to eighteen years, ranging in different geographic regions as well as socioeconomic levels in attempts to comprise a broader normative sample (Roid & Barram, 2004). This edition incorporated more objectified scoring methods, while placing less emphasis on recall memory and including a greater range of nonverbal abilities (Roid & Barram, 2004) compared to the 1916 edition.\n\nWhen Terman died in 1956, the revisions for the third edition were well underway, and Merrill was able to publish the final revision in 1960 (Roid & Barram, 2004). The use of the deviation IQ made its first appearance in this third edition by replacing the ratio IQ. While new features were added, there were no newly created items included in this revision. Instead, any items from the 1937 form that showed no substantial change in difficulty from the 1930s to the 1950s were either eliminated or adjusted (Roid & Barram, 2004).\n\nRobert Thorndike was asked to take over after Merrill’s retirement. With the help of Elizabeth Hagen and Jerome Sattler, Thorndike produced the fourth edition of the Stanford–Binet Intelligence Scale in 1986. This edition covers the ages two through twenty-three and has some considerable changes compared to its predecessors (Graham & Naglieri, 2003). This edition was the first to use the fifteen subtests with point scales in place of using the previous age scale format. In an attempt to broaden cognitive ability, the subtests were grouped and resulted in four area scores, which improved flexibility for administration and interpretation (Youngstrom, Glutting, & Watkins, 2003). The fourth edition is known for assessing children that may be referred for gifted programs. This edition includes a broad range of abilities, which provides more challenging items for those in their early adolescent years, whereas other intelligence tests of the time did not provide difficult enough items for the older children (Laurent, Swerdlik, & Ryburn, 1992).\n\nGale Roid published the most recent edition of the Stanford–Binet Intelligence Scale. Roid attended Harvard University where he was a research assistant to David McClelland. McClelland is well known for his studies on the need for achievement. While the fifth edition incorporates some of the classical traditions of these scales, there were several significant changes made.\n\n\nJust as it was used when Binet first developed the IQ test, the Stanford–Binet Intelligence Scale: Fifth Edition (SB5) is based in the schooling process to assess intelligence. It continuously and efficiently assesses all levels of ability in individuals with a broader range in age. It is also capable of measuring multiple dimensions of abilities (Ruf, 2003).\n\nThe SB5 can be administered to individuals as early as two years of age. There are ten subsets included in this revision including both verbal and nonverbal domains. Five factors are also incorporated in this scale, which are directly related to Cattell-Horn-Carroll (CHC) hierarchical model of cognitive abilities. These factors include fluid reasoning, knowledge, quantitative reasoning, visual-spatial processing, and working memory (Bain & Allin, 2005). Many of the familiar picture absurdities, vocabulary, memory for sentences, and verbal absurdities still remain from the previous editions (Janzen, Obrzut, & Marusiak, 2003), however with more modern artwork and item content for the revised fifth edition.\n\nFor every verbal subtest that is used, there is a nonverbal counterpart across all factors. These nonverbal tasks consist of making movement responses such as pointing or assembling manipulatives (Bain & Allin, 2005). These counterparts have been included to address language-reduced assessments in multicultural societies. Depending on age and ability, administration can range from fifteen minutes to an hour and fifteen minutes.\n\nThe fifth edition incorporated a new scoring system, which can provide a wide range of information such as four intelligence score composites, five factor indices, and ten subtest scores. Additional scoring information includes percentile ranks, age equivalents, and a change-sensitive score (Janzen, Obrzut, & Marusiak, 2003). Extended IQ scores and gifted composite scores are available with the SB5 in order to optimize the assessment for gifted programs (Ruf, 2003). To reduce errors and increase diagnostic precision, scores are obtained electronically through the use of computers now.\n\nThe standardization sample for the SB5 included 4,800 participants varying in age, sex, race/ethnicity, geographic region, and socioeconomic level (Bain & Allin, 2005).\n\nSeveral reliability tests have been performed on the SB5 including split-half reliability, standard error of measurement, plotting of test information curves, test-retest stability, and inter-scorer agreement. On average, IQ scores for this scale have been found quite stable across time (Janzen, Obrzut, & Marusiak, 2003). Internal consistency was tested by split-half reliability and was reported to be substantial and comparable to other cognitive batteries (Bain & Allin, 2005). The median interscorer correlation was .90 on average (Janzen, Obrzut, & Marusiak, 2003). The SB5 has also been found to have great precision at advanced levels of performance meaning that the test is especially useful in testing children for giftedness (Bain & Allin, 2005). There have only been a small amount of practice effects and familiarity of testing procedures with retest reliability; however, these have proven to be insignificant. Readministration of the SB5 can occur in a six-month interval rather than one year due to the small mean differences in reliability (Bain & Allin, 2005).\n\nContent validity has been found based on the professional judgments Roid received concerning fairness of items and item content as well as items concerning the assessment of giftedness (Bain & Allin, 2005). With an examination of age trends, construct validity was supported along with empirical justification of a more substantial \"g\" loading for the SB5 compared to previous editions. The potential for a variety of comparisons, especially for within or across factors and verbal/nonverbal domains, has been appreciated with the scores received from the SB5 (Bain & Allin, 2005).\n\nThe test publisher includes suggested score classifications in the test manual.\n\nThe classifications of scores used in the Fifth Edition differ from those used in earlier versions of the test.\n\nSince its inception, the Stanford–Binet has been revised several times. Currently, the test is in its fifth edition, which is called the \"Stanford–Binet Intelligence Scales, Fifth Edition\", or SB5. According to the publisher's website, \"The SB5 was normed on a stratified random sample of 4,800 individuals that matches the 2000 U.S. Census\". By administering the Stanford–Binet test to large numbers of individuals selected at random from different parts of the United States, it has been found that the scores approximate a normal distribution. The revised edition of the Stanford–Binet over time has devised substantial changes in the way the tests are presented. The test has improved when looking at the introduction of a more parallel form and more demonstrative standards. For one, a non-verbal IQ component is included in the present day tests whereas in the past, there was only a verbal component. In fact, it now has equal balance of verbal and non-verbal content in the tests. It is also more animated than the other tests, providing the test-takers with more colourful artwork, toys and manipulatives. This allows the test to have a higher range in the age of the test takers. This test is purportedly useful in assessing the intellectual capabilities of people ranging from young children all the way to young adults. However, the test has come under criticism for not being able to compare people of different age categories, since each category gets a different set of tests. Furthermore, very young children tend to do poorly on the test due to the fact that they lack the ability to concentrate long enough to finish it.\n\nCurrent uses for the test include clinical and neuropsychological assessment, educational placement, compensation evaluations, career assessment, adult neuropsychological treatment, forensics, and research on aptitude. Various high-IQ societies also accept this test for admission into their ranks; for example, the Triple Nine Society accepts a minimum qualifying score of 151 for Form L or M, 149 for Form LM if taken in 1986 or earlier, 149 for SB-IV, and 146 for SB-V; in all cases the applicant must have been at least 16 years old at the date of the test.\n\n\n\n"}
{"id": "33214504", "url": "https://en.wikipedia.org/wiki?curid=33214504", "title": "The Food Wars", "text": "The Food Wars\n\nThe Food Wars is a 2009 book by Walden Bello which examines the food crisis and issues relating to food security.\n\nIt was originally published on 25 September 2009.\n\n <br>\nPhilip McMichael described that book as \"A comprehensive and timely corrective to agribusiness-as-usual scenarios for solving the food crisis ... His solutions are compelling and critical for planetary sustainability.\" <br>\nNaomi Klein praised the book.\n"}
{"id": "28889762", "url": "https://en.wikipedia.org/wiki?curid=28889762", "title": "The Park Centre for Mental Health", "text": "The Park Centre for Mental Health\n\nThe Park Centre for Mental Health is a heritage-listed psychiatric hospital at 60 Grindle Road, Wacol, City of Brisbane, Queensland, Australia. It is one of the largest psychiatric hospitals in Australia. The hospital provides a range of mental health services, including extended inpatient care, mental health research, education and a high security psychiatric unit. It was designed by Kersey Cannan and built from 1866 to 1923. It is also known as Goodna Hospital for the Insane, Goodna Mental Hospital, Woogaroo Lunatic Asylum, and Wolston Park Hospital Complex. It was added to the Queensland Heritage Register on 21 October 1992.\n\nThe Wolston Park Hospital Complex, opened in 1865, occupies a 450 hectare site on the banks of the Brisbane River at Wacol and encompasses a number of mental health facilities and ancillary services operated by the Queensland government since inception of the asylum.\n\nThe hospital employs around 450 people, including 220 nurses and 20 doctors. There are also another 80 allied health staff, and 50 administration personnel.\nIn addition there are 70 support staff, including maintenance, groundskeeping, security and laundry staff.\n\nPrior to 1859, mentally ill people in the colony of Queensland had been sent to Sydney. Following the Separation of Queensland, they were lodged instead at the Brisbane Gaol. In 1861 the government instructed Colonial Architect Charles Tiffin to report on a suitable site and draw up plans for a 400-bed asylum. Tiffin recommended an area of land on the banks of the Brisbane River halfway between Brisbane and Ipswich, which was rejected by the Queensland Government in favour of another site close by, upstream at the junction of the Brisbane River and Woogaroo Creek.\n\nThe site of the new asylum had \"been formerly occupied by the residence of Dr Stephen Simpson, the Commissioner of Crown lands.\" Dr Simpson was appointed Commissioner for Crown Lands for the Moreton Bay District in 1842 when the area was first opened up for free settlement following the closure of the Moreton Bay penal settlement. He was also the acting administrator, until the arrival of John Clements Wickham, and a Justice of the Peace. Simpson's first home in the colony, built in 1843-1844, was at Woogaroo. In 1851, when the opportunity to buy land in the area arose, he purchased 640 acres to the east and soon built Wolston House further down the Brisbane River.\n\nAn 1861 survey plan indicates the presence of a house between the mouth of Woogaroo Creek and the small dam which still exists to the east of the current Wolston Park Golf Club clubhouse. If this plan is accurate, the house, most likely Simpson's, would have been sited just south-west of the clubhouse. Late 1860s plans of the asylum's original buildings indicate that they were located at the east end of the current clubhouse.\n\nTenders for the first stage of construction of the asylum were let in 1863 and by the end of 1864 sufficient buildings were completed for the asylum to begin operation. The Woogaroo Lunatic Asylum opened on 10 January 1865. On 12 January, seven prison warders (two of them women) and ten police constables escorted 57 male and 12 female lunatics from Brisbane Gaol to Woogaroo, travelling by river on the steamer \"Settler\". The 69 patients were accommodated in a two-storeyed brick building initially intended to be the administration block (no longer extant). Male patients were accommodated on the first floor and part of the ground floor. Females occupied a section of the ground floor. A tall timber fence surrounded the building and timber outbuildings accommodated a kitchen, bathroom and staff areas. Dr Kersey Cannan was appointed as Superintendent and a residence was constructed for him on the site (no longer extant). This first stage of the asylum was located at the southern end of the site between the Brisbane River and Woogaroo Creek, with the river providing access to the site. Plans of the site made and in 1878, indicate that a cemetery or graveyard was established at the far western end of the site, near the confluence of Woogaroo Creek and the Brisbane River.\n\nIn 1866 a ward for fee-paying patients was erected on an adjacent ridge about to the east of the main buildings (later Female Wards 1 & 2). The building was constructed from local sandstone extracted from a nearby sandstone quarry formerly owned by Joshua Jeays, which was also the source of stone for the construction of Parliament House in 1864. The superintendent Dr Canaan claimed responsibility for the building's design, based on principles recommended in the standard treatise on asylum construction, The Construction and Government of Lunatic Asylums of 1847 by John Conolly. The Woogaroo Asylum was not, however, in a position to receive fee-paying patients and the building was unoccupied for two years until alterations were made so that female patients could be transferred to this block. A second storey was added, constructed to the design of Charles Tiffin in 1875, and other substantial alterations and additions were made to the building in both 1904 and 1923. This building accommodated female patients for over 100 years.\n\nIn 1867 the first of many Government inquiries into the operations of the asylum took place, with the Government appointing Dr Henry Challinor to investigate conditions there. Two further inquiries occurred in 1869 - the first inquiry was conducted by public servants, and the second by a select committee of members from both houses of Queensland Parliament. Dr Cannan was dismissed from his post as a result of the first inquiry. The second inquiry revealed a multitude of mistakes and incompetency and a number of its conclusions related to the inappropriate and insufficient accommodation on site and the improvement of cooking facilities and the provision of a decent water supply. On the recommendation of the select committee, the Queensland Government introduced the Lunacy Act of 1869, based on similar legislation in other Australian colonies and Britain.\n\nIt was not until a Royal Commission was established in 1877 to investigate Woogaroo Asylum and other reception houses in the colony that the Government was forced to take the continuing problems at the asylum more seriously. Despite the construction of two cottage wards in the early 1870s (no longer extant), overcrowding remained a chronic problem and the commission urged the construction of additional wards, improvements to existing cells, upgrading of services, the planting of shade trees, the establishment of recreation facilities and the provision of employment for patients. A modest building program began in 1878 with the construction of a cottage ward for 60 female patients and continued with a block of cells for troublesome female patients in 1879, two wards each for 35 patients in the male and female sections in 1880 as well as the construction of a kitchen and laundry building to service 500 patients (these buildings are no longer extant).\n\nA boom in the Queensland economy and a major increase in expenditure on public works was the impetus for a more substantial building program at the asylum during the 1880s. At the same time, the population of the state was increasing rapidly and accompanying social changes brought greater numbers of admissions to the asylum, then known as the Goodna Asylum. The hospital population doubled in the two decades from 1880. Two new cottage wards (one of which is now known as Bostock House, 1885) and a refractory ward were erected in the female section and a new refractory ward was constructed (no longer extant) and major additions to the existing No 1 ward were undertaken in the male section. Despite this new work, conditions for patients scarcely improved as the additional accommodation barely matched the growth in patient numbers. New legislation was introduced with the Insanity Act of 1884 replacing the Lunacy Act of 1869. It was modelled on New South Wales legislation and reflected the growing medicalisation of the treatment of madness. The term lunacy was replaced by insanity and the institution where such persons were treated became known as a hospital for the insane rather than an asylum. This Act consolidated the State's role in the treatment and regulation of insane people and remained in force for over fifty years.\n\nIn 1890 the asylum experienced severe flooding as the Brisbane River rose to a height of , the highest level ever recorded. The entire male section was inundated; buildings, fences and other structures were seriously damaged and patients had to be re-located. The decision was made to abandon the low-lying area near the river where the main male section was located and consolidate it on higher ground where two wards had already been erected. The relocation brought the complex closer to the Main Line railway (opened in 1875), which replaced the river as the primary means of access to the hospital. The Recreation Hall was erected in 1890 and was used as a sewing room by female patients during the days and was also available for dances, concerts and church services.\n\nThe male section was further damaged by in the 1893 Brisbane flood that also inundated the main staff residences. In line with the decision to relocate the male section on higher ground, work began on an outdoor recreation area and Fleming House, a two storeyed brick building with accommodation for 50 male patients, was opened in 1898. Verandahs were located at ground level on the northern side of the building, overlooking the cricket oval that had been laid out by patient labour. The same year, a substantial brick residence (now Manor House), replacing a timber house badly damaged by the 1893 flood, was erected for the new medical superintendent, James Hogg, appointed in 1898. The residence was located on high ground but with its main elevation facing south-east, away from the asylum complex. Most of the other staff resided off the site. For many decades the hospital was serviced by employees who lived in the local area and there are now a number of staff who have a family history of employment at the complex going back generations. During Hogg's period in charge, the complex became known as the Goodna Hospital for the Insane.\n\nThe most significant building project of the early 1900s involved extensive alterations and additions to the original female ward. A new level was built on the existing building that significantly increased accommodation. A large two-storeyed block, the male no. 4 ward (no longer extant) was also completed, bringing the male section to a well-defined group of eight buildings. A new morgue and two brick bathroom blocks were constructed in 1902. (Both bathroom blocks remain, one of which is now known as Dawson Annexe).\n\nFollowing the sudden death of James Hogg in 1908, Henry Byam Ellerton was appointed to replace him as superintendent of Goodna and Chief Inspector of Hospitals for the Insane. Conscious of the need to find the very best possible candidate, the Queensland Government had advertised widely for the position, including in Britain. Ellerton was chosen from a list of twenty-six applicants and had fourteen years experience in English asylums. He was an ardent advocate of \"moral treatment\" or moral therapy. Moral treatment marked a major turning point in an understanding of madness and insanity. Formerly regarded as the total absence or distortion of reason and incapable of cure, insanity came to be seen as a product of an immoral or defective social environment, thus mentally ill people could be improved in an appropriate and elevating environment. A critical aspect of moral treatment was the provision of a pleasant environment, with an emphasis on well-lit and ventilated buildings with adequate bathing facilities, reasonably sized rooms with sufficient openings and views to the landscape. Recreation and employment were also considered a vital part of the therapeutic process.\n\nEllerton was superintendent of the hospital for 28 years, retiring in 1936. In this period, Wolston Park acquired its modern form with the construction of the core of its buildings and the consolidation of the institutional environment. Ellerton's vision was to create an integrated and self-sufficient community, the grounds became gardens and wooden fences were replaced with less claustrophobic wire ones. A large bush house, 100 yards long and 20 yards wide, was established in 1911 to maintain a steady supply of pot plants for the wards and recreation hall and to provide seedlings and young plants for the gardens throughout the asylum (no longer extant). The institution was opened up to visits from relatives and friends and recreational activities became integral to the asylum's operations. While aesthetically-pleasing gardens and views were considered parts of the therapeutic process, the grounds were also important to the public image of the institution. A pleasant landscaped environment with gardens, scrubs and open space suggested the asylum was a benign institution and belied its true character as a place where overcrowding was chronic and patients were strictly controlled and managed. In 1916 the hospital was again improved with the addition of a ward for those suffering a physical disease as well as a mental disorder.\n\nDuring Ellerton's reign, existing male wards were demolished and Lewis House, Noble House and McDonnell House were completed in 1915. A new bridge over Woogaroo Creek was completed in 1916. A female admission ward, Anderson House, the hospital, the administration block, the powerhouse, water reservoirs and pumping stations were completed in 1917. The laundry was completed in 1918. Osler House, a ward for difficult female patients was completed in 1929 and Pearce House, for difficult male patients was completed in 1934. The male wards Gladstone House, Jenner House and Kelsey House were completed in 1936. Upon Ellerton's retirement, the male section comprised a total of 13 blocks, all constructed of brick and designed to accommodate between 20 and 120 patients. Despite the upgrading of facilities, overcrowding remained a chronic problem. The increase in beds from 1910 to 1936 failed to correspond to the increase in the number of patients.\n\nCompared with the extensive building program in the male section between 1910 and 1936, improvements in the female section were extremely modest. Ellerton felt that the expansion of the female section was limited due to the topography of the Goodna site and advocated additional female wards at other institutions such as Ipswich Mental Hospital. In the period 1910-1920, the number of female inmates decreased by 20%, falling from 491 to 389 patients and the 1910 female population level was not regained until 1929. Male patients increased by 30% during this period, rising from 779 to 1010.\n\nDuring Ellerton's period in charge, the asylum had undergone considerable material improvement and a number of essential services such as electricity, water and a hospital had been established. Many of the buildings were well designed and are excellent examples of the output of the Queensland Department of Works during this time. Some of the buildings demonstrated a refinement in approaches to patient care, such as the small and domestic scale Anderson House that was designed to accommodate female patients when they were first admitted so they could be kept under observation and receive more individual treatment than was possible in a large ward. Recreational facilities had vastly improved and the complex now had three tennis courts, a viewing pavilion and terraces and an oval considered one of the best cricket grounds in the state. A golf course had been constructed by patient labour in the 1920s, becoming the well-regarded Gailes Golf Club, which continued to be a source of employment for patients in the upkeep and maintenance of the greens. Patients were also employed in farming activities that aided the hospital's self-sufficiency. Farm activities included a piggery, dairy, a small cattle herd, vegetable and crop growing including oats, maize and lucerne. However no new techniques or methods of treatment had been introduced. Even the later male wards, Gladstone, Jenner and Kelsey, were still firmly based on the moral therapy model despite their new designs with unusual, crab-like plan forms. The institutionalisation of people with mental illness in Queensland had become an efficient system of control and regulation with an emphasis on confinement rather than treatment or care. More patients than ever were admitted to Goodna and no other solution to the treatment of mental illness was even considered possible.\n\nEllerton was succeeded as Medical Superintendent by Dr Basil Stafford, the former Superintendent of Ipswich Mental Hospital. Ellerton's retirement provided the opportunity to review the entire mental health system in Queensland and in particular, Ellerton's total commitment to \"moral therapy\". By the late 1930s psychiatry was a well-established specialty internationally, though still in its infancy in Australia and Stafford was alert to the changes psychiatry was bringing to the treatment of mental illness. In 1937 he was sent by the Queensland government to attend the 2nd International Congress on Mental Hygiene in Paris and on a study tour of hospitals, psychiatric clinics and universities in the United States, Europe and the United Kingdom.\n\nOn his return, Stafford recommended various changes to the mental health system, including the implementation of new legislation. These recommendations led to the Mental Hygiene Act of 1938, which closely resembled the British Mental Treatment Act of 1930. The hospital was again renamed the Goodna Mental Hospital and the hospital was reorganized into two units, one for the chronically ill requiring a secure environment and the other for acute and recovering patients.The Mental Hygiene Act of 1938 brought a focus on prevention and cure through voluntary treatment. Until this time hospitals such as Goodna received only certified patients, most of whom were sent there under a Magistrate's order. However, the transition to a less coercive approach to treatment occurred slowly and in 1947 Stafford reported that only 34 of the total 570 patients had been admitted under the voluntary provisions of the Act.\n\nThe ideas of modern treatment introduced by Stafford emphasised the development of a comprehensive psychiatric approach with adequate numbers of qualified medical staff. Insanity was seen as a disease of the brain and like any other disease required hospitalisation of patients and treatment with drugs. He noted:\"Modern treatment demands exhaustive mental and clinical case histories, as well as completely thorough physical examination. This cannot be done by a skeleton staff, however willing\".This approach also brought degrees of specialisation among the staff and hospital procedures. Stafford advocated the separation of chronic wards from those dealing with admission, convalescence and hospital cases. He believed that mental illness \"demands active therapy, and treatment must not become merely custodial\" and urged the use of new types of treatment such as insulin, cardiazol and electrotherapy.\n\nThe first building at Wolston Park to reflect Stafford's modern ideas was Dawson House, a new female building completed in 1944. It provided accommodation for 60 patients and was located on a sloping site close to the existing female wards. It was recognised that a building with a basement could be built on such topography, with the basement accommodating treatment rooms for cardiazol therapy, insulin therapy, malaria therapy, somnifaine or continuous narcosis therapy and other medical treatments. The most striking difference was that minimal attention was given to the outside environment - this building was inward-looking, signalling the demise of the significance placed on the environment in \"moral treatment\" and the increasing medicalisation of the treatment of mental health. Another important building project for female patients at this time was the construction of a special female recreation facility, which commenced in 1951 on an area of approximately 2.5 hectares on the western edge on the reserve, adjacent to the Brisbane River. The principal building within the area was the cafeteria with facilities to serve 500 patients (now Wolston Park Golf Clubhouse). Patients could spend the whole day in the recreation area without needing to return to the wards for midday meals. Other facilities in the area included a sewing room, tennis court, bowling green, a large playing field, viewing shelters and storage sheds. By 1957 more than 200 patients were regularly using the facilities, highlighting the rigorous separation of patients according to gender that operated in all facets of the institution.\n\nBy January 1942, 110 returned soldiers were inmates of Goodna Mental Hospital and the Australian Government expressed concern about the growing numbers being admitted. War veterans had become a significant minority of the hospital population since the final years of the First World War and Ellerton had decided upon consideration, that using existing institutions was preferable to building new facilities. During the Second World War, however, the Australian Government agreed to fund the construction of three special wards, with the Queensland Government agreeing to responsibility for the maintenance of the buildings and for staffing. Plans for a complete repatriation unit were prepared by the Works Department in consultation with Basil Stafford. Their design essentially resurrected the principles of \"moral treatment\" - the buildings were designed to minimise the sense of confinement associated with mental hospitals and freedom was emphasised by wide verandahs and dining areas opening onto grassed courtyards and lawns. Construction of the wards began in 1946, and the Wacol Repatriation Pavilion was opened by Queensland Governor John Lavarack on 26 January 1948. It comprised three wards each with accommodation for 88 patients and a kitchen/canteen block. A recreation hall was erected in 1950 and a cricket oval in 1954.\n\nIn the late 1940s, planning began for a new farm ward complex. Farm wards at the hospital had traditionally operated as semi-independent units where patients enjoyed greater levels of freedom and autonomy, unlike the main wards where people were locked in their cells or wards. A new site on the summit of a hill adjacent to the existing farm wards was chosen and two large wards with accommodation for 175 patients and a dining/recreation block were erected between 1953 and 1957. Patients included both \"backward persons\" and people who had responded well to treatment and had the potential for recovery and discharge. In 1958, part of the farm ward complex was set aside for patients regarded as \"subnormal\" and in 1964 a five teacher school was established to teach the 160 children who lived there. Gradually, all of this block became occupied by intellectually disabled children and was renamed the Basil Stafford Centre. In 1965 a new alcohol rehabilitation centre was also established, making use of the old farm ward buildings at the northern end of the site. Alcoholics had been patients at Wolston Park since the Inebriates Act of 1892 had allowed for their admission to designated institutions; however, there had been no specific facilities for them. New buildings were erected adjacent to the former farm ward including four wards, offices and an occupational therapy area. The new centre was known as the Wacol Rehabilitation Centre. Initially it served both male and female patients; later a separate complex was built for female patients requiring treatment for alcoholism (Melaleuca House and Poinciana House).\n\nThe hospital population peaked in the mid-1950s, with an average of approximately 2500 residents daily (not including Wacol Repatriation Pavilion patients) and 700 staff.\n\nBy the late 1950s the efficacy of large-scale, all-purpose institutions for the treatment of mental illness began to be questioned. It was recognised that patients became institutionalised to the extent that living in large institutions perpetuated their mental disorders and did not assist them to recover. The Division of Mental Hygiene embarked on a program of expanding acute psychiatric beds in general hospitals and transferring elderly senile patients from mental hospitals to nursing homes. This resulted in a decline in the number of patients at Goodna and in 1960, Director Basil Stafford was able to report that, for the first time, the hospital had an excess of beds. The complex, renamed the Brisbane Mental Hospital, began to develop a different role. No longer did it cater for every type of patient from every part of the Queensland; instead the majority of inmates were long-term chronic patients. The new Mental Health Act of 1962 placed a greater emphasis on voluntary admission and the complex became known as the Brisbane Special Hospital. In 1969, it was renamed Wolston Park Hospital.\n\nIn 1976 the Minister for Health released a paper on the Care of the Intellectually Handicapped, which proved to be the catalyst for significant changes in the delivery of mental health services. A special Branch of Intellectually Handicapped Services was established within the Health Department in 1977, which took responsibility for the Basil Stafford Centre. Research into the long-term effects of institutionalisation and the lack of success in the treatment and care provided in institutional settings led to critical questioning of the institutional model for both mentally ill and intellectually and physically disabled people. In addition, the increasing criticism of conditions within mental hospitals and the abuse of patients' rights gave impetus to the development of alternative models, in particular, community-based mental health services. The community care model was adopted slowly in Queensland. Institutions were reformed, however, an emphasis on institutional care remained.\n\nShort-term care with intensive treatment was the preferred model. Several major building projects, which reflected these changing ideas, were undertaken at Wolston Park during the 1970s, as well as extensive re-modelling of existing structures. In 1978, the Barrett Psychiatry Unit was established to provide acute care. It comprised eight separate buildings, a reception and admission block, three wards with 32 beds, two wards with 16 beds, cafeteria and medical officer's flat. In 1984 it expanded to include inpatients and specialised services for young people. A new medical centre opened in 1979 and in 1980 Nyunda Park was set up as an outdoor recreation area. The John Oxley Centre, a forensic psychiatric unit, was built at the eastern side of the site next to the Brisbane River in 1990. A number of the 19th century buildings were demolished in the 1970s and 1980s, with renovation and rehabilitation of other remaining 19th century buildings occurring in the late 1990s.\n\nIn 1989 the John Oxley Memorial Hospital, a special purpose secure psychiatric facility, was opened on the grounds of the Wolston Park Hospital; it has since been demolished.\n\nAs part of the 1996 Ten Year Mental Health Plan for Queensland, the main hospital became known as The Park Centre for Mental Health and has decentralised its extended care services with a greater emphasis on rehabilitation and recovery. The Park now provides clinical treatment and rehabilitation programs to patients from central and southern Queensland, including care for people with a chronic mental disorder and for people with a mental disorder who are also intellectually disabled, forensic care services and an extended treatment service for adolescents.\n\nFrom 1999 to 2002 many new buildings were erected, including a large new maximum-security facility at the eastern edge of the site. Most of the new buildings are domestic in scale and character and include accommodation for patients and medical and administrative facilities. Some replace buildings erected during the 1970s, such as parts of the Barrett Psychiatric Centre.\n\nIn 2001 the hospital was renamed The Park Centre for Mental Health Treatment, Research & Education.\n\nThe Wolston Park Hospital Complex comprises a number of public health institutions, several of which have been decommissioned. The complex includes The Park Centre for Mental Health (former Wolston Park Hospital), Basil Stafford Centre, Wacol Rehabilitation Centre (male and female), Wacol Repatriation Pavilion, Barrett Psychiatric Centre and the John Oxley Centre. Sections of the reserve are leased to the Gailes Golf Club and the Wolston Park Golf Club.\n\nThe site can be divided into the following major elements: Central administration area; Services support area; Former residences; Male area; Female area; Female recreation area; Wacol Repatriation Pavilion; Wacol Rehabilitation Centre; Basil Stafford Centre; Nyunda Park/riverbank area and the Grounds in general.\n\nThe central administration area includes the Administration building, the Former Hospital, Pump houses and reservoir, Chapel, and Visitor's Pavilion.\n\nThe Administration Building (1917) is a two-storeyed brick building with a terracotta-tiled roof, decorative fleche and brick chimneys, designed to be the centrepiece of the institution. Arts and Crafts influences are evident in the massing of the hipped roof forms and the use of unpainted brickwork contrasting with coloured roughcast plaster above sill height. The main entrance on the eastern elevation features an arched port cochere, adjacent to an oval driveway with formal landscape elements, including plantings of cycads. The entrance is given greater prominence by two tower-like wings with separate hipped roof located on either side of the port cochere. There is a verandah on the ground floor on the western elevation with brick and timber piers and stairs located both centrally and at each end. Internally the building comprises office accommodation arranged off central hallways with regular arched partitions. The rooms generally have plastered masonry partition walls with timber joinery. The building has a central timber staircase and some stained timber and glass partition walls. An Honour Board is located in the entry hall on the ground floor.\n\nThe Former Hospital (1917) is located to the north of the Administration Building, across grassed terraces built by patients. It is a low-set, single-storeyed, symmetrical brick building with hipped terracotta-tiled roofs and a decorative fleche, sympathetic in design to the Administration Building. The entrance is marked by a projecting entry bay with gable roof and the wings of the building extend to either side. A slightly elevated verandah with brick and timber piers runs the length of the front elevation of the building and floor to ceiling multi-paned sash windows are located along all walls. Small windows are also located above the verandah roof and below the eaves of the main roof. The rear of the building has five small projecting wings, some no more than the size of a single room. The central projecting wing is the largest. It was the former operating room and has a five-sided projecting bay with large windows in each section. Timber sash windows with concrete sills and lintels are found throughout the building. The interior of the building contains office accommodation for clinical staff.\n\nThe pump houses and reservoir (1914) are located adjacent to Ellerton Drive, the principal access to the administration area. There are two timber pump houses, an elevated water reservoir and a second smaller reservoir. The northern pump house (1914) located closest to the road is sheeted with pine chamferboards and has vented semi-circular openings above all its windows. It has a hipped corrugated steel roof with exposed rafters and no gutters. The second pump house (date unknown) is located to the east and sits beneath a large tree. It is a smaller building, clad in timber weatherboards and has a pitched corrugated steel roof with galvanized iron awnings over two windows. Both pump houses are empty. The main reservoir (1914) is constructed of rendered brickwork approximately deep, enclosed by a structure consisting of high cast iron columns which support an open, lattice-framed perimeter truss. The truss supports a timber framed roof structure and the entire structure is clad on both the roof and walls in corrugated galvanized iron.\n\nA Visitor's Pavilion (1920) is located further along Ellerton Drive, on the same side as the pump houses and reservoir but closer to the Administration Building. It is a small, low-set, hexagonal timber structure accessed by a short set of timber steps. The entry is a small projecting bay with a pitched roof, decorative timber mouldings, lattice and balustrade. The building is clad in timber weatherboards, has timber framed windows and a painted corrugated steel roof with decorative finial.\n\nOne chapel building (formerly the Chapel of Hope, 1961) remains of the three chapels originally erected around a ring road about east of the Administration Building. It is a simple, box-like structure with a low-pitched roof and wide eaves. It is of portal frame construction and is clad in corrugated Colorbond steel sheeting. The building is now semi-integrated with a new building built on its western side. A tall, steel, open-frame tower is located on the eastern side of the front elevation. A statue of St Dymphna (the Catholic Patron Saint of the Mentally Ill) is located about to the east.\n\nThe Services Support Area comprises the Recreation Hall, Laundry, Power House and Morgue and is located to the west of the Administration Building.\n\nThe Recreation Hall (1890) is a symmetrical rectangular brick building with a pitched roof. The front elevation has a central elevated doorway surmounted by a decorative circular window with coloured glass and quoins accentuated in light, contrasting brickwork, a decorative detail that is repeated around the windows and doors. The building has a large central hall area with separate wings running down each side. The central hall space has a partly-lined raked ceiling from which the lower members of the roof trusses protrude and a timber floor. There is a raised timber stage at the southern end with a proscenium arch with decorative Ionic pilasters on either side. A projection room is located at the northern end of the hall. Dark brick additions with flat roofs run the full length of the building on both the east and west elevations and accommodate smaller recreation rooms and a kitchen.\n\nThe Laundry (1918) is a large single-storeyed brick building on concrete foundations, with a concrete floor. Its architectural details show an Art and Crafts influence. The building has four large gabled roofs, each of which has two raised roof lanterns that allow light to penetrate the large interior spaces of the building. Externally, the building sits on a face brick plinth with roughcast stucco, painted pale yellow, above the windowsill level. The southern elevation is characterised by striking sets of windows under each gable - each section has a large central window with arched head and side windows, all highlighted with contrasting brick surrounds and accentuated keystones. A flat roofed verandah is located on the western elevation and is accessed by a concrete ramp. There are also a series of large timber double doors and sets of louvres along this elevation. The eastern elevation runs parallel to the street and has regular sets of tall windows grouped in threes. The interior of the building has large concrete pillars supporting exposed timber roof trusses. Recent offices, meeting rooms and conference rooms have been constructed within the building and are enclosed with plasterboard partitions. A canteen is located in the northwestern corner of the building.\n\nThe Power House (1917) is an imposing red brick building with a substantial, octagonal brick chimney at its northwestern corner. It has two steel-trussed gabled roofs clad in corrugated galvanized iron with raised vented roof lantern running the length of the building. It is built on concrete foundations and contains Babcock & Wilcox tube boilers. Regular arched openings are on all sides of the building; some have sets of nine windows and others have doors. All the arches are highlighted externally by the use of bricks of a slightly deeper red tone. Circular windows are located in the gable ends on the northern and southern elevations. The upper floor has recently constructed offices, built as a free-standing series of rooms within the larger interior space of the building. These offices are constructed of plasterboard. Some internal walls are finished to a height of six feet with white enamelled brick with green trim. The huge boilers and other engineering equipment are located on the ground floor.\n\nThe Morgue (1902) is a low-set single-storeyed brick building situated below the Power House, to the north. It has a simple rectangular plan form with a hipped corrugated iron roof with a small decorative fleche. A lean-to structure with large timber doors on the western end of the building is a hearse shed. The building has large openings with concrete lintels and sills, with boarded-up openings.\n\nThe former Medical Superintendent's Residence and Assistant Medical Superintendent's Residence are located at the eastern edge of the site.\n\nThe former Medical Superintendent's Residence (1898) is now situated within the strongly fenced, high security area of the complex and is used as office accommodation. It is a substantial low-set brick residence with a corrugated steel roof. It has an asymmetrical plan with projecting bay windows and complex verandah forms. The eastern elevation has two projecting verandah wings with multi-faceted roofs and tall brick chimneys. The verandahs have timber balustrades, columns and decorative capitals. Two service wings extend from the rear of the building. The residence has a generous entrance hall, several marble fireplaces and high quality timber joinery throughout the interior.\n\nThe Assistant Medical Superintendent's Residence (1912) is located to the east of the former Medical Superintendent's Residence. It is a large timber dwelling set on stumps, with a hipped corrugated iron roof and extensive verandahs. The interior has timber joinery, two fireplaces and pressed metal ceilings in the major rooms. Mature palm trees are formally set around the house and both residences are surrounded by terraced lawn areas. A concrete garden stair is located to the south of the former Assistant Medical Superintendent's Residence, leading to an unfenced former tennis court.\n\nThe Male Area is an extensive area with a number of buildings grouped around the large Recreation Grounds. Lewis House, McDonnell House, Noble House, Osler House and Pearce House are all located along Barrett Drive to the west of the cricket oval. Fleming House, Gladstone House, Jenner House, Kelsey House and a former male bathroom are all located at the southern end of the oval.\n\nFleming House (1898) is a two-storeyed building located at the southeastern corner of the cricket oval, amongst lawns and mature trees. It is constructed of light-coloured brick with narrow bands of red bricks at sill level on both floors and at the upper floor-line. It has a hipped roof with boxed-in eaves and decorative timber brackets. A detached bathroom building (1920) is centrally located on the southern elevation; it has a pyramid roof with a raised central roof lantern and a lean-to addition at the rear with a brick chimney. There is a verandah on the ground floor on the northern side, overlooking the cricket oval. A centrally-located metal staircase dominates this elevation of the building. Narrow casement windows with concrete sills and lintels are found on all elevations.\n\nGladstone House, Jenner House and Kelsey House (all 1936) are located to the east of Fleming House and are nearly identical in form, scale and detail. Like Fleming House, these buildings are situated to overlook the cricket oval. The buildings are all single-storeyed brick buildings with unusual crab-like plan-forms, set within gardens enclosed with low wire fences. The gardens are mostly lawn with mature trees such as Poincianas. The central portion of each building comprises a large dining/day room with service facilities such as kitchens and bathrooms to the rear. The four wings of each building contain dormitories and single rooms. Each of the dining rooms has a large roof lantern with fixed glass panels that allow natural light to penetrate the room. Each of the buildings has terracotta tiled roofs and large casement windows which have aluminium security screens fitted on the outside.\nLewis House, McDonnell House and Noble House (all 1915) are ward buildings of similar design, located along Barrett Drive. On the eastern side the buildings overlook lawns and the cricket oval. A service road runs along the western side and the surroundings of the buildings are paved in concrete with a raised garden strip containing mature trees between the buildings and Barrett Drive. Lewis House is situated between Kelsey House and McDonnell House and is a substantial two-storeyed rendered masonry building with a terracotta-tiled roof. It has gabled roofs with parapetted gable ends and subtle quoins on the upper floor. The southern elevation has a projecting wing with pyramid-roofed pavilions at each corner and small square windows. The rest of the building has large casement windows throughout and is smooth rendered to sill height on the second floor and roughcast above. A short verandah with vertical timber louvres is located on the ground floor of the eastern elevation. McDonnell House is situated between Lewis House and Noble House. It is also two-storeyed and constructed of masonry but is more rectangular in plan with three short wings projecting on the western elevation. It has a large gabled roof and gabled roofs on the western wings, all of which have overhanging eaves. The roof is clad in dark concrete tiles and the building is rendered smooth up to sill height on the second floor, above which it is roughcast. There are two ground floor verandahs on the eastern elevation overlooking the cricket oval, either side of a central projecting gable. Noble House is almost identical to Lewis House but a concrete tiled roof has replaced the terracotta roof and it has a longer verandah on the ground floor on the eastern elevation.\n\nOsler House (1928) and Pearce House (1934) are one-storeyed ward buildings and are virtually identical in design. They are located adjacent to Noble House, at the northern end of Barrett Drive. The buildings are brick with terracotta-tiled gabled roofs. The eastern part of each building is an elongated U-shape in plan, with two substantial rear wings running at right angles to the U. The eastern elevations have ground floor verandahs which have sheet steel barriers erected along the roofs to prevent patients from climbing onto them. Roof lanterns are located above the central hallway of the rear wings and are visible from the outside of the building although they are closed-in by recent false ceilings in the interior. The gardens are enclosed by tall wire security fences.\n\nThe Recreation Grounds is a large expanse of open space, around which the buildings of the male section are grouped. The cricket oval (1895) is the focus of this area. It is a large grassed oval with terraced edges planted with mature trees and lawn. Tennis courts, bowling green (1951), bowling green clubhouse (1968) and plant nursery (original bush house established 1911) are located at the northern end. The Cricket Pavilion (1910) is located at the southern corner of the cricket oval. It is a small hexagonal building with a rectangular wing with gabled roof located at the back. A small timber toilet block is located at the rear of the building. The hexagonal section is surrounded by a verandah with turned timber posts and dowel balustrade. It is of single-skin timber construction with timber chamferboards and exposed bracing. The roof has decorative finials and a small gable is located above the short entry stair.\n\nThe Female Area comprises Female Wards 1&2, Anderson House, Bostock House, Dawson House and a former female bathroom.\n\nFemale Wards 1&2 (1866) is a large, two-storeyed timber and masonry building located on a ridge between Ellerton Drive and the Brisbane River. The core of the building is sandstone with a number of large timber and brick additions. The sandstone core is long and rectangular in plan with a projecting two-storeyed bay with timber verandahs on the south elevation. Two elevated brick pavilions (bathhouses) with raised roof lanterns, concrete floors and supporting posts are located either side of the projecting bay. Three-storeyed brick additions are located at each end of the building. These have corrugated iron roofs with small roof lanterns and regularly spaced sash windows. The main section of the building has three separate roofs, all corrugated iron. The largest is a hipped roof at the northwestern end; the central roof is a pyramid; and the southeastern roof is a smaller hip. A wide timber verandah with a skillion roof runs the length of the north elevation at both levels and returns around at both the eastern and western ends of the building. It is enclosed with timber shutters on the top storey and has an arched timber valance and timber posts at ground level. Sections of the verandah at the western and eastern ends have been enclosed with timber weatherboards. The sandstone part of the building has narrow, multi-paned sash windows and timber doors with fanlights. The interior of the building is gutted and only the timber floor joists and cast iron columns remain. A small Shelter Shed (1929) is located to the south of Female Wards 1&2 and was used to separate troublesome patients from the main wards. It is a brick structure with a concrete floor and fireplace and a gabled corrugated iron roof. A tall timber picket fence encloses the yard adjacent to the shed.\n\nAnderson House (1917) is located on Ellerton Drive, northeast of Female Wards 1&2. It is a single-storeyed, brick building with a hipped terracotta-tiled roof and a decorative fleche. The building is domestic in scale. It has a timber verandah with a skillion roof along the front elevation and has tall sash windows throughout. Its front garden is enclosed with a short wire fence and is dominated by a large spreading Poinciana tree. A small timber residence is located to the south of Anderson House. It is clad in weatherboards with a painted, corrugated steel roof. The front (eastern) elevation has a single gable roof and a small verandah.\n\nBostock House (1885) is located to the north of Anderson House and is also orientated to face Ellerton Drive, although it is set back within extensive lawns. It is a substantial two-storeyed building of polychromatic brickwork, with a projecting bay topped by a gabled roof on the north elevation, with ground floor verandahs located to either side. A circular window is located in the gable end. The main hipped roof and subsidiary roofs are all clad in corrugated iron. At the northern end of the building are two, single-storeyed attached pavilions; one is five-sided like a large bay window, the second is square with a pyramid roof. The southern end has a single-storeyed extension with roof lanterns. A two-storeyed timber, enclosed verandah with skillion roof is located at the rear of the building.\n\nDawson House (1944) is a sizeable brick building of two storeys with a basement, located on a sloping site behind Bostock House. The building is orientated to the north and is H-shaped in plan. The basement level is rendered and painted, while the rest of the building is dark face brickwork, harmonious with other brick buildings on the site. It has rendered strips painted cream which wrap around the building at the height of window sills and heads. The facade is symmetrical with pared-back classical architectural detailing around entry doors and some sets of windows. Each floor of the building has long central hallways with rooms of various sizes to either side. The building has two interior staircases, a lift and an external concrete fire escape stair. Windows throughout the building are multi-paned sash windows with painted cast iron security grills at low level.\n\nA small brick building with a hipped roof is located between Dawson House and the Recreation Hall, which was originally built as a female bathroom (1902) but is now known as Dawson House Annex.\n\nThe former female recreation area is situated in the western corner of the site. The area is bounded by Woogaroo Creek to the south and the Brisbane River to the north and is visually separated from the main hospital complex by bushland and mature plantings. Most of the area is now part of Wolston Park Golfcourse. The major building in the area is the cafeteria (1955, now golf clubhouse), a low-set brick building with a hipped roof and brick chimney. It overlooks the grounds and the river and has a lightweight steel roof over a terrace on the north elevation. A bowling green, shelter shed and tennis court are located to the north of the building.\n\nThe Wacol Repatriation Pavilion comprises Wards A, B and C, Kitchen Block, Recreation Hall and Recreation Grounds and is located between Barrett Drive and Wolston Park Road.\n\nWards A and B (1948) are two similar U-shaped blocks that back onto Wolston Park Road. They are constructed of cream brick with hipped, corrugated colourbond steel roofs with boxed eaves. The wings of the buildings enclose grassy courtyards, which are surrounded by verandahs. The Kitchen Block (1948) is located in the middle of the Wacol Repatriation Pavilion complex, between Wards A and B. It is two-storeyed and is constructed of the same cream brick with corrugated colourbond steel roof with fleche. It has an open-fronted canteen at the front of the building (facing northeast), opening via folding timber doors onto a terraced lawn area. The rear of the building is accessed by a service driveway from Wolston Park Road. Ward C (1948) is H-shaped in plan and is also constructed of cream brick with a hipped, corrugated colourbond steel roof. It is located at the end of Barrett Drive and has a roofed terrace on the northwest elevation. The Recreation Hall is located to the north of Ward C. The grounds consist of a mix of evenly-sloped lawns with trees randomly planted between the buildings. Clumps of Oleander bushes are formally spaced along both sides of the lower entry drive. A cricket oval (1954-5) is located to the southeast of the complex. The cricket oval has a white painted picket perimeter fence and a timber sight-screen.\n\nThe former Wacol Rehabilitation Area (now used by the Department of Corrective Services) is located in the northernmost portion of the site and comprises physically separate male and female sections, with the male section occupying former Farm Ward buildings. These consist of Quarter Way House, Farm Ward and Farm Sheds.\n\nQuarter Way House (1918) is a timber residence erected for the farm overseer. It has a front verandah and rooms are accessed from a central hallway. The former Farm Ward (1916) is a largely timber building with a central core of brick that includes a brick fireplace. It has a small brick ablutions block at the southwest corner. The verandahs are enclosed with glass louvres and the interior is lined with Masonite. Two Farm Sheds (1916) are located across a road to the north of the former ward. They are timber-framed and clad in corrugated galvanized iron.\n\nThe Basil Stafford Centre is located in the northern portion of the site and comprises the former Farm Ward Block, a school building and villa-style accommodation.\n\nThe former Farm Ward Block (1957) is a one and two storeyed, brown brick building with four distinct sections. Ward A occupies the single-storeyed section and Ward B is partly two-storey. The central part of the building contains the service areas. The building has hipped corrugated fibre-cement roofs and high level, multi-paned sash windows throughout. The grounds of the building are landscaped with open terraces paved with stone from the hospital quarry. A concrete water tower is prominently located at the crest of the hill, adjacent to the former Farm Ward building.\n\nThis area comprises a mix of open and enclosed bushland, a dam, picnic facilities adjacent to the dam, the John Oxley Centre and remnants of a sandstone quarry.\n\nThe John Oxley Centre (1990) is a low-set one-storeyed building clad in fibre-cement with a corrugated steel roof. The building is vacant and is surrounded by tall wire fences. Nyunda Park is an unused area of bushland with a large dam. There are two former sandstone quarry sites in this area, one of which is partly submerged by the dam. The second is adjacent to the riverbank and evidence of workings remain.\n\nTwo golf courses form the perimeter of the hospital complex along the southern and eastern edges. The Gailes Golf Course extends around the hillside between Wilruna Street and the railway line, the recent high security development at the eastern side of the site and the Wacol Repatriation Pavilion. The Wolston Park Golf Course is situated on the gently sloping hillside south of the Central Administration area and includes the land cleared between Woogaroo Creek and the female recreation area. The golf courses maintain the spacious, natural and open landscape setting of the complex. The site of the 1860s graveyard associated with the establishment of Woogaroo Asylum is located at the far western end of what Wolston Park Golf Course, and is a site of potential archaeological interest.\n\nThe rest of the grounds consist of a mix of open space areas with extensive lawns, clumps of scrub and numbers of mature trees. Formal gardens are found in the immediate environs of many of the buildings. Ellerton Drive is the formal road through the grounds from the Goodna entrance to the site and is flanked by an avenue of trees. The lower portion of the drive is lined with elms (Celtis sinensis), the middle portion alongside the reservoir is lined with Hoop pines and Bunya pines and the top end of the drive is planted with large pines. The road has sandstone kerbing.\n\nThe hospital currently can accommodate 192 patients through five clinical treatment and rehabilitation programs:\n\nThe hospital does not provide emergency medical services, the closest general hospital is the Ipswich Hospital.\n\nWolston Park Hospital Complex was listed on the Queensland Heritage Register on 21 October 1992 having satisfied the following criteria.\n\nThe place is important in demonstrating the evolution or pattern of Queensland's history.\n\nAs the earliest and best-known public institution providing care and treatment for mentally ill and intellectually disabled people in Queensland, Wolston Park Hospital Complex is important in demonstrating the evolution of Queensland's history. The Woogaroo Asylum was founded by the Queensland government as the first publicly-funded, mental health institution in the colony in the early 1860s and by the 1950s became the largest such institution not only in Queensland, but in Australia. The provision of health and welfare services was regarded as the responsibility of charitable and religious organizations in the 19th century; the care and treatment of mental illness was the one exception, thus the Wolston Park Hospital Complex demonstrates the role of the state in the care of mentally ill people since the 1860s. It demonstrates the changing practices in the treatment of mental illness: from a 19th-century asylum founded on confinement and separation, through moral treatment or therapy from 1909 to the 1930s, the drug and medical therapies of the 1940s (Mental Hygiene) and 1960s (Psychiatric Services) to the trend towards deinstitutionalization and community-based services by the 1980s. The physical evolution of the site highlights these changes as the complex has developed incrementally across the substantial 450hectare reserve, rather than intensively in layers in one area. The site is also significant in demonstrating the development of specialist mental health services for returned service personnel and intellectually disabled people.\n\nThe place has potential to yield information that will contribute to an understanding of Queensland's history.\n\nThe site of an early graveyard at the western end of what is now the Wolston Park Golf Course, near the confluence of Woogaroo Creek and the Brisbane River and associated with the first asylum buildings on the reserve, is an area of archeological interest with potential to yield information that will contribute to an understanding of Queensland's history.\n\nThe place is important in demonstrating the principal characteristics of a particular class of cultural places.\n\nWolston Park Hospital Complex demonstrates the principal characteristics and evolution of a major public health institution. The expansive grounds and distinctive groups of buildings at the complex evoke a strong sense of place. The self-contained nature of the place is reflected in the range of buildings and facilities on the site including ward accommodation, health and hospital facilities, administration buildings, staff quarters, recreation facilities, chapels and service buildings such as kitchens, laundries and a powerhouse. The grounds and landscaping are also important elements with recreation and agricultural facilities demonstrating the role of useful employment and recreation in the hospital's operations. The relationships between the buildings and other site elements are fundamental to our understanding of the functioning of the place as a mental health institution since the 1860s.\n\nA substantial number of buildings, structures and grounds elements survive from each major phase in the development of the institution.\n\nSignificant 19th century elements include Female Wards 1&2 (1866), Bostock House (1885), the Recreation Hall (1890), Fleming House (1898), the former Medical Superintendent's Residence (1898) and the recreation ground (1895, redeveloped into cricket oval in 1910). The remnants of a sandstone quarry along the riverbank dates from the 1860s and was one of the first sandstone quarries developed in Queensland.\n\nEarly 20th century elements include the three male blocks Lewis House (1915), Noble House (1915) and McDonnell House (1915), former male and female bathroom blocks (1902), the female ward Anderson House (1917), the former hospital ward block (1917), the Administration Building (1917) and the assistant Medical Superintendent's residence (1912); service facilities such as the morgue (1902), the reservoir (1914), pump house (1914), powerhouse (1917) and laundry (1918) and recreation facilities such as the cricket oval (1910) and the Cricket Pavilion (1910). Significant elements of the former farm ward complex include the Farm Ward (1916), two farm sheds (1916) and Quarter Way House (1918).\n\nImportant elements from the capital works program of the 1920s and 30s include the Visitor's Pavilion (1920), Osler House (1929), the shelter shed at the rear of Female Wards 1&2 (1929), Pearce House (1934), Kelsey House (1936), Gladstone House (1936), Jenner House (1936) and the Gailes Golf Course (1922–25).\n\nPostwar elements include Dawson House (1944), the Female Recreation Area encompassing the cafeteria (1955), workroom (1950) and shelter sheds (1955). The remaining chapel (1961) demonstrates the provision of religious services and chaplaincy at the complex. Significant elements of the Wacol Repatriation Pavilion established post World War Two include Ward A (1948), Ward B (1948), Ward C (1948), kitchen and canteen (1948), and Recreation Hall (1950). The former Farm Ward Block (1957), now part of the Basil Stafford Centre, is also important.\n\nThe place is important because of its aesthetic significance.\n\nThe Wolston Park Hospital Complex is important because of its aesthetic significance, which derives from the massing, architectural form and detailing of the buildings, the relationships between the buildings and the interplay between the buildings and the landscape and grounds.\n\nThe aesthetic impact of the complex is heightened by its location on the top of a hill and its setting within extensive grounds that have a distinctive, natural landscape character. The complex includes a range of architectural styles and forms; from modest timber visitor pavilions through to imposing brick ward and administration buildings. Care in the design of hospital buildings and grounds reflects efforts to mitigate the stigma attached to mental illness, while at the same time the substantial and formal character of many of the buildings demonstrates strong State control and regulation of mentally ill people in Queensland.\n\nThe place has a strong or special association with a particular community or cultural group for social, cultural or spiritual reasons.\n\nWolston Park Hospital Complex is the longest operating mental health facility in the State and a distinct culture has developed around the institution. As such, Wolston Park Hospital Complex has a strong and special association for the Queensland mental health community including staff, patients, families, friends and advocates, both past and present. The complex also has social significance for the Queensland community in general, being synonymous with the treatment of mental illness in the State.\n\n\n"}
{"id": "6654528", "url": "https://en.wikipedia.org/wiki?curid=6654528", "title": "V. T. Sambanthan", "text": "V. T. Sambanthan\n\nTun Thirunyanasambanthan s/o Veerasamy (; 16 June 1919–18 May 1979) also known as V.T. Sambanthan, was the fifth President of Malaysian Indian Congress and one of the Founding Fathers of Malaysia along with Tunku Abdul Rahman and Tan Cheng Lock. He was the MIC President from 1955 to 1973, when he was ousted by party members.\n\nSambanthan was one of the leading Indian leaders who played a prominent role in the independence movement in Malaya. As president of the Malayan Indian Congress (MIC) during this important period of transition, he worked closely with Alliance Party leader Tunku Abdul Rahman and they developed a close personal bond.\n\nHe is credited with three important developments in Malaysian political history: the consolidation of the Malayan (now Malaysian) Indian Congress, its transformation into a mass-based party, and its integral role as a partner in the current ruling alliance.\n\nThe entry of the MIC into the multi-communal Alliance in 1955 contributed greatly to enhancing the coalition's image as the main representative of the three main communities in Malaya.\n\nThe finest hour was achieved on 31 August 1957 when Independence was achieved under the Merdeka Agreement, to which Sambanthan was a signatory.\n\nSambanthan was born in Sungai Siput in 1919. His father, M.S. Veerasamy, came to Malaya in the 1896, was a pioneer rubber planter in Sungai Siput, Perak and owned several rubber plantations. His siblings are V. Meenachi Sundram, V. Krishnan and V. Saraswathy .\n\nSambanthan received his early education at Clifford High School in Kuala Kangsar, Perak. A keen sportsman, Sambanthan was an intelligent student who loved to chat and joke.\n\nSambanthan, with the intention of creating a more cohesive and unified Indian community, organised the Perak United Indian Council in 1953, the same year he was elected Perak MIC chairman.\n\nHowever, the event that helped catapult Sambanthan to the forefront of MIC politics was a visit by Vijaya Lakshmi Pandit, the younger sister of the then Indian prime minister Pandit Jawaharlal Nehru. Sambanthan had befriended her when he was involved with the Indian National Congress while studying at Annamalai University.\n\nOn his invitation, she visited Malaya in 1954 and despite the ongoing communist insurgency, visited Sungai Siput where she officially opened the Mahatma Gandhi Tamil School. The meeting between Sambanthan and Vijaya Lakshmi in 1954 helped push the former into the limelight and then on to the party president's position in 1955\n\nIn the same year, he was elected member of the legislative council for the Kinta Utara constituency. The constituency was renamed in 1959 as the Sungai Siput seat.\n\nIn the post World War II period, the Indian professional elite was largely held together by the unifying ideology of Indian nationalism. In 1946, the Indian elite in Malaya formed the MIC. For the first eight years, the MIC leaders were either North Indian or Malayalee, representing a minority among the Indians. The majority of Indians (90%) in Malaya at that time were South Indians, mainly from the labouring class.\n\nThe Emergency (declared by the British in 1948 to battle communist insurgency) regulations and new trade union legislation also led to the leadership of the trade union movement passing from the Chinese, who were much better organised, to the Indians. This dilution of the MIC's objectives affected the status of Indian plantation workers in the Malaysian economy then and its repercussions are still being felt today.\n\nIn 1954, there were serious debates within the MIC as to whether the partys should join the UMNO-MCA Alliance that was emerging as the leading political movement in the country, following their successes in local elections. The MIC had aligned itself with Datuk Onn Jaafar's Independence of Malaya Party and later Party Negara, and there was a rethink within the MIC leadership during this period.\n\nAccording to Rajeswary Ampalavanar, author of The Indian Minority and Political Change in Malaya 1954–1957, the MIC leadership was quite eager to join the Alliance but there was some resistance within the party's broader membership. They were willing to support the move if the party could secure some concessions from the Alliance on inter-communal issues, particularly on education.\n\nThen MIC president K.L. Devaser came under heavy criticism from the Tamil media for not addressing the pressing issues facing the community. While he was quite outspoken, his influence was largely among the urban-based Indian elite and he lacked wider grassroots support.\n\nSome in the party felt that there was a need for a leader with a stronger relationship with the party's grassroots. In March 1955, reports in the local daily Tamil Murasu urged Tamils to boycott the MIC.\n\nSambanthan, then a state MIC leader, emerged during this period as an alternative candidate for the party leadership. Going by historical records, he was literally coerced into taking up the presidency. Another candidate, P.P. Narayanan, was approached by party leaders but turned down their invitation because he wanted to concentrate on union activities.\n\nSambanthan initially declined but following some pressure from the Tamil leaders agreed to take on the party leadership. He was duly elected the fifth president of the MIC in May 1955. Sambanthan was also acceptable to the Malay leadership because he played down political (and to some extent, economic) rights in favour of cultural and language rights.\n\nThe MIC's main challenge was to reconcile the political aspirations of the middle class with the poverty and needs of the labouring class, who in 1938 comprised 84% of the plantation labour force. Sambanthan started a recruitment campaign among plantation workers, relying on patronage of Hinduism in its popular South Indian form, increased use and fostering of the Tamil language, and Tamil cultural activities.\n\nBut the MIC under Sambanthan failed to reconcile the needs of labour with the political aspirations of the middle class. The traditionalists and the lower middle class strengthened their hold within the party, while the upper class professionals and the intelligentsia moved away from it. Subsequently, two paths to leadership emerged among the Indians – political and trade union – with very little interaction between them.\n\nUnder Sambanthan's leadership, the MIC effectively became a Tamil party. Sambanthan served as president of the MIC from 1955–71 and was largely responsible for the transformation of the party from an active, political organisation to a conservative, traditional one, emphasising Indian culture, religion and language.\n\nIt was also the weakest of the three main political parties. It had the smallest electorate – 7.4% in 1959; and it had little support from the Indian community at large.\n\nSince the Indian community was geographically dispersed and divided, it comprised less than 25% in any constituency. Therefore, the MIC's over-riding concern was to remain a partner in the Alliance (the UMNO-MCA-MIC Alliance that had won the first elections in 1955, and that was subsequently renamed Barisan Nasional) and obtain whatever concessions it could from the dominant UMNO. In the process, political and economic rights of workers were sacrificed.\n\nSambanthan, while as MIC president, helped strengthen the party economically by selling about half of his father's 2.4 km² rubber estate to help the Indian community as well as to provide financial strength to the party coffers.\n\nSambanthan took over the mantle of the MIC during a period of turmoil in the party in 1955, barely months before the first federal elections, and over time strengthen the party and consolidated its position in the coalition. He did not always please his members, but was able to gradually unite a party that had considerable internal splits.\n\nThe year 1955 was a milestone for Malaya's advance towards self-governance. The British colonial administration had agreed to hold the first federal elections in July 1955 and Sambanthan was instantly thrown into the cauldron of electoral politics.\n\nHe met the new challenge and following negotiations with the Alliance leaders the MIC was allocated two seats – in Batu Pahat, Johor, and Sungai Siput, Perak. Sambanthan Thevar contested the Sungai Siput seat and won comfortably.\n\nThe Alliance swept 51 of the 52 seats, the exception being a seat in Perak. Following the election win, Sambanthan was appointed to the Cabinet and sworn in as Labour Minister in the Alliance government.\n\nThe coalition decided to push for a quicker transfer of power and an Alliance delegation went to London in January 1956 to hold talks on a range of issues, including independence, with Secretary of State Alan Lennox-Boyd.\n\nEarlier, in 1956, Sambanthan led the MIC delegation in the negotiations between the Alliance parties in drawing up a memorandum to be presented to the Reid Commission.\n\nSambanthan was a pragmatic negotiator and worked hard to secure the interests of the Indian community, while at the same time being sensitive to the broader interests of the Alliance party's diverse membership.\n\nHe was at times criticised by his party members for conceding on certain issues, but Sambanthan was faced with the need to find a suitable balance to the various sectoral demands and sought to take a middle path in the negotiations. For taking such as position, he was praised by the Tunku.\n\nThe final constitutional negotiations in London in May 1957 also saw a personal transformation in Sambanthan. While in London for the constitutional talks, Tunku Abdul Rahman decided that Sambanthan needed new attire.\n\nSambanthan had caused some controversy when he wore a dhoti upon being elected into the Federal Legislative Council – a practice deemed taboo during the British period. But Sambanthan defended his choice, arguing: “It makes the average man feel happier.” Even after the elections in 1955, when he was appointed Minister of Labour, his traditional Indian attire remained intact.\n\nThus when in London, Tunku decided that something must be done. As the Tunku describes in his book Looking Back: “When walking with me in London, he was always trailing behind because he could not step out far enough to keep pace with me; or perhaps I walked faster on purpose. One day when we were out for a walk, I led him into Simpson’s men’s store in Piccadilly. On reaching there, I said: ‘Come in; I want to choose a new suit’, so he followed me inside.\n\n”I asked the tailor to fit Sambanthan with a good ready-made suit. He protested, but only briefly, accepting the inevitability, and came out a new man in a new suit – West-End tailored, new shirt, new tie, new shoes and socks.”\n\nThe Tunku noted that after that incident, Sambanthan was not satisfied with just one suit and secretly went out to buy several more.\n\nDuring the debate on the draft Constitution at the Federal Legislative Council on 10 July 1957, Sambanthan urged greater co-operation between the communities, reminding them that Malaya was a plural society. He told the council:\nThe MIC's success in the early years was due to the close personal friendship between Malaysia's first prime minister, Tunku Abdul Rahman Putra Al-Haj, and Sambanthan. For his part, Sambanthan ran the MIC as a largely informal party, in deference to Umno, rather than as a political party with definite programmes.\n\nIn effect, it became a vehicle for distributing patronage (senate and legislative votes, nominations for decorations and awards, licences) to supporters, furnishing the Indian Malaysian vote, and an instrument for the leadership to entrench its role. But patronage was always in short supply and, eventually, rising dissatisfaction with Sambanthan led to a prolonged leadership crisis in the party.\n\nWhen Tun Abdul Razak Hussein succeeded Tunku Abdul Rahman as Malaysia's prime minister, the MIC was forced to become much more responsive to the dictates of UMNO. This was following the May 13 Incident and Razak was more assertive than the Tunku to demonstrate \"Malay Supremacy\" or \"Ketuanan Melayu\".\n\nSambanthan, by now bearing the title \"Tun\", was forced to retire in favour of V. Manickavasagam in 1973. This intervention is an indication of the inertia that had gripped the MIC following Sambanthan's rise to leadership in 1955.\n\nAs president of a party that was a component of the ruling Alliance Party, he was appointed Minister of Labour (1955–57), Health (1957–59), Works, Posts and Telecommunications (1959–71) and National Unity (1972–74).\n\nDuring the time the Malaysian Government decided to ban the Chinese lion dance and racial tension was high after 13 May 1969, Tun Sambanthan as National Unity Minister in the early 1970s, took some Chinese leaders to Genting to talk things over. The discussions were successful and the lion dance ban was later lifted because the Government realised it was important to maintain each race's culture.\n\nApart from ministerial duties, Tunku Abdul Rahman often assigned important tasks to Sambanthan. In 1968, the Tunku sent Sambanthan to Fiji as an emissary of peace; the Chief Minister of Fiji acknowledged Sambanthan's contribution in a letter to Tunku thanking him for the \"great success\" of the delegation \"under the superb leadership of Tun Sambanthan\".\n\nSambanthan also joined the delegation to Jakarta, Indonesia in 1966 to witness the signing of an agreement whereby diplomatic relations between Indonesia and Malaysia were normalised after the Indonesian Confrontation episode.\n\nV. T. Sambanthan was also acting prime minister for one day when both the prime minister and his deputy were out of the country at the same time .\n\nAfter resigning as president of MIC, he was appointed chairman of the National Unity Board (1974–78) that replaced the National Unity Ministry.\n\nThroughout his political career, which spanned 25 years, he had preached and practised the doctrine of unity amidst diversity. Appropriately enough, in the Malaysian context, it was to national unity that he devoted the last few years of his life.\n\nIn his own way, Sambanthan instituted some reforms among Indian plantation workers. For example, he promoted education and thrift among Indian workers, lobbied for the introduction of English language instruction in Tamil schools in Perak and for the transformation of the South Indian Immigration Labour Fund into an education fund for the children of plantation workers.\n\nThe greatest challenge that MIC faced during his presidency was the fragmentation of estates, the livelihood of almost all Indian workers. In a bid to help the fragmentation, the party sponsored cooperative efforts to acquire estates and prevent displacement of the workers.\n\nIn 1960 Tun V.T. Sambanthan touted the idea of a social co-operative to help plantation workers during the British land sell off. Tun Sambanthan and K. R. Somasundram worked closely to purchase their first estate at Bukit Sidim in that same year. The co-operative was later called National Land and Finance Co-operative Society (NLFCS).\n\nHe toured rubber plantations to persuade workers to buy shares in the cooperative; a worker with a registration fee of $2 and a share costing $100 (payable in instalments) could buy a stake in a plantation.\n\nAt the time of his death in 1979, the cooperative had bought over 18 estates, totalling 120 km² and had a membership of 85,000 workers. The Malayan Plantation Agencies administered the estates on behalf of the cooperative.\n\nHis wife, Toh Puan Umasundari Sambanthan served as chairman and director of the National Land Finance Co- operative Society (NLFC) from 1980 to 1995 and its president in 1995 and 1996.\n\nK. R. Somasundram has since taken over the Chairmanship of the company upon the death of Tun Sambanthan and is still actively involved in the co-operative. Today NLFCS has 19 estates totalling , as well as investments in Palm Oil, Property and Banking.\n\nTun Sambanthan was married to Toh Puan Umasundari Sambanthan. The couple's daughter, Deva Kunjari, is a lawyer.\n\n\nSeveral places were named after him, including:\n"}
