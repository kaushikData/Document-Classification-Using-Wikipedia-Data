{"id": "43135819", "url": "https://en.wikipedia.org/wiki?curid=43135819", "title": "AIDS United", "text": "AIDS United\n\nAIDS United is a national non-profit organization based in Washington, DC, that is dedicated to ending the AIDS epidemic in the United States.\n\nAIDS United was born out of a merger between two Washington, DC based organizations: the National Aids Fund (NAF), a strategic grantmaking foundation and public charity, and AIDS Action, an advocacy organization for sound policy creation and the dissemination of education regarding the AIDS epidemic. NAF was founded in 1987, with the mission to support community-driven responses to the HIV epidemic around the country that would reach the nation’s most disproportionately affected populations, including gay and bisexual men, communities of color, women, people living in the deep South and people living with HIV/AIDS. AIDS Action was developed out of a 1984 coalition among AIDS service organizations across the United States, in response to the federal government’s seeming indifference at that time to the needs of communities affected by HIV. Their mission was to cultivate and create policies and programs in response to the HIV epidemic, distribute information, and advocate on behalf of all those living with and affected by HIV. The two organizations merged in 2010 to form AIDS United, under the direction of Mark Ishaug, then president and CEO of the AIDS Foundation of Chicago.\n\nThe mission of AIDS United is to end the AIDS epidemic in the United States through strategic grantmaking, capacity building, policy/advocacy, technical assistance, and formative research.\n\nJesse Milan Jr..PD is the President and Chief Executive Officer of AIDS United.\n\n"}
{"id": "16977023", "url": "https://en.wikipedia.org/wiki?curid=16977023", "title": "AMD Alliance International", "text": "AMD Alliance International\n\nAMD Alliance International is a non-profit coalition of the world’s leading vision, seniors and research organizations working to raise awareness of age-related macular degeneration, understanding of available options for prevention, early detection, treatment, rehabilitation and support services. It is the only international organization in the world that concentrates exclusively on age related macular degeneration, the leading cause of vision loss in the developed world.\n\nAMD is an eye condition that\ncauses loss of central vision,\nleaving only peripheral, or side,\nvision intact. AMD is the leading\ncause of visual impairment for people\nover 50 in the Western world.\n\nMacular degeneration is often related to aging, thus the name age-related macular degeneration (AMD or ARMD). \n\nThe two most common forms of AMD are dry and wet.\n\nThis more common form, causes varying degrees of sight loss and is identified by the collection of yellow, fatty deposits called drusen in the macula the central part of the retina responsible for clear central vision.\n\nOccurs less often (10-15 percent of cases), but the chance for severe sight loss is much greater. It is characterized by development of abnormal, leaky blood vessels in the macula. Scar tissue may form causing irreversible blind spots and in many cases leads to legal blindness.\n\nArgentina\n\nAustralia\n\nAustria\n\nBelgium\n\nBrazil\n\nCanada\n\nFinland\n\nFrance\n\nGermany\n\nHong Kong\n\nIndia\n\nIreland\n\nIsrael\n\nItaly\n\nNetherlands\n\nNew Zealand\n\nPoland\n\nSouth Africa\n\nSpain\n\nSwitzerland\n\nTunisia\n\nUnited Kingdom\n\nUnited States\n\nhttps://www.nlm.nih.gov/medlineplus/maculardegeneration.html \n\nhttps://web.archive.org/web/20070420173233/http://www.lighthouse.org/aboutus/press/press-releases/pr-smoking/\n\nhttps://web.archive.org/web/20080606095302/http://www.cnib.ca/en/news/archive/amd-news-092006.aspx \n\nhttps://web.archive.org/web/20080916102223/http://www.nei.nih.gov/strategicplanning/np_part.asp\n\n\n"}
{"id": "35593211", "url": "https://en.wikipedia.org/wiki?curid=35593211", "title": "Arresødal", "text": "Arresødal\n\nArresødal is a manor estate situated in Frederiksværk, in Halsnæs Municipality on the island of Zealand in Region Hovedstaden, northeastern Denmark. Surrounded by forest to the west of lake Arresø, it now functions as a private hospice.\n\nArresødal was created as a manor in 1773 by Major General Johan Frederik Classen. He ordered the building of the main house in 1786–88. Upon his death, Classen bequeathed Arresødal to Prince Charles of Hesse-Kassel, who owned the property until Crown Prince Frederik (later King Frederick VI of Denmark) bought the property in 1804.\n\nIn 1883 the property was purchased by the Classen Fideicommis. It was then a convalescent home for women until 1944 when it was taken over by first the Germans and then the freedom fighters who used the buildings as a prison. It once again became a convalescent home until 1984 when Arresødal was sold to KMD.\n\nIn subsequent years, Arresødal became a training centre and functioned as such until 2002 when the Indian Sai Baba movement bought the building from Kommunedata and took it over on 1 April. The plan was to establish an international school there. But in the light of a pending case against the movement's Indian guru Sai Baba, there was so much opposition from the mayor and local politicians that those responsible chose to withdraw. Frederiksværk Municipality bought the property and had to pay compensation for losses incurred by the movement.\n\nThe municipality sold Arresødal to Anette and Carsten Følsgaard who converted it into a private hospital and hospice. The couple took it over on 1 January 2003. The scenic park extending down to Arresø was not part of the sale and the park is now open to the public. Arresødal Private Hospital closed in 2011. The building was sold to the non-profit foundation OK_Fonden in 2017.\n\nThe main building is designed in the Neoclassical style. It was rebuilt in 1908–09 and partly in 2004. Two other buildings on the estate are protected.\n\n\n"}
{"id": "13512662", "url": "https://en.wikipedia.org/wiki?curid=13512662", "title": "Assistant Secretary of State for Oceans and International Environmental and Scientific Affairs", "text": "Assistant Secretary of State for Oceans and International Environmental and Scientific Affairs\n\nThe Assistant Secretary of State for Oceans and International Environmental and Scientific Affairs is the head of the Bureau of Oceans and International Environmental and Scientific Affairs in the United States Department of State. The Assistant Secretary of State for Oceans and International Environmental and Scientific Affairs reports to the Under Secretary of State for Economic Growth, Energy, and the Environment.\n"}
{"id": "45784", "url": "https://en.wikipedia.org/wiki?curid=45784", "title": "Biomimetics", "text": "Biomimetics\n\nBiomimetics or biomimicry is the imitation of the models, systems, and elements of nature for the purpose of solving complex human problems. The terms \"biomimetics\" and \"biomimicry\" derive from (\"bios\"), life, and μίμησις (\"mīmēsis\"), imitation, from μιμεῖσθαι (\"mīmeisthai\"), to imitate, from μῖμος (\"mimos\"), actor. A closely related field is bionics.\n\nLiving organisms have evolved well-adapted structures and materials over geological time through natural selection. Biomimetics has given rise to new technologies inspired by biological solutions at macro and nanoscales. Humans have looked at nature for answers to problems throughout our existence. Nature has solved engineering problems such as self-healing abilities, environmental exposure tolerance and resistance, hydrophobicity, self-assembly, and harnessing solar energy.\n\nOne of the early examples of would-be biomimicry was the study of birds to enable human flight. Although never successful in creating a \"flying machine\", Leonardo da Vinci (1452–1519) was a keen observer of the anatomy and flight of birds, and made numerous notes and sketches on his observations as well as sketches of \"flying machines\". The Wright Brothers, who succeeded in flying the first heavier-than-air aircraft in 1903, allegedly derived inspiration from observations of pigeons in flight. During the 1950s the American biophysicist and polymath Otto Schmitt developed the concept of \"biomimetics\". During his doctoral research he developed the Schmitt trigger by studying the nerves in squid, attempting to engineer a device that replicated the biological system of nerve propagation. He continued to focus on devices that mimic natural systems and by 1957 he had perceived a converse to the standard view of biophysics at that time, a view he would come to call biomimetics.\n\nIn 1960 Jack E. Steele coined a similar term, \"bionics\", at Wright-Patterson Air Force Base in Dayton, Ohio, where Otto Schmitt also worked. Steele defined bionics as \"the science of systems which have some function copied from nature, or which represent characteristics of natural systems or their analogues\". During a later meeting in 1963 Schmitt stated,\n\nIn 1969 Schmitt used the term “biomimetic“ in the title one of his papers, and by 1974 it had found its way into Webster's Dictionary, bionics entered the same dictionary earlier in 1960 as \"a science concerned with the application of data about the functioning of biological systems to the solution of engineering problems\". Bionic took on a different connotation when Martin Caidin referenced Jack Steele and his work in the novel \"Cyborg\" which later resulted in the 1974 television series \"The Six Million Dollar Man\" and its spin-offs. The term bionic then became associated with \"the use of electronically operated artificial body parts\" and \"having ordinary human powers increased by or as if by the aid of such devices\". Because the term \"bionic\" took on the implication of supernatural strength, the scientific community in English speaking countries largely abandoned it.\n\nThe term \"biomimicry\" appeared as early as 1982. Biomimicry was popularized by scientist and author Janine Benyus in her 1997 book \"Biomimicry: Innovation Inspired by Nature\". Biomimicry is defined in the book as a \"new science that studies nature's models and then imitates or takes inspiration from these designs and processes to solve human problems\". Benyus suggests looking to Nature as a \"Model, Measure, and Mentor\" and emphasizes sustainability as an objective of biomimicry.\n\nBiomimetics could in principle be applied in many fields. Because of the diversity and complexity of biological systems, the number of features that might be imitated is large. Biomimetic applications are at various stages of development from technologies that might become commercially usable to prototypes. Murray's law, which in conventional form determined the optimum diameter of blood vessels, has been re-derived to provide simple equations for the pipe or tube diameter which gives a minimum mass engineering system. \n\nAircraft wing design and flight techniques are being inspired by birds and bats. Biorobots based on the physiology and methods of locomotion of animals include BionicKangaroo which moves like a kangaroo, saving energy from one jump and transferring it to its next jump. Kamigami Robots, a children's toy, mimic cockroach locomotion to run quickly and efficiently over indoor and outdoor surfaces . \n\nResearchers studied the termite's ability to maintain virtually constant temperature and humidity in their termite mounds in Africa despite outside temperatures that vary from 1.5 °C to 40 °C (35 °F to 104 °F). Researchers initially scanned a termite mound and created 3-D images of the mound structure, which revealed construction that could influence human building design. The Eastgate Centre, a mid-rise office complex in Harare, Zimbabwe, stays cool without air conditioning and uses only 10% of the energy of a conventional building of the same size.\n\nIn structural engineering, the Swiss Federal Institute of Technology (EPFL) has incorporated biomimetic characteristics in an adaptive deployable \"tensegrity\" bridge. The bridge can carry out self-diagnosis and self-repair. The arrangement of leaves on a plant has been adapted for better solar power collection.\n\nAnalysis of the elastic deformation happening when a pollinisator lands on the sheath-like perch part of the flower \"Strelitzia reginae\" (known as Bird-of-Paradise flower) has inspired architects and scientists from the University of Freiburg and University of Stuttgart for the creation of hingeless shading systems that can react to their environment. These bio-inspired products is sold under the name Flectofin.\n\nOther hingeless bioinspired system includes Flectofold. Flectofold has been inspired from the trapping system developed by the carnivorous plant \"Aldrovanda vesiculosa\".\n\nThere is a great need for new structural materials that are light weight but offer exceptional combinations of stiffness, strength and toughness. \n\nSuch materials would need to be manufactured into bulk materials with complex shapes at high volume and low cost and would serve a variety of fields such as construction, transportation, energy storage and conversion. In a classic design problem, strength and toughness are more likely to be mutually exclusive i.e., strong materials are brittle and tough materials are weak. However, natural materials with complex and hierarchical material gradients that span from nano- to macro-scales are both strong and tough. Generally, most natural materials utilize limited chemical components but complex material architectures that give rise to exceptional mechanical properties. Understanding the highly diverse and multi functional biological materials and discovering approaches to replicate such structures will lead to advanced and more efficient technologies. Bone, nacre (abalone shell), teeth, the dactyl clubs of stomatopod shrimps and bamboo are great examples of damage tolerant materials. The exceptional resistance to fracture of bone is due to complex deformation and toughening mechanisms that operate at spanning different size scales - nanoscale structure of protein molecules to macroscopic physiological scale. Nacre exhibits similar mechanical properties however with rather simpler structure. Nacre shows a brick and mortar llike structure with thick mineral layer (0.2∼0.9-μm) of closely packed aragonite structures and thin organic matrix (∼20-nm). While thin films and micrometer sized samples that mimic these structures are already produced, successful production of bulk biomimetic structural materials is yet to be realized. However, numerous processing techniques have been proposed for producing nacre like materials. \n\nBiomorphic mineralization is a technique that produces materials with morphologies and structures resembling those of natural living organisms by using bio-structures as templates for mineralization. Compared to other methods of material production, biomorphic mineralization is facile, environmentally benign and economic. \n\nFreeze casting (Ice templating), an inexpensive method to mimic natural layered structures was employed by researchers at Lawrence Berkeley National Laboratory to create alumina-Al-Si and IT HAP-epoxy layered composites that match the mechanical properties of bone with an equivalent mineral/ organic content. Various further studies also employed similar methods to produce high strength and high toughness composites involving a variety of constituent phases. \n\nRecent studies demonstrated production of cohesive and self supporting macroscopic tissue constructs that mimic living tissues by printing tens of thousands of heterologous picoliter droplets in software-defined, 3D millimeter-scale geometries. Efforts are also taken up to mimic the design of nacre in artificial composite materials using fused deposition modelling and the helicoidal structures of stomatopod clubs in the fabrication of high performance carbon fiber-epoxy composites. \n\nVarious established and novel additive manufacturing technologies like PolyJet printing, direct ink writing, 3D magnetic printing, multi-material magnetically assisted 3D printing and magnetically-assisted slip casting have also been utilized to mimic the complex micro-scale architectures of natural materials and provide huge scope for future research. \n\nSpider web silk is as strong as the Kevlar used in bulletproof vests. Engineers could in principle use such a material, if it could be reengineered to have a long enough life, for parachute lines, suspension bridge cables, artificial ligaments for medicine, and other purposes. The self-sharpening teeth of many animals have been copied to make better cutting tools. \n\nNew ceramics that exhibit giant electret hysteresis have also been realized. \n\nIn general in biological systems, self healing occurs via chemical signals released at the site of fracture which initiate a systemic response that transport repairing agents to the fracture site thereby promoting autonomic healing. To demonstrate the use of micro-vascular networks for autonomic healing, researchers developed a microvascular coating–substrate architecture that mimics human skin. Bio-inspired self-healing structural color hydrogels that maintain the stability of an inverse opal structure and its resultant structural colors were developed. A self-repairing membrane for inspired by rapid self-sealing processes in plants was developed for inflatable light weight structures such as rubber boats or Tensairity® constructions. The researchers applied a thin soft cellular polyurethane foam coating on the inside of a fabric substrate, which closes the crack if the membrane is punctured with a spike. Self-healing materials, polymers and composite materials capable of mending cracks have been produced based on biological materials. \n\nSurfaces that recreate properties of shark skin are intended to enable more efficient movement through water. Efforts have been made to produce fabric that emulates shark skin. \n\nSurface tension biomimetics are being researched for technologies such as hydrophobic or hydrophilic coatings and microactuators.\n\nSome amphibians, such as tree and torrent frogs and arboreal salamanders, are able to attach to and move over wet or even flooded environments without falling. This kind of organisms have toe pads which are permanently wetted by mucus secreted from glands that open into the channels between epidermal cells. They attach to mating surfaces by wet adhesion and they are capable of climbing on wet rocks even when water is flowing over the surface. Tire treads have also been inspired by the toe pads of tree frogs.\n\nMarine mussels can stick easily and efficiently to surfaces underwater under the harsh conditions of the ocean. Mussels use strong filaments to adhere to rocks in the inter-tidal zones of wave-swept beaches, preventing them from being swept away in strong sea currents. Mussel foot proteins attach the filaments to rocks, boats and practically any surface in nature including other mussels. These proteins contain a mix of amino acid residues which has been adapted specifically for adhesive purposes. Researchers from the University of California Santa Barbara borrowed and simplified chemistries that the mussel foot uses to overcome this engineering challenge of wet adhesion to create copolyampholytes, and one-component adhesive systems with potential for employment in nanofabrication protocols. Other research has proposed adhesive glue from mussels.\n\nLeg attachment pads of several animals, including many insects (e.g. beetles and flies), spiders and lizards (e.g. geckos), are capable of attaching to a variety of surfaces and are used for locomotion, even on vertical walls or across ceilings. Attachment systems in these organisms have similar structures at their terminal elements of contact, known as setae. Such biological examples have offered inspiration in order to produce climbing robots, boots and tape . Synthetic setae have also been developed for the production of dry adhesives.\n\nBiomimetic materials are gaining increasing attention in the field of optics and photonics. There are still little known bioinspired or biomimetic products involving the photonic properties of plants or animals. However, understanding how nature designed such optical materials from biological resources is worth pursuing and might lead to future commercial products. \nFor instance, the chiral self-assembly of cellulose inspired by the \"Pollia condensata\" berry has been exploited to make optically active films. Such films are made from cellulose which is a biodegradable and biobased ressource obtained from wood or cotton. The structural colours can potentially be everlasting and have more vibrant colour than the ones obtained from chemical absorption of light. \"Pollia condensata\" is not the only fruit showing a structural coloured skin, other berries such as \"Margaritaria nobilis\" does. These fruits show iridescent colors in the blue-green region of the visible spectrum which gives the fruit a strong metallic and shiny visual appearance. The structural colours come from the organisation of cellulose chains in the fruit's epicarp, a part of the fruit skin. Each cell of the epicarp is made of a multilayered envelope that behaves like a Bragg reflector. However, the light which is reflected from the skin of these fruits is not polarised unlike the one arising from man-made replicates obtained from the self-assembly of cellulose nanocrystals into helicoids, which only reflect left-handed circularly polarised light. \n\nThe fruit of \"Elaeocarpus angustifolius\" also show structural colour that come arises from the presence of specialised cells called iridosomes which have layered structures. Similar iridosomes have also been found in Delarbrea michieana fruits.\n\nIn plants, multi layer structures can be found either at the surface of the leaves (on top of the epidermis), such as in \"Selaginella willdenowii\" or within specialized intra-cellular organelles, the so-called iridoplasts, which are located inside the cells of the upper epidermis. For instance, the rain forest plants Begonia pavonina have iridoplasts located inside the epidermal cells. \n\nStructural colours have also been found in several algae, such as in the red alga \"Chondrus crispus\" (Irish Moss).\n\nStructural coloration produces the rainbow colours of soap bubbles, butterfly wings and many beetle scales. Phase-separation has been used to fabricate ultra-white scattering membranes from polymethylmethacrylate, mimicking the beetle \"Cyphochilus\".\n\n\"Morpho\" butterfly wings are structurally coloured to produce a vibrant blue that does not vary with angle. This effect can be mimicked by a variety of technologies. Lotus Cars claim to have developed a paint that mimics the \"Morpho\" butterfly's structural blue colour. In 2007, Qualcomm commercialised an interferometric modulator display technology, \"Mirasol\", using \"Morpho\"-like optical interference. In 2010, the dressmaker Donna Sgro made a dress from Teijin Fibers' Morphotex, an undyed fabric woven from structurally coloured fibres, mimicking the microstructure of \"Morpho\" butterfly wing scales.\n\nProtein folding has been used to control material formation for self-assembled functional nanostructures. Polar bear fur has inspired the design of thermal collectors and clothing. The light refractive properties of the moth's eye has been studied to reduce the reflectivity of solar panels. \n\nThe Bombardier beetle's powerful repellent spray inspired a Swedish company to develop a \"micro mist\" spray technology, which is claimed to have a low carbon impact (compared to aerosol sprays). The beetle mixes chemicals and releases its spray via a steerable nozzle at the end of its abdomen, stinging and confusing the victim.\n\nMost viruses have an outer capsule 20 to 300 nm in diameter. Virus capsules are remarkably robust and capable of withstanding temperatures as high as 60 °C; they are stable across the pH range 2-10. Viral capsules can be used to create nano device components such as nanowires, nanotubes, and quantum dots. Tubular virus particles such as the tobacco mosaic virus (TMV) can be used as templates to create nanofibers and nanotubes, since both the inner and outer layers of the virus are charged surfaces which can induce nucleation of crystal growth. \n\nThis was demonstrated through the production of platinum and gold nanotubes using TMV as a template. Mineralized virus particles have been shown to withstand various pH values by mineralizing the viruses with different materials such as silicon, PbS, and CdS and could therefore serve as a useful carriers of material. A spherical plant virus called cowpea chlorotic mottle virus (CCMV) has interesting expanding properties when exposed to environments of pH higher than 6.5. Above this pH, 60 independent pores with diameters about 2 nm begin to exchange substance with the environment. The structural transition of the viral capsid can be utilized in Biomorphic mineralization for selective uptake and deposition of minerals by controlling the solution pH. Possible applications include using the viral cage to produce uniformly shaped and sized quantum dot semiconductor nanoparticles through a series of pH washes. This is an alternative to the apoferritin cage technique currently used to synthesize uniform CdSe nanoparticles. Such materials could also be used for targeted drug delivery since particles release contents upon exposure to specific pH levels.\n\n\n\n"}
{"id": "47457342", "url": "https://en.wikipedia.org/wiki?curid=47457342", "title": "Birth registration campaign in Liberia", "text": "Birth registration campaign in Liberia\n\nThe Liberian government is conducting a birth registration campaign to record more than 70,000 children whose births were not listed during the Ebola crisis of 2014 and 2015. Previously Liberia had the second lowest rate of birth registration at 4 percent. But a Universal Birth Registration Plan was introduced, and by 2013, birth registration drives had increased the rates in Liberia to 25 percent.\n\nDuring the Ebola outbreak in 2014 and 2015, Liberia birth registrations dropped sharply. In 2014 many health facilities closed or had reduced services in response to the Ebola crisis, and there was a 39 per cent decrease in births registered over the previous year. In 2013, before the beginning of the Ebola epidemic, the births of 79,000 children were registered, while in 2014 the number of registrations dropped to 48,000. And only 700 children in Liberia had their births registered between January and May 2015. UNICEF is supporting a drive to implement registration systems throughout the country, and will assist with training and outreach for a nationwide campaign to register the children missed in 2014 and 2015.\n\nHistorically, Liberia had a low level of birth registrations. In 2007, birth registration rates were estimated at 4 or 5 percent. A field survey by the Ministry of Health and Social Welfare in 2008 indicated that was not a properly working birth registration system in Liberia. The government in Liberia identified the development of an improved birth registration system as a national priority in the \"Liberian Poverty Reduction Strategy.\" And by 2013, birth registration drives had increased the rates in Liberia to 25 percent.\n"}
{"id": "590032", "url": "https://en.wikipedia.org/wiki?curid=590032", "title": "Calorad", "text": "Calorad\n\nCalorad Classic is a liquid protein weight loss supplement which was first introduced to the US and Canadian marketplace in 1984. It has been advertised on both television and radio. Calorad Classic is manufactured by NutriDiem and is marketed by several companies including Essentially Yours Industries and Nysante, all of which are headquartered in Canada.\n\nCalorad Classic is a liquid dietary supplement composed primarily of 3,000 mg (3 grams) of Type II hydrolyzed collagen (hydrolysate) from either beef (bovine) or tuna (marine) sources and 8 mg of aloe vera, both of which are listed as active ingredients. The supplement label states that Calorad is fat-free and carbohydrate-free and that 1 serving (1/2 ounce) provides 3 grams of protein and 10 calories. Calorad Classic also comes in a Kosher formulation (marine). The primary claim made for the product is that regular use causes weight loss without loss of lean muscle mass. While weight loss and body fat reduction may be achieved simply by following the labeled instruction to avoid eating within three hours prior to sleep as that can result in eating fewer calories per day, most individuals fasting for 3-hours prior to bed-time alone are not successful in accomplishing long-term weight loss.\n\nFormulator Michel Grise stated that the original version of what later became known as Calorad was developed to treat chickens with fatty liver syndrome. Chickens were developing so much body fat that they stopped laying eggs. The formulation was successful in helping farmers reduce body fat of chickens to get them laying eggs again. This led to the question of whether such a product would work for humans.\n\nAlthough the manufacturer does not make claims for Calorad Classic in the treatment or cure of disease, the manufacturer does cite published clinical trials in OsteoArthritis and Osteoporosis, Rheumatoid Arthritis, and Fibromyalgia all conducted with Type II hydrolyzed collagen (collagen hydrolysate), the primary ingredient in Calorad.\n\nThe manufacturer claims that 40% of subjects will lose weight within 1 month, 75% after 2 months and 87% after 3 months. The distributors of the product offer a 30-day satisfaction guarantee. In support of these claims, the distributing companies cite a clinical study of Calorad (also unpublished and non-peer reviewed) by Joel B. Lao. Lao is a Doctor of Internal Medicine, and medical consultant in the Philippines who studied the effects of Calorad and its effect on overweight and/or obese individuals. The subjects included 50 overweight or obese individuals who were observed over a 90-day period. One bottle of Calorad was provided to each of the subjects every month for a 3-month period. In month 1, the average weight loss was 5.7 pounds. By month 3, subjects had an average reduction of 10 pounds, and an average inch loss at the waist of 3 inches.\n\nThe claim that Calorad Classic facilitates weight loss while building or maintaining lean muscle mass is based upon an unpublished and non-peer reviewed study by Davis \"et al.\" in which 300 subjects between the ages of 17–77 years, were followed for 1 year, and the majority of whom lost weight (an average of 3.75 pounds per month) but maintained lean muscle mass. Davis states: \"We also found that in the entire group, less than 0.6, or less than 1 per cent, had any loss of lean muscle mass. And 36 per cent of the group actually gained lean muscle mass during that time.\"\n\nOne of the marketing companies, Essentially Yours, states that most subjects on a weight loss regimen lose lean muscle mass along with fat and water weight, so that maintaining lean muscle mass is a benefit seen with Calorad Classic users.\n\nWhen first introduced, the manufacturer claimed that Calorad Classic could cause the user to \"lose weight while you sleep\", repair joints, and prevent or reduce the symptoms of arthritis. The manufacturer has since dropped these claims because they are \"medical treatment claims\" and require a drug treatment classification approved by the United States Food and Drug Administration, and are usually only granted following submission of large clinical trials similar to those conducted by pharmaceutical companies in substantiation of these claims. Neither the manufacturer (Nutridiem) or the distributing companies (Nysante or EYI) have conducted this type of rigorous trial on Calorad in support of such claims. The manufacturer and distributing companies have replaced these claims with the current claim that Calorad \"promotes sleep and improves the health and appearance of hair, nails and skin\" (all of which are not medical treatment claims).\n\nCalorad Classic, like all nutritional supplements, has not been evaluated by the US Food and Drug Administration, and all marketing materials related to the product carry a disclaimer to the effect that it is \"a food supplement and is not intended to diagnose, treat, cure, or prevent any disease.\"\n\n"}
{"id": "42455557", "url": "https://en.wikipedia.org/wiki?curid=42455557", "title": "Chad Kellogg", "text": "Chad Kellogg\n\nChad Kellogg (September 22, 1971 – February 14, 2014) was an American mountain climber, best known for his numerous speed climbing records and first ascents.\n\nKellogg was born in Omak, Washington in 1971. His parents, Ric and Peggy Kellogg, were missionaries, and as a result his family moved to Kenya for seven years before returning to the United States to settle in Seattle. He enrolled at the University of Washington in 1989 when he was 17 and graduated with a degree in economics. He trained with the U.S. national luge team for seven years in Lake Placid, New York, but gave up the sport after failing to qualify for the 1994 Winter Olympics.\n\nKellogg began climbing in 1984 in the North Cascades but it was not until he left the national luge team that he began to pursue mountaineering as a career. He worked as a climbing ranger in Mount Rainier National Park in 1997–1998 and later ran a Seattle-based construction business to support his climbs. He became well known in the climbing community in 1998 as he began to break records for speed ascents.\n\nIn 1998 Kellogg became the first person to climb and descend Mount Rainier in under five hours. He repeated the feat in 2004 when he ran from Paradise, Washington to the summit in 4 hours, 59 minutes. His record for the fastest climb has since been surpassed. Kellogg entered the 2003 Khan Tengri speed climbing competition in Kazakhstan, a race to climb the mountain, and won. He once held the record for the fastest ascent and descent on Mount McKinley's West Buttress route, making the round trip to the summit and back in 23 hours, 55 minutes; he was the first known person to ascend and descend in less than 24 hours. Kellogg made three attempts to break speed record on Mount Everest in 2010, 2011 and 2013, but never succeeded.\n\nThroughout his career, Kellogg claimed a number of first ascents. These included the Black Crystal Arete route on Kichatna Spire in Alaska (2005; with Joe Puryear), the southwest ridge of Mount Siguniang (2008; with Dylan Johnson), the Medicine Buddha route on Aconcagua in Argentina (2009), and Pangbuk Ri in Nepal (2011). In 2012, Kellogg traveled to Nepal with David Gottlieb to attempt the first ascent of Lunag Ri; they abandoned the attempt when Gottlieb fell sick, but in 2014 Kellogg won a Mugs Stump Award grant to return to the mountain for another attempt.\n\nKellogg and his climbing partner Jens Holsten traveled to Patagonia, Argentina in 2014 on an expedition to climb Fitz Roy. Both Kellogg and Holsten reached the summit on the afternoon of February 14, but while they were descending that night, Kellogg was hit by a falling rock and died instantly. No attempts were made to recover his body.\n\nKellogg met Lara-Karena Bitenieks, another climber, in 1994 while they were working at REI in Seattle. They began dating in 1999 and were married from 2000 until she died in 2007 while descending Mount Wake in Denali National Park, Alaska. A month after his wife's death, Kellogg was diagnosed with colorectal cancer, which later went into remission. Before his death in 2014, Kellogg was in a relationship with Mandy Kraus. He was a Buddhist.\n\n"}
{"id": "28759087", "url": "https://en.wikipedia.org/wiki?curid=28759087", "title": "Earle H Spaulding", "text": "Earle H Spaulding\n\nEarle Spaulding of Temple University (Philadelphia, Pa) in a 1939 paper on disinfection of surgical instruments in a chemical solution proposed \"a strategy for sterilization or disinfection of inanimate objects and surfaces based on the degree of risk involved in their use.\" for the medical community.\n\n\"Due to his extensive study of disinfection and sterilization of medical instruments, Spaulding further refined his classification of appropriate treatment of medical devices based upon how a device is used. Chemical disinfection was classified as low level, high level, and sterilization based upon whether a device contacted intact skin, mucous membranes, or was introduced into the sterile cavity of the body.\"\n\n\n\"A RATIONAL APPROACH TO DISINFECTION AND STERILIZATION - More than 30 years ago, Earle H. Spaulding devised a rational approach to disinfection and sterilization of patient-care items and equipment.14 This classification scheme is so clear and logical that it has been retained, refined, and successfully used by infection control professionals and others when planning methods for disinfection or sterilization.\" \n\n"}
{"id": "24232594", "url": "https://en.wikipedia.org/wiki?curid=24232594", "title": "Early Intervention Centres in Malaysia", "text": "Early Intervention Centres in Malaysia\n\nThe First Early Intervention Centre in Malaysia was established in 1987. It was initiated by Malaysian Care, a non-governmental organisation (NGO), with the help of Robert Deller, a child psychologist from Britain.\n\nThe Education Ministry's foray into early intervention services began in 2004 for children below six who have visual, hearing and learning impairments. The basic problems of running early intervention centres are lack of resources, trained staff and financial support from the Malaysian Government. The NGOs rely largely on donations and volunteers to keep the centres going. The long waiting list is not unusual as the number of special needs children continues to rise.\n\nIn 2003, primary education was made compulsory, but the services for learning disabled students remain limited and fragmented.\n\nLook at Early Childhood Intervention\n"}
{"id": "31110167", "url": "https://en.wikipedia.org/wiki?curid=31110167", "title": "European health management association", "text": "European health management association\n\nThe European Health Management Association (EHMA) was established in 1982 and is a non-profit membership organisation. Its focus is on health management capacity and capabilities and on supporting the implementation of health policy and practice.\n\nEHMA is a forum for health policy makers who need to network and share information and intelligence in a rapidly changing health sector; senior health managers who need an international and inter-sectoral network to develop their capacity to deliver health services; programme directors of health management programmes, who need an international forum to develop their programmes; and academic institutions and research organisations who can exchange experience and learning among their peers across Europe.\n\nIt is the only European membership organisation focusing on health management in the health sector.\n\nEHMA represents the interests of members on a wide range of European Commission working groups and committees, including the European Health Policy Forum and the Commission Working Group on Patient Safety and Quality. EHMA has also been involved as project leader or participant in a wide range of European Commission funded research projects and studies in public health.\n\nEHMA has two different types of membership: individual and organizational. The organizational members are represented by healthcare providers, universities, research institutions, health policy bodies and government ministries. Currently, it has 73 members from over 20 countries in the WHO region, bringing together the management, policy and research communities.\n\nThe EHMA Board sits at the heart of the Governance process and Board Members play a pivotal role in helping to shape the strategy and to oversee the delivery of the work programme. Board positions are open to all Members and are elected during the Annual General Assembly.\n\nThe role of the Scientific Advisory Committee (SAC) is to support the wider mission of EHMA, specifically providing the EHMA Board with advice on research and scientific issues. The SAC plays an important role in providing a focus for and voice for EHMA's research community, and in raising awareness of research within EHMA. Moreover, the SAC provides scientific advice and review input to planning for the Annual Conference. SAC Members are appointed by the EHMA Board for a period of 3 years.\n\nThe EHMA Young Advisory Committee (YAC) has been working on the Young EHMA network for the past years. The aim of the Young EHMA network is to offer a forum for early career professionals in health management to interact with peers about topics of interest, shared experiences, and career needs.\n\nThe European Health Management Association is involved in several of Europe's research projects following a history in managing and participating in numerous research projects, often supported by European Commission programmes. EHMA's main expertise relates not only to project management, but also to dissemination of research results – in particular 'knowledge transfer', in which the dialogue between researchers and targets group are central, is according to EHMA a key issue in strengthening both the validity of the research as well as the dissemination of results. Related to this dialogue, EHMA recognizes the actual impact of research result and the practical reality on the shop floor as a key issue.\n\nThemes of past projects have included access to healthcare, the \"basket\" of services available to patients and the legal aspects of eHealth.\n\nThe complete list is below:\n\nEHMA has been organizing its annual scientific conferences since 1982, every year the location and the topic changes. It brings together for provocative discussions not only EHMA members, but healthcare professionals, policy makers and industry representatives.\n\nHealth Services Management Research is an authoritative international peer-reviewed journal which exists to publish theoretically and empirically rigorous research on questions of enduring interest and concern to health-care organizations and systems throughout the world.\n"}
{"id": "42366668", "url": "https://en.wikipedia.org/wiki?curid=42366668", "title": "Great Rehabilitation Centre National Narcotic Board Indonesia", "text": "Great Rehabilitation Centre National Narcotic Board Indonesia\n\nGreat Rehabilitation Centre National Narcotic Board Indonesia (Balai Besar Rehabilitasi Badan Narkotika Nasional Indonesia, Babesrehab) is located in Bogor, Indonesia. This rehabilitation centre was inaugurated by Tien Soeharto, on 31 October 1974. This rehabilitation centre service addict using one stop centre system, which is composed by medical rehabilitation services and social rehabilitation under one roof. This rehabilitation centre service using the Therapeutic Community (TC) with a capacity of 500 persons, and lasted for 6 months.\n"}
{"id": "30503982", "url": "https://en.wikipedia.org/wiki?curid=30503982", "title": "Gynaecworld Clinic", "text": "Gynaecworld Clinic\n\nGynaecworld is a women's health centre. It is located in Mumbai, India and is one of several Mumbai IVF clinics that also provides surrogacy.\n\nThe Gynaecworld clinic is founded and led by MD Dr Duru Shah \n\nHere are some of the services available at Gynaecworld\n\n\n"}
{"id": "32635991", "url": "https://en.wikipedia.org/wiki?curid=32635991", "title": "Health in South Sudan", "text": "Health in South Sudan\n\nThe post conflict South Sudan has huge challenges in delivering health care to the population. The challenges include: crippled health infrastructures, nearly collapsed public health system, and inadequate qualified health professionals. The country is far from achieving the MDGs by end of 2015. The health system needs a major resuscitation, in addition to supporting and developing health training institutions. \n\nSouth Sudan is acknowledged to have some of the worst health indicators in the world.\n\nA new measure of expected human capital calculated for 195 countries from 1990 to 2016 and defined for each birth cohort as the expected years lived from age 20 to 64 years and adjusted for educational attainment, learning or education quality, and functional health status was published by The Lancet in September 2018. South Sudan had the second lowest level of expected human capital countries with 2 health, education, and learning-adjusted expected years lived between age 20 and 64 years. This was an improvement over 1990 when its score was 1. \n\nSouth Sudan has a health system structured with three tiers: Primary Health Care Units (PHCU), Primary Health Care Centers (PHCC) and Hospitals (which exist as either state, county, police or military). The structures in health services delivery is in the order of community, primary, secondary and tertiary levels. The community is located at the village level and manned by community health. The primary level includes Primary Health Care Units and Primary Health Care Centers which provide Basic Package of Health Services (BPHS). The BPHS covers preventive, curative, health promotion and managerial activities. The BPHS is financed by the government and contributions from MDTF and various NGO. The health services are meant to be free and accessible to the majority of the population at the primary and secondary levels.\nThe national ministry of health (MoH) have a decentralized health services in line with the interim constitution of South Sudan (2005) and local government act (2009).\nThe decentralized organization structure has four levels: Central, state, county and the community. \nThe national ministry of health provides policy guidance, leadership, funding, monitoring and evaluation. The state level oversees the implementation of health care services delivery at the rest of the levels. \n\nThe health situation South Sudan is far from ideal. More than 50% of the population live below the poverty line, and the adult literacy rate is at 27%. The under-five infant mortality rate is 135.3 per 1,000 (under five mortality rate (U5MR) 99/1000 live births), whilst maternal mortality is the highest in the world at 2,053.90 per 100,000 live births (Maternal Mortality Ratio (MMR) at 2045/100,000 live births in 2006 (South Sudan national bureau of statistics, 2012)). Antenatal care (ANC) attendance (1st visit) was 47.6%, 17% for four visits. and the infant mortality rate (IMR) was at 64/1,000 live births. The life expectancy is 55 years. In 2004, there were only three surgeons serving southern Sudan, with three proper hospitals, and in some areas there was just one doctor for every 500,000 people.\nA child born in South Sudan has a 25% chance of dying before their 5th birthday. The major causes of the mortality include pneumonia, diarrhea, malaria, and malnutrition. \nThe country has the lowest immunization coverage of only 26%. The proportion of children who received all recommended vaccinations dropped from 27 to 26% in 2006 and 2010 respectively.\nThe ANC coverage is very low at 40.3% women attending first visit and 17% women who completed the four recommended visit. Most of the maternal deaths occur during labor, delivery and the immediate postpartum period. Most of these deaths would have been prevented if the country had good infrastructure and skilled personnel during child birth. \nThe human resource for health in South Sudan is far below the minimum threshold recommended by the WHO. Between 2009–2010 there were only 189 doctors across eight states with one doctor for every 65,574 people. There were 309 midwives in the country and the ratio was 1 per 39,088 population. However, there is variation in the figures; other sources suggested the ratio of midwives as 1:125,000 women.\n\nIn October 2014 Reuters reported that Oxfam was warning that '2.2 million people currently faced starvation'.\n"}
{"id": "43834932", "url": "https://en.wikipedia.org/wiki?curid=43834932", "title": "Integrated floating cage aquageoponics system", "text": "Integrated floating cage aquageoponics system\n\nThe Integrated Floating Cage Aquageoponics System (IFCAS) was developed as an aquaculture-horticulture based on the concept of integrated farming system approach firstly in Bangladesh in 2013 to produce fish and vegetables in floating condition where waste materials (fish feces and unused feed) from fish culture dissolved in the pond water and settled on the bottom mud are used for vegetables production. Of the newly adopted term \"aquageoponics\", aqua, geo and ponics means water, mud/soil and cultivation, respectively. In fact, aquageoponics is a new version of traditional aquaponics where soil is used as a medium instead of conventional media such as hydroton, pebbles, and sponges.\n\nFilling the gap of supply and demand of fish and vegetables for improving household nutrition, the ANEP (Agriculture and Nutrition Extension Project) funded by the European Union (EU) works in Barisal District of Bangladesh following an integrated aquaculture-agriculture approach. Pond dykes in Barisal are commonly used for planting trees by the rural people which provide cooking fuel, fruits, and timber for sale. Trees on the pond dyke create shadow, which reduce sunlight penetration to the edges of the pond and the dykes. In this context, IFCAS was developed in the shaded ponds without changing the vegetative nature of pond dykes following the collegial principles of action research. In the whole process of action research, farmers, researchers and developers from Bangladesh Agricultural University (BAU), Mymensingh, Patuakhali Science and Technology University, Bangladesh, WorldFish-ANEP, and Bangladesh Fisheries Research Forum (BFRF) together were involved in the trial of this technology. The concept of IFCAS was developed by Dr. M. Mahfujul Haque (Ripon), Professor, Department of Aquaculture, BAU, Mymensingh who led the action research as the Principal Investigator.\n\nA 9 m rectangular iron-bar made structure was constructed, having four concave grooves in its four corners for holding floats of plastic drums. The whole bottom of the structure was surrounded by a rectangular nylon net cage with the dimensions of length-3.66 m × width-2.44 m × depth-1.25 m. Under the four corners and middle points of the net, half-brick weights were hung to ensure that the net retained a rectangular structure under the water. In the middle of both widths of IFCAS, two pits filled with dried pond mud of the same pond are used as medium for vegetable plantation. On the top of the structure, a scaffold was made using split bamboo and net for vegetables to climb on.\n\nCompared to other aquaculture technology, IFCAS showed several benefits to the adopting farmers. Like traditional aquaponics, fish and plants also rely on each other in aquageoponics. Here a mutual relationship exists between fish and plants. Unused fish feed and excrements result in nitrogenous wastes in the pond water and mud what are used as nutrients (nitrate) by the plants in IFCAS. Here some substrates such as, fallen leaves from horticulture plants, mud and materials in IFCAS (such as drums, iron plates etc.) harbour the nitrifying bacteria what convert toxic ammonia to less harmful nitrate. Plant roots hanging from IFCAS pits, absorb nutrients more effectively from water than plants do in traditional soil based agriculture as roots are longer and healthier in IFCAS. Like in aquaponics, plants grow faster in IFCAS also. Moreover, symbiotically plants facilitate by providing fish with ammonia free water in return. Harvesting fish and vegetables from IFCAS is very easy for both men and women. Apart from consumption of fish and vegetables at the household level, farmers earned money by selling fish from IFCAS. IFCAS is not only useful in the small shaded ponds but also in multi-ownership ponds, state-owned ponds, natural water bodies (beel), rivers, canals, and the waterlogged areas affected by climate change. Along with dissemination of this technology in Bangladesh, IFCAS has been trialed in ponds in Nepal which was found encouraging for nursing fish fingerlings and vegetables during dry season.\n\nProfessor Dr. M. Mahfujul Haque, the leading researcher of the IFCAS project, recommends a stocking density for monosex Tilapia of 100 fry per cubic meter. For vegetables, cucumber, bean, bitter melon, Asian spinach etc. are recommended. Tilapia production of 31 kg and 52 kg per 9 m were found within 120 days of period in the IFCAS placed heavily shaded and moderately-shaded ponds, respectively. On-station and farmer participatory on-farm research works are underway focusing suitable fish species combination in the cage of IFCAS to determine its optimum productivity potential.\n\n"}
{"id": "30414853", "url": "https://en.wikipedia.org/wiki?curid=30414853", "title": "Journal of Midwifery &amp; Women's Health", "text": "Journal of Midwifery &amp; Women's Health\n\nThe Journal of Midwifery & Women's Health is a bimonthly peer-reviewed healthcare journal covering midwifery and women's health. It is the official journal of the American College of Nurse-Midwives.\n\n"}
{"id": "11885308", "url": "https://en.wikipedia.org/wiki?curid=11885308", "title": "Khamisiyah", "text": "Khamisiyah\n\nKhamisiyah ( \"\") is an area in southern Iraq located approximately 350 km south east of Baghdad, 200 km north-west of Kuwait City and 270 km north of Al Qaysumah. Khamisiyah is under the administration of the province of Dhi Qar. The area contains a few small towns, including Khamisiyah and Sahalat, with an estimated population of 8,500. It is probably most noted for the Khamisiyah Ammunition Storage Facility (also known as Tel Al Lahm Ammunition Storage Facility) built and used during the regime of Saddam Hussein.\n\nThe Khamisiya Ammunition Storage Facility was a site approximately 25 square kilometres in area and consisted of two sections: one of 88 warehouses; the other of 100 hardened concrete bunkers surrounded by an earth berm and security fencing. The storage complex was in use by 1982. \n\nIn March 1991, combat engineers and Explosive Ordnance Disposal (EOD) teams of the U.S. Army, conducted a demolition operation. The entire storage complex, containing massive quantities of munitions, was set to be destroyed. On 4 March, all explosive charges were detonated, and witnesses stated that the resultant explosion yielded an impressive mushroom cloud. It has not been confirmed how this explosion affected Iraqi civilians in the area, if at all. \n\nIt was not known at the time, but destruction of ordnance at Khamisiya is thought to have consequently released nerve agents such as sarin and cyclosarin into the atmosphere. Computer-generated models based on atmospheric conditions project that clouds of nerve agents would have drifted south and reached allied troops. Records also show that Nuclear, Biological, Chemical (NBC) sensors monitoring the air soon reported traces of nerve agents. These NBC detection units were military units of several allied countries, including the United States, United Kingdom, and Poland.\n\nIt was unclear for a long time whether or not there had been chemical weapons at Khamisiya, partly because of an alternate name used by the Iraqi military (Tal al Lahm), and partly because there were other munitions storage locations in the area, including Talil Air Base and in the nearby town of An Nasiriyah. By 1996, it became clear to the Department of Defense that nerve agents were present at the Khamisiya storage facilities. In April 2002, the United States Department of Defense released two reports related to operations at Khamisiyah during the Gulf War. The first report is a final version of its case narrative \"U.S. Demolition Operations at Khamisiyah\". The second was a technical report detailing the modeling and risk characterization of possible chemical-warfare-agent exposure in the Gulf War.\n\nSome Gulf War veterans that were in the area have reported symptoms that meet the definitions of Gulf War Syndrome, while others report no symptoms. The U.S. Department of Defense is continuing investigations or is funding independent studies, has kept up attempts to keep track of veterans and monitor changes in personal status, as well as informing veterans and the public of any research-related progress. The United States Department of Veterans Affairs continues to treat veterans who report symptoms related to or resembling Gulf War Syndrome.\n\n"}
{"id": "23276330", "url": "https://en.wikipedia.org/wiki?curid=23276330", "title": "Latvian Museum of Pharmacy", "text": "Latvian Museum of Pharmacy\n\nThe Latvian Museum of Pharmacy is a medical museum in Riga, Latvia. It was founded in 1987 in association with the Pauls Stradins Museum for History of Medicine and is located on Richard Wagner street in an18th century building which itself is an architectural monument. The museum is dedicated to understanding the development of pharmacy and pharmacies in Latvia and contains documents and books from the 17th- 19th century, pharmacist tools and devices for preparing drugs, and drugs which were manufactured in Latvia in the 1920s and 1930s\n\n"}
{"id": "32392950", "url": "https://en.wikipedia.org/wiki?curid=32392950", "title": "Lifetrack Therapy", "text": "Lifetrack Therapy\n\nLifetrack Therapy, founded by the Japanese Keio educated and Harvard trained psychiatrist Dr. Yukio Ishizuka, is a new personality model and therapy based on universal spheres of psychological health. Ishizuka's willingness to learn from his patients, as well as his exposure to the East, He draws from the principles of both Zen Buddhism and quantum mechanics in his method of treatment.\n\nIshizuka developed Lifetrack therapy, an approach and methodology to help his patients experience psychological health.\n\nLifetrack Therapy, is Ishizuka's clinical positive mental health approach developed and tested since 1975. The new paradigm of health includes:\n\n\nIn 1975, Dr. Ishizuka hypothesized that three basic psychological spheres determine psychological health and self-actualization across cultures.\nThose three spheres are: the search for self, the need for intimacy, and the quest for achievement. Also referred to as the \"triad of psychological adjustment\" or \"tripod of happiness\" the three spheres are subjective, dynamic, and broad enough to encompass all psychological events. These three interconnected spheres characterize a person’s personality. A prolonged imbalance or a crisis in any one of these three key interconnected spheres of health influences the others and can trigger defensive symptoms such as anxiety, anger, physical symptoms, depression or in some cases psychosis. The tripod model of health is the basis for Lifetrack Therapy, a clinical approach drawing on the experience and insights accumulated by the daily self-rating data of more than 1,200 patients throughout their treatment on 41 parameters of mental health through periods of crisis to optimal health. The central goal for both the ‘distressed” and the “well” in Lifetrack Therapy is the same: well-being in the primary three spheres of life. Therapy sessions are focused on using crisis as an opportunity to transform the three spheres far beyond a previous best level of experience.\n\nLifetrack therapy uses a structured definition of positive mental health or wellness state as the central objective of therapy. Keeping the needs of his patients in mind, where Ishizuka understood the subjective response to life events to be a cause of human suffering, he hypothesized that there may be subjective spheres of life which contribute to happiness or suffering more than others. By defining three subjective spheres that contribute to well-being, Ishizuka provides a conceptual framework for positive mental health. Ishizuka's definition of the three spheres includes a breakdown of each sphere into three dimensions with nine elements each (a total of 27 parameters). States of well-being (peace, friendliness, physical wellbeing, happiness and mastery), stress (anxiety, anger, physical symptoms, depression and psychosis), physical health, and correct substance are also defined by the model contributing to a total of 41 positive mental health parameters.\n\nFor an individual to become happier or to grow in a short period of time there needs to be a means for him or her to actively think, feel and act in ways that foster positive mental health. In the experience of Lifetrack, the ability to improve the subjective world far beyond a previous best requires an active focus of one's mental states throughout therapy. Ishizuka has found that using simple definitions of positive mental health as the objective of therapy and a subjective 10 point rating scale, one can track subjective responses to life events. For example, if you depend on your spouse or significant other at only a 5 on a 10-point scale, that implies that you can think, feel and act in ways that allow you to more graciously depend.\" With his patients taking five to ten minutes daily to track self, intimacy and achievement spheres, as well as positive peaks of well-being (peace, friendliness, physical-health, happiness, mastery), negative peaks (anxiety, anger, physical symptoms, depression, psychosis), physical health, and proper use of food, beverage, or other substances, focus on incremental thinking, feeling and acting is encouraged. In therapy, Ishizuka actively uses setbacks as a means to promote growth in the three spheres. Together, the therapist and the patient use the definition of positive mental health and the subjective daily rating of the patient in 41 mental health parameters to focus weekly therapy sessions on overcoming setbacks and building health beyond a previous best level of adjustment.\n\nThe new methodology was inspired by Ishizuka's background in medicine and business, and from the needs of his patients. Although the quantification of positive mental health has limitations,\nIshizuka points out that similar limitations may exist in quantum mechanics in that the observer influences what he is observing, and that the mind can only experience one aspect of a phenomenon at a specific point in time.\n\nAccording to Ishizuka, the subjective experience of happiness, well-being, depression and the like cannot be adequately or fully described but only experienced by each individual. Since this is the case we should be aware of limits in attempting to define, quantify or track well-being or happiness. Despite that happiness and depression are not steady states, but can change from one moment to the next, Ishizuka's experience shows that repetitive self assessments according to the same fixed model yield highly valuable information. In this sense, individual self ratings in Lifetrack on one health parameter are much like a droplet in the fountain of our psychological experience. These droplets when viewed individually or in isolation may not tell us much. However, when a person uses the same model to track psychological health consistently over time, the collection of droplets accumulate creating patterns, much like the shape of a fountain.\n\nThe goal in positive mental health is not to compare psychological health or well-being between two or more individuals or to decide who is healthy and who sick, but to build and strengthen psychological health within the same individual over a period of time. In this respect, psychiatry has much to learn from physics. The physicist Finkelstein was also aware on how “experience” in the exact science of physics cannot be fully communicated to others. However, the physicist argued that if we can show how to make the experience happen and show how to measure it, then we can help others to have it. This is precisely what has been done in Lifetrack therapy.\n\nThe central goal for both the ‘distressed” and the “well” in Lifetrack Therapy is the same: health and well-being in the primary spheres of life. The focus of therapy is optimal psychological health in the three spheres, rather than the immediate elimination of distressing symptoms. Efforts are focused in therapy sessions on improving the three spheres far beyond a previous best level of experience. Therapy terminates when one has successfully established and sustained new and better balanced patterns of coping in all three spheres, not when symptoms such as depression initially decrease or disappear.\n\nWhile the scale for inner health has no optimal limit, under optimal conditions in Lifetrack therapy (one person in the couple is in sufficient distress, there is an effective therapist who can work with both, and the ‘well’ partner is willing to help), a complete transformation of personality, or breakthrough in the self, intimacy, and achievement spheres far beyond a previous best level, may be achieved in 3–6 months.\n\nIn Lifetrack therapy the therapist interprets the graphs of the patient’s subjective self-rating in weekly therapy sessions on a computer screen (daily when the patient is in the hospital or otherwise require intensive therapy). The active role of the therapist and a patient data tracking system that measures, tracks and focuses growth in one's self, intimacy and achievement spheres, helps place setbacks or crisis into proper perspective. Visualizing both breakthroughs and setbacks with the therapist in key areas that constitutes positive mental health has become an important tool and component of Lifetrack therapy leading to the following insights on the mind:\n\nThe accumulated evidence of daily self-rating data of more than 1,200 patients throughout their treatment on 41 parameters of health include:\n\n\nEven when individuals desire to build inner health (self, intimacy and achievement), due to fear, they can think, feel, and act in a contrary fashion. Such fear is found in all individuals, healthy or ‘diseased’ to varying degrees and can be triggered when a previous best level of adjustment is surpassed by the challenge one faces. For therapists and patients, understanding the nature of this fear, and predicting it ahead of time, is critical to overcoming it. An effective Lifetrack therapist reminds the patient that the very progress he is making provokes setbacks, and that each setback opens the way to further breakthrough and advance.\n\n\nOf the three spheres, Ishizuka has found that intimacy is the most central to health and also the most important conduit for fundamental personality transformation through therapy. According to Ishizuka, within the intimacy sphere, the adult couple relationship is far more important than even the best therapeutic one. More than an analysis of the past parent-child relationship or a lengthy dependence on a therapist, the couple relationship allows the individual to give and receive love, overcoming fear that may have arisen through a difficult past, failed adult relationships, fear of the unknown, or even ‘isolated’ setbacks in the achievement or self sphere that have seemingly nothing to do with intimacy. In short, intimacy is a conduit to rapid and dramatic inner growth. Even when the initial problem manifests itself in the form of a crisis in the achievement or self sphere, successful Lifetrack therapy for adults always focuses on making a breakthrough in intimacy first. This is due to the primary role that intimacy plays in human growth as well as its importance in sustaining a personality under distress (when the self and achievement spheres have collapsed). In the safe context of Lifetrack therapy, couples learn to overcome defensive symptoms on both sides. The objective is to attain a much higher level of intimacy where defenses such as anxiety, anger, physical symptoms, depression or psychosis recede and allow positive peaks of peace, friendliness, physical wellbeing, happiness and mastery to become dominant.\n\n\nIn successful Lifetrack therapy, where the individual emerges far beyond a previous best level of adjustment in his sense of self, intimacy and achievement, four stages of transformation have been observed. These four stages are the path of personality transformation (or growth) through crisis. The primary instigator of inner growth is the intimacy sphere in stages I and II. Self and achievement catch up to intimacy in stage III and stabilize and continue to advance together at much higher levels than a previous best experience in stage IV.\n\nIshizuka’s personality model, the Lifetrack model, fulfils all six conditions for measuring health by Jahoda while also integrating an understanding of ‘disease.’ Used and tested by patients who experience profound psychological distress as well as optimal health in their self, intimacy and achievement spheres, the Lifetrack model constitutes a new paradigm in health and as well as new form of clinical therapy.\n\nLifetrack uses little to no drugs and considers medication, for the most part, as symptom relief. Hence, the Lifetrack model in the current context of psychiatry that focuses on drug treatment, and allots little time to psychotherapy may not be ideally conducive to practice Lifetrack Therapy. While psychologists, social workers, marital counsellors and coaches trained in ‘talking cures’ may also be particularly effective with Lifetrack Therapy, due to strong defensive reactions (anxiety, anger, physical symptoms, depression, psychosis) that can be triggered in a minority of highly defensive individuals, psychiatrists trained in this therapy are advised to work with social workers and psychologists to help deal with all possible contingencies, including the use of medication and possible hospitalizations.\n\nAnother limitation to the new paradigm of health is that little academic literature or clinical teaching exists on the model (the book Self-Actualization is in Japanese). Ishizuka continues to give precedence to his patients and breaking clinical ground in therapy, over publishing, research, teaching or the dissemination of his ideas in academia. For English therapists interested in Lifetrack therapy, Ishizuka has presented at the APA (American Psychiatric Association Annual Meeting) and other world congresses, and has several professional publications in English including Lifetrack Therapy, Intimacy and Stress: Effective Therapeutic Intervention, Causes of Anxiety and Depression in Marriage, and Conjoint Therapy for Marital Problems, Divorce: Can and Should it be prevented? While the online tracking of health parameters is available for therapists and patients through Lifetrack.com and is systematically presented through cases for therapists in an eBook for therapists; Breakthrough Intimacy – Sad to Happy Through Closeness, or compared to other approaches such as Maslow, Murray, Freud and others on Positive Mental Health Foundation, these teaching materials give preference to those familiar with online technologies. For Lifetrack to spread, additional clinical teaching or academic literature may be useful.\n\nThe Lifetrack model incorporates both an understanding of disease and optimal health. Lifetrack defines, measures, and tracks positive mental health and provides a clinical method useful to patients to improve psychological well-being. With humanistic models of man, such as the Lifetrack model, which integrate both optimal health and disease in the same model, psychiatrists and clinical psychologists can help individuals develop and maintain health as the objective of therapy while addressing inevitable crisis and inner growth. Just as positive psychology can inform clinical psychology, clinical models in psychiatry based on health may also inform the field of psychology, including positive psychology, known to study Maslow, Rogers, Fromm, and Murray.\n\nThe Lifetrack model, based on an understanding of psychological health and healthy human beings, can have implications on other fields such as conflict negotiation (Harvard’s Program of Negotiation) or any field that makes simple assumptions about human beings such as transaction cost economics (Oliver Williamson, 2009 Nobel Laureate). With models of man that integrate both an understanding of health and disease, we are better suited to go beyond the field of psychology and apply insights from the “normal” functioning of the mind to political science, economics, international affairs, nations and organizations.\n\n"}
{"id": "9025342", "url": "https://en.wikipedia.org/wiki?curid=9025342", "title": "List of UN numbers 3101 to 3200", "text": "List of UN numbers 3101 to 3200\n\nThe UN numbers from UN3101 to UN3200 as assigned by the United Nations Committee of Experts on the Transport of Dangerous Goods.\n\n"}
{"id": "2195555", "url": "https://en.wikipedia.org/wiki?curid=2195555", "title": "List of dams and reservoirs in Iran", "text": "List of dams and reservoirs in Iran\n\nMajor dam construction started in Iran in the 1950s. Some fourteen large dams were built with the help of foreign engineers and advisors during two decades preceding the Islamic Revolution. \n\nIn the post-revolution era, Iran's dam building capacity was significantly strengthened, with some 200 contracting companies, 70 consultant firms and 30 corporations as well as hundreds of hydroelectric manufacturing units having been established inside of Iran in less than three decades. In addition to the necessity of generating electricity, Iran needs dams to effectively control and manage a growing water shortage across the country. \nIran was constructing 88 small and large dams in 2007. On average, close to two billion cubic meters of water are added to the country’s water reserves annually. As of 2010, Iran has constructed 588 dams (big and small), with 137 more under construction and 546 planned.\n\n\n\n\nOne of Iran’s most important international projects will see the construction of a $200-million hydroelectric dam in Nicaragua starting 2011. Iran is currently engaged in dam construction in Tajikistan, Armenia and Azerbaijan, and consultations are underway with a number of other countries. Kenya, Sri Lanka, Bolivia and Mali are the potential target markets being considered for exporting the country’s technical and engineering services. In 2010, Iran won a contract to build a dam in Afghanistan and the third contract to build a power plant station in Syria.\n\n\n\n"}
{"id": "32842267", "url": "https://en.wikipedia.org/wiki?curid=32842267", "title": "List of deaths at the Berlin Wall", "text": "List of deaths at the Berlin Wall\n\nThere were numerous deaths at the Berlin Wall, which stood as a barrier between West Berlin and East Germany from 13 August 1961 until 9 November 1989. Before the rise of the Berlin Wall in 1961, 3.5 million East Germans circumvented Eastern Bloc emigration restrictions, many by crossing over the border from East Berlin into West Berlin, from where they could then travel to West Germany and other Western European countries. Between 1961 and 1989, the Wall prevented almost all such emigration.\n\nThe state-funded Centre for Contemporary History (ZZF) in Potsdam has confirmed at least 140 deaths, including people attempting to escape, border guards, and innocent parties. However, researchers at the Checkpoint Charlie Museum and some others had estimated the death toll to be significantly higher.\n\nThe escape attempts claimed the lives of a wide variety of people, from a child as young as one to an 80-year-old woman, and many died because of the accidental or illegal actions of the guards. In numerous legal cases throughout the 1990s, several border guards, along with political officials responsible for the defence policies, were found guilty of manslaughter and served probation or were jailed for their role in the Berlin Wall deaths. Out of an estimated number of 5,000 escapees, a total of 239 people died while trying to cross the Berlin Wall. \n\nAfter World War II, Berlin had been divided into four sectors controlled by the Allies: the US, the Soviet Union, Great Britain and France. The sector borders inside the city could in general be used freely for passage out of the German Democratic Republic, even after the border between the Federal Republic of Germany and the GDR had been continually closed off, starting in 1952. The outer border of West Berlin, which was also the border between West-Berlin and the GDR, had also been closed down in 1952. During the night of 12 to 13 August 1961 the National People's Army, the German Border Police, the Volkspolizei and the Combat Groups of the Working Class locked down all passages between the Soviet sector and the three West sectors; construction of border protection facilities began.\n\nDuring the first years border fortifications inside the city mostly consisted of brick walls with a top made of barbed wire. Clay bricks and concrete slabs were used for construction. Further obstacles of barbed wire and upstate walls delimitated the East and at some places, like Bernauer Straße, bricked-up buildings formed the boundary line. The buildings were situated on East-Berlin territory, whereas the pavement in front of the houses belonged to West-Berlin. In many places safety installations of West-Berlin's outer ring consisted of metal fences and barbed wire barriers. Technologically advanced upgrading took place later on and only in 1975 L-shaped concrete segments that were known from the fall of the Wall were added.\n\nIdentifying deaths specifically attributable to the Berlin Wall is not straightforward. Although East Germans were aware of deaths on the Wall from West German media broadcasts which they were able to receive, reliable information was closely held by the East German authorities. A number of different West German institutions kept their own records. These included the West Berlin police, the Central Registry of State Judicial Administration in Salzgitter (which tracked all border fatalities) and the Arbeitsgruppe 13 August (Working Group 13 August), a West Berlin association. Within the jurisdiction of the West-Berlin police, the State Security Department was responsible for the registration of known incidents. The records distinguish between individuals who died at the outer border of West-Berlin (80 incidents), unclear incidents (with 5 possible wall victims) and border guards who were shot. The Central Registry of State Judicial Administrations in Salzgitter, was also given a mandate to collect evidence of actual or attempted murder in the GDR. In 1991, it published the \"Salzgitter-Report\" with the names of 78 victims. However, since the Registration Agency had no access to the GDR archives, the data was regarded as incomplete. Both agencies mainly listed incidents that could have been observed from West-Berlin or had been reported by fugitives or border patrols who left the GDR.\n\nAfter the fall of the Wall, criminal investigations into border killings were launched by the Investigating Agency for Governmental and Party Crimes (ZERV) and the Berlin public prosecutor's office. Each of these institutions used different criteria to count deaths. In 2000, the ZERV compared data from the central registration office in Salzgitter with findings in GDR archives and made a total of 122 cases of targeted killing by GDR state organs at the border to West-Berlin. This list was a pre-inquiry for the prosecution departments of Berlin and Neuruppin, which in turn gave attention to legal processing. The Salzgitter registry recorded incidents in which \"suspicion of a criminal act was justified\", while the Arbeitsgruppe 13 August, which also manages the house at Checkpoint Charlie and is run by the artist Alexandra Hildebrandt, widow of the founder Rainer Hildebrandt, counted \"all victims who died in connection with flight and/or the border regime\", including deaths by accidents or drowning, or deaths of border soldiers and policemen in suicides or firearms accidents. This gave them the figure of 235 deaths compared to the significantly lower number of 78 according to the Salzgitter registry.\n\nThe results, which are described as \"temporary\" by the working group, are regularly presented at press conferences on 13 August. The list is consistently revised with new cases being included and old ones abandoned. The Checkpoint Charlie Museum gives the number at 245 deaths, though this includes suicides by border guards and bodies found in the water even when there was no obvious link to them being an escapee. They also state that the first person to die at the Wall was in fact an East German officer who committed suicide.\n\nIn 2005, the Gedenkstätte Berliner Mauer (Centre for Contemporary History and the Berlin Wall Memorial Site and Documentation Centre) established a research project to definitively \"establish the number and identities of the individuals who died at the Berlin Wall between 1961 and 1989 and to document their lives and deaths through historical and biographical research\". The project was funded by the Federal Agency for Civic Education, Deutschlandradio and the Federal Commissioner of Culture and Media. The results were published on the website www.chronik-der-mauer.de and in a book titled \"Todesopfer an der Berliner Mauer\" (2009). The project outlines the victims' biographies, the causes of death and the sources that were used. At the time, no reliable or official information was available about the number of fatalities at the Wall. The project found that 136 people had died, using the criteria of \"either an attempted escape or a temporal and spatial link between the death and the border regime\". Not all had died immediately – one fatality occurred years later – and not all were caused by acts of violence. After reviewing 575 deaths, the project team found that at least 140 people died in shootings, were killed in accidents or committed suicide after failing to cross the Wall.\n\nEvery investigation committee had its own criteria of which cases could be counted as wall victims. The ZERV investigations focused on a working legal guilt, while the ZZF and the Arbeitsgemeinschaft 13. August developed their own criteria that went beyond purely legal guilt. The ZZF criteria required the victim to have a background for the attempted escape or to have both a temporal and a spatial connection to the border regime. Five groups were developed from the examined cases:\n\n\nThe definition coined by the Arbeitsgruppe 13. August reaches further. It includes border guards that committed suicide and cold cases involving bodies found in boundary waters.\n\nHowever, a thorough investigation of all natural cases of death has not been completed yet. One third of all files from the police of transport are gone, entire annual reports of the 1970s are missing. Analyzing the daily records of border guards and to examine activities in areas that had been under surveillance might have presented an alternative but could not be realized because of financial issues. Another 16 cases of drowning could not definitively be connected to the Wall. Many other travellers from East and West Germany and Czechoslovakia died immediately before, during or after passing through checkpoints in Berlin, with a published figure of 251 deaths: most were the result of cardiac arrest.\n\nThe exact number of casualties is unknown. There are different numbers that each derive from different investigations that used different definitions of what a victim in this case should be. Therefore, the numbers are hardly comparable. On top of that, some results are published infrequently or investigations were ceased with a provisional number. There is also a publicly held controversy between two groups regarding the number of victims. The opponents are the Arbeitsgemeinschaft 13. August and the ZZF. The former's numbers are higher, as they include, according to ZZF's Hans-Hermann Hertle, victims with an unclear or unsure connection to the border regime. After the ZZF published its interim results in August 2006, Alexandra Hildebrandt of the Arbeitsgemeinschaft has accused them of withholding numbers to invoke a more positive picture of East Germany. She argues that the ZZF project was funded by a coalition of social democrats and leftists.\nIn 2008 the Arbeitsgemeinschaft claimed that since 1961 222 people had died because of the Berlin Wall. Hertle doubted these numbers, as they evidently included some survivors. As of 2006, 36 survivors were listed as deceased because of the Wall, and some victims were mentioned more than once. Because of these shortcomings, he assessed the list as an \"extensive record of suspected cases\" that \"failed to set up a scientifically verifiable standard\". Berlin's Governing Mayor Klaus Wowereit commented on the dispute with the words \"Every single dead was one too many.\" In 2009, Hildebrandt reported of 245 dead caused by the Wall. According to her research, the first Wall victim was a suicidal GDR officer and not Ida Siekmann, as Hildebrandt also included border guards that committed suicide and cold cases of bodies found in boundary waters in her list. Another difference in Hertle's and Hildebrandt's list can be explained by the fact that Hertle had additional access to incomplete files from transport police. Therefore, their accounts vary in regard to the people that died of natural causes during border controls. Hurtle argues with a total of 251 of such cases, while Hildebrandt only compiled 38 of these cases.\n\nInformation on the dead can be found mainly in the administrative and military archives of West and East Germany. However, the records of Stasi, which were administered by the Stasi federal commissioner, are not completely accessible. Some parts, especially from the later years, were destroyed when the ministry was disbanded, some are not yet sifted. Additionally, due to the Stasi records law, many records can only be looked at in the form of anonymized excerpts. An amendment from 2007 allows direct access to research projects, provided certain conditions are met. The East German Border Troop records are kept at the Bundeswehr archive, as the border troops were part of the East German National People Army. According to Hertle, when border troop, Stasi and the records from Western authorities are evaluated, one has to take into account the \"values, interests and constraints of the record-keeping authorities and, by extension, of the respective power relations.\" The families of the victims can be another source, but were often fed with false information and therefore can only seldom answer questions regarding the events themselves.\n\nWhen Berlin was a divided city, the Berlin Wall ran along Bernauer Straße. The street itself belonged to the French sector of West Berlin and the East German authorities declared that the windows and doors that led out onto Bernauer Straße should be bricked up. In the early morning of 22 August 1961, Ida Siekmann was the first of 98 people to die while attempting to escape. She was living on the fourth floor of number 48 (third floor, 3te Stock, by German standards), threw bedding and some possessions down onto the street, and jumped out of the window of her apartment. She fell on the sidewalk and was severely injured, dying shortly afterwards on her way to the Lazarus Hospital. On 8 March 1989, Winfried Freudenberg became the last person to die in an attempt to escape from East Germany to West Berlin across the Berlin Wall by falling from a hot-air balloon.\n\nThe Berlin Wall, like the much longer inner German border between East and West Germany, was designed with two purposes in mind: to obstruct would-be border-crossers and to enable border guards to detect and stop illegal border crossings. In its final form, the wall consisted of inner and outer concrete walls separated by a \"death strip\" some to wide. It was guarded by around 11,500 \"Grenztruppen\", the Border Troops of the German Democratic Republic who were authorised to use any means necessary, including firearms, to prevent border breaches. The shooting orders, or \"Schießbefehl\", issued to the border guards instructed that people attempting to cross the Wall were criminals, and that the use of deadly force was required to deal with them: \"Do not hesitate to use your firearm, not even when the border is breached in the company of women and children, which is a tactic the traitors have often used\". Some guards have since claimed that the motto at the time was \"a dead refugee is better than an escaped one\". At first, wounded or shot refugees were left out in the open until they were removed, so that people from West Berlin and the western press could see them as well. After the reactions to the public death of Peter Fechter, border guards were ordered to move any casualties out of West Berlin's field of view. Negative reporting was sought to be prevented. Because of this, border guards often pulled people down into the car-moat that was part of the whole border security system. In some cases, the removal of the body was done only after nightfall.\n\nThe principal cause of death was shooting. Of the 140 fatalities, 99 (70.7%) were shot dead, not only escapees but also individuals on either side who were not attempting to escape, and East German border guards killed on duty. 101 of the fatalities were attempted border-crossers, of which all but three were East Germans (the exceptions were Franciszek Piesik and Czesław Kukuczka, Polish citizens, and Vladimir Ivanovich Odinzov, a Soviet Soldier). 68 of them were killed in shootings. Another 30 people died as a result of shootings or fatal accidents sustained while in the vicinity of the Wall but not trying to cross it. Eight East German border soldiers were killed on duty by escapees, escape helpers, fellow soldiers, or the West Berlin police. Three people committed suicide after escape attempts failed.\n\nAbout half of those who lost their lives on the Wall were killed in the first five years after it was originally installed. Death rates fell from then on, and took a particularly dramatic downturn after 1976. Nearly 86% of the Wall's victims, 120 people, died between 1961 and 1975; between 1976 and 1989 only 19 died. Several factors account for this reduction. The Wall became even more impregnable owing to technical improvements carried out in the mid-1970s and more restrictions were put on the area adjoining the Wall, making it more difficult to reach in the first place. The signing of the Helsinki Accords in 1975 led to new opportunities to cross the border legally, resulting in a rise in emigration applications and a corresponding fall in escape attempts.\n\nAround two-thirds of the victims were killed in inner Berlin, accounting for 93 of the 140. Berlin-Mitte and Treptow were the inner-city districts with the most fatalities; nearly half of the 64 escapees who died on the sector border lost their lives in those two districts. The remaining third died on the city's outskirts where the suburbs of West Berlin intersected with towns and villages in East Germany. Several victims, including most of the children, drowned in the Spree or the Havel.\n\nMost of those who died (comprising 78% of the fugitive victims) were young men aged between 16 and 30. Married men accounted for 20% of the deaths while only 8 (6%) were women. Nine children younger than 16 years old died, whereas 94 victims were aged between 21 and 30. The overwhelming majority came from East Berlin and the surrounding area.\n\nTheir motives for escaping evolved over time. Those who fled in the years shortly after the Wall was built had experienced the formerly open border first-hand and often had relatives in the West or had traveled there. By contrast, later escapees had grown up with the closed border, desired greater freedom and were dissatisfied with conditions in East Germany. Their attempts to escape were often triggered by specific events such as a wish to avoid conscription, repression by the authorities or the refusal of a request to emigrate. Many escapees had previously clashed with the state authorities and had been imprisoned for political offenses, often related to earlier unsuccessful escape attempts.\n\nThe use of lethal force on the Berlin Wall was an integral part of the East German state's policy towards its border system. Nonetheless, the East German government was well aware that border killings had undesirable consequences. The West German, US, British and French authorities protested killings when they occurred and the international reputation of East Germany was damaged as a result. It also undermined the East German government's support at home.\n\nThe Stasi, East Germany's secret police, adopted a policy of concealing killings as much as possible. In the case of the November 1986 shooting of Michael Bittner at the Wall, a Stasi report commented: \"The political sensitivity of the state border to Berlin (West) made it necessary to conceal the incident. Rumours about the incident had to be prevented from circulating, with information passing to West Berlin or the FRG [West Germany].\" The Stasi took charge of \"corpse cases\" and those injured while trying to cross the border, who were transported to hospitals run by the Stasi or the police where they would recuperate before being transferred to Stasi prisons. The Stasi also took sole responsibility for the disposal of the dead and their possessions. Bodies were not returned to relatives but were cremated, usually at the crematorium at Baumschulenweg. Occasionally the cost of the cremations was covered by the victims themselves using money taken from their pockets.\n\nStasi officers posing as policemen would inform the relatives, though not before trying to obtain \"valuable pieces of information on the border violation\". Deaths would be stated as being due to \"a border provocation of his own causing\", \"a fatal accident of his own causing\" or \"drowning in a border waterway\". Every border death was investigated in detail to identify how the attempt had been made, whether there were any vulnerabilities in the border system that needed to be remedied and whether anyone else had been involved. If necessary, the family, relatives, friends, colleagues and neighbours were put under surveillance. The reports produced following such cases were sent to the relevant member of the East German Politburo for consideration.\n\nThe one exception to the general rule of concealment and obfuscation was that of border guards who died on duty. Most were killed either deliberately or accidentally by escapees or escape helpers. The dead guards were hailed by East German government propaganda as heroes, but West German public opinion was divided about the morality of killing border guards. Some took the view that escapees were entitled to use force in the course of crossing the border, but (as in one case tried in a West Berlin court) others saw the guard's life as taking priority over an escapee's freedom.\n\nIn those cases they did not manage to conceal, however, the GDR's media was subject to stringent controls by the Stasi as well as the Socialist Unity Party of Germany, using \"Neues Deutschland\", the GDR's second largest daily newspaper, as their \"zentralorgan\". Through its own television station, the GDR government controlled the content shown in television broadcasting as well. The GDR border troops' actions were being portrayed as legitimate border defense and the people who were killed while trying to escape were defamed both in official statements as well as in reports of the state-controlled media. In 1962, East German journalist Karl-Eduard von Schnitzler commented on the death of Peter Fechter in the television program \"Der schwarze Kanal\": \"The life of every single one of our brave boys in uniform is worth more than the life of a lawbreaker to us. Staying away from the border, you can save yourself blood, tears and screams.\" SED newspaper \"Neues Deutschland\" claimed Fechter was driven into suicide by \"front city bandits\" as well as accusing him of being homosexual. In similar fashion, Günter Litfin was falsely depicted as being a homosexual, a prostitute as well as a criminal. In 1966, the \"Berliner Zeitung\" depicted Eduard Wroblewski as antisocial and being wanted as a Foreign Legionnaire for serious crimes in the district of Halle. These cases were exemplary of representatives of the press constructing false allegations in order to defame killed escapees.\n\nIn cases of death, the Abgeordnetenhaus of Berlin and Mayor issued statements of indignation concerning the deceased, the Wall and the situation in the GDR. In some cases, the Senate of Western Berlin asked the respective American, British or French authorities to lodge a protest at the Soviet site. Up until the late sixties, terms like Wall of Shame (German: \"Schandmauer\" or \"Mauer der Schande\") were used by politicians from Western Berlin to denominate the wall. Speaking to the press, representatives also used misrepresented incidents as examples and depicted GDR state organs as responsible. After Rudolf Müller had shot the border guard Reinhold Huhn and flown west through a self-made tunnel, Egon Bahr, speaker of the Senate at that time, announced he had only thrown him an \"uppercut\". The western press also adopted this misstatement and used the heading \"trigger-happy Vopos (colloquial German term for \"Volkspolizei\", the East German People's Police) killed own post.\" In other cases, the press published stories using drastic language to accuse the Wall as well as the people in charge. After Günter Litfins death, the \"B.Z.\"-tabloid wrote: \"Ulbricht's manhunters became murderers!\" The Frankfurter Allgemeine commented on the \"brutal cold-bloodedness\" of the guards.\n\nThe cases that were known in West Berlin provoked demonstrations among the population. Members of the Senate inspected the crime scenes and spoke to the press as well as public audiences. Various groups, and also individuals, launched protest campaigns against the Wall and the shootings. The fact that Peter Fechter bled to death in plain view of the public without anybody being able to help him lead to spontaneous mass demonstrations, which in turn resulted in riots in the following night. West Berlin policemen and US soldiers prevented a storming of the Wall. Buses bringing Soviet soldiers to the Tiergarten where they were to guard the Soviet War Memorial were pelted with stones by protesters. The incident also lead to anti-American protests, which were condemned by Willy Brandt. In the ensuing time, loudspeaker cars were sporadically set up at the Wall, urging the GDR border guards not to shoot at refugees and warning them of possible consequences. As a result of the shootings, West German groups lodged complaints with the UN Commission on Human Rights. The non-partisan Kuratorium Unteilbares Deutschland (Committee for an Indivisible Germany) sold protest placards and lapel pins in all of West Germany against the border regime and its consequences. Initially, West Berlin's regulatory authorities gave fugitives covering fire if they were being fired at by GDR border guards. This resulted in at least one lethal incident on 23 May 1962, when the border guard Peter Göring was shot dead by a West Berlin policeman while firing 44 times at a fleeing boy.\n\nIn 1991 Berlin's public prosecution department rendered this incident assistance in emergency and self-defence in consequence of the police officer stating that he felt his life being threatened. In many cases West Berliner rescuers were not able to reach wounded persons because they were either on GDR territory or in East Berlin. They had no authorization to set foot into this territory, so that a trespassing would have been life-endangering for the rescue workers. The four children Çetin Mert, Cengaver Katrancı, Siegfried Kroboth and Giuseppe Savoca, who fell into the Spree at the Gröben riverside between the years 1972 and 1975, could not be rescued even though West Berlin rescue forces arrived quickly on site. In April 1983 the transit passenger Rudolf Burkert died of a heart attack during an interrogation at the border checkpoint Derwitz. During a subsequent autopsy in West Germany several external injuries were detected, so that an external forceful impact could not be ruled out as the cause of death. This lethal incident resulted not only in negative press reports but also led to an intervention by Helmut Kohl and Franz Josef Strauss. For the imminent public-sector loans they imposed on the GDR the condition to conduct humane border controls. Two further deaths of West Germans in transit traffic, shortly after Burkert's death, set off demonstrations against the GDR regime and a broad media discussion. In the period that followed inspections decreased in transit traffic.\n\nAfter cases of death became public, the Western Allies lodged a protest at the Soviet government. In many known cases, the Western Allies did not react to requests for help. In the case of Peter Fechter, local US soldiers stated that they were not allowed to cross border and enter East Berlin, although this was permitted to Allied military personnel when uniforms are worn. Major General Albert Watson, Town Major at that time, thus contacted his superiors in the White House, without receiving clear orders. Watson said: \"This is a case for which I don't have any imperatives.\" President Kennedy was concerned over this issue and dispatched Security Advisor McGeorge Bundy to the Town Major to call for preventative measures against such incidents. Bundy, who already resided in Berlin for a pre-scheduled visit in 1962, informed Willy Brandt about the President's intention to back him up on this issue. He however clarified to Brandt and Adenauer, that US support ends at the wall, as there will be no efforts to dislodge it. Ten days after Fechter's death, Konrad Adenauer contacted the French President Charles de Gaulle, to send a letter to Nikita Khrushchev through him. De Gaulle offered his cooperation. Under the involvement of Willy Brandt, the four City Commanders reached an agreement concerning military ambulances from the western allies, which were now allowed to pick up injured persons from the border zone, to bring them to hospitals in East Berlin.\n\nMany of those involved in the killings at the Berlin Wall were investigated in a number of legal proceedings. Trials investigated border guards and senior political officials for their responsibility for the killings, some of which were believed to be unlawful.\n\nMembers of the National Defence Council, the political group responsible for the policies regarding the Berlin Wall, and the Socialist Unity Party of Germany (SED) were brought to court in the 1990s. In 1997 Egon Krenz, who had in 1989 become the last Communist leader of East Germany, was sentenced to six-and-a-half years in prison for the manslaughter of four Germans who were shot while attempting to cross the Berlin Wall. Other men to be given jail sentences include the Defence Minister at the time, Heinz Kessler, his deputy Fritz Streletz, Günter Schabowski and Günther Kleiber.\n\nIn 2009 an interview with Kessler showed that, although he was sad about the deaths, he believed the Wall should never have been removed:\n\nI deplore the fact that East Germans were shot while trying to flee westward, but the Berlin Wall served a useful purpose. It contributed to a polarisation between the two blocs, but it also gave a certain stability to their relationship. While the Wall was standing, there was peace. Today there's hardly a place that isn't in flames. Were you ever in East Germany? It was a wonderful country!\n\nTwo other key members of the National Defence Council, chairman Erich Honecker and Stasi leader Erich Mielke, were also investigated. However, during the trial both men were seriously ill and the court controversially decided to drop the cases. Honecker died in 1994 and Mielke, who had served some time in jail for the 1931 murder of two police captains, died in 2000.\n\nMany guards were themselves investigated for their actions, with the final case closing on 12 February 2004. In some of the cases there was insufficient evidence to identify which guard had fired the fatal shot and thus no prosecution could be made. Others were sentenced to probation for their role in the shootings. Only the guard who shot Walter Kittel was charged for manslaughter and sentenced to 10 years in prison. Numerous guards were the same ones who had been awarded a Medal for Exemplary Border Service or other award for the killing.\n\nThe Centre for Contemporary History and the Berlin Wall Memorial Site and Documentation Centre identified 136 people who died at the Berlin Wall. They detailed the event surrounding each death, stating where possible the role of the person. This is listed here as:\n\nNote: Some deaths occurred days or even years after the event at the Berlin Wall, with all the victims later dying in hospital.\n\nThere has been commemoration of the victims both before and after the German reunification. There are various memorial sites and memorial services. There are also streets and squares that have been named after the dead.\n\nIn remembrance of the victims there have been erected numerous memorial sites, funded by private initiatives and public bodies on the orders of the Berlin boroughs, the Berlin House of Representatives or the federal government, which are placed over various places in Berlin. The oldest date back to the days when the Wall was still standing. They include monuments, crucifixes and memorial stones, and were visited by foreign politicians during state visits. Together with the border installations, there were also some memorial sites that were removed when the Wall fell. Sites for fallen border guards were especially affected by this. Until the tenth anniversary of the building of the Wall, for every victim the private Berliner Bürger-Verein (\"Berlin Citizen Association\") placed a white wooden cross at the scene of the event. They were aided in their effort by the senate of West-Berlin. On 13 August 1971, the memorial site Weiße Keuze (\"White Crosses\") was inaugurated on the east side of the Reichstag building.\n\nOn a fence in front of the wall, there were memorial crosses with the names and date of death on them. However, since the government moved to Berlin, the white crosses had to be relocated in 1995 from the eastern side of the Reichstag. The new location is on the west side of the building at a fence of the Tiergarten. 2003, Wolfgang Thierse inaugurated a new memorial designed by Jan Wehberg with the same name as the one on Reichstagufer. On seven both-sided inscribed crosses are the names of the 13 deaths. Another memorial of the Civil Association was in Bernauer Straße. Other victims are remembered through commemorative plates embedded in sidewalks and other installations which are nearby their death spot. On October 2004, the Working Group 13 August built the Freedom Memorial at Checkpoint Charlie. It reminds people of the victims of the Berlin Wall and the inner German border with 1067 crosses. The memorial had to be removed after about half a year because the landowners terminated the lease with the working group.\n\nWith the help of other artists, performance artist Ben Wagin founded the Parliament of Trees in the former death strip on the east side of the Spree River, opposite the Reichstag. 258 names of victims of the Wall are listed on granite slabs. Some listed as \"unknown man\" or \"unknown woman\" are merely identified with a date of death. The collection, which was created in 1990, contains people who were later not considered to be victims of the Wall. Black and white painted segments of the Wall stand in the background. The memorial needed to be minimized for the construction of the Marie-Elisabeth-Lüders-Haus. In 2005, a further memorial was opened in the basement of the Bundestag building. They used wall segments of the former Parliament of Trees. In 1998, the Republic of Germany and the state of Berlin established the Berlin Wall Memorial on Bernauer Straße and declared it as a national memorial. The memorial harks back to a draft drawn up by the architects Kohlhoff & Kohlhoff. Later, it was extended and today it includes the Berlin Wall Documentation Center, a visiting center, the Chapel of Reconciliation, the Window of Remembrance with portraits of those who lost their lives on the grounds of the Berlin Wall, and a 60-meter-long section of the former border installations which is enclosed by steel walls at both ends.\nThe northern wall bears the inscription:\"In memory of the city's division from 13. August 1961 to 9. November 1989 and in commemoration of the victims of the communist reign of violence\". In remembrance of the Building of the Berlin Wall's 50th anniversary the foundation \"Berliner Mauer\" erected 29 steles, which commemorate the victims, along the former border between West Germany and the GDR. Apart from the 3,6 meters large, orange pillars, several signs inform about the wall victims. A planned stele for Lothar Hennig in Sacrow was not built for the time being, because Henning is viewed skeptically as a result of his actions for the MfS as a former IM.\n\nSeveral organizations – for a large part associations or private initiatives – have been carrying out annual commemoration services in Berlin ever since the first casualties occurred. These services are usually held on the anniversary of the building of the Berlin Wall; they were partially supported by West Berlin's district offices or by the senate minutes. As a result of this, the \"Hour of Silence\" was introduced for silent prayers on every 13 August between 20 and 21 o'clock. Ever since 13 August 1990, the Federal State of Berlin commemorates the deaths. This ceremony takes place every year at the \"Peter-Fechter-Kreuz\" in the Zimmerstraße near Checkpoint Charlie. Besides these, there are also many commemoration services and protests against the Berlin Wall at other locations in Germany and abroad on 13 August. An annual commemoration service of the fall of the Berlin Wall takes place on November 9 each year at Eureka College in Illinois, United States, the alma mater of President Ronald Reagan.\n\n\n"}
{"id": "5099796", "url": "https://en.wikipedia.org/wiki?curid=5099796", "title": "Maximum Contaminant Level", "text": "Maximum Contaminant Level\n\nMaximum Contaminant Levels (MCLs) are standards that are set by the United States Environmental Protection Agency (EPA) for drinking water quality. An MCL is the legal threshold limit on the amount of a substance that is allowed in public water systems under the Safe Drinking Water Act. The limit is usually expressed as a concentration in milligrams or micrograms per liter of water.\nTo set a Maximum Contaminant Level for a contaminant, EPA first determines how much of the contaminant may be present with no adverse health effects. This level is called the Maximum Contaminant Level Goal (MCLG). MCLGs are non-enforceable public health goals. The legally enforced MCL is then set as close as possible to the MCLG. The MCL for a contaminant may be higher than the MCLG because of difficulties in measuring small quantities of a contaminant, a lack of available treatment technologies, or if EPA determines that the costs of treatment would outweigh the public health benefits of a lower MCL. In the last case, EPA is permitted to choose an MCL that balances the cost of treatment with the public health benefits. MCLs require monitoring, remediation, and public notice when standards are exceeded. As of 2016, there were 88 MCLs for different organic and inorganic chemicals.\n\nFor some contaminants, EPA establishes a Treatment Technique (TT) instead of an MCL. TTs are enforceable procedures that drinking water systems must follow in treating their water for a contaminant.\n\nMCLs and TTs are known jointly as \"National Primary Drinking Water Regulations\" (NPDWRs), or primary standards.\n\nSome contaminants may cause aesthetic problems with drinking water, such as the presence of unpleasant tastes or odors, or cosmetic problems, such as tooth discoloration. Since these contaminants do not cause health problems, there are no legally enforceable limits on their presence in drinking water. However, EPA recommends maximum levels of these contaminants in drinking water. These recommendations are called \"National Secondary Drinking Water Regulations\" (NSDWRs), or secondary standards.\n\n\n"}
{"id": "425158", "url": "https://en.wikipedia.org/wiki?curid=425158", "title": "Microbicides for sexually transmitted diseases", "text": "Microbicides for sexually transmitted diseases\n\nMicrobicides for sexually transmitted diseases are pharmacologic agents and chemical substances that are capable of killing or destroying certain microorganisms that commonly cause human infection (for example, the human immunodeficiency virus).\n\nMicrobicides are a diverse group of chemical compounds that exert their activity by a variety of different mechanisms of action.\nMultiple compounds are being developed and tested for their microbicidal activity in clinical trials. Microbicides can be formulated in various delivery systems including gels, creams, lotions, aerosol sprays, tablets or films (which must be used near the time of sexual intercourse) and sponges and vaginal rings (or other devices that release the active ingredient(s) over a longer period). Some of these agents are being developed for vaginal application, and for rectal use by those engaging in anal sex.\n\nAlthough there are many approaches to preventing sexually transmitted diseases in general (and HIV in particular), current methods have not been sufficient to halt the spread of these diseases (particularly among women and people in less-developed nations). Sexual abstinence is not a realistic option for women who want to bear children, or who are at risk of sexual violence. In such situations, the use of microbicides could offer both primary protection (in the absence of condoms) and secondary protection (if a condom breaks or slips off during intercourse). It is hoped that microbicides may be safe and effective in reducing the risk of HIV transmission during sexual activity with an infected partner.\n\nDetergent and surfactant microbicides such as nonoxynol-9, sodium dodecyl sulfate and Savvy (1.0% C31G), act by disrupting the viral envelope, capsid or lipid membrane of microorganisms. Since detergent microbicides also kill host cells and impair the barrier function of healthy mucosal surfaces, they are less desirable than other agents. Additionally, clinical trials have not demonstrated these agents to be effective at preventing HIV transmission. Consequently, laboratory and clinical trials testing this class of products as microbicides have largely been discontinued.\n\nHealthy vaginal pH is typically quite acidic, with a pH value of around 4. However, the alkaline pH of semen can neutralize vaginal pH. One potential class of microbicides acts by reducing the pH of vaginal secretions, which may kill (or otherwise inactivate) pathogenic microorganisms. One such agent is BufferGel, a spermicidal and microbicidal gel formulated to maintain the natural protective acidity of the vagina. Candidates in this category (including BufferGel) have proven to be ineffective in preventing HIV infection.\n\nThe polyanion category of microbicides includes the carrageenans. Carrageenans are a family of linear sulfated polysaccharides chemically related to heparan sulfate, which many microbes utilize as a biochemical receptor for initial attachment to the cell membrane. Thus, carrageenan and other microbicides of its class act as decoy receptors for viral binding.\n\n\"Carrageenan\" preparations (such as 0.5% PRO 2000 and 3% Carraguard vaginal microbicide gels) have failed to demonstrate efficacy in preventing HIV transmission in phase III clinical multicenter trials. PRO 2000 was demonstrated to be safe, but it did not reduce the risk of HIV infection in women (as explained in the MDP 301 trial results, released in December 2009). Similarly, the phase III efficacy trial of Carraguard showed that the drug was safe for use but ineffective in preventing HIV transmission in women.\n\n\"Cellulose sulfate\" is another microbicide found ineffective in preventing the transmission of HIV. On February 1, 2007, the International AIDS Society announced that two phase III trials of cellulose sulfate had been stopped because preliminary results suggested a potential increased risk of HIV in women who used the compound. There is no satisfactory explanation as to why application of cellulose sulfate was associated with a higher risk of HIV infection than placebo. According to a review of microbicide drug candidates by the World Health Organization on March 16, 2007, a large number of compounds (more than 60 in early 2007) are under development; at the beginning of that year, five phase III trials testing different formulations were underway.\n\nVivaGel is a sexual lubricant with antiviral properties manufactured by Australian pharmaceutical company Starpharma. The active ingredient is a nanoscale dendrimeric molecule (which binds to viruses and prevents them from affecting an organism's cells). Experimental results with VivaGel indicate 85–100% effectiveness at blocking transmission of both HIV and genital herpes in macaque monkeys. It has passed the animal-testing phases of the drug-approval process in Australia and the United States, which will be followed by initial human safety tests. The National Institutes of Health and the National Institute of Allergy and Infectious Diseases have awarded grants totaling $25.7 million for VivaGel's development and testing. VivaGel is being developed as a standalone microbicide gel and an intra-vaginal microbicide. It is also being evaluated for use in condoms. It is hoped that VivaGel will provide an extra resource to mitigate the sub-Saharan AIDS pandemic.\n\nIt is also hoped that microbicides will block the transmission of HIV and other sexually transmitted diseases, such as those caused by certain human papillomaviruses (HPV) and herpes simplex viruses (HSV). In 2009, Starpharma released its results for a study investigating VivaGel’s antiviral activity against HIV and HSV in humans by testing cervico-vaginal samples \"in vitro\" (in a test tube). The compound displayed a high level of efficacy against HIV and HSV. While the results are encouraging, the study did not evaluate VivaGel’s effect in the body. It is still unknown what the results mean for women who would use the product in real-life settings; for example, the effect of sexual intercourse (or semen) on the gel (which often affects the protective properties of a drug) is unknown. The CAPRISA 004 trial demonstrated that topical tenofovir gel provided 51% protection against HSV-2.\n\nResearchers have begun to focus on another class of microbicides, the antiretroviral (ARV) agents. ARVs work either by preventing the HIV virus from entering a human host cell, or by preventing its replication after it has already entered. Examples of ARV drugs being tested for prevention include tenofovir, dapivirine (a diarylpyrimidine inhibitor of HIV reverse transcriptase) and UC-781. These next-generation microbicides have received attention and support because they are based on the same ARV drugs currently used to extend the survival (and improve the quality of life) of HIV-positive people. ARVs are also used to prevent vertical transmission of HIV from mother to child during childbirth, and are used to prevent HIV infection from developing immediately after exposure to the virus. Such ARV-based compounds could be formulated into topical microbicides to be administered locally in the rectum or vagina or systemically through oral or injectable formulations (pre-exposure prophylaxis). ARV-based microbicides may be formulated as long-acting vaginal rings, gels and films. The results of the first efficacy trial of an ARV-based microbicide, CAPRISA 004, tested 1% tenofovir in gel form to prevent male-to-female HIV transmission. The trial showed that the gel (which was applied topically to the vagina), was 39% effective at preventing HIV transmission. CAPRISA 004 was the 12th microbicide-efficacy study to be completed, and the first to demonstrate a significant reduction in HIV transmission. The results of this trial are statistically significant and offer proof of concept that ARVs, topically applied to the vaginal mucosa, can offer protection against HIV (and other) pathogens.\n\nMost of the first generation microbicides were formulated as semi-solid systems, such as gels, tablets, films, or creams, and were designed to be applied to the vagina before every act of intercourse. However, vaginal rings have the potential to provide long-term controlled release of microbicide drugs. Long-acting formulations, like vaginal rings, are potentially advantageous since they could be easy to use, requiring replacement only once a month. This ease of use could prove very important to make sure that products are used properly. In 2010, the International Partnership for Microbicides began the first study in Africa to test the safety and acceptability of a vaginal ring containing dapivirine. Drugs might also be administered systemically through injectable or oral formulations known as PrEP. Injectable formulations may be desirable since they could be administered infrequently, possibly once a month. It is likely, however, that such products would need to be monitored closely and would be available only through prescription. This approach also carries the risk of emergence of ARV-resistant strains of HIV.\n\nSubstantial numbers of men who have sex with men in developed countries use lubricants containing nonoxynol-9. This suggests that they might be receptive to the concept of using topical rectal microbicides if such products were to become commercially available. However, the development of rectal microbicides is not as advanced as that of vaginal microbicides. One reason for this is that the rectum has a thinner epithelium, greater surface area and lower degree of elasticity than that of the vagina. Due to these factors, a microbicidal preparation that is effective when applied vaginally might have a different degree of effectiveness when applied rectally. In January 2010, the National Institutes of Health awarded two grants totaling $17.5 million to the University of Pittsburgh to fund research into rectal microbicides. That research will include investigations into product acceptability of rectal microbicides with homosexual men ages 18 to 30 years old.\n\nUltimately, successful topical microbicides might simultaneously employ multiple modes of action. In fact, long-acting formulations such as vaginal rings could provide the technology needed to deliver multiple active ingredients with different mechanisms of action.\n\nA major breakthrough in microbicide research, announced in July 2010, reported that an ARV-based microbicide gel could partially prevent HIV. A trial led by the Centre for the AIDS Programme of Research in South Africa (CAPRISA), conducted in South Africa, demonstrated that the ARV tenofovir, when used in a vaginal gel, was 39% effective at preventing HIV transmission from men to women during sex.\n\nIn July 2010 the Centre for the AIDS Programme of Research in South Africa (CAPRISA) released results of a study establishing proof of concept that an ARV-based, topical microbicide can reduce the likelihood of HIV transmission. The trial, CAPRISA 004, was conducted among 889 women to evaluate the ability of 1% tenofovir gel to prevent male-to-female HIV transmission. The study found a 39% lower HIV infection rate in women using 1% tenofovir gel compared with women using a placebo gel. In addition, tenofovir gel was shown to be safe as tested. The results of the CAPRISA 004 trial provide statistically significant evidence that ARVs, topically applied to the vaginal mucosa, can offer protection against HIV and (potentially) other pathogens. During the study, 38 of the women who used the tenofovir gel acquired HIV and 60 women who used a placebo gel became HIV-infected. No tenofovir-resistant virus was detected in the women who acquired HIV infection during the study. In addition to demonstrating efficacy against HIV, CAPRISA 004 found evidence that tenofovir gel also prevents the transmission of herpes simplex virus type 2 (HSV-2). HSV-2 is a lifelong, incurable infection which can make those infected with the virus two-to-three times more likely to acquire HIV. Data collected during the CAPRISA 004 study indicate that tenofovir gel provided 51% protection against HSV-2. Tenofovir, developed by Gilead Sciences, is a nucleotide reverse transcriptase inhibitor (NRTI) which interferes with the replication of HIV and is approved in tablet form for use in combination with other ARVs to treat HIV. CAPRISA 004 was a collaboration among CAPRISA, Family Health International and CONRAD. It was funded by the United States Agency for International Development (USAID) and the South African Department of Science and Technology's Technology Innovation Agency.\n\nResults released in February 2009 from a clinical trial of PRO 2000 (Indevus Pharmaceuticals), a vaginal-microbicide gel (0.5%), sparked hope that it might provide modest protection against HIV. The results of a larger trial released in December 2009 showed that PRO 2000 was safe as administered, but was ineffective in reducing the risk of HIV infection. That trial (MDP 301) was sponsored by the Microbicides Development Programme. MDP 301 was conducted in South Africa, Tanzania, Uganda and Zambia with more than 9,300 women volunteers. No significant difference was found in the number of women who contracted HIV in the group given PRO 2000 compared to the group given a placebo. While this trial did not result in an effective product, it served as a model for future HIV-prevention trials; it provided scientific information and lessons from its social-science component, community engagement and preparation undertaken by the trial staff.\n\nCarrageenan may prevent HPV and HSV transmission, but not HIV. See Carrageenan#Medical Uses\n\nThe phase III clinical trial for carrageenan-based Carraguard showed that it had no statistical effect on HIV infection, according to results released in 2008. The study showed that the gel was safe, with no side effects or increased risks. The trial also provided information about usage patterns in trial participants.\n\nNonoxynol-9, a spermicide, is ineffective as a topical microbicide in preventing HIV infection. Although nonoxynol-9 has been shown to increase the risk of HIV infection when used frequently by women at high risk of infection, it remains a contraceptive option for women at low risk.\n\nEfforts are underway to develop safe and effective topical microbicides. Several different gel formulations are currently undergoing testing in phase III clinical efficacy trials, and about two dozen other products are in various phases of development. Results from CAPRISA 004, while promising, may need to be confirmed by other clinical trials before the microbicide tenofovir gel is made available to the public. This decision rests with regulators, particularly in South Africa. In 2013, the VOICE study (MTN 003), another large-scale trial, is scheduled to release results. VOICE is evaluating three different strategies to prevent HIV in women: one ARV-based microbicide and two regimens consisting of oral ARVs on a daily basis. The VOICE trial is testing 1% tenofovir vaginal gel in a once-daily formulation. It is not known at this time if VOICE will be considered a confirmatory trial for CAPRISA 004, which used a different dosing strategy. Products known as Pre-Exposure Prophylaxis, or PrEP, are also being tested at various stages of the development process. These products, administered orally or via injection, would contain ARVs to protect HIV-negative people from becoming infected. Individuals would receive ARVs before they were exposed to HIV, with the goal of lowering their risk or preventing infection. One of the potential advantages of PrEP is that an individual could use it autonomously (without the need to negotiate with a partner), and it is not dependent on the time of sex. It is hoped that those unable to negotiate condom use with their sexual partners would be able to reduce their risk of HIV infection with the use of an oral (or injectable) prophylactic drug. Current PrEP candidates in development include tenofovir and Truvada (a combination of two ARV compounds, tenofovir and emtricitabine). One potential risk of the PrEP approach is that drugs present in systemic circulation might, over time, create ARV-resistant HIV strains.\n\nCondoms are an effective method for blocking the transmission of most sexually transmitted diseases (with HPV a notable exception). However, a variety of social factors (including, but not limited to, the sexual disempowerment of women in many cultures) limit the feasibility of condom use. Thus, topical microbicides might provide a useful woman-initiated alternative to condoms.\n\nSome sub-Saharan African cultures view vaginal lubrication as undesirable. Since some topical microbicide formulations currently under development function as lubricants, such \"dry sex\" traditions may pose a barrier to the implementation of topical microbicidal programs. Recent data on product acceptability, however, show that many men and women enjoy using gels during sex that would contain a microbicidal drug.\n\n\n"}
{"id": "53069003", "url": "https://en.wikipedia.org/wiki?curid=53069003", "title": "Morinaga Milk arsenic poisoning incident", "text": "Morinaga Milk arsenic poisoning incident\n\nThe Morinaga Milk arsenic poisoning incident occurred in 1955 in Japan and is believed to have resulted in the deaths of over 100 infants. The incident occurred when arsenic was inadvertently added to dried milk via an industrial grade of monosodium phosphate additive. This incident also led to negative health effects for thousands of other infants and individuals, which has had lingering health effects.\n\nFrom June 1955, certain infants in western Japan came down with a strange sickness that was characterized by diarrhoea or constipation, vomiting, a swollen abdomen, and a darkening of skin color. All of the infants shared the same characteristic: they were bottle-fed powdered milk, which was eventually discovered to be the Morinaga Milk brand. News coverage of the rash of infants suffering and dying from the illness did not initially mention Morinaga Milk and one news reporter claimed that they were discretely told to stop feeding their infant Morinaga Milk brand powdered milk after the child fell ill. The company was not named until August of that year.\n\nAccording to William R. Cullen, Morinaga Milk showed little interest over studies of the surviving affected infants, which resulted in some boycotting the company's products during the 1960s. The company was brought to trial; however the Tokushima District Court found them not guilty as well as denying any recompense for the survivors. This decision was subjected to a review by an appellate court in Takamatsu high court, which resulted in the not guilty verdict being reversed on March 31, 1966. After a rejected final appeal three years later, the Tokushima District Court found the Morinaga Milk's head of factory production guilty and sentenced him to three years in jail.\n\nSince the poisoning multiple studies have been done on the people who survived the milk poisoning incident. Many have reported that they still suffered chronic health problems and studies have also reported \"substantially higher rates of sensory deficits and mental retardation in adolescent survivors of the Morinaga poisonings\". A study of them in 2006 showed that many of them still suffered chronic health problems. Arsenic is neurotoxin, so a disproportionate amount of them had developmental delays, epilepsy, and lower IQ scores. They were also below average height. During the civil suit process, the committee selected to make a ruling against the Morinaga company, Genbyo, and decided that the aftereffects of the victims were not a product of arsenic poisoning. Instead, they insisted that they were caused due to a previous illness that was not caused by the arsenic poisoning. The outcome of this was that parents were forced to accept their babies’ misfortune as if it was some kind of natural disaster and take responsibility for ongoing treatment. The committee intentionally tricked the public into believing that the aftereffects were the result of an unfortunate natural disaster rather than a perpetrated crime. In April 1974, the Hikari Foundation was established in order to help the Morinaga poisoning victims. By the end of March 1983, there were 13,396 victims of the Morinaga milk poisonings, and 6,389 of these were in communication with the Hikari Foundation. The work of the Foundation centred mostly on the development of the victims' independence as well as on creating social conditions for that development. The members of the Foundation were mostly parents that had been involved with the protection association.\n\n"}
{"id": "1518723", "url": "https://en.wikipedia.org/wiki?curid=1518723", "title": "National Board of Health and Welfare (Sweden)", "text": "National Board of Health and Welfare (Sweden)\n\nThe Swedish National Board of Health and Welfare () is a Swedish government agency. The agency was the result of a merger between the Swedish Royal Medical Board and the Swedish Royal Board of Social Affairs in 1968. Since 2015 it has been headed by director-general Olivia Wigzell.\n\nThe Board is the central national authority for social services, public health, infectious diseases prevention and health services. The Board establishes norms by issuing provisions and general advice. It evaluates legislation and activities conducted by municipalities, county councils and local authorities. It also issues certificates of registration to 17 professional groups. Another responsibility are the official national statistics in the social services, medical care and health and disease.\n\n"}
{"id": "56926939", "url": "https://en.wikipedia.org/wiki?curid=56926939", "title": "National Institute for Communicable Diseases", "text": "National Institute for Communicable Diseases\n\nThe National Institute for Communicable Diseases (NICD) national public health institute of South Africa. \n\nThe main goal of NICD is to be the national organ for South Africa for public health surveillance of communicable disease.\n"}
{"id": "35969065", "url": "https://en.wikipedia.org/wiki?curid=35969065", "title": "Nevin S. Scrimshaw", "text": "Nevin S. Scrimshaw\n\nNevin Stewart Scrimshaw (January 20, 1918 – February 8, 2013) was an American food scientist and Institute Professor emeritus at the Massachusetts Institute of Technology. Scrimshaw was born in Milwaukee, Wisconsin. During the course of his long career he developed nutritional supplements for alleviating protein, iodine, and iron deficiencies in the developing world. His pioneering and extensive publications in the area of human nutrition and food science include over 20 books and monographs and hundreds of scholarly articles. Scrimshaw also founded the Department of Nutrition and Food Science at the Massachusetts Institute of Technology, the Institute of Nutrition of Central America and Panama, and the Nevin Scrimshaw International Nutrition Foundation. He was awarded the Bolton L. Corson Medal in 1976 and the World Food Prize in 1991. Scrimshaw spent the last years of his life on a farm in Thornton, New Hampshire, where he died at 95.\n\n\n\n\n"}
{"id": "46559303", "url": "https://en.wikipedia.org/wiki?curid=46559303", "title": "Non-specific effect of vaccines", "text": "Non-specific effect of vaccines\n\nNon-specific effects of vaccines (also called \"heterologous effects\" or \"off-target effects\") are effects which go beyond the specific protective effects against the targeted diseases. Non-specific effects can be strongly beneficial, increasing protection against non-targeted infections, but also at times negative, increasing susceptibility to non-targeted infections. This depends on both the vaccine and the sex of the infant.\n\nAll live attenuated vaccines studied so far (BCG vaccine, measles vaccine, oral polio vaccine, smallpox vaccine) have been shown to reduce mortality more than can be explained by prevention of the targeted infections. In contrast, inactivated vaccines (diphtheria-tetanus-pertussis vaccine (DTP), hepatitis B vaccine, inactivated polio vaccine) may increase overall mortality despite providing protection against the target diseases.\n\nThese effects may be long-lasting, at least up to the time point where a new type of vaccine is given. The non-specific effects can be very pronounced, with significant effects on overall mortality and morbidity. In a situation with herd immunity to the target disease, the non-specific effects can be more important for overall health than the specific vaccine effects.\n\nThe non-specific effects should not be confused with the side effects of vaccines (such as local reactions at the side of vaccination or general reactions such as fever, head ache or rash, which usually resolve within days to weeks – or in rare cases anaphylaxis). Rather, non-specific effects represent a form of general immunomodulation, with important consequences for the immune system's ability to handle subsequent challenges.\n\nIt is estimated that millions of child deaths in low income countries could be prevented every year if the non-specific effects of vaccines were taken into consideration in immunization programs.\n\nThe hypothesis that vaccines have non-specific effects was formulated in the early 1990s by Peter Aaby at the Bandim Health Project in West Africa.\n\nThe first indication of the importance of the non-specific effects of vaccines came in a series of randomized controlled trials (RCTs) in the late 1980s. It was tested whether a high-titer (high-dose) measles vaccine (HTMV) given at 4–6 months of age was as effective against measles infection as the standard measles vaccine (MV) given at 9 months of age. Early administration of the HTMV prevented measles infection just as effectively as did the standard MV given at 9 months of age.\n\nHowever, early administration of the HTMV was associated with twofold \"higher\" overall mortality among females (there was no difference in mortality for males). In other words, the girls given HTMV died more often despite having the same protection against measles as the infants given standard MV. The discovery forced WHO to withdraw the HTMV in 1992. It was later discovered that it was not the HTMV, but rather a subsequent inactivated vaccine (DTP or IPV for different children), that caused the increase in female mortality. Although the mechanism was different than initially thought, this finding represents unexpected effects of a change in the vaccine program not attributable to the disease-specific protection provided by the vaccines.\n\nThis first observation that vaccines could protect against the target disease but at the same time affect mortality after infection with other pathogens, in a sex-differential manner, led to several further studies showing that other vaccines might also have such nonspecific effects.\n\nNumerous observational studies and randomised trials (RCTs) have found that the impact on mortality of live and inactivated vaccines differ markedly. All live vaccines studied so far (BCG, measles vaccine, oral polio vaccine (OPV) and smallpox vaccine) have been shown to reduce mortality more than can be explained by prevention of the targeted infection(s). In contrast, inactivated vaccines (diphtheria-tetanus-pertussis (DTP), hepatitis B, inactivated polio vaccine) may have deleterious effects in spite of providing target disease protection.\n\nThe live attenuated BCG vaccine developed against tuberculosis has been shown to have strong beneficial effects on the ability to combat non-tuberculosis infections.\n\nSeveral studies have suggested that BCG vaccination may reduce atopy, particularly when given early in life. Furthermore, in multiple observational studies BCG vaccination has been shown to provide beneficial effects on overall mortality. These observations encouraged randomised controlled trials to examine BCG vaccination's beneficial non-specific effects on overall health. Since BCG vaccination is recommended to be given at birth in countries that have a high incidence of tuberculosis it would have been unethical to randomize children into 'BCG' vs. 'no BCG' groups. However, many low-income countries delay BCG vaccination for low-birth-weight (LBW) infants; this offered the opportunity to directly test the effect of BCG on overall mortality.\n\nIn the first two randomised controlled trials receipt of BCG+OPV at birth vs. OPV only ('delayed BCG') was associated with strong reductions in neonatal mortality; these effects were seen as early as 3 days after vaccination. BCG protected against sepsis as well as respiratory infections. \nAmong BCG vaccinated children, those who develop a BCG scar or a positive skin test (TST) are less likely to develop sepsis and exhibit an overall reduction in child mortality of around 50%.\n\nIn a recent WHO-commissioned review based on five clinical trials and nine observational studies, it was concluded that \"the results indicated a beneficial effect of BCG on overall mortality in the first 6–12 months of life. Relevant follow-up in some of the trials was short, and all of the observational studies were regarded as being at risk of bias, so the confidence in the findings was rated as very low according to the GRADE criteria and \"There was a suggestion that BCG vaccination may be more beneficial the earlier it is given\". Furthermore, \"estimated effects are in the region of a halving of mortality risk\" and \"any effect of BCG vaccine on all-cause mortality is not likely to be attributable to any great extent to fewer deaths from tuberculosis (i.e. to a specific effect of BCG vaccine against tuberculosis)\". Based on the evidence, the WHO's Strategic Group of Experts on Immunization concluded that \"the non-specific effects on all-cause mortality warrant further research\".\n\nStandard titer measles vaccine is recommended at 9 months of age in low-income countries where measles infection is endemic and often fatal. Many observational studies have shown that measles-vaccinated children have substantially lower mortality than can be explained by the prevention of measles-related deaths. Many of these observational studies were natural experiments, such as studies comparing the mortality before and after the introduction of measles vaccine and other studies where logistical factors rather than maternal choice determined whether a child was vaccinated or not.\n\nThese findings were later supported in randomized trials from 2003 to 2009 in Guinea-Bissau. An intervention group of children given standard titer measles vaccine at 4.5 and 9 month of age had a 30% reduction in all-cause mortality compared to the children in the control group, which were only vaccinated against measles at 9 month of age.\n\nIn a recent WHO-commissioned review based on four randomized trials and 18 observational studies, it was concluded that \"There was consistent evidence of a beneficial effect of measles vaccine, although all observational studies were assessed as being at risk of bias and the GRADE rating was of low confidence. There was an apparent difference between the effect in girls and boys, with girls benefitting more from measles vaccination\", and furthermore \"estimated effects are in the region of a halving of mortality risk\" and \"if these effects are real then they are not fully explained by deaths that were established as due to measles\". Based on the evidence, the WHO's Strategic Advisory Group of Experts on Immunization concluded that \"the non-specific effects on all-cause mortality warrant further research\".\n\nDTP vaccine against diphtheria, tetanus and pertussis does not seem to have the same beneficial effects as BCG, measles vaccine, OPV and smallpox vaccine, and in fact opposite effects are observed. The negative effects are seen as long as DTP vaccine is the most recent vaccine. BCG or measles vaccine given after DTP reverses the negative effects of DTP. The negative effects are seen mostly in females.\n\nThe negative effects are found in several observational studies. However, six WHO-commissioned studies concluded that there were strong beneficial effects of DTP on overall mortality. However, controversy ensued as these studies had important methodological shortcomings. For example, the WHO-commissioned studies had counted \"no information about vaccination\" as \"unvaccinated\", and they had retrospectively updated vaccine information from surviving children, while no similar update could be made for dead children, creating a so-called \"survival bias\" which will always produce highly beneficial effect estimates for the most recent vaccine.\n\nIn a recent WHO-commissioned review of DTP based on ten observational studies, it was concluded that, \"the findings were inconsistent, with a majority of the studies indicating a detrimental effect of DTP, and two studies indicating a beneficial effect. All of the studies were regarded as being at risk of bias, so the confidence in the findings was rated as very low according to the GRADE criteria.\"\n\nFurthermore, \"three observational studies provided a suggestion that simultaneous administration of BCG and DTP may be preferable to the recommended schedule of BCG before DTP; and there was suggestion that mortality risk may be higher when DTP is given with, or after, measles vaccine compared with when it is given before measles vaccine (from five, and three, observational studies, respectively). These results are consistent with hypotheses that DTP vaccine may have detrimental effects on mortality, although a majority of the evidence was generated by a group centred in Guinea-Bissau who have often written in defence of such a hypothesis.\"\n\nWhen smallpox vaccine was introduced in the early 19s century, there were anecdotal descriptions of non-specific beneficial effects. In the second half of the 20th century the potential for beneficial non-specific effects of smallpox vaccine was reviewed, and new evidence on \"para-immune effects\" was added. More recent studies have focused on the phasing out of smallpox vaccine in the 1970s and compared vaccinated and unvaccinated cohorts.\nSmallpox vaccine leaves a very characteristic scar. In low-income countries, having a smallpox vaccine scar has been associated with reductions of more than 40% in overall mortality among adults; in high-income countries smallpox vaccination has been associated with a tendency for reduced risk of asthma, and significantly reduced risk of malignant melanoma and infectious disease hospitalizations. There are no studies that contradict these observations. However it should be noted that no randomized trials testing the effect of smallpox vaccine on overall mortality and morbidity have been conducted.\n\nNon-specific effects are frequently different in males and females. There are accumulating data illustrating that males and females may respond differently to vaccination, both in terms of the quality and quantity of the immune response. If true, then we must consider whether vaccination schedules should differ for males and females, or as has been suggested \"should we treat the sexes differently in order to treat them equally?\"\n\nThe non-specific effects of vaccines can be boosted or diminished when other immunomodulating health interventions such as other vaccines, or vitamins, are provided.\n\nThe beneficial NSEs of live vaccines are stronger with earlier vaccination, possibly due to maternal antibodies. Boosting with live vaccines also seems to enhance the beneficial effects.\n\nThe non-specific effects were primarily observed in low-income countries with high infectious disease burdens, but they may not be limited to these areas. Recent Danish register-based studies have shown that the live attenuated measles-mumps-rubella vaccine (MMR) protects against hospital admissions with infectious diseases and specifically getting ill by respiratory syncytial virus.\n\nThe findings from the epidemiological studies on the non-specific effects of vaccines pose a challenge to the current understanding of vaccines, and how they affect the immune system, and also question whether boys and girls have identical immune systems and should receive the same treatment.\n\nThe mechanisms for these effects are unclear. It is not known how vaccination induces rapid beneficial or harmful changes in the general susceptibility to infectious diseases, but the following mechanisms are likely to be involved.\n\nIt is well known from animal studies that infections, apart from inducing pathogen-specific T-cells, also induce cross-reactive T-cells through epitope sharing, so-called heterologous immunity. Heterologous T-cell immunity can lead to improved clearance of a subsequent cross-reactive challenge, but it may also lead to increased morbidity. This mechanism may explain why DTP could have negative effects.\n\nIt would, however, not explain effects occurring shortly after vaccination, as for instance the rapidly occurring beneficial effects of BCG vaccine, as the heterologous effect would only be expected to be present after some weeks, as the adaptive immune response need time to develop. Also, it is difficult to explain why the effect would vanish once a child receives a new vaccine.\n\nThe concept that not only plants and insects, but also humans have innate immune memory may provide new clues to why vaccines have non-specific effects. Studies into BCG have recently revealed that BCG induces epigenetic changes in the monocytes in adults, leading to increased pro-inflammatory cytokine production upon challenges with unrelated mitogens and pathogens (trained innate immunity).\n\nIn SCID mice that have no adaptive immune system, BCG reduced mortality from an otherwise lethal candida infection. The effects of BCG presented when tested after 2 weeks, but would be expected to occur rapidly after vaccination, and hence might be able to explain the very rapid protection against neonatal septicaemia seen after BCG vaccine.\n\nTrained innate immunity may also explain the generally increased resistance against broad disease categories, such as fevers and lower respiratory tract infections; such effects would be difficult to explain merely by shared epitopes, unless such epitopes were almost universally common on pathogens.\n\nLastly, it is plausible that the effects are reversible by a different vaccine. Hence, trained innate immunity may provide a biological mechanism for the observed non-specific effects of vaccines.\n\nIn 2000 Aaby and colleagues presented data from Guinea-Bissau which suggested that DTP vaccination could, under some circumstances (e.g. absence of pertussis) be associated with increases in overall mortality, at least until children received measles vaccine. In response, WHO sponsored the analysis of a variety of data sets in other populations to test the hypothesis. None of these studies replicated the observation of increased mortality associated with DTP vaccination. WHO subsequently concluded, that the evidence was sufficient to reject the hypothesis for an increased nonspecific mortality following DTP vaccination.\n\nHowever, Aaby and colleagues subsequently pointed out that the studies which failed to show any mortality increase associated with DTP vaccination used methods of analysis that can introduce a bias against finding such an effect.\n\nIn these studies, data on childhood vaccinations were typically collected in periodic surveys, and the information on vaccinations, which occurred between successive home visits, was updated at the time of the second visit. The person-time at risk in unvaccinated and vaccinated states was then divided up according to the date of vaccination during the time interval between visits. This method opens up a potential bias, insofar as the updating of person time at risk from unvaccinated to vaccinated is only possible for children who survive to the second follow-up. Those who die between visits typically do not have vaccinations between the first visit and death recorded, and thus they will tend to be allocated as deaths in unvaccinated children – thus incorrectly inflating the mortality rate among unvaccinated children.\n\nThis bias has been described before, but in different contexts, as the distinction between 'landmark' and 'retrospective updating' analysis of cohort data. The retrospective updating method can lead to a considerable bias in vaccine studies, biasing observed mortality rate ratios towards zero (a large effect), whereas the landmark method leads to a non-specific misclassification and biases the mortality rate ratio towards unity(no effect).\n\nAn additional problem with the literature on the nonspecific effects of vaccines has been the variety and unexpected nature of the hypotheses which have appeared (in particular relating to sex-specific effects), which has meant that it has not always been clear whether some apparent 'effects' were the result of post hoc analyses or whether they were reflections of a priori hypotheses.\n\nThis was discussed at length at a review of the work of Aaby and his colleagues in Copenhagen in 2005. The review was convened by the Danish National Research Foundation and the Novo Nordisk Foundation who have sponsored much of the work of Aaby and his colleagues. An outcome of the review was the explicit formulation of a series of testable hypotheses, agreed by the Aaby group. It was hoped that independent investigators would design and conduct studies powered to confirm or refute these hypotheses.\n\nAlso, the two foundations sponsored a workshop on the analysis of vaccine effects, which was held in London in 2008. The workshop resulted in three papers. The proceedings were forwarded to WHO which subsequently concluded that it would \"keep a watch on the evidence of nonspecific effects of vaccination\".\n\nIn 2013, WHO established a working group tasked with reviewing the evidence for the non-specific effects of BCG, measles and DTP vaccines. Two independent reviews were conducted, an immunological review and an epidemiological review. The results were presented at the April 2014 meeting of WHO's Strategic Gourp of Experts on Immunizations (SAGE). WHO/SAGE concluded that further research into the potential NSEs of vaccines was warranted.\n\nIt would have major consequences for child survival if the non-specific effects of vaccines were taken into consideration in immunization programs: BCG and MV should be given to all children as early as possible; restrictive policies for opening multi-dose vials of BCG and MV should be abandoned.\n\nContrary to current WHO-recommendations, the age of MV should not be raised when measles infection is under control; DTP should not be given simultaneously with MV or after MV; and a booster dose of DTP is likely to have a negative effect on child survival. Finally, eradicating a disease and stopping a live vaccine with beneficial NSEs is likely to have negative effects for the overall health of the affected population.\n\nDr. Frank Shann from Australia recently assessed the consequences of changing the current EPI schedule to an alternative schedule taking non-specific effects into account, and concluded: \"If all neonates in high-mortality regions were given BCG at birth, and the revised immunization schedule ... were adopted, with extra doses of measles vaccine at 14 weeks and 19 months (at a cost of only US $0.60/dose delivered), ~1 million (30%) of the 3.2 million neonatal deaths each year might be prevented in developing countries, and 1.5 million (30%) of the 4.8 million deaths between 1 month and 5 years of age might be prevented\". Furthermore: \"This very large reduction in mortality in children <5 years of age would be achieved at a low cost using only vaccines that are already in the routine EPI schedule\".\n\nIn 2008, Danish crime novel author Sissel-Jo Gazan (author of the Danish crime novel \"Dinosaur Feather\") became interested in the work of the Bandim Health Project and based her science crime novel \"The Arc of the Swallow\" (\"Svalens Graf\") on the research into non-specific effects of vaccines.\n\nThe novel was published in Danish in 2013; it was on the best-seller list for months and won the Readers' Prize 2014 in Denmark. It was published in English in the UK on November 6, 2014 and in the US on April 7, 2015.\n\n"}
{"id": "21325256", "url": "https://en.wikipedia.org/wiki?curid=21325256", "title": "Nuffield Council on Bioethics", "text": "Nuffield Council on Bioethics\n\nThe Nuffield Council on Bioethics is a UK-based independent charitable body, which examines and reports on bioethical issues raised by new advances in biological and medical research. Established in 1991, the Council is funded by the Nuffield Foundation, the Medical Research Council and the Wellcome Trust. The Council has been described by the media as a 'leading ethics watchdog', which 'never shrinks from the unthinkable'.\n\nThe Council was set up in response to concerns about the lack of a national body responsible for evaluating the ethical implications of developments in biomedicine and biotechnology. Its terms of reference are:\n\n\nThe Council has been variously labelled a “think-tank”.\n\nThe Council chooses its own topics on which to report. Members of the Council meet four to six times a year to consider progress on ongoing projects, receive updates on published reports, review recent biomedical advances that raise ethical questions, and select topics for further exploration.\nOnce the Council has identified a major ethical issue, it organises a workshop to examine the issue further. If appropriate, a Working Party is then established to report on the issue. Members of the Working Party are appointed by the Council and chosen to represent a range of specialist experience and skills. Typically, a Working Party meets regularly over a period of one to two years to produce a report. A public consultation is held to gain the views of a wide range of people to inform the findings of the report. The Council reviews drafts of the report before it is submitted for external peer review and then approves the final report prior to publication.\n\nThe Chair of Council is appointed by the Nuffield Foundation in consultation with the other funders. Chairs are appointed for five years. The other members are drawn from relevant fields of expertise including science, medicine, sociology, philosophy and law, for an initial period of three years, with the possibility of an additional three-year term. When vacancies arise, the Council advertises for new members in the national press, through its widely distributed newsletter and on its website. The Council's Membership Subgroup considers and makes recommendations to the Council on future members selected from the respondents to the advertisements.\n\n\nHugh Whittall has been the Director of the Council since February 2007.\n\nFormer Directors:\n\nCurrent\nPrevious members\n\n\nThe Council's recommendations to policy makers have often been described as 'influential'.\n\nThe Council has been cited or referred to in the following publications and parliamentary speeches:\n\nThe Council was entirely funded by the Nuffield Foundation from 1991 to 1994. Since 1994, the Council has been jointly funded by the Nuffield Foundation, the Medical Research Council and The Wellcome Trust on a five-year rolling system. Towards the end of each five-year period, a process of external review is a condition of continued support. Funding for the Council has been confirmed for the period 2012–2016 following the completion of a strategic review.\n\nThe Council takes the view that its terms of reference do not require it to adopt the same ethical framework or set of principles in all reports. The Council is therefore not bound by the values of particular schools of philosophy (for example, utilitarianism, deontology, virtue ethics) or approaches in bioethics, such as the 'four principles of bioethics' (autonomy, justice, beneficence, non-maleficence), or the Barcelona Principles (autonomy, dignity, integrity, vulnerability).\n\nIn 2006-7, John Harris, Professor of Bioethics at the University of Manchester, and Dr Sarah Chan carried out an external review of the way ethical frameworks, principles, norms and guiding concepts feature in the Council's publications. The authors found that the ethical frameworks used in the Council's publications had become increasingly explicit and transparent.\n\n"}
{"id": "1037464", "url": "https://en.wikipedia.org/wiki?curid=1037464", "title": "Nursing bra", "text": "Nursing bra\n\nA nursing bra is a specialized brassiere that provides additional support to women who are lactating and permits comfortable breastfeeding without the need to remove the bra. This is accomplished by specially designed bra cups that include flaps which can be opened with one hand to expose the nipple. The flap is usually held closed with a simple clasp or hook.\n\nA nursing bra is designed to provide quick and easy access to the breast for the purpose of breastfeeding an infant. It typically has flaps or panels that can be unclipped and folded down or to the side with one hand. Nursing bras can be worn under a variety of outer garments.\n\nMeasurements for an appropriate nursing bra can be performed by a lactation consultant. Women can choose nursing bras with strong side and undercup support and an extra-wide back for optimal support. Nursing bras usually have up to four rows of hooks in the rear closure to allow the woman to adjust her band size to a limited extent. Experts recommend a soft-cup bra made of a blend of cotton and Lycra with cups that stretch to accommodate changes in breast size. Most women buy two or more nursing bras so they can alternate between them. Small-breasted women who don't usually wear a bra may choose to wear a nursing bra to support their larger breasts or simply to prevent milk from leaking onto their clothes.\n\nA woman's breasts grow during pregnancy, usually 1 to 2 cup sizes, and potentially several cup sizes. A woman who wore a C-cup bra prior to her pregnancy may need to buy a larger bra while nursing. Once the baby is born and about 50 to 73 hours after birth, the mother will experience her breasts filling with milk (sometimes referred to as “milk coming in”) and at that point changes in the breast happen very quickly. Once lactation begins, the woman's breasts swell significantly and can feel achy, lumpy and heavy (which is referred to as engorgement). \n\nTo provide proper support and fit, to facilitate nursing, and to avoid engorged breasts or other complications that prevent an infant from nursing effectively, it is important to wear nursing bras that fit well. When a woman wears a bra that is too tight, her milk supply may be reduced, and she can experience plugged milk ducts and an extremely painful infection called mastitis. Mastitis can physically and emotionally affect the mother's ability to breastfeed.\n\nThere are an increasing variety of nursing bras designs, including softcup, underwire, seamless, and lounging styles. Some nursing bras can also serve as a sports bra, allowing a nursing mother to exercise more easily. Some outerwear like tank tops and T-shirts have nursing bras that are built into the garment, and there are also padded and plus-size nursing bras. Some experts advise against wearing an underwire nursing bra because they can restrict the flow of milk and cause mastitis. Most nursing bras have traditionally been white, but manufacturers now offer an increasing selection of colors and styles, including brown, teal, floral, and floral animal prints, and some are accessorized with lace and ribbon.\n\nDifferent manufacturers use different methods for fastening the flap to the cup, including squeeze, snaps, clasps and hooks. Most nursing bras are designed with cup flaps that fasten at the apex of the bra, at the point where the shoulder straps attach, allowing the mother to simply pull the top half of the cup down to facilitate access to the nipple. Other designs include flaps that fasten between the cups at the center of the bra, zippers under each cup, and a cross-over design that allows the woman to slip her breast out. Experts recommend that before buying a nursing bra women should try on the bra and experiment with opening the flap with one hand. Some designs utilizing stretchable fabric are suitable for smaller-breasted women, allowing them to pull the entire bra up over the breast to facilitate nursing.\n\nExperts recommend nursing bras that are stretchy, absorbent, and don't bind the breasts in any way that could interfere with milk flow. Women are recommended to wear a bra that is 100 percent cotton or a cotton-Lycra blend or other stretchy synthetic. It is not necessary to wear a bra at night, although if a woman's breasts leak excessively, she can wear a loose tanktop at night.\n\nChoosing a functional nursing bra is important to help the mother feel comfortable nursing in various circumstances. In some Western cultures, while nearly nude or nude breasts are displayed openly on beaches and in magazines and movies, there is a taboo against showing breasts in public during breastfeeding.\n\nThe first US patent for a bra was granted in 1913 to Mary Phelps Jacob. Her invention is the most widely recognized as the predecessor to the modern bra and consequently the nursing bra.\n\nIn October 1932, the S.H. Camp and Company correlated breast size and the degree they sag to letters of the alphabet, A, B, C, and D. Camp's advertising featured letter-labeled profiles of breasts in the February 1933 issue of \"Corset and Underwear Review\". These procedures were only designed to help women with the then-standard sizes A through D up to a size 38 band size and were not intended to be used for larger-breasted women. In 1937, Warner began to feature cup sizing in its products. Other companies like the Model and Fay-Miss (renamed in 1935 as the Bali Brassiere Company) also began to offer A, B, C and D cups in the late 1930s. Catalog companies continued to use the designations Small, Medium and Large through the 1940s. In the 1930s, Dunlop chemists were able to reliably transform rubber latex into elastic thread. Man-made fibres were quickly adopted by the industry because of their easy-care properties. Since a brassiere must be laundered frequently, this was of great importance. In 1937, Warners added cup sizes (A, B, C and D) to their product line, and other manufacturers gradually followed, but Britain did not take up the American standard until the 1950s. Maidenform introduced brassieres with seamless cups in 1933, but resisted using cup sizes for its products until 1949.\n\nThe first patent for a device called a \"nursing brassiere\" was obtained in 1943 by Albert A. Glasser. After World War II, the post-war baby boom stimulated a large increase in the market for nursing bras. Nursing bras saw little innovation for some time and the market was dominated by larger lingerie companies who would simply add a clip.\n\nThe nursing bra industry is very segmented. It includes traditional brassiere manufacturer such as Wonderbra. Their product is designed to accommodate the needs of women whose breast size can fluctuate up to a single cup size hourly while nursing. Another innovator is Mary Sanchez, who received a patent in 1991 for the one-handed fastening method and variable adjustment of cup size.\n\nFor women who pump their breast milk, specialized nursing bras are available that allow hands-free pumping.\n"}
{"id": "43520284", "url": "https://en.wikipedia.org/wiki?curid=43520284", "title": "Protocol on Heavy Metals", "text": "Protocol on Heavy Metals\n\nThe Protocol on Heavy Metals, a protocol to the Convention on Long-Range Transboundary Air Pollution, was adopted in Aarhus, Denmark in 1998. As of 2004, it had 36 signatories. As of 2016, it had 35 signatories and 33 parties, with no country having become a signatory since 1998. The protocol addresses the reduction of cadmium, lead and mercury emissions in the interests of environmental protection. Amendments to the Protocol were agreed in 2012 to introduce more stringent emission limits but are not yet in force.\n\n"}
{"id": "784642", "url": "https://en.wikipedia.org/wiki?curid=784642", "title": "Pulse oximetry", "text": "Pulse oximetry\n\nPulse oximetry is a noninvasive method for monitoring a person's oxygen saturation (S). Though its reading of Sp (peripheral oxygen saturation) is not always identical to the more desirable reading of Sa (arterial oxygen saturation) from arterial blood gas analysis, the two are correlated well enough that the safe, convenient, noninvasive, inexpensive pulse oximetry method is valuable for measuring oxygen saturation in clinical use.\n\nIn its most common (transmissive) application mode, a sensor device is placed on a thin part of the patient's body, usually a fingertip or earlobe, or in the case of an infant, across a foot. The device passes two wavelengths of light through the body part to a photodetector. It measures the changing absorbance at each of the wavelengths, allowing it to determine the absorbances due to the pulsing arterial blood alone, excluding venous blood, skin, bone, muscle, fat, and (in most cases) nail polish.\n\nLess commonly, reflectance pulse oximetry is used as an alternative to transmissive pulse oximetery described above. This method does not require a thin section of the person's body and is therefore well suited to a universal application such as the feet, forehead, and chest, but it also has some limitations. Vasodilation and pooling of venous blood in the head due to compromised venous return to the heart can cause a combination of arterial and venous pulsations in the forehead region and lead to spurious Sp results. Such conditions occur while undergoing anesthesia with endotracheal intubation and mechanical ventilation or in patients in the Trendelenburg position.\n\nIn 1935, Karl Matthes (German physician 1905–1962) developed the first 2-wavelength ear O saturation meter with red and green filters (later switched to red and infrared filters). His meter was the first device to measure O saturation.\n\nThe original oximeter was made by Glenn Allan Millikan in the 1940s. In 1949 Wood added a pressure capsule to squeeze blood out of the ear so as to obtain an absolute O saturation value when blood was readmitted. The concept is similar to today's conventional pulse oximetry, but was difficult to implement because of unstable photocells and light sources; the method is not now used clinically. In 1964 Shaw assembled the first absolute reading ear oximeter by using eight wavelengths of light. \n\nPulse oximetry was developed in 1972, by Takuo Aoyagi and Michio Kishi, bioengineers, at Nihon Kohden using the ratio of red to infrared light absorption of pulsating components at the measuring site. Susumu Nakajima, a surgeon, and his associates first tested the device in patients, reporting it in 1975. It was commercialized by Biox in 1980.\n\nBy 1987, the standard of care for the administration of a general anesthetic in the U.S. included pulse oximetry. From the operating room, the use of pulse oximetry rapidly spread throughout the hospital, first to the recovery room, and then into the various intensive care units. Pulse oximetry was of particular value in the neonatal unit where the patients do not thrive with inadequate oxygenation, but too much oxygen and fluctuations in oxygen concentration can lead to vision impairment or blindness from retinopathy of prematurity (ROP). Furthermore, obtaining an arterial blood gas from a neonatal patient is painful to the patient and a major cause of neonatal anemia. Motion artifact can be a significant limitation to pulse oximetry monitoring resulting in frequent false alarms and loss of data. The reason for this is that during motion and low peripheral perfusion, many pulse oximeters cannot distinguish between pulsating arterial blood and moving venous blood, leading to underestimation of oxygen saturation. Early studies of pulse oximetry performance during subject motion made clear the vulnerabilities of conventional pulse oximetry technologies to motion artifact.\n\nIn 1995, Masimo introduced Signal Extraction Technology (SET) that could measure accurately during patient motion and low perfusion by separating the arterial signal from the venous and other signals. Since then, pulse oximetry manufacturers have developed new algorithms to reduce some false alarms during motion such as extending averaging times or freezing values on the screen, but they do not claim to measure changing conditions during motion and low perfusion. So, there are still important differences in performance of pulse oximeters during challenging conditions.\n\nPublished papers have compared signal extraction technology to other pulse oximetry technologies and have demonstrated consistently favorable results for signal extraction technology. Signal extraction technology pulse oximetry performance has also been shown to translate into helping clinicians improve patient outcomes. In one study, retinopathy of prematurity (eye damage) was reduced by 58% in very low birth weight neonates at a center using signal extraction technology, while there was no decrease in retinopathy of prematurity at another center with the same clinicians using the same protocol but with non-signal extraction technology. Other studies have shown that signal extraction technology pulse oximetry results in fewer arterial blood gas measurements, faster oxygen weaning time, lower sensor utilization, and lower length of stay. The measure-through motion and low perfusion capabilities it has also allow it to be used in previously unmonitored areas such as the general floor, where false alarms have plagued conventional pulse oximetry. As evidence of this, a landmark study was published in 2010 showing clinicians using signal extraction technology pulse oximetry on the general floor were able to decrease rapid response team activations, ICU transfers, and ICU days.\n\nIn 2011, an expert workgroup recommended newborn screening with pulse oximetry to increase the detection of critical congenital heart disease (CCHD). The CCHD workgroup cited the results of two large, prospective studies of 59,876 subjects that exclusively used signal extraction technology to increase the identification of CCHD with minimal false positives. The CCHD workgroup recommended newborn screening be performed with motion tolerant pulse oximetry that has also been validated in low perfusion conditions. In 2011, the US Secretary of Health and Human Services added pulse oximetry to the recommended uniform screening panel. Before the evidence for screening using signal extraction technology, less than 1% of newborns in the United States were screened. Today, The Newborn Foundation has documented near universal screening in the United States and international screening is rapidly expanding. In 2014, a third large study of 122, 738 newborns that also exclusively used signal extraction technology showed similar, positive results as the first two large studies.\n\nHigh-resolution pulse oximetry (HRPO) has been developed for in-home sleep apnea screening and testing in patients for whom it is impractical to perform polysomnography. It stores and records both pulse rate and SpO2 in 1 second intervals and has been shown in one study to help to detect sleep disordered breathing in surgical patients.\n\nIn 1995 Masimo introduced perfusion index, quantifying the amplitude of the peripheral plethysmograph waveform. Perfusion index has been shown to help clinicians predict illness severity and early adverse respiratory outcomes in neonates, predict low superior vena cava flow in very low birth weight infants, provide an early indicator of sympathectomy after epidural anesthesia, and improve detection of critical congenital heart disease in newborns.\n\nIn 2007, Masimo introduced the first measurement of the pleth variability index (PVI), which multiple clinical studies have shown provides a new method for automatic, noninvasive assessment of a patient's ability to respond to fluid administration. Appropriate fluid levels are vital to reducing postoperative risks and improving patient outcomes: fluid volumes that are too low (under-hydration) or too high (over-hydration) have been shown to decrease wound healing and increase the risk of infection or cardiac complications. Recently, the National Health Service in the United Kingdom and the French Anesthesia and Critical Care Society listed PVI monitoring as part of their suggested strategies for intra-operative fluid management.\n\nA blood-oxygen monitor displays the percentage of blood that is loaded with oxygen. More specifically, it measures what percentage of hemoglobin, the protein in blood that carries oxygen, is loaded. Acceptable normal ranges for patients without pulmonary pathology are from 95 to 99 percent. For a patient breathing room air at or near sea level, an estimate of arterial pO can be made from the blood-oxygen monitor \"saturation of peripheral oxygen\" (SpO) reading.\n\nA typical pulse oximeter uses an electronic processor and a pair of small light-emitting diodes (LEDs) facing a photodiode through a translucent part of the patient's body, usually a fingertip or an earlobe. One LED is red, with wavelength of 660 nm, and the other is infrared with a wavelength of 940 nm. Absorption of light at these wavelengths differs significantly between blood loaded with oxygen and blood lacking oxygen. Oxygenated hemoglobin absorbs more infrared light and allows more red light to pass through. Deoxygenated hemoglobin allows more infrared light to pass through and absorbs more red light. The LEDs sequence through their cycle of one on, then the other, then both off about thirty times per second which allows the photodiode to respond to the red and infrared light separately and also adjust for the ambient light baseline. The amount of light that is transmitted (in other words, that is not absorbed) is measured, and separate normalized signals are produced for each wavelength. These signals fluctuate in time because the amount of arterial blood that is present increases (literally pulses) with each heartbeat. By subtracting the minimum transmitted light from the peak transmitted light in each wavelength, the effects of other tissues are corrected for. The ratio of the red light measurement to the infrared light measurement is then calculated by the processor (which represents the ratio of oxygenated hemoglobin to deoxygenated hemoglobin), and this ratio is then converted to SpO by the processor via a lookup table based on the Beer–Lambert law.\n\nA pulse oximeter is a medical device that indirectly monitors the oxygen saturation of a patient's blood (as opposed to measuring oxygen saturation directly through a blood sample) and changes in blood volume in the skin, producing a photoplethysmogram. The pulse oximeter may be incorporated into a multiparameter patient monitor. Most monitors also display the pulse rate. Portable, battery-operated pulse oximeters are also available for transport or home blood-oxygen monitoring.\n\nPulse oximetry is particularly convenient for noninvasive continuous measurement of blood oxygen saturation. In contrast, blood gas levels must otherwise be determined in a laboratory on a drawn blood sample. Pulse oximetry is useful in any setting where a patient's oxygenation is unstable, including intensive care, operating, recovery, emergency and hospital ward settings, pilots in unpressurized aircraft, for assessment of any patient's oxygenation, and determining the effectiveness of or need for supplemental oxygen. Although a pulse oximeter is used to monitor oxygenation, it cannot determine the metabolism of oxygen, or the amount of oxygen being used by a patient. For this purpose, it is necessary to also measure carbon dioxide (CO) levels. It is possible that it can also be used to detect abnormalities in ventilation. However, the use of a pulse oximeter to detect hypoventilation is impaired with the use of supplemental oxygen, as it is only when patients breathe room air that abnormalities in respiratory function can be detected reliably with its use. Therefore, the routine administration of supplemental oxygen may be unwarranted if the patient is able to maintain adequate oxygenation in room air, since it can result in hypoventilation going undetected.\n\nBecause of their simplicity of use and the ability to provide continuous and immediate oxygen saturation values, pulse oximeters are of critical importance in emergency medicine and are also very useful for patients with respiratory or cardiac problems, especially COPD, or for diagnosis of some sleep disorders such as apnea and hypopnea. Portable battery-operated pulse oximeters are useful for pilots operating in a non-pressurized aircraft above or in the U.S. where supplemental oxygen is required. Portable pulse oximeters are also useful for mountain climbers and athletes whose oxygen levels may decrease at high altitudes or with exercise. Some portable pulse oximeters employ software that charts a patient's blood oxygen and pulse, serving as a reminder to check blood oxygen levels.\n\nPulse oximetry solely measures hemoglobin saturation, not ventilation and is not a complete measure of respiratory sufficiency. It is not a substitute for blood gases checked in a laboratory, because it gives no indication of base deficit, carbon dioxide levels, blood pH, or bicarbonate (HCO) concentration. The metabolism of oxygen can be readily measured by monitoring expired CO, but saturation figures give no information about blood oxygen content. Most of the oxygen in the blood is carried by hemoglobin; in severe anemia, the blood will carry less total oxygen, despite the hemoglobin being 100% saturated.\n\nErroneously low readings may be caused by hypoperfusion of the extremity being used for monitoring (often due to a limb being cold, or from vasoconstriction secondary to the use of vasopressor agents); incorrect sensor application; highly calloused skin; or movement (such as shivering), especially during hypoperfusion. To ensure accuracy, the sensor should return a steady pulse and/or pulse waveform. Pulse oximetry technologies differ in their abilities to provide accurate data during conditions of motion and low perfusion.\n\nPulse oximetry also is not a complete measure of circulatory sufficiency. If there is insufficient bloodflow or insufficient hemoglobin in the blood (anemia), tissues can suffer hypoxia despite high oxygen saturation in the blood that does arrive. In 2008, a pulse oximeter that can measure hemoglobin levels in addition to oxygen saturation was introduced by Masimo. To quantify hemoglobin, the device uses additional wavelengths of light beyond the two standard ones.\n\nSince pulse oximetry measures only the percentage of bound hemoglobin, a falsely high or falsely low reading will occur when hemoglobin binds to something other than oxygen:\n\nA noninvasive method that allows continuous measurement of the dyshemoglobins is the pulse CO-oximeter, which was built in 2005 by Masimo using UK Patent GB 2320566 (1996) . It provides clinicians a way to measure the dyshemoglobins, carboxyhemoglobin, and methemoglobin along with total hemoglobin.\n\nAccording to a report by iData Research the U.S. pulse oximetry monitoring market for equipment and sensors was over in 2011. \n\nIn 2008, more than half of the major internationally exporting medical equipment manufacturers in China were producers of pulse oximeters.\n\nThe Apple Watch uses this technology for its heart rate monitor. The accuracy of the heart rate monitor has been debated, as different tests have shown it to be 91% as accurate as chest strap monitors.\n\nPleth variability index (PVI) is a measure of the variability of the plethysmographic waveform amplitude.\n\n\n"}
{"id": "22876971", "url": "https://en.wikipedia.org/wiki?curid=22876971", "title": "Radiation-induced lung injury", "text": "Radiation-induced lung injury\n\nRadiation-induced lung injury is a general term for damage to the lungs which occurs as a result of exposure to ionizing radiation. In general terms, such damage is divided into early inflammatory damage (\"radiation pneumonitis\") and later complications of chronic scarring (\"radiation fibrosis\"). Pulmonary radiation injury most commonly occurs as a result of radiation therapy administered to treat cancer.\n\nThe lungs are a radiosensitive organ, and radiation pneumonitis can occur leading to pulmonary insufficiency and death (100% after exposure to 50 gray of radiation), in a few months. Radiation pneumonitis is characterized by:\n\nHigh resolution CT thorax\n\n\n"}
{"id": "32584230", "url": "https://en.wikipedia.org/wiki?curid=32584230", "title": "Reactive gastropathy", "text": "Reactive gastropathy\n\nReactive gastropathy, also chemical gastropathy, is an abnormality in the stomach caused by chemicals, e.g. bile, alcohol, and characteristically has minimal inflammation.\n\nReactive gastropathy has a large number of causes, including:\n\nThe diagnosis is by examination of tissue, e.g. a stomach biopsy.\n\nIt is characterized, histologically, by:\n\nReactive gastropathy is morphologically distinct entity that can be separated from gastritis, which by definition has a significant inflammatory component.\n\nAs a reactive gastropathy may mimic a (true) gastritis symptomatically and visually in an endoscopic examination, it may incorrectly be referred to as a gastritis. Even aware of the underlying etiology of the pathologic process, e.g. NSAID use, the label \"chemical gastritis\" is applied to a chemical gastropathy.\n\n\n"}
{"id": "7973130", "url": "https://en.wikipedia.org/wiki?curid=7973130", "title": "Recherche et Industrie Thérapeutiques", "text": "Recherche et Industrie Thérapeutiques\n\nRecherche et Industrie Thérapeutiques (R.I.T.) was founded in Genval, Belgium, as a penicillin factory in 1945 by Dr Pieter De Somer, who later became the founder of the Rega Institute for Medical Research and rector of the Katholieke Universiteit Leuven (Leuven, Belgium). The industrialist Jean Lannoye provided the funding for the company. The company started its vaccine research and production in the 1950s. The present CEO of the company is Jean Stéphenne.\n\nIn 1968 the company was acquired by Smith, Kline & French and the name was changed in SmithKline-RIT. In 1989 it became SmithKline Beecham Biologicals, and since 2000 GlaxoSmithKline Biologicals.\n\n\n\n\n"}
{"id": "2159778", "url": "https://en.wikipedia.org/wiki?curid=2159778", "title": "Reproductive health", "text": "Reproductive health\n\nWithin the framework of the World Health Organization's (WHO) definition of health as a state of complete physical, mental and social well-being, and not merely the absence of disease or infirmity, reproductive health, or sexual health/hygiene, addresses the reproductive processes, functions and system at all stages of life. UN agencies claim, sexual and reproductive health includes physical, as well as psychological well-being vis-a-vis sexuality.\n\nReproductive health implies that people are able to have a responsible, satisfying and safer sex life and that they have the capability to reproduce and the freedom to decide if, when and how often to do so. One interpretation of this implies that men and women ought to be informed of and to have access to safe, effective, affordable and acceptable methods of birth control; also access to appropriate health care services of sexual, reproductive medicine and implementation of health education programs to stress the importance of women to go safely through pregnancy and childbirth could provide couples with the best chance of having a healthy infant.\n\nIndividuals do face inequalities in reproductive health services. Inequalities vary based on socioeconomic status, education level, age, ethnicity, religion, and resources available in their environment. It is possible for example, that low income individuals lack the resources for appropriate health services and the knowledge to know what is appropriate for maintaining reproductive health.\n\nThe WHO assessed in 2008 that \"Reproductive and sexual ill-health accounts for 20% of the global burden of ill-health for women, and 14% for men.\" Reproductive health is a part of sexual and reproductive health and rights. According to the United Nations Population Fund (UNFPA), unmet needs for sexual and reproductive health deprive women of the right to make \"crucial choices about their own bodies and futures\", affecting family welfare. Women bear and usually nurture children, so their reproductive health is inseparable from gender equality. Denial of such rights also worsens poverty.\n\nAdolescent health creates a major global burden and has a great deal of additional and diverse complications compared to adult reproductive health such as early pregnancy and parenting issues, difficulties accessing contraception and safe abortions, lack of healthcare access, and high rates of HIV and sexually transmitted infections, and mental health issues. Each of those can be affected by outside political, economic and socio-cultural influences. For most adolescent females, they have yet to complete their body growth trajectories, therefore adding a pregnancy exposes them to a predisposition to complications. These complications range from anemia, malaria, HIV and other STI's, postpartum bleeding and other postpartum complications, mental health disorders such as depression and suicidal thoughts or attempts. In 2014, adolescent birth rates between the ages of 15-19 was 44 per 1000, 1 in 3 experienced sexual violence, and there more than 1.2 million deaths. The top three leading causes of death in females between the ages of 15-19 are maternal conditions 10.1%, self-harm 9.6%, and road conditions 6.1%.\n\nThe causes for teenage pregnancy are vast and diverse. In developing countries, young women are pressured to marry for different reasons. One reason is to bear children to help with work, another on a dowry system to increase the families income, another is due to prearranged marriages. These reasons tie back to financial needs of girls' family, cultural norms, religious beliefs and external conflicts.\n\nAdolescent pregnancy, especially in developing countries, carries increased health risks, and contributes to maintaining the cycle of poverty. The availability and type of sex education for teenagers varies in different parts of the world. LGBT teens may suffer additional problems if they live in places where homosexual activity is socially disapproved and/or illegal; in extreme cases there can be depression, social isolation and even suicide among LGBT youth.\n\nNinety nine percent of maternal deaths occur in developing countries and in 25 years, maternal mortality globally dropped to 44%. Statistically, a woman’s chance of survival during childbirth is closely tied to her social economic status, access to healthcare, where she lives geographically, and cultural norms. To compare, a woman dies of complications from childbirth every minute in developing countries versus a total of 1% of total maternal mortality deaths in developed countries. Women in developing countries have little access to family planning services, different cultural practices, have lack of information, birthing attendants, prenatal care, birth control, postnatal care, lack of access to health care and are typically in poverty. In 2015, those in low-income countries had access to antenatal care visits averaged to 40% and were preventable. All these reasons lead to an increase in the Maternal Mortality Ratio (MMR).\n\nOne of the international Sustainable Development Goals developed by United Nations is to improve maternal health by a targeted 70 deaths per 100,000 live births by 2030. Most models of maternal health encompass family planning, preconception, prenatal, and postnatal care. All care after childbirth recovery is typically excluded, which includes pre-menopause and aging into old age. During childbirth, women typically die from severe bleeding, infections, high blood pressure during pregnancy, delivery complications, or an unsafe abortion. Other reasons can be regional such as complications related to diseases such as malaria and AIDS during pregnancy. The younger the women is when she gives birth, the more at risk her and her baby is for complications and possibly mortality.\n\nThere is a significant relationship between the quality of maternal services made\navailable and the greater financial standings of a country. Sub-Saharan Africa and South Asia\nexemplify this as these regions are significantly deprived of medical staff and affordable health\nopportunities. Most countries provide for their health services through a combination of\nfunding from government tax revenue and local households. Poorer nations or regions with\nextremely concentrated wealth can leave citizens on the margins uncared for or overlooked.\nHowever, the lack of proper leadership in the can result in a nation’s public sectors being\nmishandled or poorly performing despite said nation’s resources and standing. In addition,\npoorer nations funding their medical services through taxes places a greater financial burden on\nthe public and effectively the mothers themselves.\nResponsibility and accountability on the part of mental health sectors are strongly\nemphasized as to what will remedy the poor quality of maternal health globally. The impact\nof different maternal health interventions across the globe stagger variously and are vastly\nuneven. This is the result of a lack of political and financial commitment to the issue as most\nsafe motherhood programs internationally have to compete for significant funding. Some\nresolve that if global survival initiatives were promoted and properly funded it would prove to be\nmutually beneficial for the international community. Investing in maternal health would\nultimately advance several issues such as: gender inequality, poverty and general global health\nstandards. As it currently stands, pregnant women are subjugated to high financial costs\nthroughout the duration of their term internationally that are highly taxing and strenuous.\n\nAccess to reproductive health services is very poor in many countries. Women are often unable to access maternal health services due to lack of knowledge about the existence of such services or lack of freedom of movement. Some women are subjected to forced pregnancy and banned from leaving the home. In many countries, women are not allowed to leave home without a male relative or husband, and therefore their ability to access medical services is limited. Therefore, increasing women's autonomy is needed in order to improve reproductive health, however doing may require a cultural shift. According to the WHO, \"All women need access to antenatal care in pregnancy, skilled care during childbirth, and care and support in the weeks after childbirth\".\n\nThe fact that the law allows certain reproductive health services, it does not necessary ensure that such services are \"de facto\" available to people. The availability of contraception, sterilization and abortion is dependent on laws, as well as social, cultural and religious norms. Some countries have liberal laws regarding these issues, but in practice it is very difficult to access such services due to doctors, pharmacists and other social and medical workers being conscientious objectors.\n\nIn developing regions of the world, there are about 214 million women who want to avoid pregnancy but are unable to use safe and effective family planning methods. When taken correctly, the combined oral contraceptive pill is over 99% effective at preventing pregnancy. However, it does not protect from sexually transmitted infections (STIs). Some methods, such as using condoms, achieve both protection from STIs and unwanted pregnancies. There are also natural family planning methods, which may be preferred by religious people, but some very conservative religious groups, such as the Quiverfull movement, oppose these methods too, because they advocate the maximization of procreation. One of the oldest ways to reduce unwanted pregnancy is coitus interruptus - still widely used in the developing world.\n\nThere are many types of contraceptives. One type of contraceptive includes barrier methods. One barrier method includes condoms for males and females. Both types stop sperm from entering the woman’s uterus, thereby preventing pregnancy from occurring. Another type of contraception is the birth control pill, which stops ovulation from occurring by combining the chemicals progestin and estrogen. Many women use this method of contraception, however they discontinue using it equally as much as they use it. One reason for this is because of the side effects that occur from using the pill. Some side effects that result from birth control pill usage include minor side effects such as increased BMI and frequent headaches, and major side effects like dangerous blood pressure levels. Another reason stems from health care providers not taking women’s concerns about negative side effects seriously. When women report negative side effects to their physicians, they are told to continue using the pill. This causes women to dedicate more thought towards which side effects can be accepted rather than how to stop side effects.\n\nThere are many objections to the use of birth control. One argument against birth control usage states there is no need for birth control to begin with. This argument was levied in 1968 when Richard Nixon was elected president, and the argument stated that since birth rates were at their lowest point since World War II ended, birth control was not necessary. Another argument states that women should use natural methods of contraception in place of artificial ones, such as having sexual intercourse when one is infertile. Another natural method encouraged by the Catholic Church is abstinence from sex. This argument was written out in \"Humanae Vitae\", a papal encyclical released in 1968. The Catholic Church bases its argument against birth control pills on the basis that birth control pills undermine the natural law of God. The Catholic Church also argues against birth control on the basis of family size, with Cardinal Mercier of Belgium arguing,  \"...the duties of conscience are above worldly considerations, and besides, it is the large families who are the best\" (Reiterman, 216). Additionally, another argument against birth control stems from fear in the African-American community that Caucasians plan to significantly reduce their population. This fear reached a high point in the 1960s, as birth control clinics were constructed in mainly African-American areas. The fear of decimated African-American communities is a result of slavery and the disproportionate castration of African-Americans.\n\nA Sexually transmitted infection (STI) --previously known as a \"sexually transmitted disease (STD)\" or \"venereal disease (VD)--\" is an infection that has a significant likelihood of transmission between humans by means of sexual activity. The CDC analyses the eight most common STI's: chlamydia, gonorrhea, hepatitis B virus (HBV), herpes simplex virus type 2 (HSV-2), human immunodeficiency virus (HIV), human papillomavirus (HPV), syphilis, and trichomoniasis.\n\nThere are more than 600 million cases of STI's worldwide and more than 20 million new cases within the United States. Numbers of such high magnitude weigh a heavy burden on the local and global economy. A study conducted at Oxford University in 2015 concluded that despite giving participants early antiviral medications (ART), they still cost an estimated $256 billion over 2 decades. HIV testing done at modest rates could reduce HIV infections by 21%, HIV retention by 54% and HIV mortality rates by 64%, with a cost-effectiveness ration of $45,300 per Quality-adjusted life year. However, the study concluded that the United States has led to an excess in infections, treatment costs, and deaths, even when interventions do not improve over all survival rates.\n\nThere is a profound reduction on STI rates once those who are sexually active are educated about transmissions, condom promotion, interventions targeted at key and vulnerable populations through a comprehensive Sex education courses or programs. South Africa’s policy addresses the needs of women at risk for HIV and who are HIV positive as well as their partners and children. The policy also promotes screening activities related to sexual health such as HIV counseling and testing as well as testing for other STIs, tuberculosis, cervical cancer, and breast cancer.\n\nYoung African American women are at a higher risk for STI's, including HIV. A recent study published outside of Atlanta, Georgia collected data (demographic, psychological, and behavioral measures) with a vaginal swab to confirm the presence of STIs. They found a profound difference that those women who had graduated from college were far less likely to have STIs, potentially be benefiting from a reduction in vulnerability to acquiring STIs/HIV as they gain in education status and potentially move up in demographic areas and/or status.\n\nGlobally, an estimated 25 million unsafe abortions occur each year. The vast majority of such unsafe abortions occur in developing countries in Africa, Asia and Latin America. \n\nThe abortion debate is the ongoing controversy surrounding the moral, legal, and religious status of induced abortion. The sides involved in the debate are the self-described “pro-choice” and “pro-life” movements. “Pro-choice” emphasizes the right of women to decide whether to terminate a pregnancy. “Pro-life” emphasizes the right of the embryo or fetus to gestate to term and be born. Both terms are considered loaded in mainstream media, where terms such as “abortion rights” or “anti-abortion” are generally preferred. Each movement has, with varying results, sought to influence public opinion and to attain legal support for its position, with small numbers of anti-abortion advocates using violence, such as murder and arson.\n\nArticles from the World Health Organization call legal abortion a fundamental right of women regardless of where they live, and argue that unsafe abortion is a silent pandemic. In 2005, it was estimated that 19-20 million abortions had complications, some complications are permanent, while another estimated 68,000 women died from unsafe abortions. Having access to safe abortion can have positive impacts on women's health and life, and vice versa. \"Legislation of abortion on request is necessary but an insufficient step towards improving women's health. In some countries where it abortion is legal, and has been for decades, there has been no improvement in access to adequate services making abortion unsafe due to lack of healthcare services. It is hard to get an abortion due to legal and policy barriers, social and cultural barriers (gender discrimination, poverty, religious restrictions, lack of support etc., health system barriers (lack of facilities or trained personnel), however safe abortions with trained personnel, good social support, and access to facilities, can improve maternal health and increase reproductive health later in life.\n\nThe Maputo Protocol, which was adopted by the African Union in the form of a protocol to the African Charter on Human and Peoples' Rights, states at Article 14 (Health and Reproductive Rights) that: \"(2). States Parties shall take all appropriate measures to: [...] c) protect the reproductive rights of women by authorising medical abortion in cases of sexual assault, rape, incest, and where the continued pregnancy endangers the mental and physical health of the mother or the life of the mother or the foetus.\" The Maputo Protocol is the first international treaty to recognize abortion, under certain conditions, as a woman's human right.\n\nThe \"General comment No. 36 (2018) on article 6 of the International Covenant on Civil and Political Rights, on the right to life\", adopted by the Human Rights Committee in 2018, defines, for the first time ever, a human right to abortion - in certain circumstances (however these UN general comments are considered soft law, and, as such, not legally binding).\n\n\"Although States parties may adopt measures designed to regulate voluntary terminations of pregnancy, such measures must not result in violation of the right to life of a pregnant woman or girl, or her other rights under the Covenant. Thus, restrictions on the ability of women or girls to seek abortion must not, inter alia, jeopardize their lives, subject them to physical or mental pain or suffering which violates article 7, discriminate against them or arbitrarily interfere with their privacy. \"States parties must provide safe, legal and effective access to abortion where the life and health of the pregnant woman or girl is at risk, and where carrying a pregnancy to term would cause the pregnant woman or girl substantial pain or suffering, most notably where the pregnancy is the result of rape or incest or is not viable.\" [8] In addition, States parties may not regulate pregnancy or abortion in all other cases in a manner that runs contrary to their duty to ensure that women and girls do not have to undertake unsafe abortions, and they should revise their abortion laws accordingly. [9] For example, they should not take measures such as criminalizing pregnancies by unmarried women or apply criminal sanctions against women and girls undergoing abortion [10] or against medical service providers assisting them in doing so, since taking such measures compel women and girls to resort to unsafe abortion. States parties should not introduce new barriers and should remove existing barriers [11] that deny effective access by women and girls to safe and legal abortion [12], including barriers caused as a result of the exercise of conscientious objection by individual medical providers. [13]\"\n\nWhen negotiating the Cairo Programme of Action at the 1994 International Conference on Population and Development (ICPD), the issue was so contentious that delegates eventually decided to omit any recommendation to legalize abortion, instead advising governments to provide proper post-abortion care and to invest in programs that will decrease the number of unwanted pregnancies.\n\nThe Committee on the Elimination of Discrimination against Women considers the criminalization of abortion a \"violations of women’s sexual and reproductive health and rights\" and a form of \"gender based violence\"; paragraph 18 of its \"General recommendation No. 35 on gender based violence against women, updating general recommendation No. 19\" states that: \"Violations of women’s sexual and reproductive health and rights, such as forced sterilizations, forced abortion, forced pregnancy, criminalisation of abortion, denial or delay of safe abortion and post abortion care, forced continuation of pregnancy, abuse and mistreatment of women and girls seeking sexual and reproductive health information, goods and services, are forms of gender based violence that, depending on the circumstances, may amount to torture or cruel, inhuman or degrading treatment.\" The same \"General Recommendation\" also urges countries at paragraph 31 to [...] In particular, repeal:\na) Provisions that allow, tolerate or condone forms of gender based violence against women, including [...] legislation that criminalises abortion\".\n\nIn 2008, the Parliamentary Assembly of the Council of Europe, a group comprising members from 47 European countries, has adopted a resolution calling for the decriminalization of abortion within reasonable gestational limits and guaranteed access to safe abortion procedures. The nonbinding resolution was passed on April 16 by a vote of 102 to 69.\n\nAccesses to abortion is not only a question of legality, but also an issue of overcoming de \"facto barriers\", such as conscientious objections from medical stuff, high prices, lack of knowledge about the law, lack of access to medical care (especially in rural areas). The \"de facto\" inability of women to access abortion even in countries where it is legal is highly controversial because it results in a situation where women have rights only on paper not in practice; the UN in its 2017 resolution on \"Intensification of efforts to prevent and eliminate all forms of violence against women and girls: domestic violence\" urged states to guarantee access to \"safe abortion where such services are permitted by national law\".\n\nThere are two primary arguments for maintaining legalized abortion today in the U.S. The first is recognizing the full citizenship of women. The Roe v. Wade court case on abortion compared the citizenship of women and fetuses Because the Constitution defines born people as citizens, Justice Harry Blackmun ruled that fetuses were not citizens. The citizenship of women is emphasized because fetuses are not individual entities that can exist without the woman. Another reason why the full citizenship of women is defined by advocates for abortion is that it recognizes the right of women to manage their own bodies. Fertility affects women’s bodies. The argument for abortion prevents others from making decisions that alter a woman’s body. Pro-choice advocates also attempt to confirm that state-mandated education or other outside biases don’t attempt to influence these decisions. Feminists argue that women throughout history have had to justify their citizenship politically and socially. The right to manage one’s own body is a matter of health, safety, and respect. The citizenship of women and the right to manage their own bodies is a societal confirmation that feminists highlight as a pro-choice justification. \n\nThe second primary argument to uphold legalized abortion and creating better access to it is the necessity of abortion and the health and safety of pregnant women. There are two events that largely changed the course of public opinion about abortion in the U.S. . The first is Sherry Finkbine, who was denied access to an abortion by the board of obstetrician-gynecologists at her local hospital. Although she was privileged enough to afford the trip, Finkbine was forced to travel to Sweden for an abortion to avoid caring for a damaged fetus in addition to four children . The other event that changed public opinion was the outbreak of rubella in the 1950s and 60s.. Because rubella disrupted the growth of fetuses and caused deformities during pregnancy, the California Therapeutic Abortion Act was signed in 1967. This Act allowed doctors to perform abortions when the pregnancy risked the physical or mental health of the pregnant person. These two events are commonly used to show how the health and safety of pregnant women are contingent upon abortions as well as the ability to give birth to and adequately take care of a child. Another argument in favor of legalized abortion to service necessity are the reasons why an abortion might be necessary. Nearly half of all pregnancies in the United States are unintended, and over half of all unintended pregnancies in the United States are met with abortion. Unintended pregnancy can lead to serious harm to women and children for reasons such as not being able to afford to raise a baby, inaccessibility to time off of work, difficulties facing single motherhood, difficult socio-economic conditions for women. Unintended pregnancies also have a greater potential for putting women of color at risk due to systematically produced environmental hazards from proximity to pollution, access to livable income, and affordable healthy food . These factors as threats to the health and safety of pregnant women run parallel to data that shows the number of abortions in the United States did not decline while laws restricting legal access to abortion were implemented.\n\nAt a global level, the region with the strictest abortion laws is considered to be Latin America (see Reproductive rights in Latin America), a region strongly influenced by the Catholic Church in Latin America.\n\nFemale genital mutilation (FGM), also known as female genital circumcision or cutting, is the traditional, non-medical practice of altering or injuring the female reproductive organs, often by removing all or parts of the external genitalia. It is mostly practiced in 30 countries in Africa, the Middle East, and Asia, and affects over 200 million women and girls worldwide. More severe forms of FGM are highly concentrated in Djibouti, Eritrea, Ethiopia, Somalia, and Sudan.\n\nThe WHO categorizes FGM into four types:\n\n\nFGM often takes the form of a traditional celebration conducted by an elder or community leader. The age that women undergo the procedure varies depending on the culture, although it is most commonly performed on prepubescent girls. Certain cultures value FGM as coming of age ritual for girls, and use it to preserve a woman's virginity and faithfulness to the husband after marriage. It is also closely connected with some traditional ideals of female beauty and hygiene. FGM may or may not have religious connotations depending on the circumstances.\n\nThere are no health benefits of FGM, as it interferes with the natural functions of a woman's and girls' bodies, such as causing severe pain, shock, hemorrhage, tetanus or sepsis (bacterial infection), urine retention, open sores in the genital region and injury to nearby genital tissue, recurrent bladder and urinary tract infections, cysts, increased risk of infertility, childbirth complications and newborn deaths. Sexual problems are 1.5 more likely to occur in women who have undergone FGM, they may experience painful intercourse, have less sexual satisfaction, and be two times more likely to report lack of sexual desire. In addition, the maternal and fetal death rate is significantly higher due to childbirth complications.\n\nFGM can have severe negative psychological effects on women, both during and after the procedure. These can include long-term symptoms of depression, anxiety, post-traumatic stress disorder, and low self-esteem. Some women report that the procedure was carried out without their consent and knowledge, and describe feelings of fear and helplessness while it was taking place. A 2018 study found that larger quantities of the hormone cortisol were secreted in women who had undergone FGM, especially those who had experienced more severe forms of the procedure and at an early age. This marks the body's chemical response to trauma and stress, and can indicate a greater risk for developing symptoms of PTSD and other trauma disorders, although there are limited studies showing a direct correlation.\n\nLegislation has been introduced in certain countries to prevent FGM. A 2016 survey of 30 countries showed 24 had policies to manage and prevent FGM, although the process to provide funding, education, and resources were often inconsistent and lacking. Some countries have seen a slight decline in FGM rates, while others show little to no change.\n\nThe Istanbul Convention prohibits FGM (Article 38).\n\nThe practice of forcing young girls into early marriage, common in many parts of the world, is threatening their reproductive health. According to the World Health Organization:\n\n\"The sexual and reproductive health of the female in a child marriage is likely to be jeopardized, as these young girls are often forced into sexual intercourse with an older male spouse with more sexual experience. The female spouse often lacks the status and the knowledge to negotiate for safe sex and contraceptive practices, increasing the risk of acquiring HIV or other sexually transmitted infections, as well as the probability of pregnancy at an early age.\" \n\nNiger has the highest prevalence of child marriage under 18 in the world, while Bangladesh has the highest rate of marriage of girls under age 15. Practices such as bride price and dowry can contribute to child and forced marriages.\n\nThe International Conference on Population and Development (ICPD) was held in Cairo, Egypt, from 5 to 13 September 1994. Delegations from 179 States took part in negotiations to finalize a Programme of Action on population and development for the next 20 years. Some 20,000 delegates from various governments, UN agencies, NGOs, and the media gathered for a discussion of a variety of population issues, including immigration, infant mortality, birth control, family planning, and the education of women.\n\nIn the ICPD Program of Action, 'reproductive health' is defined as:\n\na state of complete physical, mental and social well-being and...not merely the absence of disease or infirmity, in all matters relating to the reproductive system and its functions and processes. Reproductive health therefore implies that people are able to have a satisfying and safe sex life and that they have the capability to reproduce and the freedom to decide if, when and how often to do so. Implicit in this last condition are the right of men and women to be informed [about] and to have access to safe, effective, affordable and acceptable methods of family planning of their choice, as well as other methods of birth control which are not against the law, and the right of access to appropriate health-care services that will enable women to go safely through pregnancy and childbirth and provide couples with the best chance of having a healthy infant.\n\nThis definition of the term is also echoed in the United Nations Fourth World Conference on Women, or the so-called Beijing Declaration of 1995. However, the ICPD Program of Action, even though it received the support of a large majority of UN Member States, does not enjoy the status of an international legal instrument; it is therefore not legally binding.\n\nThe Program of Action endorses a new strategy which emphasizes the numerous linkages between population and development and focuses on meeting the needs of individual women and men rather than on achieving demographic targets. The ICPD achieved consensus on four qualitative and quantitative goals for the international community, the final two of which have particular relevance for reproductive health:\n\n\nThe keys to this new approach are empowering women, providing them with more choices through expanded access to education and health services, and promoting skill development and employment. The programme advocates making family planning universally available by 2015 or sooner, as part of a broadened approach to reproductive health and rights, provides estimates of the levels of national resources and international assistance that will be required, and calls on governments to make these resources available.\n\nHalf of the development goals put on by the United Nations started in 2000 to 2015 with the Millennium Development Goals (MDGs). Reproductive health was Goal 5 out of 8. To monitor the progress, the UN agreed to four indicators:\n\n\nProgress was slow, and according to the WHO in 2005, about 55% of women did not have sufficient antenatal care and 24% had no access to family planning services. The MDGs expired in 2015 and were replaced with a more comprehensive set of goals to cover a span of 2016-2030 with a total of 17 goals, called the Sustainable Development Goals. All 17 goals are comprehensive in nature and build off one another, but goal 3 is \"To ensure health lives and promote wellbeing for all at all ages\". Specific goals are to reduce global maternal mortality ratio to less than 70 per 100,000 live births, end preventable deaths of newborns and children, reduce the number by 50% of accidental deaths globally, strengthen the treatment and prevention programs of substance abuse and alcohol.\n\nHIV/AIDS in Africa is a major public health problem. Sub-Saharan Africa is the worst affected world region for prevalence of HIV, especially among young women. 90% of the children in the world living with HIV are in sub-Saharan Africa.\n\nIn most African countries, the total fertility rate is very high, often due to lack of access to contraception and family planning, and practices such as forced and child marriage. Niger, Angola, Mali, Burundi and Somalia have very high fertility rates.\n\nThe updated contraceptive guidelines in South Africa attempt to improve access by providing special service delivery and access considerations for sex workers, lesbian, gay, bisexual, transgender and intersex individuals, migrants, men, adolescents, women who are perimenopausal, have a disability, or chronic condition. They also aim to increase access to long acting contraceptive methods, particularly the copper IUD, and the introductions of single rod progestogen implant and combined oestrogen and progestogen injectables. The copper IUD has been provided significantly less frequently than other contraceptive methods but signs of an increase in most provinces were reported. The most frequently provided method was injectable progesterone, which the article acknowledged was not ideal and emphasised condom use with this method because it can can increase the risk of HIV: The product made up 49% of South Africa’s contraceptive use and up to 90% in some provinces.\n\nTanzanian provider perspectives address the obstacles to consistent contraceptive use in their communities. It was found that the capability of dispensaries to service patients was determined by inconsistent reproductive goals, low educational attainment, misconceptions about the side effects of contraceptives, and social factors such as gender dynamics, spousal dynamics, economic conditions, religious norms, cultural norms, and constraints in supply chains. A provider referenced and example of propaganda spread about the side effects of contraception: \"There are influential people, for example elders and religious leaders. They normally convince people that condoms contain some microorganisms and contraceptive pills cause cancer\". Another said that women often had pressure from their spouse or family that caused them to use birth control secretly or to discontinue use, and that women frequently preferred undetectable methods for this reason. Access was also hindered as a result of a lack in properly trained medical personnel: \"Shortage of the medical attendant...is a challenge, we are not able to attend to a big number of clients, also we do not have enough education which makes us unable to provide women with the methods they want\". The majority of medical centers were staffed by people without medical training and few doctors and nurses, despite federal regulations, due to lack of resources. One center had only one person who was able to insert and remove implants, and without her they were unable to service people who wanted an implant inserted or removed. Another dispensary that carried two methods of birth control shared that they sometimes run out of both materials at the same time. Constraints in supply chains sometimes cause dispensaries to run out of contraceptive materials. Providers also claimed that more male involvement and education would be helpful. Public health officials, researchers, and programs can gain a more comprehensive picture of the barriers they face, and the efficacy of current approaches to family planning, by tracking specific, standardized family planning and reproductive health indicators.\n\n\n"}
{"id": "33094020", "url": "https://en.wikipedia.org/wiki?curid=33094020", "title": "Ring 18", "text": "Ring 18\n\nRing 18 is a genetic condition caused by a deletion of the two tips of chromosome 18 followed by the formation of a ring-shaped chromosome. It was first reported in 1964.\n\nRing 18 causes a wide range of medical and developmental concerns. As discussed above, people with ring 18 can have features of both distal 18q- and 18p-. The features of distal 18q- and 18p- vary greatly because of the variability of the deletion size and breakpoint locations between people. Because ring 18 can involve unique deletions of both the p and q arms of the chromosome there is twice as much reason for the variability between individuals. This variation is also partly attributable to the incidence of mosaicism, which is relatively common in people with ring 18.\n\n\n\nIndividuals with ring 18 have one of their two copies of chromosome 18 that has formed the shape of a ring. The ring is formed when the caps on both the long arm (q) and the short arm (p) of one copy of chromosome 18 are lost and the new ends re-join to form the ring. Because the ring involves deletions of both the long arm (18q-) and the short arm (18p-) of chromosome 18, individuals with ring 18 can have features of both 18p- as well as distal 18q-.\n\nSuspicion of a chromosome abnormality is typically raised due to the presence of developmental delays or birth defects. Diagnosis of ring 18 is usually made via a blood sample. A routine chromosome analysis, or karyotype, is usually used to make the initial diagnosis, although it may also be made by microarray analysis. Increasingly, microarray analysis is also being used to clarify breakpoints. Prenatal diagnosis is possible via amniocentesis or chorionic villus sampling.\n\nAt present, treatment for ring 18 is symptomatic, meaning that the focus is on treating the signs and symptoms of the conditions as they arise. To ensure early diagnosis and treatment, it is suggested that people with ring 18 undergo routine screenings for thyroid, hearing, and vision problems.\n\nCurrently, research is focusing on identifying the role of the genes on 18p and 18q in causing the signs and symptoms associated with deletions of 18p and/or 18q. This will ultimately enable predictive genotyping.Thus far, several genes on chromosome 18 have been linked with a phenotypic effect.\n\nTGIF - Mutations and deletions of this gene, which is located on18p, have been associated with holoprosencephaly. Penetrance is incomplete, meaning that a deletion of one copy of this gene is not in and of itself sufficient to cause holoprosencephaly. Ten to fifteen percent of people with 18p- have holoprosencephaly, suggesting that other genetic and environmental facts play a role in the etiology of holoprosencephaly in these individuals.\n\nTCF4 – In 2007, deletions of or point mutations in this gene, which is located on 18q, were identified as the cause of Pitt-Hopkins disease. This is the first gene that has been definitively shown to directly cause a clinical phenotype when deleted. If a deletion includes the TCF4 gene (located at 52,889,562-52,946,887), features of Pitt-Hopkins may be present, including abnormal corpus callosum; short neck; small penis; accessory and wide-spaced nipples; broad or clubbed fingers; and sacral dimple. Those with deletions inclusive of TCF4 have a significantly more severe cognitive phenotype.\n\nTSHZ1 - Point mutations and deletions of this gene, located on 18q, are linked with congenital aural atresia Individuals with deletions inclusive of this gene have a 78% chance of having aural atresia.\n\n\"Critical regions\" – Recent research has narrowed the critical regions for four features of the distal 18q- phenotype down to a small segment of distal 18q, although the precise genes responsible for those features remain to be identified.\n\n\"Haplolethal Regions\" - There are two regions on chromosome 18 that has never been found to be deleted. They are located between the centromere and 22,826,284 bp (18q11.2) and between 43,832,732 and 45,297,446 bp (18q21.1). It is hypothesized that there are genes in these regions that are lethal when deleted.\n\nThe phrase “ring 18” refers to the shape that the normally linear chromosome assumes when one tip of the chromosome joins the other. A ring-shaped chromosome is the result. In the case of ring 18, one of the two copies of chromosome 18 has formed a ring.\n"}
{"id": "8750302", "url": "https://en.wikipedia.org/wiki?curid=8750302", "title": "Royal Australian and New Zealand College of Ophthalmologists", "text": "Royal Australian and New Zealand College of Ophthalmologists\n\nThe Royal Australian and New Zealand College of Ophthalmologists (RANZCO) is the medical college responsible for training and professional development of ophthalmologists in Australia and New Zealand. The headquarters of the College is in Sydney, Australia.\n\nOphthalmologists who have successfully completed the training program of The Royal Australian and New Zealand College of Ophthalmologists are known as Fellows of the College (FRANZCO).\n\nIn Australia and New Zealand, an ophthalmologist is required to have undertaken a minimum of 12 years of training, including:\n\n· 5–7 years at a medical school, graduating with a degree in medicine.\n\n· 2 years (minimum) as a newly qualified doctor undertaking basic medical training.\n\n· 5 years of ophthalmic specialist training and successful completion of examinations set by The Royal Australian and New Zealand College of Ophthalmologists (RANZCO).\n\nRANZCO is responsible for training, examining and representing medical practitioners in the specialty of ophthalmology, who upon completion of training, are equipped to undertake unsupervised ophthalmology practice.\n\nRANZCO has a vital interest in the continual improvement and development of ophthalmologists in Australia and New Zealand. The RANZCO Continuing Professional Development (CPD) Program provides Fellows (FRANZCO) with a structured approach to planning their continuing education, and supports activities that cover a wide range of skills, including further clinical knowledge, risk management, clinical governance and professional values. The program consists of three categories reflecting the seven key roles and attributes of a specialist ophthalmologist - Medical Expert, Communicator, Manager, Collaborator, Health Advocate, Scholar and Professional.\n\nRANZCO’s mission is to drive improvements in eye healthcare in Australia, New Zealand and the Asia-Pacific region through continuing exceptional training, education, research and advocacy. Currently, RANZCO participates alongside the International Council of Ophthalmology (ICO), the International Agency for the Prevention of Blindness (IAPB), the Vision2020Australia Global Consortium and the Commonwealth Eye Health Consortium.\n\nOn 23 March 1938, 20 ophthalmologists from various states gathered in Sydney to form the Ophthalmological Society of Australia of the British Medical Association, with Sir James Barrett as its first President.\nPrior to this, the Intercolonial (later Australasian) Medical Congresses had provided the only vehicle for Australian ophthalmologists to meet and exchange professional ideas. Dissatisfaction with this arrangement led to the successful move to create a truly national organisation to represent the profession.\n\nIn April 1939, the Ophthalmological Society of Australia held its first annual national scientific meeting in Melbourne. This meeting was followed later in 1939 by the publication of Volume 1 of Transactions of the Ophthalmological Society of Australia, the precursor to the College's current scientific journal.\nIn the post war years there was growing dissatisfaction about the standard of ophthalmological training in Australia. Qualifications were fragmented and there was no national agreement about the basic determination of competence to practice ophthalmology. Many felt that the setting of national standards and training was a matter for organised ophthalmology, and that this should be carried out by a college rather than a society. In 1968, these views carried the day, and led to the formation of the Australian College of Ophthalmologists in May 1969.\n\nThe new College absorbed the members, assets, policies and procedures of the Society. In addition, the new Articles of Association provided for the College to supervise the training of aspiring ophthalmologists and conduct examinations to test and recognise their competence. The new arrangements were a considerable success, recognised by the grant of the Royal prefix in 1977.\n\nClose links had always existed between Australian and New Zealand ophthalmologists. Reflecting this, there were moves in 1939 to include New Zealand ophthalmologists in the Australian Society. The British Medical Association rules precluded this, however, and the Ophthalmological Society of New Zealand was formed as a separate body.\nDespite this setback, the relationship continued between Australian and New Zealand ophthalmologists, culminating in 1997 with the joint decision to form a New Zealand Branch of the College. The final change occurred in November 2000, with the change of name to The Royal Australian and New Zealand College of Ophthalmologists.\n\nThe RANZCO trains ophthalmologists through the Vocational Training Program, which typically takes 5 years which includes three stages of training; Basic training stage, Advanced training stage and then the Final Year training stage. Trainees rotate through different hospitals for clinical development and training. The 7 key roles underpinning selection, training and assessment are: ophthalmic expert and clinical decision maker, communicator, collaborator, manager, health advocate, scholar, and professional.\n\nIn January 2010, the Commonwealth Government's Department of Health and Ageing (DoHA) announced that it was to consolidate a range of programs aimed at establishing training places in settings other than the traditional public teaching hospitals into the one Specialist Training Program (STP). The STP is designed to expand the training opportunities for specialist trainees particularly in rural and private practice settings.\n\n· Clinical & Experimental Ophthalmology, a scientific journal.\n\n· EYE2EYE, a quarterly update for Fellows including activities and achievements in eye-health.\n"}
{"id": "39586060", "url": "https://en.wikipedia.org/wiki?curid=39586060", "title": "Ruth Moore Act of 2013", "text": "Ruth Moore Act of 2013\n\nThe Ruth Moore Act of 2013 () is a bill that was introduced into the 113th United States Congress and passed the United States House of Representatives on June 4, 2013. The bill would change some of the rules regarding mental health medical coverage for veterans to treat claims related to military sexual trauma more leniently with respect to requiring proof of such sexual trauma.\n\nThe bill is named after veteran Ruth Moore, a woman who was raped twice and then spent 23 years trying to get the benefits that were due to her. Many military rapes go unreported, making it difficult for service members to get help later under the existing rules.\n\n\"This summary is based largely on the summary provided by the Congressional Research Service, a public domain source.\"\n\nThe Ruth Moore Act of 2013 would direct the United States Secretary of Veterans Affairs (VA), in any case in which a veteran claims that a covered mental health condition was incurred in or aggravated by military sexual trauma during active duty, to accept as sufficient proof of service-connection a diagnosis by a mental health professional together with satisfactory lay or other evidence of such trauma and an opinion by the mental health professional that such condition is related to such trauma, if consistent with the circumstances, conditions, or hardships of such service, notwithstanding the fact that there is no official record of such incurrence or aggravation in such service, and to resolve every reasonable doubt in favor of the veteran. The law would, however, allow such service-connection to be rebutted by clear and convincing evidence to the contrary.\n\nThe Ruth Moore Act of 2013 would include as a \"covered mental health condition\" post-traumatic stress disorder, anxiety, depression, or any other mental health diagnosis that the Secretary determines to be related to military sexual trauma.\n\nFinally, if passed, the law would require the Secretary to report annually to Congress in each of 2014 through 2018 on covered claims submitted.\n\nThe Ruth Moore Act of 2013 () was introduced in the House by Rep. Chellie Pingree (D-ME) on February 13, 2013. It was referred to the United States House Committee on Veterans' Affairs and the United States House Veterans' Affairs Subcommittee on Disability Assistance and Memorial Affairs. It passed the House on June 4, 2013 by a voice vote.\n\n\n"}
{"id": "53365850", "url": "https://en.wikipedia.org/wiki?curid=53365850", "title": "Seána Talbot", "text": "Seána Talbot\n\nSeána Talbot is a former President of the UK charity National Childbirth Trust (NCT). \nShe first became a member of NCT in 1995. She was elected as a trustee in 2009. Elected as President by NCT members in September 2015, at the Annual general meeting. She was pressured into resigning along with a fellow trustee in December 2016, after a child died of cot death in a cot endorsed by the trust.\n\nShe has held various health management posts in Northern Ireland, and in 2014, was appointed as Non-Executive Director on the Board of the Patient and Client Council (PCC).\n"}
{"id": "33347048", "url": "https://en.wikipedia.org/wiki?curid=33347048", "title": "Susannah Lazar", "text": "Susannah Lazar\n\nSusannah Lazar is an American medical physicist, amateur astronomer and a discoverer of minor planets.\n\nShe is affiliated with the Highland Road Park Observatory, where she co-discovered asteroid 20430 Stout with Walter R. Cooney, Jr. at age 16, and named it after her late great-grandfather Earl Douglas Stout (c. 1895–1985).\n\nAt the time she was a home school senior in Baton Rouge, Louisiana.\n\n\n"}
{"id": "39164260", "url": "https://en.wikipedia.org/wiki?curid=39164260", "title": "Sweetened beverage", "text": "Sweetened beverage\n\nA sweetened beverage is any beverage with added sugar. It has been described as \"liquid candy\". Consumption of sweetened beverages has been linked to weight gain, obesity, and associated health risks. According to the CDC, consumption of sweetened beverages is also associated with unhealthy behaviors like smoking, not getting enough sleep and exercise, and eating fast food often and not enough fruits regularly.\n\nA number of studies suggest that there is a significant correlation between increased consumption of sweetened beverages and weight gain leading to obesity. There has also been an association between consumption of sweetened beverages and health risks such as coronary heart disease and diabetes. Due to negative health effects of overconsumption of sweetened beverages, a sweetened beverage tax (soda tax) has been recommended by the Institute of Medicine in 2009.\n\nSome countries have tried to reduce sugary beverages in an effort to bring liquid caloric intake down. Mexico placed a tax on sugar-sweetened beverages (SSBs) in 2014. Drinks that were not taxed included drinks with NNSs, milk with no added sugar, and water. Other governments are active in placing policy on school lunches or what is being offered in school cafeterias in regards to beverages. Governmental activity is trying to eventually slow down the obesity epidemic.\n\nNon-nutritive sweeteners (NNSs) have been introduced into the market in non-caloric drinks such as diet sodas. These artificial sweeteners are popular due to the growing demand for alternatives to SSBs. Consumption of artificially sweetened beverages (ASBs) with low-caloric NNSs has risen worldwide in recent years, with reports of consumption in approximately 30% of adults and 15% of children in USA between 2007 and 2008. These sweeteners are more potent than regular, natural sugars and work by promoting GLP-1 (glucagon-like peptide1) secretion, which then stimulates gastric emptying and increases insulin secretion. NNSs have shown to help short-term weight loss initiatives, but they don't show significance in the long-term. Recent studies have been conducted to see whether or not NNSs pose a great risk for the development of certain diseases.\nDue to its ability to dissociate the sensation of sweet from caloric intake via hormonal changes, NNSs may increase appetite and promote larger food consumption and weight gain. Studies have found various negative health outcomes associated with NNSs, including weight gain, obesity, metabolic syndrome, type II diabetes, cardiovascular events, and bladder cancer. NNSs pose a greater risk to children especially because caloric compensation after consumption of NNSs is more complete in children who, compared to adults, lack social cues, learned behaviors, and self-control. Children compensate for NNSs consumption by increasing meal-associated calories and thus are at a higher risk of NNSs-associated weight gain. One study researched the effect of NNSs with cardiovascular disease. The research was taken using post menopausal women. Women who consumed two or more diet drinks (containing NNSs) were found to be 30% at risk for cardiovascular disease. There has been a decline in liquid calories due to the introduction of NNSs.\n\nSugar sweetened beverages or sugary drinks are beverages that contain any form of added sugars. Out of the entire diet, Americans add sugar to beverages more so than any other product. Sugar-Sweetened beverages or sugary drinks are the leading source of added sugars in the American diet. Added sugars include syrups and other caloric sweeteners. Other examples of added sugars, especially ones that can be listed as an ingredient, include brown sugar, corn sweetener, corn syrup, dextrose, fructose, glucose, high fructose corn syrup, honey, invert sugar, lactose, malt syrup, maltose, molasses, raw sugar, sucrose, trehalose, and turbinado sugar. The added sugar content is associated with several health concerns like weight gain, obesity, type 2 diabetes, heart disease, liver disease, dental implications, and gout. Naturally occurring sugars, such as those in fruit or milk, are not added sugars. Even though there are several beverages/drinks that have sugar in them, some beverages, such as milk, fruit juice, and diet drinks, fall into a \"gray\" area because of different contributions to health and weight gain is more complex. Sugar-sweetened beverages contain added sugars such as sucrose or fructose, often in large amounts, which contribute to the overall energy density of diets. The World Health Organization (WHO) has developed guidance on free sugars. Based on the impact of free sugars intake and its effects on weight gain and dental issues the WHO has taken action on such problems. Free sugars include monosaccharides and disaccharides added to foods and beverages by the manufacturer, cook or consumer, and sugars naturally present in honey, syrups, fruit juices and fruit juice concentrates. Current evidence suggests that increasing consumption of sugar-sweetened beverages is associated with weight gain. Reducing consumption of sugar-sweetened beverages can also reduce the risk of unhealthy weight gain in adults. For a normal calorie diet, calories from added sugars should be less than 10 percent of the daily calorie limit. Eating habits that include a lesser amount of added sugars, that can be from reduced intake of sugary drinks, can be associated with reduced risk of CVD in adults, and moderate evidence indicates that these eating patterns are associated with reduced risk of obesity, type 2 diabetes, and some types of cancer in adults.\n\nEvidence regarding sugar addiction is mainly based on literature and research conducted on animals. There is a biomedical and neurological science behind the usage of mini-pigs and lab rodents. In these animal species, there are similarities with humans in terms of cognition, development of food preferences and eating disorders, digestive anatomy and functions, as well as brain development. Research has demonstrated that, under certain conditions, rats can develop addiction-like behaviors with respect to sugar. The food addiction model asserts that excessive consumption of palatable foods may be understood within the same neurobiological framework as drug addiction. The test subjects have similar brain anomalies as those described in humans. Drug addiction has an impact on the brain's reward center and substance abuse. In drug addiction, there is a \"drug-seeking\" behavior, which is similar having a \"sweet tooth\" and seeking to satisfy the desire for a sweet item. Reward from eating is controlled by the mesolimbic dopamine (DA) pathway. In the animal study, a fructose and glucose diet induced modifications in several brain regions involved in reward and eating behavior. The observations from the study asserts that food and drug consumption share a common neurobiology that \"hijack\" a neural system that primarily processes natural rewards like foods. Sugar is believed to stimulate dopamine in the central nervous system. In summary, the research provided several clinical facts and evidences on the effects of sugar consumption on the central nervous system.\nHuman research has also been conducted on sugar (in the form of sugar-sweetened beverages) and its effects on the kidneys. Sugar consumption has been associated with the rising prevalence of chronic kidney disease in the United States. Since 1997, the nation has dramatically increased sugar consumption to nearly half a pound per person per day. Much of this increase is driven by high fructose syrup (HFCS) consumption, which now amounts to over 62 lb per person per year, largely in form of sugar-sweetened beverages. In addition to dietary sugar being associated with CKD risk factors, data from animal studies do suggest that sugar consumption may independently affect kidney disease risk. Studies have been conducted to highlight the severity of sugary sweetened beverage consumption. These studies were completed with a variety of test subjects to account for age, sex, diets, lifestyle choices, physical activity, smoking, level of education, and health status. The variety in the test subjects created a wide spectrum of results to match any individual. Also, the experiments consisted of a variety of consumption frequencies. Some studies only consumed one glass of a sugary sweetened beverage a week, while others consumed more than seven glasses of a sugary sweetened beverage a week.\n\nIn a recent study, the notion of sugar addiction has been challenged. The study examined a sample of 1495 human participants to determine if foods mainly containing sugar cause \"addiction-like\" problems that meet clinical Diagnostic and Statistical Manual of Mental Disorders criteria for substance dependence. The researchers also investigated whether potential dependence on sugar relates to body weight and negative affectivity such as mood depression. The results revealed that the majority of participants experienced at least one symptom of food dependence for combined high-fat savoury (30%) and high-fat sweet (25%) foods while only a minority experienced such problems for low-fat/savoury (2%) and mainly sugar-containing foods (5%). Furthermore, while addictive-like symptoms for high-fat savoury and high-fat sweet foods correlated to overweight conditions, this was not found to be the case for foods mainly containing sugar. Consequently, the findings indicated that sugary foods have a minimal role to contributing to food dependence and the increased risk of weight gain.\n\nResearch has demonstrated when school aged children (3–7 yrs. Of age) are given the choice of choosing milk or sweetened beverages at lunch time, they tend to choose the sweetened beverages. This has major health implications for children, as nutrition is essential for proper development. Studies have shown sugar sweetened beverages displace important nutrients such as iron and calcium which result in deficiency-related conditions. For example, iron deficiency can result in nerve impulse delay. Children who do not consume the appropriate amount of calcium into their daily diets have lower calcium consumption as they get older. In contrast, as they get older, their intake of sugary beverages increases. Many children grow to have a level of intolerance to milk and another significant percentage grow to not like the taste of milk.[6] Insufficient levels of calcium throughout adolescence is a precursor for osteoporosis and even obesity in some cases. Maternal consumption of milk can influence children's consumption. A study of 9 year old girls and calcium consumption reported those who met the average recommended intake (AI) for calcium consumed almost twice as much milk and less sweetened beverages (18%) had mothers who drank milk more frequently than those who were under the AI for calcium.\n\nHealthy schools campaign is an initiative set forth by Michelle Obama that promotes nutritional enrichment through food an education. The national initiatives under this program are cooking up change, green clean schools, school nurse leadership, and national collaborations. As a result, many of the sugary drinks/ sodas in elementary, middle, and high schools have been replaced by water and other nutritious drinks.\n\nBetween 1975 and 2016, the worldwide prevalence of obesity nearly tripled. According to the World Health Organization, in 2016, more than 1.9 billion of adults, 18 years and older, were overweight. Of these, over 650 million (34%) were obese. Over 340 million children and adolescents aged 5–19 were overweight or obese in 2016. The obesity rate is forecasted to rise to 42% by 2030. Every year, the United States spends an estimated $190 billion on obesity related conditions, or 21% of all United States health care costs.\n\nObesity prevalence is due to genetic, metabolic, cultural, environmental, socioeconomic, and behavioral factors. Along with the increase in overweight and obese populations, the consumption of carbohydrates, particularly in the form of added sugars has increased.\n\nResearch studies have indicated that there is a correlation between drinking sugar-sweetened beverages and gaining weight or becoming obese. Sugar-sweetened beverages do not provide the feeling of fullness like solid foods do, which may cause one to consume more of the beverage. According to the Center for Disease Control, the Behavioral Risk Factor Surveillance System Survey found that 30.1% of American adults consume at least one sugar-sweetened beverage daily. Around the United States, sugar-sweetened beverage intake differs based on geographic regions and socio-demographic characteristics. States known for their obesity rates also had high consumption rates of sugar-sweetened beverages. For example, 47.1% of Mississippi adults consume at least one sugar-sweetened beverage a day. Their obesity rate correlates, with 35.6% of the adult population being obese in 2016.\n\nThe World Health Organization has advised reducing intake of free sugars, such as monosaccharides and disaccharides that are added to beverages by manufacturers, cooks, or consumers. Studies have supported WHO's guidance as well. A 2006 clinical trial found that when over weight or obese adults replaced caloric beverages with water or noncaloric beverages for 6 months, they averaged weight losses of 2–2.5%. In addition, The Obesity Society recommends minimizing children's intake of sugar-sweetened beverages.\n\nEfforts to reduce consumption of sugar-sweetened beverages and obesity include both monetary penalties and limiting exposure to sugar-sweetened beverages. For example, numerous states, including Vermont have proposed taxing sugar-sweetened beverages or increasing the prices to reduce consumption. Economists estimate that increasing sugar sweetened beverage prices by 10% would reduce sugar sweetened beverage consumption by 12%. Global experts in fiscal policies concluded that a minimum of 20% increase in sugar-sweetened beverage taxes would result in proportional reduction in consumption. Other solutions target children, focusing on prohibiting sugar-sweetened beverages on school/after care property, including vending machines and lunches. Limits are also being considered on sugar-sweetened beverages in the workplace. Furthermore, beverage companies are being approached about reducing portion sizing of sugar-sweetened beverages because portion sizes have increased substantially over the past few decades.\n\nOral health has shown to be affected with regard to sugar sweetened beverage consumption. Acid erosion and dental caries have been the main health concerns to sugar sweetened beverages.\n\nAcid erosion is defined as the loss of tooth enamel caused by acid attack. When consuming carbonated sugar sweetened beverages, acid deposits on the teeth, attacking the enamel. Over a gradual period, the enamel is worn down, which can lead to dental caries. Erosion of tooth enamel begins at a pH of 5.5, and ingredients found in sugar sweetened beverages such as phosphoric acid and citric acid significantly contribute to the demineralization of the enamel. Citric acid in various sugar sweetened beverages can cause chelation.\n\nConsumption of sports and energy drinks have been linked to irreversible tooth damage. This is especially common in adolescents who consume about 30-50% of the beverages that are on the market. Studies have shown that energy drinks have caused twice as much damage on teeth than sports drinks. Citric acid, the preservative found in many sugar sweetened beverages causes stripping of the enamel.\n\nFruit juices generally contain lower amounts of sugar than carbonated sugar sweetened beverages. The acidity levels found in fruit juices vary, with citrus based juices having the lowest pH levels. The low acidity found in fruit juices cause higher risk of cavities with enamel exposure.\n\nFrequency of sugar sweetened beverages results in dental caries, which are caused by Streptococcus bacteria. Dental caries is an infectious oral disease and is the breakdown of the teeth due to the bacteria in the mouth. It occurs when bacteria within the plaque metabolize the sugar, releasing various acids as waste compounds. As the acids are released, they form holes in the teeth which dissolve the enamel. The sugars, therefore provide a passageway for the activities of the oral bacteria, lowering salivary pH. The bacteria alone are not the sole cause of tooth decay, as it is the presence of these sugars that inhibit the production of acid.\n\nHypokalemia is a potassium deficiency. It is defined by the level of potassium in the blood; levels 3.5 and 5.0 mmoL are considered to be normal while levels below 3.5 mmol/L are defined as hypokalemia.\n\nThere are many case reports on the relationship between hypokalemia and sugar sweetened beverages such as cola-based drinks. Based on reports published, patients' potassium levels decreased because of an increase in cola consumption; and as the consumption was reduced potassium levels rose back to normal levels. Oral supplements and other methods did not help raise potassium levels. And so it was concluded that extreme cola consumption can lead to hypokalemia. Symptoms caused by an increased consumption of cola that lead to hypokalemia include muscle weakness, leg cramps, and fatigue.\n\nThere are three mechanisms that lead to potassium deficiency due to cola drinks. They are as follows: (1) a large intake of glucose which leads to an intracellular redistribution of potassium; (2) potassium wasting due to large masses of indigestible fructose in the gastrointestinal tract; (3) the caffeine in cola drinks lead to diuresis, an increase in the sodium-potassium pumps via cellular phosphodiesterase inhibition, increased renin levels, and also produced metabolic alkalosis which all lead to hypokalemia.\n\nThe consumption of sugar sweetened beverages has increased over the years; this includes caffeinated and un-caffeinated drinks. The rise in consumption of soft drinks is due to the current convenience, availability, and accessibility of sugar sweetened beverages today. Over these years an increase in concern and action towards the accessibility of sugar sweetened beverages have been taken through policy. Government officials and doctors alike have responded to the increase in sugar sweetened beverages and its health effects. Internists have further discussed adding extreme sugar sweetened beverages consumption to the list of usual questions about alcohol, tobacco, and illicit drugs that lead to hypokalemia. Although low potassium levels are tolerated in healthy adults, as cola consumption increases things like obesity, hypertension, and diabetes can be developed from hypokalemia.\n\nDietary improvements in expecting mothers are important for the future health of the mother and child. Sugar-sweetened beverages among other beverages like coffee and alcohol are recommended to be reduced in intake. A Norwegian study, showed that pregnant woman minimized their intake of sugar-sweetened beverages, alcohol, and coffee, when educated about the negative effects these beverages can have on their unborn child. The statistics for each beverage showed that among alcohol, coffee, and sugar-sweetened beverages, sugar-sweetened beverages were still consumed more despite there being a minimized intake. The minimized intake of coffee and alcohol is due to the less harmful effects sugar-sweetened beverages have compared to coffee and alcohol. The report declares that the minimized intake may be due to alcohol and coffee being a part of socializing and therefore becomes substituted by sugar-sweetened beverages at social events.\n\nA large prospective cohort study showed an approximate doubling of the risk of Type II Diabetes in women who consumed at least one sugary drink per day when compared to women who consumed on average less than one sugary drink daily. This risk seemed to further be linked to an increase in BMI (Body Mass Index) that is associated with obesity and weight gain over the time course of follow-up in the study. It is important to note that fruit juice (containing no added sugars) did not significantly increase the risk for Type II Diabetes throughout the course of this study and these increases in risk seemed to be associated with beverages such as fruit punch, which have much more added sugar.\n\nThe hallmarks of type II diabetes (T2DM) pathogenesis are insulin resistance and impaired insulin secretion. In the earlier stages of disease development, cells throughout the body become resistant to the effects of insulin. Therefore, insulin is unable to cause cells to take up glucose (among other impairments) and glucose builds up in the blood. As a result, insulin secretion is ramped up, to try to compensate for this lack of response. For a while this may work, but eventually, the body's ability to secrete insulin from the pancreatic beta cells gets burnt out. In later stages of T2DM, patient cells are both resistant to insulin effects and the pancreas has lost its ability to produce adequate insulin in response to glucose. Type II diabetes is a progressive disease which eventually can lead to patients becoming dependent on exogenous insulin to lower their blood glucose levels.\n\nConsumption of high fructose and sucrose-containing diets have been previously associated with increased risk of T2DM through animal studies linking increased sugar consumption to decreased insulin sensitivity. However, a definitive conclusion on this association is still controversial, owing to a lack of data and trials on the direct effect of high-sugar diets in T2DM development. Current evidence suggests that the danger of high-sugar diets in increasing T2DM risk comes not from the direct effects of sugar on insulin resistance, but more so from the imbalance of energy intake-use that high-sugar diets can contribute to.\n\nThe increase in consumption of sweetened beverages has been described as a worldwide health problem, but it is particularly visible in the United States, from where most popular drinks, like sodas, have originated. In the US, sweetened beverages such as most sodas are the most widely consumed type of foods containing added sugar, and they account for about a third of all consumption of added sugars (about half if counted together with fruit juice; about twice the amount that is gained from the categories of \"desserts\" and \"sweets\"). They represent about 7% of total energy intake, where they can account for up to 15% in children, and have been described as the \"largest single food source of calories in the US diet\". The consumption of sweetened beverages has increased in the US since the 1970s, accounting for a significant portion (perhaps as high as a half) of the rise in caloric intake among the American populace. Some more recent research suggests that the added sugar consumption in the US has started declining in the 21st century, due to a related decrease in the consumption of sweetened beverages, encouraged by the government health awareness initiative and other programs.\n\nThe following drinks have been classified in the US as sweetened beverages if they contained sugar or other caloric sweeteners: fruit or fruit-flavored drinks, energy drinks, flavored water, coffees, teas, nonalcoholic wines and beers.\n\nHousehold\n\nTaste preferences and eating behaviors in children are molded at a young age by factors, such as parents' habits and advertisements. One study compared what adults and children considered when choosing beverages. For the most part, adults considered whether beverages had sugar, caffeine, and additives. Some of the 7- to 10-year-old children in the study also mentioned \"additives\" and \"caffeine\", which may be unfamiliar terms to them. This showed the possibility of the parents' influence on their children's decision-making on food choice and eating behaviors.\n\nMedia\n\nAlthough many factors contribute to eating behaviors and food choices in children, food advertising and media are also important factors to consider. Marketing and media influences include television advertising, in-school marketing, product placements, kids clubs, the internet, toys and products with brand logos, and youth-targeted promotions. Marketers heavily target children and adolescents as consumers because of the amount of their own money spent annually, their influence on household food purchases, and their future as adult consumers. It has been estimated that US adolescents spend $140 billion a year. Of that, children under 12 years spend another $25 billion and may have the potential to influence another $200 billion of spending per year. Although there are limited studies on food advertisement on actual food intake, a literature review concluded that children exposed to advertising will choose advertised food products, attempt to influence food purchases their parents buy, and request for specific brands, all at higher rates compared to children not exposed.\n\n"}
{"id": "14544789", "url": "https://en.wikipedia.org/wiki?curid=14544789", "title": "Tele-epidemiology", "text": "Tele-epidemiology\n\nTele-epidemiology is the application of telecommunications to epidemiological research and application, including space-based and internet-based systems.\n\nTele-epidemiology applies satellite communication systems to investigate or support investigations of infectious disease outbreak, including disease reemergence. In this application, space-based systems (i.e. GIS, GPS, SPOT5) use natural index and in-situ data (i.e. NDVI, Meteosat, Envisat) to assess health risk to human and animal populations. Space-based applications of tele-epidemiology extend to health surveillance and health emergency response.\nInternet-based applications of tele-epidemiology include sourcing of epidemiological data in generating internet reports and real-time disease mapping. This entails gathering and structuring epidemiological data from news and social media outlets, and mapping or reporting this data for application with research or public health organizations. Examples of such applications include HealthMap and ProMED-mail, two web-based services that map and e-mail global cases of disease outbreak, respectively.\n\nThe United Nations Office for Outer Space Affairs often refers generally to telehealth for applications linking communication and information technologies such as telesurgery and telenursing, to healthcare administration.\n\n\n\nSpace-based tele-epidemiological initiatives, using satellites, are able to gather environmental information relevant to tracking disease outbreaks. S2E, a French multidisciplinary consortium on spatial surveillance of epidemics, has used satellites to garner relevant information on vegetation, meteorology and hydrology. This information, in concert with clinical data from humans and animals, can be used to construct predictive mathematical models that may allow for the forecasting of disease outbreaks. \n\nWeb-based tele-epidemiological services are able to aggregate information from several disparate sources to provide information on disease surveillance and potential disease outbreaks. Both ProMED-mail and Healthmap collect information in several different languages to gather worldwide epidemiological information. These services are both free and allow both health care professionals and laypeople to access reliable disease outbreak information from around the world and in real-time.\n\nSpace-based methodologies require investment of resources for the collection and management of epidemiological information; as such, these systems may not be affordable or technologically feasible for developing countries that need assistance tracking disease outbreaks. Further, the success of space-based methodologies is predicated on the collection of accurate ground-based data by qualified public health professionals. This may not be possible in developing countries because they lack basic laboratory and epidemiological resources\n\nWeb-based tele-epidemiological initiatives have a unique set of challenges that are different from those experienced by space-based methodologies. HealthMap, in an effort to provide comprehensive worldwide information, contains information from a variety of sources including eyewitness accounts, online news and validated official reports. As a result, the site necessarily relies upon third party information, the veracity of which they are not liable.\n\n"}
{"id": "4194749", "url": "https://en.wikipedia.org/wiki?curid=4194749", "title": "Ventriculitis", "text": "Ventriculitis\n\nVentriculitis is the inflammation of the ventricles in the brain. The ventricles are responsible for containing and circulating cerebrospinal fluid throughout the brain. Ventriculitis is caused by infection of the ventricles, leading to swelling and inflammation. This is especially prevalent in patients with external ventricular drains and intraventricular stents. Ventriculitis can cause a wide variety of short-term symptoms and long-term side effects ranging from headaches and dizziness to unconsciousness and death if not treated early. It is treated with some appropriate combination of antibiotics in order to rid the patient of the underlying infection. Much of the current research involving ventriculitis focuses specifically around defining the disease and what causes it. This will allow for much more advancement in the subject. There is also a lot of attention being paid to possible treatments and prevention methods to help make this disease even less prevalent and dangerous.\n\nThere is great deal of variety in the symptoms associated with ventriculitis. The symptoms vary based on a number of different factors including severity of inflammation, underlying cause, and the individual patient.\n\nPatients often present with headaches, painful cranial pressure, and neck pain early in the progression of the disease. Patients with a more advanced infection have been known to complain of many neurological effects such as dizziness, vertigo, confusion, and slurred speech. Very advanced cases can lead to mental instability, nausea, vomiting, rigors, and temporary loss of consciousness. Many patients with ventriculitis also experience some degree of hydrocephalus, which is the buildup of cerebrospinal fluid due to the inability of the ventricles to reabsorb and correctly circulate the fluid. Brain abscess is another common disorder resulting from the inflammation. If left untreated, ventriculitis can lead to serious inhibition of mental function and even death.\n\nThe symptoms vary greatly, in part, because of the underlying or causing infection. While the inflammation can cause a number of effects such as those mentioned previously, the base infection could cause other symptoms that don’t necessarily have to do with the ventriculitis, itself. One of the challenges doctors face in diagnosing ventriculitis is distinguishing indicative symptoms, in spite of the wide variety of possible presentations of the disease. A great deal of emphasis is being put on research into better and faster ways to diagnose ventriculitis without the delay inherent with microbiological testing of the cerebrospinal fluid.\nThe progression of the disease is also largely dependent on the nature of the specific case. Depending on the underlying infection, the way it entered the brain, and the type and timing of treatment, the infection may spread or withdraw on the order of months or days. Ventriculitis is a very serious condition and should be treated early to ensure as little lasting damage as possible.\n\nVentriculitis is caused by an infection of the ventricles, causing an immune response in the lining, which in turn, leads to inflammation. The ventriculitis, is in truth, a complication of the initial infection or abnormality. The underlying infection can come in the form of a number of different bacteria or viruses. The data seems to point to Staphylococci as the leading bacterial cause of infection leading to ventriculitis being present in about 90% of cases, but generally, what is of more concern is the way the infection entered the ventricles. The brain in its natural state is very protected from infection. The blood–brain barrier serves to keep pathogens from entering the sensitive areas of the brain. However, when those natural defenses are by-passed in the hospital setting, the brain is suddenly exposed to a host of potentially harmful bacteria and viruses.\n\nPatients that have had invasive brain surgery or procedures are considered to be the most at risk for experiencing ventriculitis. Two procedures, in particular have been studied extensively due to their high rate of ventriculitis contractions post operation. The first group consists of patients that have had an external ventricular drain implanted to allow physicians to reduce the intracranial pressure they experience. The duration that the drain is implanted varies by necessity, however, the longer the drain is in, the more likely an infection will occur. The second group consists of patients that have an implanted intracranial stent. Both groups of patients have a much higher rate of ventriculitis than the general populace, though there is very little supporting evidence due to the lack of definition of ventriculitis as frequent misdiagnosis. Nearly 25% of patients with an external ventricular drain experience infection-based meningitis or ventriculitis.\n\nVentriculitis is commonly diagnosed using a variety of tests or procedures. When a physician suspects that a patient has ventriculitis, the first step is typically to ascertain the presence of the inflammation using computed tomography (CT) or magnetic resonance imaging (MRI) technology to “take a picture” of the brain. The scans allow physicians to check for “intraventricular debris and pus, abnormal periventricular and subependymal signal intensity, and enhancement of the ventricular lining,” all of which indicate the likelihood of ventriculitis. MRIs have been reported as being highly effective and sensitive in detecting such indicators, even from an early stage.\n\nAfter determining whether a patient shows signs of ventriculitis, the doctor may choose to pursue a more specific and useful diagnosis to find the cause of the ventriculitis. This is done by obtaining a sample of cerebrospinal fluid, most commonly via a procedure called a lumbar puncture or spinal tap. For patients with an implanted external ventricular drain, cerebrospinal fluid can be collected from the drain’s output. After the sample of fluid is obtained, a battery of tests featuring gram staining will be performed to identify any offending pathogen or infection agent. The test will also determine any resistance the pathogen may have to antibiotics. By identifying the viral or bacterial cause of the ventriculitis, doctors are more able to effectively treat the inflammation and infection. This procedure is fairly effective, but is rarely able to isolate anaerobic organisms that may be causing the inflammation, giving cause for further research and procedural development.\nIt is important to note that, though they present with similar symptoms and often occur in tandem, meningitis and ventriculitis are two different diseases, so physicians must be able to distinguish between the two. Meningitis is the inflammation of the protective lining of the central nervous system, called meninges. Because of the similar pathologies and cause of the two types of inflammation, they are difficult to differentiate using chemical testing, but show very different visual effects in both the MRI and CT scans, hence their use as a validation that the patient does, in fact, have ventriculitis and not another, but deceptively similar condition such as meningitis.\n\nTreatment of ventriculitis is critical. If left untreated, it could lead to severe brain damage and even death in some cases. Currently, the only commonly employed treatments of ventriculitis involve an antibiotic regimen targeting the underlying infection causing the inflammation. Typically, the physician will order the patient be placed on broad-spectrum antibiotics in order to manage the symptoms and control the infection while the cerebrospinal fluid samples are analyzed. When a specific bacterial or viral cause is found, the doctor will change the treatment accordingly. There is some debate as to the most effective antibiotics and the best ways to introduce the drugs (e.g. intravenously, orally, etc.), however it is agreed that drug effectiveness is limited by the difficulty of non-invasively allowing the drugs to enter the cerebrospinal fluid.\nShould intracranial pressure reach unsafe levels, the patient may need to have cerebrospinal fluid drained. Implanted external ventricular drains are one of the more common ways to manage and monitor the intracranial pressure, however there are several risks involved with such an invasive procedure, including the risk of further infection.\n\nThere is a great deal of research focused around prevention of ventriculitis. It is crucial that any procedure involving exposing the brain is performed with the utmost care, as infections in the brain are very dangerous and potentially deadly. When patients undergo such procedures, they are often monitored closely over the next several days to ensure that there were no infections and any instance of even a small headache is treated very seriously. It is also necessary to monitor the intracranial pressure of the patients often enough to observe significant changes that could indicate the presence of and infection and ensuing ventriculitis. It is important not to measure the pressure too often, however, as it could in fact lead to infection.\n\nDue to the poor definition of the condition that is ventriculitis, there is still a great deal that is not known about this dangerous condition. While other, similar conditions, such as meningitis or encephalitis, have been thoroughly researched, ventriculitis is a very loose grouping of conditions characterized by the fact that the lining of the ventricles is inflamed. Because no solid definition has been accepted across the medical community, research in the subject has been slow to progress. However, most common research into ventriculitis has been focused on the main points of causation, demographic information, and effectiveness of treatments and prevention methods.\n\nOne of the key areas of research for ventriculitis is discovering and defining exactly what causes it. There are many bacterial and viral infections that could cause inflammation of the ventricles, but researchers are trying to define which are the most common pathogens, the risk levels associated with various medical operations and procedures, and why the symptoms vary so much on a case-by-case basis. Answering these questions will allow doctors to not only better understand ventriculitis, but better treat and prevent it as well.\n\nCurrently, there is very little understanding as to who is at increased risk for ventriculitis, other than those who have undergone neurosurgery or procedures involving brain exposure. Even then, current clinical practices can’t predict which patients will be afflicted. In order to predict which populations should be focused on, researchers must gather more case information about who is diagnosed with ventriculitis and how they present. In essence, the medical community must compile data of as many details as possible from each case so that more generalized conclusions may be drawn.\n\nSo little is currently known about how ventriculitis should be defined and those it affects that even less can be known about prevention methods. While treatment is fairly standard for any infection to some degree, prevention is a different matter. One popular theory is the use of prophylactic antibiotics, administered during insertion of external ventricular drains or ventricular stents with the hope of preventing infection. The results of these studies have been more or less inconclusive due to a lack of standardized protocol, showing no significant benefit to using antibiotics as a preventative measure.\n"}
{"id": "32109910", "url": "https://en.wikipedia.org/wiki?curid=32109910", "title": "Vygotsky Circle", "text": "Vygotsky Circle\n\nThe Vygotsky Circle (also known as Vygotsky–Luria Circle) was an influential informal network of psychologists, educationalists, medical specialists, physiologists, and neuroscientists, associated with Lev Vygotsky (1896–1934) and Alexander Luria (1902–1977), active in 1920-early 1940s in the Soviet Union (Moscow, Leningrad and Kharkov). The work of the Circle contributed to the foundation of the integrative science of mind, brain, and behavior in their cultural and bio-social development also known under somewhat vague and imprecise name of cultural-historical psychology.\n\nThe Vygotsky Circle, also referred to as \"Vygotsky boom\" incorporated the ideas of social and interpersonal relations, the practices of empirical scientific research, and \"Stalinist science\" based on the discursive practices of the Soviet science in the 1930s. The group dispersed after the German invasion of the Soviet Union at the beginning of World War II, but the influence of its former members was quite notable in Soviet science of the postwar period, especially after Soviet psychology finally came to power in early 1960s. A problem with the theories of the Vygotsky Circle and connecting it to the present generation is the biases and misconceptions with the history of Soviet Psychology.\n\nThe Circle included altogether around three dozen individuals at different periods, including Leonid Sakharov, Boris Varshava, Nikolai Bernstein, Solomon Gellerstein, Mark Lebedinsky, Leonid Zankov, Aleksei N. Leontiev, Alexander Zaporozhets, Daniil Elkonin, Lydia Bozhovich, Bluma Zeigarnik, Filipp Bassin, and many others. German-American psychologist Kurt Lewin and Russian film director and art theorist Sergei Eisenstein are also mentioned as the \"peripheral members\" of the Circle.\n\nThe Vygotsky Circle was formed around 1924 in Moscow after Vygotsky moved there from the provincial town of Gomel in Belarus. There at the Institute of Psychology he met graduate students Zankov, Solov'ev, Sakharov, and Varshava, as well as future collaborator Aleksander Luria. The group grew incrementally and operated in Moscow, Kharkov, and Leningrad; all in the Soviet Union. From the beginning of World War II 1 Sept 1939 to the start of the Great Patriotic War, 22 June 1941, several centers of post-Vygotskian research were formed by Luria, Leontiev, Zankov, and Elkonin. The Circle ended, however, when the Soviet Union was invaded by Germany to start the Great Patriotic War.\n\nHowever, as a result of growing control over science and following a period of political persecutions during Stalin's Great Terror (1936-1953) a new center was formed around 1939 under the leadership of Luria and Leontiev. In the after-war period this developed into the so-called the \"School of Vygotsky-Leontiev-Luria\". Recent studies show that this \"school\" never existed as such.\n\nThere are two problems that are related to the Vygotsky circle. First was the historical recording of the Soviet psychology with innumerable gaps in time and prejudice. Second was the almost exclusive focus on the person, Lev Vygotsky, himself to the extent that the scientific contributions of other notable characters have been forgotten.\n\nSource: Note: This list does not include some of Luria’s collaborators of 1920-30s and those members of the Kharkov group of researchers who did not work directly with Vygotsky;\n\n\nPrimary\n\nSecondary\n"}
{"id": "56379904", "url": "https://en.wikipedia.org/wiki?curid=56379904", "title": "WNT4 deficiency", "text": "WNT4 deficiency\n\nWNT4 deficiency is a rare genetic disorder that affects females and it results in the underdevelopment and sometimes absence of the uterus and vagina. WNT4 deficiency is caused by mutations of the WNT4 gene. Abnormally high androgen levels are found in the blood and can initiate and promote the development of male sex characteristics. This is seen as male pattern of hair growth on the chest and face. Those with this genetic defect develop breasts but do not have their period. Mayer–Rokitansky–Küster–Hauser syndrome is a related but distinct syndrome. Some women who have an initial diagnosis of MRKH have later been found to have WNT4 deficiency. Most women with MRKH syndrome do not have genetic mutations of the WNT4 gene. The failure to begin the menstrual cycle may be the initial clinical sign of WNT4 deficiency. WNT4 deficiency can cause significant psychological challenges and counseling is recommended.\n"}
{"id": "2056548", "url": "https://en.wikipedia.org/wiki?curid=2056548", "title": "Wildlife contraceptive", "text": "Wildlife contraceptive\n\nWildlife contraceptives of various kinds are under development. Contraceptives such as these are intended to control population growth among both tame and wild animals.\n\nWhite-tailed deer may be controlled with contraceptives in suburban areas, where they are sometimes a nuisance. In parts of the United States, does are shot with darts containing a contraceptive vaccine, rendering them temporarily infertile. The Humane Society of the United States runs a deer birth control program, but it is experimental; it may not be cost-effective in the long run. It may cost $300 to $1000 per deer.\n\nThe vaccine used is porcine zona pellucida (PZP), or derivatives. This form of immunocontraception prevents sperm from accessing an ovum. Another form of deer contraception, called GonaCon, produces antibodies to sex drive hormones in the deer, causing them to lose interest in mating.\n\nSimilar forms of injectable contraceptive are being studied for use in elk and gray squirrels.\n\nOral contraceptives may also be developed for population control among a variety of animals, including deer, feral pigs, coyotes, cougars, dogs and cats. One product that has success in mice, rats, and dogs originally went by the name Mouseopause, but was approved for commercial use under the name ContraPest.\n\nPigeons have been a target for experimental contraceptives for decades. An oral contraceptive is in use for the control of Canada geese.\n\nA slow-release hormonal contraceptive implant for female Tasmanian devils is under development. While it may seem counter-intuitive to develop contraceptives for an endangered animal, their use is intended to promote the wild behaviour of mating freely, but without certain females over-contributing to the next generation, which \"can have long-term genetic consequences for the insurance population\". Contraceptive trials in male devils showed that their testosterone increased, instead of decreasing as other male mammals' testosterone does.\n\n"}
{"id": "3855684", "url": "https://en.wikipedia.org/wiki?curid=3855684", "title": "Winifred Mary Ward", "text": "Winifred Mary Ward\n\nWinifred Mary Ward (12 October 1884 – 26 January 1979) was a pioneering British speech therapist.\n\nWinifred was born on 12 October 1884 in Victoria Street, Old Charlton, London to parents Harry Marshall Ward and Selina Mary Ward (née Kingdon).\n\nHer first career was as a singing teacher, but after World War I she was so affected by the plight of shell shock victims that she turned most of her attention to trying to help them. She began working at the West London Hospital in Maida Vale and at Pembury in Kent, helping traumatised men to speak. \n\nShe left the West End Hospital school in 1935 to spend time in South Africa. When she returned to London in the late 1930s she was unable to resume her old post and took steps to set up a different course in conjunction with a former student, Amy Swallow. Ward was instrumental in setting up the London hospitals school of speech therapy (later called the Kingdon-Ward school of speech therapy), which was founded in 1942 in Cavendish Square.\n\nShe was a founder fellow of the College of Speech Therapists now the Royal College of Speech and Language Therapists. She wrote several books on the subject of speech therapy, as well as poems for children and poems specifically for use in teaching aspects of speech. Her 1941 work on stammering was the first major text on the subject in the British literature and was one of the earliest works on any topic in the field. She was one of the first authorities to recognise that there are different types and causes of stammering and she maintained that therapists should adapt their approach accordingly.\n\nWinifred was the sister of Francis Kingdon Ward and was also known as Winifred Kingdon-Ward by association. She died in the St Charles Hospital, Kensington, London, on 26 January 1979.\n\n\n"}
{"id": "41201975", "url": "https://en.wikipedia.org/wiki?curid=41201975", "title": "Wirral Community NHS Trust", "text": "Wirral Community NHS Trust\n\nWirral Community NHS Trust runs community services in the Wirral. It was established in April 2011. It operates three Wirral walk-in centres in Eastham, Wallasey and at Arrowe Park, the GP out-of-hours service and a minor injuries unit in Wallasey. Two of the walk-in centres were inspected in September 2013 by the Care Quality Commission and both passed all aspects of checks that essential standards of quality and safety were being met.\n\nServices in the area were previously provided by Wirral and West Cheshire Community NHS Trust, and before that by the earlier Wirral Community NHS Trust, which was dissolved in 1997.\n\nIt was named by the Health Service Journal as one of the top hundred NHS trusts to work for in 2015. At that time it had 1076 full-time equivalent staff and a sickness absence rate of 4.9%. 78% of staff recommend it as a place for treatment and 60% recommended it as a place to work.\n\n"}
