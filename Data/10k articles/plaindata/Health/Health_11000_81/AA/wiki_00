{"id": "50365087", "url": "https://en.wikipedia.org/wiki?curid=50365087", "title": "Andrew Freeland Fergus", "text": "Andrew Freeland Fergus\n\nDr Andrew Freeland Fergus FRSE LLD (1858–1932) was a Scottish ophthalmic surgeon. He was President of the Royal College of Surgeons in Glasgow, President of the Chirurgical Society, President of the Royal Philosophical Society of Glasgow, and President of the Greenock Faculty of Medicine.\n\nHe was born in Glasgow the son of Dr Andrew Fergus (1822–1887) a surgeon living at 306 St Vincent Street and his wife Margaret Naismith. His younger brother was the poet/surgeon John Freeland Fergus (1865–1943). His nephew was Andrew Fergus Hewat FRSE. He studied at Glasgow University then did further studies in Europe at the University of Utrecht and Paris. He then received a role as surgeon at the Glasgow Eye Hospital in 1882.\n\nIn 1899 he was elected a Fellow of the Royal Society of Edinburgh. His proposers were William Thomson, Lord Kelvin, John Gray McKendrick, James Thomson Bottomley and Magnus Maclean.\nFrom 1909 to 1915 he was Professor of Ophthalmic Medicine and Surgery at the Anderson College in Glasgow.\n\nIn the First World War he served as a Major in the 4th Scottish General Hospital at Stobhill and was Mentioned in Dispatches.\n\nHe died on 24 October 1932.\n\n"}
{"id": "35735460", "url": "https://en.wikipedia.org/wiki?curid=35735460", "title": "Andrey Yevgenyevich Lichko", "text": "Andrey Yevgenyevich Lichko\n\nAndrey Yevgenyevich Lichko (; 1926–1994) was a Russian psychiatrist, an honored science worker of the Russian Federation, Doctor of Medicine, and vice principal of Saint-Petersburg Psychoneurological Institute n.a. V.M. Bekhterev. His main directions of scientific research were diagnostics and treatment of mental disorders of adolescents.\n\nLichko created his own personality typology on the basis of works by Pyotr Gannushkin and Karl Leonhard. He has written several psychiatry books: \"Adolescent Psychiatry\", \"Psychopathy and Accentuations of Character at Teenagers\", \"Schizophrenia in Teenagers\", and \"Adolescent Narcology\". He is also known as the author of a book called \"History as Viewed by a Psychiatrist: Ivan the Terrible, Joseph Stalin, Adolf Hitler, Nikolai Gogol, and Others\".\n\nIn the late eighties Lichko spearheaded an effort to revive the \"Bekhterev Review of Psychiatry and Medical Psychology\". After the journal had been reestablished, he became its deputy editor.\n\nHis monograph entitled \"Psychopathy and Accentuations of Character of Teenagers\" (1977) has become an indispensable textbook for many generations of Russian psychiatrists and psychologists. For writing this book, Andrey Lichko was awarded the Honorary Certificate n.a. V.M. Bekhterev by USSR Academy of Medical Sciences. In this monograph, Andrey Lichko has enriched the theory of psychopathy (what is known today as personality disorders) by demonstrating that along with psychopathy it is necessary to distinguish the so-called accentuations of character. Lichko's typology has parallels with those of \nKarl Leonhard and Pyotr Gannushkin.\n\nPersons with accentuations of character are placed somewhere between mentally sane persons and psychopaths (those who suffer from different personality disorders). Referring to the famous monograph by the German psychiatrist Karl Leonhard, \"Accentuated Persons\", Andrey Lichko emphasized that it is more correct to use the term \"accentuations of character\" instead of the term \"accentuated personality\" because personality appears to be a wider notion, which includes IQ, skills, worldview, and so on.\n\nWith his theory of accentuations of character, Andrey Lichko has contributed to the understanding of etiology of neuroses by proposing the concept of the so-called \"locus of the least resistance\" (locus resistantiae minoris) within the character structure.\n\nThis conception emerged as the result of elaboration of the idea of the \"individual sensibility\" to psychic traumas proposed by the eminent Russian developmental psychologist, Vladimir Nikolayevich Myasishchev. By improving and elaborating the conception of \"situativity\" and \"individual hypersensibility\" to outside influence, Andrey Lichko has developed the theory stating that each type of accentuation of character has its own different \"Achilles' Heel\". On the assumption of these observations, Andrey Lichko supposed that neurosis is mostly linked with the juxtaposition of a pathogenic situation and the individual peculiarities of character.\n"}
{"id": "5897564", "url": "https://en.wikipedia.org/wiki?curid=5897564", "title": "Brazilian Medical Association", "text": "Brazilian Medical Association\n\nThe Brazilian Medical Association () founded in 1951, is the national class association of physicians in Brazil. With more than 140,000 associates, is the second largest in the Americas, just after the American Medical Association.\nIts official journal, \"Revista da Associação Médica Brasileira\" (), is published by Elsevier.\n\n"}
{"id": "51725894", "url": "https://en.wikipedia.org/wiki?curid=51725894", "title": "Burundian Permanent Representative to the United Nations in New York", "text": "Burundian Permanent Representative to the United Nations in New York\n\nThe Burundian Permanent Representative to the United Nations in New York is the official representative of the Government of Burundi to the Headquarters of the United Nations.\n\n"}
{"id": "55989059", "url": "https://en.wikipedia.org/wiki?curid=55989059", "title": "Cannabis in Tonga", "text": "Cannabis in Tonga\n\nCannabis in Tonga is illegal, but cultivated illicitly. A 1990s report attributed increased cannabis usage in Tonga to foreign travelers and returned Tongan emigres.\n"}
{"id": "28132967", "url": "https://en.wikipedia.org/wiki?curid=28132967", "title": "Clinical trials registry", "text": "Clinical trials registry\n\nA clinical trials registry is an official platform and catalog for registering a clinical trial. Some countries require clinical trials being conducted in that country to be registered; others do not require it, but often strongly encourage it. ClinicalTrials.gov, run by the United States National Library of Medicine (NLM) was the first online registry for clinical trials and is the largest and most widely used today.\n\nClinical trials are conducted to allow safety and efficacy data to be collected for health interventions (e.g., drugs, diagnostics, devices, therapy protocols). The goal of a clinical trials registry is to provide increased transparency and access to clinical trials, made available to the public. Clinical trials registries are often searchable (for example, trials can be searchable by disease/indication, drug, location, etc.). Trials are registered by the pharmaceutical, biotech or medical device company (Sponsor) or by the hospital or foundation which is sponsoring the study, or by another organization, such as a contract research organization (CRO) which is running the study.\n\nThere has been a push from governments and international organizations, especially since 2005, to make clinical trial information more widely available and to standardize registries and processes of registering. The World Health Organization is working toward \"achieving consensus on both the minimal and the optimal operating standards for trial registration\".\n\nFor many years, scientists and others have worried about reporting biases such that negative or null results from initiated clinical trials may be less likely to be published than positive results, thus skewing the literature and our understanding of how well interventions work. This worry has been international and written about for over 50 years. One of the proposals to address this potential bias was a comprehensive register of initiated clinical trials that would inform the public which trials had been started. Ethical issues were those that seemed to interest the public most, as trialists (including those with potential commercial gain) benefited from those who enrolled in trials, but were not required to “give back,” telling the public what they had learned.\n\nThose who were particularly concerned by the double standard were systematic reviewers, those who summarize what is known from clinical trials. If the literature is skewed, then the results of a systematic review are also likely to be skewed, possibly favoring the test intervention when in fact the accumulated data do not show this, if all data were made public.\n\nClinicalTrials.gov was originally developed largely as a result of breast cancer consumer lobbying, which led to authorizing language in the FDA Modernization Act of 1997 (Food and Drug Administration Modernization Act of 1997. Pub L No. 105-115, §113 Stat 2296), but the law provided neither funding nor a mechanism of enforcement. In addition, the law required that ClinicalTrials.gov only include trials of serious and life-threatening diseases.\n\nThen, two events occurred in 2004 that increased public awareness of the problems of reporting bias. First, the then-New York State Attorney General Eliot Spitzer sued GlaxoSmithKline (GSK) because they had failed to reveal results from trials showing that certain antidepressants might be harmful.\n\nShortly thereafter, the International Committee of Medical Journal Editors (ICMJE) announced that their journals would not publish reports of trials unless they had been registered. The ICMJE action was probably the most important motivator for trial registration, as investigators wanted to reserve the possibility that they could publish their results in prestigious journals, should they want to.\n\nIn 2007, the Food and Drug Administration Amendments Act of 2007 (FDAAA) clarified the requirements for registration and also set penalties for non-compliance (Public Law 110-85. The Food and Drug Administration Amendments Act of 2007 .\n\nThe International Committee of Medical Journal Editors (ICMJE) decided that from July 1, 2005 no trials will be considered for publication unless they are included on a clinical trials registry. The World Health Organization has begun the push for clinical trial registration with the initiation of the International Clinical Trials Registry Platform. There has also been action from the pharmaceutical industry, which released plans to make clinical trial data more transparent and publicly available. Released in October 2008, the revised Declaration of Helsinki, states that \"Every clinical trial must be registered in a publicly accessible database before recruitment of the first subject.\"\n\nThe World Health Organization maintains an international registry portal at http://apps.who.int/trialsearch/. WHO states that the international registry's mission is \"to ensure that a complete view of research is accessible to all those involved in health care decision making. This will improve research transparency and will ultimately strengthen the validity and value of the scientific evidence base.\"\n\nSince 2007, the International Committee of Medical Journal Editors ICMJE accepts all primary registries in the WHO network in addition to clinicaltrials.gov. The complete list is as follows:\n\n\nWorldwide, there is growing number of registries. A 2013 study identified the following top five registries (numbers updated as of August 2013):\n\nThe Pan-African clinical trials registry (PACTR) is available at pactr.org. It is funded by the European and Developing Countries Clinical Trials Partnership (EDCTP) and operates out of the South African Cochrane Centre (Cochrane Collaboration) based at the South African Medical Research Council. PACTR's remit ensures that it can register all clinical trials that are conducted on the continent in all disease areas. PACTR is a primary member of the WHO's International Clinical Trials Registry Platform (ICTRP), and thus contributes data to the central search portal hosted by ICTRP.\n\nThe countries of Australia and New Zealand share a registry. The ANZCTR is located at: anzctr.org.au.\n\nRegistering trials with the ANZCTR is voluntary. It is publicly owned and managed by a non-profit organization and is funded by an enabling grant from Australia's National Health and Medical Research Council (NHMRC). The registry is in English.\n\nBrazil has a registry (the Registro Brasileiro de Ensaios Clínicos, abbreviated ReBEC) at: ensaiosclinicos.gov.br. ReBEC is a project of the Brazilian Ministry of Health, The Panamerican Health Organization (PAHO) and The Oswaldo Cruz Foundation (FIOCRUZ).\n\nThe Canadian Institutes of Health Research (CIHR) participates with the ISRCTN.\n\nChina's clinical trial registry is called ChiCTR and its website is (http://www.chictr.org.cn). It is available both in Chinese (Mandarin) and English.\n\nChiCTR was established in October 2005, one week after India's registry was established and it participates in the World Health Organization’s International Clinical Trials Registry Platform.\n\nCuba's clinical registry is the RPCEC (Cuban Public Registry of Clinical Trials).\n\nEudraCT is a non-public database of all drug trials in the European Community (EC) from May 1, 2004 onwards. Its website is eudract.ema.europa.eu. In March 2011, EUCTR was launched, which is the public version of EudraCT including phase II to IV trials plus all pediatric trials.\n\nGermany's clinical trials registry, the DRKS, is available at www.drks.de. The DRKS is an open access, free of charge online register for clinical trials and is available both in English and German. DRKS is part of the ICTRP network at WHO. The DRKS works with two partner registries in Germany, DeReG - German Registry for Somatic Gene-Transfer Trials and Clinical Trial Registry of the University Medical Center Freiburg.\n\nIndia's clinical trials registry, CTRI, was established in October 2005 and registration became mandatory from 15 June 2009. Its website is .\n\nCTRI is in English and it participates in the World Health Organization’s International Clinical Trials Registry Platform.\n\nIran's registry, the IRCT, is available at irct.ir. It is run and funded by the Iranian Ministry of Health and Medical Education.\n\nItaly's The Portal of the Clinical Research with Medicines of the Italian Medicines Agency (AIFA) is a public source of information about the clinical trials with medicines conducted in Italy, the regulations and the ethical principles ruling the research, as well as the initiatives that AIFA promotes in the field of research. Unfortunately the portal has not been working since January 2013, for technical reasons; although it was expected to restart soon, an operational date has not yet been posted so far (July 2013).\n\nJapan has three registries that work as a network known as the Japan Primary Registries Network (JPRN). Its search portal is hosted by the Japanese National Institute of Public Health. While the search portal is only available in Japanese, the three registries' sites are also available in English:\n\nThe Netherlands registry participates with WHO and its website is trialregister.nl. While the \"About\" sections of the website are only available in the Dutch language, clinical trial data are available in English.\n\nSouth Africa’s Department of Health announced in November 2005, that clinical trials conducted in the country must be submitted to the South African National Clinical Trials Register. Its site is located at: sanctr.gov. Clinical trial guidelines for South Africa are available at the Department of Health's official site.\n\nSouth Korea's registry is Clinical Research Information Service (CRiS) and available at https://web.archive.org/web/20101121001837/http://ncrc.cdc.go.kr/cris/index.jsp. It is managed by the Korea Centers for Disease Control and Prevention and funded by South Korea's Ministry of Health and Welfare.\n\nThe Sri Lanka Clinical Trials Registry (SLCTR) is available at slctr.lk. It is funded by the Sri Lanka Medical Association and managed by the Sri Lanka Clinical Trials Registry Committee.\n\nThe ISRCTN registry was launched in 2000. Originally ISRCTN stood for 'International Standard Randomised Controlled Trial Number'; however, the scope of the registry has now widened beyond randomized controlled trials to include any study designed to assess the efficacy of health interventions in a human population. It registers both observational and interventional trials and content is curated by a team of expert editors.\n\nClinical trials in the US are registered on clinicaltrials.gov.\n\nClinicaltrials.gov is the largest clinical trials registry. Clinical trials conducted in the United States are required to be registered in the registry. As of January 2, 2015, CliicalTrials.gov lists 181,612 studies with locations in 50 US states and in 187 countries. Its registrations represent about 75% of what is available through the WHO Portal (ICTRP). Despite the fact that important progress has been made, the efforts of those overseeing ClinicalTrials.gov and the other, smaller, registries do not ensure that the public has an unbiased knowledge base accessible to all. For example, problems of the concordance between the ClinicalTrials.gov record and the published record have been identified for many protocol and results items.\n\nThe registry traces back to the Health Omnibus Programs Extension Act of 1988 (HOPE or Public Law 100-607) which mandated the development of a database of AIDS Clinical Trials Information System. It would later be expanded under the Food and Drug Modernization Act of 1997 (FDAMA or Public Act 105-115). The registry is run by the United States National Library of Medicine (NLM).\n\nClinical trial registries are also set up and managed by governmental organizations, non-governmental organizations, universities, as well as commercial and nonprofit entities. This includes pharmaceutical companies, international organizations, and health organizations. A list is available at http://www.circare.org/registries.htm.\n\nThe IFPMA Clinical Trials Portal is a major pharmaceutical industry initiative designed to increase the transparency of clinical trials by providing a convenient \"one-stop-shop\" for published clinical trial information. It helps to fulfill the commitment made by the research-based pharmaceutical industry in its Joint Position on the Disclosure of Clinical Trial Information via Clinical Trial Registries and Databases. It is available here.\n"}
{"id": "1435066", "url": "https://en.wikipedia.org/wiki?curid=1435066", "title": "Convention on the Elimination of All Forms of Discrimination Against Women", "text": "Convention on the Elimination of All Forms of Discrimination Against Women\n\nThe Convention on the Elimination of all Forms of Discrimination Against Women (CEDAW) is an international treaty adopted in 1979 by the United Nations General Assembly.\nDescribed as an international bill of rights for women, it was instituted on 3 September 1981 and has been ratified by 189 states. Over fifty countries that have ratified the Convention have done so subject to certain declarations, reservations, and objections, including 38 countries who rejected the enforcement article 29, which addresses means of settlement for disputes concerning the interpretation or application of the Convention. Australia's declaration noted the limitations on central government power resulting from its federal constitutional system. The United States and Palau have signed, but not ratified the treaty. The Holy See, Iran, Somalia, Sudan, and Tonga are not signatories to CEDAW.\n\nThe CEDAW Chairperson position is currently held by Dalia Leinarte.\n\nThe Convention has a similar format to the Convention on the Elimination of All Forms of Racial Discrimination, \"both with regard to the scope of its substantive obligations and its international monitoring mechanisms\". The Convention is structured in six parts with 30 articles total.\n\nArticle 1 defines discrimination against women in the following terms:Any distinction, exclusion or restriction made on the basis of sex which has the effect or purpose of impairing or nullifying the recognition, enjoyment or exercise by women, irrespective of their marital status, on a basis of equality of men and women, of human rights and fundamental freedoms in the political, economic, social, cultural, civil or any other field.Article 2 mandates that states parties ratifying the Convention declare intent to enshrine gender equality into their domestic legislation, repeal all discriminatory provisions in their laws, and enact new provisions to guard against discrimination against women. States ratifying the Convention must also establish tribunals and public institutions to guarantee women effective protection against discrimination, and take steps to eliminate all forms of discrimination practiced against women by individuals, organizations, and enterprises.\n\nArticle 3 requires states parties to guarantee basic human rights and fundamental freedoms to women \"on a basis of equality with men\" through the \"political, social, economic, and cultural fields.\"\n\nArticle 4 notes that \"[a]doption...of special measures aimed at accelerating de facto equality between men and women shall not be considered discrimination.\" It adds that special protection for maternity is not regarded as gender discrimination.\n\nArticle 5 requires states parties to take measures to seek to eliminate prejudices and customs based on the idea of the inferiority or the superiority of one sex or on stereotyped role for men and women. It also mandates the states parties \"[t]o ensure...the recognition of the common responsibility of men and women in the upbringing and development of their children.\"\n\nArticle 6 obliges states parties to \"take all appropriate measures, including legislation, to suppress all forms of trafficking in women and exploitation of prostitution of women.\"\n\nArticle 7 guarantees women equality in political and public life with a focus on equality in voting, participation in government, and participation in \"non-governmental organizations and associations concerned with the public and political life of the country.\"\n\nArticle 8 provides that states parties will guarantee women's equal \"opportunity to represent their Government at the international level and to participate in the work of international organizations.\"\n\nArticle 9 mandates state parties to \"grant women equal rights with men to acquire, change or retain their nationality\" and equal rights \"with respect to the nationality of their children.\"\n\nArticle 10 necessitates equal opportunity in education for female students and encourages coeducation. It also provides equal access to athletics, scholarships and grants as well as requires \"reduction in female students' drop out rates.\"\n\nArticle 11 outlines the right to work for women as \"an unalienable right of all human beings.\" It requires equal pay for equal work, the right to social security, paid leave and maternity leave \"with pay or with comparable social benefits without loss of former employment, seniority or social allowances.\" Dismissal on the grounds of maternity, pregnancy or status of marriage shall be prohibited with sanction.\n\nArticle 12 creates the obligation of states parties to \"take all appropriate measures to eliminate discrimination against women in the field of healthcare in order to ensure...access to health care services, including those related to family planning.\"\n\nArticle 13 guarantees equality to women \"in economic and social life,\" especially with respect to \"the right to family benefits, the right to bank loans, mortgages and other forms of financial credit, and the right to participate in recreational activities, sports and all aspects of cultural life.\"\n\nArticle 14 provides protections for rural women and their special problems, ensuring the right of women to participate in development programs, \"to have access to adequate health care facilities,\" \"to participate in all community activities,\" \"to have access to agricultural credit\" and \"to enjoy adequate living conditions.\"\n\nArticle 15 obliges states parties to guarantee \"women equality with men before the law,\" including \"a legal capacity identical to that of men.\" It also accords \"to men and women the same rights with regard to the law relating to the movement of persons and the freedom to choose their residence and domicile.\"\n\nArticle 16 prohibits \"discrimination against women in all matters relating to marriage and family relations.\" In particular, it provides men and women with \"the same right to enter into marriage, the same right freely to choose a spouse,\" \"the same rights and responsibilities during marriage and at its dissolution,\" \"the same rights and responsibilities as parents,\" \"the same rights to decide freely and responsibly on the number and spacing of their children,\" \"the same personal rights as husband and wife, including the right to choose a family name, a profession and an occupation\" \"the same rights for both spouses in respect of the ownership, acquisition, management, administration, enjoyment and disposition of property, whether free of charge or for a valuable consideration.\"\n\nArticles 17 - 24 These articles describe the composition and procedures of the CEDAW Committee,like the hierarchical structure and rules and regulations of systematic procedure of the relationship between CEDAW and national and international legislation and the obligation of States to take all steps necessary to implement CEDAW in full form.\n\nArticles 25 - 30 (Administration of CEDAW)\n\nThese articles describe the general administrative procedures concerning enforcement of CEDAW, ratification and entering reservations of concerned states.\n\nResolutions 1325 10th anniversary events highlight use of CEDAW mechanisms\n\nThe 10th anniversary of Resolution 1325 in October 2010 highlighted the increasing demand for accountability to UN Security Council Resolution 1325 on Women, Peace and Security. Many expressed concern about the fact that only 22 Member States out of 192 have adopted national action plans. Women are still underrepresented, if not totally absent, in most official peace negotiations and sexual violence in peacetime and in conflict continue to increase.\n\nThese realities emphasized the need to use external legal mechanisms to strengthen the implementation of SCR 1325, particularly CEDAW. The well-established mechanisms of CEDAW – the Member States compliance report and the civil society shadow reporting process were cited as possible instruments to ensure accountability.\n\nSeveral regional and international meetings including the High Level Seminar \"1325 in 2020: Looking Forward…Looking Back,\" organized by the African Center for the Constructive Resolution of Disputes, and the \"Stockholm International Conference 10 years with 1325 – What now?\" called for the use of CEDAW to improve 1325 implementation.\n\nIntersection between SCR 1325 and CEDAW\nWhile CEDAW and UN Security Council Resolutions 1325 and 1820 on Women, Peace and Security are important international instruments on their own, there is also an intersection among the three standards that can be used to enhance their implementation and impact.\n\nResolutions 1325 and 1820 broaden the scope of CEDAW application by clarifying its relevance to all parties in conflict, whereas CEDAW provides concrete strategic guidance for actions to be taken on the broad commitments outlined in the two Resolutions.\n\nCEDAW is a global human rights treaty that should be incorporated into national law as the highest standard for women's rights. It requires the UN Member States that have ratified it (185 to date) to set in place mechanisms to fully realize women's rights.\n\nResolution 1325 is an international law unanimously adopted by the Security Council that mandates the UN Member States to engage women in all aspects of peacebuilding including ensuring women's participation on all levels of decision–making on peace and security issues.\n\nResolution 1820 links sexual violence as a tactic of war with the maintenance of international peace and security. It also demands a comprehensive report from the UN Secretary-General on implementation and strategies for improving information flow to the Security Council; and the adoption of concrete protection and prevention measures to end sexual violence.\n\nResolutions 1325 and 1820, and CEDAW share the following agenda on women's human rights and gender equality:\n\n\nA General Comment from the CEDAW committee could strengthen women’s advocacy for the full implementation of Resolutions 1325 and 1820 at the country and community levels. Conversely, CEDAW’s relevance to conflict-affected areas will be underscored further by the two Resolutions. In other words, all three international instruments will reinforce each other and be much more effective if used together in leveraging women’s human rights.\n\nThe six UN member states that have not ratified or acceded to the convention are Iran, Palau, Somalia, Sudan, Tonga, and the United States.\n\nThe one UN non-member state that had not acceded to the convention is the Holy See/Vatican City.\n\nThe Republic of China (Taiwan) in 2007 has also ratified the treaty in its legislature, but is unrecognized by the United Nations and is a party to the treaty only unofficially.\n\nThe latest state to have acceded the convention was South Sudan on 30 April 2015.\n\nWithin the United States, over 40 cities and local governments have adopted CEDAW ordinances or resolutions. \n\nMany reservations have been entered against certain articles of the Convention. There are also some reservations that are not specific to an article within the Convention but rather a general reservation to all aspects of the Convention that would violate a stated principle. For example, Mauritania made a reservation stating it approved the Convention \"in each and every one of its parts which are not contrary to Islamic Sharia.\" A number these reservations, especially those entered by Islamic states parties, are subject to much debate.\n\nArticle 28 of the Convention states that \"a reservation incompatible with the object and purpose of the present Convention shall not be permitted.\" As a result, many states parties have entered objections to the reservations of other states parties. Specifically, many Nordic states parties were concerned that some of the reservations were \"undermining the integrity of the text.\" Over the years, some states parties have withdrawn their reservations.\n\nAs of May 2015, sixty-two states parties have entered reservations against some part of the Convention. Twenty-four states parties have entered objections to at least one of these reservations. The most reserved article is Article 29, concerning dispute resolution and interpretation of the Convention, with thirty-nine reservations. Because reservations to Article 29 are expressly allowed by the Convention itself, these reservations were not very controversial. Article 16, concerning the equality of women in marriage and family life is subject to twenty-three reservations. The Committee, in General Recommendation No. 28, specifically stated that reservations to Article 2, concerning general non-discrimination, are impermissible. However, Article 2 has seventeen reservations.\n\nThe Committee on the Elimination of Discrimination Against Women is the United Nations (U.N.) treaty body that oversees the Convention on the Elimination of All Forms of Discrimination Against Women (CEDAW). The formation of this committee was outlined in Article 17 of the CEDAW, which also established the rules, purpose, and operating procedures of the committee. Throughout its years of operation the committee has held multiple sessions to ensure the rules outlined in the CEDAW are being followed. Over time the practices of the committee have evolved due to an increased focus on women's rights issues.\n\nThe Committee on the Elimination of Discrimination Against Women was formed on 3 September 1981 after the CEDAW received the 20 ratifications required for it to enter into force. Article 17 of the CEDAW established the committee in order to ensure that the provisions of the CEDAW were followed by the countries that had signed and agreed to be bound by it. The first regular session of the committee was held from 18–22 October 1982. In this session the first officers of the committee were elected by simple majority, with Ms. L. Ider of Mongolia becoming chairperson. Other officers elected were three vice-chairpersons: M. Caron of Canada, Z. Ilic of Yugoslavia and L. Mukayiranga of Rwanda. The final officer elected was D. P. Bernard of Guyana as rapporteur of the committee. During this session, the committee also unanimously approved to adopt its rules of procedure.\n\nThe rules regarding where and when the committee can hold sessions are laid out in their rules of procedure.\n\nThe committee is allowed to hold as many meetings as are required to perform their duties effectively, with the states party to the CEDAW and the Secretary-General of the United Nations authorizing the number of regular sessions held. In addition, special sessions can be held at the request of either a state party to the convention or the majority of the members serving on the committee. Fifty-three sessions have been held to date, with the most recent taking place from 1 October 2012 to 19 October 2012. The first thirty-nine sessions were held at the United Nations headquarters building in New York City, with the fortieth session and alternating sessions following it held in the Palais des Nations in Geneva. During each of its regular sessions the committee hears reports from states party to the CEDAW on their progress in adhering to CEDAW and implementing its ideas in their countries. The committee also holds pre-sessional work groups to discuss the issues and questions that the committee should deal with during the following session.\n\nUnder article 18 of the CEDAW states must report to the committee on the progress they have made in implementing the CEDAW within their state. As most of the information the committee works with comes from these reports, guidelines have been developed to help states prepare accurate and useful reports. Initial reports discussing the current picture of discrimination against women in the reporting states are required to specifically deal with each article of the CEDAW, and consist of no more than one-hundred pages. States are required to prepare and present these initial reports within one year of ratifying the CEDAW. Periodic reports detailing the state's progress in adhering to the articles of the CEDAW should be no more than seventy-five pages in length and should focus on the specific period of time since the state's last report. States party to the CEDAW are typically required to provide periodic reports every four years, but if the committee is concerned about the situation in that state they can request a report at any time.\n\nThe committee chooses which reports addressing by considering factors such as the amount of time the report has been pending, whether the report is initial or periodic (with more priority given to initial reports), and from which region the report originates. Eight states are invited to give their reports during each session and it is required a representative from the state is in attendance when the report is presented. The committee focuses on constructive dialogue when a report is presented and appreciates careful time management on the part of the state presenting its report. Due to the high backlog of overdue reports the committee has encouraged states to combine all of their outstanding reports into one document and sends reminders to states who have reports that are five years overdue. The CEDAW also requires that the committee provide an annual report that includes its activities, comments relating to the reports provided by states, information relating to the Optional Protocol of the CEDAW, and any other general suggestions or recommendations the committee has made. This report is given to the United Nations General Assembly through the Economic and Social Council. All reports, agendas and other official documents pertaining to the committee, including the reports provided by the states, are provided to the public unless otherwise decided by the committee.\n\nAlong with issuing its annual report and offering advice to reporting states, the committee has the ability to issue general recommendations that elaborate on its views of the obligations imposed by CEDAW. To date, the committee has issued thirty-two general recommendations, the latest dealing with the gender related dimensions of refugee status, asylum, nationality and statelessness of women. The recommendations issued by the committee in its first decade were short and dealt mainly with the content of states’ reports and reservations to the convention. Since 1991, however, recommendations have been focused on guiding states’ application of the CEDAW in specific situations. The formulation of a general recommendation begins with dialogue between the committee on the topic in the recommendation with various non-governmental organizations and other U.N. bodies. The recommendation is then drafted by a member of the committee and discussed and revised in the next session, and finally adopted in the following session.\n\nCurrently the Committee is working on the General Recommendation Trafficking in women and girls in the context of global migration.\n\nFor the first ten years the committee operated significantly differently from now. The only form of censure given to the committee by the CEDAW was their general recommendations and concluding comments following a report. Due to the emergence of the Global Campaign for Women's Human Rights in 1991 more attention was given to the CEDAW, reviving the committee. The committee made changes to the CEDAW that allowed it to meet more than once a year, and have taken advantage of this by meeting at least twice a year since 1997. The committee originally only met for two weeks in its annual sessions, but that has now been changed to meeting multiple times a year in eighteen-day sessions. CEDAW also gained new complaint and inquiry proceedings allowing the committee to initiate inquiry proceedings if it believes a state is in severe violation of the articles of the CEDAW.\n\nDespite evolving since the committee was first formed, members believe there are ways in which the committee can better meet the goals outlined in the CEDAW. One of the committee's main goals moving forward is expanding its information base, allowing it to more effectively deal with issues that arise concerning the CEDAW. The committee is authorized in Article 22 of the CEDAW to invite specialized U.N. agencies such as the United Nations Development Programme to deliver reports discussing women's rights issues in the state under discussion. Another method for gathering information is requesting reports from non-governmental organizations dealing with discrimination against women that are operating in the country under discussion. This is recommended to insure that the committee is receiving the full, unbiased picture of affairs within the reporting state.\n\nAnother recommendation for improvement involves interpreting and clarifying the language used in the CEDAW in order to make the document as useful as it can be. A third improvement that has been suggested is improving the efficiency of the committee. Due to the backlog in reports faced by the committee it has been suggested that the government officials who prepare reports presented to the committee should be trained, in order to make all reports uniform and more easily processed. A final suggestion for improvement is the implementation of a right of petition in the CEDAW, allowing the committee to hear complaints from citizens of a state against the state, increasing the committee's strength and direct impact on the problem of discrimination against women.\n\nThe official languages of the committee are English, Arabic, French, Russian, and Spanish, with any statement made in one of the official languages translated into the other four. A speaker who does not speak one of the official languages provides a translator. All formal decisions and documents issued by the committee are provided in each of the official languages. The original rules of procedure adopted by the committee did not include Arabic as an official language, but the rule was amended in the committees second session to include Arabic.\n\nTwenty-three members serve on the committee, described as experts for their experience and expertise in women's issues. The members are nominated by their national governments and elected through a secret ballot by states party to the convention. Upon winning the election and taking up their responsibilities the members of the committee recite the following statement, known as the solemn declaration, \"I solemnly declare that I shall perform my duties and exercise powers as a member of the Committee on the Elimination of Discrimination Against Women honourably, faithfully, impartially and conscientiously\". The members come from a wide range of occupations including doctors, lawyers, diplomats and educators, providing various viewpoints to the committee due to their diversity. Many members continue to hold full-time jobs outside the committee and receive little monetary payment for their work on the committee.\n\nTo insure that the nationality of members encompasses all the diverse states who have signed the CEDAW, members are elected according to regions divided into Latin America and the Caribbean, Africa, Asia, Western Europe, and Eastern Europe. The members of the committee differ from those of other treaty bodies of the United Nations in that they have all been women with only one exception. In the event a member of the committee is unable to continue serving on the committee before her term is up the state that had nominated the resigning member shall nominate another expert from their country to fill in her seat. Committee members and experts also attend an annual luncheon, hosted by the NGO Committee on the Status of Women, NY (NGO CSW/NY), where key issues are discusses and the efforts of the committee are honored.\n\nOfficers of the Committee\n\nThe officers of the committee are composed of a chairperson, three vice-chairpersons and a rapporteur. Officers of the committee are nominated by another member of the committee, as opposed to a government which nominates members for the committee. All officers are elected by majority vote to a two-year term of office, and remain eligible for re-election after their term expires. The chairperson's duties include declaring a meeting to be open or closed, directing the discussion in a session, announcing decisions made by the committee, preparing agendas in consultation with the secretary-general, designating the members of pre-sessional working groups and representing the committee at United Nations meetings which the committee is invited to participate in. In the case the chairperson is unable to perform any her duties she designates one of the three vice-chairpersons to take over her role. If the chairperson fails to designate a vice-chairperson prior to her absence then the vice-chairperson with the first name in English alphabetical order takes over. In the event an officer is unable to continue serving on the committee before her term expires a new officer from the same region as the original officer shall be nominated, elected and will take over the vacated office.\nAs of May 2015, the 23 members are:\n\nThe Optional Protocol to the Convention on the Elimination of All Forms of Discrimination against Women is a side-agreement to the Convention which allows its parties to recognise the competence of the Committee on the Elimination of Discrimination Against Women to consider complaints from individuals.\n\nThe Optional Protocol was adopted by the UN General Assembly on 6 October 1999 and entered into force on 22 December 2000. Currently it has 80 signatories and 109 parties.\n\nControversy around CEDAW comes from two opposite directions: social and religious conservatives which claim that CEDAW is seeking to impose a liberal, progressive, feminist standard on countries, in detriment of traditional values; and radical feminists, who are skeptical of the power, or even desire, of CEDAW to radically transform societies and truly liberate women, and claim that CEDAW adheres to a form of weak liberal feminism similar to other mainstream organizations.\n\n\n\n"}
{"id": "1024843", "url": "https://en.wikipedia.org/wiki?curid=1024843", "title": "David Hahn", "text": "David Hahn\n\nDavid Charles Hahn (October 30, 1976 – September 27, 2016), sometimes called the Radioactive Boy Scout or the Nuclear Boy Scout, was an American who in 1994, at age 17, attempted to build a homemade breeder reactor. A scout in the Boy Scouts of America, Hahn conducted his experiments in secret in a backyard shed at his mother's house in Commerce Township, Michigan. While his reactor never reached criticality, Hahn attracted the attention of local police when he was stopped on another matter and they found material in his vehicle that troubled them, and he warned that it was radioactive. His mother's property was cleaned up by the Environmental Protection Agency (EPA) ten months later as a Superfund cleanup site. Hahn attained Eagle Scout rank shortly after his lab was dismantled.\n\nWhile the incident was not widely publicized initially, it became better known following a 1998 \"Harper's\" article by journalist Ken Silverstein. Hahn was also the subject of Silverstein's 2004 book, \"The Radioactive Boy Scout\". It is likely Hahn received substantial doses of radiation. As an adult, Hahn served in the US Navy and the US Marine Corps. He was subsequently treated for mental illness, and his death at age thirty-nine was related to alcohol use.\n\nHahn was a Boy Scout fascinated by chemistry, and spent years conducting amateur chemistry experiments, which sometimes caused small explosions and other mishaps. He was inspired in part by reading \"The Golden Book of Chemistry Experiments\", and tried to collect samples of every element in the periodic table, including the radioactive ones. He later received a merit badge in Atomic Energy and became fascinated with the idea of creating a breeder reactor in his home. Hahn diligently amassed radioactive material by collecting small amounts from household products, such as americium from smoke detectors, thorium from camping lantern mantles, radium from clocks, and tritium (a neutron moderator) from gunsights. His \"reactor\" was a bored-out block of lead, and he used lithium from $1,000 worth of purchased batteries to purify the thorium ash using a Bunsen burner.\n\nHahn posed as an adult scientist or high school teacher to gain the trust of many professionals in letters—and succeeded, despite misspellings and obvious errors. Hahn ultimately hoped to create a breeder reactor, using low-level isotopes to transform samples of thorium and uranium into fissionable isotopes.\n\nHis homemade reactor never came anywhere near reaching critical mass—but it ended up emitting dangerous levels of radiation, likely well over 1,000 times normal background radiation. Alarmed, Hahn began to dismantle his experiments—but in a chance encounter, police discovered his activities, which triggered a Federal Radiological Emergency Response involving the FBI and the Nuclear Regulatory Commission. On June 26, 1995 the EPA, having designated Hahn's mother's property a Superfund hazardous materials cleanup site, dismantled the shed and its contents and buried them as low-level radioactive waste in Utah. Unknown to officials, his mother, fearful that she would lose her house if the full extent of the radiation were known, had already collected the majority of the radioactive material and thrown it away in the conventional garbage. Hahn refused medical evaluation for radiation exposure. EPA scientists believe that Hahn's life expectancy may have been greatly shortened by his exposure to radioactivity, particularly since he spent long periods of time in the small, enclosed shed with large amounts of radioactive material and only minimal safety precautions, but he refused their 1995 recommendation that he be examined at the Enrico Fermi Nuclear Generating Station.\n\nHahn became depressed after the scandal, a problem exacerbated by the breakup with his girlfriend and the suicide of his mother in early 1996. While he did graduate from high school, he lacked any direction or plans thereafter. His father and stepmother first encouraged him to attend Macomb Community College. He enrolled in a metallurgy program there but frequently skipped classes. He was then encouraged to join the military, so he enlisted in the Navy, assigned to the nuclear-powered aircraft carrier as an undesignated seaman. After a four-year tour, he achieved interior communications specialist with a rank of petty officer, third class.\n\nHahn had hoped to pursue a nuclear specialist career.\n\nAfter his time on USS \"Enterprise,\" Hahn enlisted in the Marines and was stationed in Japan. After a few years, he was honorably discharged on medical grounds and returned to Michigan.\n\nOn April 23, 2007, The FBI received a lead regarding Hahn's alleged possession of a second breeder reactor in his freezer. After contacting Hahn via telephone, Hahn insisted he was not in possession of radioactive material. The FBI decided there was no imminent terrorist threat but agreed to attempt a personal interview. On May 16, 2007, Hahn was interviewed at an FBI office, where discussed were flyers that Hahn had distributed promoting his book and upcoming film, theft of tires and rims from a vehicle prior to his Navy service, diagnosis of Paranoid Schizophrenia, and a few less significant topics. FBI agents then interviewed an individual (Identity not released) who stated that Hahn was using cocaine heavily, was not taking his prescribed medication, and that Hahn was paranoid of people that he claimed \"had the ability to 'shock' his genitals with their minds\", and possible visits of prostitutes. The individual also stated that he believes that Hahn was still trying to build a reactor, and was collecting radium. He stated that he did not believe Hahn had any intentions of hurting anyone, but was concerned for his mental state.\n\nThis investigation is likely what led to Hahn's arrest regarding larceny of smoke alarms.\n\nOn August 1, 2007, Hahn was charged with larceny in Clinton Township, Michigan for allegedly removing a number of smoke detectors from the halls of his apartment building. His intention was to obtain americium from them. In his mug shot, his face is covered with sores which investigators believe could possibly be from exposure to radioactive materials. During a Circuit Court hearing, Hahn pleaded guilty to attempted larceny of a building. The court’s online docket said prosecutors recommended that he be sentenced to time served and enter an inpatient treatment facility. Under terms of the plea, the original charge of larceny of a building would be dismissed at sentencing, scheduled for October 4. He was sentenced to 90 days in jail for attempted larceny. Court records stated that his sentence would be delayed by six months while Hahn underwent medical treatment in the psychiatric unit of Macomb County Jail.\n\nHahn died on Tuesday, September 27, 2016, at the age of 39 accidentally due to intoxication from the combined effects of alcohol, diphenhydramine, and fentanyl. At the time, he was a resident of Shelby Charter Township, Michigan.\n\nThe incident received scant media attention at the time, but was widely disseminated after writer Ken Silverstein published an article about the incident in \"Harper's Magazine\" in 1998. In 2004 he expanded it into a book, \"The Radioactive Boy Scout\", which was optioned for a feature film in 2016.\n\nIn 1999, University of Chicago physics majors Justin Kasper and Fred Niell, as part of a scavenger hunt that had as one of its items, \"a breeder reactor built in a shed,\" successfully built a similar nuclear reactor that produced trace amounts of plutonium.\n\nIn the \"\" episode , the character Lawrence Wagner is based on David Hahn.\n\nA television documentary, \"The Nuclear Boyscout\", aired on Channel 4 in the United Kingdom in 2003. In it, Hahn reenacted some of his methods for the camera.\n\nHahn's experiments inspired others to attempt similar feats, particularly Taylor Wilson, who at age 14 became the youngest person to produce nuclear fusion.\n\n"}
{"id": "48062230", "url": "https://en.wikipedia.org/wiki?curid=48062230", "title": "Degrees in Nursing", "text": "Degrees in Nursing\n\nIn the United States, Nursing is the largest healthcare profession, with more than 3.1 million registered nurses. Between 2012 and 2022, employment for nurses is projected to grow by 19 percent, which is more than any other profession. Nurses make up the largest component of staff in hospitals but are also able to provide care in clinic settings, patient’s homes, schools, nursing homes, public health agencies, and mental health centers. In addition, nurses can be found in the military, in industry, nursing education, and do health care research. Nurses in these various roles and settings can provide direct patient care and case management, but also develop and establish nursing practice and quality standards within complex healthcare systems. As each degree can provide a different level of care for patients and function in vastly different roles, it is important to differentiate between them. The levels of nursing degrees have different educational requirements, licensure, and credentialing that can vary state to state.\n\nThe education required for a Licensed Practical Nurse/Licensed Vocational Nurse is the completion of a 12-18 month program, typically at a technical college. The program focuses on task activities and prepares the nurse for the National Council Licensure Examination for Licensed Practical Nurses (NCLEX). Requirements for taking the NCLEX-PN include having a high school diploma or equivalent and successful completion of an accredited practical/vocational nursing program. LPN/LVNs work in a variety of settings including hospitals, clinics, nursing homes, rehabilitation centers, schools, and individual or group homes. Scope of practice for LPN/LVNs is defined by individual states, but each organization may narrow the scope of the LPN/LVN.\n\nHospital-based diplomas were historically the primary form of nursing education, first appearing in the early 20th century. The number of facilities offering this degree as well as the number of nurses obtaining their education through them have declined since the 1970s due to the growth of Associate Degree in Nursing and Bachelor of Science in Nursing programs at colleges and universities, as well as increasing financial constraints on hospitals and the healthcare systems. Diploma programs were the most abundant in the 1950s and 1960s, with nearly 1,300 diploma programs active nationwide. Presently, less than 10 percent of nursing degree programs are diploma programs, which produce less than 6 percent of registered nurses. The majority of the remaining diploma programs in the United States are concentrated in the Midwest and on the East Coast. Programs for hospital diplomas are traditionally sponsored and run by hospitals in the community, as their name implies. Courses are taught proximal to and in conjunction with the hospital, where students have practical application of their skills on the units and wards in the sponsoring facility. Diploma programs typically have a strong focus on practical application of skills, with a larger percentage of time spent on the “hands-on” component of learning. Students attend classes for two to three years, at the completion of which they take the National Council Licensure Examination for Registered Nurses (NCLEX-RN) certifying exam, a standard exam for all practicing registered nurses. Students graduate with a diploma in nursing, and passing of the NCLEX-RN allows for certification and state licensure, which permits the graduate to practice as a full registered nurse within his or her state’s statutes. Coursework taken in a diploma nursing program can frequently be used for credits toward nursing degrees such as a BSN or ADN.\n\nAn Associate Degree in Nursing (ADN) is the minimum educational requirement to become a registered nurse in the United States. All ADN prepared nurses are credentialed through individual state nursing boards after passing the NCLEX-RN. In order to be eligible to take the NCLEX-RN exam, candidates must have a high school diploma or its equivalent and a degree from a board of nursing approved nursing program. ADN nursing programs typically take two years to complete but courses required differ by state. The standard course requirement includes anatomy, physiology, microbiology, chemistry, nutrition, psychology. Background checks are also performed on all candidates prior to granting licensure. Associate degree nurses are able to work in both outpatient and inpatient settings. Of the almost 3.1 million registered nurses in the United States, 36.1 percent of them have an associate degrees in nursing.\n\nBachelor of Science in Nursing (BSN) degrees prepare nurses for a wide variety of professional roles and graduate study within nursing. It is typically acquired through a four-year program at a college or university. Baccalaureate programs include a variety of liberal arts courses and professional education and training in the nursing field. It contains additional education beyond that of an ADN that often includes physical and social sciences, communication, leadership, and critical thinking. There are 674 BSN programs in the United States. BSN programs are approved by each state’s individual board of nursing that allows students to sit for the NCLEX-RN examination to obtain a license as a registered nurse Some states have accelerated programs called “RN-to-BSN” or “BSN completion” for registered nurses with associate degrees wanting to obtain their bachelor's degree in nursing. In 2010, the Institute of Medicine called for 80 percent of nurses in the U.S. to be baccalaureate trained by the year 2020, and this has created a push for healthcare organizations to make a BSN a hiring requirement for registered nurses and instituting education assistance programs for those with associate degrees.\n\nThe Master of Science in Nursing (MSN) is an advanced degree that allows for a more specialized role in nursing. The master’s prepared nurse has a wide array of careers that he or she might aspire to fill. Career paths include certified nurse practitioner (CNP), certified nurse anesthetist (CRNA), clinical nurse specialist (CNS) or certified nurse midwife (CNM). Some other areas the MSN prepared nurse might focus are in public health, business administration or health administration. Education curriculum may vary between 18 and 24 months of full-time graduate level studies, with program length determined by the specified field. The certification exams for a master’s prepared nurse are dependent upon the role being pursued. For example, the CNM takes the American Midwifery Certification Board exam and nurse administrators may receive their certification from the American Nurses Credentialing Center (ANCC). Master’s prepared nurses are trained in advanced assessment, counseling of patients, management, leadership, research and education. They may work in both inpatient and outpatient settings as well as educational institutions, and scope of practice may vary state-by-state.\n\nThe scope of practice for a Doctor of Nursing Practice (DNP) includes assessing, diagnosing, prescribing, consulting, screening, educating, initiating referrals and the coordination of patient care. There are numerous specialties DNPs may pursue including Acute Care Nurse Practitioner, Adult Nurse Practitioner, Adult-gerontology nurse practitioner (acute or primary care), Adult Psychiatric- Mental Health Nurse Practitioner, Family Nurse Practitioner, Gerontological Nurse Practitioner, Pediatric Nurse Practitioner (acute or primary care), and School Nurse Practitioner. Specific practice guidelines can vary by state and area of practice. In order to become a DNP, one would need to obtain his or her doctorate in nursing practice. Specific program requirements vary with each program. After completing the doctorate program, one must pass the specific certification exam that corresponds to his or her specialty prior to initiating practice. In 2014 there were 3,065 DNP graduates.\n\nNurses who hold a Doctor of Philosophy Degree in Nursing (PhD), are less about hands-on patient care and more about the abstract thinking that helps move the profession forward. A nurse with a PhD has the training needed to conduct research aimed at changing nursing science or practice. The education for a PhD in nursing includes courses in scientific research methodologies and statistics and philosophy of science. Either a BSN or MSN degree are required for entry into a PhD program. Credit requirements vary by program and state and typically take anywhere from three to five years to complete. PhD programs do not have clinical practice hour requirements like DNP programs. PhD prepared nurses teach as academic faculty, conduct research, evaluate programs, hold academic and leadership positions, write books, and lead health care organizations.\n\nRetrieved from https://www.aanp.org/all-about-nps/np-fact-sheet.\nhttp://www.nursing.virginia.edu/programs/phddnpcompare/\nhttp://learn.org/articles/What_Can_I_Do_with_a_PhD_Degree_in_Nursing.html\n\n"}
{"id": "6688378", "url": "https://en.wikipedia.org/wiki?curid=6688378", "title": "Dewvaporation", "text": "Dewvaporation\n\nDewvaporation is a novel desalination technology developed at Arizona State University (Tempe) as an energy efficient tool for freshwater procurement and saline waste stream management. The system has relative low installment costs and low operation and maintenance requirements.\n\nThe process uses air as a carrier gas that transfers water vapor from ascending evaporative channels to adjacent, descending dew-forming channels. Heat flowing through the barrier allows the evaporative energy requirement to be fully satisfied by the heat released by condensation on the dew forming side. A small pressure difference is held so that the condensing cooler air is kept on the cool side.\n\nNear atmospheric operation permits corrosion free and scale-resistant polypropylene construction, and also allows the use of low-grade heat to drive the process. \n\nThe process is proprietary, developed by Dr. James R. Beckman. Currently, Altela Inc. (Albuquerque, NM) is manufacturing this technology under the AltelaRain trade name.\n\nAccording to the Bureau of Reclamation, a branch of the US Department of Interior, this process uses simple corrugated plastic tanks with many \"DewVaporation columns\" inserted in each tank. Each column is made of corrugated plastic and is divided into two compartments. The wall in the middle serves for receiving and evaporating sea-water into a hot air stream, and on the other side for condensing freshwater. The cooling from the evaporation helps water condense on the dividing wall, while the energy from the condensing vapor, now turned to droplets, passes back to the evaporation side, and is absorbed in the evaporating sea water. This way, much of the energy (as heat) is left in the process, and is not removed with the air leaving the DewVaporation column.\n\nVarious improvements have been proposed, among those reusing the output brine and adding external heat in a stacked way, so that the pressure and humidity gap between the two sides of the column are optimal and constant.\n\n\n"}
{"id": "37513831", "url": "https://en.wikipedia.org/wiki?curid=37513831", "title": "Djiboutian cuisine", "text": "Djiboutian cuisine\n\nDjiboutian cuisine is a mixture of Somali, Afar, Yemeni, and French cuisine, with some additional South Asian (especially Indian) culinary influences. Local dishes are commonly prepared using a variety of Middle Eastern spices, ranging from saffron to cinnamon. Grilled Yemeni fish, opened in half and often cooked in tandoori-style ovens, are a local delicacy. Spicy dishes come in many variations, from the traditional \"fah-fah\" or \"soupe djiboutienne\" (spicy boiled beef soup), to the \"yetakelt wet\" (spicy mixed vegetable stew). \"Xalwo\" (pronounced \"halwo\") or halva is a popular confection eaten during festive occasions, such as Eid celebrations or wedding receptions. Halva is made from sugar, corn starch, cardamom powder, nutmeg powder and ghee. Peanuts are sometimes added to enhance texture and flavor. After meals, homes are traditionally perfumed using incense (\"cuunsi\") or frankincense (\"lubaan\"), which is prepared inside an incense burner referred to as a \"dabqaad\".\n"}
{"id": "7654662", "url": "https://en.wikipedia.org/wiki?curid=7654662", "title": "Doctors Reform Society of Australia", "text": "Doctors Reform Society of Australia\n\nThe Doctors Reform Society of Australia (DRS), set up in 1973, is a medico-political thinktank and a medical association of medical practitioners and medical students that has advocated a range of alternative views to those of the Australian Medical Association. \n\nTheir initial focus was on universal health care or health insurance leading up to the establishment of the then \"Medibank\", now Medicare Australia. The DRS publishes the New Doctor journal.\n\n"}
{"id": "57993518", "url": "https://en.wikipedia.org/wiki?curid=57993518", "title": "Eau de Paris", "text": "Eau de Paris\n\nEau de Paris (Paris Water) is the publicly owned company responsible for the public water supply and waste water collection for the city of Paris.\n\nThe company was created in 2008 after a ballot initiative from then Mayor Bertrand Delanoë. The city's water was then substantially managed by two private companies (Veolia and Suez) which the municipal government bought out.\n\nThe company distributes 563,000 m³ of drinking water a day. In 2010 the company began installing drinking fountains dispensing fizzy water in the city.\n\n"}
{"id": "43978682", "url": "https://en.wikipedia.org/wiki?curid=43978682", "title": "Ebola virus epidemic in Guinea", "text": "Ebola virus epidemic in Guinea\n\nAn epidemic of Ebola virus disease in Guinea represents the first ever outbreak of Ebola in a West African country. Previous outbreaks have been confined to several countries in Sub-Saharan Africa. \n\nThe epidemic, which began with the death of a two-year-old boy in 2013, is now part of a larger Ebola virus epidemic in West Africa which has spread through Guinea and the neighboring countries of Liberia and Sierra Leone, with minor outbreaks occurring in Senegal, Nigeria, and Mali. In 2015, Guinea was declared free of Ebola transmission by the U.N. World Health Organization.\n\nResearchers from the Robert Koch Institute believe that the index case was a two-year-old boy who lived in the remote village of Meliandou, Guéckédou located in the Nzérékoré Region of Guinea. Researchers believe that the boy was said to have contracted the virus while he was playing near a tree that was a roosting place for free-tail bats infected with the virus. Dr. Fabian Leendertz, an epidemiologist who was part of the investigative team, said Ebola virus is transmitted to humans either through contact with larger wildlife or by direct contact with bats. The boy, later identified as Emile Ouamouno, fell ill on 2 December 2013 and died four days later. The boy's sister fell ill next, followed by his mother and grandmother. It is believed the Ebola virus later spread to the villages of Dandou Pombo and Dawa, both in Guéckédou, by the midwife who attended the boy. From Dawa village the virus spread to Guéckédou Baladou District and Guéckédou Farako District, and on to Macenta and Kissidougou.\n\nAlthough Ebola represents a major public health issue in sub-Saharan Africa, no cases had ever been reported in West Africa and the early cases were diagnosed as other diseases more common to the area such as Lassa fever, another hemorrhagic fever similar to Ebola. Thus, it was not until March 2014 that the outbreak was recognized as Ebola. The Ministry of Health of Guinea notified the World Health Organization (WHO), and on 23 March the WHO announced an outbreak of Ebola virus disease in Guinea with a total of 49 cases as of that date. By late May, the outbreak had spread to Conakry, Guinea's capital, a city of about two million inhabitants.\n\nIn March, Guinea's President Alpha Conde declared a national health emergency due to the outbreak. He stated efforts to control the spread of the Ebola virus would include forbidding Ebola patients from leaving their homes, border control, travel restrictions, and hospitalization for individuals suspected to be infected until cleared by laboratory results. He also banned the transporting of the dead between towns.\n\nGood disease tracing is important to prevent the outbreak from spreading. Previous Ebola outbreaks have occurred in remote areas making containment easier; the current outbreak struck in an area that lies at the centre of both a highly-mobile and densely populated region which has made tracking more difficult: \"This time, the virus is traveling effortlessly across borders by plane, car and foot, shifting from forests to cities and springing up in clusters far from any previously known infections. Border closures, flight bans and mass quarantines have been ineffective.\" Peter Piot, who co-discovered Ebola, said Ebola \"isn't striking in a 'linear fashion' this time. It's hopping around, especially in Liberia, Guinea and Sierra Leone\".\n\nContainment has also been difficult due to fear of healthcare workers. Infected people and those that they have been in contact with have evaded surveillance, moving at will and hiding their illnesses while they infect others in turn. Entire villages, stricken by fear, have closed themselves off, giving the disease an opportunity to strike in another area. It has been reported that in some areas it is believed that health workers are purposely spreading the disease to the people, while others believe that the disease does not exist. Riots broke out in the regional capital, Nzérékoré, when rumors were spread that people were being contaminated when health workers were spraying a market area to decontaminate it.\n\nIn May, the number of Ebola cases appeared to be decreasing and Médecins Sans Frontières (MSF) closed a treatment facility in the Macenta region because the outbreak of Ebola there appeared to have been resolved. At the time it was thought that the new cases were caused by people returning from Liberia or from Sierra Leone, however it was later suggested that villagers had become fearful and were hiding cases rather than reporting them. Seeing workers wearing the required protection outfits worn by health workers and taking those suspected of having Ebola or of being contacts to the treatment center (perhaps never to be seen again), refusing the usual burial rituals when a patient died, and other actions taken by the unfamiliar individuals that had come to their remote areas, had led to rumors of organ harvesting and government and tribal plots. According to a September news report, \"Many Guineans say local and foreign healthcare workers are part of a conspiracy which either deliberately introduced the outbreak, or invented it as a means of luring Africans to clinics to harvest their blood and organs.\" As described in another news article, \"The health workers don’t look like any people you’ve ever seen. They perform stiffly and slowly, and then they disappear into the tent where your mother or brother may be, and everything that happens inside is left to your imagination. Villagers began to whisper to one another—\"They’re harvesting our organs; they’re taking our limbs\"\". Moreover, due to fear, many people are avoiding hospital treatment for any ailment and are self-treating with over the counter drugs from a pharmacy.\n\nOn 18 September, eight members of a health care team were murdered by local villagers in the town of Womey near Nzérékoré. The team consisted of Guinean health and government officials accompanied by journalists, who had been distributing Ebola information and doing disinfection work. They were attacked with machetes and clubs, and their bodies were found in a septic tank. The dead included three journalists and four volunteers.\n\nThe governor of Conakry, Soriba Sorel Camara, prohibited all cultural events for the holiday of Tabaski in a decree of 2 October 2014.\n\nIn the WHO Situation Report of 8 October, it was reported, that the transmission of Ebola was persistently high with approximately 100 new confirmed cases in the first week of October. The first cases were reported in the district of Lola. Médecins Sans Frontières reported a massive spike in the number of new cases in the capital city of Conakry. One facility admitted 22 patients in a single day (October 6), 18 of them coming from Coyah region, 50 kilometres (31 miles) east of Conakry.\n\nOn 19 October, Guinea reported two new districts with Ebola cases. The Kankan district, on the border with the Côte d'Ivoire and a major trade route to Mali, confirmed one case. Kankan also borders the district of Kerouane in this country, one of the areas with the most intense virus transmissions. The Faranah district to the north of the border area of Koinadugu in Sierra Leone also reported a confirmed case. Koinadugu was one of the last Ebola-free regions in that country. According to a WHO report, this new development highlights the need for increased surveillance of cross border traffic in an effort to contain the disease to the three most affected countries.\n\nOn 23 October, Saccoba Keita, the head of Guinea's Ebola mission, announced the government has started compensating the families of health care workers who died after contracting the virus. At that time, 42 health care workers had died, including doctors, nurses, drivers, and porters. The compensation totals $10,000 (£6,200) and is to be paid as a lump sum.\n\nIn mid-November, the WHO reported that while intense transmission persists and cases and deaths continue to be under-reported, there is some evidence that case incidence is no longer increasing nationally in Guinea. They report that case numbers in some districts have been fluctuating, but they remain consistently high. \nNew case numbers have been declining in the outbreak’s epicentre of Gueckedou, but transmission continues to be high in Macenta. Of a total of 34 districts in Guinea, 10 remain unaffected by Ebola, contrasting with Liberia and Sierra Leone, where every district has been affected.\n\nOn 20 November, the local Red Cross in Kankan Prefecture sent blood samples via a courier when the taxi he was traveling in was stopped by robbers. The bandits made off with the cooler bag containing the blood samples. The Guinea authorities made a public appeal for the return of the blood samples. The robbery occurred near the town of Kissidougou.\n\nOn 14 December the WHO stated that 17 districts reported new confirmed or suspected cases in this week. Guinea reported 2,416 cases with 1,525 deaths on this date. Only 10 out of the 34 districts have not reported cases. Conakry reported 18 new cases in this week. The northern district of Siguiri is of particular concern, as it borders Mali and reported 4 new probable cases.\n\nThe country was declared free of Ebola transmission on 29 December, 42 days after the last Ebola patient tested negative for a second time. Guinea was subsequently in a 90-day period of heightened surveillance according to the U.N. World Health Organization which also offered assistance - with funding from the agency's donors.\n\nOn 17 March 2016, the government of Guinea reported 2 people had tested positive for Ebola virus in Korokpara. It was also reported that they are from the village where members of one family died recently from vomiting (and diarrhea). On 19 March, it was reported that another individual died due to the virus, at the treatment centre in Nzerekore. The country's government has quarantined an area around the home where the cases took place. This region of Guinea is where the first case was registered on December 2013, at the beginning of the Ebola outbreak. On 22 March, it was reported that medical authorities in Guinea have quarantined 816 people as possibly having had contact with the prior cases (more than one hundred individuals are considered high risk); on the same day Liberia ordered its border with Guinea closed. Macenta prefecture, 200 kilometers from Korokpara, has registered the fifth fatality due to the Ebola virus disease in Guinea. On 29 March it was reported that about 1000 contacts have been identified (142 are high risk), and on 30 March, 3 more confirmed cases were reported from the sub-prefecture of Koropara in Guinea. On 1 April it was reported that possible contacts, which number in the hundreds, have been vaccinated with an experimental vaccine, in a \"ring vaccination\" approach.\n\nOn 5 April it was reported that there were nine new cases of Ebola since the virus resurfaced. Of these nine cases eight have died. After a 42-day waiting period, the WHO declared the country free of Ebola on 1 June.\n\nAfter a trial run of an experimental Ebola vaccine involving 11,000 people in Guinea, Merck, the vaccine’s manufacturer, announced it was found to be “highly protective” against the virus. This confirmed the results of a study published in 2015 that awarded the vaccine 100 percent effectiveness after tests on 4000 people in Guinea who had been in close contact with Ebola patients. However, a study sponsored by the National Institutes of Health, the Food and Drug Administration and the U.S. Department of Health and Human Services, and conducted by researchers from the U.S. National Academy of Medicine, called the vaccine’s effectiveness in preventing Ebola infections into question. In particular, the authors criticized the methodology of the patient trail, and argued that the protection provided by the vaccine may be lower than officially announced.\n\nThe WHO approved the vaccine for use in the ongoing Ebola outbreak on May 29, 2017.\n\nIt was announced in May 2017 that the Gamaleya Center for Epidemiology and Microbiology in Russia would deliver 1000 doses of an independently produced vaccine to Guinea for testing. According to a Xinhua report, it is the only officially authorized and approved Ebola vaccine for clinical use to date.\n\n\n\n"}
{"id": "54880779", "url": "https://en.wikipedia.org/wiki?curid=54880779", "title": "Economic anxiety", "text": "Economic anxiety\n\nEconomic anxiety is the state of concern about the future of one's economic prospects. It has been widely cited (e.g. by commentators at FiveThirtyEight) as a major reason for Donald Trump's victory in the 2016 U.S. presidential election. Other commentators, however, argue that economic anxiety was less of an important factor in predicting support for Trump than \"cultural anxiety,\" or the feeling that one is a stranger in America and that illegal immigrants should be deported. The term has also been used sarcastically in response to racist statements by Trump's supporters, to mock the attempts by centrist commentators to argue that support for Trump is due to concern about their economic prospects, not to racial attitudes. \n"}
{"id": "35042000", "url": "https://en.wikipedia.org/wiki?curid=35042000", "title": "Epidemiology of malnutrition", "text": "Epidemiology of malnutrition\n\nThere were 795 million undernourished people in the world in 2014, a decrease of 216 million since 1990, despite the fact that the world already produces enough food to feed everyone—7 billion people—and could feed more than that—12 billion people.\n\nThe number of undernourished people (million) in 2010–2012 and 2014–2016 (projected).\nAccording to the FAO, these countries had 5 million or more undernourished people in 2001–2003 and in 2005–2007.\nNote: This table measures \"undernourishment\", as defined by FAO, and represents the number of people consuming (on average for years 2010 to 2012) less than the minimum amount of food energy (measured in kilocalories per capita per day) necessary for the average person to stay in good health while performing light physical activity. It is a conservative indicator that does not take into account the extra needs of people performing extraneous physical activity, nor seasonal variations in food consumption or other sources of variability such as inter-individual differences in energy requirements. Malnutrition and undernourishment are cumulative or average situations, and not the work of a single day's food intake (or lack thereof). This table does not represent the number of people who \"went to bed hungry today.\"\n\nThe below is a list of countries by percentage of population with undernourishment, as defined by the United Nations World Food Programme and the UN Food and Agriculture Organization in its \"The State of Food Insecurity in the World\" 2009 report.\n\nMalnutrition rates in Iraq had risen from 19% before the US-led invasion to a national average of 28% four years later. By 2010, according to the UN Food and Agriculture Organization, only 8% were malnourished. (See data above.)\n\nAccording to the Global Hunger Index, South Asia (also known as the Indian Subcontinent) has the highest child malnutrition rate of world's regions. India, a largely vegetarian country and second largest country in the world by population, contributes most number in malnutrition in the region.The 2006 report mentioned that \"the low status of women in South Asian countries and their lack of nutritional knowledge are important determinants of high prevalence of underweight children in the region\" and was concerned that South Asia has \"inadequate feeding and caring practices for young children\".\n\n30% children of India are underweight, one of the highest rates in the world and nearly double the rate of Sub-Saharan Africa.\n\nResearch on overcoming persistent under-nutrition published by the Institute of Development Studies, argues that the co-existence of India as an 'economic powerhouse' and home to one-third of the world's under-nourished children reflects a failure of the governance of nutrition: \"A poor capacity to deliver the right services at the right time to the right populations, an inability to respond to citizens' needs and weak accountability are all features of weak nutrition governance.\" The research suggests that to make under-nutrition history in India the governance of nutrition needs to be strengthened and new research needs to focus on the politics and governance of nutrition. At the current rate of progress the MDG1 target for nutrition will only be reached in 2042 with severe consequences for human wellbeing and economic growth.\n\nAccording to the United States Department of Agriculture in 2015, 50 million Americans experienced food insecurity in 2009, including 17 million children. This represents nearly one in four American children.\n\nAlthough the United States Department of Agriculture reported in 2012 that an estimated 85.5 percent of households in the country are food secure, millions of people in America struggle with the threat of hunger or experience hunger on a daily basis. The USDA defines food security as the economic condition of a household wherein which there is reliable access to a sufficient amount of food so all household members can lead a healthy productive life. Hunger is most commonly related to poverty since a lack of food helps perpetuate the cycle of poverty. Most obviously, when individuals live in poverty they lack the financial resources to purchase food or pay for unexpected events, such as a medical emergency. When such emergencies arise, families are forced to cut back on food spending so they can meet the financial demands of the unexpected emergency. There is not one single cause of hunger but rather a complex interconnected web of various factors. Some of the most vulnerable populations to hunger are the elderly, children, people from a low socioeconomic status, and minority groups; however, hunger's impact is not limited to these individuals.\nThe largest nonprofit food relief organization in the United States, Feeding America, feeds 46.5 million citizens a year to address the nation's food insecurity issue. This equates to one in seven Americans requiring their aid in a given year. An organization that focuses on providing food for the elderly population is Meals on Wheels, which is a nonprofit that delivers meals to seniors' homes. The government also works towards providing relief through programs such as the Supplemental Nutrition Assistance Program (SNAP) which was formerly known to the public as Food Stamps. Another well known government program is the National School Lunch Program (NSLP) which provides free or reduced lunches to students who qualify for the program.\n\nThe number of Americans suffering from hunger rose after the 2008 financial crisis, with children and working adults now making up a large proportion of those affected. In 2012, \"Gleaners Indiana Food bank\" reported that there were now 50 million Americans struggling with food insecurity (about 1 in 6 of the population), and that the number of folks seeking help from food banks had increased by 46% since 2005. According to a 2012 study by UCLA Center for Health Policy Research, even married couples who both work but have low incomes sometimes require the aid of food banks.\nChildhood malnutrition is generally thought of as being limited to developing countries, but although most malnutrition occurs there, it is also an ongoing presence in developed nations. For example, in the United States of America, one out of every six children is at risk of hunger. A study, based on 2005–2007 data from the U.S. Census Bureau and the Agriculture Department, shows that an estimated 3.5 million children under the age of five are at risk of hunger in the United States.\n\nIn developed countries, this persistent hunger problem is not due to lack of food or food programs, but is largely due to an underutilization of existing programs designed to address the issue, such as food stamps or school meals. Many citizens of rich countries such as the United States of America attach stigmas to food programs or otherwise discourage their use. In the USA, only 60% of those eligible for the food stamp program actually receive benefits.\n\nThe U.S. Department of Agriculture reported that in 2003, only 1 out of 200 U.S. households with children became so severely food insecure that any of the children went hungry even once during the year. A substantially larger proportion of these same households (3.8 percent) had adult members who were hungry at least one day during the year because of their households' inability to afford enough food.\n"}
{"id": "9510615", "url": "https://en.wikipedia.org/wiki?curid=9510615", "title": "Focal infection theory", "text": "Focal infection theory\n\nFocal infection theory is the historical concept that many chronic diseases, including systemic and common diseases, are caused by focal infections, that is, a localized infection that causes disease elsewhere in the host. But focal infections themselves are fairly infrequent, often asymptomatic, and limited to fairly uncommon diseases. The key principle of focal infection theory is injury (infection) at a distance, where the mode of infection in ordinary infectious disease is systemic, as in measles; or, the initially infected site is readily identifiable and invasion progresses contiguously from the point of infection, as in gangrene. Thus, rather than singular diseases presenting with specific progressions of an original infection, focal infection theory has historically explained virtually all diseases—including arthritis, atherosclerosis, cancer, and mental illnesses— as secondary infections caused by a distant (and often obscure) source.\n\nAn ancient concept that took modern form around 1900, focal infection theory was widely accepted in medicine by the 1920s. In the theory, the \"focus of infection\" might lead to secondary infections at sites particularly susceptible to such microbial species or toxin. Commonly alleged foci were diverse—appendix, urinary bladder, gall bladder, kidney, liver, prostate, and nasal sinuses—but most commonly were oral. Besides dental decay and infected tonsils, both dental restorations and especially endodontically treated teeth were blamed as foci. The putative \"oral sepsis\" was countered by tonsillectomies and tooth extractions, including of endodontically treated teeth and even of apparently healthy teeth, newly popular approaches—sometimes leaving individuals toothless—to treat or prevent diverse diseases.\n\nDrawing severe criticism in the 1930s, focal infection theory—whose popularity zealously exceeded consensus evidence—was discredited in the 1940s by research attacks that drew overwhelming consensus of this sweeping theory's falsity. Thereupon, dental restorations and endodontic therapy became again favored. Untreated endodontic \"disease\" retained mainstream recognition as fostering systemic disease. But only alternative medicine and later biological dentistry continued highlighting sites of dental treatment—still endodontic therapy, but, more recently, also dental implant, and even tooth extraction, too—as foci of infection causing chronic and systemic diseases. In mainstream dentistry and medicine, the primary recognition of focal infection is endocarditis, if oral bacteria enter blood and infect the heart, perhaps its valves.\n\nEntering the 21st century, scientific evidence supporting general relevance of focal infections remained slim, yet evolved understandings of disease mechanisms had established a third possible mechanism—altogether, metastasis of infection, metastatic toxic injury, and, as recently revealed, metastatic immunologic injury—that might occur simultaneously and even interact. Meanwhile, focal infection theory has gained renewed attention, as dental infections apparently are widespread and significant contributors to systemic diseases, although mainstream attention is on ordinary periodontal disease, not on hypotheses of stealth infections via dental \"treatment\". Despite some doubts renewed in the 1990s by conventional dentistry's critics, dentistry scholars maintain that endodontic therapy can be performed without creating focal infections.\n\nIn ancient Greece, Hippocrates reported cure of an arthritis case by tooth extraction. Yet modern focal infection theory awaited Robert Koch's establishment of medical bacteriology in the late 1870s to early 1880s. In 1890, Willoughby D Miller attributed a set of oral diseases to infections, and a set of general diseases—as of lung, stomach, brain abscesses, and other conditions—to those infectious oral diseases. In 1894, Miller became the first to reveal existence of bacteria in samples of dental pulp. Miller advised root canal therapy. Yet focal infection theory met a cultural climate where ancient and folk ideas, long entrenched via Galenic humoral medicine, found new outlets through bacteriology—a pillar of the new \"scientific medicine\".\n\nEmigrating from Russia in 1886, international scientific celebrity Elie Metchnikoff—discoverer of phagocytes, mediating innate immunity—was embraced in Paris by Louis Pasteur, who granted him an entire floor for research once the Pasteur Institute, the globe's first biomedical institute, opened in 1888. Later the Institute's director and 1908 Nobelist, Metchnikoff believed, as did his rival Paul Ehrlich—theorist on antibody, mediating acquired immunity—and as did Pasteur, that nutrition influenced immunity. Sharing Pasteur's view of science as a means to suppress the problems plaguing humankind, Metchnikoff brought into France its first cultures of yogurt for probiotic microorganisms to foster health and longevity by suppressing the colon's putrefactive microorganisms alleged to foster the colon's toxic seepage, \"autointoxication\".\n\nAs the 20th century opened, British surgeons were still knife-happy, and called for \"surgical bacteriology\". Surgical pioneer Sir Arbuthnot Lane, famed for an emergency appendectomy performed on England's royalty, drew from Metchnikoff and clinical observation to issue dire warnings about \"chronic intestinal stasis\"—that is, constipation—its \"flooding of the circulation with filthy material\" and causing autointoxication, which Lane then treated with colon bypass and colectomy. In America, alleged \"bowel sepsis\" wreaking degeneration and disease had been targeted since 1875 by John Harvey Kellogg in Michigan at his huge Battle Creek Sanitarium—he coined the term \"sanitarium\"—yearly receiving several thousand patients, including US Presidents and celebrities, and advertising itself as the \"University of Health\". When embracing focal infection theory, however, American medical doctors sided against alleged \"health faddists\" like Kellogg as well as Sylvester Graham, and endorsed the academic tradition of German \"scientific medicine\".\n\nIn 1900, British surgeon William Hunter blamed many disease cases on \"oral sepsis\". In 1910, lecturing in Montreal at McGill University, he claimed, \"The worst cases of anemia, gastritis, colitis, obscure fevers, nervous disturbances of all kinds from mental depression to actual lesions of the cord, chronic rheumatic infections, kidney diseases are those which owe their origin to or are gravely complicated by the oral sepsis produced by these gold traps of sepsis.\" He apparently indicted dental restorations. Incriminating their execution, rather, his American critics lobbied for stricter dental licensing requirements. Still, Hunter's lecture—as later recalled—\"ignited the fires of focal infection\". Ten years later, he proudly accepted that credit. And yet, read carefully, his lecture asserts a sole cause of the sepsis: dentists who instruct patients to \"never remove\" partial dentures.\n\nFocal infection theory's modern era really began with physician Frank Billings, based in Chicago, and his case reports of tonsillectomies and tooth extractions claimed to have cured infections of distant organs. Replacing Hunter's term \"oral sepsis\" with \"focal infection\", Billings in November 1911 lectured at the Chicago Medical Society, and published it in 1912 as an article for the American medical community. In 1916, Billings lectured in California at Stanford University Medical School, this time printed in book format. Billings thus popularized intervention by tonsillectomy and tooth extraction. A pupil of Billings, Edward Rosenow held that extraction alone was often insufficient, and urged teamwork by dentistry and medicine. Rosenow developed the principle \"elective localization\", whereby microorganisms have affinities for particular organs, and also espoused extreme pleomorphism.\n\nSince 1889, in American state Minnesota, brothers William Mayo and Charles Mayo had built an international reputation for surgical skill at their Mayo Clinic, by 1906 performing some 5,000 surgeries a year, over 50% intra-abdominal, a tremendous number at the time, with unusually low mortality and morbidity. Though originally distancing themselves from routine medicine and skeptical of laboratory data, they later recruited Rosenow from Chicago to help improve Mayo Clinic's diagnosis and care and to enter basic research via experimental bacteriology. Rosenow influenced Charles Mayo, who by 1914 published to support focal infection theory alongside Billings and Rosenow.\n\nAt Johns Hopkins University's medical school, launched in 1894 as America's first to teach \"scientific medicine\", the eminent Sir William Osler was succeeded as professor of medicine by Llewellys Barker, who became a prominent proponent of focal infection theory. Although many of Hopkins' medical faculty remained skeptics, Barker's colleague William Thayer cast support. As Hopkins' chief physician, Barker was a pivotal convert propelling the theory to the center of American routine medical practice. Russell Cecil, famed author of \"Cecil's Essentials of Medicine\", too, lent support. In 1921, British surgeon Hunter announced that oral sepsis was \"coming of age\".\n\nAlthough physicians had already interpreted pus within a bodily compartment as a systemic threat, pus from infected tooth roots often drained into the mouth and thereby was viewed as systemically inconsequential. Amid focal infection theory, it was concluded that that was often the case—while immune response prevented dissemination from the focus—but that immunity could fail to contain the infection, that dissemination from the focus could ensue, and that systemic disease, often neurological, could result. By 1930, excision of focal infections was considered a \"rational form of therapy\" undoubtedly resolving many cases of chronic diseases. Its inconsistent effectiveness was attributed to unrecognized foci—perhaps inside internal organs—that the clinicians had missed.\n\nIn 1923, upon some 25 years of researches, dentist Weston Andrew Price of Cleveland, Ohio, published a landmark book, then a related article in the \"Journal of the American Medical Association\" in 1925. Price concluded that after root canal therapy, teeth routinely host bacteria producing potent toxins. Transplanting the teeth into healthy rabbits, Price and his researchers duplicated heart and arthritic diseases. Although Price noted often seeing patients \"suffering more from the inconvenience and difficulties of mastication and nourishment than they did from the lesions from which their physician or dentist had sought to give them relief\", his 1925 debate with John P Buckley was decided in favor of Price's position: \"practically all infected pulpless teeth should be extracted\". As chairman of the American Dental Association's research section, Price was the individual who, perhaps beyond any other, shaped the dentistry profession's opinion. Textbook authors relied on Price's 1923 treatise into the late 1930s.\n\nUnsuspected periapical disease was first revealed by dental X-ray in 1911, the year that Frank Billings lectured on focal infection to the Chicago Medical Society. Introduced by C Edmund Kells, the technology became used to feed the \"mania of extracting devitalized teeth\". Even Price was cited as an authoritative source espousing conservative intervention at focal infections. Kells, too, advocated conservative dentistry. Many dentists were \"100 percenters\", extracting every tooth exhibiting either necrotic pulp or endodontic treatment, and extracted apparently healthy teeth, too, as suspected foci, leaving many persons toothless. A 1926 report published by several authors in \"Dental Cosmos\"—a dentistry journal where Willoughby Miller had published in the 1890s—advocated extraction of known healthy teeth to \"prevent\" focal infection. Endodontics nearly vanished from American dental education. Some dentists held that root canal therapy should be criminalized and penalized with six months of hard labor.\n\nBesides heredity, focal infection and autointoxication was psychiatry's predominant explanation of schizophrenia near the turn of the 20th century. In American state New Jersey, the director of the psychiatric asylum at Trenton State Hospital since 1907 was Henry Cotton. Drawing influence from the medical popularity of focal infection theory, Cotton identified focal infections as the main causes of dementia praecox (now schizophrenia) and manic depression (now bipolar disorder). Cotton routinely prescribed surgery to clean the nasal sinuses and to extract the tonsils and dentition. Yet, seeking to clean the entire body of focal infections, Cotton frequently prescribed surgical removal of the appendix, gall bladder, spleen, stomach, colon, cervix, ovaries, testicles, and thereby claimed up to 85% cure rate.\n\nDespite the death rate of some 30%, Cotton's fame rapidly spread through America and Europe, and the asylum drew influx of paying patients. \"The New York Times\" praised his accomplishments and heralded \"high hope\". Cotton made a European lecture tour, and Princeton University Press and Oxford University Press simultaneously published his book in 1922. Despite scepticism within his profession, psychiatrists were under pressure to match Cotton's treatments, as patients would ask why they were being denied successful intervention. Other patients, ostensibly for their own good, were pressured or compelled into treatment without their own consent. Cotton had his two sons' teeth extracted as preventive healthcare—although each later committed suicide. By the 1930s, however, focal infection fell from psychiatry as an explanation.\n\nAddressing the Eastern Medical Society in December 1918, New York City physician Robert Morris explained that focal infection theory had drawn much interest while factual understanding of it was incomplete, and while application of the theory was earning disrepute through the overzealousness of some advocates. Morris called for facts and explanation from scientists before physicians continued to invest so steeply in a theory that even so was triggering acrimonious disputes and division among clinicians and uncertainty among patients.\n\nIn 1919, in New Orleans, at the annual meeting of the National Dental Association (forerunner of the American Dental Association), dental X-ray originator and pioneer C Edmund Kells delivered a lecture, published in 1920 in the Association's journal, largely discussing focal infection theory, which Kells condemned as a \"crime\". Kells stressed that X-ray technology is to improve dentistry, not to enhance the \"mania of extracting devitalized teeth\". Kells urged dentists to reject physicians' prescriptions of tooth extractions.\n\nFocal infection theory's elegance suggested simple application, but the applications brought meager \"cure\" rate, occasional disease worsening, and inconsistent experimental results, although the lack of controlled clinical trials, among present criticism, was standard at the time—except in New York City. Around 1920, at Henry Cotton's claims of up to 85% success treating schizophrenia and manic depression, Cotton's major critic was George Kirby, director of the New York State Psychiatric Institute on Ward's Island. Two researchers, bacteriologist Nicolas Kopeloff and psychiatrist Clarence Cheney, ventured from the New York State Psychiatric Institute to Trenton, New Jersey, to investigate Cotton's practice.\n\nIn two controlled clinical trials with alternate allocation of patients, Kopeloff, Cheney, and Kirby found no effectiveness of Cotton's psychiatric surgeries, as patients who improved already had that prognosis and others did so without surgeries. They presented their findings at the American Psychiatric Association's 1922 and 1923 annual meetings, and published two papers. Most of Cotton's data were questioned at Johns Hopkins University by Phyllis Greenacre, who later helped steer American psychiatry into psychoanalysis. Colectomy for psychosis vanished except in Trenton until Cotton—who used publicity and word of mouth, kept the 30% death rate unpublicized, and passed a 1925 investigation by New Jersey Senate—died by heart attack in 1933.\n\nAs early as 1927, Weston Price's researches were criticized for \"faulty bacterial technique\". In the 1930s and 1940s, researchers and editors dismissed the studies of Edward Rosenow and of Price as flawed by insufficient controls, massive doses of bacteria, and contamination of endontically treated teeth during extraction. In 1938, Cecil and Angevine reported 200 cases of rheumatoid arthritis, but no consistent cures by tonsillectomies or tooth extractions. They noted that, \"Focal infection is a splendid example of a plausible medical theory which is in danger of being converted by its enthusiastic supporters into the status of an accepted fact.\" Newly a critic, Cecil alleged that foci were \"anything readily accessible to surgery\".\n\nIn 1939, E W Fish implanted bacteria into guinea pigs' jaws and reported that four zones develop. The first zone was the zone of infection, whereas the other three zones—surrounding the zone of infection—revealed immune cells or other host cells but no bacteria. Fish theorized that by removing the infectious nidus, dentists would permit recovery from the infection, and Fish's reasoning and conclusion became the basis for successful root canal treatment. Still, endodontic therapy of the era indeed posed substantial risk of failure, and fear of focal infection crucially motivated endontologists to develop new and improved technology and techniques.\n\nThe review and \"critical appraisal\" by Hobart A Reimann and W Paul Havens, published in January 1940, was perhaps the most influential criticism of focal infection theory. Recasting Hunter's views of 30 years earlier as widely misinterpreted, they summarized that \"the removal of infectious dental focal infections in the hope of influencing remote or general symptoms of disease must still be regarded as an experimental procedure not devoid of hazard\". By 1940, Louis I Grossman's textbook \"Root Canal Therapy\" flatly rejected the methods and conclusions made earlier by Price and especially by Rosenow. Amid improvements in endodontics and medicine, including release of sulfa drugs and antibiotics, a backlash to the \"orgy\" of tooth extractions and tonsillectomies ensued.\n\nEaslick's 1951 review in the \"Journal of the American Dental Association\" notes, \"Many authorities who formerly felt that focal infection was an important etiologic factor in systemic disease have become skeptical and now recommend less radical procedures in the treatment of such disorders\". A 1952 editorial in \"Journal of the American Medical Association\" tolled the era's end by stating that \"many patients with diseases presumably caused by foci of infection have not been relieved of their symptoms by removal of the foci, many patients with these same systemic diseases have no evidence focus of infection, foci of infection are as common in apparently healthy persons as in those with disease\". Some support extended into the late 1950s, yet focal infection vanished as the primary explanation of chronic, systemic diseases, and was generally abandoned in the 1950s.\n\nDespite the general theory's demise, focal infection remained a formal, if rare, diagnosis, as in idiopathic scrotal gangrene and angioneurotic edema. Meanwhile, by way of continuing case reports claiming cures of chronic diseases like arthritis after extraction of infected or root-filled teeth, and despite lack of scientific evidence, \"dental focal infection theory never died\". In fact, severe endodontic disease resembles classic focal infection theory. In 1986, it was noted that, \"in spite of a decline in recognition of the focal-infection theory, the association of decayed teeth with systemic disease is taken very seriously\". Eventually, the theory of focal infection drew reconsideration. Conversely, attribution of endocarditis to dentistry has entered doubt via case-control study, as the species usually involved is present throughout the human body.\n\nWith the 1950s introduction of antibiotics, attempts to explain unexplained diseases via bacterial etiology seemed all the more unlikely. By the 1970s, however, it was established that antibiotics could trigger bacteria's switch to their L phase. Eluding detection by traditional methods of medical microbiology, bacterial L forms and the similar mycoplasma—and, later, viruses—became the entities expected in the theory of focal infection. Yet until the 1980s, such researchers were scarce, largely via scarce funding for such investigations.\n\nDespite the limited funding, research established that L forms can adhere to red blood cells and thereby disseminate from foci within internal organs such as the spleen, or from oral tissues and the intestines, especially during dysbiosis. Perhaps some of Weston Price's identified \"toxins\" in endodontically treated teeth were L forms, thought nonexistent by bacteriologists of his time and widely overlooked into the 21st century. Apparently, dental infections, including by uncultured or cryptic microorganisms, contribute to systemic diseases.\n\nAt the 1990s' emergence of epidemiological associations between dental infections and systemic diseases, American dentistry scholars have been cautious, some seeking successful intervention to confirm causality. Some American sources emphasized epidemiology's inability to determine causality, categorized the phenomena as progressive invasion of local tissues, and distinguished that from focal infection theory—which they assert was evaluated and disproved by the 1940s. Others have found focal infection theory's scientific evidence still slim, but have conceded that evolving science might establish it. Yet select American authors affirm the return of a modest theory of focal infection.\n\nEuropean sources find it more certain that dental infections drive systemic diseases, at least by driving systemic inflammation, and probably, among other immunologic mechanisms, by molecular mimicry resulting in antigenic crossreaction with host biomolecules, while some seemingly find progressive invasion of local tissues compatible with focal infection theory. Acknowledging that beyond epidemiological associations, successful intervention is needed to establish causality, they emphasize that biological explanation is needed atop both, and the biological aspect is thoroughly established already, such that general healthcare, as for cardiovascular disease, must address prevalent periodontal disease, a stance matched in Indian literature. Thus, there has emerged the concept \"periodontal medicine\".\n\nAmid continuing research interest, Indian textbooks find focal infection theory established, if in more modest form than originally. Akshata \"et al\" have attacked the stigma and posed focal infection theory as a correct theory earlier misapplied and thereby discredited yet later refined as knowledge grew over time. In a paper winning an Indian prize, they clarify \"that the oral cavity can act as the site of origin for dissemination of pathogenic organisms to distant body sites, especially in immunocompromised hosts\", especially those \"suffering from malignancies, diabetes, rheumatoid arthritis\", or \"undergoing other immunosuppressive treatment\", and that \"uncontrolled advanced periodontitis\" \"presents a substantial infectious burden for the entire body by releasing bacteria, bacterial toxins, and other inflammatory mediators into the bloodstream that then affect the other parts of the body\", this altogether \"a paradigm shift in thinking about the directionality of oral and systemic associations\".\n\nDuring the 1980s, dentist Hal Huggins, sparking severe controversy, spawned biological dentistry, which claims that conventional tooth extraction routinely leaves within the tooth socket the periodontal ligament that often becomes gangrenous, then, forming a jawbone \"cavitation\" seeping infectious and toxic material. Sometimes forming elsewhere in bones after injury or ischemia, jawbone cavitations are recognized as foci also in osteopathy and in alternative medicine, but conventional dentists generally conclude them to be nonexistent. Although the International Academy of Oral Medicine & Toxicology claims that the scientific evidence establishing the existence of jawbone cavitations is overwhelming, and even published in textbooks, the diagnosis and related treatment remain controversial, and allegations of quackery persist.\n\nHuggins and many biological dentists also espouse Weston Price's findings on endodontically treated teeth routinely being foci of infection, although these dentists have been accused of quackery. Conventional belief is that microorganisms within inaccessible regions of a tooth's roots are rendered harmless once entrapped by the filling material, although little evidence supports this. A H Rogers in 1976 and E H Ehrmann in 1977 had dismissed any relation between endodontics and focal infection. At dentist George Meinig's 1994 book, \"Root Canal Cover-Up Exposed\", discussing researches of Rosenow and of Price, some dentistry scholars reasserted that the claims were evaluated and disproved by the 1940s. Yet Meinig was but one of at least three authors who in the early 1990s independently renewed the concern.\n\nBoyd Haley and Curt Pendergrass found especially high levels of bacterial toxins in root-filled teeth. Although such possibility appears especially likely amid compromised immunity—as in individuals cirrhotic, asplenic, elderly, rheumatoid arthritic, or using steroid drugs—there remained a lack of carefully controlled studies definitely establishing adverse systemic effects. Conversely, some if few studies have investigated effects of systemic disease on root-canal therapy's outcomes, which tend to worsen with poor glycemic control, perhaps via impaired immune response, a factor largely ignored until recently, but now recognized as important. Still, even by 2010, \"the potential association between systemic health and root canal therapy has been strongly disputed by dental governing bodies and there remains little evidence to substantiate the claims\".\n\nThe traditional root-filling material is gutta-percha, whereas a new material, Biocalex, drew initial optimism even in alternative dentistry, but Biocalex-filled teeth were later reported by Boyd Haley to likewise seep toxic byproducts of anaerobic bacterial metabolism. Seeking to sterilize the tooth interior, some dentists, both alternative and conventional, have applied laser technology. Although endodontic therapy can fail and eventually often does, dentistry scholars maintain that it \"can\" be performed without creating focal infections. And even by 2010, molecular methods had rendered no consensus reports of bacteremia traced to asymptomatic endodontic infection. In any event, the predominant view is that shunning endodonthic therapy or routinely extracting endodontically treated teeth to treat or prevent systemic diseases remains unscientific and misguided.\n"}
{"id": "41414099", "url": "https://en.wikipedia.org/wiki?curid=41414099", "title": "Francisco Javier Muñiz", "text": "Francisco Javier Muñiz\n\nFrancisco Javier Muñiz (21 December 1795 – 8 April 1871) was an Argentine colonel, legislator, and medical doctor. He treated patients and died during the Great Yellow Fever Epidemic of 1871. He was considered the first important naturalist from Argentina.\n\nFrancisco Javier Muñiz was born in San Isidro, Buenos Aires Province, Argentina on 21 December 1795.\n\nHe studied at the \"Instituto Médico Militar\" (\"Military Medical Institute\") beginning in 1814. The institute was founded by Dr. Cosme Argerich to train surgeons for the army. Muñiz graduated as a doctor in 1821 He transferred to the University of Buenos Aires and completed his surgical education in 1824. Muñiz obtained his doctorate in 1844; his dissertation was about the vaccination of indigenous peoples against smallpox. This work made him notable among European scientists. His dissertation followed the article, \"A Case of Extensive Scabby Ulcerations, Cured by Vaccination\" that he wrote and was published in the \"London Medical and Surgical Journal\" in 1833.\n\nMuñiz, upon becoming a doctor in 1821, worked as a military doctor under Juan Lavalle at Carmen de Patagones during the campaign to secure land from indigenous people. He began to study the customs of native people at this time.\nIn 1824 he was transferred to the fort at Chascomús, and began his study of paleontology. General Carlos María de Alvear ordered that he accompany Lavalle and his troops during the 1826 war with Brazil. He was promoted to Army Surgeon Major that year and transferred to Luján in 1828 to be a physician to police and military troops.\n\nMuñiz served the military and became a colonel. During the Paraguayan War, he became director of Corrientes Province area hospitals.\n\nIn 1848, Muñiz moved to Buenos Aires to become a professor of the School of Medicine where he taught in the fields of forensic medicine, gynecology and obstetrics. He was dean, or president, of a Buenos Aires medical faculty.\n\nMuñiz was a paleontologist, particularly interested in variances among fossils. Working as a physician at Lujan was of particular paleontological interest because of a famous find in 1788 of the \"Megatherium\", an immense ground sloth. He developed a collection that he intended to be used to create a natural history museum. The artifacts were sent (donated or possibly donated by force) to Juan Manuel de Rosas, the dictator of the Argentine Federation, whose support was required to establish a museum. Rosas, in an attempt to build alliances overseas, sent collected fossils to Jean Henri Dupotet, Rear Admiral of the French Navy. Dupotet then sent them to Paris. In France Muñiz collection ended up in the National Museum of Natural History where they were studied by Paul Gervais.\n\n\"Apuntes Toggraficos\", published in 1847 by Muñiz, contained his topographical notes that discussed the study of fossils in the relative ages of sedimentary strata in areas south of the Buenos Aires Province by naturalists, including Charles Darwin. Darwin began corresponding with Muñiz after reading his work on ñata cattle, indicative of the reputation that he was gaining as a naturalist. Domingo Sarmiento, who researched Muñiz's papers, commented on his influence to Darwin's theory of the origin of species.\nHe described a sabertooth, which he named \"Muni-felus Bonaerensis\", in \"Gaceta Mercantil\" in 1845. He sent his description to Darwin on 30 August 1846 for his comments. Darwin encouraged him to send specimens to France, which were received in Paris, apparently sent by Rosas. It was determined to be a \"Smilodon bonaerensis\".\n\nIn their book, \"From Man to Ape: Darwinism in Argentina,\" Novoa and Levine identify Muniz as the first important naturalist from Argentina, who donated his later collection of fossils to the Museum of Buenos Aires.\n\nHe was a legislator, elected first as a representative and then a senator.\n\nAfter having treated people with yellow fever during the great Buenos Aires epidemic, Muñiz succumbed to the illness and died on 8 April 1871. He was buried in the Cementerio de la Recoleta in Buenos Aires, Argentina. A monument was created in his honor by the city of Buenos Aires.\n\n\n"}
{"id": "3487818", "url": "https://en.wikipedia.org/wiki?curid=3487818", "title": "Hand pump", "text": "Hand pump\n\nHand pumps are manually operated pumps; they use human power and mechanical advantage to move fluids or air from one place to another. They are widely used in every country in the world for a variety of industrial, marine, irrigation and leisure activities. There are many different types of hand pump available, mainly operating on a piston, diaphragm or rotary vane principle with a check valve on the entry and exit ports to the chamber operating in opposing directions. Most hand pumps are either piston pumps or plunger pumps, and are positive displacement.\n\nHand pumps are commonly used in developing countries for both community supply and self-supply of water and can be installed on boreholes or hand-dug wells.\n\nOne sort of pump once common worldwide was a hand-powered water pump, or 'pitcher pump'. It was commonly installed over community water wells in the days before piped water supplies.\n\nIn parts of the British Isles, it was often called \"the parish pump\". Though such community pumps are no longer common, people still used the expression \"parish pump\" to describe a place or forum where matters of local interest are discussed.\n\nBecause water from pitcher pumps is drawn directly from the soil, it is more prone to contamination. If such water is not filtered and purified, consumption of it might lead to gastrointestinal or other water-borne diseases. A notorious case is the 1854 Broad Street cholera outbreak. At the time it was not known how cholera was transmitted, but physician John Snow suspected contaminated water and had the handle of the public pump he suspected removed; the outbreak then subsided.\n\nModern hand-operated community pumps are considered the most sustainable low-cost option for safe water supply in resource-poor settings, often in rural areas in developing countries. A hand pump opens access to deeper groundwater that is often not polluted and also improves the safety of a well by protecting the water source from contaminated buckets. Pumps such as the Afridev pump are designed to be cheap to build and install, and easy to maintain with simple parts. However, scarcity of spare parts for these type of pumps in some regions of Africa has diminished their utility for these areas.\n\nSuction and lift are important considerations when pumping fluids. Suction is the vertical distance between the fluid to be pumped and the centre of the pump, while lift is the vertical distance between the pump and the delivery point. The depth from which a hand pump will suck is limited by atmospheric pressure to an operating depth of less than 7 meters. The height to which a hand pump will lift is governed by the ability of the pump and the operator to lift the weight in the delivery pipe. Thus the same pump and operator will be able to achieve a greater lift with a smaller diameter pipe than they could with a larger diameter pipe.\n\nIn addition to their use in drawing water from shallow groundwater sources for water supplies, another version of the hand-powered suction pump, with low lift and high delivery, was developed in the later 19th century for use as a ship's bilge pump (for smaller coastal vessels) and as a building site contractor's pump. It was known as a deluge pump. One manufacturer who illustrated this product from the late 1880s onwards into the early 20th century was Goulds Manufacturing Co.\n\nWhere it is necessary to raise water to a height above that to which a suction or lift pump will operate effectively (about 7 metres), or to raise the pressure so that it will exit a nozzle with a strong force, such as through a fire hose, a force pump may be used. As with a suction pump, in its manual form it relies on an operator to pump a handle. The difference is however that after the water is sucked through the lower valve (as a result of raising the piston that is attached to the handle), its means of exit is via a pipe or nozzle in the side of the main cylinder. The water, once it has been drawn up above the lower valve and trapped there, is forced out the exit when the piston or plunger is pushed down again on the next stroke.\n\nA siphon (or syphon) at its simplest is a bent tube, with one end placed in the water to be moved, and the other end into the vessel to receive the water. The receiving vessel must be at a lower level than the supplying vessel. Water will always try to find its lowest level. Using this principle, very simple pumps with plastic or rubber bulb with flap valve at each end are used for emptying fuel or water cans into tanks. Once the bulb is full, the fluid will flow without further effort from the higher to the lower container. Many hand pumps will allow the passage of fluid through them in the direction of flow and diaphragm pumps are particularly good at this. Thus where the levels are correct large volumes of liquid such as swimming pools can be emptied with very little effort and no expensive energy use.\n\nA chain pump is made of an endless chain carrying a series of discs that descend into the water, and then ascend inside a tube, carrying with them a large quantity of water. They are a simply made,\nold hand-powered pumping technology In the 18th century they were used as ship's bilge pumps.\n\nDirect action hand pumps have a pumping rod that is moved up and down, directly by the user, discharging water. Direct action handpumps are easy to install and maintain but are limited to the\nmaximum column of water a person can physically lift of up to 15 m. Examples of direct action pumps include the canzee pump and the EMAS pump.\n\nDeep well hand pumps are used for high lifts of more than 15 m. The weight of the column of water is too great to be lifted directly and some form of mechanical advantage system such as a lever or flywheel is used.\nHigh lift pumps need to be stronger and sturdier to cope with the extra stresses. The installation, maintenance and repair of deep well hand pumps is more complicated than with other hand pumps.\n\nA deep well hand pump theoretically has no limit to which it can extract water. In practice, the depth is limited by the physical power a human being can exert in lifting the column of water, which is around 80 m.\n\nDiaphragm pumps have the advantage that they pump relatively lightly due to the lack of pulling rods and are corrosion resistant. Their disadvantage is that they need a specific length of tubing and high quality rubber diaphragms, which are costly and are relatively inefficient due to the extra work needed to deform the diaphragm.\n\nRubber diaphragms will eventually leak and need to be replaced. Because this is usually complicated and costly, diaphragm pumps operating in poor rural areas are often abandoned once the diaphragm wears out.\n\nProgressive cavity pumps consist of a single helix rotor inserted into a double helix stator. As the rotor is turned, the voids in the stator are screwed upwards along the axis of rotation. Progressive cavity pumps can have complicated gearing mechanisms and are difficult for local\npump technicians to maintain and repair.\n\nA rope and washer pump is a type of progressive cavity hand pump.\n\nThe range of lift of different types of hand pumps is given below:\n\nIn November 2002, the United Nations Committee on Economic, Social and Cultural Rights asserted that access to clean, safe water goes beyond the classification of water as an economic commodity. The committee stressed the fundamental right of sufficient access to clean water for both domestic and personal use. “The human right to water is indispensable for leading a life in human dignity.” With this in mind, manufacturers of water pumps, like those produced by GOAZ Development in Malaysia, have a wide range of potential customers: governments, non- governmental organizations, women’s groups, community groups and other organizations of various types interested to developing access to groundwater.\n\nVLOM, meaning Village Level Operation and Maintenance, is a term first used during the UNDP and World Bank Rural Water Supply Hand Pumps Project. This project lasted from 1981 to 1991, and studied the availability and maintenance of hand pump systems. 40 kinds of hand pumps were analyzed in laboratories, and the performance of 2700 hand pumps was analyzed in the field. The study established that centralized maintenance structure was a cause of many problems in hand pump programs, and that maintenance at the village level is best.\n\nThe VLOM concept was initially applied to hardware, with the following aims: the possibility of maintenance by village workers, having spare parts manufactured within the country to make sure spare parts are available, endurance in the field, and cost effectiveness. With time, more emphasis was placed on maintenance management. Thus, the “M” came to represent “management of maintenance.” Therefore, greater community choice of service, who will service, and financial accountability by the community to the caretakers of the pump have gained more importance within the VLOM concept.\n\nThe Swiss Centre Resource Centre and Consultancies for Development, Skat, continues to work on design and support structure for hand pump development as the host of Secretariat of the Rural Water Supply Network (RWSN).\n\nAn example of a Bank funded project that highlights many issues of hand pumps is the 1992 Mali Rural Supply Project. The project brought approximately 230 rural villages inclined towards periods of drought, and 228,000 people access to safe water. The project is notable in its attempt to bring responsibility for the upkeep of the pumps to the villages themselves. The complexity of the pumps is a fundamental problem for all programs of this kind, as well as the quality of the pumps given the heavy demands of a village. A 1994 study, also Bank funded, of the endurance of hand pumps in Africa showed that only 41 to 51 percent of hand pumps were still functioning. The Mali Rural Supply Project did positively affect the longevity of hand pumps by doing the following: establishing local depots of spare parts, training individuals to maintain pumps, scheduling inspections from officials of the project, forming local committees and recruiting volunteers.\n\nMuch attention has been given to the benefits of the use of hand pumps in developing nations, as opposed to more traditional methods. In communities reliant on groundwater, through a borehole or well, the utilization of a bucket and rope system has hygienic issues. The bucket and rope system is not compatible with the use of a cover slab, which can prevent pollution of groundwater. In addition, unwashed hands can contaminate the bucket and rope. Hand pumps avoid these issues and are therefore preferable.\n\nHowever, villagers did not stop using traditional means of gathering water during this project. This was especially true when rain provided villagers with shallow water sources. These shallow wells were often easier to access than the wells with hand pumps. When faced with the option of using near surface water or traveling to the hand pumps, many villagers chose the former.\n\nIn addition, animal contamination and the mixing of groundwater and surface water were factors in sub- par sanitation.\n\nAnother issue that faced the project was the fact that the pumps could only provide a maximum of 20 liters of water per person day, which required an unrealistic staggering of water retrieval. In addition, many depots withdrew support after the donated inventory ran out, the contracts given to consultants eventually closed, and maintenance was not kept up to a high standard.\n\nA June 2008 study, conducted by the World Bank, Review of Effectiveness of Rural Water Supply Schemes in India, showed that approximately 45 percent of rural piped water projects focused on breakdown maintenance instead of scheduled maintenance. In addition, about 20% were reported to be in “serious or somewhat serious neglect of maintenance.”\n\nWhether or not a project to use hand pumps in a developing country is an affordable alternative certainly depends on who or what organization pays the bill. However, the example of a 1992 Ethiopia aid project illustrates what the cost would be for the locals who benefit from the project. This example relates to isolated, rural communities in the rural South.\n\n165 Afridevs hand pumps were imported from India. Each cost approximately US$700, including clearing, transportation and installation. These pumps serve around 55 households each. At that time, the World Bank established that the average per capita income in Ethiopia was $120. A hand pump, first produced by researchers at the University of Waterloo and then refined at the University of Malaya, has been designed with local access to parts in mind. Materials readily available, like a rope covered in chicken fat or leather belt, can be used to ensure maintenance. GOAZ Development sells these pumps from $160 to $300. Therefore, 11% of one’s annual income would go towards accessing clean water. This is over twice as much as the 5% that the World Bank stated should be the maximum amount paid by a family.\n\n"}
{"id": "20208063", "url": "https://en.wikipedia.org/wiki?curid=20208063", "title": "Harry Tiebout", "text": "Harry Tiebout\n\nHarry M. Tiebout M.D. (2 January 1896 – 2 April 1966) was an American psychiatrist who promoted the Alcoholics Anonymous approach to the public, patients and fellow professionals. He served on the Board of Trustees of Alcoholics Anonymous from 1957–1966 and was president of the National Council on Alcoholism from 1951-1953.\n\nHarry Tiebout was raised in Brooklyn, New York. He earned his bachelor's degree at Wesleyan University in 1917, then went to Johns Hopkins University School of Medicine, where he also completed an internship with a specialization in psychiatry. The psychiatry service at Hopkins was led by Adolph Meyer, who had an eclectic approach in which Freudian theory was contributory but not dominant. John B. Watson was also at Hopkins during the time Tiebout was there, conducting research in behaviorism which would have substantial influence on the field of child development during the 1920s.\n\nTiebout was on the staff of New York Hospital, Westchester Division from 1922-24. He then began work in child guidance clinics in New York City, joining the Institute for Child Guidance as staff psychiatrist shortly after it was founded in 1927. The Institute was a well-funded center for training and research, dominated by psychoanalysis and specializing in \"exhaustive case histories 75 pages long.\" During these years Tiebout was also on the staff of Cornell Medical School and the Payne Whitney Psychiatric Clinic.\n\nIn 1935 he became medical director of Blythewood Sanitarium in Greenwich, Connecticut. Privately owned, Blythewood was situated on a beautiful, rustic estate once owned by Boss Tweed. At its peak, it had eight main buildings, eight cottages, a chapel, a building for occupational therapy, and a small golf course. There were no bars on the windows. Artistic and cultural pursuits were encouraged as part of the therapeutic program. Although the sanitarium was primarily for care of the mentally ill, it also provided care for alcoholics.\n\nIn 1939, Tiebout received a pre-publication copy of the book, \"Alcoholics Anonymous\". After looking it over, he gave it to one of his patients, Marty Mann. She had been at Blythewood for over a year but seemed no closer to conquering her alcohol problem than when she arrived, so he considered her a good test of whether the book had value. At first she read the book eagerly, delighted to know for the first time that there was a name (alcoholism) for what ailed her. However, she was soon repelled by the overbearingly religious message and told Tiebout that she could never accept it. Tiebout, according to Mann's biographers Sally and David Brown, quietly encouraged her to keep reading. Eventually taking the book to heart, she had an epiphany during a crisis of resentment and fury and was converted.\n\nOther references, also based on Mann's recollections, portray Tiebout's role a little differently. They describe an ongoing verbal battle lasting several months, in which Tiebout refused to accept Marty's rejection of the book. In the end, Mann did become an active member of AA and within a few years made education about alcoholism, and promotion of alcohol-abuse treatment, her second career. With Tiebout's support, she founded the National Council on Alcoholism (NCA).\n\nTiebout also became a friend and supporter of AA founder Bill Wilson, providing personal psychiatric care when Wilson developed depression in the 1940s. It was largely through Tiebout's influence that Bill Wilson was invited to speak at a New York state medical society meeting and then at a meeting of the American Psychiatric Association, and had his talk published in the \"American Journal of Psychiatry.\"\n\nTiebout had many years of training and experience in the management of alcohol problems before his first exposure to Alcoholics Anonymous. However, his earliest detailed article concerning alcoholism was published in 1944, 5 years into his relationship with AA, and is primarily a description of AA itself. Over the next 10 years he published a number of articles outlining his theories about alcoholism, the psychodynamic causes of the disorder and his reasons for endorsing AA as the definitive solution.\n\nHoward J. Clinebell, in a book for clergy on alcoholism counseling, recalled that Tiebout \"likened the 'runaway symptom' of alcoholism to the dangerously high fever of pneumonia. The fever is a \"symptom\" of the underlying infection, but unless it can be lowered, the person may die of the 'symptom\".\" Psychiatrists, Tiebout felt, had been ineffectual because they ignored the deadly symptom in an attempt to treat a (theoretical) underlying disease. He credited AA with an ability to target the symptom directly. Tiebout's understanding of the alcoholic mind cannot be entirely separated from his understanding of the 12-step approach, but the primary themes in his writings can be summed up under several points.\n\nIn one of his early papers Tiebout discounted the idea, common among psychoanalytically-inclined doctors, that there was a classic type of pre-alcoholic personality. In his view all of the personality characteristics associated with early alcoholism were manifestations of the tension state accompanying intermittent alcohol binges. These features included:\n\n\nHoward Clinebell understood Tiebout to mean that there was, in fact, a pre-alcoholic personality but that \"the distinctive factors have not yet been isolated\". In a 1947 lecture, Tiebout located the roots of alcoholism in poor parenting, either excessive strictness which caused the child to suffer \"perpetual frustration and blocking of his desires and expectations,\" or over-indulgence. Either way, \"Since the alcoholic's sense of self-discipline has not been developed at this point, his natural reaction is to reject all discipline. He now cannot face the realities of his existence. This would indicate that the whole point of treatment is to get the alcoholic to face and accept his limitations and capacities.\"\n\nThe concept of alcoholism which dominated treatment approaches in the second half of the 20th century, and is still influential today, defined alcoholism as a disease. The idea that alcohol problems constituted a disease was not new, but the particular synthesis associated initially with the Yale Center of Alcohol Studies (now at Rutgers) and the National Committee for Education on Alcoholism had unique features not found in earlier theories. The NCEA was one of Marty Mann's projects, and thus influenced by Tiebout. A 1990 Hazelden pamphlet cites Tiebout, Dr. William Silkworth and E.M. Jellinek as formative influences.\n\nTiebout seems to have been somewhat ambivalent about the disease model, however. In 1955, speaking of the scientific underpinnings of the alcoholism movement in general, he said \"I cannot help but feel that the whole field of alcoholism is way out on a limb which any minute will crack and drop us all in a frightful mess.\" He was consistent in his belief that the acceptance of alcoholism as a disease was essential, but this belief was partially pragmatic. In his experience, chronic alcoholics did not take the steps necessary to recover unless they became conscious of themselves as people with a disease. He emphasized a different aspect of the model in public lectures, however. Family members, friends and employers of alcoholics were encouraged to keep in mind that the condition was an illness and not a moral failing.\n\nIn a 1954 article Tiebout introduced a definition of the term \"ego\" which was to become important in his later writings, particularly those for AA audiences. Although his use of the term was new, the concept behind it had been developed by Tiebout during the early 1940s. In these early articles he was addressing a professional readership, and use of the term might have created confusion between the psychoanalytic meaning of ego and the colloquial \"ego\" which was Tiebout's essential meaning.\n\nBased on work with 250 alcoholics during his first 10 years at Blythewood, Tiebout developed the following conception of the alcoholic mind:\n\nUsing examples from dreams of patients he had analyzed, Tiebout presented evidence for the existence of this rigid barrier. As long as the barrier remained, \"As long as the self feels protected in a deep unconscious sense, it cannot be and is not disturbed by the warnings of reality, which characteristically roll like water off a duck's back.\" For the analyst,\n\nIn his 1954 article, 'The Ego Factors in Surrender in Alcoholism,' Tiebout began using the term \"ego\" to describe this concept of a self barricaded by defenses. He related it to Freud's \"His Majesty the Baby\" and to a similar concept introduced by Sandor Rado in 1933. Rado hypothesized that the elation induced by alcohol produced a reaction in the form of a \"tense depression\", which then reactivated the childish megalomania normally outgrown by adulthood. The result was a type of magical thinking in which \"the ego secretly compares its current helplessness with its original narcissistic stature . . and aspires to leave its tribulations and regain its old magnitude.\" Tiebout acknowledged his indebtedness to Rado's conception, while eliminating much of the psychoanalytic complexity of the original. He also felt that Rado was incorrect in advising only the \"reduction\" of the ego. Tiebout's view was that \"reduction\" represented a compromise and that there should be no compromise with the ego. The old ego should be eliminated entirely and replaced with a new one through \"surrender\".\n\nThe hallmark of Tiebout's work was his ability to explain 12 step ideas in psychoanalytic terms. The primary source for the steps was a religious movement popularized by Frank Buchman, with elements of the Higher Life movement tradition combined with the personal-evangelism techniques developed within the YMCA movement in the early 20th century. The Oxford Group had a successful program involving public and private meetings for witness and confession, as well as individual work. Their concept of \"surrender\" was the traditional Christian one, as a contemporary observer noted:\n\nConversion, surrender, confession, restitution and the necessity of evangelizing others were ideas brought from the Oxford Group to Alcoholics Anonymous by members who had found that the intense religious devotion they inspired was the key to a changed life. Tiebout understood the concepts in a more secular way, and approved of them.\n\nTiebout had found that superficial compliance in therapy often correlated with lack of real change, and he saw in the AA concept of surrender an antidote to this phenomenon. An act of surrender was the only cure, or practically the only one, to the problem of \"compliance\", or partial surrender to the psychiatrist's authority and the authority of the reality principle. Tiebout described true surrender as \"an unconscious event, not willed by the patient even if he or she should desire to do so. It can occur only when an individual with certain traits in his or her unconscious mind becomes involved in a certain set of circumstances,\" essentially the circumstances of \"hitting bottom\".\n\nConversion, for Tiebout, was a spiritual awakening made possible by the person's recognition of his own egocentricity. The central effect of Alcoholics Anonymous was \"to develop in the person a spiritual state which will serve as a direct neutralizing force upon the egocentric elements in the character of the alcoholic.\" A \"vague, groping, skeptical intellectual belief\" would not accomplish this but only a true emotional religious feeling, for \"unless the individual attains in the course of time a sense of the reality and the nearness of a Greater Power, his egocentric nature will reassert itself with undiminished intensity, and drinking will again enter into the picture.\"\n\nTiebout retired as medical director of Blythewood in 1950. The sanitarium was gradually changing into a long-term care facility for the elderly, with fewer psychiatric patients. He continued to see patients privately and kept up an active speaking schedule, as well as serving on the boards of various alcohol-related organizations. He died in Greenwich in 1966 of cardiac causes. He was the husband of the former Ethel Mills and father of Harry Tiebout, Jr., a philosophy professor; Charles Tiebout, an economics professor; and Sarah T. Worn.\n"}
{"id": "1242028", "url": "https://en.wikipedia.org/wiki?curid=1242028", "title": "Hyperandrogenism", "text": "Hyperandrogenism\n\nHyperandrogenism, also known as androgen excess, is a medical condition characterized by excessive levels of androgens (male sex hormones such as testosterone) in the female body and the associated effects of the elevated androgen levels. It is an endocrinological disorder similar to hyperestrogenism.\n\nThe most common conditions associated with hyperandrogenism are polycystic ovary syndrome or PCOS, a set of symptoms caused by androgen excess in females, and various cancers that can cause androgen excess. In females, the conditions usually present are some combination of acne, seborrhea (inflamed skin), hair loss on the scalp, increased body and/or facial hair (hirsutism), and an elevated sex drive or libido. The symptoms of hyperandrogenism are usually most effectively treated with antiandrogens. There is some controversy over whether hyperandrogenism provides an unfair advantage in athletics.\n\nHyperandrogenism affects 5-10% of females of reproductive age. Hyperandrogenism can affect both males and females, but is more noticeable in females due to the fact that elevated levels of androgens in females often facilitates virilization. Due to the fact that hyperandrogenism is characterized by the elevation of male sex hormone levels, symptoms of hyperandrogenism in men are often negligible. Hyperandrogenism in females is typically diagnosed in late adolescence with a medical evaluation. The medical evaluation tends to consist of a pelvic exam, observation of external symptoms, and a blood test measuring androgen levels.\n\nHyperandrogenism, especially high levels of testosterone, can cause serious adverse effects on women's bodies if left untreated. High testosterone levels have been seen to be associated with obesity, hypertension, amenorrhea (cessation of menstrual cycles), and ovulatory dysfunction, which can lead to infertility. The more prominent signs of hyperandrogenism are hirsutism (unwanted growth of hair especially in the abdominal region and places on the back), acne after adolescence, deepening of voice, and alopecia (balding).\n\nHyperandrogenism has also been seen to cause individuals to have a high tolerance to insulin, which can lead to type two diabetes, and dyslipidemia, such as high cholesterol. These effects have also been seen to have a large psychological impact on the individual, sometimes often leading to societal anxiety and depression, especially in adolescent girls and young women. Paired with obesity and hirsutism, it can cause the individual to have low self-esteem, and a poor view of oneself.\n\nEven though hyperandrogenism is not common in men, there have been studies done to look at the effects of high levels of testosterone in male bodies. A study has shown that even though many of the male participants did not have behavior changes due to the increased levels of testosterone, there were cases where the participants had instances of uncharacteristic aggression. High levels of testosterone in males have not been seen to have a direct impact on their personality, but within those studies, there have been cases of sudden aggression within the male participants.\n\nWhile hyperandrogenism in women is caused by external factors, it can also appear from natural causes.\n\nPolycystic ovary syndrome (PCOS) is an endocrine disorder characterized by an excess of androgens produced by the ovaries. It is estimated that approximately 90 percent of women with PCOS demonstrate hypersecretion of these hormones. A concrete cause for this condition is currently unknown. Speculations include genetic predisposition, although the gene or genes in particular have yet to be identified. Evidence suggests that the condition may have a hereditary basis. Other possible causes include the effects from an increase in insulin production. Insulin itself has been observed capable of inducing excess testosterone levels in the ovaries.\n\nElevated insulin concentration in the body leads to lower production of sex hormone binding globulin (SHBG), a regulatory glycoprotein that suppresses the function of androgens. High blood levels of insulin also work in conjunction with ovarian sensitivity to insulin to cause hyperandrogenemia, the primary symptom of PCOS. Obese individuals may be more biologically inclined to display PCOS due to markedly higher amounts of insulin in their bodies. This hormonal imbalance can lead to chronic anovulation, in which the ovaries experience difficulty releasing mature eggs. These cases of ovulatory dysfunction are linked to infertility and to menstrual disturbances.\n\nHyperthecosis occurs when the cells of the ovarian stroma transition from interstitial cells, which are cells located in between other cells, into luteinized theca cells. Theca cells are located in the ovarian follicles and become luteinized when the ovarian follicle breaks and a new corpus luteum is formed. The dispersal of luteinized theca cells throughout the ovarian stroma, in contrast to PCOS where the luteinized theca cells are only around cystic follicles, causes women with hyperthecosis to have higher testosterone levels and male-attributed characteristics (virilization) than women with PCOS. Excess levels of insulin in the blood, known as hyperinsulinemia, is also a characteristic of hyperthecosis. Hyperthecosis is mostly seen in postmenopausal women and is linked to acne, hirsutism, growth of the clitoris, baldness, and voice deepening.\n\nLow levels of insulin can also lead to hyperandrogenism. When the body's insulin levels drop too low, it can force itself to produce too much in an effort to make up for the loss. The result of such an overproduction is a disorder called hyperinsulinemia. An effect of hyperinsulinemia is the body's increased production of androgens in the ovaries. This is all part of HAIR-AN syndrome, a multisystem disorder that involves increased insulin levels that prompt increased androgen levels.\n\nCushing syndrome develops due to long-term exposure to the hormone cortisol. Cushing's syndrome can either be exogenous or endogenous, depending on whether it is caused by an external or internal source, respectively. The intake of glucocorticoids, which are a type of steroid hormone, is a common cause for the development of exogenous Cushing's syndrome. Endogenous Cushing's syndrome can occur when the body produces excessive amounts of cortisol. This occurs when the hypothalamus of the brain transmits corticotropin-releasing hormone (CRH) to the pituitary gland, which in turn secretes adrenocorticotropin hormone (ACTH). ACTH then causes the adrenal glands to release cortisol into the blood. Signs of Cushing's syndrome include muscle weakness, easy bruising, weight gain, male-pattern hair growth (hirsutism), colored stretch marks, and an excessively reddish complexion in the face. Cushing's syndrome has been shown to cause androgen excess, which directly links it to the signs and symptoms seen in hyperandrogenism.\n\nCongenital Adrenal Hyperplasia consists of a group of autosomal recessive disorders that cause a lack of an enzyme needed for producing cortisol and/or aldosterone, both of which are steroid hormones. Most cases of CAH are due to 21-hydroxylase deficiencies, an enzyme used by the body to produce cortisol and aldosterone. In females, CAH causes uncertainty in the genitals at birth and later on in adolescence excessive pubic hair, enlargement of the clitoris, hirsutism, and rapid growth of the body. Symptoms in males include early showings of pubic hair, enlargement of the penis, and rapid body and skeletal growth.\n\nA highly uncommon disease with incidence of 1–2 per million annually. This disease causes cancerous cells to form in the cortex of one or both of the adrenal glands. Adrenocortical tumors produce an additional number of hormones, often leading patients with steroid hormone-producing tumors to develop Cushing's syndrome, Conn syndrome and Hyperandrogenism.\n\nAdrenal Adenomas are benign tumors on the adrenal gland. In most cases the tumors display no symptoms and require no treatment. In rare cases, however, some Adrenal Adenomas may become activated, in that they begin to produce hormones in much larger quantities than what adrenal glands tend to produce leading to a number of health complications including Primary aldosteronism and Hyperandrogenism.\n\nAn arrhenoblastoma is an uncommon tumor of the ovary. It is often composed of sterol cells, leydig cells or some combination of the two. The tumor can produce male or female hormones in the patient and may cause masculinization. In a prepubescent child, a tumor may cause precocious puberty. Malignant Arrhenoblastoma accounts for 30% of all cases of Arrhenoblastoma, the other 70% being largely benign and curable with surgery.\n\nAn ovarian, Androgen producing tumor afflicting older women in most cases and often leading to the development of virilization. This tumor tends to occur around the region of the ovary where the blood vessels enter the organ otherwise known as the hilum. This type of tumor tends to be rather small in size and in most cases could be entirely removed and its symptoms reversed through surgery.\n\nA quickly developing malignant tumor that is normally found in one of or both ovaries. The tumor is caused by the transcoelomic spread. It primarily grows in the stomach and intestinal regions.\n\nOne such cause is the end of ovulation and the beginning of menopause. When the body transitions from ovulation to menopause, it stops releasing estrogen at faster rate than it stops releasing androgens. In some cases, estrogen levels can drop enough that there are substantially higher androgen levels leading to hyperandrogenism. A decrease in sex hormone levels while the free androgen index increases helps to aid this process, as well.\n\nSymptoms generally considered hyperandrogenic can also manifest as results of consuming certain drugs. This can happen according to one of five major mechanisms, namely the direct introduction of androgens to the body, the binding of the drug to androgen receptors and subsequent participation in androgenic action (as is the case with anabolic-androgenic steroids), the reduction of sex hormone-binding globulin plasma concentration that leads to a resulting increase in free testosterone, the interference with and alteration of the hypothalamic–pituitary–ovarian (HPO) axis, or the increase in release of adrenal androgens.\n\nBecause hyperandrogenism can appear as a symptom of numerous different genetic and medical conditions, it is difficult to make a general statement on whether hyperandrogenic symptoms can be passed from parent to offspring. However, a collection of the conditions with hyperandrogenic symptoms, including polycystic ovary syndrome, have been observed as hereditary in certain cases. One potential cause of polycystic ovary syndrome is maternal hyperandrogenism, where the hormonal irregularities of the mother can affect the development of the child during gestation, resulting in the passing of polycystic ovary syndrome from mother to child.\n\nFemale patients may show symptoms of hyperandrogenism in their early life, but physicians become more concerned when the patient is in her late teens or older.\n\nHyperandrogenism is most often diagnosed by checking for signs of hirsutism according to a standardized method that scores the range of excess hair growth.\n\nChecking medical history and a physical examination of symptoms are used for an initial diagnosis. Patient history assessed includes age at thelarche, adrenarche, and menarche; patterns of menstruation; obesity; reproductive history; and the start and advancement of hyperandrogenism symptoms. Patterns of menstruation are examined since irregular patterns may appear with hirsutism. Family history is also assessed for occurrences of hyperandrogenism symptoms or obesity in other family members.\n\nA laboratory test can also be done on the patient to evaluate levels of FSH, LH, DHEAS, prolactin, 17OHP, and total and free testosterone in the patient's blood. Abnormally high levels of any of these hormones help in diagnosing hyperandrogenism.\n\nSince risk factors are not known and vary among individuals with hyperandrogenism, there is no sure method to prevent this medical condition. Therefore, more longterm studies are needed first to find a cause for the condition before being able to find a sufficient method of prevention.\n\nHowever, there are a few things that can help avoid long-term medical issues related to hyperandrogenism like PCOS. Getting checked by a medical professional for hyperandrogenism; especially if one has a family history of the condition, irregular periods, or diabetes; can be beneficial. Watching your weight and diet is also important in decreasing your chances, especially in obese females, since continued exercise and maintaining a healthy diet leads to an improved menstrual cycle as well as to decreased insulin levels and androgen concentrations.\n\nTreatment of hyperandrogenism varies with the underlying condition that causes it. As a hormonal symptom of polycystic ovary syndrome, menopause, and other endocrine disorders, it is primarily treated as a symptom of these disorders. Systemically, it is treated with antiandrogens such as cyproterone acetate, flutamide and spironolactone to control the androgen levels in the patient's body. For Hyperandrogenism caused by Late-Onset Congenital Adrenal Hyperplasia (CAH), treatment is primarily focused on providing the patient with Glucocorticoids to combat the low cortisol production and the corresponding increase in androgens caused by the swelling of the Adrenal Glands. Oestrogen-based oral contraceptives are used to treat both CAH and PCOS caused hyperandrogenism. These hormonal treatments have been found to reduce the androgen excess and suppress adrenal androgen production and cause a significant decrease in hirsutism.\n\nHyperandrogenism is often managed symptomatically. Hirsutism and acne both respond well to the hormonal treatments described above, with 60-100% reporting an improvement in hirsutism. Androgenic alopecia however, does not show a significant improvement with hormonal treatments and requires other treatments, such as hair transplantation.\n\nBecause androgen excess is manifested in noticeable physical features (ex. hirsutism), a certain social stigma is associated with it. In the athletic world, multiple cases of female athletes being banned for their testosterone levels being too high have been recorded. Such social and cultural redefinitions of hyperandrogenism are important to consider outside of the clinical usage.\n\nFollowing the case of South African athlete Caster Semenya, the International Association of Athletics Federations (IAAF) introduced a now suspended policy to exclude women athletes from competing as women if they have hyperandrogenism, on the ground that the condition could confer an unfair advantage. The rules state that women may compete in the male category if their performance qualifies. The IAAF states that testosterone is linked to lean body mass(LBM), so it influences athletes' strength, speed and power.\n\nThe permissible testosterone limit was set at 10 nmol/L, based on a study of women competing in the World Championships in 2011 and 2013. 99% of the female athletes at those competitions had testosterone levels below 3.08 nmol/L. This upper limit of 10 nmol/L was more than 3 times higher than the testosterone levels of 99% of the elite female athletes in those competitions. However, a study of endocrine profiles in 693 elite athletes published in 2014 found that 13.7% of women athletes had high levels of testosterone, and 16.5% of men had low levels of testosterone levels. The authors noted that there is \"complete overlap between the sexes\", concluding, \"The IOC definition of a woman as one who has a ‘normal’ testosterone level is untenable.\"\n\nThe test has been controversial, with suggestions that it is discriminatory. There is evidence that women from developing countries have been subjected to partial clitoridectomies and gonadectomies following test results revealing hyperandrogenism. In September 2014, Dutee Chand, a sprinter from India who was barred by the IAAF from competing against other female runners, sought to appeal the ruling and asked for reinstatement. In July 2015, the Court of Arbitration for Sport suspended the IAAF ban, thus reinstating Chand's right to compete. The IAAF was given two years in which to file scientific evidence justifying the ban. In the absence of evidence, the ban will be declared void.\n\nThe suspension of the IAAF test for hyperandrogenism led to controversy in the Rio 2016 Olympic Games, in particular related to the participation and performance of South African middle distance runner Caster Semenya. Competitors Lynsey Sharp and Joanna Jóźwik spoke out about their belief that Semenya has a competitive advantage, Jóźwik reportedly claimed that she was the \"first European\" and \"second white\" to finish the race. Many bioethicists and gender equality advocates argue that preventing women with higher levels of testosterone from participating is a form of discrimination, penalizing the athlete for a natural trait of her body, much akin to the natural advantage possessed by taller basketball players or marathoners who train at higher altitudes.\n\nCultural variation can define hyperandrogenism socially—aside from clinical and chemical definitions—to make some hair growth unacceptable even if it is considered clinically normal based on metrics like the Ferriman-Gallwey score. For example, only pubic and axillary hair in North American women is tolerated, while other androgen-dependent hair such as growth on the upper lip, over the linea alba, over the thighs, and any periareolar hair is not.\n\nProfessional organizations like the Androgen Excess and PCOS Society exist to promote the research, treatment, diagnosis, and prevention of such disorders along with educating the public and scientific community about them.\n\n"}
{"id": "5515277", "url": "https://en.wikipedia.org/wiki?curid=5515277", "title": "Iridocorneal endothelial syndrome", "text": "Iridocorneal endothelial syndrome\n\nIridocorneal Endothelial (ICE) syndromes are a spectrum of diseases characteriezed by slowly progressive abnormalities of the corneal endothelium and features including corneal edema, iris distortion, and secondary angle-closure glaucoma. [1,2,4] ICE syndromes are predominantly unilateral and nonhereditary [1,2,4]. The condition occurs in predominantly middle-aged women [1,3,4].\n\nMany cases are asymptomatic, however patients many have decreased vision, glare, monocular diplopia or polyopia, and noticeable iris changes [2,6]. On exam patients have normal to decreased visual acuity, and a “beaten metal appearance” of the corneal endothelium, corneal edema, increased intraocular pressure, peripheral anterior synechiae, and iris changes [1,2,6].\n\nThe exact mechanism is unknown, however there appears to be a component of abnormal corneal endothelium that proliferates onto the iris forming a membrane that then obstructs the trabecular meshwork, leading to iris distortion [1,2]. Nodule formation can also occur when the abnormal corneal endothelium causes contractions around the iris stroma [1]. Herpesvirus DNA has been identified in some patients following keratoplasty, suggesting the possibility that herpes simplex virus may induce the abnormal endotheliazation in the anterior chamber angle and on the surface of the iris [2,3,5].\n\nThe Chandler variant of ICE is characterized by pathology on the inner surface of the cornea leading to abnormal endothelial pump function [2,6]. Other features include possible mild iris changes, corneal edema, and normal to slight elevations in intraocular pressure [1,6].\n\nCogan-Reese variant is characterized by multiple pigmented iris nodules [2,6]. This variant is most commonly unilateral and seen in middle-aged females [2].\n\nPenetrating karatoplasty and endothelial keratoplasty can be used as treatments for severe cases of ICE [2,8]. Because glaucoma and elevated intraocular pressure are often present in ICE patients, long term follow up may be needed to ensure adequate intraocular pressures are maintained [2,7]\n\nThe disease is chronic and often progresses slowly. Prognosis is generally poor when associated with glaucoma [1,2].\n\n[1] Friedman NJ, Kaiser PK, Pineda R. (2009). \"The Massachusetts Eye and Ear Infirmary Illustrated Manual of Ophthalmology\". Chapter 7: Iris and Pupils (pp. 285–287). Philadelphia PA:W.B. Saunders Company.\n\n[2] Weisenthal RW. \"2012-2013 Basic and Clinical Science Course, Section 8, Chapter 12: External Disease and Cornea\" (pp 344–345). San Francisco CA: American Academy of Ophthalmology The Eye M.D. Association.\n\n[3] Alvardo JA, Underwood JL, Green WR, et al. (1994) Detection of herpes simplex viral DNA in the iridocorneal endothelial syndrome. \"Archives of Ophthalmology, 112(12),\" 1601-1609\n\n[4] Carpel EF. (2005). \"Iridocorneal endothelial syndrome\". In: Krachmer JH, Mannis MJ, Holland EJ. \"Cornea.\" 2nd ed. Vol 1. Chapter 79 (pp 975–985). Philadelphia: Elsever/Mosby\n\n[5] Groh MJ, Seitz B, Schumacher S, Naumann GO. Detection of herpes simplex virus in aqueous humor in iridocorneal endothelial (ICE) syndrome. \"Cornea.\" 1999;18(3):359-360.\n\n[6] Herde J. Iridocorneal endothelial syndrome (ICE-S): classification, clinical picture, diagnosis. \"Klin Monatsbl Augenheilkd.\" 2005;222(10):797-801\n\n[7] Price MO, Price FW Jr. Descemet stripping with endothelial keratoplasty for treatment of iridocorneal endothelial syndrome. \"Cornea.\" 2007;26(4):493-497.\n\n"}
{"id": "34428476", "url": "https://en.wikipedia.org/wiki?curid=34428476", "title": "Jatigede Dam", "text": "Jatigede Dam\n\nThe Jatigede Dam is an embankment dam on the Cimanuk River in Sumedang Regency, West Java, Indonesia. It is located east of the town of Sumedang. Construction on the dam began in 2008 and it was completed in 2015. The power station is expected to be commissioned in 2019. The primary purpose of the dam is irrigation but it will also provide for flood control, water supply and hydroelectric power generation. Water in the reservoir will be used to help irrigate of farmland and the power station is expected to have a 110 MW capacity. The project has been become controversial, primarily due to the relocation of people in the future reservoir zone.\n\nThe dam was first proposed in 1963 after a study of the Cimanuk was carried out by Coyne et Bellier. Further planning and designs commenced thereafter. An environmental impact assessment was completed in 1986 and land acquisition study in 2003. After decades of planning and protests, the Indonesian Government announced firm plans to proceed with the dam in 2004.\n\nThe project has been surrounded with controversy over the years, particularly as its reservoir would flood of land. This includes five districts and 30 villages which include approximately 70,000 people to be relocated. Affected residents claim that compensation for their land is too low and that the government intimidated them to accept offers in the 1980s. In addition, a 2011 study by Indonesia's Ministry of Public Works estimated that the reservoir would become ineffective in 50 years due to high sedimentation of the river.\n\nDespite the controversy, the government stated in 2004 that an agreement had been reached. The contract to build the dam and power plant was awarded to China's Sinohydro Corporation in May 2007. Construction on the dam's diversion tunnel began in October 2008 and was completed in August 2011. The government announced in late 2011 that that dam was 60% complete. In July 2011, it was announced that Perusahaan Listrik Negara would oversee the construction and operation of the 110 MW power plant. The dam and power plant is expected to cost US$224 million. In May 2013 the government announced that the total cost would be around $400 million and that the dam was 70% complete. Currently, the dam was expected to start impounding its reservoir in early 2015. This major step in construction has been repeatedly delayed due to resident relocations.\n\nIn December 2014, a contract was signed with Sinohydro to construct the power station. It should be operational in 2019. On 31 August 2015, the dam began to impound its reservoir, 30 days behind the most recent schedule.\n\nThe Jatigede Dam will be a high and long rock-fill embankment dam. Its crest will be wide and the body will contain of fill. The dam's spillway will be a chute-type on the center of the downstream face. It will be controlled by four radial gates and have a discharge capacity of . The irrigation intake will be located below the spillway. The dam will withhold a reservoir with a storage capacity of which is active (or 'usable') for water supply and power generation. The reservoir's catchment area encompasses while the man-made lake will have a surface area of . The dam's crest elevation will be and the normal reservoir elevation . The intake for the power plant will be on the right abutment and will place water into a long head-race tunnel before reaching the power plant downstream. The power plant will contain two 55 MW Francis turbine-generators (total capacity 110 MW) with a design hydraulic head of .\n\n"}
{"id": "20286971", "url": "https://en.wikipedia.org/wiki?curid=20286971", "title": "John Dau Foundation", "text": "John Dau Foundation\n\nThe John Dau Foundation (JDF), also known as John Dau Sudan Foundation (JDSF) is a 501(c)(3) nonprofit that was established in July 2007 to develop health facilities that currently do not exist for most of the populations of Duk, Twic East and Bor South Counties in the State of Jonglei in South Sudan. Its mission is to \"transform healthcare in South Sudan.\" Currently, the organization’s primary focus is on funding and overseeing the Duk Lost Boys Clinic. The Duk Lost Boys Clinic specializes in the treatment of diseases such as guinea worm disease, malaria, chicken pox, diarrhea, malnourishment, bilharzias, h-worm, kalazar; the immunization of other diseases; and the provision of maternity services. The Foundation is headquartered in Syracuse, New York.\n\nJohn Dau also known as Dhieu Deng Leek is the founder and president of the John Dau Foundation. Dau is a survivor of the civil war in South Sudan and part of the exodus of the Lost Boys of Sudan who were forced to flee their families and homeland. Dau was featured in the award-winning documentary \"God Grew Tired of Us\" in 2006 which won the Grand Jury Prize and the Audience Award at the 2006 Sundance Film Festival.\n\nThe John Dau Foundation is governed by a ten-member Board of Directors that is headed by Bill Coplin, Director of the Public Affairs Department at Syracuse University. The organization’s Board of Advisors is made up of 15 members and includes Lopez Lomong, the Sudanese-born track and field athlete who carried the U.S. flag in the Opening Ceremony of the 2008 Beijing Olympics. He announced his support for JDF in September 2008 and shortly thereafter became a member of the organization’s Board of Advisors.\n\n\n\nJohn Dau has strong ties to local governmental officials in South Sudan. His uncle, Philip Thon Leek, who was a governor of the State of Jongeli and is now a Minister of Transport in the Government of National Unity, has been instrumental in providing contacts and support from the natives, Tribal Chiefs and the Sudanese Peoples Liberation Movements and its Health Ministry. The Foundation has received a commitment from the local government to provide support by the end of 2009 for the existing clinic. Although there is no guarantee that this will happen due to the government of South Sudan's financial constraint, it represents a viable strategy that will require less outside support to sustain what has been developed.\n\nIn June 2008, the American Care for Sudan Foundation (ACSF) announced that it would merge with JDF as its operational wing. ACSF was formed initially under the leadership of John Dau and the dedication and hard work of a group of members of the First Presbyterian Church of Skaneateles to build the Duk Lost Boys Clinic in Duk Payuel, South Sudan in early 2007.\n\nNotable contributions to the Duk Lost Boys Clinic and John Dau Foundation include $100,000 donated by Brad Pitt and Angelina Jolie (the Jolie-Pitt Foundation) in 2006; $50,000 by the Allyn Family of Welch Allyn in 2006; $25,000 by Volvo in 2008; and $100,000 by United Technologies Corporation in 2008.\n\n\n"}
{"id": "892195", "url": "https://en.wikipedia.org/wiki?curid=892195", "title": "MDA (TV series)", "text": "MDA (TV series)\n\nMDA is an Australian television series that aired between 2002 and 2005 on the Australian Broadcasting Corporation (ABC). It concerned the day-to-day operation of legal firm MDA, which specialised in medical defence.\n\nThe title refers to the firm Medical Defence Australia, a team of lawyers and doctors who defend doctors charged with malpractice, ranging from Botox injections gone wrong to spinal cord injuries. The firm operates by collecting annual subscriptions from doctors, rather than on a case-by-case fee basis.\n\nThe main characters in the pilot episode included Dr. Louella \"Ella\" Davis, the moral centre of the firm whose passion lies equally distributed between her work at St Albans Hospital Emergency Ward, and defending doctors; \"Happy\" Henderson, a lawyer whose nickname can be greatly misleading; Dr. Jamie Lawless, an optimistic young doctor whose passion for helping others often leads him to inner conflict; Caitlin King, the new law recruit at MDA whose ambitions far exceed what she can do at the firm; Layla Young of the Bahá'í faith, the friendly receptionist; Dr. Tony McKinnon, a doctor who works with Ella at the hospital; and Richard Savage - the cut-throat plaintiff's advocate who often does battles with MDA.\n\n\"MDA\" premiered in 2002 during a downturn in the making of Australian television. Despite critical acclaim and a number of awards, initially no renewal was made after the second season (2003). A year later, the ABC ordered another 12 episodes for 2005, but by this time several key actors had moved on. More multi-episode story arcs were used and critical response was lukewarm. Although sentiment eventually warmed, the series was not renewed after the third season.\n\nIn the opening episodes, Ella faced personal problems when her lover Nick wished to move out of the country, and she often discussed these with her sister Edwina, but those characters quickly faded into the background. Edwina did return, for one episode, in the second season.\n\nThe first episodes did not draw impressive ratings, and the critics were ambivalent, but by the eighth episode – \"Bowels, Bosch and the Whole Damn Thing\", in which Happy faced health problems – Jamie fell for Wendy Rossi, a doctor facing manslaughter, and Caitlin began to consider working with Richard instead of MDA – the show began to gain attention.\n\nOther notable characters of the first season were Helena, a prosecutor whose lack of ability often led to comic relief moments; Claudia, Richard's sardonic barrister; Giles, the amiable old barrister contracted to MDA; Dr Vince Phillips, a doctor on the MDA board whose desire to take over led to a legal battle; and Dr Mark Matthews, the head of the MDA board.\n\nIn the final episodes of the season, Ella and Tony became victims of a civil suit which led to them facing considerable press exposure. They were found not guilty, but in the final moments of the season finale, \"Divine intervention\", angry plaintiff Debbie Shanahan drove her car directly at Jamie, Tony and Ella, and the audience was left to wonder who had survived.\n\nAlthough the ratings had been average, \"MDA\" was granted a second season.\n\nThe second season improved markedly from the first season, tightening storylines and scripts. The season opened with the episode \"Eternity\" in which Tony died on the operating table, and Caitlin moved to Richard Savage's firm. Caitlin gets off to a bumpy start with the MDA when she becomes involved with Justin Harris (a man secretly under investigation for murder, played by Jeremy Callaghan). After Justin is cleared he feels that there is no trust in their relationship and leaves Caitlin.\n\nTwo new characters joined: Amanda McKay, a legal case manager; and Simon Lloyd, a doctor joining MDA. Amanda and Simon's relationship evolves as a will-they-or-won't-they? couple of the show, with the risk increased due to his wife who worked abroad. By season's end they were a couple, but were still easing into it.\n\nSignificant season two storylines included the destruction of Jamie and Wendy's relationship, Dr Phillips' increasing efforts to become head of MDA, and the potential destruction of MDA itself as he attempts to incite a revolution against the firm, Caitlin and Richard's personal and professional fighting, Layla's grandmother getting closer to death, and Happy dealing with his son Jason.\n\nIn the second half of the season, Caitlin was written out of the show, as the producers decided her character had run its course. Kerry Armstrong also decided to leave - because the low Government funding for the arts in Australia under the Howard conservative government (often criticised within the industry) meant that appearing on one television show was not a sustainable income. Ella, subsequently, took a full-time posting at St. Albans' as Head of Emergency and only appeared occasionally during the latter half of season 2, making her final appearance in the penultimate episode \"Pas de deux\".\n\nDespite increased audience size, critical response, and award nominations, the ABC made no official announcement of the show's renewal. The final episode, \"Memento Mori\", aired on 17 December 2003.\n\nWhile it was no surprise that the ABC did not make an immediate announcement about the show's fate - many Australian television series will often miss a year due to actor's schedules and production demands - it was eight months before an announcement was made. During this time, Jason Donovan and Felix Nobis both moved on to other projects.\n\nIn August 2004, the ABC finally announced its new commitment: a 12-episode order, which would air as three four-hour miniseries in 2005. While the order was small, the renewal meant that \"MDA\" was the only series to have started in 2002 which was still on the air as of 2005.\n\nThe third season began on 30 June 2005, and was greeted with lackluster ratings, despite an impressive guest cast. Critical response, initially negative, warmed as the season progressed, to the point where it was largely positive.\n\n\n\n\n\nThe ABC released online seven-day rental copies of series one and two under its ABC Digital label.\n\n\n"}
{"id": "8389", "url": "https://en.wikipedia.org/wiki?curid=8389", "title": "Major depressive disorder", "text": "Major depressive disorder\n\nMajor depressive disorder (MDD), also known simply as depression, is a mental disorder characterized by at least two weeks of low mood that is present across most situations. It is often accompanied by low self-esteem, loss of interest in normally enjoyable activities, low energy, and pain without a clear cause. People may also occasionally have false beliefs or see or hear things that others cannot. Some people have periods of depression separated by years in which they are normal, while others nearly always have symptoms present. Major depressive disorder can negatively affect a person's personal life, work life, or education, as well as sleeping, eating habits, and general health. Between 2–8% of adults with major depression die by suicide, and about 50% of people who die by suicide had depression or another mood disorder.\nThe cause is believed to be a combination of genetic, environmental, and psychological factors. Risk factors include a family history of the condition, major life changes, certain medications, chronic health problems, and substance abuse. About 40% of the risk appears to be related to genetics. The diagnosis of major depressive disorder is based on the person's reported experiences and a mental status examination. There is no laboratory test for major depression. Testing, however, may be done to rule out physical conditions that can cause similar symptoms. Major depression is more severe and lasts longer than sadness, which is a normal part of life. The United States Preventive Services Task Force (USPSTF) recommends screening for depression among those over the age 12, while a prior Cochrane review found that the routine use of screening questionnaires have little effect on detection or treatment.\nTypically, people are treated with counseling and antidepressant medication. Medication appears to be effective, but the effect may only be significant in the most severely depressed. It is unclear whether medications affect the risk of suicide. Types of counseling used include cognitive behavioral therapy (CBT) and interpersonal therapy. If other measures are not effective, electroconvulsive therapy (ECT) may be considered. Hospitalization may be necessary in cases with a risk of harm to self and may occasionally occur against a person's wishes.\nMajor depressive disorder affected approximately 216 million people (3% of the world's population) in 2015. The percentage of people who are affected at one point in their life varies from 7% in Japan to 21% in France. Lifetime rates are higher in the developed world (15%) compared to the developing world (11%). It causes the second most years lived with disability, after lower back pain. The most common time of onset is in a person's 20s and 30s. Females are affected about twice as often as males. The American Psychiatric Association added \"major depressive disorder\" to the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM-III) in 1980. It was a split of the previous depressive neurosis in the DSM-II, which also encompassed the conditions now known as dysthymia and adjustment disorder with depressed mood. Those currently or previously affected may be stigmatized.\n\nMajor depression significantly affects a person's family and personal relationships, work or school life, sleeping and eating habits, and general health. Its impact on functioning and well-being has been compared to that of other chronic medical conditions, such as diabetes.\n\nA person having a major depressive episode usually exhibits a very low mood, which pervades all aspects of life, and an inability to experience pleasure in activities that were formerly enjoyed. Depressed people may be preoccupied with, or ruminate over, thoughts and feelings of worthlessness, inappropriate guilt or regret, helplessness, hopelessness, and self-hatred. In severe cases, depressed people may have symptoms of psychosis. These symptoms include delusions or, less commonly, hallucinations, usually unpleasant. Other symptoms of depression include poor concentration and memory (especially in those with melancholic or psychotic features), withdrawal from social situations and activities, reduced sex drive, irritability, and thoughts of death or suicide. Insomnia is common among the depressed. In the typical pattern, a person wakes very early and cannot get back to sleep. Hypersomnia, or oversleeping, can also happen. Some antidepressants may also cause insomnia due to their stimulating effect.\n\nA depressed person may report multiple physical symptoms such as fatigue, headaches, or digestive problems; physical complaints are the most common presenting problem in developing countries, according to the World Health Organization's criteria for depression. Appetite often decreases, with resulting weight loss, although increased appetite and weight gain occasionally occur. Family and friends may notice that the person's behavior is either agitated or lethargic. Older depressed people may have cognitive symptoms of recent onset, such as forgetfulness, and a more noticeable slowing of movements. Depression often coexists with physical disorders common among the elderly, such as stroke, other cardiovascular diseases, Parkinson's disease, and chronic obstructive pulmonary disease.\n\nDepressed children may often display an irritable mood rather than a depressed one, and show varying symptoms depending on age and situation. Most lose interest in school and show a decline in academic performance. They may be described as clingy, demanding, dependent, or insecure. Diagnosis may be delayed or missed when symptoms are interpreted as \"normal moodiness.\"\n\nMajor depression frequently co-occurs with other psychiatric problems. The 1990–92 \"National Comorbidity Survey\" (US) reports that half of those with major depression also have lifetime anxiety and its associated disorders such as generalized anxiety disorder. Anxiety symptoms can have a major impact on the course of a depressive illness, with delayed recovery, increased risk of relapse, greater disability and increased suicide attempts. There are increased rates of alcohol and drug abuse and particularly dependence, and around a third of individuals diagnosed with ADHD develop comorbid depression. Post-traumatic stress disorder and depression often co-occur. Depression may also coexist with attention deficit hyperactivity disorder (ADHD), complicating the diagnosis and treatment of both. Depression is also frequently comorbid with alcohol abuse and personality disorders. Depression can also be exasperated during particular months (usually winter) for those with seasonal affective disorder.\n\nDepression and pain often co-occur. One or more pain symptoms are present in 65% of depressed patients, and anywhere from 5 to 85% of patients with pain will be suffering from depression, depending on the setting; there is a lower prevalence in general practice, and higher in specialty clinics. The diagnosis of depression is often delayed or missed, and the outcome can worsen if the depression is noticed but completely misunderstood.\n\nDepression is also associated with a 1.5- to 2-fold increased risk of cardiovascular disease, independent of other known risk factors, and is itself linked directly or indirectly to risk factors such as smoking and obesity. People with major depression are less likely to follow medical recommendations for treating and preventing cardiovascular disorders, which further increases their risk of medical complications. In addition, cardiologists may not recognize underlying depression that complicates a cardiovascular problem under their care.\n\nThe cause of major depressive disorder is unknown. The biopsychosocial model proposes that biological, psychological, and social factors all play a role in causing depression. The diathesis–stress model specifies that depression results when a preexisting vulnerability, or diathesis, is activated by stressful life events. The preexisting vulnerability can be either genetic, implying an interaction between nature and nurture, or schematic, resulting from views of the world learned in childhood.\n\nChildhood abuse, either physical, sexual or psychological, are all risk factors for depression, among other psychiatric issues that co-occur such as anxiety and drug abuse. Childhood trauma also correlates with severity of depression, lack of response to treatment and length of illness. However, some are more susceptible to developing mental illness such as depression after trauma, and various genes have been suggested to control susceptibility.\n\nThe 5-HTTLPR, or serotonin transporter promoter gene's short allele has been associated with increased risk of depression. However, since the 1990s, results have been inconsistent, with three recent reviews finding an effect and two finding none. Other genes that have been linked to a gene-environment interaction include CRHR1, FKBP5 and BDNF, the first two of which are related to the stress reaction of the HPA axis, and the latter of which is involved in neurogenesis. A 2018 study found 44 areas within the chromosomes that were linked to MDD.\n\nDepression may also come secondary to a chronic or terminal medical condition, such as HIV/AIDS or asthma, and may be labeled \"secondary depression.\" It is unknown whether the underlying diseases induce depression through effect on quality of life, of through shared etiologies (such as degeneration of the basal ganglia in Parkinson's disease or immune dysregulation in asthma). Depression may also be iatrogenic (the result of healthcare), such as drug-induced depression. Therapies associated with depression include interferons, beta-blockers, isotretinoin, contraceptives, cardiac agents, anticonvulsants, antimigraine drugs, antipsychotics, and hormonal agents such as gonadotropin-releasing hormone agonist. Drug abuse in early age is also associated with increased risk of developing depression later in life. Depression that occurs as a result of pregnancy is called postpartum depression, and is thought to be the result of hormonal changes associated with pregnancy. Seasonal affective disorder, a type of depression associated with seasonal changes in sunlight, is thought to be the result of decreased sunlight.\n\nThe pathophysiology of depression is not yet understood, but the current theories center around monoaminergic systems, the circadian rhythm, immunological dysfunction, HPA axis dysfunction and structural or functional abnormalities of emotional circuits.\n\nThe monoamine theory, derived from the efficacy of monoaminergic drugs in treating depression, was the dominant theory until recently. The theory postulates that insufficient activity of monoamine neurotransmitters is the primary cause of depression. Evidence for the monoamine theory comes from multiple areas. Firstly, acute depletion of tryptophan, a necessary precursor of serotonin, a monoamine, can cause depression in those in remission or relatives of depressed patients; this suggests that decreased serotonergic neurotransmission is important in depression. Secondly, the correlation between depression risk and polymorphisms in the 5-HTTLPR gene, which codes for serotonin receptors, suggests a link. Third, decreased size of the locus coeruleus, decreased activity of tyrosine hydroxylase, increased density of alpha-2 adrenergic receptor, and evidence from rat models suggest decreased adrenergic neurotransmission in depression. Furthermore, decreased levels of homovanillic acid, altered response to dextroamphetamine, responses of depressive symptoms to dopamine receptor agonists, decreased dopamine receptor D1 binding in the striatum, and polymorphism of dopamine receptor genes implicate dopamine, another monoamine, in depression. Lastly, increased activity of monoamine oxidase, which degrades monoamines, has been associated with depression. However, this theory is inconsistent with the fact that serotonin depletion does not cause depression in healthy persons, the fact that antidepressants instantly increase levels of monoamines but take weeks to work, and the existence of atypical antidepressants which can be effective despite not targeting this pathway. One proposed explanation for the therapeutic lag, and further support for the deficiency of monoamines, is a desensitization of self-inhibition in raphe nuclei by the increased serotonin mediated by antidepressants. However, disinhibition of the dorsal raphe has been proposed to occur as a result of \"decreased\" serotonergic activity in tryptophan depletion, resulting in a depressed state mediated by increased serotonin. Further countering the monoamine hypothesis is the fact that rats with lesions of the dorsal raphe are not more depressive that controls, the finding of increased jugular 5-HIAA in depressed patients that normalized with SSRI treatment, and the preference for carbohydrates in depressed patients. Already limited, the monoamine hypothesis has been further oversimplified when presented to the general public.\n\nImmune system abnormalities have been observed, including increased levels of cytokines involved in generating sickness behavior (which shares overlap with depression). The effectiveness of nonsteroidal anti-inflammatory drugs (NSAIDs) and cytokine inhibitors in treating depression, and normalization of cytokine levels after successful treatment further suggest immune system abnormalities in depression.\n\nHPA axis abnormalities have been suggested in depression given the association of CRHR1 with depression and the increased frequency of dexamethasone test non-suppression in depressed patients. However, this abnormality is not adequate as a diagnosis tool, because its sensitivity is only 44%. These stress-related abnormalities have been hypothesized to be the cause of hippocampal volume reductions seen in depressed patients. Furthermore, a meta-analysis yielded decreased dexamethasone suppression, and increased response to psychological stressors. Further abnormal results have been obscured with the cortisol awakening response, with increased response being associated with depression.\n\nTheories unifying neuroimaging findings have been proposed. The first model proposed is the \"Limbic Cortical Model\", which involves hyperactivity of the ventral paralimbic regions and hypoactivity of frontal regulatory regions in emotional processing. Another model, the \"Corito-Striatal model\", suggests that abnormalities of the prefrontal cortex in regulating striatal and subcortical structures results in depression. Another model proposes hyperactivity of salience structures in identifying negative stimuli, and hypoactivity of cortical regulatory structures resulting in a negative emotional bias and depression, consistent with emotional bias studies.\n\nA diagnostic assessment may be conducted by a suitably trained general practitioner, or by a psychiatrist or psychologist, who records the person's current circumstances, biographical history, current symptoms, and family history. The broad clinical aim is to formulate the relevant biological, psychological, and social factors that may be impacting on the individual's mood. The assessor may also discuss the person's current ways of regulating mood (healthy or otherwise) such as alcohol and drug use. The assessment also includes a mental state examination, which is an assessment of the person's current mood and thought content, in particular the presence of themes of hopelessness or pessimism, self-harm or suicide, and an absence of positive thoughts or plans. Specialist mental health services are rare in rural areas, and thus diagnosis and management is left largely to primary-care clinicians. This issue is even more marked in developing countries. The mental health examination may include the use of a rating scale such as the Hamilton Rating Scale for Depression, the Beck Depression Inventory or the Suicide Behaviors Questionnaire-Revised. The score on a rating scale alone is insufficient to diagnose depression to the satisfaction of the DSM or ICD, but it provides an indication of the severity of symptoms for a time period, so a person who scores above a given cut-off point can be more thoroughly evaluated for a depressive disorder diagnosis. Several rating scales are used for this purpose.\n\nPrimary-care physicians and other non-psychiatrist physicians have more difficulty with underrecognition and undertreatment of depression compared to psychiatric physicians, in part because of the physical symptoms that often accompany depression, in addition to many potential patient, provider, and system barriers. A review found that non-psychiatrist physicians miss about two-thirds of cases, though this has improved somewhat in more recent studies.\n\nBefore diagnosing a major depressive disorder, in general a doctor performs a medical examination and selected investigations to rule out other causes of symptoms. These include blood tests measuring TSH and thyroxine to exclude hypothyroidism; basic electrolytes and serum calcium to rule out a metabolic disturbance; and a full blood count including ESR to rule out a systemic infection or chronic disease. Adverse affective reactions to medications or alcohol misuse are often ruled out, as well. Testosterone levels may be evaluated to diagnose hypogonadism, a cause of depression in men. Vitamin D levels might be evaluated, as low levels of vitamin D have been associated with greater risk for depression.\n\nSubjective cognitive complaints appear in older depressed people, but they can also be indicative of the onset of a dementing disorder, such as Alzheimer's disease. Cognitive testing and brain imaging can help distinguish depression from dementia. A CT scan can exclude brain pathology in those with psychotic, rapid-onset or otherwise unusual symptoms. In general, investigations are not repeated for a subsequent episode unless there is a medical indication.\n\nNo biological tests confirm major depression. Biomarkers of depression have been sought to provide an objective method of diagnosis. There are several potential biomarkers, including brain-derived neurotrophic factor and various functional MRI (fMRI) techniques. One study developed a decision tree model of interpreting a series of fMRI scans taken during various activities. In their subjects, the authors of that study were able to achieve a sensitivity of 80% and a specificity of 87%, corresponding to a negative predictive value of 98% and a positive predictive value of 32% (positive and negative likelihood ratios were 6.15, 0.23, respectively). However, much more research is needed before these tests can be used clinically.\n\nThe most widely used criteria for diagnosing depressive conditions are found in the American Psychiatric Association's revised fourth edition of the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM-IV-TR), and the World Health Organization's \"International Statistical Classification of Diseases and Related Health Problems\" (ICD-10), which uses the name \"depressive episode\" for a single episode and \"recurrent depressive disorder\" for repeated episodes. The latter system is typically used in European countries, while the former is used in the US and many other non-European nations, and the authors of both have worked towards conforming one with the other.\n\nBoth DSM-IV-TR and ICD-10 mark out typical (main) depressive symptoms. ICD-10 defines three typical depressive symptoms (depressed mood, anhedonia, and reduced energy), two of which should be present to determine the depressive disorder diagnosis. According to DSM-IV-TR, there are two main depressive symptoms—depressed mood and anhedonia. At least one of these must be present to make a diagnosis of major depressive episode.\n\nMajor depressive disorder is classified as a mood disorder in DSM-IV-TR. The diagnosis hinges on the presence of single or recurrent major depressive episodes. Further qualifiers are used to classify both the episode itself and the course of the disorder. The category Depressive Disorder Not Otherwise Specified is diagnosed if the depressive episode's manifestation does not meet the criteria for a major depressive episode. The ICD-10 system does not use the term \"major depressive disorder\" but lists very similar criteria for the diagnosis of a depressive episode (mild, moderate or severe); the term \"recurrent\" may be added if there have been multiple episodes without mania.\n\nA major depressive episode is characterized by the presence of a severely depressed mood that persists for at least two weeks. Episodes may be isolated or recurrent and are categorized as mild (few symptoms in excess of minimum criteria), moderate, or severe (marked impact on social or occupational functioning). An episode with psychotic features—commonly referred to as \"psychotic depression\"—is automatically rated as severe. If the patient has had an episode of mania or markedly elevated mood, a diagnosis of bipolar disorder is made instead. Depression without mania is sometimes referred to as \"unipolar\" because the mood remains at one emotional state or \"pole\".\n\nDSM-IV-TR excludes cases where the symptoms are a result of bereavement, although it is possible for normal bereavement to evolve into a depressive episode if the mood persists and the characteristic features of a major depressive episode develop. The criteria have been criticized because they do not take into account any other aspects of the personal and social context in which depression can occur. In addition, some studies have found little empirical support for the DSM-IV cut-off criteria, indicating they are a diagnostic convention imposed on a continuum of depressive symptoms of varying severity and duration: Excluded are a range of related diagnoses, including dysthymia, which involves a chronic but milder mood disturbance; recurrent brief depression, consisting of briefer depressive episodes; minor depressive disorder, whereby only some symptoms of major depression are present; and adjustment disorder with depressed mood, which denotes low mood resulting from a psychological response to an identifiable event or stressor.\n\nThe DSM-IV-TR recognizes five further subtypes of MDD, called \"specifiers\", in addition to noting the length, severity and presence of psychotic features:\n\nIn 2016, the United States Preventive Services Task Force (USPSTF) recommended screening in the adult populations with evidence that it increases the detection of people with depression and with proper treatment improves outcomes. They recommend screening in those between the age of 12 to 18 as well.\n\nA Cochrane review from 2005 found screening programs do not significantly improve detection rates, treatment, or outcome.\n\nTo confirm major depressive disorder as the most likely diagnosis, other potential diagnoses must be considered, including dysthymia, adjustment disorder with depressed mood, or bipolar disorder. Dysthymia is a chronic, milder mood disturbance in which a person reports a low mood almost daily over a span of at least two years. The symptoms are not as severe as those for major depression, although people with dysthymia are vulnerable to secondary episodes of major depression (sometimes referred to as \"double depression\"). Adjustment disorder with depressed mood is a mood disturbance appearing as a psychological response to an identifiable event or stressor, in which the resulting emotional or behavioral symptoms are significant but do not meet the criteria for a major depressive episode. Bipolar disorder, also known as \"manic–depressive disorder\", is a condition in which depressive phases alternate with periods of mania or hypomania. Although depression is currently categorized as a separate disorder, there is ongoing debate because individuals diagnosed with major depression often experience some hypomanic symptoms, indicating a mood disorder continuum. Further differential diagnoses involve chronic fatigue syndrome.\n\nOther disorders need to be ruled out before diagnosing major depressive disorder. They include depressions due to physical illness, medications, and substance abuse. Depression due to physical illness is diagnosed as a mood disorder due to a general medical condition. This condition is determined based on history, laboratory findings, or physical examination. When the depression is caused by a medication, drug of abuse, or exposure to a toxin, it is then diagnosed as a specific mood disorder (previously called \"substance-induced mood disorder\" in the DSM-IV-TR).\n\nPreventative efforts may result in decreases in rates of the condition of between 22 and 38%. Eating large amounts of fish may also reduce the risk.\n\nBehavioral interventions, such as interpersonal therapy and cognitive-behavioral therapy, are effective at preventing new onset depression. Because such interventions appear to be most effective when delivered to individuals or small groups, it has been suggested that they may be able to reach their large target audience most efficiently through the Internet.\n\nHowever, an earlier meta-analysis found preventive programs with a competence-enhancing component to be superior to behavior-oriented programs overall, and found behavioral programs to be particularly unhelpful for older people, for whom social support programs were uniquely beneficial. In addition, the programs that best prevented depression comprised more than eight sessions, each lasting between 60 and 90 minutes, were provided by a combination of lay and professional workers, had a high-quality research design, reported attrition rates, and had a well-defined intervention.\n\nThe Netherlands mental health care system provides preventive interventions, such as the \"Coping with Depression\" course (CWD) for people with sub-threshold depression. The course is claimed to be the most successful of psychoeducational interventions for the treatment and prevention of depression (both for its adaptability to various populations and its results), with a risk reduction of 38% in major depression and an efficacy as a treatment comparing favorably to other psychotherapies.\n\nThe three most common treatments for depression are psychotherapy, medication, and electroconvulsive therapy. Psychotherapy is the treatment of choice (over medication) for people under 18. The UK National Institute for Health and Care Excellence (NICE) 2004 guidelines indicate that antidepressants should not be used for the initial treatment of mild depression, because the risk-benefit ratio is poor. The guidelines recommend that antidepressants treatment in combination with psychosocial interventions should be considered for:\n\nThe guidelines further note that antidepressant treatment should be continued for at least six months to reduce the risk of relapse, and that SSRIs are better tolerated than tricyclic antidepressants.\n\nAmerican Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors including severity of symptoms, co-existing disorders, prior treatment experience, and patient preference. Options may include pharmacotherapy, psychotherapy, exercise, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. Antidepressant medication is recommended as an initial treatment choice in people with mild, moderate, or severe major depression, and should be given to all patients with severe depression unless ECT is planned. There is evidence that collaborative care by a team of health care practitioners produces better results than routine single-practitioner care.\n\nTreatment options are much more limited in developing countries, where access to mental health staff, medication, and psychotherapy is often difficult. Development of mental health services is minimal in many countries; depression is viewed as a phenomenon of the developed world despite evidence to the contrary, and not as an inherently life-threatening condition. A 2014 Cochrane review found insufficient evidence to determine the effectiveness of psychological versus medical therapy in children.\n\nPhysical exercise is recommended for management of mild depression, and has a moderate effect on symptoms. Exercise has also been found to be effective for (unipolar) major depression. It is equivalent to the use of medications or psychological therapies in most people. In older people it does appear to decrease depression. Exercise may be recommended to people who are willing, motivated, and physically healthy enough to participate in an exercise program as treatment.\n\nThere is a small amount of evidence that skipping a night's sleep may improve depressive symptoms, with the effects usually showing up within a day. This effect is usually temporary. Besides sleepiness, this method can cause a side effect of mania or hypomania.\n\nIn observational studies, smoking cessation has benefits in depression as large as or larger than those of medications.\n\nBesides exercise, sleep and diet may play a role in depression, and interventions in these areas may be an effective add-on to conventional methods.\n\nPsychotherapy can be delivered to individuals, groups, or families by mental health professionals. A 2015 review found that cognitive behavioral therapy appears to be similar to antidepressant medication in terms of effect. A 2012 review found psychotherapy to be better than no treatment but not other treatments. With more complex and chronic forms of depression, a combination of medication and psychotherapy may be used. A 2014 Cochrane review found that work-directed interventions combined with clinical interventions helped to reduce sick days taken by people with depression. There is moderate-quality evidence that psychological therapies are a useful addition to standard antidepressant treatment of treatment-resistant depression in the short term.\n\nPsychotherapy has been shown to be effective in older people. Successful psychotherapy appears to reduce the recurrence of depression even after it has been terminated or replaced by occasional booster sessions.\n\nCognitive behavioral therapy (CBT) currently has the most research evidence for the treatment of depression in children and adolescents, and CBT and interpersonal psychotherapy (IPT) are preferred therapies for adolescent depression. In people under 18, according to the National Institute for Health and Clinical Excellence, medication should be offered only in conjunction with a psychological therapy, such as CBT, interpersonal therapy, or family therapy. Cognitive behavioral therapy has also been shown to reduce the number of sick days taken by people with depression, when used in conjunction with primary care.\n\nThe most-studied form of psychotherapy for depression is CBT, which teaches clients to challenge self-defeating, but enduring ways of thinking (cognitions) and change counter-productive behaviors. Research beginning in the mid-1990s suggested that CBT could perform as well as or better than antidepressants in patients with moderate to severe depression. CBT may be effective in depressed adolescents, although its effects on severe episodes are not definitively known. Several variables predict success for cognitive behavioral therapy in adolescents: higher levels of rational thoughts, less hopelessness, fewer negative thoughts, and fewer cognitive distortions. CBT is particularly beneficial in preventing relapse.\n\nCognitive behavioral therapy and occupational programs (including modification of work activities and assistance) have been shown to be effective in reducing sick days taken by workers with depression.\n\nSeveral variants of cognitive behavior therapy have been used in those with depression, the most notable being rational emotive behavior therapy, and mindfulness-based cognitive therapy. Mindfulness-based stress reduction programs may reduce depression symptoms. Mindfulness programs also appear to be a promising intervention in youth.\n\nPsychoanalysis is a school of thought, founded by Sigmund Freud, which emphasizes the resolution of unconscious mental conflicts. Psychoanalytic techniques are used by some practitioners to treat clients presenting with major depression. A more widely practiced therapy, called psychodynamic psychotherapy, is in the tradition of psychoanalysis but less intensive, meeting once or twice a week. It also tends to focus more on the person's immediate problems, and has an additional social and interpersonal focus. In a meta-analysis of three controlled trials of Short Psychodynamic Supportive Psychotherapy, this modification was found to be as effective as medication for mild to moderate depression.\n\nConflicting results have arisen from studies that look at the effectiveness of antidepressants in people with acute, mild to moderate depression. Stronger evidence supports the usefulness of antidepressants in the treatment of depression that is chronic (dysthymia) or severe.\n\nWhile small benefits were found, researchers Irving Kirsch and Thomas Moore state they may be due to issues with the trials rather than a true effect of the medication. In a later publication, Kirsch concluded that the overall effect of new-generation antidepressant medication is below recommended criteria for clinical significance. Similar results were obtained in a meta-analysis by Fornier.\n\nA review commissioned by the National Institute for Health and Care Excellence (UK) concluded that there is strong evidence that selective serotonin reuptake inhibitors (SSRIs), such as escitalopram, paroxetine, and sertraline, have greater efficacy than placebo on achieving a 50% reduction in depression scores in moderate and severe major depression, and that there is some evidence for a similar effect in mild depression. Similarly, a Cochrane systematic review of clinical trials of the generic tricyclic antidepressant amitriptyline concluded that there is strong evidence that its efficacy is superior to placebo.\n\nIn 2014 the U.S. Food and Drug Administration published a systematic review of all antidepressant maintenance trials submitted to the agency between 1985 and 2012. The authors concluded that maintenance treatment reduced the risk of relapse by 52% compared to placebo, and that this effect was primarily due to recurrent depression in the placebo group rather than a drug withdrawal effect.\n\nTo find the most effective antidepressant medication with minimal side-effects, the dosages can be adjusted, and if necessary, combinations of different classes of antidepressants can be tried. Response rates to the first antidepressant administered range from 50–75%, and it can take at least six to eight weeks from the start of medication to remission. Antidepressant medication treatment is usually continued for 16 to 20 weeks after remission, to minimize the chance of recurrence, and even up to one year of continuation is recommended. People with chronic depression may need to take medication indefinitely to avoid relapse.\n\nSSRIs are the primary medications prescribed, owing to their relatively mild side-effects, and because they are less toxic in overdose than other antidepressants. People who do not respond to one SSRI can be switched to another antidepressant, and this results in improvement in almost 50% of cases. Another option is to switch to the atypical antidepressant bupropion. Venlafaxine, an antidepressant with a different mechanism of action, may be modestly more effective than SSRIs. However, venlafaxine is not recommended in the UK as a first-line treatment because of evidence suggesting its risks may outweigh benefits, and it is specifically discouraged in children and adolescents.\nFor children, some research has supported the use of the SSRI antidepressant fluoxetine. The benefit however appears to be slight in children, while other antidepressants have not been shown to be effective. Medications are not recommended in children with mild disease. There is also insufficient evidence to determine effectiveness in those with depression complicated by dementia. Any antidepressant can cause low blood sodium levels; nevertheless, it has been reported more often with SSRIs. It is not uncommon for SSRIs to cause or worsen insomnia; the sedating atypical antidepressant mirtazapine can be used in such cases.\n\nIrreversible monoamine oxidase inhibitors, an older class of antidepressants, have been plagued by potentially life-threatening dietary and drug interactions. They are still used only rarely, although newer and better-tolerated agents of this class have been developed. The safety profile is different with reversible monoamine oxidase inhibitors, such as moclobemide, where the risk of serious dietary interactions is negligible and dietary restrictions are less strict.\nFor children, adolescents, and probably young adults between 18 and 24 years old, there is a higher risk of both suicidal ideations and suicidal behavior in those treated with SSRIs. For adults, it is unclear whether SSRIs affect the risk of suicidality. One review found no connection; another an increased risk; and a third no risk in those 25–65 years old and a decreased risk in those more than 65. A black box warning was introduced in the United States in 2007 on SSRIs and other antidepressant medications due to the increased risk of suicide in patients younger than 24 years old. Similar precautionary notice revisions were implemented by the Japanese Ministry of Health.\n\nThere is some evidence that omega-3 fatty acids fish oil supplements containing high levels of eicosapentaenoic acid (EPA) to docosahexaenoic acid (DHA) are effective in the treatment of, but not the prevention of major depression. However, a Cochrane review determined there was insufficient high quality evidence to suggest omega-3 fatty acids were effective in depression. There is limited evidence that vitamin D supplementation is of value in alleviating the symptoms of depression in individuals who are vitamin D-deficient. There is some preliminary evidence that COX-2 inhibitors, such as celecoxib, have a beneficial effect on major depression. Lithium appears effective at lowering the risk of suicide in those with bipolar disorder and unipolar depression to nearly the same levels as the general population. There is a narrow range of effective and safe dosages of lithium thus close monitoring may be needed. Low-dose thyroid hormone may be added to existing antidepressants to treat persistent depression symptoms in people who have tried multiple courses of medication. Limited evidence suggests stimulants, such as amphetamine and modafinil, may be effective in the short term, or as adjuvant therapy. Also, it is suggested that folate supplements may have a role in depression management.\n\nElectroconvulsive therapy (ECT) is a standard psychiatric treatment in which seizures are electrically induced in patients to provide relief from psychiatric illnesses. ECT is used with informed consent as a last line of intervention for major depressive disorder.\n\nA round of ECT is effective for about 50% of people with treatment-resistant major depressive disorder, whether it is unipolar or bipolar. Follow-up treatment is still poorly studied, but about half of people who respond relapse within twelve months.\n\nAside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia. Immediately following treatment, the most common adverse effects are confusion and memory loss. ECT is considered one of the least harmful treatment options available for severely depressed pregnant women.\n\nA usual course of ECT involves multiple administrations, typically given two or three times per week, until the patient is no longer suffering symptoms. ECT is administered under anesthesia with a muscle relaxant. Electroconvulsive therapy can differ in its application in three ways: electrode placement, frequency of treatments, and the electrical waveform of the stimulus. These three forms of application have significant differences in both adverse side effects and symptom remission. After treatment, drug therapy is usually continued, and some patients receive maintenance ECT.\n\nECT appears to work in the short term via an anticonvulsant effect mostly in the frontal lobes, and longer term via neurotrophic effects primarily in the medial temporal lobe.\n\nTranscranial magnetic stimulation (TMS) or deep transcranial magnetic stimulation is a noninvasive method used to stimulate small regions of the brain. TMS was approved by the FDA for treatment-resistant major depressive disorder (trMDD) in 2008 and as of 2014 evidence supports that it is probably effective. The American Psychiatric Association the Canadian Network for Mood and Anxiety Disorders, and the Royal Australia and New Zealand College of Psychiatrists have endorsed TMS for trMDD.\n\nBright light therapy reduces depression symptom severity, with benefit for both seasonal affective disorder and for nonseasonal depression, and an effect similar to those for conventional antidepressants. For nonseasonal depression, adding light therapy to the standard antidepressant treatment was not effective. For nonseasonal depression, where light was used mostly in combination with antidepressants or wake therapy, a moderate effect was found, with response better than control treatment in high-quality studies, in studies that applied morning light treatment, and with people who respond to total or partial sleep deprivation. Both analyses noted poor quality, short duration, and small size of most of the reviewed studies. There is insufficient evidence for Reiki and dance movement therapy in depression.\n\nMajor depressive episodes often resolve over time whether or not they are treated. Outpatients on a waiting list show a 10–15% reduction in symptoms within a few months, with approximately 20% no longer meeting the full criteria for a depressive disorder. The median duration of an episode has been estimated to be 23 weeks, with the highest rate of recovery in the first three months.\n\nStudies have shown that 80% of those suffering from their first major depressive episode will suffer from at least one more during their life, with a lifetime average of 4 episodes. Other general population studies indicate that around half those who have an episode recover (whether treated or not) and remain well, while the other half will have at least one more, and around 15% of those experience chronic recurrence. Studies recruiting from selective inpatient sources suggest lower recovery and higher chronicity, while studies of mostly outpatients show that nearly all recover, with a median episode duration of 11 months. Around 90% of those with severe or psychotic depression, most of whom also meet criteria for other mental disorders, experience recurrence.\n\nA high proportion of people who experience full symptomatic remission still have at least one not fully resolved symptom after treatment. Recurrence or chronicity is more likely if symptoms have not fully resolved with treatment. Current guidelines recommend continuing antidepressants for four to six months after remission to prevent relapse. Evidence from many randomized controlled trials indicate continuing antidepressant medications after recovery can reduce the chance of relapse by 70% (41% on placebo vs. 18% on antidepressant). The preventive effect probably lasts for at least the first 36 months of use.\n\nPeople experiencing repeated episodes of depression require ongoing treatment in order to prevent more severe, long-term depression. In some cases, people must take medications for the rest of their lives.\n\nCases when outcome is poor are associated with inappropriate treatment, severe initial symptoms including psychosis, early age of onset, previous episodes, incomplete recovery after one year of treatment, pre-existing severe mental or medical disorder, and family dysfunction.\n\nDepressed individuals have a shorter life expectancy than those without depression, in part because depressed patients are at risk of dying of suicide. However, they also have a higher rate of dying from other causes, being more susceptible to medical conditions such as heart disease. Up to 60% of people who die of suicide have a mood disorder such as major depression, and the risk is especially high if a person has a marked sense of hopelessness or has both depression and borderline personality disorder. The lifetime risk of suicide associated with a diagnosis of major depression in the US is estimated at 3.4%, which averages two highly disparate figures of almost 7% for men and 1% for women (although suicide attempts are more frequent in women). The estimate is substantially lower than a previously accepted figure of 15%, which had been derived from older studies of hospitalized patients.\n\nDepression is often associated with unemployment and poverty. Major depression is currently the leading cause of disease burden in North America and other high-income countries, and the fourth-leading cause worldwide. In the year 2030, it is predicted to be the second-leading cause of disease burden worldwide after HIV, according to the WHO. Delay or failure in seeking treatment after relapse and the failure of health professionals to provide treatment are two barriers to reducing disability.\n\nMajor depressive disorder affects approximately 216 million people in 2015 (3% of the global population). The percentage of people who are affected at one point in their life varies from 7% in Japan to 21% in France. In most countries the number of people who have depression during their lives falls within an 8–18% range. In North America, the probability of having a major depressive episode within a year-long period is 3–5% for males and 8–10% for females. Major depression is about twice as common in women as in men, although it is unclear why this is so, and whether factors unaccounted for are contributing to this. The relative increase in occurrence is related to pubertal development rather than chronological age, reaches adult ratios between the ages of 15 and 18, and appears associated with psychosocial more than hormonal factors. Depression is a major cause of disability worldwide.\n\nPeople are most likely to develop their first depressive episode between the ages of 30 and 40, and there is a second, smaller peak of incidence between ages 50 and 60. The risk of major depression is increased with neurological conditions such as stroke, Parkinson's disease, or multiple sclerosis, and during the first year after childbirth. It is also more common after cardiovascular illnesses, and is related more to those with a poor cardiac disease outcome than to a better one. Studies conflict on the prevalence of depression in the elderly, but most data suggest there is a reduction in this age group. Depressive disorders are more common in urban populations than in rural ones and the prevalence is increased in groups with poorer socioeconomic factors, e.g., homelessness.\n\nThe Ancient Greek physician Hippocrates described a syndrome of melancholia as a distinct disease with particular mental and physical symptoms; he characterized all \"fears and despondencies, if they last a long time\" as being symptomatic of the ailment. It was a similar but far broader concept than today's depression; prominence was given to a clustering of the symptoms of sadness, dejection, and despondency, and often fear, anger, delusions and obsessions were included.\n\nThe term \"depression\" itself was derived from the Latin verb \"deprimere\", \"to press down\". From the 14th century, \"to depress\" meant to subjugate or to bring down in spirits. It was used in 1665 in English author Richard Baker's \"Chronicle\" to refer to someone having \"a great depression of spirit\", and by English author Samuel Johnson in a similar sense in 1753. The term also came into use in physiology and economics. An early usage referring to a psychiatric symptom was by French psychiatrist Louis Delasiauve in 1856, and by the 1860s it was appearing in medical dictionaries to refer to a physiological and metaphorical lowering of emotional function. Since Aristotle, melancholia had been associated with men of learning and intellectual brilliance, a hazard of contemplation and creativity. The newer concept abandoned these associations and through the 19th century, became more associated with women.\nAlthough \"melancholia\" remained the dominant diagnostic term, \"depression\" gained increasing currency in medical treatises and was a synonym by the end of the century; German psychiatrist Emil Kraepelin may have been the first to use it as the overarching term, referring to different kinds of melancholia as \"depressive states\".\n\nSigmund Freud likened the state of melancholia to mourning in his 1917 paper \"Mourning and Melancholia\". He theorized that objective loss, such as the loss of a valued relationship through death or a romantic break-up, results in subjective loss as well; the depressed individual has identified with the object of affection through an unconscious, narcissistic process called the \"libidinal cathexis\" of the ego. Such loss results in severe melancholic symptoms more profound than mourning; not only is the outside world viewed negatively but the ego itself is compromised. The patient's decline of self-perception is revealed in his belief of his own blame, inferiority, and unworthiness. He also emphasized early life experiences as a predisposing factor. Adolf Meyer put forward a mixed social and biological framework emphasizing \"reactions\" in the context of an individual's life, and argued that the term \"depression\" should be used instead of \"melancholia\". The first version of the DSM (DSM-I, 1952) contained \"depressive reaction\" and the DSM-II (1968) \"depressive neurosis\", defined as an excessive reaction to internal conflict or an identifiable event, and also included a depressive type of manic-depressive psychosis within Major affective disorders.\n\nIn the mid-20th century, researchers theorized that depression was caused by a chemical imbalance in neurotransmitters in the brain, a theory based on observations made in the 1950s of the effects of reserpine and isoniazid in altering monoamine neurotransmitter levels and affecting depressive symptoms. The chemical imbalance theory has never been proven.\n\nThe term \"unipolar\" (along with the related term \"bipolar\") was coined by the neurologist and psychiatrist Karl Kleist, and subsequently used by his disciples Edda Neele and Karl Leonhard.\n\nThe term \"Major depressive disorder\" was introduced by a group of US clinicians in the mid-1970s as part of proposals for diagnostic criteria based on patterns of symptoms (called the \"Research Diagnostic Criteria\", building on earlier Feighner Criteria), and was incorporated into the DSM-III in 1980. To maintain consistency the ICD-10 used the same criteria, with only minor alterations, but using the DSM diagnostic threshold to mark a \"mild depressive episode\", adding higher threshold categories for moderate and severe episodes. The ancient idea of \"melancholia\" still survives in the notion of a melancholic subtype.\n\nThe new definitions of depression were widely accepted, albeit with some conflicting findings and views. There have been some continued empirically based arguments for a return to the diagnosis of melancholia. There has been some criticism of the expansion of coverage of the diagnosis, related to the development and promotion of antidepressants and the biological model since the late 1950s.\n\nThe term \"depression\" is used in a number of different ways. It is often used to mean this syndrome but may refer to other mood disorders or simply to a low mood. People's conceptualizations of depression vary widely, both within and among cultures. \"Because of the lack of scientific certainty,\" one commentator has observed, \"the debate over depression turns on questions of language. What we call it—'disease,' 'disorder,' 'state of mind'—affects how we view, diagnose, and treat it.\" There are cultural differences in the extent to which serious depression is considered an illness requiring personal professional treatment, or is an indicator of something else, such as the need to address social or moral problems, the result of biological imbalances, or a reflection of individual differences in the understanding of distress that may reinforce feelings of powerlessness, and emotional struggle.\n\nThe diagnosis is less common in some countries, such as China. It has been argued that the Chinese traditionally deny or somatize emotional depression (although since the early 1980s, the Chinese denial of depression may have modified). Alternatively, it may be that Western cultures reframe and elevate some expressions of human distress to disorder status. Australian professor Gordon Parker and others have argued that the Western concept of depression \"medicalizes\" sadness or misery. Similarly, Hungarian-American psychiatrist Thomas Szasz and others argue that depression is a metaphorical illness that is inappropriately regarded as an actual disease. There has also been concern that the DSM, as well as the field of descriptive psychiatry that employs it, tends to reify abstract phenomena such as depression, which may in fact be social constructs. American archetypal psychologist James Hillman writes that depression can be healthy for the soul, insofar as \"it brings refuge, limitation, focus, gravity, weight, and humble powerlessness.\" Hillman argues that therapeutic attempts to eliminate depression echo the Christian theme of resurrection, but have the unfortunate effect of demonizing a soulful state of being.\n\nHistorical figures were often reluctant to discuss or seek treatment for depression due to social stigma about the condition, or due to ignorance of diagnosis or treatments. Nevertheless, analysis or interpretation of letters, journals, artwork, writings, or statements of family and friends of some historical personalities has led to the presumption that they may have had some form of depression. People who may have had depression include English author Mary Shelley, American-British writer Henry James, and American president Abraham Lincoln. Some well-known contemporary people with possible depression include Canadian songwriter Leonard Cohen and American playwright and novelist Tennessee Williams. Some pioneering psychologists, such as Americans William James and John B. Watson, dealt with their own depression.\n\nThere has been a continuing discussion of whether neurological disorders and mood disorders may be linked to creativity, a discussion that goes back to Aristotelian times. British literature gives many examples of reflections on depression. English philosopher John Stuart Mill experienced a several-months-long period of what he called \"a dull state of nerves\", when one is \"unsusceptible to enjoyment or pleasurable excitement; one of those moods when what is pleasure at other times, becomes insipid or indifferent\". He quoted English poet Samuel Taylor Coleridge's \"Dejection\" as a perfect description of his case: \"A grief without a pang, void, dark and drear, / A drowsy, stifled, unimpassioned grief, / Which finds no natural outlet or relief / In word, or sigh, or tear.\" English writer Samuel Johnson used the term \"the black dog\" in the 1780s to describe his own depression, and it was subsequently popularized by depression sufferer former British Prime Minister Sir Winston Churchill.\n\nSocial stigma of major depression is widespread, and contact with mental health services reduces this only slightly. Public opinions on treatment differ markedly to those of health professionals; alternative treatments are held to be more helpful than pharmacological ones, which are viewed poorly. In the UK, the Royal College of Psychiatrists and the Royal College of General Practitioners conducted a joint Five-year Defeat Depression campaign to educate and reduce stigma from 1992 to 1996; a MORI study conducted afterwards showed a small positive change in public attitudes to depression and treatment.\n\nTrials are looking at the effects of botulinum toxins on depression. The idea is that the drug is used to make the person look less frowning and that this stops the negative facial feedback from the face. In 2015 results showed, however, that the partly positive effects that had been observed until then could have been due to placebo effects.\n\nMRI scans of patients with depression have revealed a number of differences in brain structure compared to those who are not depressed. Meta-analyses of neuroimaging studies in major depression reported that, compared to controls, depressed patients had increased volume of the lateral ventricles and adrenal gland and smaller volumes of the basal ganglia, thalamus, hippocampus, and frontal lobe (including the orbitofrontal cortex and gyrus rectus). Hyperintensities have been associated with patients with a late age of onset, and have led to the development of the theory of vascular depression.\n\nDepression is especially common among those over 65 years of age and increases in frequency beyond this age. In addition, the risk of depression increases in relation to the frailty of the individual. Depression is one the most important factors which negatively impact quality of life in adults, as well as the elderly. Both symptoms and treatment among the elderly differ from those of the rest of the population.\n\nAs with many other diseases, it is common among the elderly not to present with classical depressive symptoms. Diagnosis and treatment is further complicated in that the elderly are often simultaneously treated with a number of other drugs, and often have other concurrent diseases. Treatment differs in that studies of SSRIs have shown lesser and often inadequate effects among the elderly, while other drugs, such as duloxetine (an serotonin-norepinephrine reuptake inhibitor), with more clear effects have adverse effects, such as dizziness, dryness of the mouth, diarrhea and constipation, which can be especially difficult to handle among the elderly.\n\nProblem solving therapy was, as of 2015, the only psychological therapy with proven effect, and can be likened to a simpler form of cognitive behavioral therapy. However, elderly with depression are seldom offered any psychological treatment, and the evidence proving other treatments effective is incomplete. ECT has been used in the elderly, and register-studies suggest it is effective, although less so as compared to the rest of the population.\n\nThe risks involved with treatment of depression among the elderly as opposed to benefits are not entirely clear.\n\nModels of depression in animals for the purpose of study include iatrogenic depression models (such as drug-induced), forced swim tests, tail suspension test, and learned helplessness models. Criteria frequently used to assess depression in animals include expression of despair, neurovegetative changes, and anhedonia, as many other criteria for depression are untestable in animals, such as guilt and suicidality.\n\n"}
{"id": "10816148", "url": "https://en.wikipedia.org/wiki?curid=10816148", "title": "Mamadou Dembelé", "text": "Mamadou Dembelé\n\nMamadou Dembelé (21 January 1934 – 9 October 2016) was a Malian physician and politician. Dembelé served as Prime Minister of Mali from 6 June 1986 to 6 June 1988 under President Moussa Traoré. He was a member of the Democratic Union of the Malian People and responsible for the repression of the 1979-80 student movements. He died on 9 October 2016 at the age of 82. Dembélé was to have a state funeral at the paternal home in Darsalam, followed by interment at the cemetery of Hamdallaye on Tuesday 11 October 2016.\n"}
{"id": "36624493", "url": "https://en.wikipedia.org/wiki?curid=36624493", "title": "Man Therapy", "text": "Man Therapy\n\nMan Therapy is an interactive mental health campaign targeting working age men (25-54) that employs humor to cut through stigma and tackle issues like depression, divorce and anxiety. The campaign features the fictional Dr. Rich Mahogany, described by Adam Newman in the \"New York Times\" as “an affable, mustachioed, middle-aged man whose personality might be described as Dr. Phil meets Ron Burgundy, Will Ferrell’s fictional anchorman.”\n\nMan Therapy was created by Cactus, a Denver-based ad agency, in conjunction with the Carson J Spencer Foundation and the Office of Suicide Prevention at the Colorado Department of Public Health and Environment.\n\nThe purpose of the Man Therapy campaign is to provide men approaching crisis, and their loved ones, a place to go and learn more about men’s mental health, examine their own and consider a wide array of actions that will put them on the path to treatment and recovery. The message is that all men should be aware of their mental health, treat it like they would a broken leg and strive to get better.\n\nMan Therapy is built around the fictional Man Therapist, Dr. Rich Mahogany. He’s a man’s man who is dedicated to cutting through the denial with a fresh approach using his rapier wit, odd sense of humor, no BS approach and practical, useful advice for men. There exists an age-old stigma that says mental health disorders are unmanly signs of weakness. Dr. Rich Mahogany and Man Therapy, is dedicated to smashing that.\n\nThe centerpiece of the campaign is the ManTherapy.org website, where men and their loved ones will find they have a virtual appointment with Dr. Mahogany. He greets visitors, makes them feel at ease and then provides an overview of what they will find and explore during their visit. From there, visitors can navigate through Dr. Mahogany’s office where they can find useful information about men’s mental health including guy’s guide to Gentlemental Health. Men can also choose to take an 18-question quiz to evaluate their own mental health, access resources and explore a wide range of actions from accessing do-it-yourself tips, seeking therapy referral sources, links to local support groups and organizations as well as a crisis line.\n\nThe integrated communications campaign also includes a 30-second TV PSA, viral videos, social media, outdoor boards and outreach materials such as posters, coasters and Dr. Mahogany’s business card.\n\nIn 2006, as a part of their partnership with the Colorado Department of Public Health and Environment, Cactus was introduced to Jarrod Hindman, Director of the Office of Suicide Prevention (OSP). He was running an underfunded program to address the critically important issue of suicide in Colorado. Cactus agreed to do some pro bono work for the program. Through that process the agency learned a great deal about this issue and was introduced to the Carson J Spencer Foundation (CJSF), a local non-profit dedicated to suicide prevention. CJSF was founded in 2005 after its namesake, Carson Spencer, a 34-year-old Denver businessman, died by suicide following a difficult battle with bipolar disorder. Together, the three –– Cactus, OSP and CJSF –– formed a partnership to try to reach working aged men who were potentially high risk for suicide and unlikely to seek help on their own.\n\nWith a $25,000 contribution from the American Foundation for Suicide Prevention and $5,000 allocated from a larger Garrett Lee Smith Suicide Prevention grant, Cactus developed a comprehensive public education plan while conducting some very insightful and thrifty research studies. Fortunately, the Office of Suicide Prevention landed some untapped state dollars for a one-time, $400,000 campaign. Cactus competed for the contract in a competitive, state-bid process and was awarded the contract in 2009. However, a week after the contract was signed, we were informed that due to state budget cuts the entire grant and contract was cancelled. We were once again left with nothing but a really great plan and zero budget to implement it. Not to be deterred, the partnership forged ahead to launch this vital campaign. Serendipitously, Cactus heard that the Anschutz Foundation was looking to invest in a suicide prevention program. Cactus jumped on the opportunity and submitted a grant proposal on behalf of a private/public/non-profit partnership between Cactus, Office of Suicide Prevention at the Colorado Department of Public Health and Environment and the Carson J Spencer Foundation. Additionally, Cactus was awarded a grant from The Anschutz Foundation to develop a campaign while establishing a sustainable effort in Colorado and beyond.\n\nMan Therapy has received numerous awards for its innovative approach to mental health, including the Gold Addy Award for Public Service: Digital Advertising and Advertising Age awarded Man Therapy the Pro Bono Campaign of the Year. In addition, Man Therapy was recognized by the Safe States Alliance as the 2013 Innovative Initiative of the Year.\n\nAn Australian version of Man Therapy launched in May, 2013 in partnership with beyondblue.\n\n"}
{"id": "1076929", "url": "https://en.wikipedia.org/wiki?curid=1076929", "title": "Medical classification", "text": "Medical classification\n\nMedical classification, or medical coding, is the process of transforming descriptions of medical diagnoses and procedures into universal medical code numbers. The diagnoses and procedures are usually taken from a variety of sources within the health care record, such as the transcription of the physician's notes, laboratory results, radiologic results, and other sources.\n\nDiagnosis codes track diseases and other health conditions, inclusive of chronic diseases such as diabetes mellitus and heart disease, and infectious diseases such as norovirus, the flu, and athlete's foot. Procedure codes track interventions performed. These diagnosis and procedure codes are used by health care providers, government health programs, private health insurance companies, workers' compensation carriers, software developers, and others for a variety of applications in medicine, public health and medical informatics, including:\n\nThere are country specific standards and international classification systems.\n\nMany different medical classifications exist, though they occur into two main groupings: \"Statistical classifications\" and \"Nomenclatures\".\n\nA statistical classification brings together similar clinical concepts and groups them into categories. The number of categories is limited so that the classification does not become too big. An example of this is used by the International Statistical Classification of Diseases and Related Health Problems (known as ICD). ICD groups diseases of the circulatory system into one \"chapter,\" known as , covering codes I00–I99. One of the codes in this chapter (I47.1) has the code title (rubric) \"Supraventricular tachycardia\". However, there are several other clinical concepts that are also classified here. Among them are paroxysmal atrial tachycardia, paroxysmal junctional tachycardia, auricular tachycardia and nodal tachycardia.\n\nAnother feature of statistical classifications is the provision of residual categories for \"other\" and \"unspecified\" conditions that do not have a specific category in the particular classification.\n\nIn a nomenclature there is a separate listing and code for every clinical concept. So, in the previous example, each of the tachycardia listed would have its own code. This makes nomenclatures unwieldy for compiling health statistics.\n\nTypes of coding systems specific to health care include:\n\nThe World Health Organization (WHO) maintains several internationally endorsed classifications designed to facilitate the comparison of health related data within and across populations and over time as well as the compilation of nationally consistent data. This \"Family of International Classifications\" (FIC) include three main (or reference) classifications on basic parameters of health prepared by the organization and approved by the World Health Assembly for international use, as well as a number of derived and related classifications providing additional details. Some of these international standards have been revised and adapted by various countries for national use.\n\n\nDerived classifications are based on the WHO reference classifications (i.e. ICD and ICF). They include the following:\n\n\nRelated classifications in the WHO-FIC are those that partially refer to the reference classifications, e.g. only at specific levels. They include:\n\n\nICD versions before ICD-9 are not in use anywhere.\n\nICD-9 was published in 1977, and was superseded by ICD-10. ICD-9-CM (Clinical Modification), the last national variant of ICD-9 still maintained, was used in the US until September 2015. Starting on October 1, 2015, the Centers for Medicare and Medicaid Services (CMMS) granted a one-year grace period to physicians who didn't use ICD-10 coding or they would be denied Medicare Part B claims.\n\nThe International Classification of Procedures in Medicine (ICPM) is a procedural classification that has not updated since 1989, and will be replaced by ICHI. National versions of the ICPM include OPS, which is the official German procedural classification.\n\nThe categories in a diagnosis classification classify diseases, disorders, symptoms and medical signs. In addition to the ICD and its national variants, they include:\n\n\nThe categories in a procedure classification classify specific health interventions undertaken by health professionals. In addition to the ICHI and ICPC, they include:\n\nDrugs are often grouped into drug classes. Such classifications include:\n\nNational Drug File-Reference Terminology was a terminology maintained by the Veterans Health Administration (VHA). It groups drug concepts into classes. It was part of RxNorm until March 2018.\n\nMedication Reference Terminology (MED-RT) is a terminology created and maintained by Veterans Health Administration in the United States. In 2018, it replaced NDF-RT that was used during 2005-2017. Med-RT is not included in RxNorm but is included in National Library of Medicine's UMLS Metathesaurus. Prior 2017, NDF-RT was included in RxNorm. The first release of MED-RT was in the spring of 2018.\n\n\n\n\nThe Systematized Nomenclature of Medicine (SNOMED) is the most widely recognised nomenclature in healthcare. Its current version, SNOMED Clinical Terms (SNOMED CT), is intended to provide a set of concepts and relationships that offers a common reference point for comparison and aggregation of data about the health care process. SNOMED CT is often described as a reference terminology. SNOMED CT contains more than 311,000 active concepts with unique meanings and formal logic-based definitions organised into hierarchies. SNOMED CT can be used by anyone with an Affiliate License, 40 low income countries defined by the World Bank or qualifying research, humanitarian and charitable projects. SNOMED-CT is designed to be managed by computer, and it is a complex relationship concepts.\n\nThe International Classification of Disease (ICD) is the most widely recognized medical classification maintained by the World Health Organization (WHO). Its primary purpose is to categorise diseases for morbidity and mortality reporting. The United States has used a clinical modification of ICD (ICD-9-CM) for the additional purposes of reimbursement. ICD-10 was endorsed by WHO in 1990, and WHO Member states began using the classification system in 1994 for both morbidity and mortality reporting. In the US, however, it has only been used for reporting mortality since 1999. Because of the US delay in adopting its version of ICD-10, it is currently unable to compare morbidity data with the rest of the world. ICD has a hierarchical structure, and coding in this context, is the term applied when representations are assigned to the words they represent. Coding diagnoses and procedures is the assignment of codes from a code set that follows the rules of the underlying classification or other coding guidelines.\n\nSNOMED CT and ICD are designed for different purposes and each should be used for the purposes for which they were designed. As a core terminology for the EHR, SNOMED CT provides a common language that enables a consistent language that enables a consistent way of capturing, sharing, and aggregating health data across specialties and sites of care. It is highly detailed terminology designed for input not reporting. Classification systems such as ICD-9-CM, ICD-10-CM, and ICD-10-PCS group together similar diseases and procedures and organise related entities for easy retrieval. They are typically used for external reporting requirements or other uses where data aggregation is advantageous, such as measuring the quality of care monitoring resource utilisation, or processing claims for reimbursement. SNOMED is clinically-based, documents whatever is needed for patient care and has better clinical coverage than ICD. ICD’s focus is statistical with less common diseases get lumped together in “catch-all” categories, which result in loss of information. SNOMED CT is used directly by healthcare providers during the process of care, whereas ICD is used by coding professionals after the episode of care. SNOMED CT has multiple hierarchy, whereas there is single hierarchy for ICD. SNOMED CT concepts are defined logically by their attributes, whereas only textual rules and definitions in ICD.\n\nSNOMED and ICD can be coordinated. The National Library of Medicine (NLM) maps ICD-9-CM, ICD-10-CM, ICD-10-PCS, and other classification systems to SNOMED. Data Mapping is the process of identifying relationships between two distinct data models. The full value of the health information contained in an EHR system will only be realised if both systems involved in the map are up to date and accurately reflect the current practice of medicine.\n\nMedical coding and classification systems are expected to become increasingly important in the health care sector. Together with and as an integrated part of the electronic health information systems, the coding and classification systems will be used to improve the quality and effectiveness of the medical services.\n\nClinical coding is the translation of written, scanned and/or electronic clinical documentation about patient care into code format. For example, hypertension is represented by the code 'I10'; general anaethesia is represented by the code '92514-XX[1910]'.\n\nA standardised classification system, The International Statistical Classification of Diseases and Related Health Problems, 10th Revision, Australian Modification (ICD-10-AM), is applied in all Australian acute health facilities. It is based on the World Health Organization ICD-10 system, updated with the Australian Classification of Health Interventions (ACHI), Australian Coding Standards (ACS). Clinical coding is a specialised skill requiring excellent knowledge of medical terminology and disease processes, attention to detail, and analytical skills.\n\nA clinical coder is responsible for abstracting relevant information from the medical record and deciding which diagnoses and procedures meet criteria for coding as per Australian and State Coding Standards. The coder then assigns codes for these diagnoses and procedures based on ICD-10-AM conventions and standards.\n\nThe assigned codes and other patient data are processed by grouper software to determine a diagnosis-related group (DRG) for the episode of care, which is used for funding and reimbursement. This process allows hospital episodes to be grouped into meaningful categories, helping us to better match patient needs to health care resources.\n\nThe coded information is used for clinical governance, clinical audit and outcome and effectiveness of patient's care and treatment.\nStatistically this information is used to keep a track of payment by results, cost analysis, commissioning, etiology studies, health trends, epidemiology studies, clinical indicators and case-mix planning.\n\nVeterinary medical codes include the VeNom Coding Group, the U.S. Animal Hospital Codes, and the Veterinary Extension to SNOMED CT (VetSCT).\n\n"}
{"id": "20110967", "url": "https://en.wikipedia.org/wiki?curid=20110967", "title": "Midget", "text": "Midget\n\nMidget (from \"midge\", a sand fly) is a term for a person of unusually short stature that is considered by some to be pejorative. While not a medical term, it has been applied to persons of unusually short stature, often with the medical condition dwarfism, particularly proportionate dwarfism.\n\nIt may also refer to anything of much smaller than normal size, as a synonym for \"miniature\", such as a midget cell, a midget crabapple, a midget submarine, MG's Midget, Daihatsu's Midget, and the Midget Mustang airplane; or to anything that regularly uses anything that is smaller than normal (other than a person), such as midget car racing and quarter midget racing; or a smaller version of play or participation, such as midget golf; or to anything designed for very young (i.e., small) participants—in many cases children—such as Disneyland's Midget Autopia, Midget hockey, and Midget football.\n\nMerriam-Webster dictionary states that the first use of the term \"midget\" was in 1816.\n\nMidgets have always been popular entertainers, but were often regarded with disgust and revulsion in society. In the early 19th century, however, midgets were romanticized by the middle class and regarded with the same affectionate condescension extended to children, as creatures of innocence. The term \"midget\" came into prominence in the mid-19th century after Harriet Beecher Stowe used it in her novels \"Sunny Memories of Foreign Lands\" and \"Old Town Folks\" where she described children and an extremely short man, respectively. P. T. Barnum indirectly helped popularize the term \"midget\" when he began featuring General Tom Thumb, Lavinia Warren and Commodore Nutt in his circus. \"Midget\" became linked to referencing short people put on public display for curiosity and sport. Barnum's midgets, however, were elevated to a position of high society, given fantasy military titles, introduced to dignitaries and royalty, and showered with gifts.\n\nSuch performances continued to be widespread through the mid part of the twentieth century, with Hermines Midgets brought from their performances in Paris to appear at the 1939 New York World's Fair, the same year that MGM released \"The Wizard of Oz\", which featured 124 midgets in its cast, most of whom were from the Singer's Midgets troupe.\n\nWhen interviewed for a 1999 piece, performers engaged in ongoing \"Midget Wrestling\" events stated that they did not view the term \"Midget Wrestling\" as derogatory, but merely descriptive of their small size; however, others responding to the piece disagreed, with one stating that the performances themselves perpetuated an outdated and demeaning image.\n\nTowards the end of the twentieth century, the word became considered by some as a pejorative term when in reference to people with dwarfism. One notable exception, though, was accomplished actor Hervé Villechaize who preferred the term \"midget\".\n\n"}
{"id": "49793136", "url": "https://en.wikipedia.org/wiki?curid=49793136", "title": "Mohammad Farhadi", "text": "Mohammad Farhadi\n\nMohammad Farhadi (, born 1 January 1949 in Shahroud) is an Iranian physician, politician and former Minister of Science, a position he held from 26 November 2014 until 20 August 2017. He was previously President of the Red Crescent Society of the Islamic Republic of Iran from 2013 to 2014, Minister of Health from 1997 to 2001 in the first cabinet of President Mohammad Khatami, Minister of Culture and Higher Education from 1985 to 1989 in the second cabinet of Mir-Hossein Mousavi and President of the University of Tehran in 1985. He was also Vice President of the Red Crescent Society of the Islamic Republic of Iran in the first years of 1980's. \n"}
{"id": "191305", "url": "https://en.wikipedia.org/wiki?curid=191305", "title": "Mortality rate", "text": "Mortality rate\n\nMortality rate, or death rate, is a measure of the number of deaths (in general, or due to a specific cause) in a particular population, scaled to the size of that population, per unit of time. Mortality rate is typically expressed in units of deaths per 1,000 individuals per year; thus, a mortality rate of 9.5 (out of 1,000) in a population of 1,000 would mean 9.5 deaths per year in that entire population, or 0.95% out of the total. It is distinct from \"morbidity\", which is either the prevalence or incidence of a disease, and also from the incidence rate (the number of newly appearing cases of the disease per unit of time).\n\nIn the generic form, mortality rates are calculated as:\n\nformula_1\n\nwhere d represents the deaths occurring within a given time period and p represents the size of the population in which the deaths occur.\n\nOther specific measures of mortality include:\nIn most cases, there are few ways, if at all possible to obtain exact mortality rates, so epidemiologists use estimation to predict correct mortality rates. Mortality rates are usually difficult to predict due to language barriers, health infrastructure related issues, conflict, and other reasons. Maternal mortality has additional challenges, especially as they pertain to stillbirths, abortions, and multiple births. In some countries, during the 1920s a stillbirth was defined as \"a birth of at least twenty weeks' gestation in which the child shows no evidence of life after complete birth\". In most countries, however, a stillbirth was defined as \"the birth of a fetus, after 28 weeks of pregnancy, in which pulmonary respiration does not occur\".\n\nIdeally, all mortality estimation would be done using vital statistics and census data. Census data will give detailed information about the population at risk of death. The vital statistics provide information about live births and deaths in the population. Often, either census data and vital statistics data is not available. This is especially true in developing countries, countries that are in conflict, areas where natural disasters have caused mass displacement, and other areas where there is a humanitarian crisis \n\nHousehold surveys or interviews are another way in which mortality rates are often assessed. There are several methods to estimate mortality in different segments of the population. One such example is the sisterhood method. This technique involves researchers estimating maternal mortality by contacting women in populations of interest and asking whether or not they have a sister, if the sister is of child-rearing age (usually 15) and conducting an interview or written questions about possible deaths among sisters. The sisterhood method, however, does not work in cases where sisters may have died before the sister being interviewed was born.\n\nOrphanhood surveys estimate mortality by questioning children are asked about the mortality of their parents. It has often been criticized as an adult mortality rate that is very biased for several reasons. The adoption effect is one such instance in which orphans often do not realize that they are adopted. Additionally, interviewers may not realize that an adoptive or foster parent is not the child's biological parent. There is also the issue of parents being reported on by multiple children while some adults have no children, thus are not counted in mortality estimates.\n\nWidowhood surveys estimate adult mortality by responding to questions about the deceased husband or wife. One limitation of the widowhood survey surrounds the issues of divorce, where people may be more likely to report that they are widowed in places where there is the great social stigma around being a divorcee. Another limitation is that multiple marriages introduce biased estimates, so individuals are often asked about first marriage. Biases will be significant if the association of death between spouses, such as those in countries with large AIDS epidemics.\n\nSampling refers to the selection of a subset of the population of interest to efficiently gain information about the entire population. Samples should be representative of the population of interest. Cluster sampling is an approach to non-probability sampling; this is an approach in which each member of the population is assigned to a group (cluster), and then clusters are randomly selected, and all members of selected clusters are included in the sample. Often combined with stratification techniques (in which case it is called multistage sampling), cluster sampling is the approach most often used by epidemiologists. In areas of forced migration, there is more significant sampling error. Thus cluster sampling is not the ideal choice.\n\nThe ten countries with the highest crude death rate, according to the 2016 CIA World Factbook estimates, are:\n\nAccording to the World Health Organization, the ten leading causes of death in 2015 (ranked by death per 100,000 population) were:\n\n\nCauses of death vary greatly between developed and less developed countries. See list of causes of death by rate for worldwide statistics.\n\nAccording to Jean Ziegler (the United Nations Special Rapporteur on the Right to Food for 2000 to March 2008), mortality due to malnutrition accounted for 58% of the total mortality in 2006: \"In the world, approximately 62 millions people, all causes of death combined, die each year. In 2006, more than 36 million died of hunger or diseases due to deficiencies in micronutrients\".\n\nOf the roughly 150,000 people who die each day across the globe, about two thirds—100,000 per day—die of age-related causes.<ref name=\"doi10.2202/1941-6008.1011\"></ref> In industrialized nations, the proportion is much higher, reaching 90%.\n\n\n"}
{"id": "25617725", "url": "https://en.wikipedia.org/wiki?curid=25617725", "title": "Old person smell", "text": "Old person smell\n\nOld person smell is the characteristic odor of elderly humans. Much like many animal species, human odor undergoes distinct stages based on chemical changes initiated through the aging process. Research suggests that this enables humans to determine the suitability of potential partners based on age, in addition to other factors.\n\nOne study suggested that old person smell may be the result of 2-nonenal, an unsaturated aldehyde which is associated with human body odor alterations during aging; however, there are other hypotheses. Another study failed to detect 2-nonenal at all, but found significantly increased concentrations of benzothiazole, dimethylsulphone, and nonanal on older subjects.\n\nIn 2012 the Monell Chemical Senses Center published a press release claiming that the human ability to identify information such as age, illness, and genetic suitability from odor is responsible for the distinctive \"old man smell\". Sensory neuroscientist Johan Lundström stated, \"Elderly people have a discernible underarm odor that younger people consider to be fairly neutral and not very unpleasant.\"\n\nOld person smell is known as in Japan, where it is of particular concern due to the high value placed on personal hygiene.\n"}
{"id": "37778652", "url": "https://en.wikipedia.org/wiki?curid=37778652", "title": "Patient Activation Measure", "text": "Patient Activation Measure\n\nThe Patient Activation Measure (PAM) is a commercial product which assesses an individual's knowledge, skill, and confidence for managing one's health and healthcare. Individuals who measure high on this assessment typically understand the importance of taking a pro-active role in managing their health and have the skills and confidence to do so.\n\nThe PAM survey measures patients on a 0–100 scale and can segment patients into one of four activation levels along an empirically derived continuum. Each activation level reveals insight into an array of health-related characteristics, including attitudes, motivators, behaviors, and outcomes.\n\nPAM was developed using qualitative methods, Rasch analysis, and classical test theory psychometric methods. Developed by Judith Hibbard and colleagues at the University of Oregon, the resulting 13-item measure is a uni-dimensional, interval level, Guttman-like scale. The PAM has strong psychometric properties, and has been translated into 22 different languages. The measure is currently used to assess patient activation or engagement by researchers and clinicians around the world. PAM is offered to healthcare organizations exclusively by Insignia Health, a company based in Portland, Oregon.\n\nMultiple studies show that PAM scores are predictive of most health behaviors, including preventive behaviors (e.g. obtaining screenings and immunizations); healthy behaviors (e.g. healthy diet and regular exercise); self-management behaviors (e.g. monitoring and medication management); and health information seeking. Higher activated individuals also have better health outcomes and lower rates of costly utilization, such as emergency department use and hospitalizations.\n\nFurther there is evidence that with support and appropriate interventions it is possible to increase activation levels in patients.\n\nThe Patient Activation Measure is being used in a number of ways to improve the delivery of health care, including:\n\nInsignia Health holds the worldwide exclusive rights to PAM per a technology transfer from University of Oregon. Insignia licenses PAM and other related products to organizations in the U.S. and abroad. PAM is being used in 16 countries today.\n"}
{"id": "35581476", "url": "https://en.wikipedia.org/wiki?curid=35581476", "title": "Pejman Azarmina", "text": "Pejman Azarmina\n\nPejman Azarmina (Persian: پژمان آذرمینا, born in 1973) is an Iranian-American medical director, author, speaker and thinkocrat. As a physician working in the biopharmaceutical industry, his work was recognized leading or contributing to innovative medical projects through cross-functional teams to enhance the value of much-needed tests, medical devices and medicines for the US and global markets. Since 2012, his interest in leadership development led to the formation of multiple tools, projects and initiatives aiming to develop the next generation of holistic leaders and systems thinkers under the umbrella term of Thinkocrats.\n\nAzarmina published Common Medical Terms, an evidence-based medical dictionary in 1995 as a student project leading a team of seven editors and 22 term-finders, which was recognized as the best student book in 1997. In 2001, he authored six bestselling titles named \"My Doctor\" describing medical topics in plain language for the public. In 2017, he co-authored Sexuality Education Wheel of Context that introduces a \"context analysis\" practical framework for change agents working in the field of sexuality education.\n\nAzarmina is also a concert musician and santour instructor. He has released 5 music albums, published two sheet music and wrote three chapters of Love Dynasty, a multimedia encyclopedia for Persian Music. His first solo album, Old Persian Dances was released in 1996 and contained novel rearrangements of old dance forms from the original repertoire for Persian music. His next album, \"Shabdiz\", contained a collection of his compositions for solo and two santours. Azarmina's recent albums, Persian Nostalgia and Rebellious Solitude, were released in the US and contain fine renderings of some Persian music masterpieces and advanced repertoire for the santour.\n\nAzarmina has also been involved in philanthropic activities by being the Vice Chair of Leadership and Professional Development Forum at Public Affairs Alliance of Iranian Americans (PAAIA) NexGen NY and by developing and offering several leadership and professional development programs and workshop for young and talented Iranian-Americans in New York and California.\n\nAzarmina was born in Tehran, Iran; started studying the santour at age 11 with Master Faramarz Payvar (1933‒2009) and graduated from his private class after completing the 'Advanced Repertoire for the Santour' (Persian: ردیف چپ کوک) in 1994. His other music teachers include Hossein Dehlavi (music theory, harmony and songwriting) and Ahmad Pejman (composition and counterpoint).\n\nAzarmina's style of performance is perhaps one of the closest to that of late Master Payvar, yet his interpretation of Persian music is very lean, expressive, and contemporary.\n\nAzarmina studied medicine at Tehran University of Medical Sciences (1992‒1999), completed a master's degree in Healthcare Management at University of Surrey (2003‒2005) and obtained a graduate certificate in Medical Informatics from Oregon Health & Science University (2007) and a certificate in coaching from New York University (2011).\n\n\n\n\n"}
{"id": "3969035", "url": "https://en.wikipedia.org/wiki?curid=3969035", "title": "Philippine Red Cross", "text": "Philippine Red Cross\n\nThe Philippine Red Cross (abbreviated as PRC) is a member of the International Red Cross and Red Crescent Movement.\n\nThe PRC was established in 1947, with roots in the Philippine Revolution against the Spanish Empire. It was initially involved only in the provision of blood and short-term palliatives as well as participation in disaster-related activities but they now focus on a wider array of humanitarian services.\n\nAt present, the PRC provides six major services: National Blood Services, Disaster Management Services, Safety Services, Health Services, Welfare Services and Red Cross Youth. All of them embody the fundamental principles of the International Red Cross and Red Crescent Movement – humanity, impartiality, neutrality, independence, voluntary service, unity and universality. These values guide and inspire all Red Cross staff and volunteers, to whom being a Red Crosser is more than just a philosophy but a way of life.\n\nApolinario Mabini encouraged the Malolos Republic to form a national Red Cross organization. On February 17, 1899, the Malolos Republic approved the Constitution of the National Association of the Red Cross. The government appointed Hilaria del Rosario de Aguinaldo – the consort of President Emilio Aguinaldo – as the first head of the Association.\n\nFilipino diplomat Felipe Agoncillo, met with Gustave Moynier, an original member of the Committee of Five and ICRC President on 29 August 1900. He sought recognition of the Filipino Red Cross Society as well as the application of the First Geneva Convention during the Philippine–American War.\n\nOn August 30, 1905, the American Red Cross (ARC) formed a Philippine Branch with Filipino and American leaders at the Ayuntamiento. After several years of continuous effort, the ANRC officially recognized it as a Chapter on December 4, 1917.\n\nIn 1934, President Manuel L. Quezon established an independent Philippine Red Cross. However, because the Philippines was a territory and later a Commonwealth under United States sovereignty, it could not sign the Geneva Conventions and therefore it could not be recognized by the ICRC. In 1942, during the Japanese Occupation of the Philippines, the Japanese created a Philippine Red Cross that they controlled to care for internees. Once Manila was liberated by combined American and Filipino forces in 1945, local Red Cross officials and the ANRC re-established an independent Red Cross.\n\nThe Philippines gained independence from the United States on July 4, 1946. Dr. J. Horacio Yanzon was appointed the first Filipino Red Cross Manager in December 1946, with thirty-six Red Cross chapters initially set up in the country. On 14 February 1947, President Manuel A. Roxas signed the Treaty of Geneva and the Prisoners of War Convention. On 22 March 1947 President Roxas signed Republic Act 95, the Philippine Red Cross (PRC) Charter.\n\nThe ICRC approved the recognition of the PRC, and telegraphed First Lady Aurora Aragon Quezon, the first PRC Chairman, on 29 March 1947. Philippine Red Cross (PRC) had an inaugural ceremony on 15 April 1947.\n\nThe PRC was admitted as a bona fide member of the League of Red Cross and Red Crescent Societies on 17 September 1947.\n\nSince 2004, the Chairman of the PRC Board of Governors is Senator Richard J. Gordon. Since 1965, actress Rosa Rosal has sat on the Board of Governors. Rosal was awarded in 1999 the Ramon Magsaysay Award for Public Service for her activities with the PRC.\n\nThe consolidation of the Senate Bill 3285 and House Bill 6509 was signed by President Gloria Macapagal-Arroyo, and is now known as Republic Act No. 10072 or The Philippine Red Cross Act of 2009. The law is an affirmation of the country's \"conformity with the Geneva Conventions of 1949 and their additional protocols, and the Statutes of the International Red Cross and Red Crescent Movement,\" as well as a confirmation of Philippine Red Cross' stand as a \"voluntary, independent and autonomous nongovernmental society auxiliary to the authorities of the Republic of the Philippines in the humanitarian field.\"\n\nApart from the apparent change in the organization's name from \"Philippine National Red Cross\" to \"Philippine Red Cross\" - included in the Act's new provisions is the organizations' exemption from real property taxes, direct and indirect taxes, duties and fees that will emerge from its operations and its exclusive importations and purchases.\n"}
{"id": "50516307", "url": "https://en.wikipedia.org/wiki?curid=50516307", "title": "Primary care service area", "text": "Primary care service area\n\nPrimary Care Service Areas are geographic areas that are self-sufficient markets of primary care. These areas are designed in a manner such that the majority of patients living in these areas use primary care services form within the area. This ensures that any geographic targeting of policies and resources reach the patients they are meant for. These geographies have been created in Australia, United States and Switzerland using big data and Geographic information systems. In Australia, while they have been developed for the state of New South Wales, they have not found application among policymakers, where, as of 2016 much larger geographies called Primary Health Networks are used for primary care management. However, they have found an especially wide audience amongst policymakers and researchers in the United States, where they were first developed. Thus for example the Health Resources and Services Administration uses them to designate areas of workforce shortage. Primary Care Service Areas are thus for example an appropriate geography for measuring primary care physician supply or geographic access to General practitioners.\n\n"}
{"id": "47973279", "url": "https://en.wikipedia.org/wiki?curid=47973279", "title": "Project SIDA", "text": "Project SIDA\n\nProject SIDA was a scientific organization to study AIDS in Africa.\n\nHeadquartered in Kinshasa, Zaire, Project SIDA was designed as a collaboration between foreign scientists with experience studying epidemics and local scientists familiar with the local culture and customs. Initiated in 1984, with funding from the U.S. [Centers for Disease Control and Prevention] and the direction of Jonathan Mann, Project SIDA was based at Mama Yemo hospital in Kinshasa.\n\nProject SIDA was terminated in 1991 due to civil war in Zaire.\n\nProject SIDA operated successfully and generated over a thousand scientific abstracts. In particular, Project SIDA scientists were among the first to document heterosexual transmission of AIDS and the existence of AIDS outside of developed countries. Project SIDA also developed and supported local scientists and scientific infrastructure, in contrast to many scientists from the developed world who collected samples in Africa but did not attempt to train local staff. In addition to Mann, prominent scientists involved with Project SIDA include Joseph McCormick and Peter Piot.\n\n"}
{"id": "896843", "url": "https://en.wikipedia.org/wiki?curid=896843", "title": "Projective test", "text": "Projective test\n\nIn psychology, a projective test is a personality test designed to let a person respond to ambiguous stimuli, presumably revealing hidden emotions and internal conflicts projected by the person into the test. This is sometimes contrasted with a so-called \"objective test\" / \"self-report test\", which adopt a \"structured\" approach as responses are analyzed according to a presumed universal standard (for example, a multiple choice exam), and are limited to the content of the test. The responses to projective tests are content analyzed for meaning rather than being based on presuppositions about meaning, as is the case with objective tests. Projective tests have their origins in psychoanalysis, which argues that humans have conscious and unconscious attitudes and motivations that are beyond or hidden from conscious awareness.\n\nThe general theoretical position behind projective tests is that whenever a specific question is asked, the response will be consciously-formulated and socially determined. These responses do not reflect the respondent's unconscious or implicit attitudes or motivations. The respondent's deep-seated motivations may not be consciously recognized by the respondent or the respondent may not be able to verbally express them in the form and structure demanded by the questioner. Advocates of projective tests stress that the ambiguity of the stimuli presented within the tests allow subjects to express thoughts that originate on a deeper level than tapped by explicit questions, and provide content that may not be captured by responsive tools that lacks appropriate items. After some decrease in interest in the 1980s and 1990s, newer research suggesting that implicit motivation is best captured in this way has increased the research and use of these tools.\n\nThis holds that an individual puts structure on an ambiguous situation in a way that is consistent with their own conscious and unconscious needs. It is an indirect method- testee is talking about something that comes spontaneously from the self without conscious awareness or editing.\n\n\nThe best known and most frequently used projective test is the Rorschach inkblot test. This test was originally developed in 1921 to diagnose schizophrenia. Subjects are shown a series of ten irregular but symmetrical inkblots, and asked to explain what they see . The subject's responses are then analyzed in various ways, noting not only what was said, but the time taken to respond, which aspect of the drawing was focused on, and how single responses compared to other responses for the same drawing. It is important that the Rorschach test and other projective tests be conducted by experienced professionals to ensure validity and consistency of results. The Rorschach was commonly scored using the Comprehensive System (CS), until the development of the newer scoring system, the Rorschach Performance Assessment System (R-PAS) in 2011. The new scoring system has stronger psychometric properties than the CS, and, like the CS, allows for a standardized administration of the test which is something that is lacking in a majority of projective measures. Additional psychometric strengths present with the R-PAS include updated normative data. The norms from the CS were updated to also include protocols from 15 other countries, resulting in updated international norms. The CS international norm data set was based on fewer countries, most of which were European only. The new international norms provide a better representation of the Western hemisphere and westernized countries. Concerning differences in administration of the task across both scoring systems, a critical issue with CS administration was addressed in the development of the R-PAS. Following CS administration procedure, it was common to obtain too few or too many responses per card which could result in an invalidated protocol (due to too few responses) or in error. The new administration procedure introduced in the R-PAS requires the clinician to initially tell the examinee that they should provide two or three responses per card, and allows the clinician to prompt for additional responses if too few are given, or to pull cards away if too many are given. Therefore, the new administration procedure addresses the critical issue of number of responses that was prevalent with use of the CS administration procedure. The CS administration procedure prevented clinicians from prompting for more responses or pulling cards when too many responses were provided. An additional psychometric improvement concerns the presentation of obtained scores. With the R-PAS system, it is now possible to change scores to percentiles and convert percentiles to standard scores which can be presented visually and allow for easy comparison to the normative data. With the CS, this was not possible and it was more difficult to compare results to normative comparison groups. Lastly, the R-PAS scores have been shown to possess similar and sometimes stronger inter-rater reliability than was seen in scores from the CS. This means that when different clinicians score the same protocol, they are quite likely to derive the same interpretations and scores.\n\nThis is a variation of the Rorschach test, but uses a much larger pool of different images. Its main differences lie in its objective scoring criteria as well as limiting subjects to one response per inkblot (to avoid variable response productivity). Different variables such as reaction time are scored for an individual's response upon seeing an inkblot.\n\nAnother popular projective test is the Thematic Apperception Test (TAT) in which an individual views ambiguous scenes of people, and is asked to describe various aspects of the scene; for example, the subject may be asked to describe what led up to this scene, the emotions of the characters, and what might happen afterwards. A clinician will evaluate these descriptions, attempting to discover the conflicts, motivations and attitudes of the respondent. A researcher may use a specific scoring system that establishes consistent criteria of expressed thoughts and described behaviors associated with a specific trait, e.g., the need for Achievement, which has a validated and reliable scoring system. In the answers, the respondent \"projects\" their unconscious attitudes and motivations into the picture, which is why these are referred to as \"projective tests.\"\n\nThe Draw-A-Person test requires the subject to draw a person. The results are based on a psychodynamic interpretation of the details of the drawing, such as the size, shape and complexity of the facial features, clothing and background of the figure. As with other projective tests, the approach has very little demonstrated validity and there is evidence that therapists may attribute pathology to individuals who are merely poor artists. A similar class of techniques is kinetic family drawing.\n\nThe Animal Metaphor test consists of a series of creative and analytical prompts in which the person filling out the test is asked to create a story and then interpret its personal significance. Unlike conventional projective tests, the Animal Metaphor Test works as both a diagnostic and therapeutic battery. Unlike the Rorschach test and TAT, the Animal Metaphor is premised on self-analysis via self-report questions. The test combines facets of art therapy, cognitive behavioral therapy, and insight therapy, while also providing a theoretical platform of behavioral analysis. The test has been used widely as a clinical tool, as an educational assessment, and in human resource selection. The test is accompanied by an inventory, The Relational Modality Evaluation Scale, a self-report measure that targets individuals' particular ways of resolving conflict and ways of dealing with relational stress. These tests were developed by Dr. Albert J Levis at the Center for the Study of Normative Behavior in Hamden, CT, a clinical training and research center.\n\nSentence completion tests require the subject complete sentence \"stems\" with their own words. The subject's response is considered to be a projection of their conscious and/or unconscious attitudes, personality characteristics, motivations, and beliefs.\n\nCreated by Silvan Tomkins, this psychological test consists of 25 sets of 3 pictures which the subject must arrange into a sequence that they \"feel makes the best sense\". The reliability of this test has been disputed, however. For example, patients suffering from schizophrenia have been found to score as more \"normal\" than patients with no such mental disorders.\nOther picture tests:\n\nWord association testing is a technique developed by Carl Jung to explore complexes in the personal unconscious. Jung came to recognize the existence of groups of thoughts, feelings, memories, and perceptions, organized around a central theme, that he termed psychological complexes. This discovery was related to his research into word association, a technique whereby words presented to patients elicit other word responses that reflect related concepts in the patients’ psyche, thus providing clues to their unique psychological make-up \n\nGraphology is the pseudoscientific analysis of the physical characteristics and patterns of handwriting purporting to be able to identify the writer, indicating psychological state at the time of writing, or evaluating personality characteristics.\n\nGraphology has been controversial for more than a century. Although supporters point to the anecdotal evidence of positive testimonials as a reason to use it for personality evaluation, most empirical studies fail to show the validity claimed by its supporters.\n\nFrom the perspective of statistical validity, psychometrics and positivism, criticisms of projective tests, and depth psychology tests, usually include the well-known discrepancy between statistical validity and clinical validity.\n\nIn the case of clinical use, they rely heavily on clinical judgment, lack statistical reliability and statistical validity and many have no standardized criteria to which results may be compared, however this is not always the case. These tests are used frequently, though the scientific evidence is sometimes debated. There have been many empirical studies based on projective tests (including the use of standardized norms and samples), particularly more established tests. The criticism of lack of scientific evidence to support them and their continued popularity has been referred to as the \"projective paradox\".\n\nResponding to the statistical criticism of his projective test, Leopold Szondi said that his test actually discovers \"fate and existential possibilities hidden in the inherited familial unconscious and the personal unconscious, even those hidden because never lived through or because have been rejected. Is any statistical method able to span, understand and integrate mathematically all these possibilities? I deny this categorically.\"\n\nOther research, however, has established that projective tests measure things that responsive tests do not, though it is theoretically possible to combine the two, e.g., Spangler, 1992 Decades of works by advocates, e.g., David C. McClelland, David Winter, Abigail Stewart, and, more recently, Oliver Schultheiss, have shown clear validity for these tools for certain personality traits, most especially implicit motivation (as contrasted with self-attributed or \"explicit\" motivation, which are conscious states) (McClelland, Koestner, & Weinberger 1989), and that criticisms of projective tools based on techniques used for responsive tools is simply an inappropriate method of measurement.\n\n\n\nIn 2006 the terms \"objective test\" and \"projective test\" came under criticism in the \"Journal of Personality Assessment.\" The more descriptive \"rating scale or self-report measures\" and \"free response measures\" are suggested, rather than the terms \"objective tests\" and \"projective tests,\" respectively. Additionally, there are inherent biases implied in the terminology itself. For example, when individuals use the term \"objective\" to describe a test, it is assumed that the test possess accuracy and precision. Conversely, when the term \"projective\" is used to describe a test, it is assumed that these measures are less accurate. Neither of these assumptions are fully accurate, and have led researchers to develop alternative terminology to describe various projective measures. For example, it has been proposed that the Rorschach be labeled as a \"behavioral task\" due to its ability to provide an in vivo or real life sample of human behavior. It is easy to forget that both objective and projective tests are capable of producing objective data, and both require some form of subjective interpretation from the examiner. Objective testing, such as self-report measures, like the MMPI-2, require objective responses from the examinee and subjective interpretations from the examiner. Projective testing, such as the Rorschach, requires subjective responses from the examinee, and can in theory involve objective (actuarial) interpretation.\n\nProjective techniques, including TATs, are used in qualitative marketing research, for example to help identify potential associations between brand images and the emotions they may provoke. In advertising, projective tests are used to evaluate responses to advertisements. The tests have also been used in management to assess achievement motivation and other drives, in sociology to assess the adoption of innovations, and in anthropology to study cultural meaning. The application of responses is different in these disciplines than in psychology, because the responses of multiple respondents are grouped together for analysis by the organisation commissioning the research, rather than interpreting the meaning of the responses given by a single subject.\n\nProjective techniques are used extensively in people assessment; besides variants of the TAT, which are used to identify implicit motive patterns, the Behavioral Event Interview pioneered by American psychologist David McClelland and many of its related approaches (such as the Critical Incident Interview, the Behavioral Interview, and so on) is fundamentally a projective tool in that it invites someone to tell a specific story about recent actions they took, but does not ask leading questions or questions with yes or no answers. (Camp, Vielhaber, Simonetti, 2001)\n\n\n"}
{"id": "43779954", "url": "https://en.wikipedia.org/wiki?curid=43779954", "title": "RVSV-ZEBOV vaccine", "text": "RVSV-ZEBOV vaccine\n\nRecombinant vesicular stomatitis virus–Zaire Ebola virus (rVSV-ZEBOV) is an experimental vaccine for protection against Ebola virus disease. As of April 2017, ring vaccination with rVSV-ZEBOV appeared to be somewhat effective, but the extent of efficacy was uncertain. When used in ring-vaccination, rVSV-EBOV has shown a high level of protection. Around half the people given the vaccine have mild to moderate adverse effects that include headache, fatigue, and muscle pain.\nrVSV-ZEBOV is a recombinant, replication-competent vaccine. It consists of a vesicular stomatitis virus (VSV), which has been genetically engineered to express a glycoprotein from the Zaire ebolavirus so as to provoke a neutralizing immune response to the Ebola virus.\nIt was created by scientists at the National Microbiology Laboratory in Winnipeg, Manitoba, Canada, which is part of the Public Health Agency of Canada (PHAC). PHAC licensed it to a small company, NewLink Genetics, which started developing the vaccine; NewLink in turn licensed it to Merck in 2014. It was used in the DR Congo in a 2018 outbreak in Équateur province.\n\n, ring vaccination with rVSV-EBOV appeared to be somewhat effective, but the extent of efficacy was uncertain, due to the trial design and elimination of the delayed treatment arm part way through the trial.\n\nNearly 800 people were ring vaccinated on an emergency basis with VSV-EBOV when another Ebola outbreak occurred in Guinea in March 2016. In 2017, in the face of a new outbreak of Ebola in the Democratic Republic of the Congo, the Ministry of Health approved the vaccine's emergency use, but it was not immediately deployed.\n\nAdverse effects have occurred in around half the people given the vaccine, were generally mild to moderate, and included headache, fatigue, and muscle pain.\n\nrVSV-ZEBOV is a live, attenuated recombinant vesicular stomatitis virus in which the gene for the native envelope glycoprotein is replaced with that from the Ebola virus, Kikwit 1995 Zaire strain. Manufacturing of the vaccine for the Phase I trial was done by IDT Biologika. Manufacturing of vaccine for the Phase III trial was done by Merck, using cells from African green monkeys, which Merck already used to make its RotaTeq vaccine against rotavirus.\n\nScientists working for the Public Health Agency of Canada (PHAC) created the vaccine, and PHAC applied for a patent in 2003. From 2005 to 2009, three animal trials on the virus were published, all of them funded by the Canadian and U.S. governments. In 2005, a single intramuscular injection of the EBOV or MARV vaccine was found to induce completely protective immune responses in nonhuman primates (crab-eating macaques) against corresponding infections with the otherwise typically lethal EBOV or MARV.\n\nIn 2010, PHAC licensed the intellectual property on the vaccine to a small U.S. company called Bioprotection Systems, which was a subsidiary of NewLink Genetics; Newlink had funding from the U.S. Defense Threat Reduction Agency to develop vaccines.\n\nIn December 2013, the largest-ever Ebola epidemic started in West Africa, specifically, in Guinea. In September or October 2014, Newlink formed a steering committee among the interested parties, including PHAC, the NIH, and the WHO, to plan the clinical development of the vaccine.\n\nIn October 2014, NewLink Genetics began a Phase I clinical trial of rVSV-ZEBOV on healthy human subjects to evaluate the immune response, identify any side effects and determine the appropriate dosage. Phase I trials took place in Gabon, Kenya, Germany, Switzerland, the US, and Canada. In November 2014 NewLink exclusively licensed rights to the vaccine to Merck.\n\nThe Phase I study started with a high dose which caused arthritis and skin reactions in some people, and the vaccine was found replicating in the synovial fluid of the joints of the affected people; the clinical trial was halted because of that, then recommenced with a lower dose.\n\nIn March 2015, a Phase II clinical trial and a Phase III started in Guinea at the same time; the Phase II trial focused on frontline health workers, while the Phase III trial was a ring vaccination in which close contacts of people who had contracted Ebola virus were vaccinated with VSV-EBOV. Preliminary results were reported in July. In the same report, the WHO communicated that the control arm of the trial was dropped and the trial would expand.\n\nIn January 2016, the GAVI Alliance signed an agreement with Merck under which Merck agreed to provide VSV-EBOV vaccine for future outbreaks of Ebola and GAVI paid Merck US$5 million; Merck will use the funds to complete clinical trials and obtain regulatory approval. As of that date Merck had submitted an application to the World Health Organization through their Emergency Use Assessment and Listing (EUAL) program to allow for use of the vaccine in the case of another epidemic. It was used on an emergency basis in Guinea in March 2016.\n\nResults of the Phase III Guinea trial were published in December 2016. It was widely reported in the media that vaccine was safe and appeared to be nearly 100% effective, but the vaccine remained unavailable for commercial use as of December 2016.\n\nIn April 2017, scientists from the U.S. National Academy of Medicine published a review of the response to the Ebola outbreak that included a discussion of how clinical trial candidates were selected, how trials were designed and conducted, and reviewed the data resulting from the trials. The committee found that data from the Phase III Guinea trial were difficult to interpret for several reasons. The trial had no placebo arm; it was omitted for ethical reasons and everyone involved, including the committee, agreed with the decision. This left only a delayed treatment group to serve as a control, but this group was eliminated after an interim analysis showed high levels of protection, which left the trial even more underpowered. The committee found that under an intention-to-treat analysis, the rVSV-ZEBOV vaccine might have had no efficacy, agreed with the authors of the December 2016 report that it probably had some efficacy, but found statements that it had substantial or 100% efficacy to be unsupportable.\n\nDuring an outbreak in the Democratic Republic of the Congo in 2018, the ZEBOV vaccine was used, and what was once contact tracing which numbered 1,706 individuals (ring vaccination which totaled 3,330) was reduced to zero on 28 June 2018. The outbreak will complete the required 42-day cycle on 24 July.\n\n\n"}
{"id": "39042029", "url": "https://en.wikipedia.org/wiki?curid=39042029", "title": "Sania Nishtar", "text": "Sania Nishtar\n\nSania Nishtar () (Born: 16 February 1963); SI), is a Pakistani cardiologist, author and activist who is the current BISP chairperson. Previously she served in the interim federal cabinet in 2013 overseeing public health, education and science. She currently co-chairs WHO’s High-Level Commission on Non-communicable diseases along with the Presidents of Uruguay, Finland and Sri-Lanka. She is a member of the World Economic Forum’s Global Agenda Council on the future of healthcare and co-chairs the U.S National Academy of Sciences Global Study on the Quality of Healthcare in low and middle-income countries. In addition, she also chairs the United Nations International Institute for Global Health’s International Advisory Board and a member of the International Advisory Board on Global Health of the German Federal Government.\n\nBorn in Peshawar, Nishtar went to medical school at Khyber Medical College and was college best graduate for 1986. She was inducted into the College of Physicians & Surgeons of Pakistan in 1991 after completing her residency at Khyber Teaching Hospital. She joined the Pakistan Institute of Medical Sciences as a cardiologist in 1994 and worked with the institute until 2007. She left the institute on sabbatical twice, first in 1996 to at the Guy's Hospital in London, and again in 1999 to pursue her Ph.D in Medicine from the King's College London, which she received in 2002.\n\nShe became a fellow of Royal College of Physicians in 2005. While still at the institute, in 1998, Nishtar founded Heartfile, a Islamabad based health policy think tank. In 2013, Nishtar served in the caretaker government during the 2013 election's. Since 2014, Nishtar co-chair's the WHO Commission on Ending Childhood Obesity and also serves on the board of United Nations University's Institute for Global Health. Nishtar was a leading candidate for the director-general of the World Health Organization, to be elected in May 2017. She was amongst the shortlisted three nominess in the election held in January 2017, but was not successful in the final election held in 23 May 2017. If elected she would have been the first leader of WHO to come from a developing country.\n\nOn 30 October 2018, Nishtar was appointed as BISP chairwoman.\n\nSania Nishtar graduated from Khyber Medical College with her Bachelor of Medicine, Bachelor of Surgery in 1986 and was Best Graduate of the Year. She holds a Fellowship of the Royal College of Physicians and a PhD from King's College London.\n\nAfter several years as a Cardiologist at the Pakistan Institute of Medical Sciences, Sania Nishtar founded Heartfile in 1999, which has grown from a health information-focused NGO to a health policy think tank, focused on health systems issues.\n\nIn 2007, Nishtar founded Heartfile Health Financing, a program to protect poor patients from medical impoverishment.\n\nThe program is a 2008, 2012, and 2013 \n\nNishtar served as Federal Minister in the Government of Pakistan of caretaker Prime Minister Mir Hazar Khan Khoso during the 2013 caretaker government, in charge of Science and Technology, Education and Trainings and Information Technology and Telcom. She also had responsibility as focal person for health.\n\nDuring her term, Nishtar was instrumental in establishing Pakistan's Ministry of Health, which she had been advocating for. At the conclusion of her term she published Handover Papers, She also refused pay and perks and left an unusual gift for government functionaries. Her policies remained focused on promoting development; in the education sector linking academia with entrepreneurs, industry and the national priorities, and in the Ministry of IT by using the telecom sector for development. During her term in office as minister, she prevailed upon the Prime Minister to reverse the decision to dismantle the Prime Minister's Polio cell, and saved the government from what could have been an e-voting embarrassment.\n\nIn 2015, Nishtar was the Government of Pakistan's candidate to succeed António Guterres as United Nations High Commissioner for Refugees; the post eventually went to Filippo Grandi of Italy.\n\nNishtar has been Pakistan's candidate to succeed Margaret Chan as Director-General of WHO. In April 2016, the Organization of Islamic Cooperation, which has 57 member states and aims to serve as the collective voice for Muslims, \"welcomed\" Nishtar’s candidacy.\n\nSania Nishtar was one of the two favorite candidates in the shortlisting election in January 2017, where she secured 28 out of 34 votes. She qualified to be one of the three official nominees by WHO.\n\nHer candidature received broad-based support from within Pakistan, from the government, civil society and women's groups. Many high-profile Pakistanis came in support of her, such as , Pakistan's Oscar Winner filmmaker. International experts highlighted her merits shown in this letter. She was strongly supported by luminaries such as , Princess Dina Mired of Jordan, and . Various aspects of her professional life were highlighted. Robert and Ruth Bonita explained why she was the suitable candidate outlining her NCDs and health systems credentials. Voices from Latin America supported her civil society background. Others supported her because of her reform credentials and mix of civil society, ministerial and multilateral experience, and others emphasized her accountability credentials. Other views supported the three candidates to varying extents.\n\nSania Nishtar emphasized on the need for transparency and accountability during her election campaign, and was referred to as the ‘changemaker’. Sania Nishtar was defeated by Tedros Adanhom Ghebreusus in the final election in May 2017. Her defeat disappointed Pakistanis but her ethical conduct during the election and the prestige it brought for Pakistan was widely hailed.\n\nNishtar was the Chair of the Health Committee of the Aman ki Asha initiative, a campaign for peace between India and Pakistan, for which she has convened several meetings and negotiated declarations. As a member of the Pakistan Chapter of the Partners for a New Beginning, Aspen Institute, and a member of the Global Advisory Council of the Pakistan American Foundation and the US-Muslim Engagement Initiative she has been advocating for broader US-Pakistan engagement, towards improving social outcomes.\n\nNishtar's domestic focus is on health sector governance. This was illustrated recently in the case of her stance on a spurious drug scandal, abolition of the Ministry of Health, which was part of the Eighteenth Amendment to the Constitution of Pakistan, and the country's inability to eradicate polio. She also contributes time as a volunteer to health systems strengthening in her country and has signed two MoUs with Pakistan's Ministry of Health, committing her time pro bono. She authored Pakistan's first compendium of health statistics, and the country's first national public health plan for non-communicable diseases. Nishtar's book Choked Pipes, an analysis of Pakistan's health systems, became the blue print for the country's health policy. She is a member of many health initiatives in Pakistan. Through her writings she has become a proponent of governance reforms in Pakistan, and is a member of many national and international boards and initiatives, which aim to improve governance in the country, including the Pakistan Institute of Legislative Development and Transparency. She was a member of the Asia Society Task Force on Pakistan 2020, and was formerly a director of IESCO. She also serves on Pakistan's Economic Advisory Council, and is the Chair of the Steering Committee for Pakistan's National Vision for Surgical Care.\n\nNishtar has been involved with many international agencies in various capacities. She has served as temporary advisor to the World Health Organization, on more than 20 occasions, including the following: \n\nIn addition, Nishtar continues to hold several board positions, including the following.\n\nNishtar is also a member of the \"Lancet\" and Rockefeller Foundation Commission on Planetary Health and the \"Lancet\" and Harvard Commission on Pain and Palliative Care. She is a member of the Steering Committee of the Emerging Markets Symposium, which is an initiative of the Green Templeton College, Oxford University. She is also a member of the Board of the United Nations University International Institute for Global Health.\n\nNishtar also previously served on several boards, including:\n\nNishtar chaired the World Heart Day campaign in its founding years, the 'Go Red for Women' campaign in 2004, and the Expert Panel on Women and Heart Disease 2007 onwards. She also previously served as member of the Ministerial Leadership Initiative for Global Health, and was a member of the Working Group on Private Sector in Health Systems set up by Results for Development and the Rockefeller Foundation.\nNishtar has been involved in several global health declarations. She was a member of the drafting committee of the Moscow Declaration on NCDs in 2011. She chaired the drafting committee of WHO's Venice Statement on Global Health Initiatives and Health Systems in 2009. She was also a member of the International Advisory Boards of the Osaka Declaration and Victoria Declaration on Cardiovascular Diseases.\n\nNishtar is a regular plenary speaker or keynote speaker at international meetings, and speaks at forums such as Davos. She has also been invited as a thought leader at UN agencies. She has also been on the organising committees of many international conferences.\n\nNishtar's book \"Choked Pipes\" was published by the Oxford University Press in 2010. The book received reviews in \"The Lancet\", the WHO Bulletin and other periodicals, and was released in several cities. She has also authored the book \"Chapters\", and is a regular op-ed contributor to \"The News International\" and the \"Huffington Post\". She has also contributed in the Wall Street Journal and Project Syndicate. She was also editor of the Pakistan Lancet Series, released in 2013.\n\nA list of scientific publications appears below:\n\n\nNishtar is the recipient of Pakistan's Sitara e-Imtiaz, a presidential award, the European Societies Population Science Award, and the First Global Innovation Award by the Rockefeller Foundation. She was admitted to the Medical Mission Hall of Fame in Toledo, Ohio in 2011.\n\nIn the beginning of 2014, she was mentioned in the Top-20 List of 'Most Influential Women in Science in the Islamic World' by the Muslim Scientists List in recognition of her policy advocacy contributions.\n\nSania Nishtar has been frequently quoted in the press in relation to health issues relevant to Pakistan and global health issues, particularly polio eradication, non-communicable diseases, and health systems. She has been profiled in many publications as a health advocate, minister, and prominent woman in the world.\n\nRockhopper TV has made a documentary about one aspect of Nishtar's work, which involves building systems for change. The documentary was named after her book, \"Choked Pipes\", and had previews at the Royal Society of Medicine in London. It was scheduled to be released in 2016.\n\n"}
{"id": "18566740", "url": "https://en.wikipedia.org/wiki?curid=18566740", "title": "Schmöckpfuhlgraben", "text": "Schmöckpfuhlgraben\n\nThe Schmöckpfuhl is a ditch in Heinersdorf in the Pankow district of Berlin.\n\nIt meanders above ground and partly subterraneously through allotment gardens and settlements and flows finally into the Panke. It is probably fed of wastewater from the allotment gardens.\n\n"}
{"id": "6322264", "url": "https://en.wikipedia.org/wiki?curid=6322264", "title": "Seafood Watch", "text": "Seafood Watch\n\nSeafood Watch is one of the best known sustainable seafood advisory lists, and has influenced similar programs around the world. It is best known for developing science-based seafood recommendations that consumers, chefs, and business professionals use to inform their seafood purchasing decisions. \n\nSeafood Watch is a program of the Monterey Bay Aquarium. It has roots in the Monterey Bay Aquarium's \"Fishing for Solutions\" exhibit, which ran from 1997 to 1999 and produced a list of sustainable seafood. It was one of the first resources for sustainable seafood information together with the Audubon Society's \"What is a fish lover to eat?\" which also came out in the late 1990s.\n\nSeafood Watch assesses impacts on marine and freshwater ecosystems of fisheries (wild-caught) and aquaculture (farming) operations. The assessments and calculations result in an overall scoring and final rating known as a Seafood Watch Recommendation. \n\nThere is currently a seafood watch app for the iPhone and the Android. One of its features allows people to find restaurants and stores near them that serve ocean-friendly seafood. \n\nThe organization's recommendations focus on the North American market, suggesting what seafood is a green \"Best Choice,\" yellow \"Good Alternative,\" or a red \"Avoid.\" The \"Avoid\" category is for seafood which is overfished or fished or farmed in ways that harm other marine life or the environment. Health alerts for fish with high levels of contaminants (e.g. mercury, dioxins, PCBs) are also noted, although they may appear in any category.\n\nThe Seafood Watch website includes regional, country-wide, and sushi guides for the United States. Pocket guides are available from the aquarium and further information is on the web site. Several of the regional guides are also available in Spanish. The guides are updated twice annually, while the website is updated more often. Restaurants and retailers are also targeted with an educational program developed by Seafood Watch.\n\nIn 2010 Seafood Watch added its “Super Green” list, which features seafood that it is good for human health and does not harm the oceans. The Super Green list highlights products that are currently on the Seafood Watch \"Best Choices\" (green) list, are low in environmental contaminants, and are good sources of long-chain omega-3 fatty acids.\n\nSeafood Watch partners with zoos, aquariums, science museums, nature centers, and other non-profits to promote sustainable seafood. Its business and culinary initiatives assist seafood buyers, distributors, retailers, food service professionals, and chefs in moving the marketplace towards environmentally responsible fisheries and aquaculture operations. The Monterey Bay Aquarium’s Ocean Conservation Policy team works to advance policies and management measures to improve traceability in the global seafood supply chain; eliminate illegal, unreported and unregulated fishing; strengthen and advocate for fisheries management; and restore shark and Bluefin tuna populations.\n\nIndustry organizations have pushed back against Seafood Watch's efforts. After publication of a sustainable sushi guide, the National Fisheries Institute, a seafood industry trade group, wrote on its blog that the guides were \"confusing and contradictory,\" adding that they didn't fully take into account the economic, environmental and social aspects of seafood sustainability.\n\n\n"}
{"id": "44146912", "url": "https://en.wikipedia.org/wiki?curid=44146912", "title": "Sexual Recovery Anonymous", "text": "Sexual Recovery Anonymous\n\nSexual Recovery Anonymous (SRA) is one of several twelve-step programs for the treatment of sexual addiction based on the original Twelve Steps of Alcoholics Anonymous. SRA takes its place among various 12-step groups that seek recovery from sexual addiction: Sex Addicts Anonymous, Sex and Love Addicts Anonymous, Sexual Compulsives Anonymous and Sexaholics Anonymous. The New York-based group has meetings in several states. Collectively these groups are referred to as \"S\" groups since all their acronyms begin with that letter.\n\nThere is a related group called SRA-ANON for spouses, relatives, friends, and significant others of SRA members. This group is analogous to Al-Anon for family members of Alcoholics Anonymous (AA).\n\nSRA was founded around 1993 and is said to be a \"progressive offshoot\" of Sexaholics Anonymous (SA) and is said to be \"far more diverse\" with a strong presence of women, African Americans, Asians, and members of the LGBT community. SRA also differs from SA by allowing sexual relations between two people in a “committed relationship”, while SA only allows a heterosexual spouse as an acceptable partner.\n\n\n"}
{"id": "52071804", "url": "https://en.wikipedia.org/wiki?curid=52071804", "title": "Shooting of Deborah Danner", "text": "Shooting of Deborah Danner\n\nDeborah Danner, 66, was fatally shot by New York Police Department Sgt. Hugh Barry on October 18, 2016, in her home in the Bronx, New York. According to police sources, she was armed with first a pair of scissors and then a baseball bat. According to an emergency medical technician, she had put the scissors down, and never picked up a baseball bat. \n\nBarry was charged with murder and manslaughter in May, 2017. He was acquitted in February, 2018. \n\nOn October 18th, 2016, a neighbor called 911 at 6:05 p.m. and reported that Danner was erratic. Police had been called to her apartment before. \n\nAccording to the police, Danner had scissors, and Barry talked her into putting them down. Then she picked up a baseball bat and swung at him. Barry shot Danner twice, fatally wounding her. He was the only officer in the bedroom, although others were on the scene.\n\nAccording to court testimony by Brittney Mullings, an emergency medical technician, Mullings had arrived before Barry. Danner had put down the scissors and Mullings was talking to her. Danner was not holding anything in her hands. Mullings was trying to explain to Danner why they had arrived. Barry then arrived, and did not talk to Mullings or Danner. The police interrupted their conversation, and Danner retreated into her bedroom. Six police officers followed Danner into her bedroom, and a minute later, Mullings heard two shots. \n\nDanner was mentally ill and had written an essay, \"Living With Schizophrenia\", in 2012. She was a parishioner who regularly attended Trinity Church Wall Street, and was active in that community's groups and ministries.\n\nLess than six hours after the death, Sergeant Barry was placed on administrative duty and stripped of his badge and gun. According to \"The New York Times\", \"Mayor Bill de Blasio said at a news conference that the sergeant had not followed training or protocols for dealing with those with mental illness, and for some reason had neither used his Taser nor waited for specialized officers trained to deal with such situations.\"\n\nThe death of Danner, who was black, spurred a protest on October 19. Protestors marched from her apartment building to the 43rd Precinct station house. Marchers included members of the New York Black Lives Matter chapter.\n\nBarry was arrested and charged with second-degree murder on May 31, 2017.\nOn February 14, 2018, Barry was acquitted by a judge in a non-jury trial. The judge ruled that although he had violated department protocol by escalating the encounter, once he found himself in a dangerous situation in which he feared for his life, he was justified in using lethal force.\n"}
{"id": "14360242", "url": "https://en.wikipedia.org/wiki?curid=14360242", "title": "St. Jude Medical Center", "text": "St. Jude Medical Center\n\n\"Not affiliated with St. Jude Children's Research Hospital in Memphis, Tennessee\"\n\nSt. Jude Medical Center is a faith-based, not-for-profit hospital, located in Fullerton, California, which was established by the Sisters of St. Joseph of Orange in 1957.\n\nPart of the St. Joseph Health System, St. Jude Medical Center serves as a quaternary and referral center for a variety of patient services, including one of California's only accredited programs in spinal cord injury, brain injury, and comprehensive stroke rehabilitation. Other areas of specialty include: high- and low-risk maternity, digestive diseases and GI surgery, orthopedics and joint replacement, neurosciences, women's health, rehabilitation, cardiac care, robotic and minimally-invasive surgery, and cancer care. \n\nIn 2014, the hospital opened the $255 million Northwest Tower, which along with the Southwest Tower built several years earlier, created beautifully-designed, private patient rooms. Key areas of expansion included three entire floors dedicated to maternity services and another floor encompassing 14 \"smart\" surgical suites, including a \"hybrid\" cardiovascular suite with robotic c-arm imaging, and a dedicated neurosurgery suite with intraoperative MRI. Additional surgical technology includes da Vinci surgical robots as well as the superDimension robotic system for lung cancer treatment.\n\n\nSt. Jude Medical Center is one of three St. Joseph Health hospitals in Orange County – each founded by the Sisters of St. Joseph of Orange—part of a 14-hospital system within the western United States that includes outpatient services, fetal diagnostic center, as well as inpatient services. In 2014, a partnership with Hoag Hospital created an integrated health system called St. Joseph Hoag Health. \n\nThe Sisters of St. Joseph of Carondelet began operating their first hospital in Eureka, California in 1919 in response to the Spanish Flu epidemic. The Order moved its mother house to Orange County in 1922. They acquired Fullerton General Hospital, a historic facility designed by Frederick Eley, in 1931, but it did not meet postwar standards for operation. The Sisters began raising the one million dollars estimated as necessary to build a new hospital.\n\nIn 1953 a group of physicians, led by Ramiro Fernandez, M.D., met with the sisters to see about building a new hospital. It was Dr. Fernandez’s wife, Emily, who suggested the name St. Jude, the patron saint of desperate situations. \n\nA businessman, Miles Sharkey, donated land in western Fullerton with the stipulation that it be used to build a hospital. Of the acquired by the Sisters, the first was deeded to them for $10. On November 24, 1953, the hilltop property on which St. Jude Hospital was later built was blessed and dedicated.\n\nSt. Jude's Hospital was publicly dedicated on May 11, 1957, with 2000 spectators in attendance as well as dignitaries including Congressman James B. Utt and Cardinal James McIntyre, Archbishop of Los Angeles.\n\n"}
{"id": "56295168", "url": "https://en.wikipedia.org/wiki?curid=56295168", "title": "Urethrovaginal fistula", "text": "Urethrovaginal fistula\n\nA urethrovaginal fistula is an abnormal passageway between the urethra and the vagina. It results in urinary incontinence as urine continually leaves the vagina. It can occur as an obstetrical complication, catheter insertion injury or a surgical injury.\n"}
{"id": "40965283", "url": "https://en.wikipedia.org/wiki?curid=40965283", "title": "Water supply and sanitation in Algeria", "text": "Water supply and sanitation in Algeria\n\nDrinking water supply and sanitation in Algeria is characterized by achievements and challenges. Among the achievements is a substantial increase in the amount of drinking water supplied from reservoirs, long-distance water transfers and desalination at a low price to consumers, thanks to the country's substantial oil and gas revenues. These measures increased per capita water supply despite a rapidly increasing population. Another achievement is the transition from intermittent to continuous water supply in the capital Algiers in 2011, along with considerable improvements in wastewater treatment resulting in better water quality at beaches. These achievements were made possible through a public-private partnership with a private French water company. The number of wastewater treatment plants throughout the country increased rapidly from only 18 in 2000 to 113 in 2011, with 96 more under construction. However, there are also many challenges. One of them is poor service quality in many cities outside Algiers with 78% of urban residents suffering from intermittent water supply. Another challenge is the pollution of water resources. There has also been insufficient progress concerning reuse of treated water, a government priority in this dry country.\n\nIn 2015, in Algeria 84% of the population had access to \"improved\" water, 84% and 82%, in urban and rural areas, respectively. In 2015, there were still around 7 million lacking access to \"improved\" water. Regarding sanitation, 88% of the population had access to \"improved\" sanitation, 90% and 82%, in urban and rural areas, respectively.\n\nAccording to the UN, 84% of Algerians had access to an improved water source in 2010, including 74% that had access to drinking water on their premises. The remainder had access to fountains, standpipes, protected wells or protected springs, mostly in rural areas. 95% of Algerians had access to improved sanitation. The Algerian government states that access water supply is higher than shown in the UN statistics, with 93% being linked to drinking water networks in 2010. It also says that 86% of the population are connected to sewer networks.\n\nOnly 22% of urban residents in Algeria receive water 24 hours per day. 34% receive water only once per day, 24% every second day and 14% only every third day. In some regions water only comes every 10 days, such as in the Bouzeguène District and other districts in the Kabylie region. These shortages are \npoor execution and lack of completion of works, poor maintenance and numerous illegal connections to the network. Residents store water in tanks or jerry cans in their houses, or fill up jerry cans at water towers particularly during the summer. In Setif in Northeastern Algeria water shortages have led to protests and clashes with the police. In contrast, in Algiers continuous water supply was established with the help of a French private company, SUEZ, in 2011.\n\nDrinking water in Algeria comes from conventional resources – surface water and groundwater – as well as non-conventional resources such as seawater desalination.\n\nSince rainfall is highly seasonal, surface water is stored in 72 reservoirs with a total production capacity of 7.4 billion m per year in 2009. Most of this water is used for irrigation. Total drinking water supply was about 2.8 billion m per year. One of the largest reservoir systems in Algeria is the Beni Haroun complex in Mila Province that supplies water for irrigation and drinking water to 4 million people in six provinces in the East of Algeria. Another large system is the Taksebt complex in Tizi Ouzou in Kabylie. It supplies three provinces, including parts of the capital Algiers, with drinking water. In the Bouira Province, water is supplied from the Koudiat Acerdoune dam. The longest water transfer project in Algeria, dubbed \"project of the century\", transfers non-renewable groundwater from In Salah to Tamanrasset in the Sahara over a distance of 750 km. It was completed in 2011 at a cost of USD 2.5 billion.\n\nIn some parts of the country, such as in the valleys of El Oued and Ouargla, a rising water table due to seepage from septic tanks was a major problem. Beginning in 2005 at a cost of almost 1 billion USD sewers were laid, pumping stations and treatment plants were built to convey the reclaimed water to agricultural areas for reuse.\n\nPollution of water resources has reached a worrying degree. Groundwater in the Mitidja plain close to Algiers is polluted with nitrates, and groundwater in coastal areas is often damaged by saline intrusion from the sea due to overpumping. This is the case in the Oran, Algiers and Jijel areas. Major parts of the rivers Tafna, Macta, Chéliff, Soummam and Seybousse are polluted. Some of them, such as the country's largest river, the Chéliff that supplies the Oran area, are used for drinking water supply. In the Constantine area the level of manganese and of chlorides in drinking water was close to those allowed by the WHO as of 2004.\n\nAlgeria had 15 seawater desalination plants along its coast in 2011 with a capacity of 2.3 million m/day. It plans to build 43 more until 2019. Several desalination plants supply the Oran area that is particularly water-scarce. The first one was inaugurated in 2005 under the name Kahrama close to the industrial zone of Arzew. 20,000 m/day are supplied to industry and 70,000 m/day to the city. Two smaller plants became operational a few months later. In 2009 the first phase of a much larger plant with a capacity of 200,000 m/day was put into production in Chatt el Hilal to supply Aïn Témouchent and Oran. Another 200,000 m/day plant in Mostaganem was under construction as of 2010, as well as a plant in Mactaa with a capacity of 500,000 m/day, making it one of the largest plants in the world. Prior to the completion of the Mactaa plant, the Hamma plant in Algiers completed in 2008 was the largest desalination plant in Africa with a capacity of 200,000 m/day.\n\nThe reuse of treated wastewater for irrigation is a priority of the state. A government decree – Decree No. 07-149 of 20 May 2007 – sets out the procedures to grant a permit for the use of reclaimed water for irrigation. However, as of 2010 only 510 hectares were irrigated with reclaimed water. An additional 3,800 hectares were fully equipped for reuse without being operated. Studies for additional projects for irrigation of another 9,800 hectares with reclaimed water were completed.\n\nThe water distribution system in Algeria is 105,000 km long. AdE manages a network of 50,000 km as well as 2,528 wells, \n72 water treatment plants, 10 desalination plants, 1,141 pumping stations and 4,798 reservoirs.\n\nThe sewer system is 41,000 km long and there are 113 municipal wastewater treatment plants, including 56 using activated sludge technology and 67 mostly smaller plants using different kinds of lagoon technologies. There were only 18 plants in the country in 2000; 96 more plants were under construction in 2011.\n\nAccording to government sources, in 2011 average water production was as high as 170 liter per capita and day. As of 2000, per capita water production varied between different parts of the country. It was highest in Ghardaia with 220 liter per capita per day and lowest in Sidi Bel Abbes with only 65 liter. In Oran and Mostaganem water production was only 70 liter. Actual water use is lower than the above figures because of distribution losses. Non-revenue water, consisting of physical and administrative losses, was estimated at 40% in 2004.\n\nThe Ministry of Water Resources is in charge of policy-making for drinking water supply and sanitation, as well as for water resources management. Within the Ministry there is a directorate for drinking water and another directorate for sanitation and the environment. The Ministry also has 48 branches in each province (wilaya) of Algeria.\n\n80% of water distribution systems in Algeria are under the responsibility of Algérienne des Eaux (AdE), a state-owned company. Most sewer systems are under the responsibility of the Office National d'Assainissement (ONA). Both entities were created in 2001 and operate under the supervision of the Ministry of Water Resources that was established a year earlier.\n\nAdE serves 3.4 million customers in 814 out of 1,541 municipalities. By law it is charged not only to provide water services, but also to promote water conservation and to increase public awareness. The company operates extensive water transmission systems that transfer water over long distances, often covering several provinces. AdE has branches (unités) in each of the country's 48 provinces. In each of the four largest cities of Algeria, a joint subsidiary of AdE and ONA provides water and sanitation services:\n\nIn other parts of its service area, AdE directly provides water services through 15 \"zones\", each comprising two to four provinces. In 2014, AdE had 25,000 employees.\n\nONA operates sanitation systems on behalf of 708 municipalities and has more than 8,000 employees. It operates 68 wastewater treatment plants, about half the plants in the country. The remainder are operated by private companies operating under management contracts in the largest cities or by municipalities.\n\nThe Algerian Energy Company (AEC) develops power plants as well as desalination plants. It is a subsidiary of Sonatrach and Sonelgaz.\n\nThe private sector operates the water supply and sanitation systems of three large cities, i.e. Algiers, Oran and Constantine, under management contracts with AdE and ONA.\n\nAlgeria plans to invest 20 billion US dollar in the water sector during the Five-Year Plan 2010-2014. Dams, which have accounted for 43% of water investments in 1995–2004, continue to be an important focus of water investments. Most investments are financed by the Algerian state from its vast oil and gas revenues. However, many desalination plants are financed by foreign direct investment through Build-Operate-Transfer (BOT) contracts.\n\nThe legal basis for water and sanitation tariffs is Decree 05-13 of January 9, 2005, on tariff policy (politique de tarification). It specifies five tariff zones: the hydrographic zones of Algiers, Oran, Costantine, Chlef and Ouargla covering together the entire country. However, in practice water and sanitation tariffs are almost the same throughout the zones, with tariffs being only 3 percent lower in the Chlef zone and about 8 percent lower in the Ouargla zones compared to the three other zones. Tariffs comprise a fixed and a variable component. The decree also defines three user categories: residential; administration and services; as well as industrial and touristic. The variable tariff component for residential users increases by consumption blocks. In the highest of the four blocks is 6.5 times more expensive than in the lowest block. The tariff in the other two user categories corresponds to the tariff in the highest residential consumption block. Tariffs are very low and are far from covering the costs of supply. Tariff increases have to be approved by the national government.\n\nThe first block of the residential tariffs, also called \"social block\" (tranche sociale), is charged until a consumption of 25 cubic meter per quarter, corresponding to 55 liter per capita per day for a family of five. In 2005 this tariff was 6.3 Algerian Dinar per cubic meter or 9 US Cents in the Algiers, Oran and Constantine zones. In 2014, this tariff remained unchanged according to the website of AdE. This tariff is about 20 times lower than water tariffs in Central Europe. The sewer tariff is even lower than the water tariff. For residential users in the first block in the zones Algiers, Constantine and Annaba it is 2.35 Algerian dinar per cubic meter or 3 US cents.\n\nThe European Union (EU), through the European Commission, is an important external partner for the Algerian water sector. It provided a grant of 30 million Euro in 2011 to support sanitation through a program called EAU II. An earlier 20 million Euro grant called EAU I financed the updating of the National Water Plan, an operational plan for the Ghrib dam, an early warning and forecasting system for floods in Sidi Bel Abbés as well as an electronic documentation system for the Ministry of Water Resources. In 2011 the Société Wallonne des Eaux (SWDE) from Belgium and AdE signed a twinning contract to improve water quality monitoring. The contract had a duration of 18 months and was supported by the EU. It was followed by a second contract with a duration of three years signed in December 2013.\n\n"}
{"id": "32837403", "url": "https://en.wikipedia.org/wiki?curid=32837403", "title": "Zimbabwe at the 2000 Summer Paralympics", "text": "Zimbabwe at the 2000 Summer Paralympics\n\nThere were 1 female and 2 male athletes representing the country at the 2000 Summer Paralympics.\n\n\n"}
{"id": "44076906", "url": "https://en.wikipedia.org/wiki?curid=44076906", "title": "Éctor Jaime Ramírez Barba", "text": "Éctor Jaime Ramírez Barba\n\nÉctor Jaime Ramírez Barba (born 1 December 1956) is a Mexican surgeon and politician affiliated with the National Action Party. As of 2014 he served as Deputy of the LX Legislature of the Mexican Congress representing Guanajuato.\n"}
