{"id": "56746806", "url": "https://en.wikipedia.org/wiki?curid=56746806", "title": "2017–18 South African listeriosis outbreak", "text": "2017–18 South African listeriosis outbreak\n\nThe 2017–18 South African listeriosis outbreak is an ongoing widespread outbreak of \"Listeria monocytogenes\" food poisoning that resulted from contaminated processed meats produced by Enterprise Foods, a subsidiary of Tiger Brands, in Polokwane. As of 12 March 2018, there have been 183 deaths and 973 confirmed infections. It is the world's worst ever listeriosis outbreak.\n\nThe outbreak was first identified by doctors at Chris Hani and Steve Biko academic hospitals in July 2017, who notified the National Institute for Communicable Diseases (NICD) about an unusually high number of neonatal infections.\n\nInterviews conducted by the authorities with people who contracted listeriosis indicated that processed cold meats, most notably polony, was the likely cause of the outbreak. However source of the outbreak at the Enterprise Foods facility was only discovered after nine five year old children from Soweto were brought to Chris Hani Baragwanath Hospital in mid-January 2018. Samples taken from Enterprise and Rainbow Chicken polony products at the crèche the children attended tested positive for the strain of listeriosis causing the outbreak and led investigators to the infected production facilities.\n\nOn March 4 2018, Health Minister Aaron Motsoaledi announced that the disease was traced to the Enterprise processed meats factory in Polokwane. Environmental samples from the factory were found to contain the bacterium Listeria monocytogenes strain ST 6, the strain responsible for the outbreak. Additionally, further samples from another Enterprise factory in Germiston and from a Rainbow Chicken factory in the Free State tested positive for Listeria, although which strain these samples tested positive for is not yet known.\n\nIn January 2017 the first laboratory confirmed cases of the outbreak had been made. By December 2017 the outbreak had been declared by the South African Ministry of Health, stating that the ministry was “very concerned” by the outbreak. By mid-January 2018 around 557 cases had been confirmed with most incidences recorded in the Gauteng Province.\n\nBy 24 February 2018 the outbreak had caused the deaths of 164 people and infected a further 872 people. By 5 March 2018 a total of 180 people were thought to have died from the outbreak with 78 of the deaths being infants.\n\nFollowing the announcement, Tiger Brand's stock price on the Johannesburg Stock Exchange dropped by 7%, resulting in a R5.7bn (equivalent to 438.69 million USD) reduction in total value. At a press conference the next day, Tiger Brands CEO Lawrence MacDougall denied responsibility, stating \"There is no direct link between any of the deaths and our products.\" When pressed by journalists, he refused to apologize. \n\nThe South African government issued a recall notice of all products of RCL Foods Limited and Enterprise Foods and Rainbow Chicken facilities on March 4. Tiger Brands reportedly admitted to knowing about the presence of listeriosis in some of its products eighteen days before the government recall.\n\nOn March 5, Botswana, Namibia, Mauritius, Mozambique, Malawi and Zambia suspended all imports of processed meat from South Africa. Kenya followed suit on the next day. \n"}
{"id": "25953785", "url": "https://en.wikipedia.org/wiki?curid=25953785", "title": "Abortion in Estonia", "text": "Abortion in Estonia\n\nAbortion in Estonia has been legal since 23 November 1955, when Estonia was part of the Soviet Union. Estonia fine-tuned their legislation after the restoration of independence.\n\nEstonia allows abortion on-demand for any purpose, before the end the 11th week of pregnancy. Later abortions are permitted up to the 21st week (included) if the woman is younger than 15 years old or older than 45 years old, if the pregnancy endangers the woman's health, if the child may have a serious physical or mental defect, or if the woman's illness or other medical problem hinders the child's development.\n\nWomen who want to have an abortion for personal reasons not specified in the abortion legislation will be expected to pay a fee according to the abortion provider's price list. Abortion performed for medical reasons is covered for insured persons by the Estonian Health Insurance Fund.\n\n38.7% of pregnancies ended in abortion in Estonia in 2006, a decline from 49.4% just six years before.\n\nIn 2010, there were 9087 abortions in Estonia, which meant 57.4 abortions for every hundred live births. , the abortion rate was 25.5 abortions per 1000 women aged 15-44 years. \n\nMifepristone (medical abortion) was registered in 2003.\n"}
{"id": "54418352", "url": "https://en.wikipedia.org/wiki?curid=54418352", "title": "Abrasion collar", "text": "Abrasion collar\n\nThe denuded area of skin seen around projectile wounds is called an abrasion collar. Though this findings is often seen around rifled firearm entry wounds, some other high speed projectile wounds can also have this finding. A similar finding is also likely in firearm exit wounds if the skin at the exit was crushed between the outgoing bullet and an unyielding object pressed against the skin over the exit site.\n\nThe bullet shape influences the size of the abrasion collar. High velocity bullets with spitzer tip and full metal jacket are less likely to produce abrasion collar compared to civilian bullets which have a cylindrical round nose.\n"}
{"id": "8109667", "url": "https://en.wikipedia.org/wiki?curid=8109667", "title": "All About You (TV series)", "text": "All About You (TV series)\n\nAll About You was an educational television series that was syndicated to numerous educational and PBS stations during the early and mid-1970s, mainly as part of weekday in-school telecasts.\n\nThe series was first produced at WHRO-TV, \"Hampton Roads ETV\", in Hampton, Virginia. In 1974, production of the series was moved to WGBH-TV Boston, where it was produced in association with WGBH's in-school television initiative, the \"21-Inch Classroom\". The 1974 episodes were distributed in the US and Canada by the Agency for Instructional Television; this is one of a few WGBH series to have not been distributed by NET or PBS.\n\n\"All About You\" was a series of short, videotaped programs that generally ran for 15 minutes or less that were hosted by Louise McNamara and written by Ada Litchfield. The show was geared towards youngsters aged 6–8 as a way to educate them on their bodies, especially where they came from, why they have what they have, what makes them work and why they work. The show's opening and closing credits always featured slides of cartoon drawings of kids enjoying themselves at a circus with appropriate circus music.\n\n\n"}
{"id": "5471132", "url": "https://en.wikipedia.org/wiki?curid=5471132", "title": "Beginning of pregnancy controversy", "text": "Beginning of pregnancy controversy\n\nControversy over the beginning of pregnancy occurs in different contexts, particularly as it is discussed within the abortion debate in the United States. Because an abortion is defined as ending an established pregnancy, rather than as destroying a fertilized egg, depending on when pregnancy is considered to begin, some methods of birth control as well as some methods of infertility treatment might be classified as causing abortions. \n\nThe controversy is not primarily a scientific issue, since knowledge of human reproduction and development has become very refined; the linguistic questions remain debated for other reasons. The issue poses larger social, legal, medical, religious, philosophical, and political ramifications because some people, such as Concerned Women for America, equate the beginning of a pregnancy with the beginning of an individual human being's life. Many of these arguments are related to the anti-abortion movement. In this way of thinking, if the pregnancy has not yet begun, then stopping the process is not abortion and therefore can contain none of the moral issues associated with abortion, but if it is a pregnancy, then stopping it is a morally significant act. \n\nA major complication is that ideological and religious concepts such as \"ensoulment\" (whether or not a human being is said to have gone from mere matter to having a spiritual entity inside) and \"personhood\" (whether or not a human being is said to be a distinct individual with innate human rights versus otherwise) exist outside of scientific analysis, and thus many individuals have argued that the beginning of pregnancy cannot be determined strictly through physical evidence alone. No experiment exists (or can exist) to measure the spirituality of an object or living thing in the same way that height, temperature, weight, etc. can be studied. \n\nGenerally speaking, some ideological and religious commentaries have argued that pregnancy should be stated as beginning at the first, exact moment of conception in which a human sperm makes full contact with an egg cell. In contrast, other commentaries have argued that the duration of pregnancy begins at some other point, such as when the fertilization process ends (when a new, independent cell genetically distinct from the prior egg and sperm exists) or when implantation occurs (when the new set of cells lodges itself against the uterine wall, allowing it to grow rapidly). The ambiguity's implications mean that, despite the scientific community being able to describe the physical processes in detail, the decision about what should be called \"abortion\" and what should be called \"contraception\" or pregnancy prevention are not agreed upon.\n\nTraditionally, doctors have measured pregnancy from a number of convenient points, including the day of last menstruation, ovulation, fertilization, implantation and chemical detection. This has led to some confusion about the precise length of human pregnancy, as each measuring point yields a different figure.\n\nAt its 2004 Annual Meeting, The American Medical Association passed a resolution in favor of making \"Plan B\" emergency contraception available over-the-counter, and one of the claims in the resolution was that hormonal contraception that may affect implantation \"cannot terminate an established pregnancy.\" Similarly, the British Medical Association has defined an \"established pregnancy\" as beginning at implantation. The legal definition in the United Kingdom is not clear.\n\nOther definitions exist. The American Heritage Stedman's Medical Dictionary defines \"pregnancy\" as \"from conception until birth.\" Definitions like this may add to a lay person's confusion, as \"conception\" in a scientific context may be defined as fertilization, in a medical context can mean either fertilization or implantation but in lay terms may mean both.\n\nWhether conception refers to fertilization or implantation would seemingly even impact \"established pregnancies\" such as an ectopic pregnancy. If conception is defined as at implantation, ectopic pregnancies could not be called pregnancies. However, some medical professionals who oppose birth control, such as Walter Larimore of the Focus on the Family group, have argued that the medical definition of conception should include fertilization.\n\nFinally, the standard historical method of counting the duration of pregnancy begins from the last menstruation and this remains common with doctors, hospitals, and medical companies. This system is convenient because it is easy to determine when the last menstrual period was, while both fertilization and implantation occur out of sight. An interesting consequence is that the dating of pregnancy measured this way begins two weeks before ovulation.\n\nAlthough many individuals who have identified as 'anti-abortion' and/or 'pro-life', have argued that both pregnancy and status of a separate human life beginning happen at fertilization, several examples also exist of people within those movements taking alternate views. For example, doctor and social activist Bernard Nathanson wrote in his 1979 work \"Aborting America\" that a confirmed moment of implantation should be considered the point at which a distinct human being exists. He specifically stated (note that 'alpha' is his shorthand for an organized group of cells), \"Biochemically, this is when alpha announces its presence as part of the human community by means of its hormonal messages, which we now have the technology to receive... know[ing] biochemically that it is an independent organism distinct from the mother.\"\n\nIn August 2008, the U.S. Department of Health and Human Services proposed a regulation to protect certain actions of health workers: refusal to provide patient services that the health workers believe to be abortifacient. The ban on discrimination against these employees would apply to all organizations that receive grant money from HHS. A draft version leaked in July proposed that the U.S. federal government define abortion as including \"termination of [human] life... before... implantation.\" The official proposal dropped the definition of abortion, instead leaving it to the objecting individual to define abortion for him- or herself. Groups on both sides of the controversy believe the ban is intended to allow health workers to refuse to dispense IUDs and hormonal contraceptives, including emergency contraception. It has drawn widespread criticism from major medical and health groups.\n\nIn the past, pregnancy has been defined in terms of conception. For example, \"Webster's Dictionary\" defined \"pregnant\" (or \"pregnancy\") as \"having conceived\" (or \"the state of a female who has conceived\"), in its 1828 and 1913 editions. However, in the absence of an accurate understanding of human development, early notions about the timing and process of conception were often vague.\n\nBoth the 1828 and 1913 editions of \"Webster's Dictionary\" said that to \"conceive\" meant \"to receive into the womb and ... begin the formation of the embryo.\" However most references say that it was only in 1875 that Oskar Hertwig discovered that fertilization includes the penetration of a spermatozoon into an ovum. Thus, the term \"conception\" was in use long before the details of fertilization were discovered. By 1966, a more precise meaning of the word \"conception\" could be found in common-use dictionaries: the formation of a viable zygote.\n\nIn 1959, Dr. Bent Boving suggested that the word \"conception\" should be associated with the process of implantation instead of fertilization. Some thought was given to possible societal consequences, as evidenced by Boving's statement that \"the social advantage of being considered to prevent conception rather than to destroy an established pregnancy could depend on something so simple as a prudent habit of speech.\" In 1965, the American College of Obstetricians and Gynecologists (ACOG) adopted Boving’s definition: \"conception is the implantation of a fertilized ovum.\"\n\nThe 1965 ACOG definition was imprecise because, by the time it implants, the embryo is called a blastocyst, so it was clarified in 1972 to \"Conception is the implantation of the blastocyst.\" Some dictionaries continue to use the definition of conception as the formation of a viable zygote.\n\nBirth control methods usually prevent fertilization. This cannot be seen as abortifacient because, by any of the above definitions, pregnancy has not started. However, some methods might have a secondary effect of preventing implantation, thus allowing the proembryo to die. Those who define pregnancy from fertilization subsequently may conclude that the agents should be considered abortifacients.\n\nSpeculation about post-fertilization mechanisms is widespread, even appearing on patient information inserts for hormonal contraception, but there is no clinical support. One small study, using fourteen women, might be considered as providing evidence of such an effect for IUDs and a study of the combined oral contraceptive pill has been proposed.\n\n\nA related issue that comes up in this debate is how often fertilization leads to an established, viable pregnancy. Research in in-vitro fertilization patients suggests that fertilized embryos fail to implant some 30% to 70% of the time, although it is unknown whether this rate corresponds to inherently low human implantation rates (in natural conception) or to an altered physiological state. Of those that do implant, about 25% suffer early pregnancy loss by the sixth week LMP (after the woman's Last Menstrual Period), and an additional 7% miscarry or are stillborn. As a result, even without the use of birth control, between 50% and 70% of zygotes never result in established pregnancies, much less birth.\n\nThe intention of a woman to prevent pregnancy is an important factor in whether or not the act of contraception is seen as abortive by some pro-life groups. Hormonal contraceptives have a possible effect of preventing implantation of a blastocyst, as discussed previously. Use of these drugs with the intention of preventing pregnancy is seen by some pro-life groups as immoral. This is because of the possibility of causing the end of a new human life.\n\nHowever, hormonal contraception can also be used as a treatment for various medical conditions. When implantation prevention is unintentionally caused as a side effect of medical treatment, such pro-life groups do not consider the practice to be immoral, citing the bioethical principle of double effect. Likewise, when a hormonal contraceptive is used with the intention of preventing fertilisation, the intended reduction in implantation failures, miscarriages and deaths from childbearing may outweigh the possibility that the method might cause some implantation failures.\n\nA related application of the principle of double effect is breastfeeding. Breastfeeding greatly suppresses ovulation, but eventually an ovum is released. Luteal phase defect, caused by breastfeeding, makes the uterine lining hostile to implantation and as such may prevent implantation after fertilization. Some pro-choice groups have expressed concern that the movement to recognize hormonal contraceptives as abortifacient will also cause breastfeeding to be considered an abortion method.\n\nA protein called early pregnancy factor (EPF) is detectable in a woman's blood within 48 hours of ovulation if fertilization has occurred. However, testing for EPF is time consuming and expensive; most early pregnancy tests detect human chorionic gonadotropin (hCG), a hormone that is not secreted until after implantation. Defining pregnancy as beginning at implantation thus makes pregnancy a condition that can be easily tested.\n\nThe distinction in ethical value between existing persons and potential future persons has been questioned. Subsequently, it has been argued that contraception and even the decision not to procreate at all could be regarded as immoral on a similar basis as abortion. In this sense, beginning of pregnancy may not necessarily be equated with where it is ethically right or wrong to assist or intervene. In a consequentialistic point of view, an assisting or intervening action may be regarded as basically equivalent whether it is performed before, during or after the creation of a human being, because the end result would basically be the same, that is, the existence or non-existence of that human being.\n\n"}
{"id": "46176396", "url": "https://en.wikipedia.org/wiki?curid=46176396", "title": "Community for Open Antimicrobial Drug Discovery", "text": "Community for Open Antimicrobial Drug Discovery\n\nThe Community for Open Antimicrobial Drug Discovery (CO-ADD) is a not-for-profit initiative created in 2015 reaching out to chemists in academia and research organisations who have compounds that were not designed as antibiotics and would not otherwise be screened for antimicrobial activity. These academic compounds are screened against a key panel of drug-resistant bacterial strains -superbugs. Multi-drug resistant microbes are a serious health treat, and exploration of novel chemical diversity is essential to find new antibiotics.\n\nCO-ADD's goal is to find new, diverse compounds to combat the superbug crisis in screening chemical compounds for anitmicrobial activity against key ESKAPE pathogens, E. coli, K. pneumoniae, A. baumannii, P. aeruginosa, S. aureus (MRSA), as well as the fungi C. neoformans and C. albicans.\n\nCO-ADD is supported by the Wellcome Trust through a Strategic Award and The University of Queensland (Institute for Molecular Bioscience), where the compound screening facilities are located.\n\nCO-ADD is a community-driven solution to the superbug crisis problem providing chemists with:\n\nResistance of bacteria to commonly used antibiotics is increasing and contributes significantly to patient morbidity and mortality. Klebsiella species, Acinetobacter baumannii, P. aeruginosa, and Enterobacter species, together with the gram-positive Enterococcus faecium and Staphylococcus aureus are responsible for two-thirds of all health care-associated infections.\n\nThe World Health Organization (WHO) has declared antimicrobial resistance to be one of the greatest threats to human health. On World Health Day 2011, themed ‘combating antimicrobial resistance’, WHO issued an international call for concerted action to halt the spread of antimicrobial resistance, launching a six-point policy package, recommended for governments, which sets out the measures governments and their national partners need to combat drug resistance.\n\n"}
{"id": "8309538", "url": "https://en.wikipedia.org/wiki?curid=8309538", "title": "Diana Baumrind", "text": "Diana Baumrind\n\nDiana Blumberg Baumrind (August 23, 1927 - September 13, 2018) was a clinical and developmental psychologist known for her research on parenting styles and for her critique of the use of deception in psychological research.\n\nBaumrind was born into a Jewish community in New York City, the first of two daughters of Hyman and Mollie Blumberg. She completed her B.A. in Psychology and Philosophy at Hunter College in 1948, and her M.A. and Ph.D. in Psychology at the University of California, Berkeley. Her doctoral dissertation was entitled \"Some personality and situational determinants of behavior in a discussion group\".\n\nAfter being awarded her doctorate she served as a staff psychologist at Cowell Memorial Hospital in Berkeley. She was also director of two U. S. Public Health Service projects and a consultant on a California state project. From 1958-1960 she also had a private practice in Berkeley.\n\nShe is a developmental psychologist at the Institute of Human Development, University of California, Berkeley. She is known for her research on parenting styles and for her critique of deception in psychological research, especially Stanley Milgram's controversial experiment.\n\nHer parenting styles were based on two aspects of parenting that are found to be extremely important. The first was \"Parental responsiveness\", which refers to the degree the parent responds to the child's needs. The second was \"Parental demandingness\" which is the extent to which the parent expects more mature and responsible behavior from a child. Using these two dimensions, she recognizes three different parenting styles:\n\n\nBaumrind has studied the effects of corporal punishment on children, and has concluded that mild spanking, in the context of an authoritative (\"not\" authoritarian) parenting style, is unlikely to have a significant detrimental effect, if one is careful to control for other variables such as socioeconomic status. She observes that previous studies demonstrating a correlation between corporal punishment and bad outcomes failed to control for variables such as socioeconomic status. Low-income families are more likely to employ corporal punishment compared with affluent families. Children from low-income neighborhoods are more likely to commit violent crimes compared with children from affluent neighborhoods. But when appropriate controls are made for family income and other independent variables, Baumrind believes that mild corporal punishment per se does not increase the likelihood of bad outcomes. This assertion has in turn attracted criticism and counter-points from other researchers in the same publication, for example: Whether harmful or not, there is still no consistent evidence of beneficial effects.\n\nHer scientific influences include Theodor Adorno, Else Frenkel-Brunswik, Daniel J. Levinson, Nevit Sanford, Egon Brunswik, David Krech, Richard S. Crutchfield\n\n\n"}
{"id": "25821914", "url": "https://en.wikipedia.org/wiki?curid=25821914", "title": "DrugScience", "text": "DrugScience\n\nDrugScience (originally called the Independent Scientific Committee on Drugs (ISCD)) is a UK-based drugs advisory committee proposed and initially funded by hedge fund manager Toby Jackson. It is chaired by Professor David Nutt and was officially launched on 15 January 2010 with the help of the Centre for Crime and Justice Studies. The primary aim of the committee is to review and investigate the scientific evidence of drug harms without the political interference that could result from government affiliation.\n\nThe establishment of the committee followed the controversial sacking of Professor Nutt, on 30 October 2009 as chair of the UK's statutory Advisory Council on the Misuse of Drugs by UK Home Secretary, Alan Johnson after the Equasy controversy. The controversy followed his Eve Saville Memorial Lecture (2009) at the Centre.\n\nDrugScience initially focused on reviewing official risk estimates for psychedelic drugs, ecstasy and cannabis, and increasing warnings of the dangers of ketamine.\n\nIn 2010, DrugScience produced a ranking of drug harms in the UK, the results of which garnered significant media attention. Drugs were assessed on two metrics - harm to users and harms to society. The report found heroin, crack cocaine, and methamphetamine to be the most harmful drugs to individuals, with alcohol, heroin, and crack cocaine as the most harmful to others. Overall, alcohol was the most harmful drug, with heroin and crack cocaine in second and third places. Most notably, it found the legal status of most drugs bears little relation to the harms associated with them - several class A drugs including ecstacy (MDMA), LSD and magic mushrooms featured at the very bottom of the list. Similar findings were found by a Europe-wide study conducted by 40 drug experts in 2015.\n\nUsing a similar multi-criteria decision analysis process as the 2010 drug harm ranking, DrugScience looked to rank the harms of all nicotine-containing products, including cigarettes, cigars, nicotine patches and e-cigarettes. The report concluded that e-cigarettes are 95% less harmful than conventional cigarettes, advice which was subsequently used in a report by Public Health England on e-cigarettes and now forms part of the evidence-base for the positions of the UK Government and the National Health Service. This figure was widely reported on in the press, but remains controversial as the long-term harms of e-cigarettes remain unknown. More recent systematic reviews suggest that e-cigarettes are considerably less harmful that cigarettes, but that the difference may be smaller than previously estimated.\n\nDrugs Live: the ecstasy trial is a two-part TV documentary aired on Channel 4 on the 26th and 27 September 2012. The program showed an fMRI study on the effects of MDMA (ecstasy) on the brain, which was funded by Channel 4. The main researchers on the study were DrugScience's Val Curran and David Nutt who also appeared as guests on the show. Curran and Nutt oversaw research at Imperial College London, in which volunteers took part in a double blind study, taking either 83 mg of MDMA or a placebo before going into the fMRI scanner.\n\nThe documentary was presented by Christian Jessen and Jon Snow, and included debate on the harms of MDMA, as well as exhibiting the findings of the study. Some participants in the study also appeared on the show, including a vicar, an ex-soldier, writer Lionel Shriver, actor Keith Allen and former Liberal Democrat MP Evan Harris.\n\nNutt and colleagues have said they are preparing to run the UK's first clinical trial of MDMA-assisted psychotherapy for the treatment of PTSD, based on the research from the study.\n\n\n"}
{"id": "47306074", "url": "https://en.wikipedia.org/wiki?curid=47306074", "title": "Euthanasia in Uruguay", "text": "Euthanasia in Uruguay\n\nAssisted suicide, while criminal does not appear to have caused any convictions. Although a person who has assisted with the suicide must appear in court, article 37 of the Penal Code (effective 1934) states: \"The judges are authorized to forego punishment of a person whose previous life has been honorable where he commits a homicide motivated by compassion, induced by repeated requests of the victim.\". Whilst not de jure permitting the act, it has been interpreted to mean that judges may pardon the defendant of their crime, and so de facto authorising assisted suicide.\n\nThis is further reinforced in another article, 127, which states that the judge could waive the doctor, if this action was made by patient pledge and the doctor had an honorable reputation. This de facto permissive stance has led the respected Hungarian medical journal Orvosi Hetilap to consider Uruguay as having legalised a form of active euthanasia.\n\nThe Penal Code of Uruguay of Uruguay is seemingly the first legal document that include euthanasia. The main source of this Penal Code was Jimenéz de Asúa, a Spanish penalist, that introduce this concept in his book \"Libertad de amar y derecho a morir: ensayos de un criminalista sobre eugenesia, eutanasia, endocrinología\", published in Madrid/Spain, in 1928. The first proposal to understand Euthanasia as homicide was made by Ruy Santos in his MD thesis, \"Da resistencia dos estados mórbidos à therapeutica e da incurabilidade perante a euthanásia\", at Faculdade de Medicina da Bahia/Brazil, in 1928. He made a difference between Euthanasia as homicide and Euthanasia as suicide, probably the first citation about Assisted Suicide.\n\nIf parents attempt to refuse treatment to a minor, against the advice of the attending physician, then they would be in abuse of their parental authority, as they would be deemed to not always be acting in their child's best interests.\n\nArticle 37 was for years at odds with the country's otherwise conservative, pro-life attitude with regards to topics such as abortion, which until 2012 was illegal except in cases of protecting the mother’s life, rape or extreme poverty. Historically, attempts to liberalise that law had been vetoed by President Vazquez in 2009, despite senators from his party supporting the measure in a vote of 18-13.\n\nMeasures progressing the idea of a right to die did not advance until March 2009, when congress legislated to permit the right to die by removal of life-prolonging medical treatment. At the time, the Catholic Church were fiercely opposed to the bill, fearing that it would lead to measures permitting euthanasia or assisted dying, despite the bill prohibiting such measures.\n"}
{"id": "34893068", "url": "https://en.wikipedia.org/wiki?curid=34893068", "title": "Get-Well Gamers", "text": "Get-Well Gamers\n\nGet-Well Gamers is a charitable organization that aims to bring video game consoles and games to sick children in hospitals. The charity was founded in 2001 by Ryan Sharpe, who was hospitalized as a child and found that playing Donkey Kong Jr. and Zaxxon had been beneficial to his recovery. In 2005, the charity was officially recognized in the United States as 501(c)(3) charitable organization. By October 2006, the organization had expanded to cover over 40 hospitals in more than 20 states. The charity accepts donations of video game systems and games from 1989 and later from both individuals as well as companies. Since its founding, the group has received support from various other gaming-related organizations such as the International Game Developers Association and Nvidia.\n\nIn 2014, Get-Well Gamers expanded into Europe with the launch of Get-Well Gamers UK . \n\n"}
{"id": "51730493", "url": "https://en.wikipedia.org/wiki?curid=51730493", "title": "Global AIDS and Tuberculosis Relief Act of 2000", "text": "Global AIDS and Tuberculosis Relief Act of 2000\n\nGlobal AIDS and Tuberculosis Relief Act of 2000 or Global AIDS Research and Relief Act of 2000 is a United States federal law establishing the World Bank AIDS Trust Fund for the care and prevention of HIV/AIDS and tuberculosis in overseas continents supporting substantial populations. The Act of Congress endorsed the International Bank for Reconstruction and Development and International Development Association to govern the financial fund for the global opportunistic infection epidemics.\n\nThe H.R. 3519 legislation was passed by the 106th United States Congressional session and confirmed as a federal law by the 42nd President of the United States Bill Clinton on August 19, 2000.\n\nTitle 22 Chapter 76 codified law and Chapter 32 section amendments were drafted as three titled sections providing authorities for international assistance confronting the transmissible diseases HIV/AIDS and tuberculosis.\n\n"}
{"id": "608438", "url": "https://en.wikipedia.org/wiki?curid=608438", "title": "Gonadotropic cell", "text": "Gonadotropic cell\n\nGonadotropic cells are endocrine cells in the anterior pituitary that produce the gonadotropins, such as the follicle-stimulating hormone (FSH) and luteinizing hormone (LH). Release of FSH and LH by gonadotropes is regulated by gonadotropin-releasing hormone (GnRH) from the hypothalamus.\n\nGonadotropes appear basophilic in histological preparations.\n\nGonadotropes have insulin receptors, which can be overstimulated by too high insulin levels. This may lead to infertility as hormone release levels are disrupted.\n\nGonadotropes are feedback inhibited by specific hormones, including estradiol.\n\n"}
{"id": "31359869", "url": "https://en.wikipedia.org/wiki?curid=31359869", "title": "Healing the royal official's son", "text": "Healing the royal official's son\n\nHealing the royal official's son is one of the miracles of Jesus that appears in the Gospel of John (). This episode takes place at Cana, though the official's son is some distance away, at Capernaum.\n\nIn the Gospel of John (NIV):\n\nA similar episode appears in the Gospels of and , as Healing the Centurion's servant. While Fred Craddock treats these as the same miracle, R. T. France considers them separate miracles.\n"}
{"id": "25533720", "url": "https://en.wikipedia.org/wiki?curid=25533720", "title": "Health effects of radon", "text": "Health effects of radon\n\nRadon () is a radioactive, colorless, odorless, tasteless noble gas, occurring naturally as the decay product of radium. It is one of the densest substances that remains a gas under normal conditions, and is considered to be a health hazard due to its radioactivity. Its most stable isotope, Rn, has a half-life of 3.8 days. Due to its high radioactivity, it has been less well-studied by chemists, but a few compounds are known.\n\nRadon is formed as part of the normal radioactive decay chain of uranium into Pb. Uranium has been present since the earth was formed and its most common isotope has a very long half-life (4.5 billion years), which is the time required for one-half of uranium to break down. Thus, uranium and radon, will continue to occur for millions of years at about the same concentrations as they do now.\n\nRadon is responsible for the majority of the mean public exposure to ionizing radiation. It is often the single largest contributor to an individual's background radiation dose, and is the most variable from location to location. Radon gas from natural sources can accumulate in buildings, especially in confined areas such as attics, and basements. It can also be found in some spring waters and hot springs.\n\nAccording to a 2003 report \"EPA's Assessment of Risks from Radon in Homes\" from the United States Environmental Protection Agency, epidemiological evidence shows a clear link between lung cancer and high concentrations of radon, with 21,000 radon-induced U.S. lung cancer deaths per year—second only to cigarette smoking. Thus in geographic areas where radon is present in heightened concentrations, radon is considered a significant indoor air contaminant.\n\nRadon concentration is usually measured in the atmosphere in becquerels per cubic meter (Bq/m), which is an SI derived unit. As a frame of reference, typical domestic exposures are about 100 Bq/m indoors and 10-20 Bq/m outdoors. In the US, radon concentrations are often measured in picocuries per liter (pCi/l), with 1 pCi/l = 37 Bq/m.\n\nThe mining industry traditionally measures exposure using the \"working level\" (WL) index, and the cumulative exposure in \"working level months\" (WLM): 1 WL equals any combination of short-lived Rn progeny (Po, Pb, Bi, and Po) in 1 liter of air that releases 1.3 × 10 MeV of potential alpha energy; one WL is equivalent to 2.08 × 10 joules per cubic meter of air (J/m). The SI unit of cumulative exposure is expressed in joule-hours per cubic meter (J·h/m). One WLM is equivalent to 3.6 × 10 J·h/m. An exposure to 1 WL for 1 working month (170 hours) equals 1 WLM cumulative exposure.\n\nA cumulative exposure of 1 WLM is roughly equivalent to living one year in an atmosphere with a radon concentration of 230 Bq/m.\n\nThe radon (Rn) released into the air decays to Pb and other radioisotopes. The levels of Pb can be measured. The rate of deposition of this radioisotope is dependent on the weather.\n\nRadon concentrations found in natural environments are much too low to be detected by chemical means: for example, a 1000 Bq/m (relatively high) concentration corresponds to 0.17 pico-gram per cubic meter. The average concentration of radon in the atmosphere is about 6 atoms of radon for each molecule in the air, or about 150 atoms in each ml of air. The entire radon activity of the Earth's atmosphere at a time is due to some tens of grams of radon, consistently replaced by decay of larger amounts of radium and uranium. Concentrations can vary greatly from place to place. In the open air, it ranges from 1 to 100 Bq/m, even less (0.1 Bq/m) above the ocean. In caves, aerated mines, or in poorly ventilated dwellings, its concentration can climb to 20-2,000 Bq/m.\n\nIn mining contexts, radon concentrations can be much higher. Ventilation regulations try to maintain concentrations in uranium mines under the \"working level\", and under 3 WL (546 pCi Rn per liter of air; 20.2 kBq/m measured from 1976 to 1985) 95 percent of the time.\nThe concentration in the air at the (unventilated) Gastein Healing Gallery averages 43 kBq/m (about 1.2 nCi/L) with maximal value of 160 kBq/m (about 4.3 nCi/L).\n\nRadon emanates naturally from the ground and from some building materials all over the world, wherever traces of uranium or thorium can be found, and particularly in regions with soils containing granite or shale, which have a higher concentration of uranium. Every square mile of surface soil, to a depth of 6 inches (2.6 km to a depth of 15 cm), contains approximately 1 gram of radium, which releases radon in small amounts to the atmosphere Sand used in making concrete is the major source of radon in buildings. \n\nOn a global scale, it is estimated that 2,400 million curies (91 TBq) of radon are released from soil annually. Not all granitic regions are prone to high emissions of radon. Being a rare gas, it usually migrates freely through faults and fragmented soils, and may accumulate in caves or water. Due to its very small half-life (four days for Rn), its concentration decreases very quickly when the distance from the production area increases.\n\nIts atmospheric concentration varies greatly depending on the season and conditions. For instance, it has been shown to accumulate in the air if there is a meteorological inversion and little wind.\n\nBecause atmospheric radon concentrations are very low, radon-rich water exposed to air continually loses radon by volatilization. Hence, ground water generally has higher concentrations of Rn than surface water, because the radon is continuously produced by radioactive decay of Ra present in rocks. Likewise, the saturated zone of a soil frequently has a higher radon content than the unsaturated zone because of diffusional losses to the atmosphere. As a below-ground source of water, some springs—including hot springs—contain significant amounts of radon. The towns of Boulder, Montana; Misasa; Bad Kreuznach, Germany; and the country of Japan have radium-rich springs which emit radon. To be classified as a radon mineral water, radon concentration must be above a minimum of 2 nCi/L (74 Bq/L). The activity of radon mineral water reaches 2,000 Bq/L in Merano and 4,000 Bq/L in the village of Lurisia (Ligurian Alps, Italy).\n\nRadon is also found in some petroleum. Because radon has a similar pressure and temperature curve as propane, and oil refineries separate petrochemicals based on their boiling points, the piping carrying freshly separated propane in oil refineries can become partially radioactive due to radon decay particles. Residues from the oil and gas industry often contain radium and its daughters. The sulfate scale from an oil well can be radium rich, while the water, oil, and gas from a well often contains radon. The radon decays to form solid radioisotopes which form coatings on the inside of pipework. In an oil processing plant, the area of the plant where propane is processed is often one of the more contaminated areas, because radon has a similar boiling point as propane.\n\nTypical domestic exposures are of ≈ 100 Bq/m indoors, but specifics of construction and ventilation strongly affect levels of accumulation; a further complications for risk assessment is that concentrations in a single location may differ by a factor of two over an hour, and concentrations can vary greatly even between two adjoining rooms in the same structure.\n\nThe distribution of radon concentrations tends to be asymmetrical around the average, the larger concentrations have a disproportionately greater weight. Indoor radon concentration is usually assumed to follow a lognormal distribution on a given territory. Thus, the geometric mean is generally used for estimating the \"average\" radon concentration in an area.\nThe mean concentration ranges from less than 10 Bq/m to over 100 Bq/m in some European countries. Typical geometric standard deviations found in studies range between 2 and 3, meaning (given the 68-95-99.7 rule) that the radon concentration is expected to be more than a hundred times the mean concentration for 2 to 3% of the cases.\n\nThe so-called Watras incident (named after the American construction engineer Stanley Watras), in which an employee at a U.S. nuclear plant triggered radiation monitors while leaving work over several days—despite the fact that the plant had yet to be fueled, and despite the employee being decontaminated and sent home \"clean\" each evening, dramatized that radon levels in particular dwellings can occasionally be orders of magnitude higher than typical.\nThis implied a source of contamination outside the plant, which turned out to be radon levels of 100,000 Bq/m (2.7 nCi/L) in the worker's basement.\nRadon soon became a standard homeowner concern,\nthough typical domestic exposures are two to three orders of magnitude lower (100 Bq/m, or 2.5 pCi/L),\n\nRadon exists in every state and approximately 6% of all houses have elevated levels. The highest average radon concentrations in the United States are found in Iowa and in the Appalachian Mountain areas in southeastern Pennsylvania. Some of the highest readings have been recorded in Mallow, County Cork, Ireland. Iowa has the highest average radon concentrations in the United States due to significant glaciation that ground the granitic rocks from the Canadian Shield and deposited it as soils making up the rich Iowa farmland. Many cities within the state, such as Iowa City, have passed requirements for radon-resistant construction in new homes.\nIn a few locations, uranium tailings have been used for landfills and were subsequently built on, resulting in possible increased exposure to radon.\n\nIn the early 20th century, Pb-contaminated gold, from gold seeds that were used in radiotherapy which had held Rn, were melted down and made into a small number of jewelry pieces, such as rings, in the U.S.\nWearing such a contaminated ring could lead to a skin exposure of 10 to 100 millirad/day (0.004 to 0.04 mSv/h).\n\nThe health effects of high exposure to radon in mines, where exposures reaching 1,000,000 Bq/m can be found, can be recognized in Paracelsus' 1530 description of a wasting disease of miners, the \"mala metallorum.\" Though at the time radon itself was not understood to be the cause—indeed, neither it nor radiation had even been discovered—mineralogist Georg Agricola recommended ventilation of mines to avoid this mountain sickness (\"Bergsucht\"). In 1879, the \"wasting\" was identified as lung cancer by Herting and Hesse in their investigation of miners from Schneeberg, Germany.\n\nBeyond mining in general, radon is a particular problem in the mining of uranium;\nsignificant excess lung cancer deaths have been identified in epidemiological studies of uranium miners and other hard-rock miners employed in the 1940s and 1950s.\n\nThe first major studies with radon and health occurred in the context of uranium mining, first in the Joachimsthal region of Bohemia and then in the Southwestern United States during the early Cold War. Because radon is a product of the radioactive decay of uranium, underground uranium mines may have high concentrations of radon. Many uranium miners in the Four Corners region contracted lung cancer and other pathologies as a result of high levels of exposure to radon in the mid-1950s. The increased incidence of lung cancer was particularly pronounced among Native American and Mormon miners, because those groups normally have low rates of lung cancer.\nSafety standards requiring expensive ventilation were not widely implemented or policed during this period.\n\nIn studies of uranium miners, workers exposed to radon levels of 50 to 150 picocuries of radon per liter of air (2000–6000 Bq/m) for about 10 years have shown an increased frequency of lung cancer.\nStatistically significant excesses in lung cancer deaths were present after cumulative exposures of less than 50 WLM.\nThere is, however, unexplained heterogeneity in these results (whose confidence interval do not always overlap).\nThe size of the radon-related increase in lung cancer risk varied by more than an order of magnitude between the different studies.\n\nHeterogeneities are possibly due to systematic errors in exposure ascertainment, unaccounted for differences in the study populations (genetic, lifestyle, etc.), or confounding mine exposures. There are a number of confounding factors to consider, including exposure to other agents, ethnicity, smoking history, and work experience. The cases reported in these miners cannot be attributed solely to radon or radon daughters but may be due to exposure to silica, to other mine pollutants, to smoking, or to other causes.\nThe majority of miners in the studies are smokers and all inhale dust and other pollutants in mines. Because radon and cigarette smoke both cause lung-cancer, and since the effect of smoking is far above that of radon, it is complicated to disentangle the effects of the two kinds of exposure; misinterpreting the smoking habit by a few percent can blur out the radon effect.\n\nSince that time, ventilation and other measures have been used to reduce radon levels in most affected mines that continue to operate. In recent years, the average annual exposure of uranium miners has fallen to levels similar to the concentrations inhaled in some homes. This has reduced the risk of occupationally induced cancer from radon, although it still remains an issue both for those who are currently employed in affected mines and for those who have been employed in the past.\nThe power to detect any excess risks in miners nowadays is likely to be small, exposures being much smaller than in the early years of mining.\n\nA confounding factor with mines is that both radon concentration and carcinogenic dust (such as quartz dust) depend on the amount of ventilation. This makes it very difficult to state that radon causes cancer in miners; the lung cancers could be partially or wholly caused by high dust concentrations from poor ventilation.\n\nRadon-222 has been classified by International Agency for Research on Cancer as being carcinogenic to humans. In September 2009, the World Health Organization released a comprehensive global initiative on radon that recommended a reference level of 100 Bq/m for radon, urging establishment or strengthening of radon measurement and mitigation programs as well as development building codes requiring radon prevention measures in homes under construction.\nElevated lung cancer rates have been reported from a number of cohort and case-control studies of underground miners exposed to radon and its decay products. There is sufficient evidence for the carcinogenicity of radon and its decay products in humans for such exposures. However, the discussion about the opposite results is still going on, especially a recent retrospective case-control study of lung cancer risk showed substantial cancer rate reduction between 50 and 123 Bq per cubic meter relative to a group at zero to 25 Bq per cubic meter.\n\nThe primary route of exposure to radon and its progeny is inhalation. Radiation exposure from radon is indirect. The health hazard from radon does not come primarily from radon itself, but rather from the radioactive products formed in the decay of radon. The general effects of radon to the human body are caused by its radioactivity and consequent risk of radiation-induced cancer. Lung cancer is the only observed consequence of high concentration radon exposures; both human and animal studies indicate that the lung and respiratory system are the primary targets of radon daughter-induced toxicity.\n\nRadon has a short half-life (3.8 days) and decays into other solid particulate radium-series radioactive nuclides.\nTwo of these decay products, polonium-218 and 214, present a significant radiologic hazard.\nIf the gas is inhaled, the radon atoms decay in the airways or the lungs, resulting in radioactive polonium and ultimately lead atoms attaching to the nearest tissue. If dust or aerosol is inhaled that already carries radon decay products, the deposition pattern of the decay products in the respiratory tract depends on the behaviour of the particles in the lungs. Smaller diameter particles diffuse further into the respiratory system, whereas the larger — tens to hundreds of micron-sized — particles often deposit higher in the airways and are cleared by the body's mucociliary staircase. Deposited radioactive atoms or dust or aerosol particles continue to decay, causing continued exposure by emitting energetic alpha radiation with some associated gamma radiation too, that can damage vital molecules in lung cells,\nby either creating free radicals or causing DNA breaks or damage,\nperhaps causing mutations that sometimes turn cancerous. In addition, through ingestion and blood transport, following crossing of the lung membrane by radon, radioactive progeny may also be transported to other parts of the body.\n\nThe risk of lung cancer caused by smoking is much higher than the risk of lung cancer caused by indoor radon. Radiation from radon has been attributed to increase of lung cancer among smokers too. It is generally believed that exposure to radon and cigarette smoking are synergistic; that is, that the combined effect exceeds the sum of their independent effects. This is because the daughters of radon often become attached to smoke and dust particles, and are then able to lodge in the lungs.\n\nIt is unknown whether radon causes other types of cancer, but recent studies suggest a need for further studies to assess the relationship between radon and leukemia.\n\nThe effects of radon, if found in food or drinking water, are unknown. Following ingestion of radon dissolved in water, the biological half-life for removal of radon from the body ranges from 30 to 70 minutes. More than 90% of the absorbed radon is eliminated by exhalation within 100 minutes, By 600 minutes, only 1% of the absorbed amount remains in the body.\n\nWhile radon presents the aforementioned risks in adults, exposure in children leads to a unique set of health hazards that are still being researched. The physical composition of children leads to faster rates of exposure through inhalation given that their respiratory rate is higher than that of adults, resulting in more gas exchange and more potential opportunities for radon to be inhaled. In addition to this potentially higher dose of radon inhalation, children have smaller lungs, which can become damaged much more quickly than adults’ lungs. For example, children who are exposed to radon and who live in a household where they are exposed to tobacco smoke have a 20 times greater risk of developing lung cancer.\n\nThe resulting health effects in children are similar to those of adults, predominantly including lung cancer and respiratory illnesses such as asthma, bronchitis, and pneumonia. While there have been numerous studies assessing the link between radon exposure and childhood leukemia, the results are largely varied. Many ecological studies show a positive association between radon exposure and childhood leukemia; however, most case control studies have produced a weak correlation. Genotoxicity has been noted in children exposed to high levels of radon, specifically a significant increase of frequency of aberrant cells was noted, as well as an “increase in the frequencies of single and double fragments, chromosome interchanges, [and] number of aberrations chromatid and chromosome type”.\n\nBecause radon is generally associated with diseases that are not detected until many years after elevated exposure, the public may not consider the amount of radon that children are currently being exposed to. Aside from the exposure in the home, one of the major contributors to radon exposure in children are the schools in which they attend almost every day. A survey was conducted in schools across the United States to detect radon levels, and it was estimated that about one in five schools has at least one room (more than 70,000 schoolrooms) with short-term levels above 4pCi/L. The only way to know the level of radon is to test for it, and levels of radon vary across the world. This EPA mapping tool shows average levels of radon by area: <nowiki>https://www.epa.gov/radon/find-information-about-local-radon-zones-and-state-contact-information</nowiki>.\n\nMany states have active radon testing and mitigation programs in place, which require testing in buildings such as public schools. However, these are not standardized nationwide, and the rules and regulations on reducing high radon levels are even less common. The School Health Policies and Practices Study (SHPPS), conducted by the CDC in 2012, found that of schools located in counties with high predicted indoor radon levels, only 42.4% had radon testing policies, and a mere 37.5% had policy for radon-resistant new construction practices. Only about 20% of all schools nationwide have done testing, even though the EPA recommends that every school be tested. These numbers are arguably not high enough to ensure protection of the majority of children from elevated radon exposures. For exposure standards to be effective, they should be set for those most susceptible.\n\nUNSCEAR recommends a reference value of 9 nSv (Bq·h/m).\nFor example, a person living (7000 h/year) in a concentration of 40 Bq/m receives an effective dose of 1 mSv/year.\n\nStudies of miners exposed to radon and its decay products provide a direct basis for assessing their lung cancer risk. The BEIR VI report, entitled \"Health Effects of Exposure to Radon\", reported an excess relative risk from exposure to radon that was equivalent to 1.8% per megabecquerel hours per cubic meter (MBq·h/m) (95% confidence interval: 0.3, 35) for miners with cumulative exposures below 30 MBq·h/m. Estimates of risk per unit exposure are 5.38×10 per WLM; 9.68×10/WLM for ever smokers; and 1.67×10 per WLM for never smokers.\n\nAccording to the UNSCEAR modeling, based on these miner's studies, the excess relative risk from long-term residential exposure to radon at 100 Bq/m is considered to be about 0.16 (after correction for uncertainties in exposure assessment), with about a threefold factor of uncertainty higher or lower than that value.\nIn other words, the absence of ill effects (or even positive hormesis effects) at 100 Bq/m are compatible with the known data.\n\nThe ICPR 65 model follows the same approach, and estimates the relative lifelong risk probability of radon-induced cancer death to 1.23 × 10 per Bq/(m·year). This relative risk is a global indicator; the risk estimation is independent of sex, age, or smoking habit. Thus, if a smoker's chances of dying of lung cancer are 10 times that of a nonsmoker's, the relative risks for a given radon exposure will be the same according to that model, meaning that the absolute risk of a radon-generated cancer for a smoker is (implicitly) tenfold that of a nonsmoker.\nThe risk estimates correspond to a unit risk of approximately 3–6 × 10 per Bq/m, assuming a lifetime risk of lung cancer of 3%. This means that a person living in an average European dwelling with 50 Bq/m has a lifetime excess lung cancer risk of 1.5–3 × 10. Similarly, a person living in a dwelling with a high radon concentration of 1000 Bq/m has a lifetime excess lung cancer risk of 3–6%, implying a doubling of background lung cancer risk.\n\nThe BEIR VI model proposed by the National Academy of Sciences of the USA is more complex. It is a multiplicative model that estimates an excess risk per exposure unit. It takes into account age, elapsed time since exposure, and duration and length of exposure, and its parameters allow for taking smoking habits into account.\nIn the absence of other causes of death, the absolute risks of lung cancer by age 75 at usual radon concentrations of 0, 100, and 400 Bq/m would be about 0.4%, 0.5%, and 0.7%, respectively, for lifelong nonsmokers, and about 25 times greater (10%, 12%, and 16%) for cigarette smokers.\n\nThere is great uncertainty in applying risk estimates derived from studies in miners to the effects of residential radon, and direct estimates of the risks of residential radon are needed.\n\nAs with the miner data, the same confounding factor of other carcinogens such as dust applies. Radon concentration is high in poorly ventilated homes and buildings and such buildings tend to have poor air quality, larger concentrations of dust etc. BEIR VI did not consider that other carcinogens such as dust might be the cause of some or all of the lung cancers, thus omitting a possible spurious relationship.\n\nThe largest natural contributor to public radiation dose is radon, a naturally occurring, radioactive gas found in soil and rock, which comprises approximately 55% of the annual background dose.\nRadon gas levels vary by locality and the composition of the underlying soil and rocks.\n\nRadon (at concentrations encountered in mines) was recognized as carcinogenic in the 1980s, in view of the lung cancer statistics for miners' cohorts.\nAlthough radon may present significant risks, thousands of persons annually go to radon-contaminated mines for deliberate exposure to help with the symptoms of arthritis without any serious health effects.\n\nRadon as a terrestrial source of background radiation is of particular concern because, although overall very rare, where it does occur it often does so in high concentrations. Some of these areas, including parts of Cornwall and Aberdeenshire have high enough natural radiation levels that nuclear licensed sites cannot be built there—the sites would already exceed legal limits before they opened, and the natural topsoil and rock would all have to be disposed of as low-level nuclear waste.\nPeople in affected localities can receive up to 10 mSv per year background radiation.\n\nThis led to a health policy problem: what is the health impact of exposure to radon concentrations (100 Bq/m) typically found in some buildings?\n\nWhen exposure to a carcinogenic substance is suspected, the cause/effect relationship on any given case can never be ascertained. Lung cancer occurs spontaneously, and there is no difference between a \"natural\" cancer and another one caused by radon (or smoking). Furthermore, it takes years for a cancer to develop, so that determining the past exposure of a case is usually very approximative. The health effect of radon can only be demonstrated through theory and statistical observation.\n\nThe study design for epidemiological methods may be of three kinds:\n\nFurthermore, theory and observation must confirm each other for a relationship to be accepted as fully proven. Even when a statistical link between factor and effect appears significant, it must be backed by a theoretical explanation; and a theory is not accepted as factual unless confirmed by observations.\n\nCohort studies are impractical for the study of domestic radon exposure. With the expected effect of small exposures being very small, the direct observation of this effect would require huge cohorts: the populations of whole countries.\n\nSeveral ecological studies have been performed to assess possible relationships between selected cancers and estimated radon levels within particular geographic regions where environmental radon levels appear to be higher than other geographic regions.\nResults of such ecological studies are mixed; both positive and negative associations, as well as no significant associations, have been suggested.\n\nThe most direct way to assess the risks posed by radon in homes is through case-control studies.\n\nThe studies have not produced a definitive answer, primarily because the risk is likely to be very small at the low exposure encountered from most homes and because it is difficult to estimate radon exposures that people have received over their lifetimes. In addition, it is clear that far more lung cancers are caused by smoking than are caused by radon.\n\nEpidemiologic radon studies have found trends to increased lung cancer risk from radon with a no evidence of a threshold, and evidence against a threshold above high as 150 Bq/m (almost exactly the EPA's action level of 4 pCi/L). Another study similarly found that there is no evidence of a threshold but lacked the statistical power to clearly identify the threshold at this low level. Notably, the latter deviance from zero at low level convinced the World Health Organization that, \"The dose-response relation seems to be linear without evidence of a threshold, meaning that the lung cancer risk increases proportionally with increasing radon exposure.\"\n\nThe most elaborate case-control epidemiologic radon study performed by R. William Field and colleagues identified a 50% increased lung cancer risk with prolonged radon exposure at the EPA's action level of 4 pCi/L. Iowa has the highest average radon concentrations in the United States and a very stable population which added to the strength of the study. For that study, the odds ratio was found to be increased slightly above the confidence interval (95% CI) for cumulative radon exposures above 17 WLM (6.2 pC/L=230 Bq/m and above).\n\nThe results of a methodical ten-year-long, case-controlled study of residential radon exposure in Worcester County, Massachusetts, found an apparent 60% \"reduction\" in lung cancer risk amongst people exposed to low levels (0–150 Bq/m) of radon gas; levels typically encountered in 90% of American homes—an apparent support for the idea of radiation hormesis. In that study, a significant result (95% CI) was obtained for the 75-150 Bq/m category.\nThe study paid close attention to the cohort's levels of smoking, occupational exposure to carcinogens and education attainment. However, unlike the majority of the residential radon studies, the study was not population-based. Errors in retrospective exposure assessment could not be ruled out in the finding at low levels. Other studies into the effects of domestic radon exposure have not reported a hormetic effect; including for example the respected \"Iowa Radon Lung Cancer Study\" of Field et al. (2000), which also used sophisticated radon exposure dosimetry.\n\n\"Radon therapy\" is an intentional exposure to radon via inhalation or ingestion. Nevertheless, epidemiological evidence shows a clear link between breathing high concentrations of radon and incidence of lung cancer.\n\nIn the late 20th century and early 21st century, some \"health mines\" were established in Basin, Montana, which attracted people seeking relief from health problems such as arthritis through limited exposure to radioactive mine water and radon. The practice is controversial because of the \"well-documented ill effects of high-dose radiation on the body.\" Radon has nevertheless been found to induce beneficial long-term effects.\n\nRadioactive water baths have been applied since 1906 in Jáchymov, Czech Republic, but even before radon discovery they were used in Bad Gastein, Austria. Radium-rich springs are also used in traditional Japanese onsen in Misasa, Tottori Prefecture. Drinking therapy is applied in Bad Brambach, Germany. Inhalation therapy is carried out in Gasteiner-Heilstollen, Austria, in Kowary, Poland and in Boulder, Montana, United States. In the United States and Europe there are several \"radon spas\", where people sit for minutes or hours in a high-radon atmosphere in the belief that low doses of radiation will invigorate or energize them.\n\nRadon has been produced commercially for use in radiation therapy, but for the most part has been replaced by radionuclides made in accelerators and nuclear reactors. Radon has been used in implantable seeds, made of gold or glass, primarily used to treat cancers.\nThe gold seeds were produced by filling a long tube with radon pumped from a radium source, the tube being then divided into short sections by crimping and cutting. The gold layer keeps the radon within, and filters out the alpha and beta radiations, while allowing the gamma rays to escape (which kill the diseased tissue). The activities might range from 0.05 to 5 millicuries per seed (2 to 200 MBq). The gamma rays are produced by radon and the first short-lived elements of its decay chain (Po, Pb, Bi, Po).\n\nRadon and its first decay products being very short-lived, the seed is left in place. After 12 half-lives (43 days), radon radioactivity is at 1/2000 of its original level. At this stage, the predominant residual activity is due to the radon decay product Pb, whose half-life (22.3 year) is 2000 times that of radon (and whose activity is thus 1/2000 of radon's), and its descendants Bi and Po, totalizing 0.03% of the initial seed activity.\n\nThe Federal Radon Action Plan, also known as FRAP, was created in 2010 and launched in 2011. It was piloted by the U.S. Environmental Protection Agency in conjunction with the U.S. Departments of Health and Human Services, Agriculture, Defense, Energy, Housing and Urban Development, the Interior, Veterans Affairs, and the General Services Administration. The goal set forth by FRAP was to eliminate radon induced cancer that can be prevented by expanding radon testing, mitigating high levels of radon exposure, and developing radon resistant construction, and to meet Healthy People 2020 radon objectives. They identified the barriers to change as limited public knowledge of the dangers of radon exposure, the perceived high costs of mitigation, and the availability of radon testing. As a result, they also identified major ways to create change: demonstrate the importance of testing and the ease of mitigation, provide incentives for testing and mitigation, and build the radon services industry. To complete these goals, representatives from each organization and department established specific commitments and timelines to complete tasks and continued to meet periodically. However, FRAP was concluded in 2016 as The National Radon Action Plan took over. In the final report on commitments, it was found that FRAP completed 88% of their commitments. They reported achieving the highest rates of radon mitigation and new construction mitigation in the United States as of 2014. FRAP concluded that because of their efforts, at least 1.6 million homes, schools, and childcare facilities received direct and immediate positive effects.\n\nThe National Radon Action Plan, also known as NRAP, was created in 2014 and launched in 2015. It is led by The American Lung Association with collaborative efforts from the American Association of Radon Scientists and Technologists, American Society of Home Inspectors, Cancer Survivors Against Radon, Children’s Environmental Health Network, Citizens for Radioactive Radon Reduction, Conference of Radiation Control Program Directors, Environmental Law Institute, National Center for Healthy Housing, U.S. Environmental Protection Agency, U.S. Department of Health and Human Services, and U.S. Department of Housing and Urban Development. The goals of NRAP are to continue efforts set forth by FRAP to eliminate radon induced cancer that can be prevented by expanding radon testing, mitigating high levels of radon exposure, and developing radon resistant construction. NRAP also aims to reduce radon risk in 5 million homes, and save 3,200 lives by 2020. To complete these goals, representatives from each organization have established the following action plans: embed radon risk reduction as a standard practice across housing sectors, provide incentives and support to test and mitigate radon, promote the use of certified radon services and build the industry, and increase public attention to radon risk and the importance of reduction. The NRAP is currently in action, implementing programs, identifying approaches, and collaborating across organizations to achieve these goals.\n\nThe only dose-effect relationship available are those of miners cohorts (for much higher exposures), exposed to radon. Studies of Hiroshima and Nagasaki survivors are less informative (the exposure to radon is chronic, localized, and the ionizing radiations are alpha rays).\nAlthough low-exposed miners experienced exposures comparable to long-term residence in high-radon dwellings, the mean cumulative exposure among miners is approximately 30-fold higher than that associated with long-term residency in a typical home. Moreover, the smoking is a significant confounding factor in all miners' studies. It can be concluded from miner studies that when the radon exposure in dwellings compares to that in mines (above 1000 Bq/m), radon is a proven health hazard; but in the 1980s very little was known on the dose-effect relationship, both theoretically and statistical.\n\nStudies have been made since the 1980s, both on epidemiological studies and in the radiobiology field.\nIn the radiobiology and carcinogenesis studies, progress has been made in understanding the first steps of cancer development, but not to the point of validating a reference dose-effect model. The only certainty gained is that the process is very complex, the resulting dose-effect response being complex, and most probably not a linear one.\nBiologically based models have also been proposed that could project substantially reduced carcinogenicity at low doses.\nIn the epidemiological field, no definite conclusion has been reached. However, from the evidence now available, a threshold exposure, that is, a level of exposure below which there is no effect of radon, cannot be excluded. L\n\nGiven the radon distribution observed in dwellings, and the dose-effect relationship proposed by a given model, a theoretical number of victims can be calculated, and serve as a basis for public health policies.\n\nWith the BEIR VI model, the main health effect (nearly 75% of the death toll) is to be found at low radon concentration exposures, because most of the population (about 90%) lives in the 0-200 Bq/m range. Under this modeling, the best policy is obviously to reduce the radon levels of all homes where the radon level is above average, because this leads to a significant decrease of radon exposure on a significant fraction of the population; but this effect is predicted in the 0-200 Bq/m range, where the linear model has its maximum uncertainty. From the statistical evidence available, a threshold exposure cannot be excluded; if such a threshold exists, the real radon health effect would in fact be limited to those homes where the radon concentrations reaches that observed in mines — at most a few percent. If a radiation hormesis effect exists after all, the situation would be even worse: under that hypothesis, suppressing the natural low exposure to radon (in the 0-200 Bq/m range) would actually lead to an increase of cancer incidence, due to the suppression of this (hypothetical) protecting effect. As the low-dose response is unclear, the choice of a model is very controversial.\n\nNo conclusive statistics being available for the levels of exposure usually found in homes, the risks posed by domestic exposures is usually estimated on the basis of observed lung-cancer deaths caused by higher exposures in mines, under the assumption that the risk of developing lung-cancer increases linearly as the exposure increases. This was the basis for the model proposed by BEIR IV in the 1980s. The linear no-threshold model has since been kept in a conservative approach by the UNSCEAR report and the BEIR VI and BEIR VII publications, essentially for lack of a better choice:Until the [...] uncertainties on low-dose response are resolved, the Committee believes that [\"the linear no-threshold model\"] is consistent with developing knowledge and that it remains, accordingly, the most scientifically defensible approximation of low-dose response. However, a strictly linear dose response should not be expected in all circumstances.\nThe BEIR VI committee adopted the linear no-threshold assumption based on its understanding of the mechanisms of radon-induced lung cancer, but recognized that this understanding is incomplete and that therefore the evidence for this assumption is not conclusive.\n\nIn discussing these figures, it should be kept in mind that both the radon distribution in dwelling and its effect at low exposures are not precisely known, and the radon health effect has to be computed (deaths caused by radon domestic exposure cannot be observed as such). These estimations are strongly dependent on the model retained.\n\nAccording to these models, radon exposure is thought to be the second major cause of lung cancer after smoking.\nIowa has the highest average radon concentration in the United States; studies performed there have demonstrated a 50% increased lung cancer risk with prolonged radon exposure above the EPA's action level of 4 pCi/L.\n\nBased on studies carried out by the National Academy of Sciences in the United States, radon would thus be the second leading cause of lung cancer after smoking, and accounts for 15,000 to 22,000 cancer deaths per year in the US alone.\nThe United States Environmental Protection Agency (EPA) says that radon is the number one cause of lung cancer among non-smokers.\nThe general population is exposed to small amounts of polonium as a radon daughter in indoor air; the isotopes Po and Po are thought to cause the majority of the estimated 15,000–22,000 lung cancer deaths in the US every year that have been attributed to indoor radon.\nThe Surgeon General of the United States has reported that over 20,000 Americans die each year of radon-related lung cancer.\n\nIn the United Kingdom, residential radon would be, after cigarette smoking, the second most frequent cause of lung cancer deaths: according to models, 83.9% of deaths are attributed to smoking only, 1.0% to radon only, and 5.5% to a combination of radon and smoking.\n\nThe World Health Organization has recommended a radon reference concentration of 100 Bq/m (2.7 pCi/L). The European Union recommends that action should be taken starting from concentrations of 400 Bq/m (11 pCi/L) for older dwellings and 200 Bq/m (5 pCi/L) for newer ones. After publication of the North American and European Pooling Studies, Health Canada proposed a new guideline that lowers their action level from 800 to 200 Bq/m (22 to 5 pCi/L).\nThe United States Environmental Protection Agency (EPA) strongly recommends action for any dwelling with a concentration higher than 148 Bq/m (4 pCi/L),\nand encourages action starting at 74 Bq/m (2 pCi/L).\n\nEPA recommends that all homes should be monitored for radon. If testing shows levels less than 4 picocuries radon per liter of air (160 Bq/m), then no action is necessary. For levels of 20 picocuries radon per liter of air (800 Bq/m) or higher, the home owner should consider some type of procedure to decrease indoor radon levels. For instance, as radon has a half-life of four days, opening the windows once a day can cut the mean radon concentration to one fourth of its level.\n\nThe United States Environmental Protection Agency (EPA) recommends homes be fixed if an occupant's long-term exposure will average 4 picocuries per liter (pCi/L) that is 148 Bq/m. EPA estimates that one in 15 homes in the United States has radon levels above the recommended guideline of 4 pCi/L.\nEPA radon risk level tables including comparisons to other risks encountered in life are available in their citizen's guide.\nThe EPA estimates that nationally, 8% to 12% of all dwellings are above their maximum \"safe levels\" (four picocuries per liter—the equivalent to roughly 200 chest x-rays). The United States Surgeon General and the EPA both recommend that all homes be tested for radon.\n\nThe limits retained do not correspond to a known threshold in the biological effect, but are determined by a cost-efficiency analysis. EPA believes that a 150 Bq/m level (4 pCi/L) is achievable in the majority of homes for a reasonable cost, the average cost per life saved by using this action level is about $700,000.\n\nFor radon concentration in drinkable water, the World Health Organization issued as guidelines (1988) that remedial action should be considered when the radon activity exceeded 100 kBq/m in a building, and remedial action should be considered \"without long delay\" if exceeding 400 kBq/m.\n\nThere are relatively simple tests for radon gas. Radon test kits are commercially available. The short-term radon test kits used for screening purposes are inexpensive, in many cases free. Discounted test kits can be purchased online through The National Radon Program Services at Kansas State University or through state radon offices. Information about local radon zones and specific state contact information can be accessed through the EPA Map at <nowiki>https://www.epa.gov/radon/find-information-about-local-radon-zones-and-state-contact-information</nowiki>. The kit includes a collector that the user hangs in the lowest livable floor of the dwelling for 2 to 7 days. Charcoal canisters are another type of short-term radon test, and are designed to be used for 2 to 4 days. The user then sends the collector to a laboratory for analysis. Both devices are passive, meaning that they do not need power to function.\n\nIt should be noted that the accuracy of the residential radon test depends upon the lack of ventilation in the house when the sample is being obtained. Thus, the occupants will be instructed not to open windows, etc., for ventilation during the pendency of test, usually two days or more.\n\nLong-term kits, taking collections for 3 months up to one year, are also available. An open-land test kit can test radon emissions from the land before construction begins. A Lucas cell is one type of long-term device. A Lucas cell is also an active device, or one that requires power to function. Active devices provide continuous monitoring, and some can report on the variation of radon and interference within the testing period. These tests usually require operation by trained testers and are often more expensive than passive testing. The National Radon Proficiency Program (NRPP) provides a list of radon measurement professionals.\n\nRadon levels fluctuate naturally. An initial test might not be an accurate assessment of a home's average radon level. Transient weather can affect short term measurements. Therefore, a high result (over 4 pCi/L) justifies repeating the test before undertaking more expensive abatement projects. Measurements between 4 and 10 pCi/L warrant a long-term radon test. Measurements over 10 pCi/L warrant only another short-term test so that abatement measures are not unduly delayed. Purchasers of real estate are advised to delay or decline a purchase if the seller has not successfully abated radon to 4 pCi/L or less.\n\nSince radon concentrations vary substantially from day to day, single grab-type measurements are generally not very useful, except as a means of identifying a potential problem area, and indicating a need for more sophisticated testing. The EPA recommends that an initial short-term test be performed in a closed building. An initial short-term test of 2 to 90 days allows residents to be informed quickly in case a home contains high levels of radon. Long-term tests provide a better estimate of the average annual radon level.\n\nTransport of radon in indoor air is almost entirely controlled by the ventilation rate in the enclosure. Since air pressure is usually lower inside houses than it is outside, the home acts like a vacuum, drawing radon gas in through cracks in the foundation or other openings such as ventilation systems. Generally, the indoor radon concentrations increase as ventilation rates decrease. In a well ventilated place, the radon concentration tends to align with outdoor values (typically 10 Bq/m, ranging from 1 to 100 Bq/m).\n\nRadon levels in indoor air can be lowered in several ways, from sealing cracks in floors and walls to increasing the ventilation rate of the building. Listed here are some of the accepted ways of reducing the amount of radon accumulating in a dwelling:\n\n· Improving the ventilation of the dwelling and avoiding the transport of radon from the basement, or ground, into living areas;\n\n· Installing crawlspace or basement ventilation systems;\n\n· Installing sub-slab depressurization radon mitigation systems, which vacuum radon from under slab-on-grade foundations;\n\n· Installing sub-membrane depressurization radon mitigation systems, which vacuum radon from under a membrane that covers the ground used in crawlspace\n\nfoundations;\n\n· Installing a radon sump system in the basement;\n\n· Sealing floors and walls (not a stand-alone solution); and\n\n· Installing a positive pressurization or positive supply ventilation system.\n\nThe half-life for radon is 3.8 days, indicating that once the source is removed, the hazard will be greatly reduced within approximately one month (seven half-lives).\n\nPositive-pressure ventilation systems can be combined with a heat exchanger to recover energy in the process of exchanging air with the outside, and simply exhausting basement air to the outside is not necessarily a viable solution as this can draw radon gas \"into\" a dwelling. Homes built on a crawl space may benefit from a radon collector installed under a \"radon barrier, or membrane\" (a sheet of plastic or laminated polyethylene film that covers the crawl space floor).\n\nASTM E-2121 is a standard for reducing radon in homes as far as practicable below 4 picocuries per liter (pCi/L) in indoor air.\n\nIn the US, approximately 14 states have a state radon programs which train and license radon mitigation contractors and radon measurement professionals. To determine if your state licenses radon professionals contact your state health department. The National Environmental Health Association and the National Radon Safety Board administer voluntary National Radon Proficiency Programs for radon professionals consisting of individuals and companies wanting to take training courses and examinations to demonstrate their competency. Without the proper equipment or technical knowledge, radon levels can actually increase or create other potential hazards and additional costs. A list of certified mitigation service providers is available through state radon offices, which are listed on the EPA website at www.epa.gov/radon/whereyoulive.html. Indoor radon can be mitigated by sealing basement foundations, water drainage, or by sub-slab, or sub-membrane depressurization. In many cases, mitigators can use PVC piping and specialized radon suction fans to exhaust sub-slab, or sub-membrane radon and other soil gases to the outside atmosphere. Most of these solutions for radon mitigation require maintenance, and it is important to continually replace any fans or filters as needed to continue proper functioning.\n\nSince radon gas is found in most soil and rocks, it is not only able to move into the air, but also into underground water sources. Radon may be present in well water and can be released into the air in homes when water is used for showering and other household uses. If it is suspected that a private well or drinking water may be affected by radon, the National Radon Program Services Hotline at 1-800-SOS-RADON can be contacted for information regarding state radon office phone numbers. State radon offices can provide additional resources, such as local laboratories that can test water for radon.\n\nIf it is determined that radon is present in a private well, installing either a point-of-use or point-of-entry solution may be necessary. Point-of-use treatments are installed at the tap, and are only helpful in removing radon from drinking water. To address the more common problem of breathing in radon released from water used during showers and other household activities, a point-of-entry solution may be more reliable. Point-of-entry systems usually involve a granular activated carbon filter, or an aeration system; both methods can help to remove radon before it enters the home’s water distribution system. Aeration systems and granular activation carbon filters both have advantages and disadvantages, so it is recommended to contact state radon departments or a water treatment professional for specific recommendations.\n\nThe high cost of radon remediation in the 1980s led to detractors arguing that the issue is a financial boondoggle reminiscent of the swine flu scare of 1976. They further argued that the results of mitigation are inconsistent with lowered cancer risk, especially when indoor radon levels are in the lower range of the actionable exposure level.\n\n\n"}
{"id": "3158172", "url": "https://en.wikipedia.org/wiki?curid=3158172", "title": "Health promotion", "text": "Health promotion\n\nHealth promotion is as stated in the 1986 WHO Ottawa Charter on Health Promotion \"the process of enabling people to increase control over, and to improve, their health. To reach a state of complete physical, mental and social well-being, an individual or group must be able to identify and to realize aspirations, to satisfy needs, and to change or cope with the environment. Health is, therefore, seen as a resource for everyday life, not the objective of living. Health is a positive concept emphasizing social and personal resources, as well as physical capacities. Therefore, health promotion is not just the responsibility of the health sector, but goes beyond healthy life-styles to well-being.\"\n\nThe World Health Organization's (WHO) 2005 Bangkok Charter for Health Promotion in a Globalized World defines health promotion as \"the process of enabling people to increase control over their health and its determinants, and thereby improve their health\".\n\nHealth promotion involves public policy that addresses health determinants such as income, housing, food security, employment, and quality working conditions. More recent work has used the term Health in All Policies to refer to the actions to incorporate health into all public policies. Health promotion is aligned with health equity and can be a focus of NGOs dedicated to social justice or human rights. Health literacy can be developed in schools, while aspects of health promotion such as breastfeeding promotion can depend on laws and rules of public spaces. One of the Ottawa Charter Health Promotion Action items is infusing prevention into all sectors of society, to that end, it is seen in preventative healthcare rather than a treatment and curative care focused medical model.\n\nThere is a tendency among some public health officials, governments, and the medical industrial complex to reduce health promotion to just developing personal skill also known as health education and social marketing focused on changing behavioral risk factors.\n\nThis first publication of health promotion is from the 1974 Lalonde report from the Government of Canada, which contained a health promotion strategy \"aimed at informing, influencing and assisting both individuals and organizations so that they will accept more responsibility and be more active in matters affecting mental and physical health\". Another predecessor of the definition was the 1979 \"Healthy People\" report of the Surgeon General of the United States, which noted that health promotion \"seeks the development of community and individual measures which can help... [people] to develop lifestyles that can maintain and enhance the state of well-being\".\n\nAt least two publications led to a \"broad empowerment/environmental\" definition of health promotion in the mid-1980s:\n\nThe \"American\" definition of health promotion first promulgated by the \"American Journal of Health Promotion\" the late 1980s focuses more on the delivery of services with a bio-behavioral approach rather than environmental support using a settings approach, later the power on the environment over behavior was incorporated.\n\nThe WHO, in collaboration with other organizations, has subsequently co-sponsored international conferences including the 2015 Okanagan Charter on Health Promotion Universities and Colleges.\nThe process of health promotion works in all settings and sectors where people live, work, play and love. A common setting is the workplace. Work site health focus on the prevention and the intervention that reduce the health risks of the employee. The U.S. Public Health Service recently issued a report titled \"Physical Activity and Health: A Report of the Surgeon General\" which provides a comprehensive review of the available scientific evidence about the relationship between physical activity and an individual's health status. The report shows that over 60% of Americans are not regularly active and that 25% are not active at all. There is very strong evidence linking physical activity to numerous health improvements. \nHealth promotion can be performed in various locations. Among the settings that have received special attention are the community, health care facilities, schools, and worksites. Worksite health promotion, also known by terms such as \"workplace health promotion,\" has been defined as \"the combined efforts of employers, employees and society to improve the health and well-being of people at work\". WHO states that the workplace \"has been established as one of the priority settings for health promotion into the 21st century\" because it influences \"physical, mental, economic and social well-being\" and \"offers an ideal setting and infrastructure to support the promotion of health of a large audience\".\n\nWorksite health promotion programs (also called \"workplace health promotion programs,\" \"worksite wellness programs,\" or \"workplace wellness programs\") include exercise, nutrition, smoking cessation and stress management.\n\nAccording to the Centers for Disease Control and Prevention (CDC), \"Regular physical activity is one of the most effective disease prevention behaviors.\" Physical activity programs reduce feelings of anxiety and depression, reduce obesity (especially when combined with an improved diet), reduce risk of chronic diseases including cardiovascular disease, high blood pressure, and type 2 diabetes; and finally improve stamina, strength, and energy.\n\nReviews and meta-analyses published between 2005 and 2008 that examined the scientific literature on worksite health promotion programs include the following:\n\nWorldwide, government agencies (such as health departments) and non-governmental organizations have substantial efforts in the area of health promotion. Some of these entities and projects are:\n\nThe WHO and its Regional Offices such as the Pan American Health Organization are influential in health promotion around the world. The main eight health promotion campaigns marked by WHO are World Health Day, World Tuberculosis Day, World Blood Donor Day, World Immunization Week, World Malaria Day, World No Tobacco Day, World Hepatitis Day and World AIDS Day.\n\nThe International Union for Health Promotion and Education, based in France, holds international, regional, and national conferences.\n\nThe European Union is co-funding a Joint Action on Chronic Diseases and Healthy Ageing across the Life Cycle (JA-CHRODIS) with a strong focus on health promotion.\n\nThe Australian Health Promotion Association, a professional body, was incorporated in year 1988. In November 2008, the National Health and Hospitals Reform Commission released a paper recommending a national health promotion agency. ACT Health of the Australian Capital Territory supports health promotion with funding and information dissemination. The Victorian Health Promotion Foundation (VicHealth) from the state of Victoria is \"the world’s first health promotion foundation to be funded by a tax on tobacco. \". The Australian Government has come up with some initiatives to help Australians achieve a healthy lifestyle. These initiatives are:\nHealth Promotion is strong and well-established in Australia. Since 2008 there has been a number of graduate courses people can take to be involved within Health Promotion in Australia. The government since 2008 has included an initiative that involves the Aboriginal and Torres Strait Island citizens in the preventive health sector.\n\nSchool programs are based on curriculum documents from state and territory councils. Schools mainly focus on health issues that are being supported by funding and special events. Funding for many health issues are the main basis for school curriculum's health subject.\n\nAboriginal and Torres Strait Island citizens in Australia in the last couple of centuries have had poor health. The reason behind the poor health conditions is due to major events in the history of Australia, There is an increasing advancement in the promotion of health for Torres Strait Islander and Aboriginal citizens, but this cannot be achieved without the co-operation of non-indigenous Australians. For this Health promotion to be a success the citizens of Australia need to put the history between non-indigenous and indigenous citizens behind them and co-operate as equals.\n\nThe province of Ontario appointed a health promotion minister to lead its Ministry of Health Promotion in year 2005.\n\nThe Ministry’s vision is to enable Ontarians to lead healthy, active lives and make the province a healthy, prosperous place to live, work, play, learn and visit. Ministry of Health Promotion sees that its fundamental goals are to promote and encourage Ontarians to make healthier choices at all ages and stages of life, to create healthy and supportive environments, lead the development of healthy public policy, and assist with embedding behaviours that promote health.\n\nThe Canadian Health Network was a \"reliable, non-commercial source of online information about how to stay healthy and prevent disease\" that was discontinued in 2007.\n\nThe BC Coalition for Health Promotion is \"a grassroots, voluntary non-profit society dedicated to the advancement of health promotion in British Columbia\".\n\nThe Health Promotion Research Centre (HPRC) at the National University of Ireland Galway was established in 1990 with support from the Department of Health to conduct health promotion related research on issues relevant to health promotion in an Irish context. The Centre is unique in that it is the only designated research centre in Ireland dedicated to health promotion. It produces high quality research of national and international significance that supports the development of best practice and policy in the promotion of health. The Centre is a World Health Organisation (WHO) Collaborating Centre for Health Promotion Research, has an active multidisciplinary research programme, and collaborates with regional, national and international agencies on the development and evaluation of health promotion interventions and strategies.\n\nObjectives of the HPRC include:\n\nThe Health Promotion Forum (HPF) of New Zealand is the national umbrella organization of over 150 organisations committed to improving health. HPF has worked with The Cancer Society in order to produce a personal development plan for health promoters, which may be helpful to inform personal development reviews, to identify the competencies of individuals and to provide ideas for future development.\n\nThe Health Promotion Agency (HPA), formed July 1, 2012, is a Crown institution that has been established under the New Zealand Public Health and Disability Amendment Act 2012. Its board has been appointed by the Minister of Health. The work of HPA is divided into three main areas:\nHPA has a variety of programs based around many areas of work, including alcohol, immunisation, mental health, and skin cancer prevention. The agency aims to promote the wellbeing of individuals and encourage healthy lifestyles, prevent disease, illness and injury, enable environments that support health and wellbeing, and to reduce personal, economic and social harm.\n\nHealth Workforce New Zealand (HWNZ) is an organisation that is part of the National Health Board which provides national leadership on the development of the health workforce. Some health promotional programs supported by HWNZ include education and training initiatives, and the Voluntary Bonding Scheme, which rewards medical, midwifery and nursing graduates who agree to work in hard-to-staff communities, and sonography, medical physicist and radiation therapy graduates who stay in New Zealand.\n\nHealth promotion in New Zealand has become an established approach in addressing public problems since the 1980s, through increasing use of intersectoral action, the use of public policy and mass media as promotional strategies, and the increasing control Maori have taken over the provision and purchase of health promotion services. An example of health promotional initiatives is the action put in place to reduce childhood obesity in primary schools. Research was completed to identify the barriers to improving school food environments and promoting healthy nutrition in primary schools in New Zealand.\n\nConsiderable progress has also been made in the health impact assessment (HIA) research on the impact of policies on health in New Zealand. The approach has an important contribution to make in the strengthening of health and wellbeing in policymaking in New Zealand\n\nIn 2015, the life expectancy of Sri Lankan people was 72 for male and 78 for female. The disease burden has started to shift towards non-communicable diseases related to lifestyle and environmental factors. The 2012 estimated “healthy life expectancy” at birth of all Sri Lanka population is 68 for females, 63 for males, and 65 overall. \n\nThe development of the Sri Lankan National Health Promotion Policy is related to the State Policy and Strategy for Health and the Health Master Plan 2007–2016. It emphasises advocacy and empowerment to enable individuals and communities to take control of their own health, as well as improving the management of health promotion interventions across sectors.\n\nIn Sweden, on a national level, health promotion is primarily the responsibility of the Public Health Agency of Sweden. However, many regional initiatives exists concerning for example clinical health promotion programs in certain geographical areas . Health promotion is also highlighted by the Swedish National Board of Health and Welfare as the agency suggest this to be a component in health professionals' curriculum and training, which concerns for example Registered Nurses and Physicians .\n\nMany health promotion initiatives in Sweden focus on health equity and thus focus on groups in society that have seen to be experiencing poorer health status. For example, a Swedish study suggest that health promotion interventions aiming at empowering adolescents in disadvantaged communities, should enable active learning activities, use visualizing tools to facilitate self-reflection, and allow the adolescents to influence the intervention activities .\n\nThe Royal Society for Public Health was formed in October 2008 by the merger of the Royal Society for the Promotion of Health (also known as the Royal Society of Health or RSH) and the Royal Institute of Public Health (RIPH). Earlier, July 2005 saw the publication by the Department of Health and Welsh Assembly Government of Shaping the Future of Public Health: Promoting Health in the NHS. Following discussions with the Department of Health and Welsh Assembly Government officials, the Royal Society for Public Health and three national public health bodies agreed, in 2006, to work together to take forward the report's recommendations, working in partnership with other organisations. Accordingly: \n\nIn Northern Ireland, the government's Health Promotion Agency for Northern Ireland which was set up to \"provide leadership, strategic direction and support, where possible, to all those involved in promoting health in Northern Ireland\". The Health Promotion Agency for Northern Ireland was incorporated into the Public Health Agency for Northern Ireland in April 2009.\n\nRecent work in the UK \"(Delphi consultation exercise due to be published late 2009 by Royal Society of Public Health and the National Social Marketing Centre)\" on relationship between health promotion and social marketing has highlighted and reinforce the potential integrative nature of the approaches. While an independent review (NCC 'It's Our Health!' 2006) identified that some social marketing has in past adopted a narrow or limited approach, the UK has increasingly taken a lead in the discussion and developed a much more integrative and strategic approach which adopts a holistic approach, integrating the learning from effective health promotion approaches with relevant learning from social marketing and other disciplines. A key finding from the Delphi consultation was the need to avoid unnecessary and arbitrary 'methods wars' and instead focus on the issue of 'utility' and harnessing the potential of learning from multiple disciplines and sources. Such an approach is arguably how health promotion has developed over the years pulling in learning from different sectors and disciplines to enhance and develop.\n\nGovernment agencies in the U.S. concerned with health promotion include the following:\n\nNongovernmental organizations in the U.S. concerned with health promotion include:\n\n"}
{"id": "51718839", "url": "https://en.wikipedia.org/wiki?curid=51718839", "title": "Janet O'Sullivan", "text": "Janet O'Sullivan\n\nJanet O'Sullivan is a pro-choice campaigner in Ireland. She is a former spokesperson for the Abortion Rights Campaign. She publishes under both the Irish version of her name, Janet Ní Shuilleabháin, and the English version Janet O'Sullivan. In 2016, the BBC included her in the list of 100 Women for \"inspirational and influential women for 2016\"\n\nO'Sullivan has been a pro-choice believer since the early 1990s, when the X Case made the news, and had an abortion herself a few years later. As the spokesperson for the Abortion Rights Campaign, she has frequently written in national newspapers, and appeared on radio and TV about the abortion debate in Ireland.\n\nO'Sullivan is also a Bi-Visibility activist who has campaigned for Marriage Equality.\n\nO'Sullivan was in favour of the repeal of the Eighth Amendment and is working towards the goal of repealing the amendment and introducing legislation both in Ireland and Northern Ireland which ensures that women have the right to choose. On April 3, 2018 she registered as a third party with SIPO, the Irish government ethics watchdog. She was the only individual person to register as a third party.\n"}
{"id": "19234527", "url": "https://en.wikipedia.org/wiki?curid=19234527", "title": "John Thomas Quekett", "text": "John Thomas Quekett\n\nJohn Thomas Quekett (11 August 1815 – 20 August 1861) was an English microscopist and histologist.\n\nQuekett studied medicine at the London Hospital in 1831. He became a licentiate of the Apothecaries' Company and a member of the Royal College of Surgeons.\n\nIn 1839, along with his brother Edwin John Quekett) co-founded the Royal Microscopical Society. Quekett served as the society's secretary from 1841 to 1860. In 1843 he was appointed assistant conservator of the Hunterian Museum, and in 1856 conservator of the museum and professor of histology on the retirement of professor Richard Owen.\nQuekett, born at Langport, Somerset, on 11 August 1815, was the youngest son of William Quekett and Mary, daughter of John Bartlett. The father was at Cockermouth grammar school with William and Christopher Wordsworth, and from 1790 till his death in 1842 was master of Langport grammar school. He educated his sons at home, and each of them was encouraged to collect specimens in some branch of natural history. The eldest brother, William Quekett, was a rector and author.\n\nWhen only sixteen John gave a course of lectures on microscopic subjects, illustrated by original diagrams and by a microscope which he had himself made out of a roasting-jack, a parasol, and a few pieces of brass purchased at a neighbouring marine-store shop. On leaving school he was apprenticed, first to a surgeon in Langport, and afterwards to his brother Edwin John Quekett, entering King's College, London, and the London Hospital medical school. In 1840 he qualified at Apothecaries' Hall, and at the Royal College of Surgeons won the three-years studentship in human and comparative anatomy, then first instituted.\n\nHe formed a most extensive and valuable collection of microscopic preparations, injected by himself, illustrating the tissues of plants and animals in health and in disease, and showing the results and uses of microscopic investigation. In November 1843 he was appointed by the College of Surgeons assistant conservator of the Hunterian Museum, under Professor (afterwards Sir) Richard Owen, and in 1844 he was appointed demonstrator of minute anatomy. In 1846 his collection of two thousand five hundred preparations was purchased by the college, and he was directed to prepare a descriptive illustrated catalogue of the whole histological collection belonging to the college, of which they constituted the chief part. In 1852 the title of his demonstratorship was changed to that of professor of histology; and on Owen's obtaining permission to reside at Richmond, Quekett was appointed resident conservator, finally succeeding Owen as conservator in 1856. His health, however, soon failed, and he died at Pangbourne, Berkshire, whither he had gone for the benefit of his health, on 20 Aug. 1861.\n\nIn 1841 Quekett succeeded Dr. Arthur Farre as secretary of the Microscopical Society, a post which he retained until 1860, when he was elected president, but was unable to attend any meetings during his year of office. He was elected a fellow of the Linnean Society in 1857, and of the Royal Society in 1860.\n\nIn 1846 Quekett married Isabella Mary Anne (d. 1872), daughter of Robert Scott, Bengal Civil Service, by whom he had four children. There is a lithographic portrait of Quekett in Maguire's Ipswich series of 1849, and a coloured one by W. Lens Aldous. Upon Quekett's death, Joseph Henry Green, Thomas Wormald, George Gulliver and several other members of the Council of the Royal College of Surgeons strongly supported the college's granting of a pension to the widow; Wormald and James Moncrieff Arnott each contributed £100 in addition to the pension.\n\nQuekett's work as an histologist was remarkable for its originality and for its influence upon the anatomical studies of the medical profession in this country. His \"Practical Treatise on the Use of the Microscope\" (1848, 8vo) did much also to promote the study among medical men and amateurs, and among those who came to him for instruction was the prince consort. His work in this direction is commemorated by the Quekett Microscopical Club, which was established in 1865, under the presidency of Dr. Edwin Lankester.\n\nQuekett's chief publications were:\n\n\nTwenty-two papers by him are also enumerated in the Royal Society's \"Catalogue of Scientific Papers\" (v. 53–4), mostly contributed to the Microscopical Society's \"Transactions,\" and dealing with animal histology. One of the most important of these is that on the \"Intimate Structure of Bones in the four great Classes, Mammals, Birds, Reptiles, and Fishes, with Remarks on the Value of the Knowledge in determining minute Organic Remains,\" Microscopical Society's \"Transactions,\" vol. ii. 1846, pp. 46–58.\n\n\n"}
{"id": "46818806", "url": "https://en.wikipedia.org/wiki?curid=46818806", "title": "Jus Reservoir", "text": "Jus Reservoir\n\nThe Jus Reservoir () is a reservoir in Jasin District, Melaka, Malaysia.\n\nThe construction of the dam and reservoir started in 2000 to address the water needs of Malacca. The reservoir and the dam started its operation in 2003.\n\nThe dam is capable of storing 43 billion litres of water over an area of 5.5 km in an overall area of 23 km. The raw water supply for the reservoir is channeled from Durian Tunggal Reservoir, Kesang River and Batang Melaka River. The water from the reservoir goes to the water treatment facilities in Merlimau and Durian Tunggal.\n\n"}
{"id": "42735976", "url": "https://en.wikipedia.org/wiki?curid=42735976", "title": "Keswick to Barrow", "text": "Keswick to Barrow\n\nThe Keswick to Barrow, also known as the K2B, is a 40 mile charity walking race which takes place annually in May in Cumbria, England, between Keswick and Barrow-in-Furness. The race, which passes through much of the Lake District, is mainly aimed at fun-runners, and allows participants to run or walk as they choose.\n\nThe race has it origins in a 1966 challenge between a team of American experts working on the construction of HMS Resolution in Barrow, and local workers from Vickers, the owners of Barrow's shipyard. The challenge was inspired by American President John F. Kennedy's recommendation that \"every American should be capable of walking 50 miles a day\" The original walk started at the Castlerigg Stone Circle, roughly 50 miles from Barrow, but the length of the walk was in following years reduced to around 40 miles, starting south of Keswick. The walk proved popular and became an annual event. By 1974 it had 1,500 participants, and has continued to grow. Entry is currently capped at 2,900 walkers for logistical reasons, and the race is regularly oversubscribed.\n\nFor many years, the route began at Rough How Bridge on the A591 three miles south of Keswick. However, for the walk's fiftieth anniversary in 2016 and again in 2017, the start was moved to near Castlerigg Stone Circle, increasing the distance to around 43 miles. The walk follows minor roads along the west of Thirlmere, before climbing up Dunmail Raise. It passes through the village of Grasmere and over Red Bank into Elterwater and on to Coniston. Walkers then continue along the east bank of Coniston Water to the village of Lowick, before passing over Kirkby Moor, the walk's highest elevation. The route then continues into Low Furness and the village of Marton, passing the South Lakes Wild Animal Park on its way to Dalton-in-Furness. The final stretch runs close to Furness Abbey, before ending at the Hawcoat Park Sports Club in Hawcoat, Barrow. The shorter Coniston to Barrow walk is aimed at teenagers, and joins the main route in Coniston.\n\nCompetitors enter in teams of between 6 and 12, and prizes are awarded to both individuals and teams. The competition retains a close association with BAE Systems, current owners of Barrow's shipyard, and teams from the armed forces, with prizes for the best performers among both groups Competitors must raise a minimum of £80 for charity for their entry to be accepted. Up to 2016, more than £3.7M has been donated to charities over the history of the walk.\n\n"}
{"id": "24047195", "url": "https://en.wikipedia.org/wiki?curid=24047195", "title": "Landfills in the United States", "text": "Landfills in the United States\n\nMunicipal solid waste (MSW) – more commonly known as trash or garbage – consists of everyday items people use and then throw away, such as product packaging, grass clippings, furniture, clothing, bottles, food scraps and papers. In 2010, Americans generated about of trash. In the United States, landfills are regulated by the Environmental Protection Agency (EPA) and the states' environmental agencies. Municipal solid waste landfills (MSWLF) are required to be designed to protect the environment from contaminants that may be present in the solid waste stream.\n\nSome materials may be banned from disposal in municipal solid waste landfills including common household items such as paints, cleaners/chemicals, motor oil, batteries, pesticides, and electronics. These products, if mishandled, can be dangerous to health and the environment. Safe management of solid waste through guidance, technical assistance, regulations, permitting, environmental monitoring, compliance evaluation and enforcement is the goal of the EPA and state environmental agencies.\n\nThe Fresno Municipal Sanitary Landfill, opened in Fresno, California in 1937, is considered to have been the first modern, sanitary landfill in the United States, innovating the techniques of trenching, compacting, and the daily covering of waste with soil. It has been designated a National Historic Landmark, underlining the significance of waste disposal in urban society.\n\nThe first federal legislation addressing solid waste management was the Solid Waste Disposal Act of 1965 (SWDA) that created a national office of solid waste. By the mid-1970s, all states had some type of solid waste management regulations. In 1976, the U.S. House of Representatives passed the Resource Conservation and Recovery Act (RCRA) that dramatically expanded the federal government's role in managing waste disposal. RCRA divided wastes into hazardous and non-hazardous categories, and directed the EPA to develop design and operational standards for sanitary landfills and close or upgrade existing open dumps that did not meet the sanitary landfill standards.\n\nIn 1979, the EPA developed criteria for sanitary landfills that included siting restrictions in floodplains; endangered species protection; surface water protection; groundwater protection; disease and vector (rodents, birds, insects) control; opening burning prohibitions; explosive gas (methane) control; fire prevention through the use of cover materials; and prevention of bird hazards to aircraft.\n\nThe RCRA was amended in 1984. In 1991, the EPA established new federal standards for municipal solid waste landfills that updated location and operation standards, added design standards, groundwater monitoring requirements, corrective action requirements for known environmental releases, closure and post-closure requirements and financial assurances to pay for landfill future care and maintenance.\n\nThe EPA generally relies on the states to enforce their own operating permits and federal laws. If state agencies are not aggressive, violations can worsen, multiplying negative environmental impacts exponentially. There are some notable recorded violations in the U.S. such as for a landfill in Hawaii that was fined $2.8 million in 2006 for operating violations, but this is not common.\n\nModern landfills are specifically designed to protect human health and the environment by controlling water and air emissions. All MSWLF must comply with the federal regulations in 40 CFR Part 258, or equivalent state regulations. Some of the federal regulations in 40 CFR part 258 include:\n\n\nUnder Subtitle D of RCRA, states are required to adopt and implement permit programs to ensure that landfills in their states comply with relevant federal standards. The law also requires EPA to determine whether state permit programs are adequate to ensure such compliance. For permit programs to be approved, states must provide opportunities for public involvement during the permit application process. This may include public meetings or submission of concerns in writing to the permitting agency. In addition, states must have the power to issue permits and perform compliance monitoring and enforcement actions that ensure compliance with the federal standards.\n\nAgencies such as the Solid Waste Association of North America's (SWANA) Landfill Management Division provide training and technical advice related to the planning, design, construction, closure and post-closure of today's landfills. The division regularly monitors, reviews and comments on current legislative and regulatory actions that could potentially affect landfill operations and new technology. Waste Management, based in Houston, Texas, manages/operates five of the top 10 largest landfills and owns three of those outright. [Forbes]\n\nLandfill leachate is generated from liquids existing in the waste as it enters a landfill or from rainwater that passes through the waste within the facility. The leachate consists of different organic and inorganic compounds that may be either dissolved or suspended. An important part of maintaining a landfill is managing the leachate through proper treatment methods designed to prevent pollution into surrounding ground and surface waters. Based on recent EPA studies, a liner and leachate collection system constructed to current standards typically has a liquid removal efficiency of 99 to 100 percent and frequently exceeds 99.99 percent.\n\nThe leachate collection system collects the leachate so that it can be removed from the landfill and properly treated or disposed. Most leachate collection systems have the following components:\n\nFederal requirements mandate that treatment must meet drinking water quality standards, which are set to prevent harm to public health, or more stringent state standards to protect sensitive environments (high quality streams, trout streams).\n\nNearly all municipal solid waste landfills (MSWLFs) are required to monitor the underlying groundwater for contamination during their active life and post-closure care period. The exceptions to this requirement are small landfills that receive less than 20 tons of solid waste per day, and facilities that can demonstrate that there is no potential for the migration of hazardous constituents from the unit into the groundwater. All other MSWLFs must comply with the groundwater monitoring requirements found at 40 CFR Part 258, Subpart E–Ground-Water Monitoring and Corrective Action.\n\nThe groundwater monitoring system consists of a series of wells placed upgradient and downgradient of the MSWLF. The samples from the upgradient wells shows the background concentrations of constituents in the groundwater while, the downgradient wells show the extent of groundwater contamination caused by the MSWLF. The required number of wells, spacing, and depth of wells is determined on a site-specific basis based on the aquifer thickness, groundwater flow rate and direction, and the other geologic and hydrogeologic characteristics of the site. All groundwater monitoring systems must be certified by a qualified groundwater scientist and must comply with the sampling and analytical procedures outlined in the regulations.\n\nThere are three phases of groundwater monitoring requirements:\n\n\nIn the U.S., the regulatory structure for landfills specifies a 30-year post-closure monitoring period. It is presumed that at the end of the 30-year period, the landfill will be stable and will no longer require intensive monitoring. Today, landfills are designed from the start to ensure protection of the environment and public health, and the safe and productive use of the site after closure.\n\nThere are three categories of post-closure uses of landfill sites: Category 1 - open space, agricultural and passive recreation; Category 2 - Active recreation, parking or industrial/commercial activities; and Category 3 - Intensive uses such as residences, industry and commercial development.\n\nCategory 1 post-closures are the most numerous and may be the least recognizable due to the fact they appear to be nothing more than an open field. Some examples include: Westview Sanitary Landfill in Georgia - now a cemetery and Griffith Park in California - used for hiking trails.\n\nCategory 2 post-closures may have utilities, light structures or paving. Examples include Settler's Hill Landfill in Illinois - now golf courses and a minor league baseball field or the Germantown Sanitary Landfill in Wisconsin that is now a ski slope.\n\nCategory 3 post-closures are usually characterized by inclusion of major structures. Some of the most well known are Mile High Stadium in Colorado which is the football stadium for the Denver Broncos; Brickyard Shopping Center in Illinois; and Columbia Point in Massachusetts, home of the John F. Kennedy Presidential Library and Museum, and University of Massachusetts Boston's State Archives Building.\n\nThe EPA has collected and reported data on the generation and disposal of waste in the United States for more than 30 years. Recent estimates state that the amount of municipal waste disposed of in US landfills is about as of 2013.\n\nOrganic materials are estimated to be the largest component of MSW. Paper and paperboard account for 29% and yard trimmings and food scraps account for another 27%; plastics 12%; metals 9%, rubber, leather and textiles 8%; wood is approximately 6.4% and glass 5%. Other miscellaneous wastes make up approximately 3.4%.\n\nIn 2010, Americans recovered almost 65 million tons of MSW (excluding composting) through recycling.\n\nResearch has shown that leachate treatment facilities at modern landfills are capable of removing 100 percent of the trace organics and over 85 percent of the heavy metals.\n\nThe Puente Hills Landfill is the largest landfill in America. Over of garbage has risen from the ground since the area became a designated landfill site in 1957.\n\nIn 1986, there were 7,683 landfills in the United States. By 2009, there were just 1,908 landfills nationwide: a 75 percent decline in disposal facilities in less than 25 years. However, this number is deceptive. Much of the decrease is due to consolidation of multiple landfills into a single, more efficient facility. Also technology has allowed for each acre of landfill to take 30% more waste. So during this time, the available landfill per person has increased by almost 30%.\n\nMount Trashmore Park. Virginia Beach, Virginia.. Mount Trashmore Park\n\n\n"}
{"id": "26572214", "url": "https://en.wikipedia.org/wiki?curid=26572214", "title": "Leprosy in India", "text": "Leprosy in India\n\nLeprosy currently affects approximately a quarter of a million people throughout the world, with majority of these cases being reported from India.\n\nIndia is a signatory of United Nations Convention on the Rights of Persons with Disabilities (UNCRPD). India is currently running one of the largest leprosy eradication program in the world, the National Leprosy Eradication Program (NLEP). Still, 1.2 to 1.3 hundred thousand new cases of leprosy reported every year, 58.8% of the total amount of new cases reported every year.\n\nLeprosy is one of the least infectious diseases as nearly everyone has some measure of natural resistance against it. Nevertheless, it continues to spread, partially due to its extremely long incubation period, which may last as long as 30 years, as well as widespread ignorance and misinformation about the symptoms and effects of the disease. Stigma against the disease due to its disfigurement causes its victims to be isolated and shunned. They may also isolate themselves out of fear of discrimination. Patients may be impacted in every area of their life, including interpersonal relationships, economic security, and mental health and wellbeing. Leprosy is also the leading cause of permanent disability in the world and is primarily a disease of the poor.\n\nThe disease is now readily treatable with multi-drug therapy, which combines three drugs to kill the pathogen and cure the victim. Disability and disfigurement can be avoided if the disease is treated early, while conversely delay in treatment is linked to greater disability. Unfortunately, individuals with leprosy are still shunned, isolated, and stigmatised, leading to the fear of leprosy being worse than the disease itself. Additionally, the initial symptoms are not obvious and may easily be mistaken for other conditions, such as insect bites or allergic reactions. Patients may consider the disease too minor to warrant a visit to a doctor and fear losing their wages.\n\nPeople suffering from severe leprosy-related disabilities face extensive discrimination. Often, the only way they can make money is by begging. Under these conditions, they may mutilate themselves to garner more sympathy and therefore more money. Sufferers may also hide their symptoms or diagnosis from their family or colleagues, have difficulty maintaining a job, or avoid physical contact with their family.\n\nLeprosy colonies exist throughout India. These are typically made up of patients that have moved to the colony from a significant distance away, and their children and grandchildren. These colonies have a very strong community bond, formed in reaction to outside discrimination.\n\nIndia is considered the point of origin of leprosy with skeletal evidence of the disease dating to 2000 B.C. The disease is thought to have spread through trade and war to other parts of Asia, the Middle East, North Africa, and later Europe and the Americas. In ancient Indian society, individuals suffering from leprosy were alienated because the disease was chronic, contagious, resulted in disfigurement, had no cure at the time, and was associated with sin. In colonial India, the government enacted the Leprosy Act of 1898, which institutionalised leprosy victims and separated them based on gender to prevent reproduction. These laws mainly affected the poor because those who were self-sufficient were not obligated to be isolated or seek medical treatment.\n\nIn 1991, India contained 75% of the world's leprosy cases. Leprosy treatment was handled by the National Leprosy Elimination Programme, which was completely separated from other healthcare services. In 2005, this was incorporated into the broader healthcare system, and shortly afterwards, India announced that it had eliminated leprosy as a public health problem. However, this only means that there is less than 1 person in 10,000 infected with the disease. There is a lower percentage of affected individuals, but this number is still enormous in absolute terms, and India still makes up 58.8% of the world's leprosy cases. Since this announcement, funding for leprosy prevention and education programs has been drastically reduced. The prevalence and rate of infection have remained steady from 2005 to 2015, and there are still significant delays in treatment, both from the patients and the healthcare system itself, due to a lack of knowledge about the disease. Current programs include house-to-house examinations designed to identify hidden cases of leprosy.\n\nThe historical legacy and societal stigma toward leprosy are evidenced by various laws containing discriminatory clauses against leprosy victims. Laws in the states of Chhattisgarh, Rajasthan, Madhya Pradesh, Andhra Pradesh, and Orissa prohibit leprosy patients from running in local elections. Other laws include the Motor Vehicle Act of 1939 which restricts leprosy patients from obtaining a driving license and the Indian Rail Act of 1990 which prohibits leprosy patients from traveling by train.\n\nOver 100 discriminatory laws were challenged in a plea by the Vidhi Centre for Legal Policy on December 4, 2017. The Supreme Court recommended the matter to the attention of the government, following up on a previous Law Commission report. The specific laws and regulations named included Section 13 of the Hindu Marriage Act, which permits leprosy as a justification for divorce; Section 70(3)(b) of the Orissa Municipal Corporation Act, which prevents leprosy patients from running for the office of Corporator; and other similar laws.\n\nMany of these laws were written before the development of multi-drug therapy (MDT), a treatment that can make leprosy patients non-contagious and prevent further deterioration, and they have not been updated since. For example, almost all of the marriage and divorce laws of India consider leprosy as grounds for divorce with the Special Marriage Act of 1954 declaring leprosy \"incurable.\" These laws do not reflect the current understanding of leprosy.\n\n\n\n<br>\n"}
{"id": "55726255", "url": "https://en.wikipedia.org/wiki?curid=55726255", "title": "Lightwood's law", "text": "Lightwood's law\n\nLightwood's law is the principle that, in medicine, bacterial infections will tend to localise while viral infections will tend to spread. This is based on the observation that while bacterial sepsis tends, despite affecting the whole body, to have a clear site of origin or 'focus', the opposite may be true of viral infections. There may be multiple sites across the body which are affected including dermatological manifestations, respiratory symptoms and gastrointestinal symptoms. \n\nThis principle is by no means infallible and in clinical practice a variety of diagnostic tests are used to distinguish between bacterial and viral infections.\n"}
{"id": "25569133", "url": "https://en.wikipedia.org/wiki?curid=25569133", "title": "List of dams and reservoirs in Iraq", "text": "List of dams and reservoirs in Iraq\n\nThe following is a list of dams and reservoirs in Iraq. They are sorted according to their location in either the Euphrates or the Tigris river basin.\n\n\n\n\n"}
{"id": "18694954", "url": "https://en.wikipedia.org/wiki?curid=18694954", "title": "Medical Council of Canada", "text": "Medical Council of Canada\n\nMedical Council of Canada (MCC) \"(French: Le Conseil médical du Canada)\" is an organization that is charged with assessing medical candidates, evaluation of physicians through exams and granting a qualification called Licentiate of the Medical Council of Canada (LMCC) to those who wish to practise medicine in Canada.\n\nMCC is governed by a 51-member Executive Board of Council, who meets once a year to discuss budgets, policies and assets. The day-to-day operation is carried out by the Executive Director, currently Dr. M. Ian Bowmer.\n\nFounded by the \"Canada Medical Act\" in 1912 through the effort of Sir Thomas Roddick, a physician and Member of Parliament, who have been pursuing a standardized licensing scheme in Canada for over 18 years.\n\nBeginning April 1912, MCC gave the right to practise throughout Canada, to be admitted to the British Medical Register (BMR) to serve in the medical forces of the army and navy. The practice for registering physicians into the BMR eventually ceased but those who wish to practise in the UK can register themselves with the General Medical Council.\n\nA pass standing is required on both the QE Part I and the QE Part II in order to be awarded Licentiate of the Medical Council of Canada. LMCC is recognized by the 12 medical licensing authorities in Canada, and is one of the requirements for the issuance of a licence to practise medicine in Canada.\n\nLicentiate of the Medical Council of Canada, commonly abbreviated as LMCC, is a physician that, according to the bylaws of MCC:\n\n\nMCC also maintains the Canadian Medical Register, a list of physicians who have completed or exempted from the LMCC requirement. This is the first step for medical graduates who wish to obtain licence to practise prior to applying to their own regulatory body in their home province or territory.\n\n"}
{"id": "49163358", "url": "https://en.wikipedia.org/wiki?curid=49163358", "title": "Multidimensional Aptitude Battery II", "text": "Multidimensional Aptitude Battery II\n\nThe Multidimensional Aptitude Battery II is a group-administered intelligence test created by Canadian psychologist Douglas N. Jackson which is supposed to measure Verbal, Performance and Full Scale IQ. The battery consists of 10 subtests and is used for various professional, medical, military, government, law enforcement and employment settings. The test-retest reliability based on timed performance correlates with values of 0.95 for the verbal section, 0.96 for the performance section and 0.97 for the full scale.\n\nCitation.\n\nThe MAB II was created by psychologist Douglas N. Jackson and published by the company Sigma-assessment Systems Inc. It is designed to measure intellectual abilities of both adults and adolescents from ages 16 and over and can be used in any educational and career counselling settings, business, industries, clinics and mental health facilities for basic research. It can also be used in the government, law enforcement and military settings. MAB II is also available in languages such as spanish and french. Both the Verbal and Performance subtests on the MAB II takes 50 mins to finish either through computer administration or psychologist administration. All of the subtests are also constructed through multiple choice questions and went fair item selection for diverse groups including gender, nationality, age and culture. Age norms are also presented in the manual that comes with test.\n\n"}
{"id": "27859374", "url": "https://en.wikipedia.org/wiki?curid=27859374", "title": "Muskoka Initiative", "text": "Muskoka Initiative\n\nThe Muskoka Initiative on Maternal, Newborn and Child Health is a funding initiative announced at the 36th G8 summit which commits member nations to collectively spend an additional $5 billion between 2010 and 2015 to accelerate progress toward the achievement of Millennium Development Goals 4 and 5, the reduction of maternal, infant and child mortality in developing countries. A second summit on Maternal, Newborn and Child Health was held in Toronto from May 28-30, 2014 in follow-up to the original 36th G8 summit.\n\n"}
{"id": "38081305", "url": "https://en.wikipedia.org/wiki?curid=38081305", "title": "Norwegian Pharmacy Museum", "text": "Norwegian Pharmacy Museum\n\nThe Norwegian Pharmacy Museum (\"Norsk Farmasihistorisk Museum\") is located on Bygdøy in Oslo, Norway. It is operated in cooperation with the Norwegian Museum of Cultural History.\n\nThe Norwegian Pharmacy Museum was established in 1963 and opened in 1974. The purpose of the museum is to preserve pharmaceutical history. It exhibits items, inventory and literature collected from throughout Norway. The collection holds more than 19,000 items.\nThe pharmacy museum is housed in a former private residence (\"Generalitetsgården\") from Christiania dating to 1714. The house was demolished in 1918 and subsequently rebuilt at the Norwegian Folk Museum at Bygdøy. While the corner rooms in the first and second floor have been preserved from the original building, a public area from Apoteket Hjorten in Oslo has also been reconstructed in the building, illustrating an urban pharmacy from the 1860s.\n\nIn 1982, a herbal garden was added to the museum, showcasing about 160 different herbs, trees and shrubs used in the preparation of traditional remedies or mentioned in Old Norse myths and legends.\n\n"}
{"id": "34915840", "url": "https://en.wikipedia.org/wiki?curid=34915840", "title": "Office of HIV/AIDS Network Coordination", "text": "Office of HIV/AIDS Network Coordination\n\nThe Office of HIV/AIDS Network Coordination, known as HANC, works with the National Institutes of Health HIV/AIDS clinical trials networks with the intent of creating a more integrated, collaborative and flexible research structure. The networks are an affiliated group of national and international medical research institutions and investigators that conduct clinical HIV/AIDS research to develop safe and effective drugs, prevention strategies, and vaccines.\n\nThe HANC offices are located on the campus of the Fred Hutchinson Cancer Research Center in Seattle.\n\nGovernment funding for HIV and AIDS research in the United States comes from the Division of Acquired Immunodeficiency Syndrome (DAIDS) through the National Institutes of Health. The major networks receiving this funding coordinate with each other as members of HANC. Here are the member organizations in HANC:\n\n"}
{"id": "7445803", "url": "https://en.wikipedia.org/wiki?curid=7445803", "title": "Orthopaedic Nurse Certified", "text": "Orthopaedic Nurse Certified\n\nOrthopaedic Nurse, Certified (ONC) is the designation for an orthopaedic nurse who has earned nursing board certification from the Orthopaedic Nurses Certification Board (ONCB)\n\nONBC helps develop muscle health by administering a certificate to the Orthopaedic nurse that improves their skillful knowledge and improve their practice. An Orthopaedic nurse is responsible for assessing new patients for their conditions, watching the condition of their current patients, providing treatments and medication. As part of this role, the nurse also monitors vital signs, looks over the surgical sight, changes dressings, and notifies the doctor of any change in the patient's condition. Finally, the Orthopaedic nurse also performs general nursing techniques, such as changing bedpans, assisting the patient with walking, enforcing care plans, providing IV medication, and informing and supporting the patient and their families. The optimal goal for the Orthopaedic nurse is to keep the patient comfortable, which may require turning the patient and providing pain relievers as needed. \n\nThe Orthopaedic certification exam contains 150 questions,135 of which are scored while the other 15 do not affect the test score. A 97% is needed to pass the exam. Results are hosted by AMP, which is ONCB's test vendor. The ONCB then distributes the results directly to the new certified holder. The ONCB does not distribute the results to individual agencies and only uses a pass or fail system for future exams. The exam is usually given in the Fall and Spring and is offered around the United States. To take the certification exam the nurse has to be licensed and have at least 2 years experience, but doesn't need a bachelor's degree. Nurses must have 1000 hours of Orthopaedic patient care within the last 3 years. Certification lasts for 5 years, after which recertification or continuing education is required.\n\nRecertification in Orthopeadic Nursing requires 1000 practice hours in logged in an applicant's past 5 years and 100 hours of education: 70 hours in Orthopaedics and 30 hours in general nursing. The application should be handed in as soon as possible. The application can take 8 weeks to process. Paper applications should be mailed with a return receipt. \n\n\nOn average, an Orthopeadic nurse draws a salary of $69,000 a year. The need for professional Orthopaedic nurses is expected to increase by 19% in 2022. The number of jobs will increase at a higher rate due to aging adults at risk of arthritis, fractures, and many other Orthopaedic problems.\n\n\n"}
{"id": "30952587", "url": "https://en.wikipedia.org/wiki?curid=30952587", "title": "Penikese Island Leper Hospital", "text": "Penikese Island Leper Hospital\n\nThe Penikese Island Leper Hospital was a leprosy hospital located on Penikese Island, off the coast of Massachusetts, United States, from 1905 to 1921. It housed a small colony of people who suffered from leprosy over the years until it was closed in 1921 and patients were relocated to a federal hospital in Louisiana.\n\n"}
{"id": "26372323", "url": "https://en.wikipedia.org/wiki?curid=26372323", "title": "Permanent Representative of Russia to the United Nations", "text": "Permanent Representative of Russia to the United Nations\n\nThe permanent representative of Russia to the United Nations is the leader of Russia's diplomatic mission to the United Nations.\nVasily Nebenzya is charged to represent Russia in the United Nations Security Council and the formal meetings of the United Nations General Assembly except the rare ones when the most senior officers of Russia is present (President of Russia or the Minister of Foreign Affairs). Like all the Russian Ambassadors he or she must be nominated by the President and confirmed by the Federation Council.\n\nThe position of the Russian Representative to the United Nations is the highest position among all the Russian ambassadors serving in various organizations and countries respectively. The ambassador serve as the pleasure of the President.\n\nVasily Nebenzya was nominated by the President Vladimir Putin for his position and was confirmed by the Federation Council. He is serving from July 27, 2017.\n\n"}
{"id": "47331849", "url": "https://en.wikipedia.org/wiki?curid=47331849", "title": "Pill reminder", "text": "Pill reminder\n\nA pill reminder is any device that reminds users to take medications. Traditional pill reminders are pill containers with electric timers attached, which can be preset for certain times of the day to set off an alarm. More sophisticated pill reminders can also detect when they have been opened, and therefore when the user is away during the time they were supposed to take their medication, they will be reminded of it when they return. This reminder can be in the form of a light, which also helps for deaf or hearing-impaired users.\n\nA new take on the pill reminder is as a cellphone app that uses the cellphone's alarm system to remind the owner to take the medication. These programs can keep track of missed doses as well. It is just not smartphones that do this; the Pantech Breeze was a flip phone offered by AT&T in the United States from 2009 to 2013, which supported this feature.\n\nAutomatic Pill Reminder Bottles\nInvented and patented in 2004 by innovator and inventor Joseph Lai the pill reminder bottle (device is compatible and can be retrofitted inside a regular conventional pill bottle cap. This reminder device is installed inside the conventional pill bottle between the bottle cap and the bottle container. When the user closes the pill bottle cap on the bottle container, the electronic timer, with factory predetermined time interval, is automatically activated. That activated timer will generate alert signals not only remind user last pill has taken but also to remind the user to take his/hers next dose at time-out.)\n\nAutomatic Pill Dispensing System\nUsually manufactured with a rotating tray of some kind, these pill reminders are programmable, and usually dispense medication only according to the alarm set. A tray filled with the required dosages, dispenses and cycles at each alarm time. Some models like Med-e-lert also have a flashing light and audible alarm that sounds when a dosage is recommended.\n\nPill Reminder Mobile Apps\nAfter the predominant increase in mobile users, there are few of mobile apps developed to remind consumption of medicine, These Apps have features like Reminder notification, track consumption history, Track medical measurements etc... These apps are available in Android and ios as well. Here is the list of few apps.\n"}
{"id": "43265278", "url": "https://en.wikipedia.org/wiki?curid=43265278", "title": "Prior authorization", "text": "Prior authorization\n\nPrior authorization is a process used by some health insurance companies in the United States to determine if they will cover a prescribed procedure, service, or medication. The process is intended to act as a safety and cost-saving measure, although it has received criticism from physicians for being costly and time-consuming.\n\nPrior authorization is a check run by some insurance companies or third party payers before they will agree to cover certain prescribed medications or medical procedures. There are a number of reasons that insurance providers require prior authorization, including age, medical necessity, the availability of a generic alternative, or checking for drug interactions. A failed authorization can result in a requested service being denied, or an insurance company requiring the patient to go through a separate process known as \"step therapy\" or \"fail first\". Step therapy dictates that a patient must first see unsuccessful results from a medication or service preferred by the insurance provider, typically considered either more cost effective or safer, before the insurance company will cover a different service.\n\nAfter a request comes in from a qualified provider, the request will go through the prior authorization process. The process to obtain prior authorization varies from insurer to insurer, but typically involves the completion and faxing of a prior authorization form. At this point, the medical service may be approved, rejected, or additional information may be requested. If a service is rejected, the healthcare provider may file an appeal based on the provider's medical review process. In some cases, an insurer may take up to 30 days to approve a request.\n\nInsurers have stated that the purpose of prior authorization checks is to provide cost savings to consumers by preventing unnecessary procedures as well as the prescribing of expensive brand name drugs when an appropriate generic is available. In addition, a prior authorization for a new prescription may help prevent potentially dangerous drug interactions. A 2009 report from the Medical Board of Georgia showed that as many as 800 medical services require prior authorizations.\nAccording to \"Medical Economics\", physicians have expressed frustration with the current prior authorization process with regards to time spent interacting with insurance providers and the costs incurred based on that time. A 2009 study published in \"Health Affairs\" reported that primary care physicians spent 1.1 hours per week fulfilling prior authorizations, nursing staff spent 13.1 hours per week, and clerical staff spent 5.6 hours. A study in the Journal of the American Board of Family Medicine found that the annual cost per physician to conduct prior authorizations was between $2,161 and $3,430. The cost to health plans has been reported at between $10 and $25 per request. It is estimated that current prior authorization practices cost the US healthcare system between $23 and $31 billion annually.\n\nThere have been a number of legislative and technological developments which attempt to make the prior authorization process more efficient.\n\nIn 2011, the American Medical Association made recommendations that a uniform prior authorization form should be adopted along with real-time electronic processing. The organization described a next generation prior authorization process which would involve a physician ordering a medical service, their staff completing a standardized request form, and an electronic submission process that would give same-day approval or denial of the request. The reasoning behind a denial would be clearly stated, allowing physicians to easily submit an appeal.\n\nIn February 2012, The Maryland Health Care Commission presented a plan to the state legislature, which outlined a standardized, electronic filing system for prior authorization requests. In response to a 2012 bill concerning the e-filing of prescriptions, the Kansas Board of Pharmacies advocated for an electronic prior authorization process, which would generate immediate approval for prescriptions. In 2013, the Arizona House of Representatives formed a committee to research the prior authorization process and make recommendations. Also, by 2013 a Washington State Senate proposal was submitted, which would require the state Insurance Commissioner to develop a standardized prior authorization form.\n\nAs of May 2013, the National Council for Prescription Drug Programs had adopted a standardized process for the exchange of electronic prior authorizations. The American Medical Association found that the average annual savings per physician from using an electronic prior authorization process to be approximately $1,742. Additionally, a case study conducted by Prime Therapeutics, a pharmacy benefit manager, demonstrated a 90% reduction in payer response time through electronic prior authorization systems compared with the manual prior authorization process.\n\n"}
{"id": "593495", "url": "https://en.wikipedia.org/wiki?curid=593495", "title": "Psychosocial short stature", "text": "Psychosocial short stature\n\nPsychosocial short stature (PSS) or psychosocial dwarfism, sometimes called psychogenic or stress dwarfism, or Kaspar Hauser syndrome, is a growth disorder that is observed between the ages of 2 and 15, caused by extreme emotional deprivation or stress.\n\nThe symptoms include decreased growth hormone (GH) and somatomedin secretion, very short stature, weight that is inappropriate for the height, and immature skeletal age. This disease is a progressive one, and as long as the child is left in the stressing environment, his or her cognitive abilities continue to degenerate. Though rare in the population at large, it is common in feral children and in children kept in abusive, confined conditions for extended lengths of time. It can cause the body to completely stop growing but is generally considered to be temporary; regular growth will resume when the source of stress is removed.\n\nChildren with PSS have extremely low levels of growth hormone. These children possibly have a problem with growth hormone inhibiting hormone (GHIH) or growth hormone releasing hormone (GHRH). The children could either be unresponsive to GHRH, or too sensitive to GHIH.\n\nChildren who have PSS exhibit signs of failure to thrive. Even though they appear to be receiving adequate nutrition, they do not grow and develop normally compared to other children of their age.\n\nAn environment of constant and extreme stress causes PSS. Stress releases hormones in the body such as epinephrine and norepinephrine engage what is known as the 'fight or flight' response. The heart speeds up and the body diverts resources away from processes that are not immediately important; in PSS, the production of growth hormone (GH) is thus affected. As well as lacking growth hormone, children with PSS exhibit gastrointestinal problems due to the large amounts of epinephrine and norepinephrine, resulting in their bodies lacking proper digestion of nutrients and further affecting development.\n\nWhile the cure for PSS is questionable, some studies show that placing the child affected with the disease in a foster or group home increases growth rate and socialization skills.\n\nIn Günter Grass's 1959 novel \"The Tin Drum\" (\"Die Blechtrommel\"), the character Oskar Matzerath \"willfully stunted his growth at three feet tall as a three-year-old, although later in the novel he grows to four feet one inch\" in reaction to the stress he experiences – the petit-bourgeois German society.\n\nIn the novel \"Les Misérables\" by Victor Hugo, eight-year old Cosette had been abused, neglected and enslaved by the Thènardier family. The extreme abuse and neglect she faces is described as very stressful for her, and as a result she's described as simultaneously being as short as a child half her age and having an expression more appropriate for an older woman. She recovers after she's adopted by Jean Valjean and is of average height as an adult.\n\nIn \"One Flew Over the Cuckoo's Nest\", Chief Bromden claims that one of Nurse Ratched's orderlies, Williams, a black man with dwarfism, gained his short stature as the result of seeing white men rape his mother.\n\nIn the novel \"Flowers in the Attic \" by V.C. Andrews, twins Cory and Carrie Dollanganger are locked in an attic (with their two older siblings). The stress of their grandmother's abuse and lack of attention from their mother — along with arsenic poisoning and lack of outdoor play opportunities — stunts the twins' growth. Later in the series, Carrie is described as being eight years old, yet her physical appearance is that of a three-year-old.\n\n"}
{"id": "12531301", "url": "https://en.wikipedia.org/wiki?curid=12531301", "title": "Ryūhei Kawada", "text": "Ryūhei Kawada\n\nIn the late 1980s, between one and two thousand Japanese patients with haemophilia contracted HIV via tainted blood products. Upon discovering he was one of the affected, Ryuhei Kawada joined the lawsuit against Green Cross Corporation that provided the tainted blood products, which eventually led to the guilty pleas from three executives in 1997.\n\nIn the Japanese House of Councillors election, 2007, Kawada won a seat in the House of Councillors. He has expressed a desire to work on issues of health, welfare, and labour. He has also indicated he will form a Green Party of Japan based on the Rainbow and Greens which supported his campaign.\n\n\n\n"}
{"id": "17839711", "url": "https://en.wikipedia.org/wiki?curid=17839711", "title": "SBAR", "text": "SBAR\n\nSBAR is an acronym for Situation, Background, Assessment, Recommendation; a technique that can be used to facilitate prompt and appropriate communication. This communication model has gained popularity in healthcare settings, especially amongst professions such as physicians and nursing. It is a way for health care professionals to communicate effectively with one another, and also allows for important information to be transferred accurately. The format of SBAR allows for short, organized and predictable flow of information between professionals.\n\nSBAR was first developed by the military, specifically for nuclear submarines. It was then used in the aviation industry, which adopted a similar model before it was put into use in health care. It was introduced to rapid response teams (RRT) at Kaiser Permanente in Colorado in 2002 , to investigate patient safety. The main purpose was to alleviate communication problems traced from the differences in communication styles between healthcare professionals. SBAR was later adopted by many other health care organizations. It is among the most popular handover mnemonic systems in use.\n\nIt is now widely recommended in healthcare communication. For instance, the Royal College of Physicians of London, UK, recommends the use of SBAR during the handover of care between medical teams when treating patients who are seriously ill or at risk of deteriorating. SBAR is an included tool in the Interventions to Reduce Acute Care Transfers (INTERACT II) project, a US measure to reduce rehospitalization among residents of long-term care (LTC) facilities.\n\nA few things are necessary for a health care professional to know before beginning an SBAR conversation. A thorough assessment of the patient should be done. The patient’s chart should be on hand with a list of current medications, allergies, IV fluids, and labs. Vital signs should be completed before making the call, and the patients code status should be known and reported.\n\nThis part of SBAR determines what is going on and why health care professionals are needed. Health care professionals become familiar with the environment and the patient. Identify the problem and concern and provide a brief description of it. Be able to describe what is going on with the patient and why they are experiencing what is going on. During this stage of the communication the main goal is to communicate what is happening. It is recommended that this element be brief and last no more than 10 seconds.\n\nIt is recommended that health care professionals identify the person with whom they are speaking, to introduce oneself (including title or role) and where one is calling from. Providing information about the patient such as name, age, sex, and reason for admission is also important. Lastly, the health care professional is to communicate the patient's status (such as chest pain or nausea).\n\nThe goal of background is to be able to identify and provide the diagnosis or reason for the patient’s admission, their medical status, and history. The background is also the place to determine the reason or context of the patient's visit. During this stage the patient's chart is ready and as much important medical-based information is provided to set up the assessment of data. Examples of medical-based information include date and reason for admission, most recent vital signs and vital signs outside of normal parameters, current medications, allergies, and labs, code status, and other clinically important information. \n\nAt this stage, the situation is surveyed to determine the most appropriate course of action. Here the medical professional states what they believe the problem is based on current assessments and medical findings. Any impertinent information is avoided unless asked for.\n\nHealth care professionals give very precise and descriptive explanations on exactly what they need during that time frame. Possible solutions that could correct the situation at hand are discussed between health care professionals. Notably, suggesting ideas to physicians can be a weak point of nurses. Therefore, an explicit statement of what is required, how urgent, and what action needs to be taken is paramount.\n\nPreparation is an integral part of SBAR and health care professionals are suggested to prepare to be able to answer any question the physician may ask. Discussion with another colleague may help. It is highly recommended that information about medical records, medication, administration records, and patient flow sheet be studied before contacting a physician.\n\nThis is a direct example that shows how SBAR communication is used in a hospital setting involving communication between two nurses to effectively assess and diagnose the patient and correct the problem. This example is between an preoperative nurse to operating room nurse.\n\nSituation:\n\"Mary, I'm going to be sending Mrs. Porter over to you in a few minutes for repair of her fractured ankle. I want you to know what's going on with her. I'm concerned about her emotional status. I've also alerted Dr Anesthesiologist and Dr Surgeon about my concern, but they have agreed to go ahead with the surgery because she needs this procedure to salvage her foot.\"\n\nBackground:\n\"She was in an auto accident last Friday, and her husband was killed. Her children are all at the funeral home making arrangements for his burial. She's made some comments about not wanting to live. Her vital signs are stable; the foot is cool and slightly mottled. We've just given her some Versed.\"\n\nAssessment:\n\"I think her emotional status is such that this will be a very difficult period of time for her, especially during induction and awakening from anesthesia.\"\n\nRecommendation:\n\"I suggest that you meet her as soon as possible and stay with her during induction and emergence from anesthesia.\"\n\nIn a 2013 review of studies addressing communication errors during handover, the greatest problem reported was the omission of detailed patient information. SBAR has been suggested as a means to overcome this problem by applying a system and structure to the presentation of information.\n\nUsing the SBAR communication model provides for more effective and enhanced family and patient outcomes on pediatric units. Using SBAR when producing bedside reports increases patient and family satisfaction and also increases their level of comfort when dealing with outlying situations. SBAR also allows nurses to be more effective when giving reports outside of the patients room. SBAR is a model used in communication that standardizes information to be given and lessons on communication variability, making report concise, objective and relevant.\n\nAnother benefit of using SBAR is that it allows patients to have the time to ask any questions that they might have, and allows patients to gain exact knowledge of information related to their plan of care. SBAR allows patients to be fully aware of whom their nurse is on every shift and this adds to the patients sense of comfort knowing that there will always be someone around looking after them during shift change.\n\nSBAR use has not only improved the relationship between the doctors and the nurses but has also had a dramatic increase of overall health of patients. This led to a decrease in hospitalizations and deaths which efficiently improved communication between the nurse and doctor, which also led to a reduction of unexpected deaths. The problem between the communication between nurses and doctors is that the levels of teamwork and interaction are different therefore causing ineffective communication.\n\nSBAR has been used in quality improvement projects that have looked at ways of avoiding hospitalizations.\n\nSBAR communication encounters difficulties in certain situations which are:\n\n\n"}
{"id": "11958237", "url": "https://en.wikipedia.org/wiki?curid=11958237", "title": "Semen quality", "text": "Semen quality\n\nSemen quality is a measure of the ability of semen to accomplish fertilization. Thus, it is a measure of fertility in a man. It is the sperm in the semen that is of importance. Semen quality involves both sperm quantity and quality. Decreased semen quality is a major factor of male infertility.\n\nCryptorchidism, hypospadias, testicular cancer and poor semen quality make up the syndrome known as testicular dysgenesis syndrome.\nThere are many factors that influence the sperm quality. Exposure to any of the temporary factors can cause up to a three-month delay before sperm quality returns to normal, due to spermiogenesis.\n\nA 2017 review and meta-analysis found sperm counts among Western men (i.e. men in Australia, Europe, New Zealand, and North America) declined 50—60% between 1973 and 2011, with an average decline of 1.4% per year. The meta-analysis found no indication the decline is leveling off. The amount of decline among men in North America and men in Australia/Europe is similar. The decline in sperm count among men in South America, Asia, and Africa is less than men in Western countries, though the amount of decline in these regions is uncertain. Reasons for the decline are not known with certainty, but it may be associated with chemical exposure or maternal smoking during prenatal development or pesticide exposure or lifestyle changes during adulthood.\n\nAlthough it is possible for men to father children into old age, the genetic quality of sperm, as well as its volume and motility, all typically decrease with age. In other words, older sperm are less likely to result in a successful pregnancy and, moreover, the cumulative fragmentation of sperm DNA over time increases the likelihood that a small fraction of men will pass on achondroplasia and transmit multiple genetic and chromosomal defects. For example, the percentage of sperm with highly damaged DNA, comet extent, DNA break number, and other comet measures has been found to be significantly higher in men aged 36–57 years than in those aged 20–35 years. Advancing paternal age has been implicated in a number of possible health effects. One particularly well-studied connection is the link between advancing age and autism. For example, one study of 943,664 children less than 10 years old, found that, with confounding variables controlled, the risk of autism increased with increasing paternal age.\nIn men with a normal level of sperm production (normozoospermia), the percentage of sperm DNA fragmentation is positively correlated with age, and inversely correlated with progressive sperm motility. \nNo age related effects on sperm were noted in separate control groups recruited in different geographical locations, indicating that dietary habits, lifestyle or ethnicity could play a part in the quality of sperm.\n\nWhile advanced age can be a possible factor in sperm motility and health, the sperm of men below 20 years of age has likewise been linked to an increase in birth defects such as neural tube defects, hypospadias, cystic kidney, and Down syndrome.\n\nSperm are heat-sensitive, and cannot endure high temperatures. Increases of 2-3 °C are associated with increased DNA fragmentation.\nThe body has compensatory mechanisms, like the cremaster muscle relaxing and letting the testicle hang further away from the warm body, sweating and a countercurrent exchange of blood cooling inflowing blood. However, despite these compensations, there are activities that should not be performed too often, in order to prevent infertility due to heat;\n\nFever raises the body temperature, which can strike sperm quality.\nIn the same way, sperm quality can be lower in the summer.\n\nContrary to widely held beliefs, no evidence supports that wearing constrictive underwear, or \"briefs,\" decreases fertility. Even with an elevation in temperature of 0.8-1° caused by wearing constrictive underwear, no changes in sperm parameters, no decrease in spermatogenesis, and no changes in sperm function are observed \n\nA blow from outside does not affect the sperm quality of already produced sperm cells. Furthermore, the testes are well protected in the scrotum, for example by the tunica vaginalis, making the testes slide away from external pressure rather than being malformed from it; however, a hard enough hit can close or crush the capillaries that supply the sperm producing tissue, resulting in permanent or temporary and partial or total inability to produce sperm in the affected testicle.\n\nThere is suspicion that many toxic substances, including several types of medication and hormones, and also constituents of the diet, influence sperm quality. While a few chemicals with known effects on fertility have been excluded from human consumption, we cannot know if others remain undiscovered. Many products that come into direct contact with spermatozoa lack adequate testing for any adverse effect on semen quality.\n\nEndocrine disruptors are chemicals that interfere with the endocrine (hormone) system.\n\nA 2008 report demonstrated evidence of the effects of feminizing chemicals on male development in each class of vertebrate species as a worldwide phenomenon; these chemical are suspected of reducing the sex ratio and sperm counts in humans. Ninety-nine percent of over 100,000 recently introduced chemicals are poorly regulated.\n\nAt least three types of synthetic toxins have been found in the semen of student volunteers: polychlorinated biphenyls (PCBs), DDT, and hexachlorobenzene. DDT and hexachlorobenzene are associated with decreased semen quality, while PCBs are associated with decreased fertility overall. Leaks of dibromochloropropane (DBCP) have caused sterility in men. Soldiers that were exposed to dioxins and dioxin-like compounds during the Vietnam war have given rise to children with an increased rate of birth defects.\n\nPhthalates, a ubiquitous pollutant, may cause decreased sperm production when having been exposed to it during prenatal development.\n\nOther potential xenoestrogens that have been associated with decreased sperm quality in some studies are bisphenol A, nonylphenol and octylphenol.\n\n\nIn addition, \"in vitro\" studies have observed altered sperm function by the following medications:\n\nAlso, numerous products that are intended for exposure to spermatozoa have only a general assumption of safety based on the absence of evidence of actual harm.\n\n\nThe body also has natural variations in hormone concentrations, giving sperm quality natural fluctuations as well.\n\n\nEnvironmental mutagens that are associated with decreased semen quality include the following:\n\nOther environmental agents associated with decreased semen quality include:\n\nHow long the man has abstained prior to providing a semen sample correlates with the results of semen analysis and also with success rates in assisted reproductive technology (ART).\n\nBoth a too short period of time since last ejaculation and a too long one reduce semen quality.\n\nA period of time of less than one day reduces sperm count by at least 20%.\n\nLonger periods of abstinence correlate with poorer results – one study found that couples where the man had abstained for more than 10 days before an intrauterine insemination (IUI) had only a 3% pregnancy rate. An abstinence period of only 1 or 2 days produce the highest pregnancy rates per IUI cycle compared with longer intervals of ejaculatory abstinence. This increase in pregnancy rate occurs despite a lower value of total motile spermatozoa. Daily sexual activity increases sperm quality in men minimizing DNA damage in the sperm—because it is speculated to result in less storage time where damage may accumulate.\n\nSemen samples obtained via sexual intercourse contain 70-120% more sperm, with sperm having a slightly higher motility and slightly more normal morphology, compared with semen samples obtained via masturbation. Sexual intercourse also generates a 25–45% increase in ejaculate volume, mainly by increased prostate secretion.\n\nThis intercourse advantage is even greater for men with oligospermia.\n\nHowever, the single factor or factors for the intercourse advantage have not yet been isolated. It cannot be explained by presence of visual perception of physical attractiveness alone during stimulation, although there may be a slight correlation. Neither do any substantial fluctuations in sex hormones explain the intercourse advantage. It is hypothesized that sexual intercourse subdues an inhibition from the central nervous system, but what, in turn, is the subduing factor is still not completely known.\n\nThe sperm quality is better if the sample is collected at home than in the clinics. Collecting the sperm at home gives a higher sperm concentration, sperm count and motility particularly if the sperm is collected via sexual intercourse. If the semen sample is to be collected by masturbation, a specimen from the early stages of the ejaculate should be into a clean new and unused, sealed collection cup.\n\nFor semen that has been ejaculated, the quality deteriorates with time. However, this lifetime can be shortened or prolonged, depending on the environment.\n\nSperm outside the body generally has a life expectancy which is considered to depend on pH, temperature, presence of air and other factors, and is unpredictable but smaller than the life expectancy inside the human body. For instance, sperm donors who collect the sample outside the clinic are advised to have handed in the sample no more than one hour from collection, and to keep it, if not at body temperature, then at least at room temperature.\n\nIn a non-harmful environment outside the body, such as in a sterile glass container the number of motile sperm decreases by approximately 5-10% per hour. In contrast, in a latex condom, the quality decreases by 60-80% per hour, rendering the sample unusable in a relatively short time.\n\nThe environment in the uterus and fallopian tubes are advantageous. A pregnancy resulting from sperm life of eight days has been documented.\n\nTobacco smoking lowers the sperm quality, perhaps by decreased ability to attach to hyaluronan on the egg cell. Wright et al. have reviewed evidence that smoking is associated with increased sperm DNA damage and male infertility.\nSmoking cannabis can decrease sperm quantity.\n\nLong-term stress is also suggested. The practise of tucking can reduce both the sperm count and sperm quality. Meta-analysis indicates that mobile phone exposure affects sperm quality negatively.\n\nHigher levels of intelligence are also correlated with higher levels of sperm quality in three key indicators: sperm concentration, sperm count and sperm motility. Men who scored high on a battery of intelligence tests tended to have higher counts of healthy sperm, while low scorers tended to have fewer and more sickly sperm. It is conceivable that intelligence might tip off a man's overall health to women looking for a mate with healthy genes, explained University of New Mexico evolutionary psychologist Geoffrey Miller at a talk at Harvard University. \"Though the connections between brains and sperm were 'not awesome, they're there and highly significant,' Miller said. All things held equal, good sperm and good brains go together.\"\n\nRegarding diet, malnutrition or an unhealthy diet can lead to e.g. Zinc deficiency, lowering sperm quality.\n\nSperm quality is better in the afternoon than in the morning. Adrenaline-levels are higher during awakening (~06.00 to noon), which may contribute similarly to general stress.\n\nLack of exercise, as well as excessive exercise, are minor factors. In professional sports, semen quality parameters tend to decrease as training requirements increase. The effect differs substantially between different professional sport types. For example, water polo appears substantially less harmful to semen quality than triathlon.\n\nA longer duration of sexual stimulation before ejaculation slightly increases sperm quality.\n\nMales carrying Robertsonian translocations in their chromosomes have significantly higher degree of sperm cell apoptosis and lower concentration. Sperm cells also have decreased forward motility, but normal morphology.\n\nTesticular cancer, Leydig cell tumours and Sertoli cell tumours are also associated with reduced sperm count and quality.\n\nA semen analysis typically measures the number of sperm per millilitre of ejaculate, and analyzes the morphology (shape) and motility (ability to swim forward) of the sperm (the typical ejaculate of a healthy, physically mature young adult male of reproductive age with no fertility-related problems usually contains 300–500 million spermatozoa, though only a couple of hundred survive in the acidic environment of the vagina to be candidates for successful fertilization). Also usually measured are the concentration of white blood cells, the level of fructose in the semen, and the volume, pH, and liquefaction time of the ejaculate.\n\nA man's sperm are mixed with hamster eggs that have had the zona pellucida (outer membranes) removed, and the number of sperm penetrations per egg is measured. No strong correlation has been found between hamster egg penetration rates and the various semen parameters and the role of the hamster egg penetration test in the investigation of the causes of infertility should be evaluated further. However, a negative result on the hamster test correlates with a lower probability of the man's partner becoming pregnant.\n\nPresence of antisperm antibodies may be responsible for sperm agglutination, reduced sperm motility, abnormal postcoital test. Several tests are presently available including Sperm Immobilization test, Sperm Agglutination tests, Indirect immunofluorescence test, Enzyme-linked immunosorbent assay, Radiolabelled Antiglobulin Assay. One of the most informative and specific tests is Immunobead Rosette Test which can identify different antibody classes involved (IgG, IgA, IgM) and location on the sperm cell (head, body or tail).\n\nHemizona test is a test to evaluate sperm zona-binding capacity. In this test, the two halves of human zona pellucida is incubated with patient's capacitated sperm and control fertile donor's sperm.\n\n\nWhen performing cryopreservation of semen, it is the sperm quality after reviving the sample that is of importance, because many sperm cells die in the process.\n\nTo be of use in assisted reproductive technology, the sample should after thawing have more than 5 million motile sperm cells per ml with a good grade of mobility. If the grade of mobility is poor, 10 million motile cells per ml is required.\n\nHome insemination of previously frozen sperm can be accomplished with the use of a cervical cap conception device as a delivery system for the sperm.\n\nIn 10–20% of all men, the semen does not endure cryopreservation. The cause is unknown. It does not necessarily mean an otherwise bad semen quality.\n\nWhen a sperm sample is prepared for intrauterine insemination, it is washed at a facility such as a fertility clinic or a sperm bank. Some sperm does not survive the washing process, as is also the case when freezing the sperm.\n"}
{"id": "19929752", "url": "https://en.wikipedia.org/wiki?curid=19929752", "title": "St. Joseph's Regional Medical Center", "text": "St. Joseph's Regional Medical Center\n\nSt. Joseph's University Medical Center is a member of St. Joseph's Health. Located in Paterson, New Jersey, St. Joseph's University Medical Center, which includes St. Joseph's Children's Hospital, is a major academic medical center and state designated trauma center that cares for the most complex and routine cases. There is also a second campus located in Paramus, New Jersey on Century Road.\nThe hospital was founded in 1867 and is sponsored by its founders, the Sisters of Charity of Saint Elizabeth.\n\nSt. Joseph's University Medical Center is part of St. Joseph's Health, which encompasses St. Joseph's University Medical Center, St. Joseph's Children's Hospital, St. Joseph's Wayne Medical Center, St. Joseph's Healthcare and Rehab Center, and Visiting Health Services of NJ.\n\n"}
{"id": "39782216", "url": "https://en.wikipedia.org/wiki?curid=39782216", "title": "Tbilisi Medical Academy", "text": "Tbilisi Medical Academy\n\nThe Petre Shotadze Tbilisi Medical Academy, commonly referred to as Tbilisi Medical Academy, is a Georgian private medical university located in Tbilisi. The university was founded in 1992 by Petre Shotadze, in whose honor it was posthumously renamed. Tbilisi Medical Academy is the oldest private institution of higher education in Georgia.\nThe University offers 6 year educational program in Medicine and the MD degree offered is recognised around the globe.\nThe University has excellent Medical faculty and maintains perfect student to teacher ratio. The University has collaboration with many other reputed universities in Europe to which they offer various student transfer programs.\n\n"}
{"id": "23318373", "url": "https://en.wikipedia.org/wiki?curid=23318373", "title": "The Vital Dent Foundation", "text": "The Vital Dent Foundation\n\nThe Vital Dent Foundation is non-profit making organisation whose mission is to help spreading dental health habits and prevention.\nThe Foundation is present in those countries where Vital Dent operates, such as Spain, Portugal and Italy.\n\nMain areas of activity are:\n\nThe Vital Dent Foundation sponsors dentistry research via the awarding of annual prizes which range from 10 to €40.000. Although originally prizes were awarded only in Spain, since the 5th Edition the scope of countries has been extended to Italy, Portugal and United States.\n\nIn the last edition (6th edition), prizes have been split in 3 categories:\n\nWith the collaboration of non-profit organizations, the Vital Dent Foundation and its team of volunteers focus on two lines of activity: the Smile Route and the Permanent Solidarity Centre.\n\nTogether with the NGO Solidariamente, the Vital Dent Foundation offers its experience in the dental field to people who happen not to be born in a country of the wrongly called First World. Three editions have already taken place, and they have managed to perform more than 24.000 interventions, including mouth cleanings, piece extractions, filling and sealing. These editions have developed in Morocco, although the plan is to extend the reach to other equally needed countries.\n\nThe main objective is to create this centre in Morocco to insure that actions taken through the Smile Route initiative are not isolated and can be continuously developed on a daily basis with the help of Vital Dent dentist under local coordination.\n\nOne of the Foundation’s main objectives is to inform the young about the importance of dental care in their life’s health. Messages are passed with the help of a pet, the \"Perez Mouse\", who visits plenty of schools in Spain to make dental healthcare amusing for children.\n\nThe Institute’s objective is to provide continuous training to dentists to make available the newest and most advanced methodologies and techniques being used in the oral health field. The Institute runs five departments:\n\n"}
{"id": "17455605", "url": "https://en.wikipedia.org/wiki?curid=17455605", "title": "Therapeutic support staff", "text": "Therapeutic support staff\n\nTherapeutic Support Staff - (TSS) are special education assistants within the commonwealth of Pennsylvania. They are trained to provide therapy to students with attention deficit hyperactivity disorder, Tourette syndrome, autism, or other emotional support needs.\n\nA TSS meets with a child in a one-on-one situation, with family, in public or at school to provide therapy. They work with the student to improve in areas such as social skills, behavioral rehabilitation, speech, motor skills, etc. TSS workers are often confused with a wrap around, which provide many of the same supportive therapies. A TSS worker has more in depth training and education on working with special needs, where a wraparound works mainly with children that have behavioral issues.\n"}
{"id": "11891685", "url": "https://en.wikipedia.org/wiki?curid=11891685", "title": "Tummy time", "text": "Tummy time\n\nTummy time is a colloquialism used to encourage parents to ensure that their infant children spend time in the prone position while awake and supervised.\n\nIn 1992, the American Academy of Pediatrics recommended babies sleep on their backs to prevent Sudden Infant Death Syndrome (SIDS). Although the rate of SIDS decreased by 50% since the Safe to Sleep campaign started in 1994, an unintended consequence was that babies missed out on the twelve or so hours they used to spend in the prone position and there was a sharp increase in skull deformations in infants. Along with tummy time, rotating the direction infants lie in their crib as well as avoiding too much time in car seats, carriers, and bouncers are behaviors recommended to alleviate the associated risks of infants sleeping in a supine position.\n\nSince 1998 there have been several studies published which report that infants placed to sleep in the supine position lag in motor skills, social skills, and cognitive ability development when compared to infants who sleep in the prone position. In a 1998 article entitled \"Effects of Sleep Position on Infant Motor Development\" by Davis, Moon, Sachs, and Ottolini, the authors state \"We found that sleep position significantly impacts early motor development.\" The prone (stomach) sleeping infants in this study slept an average of 225.2 hours (8.3%) more in their first 6 months of life than the supine (back) sleeping infants.\n\nIn the 1998 article entitled \"Does the Supine Sleeping Position Have Any Adverse Effects on the Child? II. Development in the First 18 Months\" by Dewey, Fleming, Golding, and the ALSPAC Study Team the objective of the study was \"To assess whether the recommendations that infants sleep supine could have adverse consequences on their motor and mental development.\" They used the Denver Developmental Screening Test (DDST) and studied infants at 6 and 18 months. According to the study, at 6 months of age, the infants who were placed to sleep in the prone position had statistically significant higher social skills scores, gross motor scores, and total development scores than those infants who were put to sleep in the supine position. In the 2005 article entitled \"Influence of supine sleep positioning on early motor milestone acquisition\" by Majnemer and Barr they used the Alberta Infant Motor Scale Scores (AIMS Scores) to analyze the impact of infant sleep position. They reported that \"Typically developing infants who were sleep-positioned in supine had delayed motor development by age 6 months, and this was significantly associated with limited exposure to awake prone positioning.\" But, the authors also note that awake prone (stomach) positioning is associated with prone (stomach) sleeping. No studies have been conducted which compare supine sleeping infants who have regular awake prone positioning to prone sleeping infants who have regular awake prone positioning.\n\nPlacing infants on their stomachs while they are awake has been recommended to offset the motor skills delays associated with the back sleep position but positioning the infant on their stomach while awake will not impact the amount of slow wave sleep since tummy time only occurs when an infant is awake.\n\n\n"}
{"id": "21671198", "url": "https://en.wikipedia.org/wiki?curid=21671198", "title": "Umeå Centre for Global Health Research", "text": "Umeå Centre for Global Health Research\n\nThe Umeå Centre for Global Health Research (CGH) is a Centre of Excellence within Umeå University in Northern Sweden. The Centre operates within the university’s Division of Epidemiology and Public Health Sciences, and is led by a steering group chaired by a principal investigator.\n\nCGH seeks to engage with a global agenda on health research and practice, addressing critical issues in global health and facilitating collaboration between and within the North and South. The Centre’s long-term research programme has been developed against a background of international epidemiological research, as well as public health work within Sweden.\n\nIt publishes the academic journal, \"Global Health Action\".\n\nResearch conducted within CGH is interdisciplinary in nature, with staff and students working together from backgrounds in demography, public health sciences, epidemiology, medicine, economics, statistics and sociology. Research activities are clustered around five areas of expertise:\n\n\nMany of CGH’s research projects are hosted by INDEPTH (the International Network for the Demographic Evaluation of Populations and Their Health), a network of 38 field sites in 19 countries across Africa, Asia and South America. This network provides a platform to share and exchange vital health data between some of the world’s poorest countries and enables comparative studies of global research questions related to disease development, urbanisation and migration as well as opportunities to develop methods and evaluate interventions.\n\nResearch training is essential to CGH. The Swedish Research School for Global Health is the result of a partnership between the Centre and the Karolinska Institute, Stockholm. The School seeks to achieve multidisciplinary collaboration in education, research and training by coordinating courses and seminars in global health, and improving the quality of research training.\n\nThe international Masters in Public Health, summer course and other short courses provided by the Umeå International School of Public Health also serve as entry points to research conducted by CGH.\n\n"}
{"id": "45616624", "url": "https://en.wikipedia.org/wiki?curid=45616624", "title": "Vineland Social Maturity Scale", "text": "Vineland Social Maturity Scale\n\nThe Vineland Social Maturity Scale is a psychometric assessment instrument designed to help in the assessment of social competence. It was developed by the American psychologist Edgar Arnold Doll.\n\nIt is a quality psychometric questionnaire and a good measure of adaptive behavior.\n\nThe test consists of 8 sub-scales measuring:\n\n\n"}
{"id": "39096606", "url": "https://en.wikipedia.org/wiki?curid=39096606", "title": "Women's health in India", "text": "Women's health in India\n\nWomen's health in India can be examined in terms of multiple indicators, which vary by geography, socioeconomic standing and culture. To adequately improve the health of women in India multiple dimensions of wellbeing must be analysed in relation to global health averages and also in comparison to men in India. Health is an important factor that contributes to human wellbeing and economic growth.\n\nCurrently, women in India face a multitude of health problems, which ultimately affect the aggregate economy’s output. Addressing the gender, class or ethnic disparities that exist in healthcare and improving the health outcomes can contribute to economic gain through the creation of quality human capital and increased levels of savings and investment.\n\nThe United Nations ranks India as a middle-income country. Findings from the World Economic Forum indicate that India is one of the worst countries in the world in terms of gender inequality. The 2011 United Nations Development Programme's Human Development Report ranked India 132 out of 187 in terms of gender inequality. The value of this multidimensional indicator, Gender Inequality Index (GII) is determined by numerous factors including maternal mortality rate, adolescent fertility rate, educational achievement and labour force participation rate. Gender inequality in India is exemplified by women’s lower likelihood of being literate, continuing their education and participating in the labour force.\n\nGender is one of the main social determinants of health—which include social, economic, and political factors—that play a major role in the health outcomes of women in India and access to healthcare in india. Therefore, the high level of gender inequality in India negatively impacts the health of women. Studies have indicated that boys are more likely to receive treatment from health care facilities compared to girls, when controlled for SES status.\n\nThe role that gender plays in health care access can be determined by examining resource allocation within the household and public sphere. Gender discrimination begins before birth; females are the most commonly aborted sex in India. If a female fetus is not aborted, the mother’s pregnancy can be a stressful experience, due to her family’s preference for a son. Once born, daughters are prone to being fed less than sons, especially when there are multiple girls already in the household. As women mature into adulthood, many of the barriers preventing them from achieving equitable levels of health stem from the low status of women and girls in Indian society, particularly in the rural and poverty-affected areas.\n\nThe low status of—and subsequent discrimination against—women in India can be attributed to many cultural norms. Societal forces of patriarchy, hierarchy and multigenerational families contribute to Indian gender roles. Men use greater privileges and superior rights to create an unequal society that leaves women with little to no power. This societal structure is exemplified with women’s low participation within India’s national parliament and the labour force.\n\nWomen are also seen as less valuable to a family due to marriage obligations. Although illegal, Indian cultural norms often force payment of a dowry to the husband’s family. The higher future financial burden of daughters creates a power structure that favours sons in household formation. Additionally, women are often perceived as being incapable of taking care of parents in old age, which creates even greater preference for sons over daughters.\n\nTaken together, women are oftentimes seen less valuable than men. With lower involvement in the public sphere—as exemplified by the labour and political participation rates—and the stigma of being less valuable within a family, women face a unique form of gender discrimination.\nGender inequalities, in turn, are directly related to poor health outcomes for women. Numerous studies have found that the rates of admission to hospitals vary dramatically with gender, with men visiting hospitals more frequently than women. Differential access to healthcare occurs because women typically are entitled to a lower share of household resources and thus utilise healthcare resources to a lesser degree than men.\n\nAmartya Sen has attributed access to fewer household resources to their weaker bargaining power within the household. Furthermore, it has also been found that Indian women frequently underreport illnesses. The underreporting of illness may be contributed to these cultural norms and gender expectations within the household. Gender also dramatically influences the use of antenatal care and utilisation of immunisations.\n\nA study by Choi in 2006 found that boys are more likely to receive immunisations than girls in rural areas. This finding has led researchers to believe that the sex of a child leads to different levels of health care being administered in rural areas. There is also a gender component associated with mobility. Indian women are more likely to have difficulty traveling in public spaces than men, resulting in greater difficulty to access services.\n\nAmartya Sen’s cooperative conflicts approach to gender biases frames women’s gender disadvantage through three different responses: breakdown wellbeing, perceived interest and perceived contribution responses. The breakdown well-being response—derived from the Nash equilibrium—describes breakdown positions between individuals during cooperative decisions. When the breakdown position of one individual is less than the other person, the solution to any conflict will ultimately result in less favourable conditions for the first individual. In terms of women’s health in India, the overall gender disadvantage facing women—represented by cultural and societal factors that favour men over women—negatively impacts their ability to make decisions with regards to seeking out healthcare.\n\nThe perceived interest response describes the outcome of a bargained decision when one individual attaches less value to his or her well-being. Any bargaining solution derived between the aforementioned individual and another individual will always result in a less favourable outcome for the person who attaches less value to their well-being. The health status of women in India relates to the perceived interest response because of the societal and cultural practices that create an environment where the self-worth of women is marginalised compared to men. Therefore, outcomes relating to healthcare decisions within households will favour the men, due to greater self-worth.\n\nThe perceived contribution response describes the more favourable position of an individual when the individual’s contribution is perceived as contributing more to a group than other individuals. The more favourable perception gives the individual a better outcome in a bargaining solution. In terms of women’s health in India, males’ perceived contribution to household productivity is higher than that of women, which ultimately affects the bargaining power that women have with regards to accessing healthcare.\n\nAt the turn of the 21st Century India’s health care system is strained in terms of the number of healthcare professionals including doctors and nurses. The health care system is also highly concentrated in urban areas. This results in many individuals in rural areas seeking care from unqualified providers with varying results. It has also been found that many individuals who claim to be physicians actually lack formal training. Nearly 25 percent of physicians classified as allopathic (mainstream medical) providers actually had no medical training; this phenomenon varies geographically.\n\nWomen are negatively affected by the geographic bias within implementation of the current healthcare system in India. Of all health workers in the country, nearly two thirds are men. This especially affects rural areas where it has been found that out of all doctors, only 6 percent are women. This translates into approximately 0.5 female allopathic physicians per 10,000 individuals in rural areas.\n\nA disparity in access to maternal care between rural and urban populations is one of the ramifications of a highly concentrated urban medical system. According to Government of India National Family Health Survey (NFHS II, 1998-1999) the maternal mortality in rural areas is approximately 132 percent the number of maternal mortality in urban areas.\n\nThe Indian government has taken steps to alleviate some of the current gender inequalities. In 1992, the government of India established the National Commission for Women. The Commission was meant to address many of the inequalities women face, specifically rape, family and guardianship. However, the slow pace of change in the judicial system and the aforementioned cultural norms have prevented the full adoption of policies meant to promote equality between men and women.\n\nIn 2005 India enacted the National Rural Health Mission (NRHM). Some of its primary goals were to reduce infant mortality and also the maternal mortality ratio. Additionally, the NHRM aimed to create universal access to public health services and also balance the gender ratio. However, a 2011 research study conducted by Nair and Panda found that although India was able to improve some measures of maternal health since the enactment of the NHRM in 2005, the country was still far behind most emerging economies.\n\nThe high incidence of breast lumps among Adivasi women of Adilabad in Telangana has created apprehension of more serious health impacts for this remote population.“Leave alone breast cancer or any other type of carcinoma, even routine mammarian infections were unknown among indigenous people belonging to the Gond, Pardhan, Kolam and Thotti,” points out Dr. Thodsam Chandu, the District Immunisation Officer, himself a Gond.\n\nNutrition plays a major role in and individual’s overall health; psychological and physical health status is often dramatically impacted by the presence of malnutrition. India currently has one of the highest rates of malnourished women among developing countries. A study in 2000 found that nearly 70 percent of non-pregnant women and 75 percent of pregnant women were anemic in terms of iron-deficiency. One of the main drivers of malnutrition is gender specific selection of the distribution of food resources.\n\nA 2012 study by Tarozzi have found the nutritional intake of early adolescents to be approximately equal. However, the rate of malnutrition increases for women as they enter adulthood. Furthermore, Jose et al. found that malnutrition increased for ever-married women compared to non-married women.\n\nMaternal malnutrition has been associated with an increased risk of maternal mortality and also child birth defects. Addressing the problem of malnutrition would lead to beneficial outcomes for women and children.\n\nIndia is facing a growing cancer epidemic, with a large increase in the number of women with breast cancer. By the year 2020 nearly 70 percent of the world’s cancer cases will come from developing countries, with a fifth of those cases coming from India.\n\nMuch of the sudden increase in breast cancer cases is attributed to the rise in Westernisation of the country. This includes, but is not limited to, westernised diet, greater urban concentrations of women, and later child bearing. Additionally, problems with India’s health care infrastructure prevent adequate screenings and access for women, ultimately leading to lower health outcomes compared to more developed countries. As of 2012, India has a shortage of trained oncologists and cancer centres, further straining the health care system.\n\nThe lack of maternal health contributes to future economic disparities for mothers and their children. Poor maternal health often affects a child’s health in adverse ways and also decreases a woman’s ability to participate in economic activities. Therefore, national health programmes such as the National Rural Health Mission (NRHM) and the Family Welfare Programme have been created to address the maternal health care needs of women across India.\n\nAlthough India has witnessed dramatic growth over the last two decades, maternal mortality remains stubbornly high in comparison to many developing nations As a nation, India contributed nearly 20 percent of all maternal deaths worldwide between 1992 and 2006. The primary reasons for the high levels of maternal mortality are directly related to socioeconomic conditions and cultural constraints limiting access to care.\n\nHowever, maternal mortality is not identical across all of India or even a particular state; urban areas often have lower overall maternal mortality due to the availability of adequate medical resources. For example, states with higher literacy and growth rates tend to have greater maternal health and also lower infant mortality.\n\nAs of July 2005, women represent approximately 40 percent of the HIV/AIDS cases in India. The number of infections is rising in many locations in India; the rise can be attributed to cultural norms, lack of education, and lack of access to contraceptives such as condoms. The government public health system does not provide adequate measures such as free HIV testing, only further worsening the problem.\n\nCultural aspects also increase the prevalence of HIV infection. The insistence of a woman for a man to use a condom could imply promiscuity on her part, and thus may hamper the usage of protective barriers during sex. Furthermore, one of the primary methods of contraception among women has historically been sterilisation, which does not protect against the transmission of HIV.\n\nThe current mortality rate of HIV/AIDS is higher for women than it is for men. As with other forms of women’s health in India the reason for the disparity is multidimensional. Due to higher rates of illiteracy and economic dependence on men, women are less likely to be taken to a hospital or receive medical care for health needs in comparison to men. This creates a greater risk for women to suffer from complications associated with HIV. There is also evidence to suggest that the presence of HIV/AIDS infection in a woman could result in lower or no marriage prospects, which creates greater stigma for women suffering from HIV/AIDS.\n\nIndia legalised abortion through legislation in the early 1970s. However, access remains limited to cities. Less than 20 percent of health care centres are able to provide the necessary services for an abortion. The current lack of access is attributed to a shortage of physicians and lack of equipment to perform the procedure.\n\nThe most common foetus that is aborted in India is a female one. Numerous factors contribute to the abortion of female foetuses. For example, women who are highly educated and had a first-born female child are the most likely to abort a female. The act of sex-selective abortion has contributed to a skewed male to female ratio. As of the 2011 census, the sex ratio among children aged 0–6 continued a long trend towards more males.\n\nThe preference for sons over daughters in India is rooted in social, economic and religious reasons. Women are often believed to be of a lower value in society due to their non-breadwinner status. Financial support, old age security, property inheritance, dowry and beliefs surrounding religious duties all contribute to the preference of sons over daughters. One of the main reasons behind the preference of sons is the potential burden of having to find grooms for daughters. Families of women in India often have to pay a dowry and all expenses related to marriage in order to marry off a daughter, which increases the cost associated with having a daughter.\n\nCardiovascular disease is a major contributor to female mortality in India. Indians account for 60% of the world's heart disease burden, despite accounting for less than 20% of the world's population. Indian women have a particular high mortality from cardiac disease and NGOs such as the Indian Heart Association have been raising awareness about this issue. Women have higher mortality rates relating to cardiovascular disease than men in India because of differential access to health care between the sexes. One reason for the differing rates of access stems from social and cultural norms that prevent women from accessing appropriate care. For example, it was found that among patients with congenital heart disease, women were less likely to be operated on than men because families felt that the scarring from surgery would make the women less marriageable.\n\nFurthermore, it was found that families failed to seek medical treatment for their daughters because of the stigma associated with negative medical histories. A study conducted by Pednekar et al. in 2011 found that out of 100 boys and girls with congenital heart disease, 70 boys would have an operation while only 22 girls will receive similar treatment.\n\nThe primary driver of this difference is due to cultural standards that give women little leverage in the selection of their partner. Elder family members must find suitable husbands for young females in the households. If women are known to have adverse previous medical histories, their ability to find a partner is significantly reduced. This difference leads to diverging health outcomes for men and women.\n\nMental health consists of a broad scope of measurements of mental well being including depression, stress and measurements of self-worth. Numerous factors affect the prevalence of mental health disorders among women in India, including older age, low educational attainment, fewer children in the home, lack of paid employment and excessive spousal alcohol use. There is also evidence to suggest that disadvantages associated with gender increase the risk for mental health disorders. Women who find it acceptable for men to use violence against female partners may view themselves as less valuable than men. In turn, this may lead women to seek out fewer avenues of healthcare inhibiting their ability to cope with various mental disorders.\n\nOne of the most common disorders that disproportionately affect women in low-income countries is depression. Indian women suffer from depression at higher rates than Indian men. Indian women who are faced with greater degrees of poverty and gender disadvantage show a higher rate of depression. The difficulties associated with interpersonal relationships—most often marital relationships—and economic disparities have been cited as the main social drivers of depression.\n\nIt was found that Indian women typically describe the somatic symptoms rather than the emotional and psychological stressors that trigger the symptoms of depression. This often makes it difficult to accurately assess depression among women in India in light of no admonition of depression. Gender plays a major role in postnatal depression among Indian women. Mothers are often blamed for the birth of a female child. Furthermore, women who already have a female child often face additional pressures to have male children that add to their overall stress level.\n\nWomen in India have a lower onset of schizophrenia than men. However, women and men differ in the associated stigmas they must face. While men tend to suffer from occupational functioning, while women suffer in their marital functioning. The time of onset also plays a role in the stigmatisation of schizophrenia. Women tend to be diagnosed with schizophrenia later in life, oftentimes following the birth of their children. The children are often removed from the care of the ill mother, which may cause further distress.\n\nIndian women have higher rates of suicide than women in most developed countries. Women in India also have a higher rate of suicide compared to men. The most common reasons cited for women's suicide are directly related to depression, anxiety, gender disadvantage and anguish related to domestic violence.\n\nMany of the high rates of suicide found across India and much of south Asia have been correlated with gender disadvantage. Gender disadvantage is often expressed through domestic violence towards women. The suicide rate is particularly high among female sex workers in India, who face numerous forms of discrimination for their gender and line of work.\n\nDomestic violence is a major problem in India. Domestic violence—acts of physical, psychological, and sexual violence against women—is found across the world and is currently viewed as a hidden epidemic by the World Health Organization. The effects of domestic violence go beyond the victim; generational and economic effects influence entire societies. Economies of countries where domestic violence is prevalent tend to have lower female labour participation rate, in addition to higher medical expenses and higher rates of disability.\n\nThe prevalence of domestic violence in India is associated with the cultural norms of patriarchy, hierarchy, and multigenerational families. Patriarchal domination occurs when males use superior rights, privileges and power to create a social order that gives women and men differential gender roles. The resultant power structure leaves women as powerless targets of domestic violence. Men use domestic violence as a way of controlling behaviour.\nIn a response to the 2005-2006 India National Family Health Survey III, 31 percent of all women reported having been the victims of physical violence in the 12 months preceding the survey. However, the actual number of victims may be much higher. Women who are victimised by domestic violence may underreport or fail to report instances. This may be due to a sense of shame or embarrassment stemming from cultural norms associated with women being subservient to their husbands. Furthermore, underreporting by women may occur in order to protect family honour.\nA 2012 study conducted by Kimuna, using data from the 2005-2006 India National Family Health Survey III, found that domestic violence rates vary across numerous sociological, geographical and economic measures. The study found that the poorest women faired worst among middle and high-income women. Researchers believe that the reason for higher rates of domestic violence come from greater familial pressures resulting from poverty. Additionally the study found that women who were part of the labour force faced greater domestic violence. According to the researchers, working women may be upsetting the patriarchal power system within Indian households.\n\nMen may feel threatened by the earning potential and independence of women and react violently to shift the gender power structure back in their favour. One of the largest factors associated with domestic violence against women was the prevalence of alcohol use by men within the households. A 2005 study conducted by Pradeep Panda and Bina Agarwal found that the incidence of domestic violence against women dropped dramatically with women's ownership of immovable property, which includes land and housing.\n\n\n"}
{"id": "20517149", "url": "https://en.wikipedia.org/wiki?curid=20517149", "title": "Women's medicine in antiquity", "text": "Women's medicine in antiquity\n\nChildbirth and obstetrics in Classical Antiquity (here meaning the ancient Greco-Roman world) were studied by the physicians of ancient Greece and Rome. Their ideas and practices during this time endured in Western medicine for centuries and many themes are seen in modern women's health. Gynecology and obstetrics were originally studied and taught mainly by midwives in the ancient world, but eventually scholarly physicians of both sexes became involved as well. Obstetrics is traditionally defined as the surgical specialty dealing with the care of a woman and her offspring during pregnancy, childbirth and the puerperium (recovery). Gynecology involves the medical practices dealing with the health of women's reproductive organs (vagina, uterus, ovaries) and their breasts.\n\nMidwifery and obstetrics are distinctly different but overlap in medical practice that focuses on pregnancy and labor. Midwifery emphasizes the normality of pregnancy along with the reproductive process. Classical Antiquity saw the beginning of attempts to classify various areas of medical research, and the terms gynecology and obstetrics came into use. The \"Hippocratic Corpus,\" a large collection of treatises attributed to Hippocrates, features a number of gynecological treatises, which date to the classical period.\n\nDuring the era of Classical Antiquity, women practiced as doctors, but they were by far in the minority and typically confined to only gynecology and obstetrics. Aristotle was an important influence on later medical writers in Greece and eventually Europe. Similar to the writers of the \"Hippocratic Corpus\", Aristotle concluded that women's physiology was fundamentally different from that of men primarily because women were physically weaker, and therefore more prone to symptoms caused in some way by weakness, such as the theory of humourism. This belief claimed that both men and women had several \"humours\" regulating their physical health, and that women had a \"cooler\" humour.\n\nThe \"Hippocratic Corpus\" writers indicated that men were more rational than women, and that women's physiology made them susceptible to problems that would cause symptoms of irrationality. Continuing with this assumption that men were more rational, men dominated the profession of physicians, an occupation requiring rational research, and for which they believed women were not suited.\n\nThis did not stop women from becoming physicians, however; Agnodice, who in 300 BCE left Athens and went to Alexandria to study medicine and midwifery in Hellenistic Alexandria under Hierophilus. She returned to Athens and became a popular gynecologist among women; it was said that she disguised herself as a man in order to practice medicine on men. Agnodice became so popular among her female patients that her male colleagues charged her with seducing her patients. In court, she revealed her sex and was exonerated. Philista was a popular professor of medicine who delivered lectures from behind a curtain, to prevent her beauty from distracting her students. In ancient Greece, there was also an opportunity for midwives to receive some further medical training, to become a doctor-midwife, called in the Hellenistic, Roman and Byzantine eras as \"iatromea\" (ιατρομαία). Merit-Ptah is the first woman named in the history of medicine and perhaps that of medicine; she is immortalized as the \"chief physician\".\n\nWomen doctors may have offered specializations beyond gynecology and obstetrics, but there is not enough information to know how frequently. As obstetricians and gynecologists, they appear to have been numerous. The Law Code of Justinian presumed women doctors to be primarily obstetricians. The first medical text known to be written by a woman is by Metrodora, \"Concerning the Feminine Diseases of the Womb\", a work in 63 chapters that was part of a series of at least two works that she authored. The earliest copy dates from between the 2nd century and the 4th century CE.\n\nIt is important to remember that during Classical Antiquity, anyone could be trained as a doctor at one of the many medical schools/hospitals, the Asclepeieon. Training involved mainly practical applications as well as forming an apprenticeship to other doctors. During the Hellenistic era, the Library of Alexandria also served as a medical school, where research and training would take place on the body of the diseased. It also appears that the children, male or female, of famous doctors, would also follow the medical profession, continuing the family tradition. For example, Pantheia, who was the wife of a physician, became one herself, a pattern also seen in the careers of Aurelia Alexandria Zosime and Auguste. Auguste received recognition as a chief doctor of her city, a title her husband also received. Metilia Donata was prominent enough to commission a large public building in Lyon. Anthiochis of Tlos, a doctor who was the daughter of a prominent physician, Diodotus, was recognized by the council of Tlos for her work as a doctor and had a statue of herself erected. She was also a widely discussed expert cited by Galen and others. Aspasia is quoted extensively by Aetius on gynecology.\n\nDuring antiquity, there was no profession equal to that of our modern day nurse. No ancient medical sources discuss any sort of trained nursing personnel assisting doctors. However, many texts mention the use of slaves or members of a doctor's family as assistants. The closest similarity to that of a nurse during antiquity was a midwife. Midwifery flourished in ancient civilizations, including Egypt, Byzantium, Mesopotamia, and the Mediterranean empires of Greece and Rome. Herophilus wrote a manual for midwives, an advance for midwifery's status. This was followed by the work of the Greek Soranus of Ephesus, who was widely translated into Latin, and Galen. This Greco-Roman approach differs greatly from other ancient civilizations, where women's role as medical specialists concerning gynecology and obstetrics was apparently unquestioned. Medical schools attached to temples in ancient Egypt were numerous, including well-known medical schools for women at Heliopolis and Sais, where women are also believed to have been the professors.\n\nSoranus of Ephesus states that for a woman to be an eligible midwife she must be Soranus of Ephesus (98-138 BC) was an important gynecologist during antiquity and is credited with four books describing the female anatomy. He also discussed methods to deal with difficult births, such as using forceps. This detailed instruction on midwives served as a sort of textbook and makes evident the well-respected role that midwives filled in society.\n\nWomen practiced birth control in antiquity mainly through their knowledge of plants and herbs. Their knowledge was transmitted by herders who observed sterility of their livestock when exposed to certain plants. Knowledge of birth control was also transmitted by word of mouth, mainly originating from knowledgeable midwives. Midwives knew how to identify necessary plants, how to administer them, and most importantly, \"when\" to administer them in relation to the last menstruation or coitus.\n\nA very popular plant used for birth control by the Greeks was Silphium. It is a giant fennel-like herb which was filled with a pungent sap and offered a rich flavor. The plant was so widely used that it appeared on a Cyrenian coin as a woman touched the plant with one hand and pointed to her genitals with the other. The demand for the plant was so great that by the fourth century, it had gone extinct. It is believed that the heart shape originated from the seed of this plant as they are the same shape and the plant was associated with love, romance, and sexuality.\n\nAlthough Silphium was most popular, there were many other plants and herbs used. The seeds of Queen Anne's Lace (a wild carrot) were cut up or chewed to release ingredients that inhibited fetal and ovarian growth. These seeds are still commonly used in India. Another plant used was pennyroyal, an abortifacient. A medical document dating back to 1500 BC in Egypt includes a list of substances used as birth control. One substance involved making a paste from acacia gum, dates, fiber, honey, and other unidentified plants to create a sort of spermicide.\n\nThere were many theories used to determine whether a woman was pregnant during antiquity. A popular method involved examining the vessels of her breasts. A second method involved sitting a woman on a beer and date mash covered floor and using a proportionality equation according to the number of times she vomits. Another method included inserting an onion into a woman's vagina and determining whether or not it could be smelled from her breath. Although there is little evidence as to whether or not any of these methods were confirmed medical procedures or if they were just folklore.\n\nAbortions were uncommon, but in their few occurrences, were performed by the mother herself. The results for both mother and child were often fatal as most abortions were performed by plunging a dagger into the woman's vagina. Because of this procedure, it was most common to carry a baby full term before performing the abortion. According to the Hippocratic Corpus, there were oral alternatives used to induce abortion such as chaste, tree, copper, and Ferula species. Plato explored the control that midwives perhaps had during this process: \n\nHospitals did not exist during antiquity so delivery took place in the home of the expectant mother with a midwife and other assistants to the midwife. Religion played a major role during labor and delivery. Women called upon Artemis, a goddess with the ability to bring new life into the world as well as the ability to take it away. Though she remained a virgin herself, it was said that she witnessed the pain of her mother during the birth of her brother, Apollo, and immediately assumed the position of midwife. If a woman died during childbirth, her clothes were taken to the temple of Artemis due to the fact the woman's death was attributed to her. If the birth was successful, the mother would make an offering of thanks by sacrificing some of her clothes to the goddess as well.\n\nHerbs and other plants were used heavily in the delivery process, a practice also linked to religious belief. For example, a drink sprinkled with powdered sow’s dung was given to relieve labor pain, and fumigation with the fat from a hyena was thought to produce immediate delivery. Most of these practices had little to no medical efficacy, but they did probably provide some placebo effect. Despite the attempt to use science in advancing medical knowledge, the experimentation and teachings of the \"Hippocratic Corpus\" were not necessarily more effective than the traditional customs of midwifery. For example, the Hippocratic writers believed that the womb could move out of place and cause health problems, and the prescribed treatment was to coax the displaced womb back into place using sweet-smelling herbs.\n\nSoranus described three main stages of pregnancy: conception, which regarded keeping the male seed within the womb; pica, which occurred 40 days into pregnancy and included symptoms of nausea and cravings for extraordinary foods. During this phase women were also instructed to exercise and sleep more to build up strength as preparation for the labor process. The final stage of pregnancy was described as the labor and the process of delivery. In preparation for labor, the woman was advised to bathe in wine and sweet-water baths to calm her mind before delivery. Her belly was then rubbed with oils to decrease the appearance of stretch marks, and her genitals were anointed with herbs and injected with softeners such as goose fat.\n\nThe role of the midwife was very important during the process of childbirth and Soranus described her role in great detail. For example, the midwife was to have certain tools to ensure a safe delivery, including: clean olive oil, sea sponges, pieces of wool bandages to cradle the infant, a pillow, strong smelling herbs in case of fainting, and a birthing stool. A birthing stool is a chair from which the seat has been removed.\n\nThe midwife would ready her supplies as labor began. During the labor process, the mother would lie on her back on a hard, low bed with support under her hips. Her thighs were parted with her feet drawn up. Gentle massage was implemented to ease labor pains as cloths soaked in warm olive oil were laid over her stomach and genital area. Against the woman's sides were placed hot compresses in the form of warm oil-filled bladders.\n\nDuring the actual birth, the mother would be moved to the birthing stool, where she was seated or would squat on two large bricks with a midwife in front of her and female aides standing at her sides. In a normal headfirst delivery, the cervical opening was stretched slightly, and the rest of the body was pulled out. Soranus instructed the midwife to wrap her hands in pieces of cloth or thin papyrus so that the slippery newborn did not slide out of her grasp.\n\nThe word “caesarian” possibly derives from the ancient Roman ruler Julius Caesar, because it was believed that Caesar was delivered through this procedure. However, this is probably based more on tradition and myth than historical accuracies. Another possibility for the etymology of the word “caesarian” is the Latin word \"caedere\", meaning “to cut”. This practice is probably much older than Julius Caesar, but \"C-sections\", as performed by the Romans, were done to rescue the baby from a dying or already dead mother, and were performed post-mortem.\nEvidence suggests that Jews in ancient Rome successfully practiced C-sections on living mothers who were not in danger of dying. Evidence of these procedures is found in several collections of ancient Roman rabbis, the most famous of which is called the Mishnah. Greeks and Egyptians did not perform C-sections, either post-mortem or on living mothers. However, Greeks would have had at least some knowledge of the Caesarian operation and the procedure involved. The Greek god Aesclepius was fabled to have been extracted from his mother’s womb through this procedure.\nOther than the evidence of Jews practicing C-sections in antiquity (very little in ancient Rome, even less in ancient Greece), not much more evidence exists regarding Caesarian-operation birth. One reason could have been that C-sections were not performed very often because of medical complications or superstitions surrounding C-sections. In early Christian Rome, C-sections were almost non-existent. Loss of skill is a possibility for the lack of C-sections. Infant mortality rates were high in antiquity, so C-sections certainly could have been useful. However, early Christian doctors could have disregarded C-sections as a socially acceptable operation because of religious beliefs. Disease, a perceived need for secrecy, and social discouragement could have also been factors that lead to the decline in C-sections among early Christians in Rome. Almost no evidence exists for C-sections in the Christian world until the 10th century.\n\nThe lack of education for women and the social norm that women remained in the private sphere of life (as opposed to public) is theorized to also have contributed to a shortage of C-sections. Midwives were the primary persons involved in the childbirth process. They did not record their medical practices in writing like Soranus or Galen. Thus, C-sections could have potentially occurred on a fairly regular basis, and accounts were simply not recorded.\n\nMortality was quite high in antiquity due to a few factors: a lack of sanitation and hygienic awareness, no understanding of micro-organisms, and a dearth of effective drugs. In the context of childbirth, however, maternal and infant mortality were exponentially raised compared to modern standards. This resulted from the toll childbirth took on women, and the increased risk of infection following labor.\n\nMaternal\n\nMaternal mortality figures are available only through comparison. Maternal mortality is thought to be comparable with figures for similar, but much later, societies with more surviving records, such as eighteenth-century rural England, where maternal mortality averaged 25 per 1000 births.\n\nInfant\n\nThe question of infant mortality in antiquity is complicated by infanticide and exposure, neither of which reflect on medical ability during the period. The former does this through intentional death of the child, and the latter through abandonment, and possible death. These reflect instead on social conditions and norms. While valuable, this is not the information sought, and scholars having painstakingly attempted to eliminate the 'noise' from their inquiries.\n\nMuch like maternal mortality, it is difficult to construct actual figures of the infant mortality rate in antiquity, but comparisons have been made between ancient societies and modern non-industrialized societies. The figures suggest that they are comparable with those of modern industrialized societies to put them in perspective. While infant mortality is less than 10 per 1000 in modern industrialized societies, non-industrialized societies display rates from 50 to 200+ per 1000. Scholarship using model life tables and assuming life expectancy at birth of 25 years produces the figure of 300 per 1000 for Roman society.\n\n"}
{"id": "53985129", "url": "https://en.wikipedia.org/wiki?curid=53985129", "title": "World Conference on Women, 1975", "text": "World Conference on Women, 1975\n\nWorld Conference on Women, 1975 was held between 19 June and 2 July 1975 in Mexico City, Mexico. It was the first international conference held by the United Nations to focus solely on women's issues and marked a turning point in policy directives. After this meeting, women were viewed as part of the process to develop and implement policy, rather than recipients of assistance. The conference was one of the events established for International Women's Year and led to the creation of both the United Nations Decade for Women and follow-up conferences to evaluate the progress that had been made in eliminating discrimination against women and their equality. Two documents were adopted from the conference proceedings, the World Plan of Action which had specific targets for nations to implement for women's improvement and the Declaration of Mexico on the Equality of Women and Their Contribution to Development and Peace, which discussed how nations foreign policy actions impacted women. It also led to the establishment of the International Research and Training Institute for the Advancement of Women to track improvements and continuing issues and the United Nations Development Fund for Women to provide funding for developmental programs. The conference marked the first time that the parallel Tribune meeting was successful in submitting input to the official meeting and became a catalyst for women's groups to form throughout the world.\n\nThe World Conference on Women occurred in the 1970s amid the Cold War when geopolitical conflict was controlled based on the interests of the United States or the USSR in various regions throughout the world, polarizing the world into two camps and their respective fields of influence. At a time when the United States had just withdrawn from Vietnam, forty-eight separate conflicts would rock Asia in such places as Afghanistan, Bangladesh, Cambodia, Indonesia, Laos, Myanmar, Pakistan, Sri Lanka. African wars during the end of decolonization in the 1970s turned toward long-lasting civil wars in Angola, Ethiopia-Somali, Mozambique and other African nations, with the superpowers manipulating the conflicts in the background with troops and arms. Decolonization of the Caribbean saw twelve states gain their independence between 1962 and 1983, but simultaneously remain marginalized by pressures from world powers which continued to manipulate local concerns. Two significant Middle East conflicts occurred in 1967 and 1973 with the US backing its Arab allies and Israel, while the USSR backed Arab socialist regimes. In Central and South America various coups d'états in Argentina, Bolivia, Chile, Ecuador, El Salvador and dictatorships led to instability and decimation of indigenous populations.\n\nResponses to the conflict often had additional repercussions, such as the 1973 Oil embargo, a response to the Arab-Israeli conflict, which caused the price of oil to rise on the world market from three dollars per barrel to twelve dollars per barrel. The embargo was followed by the 1979 energy crisis, sparked by concerns over lowered production caused by the Iranian Revolution and how continued instability might impact oil availability. That in turn led to a build up of reserves, during which time the price of oil doubled and forced the world to look at alternative sources of oil. Adding to the conflicts of the time were racial inequalities, ranging from Apartheid and Zionism to Paternalism.\n\nWork had long been ongoing by the United Nations Commission on the Status of Women (CSW) to adopt a declaration to eliminate discrimination against women. By 1965, it was believed that enough support had been garnered to obtain passage of a declaration to secure women's human rights. Collating responses covering education, employment, inheritance, penal reform, and other issues, from government actors, NGO representatives and UN staff, CSW delegates began drafting a declaration. On 7 November 1967, the Declaration on the Elimination of Discrimination Against Women (DEDAW), was passed by the General Assembly. In 1972, the United States Congress passed Title IX, eliminating discrimination in education for any institution receiving federal funding. That same year, CSW proposed that DEDAW become a legally binding Convention. To that end, the United Nations proclaimed 1975 as International Women's Year and the CSW set about the tasks to prepare the \"machinery\" necessary to secure passage. Helvi Sipilä, was selected as the Assistant Secretary General for Social Development and Humanitarian affairs and placed in charge of organizing events. Added significance of the date was that the conference would take place on the thirtieth anniversary of the creation of the United Nations.\n\nWhen the United Nations designated 1975 as International Women's Year, no conference was planned as part of the celebrations because delegates on opposing sides of the Cold War could not agree to authorize one. Initially proposed by the Romanian delegate of the UN Commission on the Status of Women, communist women joined to filibuster the project, instead proposing a women's congress in East Berlin, which had nothing to do with the United Nations. As a counter, the US proposed a gender neutral conference to be held in Bogotá, Colombia to promote equality for men and women, because the presence of men would legitimize the conference. When Mexico City agreed to host the conference, Princess Ashraf of Iran began collecting funds, and each side mobilized to shape the agenda. The US position advocated for political rights and elimination of discrimination through legal remedies. The Soviet camp advocated for women to be empowered so that they could use their natural abilities as nurturers to stem violence and inequality which created poverty and injustice.\n\nThough , the Mexican Attorney General, was appointed head of the conference, the majority, 113 of the 133 delegation leaders were women. The conference was a governmental meeting, not a meeting of women, and as such the high percentage of women marked the first time that 73% of the delegates for a UN conference were women, even if the 27% participation by men was higher than the number of women typical at such conferences. The nature of the conference also dictated that all delegates, as representatives of their governments would follow the ideological agendas of their governments, rather than act upon any private convictions. Among the prominent delegates, which many feminists felt were chosen for ideological reasons or ties to prominent male politicians, were Sirimavo Bandaranaike, Prime Minister of Sri Lanka; Anna Louise Beer, chair of the Norwegian National Women's Council; Vilma Espín de Castro, sister-in-law to the Cuban president; Francoise Giroud, French Minister of Women's Affairs; Imelda Marcos, First Lady of the Philippines; Ashraf Pahlavi, twin sister of Iran's shah; Leah Rabin, First Lady of Israel; Elizabeth Anne Reid of Australia; Silvana Maria Rota, Argentine congresswoman; Jehan Sadat, First Lady of Egypt; Soviet Cosmonaut Valentina Tereshkova, the first woman in space; Vida Tomšič, Yugoslavian representative of the Non-Aligned Movement; Khunying Suparb Visessurakarn, vice president of Thailand's National Council on Social Welfare; but not First Lady Betty Ford, as the US administration feared linking the threat of anti-capitalist sentiment with women's issues.\n\nAfter opening remarks by Kurt Waldheim, President Luis Echeverría of Mexico spoke, stating that women, in their role as mothers, were allies of the oppressed and that \"no woman was more discriminated against or exploited than the woman without bread, school or medicines for her children\". Setting the stage, Echeverría's comments mirrored the position that the nurturing nature of women could help to solve the worlds' crises, if marginalization were eliminated. It was agreed that the themes of equality, development and peace were the primary focus of action, as they were international in nature and required simultaneous action by global components. In general discussion it was recognized that to achieve equality and attain the fundamental human rights and freedoms expressed in the Universal Declaration of Human Rights, the inferior status of women had to be addressed to bring about parity in civic, economic, legal, social and political spheres. Recognizing that legal changes alone could not ensure equality, the general discussion agreed that developmental programs made available to both urban and rural women must include women in all decision-making levels, from planning to implementation and analysis, and must provide adequate training. The discussion also recognized the need to monitor advances in women's progress as well a societal change in attitudes toward women via national institutions. In efforts toward peace, the discussion recognized women's contributions to developing friendly international relationships and pressing for disarmament, particularly nuclear disarmament. Increased participation by women in international and regional problem-solving summits, was discussed as a way to maintain peace and security. \nThe first committee, under the chair Jeanne Martin Cissé of Guinea, with vice-chairs, Gladys Freire de Addiego of Uruguay, of Czechoslovakia and Nilima Ibrahim of Bangladesh and Rapporteur John Bruce Campbell of Australia discussed the World Plan of Action. The plan, which had previously been drafted by a diverse range of UN committees, established a broad range of targets, considering that national developments were in varying stages, to be accomplished over the next decade (1975–1985). In addition to adopting the overall plan as revised by subcommittees, the first committee evaluating six draft resolutions, which dealt with research and training, international cooperation, women's status, the role of the UN in implementation of the Plan, women's health, and participation of women in future meetings of the UN. All were accepted with either no or minimal modification. The \"Declaration of Mexico on the Equality of Women and Their Contribution to Development and Peace\", was also reviewed by the committee and the draft accepted with minimal or no modification. Some radical feminists, uninterested in reviewing a plan already prepared by UN committees tried to take over a US embassy meeting and yet another group walked out of the conference when Leah Rabin spoke.\n\nThe second committee, under the chair Shapour Rassekh of Iran, with vice-chairs, Edmonde Dever of Belgium, Annie Jiagge of Ghana and Anna Papp of Hungary and Rapporteur of Jamaica evaluated current trends and obstacles in the roles of men and women to achieving parity in rights, opportunities, and responsibilities; and how women could be integrated into developmental programs. They discussed passage of the Convention on the Elimination of All Forms of Discrimination Against Women (CEDAW) as a critical step in the process. Recognizing the wide gap between the \"de jure\" and \"de facto\" status of women, the committee noted that to achieve equality changes would need to be made in a broad spectrum of areas including: education, employment opportunity, family, integration into existent systems, and the law. Fifty-eight draft resolutions had been submitted for the committee to review, which covered these areas and they divided them into working groups to reduce duplications. Winnowing down the drafts to twenty-one items which were accepted with modifications, the major areas concerned communications media, education and training, employment, exploitation of women and girls, family health, family planning, family security (including the elderly and disabled), financial assistance, integration to development, political and social participation, and systems to gather, collate and evaluate data on women's status. The committee evaluated seven other drafts having to do with expanding the role of women in peace initiatives and nation rebuilding, and adopted each of them with little or no modification.\n\nThe International Women's Year Tribune was a parallel conference scheduled by women to be held simultaneously with the official conference. The format allowed for non-governmental organizations (NGO) to meet and discuss the issues tabled at the official conference, but gave them no authority to take any action. There were around 6,000 delegates who attended the Tribune, organized by Mildred Persinger the UN's YWCA observer, including such women as Domitila Barrios de Chungara, head of the Siglo XX Miners' Union Housewives Committee of Bolivia; Nancy Cárdenas, Mexican lesbian activist; Jacqui Ceballos, former president of the New York chapter of National Organization for Women (NOW); Thelma Daily of the Coalition of Labor Union Women (CLUW); Carole DeSaram, president of the New York NOW Betty Friedan, founder of NOW; Ronnie Feit of the National Women's Political Caucus; Dorothy Haene of the United Auto Workers; Dorothy Height of the National Council of Negro Women; Pat Keppler of the Harvard Divinity School; Esperanza Martí, director of \"Fem\" magazine and a Mexican feminist; Jan Peterson of CLUW; and Margo St. James, founder of COYOTE. The founders of Women's World Banking met as part of the tribunal, including Michaela Walsh, a program associate at the Rockefeller Brothers Fund, who met Ela R. Bhatt, founder of Self-Employed Women's Association of India, and Esther Ocloo, a Ghanian businesswoman. \n\nThe Tribune was held on the opposite side of Mexico City, creating a physical as well as philosophical separation of the two groups. The difference in format stemmed from position that the delegates participated in discussions on official policy; whereas, the NGO tribunal women dealt with means and methods of program implementation to improve women's educational opportunities, equality, economic position and collaboration. The Tribune hosted thirty-six planned meetings and nearly two hundred spontaneously organized additional sessions covering a wide variety of topics from development, education, health, human rights, peace and work to birth control, gender violence, lesbianism, prostitution, racism and sexism. The dynamics of this conference were different from the official UN session because the participants were not governmental representatives, and delegates were free to discuss items openly avoided by the officials. But the free discussion also made apparent the divide separating the women. Westernized women focused on individual freedom, Socialist women focused on the state's obligation to enforce the collective rights of all members of a society, and those from countries not aligned to either of these views pointed to the need for development, economic empowerment, food security and correction of the structural problems in systems.\n\nWomen from developing nations pointed out issues such as how aid from industrialized nations was often harmful, as it displaced women practicing subsistence agriculture with technology. Without adequate training to utilize technology, women who had been the prevalent food producers no longer had means to support their families. If they were utilized by new industry, women tended to be exploited as a cheap labor source, as laws for equal pay were non-existent in many developing economies. In light of these survival issues, the demands of others asking for sexual and reproductive health and rights seemed frivolous and indicative of self-indulgence. Socialist women felt that equality could only come with a transformation of geopolitical relationships, which recognized the contributions of all members of society and denounced exploitation and discrimination on any basis. Amid the wide range of views, there were performances aimed at capturing media attention, with some attendees wearing national costumes and others wearing business attire, as well as rhetoric pitting ideologies against each other to gain a spotlight. At one point, frustrated that they could not be part of the official dialogue, a group of radical feminists planned to stage a march through the streets of Mexico City. Instead, a group of fifteen delegates was chosen who presented amendments to Helvi Sipilä requesting that they be given to the official committees. It was the first time that a Tribune had ever been successful in presenting their input to the officials. The amendments the Tribune proposed included establishment of a UN office to monitor success of the Plan, issue annual progress reports, and investigate human rights abuse against women. They also asked for the UN to improve their internal hiring policies so that more women were not only hired, but promoted to management and executive positions.\n\nThe conference adopted the official World Plan of Action, as well as the Declaration of Mexico on the Equality of Women and Their Contribution to Development and Peace, which was an indictment of the foreign policies that pushed military or corporatist intervention to coerce developing nations from determining their own path. The Declaration passed with a vote of eighty-nine in favor, three against, and eighteen nations abstaining. The Plan established minimum targets to be attained within the next five years to secure for women the equal access of the mechanisms to attaining equality and eliminating discrimination; to full participation in development and their integration in extant systems; and to their contributions toward world peace and non-aggression. To reach these goals, the conference made education, employment, family planning, health and nutrition, and housing key focal points. The Tribune played a uniting role, by bringing together people of diverse cultures and backgrounds to formulate the means to overcome differences in objective and create pathways for NGOs to participate in the policy-making process. The conference not only encouraged member countries to develop policies which would lead to the improvement of women's lives, but led to the establishment of the United Nations Decade for Women as a means to focus those policies, as well as establishing a series of conferences to follow-up. The first of these would be the Second World Conference on Women to be held in Copenhagen. To assist in advancing women's development with research, operations support and training, the UN created the International Research and Training Institute for the Advancement of Women (INSTRAW) and the United Nations Development Fund for Women (UNIFEM).\n\nFor the first time, institutional collection within the UN evaluated the extent of problems and conditions of women in varying nations, specifically separating data by sex to bring to light the level of inequality and discrimination towards women. It was also one of the first international meetings of organized lesbians from multiple countries and cultures. Attitudes within the member nations and the UN itself began to change as a result of the focus on women brought about by the conference. Another benefit of the conference was that it connected women to other women in their struggles. Though in many ways the conference was not as effective in poor and undeveloped countries, because enforcement of the principals established and communication with women was harder in the developing world, there was a surge in women's activists coming together across the globe, as well as governmental understanding of the needs of their constituent women.\n\n\n"}
{"id": "27921643", "url": "https://en.wikipedia.org/wiki?curid=27921643", "title": "World Health Report", "text": "World Health Report\n\nThe World Health Report (WHR) is a series of reports produced regularly by the World Health Organization (WHO). First published in 1995, the \"World Health Report\" is WHO's leading publication. Published annually or biennially in multiple languages, each report includes an expert assessment of a specific global health topic, relating to all countries that are Member States of the organization. \n\nThe main purpose of the WHR is to provide policymakers, donor agencies, international organizations and others with the information they need to help them make appropriate health policy and funding decisions. However, the report is also accessible to a wider audience, such as universities, journalists and the public at large. It is expected that anyone, with a professional or personal interest in international health issues, will be able to read and take use of it.\n\nEach WHR addresses a different theme. The following is a list of reports and themes.\n\n\nThe \"World Health Report 2013\" focuses on the importance of research in advancing progress towards universal health care coverage – in other words, full access to high-quality services for prevention, treatment and financial risk protection. The report advocates for increased international and national investment in research aimed specifically at improving coverage of health services within and between countries. Examples of required research include medical research, or investigating the causes of ill-health and the interventions needed to improve health and wellbeing, as well as health services research, focusing on how to expand service coverage and reduce inequities in coverage.\n\nThe \"World Health Report 2010\" focused on the topic of universal health care coverage, and how countries can modify their financing systems to move towards this goal. The report provided an action agenda for countries at all stages of development, and proposed ways that the international community can better support efforts in low-income countries to achieve universal coverage and improve population health outcomes.\n\nThe theme of the \"World Health Report 2008\" was the renewal of primary health care, and the need for health systems to respond better and faster to the health care challenges of a changing world.\n\nThe main concern of the \"World Health Report 2007\" was how the world is at increasing risk of disease outbreaks, epidemics, industrial accidents, natural disasters and other health emergencies which can rapidly become threats to global public health security. The report described how the new International Health Regulations help countries to work together to identify risks and act to contain and control them.\n\nThe \"World Health Report 2006\" (WHR2006) highlighted the estimated shortage of almost 4.3 million doctors, nurses, midwives, and other health human resources worldwide, calling the situation a \"global health workforce crisis\". The report laid out a ten-year action plan for building national health workforces through better training, recruitment and management processes.\n\nThe \"World Health Report 2005\" focused on the fact that almost 11 million children under five years of age die annually from causes that are largely preventable, and another half a million women die in pregnancy, childbirth or soon after. The report said that reducing this toll in line with the Millennium Development Goals would depend largely on every mother and every child having the right to access to health care from pregnancy through childbirth, the neonatal period and childhood.\n\nThe topic of the \"World Health Report 2004\" was the global HIV/AIDS pandemic.\n\nThe \"World health report 2003\" examined the global health situation and some of the major threats to health. The report advocated that major improvements in health for all were within reach, and that progress depended on collaboration among governments, international institutions, the private sector and civil society to build stronger health systems.\n\nThe \"World health report 2002\" described the amount of disease, disability and death in the world that could be attributed to a selected number of the most important risks to human health. It projected how much this burden could lowered in the next 20 years if the same risk factors were reduced.\n\nThe largely neglected area of mental health was the core focus of the \"World health report 2001\".\n\nThe \"World Health Report 2000\" introduced a conceptual framework and measurement approach to examine and compare aspects of health systems around the world, and better understand the complex factors that explain how health systems perform. The report provided an assessment of the performance of national health systems for all countries.\n\n\n"}
{"id": "24587014", "url": "https://en.wikipedia.org/wiki?curid=24587014", "title": "État second", "text": "État second\n\nÉtat second (French for \"Second State\") refers to the state of mind into which some writers go when writing short stories. It mixes abstraction and concentration at the same time, ironically telling sometimes more facts than in conscious writing. The Argentine writer Julio Cortázar often used this method to write, as he called it \"the moment of maximum creativity\".\n\n"}
