{"id": "16403503", "url": "https://en.wikipedia.org/wiki?curid=16403503", "title": "Abortion in Iceland", "text": "Abortion in Iceland\n\nAbortion in Iceland has been legal in specific medical and social circumstances since 22 May 1975. The abortion rate in Iceland is relatively high, in comparison to other Nordic countries.\n\nAbortion in Iceland was legalized on a number of grounds on 22 May 1975. Although the law does not allow abortions to be performed on request, they are allowed in various medical and social circumstances. Medically, an abortion is lawful if a pregnancy threatens a woman's physical or mental health, if the fetus has a serious congenital defect, or if the woman is deemed incapable of caring for a child because of her age or mental disability. Social grounds for allowing abortion include: if the pregnancy is the result of rape or incest; if the woman has had several children already with only brief periods between pregnancies; if the woman lives in a particularly difficult family situation; or if the woman's or her partner's ill health prevents them from being able to care for a child.\n\nAbortion is only legal if performed within the first 16 weeks of pregnancy, unless a pregnancy threatens the woman's health or the fetus has a deformity. All Icelandic women who undergo abortions are required to receive counselling both prior to and following the procedure, including education about contraceptive use.\n\nThe performance of an unlawful abortion carries a sentence of between five and seven years' imprisonment.\n\nIn April 2017, the Government proposed making changes to abortion legislation in Iceland so that abortion would no longer be described as \"fetus destruction\" (\"fóstureyðing\"), but would instead be described as \"pregnancy interruption\" (\"þungunarrof\").\n\nA study published in 2003 found that over the period of 1976-1999, the abortion rate in Iceland rose by 133%, increasing from 9.4 abortions per 1000 women to 21.9 per 1000 women, with the highest regional rates in the Reykjavík area. The authors noted that Iceland's abortion rate was higher than in any of the other Nordic countries, a trend which they attributed to the limited sex education, early initiation of sexual activity, and less effective use of contraception in Iceland.\n\n, the abortion rate in Iceland was 14.5 abortions per 1000 women aged 15-44 years.\n\nLandspítali offers pre-natal screening for chromosomal anomalies, and the high rate of pregnancy termination in response to positive results has led to the near-eradication of Down syndrome in Iceland.\n"}
{"id": "25978909", "url": "https://en.wikipedia.org/wiki?curid=25978909", "title": "Abortion in Slovakia", "text": "Abortion in Slovakia\n\nAbortion in Slovakia is legal on request until 12 weeks of pregnancy, and for medical reasons at later stages.\nAbortion was fully legalized on 23 October 1986. Abortions were provided with restrictions in Slovakia and what is now the Czech Republic as early as 19 December 1957, but it was the 1986 law which removed the requirement of medical approval for abortions before the twelfth week of pregnancy. Girls under 16 require parental consent for an abortion, while girls aged 16 and 17 can have the procedure performed without consent but the parents still have to be notified.\n\nTo procure an abortion on demand, a woman must have not exceeded the twelfth week of her pregnancy, and she must make her request for an abortion known in writing to her gynaecologist, and counseling and birth control information is given to the woman, and she is referred to a hospital to terminate her pregnancy. After twelve weeks, a group of physicians must approve the abortion, which in practice only occurs if there is a chance of irreparable harm for either the fetus or the mother.\n\nThe abortion rate peaked in the late 1980s after the liberalization of the old abortion law, with nearly 40 abortions per 1000 births. In 2004, the figure fell below 15 abortions per 1000 births, its lowest rate since the government started tracking abortion figures in 1958.\n\n, the abortion rate was 13.9 abortions per 1000 women aged 15-44 years. \n"}
{"id": "48270077", "url": "https://en.wikipedia.org/wiki?curid=48270077", "title": "Activities of daily living assistance", "text": "Activities of daily living assistance\n\nAssisting in activities of daily living (ADL) are skills required in nursing and other professions such as nursing assistants.\n\nPersonal assistance is waged support of 20 or more hours a week for people with impairments. A 2008 review reported that personal assistance is possibly beneficial to some older people and their informal carers. Further research is needed to assess which models of personal assistant are more efficient, as well as their relative total costs.\n\nInactive patients must be turned every two hours, which is the minimum time that a bed sore can develop. To move a bedridden patient to the side, the patient is first pulled closer to the opposite side that they are turning to give room to maneuver. When the patient is turned to the side, a pillow is usually placed to the back to support that position.\n\nA pillow is often placed at the head of the bed to protect the head from any injury when moving a bedridden patient up in bed. Often the patient is turned to one side at a time to place a friction reducing sheet under the patient. When moving up, the patient is asked to bend knees and push with their legs while their chin is to their chest to prevent neck injury. The patient is pulled up either by the friction reducing sheet or draw sheet.\n\nFor a bed bath, a bath blanket is put over the patient and only the area washed is exposed at a time for privacy and warmth. To make a mitt out of a washcloth, the fingers and palm of the dominant hand are placed over the washcloth and the washcloth is folded over the fingers and palm. The remaining part of the washcloth not covering the fingers and palms will be folded over and tucked in and the thumb will be out of the mitt.\n\nThe eyes are cleaned, usually first, without soap to avoid irritation. The eye is cleaned from the inner side near the nose to the outer edge to avoid carrying debris to the tear duct. The cloth is rinsed or turned before going to the other eye to prevent spreading any organisms. Each area is dried at a time before washing the next area. For perineal care, the perineum is washed from least contaminated to most contaminated to reduce the spread of microorganisms. For females, the labia is spread and washed from the pubic area toward the anal area and not the other way around. For males, the tip of the penis is cleaned first and cleaned away from the meatus. In an uncircumcised penis, the foreskin is retracted and immediately put back in place to avoid compromising circulation and the foreskin is not retracted for children in order to prevent injury.\n\nA bedpan is used for bed bound patients for bowel elimination as well urinary elimination for females. Powder is often placed along the ring of the bedpan to help reduce friction but is avoided if contraindicated by issues like allergies or if a stool sample is needed. Raising the head of the bead assists in voiding or defecating.\n\nFor those with a weaker side (such as from strokes), the arm on the stronger side is used to dress the weaker side first. When undressing, the arm or leg on the stronger side is pulled out first.\n\nA fitted sheet goes over the mattress. Often a draw sheet, also called lift sheet, is used, where it is placed over the fitted sheet and in the center where it will be under the patient’s midsection. By lifting the draw sheet, it is used to help move the patient. The fitted sheet and draw sheet, which are those that go under the patient, are firmly tucked in to prevent wrinkles, which can promote skin breakdown. A top sheet and blanket are often placed over the bed and the corners are mitered.\nWhen making an occupied bed, such as for patients who are unable or have difficulty getting out of bed, one side of the bed is made at a time. Usually, the patient rolls to one side and the old linen under the patient from the opposite side, such as the fitted sheet and draw sheet, is untucked and rolled as close to the patient as possible. The new fitted sheet and draw sheet are then tucked in and also rolled close toward the patient. Then the patient rolls back toward the other side. The old linen that was folded under the patient is removed and the new linen that was also folded under the patient is eased out to make the other side of the bed. For those for whom it is contraindicated to roll to the side, such as those recovering from hip replacement surgery, then the patient sits up in bed while the top half of the bed is made and afterwards the bottom half of the bed is made.\n\nTo maintain self-esteem, the person is involved as much as possible. His or her preferences are asked regarding the order of items eaten. Condiments are added and food cut according to patient preferences. Dentures, hearing aids or glasses are put in place before mealtime.\n\nFor those with dysphagia, the patient is placed on aspiration (choking) precautions. The rate of feeding and size of bites are adjusted to patient’s tolerance. The diet would be modified according to the nutrition consult, such as chopping, mincing, pureeing or thickening liquids because they are easier to swallow than thin liquids. Solids and liquids are alternated to help with swallowing. The patient ideally sits upright and tucks the chin towards the chest during swallowing to help prevent aspiration. Signs of aspiration include coughing, choking, cyanosis, voice changes and regurgitation. A 30-minute rest period prior to mealtime is provided to give less difficulty with swallowing.\n\nFor visually impaired patients, using a clock face analogy to relate the position of items is common. It is recommended to place foods and dishes in similar location at each meal for familiarity. For beverage, straws are used when possible, if not contradicted by dysphagia, in order to prevent spilling.\n\nFor those on suicide precautions, food is served in plastic or paper containers with plastic utensils (no knives) and sharp items should only be used only with continual staff supervision.\n\n"}
{"id": "31207598", "url": "https://en.wikipedia.org/wiki?curid=31207598", "title": "Algophagy", "text": "Algophagy\n\nAlgophagy is a feeding behaviour whereby an animal eats algae as a food source. Algae is a group of photosynthetic organisms that mostly rely on aquatic environments. They grow low to the ground as they lack vascular tissue, an adaptation postdating their origin. While the group of algal species is large, it is generally accepted that algae is high in nutritional value and often contain a variety of concentrated vitamins and minerals. \n\nAlgophagy as a feeding behaviour was first noted in literature by Deonier (1972) in their explanation of feeding habits of shore flies \"Diptera ephydridae.\" In this context, this term was used to describe the behaviour of these flies consuming and digesting algal matter. Deonier (1972) found results to support this behaviour, but this feeding style has also been noted in other animals in recent literature.\n\nWhile this behaviour has been noted in a variety of insects (specifically \"Ameletus\" mayflies), it has also been observed in other invertebrates such as the crab \"Carcinus maenas\" and the \"Nanorchestes\" mite. Additionally, this behaviour has been noted in vertebrates such as the chimpanzee \"Pan troglodytes,\" the sheep \"Ovis aries,\" and the chicken \"Gallus gallus domesticus.\" This feeding behaviour has more recently been adopted by humans as well. \n\nAlgophagy is a feeding behaviour found commonly amongst many invertebrate species. Some examples of these observations include the mayfly, mites, and certain species of crab.\n\nMayflies are a group of insects found to feed off of epilithic algae from near streams in New Mexico, U.S.A. In a study to examine ingestion and digestion of algae by larval insects, Peterson (1998) analyzed the fecal composition of varying insect larvae and nymphs. All species studied showed epilithic algae in their fecal matter, markedly in the multiple species of mayfly. This study outlines the feeding behaviours used by specifically the \"Ameletus\" mayflies to feed off of and digest algae as a source of food. This observation has also been noted in species of mites. The \"Nanorchestes\" mite is a small invertebrate of the \"Pachygnathoid\" genus that lives in the ground and is often found in extremophilic conditions. Krantz and Lindquist (1979) made observations of these mites feeding and surviving off of green algae, while also delving into the background theory behind this theory. The authors argue that algal microflora predates that of vascular plants, a step to understanding the evolutionary pathway that follows algophagy. Because of this flora timeline, the mites relied on algae as an early source of nutrition, an example in support of algophagy as a feeding behaviour. These examples of this feeding behaviour are also supported by observations of certain species of crab. The green crab is a highly invasive species found on nearly all continents of Earth. This littoral crab is an omnivore with a large array of preferred foods, forming an important ecological connection with many ocean environments. In a study performed by Ropes (1968) 3,979 green crabs were sampled and their gut contents were analyzed to reveal that algae was one of the two consumed plant foods. This was replicated in other studies such as that of Baeta, Cabral, Marques, and Pardal (2006) which also found these results nearly 40 years later. This marks yet another incidence of invertebrate algophagy feeding, adding to the growing body of literature to explain this behaviour.\n\nAlgophagy has been observed in a variety of vertebrate species, such as the chimpanzee, species of sheep, and also in the common chicken.\n\nThe chimpanzee is a primate in the same family as humans and are native to sub-Saharan Africa. While many chimpanzees are naturally hydrophobic, Sakamaki (1998) found that those in Mahale have been observed to submerge themselves into freshwater and eat algae. This observation is the first documentation of a primate using algae in the wild as a food source and is an important marker of possible adaptation in the species. While the chimpanzee in question, Sally, was one of the only algae-eaters in her group, it was assumed that she had adopted this behaviour from her natal group prior to immigrating to this new environment. Nonetheless, this anecdotal field study highlights the act of eating algae in chimpanzees. Another example here is found in certain species of sheep. The North Ronaldsay sheep is native to the island of Orkney off of Scotland and had been bred for wool until recently being listed as a vulnerable population. This species relies heavily on tidal algae as outlined by Paterson and Coleman (1982). The researchers here observed the sheep feeding largely on brown algae, commonly known as seaweed. The sheep relied on the tides to expose the nutrient rich algae and when the tides made the food inaccessible, the sheep supported their diet with other forms of grazing. This feeding behaviour exemplifies the use of algophagy in this species of sheep. While algophagy has been viewed in both chimpanzees and sheep, it has also been observed in the common chicken as well. When the Poultry Department of the University of Maryland did an assay of dried \"Chlorella pyrenoidosa\", they found it to be a rich nutrient source that could be substituted into the diet of chickens. The researcher behind this outlined the benefits of using this food replacement for chickens in that it improved growth and wellbeing of the chicken. While this example is not a natural one, it does outline the use of algae as a food source for domestic chickens, an important consideration in the future of both algophagy and agriculture.\n\nWhile this feeding behaviour is not commonly associated with human evolution or adaptation, it has gained some momentum in recent application. New dieting and food trends have veered towards the inclusion of spirulina into supplements. Spirulina is a blue-green algae that is used to supplement a variety of nutrients including essential proteins, vitamins, and minerals. In a past review of spirulina by Belay, Ota, Miyakawa, and Shimamatsu (1993), it was outlined that the algae could even be correlated to reduced risk of cholesterol problems, cancer, and heavy metal nephrotoxicity. Spirulina is relatively popular among dietary supplement enthusiasts and can be used in a varied of forms from capsules, to smoothies, to baked goods. This outlines a contemporary example of algophagy in humans that can help us appreciate the scope and breadth of algophagy in the animal kingdom\n\n"}
{"id": "58111342", "url": "https://en.wikipedia.org/wiki?curid=58111342", "title": "Ami Zota", "text": "Ami Zota\n\nAmi R. Zota is an assistant professor at George Washington University Milken School of Public Health, specializing in public and occupational health. \n\nZota graduated from the University of North Carolina at Chapel Hill in 1999 with a bachelor's degree in environmental science and engineering. She later graduated from the Harvard School of Public Health with a master's and doctorate in environmental health in 2003 and 2007, respectively.\n\nZota has undertaken research on many issues relating to public health. For instance, how fast foods eaters are more likely to be exposed to di(2-ethylhexyl) phthalate and diisononyl phthalate, and co-authoring a meta-study on household chemicals present in US household dust, concluding that many chemicals present in household dust share endocrine or reproductive toxicity.\n\nZota serves on the editorial board of journal \"Journal of Exposure Science & Environmental Epidemiology\" by \"Nature.\"\n\nZota is the recipient of a career development award from the National Institutes of Environmental Health Sciences for her work identifying how environmental hazards may interact with social disadvantage and psychosocial stressors to exacerbate harms during pregnancy. She was recognized by the Collaborative on Health and the Environment as a Pioneer under 40 in Environmental Public Health.\n"}
{"id": "23953760", "url": "https://en.wikipedia.org/wiki?curid=23953760", "title": "Angang Sewage Disposal Plant", "text": "Angang Sewage Disposal Plant\n\nThe Angang Sewage Disposal Plant is a sewage treatment plant located in the city of Gyeongju, North Gyeongsang province, South Korea. It began operating in April, 2005 by the co-investment of the Government of North Gyeongsang and Gyeongju City with a fund of 44,300,000,000 won to install the facilities to prevent the pollution of Hyeongsan River which is a main water source for Gyeongju and Pohang residents. The plant is located on a spacious site with 39,000 ㎡ in Homyeong-ri, Gangdong-myeon where nature friendly facilities are also built to provide recreational venues for the locals. Through intercepting sewer pipes with a 56.1 km length and 14 pumping stations, the plant has a capacity in dealing with 18,000 tone of domestic sewage per day that comes from Angang-eup, and Gangdong-myeon in Gyeongju. The facilities have high-powered disposal equipments which are developed by related industrial companies to maintain the final discharging water as the first or second degree water in quality, so that it is used as river maintenance flow and agricultural water in case a drought occurs.\n\n\n"}
{"id": "3800143", "url": "https://en.wikipedia.org/wiki?curid=3800143", "title": "Anton Fils", "text": "Anton Fils\n\nAnton Fils (also Antonín Fils, Johann Anton Fils, Johann Anton Filtz), 22 September 1733 (baptized) – 14 March 1760 (buried) was a German classical composer.\n\nFils was born in Eichstätt, in the Bishopric of Eichstätt. Long thought to have been of Bohemian origin (e.g., ), despite having been described as \"from Bavaria\" by Friedrich Wilhelm Marpurg in 1756, his true origins were discovered in the 1960s . Fils studied law and theology at the University of Ingolstadt, and in 1754 became part of the \"Mannheimer Hofkapelle\" as a cellist. The Mannheim orchestra at the time was led by Johann Stamitz . In 1757 Fils married Elizabeth Range, and in 1759 the couple bought a house.\n\nAlthough he died at age 26, he left an extensive body of work, including at least thirty-four symphonies. Although he composed about thirty concertos, mainly for cello and for flute, only about half have survived .\n\nFils died in Mannheim and was buried on 14 March 1760 .\n\nIn his book \"Ideas for an Aesthetic of Music\" (posthumously published in 1806), author-musician Christian Friedrich Daniel Schubart called Fils \"the greatest composer of symphonies who ever lived\" . He also attributed Fils' early death to \"his bizarre notion of eating spiders\" . Retellings of this legend were elaborated to include Fils assuring horrified observers that spiders tasted like fresh strawberries . The tale still circulates as a curious bit of classical music trivia ().\n\n"}
{"id": "57150286", "url": "https://en.wikipedia.org/wiki?curid=57150286", "title": "Ayushman Bharat Yojana", "text": "Ayushman Bharat Yojana\n\nAyushman Bharat Yojana or Pradhan Mantri Jan Arogya Yojana (PMJAY) or National Health Protection Scheme or Modicare is a program which aims to provide a service to create a healthy, capable and content new India. It has two goals, one, creating a network of health and wellness infrastructure across the nation to deliver comprehensive primary healthcare services, and another is to provide insurance cover to at least 40 per cent of India's population which is majorly deprived of secondary and tertiary care services. Indu Bhushan appointed as a Chief Executive Officer (CEO) and Dr Dinesh Arora appointed as deputy CEO of Ayushman Bharat Yojana. \n\nAyushman Bharat consists of two major elements.1. National Health Protection Scheme. 2. Wellness centres. National Health Protection Scheme will provide cashless treatment to patients. And wellness centres will provide primary care to the patients. In fact, the government will upgrade existing Public Health Centres to Wellness Centres. The welfare scheme has been rolled out on August 15, 2018. The government has roped in multiple agencies to ensure seamless coordination between the centre and states.\n\n33 states and union territories accepted the scheme except three viz. Delhi, Odisha and Telangana. More than a lakh people have taken benefit of the scheme till October 2018.\n"}
{"id": "47203040", "url": "https://en.wikipedia.org/wiki?curid=47203040", "title": "Boshe", "text": "Boshe\n\nBoshe () is a village in Jiaxi (), Lufeng, Shanwei, Guangdong province of China. The village has been in existence from at least the 13th century.\n\nFor years it has been a production centre for meth as well as ketamine. It was nicknamed \"The Fortress\" and \"Breaking Bad village\" as a consequence. The authorities finally raided it in December 2013 but appear to have failed to stamp out drug production.\n\nAccording to Xinhua News Agency the region is \"plagued with rampant drug production and trafficking\". \"Over a third of meth consumed in China originates from Boshe and neighbouring villages\" and \"one in five families is directly involved in drug production\".\n"}
{"id": "7647466", "url": "https://en.wikipedia.org/wiki?curid=7647466", "title": "Brain (novel)", "text": "Brain (novel)\n\nBrain is a medical thriller written by Robin Cook. It describes how a future generation of computers will work hard-wired to human brains.\n\nThe story starts with a girl Katherine Collins going to a private clinic for a pap smear but these people anesthetize her and steal her brain for a secret military project. She is placed in a vat of liquid and her brain is connected to a computer. The same thing happens to other patients too.\n\nThe protagonist Dr. Martin Philips, a doctor in neuroradiology at the NYC medical center is involved in creating a self-diagnostic x-ray machine, along with Michaels, who is a researcher graduating from MIT and also head of the department of artificial intelligence. Dr. Philips's girlfriend and colleague Dr. Denise Sanger (28 years old) is also involved in the same hospital. Philips and Sanger both find a secret conspiracy in the hospital to steal patients' brains without their consent. They uncover details and find that though they'd suspected Mannerheim the prima donna neurosurgeon, the real villain is the soft-spoken AI researcher Michaels and his military backers. Dr. Philips blows the whistle and seeks political asylum in Sweden.\n"}
{"id": "40362834", "url": "https://en.wikipedia.org/wiki?curid=40362834", "title": "Bridging Eastern and Western Psychiatry", "text": "Bridging Eastern and Western Psychiatry\n\nBridging Eastern and Western Psychiatry (Russian: Мост между Восточной и Западной психиатрией) is a non-profit association of professional practitioners and scholars in psychiatry and related professions. It is also the name of the association's journal. According to their journal, the aim of both the association and the journal is to promote scholarly research and collaboration between Western and Eastern European psychiatrists.\n\nThe association was established in 2002 by Maria Luisa Figueira and Mario Di Fiorino and is based in Italy. The first issue of \"Bridging Eastern and Western Psychiatry\" was published in 2003 with an issue devoted to dissociation and dissociative phenomena. The journal, whose editors-in-chief are Figuerira and Di Fiornino, is published annually in two volumes, one in English and one in Russian.\n\nThe association also organizes conferences, symposia, and workshops in both Western and Eastern European countries\n"}
{"id": "6115796", "url": "https://en.wikipedia.org/wiki?curid=6115796", "title": "Capital punishment in the Netherlands", "text": "Capital punishment in the Netherlands\n\nCapital punishment in the Netherlands (Dutch: \"doodstraf in Nederland\") was abolished in 1870 in criminal law after the States General recognized it was \"cruel and rude\". The bill was introduced by liberal-catholic Minister of Justice Franciscus van Lilaar and debated in both the Senate and House of Representatives for seven days before approval. Following the abolition of the death penalty, life imprisonment was made an official punishment in 1878.\n\nA few years after gaining independence in 1815, the Kingdom of the Netherlands determined that the death penalty could be carried out through beheading. Between 1945 and 1952 several war criminals from World War II were sentenced to death by the Bijzonder Gerechtshof for treason of the State of the Netherlands and the deportation of Dutch Jews. The last persons to be executed under military law were SS officers Andries Jan Pieters and Artur Albrecht in March 1952. Capital punishment remained a legal military option until 1983 when it was explicitly forbidden in the Constitution of the Netherlands. In 1991, all references to the death penalty were removed from Dutch law.\n\nToday the Netherlands operates a clear policy against capital punishment, not participating in extradition if the suspect has a chance of receiving the death penalty.\n\n\nThe Reformed Political Party (Dutch: Staatkundig Gereformeerde Partij, SGP), a Christian right party, supports the reintroduction of the death penalty in the Netherlands. They base this on the Bible, specifically on Genesis 9:6, \"Whoso sheddeth man's blood, by man shall his blood be shed: for in the image of God made he man,\" and Exodus 21:12, \"He that smiteth a man, so that he die, shall be surely put to death.\" \n\nGeneral note: \"All sources are in Dutch.\"\n\nSources:\n\nReferences:\n"}
{"id": "594792", "url": "https://en.wikipedia.org/wiki?curid=594792", "title": "Castration anxiety", "text": "Castration anxiety\n\nCastration anxiety is the fear of emasculation in both the literal and metaphorical sense. Castration anxiety is an overwhelming fear of damage to, or loss of, the penis; one of Sigmund Freud's earliest psychoanalytic theories.. Although Freud regarded castration anxiety as a universal human experience, few empirical studies have been conducted on the topic. Much of the research that has been done on the topic was done decades ago, although still relevant today. The theory is that a child has a fear of damage being done to their genitalia by the parent of the same sex (e.g. a son being afraid of his father) as punishment for sexual feelings toward the parent of the opposite sex (e.g. a son toward his mother). It has been theorized that castration anxiety begins between the ages of 3 and 5, otherwise known as the phallic stage of development according to Freud. Although typically associated with males, castration anxiety is theorized to be experienced in differing ways for both the male and female sexes.\n\nCastration anxiety is the conscious or unconscious fear of losing all or part of the sex organs, or the function of such. In the literal sense, castration anxiety refers to the fear of having one's genitalia disfigured or removed to punish sexual desires of a child.\n\nIn Freudian psychoanalysis, castration anxiety (\"Kastrationsangst\") refers to an unconscious fear of penile loss originating during the phallic stage of psychosexual development and lasting a lifetime. According to Freud, when the infantile male becomes aware of differences between male and female genitalia he assumes that the female's penis has been removed and becomes anxious that his penis will be cut off by his rival, the father figure, as punishment for desiring the mother figure.\n\nIn 19th century Europe it was not unheard of for parents to threaten their misbehaving sons with castration or otherwise threaten their genitals. This theme is explored in the story \"Tupik\" by French writer Michel Tournier in his collection of stories entitled \"Le Coq de Bruyère\" (1978) and is a phenomenon Freud documents several times. In this same period, Dr. Kellogg and others in America and English-speaking countries offered to Victorian parents circumcision and in grave instances, \"castration\" of their boys and girls as a terminal \"cure\" and punishment for a wide variety of misbehaviours (notably masturbation) and ills, becoming very popular over time.\n\nCastration anxiety can also refer to being castrated symbolically. In the metaphorical sense, castration anxiety refers to the idea of feeling or being insignificant; there is a need to keep one's self from being dominated; whether it be socially or in a relationship.\nSymbolic castration anxiety refers to the fear of being degraded, dominated or made insignificant, usually an irrational fear where the person will go to extreme lengths to save their pride and/or perceives trivial things as being degrading making their anxiety restrictive and sometimes damaging.\nThis can also tie in with literal castration anxiety in fearing the loss of virility or sexual dominance.\n\nThe anxiety aspect of this topic can be completely overwhelming to the individual, and can often breach other aspects of their lives. A link has been found between castration anxiety and fear of death. Although differing degrees of anxiety are common, young men who felt the most threatened in their youth tended to show chronic anxiety. Because the consequences are extreme, the fear can evolve from potential disfigurement to life-threatening situations. Essentially, castration anxiety can lead to a fear of death, and a feeling of loss of control over one's life.\n\nTo feel so powerless can be detrimental to an individual's mental health. One of the most concerning problems with all of this is the idea that the individual does not recognize that their sexual desires are the cause of the emotional distress. Because of unconscious thoughts, as theorized in the ideas of psychoanalysis, the anxiety is brought to the surface where it is experienced symbolically. This will lead to the fear associated with bodily injury in castration anxiety, which can then lead to the fear of dying or being killed.\n\nIt is implied in Freudian psychology that both girls and boys pass through the same developmental stages: oral, anal, and phallic stages. Freud, however, believed that the results may be different because the anatomy of the different sexes is different.\n\nThe counterpart of castration anxiety for females is penis envy. Penis envy, and the concept of such, was first introduced by Freud in an article published in 1908 titled \"On the Sexual Theories of Children\". The idea was presumed that females/girls envied those (mostly their fathers) with a penis because theirs was taken from them—essentially they were already \"castrated\". Freud entertained that the envy they experienced was their unconscious wish to be like a boy and to have a penis.\n\nPenis envy, in Freudian psychology, refers to the reaction of the female/young girl during development when she realizes that she does not possess a penis. According to Freud, this was a major development in the identity (gender and sexual) of the girl. The contemporary culture assumes that penis envy is the woman wishing they were in fact a man. This is unrelated to the notion of \"small penis syndrome\" which is the assumption by the man that his penis is too small. According to Freud's beliefs, girls developed a weaker superego, which he considered a consequence of penis envy.\n\nSigmund Freud's views on women created great debate between professionals and nonprofessionals interested in this field. In his 1925 paper \"The Psychic Consequences of the Anatomic Distinction between the Sexes\", Freud wrote that \"women oppose change, receive passively, and add nothing of their own\". This quote is not actually in the paper written by Freud. Among his many suggestions, Freud believed that during the phallic stage, young girls distance themselves from their mothers and instead envy their fathers and show this envy by showing love and affection towards their fathers. According to Cohler and Galatzer, Freud believed that all of the concepts related to penis envy were among his greatest accomplishments. However, these are also his most criticized theories as well—most famously by Karen Horney.\n\nFreud derived this term from the Greek tragedy \"Oedipus Rex\". In this tragedy, the main character, Oedipus, kills his father and marries a woman whom he does not know is his mother. Given this irony, Freud used the term Oedipus complex to indicate this unconscious desire.\n\nAccording to Freud, the Oedipus complex relates to a universal wish that a boy has, unknowingly, to have his mother all to himself by the removal of his father. This complex occurs during the third stage, known as the phallic stage, of Freud's psychosexual stages of personality development. It is during this stage that the child learns he has a penis and begins to associate the penis with the pleasure of touching it. In addition to this, the child becomes aware of his sexual desire toward the parent of the opposite sex, his mother. According to Freud, this lusting that the child feels toward his mother means that he wants to have sex with her. Due to this lusting, the child sees the father as a competitor for the mother's attention and love. Due to this competition, the boy identifies his father as the only obstacle inhibiting him from having his mother.\n\nThe conflict aspect of the Oedipus complex arises from within the child. The child knows to love and respect his father and yet he finds himself competing with his father for his mother's affection. Additionally, the child also knows that removing the father from the home is wrong. And yet, he finds himself wanting his competitor removed so that he can have his mother all to himself.\n\nFurthermore, the child begins to fear his father. The child understands that the father is superior to the boy in both size and strength and the father could easily use those advantages to prevent the boy from possessing his mother. Moreover, boy begins to fear a preemptive strike from the father to take away the cause of the conflict, the boy's penis. This fear of losing one's penis is called castration anxiety. This anxiety drives the child to give up his sexual desire for his mother, and redirect his attention to becoming more like his father, who already had his mother. This redirecting of attention is called identification. It is during this process that the child then identifies the father as a suitable role model. This growth in the child is the start to the resolution of the Oedipal conflict.\n\nFreud believed, however, that the Oedipus complex could never fully be resolved. He concluded that these lusting feelings must be repressed beneath the child's conscious awareness. This repression is the mind's way of freeing the child from the disturbing anxieties that are related to this complex. Freud went further to say that the sexual desires are still within the child and are often expressed in more indirect and appropriate forms of behavior. A rather typical outlet is found within the child's dreams; within the dreams the child is able to safely express his repressed desires in a non-anxiety forming and socially acceptable manner.\n\nThe term Electra comes from Greek mythology as well. Electra was a Greek character who convinced her brother to kill their mother, but only after the mother had already murdered the father. Carl Jung, one of Freud's successors, coined the term the Electra complex for the Oedipus complex in girls, which also occurs during the third stage of psychosexual development. Jung described this complex as the time when the girl begins to develop an awareness of her sex. This awareness includes identifying the other children she may encounter as boys or girls and the identification of her parents' sex.\n\nAccording to Freud, during this stage the child is initially very attached to her mother. However, when the child discovers that she does not have a penis, she redirects her attachment to her father. The child then blames her mother for \"castrating\" her. As a result of her new affection for her father, the child will begin to identify with and mimic her mother out of fear of losing her father's love. Similarly to the Oedipus complex, the girl learns her role by identifying with her mother in an attempt to have her father vicariously through her mother.\n\nFreud rejected the idea of the Electra complex and was even monotonously vague about how the phallic stage of psychosexual development is resolved for girls. Freud stated that this complex drags out for girls and may never fully be resolved. Because the successful resolution is the result of the development of the superego, Freud stated that women must be morally inferior to men. This notion led this aspect of Freud's developmental theory to not be a widely accepted theory today.\n\nThere is an assumption that the Oedipus complex is resolved when the young boy identifies with his father and gives up the notion that he may become intimate with his mother. There are many studies that look at the effects of the absence of the father on the child's development. However, there are no studies that determine this resolution if the father is unavailable to them. Mary Leichty, of Michigan State University, hypothesized then, \"that if the father is not available to play his role at this time (during the development of the Oedipus complex), there will be inadequate resolution of the conflict\".\n\nThis hypothesis suggests that when young, a boy could potentially be left in a vulnerable stage where he still believes that becoming intimate with his mother is an option. Freud would assume that this absence of the father may result in the same development that a young girl would experience. The young boy, in Freud's belief, would suffer from an underdeveloped superego, and would essentially make for a less moral human being.\n\nSarnoff et al. surmised that men differ in their degree of castration anxiety through the castration threat they experienced in childhood. Therefore, these men may be expected to respond in different ways to different degrees of castration anxiety that they experience from the same sexually arousing stimulus. The experimenters aimed to demonstrate that in the absence of a particular stimulus, men who were severely threatened with castration, as children, might experience long-lasting anxiety. The researchers claimed that this anxiety is from the repressed desires for sexual contact with women. It was thought that these desires are trying to reach the men's consciousness. The experimenters deduced that unconscious anxiety of being castrated might come from the fear the consciousness has of bodily injury. The researchers concluded that individuals who are in excellent health and who have never experienced any serious accident or illness may be obsessed by gruesome and relentless fears of dying or of being killed.\n\nIn another article related to castration anxiety, Hall et al. investigated whether sex differences would be found in the manifestations of castration anxiety in their subject's dreams. The researchers hypothesized that male dreamers would report more dreams that would express their fear of castration anxiety instead of dreams involving castration wish and penis envy. They further hypothesized that women will have a reversed affect, that is, female dreamers will report more dreams containing fear of castration wish and penis envy than dreams including castration anxiety. The results demonstrated that many more women than men dreamt about babies and weddings and that men had more dreams about castration anxiety than women.\n"}
{"id": "24223206", "url": "https://en.wikipedia.org/wiki?curid=24223206", "title": "Clara White Mission", "text": "Clara White Mission\n\nThe Clara White Mission (CWM) is a non-profit organization in Jacksonville, Florida founded by Dr. Eartha M. M. White that advocates for the poor and provides social services. According to their website, \"The Clara White Mission is to reduce homelessness through advocacy, housing, job training and employment by partnering with business and local community resources.\" CWM created an extensive and diverse network of public and private funding sources.\n\nThe Clara White Mission was formally founded in 1904, but Clara English White began feeding hungry people in her Clay street neighborhood in the 1880s. During the period between 1900 and 1950, Dr. Eartha M. M. White, a nationally recognized humanitarian who was Clara's daughter, turned the soup kitchen into an effective social agency.\n\nClara White died in 1920, but Eartha continued their \"mission work\", and at the height of the great depression the operation grew so large, it had to be moved from its residential location. The Globe Theatre had been closed for years, and Eartha White was able to purchase it. The West Ashley Street building was then dedicated in her mother's memory. At the time, the CWM was the only non-profit organization serving daily meals to the needy in Jacksonville. The mission incorporated in 1934.\n\nThe Clara White Mission was Eartha's home for over 40 years and the center of her activities. Besides the original feeding program, the building was home to a myriad of projects and initiatives through the years. The Works Progress Administration (WPA) used the mission as the work site for sewing and arts projects during the Depression; the building's top floors housed soldiers stationed in Jacksonville during World War II.\n\nBeginning with Clara and continuing with Eartha, the mission provided rooms to prisoners after their release from jail; they were also fed, given clothing and assistance finding a job. The homeless received similar assistance.\n\nThe mission provided hands-on training for cooking/canning and business skills including typing, in addition to Braille instruction. The facility was renovated in 1946 and local business owners were encouraged to lease office space on the building's first and third floors to help pay the bills.\n\nIn 1902, Eartha and Clara White began the \"Colored Old Folks Home\", which became the \"Eartha White Nursing Home\". In 1965, construction began on Eartha M. M. White Health Care, Inc., a 125-bed, $780,000.00 facility, initiated by Eartha at age 89.\n\nThroughout Eartha White's life, she actively collected period furniture, historical documents, and photos of Jacksonville's past as well as Black Americans. She solicited donations from all her contacts, both business and personal. The accumulation was housed in a building near Moncrief Springs until her death in 1974, after which many items were stolen or damaged. The remaining documents were turned over to the University of North Florida for safe keeping; the furniture and objets d'art were stored by the CWM.\n\nThe \"Eartha M.M. White Memorial Art and Historical Resource Center\" was dedicated on December 17, 1978 at the Clara White Mission. The \"museum\" is located at the north end of the second floor of the original mission building where Eartha's living quarters were located.\n\nMost of the Mission's programs help the homeless daily:\nThree quarters of area homeless are veterans and counselors are available to assist those seeking to improve their situation.\n\n\"Clara's at the Cathedral Café\" is a cooperative project between the St. Johns Cathedral and the School of Culinary Arts at the mission. Every Friday since April 13, 2007, a luncheon has been prepared by the students and staff from the Mission's culinary school. The meal is reasonably priced and attracts workers from downtown businesses and retirees.\n\n\"Ashley Street Catering\" is a full-service caterer at the mission. They prepare the food, transport it and serve it at the location of the client's event. Most of the staff are graduates of the CWM culinary arts program and all profits are returned to the mission.\n\nThere are scores of companies, organizations and agencies on CWM's list of Community Service, Hospitality and Funding providers. Among them are the Blue Foundation, Community Development Block Grant Program, City of Jacksonville, Federal Emergency Management Agency (FEMA), Jaguars Foundation, Jessie Ball duPont Fund, Kirbo Foundation, Kraft Foods, Landwirth Foundation, Public Service Grant Program, Sodexo Foundation, United States Department of Housing and Urban Development, United Way of Northeast Florida, United States Department of Veterans Affairs, Weaver Family Foundation, and WorkForce Florida.\n\nThe \"Eartha M.M. White Legacy Fund\" was established in 2005 through the Community Foundation in Jacksonville with a $1.4 million endowment, funded through the 2003 conversion of the assets of Eartha M.M. White Health Care Inc.\n\nAn annual benefit luncheon is held in mid-May for the mission called, \"Miracle on Ashley Street\". Local celebrities from business, politics and media serve guests, and chefs from area restaurants prepare their specialties. Entertainment is provided by students from the LaVilla School for the Arts. Attendance in 2008 was 1,500 and has risen steadily since the event was first held in 1998.\n\n\"Stars & Strikes Celebrity Charity Bowl\" is a joint venture with the Jacksonville Jaguars.\n\nThe CWM was awarded a $50,000 grant from the Pepsi Refresh Project on May 28, 2010. The organization was selected by weatherman and TV personality Al Roker live on the Today Show. CWM President Ju'Coby Pittman-Peele had been invited to New York ostensibly to talk about programs making a difference in their communities.\n\nThe U.S. Department of Housing and Urban Development (HUD) named the Clara White Mission as recipient of the 2007 \"HUD Secretary’s Opportunity and Empowerment Award\" in a news release on May 16, 2008.\n\nJu'Coby Pittman; CEO/President awarded the FBI Director's Community Leadership Award- December 2012\n\n"}
{"id": "28866774", "url": "https://en.wikipedia.org/wiki?curid=28866774", "title": "Clinical nutrition", "text": "Clinical nutrition\n\nClinical nutrition is nutrition of patients in health care. Clinical in this sense refers to the management of patients, including not only outpatients at clinics, but also (and mainly) inpatients in hospitals. It incorporates primarily the scientific fields of nutrition and dietetics. It aims to keep a healthy energy balance in patients, as well as providing sufficient amounts other nutrients such as protein, vitamins, minerals.\n\nAmong the routes of administration, the preferred means of nutrition is, if possible, oral administration. Alternatives include enteral administration (in nasogastric feeding) and intravenous (in parenteral nutrition).\n\nIn the field of clinical nutrition, malnutrition has causes, epidemiology and management distinct from those associated with malnutrition that is mainly related to poverty.\n\nThe main causes of \"clinical malnutrition\" are:\n\nClinical malnutrition may also be aggravated by iatrogenic factors, i.e., the inability of a health care entity to appropriately compensate for causes of malnutrition.\n\nThere are various definitions of clinical malnutrition. According to one of them, patients are defined as \"severely undernourished\" when meeting at least one of the following criteria: BMI < or = 20 kg/m and/or > or = 5% unintentional weight loss in the past month and/or > or = 10% unintentional weight loss in the past 6 months. By the same system, the patient is \"moderately undernourished\" if they met at least one of the following criteria: BMI 20.1–22 kg/m and/or 5-10% unintentional weight loss in the past six months.\n\n\nThe \"American Journal of Clinical Nutrition\" is the highest-ranked journal in ISI's nutrition category.\n"}
{"id": "46703844", "url": "https://en.wikipedia.org/wiki?curid=46703844", "title": "Couscous connection", "text": "Couscous connection\n\nThe couscous connection was an international drug trafficking gang based in Paris in the 1980s. The gang imported heroin and cocaine from Tunisia via Amsterdam and Brussels to Paris, where they distributed the drugs. The trial of the gang members in 1992 received widespread publicity since the older brother of the president of Tunisia was charged and convicted \"in absentia\" for his involvement in laundering the proceeds.\n\nThe investigation began in January 1989 after an informer gave drug squad investigators in Belleville, Paris the names of three couriers bringing heroin and cocaine from Amsterdam and Brussels to Paris. The police found that the couriers always used rental cars for which they paid in cash. The investigators obtained search warrants and permission to tap telephones. In one of the couriers' apartments they found 180 grams of heroin, a false Dutch driving license, a sawed-off rifle, savings bank receipts and invoices for jewelry purchases using cash.\n\nThe investigators traced links to the \"Roma brothers\", and gradually built up a picture of the import and distribution networks. One of the leads took them to Hedi Ben Hassen, nephew of Frej Guedoura, chief of special services and national security in Tunisia, and Habib Ben Ali, known as Moncef, brother of President Zine El Abidine Ben Ali of Tunisia. In February 1990 the police tried to arrest these two at an airport before they left France for Tunisia. Ben Ali showed his diplomatic passport, explained his relationship to the president, claimed immunity and was allowed to leave.\n\nThe gang had at least 30 members, of whom 25 were arrested and appeared in court.\nThe leaders of the gang were the six Roma brothers, of whom four appeared in court and two were on the run as of 1992. An international arrest warrant was issued for Habib Ben Ali.\n\nThe trial of the \"couscous connection\", the nickname given to the drug trafficking network, opened on 17 November 1992 in the Fourteenth Chamber of the Paris Criminal Court. Habib Ben Ali was said to have been the bag carrier for the proceeds of the sales of heroin and cocaine trafficked between Tunisia, Amsterdam and Paris, and was charged with laundering drug money and breaking narcotics laws. He did not appear. The normal broadcast in Tunisia of the news program of France's second television channel was suspended during the trial.\nOn 30 November 1992 Ben Ali was found guilty \"in absentia\" and sentenced to ten years imprisonment. As part of the same case 23 other gang members, mostly Tunisian, were sentenced to various punishments.\n\nOn 1 December 1992 Ben Ali's French lawyer met his client in Tunis. The lawyer gave a press conference in which he claimed there was no evidence that Ben Ali deserved the sentence. He said the conviction was due to political manipulation. He blamed Islamic fundamentalists for concocting the charges in an effort to blacken the family name.\nMezri Haddad signed an article in \"Libération\" in 1992 about the \"Couscous connection\". According to the Canadian writer Lise Garon, \"Haddad is probably the only Tunisian to have signed an article about the involvement of the president's brother in international drug trafficking.\"\n\nBen Ali was found murdered on 14 May 1996 in a Tunis apartment. There was much speculation about who had ordered his death.\n\n"}
{"id": "1331655", "url": "https://en.wikipedia.org/wiki?curid=1331655", "title": "Dew pond", "text": "Dew pond\n\nA dew pond is an artificial pond usually sited on the top of a hill, intended for watering livestock. Dew ponds are used in areas where a natural supply of surface water may not be readily available. The name dew pond (sometimes cloud pond or mist pond) is first found in the \"Journal of the Royal Agricultural Society\" in 1865. Despite the name, their primary source of water is believed to be rainfall rather than dew or mist.\n\nThey are usually shallow, saucer-shaped and lined with puddled clay, chalk or marl on an insulating straw layer over a bottom layer of chalk or lime. To deter earthworms from their natural tendency of burrowing upwards, which in a short while would make the clay lining porous, a layer of soot would be incorporated or lime mixed with the clay. The clay is usually covered with straw to prevent cracking by the sun and a final layer of chalk rubble or broken stone to protect the lining from the hoofs of sheep or cattle.\n\nA method of constructing the base layer using chalk puddle was described in \"The Field\" 14 December 1907. \nA Sussex farmer born in 1850 tells how he and his forefathers made dew ponds:\nIf the pond's temperature is kept low, evaporation (a major water loss) may be significantly reduced, thus maintaining the collected rainwater. According to researcher Edward Martin, this may be attained by building the pond in a hollow, where cool air is likely to gather, or by keeping the surrounding grass long to enhance heat radiation. As the water level in the basin falls a well of cool, moist air tends to form over the surface, restricting evaporation.\n\nThe mystery of dew ponds has drawn the interest of many historians and scientists, but until recent times there has been little agreement on their early origins. It was widely believed that the technique for building dew ponds has been understood from the earliest times, as Kipling tells us in \"Puck of Pook's Hill\". The two Chanctonbury Hill dew ponds were dated, from flint tools excavated nearby and similarity to other dated earthworks, to the neolithic period. Landscape archaeology too seemed to demonstrate that they were used by the inhabitants of the nearby hill fort (probably from an earlier date than that of the surviving late Bronze Age structure) for watering cattle. A more prosaic assessment from Maud Cunnington, an archaeologist from Wiltshire, while not ruling out a prehistoric origin, describes such positive interpretations of the available evidence as no more than “flights of fancy”. A strong claim to antiquity may, however, be made for at least one Wiltshire dew pond: A land deed dated 825 CE mentions Oxenmere () at Milk Hill, Wiltshire, showing that dew ponds were in use during the Saxon period. The parliamentary enclosures of the mid eighteenth to mid nineteenth centuries caused many new upland ponds to be made, as access to traditional sources of drinking water for livestock was cut off. The naturalist Gilbert White noted that during extended periods of summer drought the artificial ponds on the downs above his native Selborne, Hampshire, retained their water, despite supplying flocks of sheep, while larger ponds in the valley below had dried up. Later observations demonstrated that during a night of favourable dew formation a typical increase in water level of some two or three inches was possible.\n\nThere is equal controversy on the means of replenishment of dew ponds. Experiments conducted in 1885 to determine the origin of the water found that dew forms not from dampness in the air but from moisture in the ground directly beneath the site of the condensation: dew, therefore, was ruled out as a source of replenishment. Other scientists have pointed out that the 1885 experiments failed to take into account the insulating effect of the straw and the cooling effect of the damp clay: the combined effect would be to keep the pond at a lower temperature than the surrounding earth and thus able to condense a disproportionate share of moisture.\nIn turn these conclusions were disproved in the 1930s, when it was pointed out that the heat-retaining quality of water (its thermal capacity) was many times greater than that of earth and therefore the air above a pond in summer would be the last place to attract condensation. The deciding factor, it was concluded, is the extent of the saucer-shaped basin extending beyond the pond itself: the large basin would collect more rainfall than a pond created without such a surrounding feature.\n\nDew ponds are still common on the downlands of southern England, the North Derbyshire and Staffordshire moorlands and in Nottinghamshire.\n\nAt the dew pond Helmfleeth in the municipality Poppenbüll (Peninsula Eiderstedt in Schleswig-Holtstein, Germany), In situ measurements of the evaporation and condensation were taken. For this reason, meteorological measuring instruments and a floating evaporation pan after Brockamp & Werner (1970) were used. These measurements proved the dew formation on the basis of temperature changes and the weather conditions. The dew pond Helmfleeth is part of the water supply of marsh areas and is used until today.\n\nIn 2014, the traditional technique was verified by means of modern building material at reproductions of dew ponds in East Friesland. In this context, various techniques were tried in two terrestrial hollows. Commercially available PVC-film was used for the sealing and foam glass gravel for the insulation. The construction was carried out by craftsmen and the climatological analysis by Werner and Coldewey.\n\nThe nursery rhyme Jack & Jill may refer to a dew pond at the peak of a hill rather than a well.\n\n\n\n\n\n\n\n\n"}
{"id": "42327240", "url": "https://en.wikipedia.org/wiki?curid=42327240", "title": "Dignity of risk", "text": "Dignity of risk\n\nDignity of risk is the idea that self-determination and the right to take reasonable risks are essential for dignity and self esteem and so should not be impeded by excessively-cautious caregivers, concerned about their duty of care. The concept is applicable to adults who are under care such as elderly people, disabled people, and people with mental health problems.\n\nThe concept was first articulated in a 1972 article \"The dignity of risk and the mentally retarded\" by Robert Perske:\nOverprotection may appear on the surface to be kind, but it can be really evil. An oversupply can smother people emotionally, squeeze the life out of their hopes and expectations, and strip them of their dignity. Overprotection can keep people from becoming all they could become. Many of our best achievements came the hard way: We took risks, fell flat, suffered, picked ourselves up, and tried again. Sometimes we made it and sometimes we did not. Even so, we were given the chance to try. Persons with special needs need these chances, too. Of course, we are talking about prudent risks. People should not be expected to blindly face challenges that, without a doubt, will explode in their faces. Knowing which chances are prudent and which are not – this is a new skill that needs to be acquired. On the other hand, a risk is really only when it is not known beforehand whether a person can succeed. The real world is not always safe, secure, and predictable, it does not always say “please,” “excuse me”, or “I’m sorry”. Every day we face the possibility of being thrown into situations where we will have to risk everything … In the past, we found clever ways to build avoidance of risk into the lives of persons living with disabilities. Now we must work equally hard to help find the proper amount of risk these people have the right to take. We have learned that there can be healthy development in risk taking and there can be crippling indignity in safety!\n\nAllowing people under care to take risks is often perceived to be in conflict with the caregivers' duty of care. Finding a balance between these competing considerations can be difficult when formulating policies and guidelines for caregiving.\n\nOverprotection of people with disabilities causes low self-esteem and underachievement because of lowered expectations that come with overprotection. Internalisation of low expectations causes the disabled person to believe that they are less capable than others in similar situations.\n\nIn elderly people, overprotection can result in learned dependency and a decreased ability for self-care:\n\n\"It is possible to deliver physical care that has positive outcomes and returns a person to full function, yet, if during that care they have not been involved, allowed to make choices and respectfully assisted with activities of daily living, it may be possible to cause psychological damage through undermining that person's dignity.\"\n\nThe right to fail and the dignity of risk is one of the basic tenets of the philosophy of the independent living movement.\n\nThe first of eight \"guiding principles\" of the United Nations' Convention on the Rights of Persons with Disabilities states: \"Respect for inherent dignity, individual autonomy including the freedom to make one’s own choices, and independence of persons.\"\n\n"}
{"id": "49914563", "url": "https://en.wikipedia.org/wiki?curid=49914563", "title": "European Medical Association", "text": "European Medical Association\n\nThe European Medical Association (EMA) was established in 1990 in Belgium, EMA is the main association representing Medical Doctors in Europe supported the European Commission - Lifelong Learning Programme (LLP).\n\n"}
{"id": "814709", "url": "https://en.wikipedia.org/wiki?curid=814709", "title": "Father of medicare", "text": "Father of medicare\n\nSeveral individuals have been described as the father of medicare in Canada. Medicare is the country's publicly funded health system.\n\n\nThis list includes individuals from three major distinct and competing Canadian political traditions: Douglas and Lloyd from the Co-operative Commonwealth Federation, later the New Democratic Party; Hall, a Progressive Conservative; and Martin and Pearson, Liberals.\n"}
{"id": "57618746", "url": "https://en.wikipedia.org/wiki?curid=57618746", "title": "GATA2 deficiency", "text": "GATA2 deficiency\n\nGATA2 deficiency (also termed GATA2 haploinsufficiency or GATA2 deficiency syndrome) is a recently defined grouping of several disorders caused by common defect, viz., familial or sporadic inactivating mutations in one of the two parental \"GATA2\" genes. These autosomal dominant mutations cause a reduction, i.e. a haploinsufficiency, in the cellular levels of the gene's product, GATA2. The GATA2 protein is a transcription factor critical for the embryonic development, maintenance, and functionality of blood-forming, lympathic-forming, and other tissue-forming stem cells. In consequence of these mutations, cellular levels of GATA2 are deficient and individuals develop over time hematological, immunological, lymphatic, or other presentations that may begin as apparently benign abnormalities but commonly progress to severe organ (e.g. lung) failure, opportunistic infections, virus infection-induced cancers, the myelodysplastic syndrome, and/or leukemia. GATA2 deficiency is a life-threatening and precancerous condition.\n\nThe various presentations of GATA2 deficiency include: 1) Monocytopenia and Mycobacterium Avium Complex/Dendritic Cell, Monocyte, B and NK Lymphocyte deficiency (i.e. MonoMAC or MonoMAC/DCML); 2) Emberger syndrome; 3) familial myelodysplastic syndrome/acute myeloid leukemia (i.e. familial MDS/AML); 3) chronic myelomonocytic leukemia (i.e. CMML); and 4) other anomalies such as aplastic anemia, chronic neutropenia, and wide-ranging immunological defects. Each of these presentations is characterized by a specific constellation of signs and symptoms but often includes signs and symptoms more characteristic of other GATA2 deficiency presentations. Furthermore, individuals with identical \"GATA2\" gene mutations can exhibit very different presentations.\n\nPrior to 2011, MonoMAC and the Emberger syndrome were clinically defined as unrelated genetic disorders. In 2011, however, all cases of both disorders were found to be caused by inactivating mutations in the \"GATA2\" gene. Subsequently, some but not all cases of an expanding list of other well-defined disorders have been attributed to inactivating \"GATA2\" mutations. While MonoMAC, the Emberger syndrome, and the growing list of all other disorders marked by inactivating \"GATA2\" gene mutations are now being classified as a single clinical entity termed GATA2 deficiency, MonoMAC and the Emberger syndrome are sometimes still regarded as separate clinical entities. Here, GATA2 deficiency is taken to include all disorders caused by inactivating \"GATA2\" mutations. Defined as such, GATA2 deficiency is an unexpectedly common underlying cause for a growing list of disorders. Importantly, however, its treatment differs critically from that used to treat cases of these disorders which are not due to GATA2 deficiency.\n\nIn 2011, all cases of the previously described disorders of Emberger syndrome and MonoMAC as well as some cases of the previously described disorder of familial MDS/AML were discovered to be due to inactivating mutations in the \"GATA2\" gene. Subsequently, numerous studies discovered that a significant percentage of many other well-known hematological, immunological, autoimmune, and infectious diseases were associated with, and apparently due to, inactivating mutations in the \"GATA2\" gene.\n\nInactivating mutations in the \"GATA2\" gene are the primary cause of GATA2 deficiency disorders. This gene is a member of the evolutionarily conserved GATA transcription factor gene family. All vertebrate species tested so far, including humans and mice, express 6 GATA genes, \"GATA1\" through \"GATA6\". The human \"GATA2\" gene is located on the long (or \"q\") arm of chromosome 3 at position 21.3 (i.e. the 3q21.3 locus). It consists of 8 exons. Two sites, one more toward the 5' end, the second more toward the 3' end of the gene code for two Zinc finger structural motifs, ZF1 and ZF2, respectively, of the GATA2 transcription factor. ZF1 and ZF2 are critical for regulating the ability of GATA2 transcription factor to stimulate its target genes.\n\nThe \"GATA2\" gene has at least five separate sites which bind nuclear factors that regulate its expression. One particularly important such site is located in intron 4. This site, termed the 9.5 kb enhancer, is located 9.5 kilobases (i.e. kb) down-stream from the gene's transcript initiation site and is a critically important enhancer of the gene's expression. Regulation of \"GATA2\" expression is highly complex. For example, in hematological stem cells, GATA2 transcription factor itself binds to one of these sites and in doing so is part of functionally important positive feedback autoregulation circuit wherein the transcription factor acts to promote its own production; in a second example of a positive feed back circuit, GATA2 stimulates production of Interleukin 1 beta and CXCL2 which act indirectly to simulate \"GATA2\" expression. In an example of a negative feedback circuit, the GATA2 transcription factor indirectly causes activation of the G protein coupled receptor, GPR65, which then acts, also indirectly, to repress \"GATA2\" gene expression. In a second example of negative feed-back, GATA2 transcription factor stimulates the expression of the GATA1 transcription factor which in turn can displace GATA2 transcription factor from its gene-stimulating binding sites thereby limiting GATA2's actions (see GATA2 switch in \"GATA2 transcription factor\" section).\n\nThe human \"GATA2\" gene is expressed in hematological bone marrow cells at the stem cell and later progenitor cell stages of their development. Increases and/or decreases in the gene's expression regulate the self-renewal, survival, and progression of these immature cells toward their final mature forms viz., erythrocytess, certain types of lymphocytes (i.e. B cells, NK cells, and T helper cells), monocytes, neutrophils, platelets, plasmacytoid dendritic cells, macrophages and mast cells. The gene is likewise critical for the formation of the lymphatic system, particularly for the development of its valves. The human gene is also expressed in endothelium, some non-hematological stem cells, the central nervous system, and, to lesser extents, prostate, endometrium, and certain cancerous tissues.\n\nScores of different types of inactivating \"GATA\" mutations have been associated with GATA2 deficiency; these include frameshift, point, insertion, splice site and deletion mutations scattered throughout the gene but concentrated in the region encoding the GATA2 transcription factor's ZF1, ZF2, and 9.5 kb sites. Rare cases of GATA2 deficiency involve large mutational deletions that include the 3q21.3 locus plus contiguous adjacent genes; these mutations seem more likely than other types of \"GATA\" mutations to cause increased susceptibilities to viral infections, developmental lymphatic disorders, and neurological disturbances.\n\nAnalyses of individuals with AML have discovered many cases of GATA2 deficiency in which one parental \"GATA2\" gene was not mutated but silenced by hypermethylation of its gene promotor. Further studies are required to define the involvement of this hypermethylation-induced form of GATA2 deficiency in other disorders as well to integrate it into the diagnostic category of GATA2 deficiency.\n\nGATA2 deficiency disorders are variably associated with secondary genetic abnormalities. Monosomy of chromosome 7 (i.e. lose of one of the two chromosomes 7) or deletion of the \"q\" (i.e. short arm) of one chromosome 7 are the most common abnormal karyotypes (i.e. abnormal chromosome number or appearance) associated with GATA2 deficiency, occurring in ~41% of cases; less common abnormal karyotypes associated with the deficiency include chromosome 8 trisomy (8% of cases) and, rarely, chromosome 21 monosomy. GATA2 deficiency is also associated with somatic mutaions in at least three other genes viz., \"ASXL1\", \"SETBP1\", and \"STAG2\". Independently of \"GATA2\" mutations and the development of GATA2 deficiency, \"ASXL1\" mutations are associated with MDS, AML, CMML, chronic lymphocytic leukemia, myeloproliferative neoplasm, and cancers of the breast, cervix, and liver, \"SETBP1\" mutations are associated with atypical MDS, CMML, chronic myelogenous leukemia, and chronic neutrophilic leukemia, and \"STAG2\" mutations are associated with MDS, AML, CMML, chronic myelogenous leukemia, and cancers of the bladder, stomach, colon, rectum, and prostate gland. The roles, if any, of these karyotypes and somatic mutations on the development, types of presentation, and progression of GATA2 deficiency are unclear and require further study.\n\nThe GATA2 transcription factor contains two zinc finger (i.e. ZnF) motifs. C-ZnF is located toward the protein's C-terminus and is responsible for binding to specific DNA sites. N-ZnF is located toward the proteins N-terminus and is responsible for interacting with various other nuclear proteins that regulate its activity. The transcription factor also contains two transactivation domains and one negative regulatory domain which interact with nuclear proteins to up-regulate and down-regulate, respectively, its activity. In promoting haematopoiesis (i.e. maturation of hematological and immunological cells), GATA2 interacts with other transcription factors (viz., RUNX1, SCL/TAL1, GFI1, GFI1b, MYB, IKZF1, Transcription factor PU.1, LYL1) and cellular receptors (viz., MPL, GPR56).\n\nGATA2 binds to a specific nucleic acid sequence viz., (T/A(GATA)A/G), on the promoter and enhancer sites of its target genes and in doing so either stimulates or suppresses the expression of these target genes. However, there are thousands of sites in human DNA with this nucleotide sequence but, for unknown reasons, GATA2 binds to <1% of these. Furthermore, all members of the GATA transcription factor family bind to this same nucleotide sequence and in doing so may in certain instances serve to interfere with GATA2 binding or even displace the GATA2 that is already bound to these sites. For example, displacement of GATA2 bond to this sequence by the GATA1 transcription factor appears important for the normal development of some types of hematological stem cells. This displacement phenomenon is termed the \"GATA switch\". In all events, the actions of GATA2 in regulating its target genes is extremely complex and not fully understood.\n\nThe age of onset of the GATA2 deficiency is variable with rare individuals showing first signs or symptoms in their infancy and others showing first symptoms or signs at almost any time thereafter including their later years. Rare individuals with inactivating GATA2 mutations may never develop symptoms, i.e. the disorder has a very high but nonetheless incomplete degree of penetrance. This variability can occur between members of the same family who are documented to have the same \"GATA2\" mutation. The many signs and symptoms that are the direct or indirect consequences of GATA2 deficiency organized based on the types of involvement are:\n\n\nDeletion of both \"Gata2\" genes in mice is lethal by day 10 of embryogenesis due to a total failure in the formation of mature blood cells. Inactivation of one mouse \"Gata2\" gene is neither lethal nor associated with most of the signs of human GATA2 deficiency; however, these animals do show a ~50% reduction in their hematopoietic stem cells along with a reduced ability to repopulate the bone marrow of mouse recipients. The latter findings, human clinical studies, and experiments on human tissues support the conclusion that in humans both parental \"GATA2\" genes are required for sufficient numbers of hematopoietic stem cells to emerge from the hemogenic endothelium during embryogenesis and for these cells and subsequent progenitor cells to survive, self-renew, and differentiate into mature cells. As GATA2 deficient individuals age, their deficiency in hematopoietic stem cells worsens, probably as a result of factors such as infections or other stresses. In consequence, the signs and symptoms of their disease appear and/or become progressively more severe.\n\nMonoMAC-afflicted individuals exhibit reduced levels of common lymphoid progenitor cells (i.e. a heterogenous group of precursors to various lymphocyte types) and granulocyte-macrophage progenitor cells (i.e. precursors to granulocytes and monocytes). In mice and presumably humans, GATA2 deficiency also leads to reduced levels of early erythrocyte stem cells. While our understanding of human hematopoiesis is incomplete, it is proposed that these or related progenitor cell reductions causes a progressively worsening depletion of circulating and/or tissue bound B cells, NK cells, T helper cells, monocytes, plasmacytoid dendritic cells, neutrophils, and/or red blood cells. In consequence, GATA2 deficient individuals may exhibit the clinically significant disorders of chronic neutropenia, aplastic anemia, bone marrow failure, or the myelodysplastic syndrome. However, the role of GATA2 deficiency in leading to a leukemias is not understood, particularly since mutations which increase the activity of this transcription factor appear to be associated with the progression of non-familial AML as well as development of the blast crisis in chronic myelogenous leukemia.\n\nThe depletion of hematologic cells, particularly dendritic cells, caused by GATA2 deficiency (see previous section) also appears responsible for the development of defective innate and adaptive immune responses. In consequence, these individuals become increasing susceptibility to infectious agents and to cancers caused by infective agents. This defect in mounting immune responses is mostly restricted to new antigenic challenges. That is, secondary immune responses to which individuals had mounted effective primary immune responses before GATA2 deficiency paralyzed their immune system generally remain intact. Immune system deterioration would also appear responsible for the development of the pathological autoimmune reactions which afflicted individuals may mount against their own tissues.\n\nThe GATA2 transcription factor contributes to controlling the expression of two genes, \"PROX1\" and \"FOXC2\", which are required for the proper development of the lymphathic system, particularly lymph vessel valves. It is proposed that GATA2 deficiency causes a failure to develop competent valves and/or vessels in the lymphatic system and thereby leads to lymphedema.\n\nGATA2 deficiency-induced abnormalities in the lymphatic system are also proposed to be responsible for a failure in generating the perilymphatic space around the inner ear's semicircular canals, which in turn underlies the development of sensorineural hearing loss in GATA2 deficient individuals, particularly those diagnosed with the Emberger syndrome.\n\nThe pathophysiology behind the other defects associated with GATA2 deficiency such as hypothyroidism, endocarditis, pulmonary alveolar proteinosis; cryptogenic organizing pneumonia-like disease, pulmonary hypertension, pulmonary ventilator and diffusion defects, miscarriages, etc., is as yet undefined. It is possible that many of these other defects are secondary, i.e. associated with GATA2 deficiency but not a direct result of low cellular levels of the GATA2 transcription factor.\n\nThe presentations of GATA2 deficiency commonly fall into various categories with MonoMAC and Emberger syndrome in the past and sometimes even currently being considered as separate entities. In most cases, the age of onset and initial signs and symptoms are variable with each presentation often being accompanied by signs or symptoms more typical of other presentations. Nonetheless, most cases of the deficiency exhibit a combination of signs and symptoms that fit the following presentations.\n\nIndividuals afflicted with MonoMAC commonly present in early adulthood afflicted with one or more of the opportunistic infections listed in the above Signs and symptoms section and have profoundly low numbers of circulating monocytes which may have existed for many years before symptoms developed. These individuals also have low numbers of two other types of circulating blood cells viz., B lymphocytes and NK cells. Other presentations and/or developments (see Signs and symptoms)include: 1) pulmonary alveolar proteinosis; 2) tumors caused by opportunistic viral infections; 3) autoimmunity disturbances; and 4) the myelodysplastic syndrome, acute myeloblastic leukemia, or chronic myelomonocytic leukemia.\n\nEmberger syndrome presents as early as infancy but more typically in childhood or early adulthood with lymphedema of the lower limbs or testes, i.e. hydrocele, and congenital sensorineural hearing loss. Afflicted individuals may also exhibit one or more of the dysplasias listed in the above \"Signs and symptoms\" section. These presentations typically occur along side of or are followed by hematalogic abnormalities including but often only after many years or decades seriously life-threatening myelodysplastic syndrome and/or acute myeloid leukemia. Individuals afflicted by the syndrome may also exhibit increased susceptibility to opportunistic viral infections, particularly in individuals that have Null mutations (i.e. mutations that cause complete lose of a functional gene product) in the \"GATA2\" gene.\n\nFamilial MDS/AML is an inherited predisposition to develop MDS, i.e. a disorder characterized by the development of a genetically distinct subpopulation (i.e. clone) of bone marrow hematopoietic stem cells, decreased levels of one or more types of circulating blood cells, and an increased risk of progressing to leukemia, particularly AML. GATA2 deficiency commonly presents as MDS in childhood (usually >4 years of age) and adolescent (generally <18 years of age) individuals and as such is the most common germline mutation responsible for familial MDS/AML in this age group. Inactivating \"GATA2\" mutations appear responsible for ~15% in cases of advanced familial MDS (i.e. cases in which hematologic blast cells are ≥2% in blood or ≥2% but ≤20% in bone marrow) and in 4% of cases diagnosed as low-grade familial MDS (i.e. blast cells are <2% in blood or <5% in blood). Individuals exhibiting >20% blast cells in blood or bone marrow are diagnosed as having AML. Thus, GATA2 deficiency may also present as AML that was preceded by MPS. In about 70% of the cases, the inactivating \"GATA2\" mutations found in Familial MDS/AML are associated with advanced disease and exhibit monosomy of their 7 chromosome. GATA2 deficiency-induced familial MDS/AML is often diagnosed in one member of a family that has other members with identical \"GATA2\" gene mutations but either are classified as having another type of GATA2 deficiency presentation or have no signs or symptoms whatsoever of GATA2 deficiency.\n\nCongenital neutropenia refers to an assorted group of diseases that share a common set of signs and symptoms, viz., neutropenia, i.e. a low circulating blood neutrophil count, increased susceptibility to infections, various organ dysfunctions, and an extraordinarily high risk of developing leukemia. A small percentage of individuals with familial or sporadic GATA2 deficiency present in their childhood with asymptomatic mild neutropenia but no other discernible hematological abnormalities except perhaps monocytopenia and macrocytosis, i.e. enlarged red blood cells. This presentation often persists for years but commonly progresses to include thrombocytopenia, increases susceptibility to infections due to, e.g. atypical mycobacteria or human papillomavirus, dysfunction of non-hematological organs, MDS, and leukemia (primarily AML and less commonly CMML). It is estimated that by age 30, 60% of these individuals develop leukemia. Some of these individuals have large deletion mutations that span the \"GATA2\" along with nearby genes and exhibit in addition to hematological defects various developmental abnormalities, neurological abnormalities, and/or body dysmorphic disorders.\n\nGATA2 deficiency has been diagnosed in up to 10% of individuals presenting with aplastic anemia. It is also the most common cause of hereditary bone marrow failure and may present with this disorder. GATA 2 deficiency has been diagnosed in rare cases presenting as humoral immune deficiency due to B cell depletion, severe Epstein–Barr virus infection, or Epstein-Barr associated cancers. In all of these presentations, individuals may have or develop other manifestations of the deficiency and are of particularly high risk for developing AML or CMML.\n\nRare cases of individuals with GATA2 deficiency may also present with extreme monocytosis (i.e. increases in circulating blood monocytes) or CMML, i.e. monocytosis plus the presence of abnormal (blasts) in the circulation and/or bone marrow. GATA2 deficient individuals who develop CMML often exhibit mutations in one of their \"ASXL1\" genes. Since mutations in this gene are associated with CMML independently of \"GATA2\" mutations, \"ASXL1\" mutations may promote the development of CMML in GATA2 deficiency.\n\nIndividuals with GATA2 deficiency commonly exhibit abnormalities in their circulating blood cells (see above \"Hematologic\" section of Signs and symptoms) that may precede other signs and symptoms of the disease by years. Their bone marrows typically shows significant reductions in one or more types of blood cell lines (i.e. hypocellularity) with characteristic dysplastic features of increased sizes of cells in the red blood cell line (i.e. macrocytic erythropoiesis), small or enlarged megakaryocytes, abnormalities in the maturation of cells in the granulocyte cell line, fibrosis consisting of reticular fibers, increased numbers of T cells containing numerous large granules in their cytoplasm, and in advanced cases increases in blast cell numbers. The bone marrow in advanced cases may also exhibit increase in cellularity, i.e. hypercellularity. GATA2 deficient individuals often have highly increased blood levels of FMS-like tyrosine kinase 3 ligand However, these as well as other features are diagnostic of a hematologic disorder but not necessarily of GATA2 deficiency. DNA sequencing of the full \"GATA2\" gene coding region including the intron4 enhancer by Sanger sequencing or high-throughput methods along with DNA copy number analysis and karyotyping should establish the presence of \"GATA2\" gene mutations; comparison of detected gene mutations to the list of inactivating GATA2 gene mutations plus the clinical presentation and family history are essentials in making the diagnosis of GATA2 deficiency.\n\nThe various interventions recommended for GATA2 deficiency fall into three categories: family counseling, prevention of the disease's many complications, and bone marrow transplantation in an effort to restore GATA2-sufficient stem cells. However, due to the uncommonness of, and only recent appreciation for, the disease, standard phase 2 clinical trials to establish the efficacy of a drug(s), and/or non-drug treatment regiments against an appropriate placebo treatment regimen have not been reported.\n\nFamily members of an individual(s) diagnosed with an inactivating \"GATA2\" gene mutation should be told of their chances of having this mutation, advised of the consequences of this mutation, recommended to be tested for the mutation, warned that they are not suitable donors for any GATA2 deficient individual, and offered long term follow up of their mutation.\n\nRecommendations for individuals exhibiting susceptibility to the infectious complications of GATA2 deficiency (e.g. MonoMAC-afflicted individuals) include: early vaccination for papillomavirus, early vaccination or prophylaxis drug treatment for nontuberculosus mycobacteria, and, perhaps, prophylaxis drug treatment (e.g. Azithromycin) for bacteria. Standard methods are recommended for the prevention of deep vein thrombosis and/or the embolism that occur in lymphedema of the lower extremities and for the blood hypercoagulability state complicating GATA2 insufficiency presentations such as the Emberger syndrome. GATA2 deficient individuals should be routinely monitored by: a) frequent complete blood counts and when indicated bone marrow examinations to detect progression of their disorder to more MDS or leukemia; b) and clinical evaluation of respiratory function and when indicated lung function tests to detect deterioration of lung function,; and c) clinical evaluaton analyses to determine the infection susceptibility, tumor formation, and the worsening function of other organs.\n\nMany authorities currently recommend GATA2 deficiency be treated by a moderately but not maximally aggressive myeloablative conditioning regimen to remove native bone marrow stem/progenitor cells followed by hematopoietic stem cell transplantation to repopulate the bone marrow with GATA2 sufficient stem cells. The use of this procedure should be anticipatory and occur before the development of a hyperellular bone marrow or a bone marrow or blood populated by an excess of progenitor cells (i.e. blast cells >2% to 5%). These developments are often followed by transformation of the disorder to a leukemia. This regiment should also be performed before the development of severe systemic infections, tumors, or deterioration in lung function. disease. While it takes up to 3.5 years for this regiment to fully re-institute good immune function, it significantly reduces susceptibility to infections and infection-induced tumor formation. The regimen also improves or normalizes lung function in cases of pulmonary alveolar proteinosis and pulmonary artery hypertension and may halt the progression or improve the function of other organs directly injured by GATA2 deficiency.\n\nMany reports on the recommended treatment of GATA2 deficiency follow an NIH clinical trial termed \"A Pilot and Feasibility Study of Reduced-Intensity Hematopoietic Stem Cell Transplant regimen for Patients With GATA2 Mutations\". This trial used a regimen of drugs (cyclophosphamide, fludarabine) and total body irradiation conditioning followed by allogenic hematopoietic Stem Cell Transplant on 10 patients. The trial had 8 disease-free survivors and obtained an overall survival 76 months with a range of 18 to 95 months. An NIH intervention study is in the process of recruiting and treating 144 individuals with GATA2 deficiency to determine the success of a treatment regimen consisting of druga (fludarabine, busulfan, cyclophosphamide) and total body irradiation conditioning followed by allogenic hematopoietic stem cell transplantation.\n\nOverall survival in a NIH study using a modest conditioning regimen (see previous section) followed by hematologic stem cell transplantation in GATA2 deficient patients afflicted with immune deficiencies was 54% at 4 years; GATA2 deficient childrent transplanted for MDS with monosomy 7 experienced a 5 year survival of 68%.\n"}
{"id": "23100954", "url": "https://en.wikipedia.org/wiki?curid=23100954", "title": "Global Forum for Health Research", "text": "Global Forum for Health Research\n\nThe Global Forum for Health Research is an international foundation headquartered in Geneva, Switzerland established in 1997 to increase the amount of research into global health issues. It coined the phrase 10/90 gap to identify the observation that only 10% of the world's health research spending is targeted at 90% of present health problems.\n\nThe Global Forum is a partner to the World Health Organization. In her keynote address to the Forum in 1999 Gro Harlem Brundtland, then Director–General of WHO, declared that the Global Forum was key in the involvement of all the various levels, sectors and disciplines of \"development agencies, the research community, health workers and end–users\".\n\nThe Global Forum represents all the parties interested in health research: governments, non-governmental organizations (NGOs), United Nations agencies, research centers, universities, and the pharmaceutical industry. It is run by a governing council and provides support to programmes of research that benefit the developing world. It draws attention to global health research aims with an annual forum that draws together international health researchers and policy makers.\n\nThe Global Forums take place in a different international location each year: Geneva, Bangkok, Arusha, Mexico City, Mumbai, Cairo. The 11th was in Beijing in 2007, the 12th in Bamako, Mali in 2008 and Cuba hosted the 2009 Forum.\n\nAs a non-profit foundation the Global Forum is currently funded by the World Bank, the World Health Organization; the governments of Brazil, Canada, Ireland, Mexico, Norway, Switzerland; and private philanthropy groups including the Rockefeller Foundation.\n\n\n"}
{"id": "48216716", "url": "https://en.wikipedia.org/wiki?curid=48216716", "title": "Global Medical Excellence Cluster", "text": "Global Medical Excellence Cluster\n\nGlobal Medical Excellence Cluster (GMEC) describes the business cluster model formed by premier UK academic institutions with medical centres in biomedical and related technologies and patient care with a view of forging resources and strengths towards medical innovation and healthcare improvement research. Currently, GMEC represents the largest life science bio-cluster in the world.\n\nGMEC was founded by five universities, namely: University of Cambridge, University College London, Imperial College London, King's College London and University of Oxford. It was then joined by Queen Mary University of London in 2012. \n\nGMEC is the UK's answer to the biomedical clusters that is trending in the USA, Europe and Asia, where academia and industry collaborate to deliver medical innovation and generate economic value.\n\n\n"}
{"id": "265751", "url": "https://en.wikipedia.org/wiki?curid=265751", "title": "Health Economics", "text": "Health Economics\n\nHealth Economics is a monthly peer-reviewed academic journal published by John Wiley & Sons, covering the subject of health economics. It was established in 1992.\n\nAccording to the \"Journal Citation Reports\", the journal has a 2011 impact factor of 2.123, ranking it 15th out of 62 journals in the category \"Health Policy & Services\", 27th out of 76 journals in the category \"Health Care Sciences & Services\", and 36th out of 320 journals in the category \"Economics\",\n\n"}
{"id": "23917069", "url": "https://en.wikipedia.org/wiki?curid=23917069", "title": "Health in Kuwait", "text": "Health in Kuwait\n\nLife expectancy at birth in 2013 was 78 for men and 79 for women.\n\nObesity is a growing health concern in Kuwait. According to \"Forbes\" magazine, Kuwait ranked 8 on a 2007 list of fattest countries with a percentage of 74.2% of Kuwait's total population with an unhealthy weight. In 2011, the number of bariatric operations in Kuwait was 5,000.\n\nFrom 1980 to 1993, the percentage of individuals age 18–29 that were overweight rose from 30.6% to 54.4% and the percentage of those who were overweight increased from 12.8% to 24.6%. The number of women who are either overweight or obese has jumped to 80% in 2010. In the book \"Top 10 of Everything 2011\", the women of Kuwait ranked 5th for the highest percentage of obesity. In 2000, it was determined that amongst children age 10–14, 30% of boys and 31.8% of girls were overweight.\n\nAccording to the Dasman Center for Research and Treatment of Diabetes, 15% of the adult population has diabetes, with 50% of adults over 45 living with the disease. 22 of every 100 children have developed diabetes as a result of an unhealthy weight.\n\nThe increased risk of excess weight or obesity is due to a combination of overeating energy-dense, high-fat foods and sedentary lifestyles. Meals consisting of processed ingredients with preservatives, saturated fats, and hydrogenated oil are preferred over traditional foods. Advertisements for unhealthy junk food are seen everywhere and public schools sell candy, chocolate, and soda to their students. Specifically in Kuwaiti universities, other factors include eating between meals, marital status, and a male domination of sports.\n\nA smoking ban in public places was introduced by Law No 15 of 1995 but it is not strictly enforced. New regulations were introduced in 2015.\n\nSmoking while driving is considered one of the major causes of accidents, so that the General Traffic Department is considering enforcing the law that bans motorists smoking inside their vehicles while driving.\n"}
{"id": "35939053", "url": "https://en.wikipedia.org/wiki?curid=35939053", "title": "Hélio Viana", "text": "Hélio Viana\n\nHélio Viana de Freitas is a Brazilian businessman and CEO of World Sports Business and HBusiness Bank.\n\nHe was one of the principal authors of Brazil's Pelé Law of 1998, which abolished the “pass” which tied professional players to clubs, made possible the creation of leagues, and defined the professionalization of soccer. The Pelé Law also established the Consumer Law in Sports, obliged the accountability of managers, and created funding for Olympic and Paralympic sports. Viana also created the Indigenous Olympic Games and the Supportive Sport Program.\n\nHe received a master's degree in Business Administration from Fundação Getúlio Vargas.\nViana was Vice President of the board of the Brazilian National Institute for the Development of Sports (INDESP - \"Instituto Nacional de Desenvolvimento do Desporto\"), the precursor to today’s Ministry of Sports, from 1995 to 1998. The President was Pelé, and other members included Carlos Arthur Nuzman, Hortência Marcari, Carlos Miguel Aidar, Nelson Piquet, Rogério Amato, and Manuel Tubino.\n\nViana designed the Pact of Soccer in 2001, which restructured Brazilian soccer, turning the national championship into consecutive points, and accompanied the organization of four World Cups and three Olympic Games.\n"}
{"id": "533235", "url": "https://en.wikipedia.org/wiki?curid=533235", "title": "International Epidemiological Association", "text": "International Epidemiological Association\n\nThe International Epidemiological Association (IEA) is a worldwide association with more than 2000 members in over 100 different countries, who follow the aims of the association to facilitate communication amongst those engaged in research and teaching of epidemiology throughout the world, and to encourage its use in all fields of health including social, community and preventative medicine. These aims are achieved by holding scientific meetings and seminars, by publication of journals, reports, translations of books, by contact amongst members and by other activities consistent with these aims. Members are accepted without regard to race, religion, sex, political affiliation or country of origin.\n\nThe association publishes its own Journal, the \"International Journal of Epidemiology\" (IJE) , which is published bi-monthly, a complimentary copy of which is included in the membership dues. It also sponsors a number of highly reputable publications such as \"A Dictionary of Epidemiology\", and \"The Development of Modern Epidemiology\" . In addition, the association organizes The World Congress of Epidemiology (WCE) which is held triennially in different parts of the world. The 19th WCE was held in Edinburgh, Scotland, August 2011, while the 20th WCE will be held in Anchorage, Alaska, August 2014 . Regional Scientific Meetings are also held in the IEA regions during three-year periods between WCEs.\n\nThe IEA is in official relations with the World Health Organization (WHO) and is run by a council including executive and regional councilors for its 7 regions in addition to the ex-officio members.\n\nThe objectives of the IEA are to:\n\n\nThese objectives are achieved through networking professionals working in the field of epidemiology through different means, including its website: www.IEAweb.org ; holding national, regional and international scientific meetings and congresses, as well as individual contacts between professional members. These have guided IEA's activities over the years.\n\nA determined effort was made in this decade to develop regional activities and to strengthen IEA links and co-operation with the WHO.\n\nThe International Corresponding Club, as the IEA was first called, was started in 1954 by John Pemberton of Great Britain and Harold N Willard of the United States with the advice and help of Robert Cruickshank. They had found, as traveling Research Fellows each in the other's country, that they were handicapped by not being sufficiently well informed about the research and teaching in the field of social and preventive medicine in the various medical schools and research institutes. Initially it was to try and remedy this defect, that the Club was established on a small and informal basis. At first it was just a corresponding club whose object was ‘to facilitate the communication between physicians working for the most part in university departments of preventive and social medicine, or in research institutes devoted to these aspects of medicine, throughout the world’. This was to be achieved by the publication of a Bulletin twice a year and by members endeavouring to ‘ensure a friendly and hospitable welcome for visitors’ from other countries. The first issue of the Bulletin appeared in January 1955 and contained contributions from 26 correspondents from nine countries.\n\nCorrespondents soon felt the need to meet to discuss research and teaching and the first formal meeting took place at the Ciba Foundation in London at the end of June 1956. By this time there were 49 correspondents from 18 countries, and one of them, A. Querido of Amsterdam invited the Club to hold its First International Scientific Meeting in the Netherlands. As a consequence a ‘Study Group on Current Epidemiological Research’, supported by a grant from the Rockefeller Foundation, took place at Noordwijk in September 1957. There were 58 participants representing 44 university departments from 20 countries at this meeting. A constitution was formulated and the first executive committee was elected. The Noordwijk meeting was the first of the nineteenth international scientific meetings which have been held to date. The second was held in the Universidad del Valle in Cali, Colombia in 1959 when the present title of the association was adopted.\n\nWith few exceptions, the scientific meetings of the association have been held every three years since 1957 in different locations around the world. At the first Council Meeting held in Montreal 17–18 August 2002, it was agreed that all meetings formerly entitled International Scientific Meeting would henceforth be called World Congress of Epidemiology (WCE), with a continued sequence of numbering. Here is a list of the WCE held since 1957:\n\n\nThe IEA has always attached great importance to the educational aspects of its work and its first Chairman, Robert Cruikshank, often used the phrase ‘spreading the gospel’ to describe these aims.\n\nThe meeting in Cali in 1959 stimulated great interest in epidemiology in Colombia and as a result three seminars on epidemiology were later organized by the IEA in that country. This marked the beginning of a series of seminars in the South American continent and the Caribbean area.\n\nThe Milbank Memorial Fund helped to make this extensive series of seminars possible and the WHO, through the Pan American Health Organization, also cooperated in these seminars. By 1977 the IEA had organized, or played a prominent part in, 23 Seminars or Workshops on epidemiology in 19 different countries. These were often conducted in association with the WHO. The association only undertakes to organize or participate in seminars at the invitation of the national or local educational or governmental bodies concerned.\n\nIn 1969 a decision was taken to produce a guide on the teaching of epidemiology which would be suitable for use throughout the world. The WHO agreed to cooperate in this project and Dr Ronald Lowe and Jan Kostrzewski were asked to edit the guide. It was published first in English as Epidemiology: A guide to Teaching Methods and also published in French, German, Polish, Serbo-Croat Slovak, and Spanish editions; and editions in Russian and Slovakare in preparation.\n\nOther of the classic texts sponsored by the IEA in collaboration with Oxford University Press is ‘A Dictionary of Epidemiology’ which remains the definitive dictionary in epidemiology worldwide. In fact, with contributions from over 220 epidemiologists and other users of epidemiology from around the globe, it is more than a dictionary: it includes explanations and comments on both core epidemiologic terms and on other scientific terms relevant to all professionals in clinical medicine and public health, as well as to professionals in the other health, life, and social sciences. The aim of the IEA in cosponsoring this dictionary in its more than 20 years’ history has been to facilitate communication among epidemiologist to develop a \"common language\" to the extent that this is possible. The first fourth editions of the dictionary were edited by John Last and the fifth edition was edited by Miquel Porta. In addition, the IEA has produced a publication to commemorate its 50th anniversary called \"History of Modern Epidemiology\" in addition to supporting 3 editions of the important publication \"Teaching Epidemiology\" . The IEA offers a free copy of one of the first two publications as an incentive for life-time (10-years) or 3-year membership.\n\nThe IEA also comments on current topical issues in epidemiology through a series of online \"rapid response\" commentaries .\n\nAn important decision was taken at the Sixth International Meeting in 1971 to found an international quarterly journal of epidemiology. The council believed that the journal could replace the old Bulletin in providing a link between members in intervals between international meetings by publishing association news, and serve a valuable purpose by publishing original articles in the field of epidemiology. Walter W. Holland was appointed the first editor in 1972. The IJE continues to go from strength to strength. Between 2001 - 2016 under the editorship of George Davey Smith and Shah Ebrahim, the journal expanded. They introduced a number of new features and the positive effects of these changes are reflected in its improved impact factor (7.2 in 2015), which places it first among the international epidemiology journals. Six issues of the journal are published every year. Stephen Leeder took over as editor in 2017.\n\nThe association has a long tradition of collaboration with other organizations, particularly with the WHO and the Council for International Organizations of Medical Sciences (CIOMS) and International Clinical Epidemiologic Network (INCLEN) .\n\nThe IEA became affiliated with the CIOMS in 1955 and was represented on its executive committee. This affiliation led the association to the participation in preparing the international ethical guidelines for epidemiological studies, recognized by WHO as a key reference.\n\nIn 1966 the association was recognized by the WHO as a Non-Governmental Organization. In addition to representation at the World Health Assembly and regional committees, this affiliation contributed to excellent working relationships with WHO in the planning and execution of educational programmes of the IEA and in the production of the \"Guide to Teaching Epidemiology\".\n\nThe IEA is also an active member of the Countdown initiative, and provides oversight on data quality, analyses and interpretation. The Countdown to 2015: Maternal, Newborn and Child Health is a global initiative that includes academics and representatives of multilateral and bilateral agencies, professional organizations and civil society who share the common goal of increasing accountability for progress towards the Millennium Development Goals for improving the health of mothers and children.\n\nIn the earlier years of the IEA, British and North American members were in the majority, mainly because the association had its origins in the UK and US. The council of the association has always been very conscious of this tendency and made active efforts to broaden the representativeness of the association by encouraging members to nominate epidemiologists from other countries. Nowadays, membership is growing in the association, with over 2,000 current members from around the world. Current membership categories include:\n\n\nThe IEA has recently introduced a scheme of joint membership with various national epidemiological societies. Members of participating national societies join IEA at 30% of the usual rate and have all of the benefits of regular IEA membership, except that they receive the e-version of the IJE only. Joint membership have established with the following associations:\n\nThe development and strengthening of regional activities is manifested by the record of the regional meetings. These have been stimulating affairs as shown by the publications which resulted. There have been regular meetings in most IEA Regions, including: Africa, South-East Asia, Eastern Mediterranean, Europe, Latin America & Caribbean, North America and Western Pacific and occasional ones in the remainder. Of particular note have been those which marked the foundation and strength of national epidemiological associations as in Japan, China and Holland. The growth and interest in epidemiology and the enormous improvement in the quality, as well as the quantity of epidemiological research has been particularly notable in some IEA regions as South East Asia. For example, the Australian Regional IEA meeting in 1973 was attended by 9 Japanese - at that time the only such practicing scientists in that country. There was, by 1995, a flourishing national association with more than 900 members and its own Journal published in English. It was the host for the 1996 International Scientific Meeting (ISM). The number of participants, at Regional Meetings in this area e.g. from China, Indonesia, Malaysia, Philippines, Singapore and Thailand illustrate the increasing penetration of Epidemiology discipline.\n\nThe growth and strengthening of Epidemiology discipline outside Western Europe and North America has also led to increase in bids to act as hosts for ISMs, now known as WCEs.\n\nRegional meetings are held in the years between the WCEs.\n\nIn effort of enforcing the capacity building role of IEA and moving the 20-year-old Florence course to the south, IEA has started an annual short-course in epidemiological methods. Indeed, the course is allied to the IEA-sponsored European Educational Programme in Epidemiology , annually held in Florence for three weeks every June/July, under the directorship of Rodolfo Saracci, for more than 2 decades. Thus, such course is intended as a \"Florence South\" course, run annually on a five-year cycle of the IEA regions outside of Europe and North America (South East Asia, Eastern Mediterranean, Africa, Latin America and Western Pacific). Introductory, intermediate and advance level courses are offered to provide epidemiologists and public health professionals an opportunity to become acquainted with the advances in epidemiologic methods that can enhance the role of epidemiology in clinical medicine and public health. These courses are addressed to epidemiologists, public health professionals, statisticians, and clinicians and include lectures, computer based analyses, exercises, discussion sessions, and practical experience in the design of a research proposal. The first course was held in Jaipur, India, in April 2009, the second in Riyadh, Saudi Arabia in April, 2010, the third in Malawi in April 2011, while the latest was held in Lima, Peru during May 2012. It is planned to have the upcoming course in Hangzhou, China, 2013 .\n\nThe IEA also sponsors pre-conference courses prior to the WCE.\n\nIn commemoration of Sir Richard Doll, IEA established in 2007 the \"Richard Doll Prize in Epidemiology\" to be awarded on triennial basis. The prize is awarded to an epidemiologist of the highest scientific standard. The recipient is honored for his/her scientific achievements that have advanced our understanding of the determinants of a disease of importance for health in populations through a body of research that may involve a series of studies, rather than a single publication. The prize winner is selected by a committee which includes current IEA president, president-elect, past-president in addition to two members appointed by the IEA Council. The prize is presented at the triennial WCE as $30,000 and a special plaque. The first prize has been conferred in 2008 to Prof , while the second was awarded to Prof David Barker in 2011.\n\nThe IEA Executive Committee recently decided to create an International (worldwide) Early Career Epidemiologists group (ECE) within the IEA structure. A successful first meeting of ECE was held during the XIX IEA World Congress of Epidemiology (WCE) in Edinburgh (Scotland). The aims of this group are similar to those of the IEA, with a focus on identifying tools and opportunities to develop knowledge and careers for emerging professionals engaged in the field of epidemiology throughout the world. The IEA has decided to invest effort and resources in ensuring the connectivity among ECE and thus facilitate the promulgation of opportunities for IEA training events, a mentoring scheme, and other activities which promote the advance and appropriate use of the epidemiological methods and its development in all regions.\n\nThe educational work of the IEA has always been regarded as one of its most important functions. This will continue through the media of the \"International Journal of Epidemiology\" and the International and Regional Scientific meetings. It is hoped that the IEA will be able to continue to play a part in the organization of seminars particularly in those parts of the world where epidemiology is not well developed. Owing to the lack of funds for this purpose such activities may have to be confined, for the present, to co-operation with national or international organizations, in particular the WHO, by providing faculty members and resource material rather than funds.\n\nThere was general support for continued regional development at the Seventh International Meeting and the first steps were taken towards the organization of further regional meetings. The previous council recommended that regional IEA councils covering the WHO regions should be established in order to stimulate recruitment of members and the organization of international meetings within regions. The present council consists of members from all the WHO regions and it is now considering the whole question of regional development.\n\n"}
{"id": "2767240", "url": "https://en.wikipedia.org/wiki?curid=2767240", "title": "Jacques Balmat", "text": "Jacques Balmat\n\nJacques Balmat, called \"le Mont Blanc\" (1762–1834) was a mountaineer, a Savoyard mountain guide, born in the Chamonix valley in Savoy, at this time part of the Kingdom of Sardinia.\n\nA chamois hunter and collector of crystals, Balmat completed the first ascent of Mont Blanc with physician Michel-Gabriel Paccard on 8 August 1786. For this feat, King Victor Amadeus III gave him the honorary title \"le Mont Blanc\".\n\nBalmat and Paccard's ascent of Mont Blanc was a major accomplishment in the early history of mountaineering. C. Douglas Milner wrote \"The ascent itself was magnificent; an amazing feat of endurance and sustained courage, carried through by these two men only, unroped and without ice axes, heavily burdened with scientific equipment and with long iron-pointed batons. The fortunate weather and a moon alone ensured their return alive.\"\n\nEric Shipton wrote \"Theirs was an astounding achievement of courage and determination, one of the greatest in the annals of mountaineering. It was accomplished by men who were not only on unexplored ground but on a route that all the guides believed to be impossible.\"\n\nGaston Rébuffat praised Balmat's climbing abilities, describing him as \"This man, robust, resolute, this crystal hunter who, as it turns out, possesses an extraordinary mountaineering sense, an unerring instinct for the crevasses and seracs of the glaciers ...\"\n\nAfter the successful ascent, Balmat collected the reward offered 25 years before by Horace-Bénédict de Saussure to the first man who could climb Mont Blanc. On 3 August 1787 he assisted de Saussure himself to reach the summit with a party of about 17 people.\n\nDuring the Napoleonic Wars, Savoy fell under French control, and Citizen Jacques Balmat became a member of the council of the commune. He led an unsuccessful attempt to introduce Merino sheep into the Chamonix valley.\n\nBalmat was criticized for his autobiographical account of the climb, later published in English as \"Jacques Balmat, or The First Ascent of Mont Blanc\", since his account downplayed the role of Dr. Paccard. Milner describes Balmat's story as \"cloudily romantic and largely fictional\" and quotes four analysts of mountaineering history who discovered errors in Balmat's version of events.\n\nShipton describes Balmat as \"boastful and conceited\" and that \"in character, he was both vain and mean. Success went to his head, and he soon began to amplify his part in the exploit.\"\n\nBalmat died by falling off a cliff while prospecting for gold in the Sixt valley in 1834.\n"}
{"id": "14833745", "url": "https://en.wikipedia.org/wiki?curid=14833745", "title": "John Buse", "text": "John Buse\n\nJohn B. Buse formerly held the position of President, Medicine & Science on the board of the American Diabetes Association during 2008. Buse currently serves as the Director of the Diabetes Care Center at UNC.\n\nBuse attended high school at Porter-Gaud School School in Charleston, South Carolina, SC. He went on to receive his Bachelor's degree in Biochemistry from Dartmouth College and his Medical and Doctoral degrees from Duke University. He completed his internship and residency in internal medicine and his fellowship in endocrinology at the University of Chicago. He was renowned for the large, round glasses and bushy mustache that he wore until the mid-1990s. He is the brother of Paul Buse, MD.\n"}
{"id": "41114766", "url": "https://en.wikipedia.org/wiki?curid=41114766", "title": "Kenya Red Cross Society", "text": "Kenya Red Cross Society\n\nKenya Red Cross is one of the many International Red Cross and Red Crescent Movement societies around the world. The Kenya organisation was established in 1965, The Kenya Red Cross supports and runs a number of projects whilst raising awareness to the Kenyan public about the current issues or problems which may affect them. Some of the projects which are either run by or assisted by the Kenya Red Cross are Famine, blood services, first aid projects, disaster and emergency services and education services.\n\nThe patron of the Kenya Red Cross is Uhuru Kenyatta, President of Kenya. A council administers and performs a limited number of duties, and is made up of the Secretary General and twelve voting members. All other responsibilities are held by the Board which consists of 16 persons.\n\nTo supplement its humanitarian efforts, Kenya Red Cross launched a state-of-the art and first of its kind humanitarian app; the KRCS App that offers users real-time emergency alerts and life-saving tips, activities, easy access to Membership and Volunteerism, events and training from Kenya Red Cross, job posts plus different groups such as blood groups, youth groups and volunteer groups where members can connect and share ideas. \n\n"}
{"id": "39875921", "url": "https://en.wikipedia.org/wiki?curid=39875921", "title": "Landau reflex", "text": "Landau reflex\n\nLandau reflex or Landau reaction refers to a reflex seen in infants when held horizontally in the air in the prone position. It emerges 3 months after birth and lasts until up to 12 months to 24 months of age. A normal response of infants when held in a horizontal prone position is to maintain a convex arc with the head raised and the legs slightly flexed. It is poor in those with floppy infant syndrome and exaggerated in hypertonic and opisthotonic infants.\n\nAn abnormal Landau reflex may indicate hypotonia or hypertonia and may indicate a motor development issue.\n"}
{"id": "36786006", "url": "https://en.wikipedia.org/wiki?curid=36786006", "title": "Life Study (project)", "text": "Life Study (project)\n\nLife Study is a cross-disciplinary research study that will look at the health and wellbeing of thousands of children across the UK. It will collect a large amount of information on the health, growth and life factors of a new generation of children born in the UK. \nThis study will create a large storehouse of social, medical and environmental information and linked routine health data for use by UK academics and policy communities. The information in this storehouse resource will help answer questions regarding early life development of health and disease, and physical, psychological and social well-being.\n\nIt is funded by the UK Department for Business, Innovation and Skills (BIS), Economic and Social Research Council (ESRC) and Medical Research Council (MRC) academics from the Institute of Child Health's Paediatric Epidemiology Unit at University College London (UCL) are leading the study, with Professor Carol Dezateux the Director of the project.\n\nThe study aims to understand how biological and environmental factors interact with a baby's early life experiences and the outcomes this has later in life. The study will cover five main research themes:\n\n\nThis will be the fifth UK birth cohort study (beginning in 1946) which have followed the lives of children from birth to adult life. As was the case with these earlier studies, Life Study will provide a wide range of new information into the health, growth and life factors of this new generation of UK children.\n\nThe Economic and Social Research Council (ESRC) and the Medical Research Council (MRC) discontinued Research Councils’ funding for Life Study in early 2016 due to the challenges encountered in recruiting participants.\n"}
{"id": "47941120", "url": "https://en.wikipedia.org/wiki?curid=47941120", "title": "List of dental journals", "text": "List of dental journals\n\nThis is a list of medical journals in dentistry by specialty.\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "45397625", "url": "https://en.wikipedia.org/wiki?curid=45397625", "title": "List of websites about food and drink", "text": "List of websites about food and drink\n\nThis is a list of websites about food and drink.\n\n"}
{"id": "20423", "url": "https://en.wikipedia.org/wiki?curid=20423", "title": "Malaria", "text": "Malaria\n\nMalaria is a mosquito-borne infectious disease affecting humans and other animals caused by parasitic single-celled microorganisms belonging to the \"Plasmodium\" group. Malaria causes symptoms that typically include fever, tiredness, vomiting, and headaches. In severe cases it can cause yellow skin, seizures, coma, or death. Symptoms usually begin ten to fifteen days after being bitten by an infected mosquito. If not properly treated, people may have recurrences of the disease months later. In those who have recently survived an infection, reinfection usually causes milder symptoms. This partial resistance disappears over months to years if the person has no continuing exposure to malaria.\nThe disease is most commonly transmitted by an infected female \"Anopheles\" mosquito. The mosquito bite introduces the parasites from the mosquito's saliva into a person's blood. The parasites travel to the liver where they mature and reproduce. Five species of \"Plasmodium\" can infect and be spread by humans. Most deaths are caused by \"P. falciparum\" because \"P. vivax\", \"P. ovale\", and \"P. malariae\" generally cause a milder form of malaria. The species \"P. knowlesi\" rarely causes disease in humans. Malaria is typically diagnosed by the microscopic examination of blood using blood films, or with antigen-based rapid diagnostic tests. Methods that use the polymerase chain reaction to detect the parasite's DNA have been developed, but are not widely used in areas where malaria is common due to their cost and complexity.\nThe risk of disease can be reduced by preventing mosquito bites through the use of mosquito nets and insect repellents, or with mosquito control measures such as spraying insecticides and draining standing water. Several medications are available to prevent malaria in travellers to areas where the disease is common. Occasional doses of the combination medication sulfadoxine/pyrimethamine are recommended in infants and after the first trimester of pregnancy in areas with high rates of malaria. Despite a need, no effective vaccine exists, although efforts to develop one are ongoing. The recommended treatment for malaria is a combination of antimalarial medications that includes an artemisinin. The second medication may be either mefloquine, lumefantrine, or sulfadoxine/pyrimethamine. Quinine along with doxycycline may be used if an artemisinin is not available. It is recommended that in areas where the disease is common, malaria is confirmed if possible before treatment is started due to concerns of increasing drug resistance. Resistance among the parasites has developed to several antimalarial medications; for example, chloroquine-resistant \"P. falciparum\" has spread to most malarial areas, and resistance to artemisinin has become a problem in some parts of Southeast Asia.\nThe disease is widespread in the tropical and subtropical regions that exist in a broad band around the equator. This includes much of Sub-Saharan Africa, Asia, and Latin America. In 2016, there were 216 million cases of malaria worldwide resulting in an estimated 445,000 to 731,000 deaths. Approximately 90% of both cases and deaths occurred in Africa. Rates of disease have decreased from 2000 to 2015 by 37%, but increased from 2014 during which there were 198 million cases. Malaria is commonly associated with poverty and has a major negative effect on economic development. In Africa, it is estimated to result in losses of US$12 billion a year due to increased healthcare costs, lost ability to work, and negative effects on tourism.\n\nThe signs and symptoms of malaria typically begin 8–25 days following infection, but may occur later in those who have taken antimalarial medications as prevention. Initial manifestations of the disease—common to all malaria species—are similar to flu-like symptoms, and can resemble other conditions such as sepsis, gastroenteritis, and viral diseases. The presentation may include headache, fever, shivering, joint pain, vomiting, hemolytic anemia, jaundice, hemoglobin in the urine, retinal damage, and convulsions.\n\nThe classic symptom of malaria is paroxysm—a cyclical occurrence of sudden coldness followed by shivering and then fever and sweating, occurring every two days (tertian fever) in \"P. vivax\" and \"P. ovale\" infections, and every three days (quartan fever) for \"P. malariae\". \"P. falciparum\" infection can cause recurrent fever every 36–48 hours, or a less pronounced and almost continuous fever.\n\nSevere malaria is usually caused by \"P. falciparum\" (often referred to as falciparum malaria). Symptoms of falciparum malaria arise 9–30 days after infection. Individuals with cerebral malaria frequently exhibit neurological symptoms, including abnormal posturing, nystagmus, conjugate gaze palsy (failure of the eyes to turn together in the same direction), opisthotonus, seizures, or coma.\n\nMalaria has several serious complications. Among these is the development of respiratory distress, which occurs in up to 25% of adults and 40% of children with severe \"P. falciparum\" malaria. Possible causes include respiratory compensation of metabolic acidosis, noncardiogenic pulmonary oedema, concomitant pneumonia, and severe anaemia. Although rare in young children with severe malaria, acute respiratory distress syndrome occurs in 5–25% of adults and up to 29% of pregnant women. Coinfection of HIV with malaria increases mortality. Renal failure is a feature of blackwater fever, where hemoglobin from lysed red blood cells leaks into the urine.\n\nInfection with \"P. falciparum\" may result in cerebral malaria, a form of severe malaria that involves encephalopathy. It is associated with retinal whitening, which may be a useful clinical sign in distinguishing malaria from other causes of fever. Enlarged spleen, enlarged liver or both of these, severe headache, low blood sugar, and hemoglobin in the urine with renal failure may occur. Complications may include spontaneous bleeding, coagulopathy, and shock.\n\nMalaria in pregnant women is an important cause of stillbirths, infant mortality, abortion and low birth weight, particularly in \"P. falciparum\" infection, but also with \"P. vivax\".\n\nMalaria parasites belong to the genus \"Plasmodium\" (phylum Apicomplexa). In humans, malaria is caused by \"P. falciparum\", \"P. malariae\", \"P. ovale\", \"P. vivax\" and \"P. knowlesi\". Among those infected, \"P. falciparum\" is the most common species identified (~75%) followed by \"P. vivax\" (~20%). Although \"P. falciparum\" traditionally accounts for the majority of deaths, recent evidence suggests that \"P. vivax\" malaria is associated with potentially life-threatening conditions about as often as with a diagnosis of \"P. falciparum\" infection. \"P. vivax \" proportionally is more common outside Africa. There have been documented human infections with several species of \"Plasmodium\" from higher apes; however, except for \"P. knowlesi\"—a zoonotic species that causes malaria in macaques—these are mostly of limited public health importance.\n\nIn the life cycle of \"Plasmodium\", a female \"Anopheles\" mosquito (the definitive host) transmits a motile infective form (called the sporozoite) to a vertebrate host such as a human (the secondary host), thus acting as a transmission vector. A sporozoite travels through the blood vessels to liver cells (hepatocytes), where it reproduces asexually (tissue schizogony), producing thousands of merozoites. These infect new red blood cells and initiate a series of asexual multiplication cycles (blood schizogony) that produce 8 to 24 new infective merozoites, at which point the cells burst and the infective cycle begins anew.\n\nOther merozoites develop into immature gametocytes, which are the precursors of male and female gametes. When a fertilized mosquito bites an infected person, gametocytes are taken up with the blood and mature in the mosquito gut. The male and female gametocytes fuse and form an ookinete—a fertilized, motile zygote. Ookinetes develop into new sporozoites that migrate to the insect's salivary glands, ready to infect a new vertebrate host. The sporozoites are injected into the skin, in the saliva, when the mosquito takes a subsequent blood meal.\n\nOnly female mosquitoes feed on blood; male mosquitoes feed on plant nectar and do not transmit the disease. Females of the mosquito genus \"Anopheles\" prefer to feed at night. They usually start searching for a meal at dusk and will continue throughout the night until taking a meal. Malaria parasites can also be transmitted by blood transfusions, although this is rare.\n\nSymptoms of malaria can recur after varying symptom-free periods. Depending upon the cause, recurrence can be classified as either recrudescence, relapse, or reinfection. Recrudescence is when symptoms return after a symptom-free period. It is caused by parasites surviving in the blood as a result of inadequate or ineffective treatment. Relapse is when symptoms reappear after the parasites have been eliminated from blood but persist as dormant hypnozoites in liver cells. Relapse commonly occurs between 8–24 weeks and is often seen in \"P. vivax\" and \"P. ovale\" infections. However, relapse-like \"P. vivax\" recurrences are probably being over-attributed to hypnozoite activation. Some of them might have an extra-vascular merozoite origin, making these recurrences recrudescences, not relapses. One newly recognized, non-hypnozoite, possible contributing source to recurrent peripheral \"P. vivax\" parasitemia is erythrocytic forms in bone marrow. \"P. vivax\" malaria cases in temperate areas often involve overwintering by hypnozoites, with relapses beginning the year after the mosquito bite. Reinfection means the parasite that caused the past infection was eliminated from the body but a new parasite was introduced. Reinfection cannot readily be distinguished from recrudescence, although recurrence of infection within two weeks of treatment for the initial infection is typically attributed to treatment failure. People may develop some immunity when exposed to frequent infections.\n\nGlobal climate change is likely to affect malaria transmission, but the degree of effect and the areas effected is uncertain. Greater rainfall in certain areas of India and following an El Nino event is associated with increased mosquito numbers.\n\nMalaria infection develops via two phases: one that involves the liver (exoerythrocytic phase), and one that involves red blood cells, or erythrocytes (erythrocytic phase). When an infected mosquito pierces a person's skin to take a blood meal, sporozoites in the mosquito's saliva enter the bloodstream and migrate to the liver where they infect hepatocytes, multiplying asexually and asymptomatically for a period of 8–30 days.\n\nAfter a potential dormant period in the liver, these organisms differentiate to yield thousands of merozoites, which, following rupture of their host cells, escape into the blood and infect red blood cells to begin the erythrocytic stage of the life cycle. The parasite escapes from the liver undetected by wrapping itself in the cell membrane of the infected host liver cell.\n\nWithin the red blood cells, the parasites multiply further, again asexually, periodically breaking out of their host cells to invade fresh red blood cells. Several such amplification cycles occur. Thus, classical descriptions of waves of fever arise from simultaneous waves of merozoites escaping and infecting red blood cells.\n\nSome \"P. vivax\" sporozoites do not immediately develop into exoerythrocytic-phase merozoites, but instead, produce hypnozoites that remain dormant for periods ranging from several months (7–10 months is typical) to several years. After a period of dormancy, they reactivate and produce merozoites. Hypnozoites are responsible for long incubation and late relapses in \"P. vivax\" infections, although their existence in \"P. ovale\" is uncertain.\n\nThe parasite is relatively protected from attack by the body's immune system because for most of its human life cycle it resides within the liver and blood cells and is relatively invisible to immune surveillance. However, circulating infected blood cells are destroyed in the spleen. To avoid this fate, the \"P. falciparum\" parasite displays adhesive proteins on the surface of the infected blood cells, causing the blood cells to stick to the walls of small blood vessels, thereby sequestering the parasite from passage through the general circulation and the spleen. The blockage of the microvasculature causes symptoms such as in placental malaria. Sequestered red blood cells can breach the blood–brain barrier and cause cerebral malaria.\n\nAccording to a 2005 review, due to the high levels of mortality and morbidity caused by malaria—especially the \"P. falciparum\" species—it has placed the greatest selective pressure on the human genome in recent history. Several genetic factors provide some resistance to it including sickle cell trait, thalassaemia traits, glucose-6-phosphate dehydrogenase deficiency, and the absence of Duffy antigens on red blood cells.\n\nThe impact of sickle cell trait on malaria immunity illustrates some evolutionary trade-offs that have occurred because of endemic malaria. Sickle cell trait causes a change in the hemoglobin molecule in the blood. Normally, red blood cells have a very flexible, biconcave shape that allows them to move through narrow capillaries; however, when the modified hemoglobin S molecules are exposed to low amounts of oxygen, or crowd together due to dehydration, they can stick together forming strands that cause the cell to sickle or distort into a curved shape. In these strands the molecule is not as effective in taking or releasing oxygen, and the cell is not flexible enough to circulate freely. In the early stages of malaria, the parasite can cause infected red cells to sickle, and so they are removed from circulation sooner. This reduces the frequency with which malaria parasites complete their life cycle in the cell. Individuals who are homozygous (with two copies of the abnormal hemoglobin beta allele) have sickle-cell anaemia, while those who are heterozygous (with one abnormal allele and one normal allele) experience resistance to malaria without severe anemia. Although the shorter life expectancy for those with the homozygous condition would tend to disfavor the trait's survival, the trait is preserved in malaria-prone regions because of the benefits provided by the heterozygous form.\n\nLiver dysfunction as a result of malaria is uncommon and usually only occurs in those with another liver condition such as viral hepatitis or chronic liver disease. The syndrome is sometimes called \"malarial hepatitis\". While it has been considered a rare occurrence, malarial hepatopathy has seen an increase, particularly in Southeast Asia and India. Liver compromise in people with malaria correlates with a greater likelihood of complications and death.\n\nOwing to the non-specific nature of the presentation of symptoms, diagnosis of malaria in non-endemic areas requires a high degree of suspicion, which might be elicited by any of the following: recent travel history, enlarged spleen, fever, low number of platelets in the blood, and higher-than-normal levels of bilirubin in the blood combined with a normal level of white blood cells. Reports in 2016 and 2017 from countries were malaria is common suggest high levels of over diagnosis due to insufficient or inaccurate laboratory testing.\n\nMalaria is usually confirmed by the microscopic examination of blood films or by antigen-based rapid diagnostic tests (RDT). In some areas, RDTs need to be able to distinguish whether the malaria symptoms are caused by \"Plasmodium falciparum\" or by other species of parasites since treatment strategies could differ for non-\"P. falciparum\" infections. Microscopy is the most commonly used method to detect the malarial parasite—about 165 million blood films were examined for malaria in 2010. Despite its widespread usage, diagnosis by microscopy suffers from two main drawbacks: many settings (especially rural) are not equipped to perform the test, and the accuracy of the results depends on both the skill of the person examining the blood film and the levels of the parasite in the blood. The sensitivity of blood films ranges from 75–90% in optimum conditions, to as low as 50%. Commercially available RDTs are often more accurate than blood films at predicting the presence of malaria parasites, but they are widely variable in diagnostic sensitivity and specificity depending on manufacturer, and are unable to tell how many parasites are present.\n\nIn regions where laboratory tests are readily available, malaria should be suspected, and tested for, in any unwell person who has been in an area where malaria is endemic. In areas that cannot afford laboratory diagnostic tests, it has become common to use only a history of fever as the indication to treat for malaria—thus the common teaching \"fever equals malaria unless proven otherwise\". A drawback of this practice is overdiagnosis of malaria and mismanagement of non-malarial fever, which wastes limited resources, erodes confidence in the health care system, and contributes to drug resistance. Although polymerase chain reaction-based tests have been developed, they are not widely used in areas where malaria is common as of 2012, due to their complexity.\n\nMalaria is classified into either \"severe\" or \"uncomplicated\" by the World Health Organization (WHO). It is deemed severe when \"any\" of the following criteria are present, otherwise it is considered uncomplicated.\n\nCerebral malaria is defined as a severe \"P. falciparum\"-malaria presenting with neurological symptoms, including coma (with a Glasgow coma scale less than 11, or a Blantyre coma scale less than 3), or with a coma that lasts longer than 30 minutes after a seizure.\n\nVarious types of malaria have been called by the names below:\n\nMethods used to prevent malaria include medications, mosquito elimination and the prevention of bites. There is no vaccine for malaria. The presence of malaria in an area requires a combination of high human population density, high anopheles mosquito population density and high rates of transmission from humans to mosquitoes and from mosquitoes to humans. If any of these is lowered sufficiently, the parasite will eventually disappear from that area, as happened in North America, Europe and parts of the Middle East. However, unless the parasite is eliminated from the whole world, it could become re-established if conditions revert to a combination that favors the parasite's reproduction. Furthermore, the cost per person of eliminating anopheles mosquitoes rises with decreasing population density, making it economically unfeasible in some areas.\n\nPrevention of malaria may be more cost-effective than treatment of the disease in the long run, but the initial costs required are out of reach of many of the world's poorest people. There is a wide difference in the costs of control (i.e. maintenance of low endemicity) and elimination programs between countries. For example, in China—whose government in 2010 announced a strategy to pursue malaria elimination in the Chinese provinces—the required investment is a small proportion of public expenditure on health. In contrast, a similar program in Tanzania would cost an estimated one-fifth of the public health budget.\n\nIn areas where malaria is common, children under five years old often have anemia which is sometimes due to malaria. Giving children with anemia in these areas preventive antimalarial medication improves red blood cell levels slightly but did not affect the risk of death or need for hospitalization.\n\nVector control refers to methods used to decrease malaria by reducing the levels of transmission by mosquitoes. For individual protection, the most effective insect repellents are based on DEET or picaridin. Insecticide-treated mosquito nets (ITNs) and indoor residual spraying (IRS) have been shown to be highly effective in preventing malaria among children in areas where malaria is common. Prompt treatment of confirmed cases with artemisinin-based combination therapies (ACTs) may also reduce transmission.\n\nMosquito nets help keep mosquitoes away from people and reduce infection rates and transmission of malaria. Nets are not a perfect barrier and are often treated with an insecticide designed to kill the mosquito before it has time to find a way past the net. Insecticide-treated nets are estimated to be twice as effective as untreated nets and offer greater than 70% protection compared with no net. Between 2000 and 2008, the use of ITNs saved the lives of an estimated 250,000 infants in Sub-Saharan Africa. About 13% of households in Sub-Saharan countries owned ITNs in 2007 and 31% of African households were estimated to own at least one ITN in 2008. In 2000, 1.7 million (1.8%) African children living in areas of the world where malaria is common were protected by an ITN. That number increased to 20.3 million (18.5%) African children using ITNs in 2007, leaving 89.6 million children unprotected and to 68% African children using mosquito nets in 2015. Most nets are impregnated with pyrethroids, a class of insecticides with low toxicity. They are most effective when used from dusk to dawn. It is recommended to hang a large \"bed net\" above the center of a bed and either tuck the edges under the mattress or make sure it is large enough such that it touches the ground.\nIndoor residual spraying is the spraying of insecticides on the walls inside a home. After feeding, many mosquitoes rest on a nearby surface while digesting the bloodmeal, so if the walls of houses have been coated with insecticides, the resting mosquitoes can be killed before they can bite another person and transfer the malaria parasite. As of 2006, the World Health Organization recommends 12 insecticides in IRS operations, including DDT and the pyrethroids cyfluthrin and deltamethrin. This public health use of small amounts of DDT is permitted under the Stockholm Convention, which prohibits its agricultural use. One problem with all forms of IRS is insecticide resistance. Mosquitoes affected by IRS tend to rest and live indoors, and due to the irritation caused by spraying, their descendants tend to rest and live outdoors, meaning that they are less affected by the IRS.\nThere are a number of other methods to reduce mosquito bites and slow the spread of malaria. Efforts to decrease mosquito larva by decreasing the availability of open water in which they develop or by adding substances to decrease their development is effective in some locations. Electronic mosquito repellent devices which make very high-frequency sounds that are supposed to keep female mosquitoes away, do not have supporting evidence.\n\nCommunity participation and health education strategies promoting awareness of malaria and the importance of control measures have been successfully used to reduce the incidence of malaria in some areas of the developing world. Recognizing the disease in the early stages can prevent the disease from becoming fatal. Education can also inform people to cover over areas of stagnant, still water, such as water tanks that are ideal breeding grounds for the parasite and mosquito, thus cutting down the risk of the transmission between people. This is generally used in urban areas where there are large centers of population in a confined space and transmission would be most likely in these areas. Intermittent preventive therapy is another intervention that has been used successfully to control malaria in pregnant women and infants, and in preschool children where transmission is seasonal.\n\nThere are a number of medications that can help prevent or interrupt malaria in travelers to places where infection is common. Many of these medications are also used in treatment. In places where \"Plasmodium\" is resistant to one or more medications, three medications—mefloquine, doxycycline , or the combination of atovaquone/proguanil (\"Malarone\")—are frequently used for prevention. Doxycycline and the atovaquone/proguanil are better tolerated while mefloquine is taken once a week. Areas of the world with chloroquine sensitive malaria are uncommon.\n\nThe protective effect does not begin immediately, and people visiting areas where malaria exists usually start taking the drugs one to two weeks before arriving and continue taking them for four weeks after leaving (except for atovaquone/proguanil, which only needs to be started two days before and continued for seven days afterward). The use of preventative drugs is often not practical for those who live in areas where malaria exists, and their use is usually only in pregnant women and short-term visitors. This is due to the cost of the drugs, side effects from long-term use, and the difficulty in obtaining anti-malarial drugs outside of wealthy nations. During pregnancy, medication to prevent malaria has been found to improve the weight of the baby at birth and decrease the risk of anemia in the mother. The use of preventative drugs where malaria-bearing mosquitoes are present may encourage the development of partial resistance.\n\nMalaria is treated with antimalarial medications; the ones used depends on the type and severity of the disease. While medications against fever are commonly used, their effects on outcomes are not clear.\nSimple or uncomplicated malaria may be treated with oral medications. The most effective treatment for \"P. falciparum\" infection is the use of artemisinins in combination with other antimalarials (known as artemisinin-combination therapy, or ACT), which decreases resistance to any single drug component. These additional antimalarials include: amodiaquine, lumefantrine, mefloquine or sulfadoxine/pyrimethamine. Another recommended combination is dihydroartemisinin and piperaquine. ACT is about 90% effective when used to treat uncomplicated malaria. To treat malaria during pregnancy, the WHO recommends the use of quinine plus clindamycin early in the pregnancy (1st trimester), and ACT in later stages (2nd and 3rd trimesters). In the 2000s (decade), malaria with partial resistance to artemisins emerged in Southeast Asia. Infection with \"P. vivax\", \"P. ovale\" or \"P. malariae\" usually do not require hospitalization. Treatment of \"P. vivax\" requires both treatment of blood stages (with chloroquine or ACT) and clearance of liver forms with primaquine. Treatment with tafenoquine prevents relapses after confirmed \"P. vivax\" malaria.\nSevere and complicated malaria are almost always caused by infection with \"P. falciparum\". The other species usually cause only febrile disease. Severe and complicated malaria are medical emergencies since mortality rates are high (10% to 50%). Cerebral malaria is the form of severe and complicated malaria with the worst neurological symptoms.\nRecommended treatment for severe malaria is the intravenous use of antimalarial drugs. For severe malaria, parenteral artesunate was superior to quinine in both children and adults. In another systematic review, artemisinin derivatives (artemether and arteether) were as efficacious as quinine in the treatment of cerebral malaria in children. Treatment of severe malaria involves supportive measures that are best done in a critical care unit. This includes the management of high fevers and the seizures that may result from it. It also includes monitoring for poor breathing effort, low blood sugar, and low blood potassium.\n\nDrug resistance poses a growing problem in 21st-century malaria treatment. Resistance is now common against all classes of antimalarial drugs apart from artemisinins. Treatment of resistant strains became increasingly dependent on this class of drugs. The cost of artemisinins limits their use in the developing world. Malaria strains found on the Cambodia–Thailand border are resistant to combination therapies that include artemisinins, and may, therefore, be untreatable. Exposure of the parasite population to artemisinin monotherapies in subtherapeutic doses for over 30 years and the availability of substandard artemisinins likely drove the selection of the resistant phenotype. Resistance to artemisinin has been detected in Cambodia, Myanmar, Thailand, and Vietnam, and there has been emerging resistance in Laos.\n\nWhen properly treated, people with malaria can usually expect a complete recovery. However, severe malaria can progress extremely rapidly and cause death within hours or days. In the most severe cases of the disease, fatality rates can reach 20%, even with intensive care and treatment. Over the longer term, developmental impairments have been documented in children who have suffered episodes of severe malaria. Chronic infection without severe disease can occur in an immune-deficiency syndrome associated with a decreased responsiveness to \"Salmonella\" bacteria and the Epstein–Barr virus.\n\nDuring childhood, malaria causes anemia during a period of rapid brain development, and also direct brain damage resulting from cerebral malaria. Some survivors of cerebral malaria have an increased risk of neurological and cognitive deficits, behavioural disorders, and epilepsy. Malaria prophylaxis was shown to improve cognitive function and school performance in clinical trials when compared to placebo groups.\n\nThe WHO estimates that in 2015 there were 214 million new cases of malaria resulting in 438,000 deaths. Others have estimated the number of cases at between 350 and 550 million for falciparum malaria The majority of cases (65%) occur in children under 15 years old. About 125 million pregnant women are at risk of infection each year; in Sub-Saharan Africa, maternal malaria is associated with up to 200,000 estimated infant deaths yearly. There are about 10,000 malaria cases per year in Western Europe, and 1300–1500 in the United States. About 900 people died from the disease in Europe between 1993 and 2003. Both the global incidence of disease and resulting mortality have declined in recent years. According to the WHO and UNICEF, deaths attributable to malaria in 2015 were reduced by 60% from a 2000 estimate of 985,000, largely due to the widespread use of insecticide-treated nets and artemisinin-based combination therapies. In 2012, there were 207 million cases of malaria. That year, the disease is estimated to have killed between 473,000 and 789,000 people, many of whom were children in Africa. Efforts at decreasing the disease in Africa since the turn of millennium have been partially effective, with rates of the disease dropping by an estimated forty percent on the continent.\n\nMalaria is presently endemic in a broad band around the equator, in areas of the Americas, many parts of Asia, and much of Africa; in Sub-Saharan Africa, 85–90% of malaria fatalities occur. An estimate for 2009 reported that countries with the highest death rate per 100,000 of population were Ivory Coast (86.15), Angola (56.93) and Burkina Faso (50.66). A 2010 estimate indicated the deadliest countries per population were Burkina Faso, Mozambique and Mali. The Malaria Atlas Project aims to map global endemic levels of malaria, providing a means with which to determine the global spatial limits of the disease and to assess disease burden. This effort led to the publication of a map of \"P. falciparum\" endemicity in 2010. As of 2010, about 100 countries have endemic malaria. Every year, 125 million international travellers visit these countries, and more than 30,000 contract the disease.\n\nThe geographic distribution of malaria within large regions is complex, and malaria-afflicted and malaria-free areas are often found close to each other. Malaria is prevalent in tropical and subtropical regions because of rainfall, consistent high temperatures and high humidity, along with stagnant waters in which mosquito larvae readily mature, providing them with the environment they need for continuous breeding. In drier areas, outbreaks of malaria have been predicted with reasonable accuracy by mapping rainfall. Malaria is more common in rural areas than in cities. For example, several cities in the Greater Mekong Subregion of Southeast Asia are essentially malaria-free, but the disease is prevalent in many rural regions, including along international borders and forest fringes. In contrast, malaria in Africa is present in both rural and urban areas, though the risk is lower in the larger cities.\n\nAlthough the parasite responsible for \"P. falciparum\" malaria has been in existence for 50,000–100,000 years, the population size of the parasite did not increase until about 10,000 years ago, concurrently with advances in agriculture and the development of human settlements. Close relatives of the human malaria parasites remain common in chimpanzees. Some evidence suggests that the \"P. falciparum\" malaria may have originated in gorillas.\n\nReferences to the unique periodic fevers of malaria are found throughout recorded history. Hippocrates described periodic fevers, labelling them tertian, quartan, subtertian and quotidian. The Roman Columella associated the disease with insects from swamps. Malaria may have contributed to the decline of the Roman Empire, and was so pervasive in Rome that it was known as the \"Roman fever\". Several regions in ancient Rome were considered at-risk for the disease because of the favourable conditions present for malaria vectors. This included areas such as southern Italy, the island of Sardinia, the Pontine Marshes, the lower regions of coastal Etruria and the city of Rome along the Tiber. The presence of stagnant water in these places was preferred by mosquitoes for breeding grounds. Irrigated gardens, swamp-like grounds, runoff from agriculture, and drainage problems from road construction led to the increase of standing water.\n\nThe term malaria originates from Medieval —\"bad air\"; the disease was formerly called \"ague\" or \"marsh fever\" due to its association with swamps and marshland. The term first appeared in the English literature about 1829. Malaria was once common in most of Europe and North America, where it is no longer endemic, though imported cases do occur.\n\nScientific studies on malaria made their first significant advance in 1880, when Charles Louis Alphonse Laveran—a French army doctor working in the military hospital of Constantine in Algeria—observed parasites inside the red blood cells of infected people for the first time. He, therefore, proposed that malaria is caused by this organism, the first time a protist was identified as causing disease. For this and later discoveries, he was awarded the 1907 Nobel Prize for Physiology or Medicine. A year later, Carlos Finlay, a Cuban doctor treating people with yellow fever in Havana, provided strong evidence that mosquitoes were transmitting disease to and from humans. This work followed earlier suggestions by Josiah C. Nott, and work by Sir Patrick Manson, the \"father of tropical medicine\", on the transmission of filariasis.\n\nIn April 1894, a Scottish physician, Sir Ronald Ross, visited Sir Patrick Manson at his house on Queen Anne Street, London. This visit was the start of four years of collaboration and fervent research that culminated in 1897 when Ross, who was working in the Presidency General Hospital in Calcutta, proved the complete life-cycle of the malaria parasite in mosquitoes. He thus proved that the mosquito was the vector for malaria in humans by showing that certain mosquito species transmit malaria to birds. He isolated malaria parasites from the salivary glands of mosquitoes that had fed on infected birds. For this work, Ross received the 1902 Nobel Prize in Medicine. After resigning from the Indian Medical Service, Ross worked at the newly established Liverpool School of Tropical Medicine and directed malaria-control efforts in Egypt, Panama, Greece and Mauritius. The findings of Finlay and Ross were later confirmed by a medical board headed by Walter Reed in 1900. Its recommendations were implemented by William C. Gorgas in the health measures undertaken during construction of the Panama Canal. This public-health work saved the lives of thousands of workers and helped develop the methods used in future public-health campaigns against the disease.\n\nThe first effective treatment for malaria came from the bark of cinchona tree, which contains quinine. This tree grows on the slopes of the Andes, mainly in Peru. The indigenous peoples of Peru made a tincture of cinchona to control fever. Its effectiveness against malaria was found and the Jesuits introduced the treatment to Europe around 1640; by 1677, it was included in the London Pharmacopoeia as an antimalarial treatment. It was not until 1820 that the active ingredient, quinine, was extracted from the bark, isolated and named by the French chemists Pierre Joseph Pelletier and Joseph Bienaimé Caventou.\n\nQuinine became the predominant malarial medication until the 1920s when other medications began to be developed. In the 1940s, chloroquine replaced quinine as the treatment of both uncomplicated and severe malaria until resistance supervened, first in Southeast Asia and South America in the 1950s and then globally in the 1980s.\n\nThe medicinal value of \"Artemisia annua\" has been used by Chinese herbalists in traditional Chinese medicines for 2,000 years. In 1596, Li Shizhen recommended tea made from qinghao specifically to treat malaria symptoms in his \"Compendium of Materia Medica\". Artemisinins, discovered by Chinese scientist Tu Youyou and colleagues in the 1970s from the plant \"Artemisia annua\", became the recommended treatment for \"P. falciparum\" malaria, administered in severe cases in combination with other antimalarials. Tu says she was influenced by a traditional Chinese herbal medicine source, \"The Handbook of Prescriptions for Emergency Treatments\", written in 340 by Ge Hong. For her work on malaria, Tu Youyou received the 2015 Nobel Prize in Physiology or Medicine.\n\n\"Plasmodium vivax\" was used between 1917 and the 1940s for malariotherapy—deliberate injection of malaria parasites to induce a fever to combat certain diseases such as tertiary syphilis. In 1927, the inventor of this technique, Julius Wagner-Jauregg, received the Nobel Prize in Physiology or Medicine for his discoveries. The technique was dangerous, killing about 15% of patients, so it is no longer in use.\n\nThe first pesticide used for indoor residual spraying was DDT. Although it was initially used exclusively to combat malaria, its use quickly spread to agriculture. In time, pest control, rather than disease control, came to dominate DDT use, and this large-scale agricultural use led to the evolution of resistant mosquitoes in many regions. The DDT resistance shown by \"Anopheles\" mosquitoes can be compared to antibiotic resistance shown by bacteria. During the 1960s, awareness of the negative consequences of its indiscriminate use increased, ultimately leading to bans on agricultural applications of DDT in many countries in the 1970s. Before DDT, malaria was successfully eliminated or controlled in tropical areas like Brazil and Egypt by removing or poisoning the breeding grounds of the mosquitoes or the aquatic habitats of the larva stages, for example by applying the highly toxic arsenic compound Paris Green to places with standing water.\n\nMalaria vaccines have been an elusive goal of research. The first promising studies demonstrating the potential for a malaria vaccine were performed in 1967 by immunizing mice with live, radiation-attenuated sporozoites, which provided significant protection to the mice upon subsequent injection with normal, viable sporozoites. Since the 1970s, there has been a considerable effort to develop similar vaccination strategies for humans. The first vaccine, called RTS,S, was approved by European regulators in 2015.\n\nMalaria is not just a disease commonly associated with poverty: some evidence suggests that it is also a cause of poverty and a major hindrance to economic development. Although tropical regions are most affected, malaria's furthest influence reaches into some temperate zones that have extreme seasonal changes. The disease has been associated with major negative economic effects on regions where it is widespread. During the late 19th and early 20th centuries, it was a major factor in the slow economic development of the American southern states.\n\nA comparison of average per capita GDP in 1995, adjusted for parity of purchasing power, between countries with malaria and countries without malaria gives a fivefold difference ($1,526 USD versus $8,268 USD). In the period 1965 to 1990, countries where malaria was common had an average per capita GDP that increased only 0.4% per year, compared to 2.4% per year in other countries.\n\nPoverty can increase the risk of malaria since those in poverty do not have the financial capacities to prevent or treat the disease. In its entirety, the economic impact of malaria has been estimated to cost Africa US$12 billion every year. The economic impact includes costs of health care, working days lost due to sickness, days lost in education, decreased productivity due to brain damage from cerebral malaria, and loss of investment and tourism. The disease has a heavy burden in some countries, where it may be responsible for 30–50% of hospital admissions, up to 50% of outpatient visits, and up to 40% of public health spending.\nCerebral malaria is one of the leading causes of neurological disabilities in African children. Studies comparing cognitive functions before and after treatment for severe malarial illness continued to show significantly impaired school performance and cognitive abilities even after recovery. Consequently, severe and cerebral malaria have far-reaching socioeconomic consequences that extend beyond the immediate effects of the disease.\n\nSophisticated counterfeits have been found in several Asian countries such as Cambodia, China, Indonesia, Laos, Thailand, and Vietnam, and are an important cause of avoidable death in those countries. The WHO said that studies indicate that up to 40% of artesunate-based malaria medications are counterfeit, especially in the Greater Mekong region and have established a rapid alert system to enable information about counterfeit drugs to be rapidly reported to the relevant authorities in participating countries. There is no reliable way for doctors or lay people to detect counterfeit drugs without help from a laboratory. Companies are attempting to combat the persistence of counterfeit drugs by using new technology to provide security from source to distribution.\n\nAnother clinical and public health concern is the proliferation of substandard antimalarial medicines resulting from inappropriate concentration of ingredients, contamination with other drugs or toxic impurities, poor quality ingredients, poor stability and inadequate packaging. A 2012 study demonstrated that roughly one-third of antimalarial medications in Southeast Asia and Sub-Saharan Africa failed chemical analysis, packaging analysis, or were falsified.\n\nThroughout history, the contraction of malaria has played a prominent role in the fates of government rulers, nation-states, military personnel, and military actions. In 1910, Nobel Prize in Medicine-winner Ronald Ross (himself a malaria survivor), published a book titled \"The Prevention of Malaria\" that included a chapter titled \"The Prevention of Malaria in War.\" The chapter's author, Colonel C. H. Melville, Professor of Hygiene at Royal Army Medical College in London, addressed the prominent role that malaria has historically played during wars: \"The history of malaria in war might almost be taken to be the history of war itself, certainly the history of war in the Christian era. ... It is probably the case that many of the so-called camp fevers, and probably also a considerable proportion of the camp dysentery, of the wars of the sixteenth, seventeenth and eighteenth centuries were malarial in origin.\"\n\nMalaria was the most significant health hazard encountered by U.S. troops in the South Pacific during World War II, where about 500,000 men were infected. According to Joseph Patrick Byrne, \"Sixty thousand American soldiers died of malaria during the African and South Pacific campaigns.\"\n\nSignificant financial investments have been made to procure existing and create new anti-malarial agents. During World War I and World War II, inconsistent supplies of the natural anti-malaria drugs cinchona bark and quinine prompted substantial funding into research and development of other drugs and vaccines. American military organizations conducting such research initiatives include the Navy Medical Research Center, Walter Reed Army Institute of Research, and the U.S. Army Medical Research Institute of Infectious Diseases of the US Armed Forces.\n\nAdditionally, initiatives have been founded such as Malaria Control in War Areas (MCWA), established in 1942, and its successor, the Communicable Disease Center (now known as the Centers for Disease Control and Prevention, or CDC) established in 1946. According to the CDC, MCWA \"was established to control malaria around military training bases in the southern United States and its territories, where malaria was still problematic\".\n\nSeveral notable attempts are being made to eliminate the parasite from sections of the world, or to eradicate it worldwide. In 2006, the organization Malaria No More set a public goal of eliminating malaria from Africa by 2015, and the organization plans to dissolve if that goal is accomplished. Several malaria vaccines are in clinical trials, which are intended to provide protection for children in endemic areas and reduce the speed of transmission of the disease. , The Global Fund to Fight AIDS, Tuberculosis and Malaria has distributed 230 million insecticide-treated nets intended to stop mosquito-borne transmission of malaria. The U.S.-based Clinton Foundation has worked to manage demand and stabilize prices in the artemisinin market. Other efforts, such as the Malaria Atlas Project, focus on analysing climate and weather information required to accurately predict the spread of malaria based on the availability of habitat of malaria-carrying parasites. The Malaria Policy Advisory Committee (MPAC) of the World Health Organization (WHO) was formed in 2012, \"to provide strategic advice and technical input to WHO on all aspects of malaria control and elimination\". In November 2013, WHO and the malaria vaccine funders group set a goal to develop vaccines designed to interrupt malaria transmission with the long-term goal of malaria eradication.\n\nMalaria has been successfully eliminated or greatly reduced in certain areas. Malaria was once common in the United States and southern Europe, but vector control programs, in conjunction with the monitoring and treatment of infected humans, eliminated it from those regions. Several factors contributed, such as the draining of wetland breeding grounds for agriculture and other changes in water management practices, and advances in sanitation, including greater use of glass windows and screens in dwellings. Malaria was eliminated from most parts of the USA in the early 20th century by such methods, and the use of the pesticide DDT and other means eliminated it from the remaining pockets in the South in the 1950s as part of the National Malaria Eradication Program.\n\nIn 2018, WHO announced that Paraguay was free of malaria, after an eradication effort that began in 1950.\n\nIn 2015 the WHO targeted a 90% reduction in deaths from malaria by 2030 and Bill Gates said in 2016 that he thought global eradication would be possible by 2040.\n\nThe Malaria Eradication Research Agenda (malERA) initiative was a consultative process to identify which areas of research and development (R&D) needed to be addressed for the worldwide eradication of malaria.\n\nA vaccine against malaria called RTS,S, was approved by European regulators in 2015. It is undergoing pilot trials in select countries in 2016.\n\nImmunity (or, more accurately, tolerance) to \"P. falciparum\" malaria does occur naturally, but only in response to years of repeated infection. An individual can be protected from a \"P. falciparum\" infection if they receive about a thousand bites from mosquitoes that carry a version of the parasite rendered non-infective by a dose of X-ray irradiation. The highly polymorphic nature of many \"P. falciparum\" proteins results in significant challenges to vaccine design. Vaccine candidates that target antigens on gametes, zygotes, or ookinetes in the mosquito midgut aim to block the transmission of malaria. These transmission-blocking vaccines induce antibodies in the human blood; when a mosquito takes a blood meal from a protected individual, these antibodies prevent the parasite from completing its development in the mosquito. Other vaccine candidates, targeting the blood-stage of the parasite's life cycle, have been inadequate on their own. For example, SPf66 was tested extensively in areas where the disease is common in the 1990s, but trials showed it to be insufficiently effective.\n\nMalaria parasites contain apicoplasts, organelles usually found in plants, complete with their own genomes. These apicoplasts are thought to have originated through the endosymbiosis of algae and play a crucial role in various aspects of parasite metabolism, such as fatty acid biosynthesis. Over 400 proteins have been found to be produced by apicoplasts and these are now being investigated as possible targets for novel anti-malarial drugs.\n\nWith the onset of drug-resistant \"Plasmodium\" parasites, new strategies are being developed to combat the widespread disease. One such approach lies in the introduction of synthetic pyridoxal-amino acid adducts, which are taken up by the parasite and ultimately interfere with its ability to create several essential B vitamins. Antimalarial drugs using synthetic metal-based complexes are attracting research interest.\n\n\nA non-chemical vector control strategy involves genetic manipulation of malaria mosquitoes. Advances in genetic engineering technologies make it possible to introduce foreign DNA into the mosquito genome and either decrease the lifespan of the mosquito, or make it more resistant to the malaria parasite. Sterile insect technique is a genetic control method whereby large numbers of sterile male mosquitoes are reared and released. Mating with wild females reduces the wild population in the subsequent generation; repeated releases eventually eliminate the target population.\n\nGenomics is central to malaria research. With the sequencing of \"P. falciparum\", one of its vectors \"Anopheles gambiae\", and the human genome, the genetics of all three organisms in the malaria lifecycle can be studied. Another new application of genetic technology is the ability to produce genetically modified mosquitoes that do not transmit malaria, potentially allowing biological control of malaria transmission.\n\nIn one study, a genetically-modified strain of \"Anopheles stephensi\" was created that no longer supported malaria transmission, and this resistance was passed down to mosquito offspring.\n\nGene drive is a technique for changing wild populations, for instance to combat or eliminate insects so they cannot transmit diseases (in particular mosquitoes in the cases of malaria, zika, dengue and yellow fever).\n\nNearly 200 parasitic \"Plasmodium\" species have been identified that infect birds, reptiles, and other mammals, and about 30 species naturally infect non-human primates. Some malaria parasites that affect non-human primates (NHP) serve as model organisms for human malarial parasites, such as \"P. coatneyi\" (a model for \"P. falciparum\") and \"P. cynomolgi\" (\"P. vivax\"). Diagnostic techniques used to detect parasites in NHP are similar to those employed for humans. Malaria parasites that infect rodents are widely used as models in research, such as \"P. berghei\". Avian malaria primarily affects species of the order Passeriformes, and poses a substantial threat to birds of Hawaii, the Galapagos, and other archipelagoes. The parasite \"P. relictum\" is known to play a role in limiting the distribution and abundance of endemic Hawaiian birds. Global warming is expected to increase the prevalence and global distribution of avian malaria, as elevated temperatures provide optimal conditions for parasite reproduction.\n\n\n\n"}
{"id": "54694072", "url": "https://en.wikipedia.org/wiki?curid=54694072", "title": "Maternal mortality in the United States", "text": "Maternal mortality in the United States\n\nMaternal mortality refers to the death of a woman during her pregnancy or up to a year after her pregnancy has terminated, if the death was related to her pregnancy. The United States Centers for Disease Control and Prevention (CDC) monitors maternal death per 100,000 live births. The CDC reported a baseline maternal mortality ratio (MMR) of 18.8 maternal deaths per 100,000 births in 2016, which was higher than anticipated. In 2014 there was a 26.6% increase representing 23.8 maternal deaths per 100,000 births. Maternal mortality as well as maternal morbidity has been increasing over the last several decades in the United States, with an estimated 50% of deaths due to preventable causes. \n\nBy 2010, although the United States was spending more on healthcare than any other country in the world, more than two women died during childbirth every day, making maternal mortality the highest in the United States compared to 49 other countries in the developed world and three times higher than neighboring Canada. In 2016, as many as 900 women between the ages of 16 and 43, died from pregnancy- and childbirth-related causes. The Centers for Disease Control and Prevention (CDC) declares that 60% of these deaths are preventable.\n\nIn the U.S., hospital bills for maternal healthcare costs over $98 billion, and concerns about the degradation of the MMR resulted in a state-by-state breakdown. Race, location, and financial status all contribute to how maternal mortality affects women across the country, but Texas has the worst MMR, which caused the Department of State to create the Maternal Mortality and Morbidity Task Force in 2013.\n\nIn 1986, the Centers for Disease Control and Prevention (CDC) and the American College of Obstetricians and Gynecologists (ACOG) created the Pregnancy-Related Mortality Surveillance System to monitor maternal death within a year of women giving birth and dying from any and all pregnancy and childbirth related causes per 100,000 live births. Prior to this change, the maternal mortality ratio monitored women 6 weeks postpartum per 100,000 live births. \n\nIn 2016 the CDC Foundation, the Centers for Disease Control and Prevention (CDC) and the Association of Maternal and Child Health Programs (AMCHP) undertook a collaborative initiative—\"Building U.S. Capacity to Review and Prevent Maternal Deaths\"— funded by Merck under the Merck for Mothers program. They are reviewing maternal mortality to enhance understanding of the increase in MMR in the United States, and to identify preventative interventions. Through this initiative, they have created Review to Action website which hosts their reports and resources.\n\nIn their 2017 report, four states, Colorado, Delaware, Georgia, and Ohio, supported the development of the Maternal Mortality Review Data System (MMRDS) which was intended as a precursor to the Maternal Mortality Review Information Application (MMRIA).\n\nThe three agencies have partnered with Colorado, Delaware, Georgia, Hawaii, Illinois, North Carolina, Ohio, South Carolina, and Utah to collect data for the Maternal Mortality Review Information Application (MMRIA). The nine states submitted their first reports in 2018. \n\nAfter decades of inaction on the part of the U.S. Congress towards reducing MMR, the United States Senate Committee on Appropriations voted on June 28, 2018 to request $50 million to prevent the pregnancy-related deaths of American women. The CDC would receive $12 million for research and data collection. They would also support individual states in counting and reviewing data on maternal deaths. The federal Maternal and Child Health Bureau would receive the remaining $38 million directed towards Healthy Start program and \"life saving, evidence-based programs\" at hospitals. MCHB's Healthy Start was mandated to reduce the infant mortality rate. \n\nA widely cited 2016 study by Centers for Disease Control and Prevention (CDC) statistician Marian F. MacDorman and others, reported a baseline rate of 18.8 maternal deaths per 100,000 births, which was higher than previously thought. In 2014 there was a 26.6% increase representing 23.8 maternal deaths per 100,000 births. MacDorman et al. concluded that, \"the maternal mortality rate for 48 states and Washington D.C. from 2000–2014 was higher than previously reported, is increasing, and places the U.S. far behind other industrialized nations.\" \n\nAccording to the Centers for Disease Control and Prevention (CDC) Foundation 2018 report, 60% of maternal deaths are preventable.\"\n\nAccording to a 2016 article in \"Obstetrics and Gynecology\" by MacDorman et al, one factor affecting the US maternal death rate is the variability in calculation of maternal deaths. The WHO deems maternal deaths to be those occurring within 42 days of the end of pregnancy, whereas the United States Pregnancy Mortality Surveillance System measures maternal deaths as those occurring within a year of the end of pregnancy. Some states allow multiple responses, such as whether death occurred during pregnancy, within 42 days after pregnancy, or within a year of pregnancy, but some states, such as California, ask simply whether death occurred within a year postpartum.In their article, the authors described how data collection on maternal mortality rates became an \"international embarrassment\". In 2003 the national U.S. standard death certificate added a \"tick box\" question regarding the pregnancy status of the deceased. Many states delayed adopting the new death certificate standards. This \"muddied\" data and obstructed analysis of trends in maternal mortality rates. It also meant that for many years, the United States could not report a national maternal mortality rate to the OECD or other repositories that collect data internationally.\n\nIn response to the MacDorman study, revealing the \"inability, or unwillingness, of states and the federal government to track maternal deaths\", ProPublica and NPR found that in 2016 alone, between 700 and 900 women died from pregnancy- and childbirth-related causes. In \"Lost Mothers\" they published stories of some of women who died. They ranged in age from 16 to 43.\n\nAmnesty International considers maternal mortality a healthcare crisis, based on their extensive research between 2008 and 2009. \n\nHealthy People is a federal organization that is managed by the Office of Disease Prevention and Health Promotion (ODPHP) at the U.S. Department of Health and Human Services (HHS). In 2010, the US maternal mortality ratio was 12.7 (deaths per 100,000 live births). This was 3 times as high as the Healthy People 2010 goal, a national target set by the US government.\n\nAccording to a 2009 article in \"Anthropology News\", studies conducted by but not limited to Amnesty International, the United Nations, and federal programs such as the CDC, maternal mortality has not decreased since 1999 and may have been rising.\n\nBy November 2017, Baltimore and Philadelphia, and New York City had established committees to \"review deaths and severe complications related to pregnancy and childbirth\" in their cities to prevent maternal mortality. New York's panel, the Maternal Mortality and Morbidity Review Committee (M3RC) doctors, nurses, \"doulas, midwives and social workers\". New York City will be collaborating with the State of New York, the first such collaboration in the US. In July 2018, New York City's de Blasio's administration announced that it would be allocating $12.8 million for the first three years of its five-year plan to \"reduce maternal deaths and life-threatening complications of childbirth among women of color\".\n\nIn the 2017 NPR and ProPublica series \"Lost Mothers: Maternal Mortality in the U.S.\" based on a six-month long collaborative investigation, they reported that the United States has the highest rate of maternal mortality than any other developed country and it is the only country where the rate of women who die has been rising. The maternal mortality rate in the United States is three times higher than that in neighboring Canada and six times as likely to die of as Scandinavians.\n\nIn the 1950s the maternal mortality rate in the United Kingdom and the United States was the same—1 in 1000 pregnant and new mothers died. By 2018, the rate in the UK was three times lower than in the United States.\nAccording to a 2015 WHO report, in the United States the MMR between 1990 and 2013 \"more than doubled from an estimated 12 to 28 maternal deaths per 100 000 births.\" By 2015, the United States had a higher MMR than the \"Islamic Republic of Iran, Libya and Turkey\".\n\nComparison of the US maternal death rate to the death rate in that of other countries is complicated by the lack of standardization. Some counties do not have a standard method for reporting maternal deaths and some count in statistics death only as a direct result of pregnancy.\n\nIn 2010, Amnesty International published a 154-page report on maternal mortality in the United States. In 2011 the United Nations described maternal mortality as a human rights issue at the forefront of American healthcare, as the mortality rates worsened over the years. \n\nAccording to a 2017 BBC report, Texas has the highest MMR in the United States and the lowest number of people covered by health insurance.\n\nThe Department of State created the Maternal Mortality and Morbidity Task Force in 2013.\n\nMaternal death can be traced to maternal health, which includes wellness throughout the entire pregnancy and access to basic care. In this context, the causes of maternal death can be illustrated as a continuum wherein \"maternal health from wellness to morbidity to severe morbidity to death\" is the cycle in which mothers often die of pregnancy related causes.\n\nMore than half of maternal deaths occur within the first 42 days after birth. According to Amnesty International's 2010 report, five medical conditions collectively account for 74% of maternal deaths in the US. These are Embolism (20%), Hemorrhage (17%), Pre-eclampsia and eclampsia (16%), Infection (13%), and Cardiomyopathy (8%).\n\nSocial factors and healthcare access issues also contribute to the maternal mortality rate. In no particular order, these factors include:\n\nInconsistent obstetric practice (which can allow complications to progress to fatal conditions), increase in women with chronic conditions, and lack of maternal health data all contribute to maternal mortality in the US. According to a 2015 WHO editorial, a nationally implemented guideline for pregnancy and childbirth, along with easy and equal access to antenatal services and care, and active participation from all 50 states to produce better maternal health data are all necessary components to reduce maternal mortality.\n\nRecent improvements in pregnancy-related health care have focused on fetuses and newborns, which has left mothers neglected in comparison. Mothers get 6% of federal block grants in this area, and even hospitals with intensive care units for newborns can be unprepared for maternal complications (like having platelets on hand for bleeding). A significant proportion of physicians in maternal-fetal medicine programs are able to complete a program in without ever attending a labor.\n\nThe Hospital Corporation of America has found that a uniform guideline for birth can improve maternal care, thereby reducing the amount of \"lower maternal and fetal injury, fewer c-sections and reduced litigation.\" However, no such mandated guideline currently exists.\n\nTo prevent maternal mortality moving forward, Amnesty International suggests these steps:\n\nAccording to the U.S. Department of Health and Human Services, Centers for Disease Control and Prevention, National Center for Health Statistics, out-of-hospital births (such as home births and birthing centers with midwifery assistance) \"generally provided a lower risk profile than hospital births.\" \n\nProcedures such as Episiotomies and cesareans, while helpful in some cases, when administered unnecessarily increase the risk of maternal death. Midwifery and mainstream obstetric care can be complementary, which is commonly the case in Canada, where women have a wide arrange of pregnancy and birthing options, wherein informed choice and consent are fundamental tenants of their reformed maternity care. The maternal mortality rate is twice as low in Canada than the United States, according to a global survey conducted by the United Nations and the World Bank.\n\nThe UK has had success drastically reducing preeclampsia deaths by implementing a nationwide standard protocol.\n\nGender bias and obstetric violence in the medical field are also important factors when discussing maternal wellness, care, and death in the United States.\n\n\n"}
{"id": "14195313", "url": "https://en.wikipedia.org/wiki?curid=14195313", "title": "Milieu therapy", "text": "Milieu therapy\n\nMilieu therapy is a form of psychotherapy that involves the use of therapeutic communities. Patients join a group of around 30, for between 9 and 18 months. During their stay, patients are encouraged to take responsibility for themselves and the others within the unit, based upon a hierarchy of collective consequences. Patients are expected to hold one another to following rules, with more senior patients expected to model appropriate behavior for newer patients. If one patient violates the rules, others who were aware of the violation but did not intervene may also be punished to varying extents based upon their involvement. Milieu therapy is thought to be of value in treating personality disorders and behavioural problems, and can also be used with a goal of stimulating the patient's remaining cognitive-communicative abilities. Organizations known to use milieu therapy include Henderson Hospital, in London, Forest Heights Lodge in Evergreen, CO, and the United States Veteran's Administration.\n\nVarcarolis, E.M. (1990). Foundations of Psychiatric Mental Health Nursing. New York: W.B. Saunders Company, p. 30. \n\n"}
{"id": "35897307", "url": "https://en.wikipedia.org/wiki?curid=35897307", "title": "Ministry of Health and Social Development", "text": "Ministry of Health and Social Development\n\nMay refer to the Ministry of Health (Russia) or to the ministry in Anguilla\n"}
{"id": "1885635", "url": "https://en.wikipedia.org/wiki?curid=1885635", "title": "National Toxicology Program", "text": "National Toxicology Program\n\nThe National Toxicology Program (NTP) is an inter-agency program run by the United States Department of Health and Human Services to coordinate, evaluate, and report on toxicology within public agencies.\n\nThe National Toxicology Program is headquartered at the National Institute of Environmental Health Sciences (NIEHS). The NIEHS Director, currently Dr. Linda Birnbaum, Ph.D., D.A.B.T., A.T.S., also concurrently serves as NTP Director. The Associate Director of the Program is Dr. John R. Bucher, Ph.D. \n\nThe NIEHS National Toxicology Program's Office of the Report on Carcinogens, directed by Dr. Ruth Lunn, Dr.P.H., is responsible for publishing the Report On Carcinogens; with the current year 2011 Report included, there have been 12 editions.\n\nThe program was established in 1978 by Joseph A. Califano, Jr., then the United States Secretary of Health, Education, and Welfare (today known as the Secretary of Health and Human Services). The program arose from congressional concerns about the health effects of chemical agents in the environment. In October 1981, Secretary Richard S. Schwiker granted permanent status to the program.\n\nThe NTP Interagency Center for the Evaluation of Alternative Toxicological Methods (NICEATM) supports the development and evaluation of new, revised, and alternative methods for chemical safety testing. Alternative methods are methods for safety testing of chemicals and chemical products that use fewer or no animals or that minimize or prevent animal pain and distress. NICEATM is directed by Dr. Warren Casey, PhD, DABT.\n\nThe NIH Revitalization Act of 1993 directed NIEHS to establish criteria for the validation and regulatory acceptance of alternative test methods and a process for their subsequent implementation. This led to the establishment of the Interagency Coordinating Committee on the Validation of Alternative Methods via the ICCVAM Authorization Act of 2000, which stated that ICCVAM would exist as a permanent interagency committee of NIEHS under NICEATM.\n\nIn addition to supporting ICCVAM, NICEATM activities include:\nNICEATM publishes results of its analyses of alternative test methods and approaches in the peer-reviewed literature and presents at meetings of the Society of Toxicology and the World Congress on Alternatives and Animal Use in the Life Sciences.\n\n"}
{"id": "54000061", "url": "https://en.wikipedia.org/wiki?curid=54000061", "title": "Neurogastronomy", "text": "Neurogastronomy\n\nNeurogastronomy is the study of flavor perception and the ways it affects cognition and memory. This interdisciplinary field is influenced by the psychology and neuroscience of sensation, learning, satiety, and decision making. Areas of interest include how olfaction contributes to flavor, food addiction and obesity, taste preferences, and the linguistics of communicating and identifying flavor. The term neurogastronomy was coined by neuroscientist Gordon M. Shepherd.\n\nOut of all the sensory modalities, olfaction contributes most to the sensation and perception of flavor processing. Olfaction has two sensory modalities, orthonasal smell, the detection of odor molecules originating outside the body, and retronasal smell, the detection of odor molecules originating during mastication. It is retronasal smell, whose sensation is felt in the mouth, that contributes to flavor perception. Anthropologically, over human evolution, the shortening of the nasopharynx and other shifts in bone structure suggest a constant improvement of flavor perception capabilities.\n\nAfter mastication, odor molecules travel through the back of the mouth and up the nasopharynx. The odorants are detected by myriad receptors on the olfactory epithelium. These receptors respond to a variety of dimensions of chemical properties. Odor receptors that respond to a dimension within a molecular receptive range are aggregated by glomeruli in the olfactory bulb. Here, the multi-dimensional nature of odorant stimuli is reduced to two dimensions. This input undergoes edge enhancement, increasing its signal-to-noise ratio by way of lateral inhibition due to mitral cells stemming from the glomerular layer.\n\nThis input then reaches the olfactory cortex. Here, Hebbian learning networks allow for recall with partial or weak stimuli, indicating the first stage of conscious perception. Here, connections with the hypothalamus and hippocampus indicate that olfaction stimuli affect emotion, decision making, and learning only after significant processing and rudimentary identification.\n\nThe hedonic value of food and its decision making relies on several concurrent neural processings. The attentional drive to seek and consume food is modulated by homeostatic signaling of hunger and satiety. Habit, social interactions, and nutritional needs affect this signaling. Analysis of non-human primates' orbitofrontal cortex suggests decision making is additionally modulated by food identification, independent of hunger. Activity in the medial orbitofrontal cortex and anterior singulate suggest that an affective value is assigned to every food identification. Hedonic pleasure increases when engaging with food consumption and peaks during satiety. Impairments in these systems greatly impact the ability to resist the urge to eat. Imaging studies show that obese subjects with impairment in dopamine circuits that regulate hedonic value have issues with reward sensitivity and resist functional homeostatic signals that normally would prevent overeating.\n\nThe consumption of comfort foods can facilitate feelings of relational connection and belonging, and the motivation behind pursuing certain foods can be modulated by social context and environment.\n\nAlthough the consumption of spicy food can cause pain, people in many cultures ascribe a high hedonic value to it. Psychologist Paul Rozin puts forth the idea of \"benign masochism\", a learned tendency that overrides the typically aversive stimuli because of the risk-taking or thrill-seeking associated with overcoming pain.\n\nLearned taste preferences as early as in utero, where the fetus is exposed to flavors through amniotic fluid. Early, innate, preferences exhibit tendencies towards calorie and protein dense foods. As children grow older, more factors such as peers, repeated exposures, environments and food availability will modulate taste preferences.\n\nWhile naming a flavor or food refines its representation strengthens its recall in memory, the patterns and tendencies in word choice to describe flavor suggests limits to the our perception and communication. In describing the flavor of wine, tasters tend to use words that function as a combination of visual and texture descriptors, and references to objects with similar odorant profiles. Color perception heavily influences the word choice describing a flavor; the color of word's semantic reference is often congruent with the food's color when the taster can see the food.\n"}
{"id": "842059", "url": "https://en.wikipedia.org/wiki?curid=842059", "title": "Political abuse of psychiatry in the Soviet Union", "text": "Political abuse of psychiatry in the Soviet Union\n\nThere was systematic political abuse of psychiatry in the Soviet Union, based on the interpretation of political opposition or dissent as a psychiatric problem. It was called \"psychopathological mechanisms\" of dissent.\n\nDuring the leadership of General Secretary Leonid Brezhnev, psychiatry was used to disable and remove from society political opponents (\"dissidents\") who openly expressed beliefs that contradicted the official dogma. The term \"philosophical intoxication\", for instance, was widely applied to the mental disorders diagnosed when people disagreed with the country's Communist leaders and, by referring to the writings of the Founding Fathers of Marxism–Leninism—Karl Marx, Friedrich Engels, and Vladimir Lenin—made them the target of criticism.\n\nArticle 58-10 of the Stalin-era Criminal Code, \"Anti-Soviet agitation\", was to a considerable degree preserved in the new 1958 RSFSR Criminal Code as Article 70 \"Anti-Soviet agitation and propaganda\". In 1967, a weaker law, Article 190-1 \"Dissemination of fabrications known to be false, which defame the Soviet political and social system\", was added to the RSFSR Criminal Code. These laws were frequently applied in conjunction with the system of diagnosis for mental illness, developed by Academician Andrei Snezhnevsky. Together they established a framework within which non-standard beliefs could easily be defined as a criminal offence and the basis, subsequently, for a psychiatric diagnosis.\n\nThe \"anti-Soviet\" political behavior of some individuals — being outspoken in their opposition to the authorities, demonstrating for reform, and writing critical books — were defined simultaneously as criminal acts (e.g., a violation of Articles 70 or 190-1), symptoms of mental illness (e.g., \"delusion of reformism\"), and susceptible to a ready-made diagnosis (e.g., \"sluggish schizophrenia\"). Within the boundaries of the diagnostic category, the symptoms of pessimism, poor social adaptation and conflict with authorities were themselves sufficient for a formal diagnosis of \"sluggish schizophrenia.\"\n\nThe psychiatric incarceration of certain individuals was prompted by their attempts to emigrate, to distribute or possess prohibited documents or books, to participate in civil rights protests and demonstrations, and become involved in forbidden religious activities. The religious beliefs of prisoners, including those of well-educated former atheists who had become adherents of a religious faith, was considered to be a form of mental illness that required treatment. The KGB routinely sent dissenters to psychiatrists for diagnosing to avoid embarrassing publiс trials and to discredit dissidence as the product of ill minds. Highly classified government documents which have become available after the dissolution of the Soviet Union confirm that the authorities consciously used psychiatry as a tool to suppress dissent.\n\nAccording to the \"Commentary\" to the post-Soviet \"Russian Federation Law on Psychiatric Care\", individuals forced to undergo treatment in Soviet psychiatric medical institutions were entitled to rehabilitation in accordance with the established procedure and could claim compensation. The Russian Federation acknowledged that before 1991 psychiatry had been used for political purposes and took responsibility for the victims of \"political psychiatry.\"\n\nThe political abuse of psychiatry in Russia has continued, nevertheless, since the fall of the Soviet Union and human rights activists may still face the threat of a psychiatric diagnosis for their legitimate civic and political activities.\n\nPolitical abuse of psychiatry is the misuse of psychiatric diagnosis, detention and treatment for the purposes of obstructing the fundamental human rights of certain groups and individuals in a society. It entails the exculpation and committal of citizens to psychiatric facilities based upon political rather than mental health-based criteria. Many authors, including psychiatrists, also use the terms \"Soviet political psychiatry\" or \"punitive psychiatry\" to refer to this phenomenon.\n\nIn his book \"Punitive Medicine\" (1979) Alexander Podrabinek defined the term \"punitive medicine\", which is identified with \"punitive psychiatry,\" as \"a tool in the struggle against dissidents who cannot be punished by legal means.\" Punitive psychiatry is neither a discrete subject nor a psychiatric specialty but, rather, it is an emergency arising within many applied sciences in totalitarian countries where members of a profession may feel themselves compelled to serve the diktats of power. Psychiatric confinement of sane people is uniformly considered a particularly pernicious form of repression and Soviet punitive psychiatry was one of the key weapons of both illegal and legal repression.\n\nAs Vladimir Bukovsky and Semyon Gluzman wrote in their joint \"A Manual on Psychiatry for Dissenters\", \"the Soviet use of psychiatry as a punitive means is based upon the deliberate interpretation of dissent... as a psychiatric problem.\"\n\nPsychiatry possesses an inherent capacity for abuse that is greater than in other areas of medicine. The diagnosis of mental disease can give the state license to detain persons against their will and insist upon therapy both in the interest of the detainee and in the broader interests of society. In addition, receiving a psychiatric diagnosis can in itself be regarded as oppressive. In a monolithic state, psychiatry can be used to bypass standard legal procedures for establishing guilt or innocence and allow political incarceration without the ordinary odium attaching to such political trials.\n\nIn the period from the 1960-s to 1986, the abuse of psychiatry for political purposes was reported to have been systematic in the Soviet Union and episodic in other Eastern European countries such as Romania, Hungary, Czechoslovakia, and Yugoslavia. The practice of incarceration of political dissidents in mental hospitals in Eastern Europe and the former USSR damaged the credibility of psychiatric practice in these states and entailed strong condemnation from the international community. Psychiatrists have been involved in human rights abuses in states across the world when the definitions of mental disease were expanded to include political disobedience. As scholars have long argued, governmental and medical institutions have at times classified threats to authority during periods of political disturbance and instability as a form of mental disease. In many countries, political prisoners are still sometimes confined and abused in mental institutions.\n\nIn the Soviet Union, dissidents were often confined in the so-called \"psikhushka\", or psychiatric wards. \"Psikhushka\" is the Russian ironic diminutive for \"mental hospital\". One of the first \"psikhushkas\" was the Psychiatric Prison Hospital in the city of Kazan. In 1939, it was transferred to the control of the NKVD (the secret police and precursor of the KGB) on the orders of Lavrentiy Beria, the head of the NKVD. International human rights defenders such as Walter Reich have long recorded the methods by which Soviet psychiatrists in \"Psikhushka\" hospitals diagnosed schizophrenia in political dissenters. Western scholars examined no aspect of Soviet psychiatry as thoroughly as its involvement in the social control of political dissenters.\n\nAs early as 1948, the Soviet secret service took an interest in this area of medicine. One of those with overall responsibility for the Soviet secret police, pre-war Procurator General and State Prosecutor, the deputy Minister of Foreign Affairs Andrey Vyshinsky, was the first to order the use of psychiatry as a tool of repression. Russian psychiatrist Pyotr Gannushkin also believed that in a class society, especially during the most severe class struggle, psychiatry was incapable of not being repressive. A system of political abuse of psychiatry was developed at the end of Joseph Stalin's regime.\n\nPunitive psychiatry was not simply an inheritance from the Stalin era, however, according to Alexander Etkind. The GULag, or Chief Administration for Corrective Labor Camps, was an effective instrument of political repression. There was no compelling requirement to develop an alternative and more expensive psychiatric substitute. The abuse of psychiatry was a natural product of the later Soviet era. From the mid-1970s to the 1990s, the structure of the USSR mental health service conformed to the double standard in society, being represented by two distinct systems which co-existed peacefully for the most part, despite periodic conflicts between them:\nThe hundreds of hospitals in the provinces combined elements of both systems.\n\nIf someone was mentally ill then, he was sent to a psychiatric hospital and confined there until his dying day. If his mental health was uncertain but he was not constantly unwell, he and his \"kharakteristika\" [testimonial from employers, the Party and other Soviet institutions] were sent to a labour camp or to be shot. When allusions to socialist legality started to be made, it was decided to prosecute such people. Soon it became apparent that putting people who gave anti-Soviet speeches on trial only made matters worse for the regime. Such individuals were no longer tried in court. Instead they were given a psychiatric examination and declared insane.\n\nIn the 1950s, the psychiatrists of the Soviet Union turned themselves into the medical arm of the Gulag State. A precursor of later abuses in psychiatry in the Soviet Union, the \"Joint Session\" of the USSR Academy of Medical Sciences and the Board of the All-Union Neurological and Psychiatric Association took place from 10 to 15 October 1951. The event was dedicated, supposedly, to the great Russian physiologist Ivan Pavlov and alleged that several of the USSR's leading neuroscientists and psychiatrists of the time (among them Grunya Sukhareva, Vasily Gilyarovsky, Raisa Golant, Aleksandr Shmaryan, and Mikhail Gurevich) were guilty of practicing \"anti-Pavlovian, anti-Marxist, idealistic [and] reactionary\" science, and this was damaging to Soviet psychiatry.\n\nDuring the Joint Session, these eminent psychiatrists, motivated by fear, had to publicly admit that their scientific positions were erroneous and they also had to promise to conform to \"Pavlovian\" doctrines. These public declarations of obedience proved insufficient. In the closing speech Snezhnevsky, the lead author of the Session's policy report, stated that the accused psychiatrists \"have not disarmed themselves and continue to remain in the old anti-Pavlovian positions\", thereby causing \"grave damage to the Soviet psychiatric research and practice\". The vice president of the USSR Academy of Medical Sciences accused them of \"diligently worshipping the dirty source of American pseudo-science\". Those who articulated these accusations at the Joint Session — among them Irina Strelchuk, Vasily Banshchikov, Oleg Kerbikov, and Snezhnevsky — were distinguished by their careerist ambition and fear for their own positions. Not surprisingly, many of them were promoted and appointed to leadership posts shortly after the session.\n\nThe Joint Session also had a negative impact on several leading Soviet academic neuroscientists, such as Pyotr Anokhin, Aleksey Speransky, Lina Stern, Ivan Beritashvili, and Leon Orbeli. They were labeled as anti-Pavlovians, anti-materialists and reactionaries and subsequently they were dismissed from their positions. In addition to losing their laboratories some of these scientists were subjected to torture in prison. The Moscow, Leningrad, Ukrainian, Georgian, and Armenian schools of neuroscience and neurophysiology were damaged for a period due to this loss of personnel. The Joint Session ravaged productive research in neurosciences and psychiatry for years to come. Pseudo-science took control.\n\nFollowing a previous joint session of the USSR Academy of Sciences and the USSR Academy of Medical Sciences (28 June–4 July 1950) and the 10-15 October 1951 joint session of the Presidium of the Academy of Medical Sciences and the Board of the All-Union Society of Neuropathologists and Psychiatrists, Snezhnevky's schoolthe was given the leading role. The 1950 decision to give monopoly over psychiatry to the Pavlovian school of Snezhnevsky was one of the crucial factors in the rise of political psychiatry. The Soviet doctors, under the incentive of Snezhnevsky, devised a \"Pavlovian theory of schizophrenia\" and increasingly applied this diagnostic category to political dissidents.\n\n\"The incarceration of free thinking healthy people in madhouses is spiritual murder, it is a variation of the gas chamber, even more cruel; the torture of the people being killed is more malicious and more prolonged. Like the gas chambers, these crimes will never be forgotten and those involved in them will be condemned for all time during their life and after their death.\" \n\nPsychiatric diagnoses such as the diagnosis of \"sluggish schizophrenia\" in political dissidents in the USSR were used for political purposes. It was the diagnosis of \"sluggish schizophrenia\" that was most prominently used in cases of dissidents. Sluggish schizophrenia as one of the new diagnostic categories was created to facilitate the stifling of dissidents and was a root of self-deception among psychiatrists to placate their consciences when the doctors acted as a tool of oppression in the name of a political system. According to the Global Initiative on Psychiatry chief executive Robert van Voren, the political abuse of psychiatry in the USSR arose from the conception that people who opposed the Soviet regime were mentally sick since there was no other logical rationale why one would oppose the sociopolitical system considered the best in the world. The diagnosis \"sluggish schizophrenia,\" a longstanding concept further developed by the Moscow School of Psychiatry and particularly by its chief Snezhnevsky, furnished a very handy framework for explaining this behavior.\n\nThe weight of scholarly opinion holds that the psychiatrists who played the primary role in the development of this diagnostic concept were following directives from the Communist Party and the Soviet secret service, or KGB, and were well aware of the political uses to which it would be put. Nevertheless, for many Soviet psychiatrists \"sluggish schizophrenia\" appeared to be a logical explanation to apply to the behavior of critics of the regime who, in their opposition, seemed willing to jeopardize their happiness, family, and career for a reformist conviction or ideal that was so apparently divergent from the prevailing social and political orthodoxy.\n\nSnezhnevsky, the most prominent theorist of Soviet psychiatry and director of the Institute of Psychiatry of the USSR Academy of Medical Sciences, developed a novel classification of mental disorders postulating an original set of diagnostic criteria. A carefully crafted description of sluggish schizophrenia established that psychotic symptoms were non-essential for the diagnosis, but symptoms of psychopathy, hypochondria, depersonalization or anxiety were central to it. Symptoms referred to as part of the \"negative axis\" included pessimism, poor social adaptation, and conflict with authorities, and were themselves sufficient for a formal diagnosis of \"sluggish schizophrenia with scanty symptoms.\" According to Snezhnevsky, patients with sluggish schizophrenia could present as quasi sane yet manifest minimal but clinically relevant personality changes which could remain unnoticed to the untrained eye. Thereby patients with non-psychotic mental disorders, or even persons who were not mentally sick, could be easily labelled with the diagnosis of sluggish schizophrenia. Along with paranoia, sluggish schizophrenia was the diagnosis most frequently used for the psychiatric incarceration of dissenters. As per the theories of Snezhnevsky and his colleagues, schizophrenia was much more prevalent than previously considered since the illness could be presented with comparatively slight symptoms and only progress afterwards. As a consequence, schizophrenia was diagnosed much more often in Moscow than in cities of other countries, as \"the World Health Organization Pilot Study on Schizophrenia\" reported in 1973. The city with the highest prevalence of schizophrenia in the world was Moscow. In particular, the scope was widened by sluggish schizophrenia because according to Snezhnevsky and his colleagues, patients with this diagnosis were capable of functioning almost normally in the social sense. Their symptoms could be like those of a neurosis or could assume a paranoid character. The patients with paranoid symptoms retained some insight into their condition but overestimated their own significance and could manifest grandiose ideas of reforming society. Thereby, sluggish schizophrenia could have such symptoms as \"reform delusions,\" \"perseverance,\" and \"struggle for the truth.\" As Viktor Styazhkin reported, Snezhnevsky diagnosed a reformation delusion for every case when a patient \"develops a new principle of human knowledge, drafts an academy of human happiness, and many other projects for the benefit of mankind.\"\n\nIn the 1960s and 1970s, theories, which contained ideas about reforming society and struggling for truth, and religious convictions were not referred to delusional paranoid disorders in practically all foreign classifications, but Soviet psychiatry, proceeding from ideological conceptions, referred critique of the political system and proposals to reform this system to the delusional construct. Diagnostic approaches of conception of sluggish schizophrenia and paranoiac states with delusion of reformism were used only in the Soviet Union and several Eastern European countries.\n\nOn the covert orders of the KGB, thousands of social and political reformers—Soviet \"dissidents\"—were incarcerated in mental hospitals after being labelled with diagnoses of \"sluggish schizophrenia\", a disease fabricated by Snezhnevsky and \"Moscow school\" of psychiatry. American psychiatrist Alan A. Stone stated that Western criticism of Soviet psychiatry aimed at Snezhnevsky personally, because he was essentially responsible for the Soviet concept of schizophrenia with a \"sluggish type\" manifestation by \"reformerism\" including other symptoms. One can readily apply this diagnostic scheme to dissenters. Snezhnevsky was long attacked in the West as an exemplar of psychiatric abuse in the USSR. The leading critics implied that Snezhnevsky had designed the Soviet model of schizophrenia and this diagnosis to make political dissent into a mental disease. He was charged with cynically developing a system of diagnosis which could be bent for political purposes, and he himself diagnosed or was involved in a series of famous dissident cases, and, in dozens of cases, he personally signed a commission decision on legal insanity of mentally healthy dissidents including Vladimir Bukovsky, Natalya Gorbanevskaya, Leonid Plyushch, , and Pyotr Grigorenko.\n\nThe campaign to declare political opponents mentally sick and to commit dissenters to mental hospitals began in the late 1950s and early 1960s. As Vladimir Bukovsky commented on the emergence of the political abuse of psychiatry, Nikita Khrushchev reckoned that it was impossible for people in a socialist society to have an anti-socialist consciousness. Whenever manifestations of dissidence could not be justified as a provocation of world imperialism or a legacy of the past, they were self-evidently the product of mental disease. In a speech published in the \"Pravda\" daily newspaper on 24 May 1959, Khrushchev said:\n\nThe now available evidence supports the conclusion that the system of political abuse of psychiatry was carefully designed by the KGB to rid the USSR of undesirable elements. According to several available documents and a message by a former general of the Fifth (dissident) Directorate of the Ukrainian KGB to Robert van Voren, political abuse of psychiatry as a systematic method of repression was developed by Yuri Andropov along with a selected group of associates.\n\nAndropov was in charge of the wide-ranging deployment of psychiatric repression from the moment he was appointed to head the KGB. He became KGB Chairman on 18 May 1967. On 3 July 1967, he made a proposal to establish a Fifth Directorate (ideological counterintelligence) within the KGB to deal with internal political opposition to the Soviet regime. The Directorate was set up at the end of July and took charge of KGB files on all Soviet dissidents, including Andrei Sakharov and Alexander Solzhenitsyn. In 1968, KGB Chairman Andropov issued a departmental order \"On the tasks of State security agencies in combating the ideological sabotage by the adversary\", calling for the KGB to struggle against dissidents and their imperialist masters. His aim was \"the destruction of dissent in all its forms\" and he insisted that the positions of the capitalist countries on human rights, and their criticisms of the Soviet Union and its own politics of human rights from these positions, was just one part of a wide-ranging imperialist plot to undermine the Soviet state's foundation. Similar ideas can be found in the 1983 book \"Speeches and Writings\" by Andropov published when he had become General Secretary of the CPSU:\nOn 29 April 1969, Andropov submitted an elaborate plan to the Central Committee of the Communist Party of the Soviet Union to set up a network of mental hospitals that would defend the \"Soviet Government and the socialist order\" from dissenters. To persuade his fellow Politburo members of the risk posed by the mentally ill, Andropov circulated a report from the Krasnodar Region. A secret resolution of the USSR Council of Ministers was adopted. Andropov's proposal to use psychiatry for struggle against dissenters was adopted and implemented.\n\nIn 1929, the USSR had 70 psychiatric hospitals and 21,103 psychiatric beds. By 1935, this had increased to 102 psychiatric hospitals and 33,772 psychiatric beds, and by 1955 there were 200 psychiatric hospitals and 116,000 psychiatric beds in the Soviet Union. The Soviet authorities built psychiatric hospitals at a rapid pace and increased the quantity of beds for patients with nervous and mental illnesses: between 1962 and 1974, the number of beds for psychiatric patients increased from 222,600 to 390,000. Such an expansion in the number of psychiatric beds was expected to continue in the years up to 1980. Throughout this period the dominant trend in Soviet psychiatry ran counter to the vigorous attempts in Western countries to treat as many as possible as out-patients rather than in-patients.\n\nOn 15 May 1969, a Soviet Government decree (No. 345–209) was issued \"On measures for preventing dangerous behavior (acts) on the part of mentally ill persons.\" This decree confirmed the practice of having undesirables hauled into detention by psychiatrists. Soviet psychiatrists were told whom they should examine and were assured that they might detain these individuals with the help of the police or entrap them into coming to the hospital. The psychiatrists thereby doubled as interrogators and as arresting officers. Doctors fabricated a diagnosis requiring detention and no court decision was required for subjecting the individual to indefinite confinement in a psychiatric institution.\n\nBy the end of the 1950s, confinement to a psychiatric institution had become the most commonly used method of punishing leaders of the political opposition. In the 1960s and 1970s, the trials of dissenters and their referral for \"treatment\" to the Special Psychiatric Hospitals under MVD control and oversight came out into the open, and the world learned of a wave of \"psychiatric terror\" which was flatly denied by those in charge of the Serbsky Institute. The bulk of psychiatric repression spans the period from the late 1960s to the early 1980s. As CPSU General Secretary, from November 1982 to February 1984, Yury Andropov demonstrated little patience with domestic dissafection and continued the Brezhnev Era policy of confining dissenters in mental hospitals.\n\nPolitical dissidents were usually charged under Articles 70 (agitation and propaganda against the Soviet state) and 190-1 (dissemination of false fabrications defaming the Soviet state and social system) of the RSFSR Criminal Code. Forensic psychiatrists were asked to examine offenders whose mental state was considered abnormal by the investigating officers.\n\nIn almost every case, dissidents were examined at the Serbsky Central Research Institute for Forensic Psychiatry in Moscow, where persons being prosecuted in court for committing political crimes were subjected to a forensic-psychiatric expert evaluation. Once certified, the accused and convicted were sent for involuntary treatment to the Special Psychiatric Hospitals controlled by the Ministry of Internal Affairs (MVD) of the Russian Soviet Federative Socialist Republic.\n\nThe accused had no right of appeal. The right was given to their relatives or other interested persons but they were not allowed to nominate psychiatrists to take part in the evaluation, because all psychiatrists were considered fully independent and equally credible before the law.\n\nAccording to dissident poet Naum Korzhavin, the atmosphere at the Serbsky Institute in Moscow altered almost overnight when Daniil Lunts took over as head of the Fourth Department (otherwise known as the Political Department). Previously, psychiatric departments were regarded as a 'refuge' against being dispatched to the Gulag. Now that policy altered. The first reports of dissenters being hospitalized on non-medical grounds date from the early 1960s, not long after Georgy Morozov was appointed director of the Serbsky Institute. Both Morozov and Lunts were personally involved in numerous well-known cases and were notorious abusers of psychiatry for political purposes. Most prisoners, in Viktor Nekipelov's words, characterized Daniil Lunts as \"no better than the criminal doctors who performed inhuman experiments on the prisoners in Nazi concentration camps.\" Indeed, experimentation took place on patients, including sleep deprivation and exposure to electromagnetic radiation for the inducement of auditory hallucinations.\n\nA well-documented practice was the use of psychiatric hospitals as temporary prisons during the two or three weeks around the 7 November (October Revolution) Day and May Day celebrations, to isolate \"socially dangerous\" persons who otherwise might protest in public or manifest other deviant behavior.\n\nIn the 1960s, a vigorous movement grew up protesting against abuse of psychiatry in the USSR. Political abuse of psychiatry in the Soviet Union was denounced in the course of the Congresses of the World Psychiatric Association in Mexico City (1971), Hawaii (1977), Vienna (1983) and Athens (1989). The campaign to terminate political abuse of psychiatry in the USSR was a key episode in the Cold War, inflicting irretrievable damage on the prestige of medicine in the Soviet Union.\n\nUpon analysis of over 200 well-authenticated cases covering the period 1962–1976, Sidney Bloch and Peter Reddaway developed a classification of the victims of Soviet psychiatric abuse. They were classified as:\nThe advocates of human rights and democratization, according to Bloch and Reddaway, made up about half the dissidents repressed by means of psychiatry. Nationalists made up about one-tenth of the dissident population dealt with psychiatrically. Would-be emigrants constituted about one-fifth of dissidents victimized by means of psychiatry. People detained only because of their religious activity made up about fifteen per cent of dissident-patients. Citizens inconvenient to the authorities because of their \"obdurate\" complaints about bureaucratic excesses and abuses accounted for about five per cent of dissidents subject to psychiatric abuse.\n\nIn 1985, Peter Reddaway and Sidney Bloch provided documented data on some five hundred cases in their book \"Soviet Psychiatric Abuse\".\n\nOn basis of the available data and materials accumulated in the archives of the International Association on the Political Use of Psychiatry, one can confidently conclude that thousands of dissenters were hospitalized for political reasons. From 1994 to 1995, an investigative commission of Moscow psychiatrists explored the records of five prison psychiatric hospitals in Russia and discovered about two thousand cases of political abuse of psychiatry in these hospitals alone. In 2004, Anatoly Prokopenko said he was surprised at the facts obtained by him from the official classified top secret documents by the Central Committee of the CPSU, by the KGB, and MVD. According to his calculations based on what he found in the documents, about 15,000 people were confined for political crimes in the psychiatric prison hospitals under the control of the MVD. In 2005, referring to the Archives of the CPSU Central Committee and the records of the three Special Psychiatrial Hospitals — Sychyovskaya, Leningrad and Chernyakhovsk hospitals — to which human rights activists gained access in 1991, Prokopenko concluded that psychiatry had been used as punitive measure against about 20,000 people for purely political reasons. This was only a small part of the total picture, Prokopenko said. The data on the total number of people who had been held in all sixteen prison hospitals and in the 1,500 \"open\" psychiatric hospitals remains unknown because parts of the archives of the prison psychiatric hospitals and hospitals in general are classified and inaccessible. The figure of fifteen or twenty thousand political prisoners in psychiatric hospitals run by the Soviet Ministry of Internal Affairs was first put forward by Prokopenko in the 1997 book \"Mad Psychiatry\" (\"Безумная психиатрия\"), which was republished in 2005.\n\nAn indication of the extent of the political abuse of psychiatry in the USSR is provided by Semyon Gluzman's calculation that the percentage of \"the mentally ill\" among those accused of so-called anti-Soviet activities proved many times higher than among criminal offenders. The attention paid to political prisoners by Soviet psychiatrists was more than 40 times greater than their attention to ordinary criminal offenders. This derives from the following comparison: 1–2 % of all the forensic psychiatric examinations carried out by the Serbsky Institute targeted those accused of anti-Soviet activities; convicted dissidents in penal institutions made up 0.05% of the total number of convicts; 1–2 % is 40 times greater than 0.05%.\n\nAccording to Viktor Luneyev, the struggle against dissent operated on many more layers than those registered in court sentences. We do not know how many the secret services kept under surveillance, held criminally liable, arrested, sent to psychiatric hospitals, or who were sacked from their jobs, and restricted in all kinds of other ways in the exercise of their rights. No objective assessment of the total number of repressed persons is possible without fundamental analysis of archival documents. The difficulty is that the required data are very diverse and are not to be found in a single archive. They are scattered between the State Archive of the Russian Federation, the archive of the Russian Federation State Statistical Committee (Goskomstat), the archives of the RF Ministry of Internal Affairs (MVD of Russia), the FSB of Russia, the RF General Prosecutor's Office, and the Russian Military and Historical Archive. Further documents are held in the archives of 83 constituent entities of the Russian Federation, in urban and regional archives, as well as in the archives of the former Soviet Republics, now the 11 independent countries of the Commonwealth of Independent States or the three Baltic States (Baltics).\n\nAccording to Russian psychiatrist Emmanuil Gushansky, the scale of psychiatric abuses in the past, the use of psychiatric doctrines by the totalitarian state have been thoroughly concealed. The archives of the Soviet Ministries of Internal Affairs (MVD) and Health (USSR Health Ministry), and of the Serbsky Institute for Forensic Psychiatry, which between them hold evidence about the expansion of psychiatry and the regulations governing that expansion, remain totally closed to researchers, says Gushansky. Dan Healey shares his opinion that the abuses of Soviet psychiatry under Stalin and, even more dramatically, in the 1960s to 1980s remain under-researched: the contents of the main archives are still classified and inaccessible. Hundreds of files on people who underwent forensic psychiatric examinations at the Serbsky Institute during Stalin's time are on the shelves of the highly classified archive in its basement where Gluzman saw them in 1989. All are marked by numbers without names or surnames, and any biographical data they contain is unresearched and inaccessible to researchers.\n\nAnatoly Sobchak, the former Mayor of Saint Petersburg, wrote:\nIn Ukraine, a study of the origins of the political abuse of psychiatry was conducted for five years on the basis of the State archives. A total of 60 people were again examined. All were citizens of Ukraine, convicted of political crimes and hospitalized on the territory of Ukraine. Not one of them, it turned out, was in need of any psychiatric treatment.\n\nFrom 1993 to 1995, a presidential decree on measures to prevent future abuse of psychiatry was being drafted at the Commission for Rehabilitation of the Victims of Political Repression. For this purpose, Anatoly Prokopenko selected suitable archival documents and, at the request of Vladimir Naumov, the head of research and publications at the Commission, Emmanuil Gushansky drew up the report. It correlated the archival data presented to Gushansky with materials received during his visits, conducted jointly with the commission of the Independent Psychiatric Association of Russia, to several strict-regime psychiatric hospitals (former Special Hospitals under MVD control). When the materials for discussion in the Commission for Rehabilitation of the Victims of Political Repression were ready, however, the work came to a standstill. The documents failed to reach the head of the Commission Alexander Yakovlev.\n\nThe report on political abuse of psychiatry prepared at the request of the Commission by Gushansky with the aid of Prokopenko lay unclaimed and even the \"Independent Psychiatric Journal\" (Nezavisimiy Psikhiatricheskiy Zhurnal) would not publish it. The Moscow Research Center for Human Rights headed by Boris Altshuler and Alexei Smirnov and the Independent Psychiatric Association of Russia whose president is Yuri Savenko were asked by Gushansky to publish the materials and archival documents on punitive psychiatry but showed no interest in doing so. Publishing such documents is dictated by present-day needs and by how far it is feared that psychiatry could again be abused for non-medical purposes.\n\nIn its 2000 report, the Commission for Rehabilitation of the Victims of Political Repression included only the following four phrases about the political abuse of psychiatry:\nIn the 1988 and 1989, about two million people were removed from the psychiatric registry at the request of Western psychiatrists. It was one of their conditions for the re-admission of Soviet psychiatrists to the World Psychiatric Association. Yury Savenko has provided different figures in different publications: about one million, up to one and a half million, about one and a half million people removed from the psychiatric registry. Mikhail Buyanov provided the figure of over two million people removed from the psychiatric registry.\n\nIn 1990, \"Psychiatric Bulletin of the Royal College of Psychiatrists\" published the article \"Compulsion in psychiatry: blessing or curse?\" by Russian psychiatrist Anatoly Koryagin. It contains analysis of the abuse of psychiatry and eight arguments by which the existence of a system of political abuse of psychiatry in the USSR can easily be demonstrated. As Koryagin wrote, in a dictatorial State with a totalitarian regime, such as the USSR, the laws have at all times served not the purpose of self-regulation of the life of society but have been one of the major levers by which to manipulate the behavior of subjects. Every Soviet citizen has constantly been straight considered state property and been regarded not as the aim, but as a means to achieve the rulers' objectives. From the perspective of state pragmatism, a mentally sick person was regarded as a burden to society, using up the state's material means without recompense and not producing anything, and even potentially capable of inflicting harm. Therefore, the Soviet State never considered it reasonable to pass special legislative acts protecting the material and legal part of the patients' life. It was only instructions of the legal and medical departments that stipulated certain rules of handling the mentally sick and imposing different sanctions on them. A person with a mental disorder was automatically divested of all rights and depended entirely on the psychiatrists' will. Practically anybody could undergo psychiatric examination on the most senseless grounds and the issued diagnosis turned him into a person without rights. It was this lack of legal rights and guarantees that advantaged a system of repressive psychiatry in the country.\n\nAccording to American psychiatrist Oleg Lapshin, Russia until 1993 did not have any specific legislation in the field of mental health except uncoordinated instructions and articles of laws in criminal and administrative law, orders of the USSR Ministry of Health. In the Soviet Union, any psychiatric patient could be hospitalized by request of his headman, relatives or instructions of a district psychiatrist. In this case, patient's consent or dissent mattered not. The duration of treatment in a psychiatric hospital also depended entirely on the psychiatrist. All of that made the abuse of psychiatry possible to suppress those who opposed the political regime, and that created the vicious practice of ignoring the rights of the mentally ill.\n\nAccording to Yuri Savenko, the president of the Independent Psychiatric Association of Russia (the IPA), punitive psychiatry arises on the basis of the interference of three main factors:\nTheir interaction system is principally sociological: the presence of the Penal Code article on slandering the state system inevitably results in sending a certain percentage of citizens to forensic psychiatric examination. Thus, it is not psychiatry itself that is punitive, but the totalitarian state uses psychiatry for punitive purposes with ease.\n\nAccording to Larry Gostin, the root cause of the problem was the State itself. The definition of danger was radically extended by the Soviet criminal system to cover \"political\" as well as customary physical types of \"danger\". As Bloch and Reddaway note, there are no objective reliable criteria to determine whether the person's behavior will be dangerous, and approaches to the definition of dangerousness greatly differ among psychiatrists.\n\nRichard Bonnie, a professor of law and medicine at the University of Virginia School of Law, mentioned the deformed nature of the Soviet psychiatric profession as one of the explanations for why it was so easily bent toward the repressive objectives of the state, and pointed out the importance of a civil society and, in particular, independent professional organizations separate and apart from the state as one of the most substantial lessons from the period.\n\nAccording to Norman Sartorius, a former president of the World Psychiatric Association, political abuse of psychiatry in the former Soviet Union was facilitated by the fact that the national classification included categories that could be employed to label dissenters, who could then be forcibly incarcerated and kept in psychiatric hospitals for \"treatment\". Darrel Regier, vice-chair of the DSM-5 task force, has a similar opinion that the political abuse of psychiatry in the USSR was sustained by the existence of a classification developed in the Soviet Union and used to organize psychiatric treatment and care. In this classification, there were categories with diagnoses that could be given to political dissenters and led to the harmful involuntary medication.\n\nAccording to Moscow psychiatrist Alexander Danilin, the so-called \"nosological\" approach in the Moscow psychiatric school established by Snezhnevsky boiles down to the ability to make the only diagnosis, schizophrenia; psychiatry is not science but such a system of opinions and people by the thousands are falling victims to these opinions—millions of lives were crippled by virtue of the concept \"sluggish schizophrenia\" introduced some time once by an academician Snezhnevsky, whom Danilin called a state criminal.\n\nSt Petersburg academic psychiatrist professor Yuri Nuller notes that the concept of Snezhnevsky's school allowed psychiatrists to consider, for example, schizoid psychopathy and even schizoid character traits as early, delayed in their development, stages of the inevitable progredient process, rather than as personality traits inherent to the individual, the dynamics of which might depend on various external factors. The same also applied to a number of other personality disorders. It entailed the extremely broadened diagnostics of sluggish (neurosis-like, psychopathy-like) schizophrenia. Despite a number of its controversial premises and in line with the traditions of then Soviet science, Snezhnevsky's hypothesis has immediately acquired the status of dogma which was later overcome in other disciplines but firmly stuck in psychiatry. Snezhnevsky's concept, with its dogmatism, proved to be psychologically comfortable for many psychiatrists, relieving them from doubt when making a diagnosis. That carried a great danger: any deviation from a norm evaluated by a doctor could be regarded as an early phase of schizophrenia, with all ensuing consequences. It resulted in the broad opportunity for voluntary and involuntary abuses of psychiatry. However, Snezhnevsky did not take civil and scientific courage to reconsider his concept which clearly reached a deadlock.\n\nAccording to American psychiatrist Walter Reich, the misdiagnoses of dissidents resulted from some characteristics of Soviet psychiatry that were distortions of standard psychiatric logic, theory, and practice.\n\nAccording to Semyon Gluzman, abuse of psychiatry to suppress dissent is based on condition of psychiatry in a totalitarian state. Psychiatric paradigm of a totalitarian state is culpable for its expansion into spheres which are not initially those of psychiatric competence. Psychiatry as a social institution, formed and functioning in the totalitarian state, is incapable of not being totalitarian. Such psychiatry is forced to serve the two differently directed principles: care and treatment of mentally ill citizens, on the one hand, and psychiatric repression of people showing political or ideological dissent, on the other hand. In the conditions of the totalitarian state, independent-minded psychiatrists appeared and may again appear, but these few people cannot change the situation in which thousands of others, who were brought up on incorrect pseudoscientific concepts and fear of the state, will sincerely believe that the uninhibited, free thinking of a citizen is a symptom of madness. Gluzman specifies the following six premises for the unintentional participation of doctors in abuses:\nGluzman says that there, of course, may be a different approach to the issue expressed by Michel Foucault.\nAccording to Michael Perlin, Foucault in his book \"Madness and Civilization\" documented the history of using institutional psychiatry as a political tool, researched the expanded use of the public hospitals in the 17th century in France and came to the conclusion that \"confinement [was an] answer to an economic crisis... reduction of wages, unemployment, scarcity of coin\" and, by the 18th century, the psychiatric hospitals satisfied \"the indissociably economic and moral demand for confinement.\"\n\nIn 1977, British psychiatrist David Cooper asked Foucault the same question which Claude Bourdet had formerly asked Viktor Fainberg during a press conference given by Fainberg and Leonid Plyushch: when the USSR has the whole penitentiary and police apparatus, which could take charge of anybody, and which is perfect in itself, why do they use psychiatry? Foucault answered it was not a question of a \"distortion\" of the use of psychiatry but that was its fundamental project. In the discussion \"Confinement, Psychiatry, Prison\", Foucault states the cooperation of psychiatrists with the KGB in the Soviet Union was not abuse of medicine, but an evident case and \"condensation\" of psychiatry's \"inheritance\", an \"intensification, the ossification of a kinship structure that has never ceased to function.\" Foucault believed that the abuse of psychiatry in the USSR of the 1960s was a logical extension of the invasion of psychiatry into the legal system. In the discussion with Jean Laplanche and Robert Badinter, Foucault says that criminologists of the 1880—1900s started speaking surprisingly modern language: \"The crime cannot be, for the criminal, but an abnormal, disturbed behavior. If he upsets society, it's because he himself is upset\". This led to the twofold conclusions. First, \"the judicial apparatus is no longer useful.\" The judges, as men of law, understand such complex, alien legal issues, purely psychological matters no better than the criminal. So commissions of psychiatrists and physicians should be substituted for the judicial apparatus. And in this vein, concrete projects were proposed. Second, \"We must certainly treat this individual who is dangerous only because he is sick. But, at the same time, we must protect society against him.\" Hence comes the idea of mental isolation with a mixed function: therapeutic and prophylactic. In the 1900s, these projects have given rise to very lively responses from European judicial and political bodies. However, they found a wide field of applications when the Soviet Union became one of the most common but by no means exceptional cases.\n\nAccording to American psychiatrist Jonas Robitscher, psychiatry has been playing a part in controlling deviant behavior for three hundred years. Vagrants, \"originals,\" eccentrics, and homeless wanderers who did little harm but were vexatious to the society they lived in were, and sometimes still are, confined to psychiatric hospitals or deprived of their legal rights. Some critics of psychiatry consider the practice as a political use of psychiatry and regard psychiatry as promoting timeserving.\n\nAs Vladimir Bukovsky and Semyon Gluzman point out, it is difficult for the average Soviet psychiatrist to understand the dissident's poor adjustment to Soviet society. This view of dissidence has nothing surprising about it—conformity reigned in Soviet consciousness; a public intolerance of non-conformist behavior always penetrated Soviet culture; and the threshold for deviance from custom was similarly low.\n\nAn example of the low threshold is a point of Donetsk psychiatrist Valentine Pekhterev, who argues that psychiatrists speak of the necessity of adapting oneself to society, estimate the level of man's social functioning, his ability to adequately test the reality and so forth. In Pekhterev's words, these speeches hit point-blank on the dissidents and revolutionaries, because all of them are poorly functioning in society, are hardly adapting to it either initially or after increasing requirements. They turn their inability to adapt themselves to society into the view that the company breaks step and only they know how to help the company restructure itself. The dissidents regard the cases of personal maladjustment as a proof of public ill-being. The more such cases, the easier it is to present their personal ill-being as public one. They bite the society's hand that feed them only because they are not given a right place in society. Unlike the dissidents, the psychiatrists destroy the hardly formed defense attitude in the dissidents by regarding \"public well-being\" as personal one. The psychiatrists extract teeth from the dissidents, stating that they should not bite the feeding hand of society only because the tiny group of the dissidents feel bad being at their place. The psychiatrists claim the need to treat not society but the dissidents and seek to improve society by preserving and improving the mental health of its members. After reading the book \"Institute of Fools\" by Viktor Nekipelov, Pekhterev concluded that allegations against the psychiatrists sounded from the lips of a negligible but vociferous part of inmates who when surfeiting themselves with cakes pretended to be sufferers.\n\nAccording to the response by Robert van Voren, Pekhterev in his article condescendingly argues that the Serbsky Institute was not so bad place and that Nekipelov exaggerates and slanders it, but Pekhterev, by doing so, misses the main point: living conditions in the Serbsky Institute were not bad, those who passed through psychiatric examination there were in a certain sense \"on holiday\" in comparison with the living conditions of the Gulag; and all the same, everyone was aware that the Serbsky Institute was more than the \"gates of hell\" from where people were sent to specialized psychiatric hospitals in Chernyakhovsk, Dnepropetrovsk, Kazan, Blagoveshchensk, and that is not all. Their life was transformed to unimaginable horror with daily tortures by forced administration of drugs, beatings and other forms of punishment. Many went crazy, could not endure what was happening to them, some even died during the \"treatment\" (for example, a miner from Donetsk Alexey Nikitin). Many books and memoirs are written about the life in the psychiatric Gulag and every time when reading them a shiver seizes us. The Soviet psychiatric terror in its brutality and targeting the mentally ill as the most vulnerable group of society had nothing on the Nazi euthanasia programs. The punishment by placement in a mental hospital was as effective as imprisonment in Mordovian concentration camps in breaking persons psychologically and physically. The recent history of the USSR should be given a wide publicity to immunize society against possible repetitions of the Soviet practice of political abuse of psychiatry. The issue remains highly relevant.\n\nAccording to Fedor Kondratev, an expert of the Serbsky Center and supporter of Snezhnevsky and his colleagues who developed the concept of sluggish schizophrenia in the 1960s, those arrested by the KGB under RSFSR Criminal Code Article 70 (\"anti-Soviet agitation and propaganda\"), 190-1 (\"dissemination of knowingly false fabrications that defame the Soviet state and social system\") made up, in those years, the main group targeted by the period of using psychiatry for political purposes. It was they who began to be searched for \"psychopathological mechanisms\" and, therefore, mental illness which gave the grounds to recognize an accused person as mentally incompetent, to debar him from appearance and defence in court, and then to send him for compulsory treatment to a special psychiatric hospital of the Ministry of Internal Affairs. The trouble (not guilt) of Soviet psychiatric science was its theoretical overideologization as a result of the strict demand to severely preclude any deviations from the \"exclusively scientific\" concept of Marxism–Leninism. This showed, in particular, in the fact that Soviet psychiatry under the totalitarian regime considered that penetrating the inner life of an ill person was flawed psychologization, existentionalization. In this connection, one did not admit the possibility that an individual can behave \"in a different way than others do\" not only because of his mental illness but on the ground alone of his moral sets consistently with his conscience. It entailed the consequence: if a person different from all others opposes the political system, one needs to search for \"psychopathological mechanisms\" of his dissent. Even in cases when catamnesis confirmed the correctness of a diagnosis of schizophrenia, it did not always mean that mental disorders were the cause of dissent and, all the more, that one needed to administer compulsory treatment \"for it\" in special psychiatric hospitals. What seems essential is another fact that the mentally ill could oppose the totalitarianism as well, by no means due to their \"psychopathological mechanisms\", but as persons who, despite having the diagnosis of schizophrenia, retained moral civic landmarks. Any ill person with schizophrenia could be a dissident if his conscience could not keep silent, Kondratev says.\n\nAccording to St Petersburg psychiatrist Vladimir Pshizov, with regard to punitive psychiatry, the nature of psychiatry is of such a sort that using psychiatrists against opponents of authorities is always tempting for the authorities, because it is seemingly possible not to take into account an opinion by the person who received a diagnosis. Therefore, the issue will always remain relevant. While we do not have government policy of using psychiatry for repression, psychiatrists and former psychiatric nomenklatura retained the same on-the-spot reflexes.\n\nAs Ukrainian psychiatrist Ada Korotenko notes, the use of punitive psychiatry allowed of avoiding the judicial procedure during which the accused might declare the impossibility to speak publicly and the violation of their civil rights. Making a psychiatric diagnosis is insecure and can be based on a preconception. Moreover, while diagnosing mental illness, subjective fuzzy diagnostic criteria are involved as arguments. The lack of clear diagnostic criteria and clearly defined standards of diagnostics contributes to applying punitive psychiatry to vigorous and gifted citizens who disagree with authorities. At the same time, most psychiatrists incline to believe that such a misdiagnosis is less dangerous than not diagnosing mental illness.\n\nGerman psychiattist Hanfried Helmchen says the uncertainty of diagnosis is prone to other than medical influence, e.g., political influence, as was the case with Soviet dissenters who were stifled by a psychiatric diagnosis, especially that of \"sluggish schizophrenia,\" in order to take them away from society in special psychiatric hospitals.\n\nAccording to Russian psychologist Dmitry Leontev, punitive psychiatry in the Soviet Union was based on the assumption that only a madman can go against public dogma and seek for truth and justice.\n\nK. Fulford, A. Smirnov, and E. Snow state: \"An important vulnerability factor, therefore, for the abuse of psychiatry, is the subjective nature of the observations on which psychiatric diagnosis currently depends.\" The concerns about political abuse of psychiatry as a tactic of controlling dissent have been regularly voiced by American psychiatrist Thomas Szasz, and he mentioned that these authors, who correctly emphasized the value-laden nature of psychiatric diagnoses and the subjective character of psychiatric classifications, failed to accept the role of psychiatric power. Musicologists, drama critics, art historians, and many other scholars also create their own subjective classifications; however, lacking state-legitimated power over persons, their classifications do not lead to anyone's being deprived of property, liberty, or life. For instance, plastic surgeon's classification of beauty is subjective, but the plastic surgeon cannot treat his or her patient without the patient's consent, therefore, there \"cannot\" be any political abuse of plastic surgery. The bedrock of political medicine is coercion masquerading as medical treatment. What transforms coercion into therapy are physicians \"diagnosing\" the person's condition a \"illness,\" \"declaring\" the intervention they impose on the victim a \"treatment,\" and legislators and judges \"legitimating\" these categorizations as \"illnesses\" and \"treatments.\" In the same way, physician-eugenicists advocated killing certain disabled or ill persons as a form of treatment for both society and patient long before the Nazis came to power. Szasz argued that the spectacle of the Western psychiatrists loudly condemning Soviet colleagues for their abuse of professional standards was largely an exercise in hypocrisy. Psychiatric abuse, such as people usually associated with practices in the former USSR, was connected not with the misuse of psychiatric diagnoses, but with the political power built into the social role of the psychiatrist in democratic and totalitarian societies alike. Psychiatrically and legally fit subjects for involuntary mental hospitalization had always been \"dissidents.\" It is the contents and contours of dissent that has changed. Before the American Civil War, dissent was constituted by being a Negro and wanting to escape from slavery. In Soviet Russia, dissent was constituted by wanting to \"reform\" Marxism or emigrate to escape from it. As Szasz put it, \"the classification by slave owners and slave traders of certain individuals as Negroes was scientific, in the sense that whites were rarely classified as blacks. But that did not prevent the \"abuse\" of such racial classification, because (what we call) its abuse was, in fact, its use.\" The collaboration between psychiatry and government leads to what Szasz calls the \"Therapeutic State\", a system in which disapproved actions, thoughts, and emotions are repressed (\"cured\") through pseudomedical interventions. Thus suicide, unconventional religious beliefs, racial bigotry, unhappiness, anxiety, shyness, sexual promiscuity, shoplifting, gambling, overeating, smoking, and illegal drug use are all considered symptoms or illnesses that need to be cured.\n\nAs Michael Robertson and Garry Walter suppose, psychiatric power in practically all societies expands on the grounds of public safety, which, in the view of the leaders of the USSR, was best maintained by the repression of dissidence. According to Gwen Adshead, a British forensic psychotherapist at the Broadmoor Hospital, the question is what is meant by the word \"abnormal.\" Evidently it is possible for abnormal to be identified as \"socially inappropriate.\" If that is the case, social and political dissent is turned into a symptom by the medical terminology, and thereby becomes an individual's personal problem, not a social matter.\n\nAccording to Russian psychiatrist Emmanuil Gushansky, psychiatry is the only medical specialty in which the doctor is given the right to violence for the benefit of the patient. The application of violence must be based on the mental health law, must be as much as possible transparent and monitored by representatives of the interests of persons who are in need of involuntary examination and treatment. While being hospitalized in a psychiatric hospital for urgent indications, the patient should be accompanied by his relatives, witnesses, or other persons authorized to control the actions of doctors and law-enforcement agencies. Otherwise, psychiatry becomes an obedient maid for administrative and governmental agencies and is deprived of its medical function. It is the police that must come to the aid of citizens and is responsible for their security. Only later, after the appropriate legal measures for social protection have been taken, the psychiatrist must respond to the queries of law enforcement and judicial authorities by solving the issues of involuntary hospitalization, sanity, etc. In Russia, all that goes by opposites. The psychiatrist is vested with punitive functions, is involved in involuntary hospitalization, the state machine hides behind his back, actually manipulating the doctor. The police are reluctant to investigate offences committed by the mentally ill. After receiving the information about their disease, the bodies of inquiry very often stop the investigation and do not bring it to the level of investigative actions. Thereby psychiatry becomes a cloak for the course of justice and, by doing so, serves as a source for the rightlessness and stigmatization of both psychiatrists and persons with mental disorders. The negative attitude to psychiatrists is thereby supported by the state machine and is accompanied by the aggression against the doctors, which increases during the periods of social unrest.\n\nVladimir Bukovsky, well known for his struggle against political abuse of psychiatry in the Soviet Union, explained that using psychiatry against dissidents was usable to the KGB because hospitalization did not have an end date, and, as a result, there were cases when dissidents were kept in psychiatric prison hospitals for 10 or even 15 years. \"Once they pump you with drugs, they can forget about you\", he said and added, \"I saw people who basically were asleep for years.\"\n\nUS President Ronald Reagan attributed the view that the \"brutal treatment of Soviet dissidents was due to bureaucratic inertia.\"\n\nIn the opinion of the Moscow Helsinki Group chairwoman Lyudmila Alexeyeva, the attribution of a mental illness to a prominent figure who came out with a political declaration or action is the most significant factor in the assessment of psychiatry during the 1960–1980s. The practice of forced confinement of political dissidents in psychiatric facilities in the former USSR and Eastern Europe destroyed the credibility of psychiatric practice in these countries. When psychiatric profession is discredited in one part of the world, psychiatry is discredited throughout the world. Psychiatry lost its professional basis entirely with its abuse to stifle dissidence in the former USSR and in the so-called euthanasia program in Nazi Germany. There is little doubt that the capacity for using psychiatry to enforce social norms and even political interests is immense. Now psychiatry is vulnerable because many of its notions have been questioned, and the sustainable pattern of mental life, of boundaries of mental norm and abnormality has been lost, director of the Moscow Research Institute for Psychiatry Valery Krasnov says, adding that psychiatrists have to seek new reference points to make clinical assessments and new reference points to justify old therapeutical interventions.\n\nAs Emmanuil Gushansky states, today subjective position of a Russian patient toward a medical psychologist and psychiatrist is defensive in nature and prevents the attempt to understand the patient and help him assess his condition. Such a position is related to constant, subconscious fear of psychiatrists and psychiatry. This fear is caused by not only abuse of psychiatry, but also constant violence in the totalitarian and post-totalitarian society. The psychiatric violence and psychiatric arrogance as one of manifestations of such violence is related to the primary emphasis on symptomatology and biological causes of a disease, while ignoring psychological, existential, and psychodynamic factors. Gushainsky notices that the modern Russian psychiatry and the structure of providing mental health care are aimed not at protecting the patient's right to an own place in life, but at discrediting such a right, revealing symptoms and isolating the patient.\n\nThe psychiatrist became a scarecrow attaching psychiatric labels. He is feared, is not confided, is not taken into confidence in the secrets of one's soul and is asked to provide only medications. Psychiatric labels, or stigmas, have spread so widely that there is no such thing as the media that does not call a disliked person \"schizo\" and does not generalize psychiatric assessments to phenomena of public life. The word \"psikhushka\" entered everyday vocabulary. All persons who deviate from the usual standards of thought and behavior are declared mentally ill, with an approving giggling of public. Not surprisingly, during such a stigmatization, people with real mental disorders fear publicity like the plague. Vilnius psychologist Oleg Lapin has the same point that politicians and the press attach psychological, psychiatric and medical labels; he adds that psychiatry has acquired the new status of normalizing life that was previously possessed by religion. Formerly, one could say: you are going against God or God is with us; now one can say: I behave reasonably, adequately, and you do not behave in that way. In 2007, Alexander Dugin, a professor at the Moscow State University and adviser to State Duma speaker Sergei Naryshkin, presented opponents of Vladimir Putin's policy as mentally ill by saying, \"There are no longer opponents of Putin's policy, and if there are, they are mentally ill and should be sent to prophylactic health examination.\" In \"The Moscow Regional Psychiatric Newspaper\" of 2012, psychiatrist Dilya Enikeyeva in violation of medical privacy and ethics publicized the diagnosis of histrionic personality disorder, which she in absentia gave Kseniya Sobchak, a Russian TV anchor and a member of political opposition, and stated that Sobchak was harmful to society.\n\nRobert van Voren noted that after the fall of the Berlin Wall, it became apparent that the political abuse of psychiatry in the USSR was only the tip of the iceberg, the sign that much more was basically wrong. This much more realistic image of Soviet psychiatry showed up only after the Soviet regime began to loosen its grip on society and later lost control over the developments and in the end entirely disintegrated. It demonstrated that the actual situation was much sorer and that many individuals had been affected. Millions of individuals were treated and stigmatized by an outdated biologically oriented and hospital-based mental health service. Living conditions in clinics were bad, sometimes even terrible, and violations of human rights were rampant. According to the data of a census published in 1992, the mortality of the ill with schizophrenia exceeded that of the general population by 4–6 times for the age of 20–39 years, by 3–4 times for the age of 30–39 years, by 1.5–2 times for the age over 40 years (larger values are for women).\n\nAccording to Robert van Voren, although for several years, especially after the implosion of the USSR and during the first years of Boris Yeltsin's rule, the positions of the Soviet psychiatric leaders were in jeopardy, now one can firmly conclude that they succeeded in riding out the storm and retaining their powerful positions. They also succeeded in avoiding an inflow of modern concepts of delivering mental health care and a fundamental change in the structure of psychiatric services in Russia. On the whole, in Russia, the impact of mental health reformers has been the least. Even the reform efforts made in such places as St. Petersburg, Tomsk, and Kaliningrad have faltered or were encapsulated as centrist policies under Putin brought them back under control.\n\nThroughout the post-communist period, the pharmaceutical industry has mainly been an obstacle to reform. Aiming to explore the vast market of the former USSR, they used the situation to make professionals and services totally dependent on their financial sustenance, turned the major attention to the availability of medicines rather than that of psycho-social rehabilitation services, and stimulated corruption within the mental health sector very much.\n\nAt the turn of the century, the psychiatric reform that had been implemented by Franco Basaglia in Italy became known and was publicly declared to be implemented in Russia, with the view of retrenchment of expenditures. But when it became clear that even more money was needed for the reform, it got bogged down in the same way the reform of the army and many other undertakings did. Russia is decades behind the countries of the European Union in mental health reform, which has already been implemented or is being implemented in them. Until Russian society, Gushansky says, is aware of the need for mental health reform, we will live in the atmosphere of animosity, mistrust and violence. Many experts believe that problems spread beyond psychiatry to society as a whole. As Robert van Voren supposes, the Russians want to have their compatriots with mental disorders locked up outside the city and do not want to have them in community. Despite the 1992 Russian Mental Health Law, coercive psychiatry in Russia remains generally unregulated and fashioned by the same trends toward hyperdiagnosis and overreliance on institutional care characteristic of the Soviet period. In the Soviet Union, there had been an increase of the bed numbers because psychiatric services had been used to treat dissidents.\n\nIn 2005, the Russian Federation had one of the highest levels of psychiatric beds per capita in Europe at 113.2 per 100,000 population, or more than 161,000 beds. In 2014, Russia has 104.8 beds per 100,000 population and no actions have been taken to arrange new facilities for outpatient services. Persons who do not respond well to treatment at dispensaries can be sent to long-term social care institutions (internats) wherein they remain indefinitely. The internats are managed by oblast Social Protection ministries. Russia had 442 psychoneurologic internats by 1999, and their number amounted to 505 by 2013. The internats provided places for approximately 125,000 people in 2007. In 2013, Russian psychoneurologic internats accommodated 146,000 people, according to the consolidated data of the Department of Social Protection of Moscow and the Ministry of Labour and Social Protection of the Russian Federation. It is supposed that the number of beds in internats is increasing at the same rate with which the number of beds is decreasing in psychiatric hospitals. Lyubov Vinogradova of the Independent Psychiatric Association of Russia provides the different figure of 122,091 or 85.5 places in psychoneurologic institutions of social protection (internats) per 100,000 population in 2013 and says that Russia is high on Europe's list of the number of places in the institutions. Vinogradova states that many regions have the catastrophic shortage of places in psychoneurological internats, her words point out to the need to increase the number of places there and to the fact that the Independent Psychiatric Association of Russia is forcing transinstitutionalization—relocating the mentally ill from their homes and psychiatric hospitals to psychoneurological internats.\n\nAt his press conference in 2008, Semyon Gluzman said that the surplus in Ukraine of hospitals for inpatient treatment of the mentally ill was a relic of the totalitarian communist regime and that Ukraine did not have epidemic of schizophrenia but somehow Ukraine had about 90 large psychiatric hospitals including the Pavlov Hospital where beds in its children's unit alone were more than in the whole of Great Britain. In Ukraine, public opinion did not contribute to the protection of citizens against possible recurrence of political abuse of psychiatry. There were no demonstrations and rallies in support of the mental health law. But there was a public campaign against developing the civilized law and against liberalizing the provision of psychiatric care in the country. The campaign was initiated and conducted by relatives of psychiatric patients. They wrote to newspapers, yelled in busy places and around them, behaved in the unbridled way in ministerial offices and corridors. Once Gluzman saw through a trolleybus window a group of 20-30 people standing by a window of the Cabinet of Ministers of Ukraine with red flags, portraits of Lenin and Stalin and the slogan coarsely written on the white cardboard: \"Get the Gluzman psychiatry off Ukraine!\" Activists of the dissident movement far from the nostalgia for the past also participated in the actions against changes in the mental health system. But in general, it should be remembered that all these protest actions have been activated by nomenklatura psychiatrists. The whole Ukrainian psychiatric system actually consists of the two units: hospital for treatment of acute psychiatric conditions and internat-hospice for helpless \"chronic patients\" unable to live on their own. And between hospital and internat-hospice is desert. That is why about 40 percent of patients in any Ukrainian psychiatric hospital are so-called social patients whose stay in the psychiatric hospital is not due to medical indications. A similar pattern is in internats. A significant part of their lifelong customers could have lived long enough in society despite their mental illnesses. They could have lived quite comfortably and safely for themselves and others in special dorms, nursing homes, \"halfway houses\". Ukraine does not have anything like that.\n\nIn the Soviet times, mental hospitals were frequently created in former monasteries, barracks, and even concentration camps. Sofia Dorinskaya, a human rights activist and psychiatrist, says she saw former convicts who have been living in a Russian mental hospital for ten years and will have been staying there until their dying day because of having no home. Deinstitutionalization has not touched many of the hospitals, and persons still die inside them. In 2013, 70 persons died in a fire just outside Novgorod and Moscow. Living conditions are often insufficient and sometimes horrible: 12 to 15 patients in a big room with bars on the windows, no bedside tables, often no partitions, not enough toilets. The number of outpatient clinics designed for the primary care of the mentally disordered stopped increasing in 2005 and was reduced to 277 in 2012 as against 318 in 2005. Stigma linked to mental disease is at the level of xenophobia. The Russian public perceive the mentally sick as harmful, useless, incurable, and dangerous. The social stigma is maintained not only by the general public but also by psychiatrists.\n\nTraditional values have endured the attempt by western institutions to impose a positive image of deviant behavior. For instance, in spite of the removal of homosexuality from the nomenclature of mental disorders, 62.5% of 450 surveyed psychiatrists in the Rostov Region view it as an illness, and up to three quarters view it as immoral behavior. The psychiatrists sustain the ban on gay parades and the use of veiled schemes to lay off openly lesbian and gay persons from schools, child care centers, and other public institutions. The chief psychiatrist of Russia Zurab Kekelidze in his 2013 interview to Dozhd says that a part of the cases of homosexuality is a mental disorder, he counters the remark that the World Health Organization removed homosexuality from the list of mental disorders by stating that it is not true. Homosexuality, which is a mental disorder, was continuously defined as such by the Independent Psychiatric Association of Russia in 2005 when its president Savenko expressed their joint surprise at the proposal by the Executive Committee of the American Psychiatric Association to exclude homosexuality as a mental disorder from manuals on psychiatry due to political pressure from western NGOs and governments, referred the proposal to antipsychiatric actions, and stated that ideological, social and liberal reasoning for the proposal was substituted for scientific one. In 2014, Savenko changed his mind about homosexuality, and he along with Alexei Perekhov succumb to pressure and, in their joint paper criticized and referred the trend to consider homosexuality as a mental disorder to Soviet mentality.\n\nIn 1994, there was organized a conference concerned with the theme of political abuse of psychiatry and attended by representatives from different former Soviet Republics — from Russia, Belarus, the Baltics, the Caucasus, and some of the Central Asian Republics. Dainius Puras made a report on the situation within the Lithuanian Psychiatric Association, where discussion had been held but no resolution had been passed. Yuri Nuller talked over how in Russia the wind direction was gradually changing and the systematic political abuse of psychiatry was again being denied and degraded as an issue of \"hyperdiagnosis\" or \"scientific disagreement.\" It was particularly noteworthy that Tatyana Dmitrieva, the then Director of the Serbsky Institute, was a proponent of such belittlement. This was not so queer, because she was a close friend of the key architects of \"political psychiatry.\"\n\nIn the early 1990s, she spoke the required words of repentance for political abuse of psychiatry which had had unprecedented dimensions in the Soviet Union for discrediting, intimidation and suppression of the human rights movement carried out primarily in this institution. Her words were widely broadcast abroad but were published only in the St. Petersburg newspaper \"Chas Pik\" within the country. However, in her 2001 book \"Aliyans Prava i Milosediya\" (\"The Alliance of Law and Mercy\"), Dmitrieva wrote that there were no psychiatric abuses and certainly no more than in Western countries. Moreover, the book makes the charge that professor Vladimir Serbsky and other intellectuals were wrong not to cooperate with the police department in preventing revolution and bloodsheds and that the current generation is wrong to oppose the regime. In 2007, Dmitrieva asserted that the practice of \"punitive psychiatry\" had been grossly exaggerated, while nothing wrong had been done by the Serbsky Institute. After that an official at the Serbsky Institute declared \"patient\" Vladimir Bukovsky, who was then going to run for the President of the Russian Federation, undoubtedly \"psychopathic\".\n\nWhile speaking of the Serbsky Center, Yuri Savenko alleges that \"practically nothing has changed. They have no shame at the institute about their role with the Communists. They are the same people, and they do not want to apologize for all their actions in the past.\" Attorney Karen Nersisyan agrees: \"Serbsky is not an organ of medicine. It's an organ of power.\" According to human rights activist and former psychiatrist Sofia Dorinskaya, the system of Soviet psychiatry has not been destroyed, the Serbsky Institute is standing where it did, the same people who worked in the Soviet system are working there. She says we have a situation like after the defeat of fascism in Germany, when fascism officially collapsed, but all governors of acres, judges and all people remained after the fascist regime.\n\nIn his article of 2002, Alan A. Stone, who as a member of team had examined Pyotr Grigorenko and found him mentally healthy in 1979, disregarded the findings of the World Psychiatric Association and the later avowal of Soviet psychiatrists themselves and put forward the academically revisionist theory that there was no political abuse of psychiatry as a tool against pacific dissidence in the former USSR. He asserted that it was time for psychiatry in the Western countries to reconsider the supposedly documented accounts of political abuse of psychiatry in the USSR in the hope of discovering that Soviet psychiatrists were more deserving of sympathy than condemnation. In Stone's words, he believes that Snezhnevsky was wrongly condemned by critics. According to Stone, one of the first points the Soviet psychiatrists who have been condemned for unethical political abuse of psychiatry make is that the revolution is the greatest good for the greatest number, the greatest piece of social justice, and the greatest beneficence imaginable in the twentieth century. In the Western view, the ethical compass of the Soviet psychiatrists begins to wander when they act in the service of this greatest beneficence.\n\nAccording to St Petersburg psychiatrist Vladimir Pshizov, a disastrous factor for domestic psychiatry is that those who had committed the crime against humanity were allowed to stay on their positions until they can leave this world in a natural way. Those who retained their positions and influence turned domestic psychiatry from politically motivated one to criminally motivated one because the sphere of interests of this public has been reduced to making a business of psychopharmacologic drugs and taking possession of the homes of the ill. In Soviet times, all the heads of departments of psychiatry, all the directors of psychiatric research institutes, all the head doctors of psychiatric hospitals were the CPSU nomenklatura, which they remained so far. The representative of nomenklatura in psychiatry had the scheme of career that is simple and often stereotyped: for one to two years, he run errands as a resident, then joined the party and became a partgrouporg. His junior colleagues (usually non-partisan ones) collected and processed material for his dissertation. Its review of literature, particularly in a research institute for psychiatry, was often written by patients, because only they knew foreign languages, and their party comrades were not up to it, the natural habitat did not stimulate learning a foreign language.\n\nRobert van Voren also says Russian psychiatry is now being headed by the same psychiatrists who was heading psychiatry in Soviet times. Since then Russian psychiatric system has not almost changed. In reality, we still see a sort of the Soviet psychiatry that was in the late 1980s. Russian psychiatrists do not have access to specialized literature published in other countries and do not understand what is world psychiatry. Staff training has not changed, literature is inaccessible, the same psychiatrists teach new generations of specialists. Those of them who know what is world psychiatry and know it is not the same as what is happening in Russia are silent and afraid. The powerful core of the old nomenklatura in psychiatry was concentrated in Moscow, and it was clear that the struggle inside their fortress would be not only difficult, but also it would be a waste of time, energy and resources, so the Global Initiative on Psychiatry has been avoiding Moscow almost completely for all the years. Instead, the Global Initiative on Psychiatry took active part in projects for reforming the mental health service in Ukraine, donated a printing plant to Ukrainian public, organized a publishing house, helped print a huge amount of medical and legal literature distributed for free, but the Ukrainian tax police accused the publishing house of manufacturing counterfeit dollars, and a significant part of humanitarian aid that the Global Initiative on Psychiatry had gathered in the Netherlands for Ukrainian psychiatric hospitals was stolen in Kiev.\n\nMany of the current leaders of Russian psychiatry, especially those who were related to the establishment in Soviet period, have resiled from their avowal read at the 1989 General Assembly of the WPA that Soviet psychiatry had been systematically abused for political purposes. Among such leaders who did so is Aleksandr Tiganov, a pupil of Snezhnevsky, full member of the Russian Academy of Medical Sciences, the director of its Mental Health Research Center, and the chief psychiatrist of the Ministry of Health of the Russian Federation. In 2011, when asked whether ill or healthy were those examined because of their disagreements with authority, Tiganov answered, \"These people suffered from sluggish schizophrenia and were on the psychiatric registry.\" According to Tiganov, it was rumored that Snezhnevsky took pity on dissenters and gave them a diagnosis required for placing in a special hospital to save them from a prison, but it is not true, he honestly did his medical duty. The same ideas are voiced in the 2014 interview by Anatoly Smulevich, a pupil of Snezhnevsky, full member of the Russian Academy of Medical Sciences; he says what was attributed to Snesnevsky was that he recognized the healthy as the ill, it did not happen and is pure slander, it is completely ruled out for him to give a diagnosis to a healthy person.\n\nIn 2007, Mikhail Vinogradov, one of the leading staff members of the Serbsky Center, strongly degraded the human rights movement of the Soviet era in every possible way and tried to convince that all political dissidents who had been to his institution were indeed mentally ill. In his opinion, \"now it is clear that all of them are deeply affected people.\" In 2012, Vinogradov said the same, \"Do you talk about human rights activists? Most of them are just unhealthy people, I talked with them. As for the dissident General Grigorenko, I too saw him, kept him under observation, and noted oddities of his thinking. But he was eventually allowed to go abroad, as you know... Who? Bukovsky? I talked with him, and he is a completely crazy character. But he too was allowed to go abroad! You see, human rights activists are people who, due to their mental pathology, are unable to restrain themselves within the standards of society, and the West encourages their inability to do so.\" In the same year, he offered to restore Soviet mental health law and said it \"has never been used for political persecution.\" Human rights activists who claim it did, in Vinogradov's words, \"are not very mentally healthy.\"\n\nRussian psychiatrist Fedor Kondratev not only denied accusations that he was ever personally engaged in Soviet abuses of psychiatry; he stated publicly that the very conception of the existence of Soviet-era \"punitive psychiatry\" was nothing more than: \"the fantasy [vymysel] of the very same people who are now defending totalitarian sects. This is slander, which was [previously] used for anti-Soviet ends, but is now being used for anti-Russian ends.\" He says that there were attempts to use of psychiatry for political purposes but there was no mass psychiatric terror, he calls allegations about the terror a propagandistic weapon of activists of the Cold War. As Alexander Podrabinek writes, psychiatrists of punitive conscription and namely Kondratev are relatively indifferent to the public's indignation over illegal use of psychiatry both in Soviet times and now, they do not notice this public, allowing themselves to ignore any unprofessional opinion. In response to the article by Podrabinek, Kondratev instituted a suit against Podrabinek under Russian Civil Code Article 152 on protecting one's honor, dignity and business reputation. According to Valery Krasnov and Isaak Gurovich, official representatives of psychiatry involved in its political abuse never acknowledged the groundlessness of their diagnostics and actions. The absence of the acknowledgement and the absence of an analysis of made errors cast a shadow upon all psychiatrists in the USSR and, especially, in Russia. As Russian-American historian Georgi Chernyavsky writes, after the fall of the communist regime, no matter how some psychiatrists lean over backwards, foaming at the mouth to this day when stating that they were slandered, that they did not give dissidents diagnoses-sentences, or that, at least, these cases were isolated and not at all related to their personal activities, no matter how the doctors, if one may call them so, try to rebut hundreds if not thousands of real facts, it is undoable.\n\nIn 2004, Savenko stated that the passed law on the state expert activity and the introduction of the profession of forensic expert psychiatrist actually destroyed adversary-based examinations and that the Serbsky Center turned into the complete monopolist of forensic examination, which it had never been under Soviet rule. Formerly, the court could include any psychiatrist in a commission of experts, but now the court only chooses an expert institution. The expert has the right to participate only in commissions that he is included in by the head of his expert institution, and can receive the certificate of qualification as an expert only after having worked in a state expert institution for three years. The Director of the Serbsky Center Dmitrieva was, at the same time, the head of the forensic psychiatry department which is the only one in the country and is located in her Center. No one had ever had such a monopoly.\n\nAccording to Savenko, the Serbsky Center has long labored to legalize its monopolistic position of the Main expert institution of the country. The ambition and permissiveness—which, due to proximity to power, allow the Serbsky Center to get in touch over the telephone with the judges and explain to them who is who and what is the guideline, although the judges themselves have already learned it—have turned out to be a considerable drop in the level of the expert reports on many positions. Such a drop was inevitable and foreseeable in the context of the Serbsky Center efforts to eliminate adversary character of the expert reports of the parties, then to maximally degrade the role of the specialist as a reviewer and critic of the presented expert report, and to legalize the state of affairs. Lyubov Vinogradova believes there has been a continuous diminution in patients' rights as independent experts are now excluded from processes, cannot speak in court and can do nothing against the State experts.\n\nOn 28 May 2009, Yuri Savenko wrote to the then President of the Russian Federation Dmitry Medvedev an open letter, in which Savenko asked Medvedev to submit to the State Duma a draft law prepared by the Independent Psychiatric Association of Russia to address the sharp drop in the level of forensic psychiatric examinations, which Savenko attributed to the lack of competition within the sector and its increasing nationalization. The open letter says that the level of the expert reports has dropped to such an extent that it is often a matter of not only the absence of entire sections of the report, even such as the substantiation of its findings, and not only the gross contradiction of its findings to the descriptive section of the report, but it is often a matter of concrete statements which are so contrary to generally accepted scientific terms that doubts about the disinterestedness of the experts arise. According to the letter, courts, in violation of procedural rules, do not analyze the expert report, its coherence and consistency in all its parts, do not check experts' findings for their accuracy, completeness, and objectivity.\n\nOn 15 June 2009, the working group chaired by the Director of the Serbsky Center Tatyana Dmitrieva sent the Supreme Court of the Russian Federation a joint application whose purport was to declare appealing against the forensic expert reports of state expert institutions illegal and prohibit courts from receiving lawsuits filed to appeal against the reports. The reason put forward for the proposal was that the appeals against the expert reports were allegedly filed \"without regard for the scope of the case\" and that one must appeal against the expert report \"only together with the sentence.\" In other words, according to Yuri Savenko, all professional errors and omissions are presented as untouchable by virtue of the fact that they were infiltrated into the sentence. That is cynicism of administrative resources, cynicism of power, he says.\n\nThe draft of the application to the Supreme Court of the Russian Federation was considered in the paper \"Current legal issues relevant to forensic-psychiatric expert evaluation\" by Elena Shchukina and Sergei Shishkov focusing on the inadmissibility of appealing against the expert report without regard for the scope of the evaluated case. While talking about appealing against \"the reports\", the authors of the paper, according to lawyer Dmitry Bartenev, mistakenly identify the reports with actions of the experts (or an expert institution) and justify the impossibility of the \"parallel\" examination and evaluation of the actions of the experts without regard for the scope of the evaluated case. Such a conclusion made by the authors appears clearly erroneous because abuse by the experts of rights and legitimate interests of citizens including trial participants, of course, may be a subject for a separate appeal.\n\nAccording to the warning made in 2010 by Yuri Savenko at the same Congress, prof. Anatoly Smulevich, author of the monographs \"Problema Paranoyi\" (\"The Problem of Paranoia\") (1972) and \"Maloprogredientnaya Shizofreniya\" (\"Continuous Sluggish Schizophrenia\") (1987), which had contributed to the hyperdiagnosis of \"sluggish schizophrenia\", again began to play the same role he played before. Recently, under his influence therapists began to widely use antidepressants and antipsychotics but often in inadequate cases and in inappropriate doses, without consulting psychiatrists. This situation has opened up a huge new market for pharmaceutical firms, with their unlimited capabilities, and the flow of the mentally ill to internists. Smulevich bases the diagnosis of continuous sluggish schizophrenia, in particular, on appearance and lifestyle and stresses that the forefront in the picture of negative changes is given to the contrast between retaining mental activity (and sometimes quite high capacity for work) and mannerism, unusualness of one's appearance and entire lifestyle.\n\nAccording to the commentary by the Independent Psychiatric Association of Russia on the 2007 text by Vladimir Rotstein, a doctrinist of Snezhnevsky's school, there are sufficient patients with delusion of reformism in psychiatric inpatient facilities for involuntary treatment. In 2012, delusion of reformism was mentioned as a symptom of mental disorder in \"Psychiatry. National Manual\" edited by Tatyana Dmitrieva, Valery Krasnov, Nikolai Neznanov, Valentin Semke, and Alexander Tiganov. In the same year, Vladimir Pashkovsky in his paper reported that he diagnosed 4.7 percent of 300 patients with delusion of reform. As Russian sociologist Alexander Tarasov notes, you will be treated in a hospital so that you and all your acquaintances get to learn forever that only such people as Anatoly Chubais or German Gref can be occupied with reforming in our country; and you are suffering from \"syndrome of litigiousness\" if in addition you wrote to the capital city complaints, which can be written only by a reviewing authority or lawyer.\n\nAccording to Doctor of Legal Sciences Vladimir Ovchinsky, regional differences in forensic psychiatric expert reports are striking. For example, in some regions of Russia, 8 or 9 percent of all examinees are pronounced sane; in other regions up to 75 percent of all examinees are pronounced sane. In some regions less than 2 percent of examinees are declared schizophrenics; in other regions up to 80 percent of examinees are declared schizophrenics.\n\nIn April 1995, the State Duma considered the first draft of a law that would have established a State Medical Commission with a psychiatrist to certify the competence of the President, the Prime Minister, and high federal political officials to fulfill the responsibilities of their positions. In 2002, Ukrainian psychiatrist Ada Korotenko stated that today the question was raised about the use of psychiatry to settle political accounts and establish psychiatric control over people competing for power in the country. Obviously, one will find supporters of the feasibility of such a filter, she said, though is it worthwhile to substitute experts' medical reports for elections? In 2003, the suggestion of using psychiatry to prevent and dismiss officials from their positions was supported by Alexander Podrabinek, author of the book \"Punitive Medicine\", a 265-page monograph covering political abuses of psychiatry in the Soviet Union. He suggested that people who seek high positions or run for the legislature should bring from the psychiatric dispensary a reference that they are not on the psychiatric registry and should be subjected to psychiatric examination in the event of inappropriate behavior. Concerned about the problem, authorities ruled that the Russian Mental Health Law should not be applied to senior officials and the judiciary on the ground that they are vested with parliamentary or judicial immunity. A psychiatrist who violates this rule can be deprived of his diploma and sentenced to imprisonment. In 2011, Russian psychiatrists again tried to promote the idea that one's marked aspiration in itself for power can be referred to psychopathic symptoms and that there are statistics about 60 percent of current leaders of states suffering from various forms of mental abnormalities.\n\nThe evidence for the misuse of psychiatry for political purposes in the Soviet Union was documented in a number of articles and books. Several national psychiatric associations examined and acted upon this documentation.\n\nThe widely known sources including published and written memoirs by victims of psychiatric arbitrariness convey moral and physical sufferings experienced by the victims in special psychiatric hospitals of the USSR.\n\nIn August 1969, Natalya Gorbanevskaya completed \"Noon\" (\"Полдень\"), her book about the case of the 25 August 1968 Demonstration on Red Square and began circulating it in samizdat. It was translated into English and published under the title \"Red Square at Noon\". Parts of the book describe Special Psychiatric Hospitals and psychiatric examinations of dissidents. The book includes \"On Special Psychiatric Hospitals\", an article written by Pyotr Grigorenko in 1968.\n\nIn 1971, twin brothers Zhores Medvedev and Roy Medvedev published in London their joint account of Zhores' incarceration in a psychiatric hospital and the Soviet practice of diagnosing political oppositionists as the mentally ill in London, in both English \"A Question of Madness: Repression by Psychiatry in the Soviet Union\" and Russian (\"Who is Mad?\" \"Кто сумасшедший\") editions.\n\nYury Maltsev's \"Report from a Madhouse\", his memoirs in Russian (\"Репортаж и сумасшедшего дома\"), were issued by the New York-based \"Novy zhurnal\" publishing house in 1974.\n\n1975 saw the article \"My Five Years in Mental Hospitals\" by Viktor Fainberg, who had emigrated to France the previous year after four years in the Leningrad Special Psychiatric Hospital.\n\nIn 1976, Viktor Nekipelov published in samizdat his book \"Institute of Fools: Notes on the Serbsky Institute\" documenting his personal experiences during two months' examination at the Serbsky Institute in Moscow. In 1980, the book was translated and published in English. The book was first published in Russia in 2005.\n\nVarious documents and reports were published in the \"Information Bulletin\" of the Working Commission on the Abuse of Psychiatry For Political Purposes, and circulated in the samizdat periodical \"Chronicle of Current Events.\" Other sources were documents by the Moscow Helsinki Group and in books by Alexander Podrabinek (\"Punitive Medicine\", 1979) Anatoly Prokopenko (\"Mad Psychiatry\", 1997, \"Безумная психитрия\") by and Vladimir Bukovsky (\"Judgment in Moscow\", 1994). To these may be added \"Soviet psychiatry – fallacies and fantasy\" by Ada Korotenko and Natalia Alikina (\"Советская психиатрия. Заблуждения и умысел\") and \"Executed by Madness\", 1971 (\"Казнимые сумасшествием\").\n\nIn 1972, 1975, 1976, 1984, and 1988 the United States Government Printing Office published documents on political abuse of psychiatry in the Soviet Union .\n\nFrom 1987 to 1991, the International Association on the Political Use of Psychiatry (IAPUP) published forty-two volumes of \"Documents on the Political Abuse of Psychiatry in the USSR\". Today these are preserved by the Columbia University Libraries in the archival collection entitled \"Human\nRights Watch Records: Helsinki Watch, 1952–2003, Series VII: Chris\nPanico Files, 1979–1992, USSR, Psychiatry, International Association on\nthe Political Use of Psychiatry\", Box 16, Folder 5–8 (English version) and Box 16, Folder 9–11 (Russian version).\n\nIn 1992, the British Medical Association published certain some documents on the subject in \"Medicine Betrayed: The Participation of Doctors in Human Rights Abuses\".\n\nIn 1978, the book \"I Vozvrashchaetsa Veter...\" (\"And the Wind Returns...\") by Vladimir Bukovsky, describing the dissident movement, their struggle or freedom, practices of dealing with dissenters, and dozen years spent by Bukovsky in Soviet labor camps, prisons and psychiatric hospitals, was published and later translated into English under the title \"To Build a Castle: My Life as a Dissenter\".\n\nIn 1979, Leonid Plyushch published his book \"Na Karnavale Istorii\" (\"At History's Сarnival\") in which he described how he and other dissidents were committed to psychiatric hospitals. The same year, the book was translated into English under the title \"History's Carnival: A Dissident's Autobiography\".\n\nIn 1980, the book by Yuri Belov \"Razmyshlenia ne tolko o Sychovke: Roslavl 1978\" (\"Reflections not only on Sychovka: Roslavl 1978\") was published.\n\nIn 1981, Pyotr Grigorenko published his memoirs \"V Podpolye Mozhno Vstretit Tolko Krys\" (\"In Underground One Can Meet Only Rats\"), which included the story of his psychiatric examinations and hospitalizations. In 1982, the book was translated into English under the title \"Memoirs\".\n\nIn 1982, Soviet philosopher Pyotr Abovin-Yegides published his article \"Paralogizmy politseyskoy psikhiatrii i ikh sootnoshenie s meditsinskoy etikoy (Paralogisms of police psychiatry and their relation to medical ethics).\"\n\nIn 1983, Evgeny Nikolaev's book \"Predavshie Gippokrata\" (\"Betrayers of Hippocrates\"), when translated from Russian into German under the title \"Gehirnwäsche in Moskau\" (\"Brainwashing in Moscow\"), first came out in München and told about psychiatric detention of its author for political reasons. In 1984, the book under its original title was first published in Russian which the book had originally been written in.\n\nIn 1983, Yuri Vetokhin published his memoirs \"Sklonen k Pobegu\" translated into English under the title \"Inclined to Escape\" in 1986.\n\nIn 1987, Robert van Voren published his book \"Koryagin: A man Struggling for Human Dignity\" telling about psychiatrist Anatoly Koryagin who resisted political abuse of psychiatry in the Soviet Union.\n\nIn 1988, \"Reportazh iz Niotkuda\" (\"Reportage from Nowhere\") by Viktor Rafalsky was published. In the publication, he described his confinement in Soviet psychiatric hospitals.\n\nIn 1993, Valeriya Novodvorskaya published her collection of writings \"Po Tu Storonu Otchayaniya\" (\"Beyond Despair\") in which her experience in the prison psychiatric hospital in Kazan was described.\n\nIn 1996, Vladimir Bukovsky published his book \"Moskovsky Protsess\" (\"Moscow trial\")\ncontaining an account of developing the punitive psychiatry based on\ndocuments that were being submitted to and considered by the Politburo of the Central Committee of the Communist Party of the Soviet Union. The book was translated into English in 1998 under the title \"Reckoning With Moscow: A Nuremberg Trial for Soviet Agents and Western Fellow Travelers\".\n\nIn 2001, Nikolay Kupriyanov published his book \"GULAG-2-SN\" which has a foreword by Anatoly Sobchak, covers repressive psychiatry in Soviet Army, and tells about humiliations Kupriyanov underwent in the psychiatric departments of the Northern Fleet hospital and the Kirov Military Medical Academy.\n\nIn 2002, St. Petersburg forensic psychiatrist Vladimir Pshizov published his book \"Sindrom Zamknutogo Prostranstva\" (\"Syndrome of Closed Space\") describing the hospitalization of Viktor Fainberg.\n\nIn 2003, the book \"Moyа Sudba i Moyа Borba protiv Psikhiatrov\" (\"My Destiny and My Struggle against Psychiatrists\") was published by Anatoly Serov, who worked as a lead design engineer before he was committed to a psychiatric hospital.\n\nIn 2010, Alexander Shatravka published his book \"Pobeg iz Raya\" (\"Escape from Paradise\") in which he described how he and his companions were caught after they illegally crossed the border between Finland and the Soviet Union to escape from the latter country and, as a result, were confined to Soviet psychiatric hospitals and prisons. In his book, he also described methods of brutal treatment of prisoners in the institutions.\n\nIn 2012, Soviet dissident and believer Vladimir Khailo’s wife published her book \"Subjected to Intense Persecution\".\n\n2014 saw the book \"Zha Zholtoy Stenoy\" (\"Behind the Yellow Wall\") by Alexander Avgust, a former inmate of Soviet psychiatric hospitals who in his book describes the wider circle of their inhabitants than literature on the issue usually does.\n\nIn 1965, Valery Tarsis published in the West his book \"Ward 7: An Autobiographical Novel\"\nbased upon his own experiences in 1963–1964 when he was detained in the\nMoscow Kashchenko psychiatric hospital for political reasons. The book was the first literary work to deal with the Soviet authorities' abuse of psychiatry.\n\nIn 1968, the Russian poet Joseph Brodsky wrote \"Gorbunov and Gorchakov\",\na forty-page long poem in thirteen cantos consisting of lengthy\nconversations between two patients in a Soviet psychiatric prison as\nwell as between each of them separately and the interrogating\npsychiatrists. The topics vary from the taste of the cabbage served for supper to the meaning of life and Russia's destiny. The poem was translated into English by Harry Thomas. The experience underlying \"Gorbunov and Gorchakov\" was formed by two stints of Brodsky at psychiatric establishments.\n\nIn 1977, British playwright Tom Stoppard wrote the play \"Every Good Boy Deserves Favour\" that criticized the Soviet practice of treating political dissidence as a form of mental illness. The play is dedicated to Viktor Fainberg and Vladimir Bukovsky, two Soviet dissidents expelled to the West.\n\nIn the 1983 novel \"Firefox Down\" by Craig Thomas,\ncaptured American pilot Mitchell Gant is imprisoned in a KGB\npsychiatric clinic \"associated with the Serbsky Institute\", where he is\ndrugged and interrogated to force him to reveal the location of the Firefox aircraft, which he has stolen and flown out of Russia.\n\nThe use of psychiatry for political purposes in the USSR was discussed in several television documentaries:\n\nArchival sources\n\nGovernment publications and official reports\n\nBooks\n\nJournal articles and book chapters\n\nNewspapers\n\nWebsites\n\nAudio-visual material\n\n"}
{"id": "8767449", "url": "https://en.wikipedia.org/wiki?curid=8767449", "title": "Public health genomics", "text": "Public health genomics\n\nPublic health genomics is the use of genomics information to benefit public health. This is visualized as more effective preventive care and disease treatments with better specificity, tailored to the genetic makeup of each patient. According to the Centers for Disease Control and Prevention (U.S.), Public Health genomics is an emerging field of study that assesses the impact of genes and their interaction with behavior, diet and the environment on the population’s health.\n\nThis field of public health genomics is less than a decade old. A number of think tanks, universities, and governments (including the U.S., UK, and Australia) have started public health genomics projects. Research on the human genome is generating new knowledge that is changing public health programs and policies. Advances in genomic sciences are increasingly being used to improve health, prevent disease, educate and train the public health workforce, other healthcare providers, and citizens.\n\nPublic policy has protected people against genetic discrimination, defined in \"Taber's Cyclopedic Medical Dictionary\" (2001) as unequal treatment of persons with either known genetic abnormalities or the inherited propensity for disease; genetic discrimination may have a negative effect on employability, insurability and other socio-economic variables. Public policy in the U.S. that protect individuals and groups of people against genetic discrimination include the Americans with Disabilities Act of 1990, (2000) that prohibits genetic discrimination in the workplace for federal employees, and the Genetic Information Nondiscrimination Act of 2008.\n\nMain public concerns regarding genomic information are that of confidentiality, misuse of information by health plans, employers, and medical practitioners, and the right of access to genetic information.\n\nOne of the many facets involved in public health genomics is that of bioethics. This has been highlighted in a study in 2005 by Cogent Research, that found when American citizens were asked what they thought the strongest drawback was in using genetic information, they listed \"misuse of information/invasion of privacy\" as the single most important problem. In 2003, the Nuffield Council on Bioethics published a report, \"Pharmacogenetics: Ethical Issues\". Authors of the document explore four broad categories of ethical and policy issues related to pharmacogenetics: information, resource, equity and control. In the introduction to the report, the authors clearly state that the development and application of pharmacogenetics depend on scientific research, but that policy and administration must provide incentives and restraints to ensure the most productive and just use of this technology.\n\nSingle nucleotide polymorphisms (SNPs) are single bases within a gene sequence that differ from that gene's consensus sequence, and are present in a subset of the population. SNPs may have no effect on gene expression, or they can change the function of a gene completely. Resulting gene expression changes can, in some cases, result in disease, or in susceptibility to disease (e.g., viral or bacterial infection).\n\nSome current tests for genetic diseases include: cystic fibrosis, Tay-Sachs disease, amyotrophic lateral sclerosis (ALS), Huntington’s disease, high cholesterol, some rare cancers and an inherited susceptibility to cancer. A select few are explored below.\n\nSince the field of genomics takes into account the entire genome of an organism, and not simply its individual genes, the stud of latent viral infection falls into this realm. For example, the DNA of a latent herpesvirus integrates into the host’s chromosome and propagates through cell replication, although it is not part of the organism's genome, and was not present at the birth of the individual.\n\nAn example of this is found in a study published in Nature, which showed that mice with a latent infection of a herpesvirus were less susceptible to bacterial infections. Murine mice were infected with murine gammaherpesvirus 68 and then challenged with the \"Listeria monocytogenes\" bacterium. Mice that had a latent infection of the virus had an increased resistance to the bacteria, but those with a non-latent strain of virus had no change in susceptibility to the bacteria. The study went on to test mice with murine cytomegalovirus, a member of the betaherpesvirinae subfamily, which provided similar results. However, infection with human herpes simplex virus type-1 (HSV-1), a member of the alphaherpesvirinae subfamily, did not provide increased resistance to bacterial infection. They also used \"Yersinia pestis\" (the causative agent of the Black Death) to challenge mice with a latent infection of gammaherpesvirus 68, and they found the mice did have an increased resistance to the bacteria. The suspected reason for this is that peritoneal macrophages in the mouse are activated after latent infection of the herpesvirus, and since macrophages play an important role in immunity, this provides the mouse with a stronger, active immune system at the time of bacterial exposure. It was found that the latent herpesvirus caused an increase in interferon-gamma (IFN-γ) and tumor necrosis factor-alpha (TNF-α), cytokines which both lead to activation of macrophages and resistance to bacterial infection.\n\nVariations within the human genome can be studied to determine susceptibility to infectious diseases. The study of variations within microbial genomes will also need to be evaluated to use genomics of infectious disease within public health. The ability to determine if a person has greater susceptibility to an infectious disease will be valuable to determine how to treat the disease if it is present or prevent the person from getting the disease. Several infectious diseases have shown a link between genetics and susceptibility in that families tend to have heritability traits of a disease.\n\nDuring the course of the past influenza pandemics and the current influenza epizootic there has been evidence of family clusters of disease. Kandun, et al. found that family clusters in Indonesia in 2005 resulted in mild, severe and fatal cases among family members. The findings from this study raise questions about genetic or other predispositions and how they affect a persons susceptibility to and severity of disease. Continued research will be needed to determine the epidemiology of H5N1 infection and whether genetic, behavioral, immunologic, and environmental factors contribute to case clustering.\n\nHost genetic factors play a major role in determining differential susceptibility to major infectious diseases of humans. Infectious diseases in humans appear highly polygenic with many loci implicated but only a minority of these convincingly replicated. Over the course of time, humans have been exposed to organisms like \"Mycobacterium tuberculosis\". It is possible that the human genome has evolved in part from our exposure to \"M. tuberculosis\". Animal model studies and whole genome screens can be used to identify potential regions on a gene that suggest evidence of tuberculosis susceptibility. In the case of \"M. tuberculosis,\" animal model studies were used to suggest evidence of a locus which was correlated with susceptibility, further studies were done to prove the link between the suggested locus and susceptibility. The genetic loci that have been identified as associated with susceptibility to tuberculosis are HLA-DR, INF-γ, SLC11A1, \"VDR\", MAL/TIRAP, and CCL2. Further studies will be needed to determine genetic susceptibility to other infectious diseases and ways public health officials can prevent and test for these infections to enhance the concept of personalized medicine.\n\nThe term genomics, referring to the organism’s whole genome, is also used to refer to gene informatics, or the collection and storage of genetic data, including the functional information associated with the genes, and the analysis of the data as combinations, patterns and networks by computer algorithms. Systems biology and genomics are natural partners, since the development of genomic information and systems naturally facilitates analysis of systems biology questions involving relationships between genes, their variants (SNPs) and biological function. Such questions include the investigation of signaling pathways, evolutionary trees, or biological networks, such as immune networks and pathways. For this reason, genomics and these approaches are particularly suited to studies in immunology. The study of immunology using genomics, as well as proteomics and transcriptomics (including gene profiles, either genomic or expressed gene mRNA profiles), has been termed immunomics.\n\nAccurate and sensitive prediction of disease, or detection during early stages of disease, could allow the prevention or arrest of disease development as immunotherapy treatments become available. Type-1 diabetes markers associated with disease susceptibility have been identified, for example HLA class II gene variants, however possession of one or more of these genomic markers does not necessarily lead to disease. Lack of progression to disease is likely due to the absence of environmental triggers, absence of other susceptibility genes, presence of protective genes, or differences in the temporal expression or presence of these factors. Combinations of markers have also been associated with susceptibility to type-1 diabetes however again, their presence may not always predict disease development, and conversely, disease may be present without the marker group. Potential variant genes (SNPs) or markers that are linked to the disease include genes for cytokines, membrane-bound ligands, insulin and immune regulatory genes.\n\nMeta-analyses have been able to identify additional associated genes, by pooling a number of large gene datasets. This successful study illustrates the importance of compiling and sharing large genome databases. The inclusion of phenotypic data in these databases will enhance discovery of candidate genes, while the addition of environmental and temporal data should be able to advance the disease progression pathways knowledge. HUGENet, which was initiated by the Centers for Disease Control and Prevention (U.S.), is accomplishing the integration of this type of information with the genome data, in a form available for analysis. This project could be thought of as an example of ‘metagenomics’, the analysis of a community’s genome, but for a human rather than a microbial community. This project is intended to promote international data sharing and collaboration, in addition to creating a standard and framework for the collection of this data.\n\nVariations within the human genome are being studied to determine susceptibility to chronic diseases, as well as infectious diseases. According to Aileen Kenneson and Coleen Boyle, about one sixth of the U.S. population has some degree of hearing loss. Recent research has linked variants in the \"gap junction beta 2\" (\"GJB2\") gene to nonsyndromic prelingual sensorineural hearing loss. \"GJB2\" is a gene encoding for connexin, a protein found in the cochlea. Scientists have found over 90 variants in this gene and sequence variations may account for up to 50% of nonsyndromic hearing loss. Variants in \"GJB2\" are being used to determine age of onset, as well as severity of hearing loss.\n\nIt is clear that there are also environmental factors to consider. Infections such as rubella and meningitis and low birth weight and artificial ventilation, are known risk factors for hearing loss, but perhaps knowing this, as well as genetic information, will help with early intervention.\n\nInformation gained from further research in the role of \"GJB2\" variants in hearing loss may lead to newborn screening for them. As early intervention is crucial to prevent developmental delays in children with hearing loss, the ability to test for susceptibility in young children would be beneficial. Knowing genetic information may also help in the treatment of other diseases if a patient is already at risk.\n\nFurther testing is needed, especially in determining the role of \"GJB2\" variants and environmental factors on a population level, however initial studies show promise when using genetic information along with newborn screening.\n\nThe World Health Organization has defined pharmacogenomics as the study of DNA sequence variation as it relates to different drug responses in individuals, i.e., the use of genomics to determine an individual’s response. Pharmacogenomics refers to the use of DNA-based genotyping in order to target pharmaceutical agents to specific patient populations in the design of drugs.\n\nCurrent estimates state that 2 million hospital patients are affected by adverse drug reactions every year and adverse drug events are the fourth leading cause of death. These adverse drug reactions result in an estimated economic cost of $136 billion per year. Polymorphisms (genetic variations) in individuals affect drug metabolism and therefore an individual's response to a medication. Examples of ways in which genetics may affect an individual’s response to drugs include: drug transporters, metabolism and drug interactions. Pharmacogenetics may be used in the near future by public health practitioners to determine the best candidates for certain drugs, thereby reducing much of the guesswork in prescribing drugs. Such actions have the potential to improve the effectiveness of treatments and reduce adverse drug events.\n\nNutrition is very important in determining various states of health. The field of nutrigenomics is based on the idea that everything ingested into a person’s body affects the genome of the individual. This may be through either upregulating or downregulating the expression of certain genes or by a number of other methods. While the field is quite young there are a number of companies that market directly to the public and promote the issue under the guise of public health. Yet many of these companies claim to benefit the consumer, the tests performed are either not applicable or often result in common sense recommendations. Such companies promote public distrust towards future medical tests that may test more appropriate and applicable agents.\n\nAn example of the role of nutrition would be the methylation pathway involving methylene tetrahydrofolate reductase (MTHFR). An individual with the SNP may need increased supplementation of vitamin B12 and folate to override the effect of a variant SNP. Increased risk for neural tube defects and elevated homocysteine levels have been associated with the MTHFR C677T polymorphism.\n\nIn 2002, researchers from the Johns Hopkins Bloomberg School of Public Health identified the blueprint of genes and enzymes in the body that enable sulforaphane, a compound found in broccoli and other vegetables, to prevent cancer and remove toxins from cells. The discovery was made using a “gene chip,” which allows researchers to monitor the complex interactions of thousands of proteins on a whole genome rather than one at time. This study was the first gene profiling analysis of a cancer-preventing agent using this approach. University of Minnesota researcher Sabrina Peterson, coauthored a study with Johanna Lampe of the Fred Hutchinson Cancer Research Center, Seattle, in October 2002 that investigated the chemoprotective effect of cruciferous vegetables (e.g., broccoli, brussels sprouts). Study results published in The Journal of Nutrition outline the metabolism and mechanisms of action of cruciferous vegetable constituents, discusses human studies testing effects of cruciferous vegetables on biotransformation systems and summarizes the epidemiologic and experimental evidence for an effect of genetic polymorphisms (genetic variations) in these enzymes in response to cruciferous vegetable intake.\n\nMembers of the public are continually asking how obtaining their genetic blueprint will benefit them, and why they find that they are more susceptible to diseases that have no cures.\n\nResearchers have found that almost all disorders and diseases that affect humans reflect the interplay between the environment and their genes; however we are still in the initial stages of understanding the specific role genes play on common disorders and diseases. For example, while news reports may give a different impression, most cancer is not inherited. It is therefore likely that the recent rise in the rates of cancer worldwide can be at least partially attributed to the rise in the number of synthetic and otherwise toxic compounds found in our society today. Thus, in the near future, public health genomics, and more specifically environmental health, will become an important part of the future healthcare-related issues.\n\nPotential benefits of uncovering the human genome will be focused more on identifying causes of disease and less on treating disease, through: improved diagnostic methods, earlier detection of a predisposing genetic variation, pharmacogenomics and gene therapy.\n\nFor each individual, the experience of discovering and knowing their genetic make-up will be different. For some individuals, they will be given the assurance of not obtaining a disease, as a result of familial genes, in which their family has a strong history and some will be able to seek out better medicines or therapies for a disease they already have. Others will find they are more susceptible to a disease that has no cure. Though this information maybe painful, it will give them the opportunity to prevent or delay the on-set of that disease through: increased education of the disease, making lifestyle changes, finding preventive therapies or identifying environmental triggers of the disease. As we continue to have advances in the study of human genetics, we hope to one day incorporate it into the day-to-day practice of healthcare. Understanding one's own genetic blueprint can empower oneself to take an active role in promoting their own health.\n\nGenomics and understanding of disease susceptibility can help validate family history tool for use by practitioners and the public. IOM is validating the family history tool for six common chronic diseases (breast, ovarian, colorectal cancer, diabetes, heart disease, stroke) (IOM Initiative). Validating cost effective tools can help restore importance of basic medical practices (e.g. family history) in comparission to technology intensive investigations.\n\nA critical set of phenomena that ties together various aspects of health interventions, such as drug sensitivity screening, cancer or autoimmune susceptibility screening, infectious disease prevalence and application of pharmacologic or nutrition therapies, is the systems biology of the immune response. For example, the influenza epidemic of 1918, as well as the recent cases of human fatality due to H5N1 (avian flu), both illustrate the potentially dangerous sequence of immune responses to this virus. Also well documented is the only case of spontaneous \"immunity\" to HIV in humans, shown to be due to a mutation in a surface protein on CD4 T cells, the primary targets of HIV. The immune system is truly a sentinel system of the body, with the result that health and disease are carefully balanced by the modulated response of each of its various parts, which then also act in concert as a whole. Especially in industrialized and rapidly developing economies, the high rate of allergic and reactive respiratory disease, autoimmune conditions and cancers are also in part linked to aberrant immune responses that are elicited as the communities' genomes encounter swiftly changing environments. The causes of perturbed immune responses run the gamut of genome-environment interactions due to diet, supplements, sun exposure, workplace exposures, etc. Public health genomics as a whole will absolutely require a rigorous understanding of the changing face of immune responses.\n\nThe experience of newborn screening serves as the introduction to public health genomics for many people. If they did not undergo prenatal genetic testing, having their new baby undergo a heel stick in order to collect a small amount of blood may be the first time an individual or couple encounters genetic testing. Newborn genetic screening is a promising area in public health genomics that appears poised to capitalize on the public health goal of disease prevention as a primary form of treatment.\n\nMost of the diseases that are screened for are extremely rare, single-gene disorders that are often autosomal recessive conditions and are not readily identifiable in neonates without these types of tests. Therefore, often the treating physician has never seen a patient with the disease or condition and so an immediate referral to a specialty clinic is necessary for the family.\n\nMost of the conditions identified in newborn screening are metabolic disorders that either involve i) lacking an enzyme or the ability to metabolize (or breakdown) a particular component of the diet, like phenylketonuria, ii) abnormality of some component of the blood, especially the hemoglobin protein, or iii) alteration of some component of the endocrine system, especially the thyroid gland. Many of these disorders, once identified, can be treated before more severe symptoms, such as mental retardation or stunted growth, set in.\n\nNewborn genetic screening is an area of tremendous growth. In the early 1960s, the only test was for phenylketonuria. In 2000, roughly two-thirds of states in the US screened for 10 or fewer genetic diseases in newborns. Notably, in 2007, 95% of states in the US screen for more than 30 different genetic diseases in newborns. Especially as costs have come down, newborn genetic screening offers “an excellent return on the expenditure of public health dollars.”\n\nGenomics will help develop an understanding of the practices that have evolved over centuries in old civilizations and which have been strengthened by observations (phenotype presentations) from generation to generation, but which lack documentation and scientific evidence. Traditional healers associated specific body types with resistance or susceptibility to particular diseases under specific conditions. Validation and standardization of this knowledge/ practices has not yet been done by modern science. Genomics, by associating genotypes with the phenotypes on which these practices were based, could provide key tools to advance the scientific understanding of some of these traditional healing practices.\n\n\n\n\n"}
{"id": "3886127", "url": "https://en.wikipedia.org/wiki?curid=3886127", "title": "Richardson Olmsted Complex", "text": "Richardson Olmsted Complex\n\nThe Richardson Olmsted Campus in Buffalo, New York, United States was designated a National Historic Landmark in 1986. The site was designed by the American architect, Henry Hobson Richardson, in concert with the famed landscape team of Frederick Law Olmsted and Calvert Vaux in the late 1800s, incorporating a system of enlightened treatment for people with mental illness developed by Dr. Thomas Story Kirkbride. Over the years, as mental health treatment changed and resources were diverted, the buildings and grounds began a slow deterioration. In 2006, the Richardson Center Corporation was formed with a mandate to save the buildings and bring the Campus back to life through a State appropriation for this architectural treasure.\n\nToday, the Richardson Olmsted Campus is being transformed into a cultural amenity for the city, beginning with the now open Hotel Henry Urban Resort Conference Center and 100 Acres: The Kitchens at Hotel Henry, both nestled within the iconic Towers Building and two flanking buildings (about one-third of the Campus). Arriving in 2018, the Richardson Olmsted Campus will also welcome the Lipsey Architecture Center of Buffalo. The remaining buildings have been stabilized pending future opportunities.\n\nOpened in April 2017, Hotel Henry Urban Resort Conference Center is the first phase and 1/3 of the redevelopment of the Richardson Olmsted Campus, bringing new life and meaning to the National Historic Landmark. The original-concept hotel features 88 guest rooms and suites with full-service amenities and seamlessly integrated technology. The Urban Resort amenities span throughout the surrounding Buffalo neighborhoods and the property boasts over 20,000 square feet of adaptable meeting & event spaces. 100 Acres: The Kitchens at Hotel Henry stands on Hotel Henry's first floor, welcoming hotel guests and the surrounding Buffalo neighborhoods to enjoy a selectively-sourced, seasonal New American menu.\n\nThe large Medina red sandstone and brick hospital buildings were designed in 1870 in the Kirkbride Plan by architect Henry Hobson Richardson with grounds by landscape architect Frederick Law Olmsted. The campus consists of a central administrative tower and five pavilions or wards progressively set back on each side, for eleven buildings total, all connected by short curved two-story corridors. Patients were segregated by sex, males on the east side, females on the west. The wards housed patients until the mid-1970s. The central administration building was used for offices until 1994. In 1973, the Asylum was added to the National Register of Historic Places and in 1986, it was designated a National Historic Landmark.\n\nThe campus, the largest commission of Richardson's career, marks the advent of his characteristic Romanesque Revival style. When emulated by later architects, this style is referred to as Richardsonian Romanesque. It has been the subject of a long-term preservation campaign. Nevertheless, three pavilions on the east side were demolished in the 1970s to make way for newer psychiatric facilities. In 1927, the northern farmlands were transferred back to the State for the development of what is today Buffalo State College.\n\nPatient records from 1881 to 1975 are in the collection of the New York State Archives in Albany, NY.\n\nA successful lawsuit filed by the Preservation Coalition of Erie County (renamed \"Preservation Buffalo Niagara\" in October 2008) forced the State of New York to commit $100 million to its rehabilitation. Both former New York State Assembly Member Sam Hoyt and former Buffalo State College President Muriel A. Howard were actively involved in plans for the restoration and reuse of the Richardson. As a result, the State established the Richardson Center Corporation in 2006 to rehabilitate the site. Perimeter fencing and lighting have been installed and a Peace Officer is on duty at all times to conduct regular patrols of the area to prevent and deter crime.\n\nOn March 5, 2008, stabilization began with the most severely damaged buildings, including the roof and down-spouts. Stabilization was completed in 2012.\n\nOn April 10, 2010, a two-alarm fire occurred. The cause of the fire was under investigation. Damage was estimated at $200,000.\n\nIn 2013, the South Lawn landscape on the property was completed. The re-greening of the nine-acre South Lawn transformed two large parking lots at the Campus' south entry into a welcoming space for community gathering and recreation.\n\nAt every stage of planning, the Richardson Center Corporation has used an active public process, which has helped to inform the Master Plan and all phases of redevelopment for the Campus. Ten public meetings have taken place since 2007 to inform the planning and reuse. A Community Advisory Group includes representatives from the adjacent neighborhoods, business districts, cultural institutions, Buffalo Psychiatric Center, SUNY Buffalo State, and historic preservation groups.\n\nIn 1983 a portion of a ground floor hallway and one hospital room were prepared to appear as a maternity ward and used as a location for The Natural, where the character Roy Hobbs, as played by Robert Redford, was shown recovering from internal injuries. \n\nThe Mount Massive Asylum from Outlast was modeled based on the Richardson Olmsted Complex.\n\nOn January 25, 2013, Phase I plans were announced to redevelop 1/3 of the Campus into Hotel Henry Urban Resort Conference Center, 100 Acres: The Kitchens at Hotel Henry and the Buffalo Architecture Center. This first phase of redevelopment was completed in 2016. Hotel Henry opened in May 2017, and the architecture center will open later in 2017.\n\n"}
{"id": "6112487", "url": "https://en.wikipedia.org/wiki?curid=6112487", "title": "Sports nutrition", "text": "Sports nutrition\n\nSports nutrition is the study and practice of nutrition and diet with regards to improving anyone's athletic performance. Nutrition is an important part of many sports training regimens, being popular in strength sports (such as weightlifting and bodybuilding) and endurance sports (e.g. cycling, running, swimming, rowing). Sports Nutrition focuses its studies on the type, as well as the quantity of fluids and food taken by an athlete. In addition, it deals with the consumption of nutrients such as vitamins, minerals, supplements and organic substances that include carbohydrates, proteins and fats.\n\nDietary supplements contain one or more dietary ingredients (including vitamins; minerals; amino acids; herbs or other botanicals; and other substances) or their constituents is intended to be taken by mouth as a pill, capsule, tablet, or liquid. Athletes may choose to consider taking dietary supplements to assist in improving their athletic performance. There are many other supplements out there that include performance enhancing supplements (steroids, blood doping, creatine, human growth hormone), energy supplements (caffeine), and supplements that aid in recovery (protein, BCAAs).\n\nAthletes sometimes turn to energy supplements to increase their ability to exercise more often. Common supplements to increase an athlete's energy include: Caffeine, Guarana, Vitamin B12, and Asian ginseng. Caffeine, a common energy supplement, can be found in many different forms such as pills, tablets or capsules, and can also be found in common foods, such as coffee and tea. Caffeine is used to improve energy and increases metabolism. Guarana is another supplement that athletes take to enhance their athletic ability, it is frequently used for weight loss and as an energy supplement.\n\nA 2009 study from the University of Texas reports that caffeinated energy drinks decrease sporting performance. They found that after drinking an energy drink, 83% of participants improved their physical activity parameters by an average of 4.7%. This was attributed to the effects of caffeine, sucrose and Vitamin B in the drink - however scientific consensus does not support the efficacy of using Vitamin B as a performance enhancer. To explain the performance improvement the writers report an increase in blood levels of epinephrine, norepinephrine and beta-Endorphin. The adenosine receptor antagonism of caffeine accounts for the first two, while the latter is accounted for by the Neurobiological effects of physical exercise.\n\nCaffeine has been around since the 1900s and became popularly used in the 1970s when its power of masking fatigue became highly recognized. Similarly, the caffeine found in energy drinks and coffee shows an increased reaction performance and feelings of energy, focus and alertness in quickness and reaction anaerobic power tests. In other words, consuming an energy drink or any drink with caffeine increases short time/rapid exercise performance (like short full-speed sprints and heavy power weight lifting). Caffeine is chemically similar to adenosine, a type of sugar that helps in the regulation of important body processes, including the firing of neurotransmitters. Caffeine takes the place of adenosine in your brain, attaching itself to the same neural receptors affected by adenosine, and causing your neurons to fire more rapidly, hence caffeine's stimulating effects.\n\nCommon supplements to help athletes recover from exercising include protein and amino acid supplements. The main use for athletes to take dietary proteins are for hormones, oxygen transport, cellular repair, enzymes and conversion to fuel. The intake of protein is a part of the nutrient requirements for the normal athlete and is an important component of exercise training. In addition, it aids in performance and recovery. Dietary protein intake for well-trained athletes should occur before, during and after physical activity as it is advantageous in gaining muscle mass and strength. However, if too much protein and amino acid supplements is consumed it can be more harmful to the body than it is beneficial; health risks include: dehydration, gout, calcium loss, liver, renal damage, diarrhea, bloating, and water loss. A bountiful protein diet must be paired with a healthy, well-rounded meal plan and regular resistance exercise. Characteristics of this particular diet include the type of exercise, intensity, duration and carbohydrate values of diet. The most effective way to secure the natural nutrients required by the body for optimum health and physiological performance is by consuming vitamins, minerals, proteins, fats, sugars and carbohydrates, which can be procured from fresh fruits and vegetables.\n\nPost-exercise nutrition is an important factor in a nutrition plan for athletes as it pertains to the recovery of the body. Traditionally, sports drinks such as Gatorade and Powerade, are consumed during and after exercise because they effectively rehydrate the body by refueling the body with minerals and electrolytes. Electrolytes regulate the bodies nerve and muscle function, blood pH, blood pressure, and the rebuilding of damaged tissue. These types of drink are commonly made of glucose and sucrose in water and has been seen to improve the football players' performance.\n\nA substitute for sports drinks is milk, which contains many electrolytes, nutrients and other elements that help to make it an effective post-exercise beverage. It is true that milk helps replace fluids and electrolytes lost after the athlete has worked out. A recovery drink is supposed to replenish the sugar lost, and help recover the muscles to be able to workout at full intensity by the next time they workout. When compared to plain water or sports drinks, research suggests that chocolate milk is more effective at replacing fluids lost through sweat and maintaining normal body fluid levels. Athletes drinking chocolate milk following exercise-induced dehydration had fluid levels about 2 percent higher (on initial body mass) than those using other post-exercise recovery beverages. These results allowed for prolonged performance, especially in repeated bouts of exercise or training.\n\nIn the extreme case of performance-enhancing supplements, athletes, particularly bodybuilders may choose to use illegal substances such as anabolic steroids. These compounds which are related to the hormone testosterone, can quickly build mass and strength, but have many adverse effects such as high blood pressure and negative gender specific effects. Blood doping, another illegal ergogenic, was discovered in the 1940s when it was used by World War II pilots. Blood doping also known as blood transfusions, increases oxygen delivery to exercising tissues and has been demonstrated to improve performance in endurance sports, such as long-distance cycling. \n\nThe supplement, Creatine, may be helpful for well-trained athletes to increase exercise performance and strength in relation with their dietary regimen. The substance glutamine, found in whey fiber supplements, is the most abundant free amino acid found in the human body. It is considered that glutamine may have a possible role in stimulated anabolic processes such as muscle glycogen and protein synthesis, for well-trained and well-nourished athletes. Other popular studies done on supplements include androstenedione, chromium, and ephedra. The findings show that there are no substantial benefits from the extra intake of these supplements, yet higher health risks and costs.\n\nDiffering conditions and objectives suggest the need for athletes to ensure that their sports nutritional approach is appropriate for their situation. Factors that may affect an athlete's nutritional needs include type of activity (aerobic vs. anaerobic), gender, weight, height, body mass index, workout or activity stage (pre-workout, intro-workout, recovery), and time of day (e.g. some nutrients are utilized by the body more effectively during sleep than while awake).Most culprits that get in the way of performance are fatigue, injury and soreness. A proper diet will reduce these disturbances in performance. The key to a proper diet is to get a variety of food, and to consume all the macro-nutrients, vitamins, and minerals needed. According to Eblere's article (2008), it is ideal to choose raw foods, for example unprocessed foods such as oranges instead of orange juice. Eating foods that are natural means the athlete is getting the most nutritional value out of the food. When foods are processed, the nutritional value is normally reduced.\n\nDuring anaerobic exercise, the process of glycolysis breaks down the sugars from carbohydrates for energy without the use of oxygen. This type of exercise occurs in physical activity such as power sprints, strength resistances and quick explosive movement where the muscles are being used for power and speed, with short-time energy use. After this type of exercise, there is a need to refill glycogen storage sites in the body (the long simple sugar chains in the body that store energy), although they are not likely fully depleted.\n\nTo compensate for this glycogen reduction, athletes will often take in large amounts of carbohydrates, immediately following their exercise. Typically, high-glycemic-index carbohydrates are preferred for their ability to rapidly raise blood glucose levels.For the purpose of protein synthesis, protein or individual amino acids are ingested as well. Branched-chain amino acids are important since they are most responsible for the synthesis of protein. According to Lemon et al. (1995) female endurance runners have the hardest time getting enough protein in their diet. Endurance athletes in general need more protein in their diet than the sedentary person.Research has shown that endurance athletes are recommended to have 1.2 to 1.4 g of protein per kg of body weight in order to repair damaged tissue. If the athlete consumes too few calories for the body's needs, lean tissue will be broken down for energy and repair. Protein deficiency can cause many problems such as early and extreme fatigue, particularly long recovery, and poor wound healing. Complete proteins such as meat, eggs, and soy provide the athlete with all essential amino acids for synthesizing new tissues. However, vegetarian and vegan athletes frequently combine legumes with a whole grain to provide the body with a complete protein across the day's food intake. A popular combination being rice and beans.\n\nSpada's research on endurance sports nutrition (2000) and where the types of carbohydrates come from will be explained. He advises for carbohydrates to be unprocessed and/or whole grains for optimal performance while training. These carbohydrates offer the most fuel, nutritional value, and satiety. Fruits and vegetables contribute important carbohydrate foundation for an athlete's diet. They provide vitamins and minerals that are lost through exercise and later needed to be replenished. Both fruits and vegetables improve healing, aid in recovery, and reduce risks of cancer, high blood pressure, and constipation. Vegetables offer a little more nutritional value than fruits for the amount of calories, therefore an athlete should strive to eat more vegetables than fruits. Dark-colored vegetables usually have more nutritional value than pale colored ones.(add info) A general rule is the darker the color the more nutrient dense it is. Like all foods, it is very important to have a variety. To get the most nutritional value out of fruits and vegetables it is important to eat them in their natural, unprocessed form with no other nutrient (sugar) added.\n\nOften in the continuation of this anaerobic exercise, the product from this metabolic mechanism builds up in what is called lactic acid fermentation. Lactate is produced more quickly than it is being removed and it serves to regenerate NAD cells on where it's needed. During intense exercise when oxygen is not being used, a high amount of ATP is produced and pH levels fall causing acidosis or more specifically lactic acidosis. Lactic acid build up can be treated by staying well-hydrated throughout and especially after the workout, having an efficient cool down routine and good post-workout stretching.\n\nIntense activity can cause significant and permanent damage to bodily tissues. In order to repair, vitamin E and other antioxidants are needed to protect muscle damage. Oxidation damage and muscle tissue breakdown happens during endurance running so athletes need to eat foods high in protein in order to repair these muscle tissues. It is important for female endurance runners to consume proper nutrients in their diet that will repair, fuel, and minimize fatigue and injury. To keep a female runner's body performing at its best, the ten nutrients need to be included in their diets.\n\n\n"}
{"id": "23184143", "url": "https://en.wikipedia.org/wiki?curid=23184143", "title": "Sugary drink tax", "text": "Sugary drink tax\n\nA sugary drink tax or soda tax is a tax or surcharge designed to reduce consumption of drinks with added sugar. Drinks covered under a soda tax often include carbonated soft drinks, sports drinks and energy drinks.\n\nThe tax is a matter of public debate in many countries and beverage producers like Coca-Cola often oppose it. Advocates such as national medical associations and the World Health Organization promote the tax as an example of Pigovian taxation, aimed to discourage unhealthy diets and offset the growing economic costs of obesity.\n\nType II diabetes is a growing health concern in many developed and developing countries around the world, with 1.6 million deaths directly due to this disease in 2015 alone. Unlike sugar from food, the sugar from drinks enters the body so quickly that it can overload the pancreas and the liver, leading to diabetes and heart disease over time. A 2010 study said that consuming one to two sugary drinks a day increases your risk of developing diabetes by 26%.\n\nHeart disease is responsible for 31% of all global deaths and although one sugary drink has minimal effects on the heart, consuming sugary drinks daily are associated with long term consequences. A study found that men, for every added serving per day of sugar-sweetened beverages, each serving was associated with a 19% increased risk of developing heart disease. Another study also found increased risks for heart disease in women who drank sugary drinks daily.\n\nObesity is also a global public and health policy concern, with the percentage of overweight and obese people in many developed and middle income countries rising rapidly. Consumption of added sugar in sugar-sweetened beverages has been positively correlated with high calorie intake, and through it, with excess weight and obesity. The addition of one sugar-sweetened beverage per day to the normal US diet can amount to 15 pounds of weight gain over the course of 1 year. Added sugar is a common feature of many processed and convenience foods such as breakfast cereals, chocolate, ice cream, cookies, yogurts and drinks produced by retailers. The ubiquity of sugar-sweetened beverages and their appeal to younger consumers has made their consumption a subject of particular concern by public health professionals. In both the United States and the United Kingdom, sugar sweetened drinks are the top calorie source in teenager's diets.\n\nTrends indicate that traditional soda consumption is declining in many developed economies, but growing rapidly in middle income economies such as Vietnam and India. In the United States, the single biggest market for carbonated soft drinks, consumers annual average per capita purchase of soda was 154 liters.\n\nDenmark began taxing soft drinks and juices in the 1930s. More recently, Finland reintroduced an earlier soft drink tax in 2011, while Hungary taxes sugary drinks as part of its 2011 public health product tax, which covers all food products with unhealthy levels of sugar. France introduced a targeted sugar tax on soft drinks in 2012. At a national level similar measures have also been announced in Mexico in 2013 and in the United Kingdom in 2016. In November 2014, Berkeley, California was the first city in the U.S. to pass a targeted tax on surgary drinks.\n\nProponents of soda taxes cite the success of tobacco taxes worldwide when explaining why they think a soda tax will work to lower soda consumption. Where the main concern with tobacco is cancer, the main concerns with soda are diabetes and obesity. The tactics used to oppose soda taxes by soda companies mimic those of tobacco companies, including funding research that downplays the health risks of its products.\n\nThe U.S. Department of Health and Human Services reports that a targeted tax on sugar in soda could generate $14.9 billion in the first year alone. The Congressional Budget Office (CBO) estimates that three-cent-per-ounce tax would generate over $24 billion over four years. Some tax measures call for using the revenue collected to pay for relevant health needs: improving diet, increasing physical activity, obesity prevention, nutrition education, advancing healthcare reform, etc. Another area to which the revenue raised by a soda tax might go, as suggested by Mike Rayner of the United Kingdom, is to subsidize healthier foods like fruits and vegetables.\n\nThe imposition of a sugar tax means that sellers of sugary drinks would have to increase the price of their goods by an amount P2 from the original price X, and then take on the rest of the tax themselves (P1) in the form of lower profit per unit sold. The tax burden on consumers (P2) makes it more expensive for consumers to buy sugary drinks and hence a higher proportion of their incomes would have to be spent to buy the same amount of sugary drinks. This decreases the equilibrium quantity of sugary drinks that will be sold. Whether the sugary drinks tax is imposed on the seller or consumer, in both cases the tax burden is shared between both.\n\nThe way that the tax burden is divided upon the consumer and seller depends on the price elasticity for sugary drinks. The tax burden will fall more on sellers when the price elasticity of demand is greater than the price elasticity of supply while on buyers when the price elasticity of supply is greater than the price elasticity of demand. The price elasticity for sugary drinks is different from country to country. For instance, the price elasticity of demand for sugary drinks was found to be -1.37 in Chile while -1.16 in Mexico. Hence if both of those results were realistic and the price elasticity of supply would be the same for both, the tax burden on consumers would be higher in Mexico than in Chile.\n\nThe reasons for a sugar tax are the negative externalities of consuming sugar. As over-consumption of sugar causes health problems (external costs) such as obesity, type 2 diabetes and other diseases, and lost productivity, the third party impacted by this is the ‘public health system’ that will need to deal with those issues. More demand for health services leads to higher costs for health care and hence this increased stress on the public health system is a negative consumption externality of sugar consumption.\n\nIn economics terms, the marginal social benefit (MSB) of sugar consumption is less than the marginal private benefit (MB). This can also be illustrated in the following equation. MSB = MB – Marginal External Cost (MXC). This is the case due to the fact that consumers think only of the benefit of sugar consumption to them (MB) and not the negative externalities to third parties (MXC) and so want to consume at the unregulated market equilibrium to maximize their utility. This means that there is overconsumption of sugar and a welfare loss is created.\n\nThe sugary drinks tax, a Pigovian tax, is a way to correct the negative externality by regulating the consumption of sugary drinks. Without a sugary drink tax, taxpayer money is used to pay for higher health care costs incurred from high consumption of sugar. Although this solution corrects the negative consumption externality, taxpayers that consume sugary drinks moderately and hence do not contribute to higher health care costs, still need to pay for this negative externality. Hence a sugary drinks tax may be a more appropriate solution as tax revenue that is collected from the sugar tax can be used to create childhood nutrition programs or obesity-prevention programs. This is a solution that could also correct the negative externality of sugar consumption as well as is a way to make the parties that cause the negative externality pay their fair share.\n\nThe Australian Beverages Council announced in June 2018 that the industry would cut sugar content by 10% by 2020, and by another 10% by 2025. This was seen as an attempt to stave off a sugar tax. There were no plans to reduce the sugar content in the high sugar drinks. The plan is primarily to increase consumption of low-sugar or no-sugar drinks. sales of Coca-Cola Amatil's fizzy drinks have fallen 8.1% by volume from 2016 to 2018. The Australian Medical Association continued to press for a sugar tax.\n\nA 2016 proposal for a 20% sugary drink tax, campaigned by Educar Consumidores, was turned down by the Colombian legislature despite popular support for it. Soda is often less expensive than bottled water in Colombia.\n\nDenmark instituted a soft drink tax in the 1930s (it amounted to 1.64 Danish krone per liter), but announced in 2013 that they were going to abolish it along with an equally unpopular fat tax, with the goal of creating jobs and helping the local economy. Critics claimed that the taxes were notably ineffective; to avoid the fat and sugar taxes, local retailers had complained that Danes simply went to Sweden and Germany, where prices were lower to buy butter, ice cream and soda. Denmark repealed the fat tax in January 2013 and repealed the tax on soft drinks in 2014.\n\nFrance first introduced a targeted tax on sugary drinks at a national level in 2012; following introduction, soft drinks are estimated to be up to 3.5% more expensive. Analysis by the market research firm Canadean found that sales of soft drinks declined in the year following the introduction of the tax, following several years of annual growth. However, the tax applies to both drinks with added sugars and drinks with artificial sweeteners, possibly limiting its effects on the healthfulness of soda products.\n\nA 2016 study by Mazzochi has shown that the sugary drinks tax saw a 19 euro-cent per liter increase in price of non-pure fruit juices, a 16 euro-cent per liter increase for diet sodas and little impact on regular soft drinks prices. The study also estimated that the quantity consumed of the taxed drinks has decreased by 9 centiliters per week per person after the tax has been implemented.\n\nHungary's tax, which came into effect in September 2011, is a 4-cent tax on foods and drinks that contain large quantities of sugar and salt, such as soft drinks, confectionery, salty snacks, condiments, and fruit jams. In 2016, the tax has resulted in a 22% reduction in energy drink consumption and 19% of people reduced their intake of sugary soft drinks.\n\nSoda tax introduced on May 1st 2018. The tax will see 30 cent per litre added to the price of popular sweetened drinks containing more than 8g of sugar per 100ml.\n\nIn September 2013, Mexico's president Enrique Peña Nieto, on his fiscal bill package, proposed a 10% tax on all soft drinks, especially carbonated drinks, with the intention of reducing the number of patients with diabetes and other cardiovascular diseases in Mexico, which has one of the world's highest rates of obesity. According to Mexican government data, in 2011, the treatment for each patient with diabetes cost the Mexican public health care system (the largest of Latin America) around 708 USD per year, with a total cost of 778,427,475 USD in 2010, and with each patient paying only 30 MXN (around 2.31 USD).\n\nIn September 2013, soda companies launched a media campaign to discourage the Mexican Chamber of Deputies and Senate from approving the 10% soda tax. They argued that such measure would not help reduce the obesity in Mexico and would leave hundreds of Mexicans working in the sugar cane industry jobless. They also publicly accused New York City Mayor Michael Bloomberg of orchestrating the controversial bill from overseas. In late October 2013, the Mexican Senate approved a 1 MXN per litre tax (around 0.08 USD) on sodas, along with a 5% tax on junk food.\n\nResearch has shown that Mexico's sugary drinks tax reduced soft drink consumption. According to a 2016 study published in \"BMJ\", annual sales of sodas in Mexico declined 6% in 2014 after the introduction of the soda tax. Monthly sales figures for December 2014 were down 12% on the previous two years. Households with the fewest resources had an average reduction in purchases of 9% in 2014, increasing to 17% by December. Furthermore, purchases of water and non-taxed beverages increased by about 4% on average. Whether the imposition of the tax and the resulting 6% decline in sales of soft drinks will have any measurable impact on long-term obesity or diabetes trends in Mexico has yet to be determined. The authors of the study urged the Mexican authorities to double the tax to further reduce consumption.\n\nA 2016 study published in \"PLoS Medicine\" suggested that a 10% excise tax on soda \"could prevent 189,300 new cases of Type 2 diabetes, 20,400 strokes and heart attacks, and 18,900 deaths among adults 35 to 94 years old\" over a ten-year period. The study also included that \"the reductions in diabetes alone could yield savings in projected healthcare costs of $983 million.\"\n\nA 2017 study in the \"Journal of Nutrition\" found a 6.3% reduction in soft drink consumption, with the greatest reductions \"among lower-income households, residents living in urban areas, and households with children. We also found a 16.2% increase in water purchases that was higher in low- and middle-income households, in urban areas, and among households with adults only.\"\n\nNorway has had a generalized sugar tax measure on refined sugar products since 1922, introduced to boost state income rather than reducing sugar consumption. Non-alcoholic beverages have since been separated from the general tax, and in 2017, the tax for sugary drinks was set to 3.34 kroner per litre.\n\nIn January 2018, the Norwegian government increased the sugar tax level by 83% for general sugar-containing ready-to-eat products, and 42% for beverages. The sugar tax per litre was bumped up to 4.75 kroner, and applies to beverages which are either naturally or artificially sweetened.\n\nIn the taxation reform law dubbed as the Tax Reform for Acceleration and Inclusion Law (TRAIN) signed by Philippine President Rodrigo Duterte in December 2017. It includes taxation on sugar-sweetened drinks which will be implemented the following year, as an effort to increase revenue and to fight obesity. Drinks with caloric and non-caloric sweeteners will be taxed ₱6.00 per liter, while those using high-fructose corn syrup, a cheap sugar substitute, will be taxed at ₱12 per liter.\n\nExempted from the sugar tax are all kinds of milk, whether powdered or in liquid form, ground and 3-in-1 coffee packs, and 100-percent natural fruit and vegetable juices, meal replacements and medically indicated drinks, as well as beverages sweetened with stevia or coco sugar. These drinks, especially 3-in-1 coffee drinks which are popular especially among lower-income families, are to be taxed as initially proposed by the House of Representatives version of the bill, but were exempted in the Senate version.\n\nSouth Africa proposed a sugar-sweetened beverages tax in the 2016 South African national government budget. South Africa introduced a sugar tax on 1 April 2018. The levy was fixed at 2.1 cents per gram of sugar, for each gram above 4g per 100ml of sweetened beverage. The levy excludes fruit juices.\n\nOn October 2017, the United Arab Emirates introduced a 50% tax on soft drinks and a 100% tax on energy drinks, to curb unhealthy consumption of sugary drinks that can lead to diabetes; it also added a 100% tax on cigarettes.\n\nIn the 2016 United Kingdom budget, the UK Government announced the introduction of a sugar tax, officially named the \"Soft Drinks Industry Levy\". The tax came into effect on 6 April 2018. Beverage manufacturers are taxed according to the volume of sugar-sweetened beverages they produce or import. The tax is imposed at the point of production or importation, in two bands. Drinks with total sugar content above 5g per 100 millilitres are taxed at 18p per litre and drinks above 8g per 100 millilitres at 24p per litre. The measure is estimated to generate an additional £1 billion a year in tax revenue which will be spent on funding for sport in UK schools.\n\nIt was proposed that pure fruit juices, milk-based drinks and the smallest producers would not be taxed. For other beverages there was an expectation that some manufacturers would reduce sugar content in order to avoid the taxation. Indeed, manufacturer A.G. Barr significantly cut sugar content in their primary product Irn-Bru in advance of the tax.\n\nNotable research on effect of excess sugar in modern diets in the United Kingdom includes the work of Professor John Yudkin with his book called, \"Pure, White and Deadly: The Problem of Sugar\" first published in 1972. With regard to a proposed tax on sugar-sweetened beverages, a study published in the British Medical Journal on 31 October 2013, postulated that a 20% tax on sugar-sweetened beverages would reduce obesity in the United Kingdom rates by about 1.3%, and concluded that taxing sugar-sweetened beverages was \"a promising population measure to target population obesity, particularly among younger adults.\"\n\nThe tax has been criticised on several grounds, including its likely efficacy and its narrow base. UK Member of Parliament Will Quince as, \"patronising, regressive and the nanny state at its worst.\" In addition a study by the University of Glasgow, which sampled 132,000 adults, found that focusing on sugar in isolation misleads consumers as reducing fat intake is also crucial to reducing obesity.\n\nFrom an opposing standpoint, Professor Robert Lustig of the University of California, San Francisco School of Medicine, has argued that the UK tax measure may not go far enough and that, \"juice should be taxed the same way as soda because from a metabolic standpoint juice is the same as soda.\" Campaigners have since called for the soft drinks tax to be extended to include confectionery and sweets to help tackle childhood obesity.\n\nThe United States does not have a nationwide soda tax, but a few of its cities have passed their own tax and the U.S. has seen a growing debate around taxing soda in various cities, states and even in Congress in recent years. A few states impose excise taxes on bottled soft drinks or on wholesalers, manufacturers, or distributors of soft drinks.\n\nMedical costs related to obesity in the United States alone were estimated to be $147 billion a year in 2009. In the same year, the American Heart Association reported that the soft drinks and sugar sweetened beverages are the largest contributors of added sugars in Americans' diets. Added sugars are sugars and syrups added to foods during processing or preparation and sugars and syrups added after preparation. Excessive intake of added sugars, as opposed to naturally occurring sugars, is implicated in the rise in obesity.\n\nPhiladelphia and Berkeley are the first two cities to pass a tax on sugary drinks in the U.S. Berkeley's tax of 1 cent/oz of sugary drink has seen a decline in soda consumption by more than 20 percent. Philadelphia's tax of 1.5 cents/oz took effect on January 1, 2017.\n\nThe Measure D soda tax was approved by 76% of Berkeley voters on 4 November 2014, and took effect on 1 January 2015 as the first such tax in the United States. The measure imposes a tax of one cent per ounce on the distributors of specified sugar-sweetened beverages such as soda, sports drinks, energy drinks, and sweetened ice teas but excluding milk-based beverages, meal replacement drink, diet sodas, fruit juice, and alcohol. The revenue generated will enter the general fund of the City of Berkeley. A similar measure in neighboring San Francisco received 54% of the vote, but fell short of the supermajority required to pass. In August 2015, researchers found that average prices for beverages covered under the law rose by less than half of the tax amount. For Coke and Pepsi, 22 percent of the tax was passed on to consumers, with the balance paid by vendors. UC Berkeley researchers found a higher pass-through rate for the tax: 47% of the tax was passed-through to higher prices of sugar-sweetened beverages overall with 69% being passed-through to higher soda prices. In August 2016, a UC Berkeley study showed a 21% drop in the drinking of soda and sugary beverages in low-income neighborhoods in its city.\n\nA study from 2016 compared the changing intake of sugar sweetened beverages and water in Berkeley versus San Francisco and Oakland (which did not have a sugary drink tax passed) before and after Berkeley passed its sugary drink tax. This analysis showed a 26% decrease of soda consumption in Berkeley and 10% increase in San Francisco and Oakland while water intake increased by 63% in Berkeley and 19% in the two neighboring cities. A 2017 before and after study has concluded that one year after the tax was introduced in Berkeley, sugary drink sales decreased by 9.6% when compared to a scenario where the tax was not in place. This same study was also able to show that overall consumer spending did not increase, contradicting the argument of opponents of the Sugary Drink Tax. Another 2017 study results were that purchases of healthier drinks went up and sales of sugary drinks went down, without overall grocery bills increasing or the local food sector losing money.\n\nDemocratic Philadelphia mayor Jim Kenney proposed a citywide soda tax that would raise the price of soda at three cents per ounce. At the time, it was the biggest soda tax proposal in the United States. Kenney promoted using tax revenue to fund universal pre-K, jobs, and development projects, which he predicted would raise $400 million over five years, all the while reducing sugar intake by decreasing the demand for sugary beverages. Kenney's soda tax proposal was brought to the national spotlight and divided key members of the Democratic Party. Presidential hopeful Bernie Sanders argued in an op-ed that the tax would hurt the poor. His opponent, Hillary Clinton, on the other hand, said that she was \"very supportive\" of the idea. The American Beverage Association (ABA), funded by soda companies and distributors, ran local television, radio, and newspaper advertisements against the idea, claiming that the tax would disproportionately hurt the poor. The ABA spent $10.6 million in 2016 in its effort against the tax. The American Medical Association, American Heart Association, and other medical and public health groups support the tax.\n\nThe Philadelphia City Council approved a 1.5-cents-per-ounce tax on 16 June 2016. As part of the compromise legislation that passed, the tax is also imposed on artificially sweetened beverages, such as diet soda. The law became effective on 1 January 2017. It was reported after two months of the tax that Philadelphia supermarkets and beverage distributors are planning layoffs because sugary beverage sales are down between 30 and 50 percent.\n\nAfter the tax took effect, Kenney said it was \"wrong\" and \"misleading\" for businesses to pass the tax on to their customers in the form of higher soda prices. In February 2017, soda manufacturers and retailers announced sales declines of 30-50% in Philadelphia and announced job cuts and layoffs. Kenny characterized the layoffs as evidence of greed among manufacturers. In the first four months of the soda tax $25.6 million was collected, which is lower than predicted. The revenue is intended to pay for a pre-K program (49% of tax revenue), government employee benefits and city programs (20%), and rebuilding city parks and recreation centers. A recent study from 2017 found that Philadelphia's tax has decreased sugary beverage consumption in impoverished youth by 1.3 drinks/week. Langellier et al. also found that when paired with the pre-K program, attendance increases significantly, a finding that is likely to have longer term positive effects than a sugary drink tax alone.\n\nIn March 2017, Pepsi laid off between 80 and 100 employees at two distribution plants in Philadelphia and one plant in nearby Wilmington, Delaware. The company blamed the layoffs on the tax, an assertion rejected by the city government.\n\nIn September 2016, the American Beverage Association, Philadelphia business owners, and other plaintiffs filed a lawsuit against the soda tax, alleging that the tax violated the \"Tax Uniformity Clause\" of the state constitution. The legal challenge was dismissed by the Court of Common Pleas in December 2016, and in June 2017 the Commonwealth Court of Pennsylvania (in a 5-2 decision) affirmed that ruling. The ABA is appealing the decision to the Pennsylvania Supreme Court.\n\nA one-cent-per-ounce soda tax (Prop V) passed with over 61% of the vote on 8 November 2016 and applies to distributors of sugary beverages on 1 January 2018. Exemptions for the tax include infant formulas, milk products, supplements, drinks used for medical reasons, and 100% fruit and vegetable juices. The soda industry spent almost $20 million in its unsuccessful push to defeat the soda tax initiative, a record-breaking amount for a San Francisco ballot initiative.\n\nIn 2014, the first referendum on a soda tax, Proposition E, was voted down by San Francisco; the 2014 referendum received the support of 55 percent of voters, short of the two-thirds required for a referendum directing money to a specific item (the referendum proposed directing the revenue raised to children's physical education and nutrition programs, and in San Francisco such earmarking requires a two-thirds vote to pass). In that referendum campaign, the soda industry spent about $10 million in opposition to the proposed tax.\n\nA one-cent-per-ounce soda tax (Measure HH) passed with over 60% of the vote on 8 November 2016. The tax went into effect on 1 July 2017.\n\nA one-cent-per-ounce soda tax (Prop O1) passed with over 70% of the vote on 8 November 2016. The tax went into effect on April 1, 2017\n\nA two-cents-per-ounce soda tax (Measure 2H) passed with 54% of the vote on 8 November 2016. The tax took effect on July 1, 2017, and revenue will be spent on health promotion, general wellness programs and chronic disease prevention that improve health equity, and other health programs especially for residents with low income and those most affected by chronic disease linked to sugary drink consumption. The tax is exempted at the University of Colorado, Boulder, campus as school officials survey what types of drinks students wish to have. The University was not aware it would be involved in the soda tax, and would have to pay as much as $1 million a year to purchase it.\n\nA one-cent-per-ounce soda tax passed on November 10, 2016, by a 9-8 vote, with Cook County Board of Commissioners President Toni Preckwinkle breaking the 8-8 tie. Cook County includes Chicago and has a population of nearly 5.2 million. This was the most populous jurisdiction with a soda tax in the U.S. The campaign to introduce the tax was heavily funded by Mike Bloomberg.\n\nOn June 30, 2017, a Cook County judge granted a temporary restraining order filed by the Illinois Retail Merchants Association and several Cook County-based grocers that prohibited the tax from being put into effect until at least July 12. The tax eventually went into effect on August 2. Due to a conflict with the Supplemental Nutrition Assistance Program, this soda tax did not apply to any soda purchases made with food stamps, which were used by over 870,000 people. Controversially, the tax affected diet drinks but not sugar-packed fruit juices.\n\nOn October 10, 2017, the Board of Commissioners voted to repeal the tax in a 15-1 vote. The tax stayed in effect up until December 1. The tax was highly unpopular and seen mainly as an attempt to plug the county’s $1.8 billion budget deficit, rather than a public health measure.\n\nThe Coalition for Healthy Kids and Education is currently campaigning to get a soda tax on the May 2018 ballot. Their aim is to implement a 1.15 cents per ounce tax on sugary drinks. There are 18,000 signatures required by December 15, 2017 in order for the tax to be voted on in May.\n\nOn June 5, 2017, Seattle's City Council voted 7-1 to pass a 1.75 cents per ounce tax on sugary drinks; the tax does not include diet soda drinks or fruit drinks and it started on January 1, 2018. After the tax was implemented, people were surprised that the tax made a case (24 cans) of Coke become $7.35 more expensive when compared to a case of Diet Coke or Coke Zero. The $15 million Seattle assumes will be collected from the tax will be used for programs that give access to more fruits and vegetables for low-income families, adding education programs and studying the tax on how it impacts behavior. Seattle collected $4 million in the first four months of the tax.\n\nCoca-Cola has been under fire since 2015 when emails revealed that funding for scientific studies sought to influence research to be more favorable to soda. Research funded by soda companies are 34 times more likely to find soda has no significant health impacts on obesity or diabetes.\n\nTaxing soda can lead to a reduction in overall consumption, according to a scientific study published in the \"Archives of Internal Medicine\" in March 2010. The study found that a 10 percent tax on soda led to a 7 percent reduction in calories from soft drinks. These researchers believe that an 18 percent tax on these foods could cut daily intake by 56 calories per person, resulting in a weight loss of 5 pounds (2 kg) per person per year. The study followed 5,115 young adults ages 18 to 30 from 1985 to 2006.\n\nA 2010 study published in the medical journal \"Health Affairs\" found that if taxes were about 18 cents on the dollar, they would make a significant difference in consumption.\n\nResearch from Duke University and the National University of Singapore released in December 2010 tested larger taxes and determined that a 20 percent and 40 percent taxes on sugar-sweetened beverages would largely not affect calorie intake because people switch to untaxed, but equally caloric, beverages. Kelly Brownell, a proponent of soda taxes, reacted by stating that “[t]he fact is that nobody has been able to see how people will really respond under these conditions.” Similarly, a 2010 study concluded that while people would drink less soda as a result of a soda tax, they would also compensate for this reduction by switching to other high-calorie beverages. In response to these arguments, the American Public Health Association released a statement in 2012 in which they argued that \"Even if individuals switch to 100% juice or chocolate milk, this would be an improvement, as those beverages contribute some nutrients to the diet.\"\n\nA 2011 study in the journal \"Preventive Medicine\" concluded that \"a modest tax on sugar-sweetened beverages could both raise significant revenues and improve public health by reducing obesity\". It has been used by the Rudd Center for Food Policy and Obesity at Yale to estimate revenue from a soda tax, depending on the state, year and tax rate.\n\nA 2012 study by Y. Claire Wang, also in the journal \"Health Affairs\", estimates that a penny per ounce tax on sugared beverages could prevent 2.4 million cases of diabetes per year, 8,000 strokes, and 26,000 premature deaths over 10 years.\n\nIn 2012, just before the city of Richmond began voting on a soda tax, a study was presented at a conference held by the American Public Health Association regarding the potential effects of such a tax in California. The study concluded that, given that soda's price elasticity is such that taxing it would reduce consumption by 10–20 percent, that this reduction \"...is projected to reduce diabetes incidence by 2.9–5.6% and CHD by 0.6–1.2%.\"\n\nA 2013 study in the \"American Journal of Agricultural Economics\" concluded that a 0.5-cent-per-ounce tax on soft drinks would reduce consumption, but \"increase sodium and fat intakes as a result of product substitution,\" in line with the Duke University study mentioned above.\n\nA 2014 study published in the \"American Journal of Public Health\" concluded that Sugar-Sweetened Beverages (SSBs) don’t have a negative impact on employment. Even though job losses in the taxed industry occurred, they were offset by new employment in other sectors of the economy.\n\nA 2016 modelling study estimated that a 20% tax on SSBs would decrease the consumption of SSBs in Australia by 12.6%. The tax could decline the prevalence of obesity in the Australian population, which could lead to gains in health-adjusted life years. The results showed an increase of 7.6 days in full health for a 20-24-year-old male and a 3.7 day increase in longevity for their female peers.\n\nThere have been a number of proposed taxes on sugary beverages, including:\n\n\nA 2016 poll by Morning Consult-Vox finds Americans split on their support of a soda tax. Attitudes seem to have shifted a lot since 2013 when a poll concluded that \"respondents were opposed to government taxes on sugary drinks and candy by a more than 2-to-1 margin.\" In California, however, support for a tax has been high for a few years. According to a Field Poll conducted in 2012, \"Nearly 3 out of 5 California voters would support a special fee on soft drinks to fight childhood obesity.\" \nSupport for a soda tax in New York was higher when pollsters say the money will go towards health care. A Quinnipiac University poll released in April 2010 found that New Yorkers opposed a state tax on soda of one penny per ounce by a 35-point margin, but opposition dropped to a margin of one point when respondents were told the money would go towards health care. A Thompson Reuters poll released in the same month found that 51 percent of Americans opposed a soda tax, while 33 percent supported one.\n\nFighting the creation of soft drink taxes, the American Beverage Association, the largest U.S. trade organization for soft drink bottlers, has spent considerable money lobbying Congress. The Association's annual lobbying spending rose from about $391,000 to more than $690,000 from 2003 to 2008. And, in the 2010 election cycle, its lobbying grew to $8.67 million. These funds helped to pay for 25 lobbyists at seven different lobbying firms.\n\nAn industry group called \"Americans Against Food Taxes,\" backed by juice maker Welch's, soft drink maker PepsiCo Inc, the American Beverage Association, the Corn Refiners Association, McDonald's Corporation and Burger King Holdings Inc used national advertising and conducted lobbying to oppose these taxes. The group has characterized the soda tax as a regressive tax, which would unfairly burden the poor\n\n\nIsland nations and territories have been successful in passing soda taxes. Just like with tobacco taxes, smaller communities are often the first to pass a new type of tax.\n\nBarbados passed a soda tax in September 2015, applied as an excise of 10%.\n\nFiji has an import tax and an excise tax on soda.\n\nFrench Polynesia implemented taxes on soft drinks in 2002.\n\nMauritius passed a soda tax in 2013.\n\nNauru implemented a soda tax in 2007.\n\nSamoa passed a soda tax in 1984.\n\nIn March 2014, the government of the island of St Helena, a British Overseas Territory in the South Atlantic, announced that it would be introducing an additional import duty of 75 pence per litre on sugar-sweetened carbonated drinks with more than 15 grams of sugar per litre. The measure was introduced in May 2014 as part of a number of measures to tackle obesity on the island and the resulting high incidence of type 2 diabetes.\n\nTonga has a soda tax.\n\n\n"}
{"id": "10033492", "url": "https://en.wikipedia.org/wiki?curid=10033492", "title": "Tairunnessa Memorial Medical College", "text": "Tairunnessa Memorial Medical College\n\nTairunnessa Memorial Medical College (TMMC) () is a private medical school in Bangladesh, established in 1995. It is an institution of the Tairunnessa Memorial Medical Centre. It was founded by M. Shamsul Hoque, named after his mother, the late Tairunnessa, a social reformer. There is a girls' school in her name in Balaganj as well.\n\nIt offers a five-year course of study leading to a Bachelor of Medicine, Bachelor of Surgery (MBBS) degree. A one-year internship after graduation is compulsory for all graduates. The degree is recognised by the Bangladesh Medical and Dental Council.\n\nM Shamsul Hoque was born in January 1943 in Hamidpur of Rajnagar Upazila in Moulovibazar which was then part of greater Sylhet. He helped the religious minorities to flee the country with a small ship he owned. As a result, he was wanted by the Pakistani army in 1971. He established a School named Tairunnessa Girls' High School in Balaganj in 1977.\n\nTairunnessa Memorial Medical Center started as a small outpatient department at Konya, Gazipur District in 1995 which over the years has turned into a hospital and research center; TMMC Hospital, a 500-bed hospital complex, a 9 storied college building and an administrative block, a ladies' hostel. It is now one of the renowned Medical colleges in Dhaka with all departments.\n\nTairunnessa Memorial Medical College is listed in the World Directory of Medical Schools, published by the World Health Organization (WHO) and now maintained as the Avicenna Directory for Medicine and also listed in the International Medical Education Directory (IMED). \nIMED (International Medical Education Directory) recognition allow TMMC medical students/ graduates to apply for USMLE examination by ECFMG, USA for employment and for post-graduate training in the United States and Canada as well as can apply for PLAB, AMC and NZREX examinations etc. Also Graduates of TMMC are eligible for limited registration with the General Medical Council of United Kingdom.\n\nA Nursing institute was formed in 2008, awarding a B.S.C nursing degree. This became a unit of Tairunnessa Memorial Medical College in 2013.\n\nThe TMMC has around 600 students, including students from Nepal and India. The hospital has expanded to 500-beds, and provides a 24-hour emergency service, with additional trauma center, EPI etc. 255 MBBS doctors have passed till 2014 December.\n\n"}
{"id": "51306302", "url": "https://en.wikipedia.org/wiki?curid=51306302", "title": "The Mines Rescue Rules, 1985", "text": "The Mines Rescue Rules, 1985\n\nThe Mines Rescue Rules, 1985 came into force with effect from 2 April 1985 in India, replacing the previous Coal Mines Rescue Rules-1959, to provide for rescue of work persons in the event of explosion, fire etc. in the Mines. \n\nThese rules apply to coal and metalliferous underground mines to provide for the establishment of rescue stations and conduct of rescue work. In case of explosion or fire, an inrush of water or influx of gases, services of specially trained men with special rescue apparatuses are required.\nChapter I - Preliminary\n\nChapter II - Rescue Stations and Rescue Rooms\n\nChapter III - Duties and Responsibilities of Superintendents etc.\n\nChapter IV - Organisation and Equipment in Mines\n\nChapter V - Conduct of Rescue Work\n\nChapter VI – Miscellaneous\n\n"}
{"id": "41065226", "url": "https://en.wikipedia.org/wiki?curid=41065226", "title": "Time to Change (mental health campaign)", "text": "Time to Change (mental health campaign)\n\nTime to Change is a mental health campaign in England, launched in 2007 with the objective of reducing mental health-related stigma and discrimination.\n\n\"Time to Change\" (TTC) was formed in 2007 by mental health charities MIND and Rethink Mental Illness, aiming to reduce mental health-related stigma and discrimination. A specific objective was to reduce stigma and discrimination by 5 per cent in the first 12 months. The first four years were funded by grants of £20.5 million from the Big Lottery Fund and Comic Relief.\n\nTTC also asks organisations and individuals to sign a pledge supporting its anti-stigma programme. Organisations signing the pledge include the Bank of England, the Financial Conduct Authority, British Gas, British Telecom, Lloyds Banking Group, Ernst & Young, E.ON, PepsiCo and parts of the National Health Service. A pledge event took place at the Houses of Parliament in October 2013, giving MPs an opportunity to sign up.\n\nIn 2011, TTC launched a four-week television advertising campaign to promote its new slogan: \"It's time to talk. It's Time to Change.\"\n\nThe campaign has been fronted by a number of celebrities, including political strategist Alastair Campbell, presenter Davina McCall, singer Frankie Sandford, and boxer Ricky Hatton. In 2014, the campaign supported the \"Laughing for a Change\" project run by actress Janice Connolly, which aimed to promote awareness of mental health through a stand-up comedy tour.\n\nAn academic study was carried out to measure whether TTC had met their 5 per cent target in the first 12 months. Though the participation in the telephone surveys was very low, they measured \"progress toward meeting TTC's target of a 5 per cent reduction in discrimination\".\n\nAn independent evaluation of the campaign's first four years took place in 2013. Though it found a reduction in discrimination from friends and families, change in attitudes from health professionals was negligible.\n\nIn Wales the campaign was launched in 2012 under the name \"Time to Change Wales\", led by Welsh mental health charities MIND Cymru, Gofal and Hafal.\n\n\n"}
{"id": "42561826", "url": "https://en.wikipedia.org/wiki?curid=42561826", "title": "Water towers in Września", "text": "Water towers in Września\n\nThree water towers in Września once supplied water in Września, Poland. Two water towers are still in use.\n\nThe tallest was built in 1904 (some sources say 1907 and 1911) and is the highest building in the vicinity. The tower is tall and its top is finished with an interesting brass dome. The building belongs to the municipal Water Supply and Sewerage Enterprise. Next to the water tower stands the water treatment plant. The tower is near two ponds, allotment gardens and Polytechnic School.\n\nAnother tower, built in 1907 and now unused, is located at the Września railway station, near several apartment buildings and an overpass. Another, smaller tower has been destroyed during the bombing on 5 October 1939.\n\nA former tower was located in the prussian Barracks Complex in Września. It did not survive the Russian invasion. The location houses a cinema, a club and Wielkopolska Insurgents’ Trade School No 2.\n"}
{"id": "49268578", "url": "https://en.wikipedia.org/wiki?curid=49268578", "title": "Zygoma Implant", "text": "Zygoma Implant\n\nZygoma implants (or Zygomatic implants) are different from conventional dental implants in that they anchor in to the zygomatic bone (cheek bone) rather than the maxilla (upper jaw). They may be used when maxillary bone quality or quantity is inadequate for the placement of regular dental implants. Inadequate maxillary bone volume may be due to bone resorption as well as to pneumatization of the maxillary sinus or to a combination of both. The minimal bone height for a standard implant placement in the posterior region of the upper jaw should be about 10 mm to ensure acceptable implant survival. When there is inadequate bone available, bone grafting procedures and sinus lift procedures may be carried out to increase the volume of bone.Bone grafting procedures in the jaws have the disadvantage of prolonged treatment time, restriction of denture wear, morbidity of the donor surgical site and graft rejection.\n\nZygoma implants were first introduced in late 1990s by Dr. Per Ingvar Branemark widely acknowledged as the \"Father of Dental Implantology\". Zygomatic implants have been used for dental rehabilitation in patients with insufficient bone in the posterior upper jaw, due to, for example, aging, tumor resection, trauma, or atrophy. Zygoma implants take the anchorage from the Zygoma/ zygomatic bone (cheek bone).The Zygomatic bone is denser in quality and more cortical in nature than posterior maxillary bone . Because of the sturdy anchorage achievable in the dense bone of the zygomatic region, and the wide stress distribution achieved on these tilted implants, a prosthesis can often be immediately placed at the time of surgery . The Zygoma implant is available in lengths ranging from 30 to 52.5 mm. The head of the zygoma implant is engineered to allow prosthesis attachment at a 45-degree angle to the long axis of the implant. Zygomatic implants can be used in patients who do not have any teeth in the upper jaw, patients who have heavily broken down teeth or very mobile teeth due to diseases such as generalised aggressive periodontitis. The success rate of zygomatic implants reported in the literature world-wide is 97 - 98%. The complications associated with these implants are sinusitis, paresthesia in the cheek region and oro-antral fistula.\n"}
