{"id": "14658661", "url": "https://en.wikipedia.org/wiki?curid=14658661", "title": "Abortion in Russia", "text": "Abortion in Russia\n\nAbortion in Russia is legal as an elective procedure up to the 12th week of pregnancy, and in special circumstances at later stages. In 1920, Russian Soviet Republic became the first country in the world to allow abortion in all circumstances, but over the course of the 20th century, the legality of abortion changed more than once, with a ban being enacted again from 1936 to 1955. Russia had the highest number of abortions per woman of child-bearing age in the world according to UN data as of 2010. In terms of the total number, in 2009 China reported that it had over 13 million abortions, out of a population of 1.3 billion, compared to the 1.2 million abortions in Russia, out of a population of 143 million people.\n\nAbortion was illegal in the Russian Empire. The practice is not directly referenced in the Domostroi, though child rearing is a common topic. During Tsar Alexis Romanov's reign the punishment for abortion was death, only later removed by Peter the Great. Abortion continued to be a serious crime until 1917. Through articles 1462 and 1463 of the Russian Penal Code individuals \"guilty of the crime could be deprived of civil rights and exiled or sentenced to hard labor.\" Despite its illegality, \"black market\" abortions existed. Underground obstetric personnel known as \"povival’nye babki\" and \"sel’skie povival’nye babki\", usually translated as midwives and rural midwives, respectively and commonly referred to as simply \"babki\", literally \"old women\" and \"povitukhi\" (midwives) performed abortions. Not merely abortionists, \"babki\" were trained health care professionals—they served as nurses and midwives in especially rural areas where proper medical service was unavailable. The number of abortions increased in Moscow two-and-a-half times between 1909 and 1914; the increased frequency of abortions in St. Petersburg was many times higher over the turn of the century, 1897-1912. Statistical data from the beginning of the 20th century suggest that the strict laws were rarely enforced. For instance, figures for sentences pronounced during the years before the First World War include: 20 (1910), 28 (1911), 31 (1912), and 60 (1914).\n\nIn the late Russian Empire, doctors and jurists began to advocate for relaxed abortion laws and increased contraception. The motivation was to make abortions less dangerous. According to historians, the movement to legalize abortion and encourage contraception arose differently than it did in Western Europe. Rather than among the political scene (as in France, for example), proponents came from medical fields. In 1889 the Third Congress of the Pirogov Society, a medical scientific society whose works had a resounding influence in Russia, started the discussion on decriminalization of abortion. Others followed: in 1911 the Fourth Congress of the Society of Russian Midwives, in 1913 the Pirogov Society's Twelfth Congress, and in 1914 the Russian group of the International Society of Criminologists came forward supporting decriminalization.\n\nThe Soviet government was the first government in Europe to legalize abortion. In October 1920 the Bolsheviks made abortion legal within the Russian Soviet Federative Socialist Republic with their “Decree on Women’s Healthcare.” After the RSFSR the law was introduced in Ukraine (5 July 1921) and then the remainder of the Soviet Union. The government saw legalization as a temporary necessity, as after the economic crisis and nearly a decade of unrest, war, revolution, and civil war, many women would be seeking abortions due to not being able to take care of their child. Restrictions were placed on the criteria for abortions and by 1924 it was only permitted where pregnancy risked the life of the woman or the unborn child. The Soviet Union encouraged pronatal policies; however, Soviet officials argued that women would be getting abortions regardless of legality, and the state would be able to regulate and control abortion only if it was legalized. In particular, the Soviet government hoped to provide access to abortion in a safe environment performed by a trained doctor instead of \"babki\". While this campaign was extremely effective in the urban areas (as much as 75% of abortions in Moscow were performed in hospitals by 1925), it had much less on rural regions where there was neither access to doctors, transportation, or both and where women relied on traditional medicine. In the countryside in particular, women continued to see \"babki\", midwives, hairdressers, nurses, and others for the procedure after abortion was legalized in the Soviet Union.\n\nThe Soviet Union became the first country to have abortion available, on request, often for no cost. There was intense debate among government and medical officials surrounding its legalization. The main arguments used in opposition to legalizing abortion were that it would have a harmful effect on population growth or on the grounds that it was too medically harmful to the woman. By the mid-1920s, hospitals were so severely congested by abortion procedures that special clinics had to be opened to free up beds. The enormous rate of abortions being performed also caused many doctors to become concerned and restrictions started being passed to limit abortion after the third month of pregnancy and to ensure that priority was given only to women deemed too poor, single, or who already had several children. Only six months between a first abortion and a second abortion was permitted. In addition, renewed efforts were made to prosecute \"babki\". This had first started with the legalization of abortion in 1920 and a fair number of \"babki\" were caught and punished as legal abortion gave them no excuse to continue operating. During the collectivization drives in the early 1930s, this was temporarily put on the back burner, but in 1934 new, stricter laws were passed on performing illegal abortions, including a circular of the RSFSR Procuracy and extensive stories on them in the major newspapers. The circular requested that regional prosecutors step up efforts to combat unsanctioned abortion, citing a letter submitted to the Procuracy by an anonymous private citizen decrying the harm done to women by \"babki\" in one rural district. A month later, \"Izvestiia\" ran a piece condemning \"the plight of young women who ended up at the abortionist's doorstep after being unable to find employment.\"\n\nIn 1936 the Soviet Union made abortion illegal again, stemming largely from Joseph Stalin’s worries about population growth. The law that outlawed abortion did not only do just that, but rather contained several different decrees. The official title of the law was, “Decree on the Prohibition of Abortions, the Improvement of Material Aid to Women in Childbirth, the Establishment of State Assistance to Parents of Large Families, and the Extension of the Network of Lying-in Homes, Nursery schools and Kindergartens, the Tightening-up of Criminal Punishment for the Non-payment of Alimony, and on Certain Modifications in Divorce Legislation.” All of this was part of Stalin’s initiative to encourage population growth, as well as place a stronger emphasis on the importance of the family unit to communism.\n\nThis decree provoked widespread resentment and opposition, with urban women arguing that it was often impossible to have a child when they were trying to further their careers (as the Soviet state actively promoted female education and work placement) and because of inadequate housing and supplies needed to care for children. The anti-abortion laws in practice were only marginally more enforceable than in tsarist times and \"babki\" continued to ply their trade, knowing that there was little risk of being caught. Although there were numerous cases of women checking into hospitals after undergoing botched abortions, it was usually impossible to tell if they had had a miscarriage, a self-performed one, or one performed by a \"babka\". The unwritten code of female solidarity also held strong and women seldom ratted out \"babki\" to the authorities.\n\nIn practice, the abortion rate was affected little by the 1936 decrees, although it was observed that the rate of infant mortality rose between 1935 and 1940 due to apparently women injuring themselves in illegal abortions that then prevented them from producing healthy children. \"Babki\" abortion services remained as they had always been, unsafe, expensive, and forcing women to lie to authorities.\n\nThe law provided allowances to women for their seventh and subsequent children up until their third birthday. In 1944 the benefits were expanded to offer allowances for the third children until their fourth birthday and for fourth and subsequent children until their seventh birthday. However, all of this aid was cut in 1948, after the largest source of population depletions, World War II, was over. Despite abortion being outlawed and these fertility policies, abortion rates remained high during this time. Illegal abortions caused an estimated 4,000 deaths per year from complications from underground abortions. Women continued to get illegal abortions during this time due to policies encouraging married women to be employed and economic policies favoring heavy industry and national defense over housing and consumer goods.\n\nDuring the postwar era, millions of men were dead and the government was forced to legitimize single-mother families. The New Family Law of 1944 sanctioned single motherhood as a site of reproduction by providing financial support for single mothers. The prevalence of single mothers in this time was a reality; by 1957, 3.2 million women were claiming government aid as single mothers.\n\nAfter Stalin’s death in 1953, the Soviet government revoked the 1936 laws and issued a new law on abortion. The decree stated that “measures carried out by the Soviet state to encourage motherhood and protect infancy, as well as the uninterrupted growth of the consciousness and culturedness of women,” allowed for the change in policy. The language of the decree implied that most women would choose motherhood over abortion and that preventing abortion remained a goal of the government, as it was still encouraging population growth.\n\nDuring the late 1950s and 1960s, it is estimated that the Soviet Union had some of the highest abortion rates in the world. The abortion rate during this period is not known for sure, because the Soviet Union did not start releasing abortion statistics until perestroika. The best estimates, which are based on surveys of medical professionals during this time, say that about 6 to 7 million abortions were performed per year.\n\nOne of the few insights we have regarding abortion during the late 1950s is a survey, conducted between 1958 and 1959, of 26,000 women seeking abortions, 20,000 from urban areas and 6,000 from rural areas. Several facts can be gathered from this survey regarding what kind of women sought abortions and their reasons for doing so. First of all, an “overwhelming majority” of the women were married, though the survey results do not give an exact percentage. Second, we can learn how many children the women had. Of the urban women, 10.2% were childless, 41.2% had one child, 32.1% had two children, and 16.5% had three or more children, making the median number of children 1.47. Of the rural women, 6.2% were childless, 26.9% had one child, 30% had two children, and 36.9% had three or more children, the median number of children being 2.06. Of women seeking abortions, urban women were more likely to have fewer or no children. This may have been an effect of the lack of space faced by urban women.\n\nThe survey also examined women’s reasons for seeking abortions. It divided the reasons into four categories. The first was “unconditionally removable”, things that could be remedied by government action, such as material need, lack of space, no one at home, or no institution to put child in. The second category was “conditionally removable”, things that might possibly be remedied by government action, such as the absence of husband, family troubles, or illness of one or both parents. The third category was “unremovable”, things that were not caused by social conditions, such as a baby in family or many children already. The fourth category was “unclear causes”, such as one or both parents unwilling to have a child and other or multiple reasons.\n\nThe results for this question were: of the reasons given by urban women, 35% were unconditionally removable, 16.5%, were conditionally removable, 10% were unremovable, and 37.9% were unclear. Of the reasons given by rural women, 26.3% were unconditionally removable, 18% were conditionally removable, 10% were unremovable, and 45.2% were unclear. The most marked different was that more urban women cited lack of space as a reason. The survey results found that abortion rates were much higher among women who work, unsurprisingly, with a rate of 105.5 abortions per thousand pregnancies, as against 41.5 per thousand in women who did not work.\n\nIf the abortion rates of this survey are taken to be representative, then during this period the number of annual abortions was higher than the number of live births. This would also mean that the abortion rates in the Soviet Union were the highest of any in the world at that time. By the end of the Brezhnev era in 1982, Soviet birthrates hovered just at or below replacement level except in the Muslim-majority Central Asian republics.\n\nThe early years of the Russian Federation were marked by declining rates of fertility and abortion and increased access to and use of preventative birth control. The official policy of the Soviet Union at the time of its collapse was pro-family planning, although contraceptives were generally unavailable to the public, leaving most women with abortion as the only way to regulate family size. The declining rate of abortion indicates that less and less Russian pregnancies were intended. \nMost common in the 1990s were ‘miniabortions,’ abortions by vacuum aspiration performed during the first seven weeks of pregnancy. The legalization of miniabortions in 1988 made the previously required three-day hospital stay unnecessary. \nUnreliable quality and availability of contraceptive options may have partially slowed the decline in abortion rates in Russia in the 1990s. In Russia at the beginning of the 1990s no more than 75% of sexually active women used preventative birth control of any kind. While such resources became more available with the fall of the Soviet Union, by 1993 still less than half of Russian women felt they had adequate access to them. In the first decade of the Russian Federation alone both of Russia’s condom factories and the only Russian IUD factory shut down for periods of time because of concerns about latex prices and quality control. With the start of democracy in Russia still 41% of sexually active women relied on unreliable ‘traditional methods’ of birth control. Many women who used those methods cited the availability of abortions as a factor in their reasoning. Many women who used no method of birth control at all also cited the option of abortion as a reason that they did not concern themselves with modern or even traditional family planning strategies.\nBetween 1990 and 2000 the number of annual abortions in Russia declined by half, but the ratio of abortions to live births (2.04 in 1990 to 1.92 in 1996) declined similarly. This means not only that fewer abortions were performed, but that fewer women became pregnant overall. This overall declining rate of fertility was a partial cause of one of the two main structural factors in Russia that promote abortion over preventative birth control. Other factors lowering the rate of abortion include measures taken by President Vladimir Putin to increase family size in Russia. In the early 2000s he called for federal financial support for children in the first 18 months of life as a way to encourage women to have a second or third child. When he first proposed this the Russian population was declining by 700,000 people every year. In the first ten years of the Russian Federation, the population of Russia declined by 3 million. Concerns about population decline in Russia are widespread and very important to the dialogue on abortion. Attempts to mitigate population decline started with increased financial support for young children in Russia and eventually lead to restricted access to abortion.\n\nOther factors in the decline of abortion in Russia include the legalization of sterilization. Regulations of contraceptive sterilization had been in place since the 1930s but were lifted in 1993. In the first seven years that the practice was legal, almost 100,000 women sought and obtained sterilizations. This is a factor in the declining rates of unintended pregnancy in Russia. 2003 was the first time in fifty years that laws regarding access to abortion were made stricter; every other piece of legislation on the topic in both the Soviet Union and the Russian Federation was to grant women easier access.\nIn 1991, the year of the fall of the Soviet Union a record of about 3,608,000 abortions were performed in Russia. This number declined steadily over the years and by 2002 Russian doctors were performing 1,802,000 abortions annually. This is a significant decline, but leaves Russia with still the second-highest rate of abortions per capita. (While abortions in Russia overall were declining, in the Asian part of the country the rate was actually increasing.) While abortion rates in these Asian republics were not as high as those in Western Russia at the time of the collapse of the Soviet Union, and are still not the highest in the country, they did rise. The decrease in overall rates of abortion is mostly due to the very steep drop in abortions per year in the two biggest cities in Russia, Moscow and St. Petersburg.\nNational concern about declining population was a continuing trend since the 1980s, and caused the new regime to adopt anti-family planning policies. The use of contraceptives slowly rose over the 1990s but still in 1997 one in ten Russian pregnancies ended in abortion, and so it could be assumed that at least one in ten Russian pregnancies was unintended. Legally in Russia, the abortion procedure must take place in a hospital and as a result abortions provide an important source of income for healthcare providers.\nAs abortions became slightly less common they hardly got safer. By 1998 still two in three abortions had some kind of health complication. Among the most common of these complications is unintentional secondary sterilization, which happens to one in ten Russian women who seeks an abortion in her lifetime. Among minors getting abortions, this rate is twice as high. Illegal abortions, performed without license by doctors or \"babki\", have higher rates of mortality and sterilization even than legal abortions, but remain relatively popular because of their confidentiality.\n\nDuring the 2000s, Russia's steadily falling population (due to both negative birthrates and low life expectancy) became a major source of concern, even forcing the military to curtail conscription due to shortages of young males. On 21 October 2011, the Russian Parliament passed a law restricting abortion to the first 12 weeks of pregnancy, with an exception up to 22 weeks if the pregnancy was the result of rape, and for medical necessity it can be performed at any point during pregnancy. The new law also made mandatory a waiting period of two to seven days before an abortion can be performed, to allow the woman to \"reconsider her decision\". Abortion can only be performed in licensed institutions (typically hospitals or women’s clinics) and by physicians who have specialized training. The physician can refuse to perform the abortion, except the abortions for medical necessity. The new law is stricter than the previous one, in that under the former law abortions after 12 weeks were allowed on broader socioeconomic grounds, whereas under the current law such abortions are only allowed if there are serious medical problems with the mother or fetus, or in case of rape.\n\nAccording to the Criminal Code of Russia (article 123), the performance of an abortion by a person who does not have a medical degree and specialized training is punishable by fine of up to 800,000 RUB; by a fine worth up to 8 months of the convicted's income; by community service from 100 to 240 hours; or by a jail term of 1 to 2 years. In cases when the illegal abortion resulted in the death of the pregnant woman, or caused significant harm to her health, the convicted faces a jail term of up to 5 years.\n\nThe abortion issue has gained renewed attention in 2011 in a debate that \"The New York Times\" says \"has begun to sound like the debate in the United States\". Parliament passed and President Dmitri Medvedev signed several restrictions on abortion into law to combat \"a falling birthrate\" and \"plunging population\". The restrictions include requiring abortion providers to devote 10% of advertising costs to describing the dangers of abortion to a woman's health and make it illegal to describe abortion as a safe medical procedure. Medvedev's wife Svetlana Medvedeva has taken up the pro-life cause in Russia in a weeklong national campaign against abortion called \"Give Me Life!\" and a \"Day of Family, Love and Faithfulness\" by her Foundation for Social and Cultural Initiatives in conjunction with the Russian Orthodox Church.\n\nDespite a significant reduction in the abortion to birth ratio since the mid-1990s, the countries of the former Soviet Union maintain the highest rate of abortions in the world. In 2001, 1.31 million children were born in Russia, while 2.11 million abortions were performed. In 2005, 1.6 million abortions were registered in Russia; 20% of these involved girls under the age of 18. Official statistics put the number at 989,000 in 2011.\n\n, the abortion rate was 37.4 abortions per 1000 women aged 15–44 years, the highest of any country reported in UN data.\n\nAbortion statistics were considered state secrets in the Soviet Union until the end of the 1980s. During this period, the USSR had one of the highest abortion rates in the world. The abortion rate in the USSR peaked in 1965, when 5.5 million abortions were performed, the highest number in Russia’s history. Nevertheless, the legalization of abortion did not fully eliminate criminal abortions. [E.A. Sadvokasova]\n\n\n"}
{"id": "36344812", "url": "https://en.wikipedia.org/wiki?curid=36344812", "title": "Aisha Diori", "text": "Aisha Diori\n\nAisha Diori (born 8 Sep, in Lagos, Nigeria) is a Event's Specialist, Community Mobiliser, HIV/AIDS Preventionist, Educator, Host, Pan Africanist, and named \"Iconic Mother\" in Ball culture. Her father is Abdoulaye Hamani Diori, a Nigerien political leader and businessman and her mother is Betty Graves first Nigerian/Ghanaian woman to own a travel agency in Nigeria. Diori holds a Bachelor of Arts in advertising & marketing communications from Fashion Institute of Technology where she graduated magna cum laude. Diori's HIV prevention work with LGBTQ youth in Ball culture, an LGBT subculture, has been influential in the field of public health. She is the founder of the KiKi Ballroom scene and is considered an expert in engaging this historically difficult-to-reach population. Her expertise is requested for grants/program development, research and curriculum development. She worked at the Hetrick-Martin Institute as a Director of Health & Wellness and is the Mother of the House of Iman, a WBT (women, butch and transgender) people House in New York City. In February 2014, Diori joined the renowned Schomburg Center for Research in Black Culture in Harlem as an employee. Serving as Special Events Manager for the Schomburg, Diori continues to mentor and lend her expertise to anything impacting LGBTQ people involved in the House Ball Community.\n\nWhile Aisha's father was in exile, he had a relationship with Betty Graves, who gave birth to both Diori and Chris in Nigeria. Betty Graves was a tour operator and moved to America to further her career at New York University. When Diori and her brother, Chris, came to America to visit their mother on vacation when Diori was about 6, they both refused to move back to Africa, and remained in New York City ever since.\n\nDiori was an AmeriCorps VISTA volunteer through the Council of Churches of the City of New York. She developed programming for inner city elderly people.\n\nIn the summer of 1997, Diori attended the Mooshood Ball and became enamored with the gender nonconformity, queer pageantry. The Ball was not simply a gay dance party, she notes in her biography on her blog, \"It was full of safer sex messaging, freedom, pageantry sexiness, beautiful feminine women, strong handsome butch women…\" Diori approached Arbert Santana, who was then the Mother of the House of Latex and a tireless LGBT and HIV awareness activist. Though unable to make contact at first, Diori connected with fellow Fashion Institute of Technology classmate the Legendary Big Boy Runway Ricky Revlon. Revlon, who later became Diori's \"gay father\", along with Santana who later became Diori's \"gay mother\", helped Diori into the House of Latex, forever changing her commitment to the LGBTQ community. The House of Latex is a program of Gay Men's Health Crisis (GMHC) that gives life to youth in the House and Ball scene and empowers the community to promote HIV prevention and awareness. House of Latex balls have attracted many celebrity guests, including Janet Jackson Patricia Fields, Estelle, and Jay Alexander from America's Next Top Model.\n\nDiori began working as an outreach worker at the Gay Men's Health Crisis (GMHC), hosting HIV prevention balls to effectively curtail the number of newly HIV infected youth. Diori began participating in \"walking\" balls. Under the guise of her gay parents, Diori was advised to walk in the \"Women's Face\" and \"Big Girls Runway\" categories for her first ball, The Black Pride Ball. Diori won the top prize in both categories. Her interests in the ballroom culture began to shift from active participant to community organiser and intervention specialist. Diori received the title of \"house mother\" from The House of Latex, due to her commitment to ballroom culture, a title she held for nearly 5 years.\n\nIn late 2007, Diori opened the House of Iman, pairing safer sex and prevention messages that specifically targeted the Women, Butch and Transgender (WBT) ballroom scene. Aisha infused progressive safer sex and educational messaging with pageantry. The House of Iman, a name that pays homage to Diori's Nigerian heritage, continues to provide leadership in the WBT community.\n\nAcknowledging youth were not best served in the mainstream ballroom scene, Diori and Mother Arbert Santana created the \"KiKi scene\": a ballroom-infused HIV prevention intervention and movement focusing on LGBTQ youth ages 12 – 24, where the young people Vogue, hang out with friends and get connected to services, like HIV testing, counselling and connection to healthcare. \"KiKi Lounge,\" a drop in group for LGBTQ youth to vogue and connect to services and \"Vogue Femme Fridays,\" KiKi balls led by LGBTQ youth infused with prevention messaging, are offered at Hetrick-Martin Institute and are being replicated by other CBO's across the country. Since its inception, the KiKi scene has conducted over many safer-sex/harm reduction functions through different providers including resources for some 20,000+ at-risk LGBTQ youth.\n\nIn February 2014, Diori joined the renowned Schomburg Center for Research in Black Culture in Harlem as an employee. Serving as Special Events Manager for the Schomburg, Diori has secured many successful rentals and has brought many exciting and culturally relevant events to the Schomburg. Aisha curates and manages the very popular Schomburg First Fridays event series that target diverse community members interested in the diasopra and community networking with access to some of the Schomburgs rich collections. On 9 June 2014, Diori moderated Visually Speaking: LGBTQ Cultures in Photography, a talk curated by Terrence Jennings and featuring photographers Gerard Gaskin and Samantha Box\n\n\n\nDiori's social awareness campaigns at Hetrick-Martin Institute and GMHC including the \"You Are Loved\" campaign and the \"No Shade\" campaign, highlighting the importance of self-love and self-efficacy amongst LGBTQ youth surrounding education, sexual health and civic engagement. She also created Crystal Meth Campaigns, Soul Food Programs campaign, Transgender Health and Condom Kit campaigns targeted to specific LGBTQ communities, as well as promotional materials for outreach and program advertising through GMHC. Diori created advertising materials and event planning for Department of Health, Public Health Solutions.\n\nDiori was also a DJ and event planner during her college years. She continues to plan and promote all of her own balls and events for various Houses and programs. She creates graphics and promotional flyers.\n\n\"Young people know AIDS is still a problem but it's kind of hidden. Too many take a 'see no evil, hear no evil' approach by not taking it seriously. We try to make it serious by continuing our outreach, making testing and information available. We develop relationships with the young people we're serving. We've opened up our doors. We let the kids who might feel forgotten in the gay scene know that we're here for them.\" Aisha Diori, House of Latex, on reaching youth, a high-risk group.\n\n"}
{"id": "15044244", "url": "https://en.wikipedia.org/wiki?curid=15044244", "title": "Authorized generics", "text": "Authorized generics\n\nAuthorized generics are prescription drugs produced by brand pharmaceutical companies and marketed under a private label, at generic prices. Authorized generics compete with generic products in that they are identical to their brand counterpart in both active and inactive ingredients; whereas according to the U.S. Food and Drug Administration's Office of Generic Drugs, generic drugs are required to contain only the identical active ingredients as the brand. Authorized generics compete with generics on price, quality and availability in the generic marketplace, and are marketed to consumers during and after what is commonly known as “the 180-day exclusivity period”.\n\nIn 2011 the FTC issued a final report on authorized generics (following its 2009 interim report) that showed that when innovator companies launched authorized generics during the 180 day exclusivity period granted to the first generic company to file an ANDA, prices were significantly lower that when there was no authorized generic and no competition, thus benefiting consumers.\n\nAccording to Roper Public Affairs & Media, 2005 public research underlines consumer demand to have authorized generic prescription drugs available, showing over 80 percent of Americans want the option of authorized generic prescription drugs. Several independent organizations, including Pharmaceutical Research and Manufacturers of America,\nSonecon, and GPhA have commissioned their own studies on authorized generics, furthering the competitive debate.\n\n"}
{"id": "13036371", "url": "https://en.wikipedia.org/wiki?curid=13036371", "title": "Buschke–Ollendorff syndrome", "text": "Buschke–Ollendorff syndrome\n\nBuschke–Ollendorff syndrome, also known as dermatofibrosis lenticularis disseminata, is a rare genetic disorder associated with LEMD3. It is believed to be inherited in an autosomal dominant manner. It is named for Abraham Buschke and Helene Ollendorff Curth who described it in a 45-year-old woman. Its frequency is almost 1 case per every 20,000 people and is equally found in both males and females.\n\nThe signs and symptoms of this condition are consistent with the following (possible complications include aortic stenosis and hearing loss):\n\nBuschke–Ollendorff syndrome is caused by one important factor: mutations in the LEMD3 gene (12q14), located on chromosome 12.\n\nAmong the important aspects of Buschke–Ollendorff syndrome condition, genetically speaking are:\n\nThe diagnosis of this condition can be ascertained via several techniques one such method is genetic testing, as well as:\n\nThe differential diagnosis for an individual believed to have Buschke–Ollendorff syndrome is the following:\n\n\nIn terms of the treatment of Buschke–Ollendorff syndrome, should the complication of aortic stenosis occur then surgery may be required. Treatment for hearing loss may also require surgical intervention.\n\n\n\n"}
{"id": "17548322", "url": "https://en.wikipedia.org/wiki?curid=17548322", "title": "Canadian Society of Safety Engineering", "text": "Canadian Society of Safety Engineering\n\nThe Canadian Society of Safety Engineering (CSSE) is a Canadian association which promotes accident prevention. It was founded in 1949 by a small group of individuals drawn together in the common cause of accident prevention. It grew from a provincially based organization to become a large professional organization for health and safety practitioners.\n\nToday, the CSSE has over 5,000 members across Canada, the United States, and around the world. The CSSE supports the operation of 35 local chapters, which provide a local forum for information exchange and networking among professionals. Through chapter meetings and activities, members promote and enhance the profile of the profession in communities throughout Canada.\n\nThe mission of the CSSE is to be the resource for professional development, knowledge and information exchange to its members, its profession and the Canadian public.\n\nCertified Health and Safety Consultant (CHSC) The CHSC designation is awarded by the CSSE to health and safety professionals who have met certain academic and experience requirements and passed a series of examinations designed to test knowledge of occupational health and safety.\n\nCSSE promotes active participation of members, individuals and organizations during North American Occupational Safety and Health Week (NAOSH), which, along with CSSE's strategic partners, seeks to raise awareness of occupational safety and health.\n\n"}
{"id": "48375985", "url": "https://en.wikipedia.org/wiki?curid=48375985", "title": "Cannabis in Svalbard", "text": "Cannabis in Svalbard\n\nCannabis in Svalbard is illegal. Practically functioning as ungoverned terra nullius prior to the Svalbard Treaty of 1920, the Arctic Ocean archipelago dominated by glaciers and barren rock, is part of Norway, and hence Norwegian law applies. Under it, there is a sliding scale approach to cannabis legislation. Possession for personal use, defined as up to 15 grams, is punished with a fine of between roughly 1,500 and 15,000 Norwegian kroner. \nPossession of amounts larger than that is punished by jail, ranging from 6 months all the way up to 21 years. These laws are enforced by the Norwegian Police Service, the small Svalbard district of which is run by the Governor of Svalbard.\n\nWith the exception of minor scientific stations, Svalbard has three main permanently inhabited settlements – the administrative capital Longyearbyen, the Russian coal mining town Barentsburg, and the small research settlement Ny-Ålesund. As of 1 July 2015, the archipelago's total population is 2,677 people, in addition to large numbers of temporary workers and tourists. The use of illegal drugs is a small but growing issue within Svalbard's society, according to the Longyearbyen Community Council. While there is reportedly little evidence of an active narcotics trade in Longyearbyen, authorities are encouraged to pay close attention to the increasing liberalization of opinions relating to drug use among Svalbard's youths, and ample amounts of substance abuse prevention measures have been enacted. A 2013 survey has shown that cannabis consumption among youths on Svalbard is somewhat lower than among youths on the Norwegian mainland, although certainly still existent. Significantly, only 7% of those surveyed stated that a belief that they – if they wanted to – could procure cannabis within a couple of days, compared to 41% of youths on the mainland.\n\nIn 2011 the police made one of Svalbard's first drug busts, in which a total of 11 people were apprehended under suspicion of both using and selling cannabis. They were charged with a total of 24 offenses, which resulted in a 26 percent rise in the regional crime rate that year. One of them was later expelled from the archipelago, and another given a preliminary warning of expulsion. That autumn, the Governor of Svalbard officially announced the presence of illegal drugs among \"young adults\" in Longyearbyen. Following a lengthy investigation, a similar drug bust was made in October 2015, when a multi-national group of 11 men and women in their twenties were arrested and charged with, primarily, possession of cannabis, with some suspicion of cocaine usage as well. Several of those apprehended were given fines ranging between 4,000 and 9,000 Norwegian kroner. Whether any of them are to be expelled from Svalbard is currently under investigation. Following this event, an online poll run by the local newspaper \"Svalbardposten\" showed that 86% of respondents favored expulsion for drug crimes, although some sentiment towards legalization or decriminalization was also found. The Governor of Svalbard, Kjerstin Askholt, stated that her administration has zero-tolerance policy towards illegal drugs, and \"will do what we can to prevent a drugs culture from establishing itself here\".\n\nWhile cannabis is strictly illegal in Svalbard, there is one place in the archipelago that possesses an amount of it – the Svalbard Global Seed Vault. A seed bank located outside of Longyearbyen, the secure vault contains thousands of seeds from around the world, in order to ensure their preservation in case of other seed banks being destroyed or damaged during large-scale regional or global crises. Among the species of plant preserved in the vault are around 21,500 seeds belonging to the cannabis genus, donated in 2014. The seeds were provided by Alchimia, a Spanish seed bank. This will ensure the survival of cannabis, for use by future generations.\n"}
{"id": "58892829", "url": "https://en.wikipedia.org/wiki?curid=58892829", "title": "Catherine Hollingworth", "text": "Catherine Hollingworth\n\nCatherine Hollingworth, (February 1904– 25 July 1999) was a Scottish speech therapist and a pioneer of Child drama. \n\nHollingworth started her teaching career in speech training at St Margaret's School in Aberdeen in 1927 and then taught in her home town of Forfar before moving to London, where she spent time observing the work done by surgeons who were using speech therapy on their patients after throat operations. She set up her own practice as a result of these experiences. The evacuation of civilians during World War II prompted Hollingworth to return to Aberdeen in 1941, where she was appointed as speech specialist for the education department. The following year she founded The Children's Theatre, which went on to develop an international reputation.\n\nHollingworth was elected a Fellow of the Royal College of Speech and Language Therapists in 1959. \n\nShe was awarded an OBE in the 1965 Birthday Honours whilst serving as the Superintendent of Speech Therapy and Speech Training for Aberdeen.\n\nHollingworth is named in a commemorative plaque outside of the Aberdeen Municipal Children's Theatre. It reads: \"CATHERINE HOLLINGWORTH 1904-1999. Child drama pioneer, speech therapist and founder of Aberdeen Municipal Children's Theatre which she directed in this building 1956-1968.\"\n\n"}
{"id": "19947750", "url": "https://en.wikipedia.org/wiki?curid=19947750", "title": "Chernobyl Forum", "text": "Chernobyl Forum\n\nThe Chernobyl Forum is the name of a group of UN agencies, founded on 3–5 February 2003 at the IAEA (International Atomic Energy Agency) Headquarters in Vienna, to scientifically assess the health effects and environmental consequences of the Chernobyl accident and to issue factual, authoritative reports on its environmental and health effects.\n\nEight UN organizations are involved in the Chernobyl Forum:\n\n\nThe Chernobyl Forum also comprises the governments of Belarus, Russia and Ukraine.\n\nThe Chernobyl Forum released on 5 September 2005 a comprehensive scientific assessment report on the consequences of the Chernobyl accident titled: \"Chernobyl’s Legacy: Health, Environmental and Socio-Economic Impacts\". A revised edition was released in March 2006 and is available here, together with the Forum's report \"Recommendations to the Governments of Belarus, the Russian Federation and Ukraine\".\n\nThe report covers environmental radiation, human health and socio-economic aspects. About 100 recognized experts from many countries, including Belarus, Russia and Ukraine, have contributed. The report claims to be \"the most comprehensive evaluation of the accident’s consequences to date\" and to represents \"a consensus view of the eight organizations of the UN family according to their competences and of the three affected countries\".\n\nOn the death toll of the accident, the report states that 28 emergency workers died from acute radiation syndrome and 15 patients died from thyroid cancer. It roughly estimates that cancers deaths caused by the Chernobyl accident might eventually reach a total of up to 4,000 among the 600,000 cleanup workers or \"liquidators\" who received the greatest exposures. \n\nOne paper estimates an additional 5,000 deaths from the Chernobyl accident among the exposed population of around 6 million living in the contaminated areas of Ukraine, Belarus and Russia However, the paper notes that no significant increased cancer risk apart from thyroid cancer has been scientifically demonstrated to date; this prediction is only an indication of the \"possible\" impact of the accident, and should not be taken at face value.\n\nThe report quotes 4,000 cases of thyroid cancer resulting from the accident, mainly in children and adolescents at the time of the accident; however the survival rate is almost 99%. Since most emergency workers and people living in contaminated areas received relatively low radiation doses, comparable to natural background levels, no decrease in fertility or increase in congenital malformations have been observed.\n\nThe report indicates that many people were traumatised by the accident and the rapid relocation that followed; they remain anxious about their health, perceiving themselves as helpless victims rather than survivors, mainly because of the lack of credible information about the effects of the accident. The Chernobyl Forum recommends that relocated people be helped to normalise their lives and better access social services and employment. \n\nThe report also concluded that a greater risk than the long-term effects of radiation exposure, is the risk to mental health caused by exaggerated fears about the effects of radiation:\n\" ... The designation of the affected population as “victims” rather than “survivors” has led them to perceive themselves as helpless, weak and lacking control over their future. This, in turn, has led either to over cautious behavior and exaggerated health concerns, or to reckless conduct, such as consumption of mushrooms, berries and game from areas still designated as highly contaminated, overuse of alcohol and tobacco, and unprotected promiscuous sexual activity.\"\n\n\n"}
{"id": "13324564", "url": "https://en.wikipedia.org/wiki?curid=13324564", "title": "Chief Medical Officer (Ireland)", "text": "Chief Medical Officer (Ireland)\n\nThe Chief Medical Officer (CMO) () for Ireland is the most senior government advisor on health related matters. It is a government post as the lead medical expert in the Department of Health.\n\nThe key responsibilities of the CMO include providing expert medical evidence, especially in public health matters, as well as leading on patient safety issues, emergency planning and other areas.\n\n\n\n"}
{"id": "156339", "url": "https://en.wikipedia.org/wiki?curid=156339", "title": "Corporate farming", "text": "Corporate farming\n\nCorporate farming is a term used to describe companies that own or influence farms and agricultural practices on a large scale. This includes not only corporate ownership of farms and selling of agricultural products, but also the roles of these companies in influencing agricultural education, research, and public policy through funding initiatives and lobbying efforts.\n\nThe definition and effects of corporate farming on agriculture are widely debated, though most sources that describe large businesses in agriculture as \"corporate farms\" portray their role in a negative light.\n\nThe varied and fluid meanings of \"corporate farming\" have resulted in conflicting definitions of the term, with implications in particular for legal definitions. \n\nMost legal definitions of corporate farming in the United States pertain to tax laws, anti–corporate farming laws, and census data collection. These definitions mostly reference farm income, indicating farms over a certain threshold as corporate farms, as well as ownership of the farm, specifically targeting farms that do not pass ownership through family lines.\n\nIn public discourse, the term \"corporate farming\" lacks a firmly established definition and is variously applied. However, several features of the term's usage frequently arise:\n\n\n\"Family farm\" and \"corporate farm\" are often defined as mutually exclusive terms, with the two having different interests. This mostly stems from the widespread assumption that family farms are small farms while corporate farms are large-scale operations. While it is true that the majority of small farms are family owned, many large farms are also family businesses, including some of the largest farms in the US.\n\nAdditionally, there are large economic and legal incentives for family farmers to incorporate their businesses.\n\nFarming contracts are agreements between a farmer and a buyer that stipulates what the farmer will grow and how much they will grow usually in return for guaranteed purchase of the product or financial support in purchase of inputs (e.g. feed for livestock growers). In most instances of contract farming, the farm is family owned while the buyer is a larger corporation. This makes it difficult to distinguish the contract farmers from \"corporate farms,\" because they are family farms but with significant corporate influence. This subtle distinction left a loop-hole in many state laws that prohibited corporate farming, effectively allowing corporations to farm in these states as long as they contracted with local farm owners.\n\nMany people also choose to include non-farming entities in their definitions of corporate farming. Beyond just the farm contractors mentioned above, these types of companies commonly considered part of the term include Cargill, Monsanto, and DuPont Pioneer among others. These corporations do not have production farms, meaning they do not produce a significant amount of farm products. However, their role in producing and selling agricultural supplies and their purchase and processing of farm products often leads to them being grouped with corporate farms. While this is technically incorrect, it is widely considered substantively accurate because including these companies in the term \"corporate farming\" is necessary to describe their real influence over agriculture.\n\nFamily farms maintain traditions including environmental stewardship and taking longer views than companies seeking profits. Family farmers may have greater knowledge about soil and crop types, terrains, weather and other features specific to particular local areas of land can be passed from parent to child over generations, which would be harder for corporate managers to grasp. \n\nThe 2012 US Census of Agriculture indicates that 5.06 percent of US farms are corporate farms. These include family corporations (4.51 percent) and non-family corporations (0.55 percent). Of the family farm corporations, 98 percent are small corporations, with 10 or fewer stockholders. Of the non-family farm corporations, 90 percent are small corporations, with 10 or fewer stockholders. Non-family corporate farms account for 1.36 percent of US farmland area. Family farms (including family corporate farms) account for 96.7 percent of US farms and 89 percent of US farmland area; a USDA study estimated that family farms accounted for 85 percent of US gross farm income in 2011. Other farmland in the US is accounted for by several other categories, including single proprietorships where the owner is not the farm operator, non-family partnerships, estates, trusts, cooperatives, collectives, institutional, research, experimental and American Indian Reservation farms. \n\nIn the US, the average size of a non-family corporate farm is 1078 acres, i.e. smaller than the average family corporate farm (1249 acres) and smaller than the average partnership farm (1131 acres).\n\nIn Canada, 17.4 percent of farms are owned by family corporations and 2.4 percent by non-family corporations. In Canada (as in some other jurisdictions) conversion of a sole proprietorship family farm to a family corporation can have tax planning benefits, and in some cases, the difference in combined provincial and federal taxation rates is substantial. Also, for farm families with significant off-farm income, incorporating the farm can provide some shelter from high personal income tax rates. Another important consideration can be some protection of the corporate shareholders from liability. Incorporating a family farm can also be useful as a succession tool, among other reasons because it can maintain a family farm as a viable operation where subdivision of the farm into smaller operations among heirs might result in farm sizes too small to be viable.\n\nFamily farms across Europe are heavily protected by EU regulations, which have been driven in particular by French farmers and the French custom splitting land inheritance between children to produce many very small family farms. In regions such as East Anglia, UK, some agribusiness is practiced through company ownership, but most large UK land estates are still owned by wealthy families such as traditional aristocrats, as encouraged by favourable inheritance tax rules.\n\nMost farming in the Soviet Union and its Eastern Bloc satellite states was collectivized. After the dissolution of those states via the revolutions of 1989 and the dissolution of the Soviet Union, decades of decollectivization and land reform have occurred, with the details varying substantially by country. In Russia, some amount of family farming has developed, but many former collective farms (kolkhozy) and state farms (sovkhozy) retained their collective/joint nature and instead became corporate farms with stock ownership, the farmers having incorporated.\n\nCorporate farming has begun to take hold in some African countries, where listed companies such as Zambeef, Zambia are operated by MBAs as large businesses. In some cases, this has caused debates about land ownership where shares have been bought by international investors, especially from China.\n\nSome oil-rich middle east countries operate corporate farming including large-scale irrigation of desert lands for cropping, mostly through partially or fully state-owned companies.\n\nTo date, nine US states have enacted laws that restrict or prohibit corporate farming. The first of these laws were enacted in the 1930s by Kansas and North Dakota respectively. In the 1970s, similar laws were passed in Iowa, Minnesota, Missouri, South Dakota and Wisconsin. In 1982, after failure to pass an anti–corporate farming law, the citizens of Nebraska enacted by initiative a similar amendment into their state constitution. The citizens of South Dakota similarly amended their state constitution in 1998.\n\nAll nine laws have similar content. They all restrict corporate ability to own and operate on farmland. They all outline exceptions for specific types of corporations. Generally, family farm corporations are exempted, although certain conditions may have to be fulfilled for such exemption (e.g. one or more of: shareholders within a specified degree of kinship owning a majority of voting stock, no shareholders other than natural persons, limited number of shareholders, at least one family member residing on the farm). However, the laws vary significantly in how they define a corporate farm, and in the specific restrictions. Definitions of a farm can include any and all farm operations, or be dependent on the source of income, as in Iowa, where 60 percent of income must come from farm products. Additionally, these laws can target a corporation's use of the land, meaning that companies can own but not farm the land, or they may outright prohibit corporations from buying and owning farmland. The precise wording of these laws has significant impact on how corporations can participate in agriculture in these states with the ultimate goal of protecting and empowering the family farm.\n"}
{"id": "14894253", "url": "https://en.wikipedia.org/wiki?curid=14894253", "title": "Dental fear", "text": "Dental fear\n\nDental fear, dental anxiety and dental phobia are quite often used inter-changeably. Dental fear is a normal emotional reaction to one or more specific threatening stimuli in the dental situation. However, dental anxiety is indicative of a state of apprehension that something dreadful is going to happen in relation to dental treatment, and it is usually coupled with a sense of losing control. Similarly, dental phobia denotes a severe type of dental anxiety, and is characterised by marked and persistent anxiety in relation to either clearly discernible situations or objects (e.g. drilling, local anaesthetic injections) or to the dental setting in general.\nThe term ‘dental fear and anxiety’ (DFA) is often used to refer to strong negative feelings associated with dental treatment among children, adolescents and adults, whether or not the criteria for a diagnosis of dental phobia are met.\n\nIt is viewed as counterproductive to discuss dental fear with patients because it is believed that this may exacerbate the pre existing fear. Despite this common idea, it has been found that it is actually more beneficial in most cases to discuss dental fear with the patient. The first step in accommodating to patients with dental fear is to:\nSelf- report scales that can be used to measure dental fear and anxiety include:\n\nDental fear is associated with prior sexual abuse.\n\nDental fear was 30% heritable and fear of pain was 34% heritable.\n\nDental fear can be transmitted through social media, reading a comic dental paper, watching a movie involving gruesome dental scenes and listening to a fearful dental story from a friend or a family member. Dental fear can also arise from observation of other people attending for complex dental treatments.\n\nDental fear varies across a continuum, from very mild fear to severe. Therefore, in dental setting, it is also the case where the technique and management that works for one patient might not work for another. Some individuals may require a tailored management and treatment approach.\n\nBy doing so, communication skills create a bond of understanding, trust and confidence between the dental practitioner and the patient. \n\n\nSome common strategies for the patient to help get through the appointment: \n\nDental fear often lead patient to cause unrealistic expectations about dental treatment, especially in children. Cognitive therapy aims to alter and restructure negative beliefs to reduce dental fear by enhancing the control of negative thoughts. “The process involves identifying the misinterpretations and catastrophic thoughts often associated with dental fear, challenging the patient’s evidence for them, and then replacing them with more realistic thoughts.”\n\n\nIndividuals who are highly anxious about undergoing dental treatment comprise approximately one in six of the population. Younger people, female, and those who have experienced prior unpleasant dental experience have higher rates.\n"}
{"id": "24179993", "url": "https://en.wikipedia.org/wiki?curid=24179993", "title": "Electro Physiological Feedback Xrroid", "text": "Electro Physiological Feedback Xrroid\n\nElectro Physiological Feedback Xrroid (EPFX) (), also known as Quantum Xrroid Consciousness Interface (QXCI), is a so-called energy medicine device which claims to read the body’s reactivity to various frequencies and then send back other frequencies to make changes in the body. It is manufactured and marketed by self-styled \"Professor Bill Nelson,\" also known as Desiré Dubounet. Nelson is currently operating in Hungary, a fugitive from the US following indictment on fraud charges connected to EPFX.\n\nDescriptions of the device in mainstream media note its high price tag ($20,000 US) and the improbable nature of the claims made for it. It has reportedly been used to \"treat\" a variety of serious diseases including cancer. In one documented case, undiagnosed and untreated leukaemia resulted in the death of a patient.\n\nThe website Quackwatch posted an analysis of the device by Stephen Barrett which concludes: \"The Quantum Xrroid device is claimed to balance 'bio-energetic' forces that the scientific community does not recognize as real. It mainly reflects skin resistance (how easily low-voltage electric currents from the device pass through the skin), which is not related to the body's health.\"\n\nImports to the US are now banned.\n\n\n"}
{"id": "14913778", "url": "https://en.wikipedia.org/wiki?curid=14913778", "title": "Emotional support animal", "text": "Emotional support animal\n\nAn emotional support animal (ESA) or support animal, is a companion animal (pet) that a medical professional says provides some benefit for a person disabled by a mental health condition or emotional disorder. Emotional support animals are typically dogs, but are sometimes cats or other animals. \n\nPeople who qualify for emotional support animals have verifiable psychological disabilities that substantially interfere with major life activities, such as anxiety disorder, major depressive disorder, or panic attacks. \n\nAn emotional support animal differs from a service animal. Service animals are trained to perform specific tasks (such as helping a blind person walk), while emotional support animals receive no specific training. (It therefore stands that in the setting of mental illness, whether or not the animal is a \"service animal\" vs. an Emotional Support Animal would hinge on whether the dog is formally trained to do something specific to mitigate the mental illness.) Any animal that provides support, well-being, comfort, or aid, to an individual through companionship, non-judgmental positive regard, and affection may be regarded as an emotional support animal.\n\nIn the US, disabled people with emotional support animals are exempted from certain rules against having animals in most housing and travel situations. To be afforded protection under United States federal law, the owners of emotional support animals must meet the federal definition of disability and must have a letter from their healthcare providers stating that they are being treated for a disabling condition and that their emotional support animals improve or benefit some component of the disability.\n\nSmall dogs are the most common type of emotional support animal.\n\nIn terms of obtaining exemptions from housing and transportation laws, emotional support animals must be a \"usual\" type, which excludes snakes and other reptiles, ferrets, rodents, and spiders. \n\nIn 2018, Delta Airlines banned pit bulls and similar breeds of dogs from being accepted as emotional support animals, after a pit bull dog traveling as an emotional support animal bit two employees. Emotional support animals are allowed to travel on airplanes without muzzles or other devices that would keep them from biting staff or passengers.\n\nAnother animal people get for emotional support are cats. Cats can understand when their owner has depression, anxiety, and more. It all depends on the owner if they want to have a special relationship with their cat. If they do they will get the emotional support that the person needs. Being attached to an animal can help relieve loneliness and can help a person's well being.  \n\nThere are no requirements for training emotional support animals. Emotional support animals typically have no training beyond what would be expected for the same type of pet. Emotional support animals perform no tasks other than what a pet of the same type would do – including unwanted behaviors, such as defecating in inappropriate places, growling and barking at people, or biting them. \n\nBoth poorly trained emotional support animals and poorly trained pets that are being fraudulently passed off as emotional support animals represent a threat to the health, safety, and function of both people and trained service animals.\n\nTo qualify for an emotional support animal in the US, the owners of emotional support animals must have an emotional or mental disability that is certified by a mental health professional such as a psychiatrist, psychologist, or other licensed mental health care provider. These are often invisible disabilities, because they are normally not visible.\n\nThe owner's mental health impairment must be substantial enough to produce disability, rather than discomfort or a desire to have a pet. Furthermore, for the provider to certify the animal, non-fraudulently, the emotional support animal's presence must provide a significant benefit, that makes the difference between the person functioning adequately and not.\n\nSome websites scam people by printing fake certificates that claim an animal is an emotional support animal, but which have no legal value. These website have encouraged even people who are not disabled to pay a fee to buy an official-looking piece of paper, so that they can get approval to have a family pet in no-pets housing, or to get free air travel for their pet on US airlines. \n\nSince a 2003 rule change by the US Department of Transportation, the normal documentation is a letter from psychologist or other mental healthcare professional who is currently providing treatment to the passenger. Airlines are not obligated to accept certificates or letters ordered off of websites.\n\nThe ability to avoid extra costs, such as paying damage deposits for pets in a rental apartment or extra baggage fees for taking an animal on an airplane, has incentivized what one journalist described as \"mass cheating\". Especially since a woman tried to board a flight with her peacock, named Dexter, in January 2018, airlines have substantially tightened their requirements. \n\nIn some US states, providing a letter, registry, or certificate to a person who is not disabled is a crime.\n\nIn the U.S., legal protection against housing discrimination is afforded to mentally disabled persons under two federal statutes: Section 504 of the Rehabilitation Act of 1973 and the Federal Fair Housing Amendments Act (FHAA) of 1988. These statutes, and the corresponding case law, create the general rule that a landlord cannot discriminate against disabled persons in housing, and if a reasonable accommodation will enable a disabled person to equally enjoy and use the rental unit, the landlord must provide the accommodation. Persons with disabilities may request a reasonable accommodation, such as a waiver of a \"no pets policy\", for any assistance animal, including an emotional support animal, under both the FHAA and Section 504.\n\nSection 504 of the Rehabilitation Act was enacted in 1973 and made broad and sweeping statements that discrimination against the disabled in any program receiving federal financial assistance was illegal. However, it was not until 1988 when the U.S. Department of Housing and Urban Development (HUD) created regulations under the statute. Section 504 states:\n\nIn the context of housing discrimination, this statute creates the rule that public housing authorities cannot deny housing to a disabled person solely because of his or her disability, and that if a reasonable accommodation can be made to make housing available to a disabled person, the landlord is required to make the accommodation. Even though the statute does not expressly use the phrase \"reasonable accommodation\", it has been read into the statute by case law and HUD regulations interpreting the statute.\n\nTo establish that a \"no pets\" waiver for an emotional support animal is a reasonable accommodation under Section 504, the tenant must: have a disability, be \"otherwise qualified\" to receive the benefit, be denied the benefit solely because of the disability, and the housing authority must receive federal financial assistance. Courts have held that \"otherwise qualified\" means that the tenant must be able to meet the requirements of the program in spite of the handicap. Also, the tenant must be able to meet the general rules of tenancy, such as cleaning up after the animal and walking the animal in designated areas.\n\nThe Majors and Whittier Terrace courts established the foundational principles that a tenant can be \"otherwise qualified\" under Section 504 despite an inability to comply with a \"no pets\" policy, and that a waiver of a \"no pets\" policy can be a reasonable accommodation under Section 504. However, several courts have consistently held that a tenant requesting an emotional support animal as a reasonable accommodation must demonstrate a relationship between his or her ability to function and the companionship of the animal. This required nexus between the disability and the emotional support animal has been refined by several courts. For instance, in \"Janush v. Charities Housing Development Corp\" (N.D. Ca., 2000), the U.S. Northern District Court of California held the reasonable accommodation is a fact-based, and not species-based, issue. In \"Nason v. Stone Hill Realty Association\" (1996), a Massachusetts trial court recognized that there were more reasonable accommodations to lessen the effects of a person's disability, other than keeping an emotional support animal, and therefore denied the tenant's motion for preliminary injunction. Courts have held the emotional distress expected to occur if a person is forced to give up his or her emotional support animal will not support a reasonable accommodation claim.\n\nSince a violation of Section 504 requires the housing authority to receive federal funding, this act did not cover private housing providers. This legislative gap existed until 1988 when Congress passed the Fair Housing Act Amendments.\n\nWhereas only housing authorities receiving federal financial assistance are subject to Section 504, both public and private housing authorities are subject to the provisions of the Fair Housing Act. Enacted as part of the Civil Rights Act of 1968 legislation, the Fair Housing Act (FHA) focused on housing discrimination on the basis of race, color, national origin, or gender; in 1988, however, the Federal Fair Housing Act Amendments (FHAA) expanded this scope to include handicapped persons. The FHAA states that it is unlawful \"to discriminate in the sale or rental...of a dwelling to any buyer or renter because of a handicap of that buyer or renter, a person residing in or intending to reside in that dwelling after it is so sold, rented, or made available, or any person associated with that buyer or renter.\" Further, it is discrimination for any person to: \"refuse to make reasonable accommodations in rules, policies, practices, or services, when such accommodations may be necessary to afford a handicapped person equal opportunity to use and enjoy a dwelling unit, including public and common use areas.\" Thus, like Section 504, the FHAA requires landlords to make reasonable accommodations for tenants. Additionally, the FHAA, in section 3602 (h), defines handicap, with respect to a person, as: (1) a physical or mental impairment which substantially limits one or more of such person's major life activities; (2) a record of having such an impairment; or (3) being regarded as having such an impairment. The term \"major life activities\" has been interpreted broadly to include those \"activities that are of central importance to daily life,\" such as \"seeing, hearing, walking, breathing, performing manual tasks, caring for one's self, learning, speaking, and reproducing.\" The United States Department of Housing and Urban Development (HUD) is responsible for administering the FHAA; the Attorney General or private persons have authority to enforce it.\n\nTo establish a \"prima facie\" case of housing discrimination under the FHAA: the tenant must have a qualifying disability, the landlord knew of the handicap or should reasonably be expected to know of it, accommodation of the handicap may be necessary to afford the tenant an equal opportunity to use and enjoy the dwelling, and the landlord must deny the request, such as refusing to waive the \"no pets\" policy.\n\nThe second element, that the landlord knew of the handicap or should have known of it, places an affirmative burden on the tenant to request the reasonable accommodation, such as a waiver of a \"no pets\" policy for an emotional support animal. A tenant wishing to obtain a waiver of a \"no pets\" policy for an emotional support animal may meet this burden by providing a letter from his or her physician or mental health professional: stating that the tenant has a mental disability, explaining that the animal is needed to lessen the effects of the disability, and requesting that the animal be allowed in the rental unit as a reasonable accommodation for the mental disability. Landlords are entitled to ask for supporting materials which document the need for an\nemotional support animal. Mere emotional distress that would result from having to give up an animal because of a \"no pets\" policy will not qualify under federal law. Instead, there must be a link, or a nexus, between the animal and the disability. The nexus between the animal and the disability is analyzed under the third element of an FHAA housing discrimination case, known as the necessity requirement, and requires that the accommodation will affirmatively enhance a disabled tenant's quality of life by ameliorating the effects of the disability. So long as the requested accommodation does not constitute an undue financial or administrative burden for the landlord, or fundamentally alter the nature of the housing, the landlord must provide the accommodation.\n\nAlthough The Fair Housing Act covers both multi- and single-family detached home, the sale or rental of a single family dwelling by an owner is exempt from the statute. There are two exceptions to this exemption, however. One is that the exception will not apply if the private individual owner owns more than three single-family homes. The other exception to this exemption is the use of a real estate agent or a broker to rent out the home.\n\nA tenant may be awarded actual and punitive damages, injunctions, and attorney fees at the discretion of the court for a landlord's violation of the FHAA.\n\nThe Americans with Disabilities Act of 1990 (ADA) allows people with disabilities to bring their service animals in public places. However, the ADA only extends these protections to dogs that have been \"individually trained\" to \"perform tasks for the benefit of an individual with a disability,\" which is the definition of service animals under 28 C.F.R. § 36.104. Since emotional support animals are typically not trained for an individual's specific disability and since emotional support animals might not be dogs, they do not receive the protections of the ADA. A public place can therefore deny an emotional support animal admission.\n\nIn situations where the ADA and the FHAA/Section 504 apply simultaneously (e.g., a public housing agency, sales or leasing offices, or housing associated with a university or other place of education), housing providers must meet their obligations under both the reasonable accommodation standard of the FHAct/Section 504 and the service animal provisions of the ADA.\n\nThe lack of training for emotional support animals has also led to controversy in the courts. Specifically, there is controversy over whether the ADA definition of service animal, with its requirement of training, applies to reasonable accommodation claims for animals under the FHAA. However, HUD administrative judges have ruled in favor of emotional support animals, despite their lack of training, as being reasonable accommodations. Additionally, several courts have also ruled that untrained assistance animals are reasonable accommodations under the FHAA. Yet, there are cases that have held an assistance animal, in order to be considered a reasonable accommodation under the FHAA, must be trained.\n\nMany landlords have \"no pets\" policies for their rental properties, and many landlords that allow pets impose restrictions on the type and size of pets that tenants are allowed to bring into the rental property. Many landlords are reluctant to waive their pet policies and restrictions, even when requested by a tenant who is requesting accommodation of a mental or emotional disability.\n\nLandlords may be concerned that waiving a \"no pet\" policy for one tenant will inspire many others to claim mental illnesses and the need for emotional support animals. Landlords may believe that as more tenants have animals on the property, odors and noises from the animals may deter other tenants from renting and thus lower the value of the rental property. Landlords may also believe that making exceptions to a \"no pets\" policy for a tenant's emotional support animal may confuse other tenants who do not understand why one person was allowed an animal while they were not. However, if a tenant documents the need for an emotional support animal under the Fair Housing act or state law, and the landlord is not exempt from those laws, the landlord must allow the tenant to possess an emotional support animal.\n\nThe U.S. Department of Housing and Urban Development and Department of Justice have held that \"providers may not require persons with disabilities to pay extra fees or deposits as a condition of receiving a reasonable accommodation.\" In 1990, a HUD administrative judge enjoined owners of an apartment complex from charging a disabled person a pet deposit fee. The judge held that an auxiliary aid, like a service, guide, or signal dog, may be necessary to afford the individual an equal opportunity to use and enjoy the dwelling unit, including public and common areas. Accordingly, when a tenant qualifies for a service animal or emotional support animal, a landlord may not charge the tenant additional fees in association with the presence of the animal in the rental property. This prohibition extends to pet deposits and fees, even when those fees are charged to other tenants who have pets.\n\nA landlord may charge a tenant for damage cause to a rental property by the tenant's emotional support animal, and may deduct the cost of repairs from the tenant's security deposit, but may not increase the security deposit based upon the tenant's possession of an emotional support animal.\n\nExceptions may apply to a landlord's obligation to allow a tenant to possess an emotional support animal. For example, owner-occupied buildings with four or fewer rental units are exempt from the federal Fair Housing Act. The Fair Housing Act also exempts private owners of single-family housing sold or rented without the use of a broker, as long as the owner does not own more than three single family homes, as well as housing operated by organizations and private clubs that restrict occupancy to members. Exemptions under state law may be more restrictive than federal exemptions.\n\nEven when the Fair Housing Act applies, circumstances may arise under which a landlord may restrict a tenant from possessing an emotional support animal.\n\nIf the requested accommodation (i.e., the waiver of a \"no pets\" policy for an emotional support animal) constitutes an undue financial or administrative burden for the landlord, or fundamentally alters the nature of the housing, the landlord may not have to provide the reasonable accommodation. However, as the burden of allowing emotional support animals is generally modest, most landlords have been unsuccessful in arguing a denial of a waiver of a \"no pets\" policy on the basis of a claimed extreme burden.\n\nOn April 25, 2013, the U.S. Department of Housing and Urban Development sent notice to its regional offices that public universities are required to comply with the Fair Housing Act, which includes allowing emotional support animals into college dormitories and residence halls. , colleges in the United States such as St. Mary's College of Maryland were trying to accommodate students with a documented need for emotional support animals.\n\n\"Bona fide\" emotional support animals are also allowed to travel at no additional charge on US airlines, with their disabled owners.\n\nThe Air Carrier Access Act established a procedure for modifying pet policies on aircraft to permit a person with a disability to travel with a prescribed emotional support animal, so long as they have appropriate documentation and the animal is not a danger to others and does not interfere with others (through unwanted attention, barking, inappropriate toileting, etc.). \"Unusual\" animals, including all snakes and other reptiles, can legally be refused.\n\nIn regards to airline policies affecting persons flying with animals, most airlines charge fees and require the animal to be in a cage that can fit under the seat; if a caged animal cannot be placed under the seat, the animal flies with the luggage. With emotional assistance animals, on the other hand, they are not required to be caged, nor are people charged for flying with an emotional support animal. In 2017, a quarter million passengers brought emotional support animals with them on just Delta Air Lines.\n\nWith the exceptions provided to emotional support animals, many people who do not have a mental disability have tried to bring their animals on a plane and pass them off as emotional support animals. Airlines, like Southwest and JetBlue, however, typically have policies that passengers flying with emotional support animals must follow. While an airline is allowed to require a passenger traveling with an emotional support animal to provide written documentation that the animal is an emotional support animal, the same is not true for a service animal.\n\nThe rights of passengers with emotional disabilities to travel with an animal are specifically enshrined in US law; the rights of passengers who are allergic to those emotional support animals do not have specific protections, and often feel that their right to a safe flight is treated as less important. The Federal Aviation Administration's advice to airlines prioritizes passengers with service animals, but not household pets, over passengers with allergies to those animals. (It does not mention whether emotional support animals should be treated like trained service animals or like household pets in such an instance.) Passengers who are allergic to dogs, cats, or other animals are usually seated in a different part of the airplane, and may be denied boarding, removed from flights, moved to other flights, or required to provide a letter from a licensed physician, dated with the last 10 days, saying that even if they are exposed to animal dander, they will not die before the flight ends.\n\nThe required documentation for US-based airlines is a letter, printed on a healthcare provider's letterhead that meets all of the following requirements:\n\n\nWriting letters such as this is considered extratherapeutic administrative paperwork, rather than professional care. The specific requirement to have a letter from a healthcare provider that is providing treatment to the passenger excludes all \"certificates\" or letters from websites that sell unofficial registries without providing professional care to the passenger.\n\nSome airlines, including United and Delta, additionally require passengers traveling with emotional support animals to complete forms provided by the airline, at least 48 hours before departure, that certify that the animal is properly vaccinated, in good health, and has been trained to behave well in public.\n\nWhile there do not seem to be any cases dealing with the issue of multiple emotional support animals, the basic requirements for this accommodation would be the same. Thus, if a disabled person claimed to need multiple emotional support animals, he or she would need documentation supporting this claim from his or her psychologist or other licensed healthcare professional. The practitioner would need to provide documentation that each support animal alleviated some symptom of the disability.\n\nAs of 2018, Delta airlines limits free travel for emotional support animals to one animal per ticketed passenger.\n\nThe main controversies are the behavior of some animals, harms to other people, the problem of widespread fraud, and the open scientific question about whether emotional support animals provide significant benefit.\n\nThere are so many things these days to distract students from doing their work, cell phones, laptops, etc, but what crosses the line where it becoming too distracting? College courses are already hard enough, and having an animal in the room could take the attention from the professor. If the animal is being a distraction how is that fair to other students in the classroom? It is not just that they are distracting, it could be because of different instances such as allergies. \n\nAn emotional support animal may cause problems that a trained assistance dog may not. For instance, due to the lack of training, an emotional support animal may bark at and smell other people, whereas service dogs are trained not to do so. \n\nPeople with a different type of invisible disability – allergy to animal dander – have suffered from allergic attacks triggered by emotional support animals.\n\nAlthough there is general support for individuals being able to have pets, and widespread belief that owning an animal makes pet owners happy, there is concern about people abusing the system by acquiring an emotional support animal even though they are legally not considered disabled. According to one survey, Americans generally believe that a majority of emotional support animals serve a legitimate need, but the more experience the respondents had with service animals and emotional support animals, the more aware they were of abuse. The prevalence of abuse and the rising popularity of emotional support animals has increased the number of animals in public places where animals are normally not allowed. Multiple dangerous incidents reported in the media, such as a large emotional support dog mauling another passenger on a flight, have led to a backlash against people with disabilities, including people with well-trained service dogs. \n\nAlthough the concept is popular and many owners attribute improvements to their animals, there is no solid scientific evidence that untrained emotional support dogs provide any significant benefit to people with mental or emotional disabilities. Interacting with an animal may reduce perceived emotional distress for some people, but the scientific research is limited, of low scientific quality, and what little research exists suggests that the benefit, if any, is smaller than its proponents hoped. A small number of studies have found that emotional support animals increased their owners' distress. There is no research at all on unusual animals, such as hamsters.\n\nRequests for letters to obtain exemption from airline baggage fees or no-pet housing rules can also damage the owner's therapeutic relationship with the psychologist or other mental healthcare provider, regardless of whether the request is approved or denied. Ethically, providers of psychotherapy may choose to recommend an emotional support animal for the people they are treating if it will play a temporary part in a larger treatment plan, but not as a form of permanent palliation of symptoms. For permanent situations, therapists often refer the client to a neutral, independent psychologist, who can determine whether the person is disabled and whether an emotional support animal would be appropriate. This process is not a careless rubber-stamping of the request; the neutral, independent provider should review the client's records, interview the client, consult with the therapist, and do whatever additional testing is necessary to determine the extent of disability and the appropriateness of the recommendation, and, if necessary, be willing and able to defend the diagnosis and decision to prescribe the animal in court.\n\nEmotional support animals are only one type of animal that is used for people with disabilities or similar issues. Other types of animals used by and for people with disabilities include:\n\n\n\n"}
{"id": "24864904", "url": "https://en.wikipedia.org/wiki?curid=24864904", "title": "Fédération Internationale de Medicine Sportive", "text": "Fédération Internationale de Medicine Sportive\n\nInternational Federation of Sports Medicine ( or FIMS) is an international organization comprising national sports medicine associations that span all five continents.\n\nThe aim of FIMS is to assist athletes in achieving optimal performance by maximizing their genetic potential, health, nutrition, and high-quality medical care and training.\n\nThe international sports federations were also founded at the time that the Olympic Games were re-established. The existing sports professionals of the time were being influenced by the organization of the sports and the realization of the importance of promoting the ideas of sports medicine, and at the Winter Olympics held in St Moritz, Switzerland in February 1928, the Association International Medico-Sportive (AIMS) was founded. The main purpose of this Association was to cooperate with the international sports federations and the International Olympic Committee to provide the best medical care for the athletes competing in the Summer and Winter Olympics.\n\nThe 1st AIMS International Congress of Sports Medicine was held during the IXth Summer Olympic Games held in Amsterdam, The Netherlands, in August 1928. At least 280 sports physicians from 20 countries attended the meeting, and they had the opportunity to study many of the athletes taking part in the Games through the collection of anthropometric, cardiovascular, physiological and metabolic data.\n\nAfter several renamings (in 1933: Fédération International Médico-Sportive et Scientifique; in 1934: Fédération International de Médecine Sportive) the name is since 1998: Fédération Internationale de Médecine du Sport (FIMS). As FIMS was born under the umbrella of the Olympic Games, this strong association with the International Olympic Committee (IOC) is reflected in the five Olympic rings in the FIMS flag and logo. FIMS continues to grow as an international community of sports medicine specialists, researching and practicing the latest techniques in medicine for athletes and others who lead active lives.\n\nFIMS supports national and continental scientific meetings, hosts a biennial FIMS Sports Medicine Congress, hosts regular team physician development courses on all continents, and distributes publications on important sports medicine matters on a regular basis.\n\n\nIst Congress : Amsterdam, Netherlands, 1928 <br>\nXXXth Barcelona, 2008 \n\n\n"}
{"id": "17042255", "url": "https://en.wikipedia.org/wiki?curid=17042255", "title": "Henry Foster Adams", "text": "Henry Foster Adams\n\nHenry Foster Adams (1882–1973) was an American psychologist and writer. He published several scientific articles and books on psychology and in particular the psychology of advertising, and advocated the use of empirical and statistical methods to understand people's responses to advertising.\n\nA student of Raymond Dodge and a longtime professor at the University of Michigan, among Adams' works are \"Advertising and its Mental Laws\" (1916) and \"The Ways of the Mind: The Study and Use of Psychology\" (1925).\n\nHe also produced over 30 scientific articles that were published in Journal of Applied Psychology, Journal of Educational Psychology and Psychological Review.\n"}
{"id": "14848060", "url": "https://en.wikipedia.org/wiki?curid=14848060", "title": "History of commercial tobacco in the United States", "text": "History of commercial tobacco in the United States\n\nThe history of commercial tobacco production in the United States dates back to the 17th century when the first commercial crop was planted. The industry originated in the production of tobacco for pipes and snuff. Different war efforts in the world created a shift in demand and production of tobacco in the world and the American colonies. With the onset of the American Revolution trade with the colonies was interrupted which shifted trade to other countries in the world. During this shift there was an increase in demand for tobacco in the United States, where the demand for tobacco in the form of cigars and chewing tobacco increased. Other wars, such as the War of 1812 would introduce the Andalusian cigarette to the rest of Europe. This, accompanied with the American Civil War changed the production of tobacco in America to the manufactured cigarette.\n\nThroughout the 17th century, Europe had a growing demand for tobacco. However, in areas of the American south, where tobacco grew well, capital was needed in order to grow this highly demanding crop. These farmers saw tobacco as merely a temporary crop to get them started until they could plant something else. Their reasoning behind the temporary status given to tobacco had to do with low prices. During the 17th century in Virginia, tobacco was selling for pennies per pound. Solutions to this problem came with slavery. Slavery had already existed in the colonies, but a new influx would greatly expand tobacco production.\n\nThe need for slaves was a response to low birth rates of the European settlers in America. Slavery would help keep costs down and profits higher. Slavery would mark a change from small tobacco farms, to larger farms, which necessitated large labour forces provided by the slaves. These large tobacco farms, accounted for a small part of the overall production of agriculture in the colonies leading into the later part of the 17th century, as tobacco had already begun to fail in less fertile regions of the country. This failure was due to lack of crop rotation, which depleted the soil of the nutrients needed by the tobacco plants. Those who created large plantations in the more fertile regions, however, saw great prosperity, even at the low price per pound of tobacco. This prosperity in turn helped to make them richer and able to purchase even more slaves which helped these large farms to continuously expand.\n\nInto the late 17th century, however, farmers in the Caribbean islands had the same ideas of creating large farms with the use of slaves. Most slaves were not treated as animals, though, for the farmer it would have cost them more money than needed to replace a slave than to keep the ones already owned alive. In comparison, however, even in the Caribbean, the slaves working on tobacco were treated somewhat more fairly than those on sugar plantations whereas the slaves growing tobacco on the islands had often come from regions in Africa that grew tobacco and as such had an appreciated knowledge for the planting and harvesting of tobacco. However, this is not to say they were treated equally.\n\nSlavery was an important part of the process of growing tobacco, especially in the American colonies. The use of slaves kept the cost down in general. But with successive generations of slaves born to past generations, slave masters gained new employees at little or no cost. This fact is proven by a trend toward low immigration of African slaves, while there was still an increase in African population in the colonies. However, issues still ensued with taxation by Britain. In the mid-1770s taxes blossomed to 300,000 pounds sterling per year for exportation of tobacco alone.\n\nIn 1735, John Cockburn published an excerpt on the use of \"ceegars\" (cigars) in Spanish colonies. This publication helped support the sale of tobacco goods. Although for a time in Britain and other European countries like Germany, \"smoking\" tobacco was frowned upon, it would find its favor eventually amongst society who, up to this time, took tobacco mainly as \"snuff.\" Although tobacco began to find favor amongst certain societies, the American Revolution would become a temporary setback for some, and a permanent one for others.\n\nThe American Revolution would have profound effects upon the social and economic stability of the colonies. With a temporary lapse in tobacco exports to Europe, even more small farmers found themselves switching over to crops other than tobacco. In South Carolina, there was a shift toward rice plantations; while in other areas other sorts of much needed vegetation was grown for sustenance of the nation. Another issue that arose with the blockade of tobacco from the American colonies was a shift toward British use of Turkish and Egyptian tobacco. As part of the British disdain for American independence, the British seized and destroyed over 10,000 hogsheads of tobacco in 1780–1781. Led by generals Phillips, Arnold and Cornwallis, this attack on the American tobacco industry is sometimes entitled the \"Tobacco War\" by historians.\nMany other countries were blockaded from trading with the American colonies during the American Revolution and, as such, turned to other resources for their tobacco. Many of these other countries never resumed trade with the newly formed United States so this portion of trade was permanently lost. What did grow, however, was the consumption of tobacco in the United States and a new desire for tobacco grew in Germany and Russia post Revolution. American tobacco customs began to switch from the earlier pipe smoke to the cigar as mentioned earlier, as well as the great American western icon of the spittoon, which was linked to chewing tobacco. These latter two were considered a more coarse form of taking tobacco and, as such, were deemed very \"American\" in nature by Europeans as spitting was a trait attributed to their usage. Americans also enjoyed the flavor of island tobacco more, but since many smokers in the USA were not wealthy, working farmers took to smoking tobacco grown from their own land. This may also have come more from the American desire to be independent, not only in a legal sense by being a free-nation, but economically as well.\n\nThe lower class French men that served in the French military gained a liking for tobacco during the War of 1812. Having occupied Andalusia (Spain) they even got to see what would become the future of the American tobacco industry. Known in Andalusia as \"tabaco picado,\" (minced tobacco), this style of tobacco was relegated to the poor class in the conquered region, so the French did not take up to smoking it in mass at this time. Eventually it would prove popular even in France. The rural poor smoked the minced tobacco, wrapped in maize husks, but the upper class of Andalusia urban areas would wrap the tobacco in paper. The paper-wrapping trend was short-lived at the time however, because the Spanish government outlawed \"white tobacco\" in 1801 as some were smuggling tobacco illegally, labeling the contents as different substances that did not require taxation.\n\nBy the end of the 18th century, a renewed interest in tobacco took hold. In turn, this meant more demand for tobacco from America again, and this meant a boom in increased slavery in the southern United States where tobacco was grown. Post American Revolution, tobacco skyrocketed in price. Wartime had a huge influence over the price of tobacco because, just prior to the Revolution, there was a small peak in price during the Seven Years' War when different cultures gained a desire for tobacco after fighting opponents who had been smoking it.\n\nThe demand had increased so much after 1776, that many farmers were unable to meet the demands for exports, which increased the prices of tobacco even further. With a desire to increase the amount of tobacco available, many American farmers took out credit loans from the British to increase the size of their landholdings as well as increase the number of slaves they owned. Much of this credit went to gentleman farmers, but the desire for tobacco was so strong that even middle class farmers found it easy to receive loans to increase their farm production. Many of these farmers opted not to pay back these loans however, and many in turn found themselves jailed toward the end of the century for not paying their debts. Many of these debtors were small farmers, causing a further consolidation of smaller farms into larger ones.\n\nA significant change began in the establishment of Victorian society in Europe. In an attempt to civilize anything that seemed coarse or uncivil, much of Victorian society would adapt cultural items to suit their tastes. Ironically the British adopted the paper wrapped minced tobacco. Such an item, originally relegated to the poor in Spain, seemed at face value a contradiction; however, one must consider the need for human manipulation of tobacco, including, chopping it up, wrapping it in a man-made piece of paper, and then inserting it into a piece of cane for a mouth piece. One can then see that this was just another way of civilizing part of the coarser aspects of the British Empire. A feministic culture dominated smoking at this time as well as lots of tobacco, and this gave further rise to this \"dainty\" cigarette, bearing a feminine name.\nAn African slave named Stephan changed the process of curing the Bright Leaf tobacco variety (a lighter flavored tobacco leaf) by curing it with charcoal taken from a local blacksmith's fire rather than the usual logwood. This fire burned hotter and faster and accelerated the curing process. The process was refined further to include a furnace in which heat from the charcoal was applied through flues, so that dark soot and off flavors did not come in contact with the tobacco. This changed the curing process of a lighter leaf and produced a new, lighter tobacco which was able to be inhaled. This, linked together with the British Victorian desire for cigarettes, along with the aforementioned French and other European countries, gave way to an emerging market to minced tobacco. This trend had not yet hit America for its export market.\n\nThe American Civil War and the Emancipation Proclamation freed the entire slave workforce of the American South. Although some slaves stayed on for pay with their prior slave owners, many left entirely to make their own lives in other parts of the country. Tobacco farmers needed to adapt. Not only had they lost their workforce, but also a shift in demand had occurred. In Europe, there was a desire for not only snuff, pipes and cigars, but cigarettes appeared as well. Cigar rolling and even the creation of pipe tobacco at the time was labor-intensive and, without slave labor, innovation needed to occur.\nThose farmers that did not go out of business consolidated their holdings with land from other farmers, who now had no workforce. The answer to the labor problem came from the cigarette. The quality of the tobacco, although still considered, did not have to be perfect as it would be minced to be wrapped into paper. The next step to limiting labor was the process of creating the cigarette. During the 1870s a machine was invented by Albert Pease of Dayton, Ohio, which chopped up the tobacco for cigarettes. Up until the 1880s, cigarettes were still made by hand and were high in price. In 1881, James Bonsack, an avid craftsman, created a machine that revolutionized cigarette production. The machine chopped the tobacco, then dropped a certain amount of the tobacco into a long tube of paper, which the machine would then roll and push out the end where it would be sliced by the machine into individual cigarettes. This machine operated at thirteen times the speed of a human cigarette roller.\n\nThe tobacco industry began advertising the now inexpensive cigarettes to Europe and United States citizens. Many other forms of tobacco quickly dropped from production in the United States in favor of this easy to produce, easy to inhale tobacco product. Sales of cigarettes grew astronomically. In one example, American Tobacco Co., listed on the American Stock Exchange, with sales of $25,000,000 in 1890, increased its sales to $316,000,000 in 1903. After the Civil War debts were paid off, taxes were almost completely removed from cigarettes. It was at this point, that the cigarette became an integral part of American culture, which lasted until scientific discoveries revealed the health consequences of smoking.\n\n\n"}
{"id": "27669729", "url": "https://en.wikipedia.org/wiki?curid=27669729", "title": "History of water filters", "text": "History of water filters\n\nThe history of water filters can be traced to the earliest civilisations with written records. Water filters have been used throughout history to improve the safety and aesthetics of water intended to be used for drinking or bathing. In modern times, they are also widely used in industry and commerce. The history of water filtration is closely linked with the broader history of improvements in public health.\n\nAncient Sanskrit and Egyptian writings document practices that were followed to keep water pure for drinking. The \"Sushruta Samhita\" (3rd or 4th century CE) specified various methods, including: boiling and heating under the sun. The text also recommends filtering water through sand and coarse gravel. Images in Egyptian tombs, dating from the 15th to 13th century BCE depict the use of various water treatment devices.\n\nHippocrates conducted his own experiments in water purification. His theory of the four humors of the body led him to believe that the maintenance of good health required that the four humors be kept in balance. He recommended that feverish patients immerse themselves in a bath of cool water, which would help realign the temperature and harmony of the four humors. Hippocrates believed that water had to be clean and pure and he designed a crude water filter to “purify” the water he used for his patients. Later known as the “Hippocratic sleeve,” this filter was a cloth bag through which water could be poured after being boiled.\n\nVarious methods for masking bad water were used: Diophanes of Nicaea of the first century BC advised putting macerated laurel into rainwater, Paxamus proposed that bruised coral or pounded barley, in a bag, be immersed in bad tasting water. and the eighth century Arabian alchemist, Gerber, described various stills for purifying water that used wick siphons — to transfer water from one vessel to another.\n\nSir Francis Bacon in his famous compilation \"A Natural History of Ten Centuries\" 1627 (Baker & Taras, 1981) discussed desalination and began the first scientific experimentation into water filtration. He believed that if seawater was allowed to percolate through the sand, it would be purified of salt. He thought that sand particles would obstruct the passage of salt in the water. Although his hypothesis was proven incorrect, it marked the beginning of a new interest in the field.\n\nAn experiment of sand filtration was illustrated by the Italian physician Lucas Antonius Portius. He wrote about the multiple sand filtration method in his work \"Soldier's Vade Mecum\". He illustrated water filtration experiment by using three pairs of sand filters.\n\nFathers of microscopy, Antonie van Leeuwenhoek and Robert Hooke, used the newly invented microscope to observe for the first time small material particles that lay suspended in the water, laying the groundwork for the future understanding of waterborne pathogens.\n\nThe first documented use of sand filters to purify the water supply dates to 1804, when the owner of a bleachery in Paisley, Scotland, John Gibb, installed an experimental filter, selling his unwanted surplus to the public. This method was refined in the following two decades by engineers working for private water companies, and it culminated in the first treated public water supply in the world, installed by engineer James Simpson for the Chelsea Waterworks Company in London in 1829. This installation provided filtered water for every resident of the area, and the network design was widely copied throughout the United Kingdom in the ensuing decades.\n\nThe practice of water treatment soon became mainstream, and the virtues of the system were made starkly apparent after the investigations of the physician John Snow during the 1854 Broad Street cholera outbreak. Snow was sceptical of the then-dominant miasma theory that stated that diseases were caused by noxious \"bad airs\". Although the germ theory of disease had not yet been developed, Snow's observations led him to discount the prevailing theory. His 1855 essay \"On the Mode of Communication of Cholera\" conclusively demonstrated the role of the water supply in spreading the cholera epidemic in Soho, with the use of a dot distribution map and statistical proof to illustrate the connection between the quality of the water source and cholera cases. His data convinced the local council to disable the water pump, which promptly ended the outbreak.\n\nThe Metropolis Water Act introduced the regulation of the water supply companies in London, including minimum standards of water quality for the first time. The Act \"made provision for securing the supply to the Metropolis of pure and wholesome water\", and required that all water be \"effectually filtered\" from 31 December 1855. This was followed up with legislation for the mandatory inspection of water quality, including comprehensive chemical analyses, in 1858. This legislation set a worldwide precedent for similar state public health interventions across Europe. The Metropolitan Commission of Sewers was formed at the same time, water filtration was adopted throughout the country, and new water intakes on the Thames were established above Teddington Lock. Automatic pressure filters, where the water is forced under pressure through the filtration system, were innovated in 1899 in England.\n\nLimited drinking water standards were first implemented in the US in 1914, but it would not be until the 1940s that federal drinking water standards were widely applied. In 1972, the Clean Water Act passed through Congress and became law, requiring industrial plants to proactively improve their waste procedures in order to limit the effect of contaminants on freshwater sources. In 1974, the Safe Drinking Water Act was adopted by all 50 U.S. states for the regulation of public water systems within their jurisdictions.\n\nBy the early 1900s, water treatment experimentation had turned from the prevention of waterborne diseases to the creation of softer, less-mineralized water. Water softeners, which use sodium ions to replace water-hardening minerals in water, were first introduced into the water treatment market in 1903.\n\nThe theory of ion exchange involves replacing undesirable or potentially harmful ions with more desirable or harmless ones. This is implemented in domestic water treatment system as water softeners. These not only remove calcium ions, but also lead and other heavy metals from water.\n\n"}
{"id": "5248893", "url": "https://en.wikipedia.org/wiki?curid=5248893", "title": "International Society of Blood Transfusion", "text": "International Society of Blood Transfusion\n\nThe International Society of Blood Transfusion (ISBT) is a scientific society, founded in 1935, which aims to promote the study of blood transfusion, and to spread the know-how about the manner in which blood transfusion medicine and science best can serve the patient's interests. The society's central office is in Amsterdam, and there are around 1700 members in 97 countries. Currently, the President is Martin L. Olsson.\n\nThe Society organizes an international congress every other even year and two regional congresses in odd years, one in Europe and one in Asia. ISBT advocates standardisation and harmonisation in the field of blood transfusion. The other major impact on the transfusion community is the classification of various Human blood group systems under a common nomenclature. ISBT's coordination also extends to obtaining donors with rare antigens, a process that often involves international searches, and a common terminology is critical to that process.\n\nThe history of ISBT was described by Dr. Hans Erik Heier in 2015. He distinguished four phases in the formation of the society as we know it today.\n\nThe formation of the International Society of Blood Transfusion, or Societé International de Transfusion Sanguine, as it was called at the time, was initiated in Rome at a meeting between representatives from 20 nations, the International Red Cross and the Bogdanov institute in Moscow. Blood transfusion was a rather new therapeutic option, and therefore it was decided that transfusion-specific congresses should be organised, to highlight the potential importance of transfusion. To organize these congresses, a society was needed.\n\nAfter it was decided that a society dedicated to organizing transfusion-related congresses should be created, it did not take long until ISBT was founded. In 1937 in Paris a Central Office (CO) was set up, led by newly appointed Secretary General Arnault Tzanck. Only two years later the CO activities had to be suspended in 1939 because of the Second World War (WW2).\n\nIn the period surrounding WW2 immunohaematology and transfusion technology had developed almost explosively. Blood banks were created, voluntary blood donations came in great numbers in the allied nations to support the fight for a free society, plasma-transfusion became a standard anti-shock treatment, Rh and Kell systems were discovered, and industrial blood plasma fractionation was developed to produce albumin, which can be used as a substitute for plasma. In 1947 the first post-war congress was organised in Turin, Italy. Here some specific future goals were laid out to complement the main activity of the Society, the organization of congresses.\n- Non-commercialisation of blood and –derivatives\n- Oversee and initiate standardization of equipment, reagents and nomenclature.\n- Stimulate the set-up of central transfusion organisations for every country, under flag of the National Red Cross Society, unless otherwise organised.\n\nThese goals show the strong ambitions of the young, post-war society to not just organise congresses, but be a stimulating factor in the development of modern blood transfusion science and practice, taking into account socio-political and socio-economic aspects. After the congress in Turin and the goals that were set there the society was able to continue its work for 40 years, until 1985, the year of crisis.\n\nIn 1985 the HIV/AIDS epidemic struck transfusion medicine. During that time the ISBT CO was still located in Paris as a part of the Centre National de Transfusion Sanguine (CNTS) as their head, Michel Garretta, was also ISBT Secretary General at the time. In June 1991 he had to step down as head of CNTS, as the HIV/AIDS crisis had become a catastrophe for the transfusion system in France and eventually lead to a reorganisation of CNTS in 1991. Subsequently, at the ISBT Congress in Hong Kong it was decided that ISBT could no longer be linked to CNTS, ruling out Garretta’s succession of a French colleague. Harold Gunson, who was President of ISBT in 1991, agreed to take on a second role as acting Secretary General. Together with CNTS, and ISBT Secretary Claudine Hossenlopp he supervised the move of the CO from Paris to Manchester, UK. In 1994 he resigned from his post as blood centre director in Manchester and moved the ISBT CO to Lancaster, into his own home. He upheld the CO together with his wife until 1999. The end of Gunson’s term meant having to find a new location for the CO, and a new Secretary General.\n\nIn 1999 the new location for the ISBT CO was Amsterdam, where it became a part of professional congress organiser (PCO) Eurocongress. Paul Strengers, a doctor at Sanquin Blood Supply took up the role of Secretary General. A new vision for the 2002-2006 period of ISBT was created by the executive committee, focusing on developing ISBT into an umbrella organization, improving communication with the membership, educational and scientific activities, and professionalizing the central office. In the coming ten years the society would work had to achieve these goals, with Strengers to remain Secretary General for that period. Eurocongress organised ISBT congresses together with the CO and local organizing committees. The help of a PCO took away economic risks attached to congresses as they were able to provide professional assistance and detailed advice. As the CO had moved to a different country, the ISBT statutes and by-laws were also updated and adapted to Dutch law.\n\nThe reformations made in the previous years had led to an increase in workload for the ISBT CO. In order to continue the fulfilment of the strategic plans of the ISBT, a full-time, paid Chief Executive Officer (CEO) was hired in 2010. In 2012 the CO moved to a separate location in Amsterdam as the shared space with Eurocongress did not meet the needs of the expanded CO staff. Currently, 5 paid persons are employed full-time at the CO, managed by CEO Judith Chapman (2010 – today). Congresses are organised by MCI, of which Eurocongress became a part in 2010. In that same year Martin Olsson was appointed as Scientific Secretary (non-remunerated) to overlook the scientific programming of ISBT congresses and to guarantee the high scientific quality. The second scientific secretary, Ellen van der Schoot, is currently in office until 2018.\n\nThe organisation of congresses was the main reason for creating ISBT in 1935. So far, 34 International Congresses and 26 Regional Congresses have been organised. ISBT congresses discuss a wide range of state of the art topics in the field of transfusion medicine, with invited speakers for plenary and parallel sessions. Congresses typically start with a local or regional day on Saturday, followed by a day organised by the ISBT Academy on Sunday. Monday, Tuesday, and Wednesday are dedicated to parallel sessions, plenary sessions, workshops, and specialised group sessions. International congresses are typically one day longer and include Wednesday afternoon and Thursday morning in the scientific programming. All ISBT Congresses are complemented by a scientific exhibition with companies relevant to transfusion medicine.\n\nCongresses provide networking and learning opportunities to delegates, as well as the prospect to connect with industry. The society is committed to organizing congresses around the world. The international congresses take place once every even year. In the odd years two regional congresses are organised, of which one is in Europe and the other in a different part of the world. All congresses are organised in cooperation with a local organizing committee and a local scientific committee, and in some instances are organised in conjunction with a congress by another scientific society.\n\nIn 2011 the ISBT Academy was founded with the aim to provide support educational and research activities around the world. In 2013 it was decided that the Academy would focus solely on education, as it was not able to provide the resources to sustain a fruitful research programme. All education and knowledge activities from ISBT are facilitated through the Academy nowadays. The Academy has three specific goals: Overseeing the ISBT Academy ePortal, supporting workshops or educational activities financially or by the use of the ISBT logo, or host workshops or educational activities, for example at ISBT Congresses.\n\nThe Academy is governed by the ISBT Academy Standing Committee, currently chaired by vice president So-Yong Kwon. The members of the committee represent all regions across the globe and work together with the ISBT Scientific Officer. The Academy receives financial support from the ISBT Foundation, simultaneously acting as the advisory committee to the Foundation. The Standing Committee reviews all incoming applications for Academy support and decides whether requests are honoured.\n\nThe ISBT Education is an online learning environment accessible exclusively to members of ISBT. The platform contains a range of educational, scientific content, including eBooks, an interactive fainting module, accredited webcasts, interviews, recordings of the monthly ISBT webinars and Live Journal Clubs, learning quizzes, and guidelines. Special content from ISBT Congresses are also posted on ISBT Education, such as ePosters, abstracts, and recordings of scientific sessions, which are typically complemented with a learning quiz. The ISBT Education is also available as a mobile application.\n\nEvery two years at the ISBT International Congress this award is presented to a Blood Service or an institutional department of Transfusion Medicine from a Developing Country as a recognition of their significant contribution to improving blood transfusion practise in that country. The award is reserved to candidates from Low or Medium UNDP Human Development Index countries.\n\nThis award, named after the Society’s first Secretary General, was established in 1962. It is awarded to scientists under 40 years of age in recognition of their recent scientific work on blood transfusion related subjects. Individual members of ISBT can apply themselves for the prize, which is awarded once every two years at the ISBT International Congress. The winner of the Jean Julliard Prize is expected to give a prize lecture at the plenary session.\n\nThis award is granted to a senior person who has made significant contributions to transfusion medicine. It is awarded by the Foundation Transfusion Medicine to those that advanced transfusion medicine or a related field through the practice of transfusion therapy, basic or applied original research, or through educational or service contributions to the field. The winner is chosen by the Nomination Committee, consisting of the ISBT President, President Elect, the ISBT Scientific Officer, and the chairman and a member of the Board of the Foundation Transfusion Medicine. The award is presented once every two years at the ISBT International congress.\n\nThis award is presented to those who have contributed significantly to transfusion medicine and science, especially in relation to education. The award is presented during the opening ceremony of ISBT congresses. Typically two ISBT Awards are presented each congress. Members of the Executive committee decide who are to receive the award.\n\nThe Harold Gunson Fellowships were introduced in 2007 in recognition of the work Harold Gunson carried out as Secretary General and President of ISBT. The fellowship is essentially a travel grant, allowing applicants under 40 years of age to attend ISBT Congresses. The fellowship covers the congress registration fee, travel expenses, and hotel cost. Early 2016 regulations were changed to not only allow people from low- and medium HDI countries to apply, but allow people from all countries to apply for the grant. In order to be eligible for this grant, one must be the first, submitting, and presenting author of an abstract that has been accepted to the scientific programme of that congress. After the congress, Fellowship winners are expected to write a report on their experience.\n\nThis scientific award is presented to the author(s) of the best original paper that was published in the ISBT journal Vox Sanguinis in the past calendar year. The selection of eligible articles is made by the editors of Vox Sanguinis. The prize is granted by the Editorial Board and the Standing Committee on Vox Sanguinis. The value of the prize is €5000 .\n\n\n"}
{"id": "5963234", "url": "https://en.wikipedia.org/wiki?curid=5963234", "title": "Jerejak Island", "text": "Jerejak Island\n\nJerejak Island is an islet off the eastern coast of Penang Island in the State of Penang, Malaysia. Located within the Northeast Penang Island District, it is also a short ferry ride from the town of Bayan Lepas near the southeastern tip of Penang Island. It was formerly the main leper asylum for the Straits Settlements (1868), a Quarantine Station (1875) and a penal colony (1969).\n\nFrancis Light, the founder of Penang, was said to have arrived in Jerejak Island in early 1786 before heading on to Penang. In 1797, Colonel Arthur Wellesley had proposed Jerejak as the possible site for Fort Cornwallis. His idea of establishing a military post in Jerejak was to offer protection to a new township called Jamestown, which was to be set up in present-day Bayan Lepas. Earlier in 1794, there had been an outbreak of malaria caused most likely by the clearing of the jungle to establish George Town, claiming many lives, including Francis Light himself. Thus, Wellesley was not in favour of the site for Fort Cornwallis to be on Penang island.\n\nThis plan did not materialise as George Town was starting to become a profitable port and it soon became unnecessary to establish Jamestown or have a military facility in that location.\n\nAs a result of Francis Light's earlier ruling whereby immigrants were allowed to claim whatever land they could clear, Penang became flooded with immigrants. As a precautionary step, these immigrants were sent to Jerejak's health inspection centre before they were allowed to proceed to Penang.\n\nIn 1868, a leper asylum was completed but only in used in 1871. The cost of construction was supported by the local community. In 1880, it was expanded becoming the collection centre of leprosy (leprosarium) for the Straits Settlements until the 1930s.The leprosarium was closed in 1960s and the inmates were transferred to Sungai Buloh Leper Settlement/Leprosarium. Part of the island was made a health quarantine centre for immigrants in 1875 at the eastern and northern parts of the island.\n\nA memorial is located in the island dedicated to two crew members of the Imperial Russian Navy who died when their cruiser was sunk by the cruiser of the Kaiserliche Marine in the Battle of Penang on 28 October 1914. This is one of the few incidences of action which took place in Malaysian territory during World War I.\n\nAfter World War II, there was an increase in the number of tuberculosis patients and a sanatorium was set up in Jerejak for victims. On 12 June 1969, the Jerejak Rehabilitation Centre was set as a maximum security prison, hence earning the island the moniker, the Alcatraz of Malaysia. The centre was eventually closed in August 1993.\n\nThe Jerejak Island situated on a 362 ha island, just 10 minutes away from the hustle & bustle of Penang Island, west coast of Peninsular Malaysia. From there, take a 5 minutes ferry ride to Jerejak Island. Ferry ticket must be purchased from the ticket counter at the jetty. RM25 per adult and RM16 per child (two way transfer).\n\nPlans were made to redevelop Jerejak into a resort in 2000 and this resulted in the closure of the more \"unsavoury\" institutions in the island like the sanatorium and prison. In January 2004, the Jerejak Resort & Spa was opened for business. The resort was built over the area once occupied by the leprosarium.\n\nThis development remains somewhat controversial with concerns about the systematic removal of the island's historical remains and heritage and the impact on Jerejak's fragile eco-system.\n\n"}
{"id": "17503", "url": "https://en.wikipedia.org/wiki?curid=17503", "title": "Leisure", "text": "Leisure\n\nLeisure has often been defined as a quality of experience or as free time. Free time is time spent away from business, work, job hunting, domestic chores, and education, as well as necessary activities such as eating and sleeping. Situationist International proposes that leisure does not evolve from free time, and free-time is an illusory concept that is rarely fully \"free\"; economic and social forces appropriate free time from the individual and sell it back to them as the commodity known as \"leisure\". Certainly most people's leisure activities are not a completely free choice and may be constrained by social pressures, e.g. people may be coerced into spending time gardening by the need to keep up with the standard of neighbouring gardens or go to a party because of social pressures.\n\nLeisure as experience usually emphasizes dimensions of perceived freedom and choice. It is done for \"its own sake\", for the quality of experience and involvement. Other classic definitions include Thorsten Veblen's (1899) of \"nonproductive consumption of time.\" Different disciplines have definitions reflecting their common issues: for example, sociology on social forces and contexts and psychology as mental and emotional states and conditions. From a research perspective, these approaches have an advantage of being quantifiable and comparable over time and place.\n\nLeisure studies and sociology of leisure are the academic disciplines concerned with the study and analysis of leisure. Recreation differs from leisure in that it is a purposeful activity that includes the experience of leisure in activity contexts. Economists consider that leisure times are valuable to a person like wages that they could earn for the same time spend towards the activity. If it were not, people would have worked instead of taking leisure. However, the distinction between leisure and unavoidable activities is not a rigidly defined one, e.g. people sometimes do work-oriented tasks for pleasure as well as for long-term utility. A related concept is social leisure, which involves leisurely activities in social settings, such as extracurricular activities, e.g. sports, clubs. Another related concept is that of family leisure. Relationships with others is usually a major factor in both satisfaction and choice.\n\nLeisure has historically been the privilege of the upper-class. Opportunities for leisure came with more money, or organization, and less working time, rising dramatically in the mid to late 19th century, starting in Great Britain and spreading to other rich nations in Europe. It spread as well to the United States, although that country had a reputation in Europe for providing much less leisure despite its wealth. Immigrants to the United States discovered they had to work harder than they did in Europe. Economists continue to investigate why Americans work longer hours. In a recent book, Laurent Turcot argues that leisure was not created in the 19th century but is imbricated in the occidental world since the beginning of history.\n\nIn Canada, leisure in the country is related to the decline in work hours and is shaped by moral values, and the ethnic-religious and gender communities. In a cold country with winter's long nights, and summer's extended daylight, favorite leisure activities include horse racing, team sports such as hockey, singalongs, roller skating and board games. The churches tried to steer leisure activities, by preaching against drinking and scheduling annual revivals and weekly club activities. By 1930 radio played a major role in uniting Canadians behind their local or regional hockey teams. Play-by-play sports coverage, especially of ice hockey, absorbed fans far more intensely than newspaper accounts the next day. Rural areas were especially influenced by sports coverage.\n\nLeisure by the mid 19th century was no longer an individualistic activity. It was increasingly organized. In the French industrial city of Lille, with a population of 80,000 in 1858, the cabarets or taverns for the working class numbered 1300, or one for every three houses. Lille counted 63 drinking and singing clubs, 37 clubs for card players, 23 for bowling, 13 for skittles, and 18 for archery. The churches likewise have their social organizations. Each club had a long roster of officers, and a busy schedule of banquets, festivals and competitions.\n\nAs literacy, wealth, ease of travel, and a broadened sense of community grew in Britain from the mid 19th century onward, there was more time and interest in leisure activities of all sorts, on the part of all classes.\n\nOpportunities for leisure activities increased because real wages continued to grow and hours of work continued to decline. In urban Britain, the nine-hour day was increasingly the norm; 1874 factory act limited the workweek to 56.5 hours. The movement toward an eight-hour day. Furthermore, system of routine annual vacations came into play, starting with white-collar workers and moving into the working-class. Some 200 seaside resorts emerged thanks to cheap hotels and inexpensive railway fares, widespread banking holidays and the fading of many religious prohibitions against secular activities on Sundays.\n\nBy the late Victorian era, the leisure industry had emerged in all British cities, and the pattern was copied across Western Europe and North America. It provided scheduled entertainment of suitable length and convenient locales at inexpensive prices. These include sporting events, music halls, and popular theater. By 1880 football was no longer the preserve of the social elite, as it attracted large working-class audiences. Average gate was 5,000 in 1905, rising to 23,000 in 1913. That amounted to 6 million paying customers with a weekly turnover of £400,000. Sports by 1900 generated some three percent of the total gross national product in Britain. Professionalization of sports was the norm, although some new activities reached an upscale amateur audience, such as lawn tennis and golf. Women were now allowed in some sports, such as archery, tennis, badminton and gymnastics.\n\nLeisure was primarily a male activity, with middle-class women allowed in at the margins. There were class differences with upper-class clubs, and working-class and middle-class pubs. Heavy drinking declined; there was more betting on outcomes. Participation in sports and all sorts of leisure activities increased for average English people, and their interest in spectator sports increased dramatically.\n\nBy the 1920s the cinema and radio attracted all classes, ages, and genders in very large numbers. Giant palaces were built for the huge audiences that wanted to see Hollywood films. In Liverpool 40 percent of the population attended one of the 69 cinemas once a week; 25 percent went twice. Traditionalists grumbled about the American cultural invasion, but the permanent impact was minor.\n\nThe British showed a more profound interest in sports, and in greater variety, that any rival. They gave pride of place to such moral issues as sportsmanship and fair play. Cricket became symbolic of the Imperial spirit throughout the Empire. Soccer proved highly attractive to the urban working classes, which introduced the rowdy spectator to the sports world. In some sports, there was significant controversy in the fight for amateur purity especially in rugby and rowing. New games became popular almost overnight, including golf, lawn tennis, cycling and hockey. Women were much more likely to enter these sports than the old established ones. The aristocracy and landed gentry, with their ironclad control over land rights, dominated hunting, shooting, fishing and horse racing.\n\nCricket had become well-established among the English upper class in the 18th century, And was a major factor in sports competition among the public schools. Army units around the Empire had time on their hands, and encouraged the locals to learn cricket so they could have some entertaining competition. Most of the Empire embraced cricket, with the exception of Canada. Cricket test matches (international) began by the 1870s; the most famous is that between Australia and Britain for \"The Ashes.\"\n\nThe range of leisure activities extends from the very informal and casual to highly organised and long lasting activities. A significant subset of leisure activities are hobbies which are undertaken for personal satisfaction, usually on a regular basis, and often result in satisfaction through skill development or recognised achievement, sometimes in the form of a product. The list of hobbies is ever changing as society changes.\n\nSubstantial and fulfilling hobbies and pursuits are described by Stebbins as \"serious leisure\". The \"Serious Leisure Perspective\" is a way of viewing the wide range of leisure pursuits in three main categories: Casual Leisure, Serious Leisure, and Project-based Leisure.\n\n\"\"Serious leisure\" is the systematic pursuit of an amateur, hobbyist, or volunteer ... that is highly substantial, interesting, and fulfilling and where ... participants find a [leisure] career...\". For example, collecting stamps or maintaining a public wetland area.\n\nPeople undertaking serious leisure can be categorised as amateurs, volunteers or hobbyists. Their engagement is distinguished from casual leisure by a high level of perseverance, effort, knowledge and training required and durable benefits and the sense that one can create in effect a leisure career through such activity.\n\nThe range of serious leisure activities is growing rapidly in modern times with developed societies having greater leisure time, longevity and prosperity. The internet is providing increased support for amateurs and hobbyists to communicate, display and share products.\n\nAs literacy and leisure time expanded after 1900, reading became a popular pastime. New additions to adult fiction doubled during the 1920s, reaching 2800 new books a year by 1935. Libraries tripled their stock, and saw heavy demand for new fiction. A dramatic innovation was the inexpensive paperback, pioneered by Allen Lane (1902–70) at Penguin Books in 1935. The first titles included novels by Ernest Hemingway and Agatha Christie. They were sold cheap (usually sixpence) in a wide variety of inexpensive stores such as Woolworth's. Penguin aimed at an educated middle class \"middlebrow\" audience. It avoided the downscale image of American paperbacks. The line signaled cultural self-improvement and political education. The more polemical Penguin Specials, typically with a leftist orientation for Labour readers, were widely distributed during World War II. However the war years caused a shortage of staff for publishers and book stores, and a severe shortage of rationed paper, worsened by the air raid on Paternoster Square in 1940 that burned 5 million books in warehouses.\n\nRomantic fiction was especially popular, with Mills and Boon the leading publisher. Romantic encounters were embodied in a principle of sexual purity that demonstrated not only social conservatism, but also how heroines could control their personal autonomy. Adventure magazines became quite popular, especially those published by DC Thomson; the publisher sent observers around the country to talk to boys and learn what they wanted to read about. The story line in magazines and cinema that most appealed to boys was the glamorous heroism of British soldiers fighting wars that were perceived as exciting and just.\n\n\"\"Casual leisure\" is immediately, intrinsically rewarding; and it is a relatively short-lived, pleasurable activity requiring little or no special training to enjoy it.\" For example, watching TV or going for a swim.\n\n\"\"Project-based leisure\" is a short-term, moderately complicated, either one-shot or occasional, though infrequent, creative undertaking carried out in free time.\" For example, working on a single Wikipedia article or building a garden feature.\n\nTime available for leisure varies from one society to the next, although anthropologists have found that hunter-gatherers tend to have significantly more leisure time than people in more complex societies. As a result, band societies such as the Shoshone of the Great Basin came across as extraordinarily lazy to European colonialists.\n\nWorkaholics, less common than the social myths, are those who work compulsively at the expense of other activities. They prefer to work rather than spend time socializing and engaging in other leisure activities.\n\nMen generally have more leisure time than women, due to both household and parenting responsibilities and increasing participation in the paid employment. In Europe and the United States, adult men usually have between one and nine hours more leisure time than women do each week.\n\nFamily leisure is defined as time that parents and children spend together in free time or recreational activities, and it can be expanded to address intergenerational family leisure as time that grandparents, parents, and grandchildren spend together in free time or recreational activities. Leisure can become a central place for the development of emotional closeness and strong family bonds. Contexts such as urban/rural shape the perspectives, meanings, and experiences of family leisure. For example, leisure moments are part of work in rural areas, and the rural idyll is enacted by urban families on weekends, but both urban and rural families somehow romanticize rural contexts as ideal spaces for family making (connection to nature, slower and more intimate space, notion of a caring social fabric, tranquillity, etc.). Also, much \"family leisure\" requires tasks that are most often assigned to women.\n\nLeisure is important across the lifespan and can facilitate a sense of control and self-worth. Older adults, specifically, can benefit from physical, social, emotional, cultural, and spiritual aspects of leisure. Leisure engagement and relationships are commonly central to \"successful\" and satisfying aging. For example, engaging in leisure with grandchildren can enhance feelings of generativity, whereby older adults can achieve well-being by leaving a legacy beyond themselves for future generations.\n\n\n\n"}
{"id": "30631568", "url": "https://en.wikipedia.org/wiki?curid=30631568", "title": "Lifting Operations and Lifting Equipment Regulations 1998", "text": "Lifting Operations and Lifting Equipment Regulations 1998\n\nThe Lifting Operations Lifting Equipment Regulations 1998 (LOLER) are set of regulations created under the Health and Safety at Work etc. Act 1974 which came into force in Great Britain on 5 December 1998 and replaced a number of other pieces of legislation which covered the use of lifting equipment. The purpose of the regulations was to reduce the risk of injury from lifting equipment used at work. Areas covered in the regulations include the requirement for lifting equipment to be strong and stable enough for safe use and to be marked to indicate safe working loads; ensuring that any equipment is positioned and installed so as to minimise risks; that the equipment is used safely ensuring that work is planned, organised and performed by a competent person; that equipment is subject to ongoing thorough examination and where appropriate, inspection by competent people.\n\nThe regulations define lifting equipment as \"work equipment for lifting or lowering loads and includes its attachments used for anchoring, fixing or supporting it\". The regulations involve anything which involves the lifting of goods or people at work. Equipment covered would include lifts, cranes, ropes, slings, hooks, shackles, eyebolts, rope and pulley systems and forklift trucks. The regulations apply to all workplaces and all the provisions of the 'Provision and Use of Work Equipment Regulations 1998' also apply to lifting equipment.\n\nA safe working load (SWL) should, according to the regulations be marked onto lifting equipment with the relevant SWL being dependent on the configuration of the equipment, accessories for lifting such as eye bolts, lifting magnets and lifting beams should also be marked. The load itself would be based on the maximum load that the equipment can lift safely. Lifting equipment that is designed for lifting people must also be appropriately and clearly marked.\n\nThe regulations stated that all lifts provided for use with work activities should be thoroughly examined by a 'competent person' at regular intervals. Regulation 9 of the Lifting Operations and Lifting Equipment Regulations requires all employers to have their equipment thoroughly examined prior to it being put into service and after there has been any major alteration that could affect its operation. Owners or people responsible for the safe operation of a lift at work are known as 'dutyholders' and have a responsibility to ensure that the lift has been thoroughly examined and is safe to use. Lifts when in use should be thoroughly examined every six months if, at any time, the lift has been used to carry people. Lifts used to only carry loads should be examined every 12 months. Any substantial or significant changes should have been made to the equipment then this would also require an examination as would any change in operating condition which is likely to affect the integrity of the equipment.\n\nThese are a legal requirement and should be carried out by a competent person, usually your insurance company will request a 3rd party independent Inspector. These inspections should be carried out at 6month intervals for all lifting items and 12 months for those that could be covered by PUWER although a competent person may deem different time scales:\n\nStandards state that as a minimum;\nLOLER Frequency (in months):\nOn 17 January 2011 a Liverpool nursing home was fined £18,000 after Frances Shannon, an 81-year-old woman fell to the ground whilst being lifted out of bed.\n\nThe Christopher Grange nursing home run by the Catholic Blind Institute was prosecuted by the health and safety executive for failing to carry out regular checks of the sling equipment which was used to lift Mrs Shannon, who suffered a broken shoulder and injuries to her back and elbow. \n\nTaken to the Royal Liverpool University Hospital, Mrs Shannon died the day following the incident. Speaking of the prosecution Sarah Wadham, the HSE's inspecting officer, said that the incident could have been prevented, saying to the press \"There should have been regular checks of the sling and it should have been thoroughly examined at least once every six months. Sadly this did not happen.\"\n\nThe Catholic Blind Institute was charged under section 9 of the Lifting Operation and Lifting Equipment regulations and ordered to also pay £13,876 costs.\n\nLOLER 1998 essentially puts in place four key protocols that all employers and workers must abide by:\n1) All equipment must be safe and suitable for purpose \nThe manufacturer must identify any hazards associated with the equipment in question, they must then assess these hazards to bring them down to acceptable levels. All lifting equipment is normally put through an independent type testing process to establish that it will safely perform the tasks required to one of the below standards.\n• BS (British Standard, used mainly in the UK)\n• ISO Standards (International Standard)\n• EN (Euronorm, used throughout Europe)\n• CEN/CENELEC (Euronorm Standards)\nThe above standards are a published specification that establishes a common language and contains a technical specification or other precise criteria. They are designed to be used consistently as a rule, guideline or definition.\n\n2) All personnel must be suitably trained.\nAll manufacturers of lifting equipment are obliged to send out instructions for use of all products. \nThe employer is then obliged to make sure employees are aware of these instructions and use the lifting equipment correctly.\nTo achieve this the employees must be competent. Competence is achieved through experience, technical knowledge and training. \n\n3) All equipment must be maintained in a safe condition.\nIt is good practice for all personnel using lifting equipment to conduct a pre-use inspection on all items.\nRegulation 9 of LOLER also outlines specific requirements for the formal inspection of lifting equipment at mandatory intervals. \nThese inspections are to be performed by a competent person and the findings of the inspections recorded.\nMaximum fixed periods for thorough examinations and inspection of lifting equipment as stated in regulation 9 of LOLER are:\n•Lifting Accessories – 6 Months\n•Lifting Appliances – 12 Months\n•Man Riding Equipment – 6 Months\nOr in accordance with a written scheme of examination. Any inspection record must be made in line with the requirements of schedule 1 of LOLER\nThe only exception to this is: If the lifting equipment has not been used before and; In the case of lifting equipment issued with an EC declaration of conformity, the employer has possession of such declaration and it is not made more than 12 months before the lifting equipment is put into service.\n\nYou are legally required to ensure that reports of thorough examinations are kept available for consideration by health and safety inspectors for at least two years or until the next report, whichever is longer.\n\nRecords must be kept for all equipment. All equipment manufactured should be given a “birth certificate”. This should prove that when first made, it complied with any requirement. In Europe today, this document would normally be an EC Declaration of conformity plus a manufacturers certificate if called for by the standard worked to.\n\nThey may be kept electronically as long as you can provide a written report if requested.\n\nTo gain an understanding of the your Health and Safety requirements in the motor vehicle repair industry in full read document HSG261.\n"}
{"id": "47247372", "url": "https://en.wikipedia.org/wiki?curid=47247372", "title": "List of average annual labor hours in OECD countries", "text": "List of average annual labor hours in OECD countries\n\nThe following list is the average annual hours worked by participants in the labor force of the OECD member states. As of 2014, Mexico, Costa Rica and South Korea ranked first with the highest number of hours worked per year. As of 2014 Greece ranked the highest In EU with 2042 average hours per year, while Germany ranked the lowest with 1371 average hours worked respectively. Similarly, Netherlands has one of the lowest hours worked per labor participant. \n"}
{"id": "2684302", "url": "https://en.wikipedia.org/wiki?curid=2684302", "title": "Lockout-tagout", "text": "Lockout-tagout\n\nLockout-tagout (LOTO) or lock and tag is a safety procedure which is used in industry and research settings to ensure that dangerous machines are properly shut off and not able to be started up again prior to the completion of maintenance or repair work. It requires that hazardous energy sources be \"isolated and rendered inoperative\" before work is started on the equipment in question. The isolated power sources are then locked and a tag is placed on the lock identifying the worker who placed it. The worker then holds the key for the lock ensuring that only he or she can remove the lock and start the machine. This prevents accidental startup of a machine while it is in a hazardous state or while a worker is in direct contact with it.\n\nLockout-tagout is used across industries as a safe method of working on hazardous equipment and is mandated by law in some countries.\n\nMachinery can contain many hazards to workers, such as: \n\nFor example, a single industrial device may contain hot fluids, presses, blades, impellers, electrical heaters, conveyor belts with pinch points, moving chains, and ultraviolet light.\n\nDisconnecting or making safe the equipment involves the removal of all energy sources and is known as \"isolation\". The steps necessary to isolate equipment are often documented in an \"isolation procedure\" or a \"lockout tagout procedure\". The isolation procedure generally includes the following tasks:\n\nThe locking and tagging of the isolation point lets others know not to de-isolate the device. To emphasize the last step above in addition to the others, the entire process can be referred to as lock, tag, and try (that is, trying to turn on the isolated equipment to confirm it has been de-energized and cannot operate).\n\nThe National Electric Code states that a safety/service disconnect must be installed within sight of serviceable equipment. The safety disconnect ensures the equipment can be isolated and there is less chance of someone turning the power back on if they can see the work going on. These safety disconnects usually have multiple places for locks so more than one person can work on equipment safely.\n\nIn industrial processes it can be difficult to establish where the appropriate danger sources might be. For example, a food processing plant may have input and output tanks and high-temperature cleaning systems connected, but not in the same room or area of the factory. It would not be unusual to have to visit several areas of the factory in order to effectively isolate a device for service (the device itself for power, upstream material feeders, downstream feeders and control room).\n\nSafety equipment manufacturers provide a range of isolation devices specifically designed to fit various switches, valves and effectors. For example, most circuit breakers have a provision to have a small padlock attached to prevent their activation. For other devices such as ball or gate valves, plastic pieces which either fit against the pipe and prevent movement, or clamshell-style objects which completely surround the valve and prevent its manipulation are used.\n\nA common feature of these devices is their bright color, usually red, to increase visibility and allow workers to readily see if a device is isolated. Also, the devices are usually of such a design and construction to prevent it being removed with any moderate force - for example, an isolation device does not have to resist a chainsaw, but if an operator forcibly removes it, it will be immediately visible that it has been tampered with.\n\nTo protect one or more circuit breakers in an electrical panel, a lockout-tagout device called the Panel Lockout can be used. It keeps the panel door locked and prevents the panel cover from being removed. The circuit breakers remain in the off position while electrical work is done.\n\nWhen two or more people are working on the same or different parts of a larger overall system, there must be multiple holes to lock the device. To expand the number of available holes, the lockout device is secured with a folding scissors clamp that has many pairs of padlock holes capable of keeping it closed. Each worker applies their own padlock to the clamp. The locked-out machinery cannot be activated until all workers have removed their padlocks from the clamp.\n\nIn the United States a lock selected by color, shape or size, such as a red padlock, is used to designate a standard safety device, locking and securing hazardous energy. No two keys or locks should ever be the same. A person's lock and tag must only be removed by the individual who installed the lock and tag unless removal is accomplished under the direction of the employer. Employer procedures and training for such removal must have been developed, documented and incorporated into the employer energy control program.\n\nBy US Federal regulation 29 CFR 1910.147 (c) (5) (ii) (c) (1) the tag must have an identification showing the name of the person doing the lock and tag. \nWhile this may be true for the United States, it is not mandatory in Europe. The lockout can also be done by a \"role\" such as the shift leader. Using a \"lockbox\", the shift leader is always the last one to remove the lock and has to verify it is safe to start up equipment.\n\nAccording to the European standard EN 50110-1, the safety procedure before working on electric equipment comprises the following five steps:\n\nMany sites have the officially-stated policy that only the person who tagged the device can untag it. This means that if a worker goes home after their shift without removing their tag from a device which is ready to use, they will have to return to the site to untag it. Giving approval for the removal of a tag over the phone is prohibited.\n\nWhile this policy might seem to encourage workers to take the risk of not tagging a device in the first place, it is usually accompanied by another policy stating that working on a device without tagging it will result in instant dismissal.\n\nAll Canadian jurisdictions legally require lockout for certain work. However, the specific activities required for appropriate lockout are usually not specified in law. These specifics are provided through industry standards. The Canadian Standards Association's standard CSA Z460, based on industry, labour and government consultations, outlines the specific activities of a lockout program and is usually considered the appropriate standard of good practice for lock out. All Canadian health and safety legislation places a general duty on an employer to take all reasonable precautions and carrying out this standard of good practice is usually considered a mark of due diligence.\n\nLockout-tagout in the US, has five required components to be fully compliant with OSHA law. The five components are:\n\nIn industry this is an Occupational Safety and Health Administration (OSHA) standard, as well as for electrical NFPA 70E. OSHA’s standard on the Control of Hazardous Energy (Lockout-Tagout), found in 29 CFR 1910.147, spells out the steps employers must take to prevent accidents associated with hazardous energy. The standard addresses practices and procedures necessary to disable machinery and prevent the release of potentially hazardous energy while maintenance or servicing activities are performed.\n\nTwo other OSHA standards also contain energy control provisions: 29 CFR 1910.269 and 29 CFR 1910.333. In addition, some standards relating to specific types of machinery contain de-energization requirements such as 29 CFR 1910.179(l)(2)(i)(c)(requiring the switches to be \"open and locked in the open position\" before performing preventive maintenance on overhead and gantry cranes). The provisions of Part 1910.147 apply in conjunction with these machine-specific standards to assure that employees will be adequately protected against hazardous energy.\n\nIf employees service or maintain machines where the unexpected startup, energization, or the release of stored energy could cause injury, the OSHA standard applies, unless an equivalent level of protection can be proven. Equivalent level of protection may be achieved in some cases through standard operating procedures (SOP) and custom machine guarding solutions that are combined to establish machine control to protect the worker for specific tasks. The standard applies to all sources of energy, including, but not limited to: mechanical, electrical, hydraulic, pneumatic, chemical, and thermal energy.\n\nThe standard does not cover electrical hazards from work on, near, or with conductors or equipment in electric utilization (premise wiring) installations, which are outlined by 29 CFR Part 1910 Subpart S. The specific lockout and tagout provisions for electrical shock and burn hazards can be found in 29 CFR Part 1910.333. Controlling hazardous energy in installations for the exclusive purpose of power generation, transmission, and distribution, including related equipment for communication or metering, is covered by 29 CFR 1910.269.\n\nThe standard also does not cover the agriculture, construction, and maritime industries or oil and gas well drilling and servicing. Other standards concerning the control of hazardous energy, however, apply in many of these industries and situations.\n\nThe standard does not apply to general industry service and maintenance activities in the following situations, when:\n\n\nThere are a few instances across UK regulations that refer to ‘Lockout Tagout’ indirectly. The use of ‘Lockout Tagout’ is not currently enforced in the UK but has been proven to be best practice for multiple UK industries.\n\nThe BS7671:2008 is a regulation in the UK that ensures that all wiring and electrical installations completed within any building is of the highest standard. It also states that \"“Every employer shall ensure that where appropriate, work equipment is provided with a suitable means to isolate it from all its sources of energy. Every employer shall take appropriate measures to ensure that reconnection of any energy source to work equipment does not expose any person using the equipment to any risk to their health or safety”\". Find out more about BS7671 here. [Provision of Work Equipment Regulations – Regulation 19 – Isolation from Sources of Energy]\n\nPUWER is the key regulation that is enforced within the Manufacturing industry within the UK. \"‘PUWER stands for the Provision and Use of Work Equipment Regulations 1998 (1999 in Northern Ireland). The regulations deal with the work equipment and machinery used every day in workplaces and aims to keep people safe wherever equipment and machinery is used at work.’\" This reinforces that employers should make all machinery safe for use, including adding additional precautions such as extra Guards and safer PPE (Personal Protective Equipment). Machinery should also be inspected at regular intervals to ensure it is in a continued ‘safe to use’ state.\n\nThere are citations within the PUWER regulations that argue the use of safety devices such as Lockout Tagout, however at no point do the regulations state this outright. But it does explain that ‘lockout devices’ should be used to enhance the safety of employees. So, it may not be written in black and white under English Regulations that Lockout Tagout should be used but the document does mention a \"‘Hierarchy of measures\"’ for standardising safety procedures that are \"Lockout Tagout\" related but they are explained as a permanent fixture to any machine or tool. For instance one of the three measures mentioned is to \"‘provide protection appliances (jigs, holders, push sticks)’\". And as a wider assumption this could include LOTO devices but it doesn’t specifically say that in the regulation. This part of the regulation is more about ensuring that the day to day workplace risks are assessed properly and thoroughly. However in the same set of regulations, later on, it states that employers should ensure that all work equipment is accompanied by an appropriate way to isolate power/energy. Including an appropriate set of actions (and facilities) to turn the power back on without creating a potential hazard for other employees. This is more aligned with the American OSHA guidelines and practices and defines that the Lockout Tagout Safety movement is on the rise in the UK.  \n\nLifting Operations and Lifting Equipment Regulations 1998 (LOLER) acts as an acknowledgement that businesses with lifting equipment should inspect the lifting machinery regularly. This can be completed through a series of Tagging Systems specially designed to be used in conjunction with machinery described as a lifting accessory. Tagging Systems are made up of holders and inserts, the holders are to be permanently fixed to the machinery/tools and the inserts filled in and placed inside of the holder with the inspection details showing.\n\nIn EU, the guidelines are OSHA based and therefore pick up on American characteristics in its legislation, but it is 89/655 paragraph 2.14 that states that \"“every piece of equipment must be fitted with clearly visible devices with which it can be separated from every energy source”\" [EU Guidelines 89/655 (Paragraph 2.14)]. This indicates that all workplace machinery should be fitted with permanent LOTO solutions for easy and safe Lockout Tagout procedures. \n"}
{"id": "58205473", "url": "https://en.wikipedia.org/wiki?curid=58205473", "title": "Lybrate", "text": "Lybrate\n\nLybrate is a mobile healthcare technology company that developed an online platform to connect doctors and patients. The company was founded in 2013 and is headquartered in Delhi, India. The service allows patients to connect with the doctor online through a video call or schedule an appointment and can get info about medication.\n\nThe service was founded in July 2013 by Saurabh Arora formerly worked at Facebook in the US and Rahul Narang, former professionals of Snapdeal. Arora and Narang teamed up to create an online platform to connect patients with doctors and eliminate self-medication in India. They started building the company with their own funds and in August 2014, they raised $1.23 million seed funding from Nexus Venture Partners. In July 2015, Lybrate raised $10.2 million Series A funding lead by Tiger Global, Nexus and Ratan Tata, Chairman Emeritus of Tata Sons to scale technology and operations, develop products and recruit talent. In 2015, Lybrate collaborated with Indian Medical Association as digital partner to educate doctors, incorporate technology in their practice for communicating with patients.\n\nLybrate was initially launched to connect people with healthcare professionals, allowing them to book appointments with doctors using the web portal and mobile application. In May 2016, Lybrate launch Lybrate Lab+, an online lab testing service that allows a patient sample to be collected right from their home, with results later shared online. It also provides patient management services for doctors, and remote doctor-patient consultancy. The service currently has over 1 Lakh certified doctors available and connect patients with medical care professionals.\n"}
{"id": "41096325", "url": "https://en.wikipedia.org/wiki?curid=41096325", "title": "MNsure", "text": "MNsure\n\nMNsure is the health insurance marketplace for the U.S. state of Minnesota. The exchange enables people and small businesses to purchase health insurance at federally subsidized rates. The current CEO is Nate Clark.\n\nHealth insurance exchanges were established as a part of the 2010 Patient Protection and Affordable Care Act to enable individuals to purchase health insurance in state-run marketplaces. In this legislation, states could choose to establish their own health insurance exchanges; if they choose not to do so, the federal government would run one for the state.\n\nOn March 18, 2013, the Minnesota Legislature passed the Minnesota Insurance Marketplace Act establishing Minnesota's health insurance marketplace. It was signed by Governor Mark Dayton two days later on March 20 in a signing ceremony.\n"}
{"id": "3215795", "url": "https://en.wikipedia.org/wiki?curid=3215795", "title": "Maxillary second molar", "text": "Maxillary second molar\n\nThe maxillary second molar is the tooth located distally (away from the midline of the face) from both the maxillary first molars of the mouth but mesial (toward the midline of the face) from both maxillary third molars. This is true only in permanent teeth. In deciduous (baby) teeth, the maxillary second molar is the last tooth in the mouth and does not have a third molar behind it. The function of this molar is similar to that of all molars in regard to grinding being the principal action during mastication, commonly known as chewing. There are usually four cusps on maxillary molars, two on the buccal (side nearest the cheek) and two palatal (side nearest the palate). \n\nThere are great differences between the deciduous (baby) maxillary molars and those of the permanent maxillary molars, even though their function are similar. The permanent maxillary molars are not considered to have any teeth that precede it. Despite being named molars, the deciduous molars are followed by permanent premolars. The deciduous maxillary second molar is the most likely deciduous tooth to have an oblique ridge.\n\nIn the universal system of notation, the deciduous maxillary second molars are designated by a letter written in uppercase. The right deciduous maxillary second molar is known as \"A\", and the left one is known as \"J\". The international notation has a different system of notation. Thus, the right deciduous maxillary second molar is known as \"55\", and the left one is known as \"65\".\n\nIn the universal system of notation, the permanent maxillary second molars are designated by a number. The right permanent maxillary second molar is known as \"2\", and the left one is known as \"15\". In the Palmer notation, a number is used in conjunction with a symbol designating in which quadrant the tooth is found. For this tooth, the left and right second molars would have the same number, \"7\", but the right one would have the symbol, \"┘\", underneath it, while the left one would have, \"└\". The international notation has a different numbering system than the previous two, and the right permanent maxillary second molar is known as \"17\", and the left one is known as \"27\".\n\n"}
{"id": "17200325", "url": "https://en.wikipedia.org/wiki?curid=17200325", "title": "Nutritional anthropology", "text": "Nutritional anthropology\n\nNutritional anthropology is the interplay between human biology, economic systems, nutritional status and food security, and how changes in the former affect the latter. If economic and environmental changes in a community affect access to food, food security, and dietary health, then this interplay between culture and biology is in turn connected to broader historical and economic trends associated with globalization. Nutritional status affects overall health status, work performance potential, and the overall potential for economic development (either in terms of human development or traditional western models) for any given group of people.\n\nMost scholars construe economy as involving the production, distribution, and consumption of goods and services within and between societies. A key concept in a broad study of economies (versus a particular econometric study of commodities and stock markets) is social relations. For instance, many economic anthropologists state that the reciprocal gift exchange, competitive gift exchange, and impersonal market exchange are all reflective of dominant paradigms of social relations within a given society. The main forms of economy extant around most of the world today, in terms of a simple production, distribution, consumption model, are subsistence based and market economies. Subsistence refers to production and consumption on a small-scale of the household or community, while a market-based economy implies a much broader scale of production, distribution, and consumption. A market economy also entails the exchange of goods for currency, versus bartering commodities or being under continuing reciprocal gift exchange obligations. This is not to say that market economies do not coexist with subsistence economies and other forms, but that one type usually dominates within a given society. However, a broad array of scholarship exists, stating that market economies are rapidly increasing in importance on a global scale, even in societies that have traditionally relied much more heavily on subsistence production. This economic shift has nutritional implications that this entry will explore further.\n\nThe most important step in understanding the links between economics and nutrition is to understand major modes of production that societies have used to produce the goods (and services) they have needed throughout human history; these modes are foraging, shifting cultivation, pastoralism, agriculture, and industrialism (Park 2006).\nForaging, also known as hunting and gathering, is a subsistence strategy in which a group of people gathers wild plants and hunts wild animals in order to obtain food. This strategy was the sole mode of existence for human beings for the vast majority of human history (inclusive of the archeological and fossil record) and continued to be practiced by a few groups at least into the middle part of the 20th century. This mode of production is generally associated with small, nomadic groups of no more than fifty, also known as bands. The vast majority of foraging societies do not acknowledge exclusive ownership of land or other major resources, though they do acknowledge primary use rights for groups and people may individually possess small objects or tools such as a bow or cutting tools. Because foraging usually involves frequent movement and taking food naturally available rather than altering landscapes for production, many scholars state the foraging has a minimal negative environmental impact compared to other modes of production. Though foragers are generally limited in absolute amount of food available in a given area, foraging groups such as the !Kung in the Kalahari Desert have often been cited as having a more diverse diet and spending less time per week procuring food than societies that practice other modes of production such as intensive agriculture. \nShifting cultivation is a mode of production involving the low intensity production of plant-based foods; this mode is also known as horticulture or ‘slash and burn agriculture’ in some texts. Horticultural societies are generally situated in semi-sedentary villages of a few hundred that clear a field and burn the cleared vegetation in order to use the ashes to nourish the soil (hence the phrase slash and burn). Next, the group plants a crop or crops in this clearing and uses it for cultivation for several years. At the end of this period, the entire village relocates and starts the process anew, leaving the old clearing fallow for a period of decades in order to allow regeneration through the regrowth of wild vegetation. These food items can be supplemented through the raising of livestock, hunting wild game, and in many cases with the gathering of wild plants (Miller 2005; Park 2006). Though periodic movement precludes absolute permanent ownership of land, some horticultural societies fiercely defend current territories and practice violence against neighboring groups. For instance, Napoleon Chagnon (1997) depicts the Yanamamo of Venezuela and Brazil as the “Fierce People”, though others have been highly critical of Chagnon’s account of this society. Horticulture can also produce a broad diet, and in some cases more food per unit of land area than foraging. Though populations of horticulturalists tend to have greater density than those of foragers, they are generally less dense than those which practice other modes of production. If practiced on a small scale, over a large area, with long fallow periods, horticulture has less negative environmental impact than agriculture or industrialism, but more than foraging (Miller 2005). Generally, horticulture coincides with a subsistence type of economy in terms of production, distribution.\nPastoralism, defined as reliance on products from livestock coupled with a seasonal nomadic herding tradition, is similar to horticulture in that it is extensive in its use of land area. Social groups in pastoral societies tend to have similar numbers and population density to horticultural societies. Pastoral societies often trade animal products with agricultural societies for plant based foods to augment their diet. Frequent movement often means that pastoralism has a similar environmental impact to horticulture, though instances of overgrazing, and consequent land degradation (see later subsection under Globalization and Nutrition), have been sited in some cases. Pastoralism generally entails a greater reliance on meat or other animal products, such as milk or blood, than other modes of production. This mode of production has a similar use rights profile to shifting cultivation. Traditionally, pastoralism has coincided with a subsistence based economy, but in the last several decades, some pastoralist societies, such as Mongolia, have herded animals and practiced nomadic living patterns but have produced livestock primarily for market exchange.\nAgriculture, sometimes referred to as intensive agriculture, involves clearing and using the same plot of land for an extended period, sometimes several generations; it also involves the use of plows and draft animals in the preparation of land for planting and the cultivation of crops. Agriculture often supports much higher population densities than other modes of production (except industrialism) and agricultural societies can range in population from a few thousand into the millions. Though agriculture produces more food per unit of land area than the previously mentioned modes, the tendency of agricultural societies to focus on relatively few crops has often meant that these societies have much less diverse diets than foraging and horticultural societies. There is some archaeological and fossil evidence that populations in transition from foraging to agriculture have tended to suffer reduced stature, reduced musculature, and to exhibit other markers of malnutrition. Research has suggested that agriculture paradoxically allows a higher, but less healthy population for a given area. The advent of agriculture has marked that advent of social stratification in many parts of the world, with marked differentials in access to resources between segments of the same society. This mode of production also is more likely to entail permanent individual or family ownership of particular tracts of land than previously mentioned modes of production. Agriculture has co-occurred with both subsistence and market economies, often with a single society exhibiting some degree of both types of economies and has a more negative impact on the environment than the aforementioned modes of production.\nIndustrialism combines agriculture with mechanized industrial production of goods through the use of fossil fuels. Additionally, industrial societies use mechanized equipment in order to prepare land for planting, harvest crops, and distribute food to locations distant from where the original crops were planted. Industrialism shows similar trends to agriculture in terms of population density, and environmental impact, except to a much greater degree. Dietary diversity can be highly variable under an industrial mode of production and can depend on access to foods produced for local subsistence on the one hand, or to income level and purchasing power visa vie foods available in food markets (Leatherman and Goodman 2005). Dietary diversity and nutritional health often correlate with the degree of social stratification within an industrial society and sometimes between societies. With the exception of Soviet model states, industrial societies are heavily based on the concept of private property rights and the accumulation of profit through “free enterprise”.\nThe general trend for many societies over the past several millennia has been toward agriculture, and in the past two centuries, toward industrialism. Though these two modes of production are by no means superior to other modes in every respect, the fact that societies that practice them tend to have larger populations, higher population densities, and a more complex social structure has correlated with the geographic expansion of agricultural and industrial societies at the expense of societies emphasizing other modes of production. Concurrent with this trend toward intensified agricultural and industrial production has been the rise of the social and economic paradigm of capitalism, which entails the production and sale of goods and services in the market place in order to produce a profit. These trends have had profound implications for nutritional status for human beings on a global scale. In order to discern how broader economic and environmental trends affect a community’s food systems, food security, and nutritional status, it is important to summarize one of the most significant economic and ecological phenomena today, globalization. The next section will treat the linkages between economic and ideological trends over the last several centuries and environmental and political economic factors affecting access to food and nutritional status.\n\nThough the scope and dimensions of globalization as most people currently construe it are of fairly recent origin, the broader phenomenon of global interconnections through cultural diffusion and trade is several centuries old. Starting in the late Fifteenth century, European powers expanded beyond the European sub-continent to found colonies in the Americas, East Asia, South Asia, Australia and Oceania. This expansion has had a profound impact in terms of wealth creation in Europe and extraction elsewhere, cultural changes in most of the world’s societies, and biological phenomena such as the introduction of several infectious diseases into the Western Hemisphere, which caused tremendous disruption and population reduction for indigenous societies there. These events, far from occurring coincidentally, have had synergistic relationships, in one vivid example, the decimation of Amerindian populations through infectious disease often preceding and facilitating subsequent conquest by European powers. Such conquests in turn have often had significantly negative impacts on internal cohesion, ability of populations to attain adequate resources for their own subsistence and traditional social obligations, and local environments for colonized societies. In order to understand the effects of globalization on nutritional status and food security, it is important to understand the historical circumstances that have led to contemporary globalization, and that still manifest themselves in political, social, material, and physical/health differentials between (and within) the different peoples of the world today.\n“The Rise of the Merchant, Industrialist, and Capital Controller,” written by Richard Robbins in 2005, uses a hypothetical scenario of the reader as a “merchant adventurer” to detail economic world history starting in 1400. In 1400, China was arguably the most cosmopolitan and technologically complex society in the world. It was a center of trade, along with the Middle East, East Africa, and ports on the Mediterranean Sea. Western Europe, while playing a part in this network, did not dominate it by any means; one could argue for European marginalization in fact. This circumstance began to change when the Europeans “discovered” the Americas, setting in motion a process that would disrupt many societies and devastate indigenous populations of the Western Hemisphere. The dominant economic paradigm of this period was mercantilism, whereby European merchants began to achieve power in world markets and in relation to European governing aristocracies. Robbins cites example of government protections that facilitated mercantilism in the form of exclusive proprietary rights to trading companies and armies used to protect trade by force if necessary. He details instances of government protection such as the example of how Great Britain destroyed India's textile industry and turned that society into an importer of textiles is especially illustrative. In dealing with imperialism, capitalism, and the rise of corporations, Robins further details the manner in which the “West” transformed various regions/peoples from proactive participants on global trade networks into sources of raw materials and consumers of European or North American exports. This history of world trade is important to the consideration of current issues of disparity of power and wealth.\nThere are many critiques the policies of the World Bank and the International Monetary Fund (IMF) in the promotion of high intensity capital investment in developing nations (e.g. Weller et al. 2001; Fort et al. 2004). Disparities within nations and growing poverty rates in many nations also provide compelling evidence of the idea that the rewards of economic globalization are uneven at best. There is a great deal of literature about globalization and increases in health disparities both between and within countries.\nFinally, there is Amartya Sen with \"Development as Freedom\" (1999); here Sen disagrees about whether or not the world’s poor are getting poorer, but also maintains that this criterion is not the most important. He argues that relative disparities and power differentials are the most important problems of globalization. Sen states that the increasing interconnection of the Worlds societies can have positive benefits, but that the disparities and opportunities for exploitation must be mitigated to the greatest extent possible, if they can not be eliminated outright. Sen provides groundwork for a nuanced middle ground between unabashed proponents and opponents of globalization. \nFar from being universally decried, the recent accelerated expansion of western capitalism, geographically, politically, and ideologically, has been lauded in many quarters. International and bilateral agencies such as the World Bank, IMF, and the United States Agency for International Development (USAID) have utilized free market capitalist theories extensively in development programs in many corners of the globe whose state aims are to promote economic growth for communities and nation-states and to alleviate poverty. Likewise prominent individuals such as former U.S. Federal Reserve Board Chair Alan Greenspan and U.S. based journalist Thomas Friedman have held forth extensively about the possibilities of economic and social improvement in developed and developing nations alike, mainly through increased access to appropriate education, sophisticated communications and transportation technology, and a paradigm of social and economic “flexibility”, where individuals and communities who can best adapt to rapid changes in the role of governments and the particular economic base of a given location would be in the best position to take advantage of the opportunities offered by economic, political, and cultural globalization. This free market ideology is also predominant in the policies and procedures of the World Trade Organization (WTO) and many transnational corporations (TNC’s), most of which are headquartered in developed nations. The rise of Capitalism and the free market society have indeed increased and exacerbated food insecurity in the world's poor due to the structure and function of a Capitalist society where only those who can afford to buy food to feed themselves are the only ones with access to a secure and adequate food supply. Food is no longer a human right to life and health due to the Capitalist approach to commodifying food in the free market society that as a result of globalization has spread all over the world. Transnational corporations and trade organizations such as NAFTA facilitate this approach of commodifying our world's food supply by enforcing laws and regulations which further deepen the inequality of wealth and unequal distribution of common goods such as food between the rich and the poor.\nIn contrast to the “western” economic model, most early social scholarship about economics stressed the predominance of reciprocity as a primary driving force in traditional non-Western societies. Marcel Mauss referred to the gift as a “total social phenomenon”, fraught with ritual and socio political as well as material significance. Though some objects, such as armbands or shell necklaces in the kula ring that runs through several island groups off the coast of Papua New Guinea, might induce some form of prestige based competition, the terms of exchange are significantly different than a monetary transaction under a modern capitalist system. While Appadurai actually describes ritual objects as a type of commodity, he couches them as such under significantly different terms than the market-based types of commodity normally treated by economists. Annette Wiener criticizes earlier works in anthropology and sociology that depicted “simple” societies utilizing a simple version of reciprocity. Whatever the theoretical stance of social scholars on non-western traditional economies, there is a consensus that such essentials as food and water tended to be shared more freely than other types of goods or services. This dynamic tends to change with the introduction of a market-based economy into a society, with food coming to be increasingly treated as a commodity, rather than a social good or an essential component of health and survival.\n\nRegardless of one’s overall perspective on the costs and benefits of economic globalization, there are several examples in social scholarship of groups of people suffering a decline in nutritional statues subsequent to the introduction of a capitalist market-based economy into an area that has previously practiced an economy based more on subsistence production and reciprocity. Although some people’s food security may improve with access to more steady income, many people in communities that have heretofore practiced a subsistence economy may experienced greater food insecurity and nutritional status due to insufficient income to replace the foods no longer produced by a household. Whether the growth of food insecurity and socioeconomic disparities in many parts of the world in recent decades is an inherent part of globalization or a temporary “growing pain” until economic development attains its full efficacy is a matter of debate, but there are many empirical examples of communities being dissociated from traditional means of food production and not being able to find sufficient wages in a new market economy to achieve a balanced and calorically sufficient diet. Several factors affecting food security and nutritional status range on a continuum from more physical phenomena such as land degradation and land expropriation, to more culturally and socio-politically driven things such as cash cropping, dietary delocalization, and commoditization of food; one important caveat is that all of these trends are interconnected and fall under a broad category of socio-cultural and economic disruptions and dislocations under the current paradigm of globalization.\n\nThough Blakie and Brookfield acknowledge the problematic aspects of defining land degradation, with definitional variation depending in large part on the scholar or stakeholder in question, they do outline a general idea of reduced soil fertility and reduced ability of a given area of land to provide for people’s subsistence needs, as compared to earlier periods in human history on that same land area. Paul Farmer discusses the effects of land degradation in central Haiti on local people’s ability to produce sufficient food for their families within the environs of their own communities. Farmer links malnutrition in a Haitian village with vulnerability to infectious diseases, including tuberculosis and HIV/AIDS, both in terms of chance of infection and severity of symptoms for those infected. While the extremely low percentage of the U.S. population involved in agriculture strongly suggests that direct access to arable land is not an absolute necessity for food security and nutritional health, land degradation in many developing nations is accelerating the rate of rural to urban migration at a more accelerated rate than most major cities are equipped to handle. Leatherman and Goodman also allude to land degradation co-occurring with decreases in food security and nutritional status in some communities in the Mexican state of Quintana Roo. Walter Edgar discusses the correlation between land degradation and economic disruption, as well as nutritional hardship, in the U.S. state of South Carolina in the decades following the Reconstruction Period. Coupled with land expropriation, land degradation has the effect of thrusting unprepared subsistence producers or other peasant farmers into a fast-paced and complex market economy heavily influence by policy makers who are far removed from the concerns and worldview of small scale farmers in developing countries.\n\nOccurring for a variety of reasons, land expropriation, or the disruption of traditional ownership of land by more powerful interests such as local elites, governments, or transnational corporations, can also markedly affect nutritional status. Robbins details examples in Mexico of peasants facing land expropriation in the face of agribusiness consolidation under the North American Free Trade Agreement (NAFTA); in many cases, these subsistence producers are forced either to migrate to cities or work sporadically as agricultural labors. Since most if not all food must be purchased under these circumstances, the food security and nutritional status of these newer additions to the pool of poor unskilled labor often declines. Another common impetus for expropriation is non-agricultural “economic development”, often in the form of tourism. In one Example, Donald MacLeod details curtailment of subsistence activities, mainly fishing and cultivation, in areas of the Canary Islands in the face of pressures from tourism interests wishing to monopolize the “pristine” beauty of locations catering to Germans and other tourists from EU nations. Ironically, local people see relatively little monetary benefit from the rise in tourism, as many vacations are planned by German tour companies (linked with all inclusive German owned resorts in the Canary Islands) and are paid for before tourists ever arrive at their vacation destination. Leatherman and Goodman and Daltabuit point to circumscription of land available for traditional milpa horticultural production in communities in the Mexican state of Quintana Roo in the face of growing demands for land for resorts by tourism interests, under the auspices of the Mexican national government. One expropriation scenario with a long history is cash cropping, where crops grown for revenue from exports are prioritized over crops grown for local consumption.\n\nIn \"Sweetness and Power\", written by Sidney Mintz in 1985, details examples of mono-cropping, or planting massive areas with one cash crop, in several Caribbean Islands, including Cuba. He states that Cuba went from being an economically diverse place with many small scale subsistence producers to a mono-crop plantation system dependent on cash from its sugar crop and substantial food imports for the later centuries of the Spanish Colonial Period. He describes Cuba as an example of growing impoverishment and malnutrition concurrent with increasing concentration of land and other resources in fewer hands. Gross and Underwood illustrate the mid Twentieth Century example of the advent of sisal production in Northeastern Brazil. These authors detail a vicious cycle of the unfulfilled promises of sisal production for smallholders; because owners of sisal processing machines did not think small farms worth their time, small holders could not process and sell their sisal and were often forced to work as laborers on large farms. Sisal is cited as being particularly insidious because it is hard to eradicate once introduced and makes subsequent subsistence production virtually impossible. This article treats a common situation of households prioritizing working males in food allocation, exposing growing children to malnutrition, particularly under nutrition and micronutrient deficiency, and all of its attendant ills. Edgar discusses how exclusive planting of cotton in the Southeastern United States during the late Nineteenth and early Twentieth Centuries caused substantial land degradation, lead to a great deal of land expropriation from small scale farmers, and occurred in a context of widespread malnutrition. Especially in Today’s complex, accelerated version of globalization, cash cropping is intimately linked with the delocalization of diets and the commoditization of food and has profound, though varied, implications for food security and nutritional status.\n\nIn “Diet and Delocalization: Dietary Challenges since 1750”, Pelto and Pelto trace the concurrent historical development of global capitalism and dietary delocalization, a process in which increasing portions of diet for a household or community come from an increasing distance away from that same community. Nutritional scholars explicitly state that delocalization does not necessarily entail increased food insecurity and malnutrition, but that access to an adequate diet becomes increasingly removed from local control and increasingly contingent on access to hard cash or some other non-food precious resource. Leatherman and Goodman discuss the ironic result of their study in Quintana Roo that both the groups with the best and worst food security and nutritional status worked in service industries related to tourism, with the median group being a milpa community. They differentiate between those with stable employment and income who have access to a wide variety of foods on a regular basis and those with sporadic employment who struggle for caloric sufficiency within the household and have low dietary diversity. The main import of these examples is not that delocalization is universally negative, but that it tends to increase disparities of food security and nutritional status within and between social groups, with some segments suffering marked degradation of both.\nClosely linked with delocalization is food commoditization, or the treatment of food primarily as a market commodity, rather than prioritizing other uses, such as sustenance, human rights entitlement, or social relations. Dewey describes the deleterious effects of food commoditization for rural communities in Central America, to include reductions in food security and nutritional status. Much of tourism literature details marked increases in the commoditization of food subsequent to the introduction of tourism as a form of market based economic development. Dewey and Robbins also state that when food is primarily seen as a commodity by powerful interests, not only does such an ideology increase delocalization, but also land degradation and expropriation as elite land owners or transnational corporations cause massive social and ecological disruptions in the process of mono-cropping food crops over broad swaths of land in order to reap maximum profits from overseas sales. Indeed, delocalization and commoditization have significant potential to diminish food security and nutritional status in poor communities over broad areas of the world.\n\nIn terms of food security and dietary diversity, which are defined as reliable access to a caloric sufficiency and access to a wide variety of macro and micro nutrients in order to maintain nutritive balance, respectively, the commoditization of food plays a key role in diminishing the control local populations have over their own subsistence production. Delocalization of food systems, which Pelto and Pelto define as taking production of food out of a local subsistence context and tying it to geographically broader market systems, can precipitate marked cultural and nutritional disruption. Likewise commoditization of food systems, defined as a paradigm shift from one of subsistence or social significances shift toward one which treats food primarily as a market commodity, can affect dietary health as well as collective identity. Commoditization tends to shift food security and dietary diversity away from integrated kinship or other reciprocal distribution networks toward being an issue of who can best compete in a free market to achieve these ends; indeed, commoditization has often been linked to breakdowns in food entitlements, which are defined as cultural or social norms that ensure food access for all members of a given social group.\n\nThe deleterious effects of mild to moderate malnutrition (MMM) not only pertain to caloric insufficiency (often closely associated with food insecurity) but also to poor dietary diversity; in particular, curtailed access to protein, complex carbohydrates, zinc, iron, and other micronutrients. The ways in which undernutrition and micronutrient deficiency interact with other health effects are myriad. The most obvious manifestation of MMM, stunting is defined as height and or weight below the standard range for a particular age group. However, far from being a mere difference in height and weight, stunting was correlated with a wide variety of health effects. Closely related to stunting, level of physical activity closely articulates with nutritional status and affects childhood development. Chronically malnourished infants and toddlers showed decreased physical activity compared to supplemented groups or those who are adequately nourished.\n\nPerhaps, the most critical facets of human development correlated to nutrition levels are behavior and cognition; development in these two areas could have profound effects on life chances for individuals and populations. In comparing a group of southern Mexican children subject to MMM and a group in the same region who received dietary supplements, Chavez et al. show a relation between MMM and poorer school performance; unsupplemented children showed poorer participation, greater degree of in-class distraction, more sleeping in class, and poorer performance on standardized tests. In addition, malnourished children showed poorer scores on intelligence quotient (I.Q.) tests than their supplemented counterparts. \nOf all the aspects of human existence, sexual reproduction may have the most detailed articulation with malnutrition. In populations subject to MMM, menarche occurs later (15.5 years) than in adequately nourished populations; an early average menopause (40.5 years) makes for a relatively short reproductive period for women in the study area for Chavez et al. Because of longer postpartum periods of amenorrhea, birth spacing was an average of 27 months, versus 19 months. Though longer birth spacing can help control population growth, the evidence that Chavez et al. present suggest a curtailing of reproductive choice and adaptability due to malnutrition. This study also linked maternal MMM with higher infant and young child mortality.\n\nAnother effect of MMM crucial to life chances is work capacity; MMM shows a cyclical pattern of decreasing work capacity and its rewards, further exacerbating the problem. Allen found a correlation between reduced VO2 max rates among MMM populations and decreased muscular strength and endurance in the performance of strenuous manual labor. Although personal motivation can have a strong positive impact on individual work performance, better muscular development associated with a history of adequate nutrition increases overall work capacity, irrespective of effort. Among Jamaican cane cutters, those within normal size range cut more cane than those who showed stunting. One cultural variation in this trend was found among MMM Guatemalan workers who put forth work effort comparable to better nourished counterparts, but were likely to engage in resting behavior than in recreational or social activity during off hours. In wage economies where workers get paid in proportion to productive output, reduced work capacity can translate to reduced food security, increasing the risk of MMM.\nAdditionally, malnutrition and infectious disease have a synergistic relationship that can lead to spiraling health deterioration. According to Allen, the incidence of infectious disease does not vary significantly between MMM and adequately nourished populations, but the duration and severity of disease episodes is greater for MMM populations. A key reason for this disparity is that infectious disease often results in poor food intake and nutrient absorption. Not only do sick people generally eat little, but what they do eat is often of minimal benefit due to nausea and diarrhea.\n\nAside from MMM due to under-nutrition or micro-nutrient deficiency, over-nutrition, defined as the consumption of too many calories for one’s body size and physical activity level, is also becoming an increasingly significant problem for much of the World. Overnutrition has been associated with obesity, which the USDA and McEwen and Seeman correlate with increased risk of type II diabetes, cardiovascular disease, and stroke. Overnutrition is also often associated with the co-occurrence of caloric sufficiency (or over-sufficiency) and micronutrient deficiency, as is often the case where processed foods that are high in calories, but low in most nutrients, increase in dietary prominence. Leatherman and Goodman and Guest and Jones discuss the growing coincidence of stunting and other symptoms of MMM and obesity within developing nations, sometimes within the same community. This trend can be linked to changing economies and food practices in much of the World under contemporary economic globalization.\n\n"}
{"id": "43025901", "url": "https://en.wikipedia.org/wiki?curid=43025901", "title": "Pallium India", "text": "Pallium India\n\nPallium India is a national registered charitable trust formed in 2003 aimed at providing quality palliative care and effective pain relief for patients in India. Dr. M. R. Rajagopal is the founder and chairman of Pallium India. Pallium India works in collaboration with several national and international organisations to improve the accessibility and affordability of pain relief drugs (opioids) and other low-cost medicines, to ensure the availability of palliative care services in India and to improve the quality of palliative care services provided by the healthcare and allied health care professionals. In February 2016, Pallium India was accredited by Social Justice Department of Government of Kerala.\n\nPallium India's vision is an India in which palliative care is integrated in all health care so that every person has access to effective pain relief and quality palliative care along with disease–specific treatment and across the continuum of care. Pallium India's mission is to catalyze the development of effective pain relief and quality palliative care services and their integration in health care across India through delivery of services, education, building capacities, policy, research, advocacy and information.\n\nThe activities spearheaded by Pallium India concentrate mostly on areas inadequately addressed by existing organizations. Pallium India works with Central and State Governments of India for integrating palliative care into the healthcare system, facilitating palliative care education and improving access to essential and affordable medicines like morphine and other opioids.\n\nIn 2017, Pallium India opened a library dedicated to palliative care. Books were donated by Elisabeth Kübler-Ross Foundation and Dr Odette Spruyt of Peter MacCallum Cancer Centre.\n\nPallium India collaborates with the following organizations in the field of palliative care:\n\nPallium India runs home visit programs in and around Trivandrum, as well as inpatient and outpatient clinics in collaboration with different hospitals in Trivandrum. Other services include bereavement support groups, Vocational Rehabilitation Program for patients and families and education of children whose parents are under treatment by Pallium India. Services to poor patients are provided free of cost. Expenses in this regard are met by donations.\n\nTrivandrum Institute of Palliative Sciences (TIPS) is an organ of Pallium India, established in 2006. In 2012, TIPS was declared a World Health Organization Collaborating Centre (WHOCC) for Training and Policy on Access to Pain Relief. Education and research are major activities of TIPS. TIPS provides medical care (inpatient, out-patient and home care services), counselling care, rehabilitation and other supportive services.\n\nBruce Davis Training Centre (BDTC), the training division of Pallium India, runs a number of different awareness programs and trainings throughout the year with a focus on improving the general awareness among the public and improving the expertise and competency of healthcare and allied healthcare professionals. These include Certificate Course in Pain and Palliative Medicine (CCPPM) for doctors, in Palliative Nursing (CCPN) for nurses and in Palliative Care (CCPC) for allied healthcare professionals. There are also volunteer training programs conducted frequently.\n\nPallium India works with several hospitals and organizations to catalyse the development of palliative care centres across India and for introducing palliative care education to professionals.\n\nPallium India collaborates with the Department of Social Justice of Government of Kerala to improve the facilities for wheelchair-bound people in the state. This includes providing rehabilitation services and advocacy for their improved mobility, including creating pavements and buildings that are wheelchair-friendly. Pallium India regularly organizes awareness programs for the public, get-together for patients, art and craft exhibition, food festival and cultural events to spread the message of palliative care.\n\nPallium India works with Paediatric and Paediatric Neurology departments of S.A.T Hospital, Thiruvananthapuram to provide palliative care for children suffering from various illnesses. Pallium India works out of its office at Arumana Hospital, Airport Road, Subash Nagar, Vallakadavu P.O, Thiruvananthapuram – 695 008, Kerala, India.\n\nCurrently, Pallium India is advocating for a rational national legislation for end of life care, which allows natural death with dignity and in incurable diseases with access to palliative care, rather than intensive care.\n\nPallium India played a major role in the steps leading to the declaration of a National Program on Palliative care by the Government of India in 2012 November and the Amendment of Narcotic Drugs and Psychotropic Substances(NDPS) Act of India in 2014. In 2008, Pallium India initiated and followed up a proposal that resulted in the declaration of a \"Palliative Care Policy\" by the Government of Kerala, making it the first Government in a developing country to have such a policy.\n\nIn 2016, Pallium India was awarded the Cancer Aid Society Annual Award for Excellence and Leadership in Palliative Care for the South Asian Association for Regional Cooperation (SAARC) Countries. In November 2017, Pallium India was awarded Sat Paul Mittal Award of appreciation, in Ludhiana.\n\nA group of palliative care experts under the leadership of Dr M R Rajagopal, collaborated to prepare the draft curriculum for M.D. Palliative Medicine, on behalf of Medical Council of India. A curriculum that introduces palliative care to undergraduate medical and nursing education has been submitted to the Medical Council of India.\n\nPallium India has catalyzed the development of training centres offering quality education in palliative care in Trivandrum (TIPS), Hyderabad (MNJIO RCC), Jaipur (BMCHRC) and Ahmedabad (GCRI).\n\nWith financial support from international agencies, ten palliative care service centres were established in different states of India - Jharkhand, Tripura, Uttar Pradesh, Manipur, Mizoram, Bihar, Orissa, Gujarat, Meghalaya, Tamil Nadu and Lakshadweep. In collaboration with Australasian Palliative Link International (APLI), Pallium India developed a mentoring program called Project Hamrahi for budding palliative care organizations in India\n\nWorking with national and international experts, Pallium India created the National Standards tool (Minimum Standards for Palliative Care Programs) to ensure quality palliative care.\n\nAn advocacy tool initiated by Pallium India with two international partners, called 'the Morphine Manifesto', caught the attention of the international palliative care community so much that 63 international organizations signed up to be launch partners.\n\n"}
{"id": "12269905", "url": "https://en.wikipedia.org/wiki?curid=12269905", "title": "Piotr Morawski", "text": "Piotr Morawski\n\nPiotr Morawski (December 27, 1976 – April 8, 2009) was a Polish mountaineer. He was best known for making the first successful winter ascent together with Simone Moro of Shishapangma on January 14, 2005. Morawski died aged 32 during an international Dhaulagiri/Manaslu expedition in Nepal. He fell into a crevasse at an elevation of 5500 m while acclimatizing.\n\n"}
{"id": "20951784", "url": "https://en.wikipedia.org/wiki?curid=20951784", "title": "Puquios", "text": "Puquios\n\nThe puquios are an old system of subterranean aqueducts near the city of Nazca, Peru. Out of 36 puquios, most are still functioning and even relied upon to bring fresh water into the arid desert. The puquios have never been fully mapped, nor have any been excavated.\n\nResearch regarding when the aqueducts were actually built has led to conflicting results, in part due to a general lack of historical references both before and after the time of the Spanish Empire. Some archaeologists contend that they were built by Pre-Columbian Nazca architects around 540 CE in response to two prolonged droughts during that time, while others doubt that. The first historical writing of their existence was in 1605 by Reginaldo de Lizárraga, which some have contended could indicate that they were built by the Spanish. The available Spanish texts, however, do not mention a project to build the puquios, nor do the early Spanish texts describe water systems having already been in place when they conquered the territory.\n\nIn their book \"Irrigation and Society in the Peruvian Desert\", Katharina Schreiber and Josue Lancho Rojas explore puquios and show evidence that puquios were constructed by a pre-Hispanic civilization. Monica Barnes and David Fleming on the other hand, argue that Schreiber and Rojas misinterpreted evidence, presumably ignoring easier explanations for a construction in colonial times. Some investigations have been performed to determine the age of puquios by using radiocarbon dating of organic materials (Bonn-1972) and accelerator mass spectrometer to date rock varnishes. With this technique, some puquios were dated to around the 6th or 7th century CE.\n\nRosa Lasaponara, Nicola Masini, and their team of the Italian CNR (National Research Council), in cooperation with the archaeologist Giuseppe Orefici, studied the puquios using satellite imaging. They found clear evidence that the puquio system must previously have been much more developed than it appears today. A series of canals was used to bring to the surface water from underground aquifers and channel it to the areas where it was needed. Any excess was stored in surface reservoirs. To help keep the water flowing, chimneys were excavated above the canals in the shape of corkscrewing funnels. These funnels admitted wind into the canals, and the difference in atmospheric pressure along the canal length forced the water through the system and eventually to the desired destination. Satellite imagery also revealed additional previously unknown puquios in the Nasca drainage basin.\n\n\n"}
{"id": "2244264", "url": "https://en.wikipedia.org/wiki?curid=2244264", "title": "Rat-bite fever", "text": "Rat-bite fever\n\nRat-bite fever is an acute, febrile human illness caused by bacteria transmitted by rodents, in most cases, which is passed from rodent to human by the rodent's urine or mucous secretions. Alternative names for rat-bite fever include streptobacillary fever, streptobacillosis, spirillary fever, bogger, and epidemic arthritic erythema. It is a rare disease spread by infected rodents and can be caused by two specific types of bacteria. Most cases occur in Japan, but specific strains of the disease are present in the United States, Europe, Australia, and Africa.\nSome cases are diagnosed after patients were exposed to the urine or bodily secretions of an infected animal. These secretions can come from the mouth, nose, or eyes of the rodent. The majority of cases are due to the animal's bite. It can also be transmitted through food or water contaminated with rat feces or urine. Other animals can be infected with this disease, including weasels, gerbils, and squirrels. Household pets such as dogs or cats exposed to these animals can also carry the disease and infect humans.\nIf a person is bitten by a rodent, it is important to quickly wash and cleanse the wound area thoroughly with antiseptic solution to reduce the risk of infection.\n\nSymptoms are different for every person depending on the type of rat-bite fever with which the person is infected. Both spirillary and streptobacillary rat-bite fever have a few individual symptoms, although most symptoms are shared. Streptobacillosis is most commonly found in the United States and spirillary rat-bite fever is generally diagnosed in patients in Africa. Rat-bite symptoms are visually seen in most cases and include inflammation around the open sore. A rash can also spread around the area and appear red or purple. Other symptoms associated with streptobacillary rat-bite fever include chills, fever, vomiting, headaches, and muscle aches. Joints can also become painfully swollen and pain can be experienced in the back. Skin irritations such as ulcers or inflammation can develop on the hands and feet. Wounds heal slowly, so symptoms possibly come and go over the course of a few months.\n\nSymptoms associated with spirillary rat-bite fever include issues with the lymph nodes, which often swell or become inflamed as a reaction to the infection. The most common locations of lymph node swelling are in the neck, groin, and underarm. Symptoms generally appear within 2 to 10 days of exposure to the infected animal. It begins with the fever and progresses to the rash on the hands and feet within 2 to 4 days. Rash appears all over the body with this form, but rarely causes joint pain.\n\nTwo types of Gram-negative, facultatively anaerobic bacteria can cause the infection.\n\nRat-bite fever transmitted by the Gram-negative coiled rod \"Spirillum minus\" (also known as \"Spirillum minor\") is more rare, and is found most often in Asia. In Japan, the disease is called \"sodoku\". Symptoms do not manifest for two to four weeks after exposure to the organism, and the wound through which it entered exhibits slow healing and marked inflammation. The fever lasts longer and is recurring, for months in some cases. Rectal pain and gastrointestinal symptoms are less severe or are absent. Penicillin is the most common treatment.\n\nThe streptobacillosis form of rat-bite fever is known by the alternative names Haverhill fever and epidemic arthritic erythema. It is a severe disease caused by \"Streptobacillus moniliformis\", transmitted either by rat bite or ingestion of contaminated products (Haverhill fever). After an incubation period of 2–10 days, Haverhill fever begins with high prostrating fevers, rigors (shivering), headache, and polyarthralgia (joint pain). Soon, an exanthem (widespread rash) appears, either maculopapular (flat red with bumps) or petechial (red or purple spots) and arthritis of large joints can be seen. The organism can be cultivated in blood or articular fluid. The disease can be fatal if untreated in 20% of cases due to malignant endocarditis, meningoencephalitis, or septic shock. Treatment is with penicillin, tetracycline, or doxycycline.\n\nThis condition is diagnosed by detecting the bacteria in skin, blood, joint fluid, or lymph nodes. Blood antibody tests may also be used. To get a proper diagnosis for rat-bite fever, different tests are run depending on the symptoms being experienced.\n\nTo diagnosis streptobacillary rat-bite fever, blood or joint fluid is extracted and the organisms living in it are cultured. Diagnosis for spirillary rat bite fever is by direct visualization or culture of spirilla from blood smears or tissue from lesions or lymph nodes. Treatment with antibiotics is the same for both types of infection. The condition responds to penicillin, and where allergies to it occur, erythromycin or tetracyclines are used.\n\nWhile obviously preventable by staying away from rodents, otherwise hands and face should be washed after contact and any scratches both cleaned and antiseptics applied. The effect of chemoprophylaxis following rodent bites or scratches on the disease is unknown. No vaccines are available for these diseases.\nImproved conditions to minimize rodent contact with humans are the best preventive measures. Animal handlers, laboratory workers, and sanitation and sewer workers must take special precautions against exposure. Wild rodents, dead or alive, should not be touched and pets must not be allowed to ingest rodents.\nThose living in the inner cities where overcrowding and poor sanitation cause rodent problems are at risk from the disease. Half of all cases reported are children under 12 living in these conditions.\n\nWhen proper treatment is provided for patients with rat-bite fever, the prognosis is positive. Without treatment, the infection usually resolves on its own, although it may take up to a year to do so. A particular strain of rat-bite fever in the United States can progress and cause serious complications that can be potentially fatal. Before antibiotics were used, many cases resulted in death. If left untreated, streptobacillary rat-bite fever can result in infection in the lining of the heart, covering over the spinal cord and brain, or in the lungs. Any tissue or organ throughout the body may develop an abscess.\n\n"}
{"id": "37313606", "url": "https://en.wikipedia.org/wiki?curid=37313606", "title": "Relaxin family peptide hormones", "text": "Relaxin family peptide hormones\n\nRelaxin family peptide hormones in humans are represented by 7 members: three relaxin-like (RLN) and four insulin-like (INSL) peptides. This subdivision into 2 classes (RLN and INSL) is based primarily on early findings, and does not reflect the evolutionary origins or physiological differences between peptides. For example, it is known that the genes coding for RLN3 and INSL5 arose from one ancestral gene, and INSL3 shares origin with RLN2 and its multiple duplicates (e.g. RLN1, INSL4, INSL6).\n\nIn humans and many other tetrapods, the RLN/INSL-encoding genes exist in 4 distinct clusters. The largest cluster contains 4 loci: RLN1, RLN2, INSL4 and INSL6, situated in tandem on human chromosome 9 (chromosome 9). This cluster arose from multiple local gene duplications that took place in the ancestor of placental mammals. The other three RLN/INSL genes exist as single loci in two linkage groups: RLN3 (chromosome 19), INSL3 (chromosome 19, 3.8 Mb apart from RLN3) and INSL5 (chromosome 1).\n\nThe physiological action of RLN and its tandem duplicates (RLN1, INSL4, INSL6) and INSL3 has been quite well studied in human and mouse- they are primarily associated with reproductive functions, such as the relaxation of uterine musculature and of the pubic symphysis during labor (RLN1 & RLN2), the progression of spermatogenesis (INSL6) and possibly trophoblast development (INSL4) and testicular descent and germ cell survival (INSL3), but the functions of INSL5 and RLN3 are relatively unexplored. Both RLN3 and INSL5 are thought to play important roles in neuroendocrine regulation. In the case of INSL5 this hypothesis is based on its expression (and also co-expression with its receptor) in the central nervous system (CNS), intestine and lymph nodes. At the same time, RLN3 is predominantly localized in the brain and locally affects selected regions of the CNS, such as those responsible for the sense of appetite and stress regulation. Moreover, it has been shown that RLN3 stimulates the hypothalamic-pituitary-gonadal (HPG) axis and hence affects levels of luteinizing hormone (LH) in the blood.\n\nData available on the functions of relaxin family peptides in vertebrates other than human are very fragmented.\n\nThe receptors for the RLN/INSL peptides are collectively called “Relaxin family peptide receptors (RXFPs)”. There are two distinct families of RXFPs, all of which are cell membrane-associated and coupled to G-proteins (known as G protein-coupled receptors or GPCRs). In humans there are 4 RXFP receptors: RXFP1 and RXFP2 are evolutionarily related to the receptors of follicle-stimulating and luteinizing hormones (FSH and LH, respectively), and are the cognate receptors for RLN and INSL3 respectively in humans . On the other hand, RXFP3 and RXFP4 are related to somatostatin et al. and, in humans, are the cognate receptors for RLN3 and INSL5. There is evidence that some relaxin hormones may also be able to interact with glucocorticoid-type nuclear receptors, which are found floating freely between the cytoplasm and nucleoplasm.\n\nFour RXFPs in humans are located in different linkage groups. Additionally there are two RXFP pseudogenes (\"RXFP3-3\" and \"RXFP2-like\") which have functional counterparts in other species.\n\nThe evolution of the gene family in primitive vertebrates is not well understood. For example, it has been shown that the gene coding for the ancestral relaxin peptide existed independently from the other genes of the insulin superfamily, i.e. INS and IGF genes, in the early chordate ancestor. \nIt is known that the genes coding for RLN3 and INSL5 arose from one ancestral gene, and INSL3 shares origin with RLN2 and its multiple duplicates. However the exact origins of the family still remain to be elucidated. Other studies attempted to show the existence of relaxin family peptide genes in the tunicate Ciona, but it has not been shown that any of these are in the same linkage group as modern relaxin genes. Multiple relaxin genes have also been identified in Amphioxus, but again syntenic relationship of these genes to modern relaxin genes is unclear and experimental work is lacking. A relaxin-like peptide, previously referred to as “Gonad Stimulating Substance” was also characterized in the echinoderm Patiria pectinifera (starfish). There is evidence that the starfish peptide is involved in reproductive processes and functions via a G-protein coupled receptor, which supports its relatedness to vertebrate relaxins.\n\nRelaxin peptides and their receptors are an example of vigorously diversified ligand-receptor systems in vertebrates. The number of peptides and their receptors is varied among vertebrates due to lineage specific gene loss and duplications For example, teleost fish have almost twice as many relaxin family peptide receptors compared to humans, which is attributable to the Fish-Specific Whole Genome Duplication and teleost-specific gene duplication.\n\n"}
{"id": "35672535", "url": "https://en.wikipedia.org/wiki?curid=35672535", "title": "Rotaviral gastroenteritis", "text": "Rotaviral gastroenteritis\n\nRotavirus enteritis is the most common cause of severe diarrhoea among infants and young children. It is caused by Rotavirus, a genus of double-stranded RNA virus in the family \"Reoviridae\". By the age of five, nearly every child in the world has been infected with rotavirus at least once. However, with each infection, immunity develops, and subsequent infections are less severe; adults are rarely affected. There are five species of this virus, referred to as A, B, C, D, and E. Rotavirus A, the most common, causes more than 90% of infections in humans.\n\nThe virus is transmitted by the faecal-oral route. It infects and damages the cells that line the small intestine and causes gastroenteritis (which is often called \"stomach flu\" despite having no relation to influenza). Although rotavirus was discovered in 1973 and accounts for up to 50% of hospitalisations for severe diarrhoea in infants and children, its importance is still not widely known within the public health community, particularly in developing countries. In addition to its impact on human health, rotavirus also infects animals, and is a pathogen of livestock.\n\nRotavirus is usually an easily managed disease of childhood, but worldwide nearly 500,000 children under five years of age still die from rotavirus infection each year and almost two million more become severely ill. In the United States, before initiation of the rotavirus vaccination programme, rotavirus caused about 2.7 million cases of severe gastroenteritis in children, almost 60,000 hospitalisations, and around 37 deaths each year. Public health campaigns to combat rotavirus focus on providing oral rehydration therapy for infected children and vaccination to prevent the disease. The incidence and severity of rotavirus infections has declined significantly in countries that have added rotavirus vaccine to their routine childhood immunisation policies.\n\nRotavirus gastroenteritis is a mild to severe disease characterised by vomiting, watery diarrhoea, and low-grade fever. Once a child is infected by the virus, there is an incubation period of about two days before symptoms appear. Symptoms often start with vomiting followed by four to eight days of profuse diarrhoea. Dehydration is more common in rotavirus infection than in most of those caused by bacterial pathogens, and is the most common cause of death related to rotavirus infection.\n\nRotavirus A infections can occur throughout life: the first usually produces symptoms, but subsequent infections are typically mild or asymptomatic, as the immune system provides some protection. Consequently, symptomatic infection rates are highest in children under two years of age and decrease progressively towards 45 years of age. Infection in newborn children, although common, is often associated with mild or asymptomatic disease; the most severe symptoms tend to occur in children six months to two years of age, the elderly, and those with compromised or absent immune system functions. Due to immunity acquired in childhood, most adults are not susceptible to rotavirus; gastroenteritis in adults usually has a cause other than rotavirus, but asymptomatic infections in adults may maintain the transmission of infection in the community.\n\nRotavirus is transmitted by the faecal-oral route, via contact with contaminated hands, surfaces and objects, and possibly by the respiratory route. The faeces of an infected person can contain more than 10 trillion infectious particles per gram; fewer than 100 of these are required to transmit infection to another person.\n\nRotaviruses are stable in the environment and have been found in estuary samples at levels as high as 1–5 infectious particles per US gallon. Sanitary measures adequate for eliminating bacteria and parasites seem to be ineffective in control of rotavirus, as the incidence of rotavirus infection in countries with high and low health standards is similar.\n\nThere are five species of rotavirus, referred to as A, B, C, D and E. Humans are primarily infected by species A, B and C, most commonly by species A. All five species cause disease in other animals.\nWithin rotavirus A there are different strains, called serotypes. As with influenza virus, a dual classification system is used based on two proteins on the surface of the virus. The glycoprotein VP7 defines the G serotypes and the protease-sensitive protein VP4 defines P serotypes. Because the two genes that determine G-types and P-types can be passed on separately to progeny viruses, different combinations are found.\n\nRotaviruses replicate mainly in the gut, and infect enterocytes of the villi of the small intestine, leading to structural and functional changes of the epithelium. The triple protein coats make them resistant to the acidic pH of the stomach and the digestive enzymes in the gut.\n\nThe virus enter cells by receptor mediated endocytosis and form a vesicle known as an endosome. Proteins in the third layer (VP7 and the VP4 spike) disrupt the membrane of the endosome, creating a difference in the calcium concentration. This causes the breakdown of VP7 trimers into single protein subunits, leaving the VP2 and VP6 protein coats around the viral dsRNA, forming a double-layered particle (DLP).\n\nThe eleven dsRNA strands remain within the protection of the two protein shells and the viral RNA-dependent RNA polymerasecreates mRNA transcripts of the double-stranded viral genome. By remaining in the core, the viral RNA evades innate host immune responses called RNA interference that are triggered by the presence of double-stranded RNA.\n\nDuring the infection, rotavirus produces mRNA for both protein biosynthesis and gene replication. Most of the rotavirus proteins accumulate in viroplasm, where the RNA is replicated and the DLPs are assembled. Viroplasm is formed around the cell nucleus as early as two hours after virus infection, and consists of viral factories thought to be made by two viral nonstructural proteins: NSP5 and NSP2. Inhibition of NSP5 by RNA interference results in a sharp decrease in rotavirus replication. The DLPs migrate to the endoplasmic reticulum where they obtain their third, outer layer (formed by VP7 and VP4). The progeny viruses are released from the cell by lysis.\n\nThe diarrhoea is caused by multiple activities of the virus. Malabsorption occurs because of the destruction of gut cells called enterocytes. The toxic rotavirus protein NSP4 induces age- and calcium ion-dependent chloride secretion, disrupts SGLT1 transporter-mediated reabsorption of water, apparently reduces activity of brush-border membrane disaccharidases, and possibly activates the calcium ion-dependent secretory reflexes of the enteric nervous system. Healthy enterocytes secrete lactase into the small intestine; milk intolerance due to lactase deficiency is a symptom of rotavirus infection, which can persist for weeks. A recurrence of mild diarrhoea often follows the reintroduction of milk into the child's diet, due to bacterial fermentation of the disaccharide lactose in the gut.\n\nDiagnosis of infection with rotavirus normally follows diagnosis of gastroenteritis as the cause of severe diarrhoea. Most children admitted to hospital with gastroenteritis are tested for \nSpecific diagnosis of infection with is made by finding the virus in the child's stool by enzyme immunoassay. There are several licensed test kits on the market which are sensitive, specific and detect all serotypes of . Other methods, such as electron microscopy and PCR, are used in research laboratories. Reverse transcription-polymerase chain reaction (RT-PCR) can detect and identify all species and serotypes of human rotavirus.\n\nBecause improved sanitation does not decrease the prevalence of rotaviral disease, and the rate of hospitalisations remains high, despite the use of oral rehydrating medicines, the primary public health intervention is vaccination. Two rotavirus vaccines against Rotavirus A infection are safe and effective in children: Rotarix by GlaxoSmithKline and RotaTeq by Merck. Both are taken orally and contain attenuated live virus.\n\nRotavirus vaccines are licensed in more than 100 countries, but only 17 countries have introduced routine rotavirus vaccination. Following the introduction of routine rotavirus vaccination in the US in 2006, the health burden of rotavirus gastroenteritis \"rapidly and dramatically reduced\" despite lower coverage levels compared to other routine infant immunizations. Clinical trials of the Rotarix rotavirus vaccine in South Africa and Malawi, found that the vaccine significantly reduced severe diarrhoea episodes caused by rotavirus, and that the infection was preventable by vaccination. A 2012 Cochrane review of 41 clinical trials that included 186,263 participants concluded Rotarix and RotaTeq are effective vaccines. Additional rotavirus vaccines are under development. The World Health Organization(WHO) recommends that rotavirus vaccine be included in all national immunisation programmes. The incidence and severity of rotavirus infections has declined significantly in countries that have acted on this recommendation.\n\nThe Rotavirus Vaccine Program is a collaboration between PATH, the (WHO), and the U.S. Centers for Disease Control and Prevention, and is funded by the GAVI Alliance. The Program aims to reduce child morbidity and mortality from diarrhoeal disease by making a vaccine against rotavirus available for use in developing countries.\n\nTreatment of acute rotavirus infection is nonspecific and involves management of symptoms and, most importantly, maintenance of hydration. If untreated, children can die from the resulting severe dehydration. Depending on the severity of diarrhea, treatment consists of oral rehydration, during which the child is given extra water to drink that contains small amounts of salt and sugar. Some infections are serious enough to warrant hospitalisation where fluids are given by intravenous drip or nasogastric tube, and the child's electrolytes and blood sugar are monitored. Antibiotics are not recommended.\n\nRotavirus infections rarely cause other complications and for a well managed child the prognosis is excellent.\n\nRotavirus A, which accounts for more than 90% of rotavirus gastroenteritis in humans, is endemic worldwide. Each year rotavirus causes millions of cases of diarrhoea in developing countries, almost 2 million resulting in hospitalisation and an estimated 453,000 resulting in the death of a child younger than five. This is about 40 per cent of all hospital admissions related to diarrhea in children under five worldwide.\n\nIn the United States alone—before initiation of the rotavirus vaccination programme—over 2.7 million cases of rotavirus gastroenteritis occurred annually, 60,000 children were hospitalised and around 37 died from the results of the infection. The major role of rotavirus in causing diarrhoea is not widely recognised within the public health community, particularly in developing countries. Almost every child has been infected with rotavirus by age five. It is the leading single cause of severe diarrhoea among infants and children, being responsible for about 20% of cases, and accounts for 50% of the cases requiring hospitalisation. Rotavirus causes 37% of deaths attributable to diarrhoea and 5% of all deaths in children younger than five. Boys are twice as likely as girls to be admitted to hospital.\nRotavirus infections occur primarily during cool, dry seasons. The number attributable to food contamination is unknown.\n\nOutbreaks of rotavirus A diarrhoea are common among hospitalised infants, young children attending day care centres, and elderly people in nursing homes. An outbreak caused by contaminated municipal water occurred in Colorado in 1981.\nDuring 2005, the largest recorded epidemic of diarrhoea occurred in Nicaragua. This unusually large and severe outbreak was associated with mutations in the rotavirus A genome, possibly helping the virus escape the prevalent immunity in the population. A similar large outbreak occurred in Brazil in 1977.\n\nRotavirus B, also called adult diarrhoea rotavirus or ADRV, has caused major epidemics of severe diarrhoea affecting thousands of people of all ages in China. These epidemics occurred as a result of sewage contamination of drinking water. Rotavirus B infections also occurred in India in 1998; the causative strain was named CAL. Unlike ADRV, the CAL strain is endemic. To date, epidemics caused by rotavirus B have been confined to mainland China, and surveys indicate a lack of immunity to this species in the United States.\n\nIn 1943, Jacob Light and Horace Hodes proved that a filterable agent in the faeces of children with infectious diarrhoea also caused scours (livestock diarrhoea) in cattle. Three decades later, preserved samples of the agent were shown to be rotavirus. In the intervening years, a virus in mice was shown to be related to the virus causing scours. In 1973, Ruth Bishop and colleagues described related viruses found in children with gastroenteritis.\n\nIn 1974, Thomas Henry Flewett suggested the name \"rotavirus\" after observing that, when viewed through an electron microscope, a rotavirus particle looks like a wheel (\"rota\" in Latin); the name was officially recognised by the International Committee on Taxonomy of Viruses four years later. In 1976, related viruses were described in several other species of animals. These viruses, all causing acute gastroenteritis, were recognised as a collective pathogen affecting humans and animals worldwide. Rotavirus serotypes were first described in 1980, and in the following year, rotavirus from humans was first grown in cell cultures derived from monkey kidneys, by adding trypsin (an enzyme found in the duodenum of mammals and now known to be essential for rotavirus to replicate) to the culture medium. The ability to grow rotavirus in culture accelerated the pace of research, and by the mid-1980s the first candidate vaccines were being evaluated.\n\nIn 1998, a rotavirus vaccine was licensed for use in the United States. Clinical trials in the United States, Finland, and Venezuela had found it to be 80 to 100% effective at preventing severe diarrhoea caused by rotavirus A, and researchers had detected no statistically significant serious adverse effects. The manufacturer, however, withdrew it from the market in 1999, after it was discovered that the vaccine may have contributed to an increased risk for intussusception, a type of bowel obstruction, in one of every 12,000 vaccinated infants. The experience provoked intense debate about the relative risks and benefits of a rotavirus vaccine.\nIn 2006, two new vaccines against infection were shown to be safe and effective in children, and in June 2009 the World Health Organization recommended that rotavirus vaccination be included in all national immunisation programmes to provide protection against this virus.\n\nRotaviruses infect the young of many species of animals and they are a major cause of diarrhoea in wild and reared animals worldwide. As a pathogen of livestock, notably in young calves and piglets, rotaviruses cause economic loss to farmers because of costs of treatment associated with high morbidity and mortality rates. These rotaviruses are a potential reservoir for genetic exchange with human rotaviruses. There is evidence that animal rotaviruses can infect humans, either by direct transmission of the virus or by contributing one or several RNA segments to reassortants with human strains.\n"}
{"id": "18107778", "url": "https://en.wikipedia.org/wiki?curid=18107778", "title": "Royal Tru", "text": "Royal Tru\n\nRoyal Tru (often referred to simply as Royal) is a carbonated fruit-flavored soft drink brand owned by The Coca-Cola Company that is only available in the Philippines. The brand was introduced in 1922 by the original San Miguel Brewery. Since being acquired by Coca-Cola's Philippine unit in 2007, the brand has become the Philippine counterpart of Coca-Cola's Fanta brand.\n\nThe brand was first introduced in the 1922 by the original San Miguel Brewery as its first non-alcoholic, carbonated beverage. In 1927, San Miguel became the first international bottler of Coca-Cola. The brand became best associated with its orange-flavored soft drink, Royal Tru-Orange.\n\nIn 1981, San Miguel spun off its soft drink business (its Coca-Cola franchise and the manufacture of Royal beverages) to a new company known as Coca-Cola Bottlers Philippines, Inc. (CCBPI), a joint-venture with The Coca-Cola Company. The brand continued to be owned by San Miguel until 2007, when San Miguel sold the rights to the brand along with its entire interest in CCBPI to The Coca-Cola Company. CCBPI was renamed Coca-Cola FEMSA Philippines, Inc. since January 2013 after the entry of Mexico-based Coca-Cola FEMSA S.A. de C.V. \n\n\n\nThe beverage targets teenagers as its consumers. The product was available during the 1970s in single-serve bottles and contained orange \"pulp bits\" (pulp) \"from California Valencia oranges\".\n\nWhen San Miguel Corporation became one of the founding members of the Philippine Basketball Association in 1975, its basketball franchise played under the name \"Royal Tru-Orange\" from 1975 to 1980.\n\nRoyal Tru-Orange gained much attention in the mid-1980's following the restoration of democracy in the Philippines, after its logo and formulation (now without the orange pulp) were changed through an advertising campaign that starred teen model RJ Ledesma (playing the role of \"Joey\"). The first television advertisement in the series, wherein Joey was being egged on by friends to introduce himself to a girl named Jenny, was directed by noted film director Lino Brocka.\n\n\nRoyal Tru-Orange was one of 300 products of the Philippines barred by the U.S. Food and Drug Administration in 2004 from entering the United States due to \"failure to meet its requirements.\n"}
{"id": "22802779", "url": "https://en.wikipedia.org/wiki?curid=22802779", "title": "Sedation dentistry", "text": "Sedation dentistry\n\nSedation dentistry refers to the use of pharmacological agents to calm and relax a patient prior to and during a dental appointment. The pharmacological agents usually belong to a class of drugs called sedatives, which exert their action by depressing the central nervous system, specifically those areas concerned with conscious awareness.\n\nThere are different degrees of central nervous system depression, each corresponding to a level of relaxation which ranges from minimal, moderate, to deep sedation. In general, minimal sedation refers to a patient who has reduced anxiety but readily responds to verbal or physical stimulation. With moderate sedation the patient is even more relaxed, and will respond to purposeful stimulation. In deep sedation, the patient may not exhibit any signs of consciousness and therefore be unresponsive to stimulation.\n\nSedation by pharmacologic methods may be obtained by two general routes. The enteral route involves absorption of medication across enteric membranes which line the alimentary canal from the oral cavity, through the digestive tract, ending in the rectum. This route includes medications that are either swallowed, absorbed through the mucosa of the oral cavity, or inserted rectally. The parenteral route involves the administration of sedative drugs other than absorption across enteric membranes (outside of the alimentary canal). These methods include intravenous, inhalation, intramuscular, and submucosal administration, among others.\n\nSedation dentistry has become popular because it offers benefits for both the patient and the dentist. For some patient groups, the use of sedation dentistry is the only way that they can get the dental care they need and improve their dental health. Dental sedation can offer:\n"}
{"id": "37032258", "url": "https://en.wikipedia.org/wiki?curid=37032258", "title": "Ship Sanitation Certificate", "text": "Ship Sanitation Certificate\n\nA Ship Sanitation Certificate is a document that corroborates a ship's compliance with maritime sanitation and quarantine rules specified in article 39 of the International Health Regulations (2005) issued by the World Health Organization. The certificate serves as proof that the ship is free of clear sources of contagion and may be a requirement for permission of entry into port in some jurisdictions. \n\nSSC's are issued by competent health authorities in authorized ports, after inspection. Certificates are valid for six months, revocable if evidence of health risks are found, and the ship remains liable to further inspection at all times.\n\nShip sanitation certificates can be of two types: Ship Sanitation Control Exemption Certificates (SSCEC) are issued to vessels that have passed flying fists that verifies that the ship is free of animal vectors, potential disease reservoirs or ill humans. Ship Sanitation Control Certificates (SSCC) are issued when a health risk is found, and control measures (fumigation, etc.) have been successfully carried out.\n\nThe Ship Sanitation Certificates replaced the older Deratting Certificates in 2007.\n"}
{"id": "36374631", "url": "https://en.wikipedia.org/wiki?curid=36374631", "title": "Skill mix", "text": "Skill mix\n\nSkill mix is the combination or grouping of different categories of workers that is employed in any field of work. In the context of health care provision it can be applied to broad (e.g. national) macro level planning or micro level in the context of local service delivery.\n\nIn the context of health care provision, it can refer to:\n"}
{"id": "28353208", "url": "https://en.wikipedia.org/wiki?curid=28353208", "title": "Smoking in Iceland", "text": "Smoking in Iceland\n\nSmoking in Iceland is banned in restaurants, cafés, bars and night clubs as of June 2007. A large majority of Icelanders approve of the ban. At the time the ban went into effect, almost one in four Icelandic people were smokers.\n\nIceland has the third highest proportion of people who never smoke at 81%, when compared to other European countries. \n\nIn 1971, Iceland because the first country to ban tobacco advertising in the mass media, movie theaters, and outdoors. In addition, the country required that 0.2% of tobacco sales were diverted towards tobacco control. \n\nIn 1977 all remaining tobacco promotion was banned.\n\nIn 1984 the first full length Tobacco Control Act passed making warning labels on packages mandatory, sales to those under 16-years of age banned, and smoking in certain public locations prohibited. \n\nChanges to this Tobacco Control Act includes provisions on help for quitting and more smoking bans in public locations. \n\nIn 2001, all mass coverage of tobacco products was banned and it is required that these products are not visible at the point of sale. \nThe average cost for a 20-pack of cigarettes falls around 1,300.00 kr, or $10.45 USD. \n\nThe price of the lowest cost cigarettes, as of 2016-17 is the brand American Legend, priced at 1055.00 ISK, or $8.49 USD per pack of 20 cigarettes. \n\nThe price of the highest cost, or premium cigarettes, as of 2016-17 is the brand Winston Classic Red, priced at 1271.00 ISK, or $10.22 USD per pack of 20 cigarettes.\n\nTo legally buy cigarettes in Iceland you need to be at least 18 years of age. In addition, cigarettes are not allowed to be sold in vending machines and instead are most likely to be found in convenience stores and gas stations. \n\nSmoking is heavily restricted in restaurants, nightclubs, bars, and other public places. Smoking in taxis, buses, healthcare facilities, educational facilities, and private worksites is banned. \n\nTobacco companies are required to have a health warning or message on their packaging what describes the harmful effects of tobacco use. These warnings must not be obscured in any way and must include a photo or graphic. The law requires that 30% of the front and 35% of the rear of tobacco packages must be covered in health warnings. As of January 2013, 14 new warnings must be regularly rotated. \n\nAccording to the Regulation No. 790 of 2011 on Picture and Text Warnings on Tobacco, article 3, these 14 warmings include: \n\n\nThese packages are also required to contain one of the following warnings: \n\n\nTobacco companies are banned from advertising in certain locations to certain audiences, these direct bans include: national TV and radio, local magazines and newspapers, billboard and outdoor ads, and ads on the Internet. Other indirect bans include: free distribution, promotional discounts, and product placement or appearance in TV and films. Sponsored advertising of events as well as sponsorship or promotion for certain audiences is banned as well.\n\nTobacco products sold in Iceland cannot contain more than 10mg of Tar, 1mg of Nicotine, and 10 mg of Carbon Monoxide per cigarette. \nIn Iceland there isn't much of a difference between gender in respect to smoking rates: according to the WHO, 15% of adult women are reported to take part, while similarly 15.3% of adult men admit to smoking regularly.\n\nThose with higher income are reportedly less likely to smoke. \nTobacco in Iceland is regulated mainly under the Tobacco Control Act of 2002, with the most recent amendment being in 2013. These laws cover the environments in which smoking is allowed or prohibited, tobacco advertising, promotion, sponsorship, and packaging and labeling. \n\nIn a nation-wide effort to lower the amount of teen drug and tobacco use, Icelandic governments not only restricted the age to purchase cigarettes in their country, but imposed a curfew and introduced classes in music, dance, and martial arts to their youth. This effort was made in an attempt to offer teens a \"natural high alternative\" to drug use. Between 1998 and 2016 the percentage of 15 to 16-year-olds smoking daily fell from 23% to only 3%. \n\nAccording to a study done by Iceland’s Directorate of Health, around 10,700 Icelanders use e-cigarettes daily. This number equals approximately 5% of the total population, and is greatest among individuals younger than 35 years of age. \n\nThe last reported amount in 2008 states that government expenditures on tobacco control equal approximately 70,000,000 ISK, or $562,610.87 USD. \n\nToll-free telephone helplines are available for help and information on quitting throughout the country. Nicotine replacement treatments are available for legal purchase without a prescription, and are not covered by federal or national health insurance. Other treatments such as Bupropion and Varenicline are also sold legally; however, a prescription is required and the cost is also not covered by federal or national health insurance.\n"}
{"id": "18369506", "url": "https://en.wikipedia.org/wiki?curid=18369506", "title": "Social Science &amp; Medicine", "text": "Social Science &amp; Medicine\n\nSocial Science & Medicine is a peer-reviewed academic journal covering social science research on health, including anthropology, economics, geography, psychology, social epidemiology, social policy, sociology, medicine and health care practice, policy, and organization. It was established in 1967 and is published by Elsevier.\n\n\"Social Science & Medicine\" () was published quarterly from 1967 to 1977 by Pergamon Press and, according to the National Library of Medicine and the Library of Congress, was then split into:\n\n\nIn 1982, Parts A-F were merged back into one journal. It was published by Pergamon Press, until that company was acquired by Elsevier in 1992.\n\n2012 to Current – Ichiro Kawachi and S.V. Subramanian, both at Harvard T.H. Chan School of Public Health, US. \n\n2004 to 2012 – Ellen Annandale, currently Department of Sociology, University of York, UK.\n\n1995 to 2004 - Sally Macintyre, MRC / CSO Social and Public Health Sciences Unit, University of Glasgow, UK.\n\n1967 to 1995 - Peter J. M. McEwan (Founding Editor).\n\nThe journal is abstracted and indexed in:\n\nAccording to the \"Journal Citation Reports\", the journal has a 2012 impact factor of 2.733.\n\n"}
{"id": "55012233", "url": "https://en.wikipedia.org/wiki?curid=55012233", "title": "Spain at the Deaflympics", "text": "Spain at the Deaflympics\n\nSpain competed at the inaugural edition of the Deaflympics in 1957. But they did not participate in a Deaflympics competition until 1973. Since then Spain has been regularly participating at the Deaflympics. Spain won its first Deaflympics medal way back in 1981.\n\nSpain has competed at the Winter Deaflympics in 1985 and in 2015.\n\n"}
{"id": "43467592", "url": "https://en.wikipedia.org/wiki?curid=43467592", "title": "Spoon theory", "text": "Spoon theory\n\nThe spoon theory is a disability metaphor and neologism used to explain the reduced amount of energy available for activities of living and productive tasks that may result from disability or chronic illness. Spoons are a visual representation used as a unit of measure in order to quantify how much energy a person has throughout a given day. Each activity requires a given number of spoons, which will only be replaced as the person \"recharges\" through rest. A person who runs out of spoons has no choice but to rest until their spoons are replenished.\n\nThis metaphor is used to describe the planning that many people have to do to conserve and ration their energy reserves to accomplish their activities of daily living. The planning and rationing of energy-consuming tasks has been described as being a major concern of those with chronic and fatigue-related diseases, illness, or conditions. The theory explains the difference between those who don't seem to have energy limits and those that do. The theory is used to facilitate discussions between those with limited energy reserves and those without. Because healthy people typically are not concerned with the energy expended during ordinary tasks such as bathing and getting dressed, the theory helps healthy people realize the amount of energy expended by chronically ill or disabled people to get through the day.\n\nSpoons are widely discussed within autoimmune, disability, mental and other chronic illness online communities, as an emic descriptor. The term \"spoonie\" is sometimes used to refer to a person with a chronic illness that can be explained with the spoon theory.\n\nThe term \"spoons\" was coined by Christine Miserandino in 2003 in her essay \"The Spoon Theory\". The essay describes a conversation between Miserandino and a friend. The discussion was initiated by a question from the friend in which she asked about what having lupus feels like. The essay then describes the actions of Miserandino who took spoons from nearby tables to use as a visual aid. She handed her friend twelve spoons and asked her to describe the events of a typical day, taking a spoon away for each activity. In this way, she demonstrated that her spoons, or units of energy, must be rationed to avoid running out before the end of the day. Miserandino also asserted that it is possible to exceed one's daily limit, but that doing so means borrowing from the future and may result in not having enough spoons the next day. Miserandino suggested the spoon theory can describe the effects of mental illnesses as well.\n\nAccording to the spoon theory, spoons (units of energy) may be replaced after rest or a night of sleep. However, people with chronic diseases, such as autoimmune diseases, and various disabilities may have sleep difficulties. This can result in a particularly low supply of energy. Some disabled people may not be fatigued by the disabilities themselves, but by the constant effort required to pass as non-disabled.\n\n"}
{"id": "59156197", "url": "https://en.wikipedia.org/wiki?curid=59156197", "title": "Steven Beach", "text": "Steven Beach\n\nSteven R. H. Beach (born May 29, 1956) is Distinguished Research Professor in the Department of Psychology at the University of Georgia, where he also serves as co-director of the Center for Family Research. He is known for his research on marriage and depression.\n\n"}
{"id": "23666630", "url": "https://en.wikipedia.org/wiki?curid=23666630", "title": "Sulejowski Reservoir", "text": "Sulejowski Reservoir\n\nThe Sulejowski Reservoir (, ) is an artificial lake, a reservoir created by a dam, in the Łódź Voivodeship, built in the years 1969-1974 within the territories of three local gminas: Tomaszów, Piotrków and Wolbórz. The aim of this reservoir was to supply a fresh drinking water to the city of Łódź and Tomaszów Mazowiecki. At full capacity the reservoir contains up to 95 million m of water and has an average depth of 3.3m.\n\nThe reservoir is held back by a concrete dam and an earth embankment with a length of 1,200 m and a height of 16 m. The shoreline perimeter extends to .\n\nDue to its sheer size of in length, and on top of its industrial functions of retaining water for consumption as well as energy generation, the artificial lake created as a result of the dam construction is used for a variety of recreational purposes such as, but not limited to, windsurfing, kayaking, and sailing.\n"}
{"id": "228824", "url": "https://en.wikipedia.org/wiki?curid=228824", "title": "Teenage pregnancy", "text": "Teenage pregnancy\n\nTeenage pregnancy, also known as adolescent pregnancy, is pregnancy in a female under the age of 20. Pregnancy can occur with sexual intercourse after the start of ovulation, which can be before the first menstrual period (menarche) but usually occurs after the onset of periods. In well-nourished females, the first period usually takes place around the age of 12 or 13.\nPregnant teenagers face many of the same pregnancy related issues as other women. There are additional concerns for those under the age of 15 as they are less likely to be physically developed to sustain a healthy pregnancy or to give birth. For girls aged 15–19, risks are associated more with socioeconomic factors than with the biological effects of age. Risks of low birth weight, premature labor, anemia, and pre-eclampsia are connected to biological age, being observed in teen births even after controlling for other risk factors (such as accessing prenatal care etc.).\nTeenage pregnancies are associated with social issues, including lower educational levels and poverty. Teenage pregnancy in developed countries is usually outside of marriage and carries a social stigma. Teenage pregnancy in developing countries often occurs within marriage and half are planned. However, in these societies, early pregnancy may combine with malnutrition and poor health care to cause medical problems. When used in combination, educational interventions and access to birth control can reduce unintended teenage pregnancies.\nIn 2015 about 47 females per 1,000 had children well under the age of 20. Rates are higher in Africa and lower in Asia. In the developing world about 2.5 million females under the age of 16 and 16 million females 15 to 19 year old have children each year. Another 3.9 million have abortions. It is more common in rural than urban areas. Worldwide, complications related to pregnancy are the most common cause of death among females 15 to 19 year old.\n\nThe age of the mother is determined by the easily verified date when the pregnancy \"ends\", not by the estimated date of conception. Consequently, the statistics do not include pregnancies that began at age 19, but that ended on or after the woman's 20th birthday. Similarly, statistics on the mother's marital status are determined by whether she is married at the end of the pregnancy, not at the time of conception.\n\nAccording to the United Nations Population Fund (UNFPA), \"Pregnancies among girls less than 18 years of age have irreparable consequences. It violates the rights of girls, with life-threatening consequences in terms of sexual and reproductive health, and poses high development costs for communities, particularly in perpetuating the cycle of poverty.\" Health consequences include not yet being physically ready for pregnancy and childbirth leading to complications and malnutrition as the majority of adolescents tend to come from lower-income households. The risk of maternal death for girls under age 15 in low and middle income countries is higher than for women in their twenties. Teenage pregnancy also affects girls' education and income potential as many are forced to drop out of school which ultimately threatens future opportunities and economic prospects.\n\nSeveral studies have examined the socioeconomic, medical, and psychological impact of pregnancy and parenthood in teens. Life outcomes for teenage mothers and their children vary; other factors, such as poverty or social support, may be more important than the age of the mother at the birth. Many solutions to counteract the more negative findings have been proposed. Teenage parents who can rely on family and community support, social services and child-care support are more likely to continue their education and get higher paying jobs as they progress with their education.\n\nA holistic approach is required in order to address teenage pregnancy. This means not focusing on changing the behaviour of girls but addressing the underlying reasons of adolescent pregnancy such as poverty, gender inequality, social pressures and coercion. This approach should include \"providing age-appropriate comprehensive sexuality education for all young people, investing in girls' education, preventing child marriage, sexual violence and coercion, building gender-equitable societies by empowering girls and engaging men and boys and ensuring adolescents' access to sexual and reproductive health information as well as services that welcome them and facilitate their choices\".\n\nIn the United States one third of high school students reported being sexually active. In 2011–2013, 79% of females reported using birth control. Teenage pregnancy puts young women at risk for health issues, economic, social and financial issues.\n\nBeing a young mother in a first world country can affect one's education. Teen mothers are more likely to drop out of high school. However, recent studies have found that many of these mothers had already dropped out of school before becoming pregnant, but those in school at the time of their pregnancy were as likely to graduate as their peers. One study in 2001 found that women who gave birth during their teens completed secondary-level schooling 10–12% as often and pursued post-secondary education 14–29% as often as women who waited until age 30.\n\"Young motherhood\" in an industrialized country can affect employment and social class. Less than one third of teenage mothers receive any form of child support, vastly increasing the likelihood of turning to the government for assistance. The correlation between earlier childbearing and failure to complete high school reduces career opportunities for many young women. One study found that, in 1988, 60% of teenage mothers were impoverished at the time of giving birth. Additional research found that nearly 50% of all adolescent mothers sought social assistance within the first five years of their child's life. A study of 100 teenaged mothers in the UK found that only 11% received a salary, while the remaining 89% were unemployed. Most British teenage mothers live in poverty, with nearly half in the bottom fifth of the income distribution. Teenage women who are pregnant or mothers are seven times more likely to commit suicide than other teenagers. Professor John Ermisch at the Institute of Social and Economic Research at Essex University and Dr Roger Ingham, director of the Centre of Sexual Health at Southampton University, found that comparing teenage mothers with other girls with similarly deprived social-economic profiles, bad school experiences and low educational aspirations, the difference in their respective life chances was negligible.\n\nTeenage motherhood may actually make economic sense for young women with less money, some research suggests. For instance, long-term studies by Duke University economist V. Joseph Hotz and colleagues, published in 2005, found that by age 35, former teen mothers had earned more in income, paid more in taxes, were substantially less likely to live in poverty and collected less in public assistance than similarly poor women who waited until their 20s to have babies. Women who became mothers in their teens—freed from child-raising duties by their late 20s and early 30s to pursue employment while poorer women who waited to become mothers were still stuck at home watching their young children—wound up paying more in taxes than they had collected in welfare. Eight years earlier, the federally commissioned report \"Kids Having Kids\" also contained a similar finding, though it was buried: \"Adolescent childbearers fare slightly better than later-childbearing counterparts in terms of their overall economic welfare.\"\n\nAccording to the National Campaign to Prevent Teen Pregnancy, nearly 1 in 4 teen mothers will experience another pregnancy within two years of having their first. Pregnancy and giving birth significantly increases the chance that these mothers will become high school dropouts and as many as half have to go on welfare. Many teen parents do not have the intellectual or emotional maturity that is needed to provide for another life. Often, these pregnancies are hidden for months resulting in a lack of adequate prenatal care and dangerous outcomes for the babies. Factors that determine which mothers are more likely to have a closely spaced repeat birth include marriage and education: the likelihood decreases with the level of education of the young woman – or her parents – and increases if she gets married.\n\nEarly motherhood can affect the psychosocial development of the infant. The children of teen mothers are more likely to be born prematurely with a low birth weight, predisposing them to many other lifelong conditions. Children of teen mothers are at higher risk of intellectual, language, and socio-emotional delays. Developmental disabilities and behavioral issues are increased in children born to teen mothers. One study suggested that adolescent mothers are less likely to stimulate their infant through affectionate behaviors such as touch, smiling, and verbal communication, or to be sensitive and accepting toward his or her needs. Another found that those who had more social support were less likely to show anger toward their children or to rely upon punishment.\n\nPoor academic performance in the children of teenage mothers has also been noted, with many of the children being held back a grade level, scoring lower on standardized tests, and/or failing to graduate from secondary school. Daughters born to adolescent parents are more likely to become teen mothers themselves. Sons born to teenage mothers are three times more likely to serve time in prison.\n\nMaternal and prenatal health is of particular concern among teens who are pregnant or parenting. The worldwide incidence of premature birth and low birth weight is higher among adolescent mothers. In a rural hospital in West Bengal, teenage mothers between 15 and 19 years old were more likely to have anemia, preterm delivery, and a baby with a lower birth weight than mothers between 20 and 24 years old.\n\nResearch indicates that pregnant teens are less likely to receive prenatal care, often seeking it in the third trimester, if at all. The Guttmacher Institute reports that one-third of pregnant teens receive insufficient prenatal care and that their children are more likely to have health issues in childhood or be hospitalized than those born to older women.\n\nIn the case for Latinas and teenage pregnancy there are barriers that prevent them from receiving any health care. That is because the Latino population is the least uninsured group in the Unites States \n\nYoung mothers who are given high-quality maternity care have significantly healthier babies than those who do not. Many of the health-issues associated with teenage mothers appear to result from lack of access to adequate medical care.\n\nMany pregnant teens are at risk of nutritional deficiencies from poor eating habits common in adolescence, including attempts to lose weight through dieting, skipping meals, food faddism, snacking, and consumption of fast food.\n\nInadequate nutrition during pregnancy is an even more marked problem among teenagers in developing countries. Complications of pregnancy result in the deaths of an estimated 70,000 teen girls in developing countries each year. Young mothers and their babies are also at greater risk of contracting HIV. The World Health Organization estimates that the risk of death following pregnancy is twice as high for girls aged 15–19 than for women aged 20–24. The maternal mortality rate can be up to five times higher for girls aged 10–14 than for women aged 20–24. Illegal abortion also holds many risks for teenage girls in areas such as sub-Saharan Africa.\n\nRisks for medical complications are greater for girls aged under 15, as an underdeveloped pelvis can lead to difficulties in childbirth. Obstructed labour is normally dealt with by caesarean section in industrialized nations; however, in developing regions where medical services might be unavailable, it can lead to eclampsia, obstetric fistula, infant mortality, or maternal death. For mothers who are older than fifteen, age in itself is not a risk factor, and poor outcomes are associated more with socioeconomic factors rather than with biology.\n\nRates of teenage pregnancies are higher in societies where it is traditional for girls to marry young and where they are encouraged to bear children as soon as they are able. For example, in some sub-Saharan African countries, early pregnancy is often seen as a blessing because it is proof of the young woman's fertility. Countries where teenage marriages are common experience higher levels of teenage pregnancies. In the Indian subcontinent, early marriage and pregnancy is more common in traditional rural communities than in cities. The lack of education on safe sex, whether it is from parents, schools, or otherwise, is a cause of teenage pregnancy. Many teenagers are not taught about methods of birth control and how to deal with peers who pressure them into having sex before they are ready. Many pregnant teenagers do not have any cognition of the central facts of sexuality.\n\nEconomic incentives also influence the decision to have children. In societies where children are set to work at an early age, it is economically attractive to have many children.\n\nIn societies where adolescent marriage is less common, such as many developed countries, young age at first intercourse and lack of use of contraceptive methods (or their inconsistent and/or incorrect use; the use of a method with a high failure rate is also a problem) may be factors in teen pregnancy. Most teenage pregnancies in the developed world appear to be unplanned. Many Western countries have instituted sex education programs, the main objective of which is to reduce unplanned pregnancies and STIs. Countries with low levels of teenagers giving birth accept sexual relationships among teenagers and provide comprehensive and balanced information about sexuality.\n\nTeen pregnancy and motherhood can influence younger siblings. One study found that the younger sisters of teen mothers were less likely to emphasize the importance of education and employment and more likely to accept human sexual behavior, parenting, and marriage at younger ages; younger brothers, too, were found to be more tolerant of non-marital and early births, in addition to being more susceptible to high-risk behaviors. If the younger sisters of teenage parents babysit the children, they have an increased risk of getting pregnant themselves. Once an older daughter has a child, parents often become more accepting as time goes by. The probability of the younger sister having a teenage pregnancy went from one in five to two in five if the elder sister had a baby as a teenager.\n\nIn most countries, most males experience sexual intercourse for the first time before their 20th birthday. Males in Western developed countries have sex for the first time sooner than in undeveloped and culturally conservative countries such as sub-Saharan Africa and much of Asia.\n\nIn a 2005 Kaiser Family Foundation study of U.S. teenagers, 29% of teens reported feeling pressure to have sex, 33% of sexually active teens reported \"being in a relationship where they felt things were moving too fast sexually\", and 24% had \"done something sexual they didn’t really want to do\". Several polls have indicated peer pressure as a factor in encouraging both girls and boys to have sex. The increased sexual activity among adolescents is manifested in increased teenage pregnancies and an increase in sexually transmitted diseases.\n\nInhibition-reducing drugs and alcohol may possibly encourage unintended sexual activity. If so, it is unknown if the drugs themselves directly influence teenagers to engage in riskier behavior, or whether teenagers who engage in drug use are more likely to engage in sex. Correlation does not imply causation. The drugs with the strongest evidence linking them to teenage pregnancy are alcohol, cannabis, \"ecstasy\" and other substituted amphetamines. The drugs with the least evidence to support a link to early pregnancy are opioids, such as heroin, morphine, and oxycodone, of which a well-known effect is the significant reduction of libido – it appears that teenage opioid users have significantly reduced rates of conception compared to their non-using, and alcohol, \"ecstasy\", cannabis, and amphetamine using peers.\n\nGirls who mature early (precocious puberty) are more likely to engage in sexual intercourse at a younger age, which in turn puts them at greater risk of teenage pregnancy.\n\nAdolescents may lack knowledge of, or access to, conventional methods of preventing pregnancy, as they may be too embarrassed or frightened to seek such information. Contraception for teenagers presents a huge challenge for the clinician. In 1998, the government of the UK set a target to halve the under-18 pregnancy rate by 2010. The Teenage Pregnancy Strategy (TPS) was established to achieve this. The pregnancy rate in this group, although falling, rose slightly in 2007, to 41.7 per 1000 women. Young women often think of contraception either as 'the pill' or condoms and have little knowledge about other methods. They are heavily influenced by negative, second-hand stories about methods of contraception from their friends and the media. Prejudices are extremely difficult to overcome. Over concern about side-effects, for example weight gain and acne, often affect choice. Missing up to three pills a month is common, and in this age group the figure is likely to be higher. Restarting after the pill-free week, having to hide pills, drug interactions and difficulty getting repeat prescriptions can all lead to method failure.\n\nIn the U.S., according to the 2002 National Survey of Family Growth, sexually active adolescent women wishing to avoid pregnancy were less likely than older women to use contraceptives (18% of 15–19-year-olds used no contraceptives, versus 10.7% for women aged 15–44). More than 80% of teen pregnancies are unintended. Over half of unintended pregnancies were to women not using contraceptives, most of the rest are due to inconsistent or incorrect use. 23% of sexually active young women in a 1996 \"Seventeen\" magazine poll admitted to having had unprotected sex with a partner who did not use a condom, while 70% of girls in a 1997 \"PARADE\" poll claimed it was embarrassing to buy birth control or request information from a doctor.\n\nThe National Longitudinal Study of Adolescent Health surveyed 1027 students in the U.S. in grades 7–12 in 1995 to compare the use of contraceptives among Whites, Blacks, and Hispanics. The results were that 36.2% of Hispanics said they never used contraception during intercourse which is a high rate compared to 23.3% of Black teens and 17.0% of White teens who also did not use contraceptives during intercourse\n\nIn a 2012 study, over 1,000 females were surveyed to find out factors contributing to not using contraception. Of those surveyed, almost half had been involved in unprotected sex within the previous three months. These women gave three main reasons for not using contraceptives: trouble obtaining birth control (the most frequent reason), lack of intention to have sex, and the misconception that they \"could not get pregnant\".\nIn a study for The Guttmacher Institute, researchers found that from a comparative perspective, however, teenage pregnancy rates in the U.S. are less nuanced than one might initially assume. “Since timing and levels of sexual activity are quite similar across [Sweden, France, Canada, Great Britain, and the U.S.], the high U.S. rates arise primarily because of less, and possibly less-effective, contraceptive use by sexually active teenagers.” Thus, the cause for the discrepancy between rich nations can be traced largely to contraceptive-based issues.\n\nAmong teens in the UK seeking an abortion, a study found that the rate of contraceptive use was roughly the same for teens as for older women.\n\nIn other cases, contraception is used, but proves to be inadequate. Inexperienced adolescents may use condoms incorrectly, forget to take oral contraceptives, or fail to use the contraceptives they had previously chosen. Contraceptive failure rates are higher for teenagers, particularly poor ones, than for older users. Long-acting contraceptives such as intrauterine devices, subcutaneous contraceptive implants, and contraceptive injections (such as Depo-Provera and Combined injectable contraceptive), which prevent pregnancy for months or years at a time, are more effective in women who have trouble remembering to take pills or using barrier methods consistently.\n\nAccording to The Encyclopedia of Women's Health, published in 2004, there has been an increased effort to provide contraception to adolescents via family planning services and school-based health, such as HIV prevention education.\n\nStudies from South Africa have found that 11–20% of pregnancies in teenagers are a direct result of rape, while about 60% of teenage mothers had unwanted sexual experiences preceding their pregnancy. Before age 15, a majority of first-intercourse experiences among females are reported to be non-voluntary; the Guttmacher Institute found that 60% of girls who had sex before age 15 were coerced by males who on average were six years their senior. One in five teenage fathers admitted to forcing girls to have sex with them.\n\nMultiple studies have indicated a strong link between early childhood sexual abuse and subsequent teenage pregnancy in industrialized countries. Up to 70% of women who gave birth in their teens were molested as young girls; by contrast, 25% of women who did not give birth as teens were molested.\n\nIn some countries, sexual intercourse between a minor and an adult is not considered consensual under the law because a minor is believed to lack the maturity and competence to make an informed decision to engage in fully consensual sex with an adult. In those countries, sex with a minor is therefore considered statutory rape. In most European countries, by contrast, once an adolescent has reached the age of consent, he or she can legally have sexual relations with adults because it is held that in general (although certain limitations may still apply), reaching the age of consent enables a juvenile to consent to sex with any partner who has also reached that age. Therefore, the definition of statutory rape is limited to sex with a person under the minimum age of consent. What constitutes statutory rape ultimately differs by jurisdiction (see age of consent).\n\nStudies have indicated that adolescent girls are often in abusive relationships at the time of their conceiving. They have also reported that knowledge of their pregnancy has often intensified violent and controlling behaviors on part of their boyfriends. Girls under age 18 are twice as likely to be beaten by their child's father than women over age 18. A UK study found that 70% of women who gave birth in their teens had experienced adolescent domestic violence. Similar results have been found in studies in the U.S. A Washington State study found 70% of teenage mothers had been beaten by their boyfriends, 51% had experienced attempts of birth control sabotage within the last year, and 21% experienced school or work sabotage.\n\nIn a study of 379 pregnant or parenting teens and 95 teenage girls without children, 62% of girls aged 11–15 and 56% of girls aged 16–19 reported experiencing domestic violence at the hands of their partners. Moreover, 51% of the girls reported experiencing at least one instance where their boyfriend attempted to sabotage their efforts to use birth control.\n\nTeenage pregnancy has been defined predominantly within the research field and among social agencies as a social problem. Poverty is associated with increased rates of teenage pregnancy. Economically poor countries such as Niger and Bangladesh have far more teenage mothers compared with economically rich countries such as Switzerland and Japan.\n\nIn the UK, around half of all pregnancies to under 18 are concentrated among the 30% most deprived population, with only 14% occurring among the 30% least deprived. For example, in Italy, the teenage birth rate in the well-off central regions is only 3.3 per 1,000, while in the poorer Mezzogiorno it is 10.0 per 1,000. Similarly, in the U.S., sociologist Mike A. Males noted that teenage birth rates closely mapped poverty rates in California:\n\nTeen pregnancy cost the U.S. over $9.1 billion in 2004, including $1.9 billion for health care, $2.3 billion for child welfare, $2.1 billion for incarceration, and $2.9 billion in lower tax revenue.\n\nThere is little evidence to support the common belief that teenage mothers become pregnant to get benefits, welfare, and council housing. Most knew little about housing or financial aid before they got pregnant and what they thought they knew often turned out to be wrong.\n\nWomen exposed to abuse, domestic violence, and family strife in childhood are more likely to become pregnant as teenagers, and the risk of becoming pregnant as a teenager increases with the number of adverse childhood experiences. According to a 2004 study, one-third of teenage pregnancies could be prevented by eliminating exposure to abuse, violence, and family strife. The researchers note that \"family dysfunction has enduring and unfavorable health consequences for women during the adolescent years, the childbearing years, and beyond.\" When the family environment does not include adverse childhood experiences, becoming pregnant as an adolescent does not appear to raise the likelihood of long-term, negative psychosocial consequences. Studies have also found that boys raised in homes with a battered mother, or who experienced physical violence directly, were significantly more likely to impregnate a girl.\n\nStudies have also found that girls whose fathers left the family early in their lives had the highest rates of early sexual activity and adolescent pregnancy. Girls whose fathers left them at a later age had a lower rate of early sexual activity, and the lowest rates are found in girls whose fathers were present throughout their childhood. Even when the researchers took into account other factors that could have contributed to early sexual activity and pregnancy, such as behavioral problems and life adversity, early father-absent girls were still about five times more likely in the U.S. and three times more likely in New Zealand to become pregnant as adolescents than were father-present girls.\n\nLow educational expectations have been pinpointed as a risk factor. A girl is also more likely to become a teenage parent if her mother or older sister gave birth in her teens. A majority of respondents in a 1988 Joint Center for Political and Economic Studies survey attributed the occurrence of adolescent pregnancy to a breakdown of communication between parents and child and also to inadequate parental supervision.\n\nFoster care youth are more likely than their peers to become pregnant as teenagers. The National Casey Alumni Study, which surveyed foster care alumni from 23 communities across the U.S., found the birth rate for girls in foster care was more than double the rate of their peers outside the foster care system. A University of Chicago study of youth transitioning out of foster care in Illinois, Iowa, and Wisconsin found that nearly half of the females had been pregnant by age 19. The Utah Department of Human Services found that girls who had left the foster care system between 1999 and 2004 had a birth rate nearly 3 times the rate for girls in the general population.\n\nA study conducted in 2006 found that adolescents who were more exposed to sexuality in the media were also more likely to engage in sexual activity themselves.\n\nAccording to \"Time\", \"teens exposed to the most sexual content on TV are twice as likely as teens watching less of this material to become pregnant before they reach age 20\".\n\nComprehensive sex education and access to birth control appear to reduce unplanned teenage pregnancy. It is unclear which type of intervention is most effective.\n\nIn the U.S. free access to a long acting form of reversible birth control along with education decreased the rates of teen pregnancies by around 80% and the rate of abortions by more than 75%. Currently there are four federal programs aimed at preventing teenage pregnancy: Teen Pregnancy Prevention (TPP), Personal Responsibility Education Program (PREP), Title V Sexual Risk Avoidance Education, and Sexual Risk Avoidance Education.\n\nThe Dutch approach to preventing teenage pregnancy has often been seen as a model by other countries. The curriculum focuses on values, attitudes, communication and negotiation skills, as well as biological aspects of reproduction. The media has encouraged open dialogue and the health-care system guarantees confidentiality and a non-judgmental approach.\n\nSome schools provide abstinence-only sex education. Evidence does not support the effectiveness of abstinence-only sex education. It has been found to be ineffective in decreasing HIV risk in the developed world, and does not decrease rates of unplanned pregnancy when compared to comprehensive sex education. It does not decrease the sexual activity rates of students, when compared to students who undertake comprehensive sexual education classes.\n\nIn the U.S., one policy initiative that has been used to increase rates of contraceptive use is Title X. Title X of the Family Planning Services and Population Research Act of 1970 () provides family planning services for those who do not qualify for Medicaid by distributing \"funding to a network of public, private, and nonprofit entities [to provide] services on a sliding scale based on income.\" Studies indicate that, internationally, success in reducing teen pregnancy rates is directly correlated with the kind of access that Title X provides: “What appears crucial to success is that adolescents know where they can go to obtain information and services, can get there easily and are assured of receiving confidential, nonjudgmental care, and that these services and contraceptive supplies are free or cost very little.” In addressing high rates of unplanned teen pregnancies, scholars agree that the problem must be confronted from both the biological and cultural contexts.\n\nOn September 30, 2010, the U.S. Department of Health and Human Services approved $155 million in new funding for comprehensive sex education programs designed to prevent teenage pregnancy. The money is being awarded \"to states, non-profit organizations, school districts, universities and others. These grants will support the replication of teen pregnancy prevention programs that have been shown to be effective through rigorous research as well as the testing of new, innovative approaches to combating teen pregnancy.\" Of the total of $150 million, $55 million is funded by Affordable Care Act through the Personal Responsibility Education Program, which requires states receiving funding to incorporate lessons about both abstinence and contraception.\n\nIn the developing world, programs of reproductive health aimed at teenagers are often small scale and not centrally coordinated, although some countries such as Sri Lanka have a systematic policy framework for teaching about sex within schools. Non-governmental agencies such as the International Planned Parenthood Federation and Marie Stopes International provide contraceptive advice for young women worldwide. Laws against child marriage have reduced but not eliminated the practice. Improved female literacy and educational prospects have led to an increase in the age at first birth in areas such as Iran, Indonesia, and the Indian state of Kerala.\n\nA team of researchers and educators in California have published a list of \"best practices\" in the prevention of teen pregnancy, which includes, in addition to the previously mentioned concepts, working to \"instill a belief in a successful future\", male involvement in the prevention process, and designing interventions that are culturally relevant.\n\nIn reporting teenage pregnancy rates, the number of pregnancies per 1,000 females aged 15 to 19 when the pregnancy ends is generally used.\n\nWorldwide, teenage pregnancy rates range from 143 per 1000 in some sub-Saharan African countries to 2.9 per 1000 in South Korea. In the U.S., 82% of pregnancies in those between 15 and 19 are unplanned. Among OECD developed countries, the U.S., the UK and New Zealand have the highest level of teenage pregnancy, while Japan and South Korea have the lowest in 2001. According to UNFPA, “In every region of the world – including high-income countries – girls who are poor, poorly educated or living in rural areas are at greater risk of becoming pregnant than those who are wealthier, well-educated or urban. This is true on a global level, as well: 95 per cent of the world’s births to adolescents (aged 15–19) take place in developing countries. Every year, some 3 million girls in this age bracket resort to unsafe abortions, risking their lives and health.”\n\nAccording to a 2001 UNICEF survey, in 10 out of 12 developed nations with available data, more than two thirds of young people have had sexual intercourse while still in their teens. In Denmark, Finland, Germany, Iceland, Norway, the UK and the U.S., the proportion is over 80%. In Australia, the UK and the U.S., approximately 25% of 15-year-olds and 50% of 17-year-olds have had sex. According to \"The Encyclopedia of Women's Health\", published in 2004, approximately 15 million girls under the age of 20 in the world have a child each year. Estimates were that 20–60% of these pregnancies in developing countries are mistimed or unwanted.\n\nSave the Children found that, annually, 13 million children are born to women aged under 20 worldwide, more than 90% in developing countries. Complications of pregnancy and childbirth are the leading cause of mortality among women aged 15–19 in such areas.\n\nThe highest rate of teenage pregnancy in the world is in sub-Saharan Africa, where women tend to marry at an early age. In Niger, for example, 87% of women surveyed were married and 53% had given birth to a child before the age of 18.\n\nIn the Indian subcontinent, early marriage sometimes results in adolescent pregnancy, particularly in rural regions where the rate is much higher than it is in urbanized areas. Latest data suggests that teen pregnancy in India is high with 62 pregnant teens out of every 1,000 women. India is fast approaching to be the most populous country in the world by 2050 and increasing teenage pregnancy, an important factor for the population rise, is likely to aggravate the problems.\n\nThe rates of early marriage and pregnancy in some Asian countries are high. In recent years, the rates have decreased sharply in Indonesia and Malaysia, although it remains relatively high in the former. However, in the industrialized Asian nations such as South Korea and Singapore, teenage birth rates remain among the lowest in the world.\n\nIn 2015, the birth rate among teenage women in Australia was 11.9 births per 1,000 women. The rate has fallen from 55.5 births per 1,000 women in 1971, probably due to ease of access to effective birth control, rather than any decrease in sexual activity.\n\nThe overall trend in Europe since 1970 has been a decreasing total fertility rate, an increase in the age at which women experience their first birth, and a decrease in the number of births among teenagers. Most continental Western European countries have very low teenage birth rates. This is varyingly attributed to good sex education and high levels of contraceptive use (in the case of the Netherlands and Scandinavia), traditional values and social stigmatization (in the case of Spain and Italy) or both (in the case of Switzerland).\n\nOn the other hand, the teen birth rate is very high in Bulgaria and Romania. As of 2015, Bulgaria had a birth rate of 37/1.000 women aged 15–19, and Romania of 34. The teen birth rate of these two countries is even higher than that of underdeveloped countries like Burundi and Rwanda.\nMany of the teen births occur in Roma populations, who have an occurrence of teenage pregnancies well above the local average.\n\nThe teen pregnancy rate in England and Wales was 23.3 per 1,000 women aged 15 to 17. There were 5,740 pregnancies in girls aged under 18 in the three months to June 2014, data from the Office for National Statistics shows. This compares with 6,279 in the same period in 2013 and 7,083 for the June quarter the year before that. Historically, the UK has had one of the highest teenage pregnancy and abortion rates in Western Europe.\n\nThere are no comparable rates for conceptions across Europe, but the under-18 birth rate suggests England is closing the gap. The under-18 birth rate in 2012 in England and Wales was 9.2, compared with an EU average of 6.9. However, the UK birth rate has fallen by almost a third (32.3%) since 2004 compared with a fall of 15.6% in the EU. In 2004, the UK rate was 13.6 births per 1,000 women aged 15–17 compared with an EU average rate of 7.7.\n\nA spokeswoman for the British Pregnancy Advisory Service said: \"Contrary to popular perception, this data shows that the teenage pregnancy rate is falling dramatically in England and Wales. While the UK has historically had a high teenage conception rate, it is now at its lowest level on record and not significantly out of step with other European countries.\n\n\"We have seen a huge decline in the number of babies born to teenage mothers over the last decade, in part due to the improvements we've seen in contraception advice and services for younger women, with straightforward access to abortion services when their chosen method lets them down. But it also reflects broader societal shifts, with younger women quite rightly expecting and able to pursue educational and professional ambitions.\"\n\nIn 2001, the teenage birth rate in the U.S. was the highest in the developed world, and the teenage abortion rate is also high. In 2005 in the U.S., the majority (57%) of teen pregnancies resulted in a live birth, 27% ended in an induced abortion, and 16% in a fetal loss. The U.S. teenage pregnancy rate was at a high in the 1950s and has decreased since then, although there has been an increase in births out of wedlock. The teenage pregnancy rate decreased significantly in the 1990s; this decline manifested across all racial groups, although teenagers of African-American and Hispanic descent retain a higher rate, in comparison to that of European-Americans and Asian-Americans. The Guttmacher Institute attributed about 25% of the decline to abstinence and 75% to the effective use of contraceptives. While in 2006 the U.S. teen birth rate rose for the first time in fourteen years, it reached a historic low in 2010: 34.3 births per 1,000 women aged 15–19.\n\nThe Latina teenage pregnancy rate is 75% higher pregnancy rate than the national average.\n\nThe latest data from the U.S. shows that the states with the highest teenage birthrate are Mississippi, New Mexico and Arkansas while the states with the lowest teenage birthrate are New Hampshire, Massachusetts and Vermont.\n\nThe Canadian teenage birth trended towards a steady decline for both younger (15–17) and older (18–19) teens in the period between 1992 and 2002; however, teen pregnancy has been on the rise since 2013.\n\nIn some cases, the father of the child is the husband of the teenage girl. The conception may occur within wedlock, or the pregnancy itself may precipitate the marriage (the so-called shotgun wedding). In countries such as India, the majority of teenage births occur within marriage.\n\nIn other countries, such as the U.S. and the Ireland, the majority of teenage mothers are not married to the father of their children. In the UK, half of all teenagers with children are lone parents, 40% are cohabitating as a couple and 10% are married. Teenage parents are frequently in a romantic relationship at the time of birth, but many adolescent fathers do not stay with the mother and this often disrupts their relationship with the child. U.S. surveys tend to under-report the prevalence of teen fatherhood.\nIn many cases, \"teenage father\" may be a misnomer. Studies by the Population Reference Bureau and the National Center for Health Statistics found that about two-thirds of births to teenage girls in the U.S. are fathered by adult men aged over 20. The Guttmacher Institute reports that over 40% of mothers aged 15–17 had sexual partners three to five years older and almost one in five had partners six or more years older. A 1990 study of births to California teens reported that the younger the mother, the greater the age gap with her male partner. In the UK 72% of jointly registered births to women aged under 20, the father is over 20, with almost 1 in 4 being over 25.\n\nTeenage pregnancy (with conceptions normally involving girls between age 16-19), was far more normal in previous centuries, and common in developed countries in the 20th century. Among Norwegian women born in the early 1950s, nearly a quarter became teenage mothers by the early 1970s. However, the rates have steadily declined throughout the developed world since that 20th century peak. Among those born in Norway in the late 1970s, less than 10% became teenage mothers, and rates have fallen since then.\n\nSome politicians condemn pregnancy in unmarried teenagers as a drain on taxpayers, if the mothers and children receive welfare payments from the government.\n\n\n"}
{"id": "57890213", "url": "https://en.wikipedia.org/wiki?curid=57890213", "title": "Tulabhara", "text": "Tulabhara\n\nTulabhara, also known as Tula-purusha (IAST: Tulāpuruṣa) is an ancient Hindu practice in which a person is weighed against a commodity (such as gold, grain, fruits or other objects), and the equivalent weight of that commodity is offered as donation. The Tulabhara ceremony is observed in several parts of India.\n\nThe \"Atharvaveda\"-\"parishishta\", composed in the 1st millennium BCE, describes tula-purusha, besides other sacrifices such as the hiranya-garbha (the donation of a golden vessel) and go-sahasra (the donation of a thousand cows). A section of the later text \"Matsya Purana\" mentions the tula-purusha ceremony as the first and the best among the sixteen great donations (\"maha-danas\"). According to scholar R. C. Hazara, this particular section was composed during 550-650 CE.\n\nThe \"Linga Purana\" also mentions the sixteen great donations; according to R. C. Hazara, the relevant portion of the text was composed during c. 600-1000 CE, most probably after 800 CE. These donations are also described in the later digests devoted to the topic of charity (dāna), such as Ballala's \"Dana-sagara\", and the \"Danakhanda\" section of Hemadri's \"Chaturvarga-chintamani\" (13th century).\n\nThe \"Matsya Purana\" provides several requirements for a tula-purusha ceremony, including directions for constructing the mandapa (pavillion) required for the ceremony. It states that the weighing scale (\"tula\") should have two posts and a crossbeam, made from the same wood, and should be ornamented with gold.\n\nThe text further states that the ceremony should be officiated by eight priests (\"rtvij\"), two for each of the four Vedas. A man knolwedgable about the Vedanta, the Puranas, and the Shastras, should be appointed as the preceptor (\"guru\"). Four \"homas\" should be offered to the deities, accompanied by the recital of Vedic hymns. After the \"homa\" ceremony, the \"guru\" should invoke the Lokapalas (deities associated with directions) with flowers, incense, and recital of mantras. Next, the brahmanas should bathe the donor, and have him wear a white garment. The donor should wear garlands made of white flowers, and circumambulate the weighing scale with flowers in his folded hands.\n\nFinally, the text states, the donor should step into one of the pans of the weighing scale, and the brahmanas should place place pure gold pieces of equal weight in the other pan. After invoking the Goddess Earth, the donor should give half the gold to the \"guru\", and the rest to the brahmanas. The donor may also grant villages to the priests. The donor should \"honour the brahmanas, other respectable people, and the poor and the helpless with gifts\".\n\nThe \"Linga Purana\" gives a similar description, and adds that the gold pieces should be dedicated to the god Shiva.\n\nSeveral legendary performances of Tulabhara are mentioned in the ancient Indian texts. For example, in the \"Mahabharata\", King Shibi, a descendant of King Bharata of the Lunar dynasty, was tested by Lord Dharmaraja and Agni. They approached Shibi in the forms of an eagle and a dove. The dove sought Shibi's protection from the eagle, who asked Shibi to give his flesh measure for measure in exchange for the dove's life. Shibi, ready to offer anything to save the dove, began slice off bits of himself. Even after much cutting, the balance scales did not move, and when at last when Shibi himself stood on the scale of the balance, the Gods appeared to him and blessed him. This story is found in other Sanskrit works, Sangam Tamil literature, \"Silappadikaram\" and Sumerian culture has references to Tulabharam.\n\nSeveral inscriptions of India also mention the historical performances of the \"tula-purusha\". Tulabhara mandapas are two small four pillared found in temples like Sri Varadharajaswami temple, Kanchi where Vijayanagar king Achyutaraya performed Muladhara in 1532. Sivayoganathaswamin temple at Tiruvisalur is the place where Chola king Rajaraja I performed his Tulabhara. It is stated in the Tamil work \"Koyilolugu\" that Jatavarman Sundara Pandya I constructed several tulapurusha mandapas in Srirangam temple and performed tulabhara there.\n\nIn 2015, the Sri Lankan prime minister Ranil Wickramasinghe participated in a \"tulabharam\" ceremony at the Guruvayur Temple, and offered 77 kg of sandalwood worth approximately 850,000 to the temple.\n\n"}
{"id": "37750865", "url": "https://en.wikipedia.org/wiki?curid=37750865", "title": "War sand", "text": "War sand\n\nWar sand is sand contaminated by remains of projectiles used in war. This kind of sand has been found in Normandy, since the invasion of Normandy, among other places. In 1988, the sand on Omaha Beach was discovered to contain man-made metal and glass particles deriving from shrapnel; 4% of the sand in the sample was composed of shrapnel particles. Researchers also discovered iron and glass beads in the sand, originating from munitions explosions. \n"}
{"id": "18304723", "url": "https://en.wikipedia.org/wiki?curid=18304723", "title": "Water supply and sanitation in Iran", "text": "Water supply and sanitation in Iran\n\nWater supply and sanitation in Iran has witnessed some important improvements, especially in terms of increased access to urban water supply, while important challenges remain, particularly concerning sanitation and service provision in rural areas.\nInstitutionally, the Ministry of Energy is in charge of policy and provincial companies are in charge of service provision.\n\nThe sector is characterized by a wide discrepancy in coverage of water and sewerage services, as well as between urban and rural areas. The Joint Monitoring Programme for Water Supply and Sanitation of the WHO and UNICEF, which monitors access figures based on national surveys and censuses, estimated access in Iran from the results of the censuses of 1996, 2006 and 2011 as well as a 1995 Multiple Indicator Cluster Survey. According its estimates, in 2011 access to an improve yourater supply was 98% in urban areas where more than two thirds of Iranians live. It was 90% in rural areas (87% house connections). Access to sewerage in urban areas was estimated at 19% in the late 1990s. Access to improved sanitation was estimated at close to 100%.\n\nRainfall in Iran is highly seasonal, with a rainy season between October and March, leaving the land parched for the remainder of the year. Immense seasonal variations in flow characterize Iran's rivers. For example, the Karun River in Khuzestan carries water during periods of maximum flow that is ten times the amount borne in dry periods. In numerous localities, there may be no precipitation until sudden storms, accompanied by heavy rains, dump almost the entire year's rainfall in a few days. Water shortages are compounded by the unequal distribution of water. Near the Caspian Sea, rainfall averages about 1,280 mm per year, but in the Central Plateau and in the lowlands to the south it seldom exceeds 100 mm.\n\nInternal renewable water resources are estimated at 128.5 billion cubic meters (BCM)/year (average for 1977-2001). Surface runoff represents a total of 97.3 BCM/year, of which 5.4 BCM/year comes from drainage of the aquifers and thus needs to be subtracted from the total. Groundwater recharge is estimated at about 49.3 BCM/year, of which 12.7 BCM/year is obtained from infiltration in the river bed and also needs to be subtracted. Iran receives 6.7 BCM/year of surface water from Pakistan and some water from Afghanistan through the Helmand River. The flow of the Arax river, at the border with Azerbaijan, is estimated at 4.6 BCM/year. The surface runoff to the sea and to other countries is estimated at 55.9 BCM/year. Per capita water availability in the pre-Islamic Revolution era was about 4,500 cubic meters. But, in 2009 this figure was less than 2,000 cubic meters. The total water withdrawal was estimated at about 70 BCM in 1993, rising to 93 BCM in 2004, of which 92% was used for agricultural purposes, 6% for domestic use and 2% for industrial use. Although this is equal to 51% of the actual available renewable water resources, annual abstraction from aquifers (57 BCM in 1993, 53 BCM in 2004) is already more than the estimated safe yield (46 BCM). Of the 4.3 BCM/year in 1993 (6.2 in 2004) used for domestic purposes, 61% is supplied from surface water and 39% from groundwater. As of 2014, Iran is using 70% of its total renewable freshwater, far above the upper limit of 40% recommended according to international norms. A large part of the water used in agriculture is evaporated instead of properly used because of inefficient consumption patterns. 16 BCM of water was used for power generation in 1999.\n\nGreater Tehran with its population of more than 13 million is supplied by surface water from the Lar dam on the Lar River in the Northeast of the city, the Latyan dam on the Jajrood River in the North, the Karaj River in the Northwest, as well as by groundwater in the vicinity of the city. The average Tehran resident uses 325 liters of water (86 gallons) per day. Tap water consumption in the country is 70% over and above the global average.\n\nIn March 2016 President Hassan Rouhani said at a conference that the \"water consumption pattern\" in Iran had to be changed, without making any specific recommendations on how this could best be achieved.\n\nThe Iranian government envisages massive investments in seawater desalination and in pipelines to bring water from the Southern shores to the interior of the country. In a first stage, desalination plants are to be built to supply coastal cities, while in a second stage cities on the central plateau are to be served as well. The plants and pipelines are expected to be financed by the private sector under Build-Own-Operate (BOO) Contracts where the government pays annual fees for the water produced. Such contracts for desalination plants already exist on a small scale with Iranian companies and are expected to be extended to larger contracts with international companies. The power for the desalination plants is expected to be provide at least partly by \"small\" nuclear power plants. Iranian Energy Minister Hamid Chitchian said that desalinated water would be provided to 45 million people in 17 provinces through 50 desalination plants, without specifying the costs or funding sources. Initially, water desalinated at Bandar Abbas would be transferred to Kerman Province.\n\nMost drinking water in Iran is supplied through modern infrastructure, such as dams, reservoirs, long-distance transmission pipelines - some of which are more than 300 km long - and deep wells. There are 42 large dams under operation in Iran with a combined storage capacity of 33 BCM/year. These dams lose about 200 million cubic meters of storage capacity every year due to sedimentation (0.5-0.75% of their storage capacity). Most dams are multi-purpose dams for hydropower, irrigation, flood control and - in some cases - drinking water supply.\n\nAn estimated 60,000 traditional Karez (کاریز) systems in the plateau regions of Iran in Yazd, Khorasan and Kerman - are still in use today for irrigation and drinking water supply in rural areas and small towns. The oldest and largest known Karez is in the Iranian city of Gonabad which after 2700 years still provides drinking and agricultural water to nearly 40,000 people. Its main well depth is more than 360 meters and its length is 45 kilometers.\n\nWater pollution is caused by industrial and municipal wastewater, as well as by agriculture. Concerning municipal wastewater, the bulk of collected sewage is discharged untreated and constitutes a major source of pollution to groundwater and a risk to public health. In a number of cities without sanitary sewerage, households discharge their sewage through open rainwater drains.\n\nUp to 1990 the water and sanitation sector was highly decentralized. Most water and wastewater service provision was the responsibility of municipalities and provinces. This was changed through a fundamental sector reform in 1990 with the ratification of the Provincial Water and Wastewater Companies Law of September 1990.\n\nIn September 2003 the Government of Iran and the World Bank agreed on a sector strategy with the targets for improved cost recovery and collection and increased efficiency. It is not clear what were the baseline data in 2003 and to what extent progress has been made to reach these targets.\nIn November 2008 the government announced that it has approved the construction of 177 dams nationwide. Dams in Iran serve primarily for hydropower generation, irrigation and flood control. However, one of the projects will provide drinking water and water for industrial use to the cities of Qom, Golpaygan, Delijan, Saveh, Khomein and Nimvar in the central provinces of Qom, Isfahan and Markazi.\n\nIn April 2012, the government launched a project to transfer Caspian Sea water to the central regions of Iran, bringing about 200 million cubic meters (7,062 cubic feet) of water per year.\n\nIn April 2016 Deputy Minister of Energy Sattar Mahmoudi said that six major cities - Bandar Abbas, Shiraz, Kerman, Mashhad and Hamadan - faced acute water shortages, and water resources were under strain in another 450. Parts of Iran have faced droughts for the past 15 years.\n\nSince the 1980s access to urban water supply has increased from 75.5% to 98%. According to one Iranian observer, the water quantity supplied has increased and the quality has improved. He concludes that the reform has been “very successful” and is “an example of best practice” that should “be proposed to other countries.\n\nHowever, a number of challenges remain. According to the World Bank, the sector is affected by “low water use efficiency in urban and rural uses; limited participation by stakeholders in development planning and management; large needs for rehabilitation and development of hydraulic infrastructure for sustainable water usage; problems of pollution caused by the discharge of untreated wastewater into public waterways and aquifers; and weak institutions involved in the sector and limited coordination among stakeholders.” Still according to the World Bank it is also characterized by “poor performance of water supply and on-site wastewater disposal facilities, causing increasing risk for ground and surface water pollution and health and environmental risks resulting from the discharge and re-use of untreated effluent for irrigation; limited technical, institutional and financial capacity of water and wastewater companies; a lack of clarity of institutional responsibilities of sector entities; and non transparent and inadequate tariff structures and levels.”\n\nThe Ministry of Energy, through its Deputy Ministry for Urban and Rural Water and Wastewater Management, is in charge of setting sector policies. The Deputy Ministry of Water Affairs in the same Ministry is in charge of water resources management, together with eleven Regional Water Boards. The Environmental Protection Organization is in charge of water pollution control. The Ministry of Health and Medical Education is responsible for setting drinking water quality standards, as well as monitoring and enforcing them.\nThe National Water and Wastewater Engineering Company (NWWEC) provides oversight and assistance to service providers in areas such as investment planning, human resources development, and in the establishment of standardized systems and procedures. The National Economic Council sets tariff policy for the whole country, with some differentiation across regions.\n\nIn 2008 sixty companies were responsible for the provision of water and wastewater services. Evenly spread over Iran’s thirty provinces, each province has one urban and one rural water and wastewater company (WWC). The 60 companies had 38,000 employees. Only Tehran has two separate companies for water and sewerage. In all other provinces, water and sanitation services are provided together. The regional water boards provide bulk raw water through transmission pipelines to the water and wastewater companies, which treat and distribute it.\n\nThe state-owned WWCs are able to manage their day-to-day operations with a measure of autonomy where Managing Directors can make most decisions on operations and staffing within the limits of the centrally authorized staffing levels and with some flexibility to provide extra compensation to well performing employees. However, the WWCs do not control their own investment programs and, therefore, have limited scope to improve investment and operating efficiency and the level and quality of service. Moreover, the WWCs have to follow an organizational model developed by the NWWEC and cannot select a model that would be more appropriate for their particular situation.\n\nUntil 2005, the national budget for the water sector stood at 1,400 billion rials while it has reached 3,500 billion rials (US$350 million using the official exchange rate) in 2008. This budget apparently includes multi-purpose dam and irrigation as well as water supply and sanitation. The government said in 2011 that investment needs stood at US$150 billion over the next 15 years, 20% of which should be financed by the private sector.\n\nOn average, the service providers do not recover operation and maintenance costs due to low tariffs and low bill collection. For example, the Provincial Water and Sewerage Companies for Ahwaz and Shiraz have been incurring significant net losses at least prior to 2004. The financial performance of the companies is further aggravated by high water losses of 38% in 2002/03 in Ahwaz and about 30% in Shiraz. Of the water that has been billed, only about 73% was collected in 2002/03 in Ahwaz, while it was higher in Shiraz.\n\nThe current urban tariff system is based on a fixed fee that depends on the size of the connection pipe and on the type of customer (household or other types), and on a volumetric charge based on increasing block-tariffs. The fixed fee, or the subscription fee, was about 2,000 Rials in 2004 (25 US cents) for most domestic customers while the structure of variable tariffs is based on a complex formula. The formula is the same for all companies and there is no volumetric charge if consumption falls below 5 cubic meter per month. Above this minimum, the tariff increases with the level of consumption and generally varies across companies. The average volumetric tariff for the country stood at about 6 US cents in 2002. It varied from 2 cents for monthly consumption below 20 cubic meter, to about 4.5 cents and 12.5 cents respectively for 20-40 and for more than 40 cubic meter of monthly consumption.\n\nAccording to the World Bank, the rate structure is needlessly complex for both volumetric rates and connection fees. Volumetric tariffs are based on complex formulas that differ across consumption brackets and water and wastewater companies. Because of this complexity the tariff structure lacks transparency. Moreover, the structure is such that rates increase by more than threefold when consumption rises from 20 cubic meter or less to slightly higher volumes. Regarding sewage bills they are currently levied and collected only in neighborhoods where a network exists and are a percentage of water bills (70%).\n\nAverage connection fees are about US$310 for the whole country and the minimum fee is approximately equal to US$l50. With a few exceptions, the connection fee for wastewater is the same as that for water. These fees have been regularly increased between 1999 and 2003, at the rate of 10% annually with the exception of the year 2000 in which the fee was increased by 15%. In addition to connection fees, the water and wastewater companies charge the customer the full cost for house connection.\n\nThe main external partner of the Iranian water and sanitation sector during the first decade of the 21st century was the World Bank. Today the main external partners are the Islamic Development Bank, the United Nations and NGOs.\n\nThe Islamic Development Bank (IDB) has allocated more than 800 million euros of loans in total for Iran's water and wastewater projects as of 2014, including 65 million euros for eastern Mashhad's wastewater project, 140 million euros for projects in the cities of Qom and Kashan in central Iran, 175 million euros to Tehran, 195 million euros to rural wastewater projects and 92 million euros to Qom province's water project, 80 million euros for wastewater projects in Hamedan and Qeshm, and 144 million euro for wastewater projects in the southern Fars province. The Iranian wastewater sector is the largest recipient of IDB water and wastewater funds in the world, as the IDB has funded some of the gap caused by international sanctions. With 8.28% of the shares Iran is the third-largest shareholder of the IDB, whose largest shareholder is Saudi Arabia.\n\nUNESCO-IHE in Delft, The Netherlands, together with the Power and Water University of Technology (Shahid Abbaspour) in Iran, will train 2,100 Iranian professionals in water and wastewater technologies, planning and management. The training will consist of 59 courses to take place in 2008 and the first half of 2009. In addition, 20 study tours to European water and wastewater companies for senior managerial, financial and technical staff will be organised.\n\nUnlike other lower and middle-income countries, Iran hosts few private international non-governmental organizations that pursue environmental or social aims. Despite the difficult operating environment and friction with ruling bodies, the Iranian Government has moved to encourage an increased participation by foreign NGOs. As a result, some organizations that closed operations have resumed their activities, and new startup organizations, including those that work in the areas of water and sanitation, have initiated projects in Iran. One such organization, Healing For Iran, recently launched a program to improve rural access to water and investigate the causes of water contamination in disadvantaged populations.\n\nThe World Bank was engaged in water and sanitation in the Islamic Republic of Iran between 2000 and 2010. Its engagement began with the approval of the Tehran Sewerage Project in 2000, followed by the approval of two other projects in 2004 and 2005. In 2010 its last project, The Northern Cities Water Supply and Sanitation Project, closed. The project, supported by a US$ 224m loan, aimed to enhance the quality of life in the four northern cities of Rasht and Anzali in Gilan Province, as well as Sari and Babol in Mazandaran Province. It aimed to do so by improving the operational efficiency and financial sustainability of the two Provincial Water and Wastewater Companies (WWCs). The project financed the extension and improvement of water distribution systems including metering, sanitary sewers, and a wastewater treatment plant (in Sari) which was not completed at project closure. The project did not succeed in improving the financial situation of the two water and wastewater companies, since tariff increases were delayed.\n\nThe Ahvaz and Shiraz Water Supply and Sanitation Project, supported by a US$ 279m loan approved in 2004 and closed in 2009, aimed to improve access to satisfactory water supply and significantly increasing coverage of sanitation services; and improve environmental, hygiene and health conditions, as well as promoting reuse of treated effluents. It also aimed to strengthen and develop the capacity of Ahvaz and Shiraz Water and Wastewater Companies, and assist the latter in improving their efficiency, sustainability and financial autonomy. It also aimed to initiate sector reforms, particularly with respect to institutional arrangements, the regulatory framework, demand management, as well as prepare a sanitation strategy.\n\nThe Tehran Sewerage Project, supported by a US$ 145m loan, closed in 2008. Its objective was to improve the environmental conditions in the Greater Tehran area through the installation of wastewater collection and treatment facilities, to improve public health, and enable unrestricted irrigation practices in the surrounding areas. Chlorination would disinfect effluents treated at the secondary level for suitable irrigation purposes, and a further tertiary treatment was to be extended if required. Treated effluents, and sludge were to be reused for agricultural purposes. The project allowed to connect more than 1.3 million people to the sewer system and to build a wastewater treatment plant that was completed in June 2009. A World Bank completion report concluded that the project reached its objectives and performed satisfactorily.\n\nThe World Bank says that international financial institutions are exempt from the sanctions imposed by the UN on Iran. In September 2013, the World Bank removed Iran from its list of borrowers that cannot receive new loans, saying the Islamic Republic had paid outstanding loan amounts. In April 2014, Iranian Finance and Economic Affairs Minister Ali Tayyebnia asked the World Bank to provide Iran with financial assistance to implement development projects.\n\n\nPeter Beaumont, \"Water Resource Development in Iran\", in The Geographical Journal, Vol. 140, No. 3 (Oct., 1974), pp. 418–431, at JSTOR\n\n"}
{"id": "30717904", "url": "https://en.wikipedia.org/wiki?curid=30717904", "title": "Water supply and sanitation in Lebanon", "text": "Water supply and sanitation in Lebanon\n\n\"This article's last major overhaul was conducted in December 2013.\"\n\nWater supply and sanitation in Lebanon is characterized by a number of achievements and challenges. The achievements include the reconstruction of infrastructure after the 1975–90 Civil War and the 2006 war with Israel, as well as the reform of the water and sanitation sector through a water law passed in 2000. The law created four Regional Water Establishments to consolidate numerous smaller utilities.\n\nThe challenges include poor service quality, in particular intermittent water supply that persists despite the availability of relatively abundant water resources; the slow implementation of the water reform; the separation of responsibilities between various entities such as the Council for Development and Reconstruction, which are de facto in charge of investment, and the Regional Water Establishments, which are in charge of operation and maintenance; limited institutional capacity in the public sector, and in particular the Regional Water Establishments; politicization of decision-making; the absence of an autonomous regulatory agency; poor information about water resources, sector performance and assets; a very low share of metering and the absence of volumetric water tariffs; a high level of water distribution losses; limited cost recovery for water supply; and no cost recovery for sewerage and wastewater treatment. These challenges persist more than two decades after the end of the Civil War.\n\nThe Lebanese water and sanitation sector has received and continues to receive substantial foreign aid in the form of grants and soft loans from a dozen Western and Arab donors.\n\nAccording to UN estimates that are not based on any household survey access to an improved water source in Lebanon is universal. The UN figures on water access may not give an accurate picture of the real situation: A representative survey carried out by the World Bank in 2008 estimated that the average connection rate to the public water network was 80%, varying from 96% in Beirut to 55% in the North. These figures are similar to those that came out of a 2004 Household Living Conditions Survey carried out by the Lebanese Central Administration of Statistics. Even considering that improved water sources include protected wells and springs in addition to piped water connections, it is unlikely that water access in Lebanon is universal. For example, many urban households that are not connected to the network rely on water bought from tanker trucks.\n\nThe UN statistics show no data on access to sanitation in Lebanon. The World Bank quotes estimates by the Council for Development and Reconstruction showing a 58% share of connection to sewers in 2002. Wastewater collection was highest in Beirut-Mount Lebanon (74%) and lowest in the South (35%). The remaining buildings either use cesspools and septic tanks or simply release raw sewage directly into the environment. A census of Buildings and Establishments in 1996–97 had estimated that only about 37% of the buildings in Lebanon were connected to a sewer network at that time, indicating that the share increased substantially between 1997 and 2002.\n\nThe quality of water service provision is poor. According to official figures from 2009, the average water availability per day was as follows: 22 hours in the North, 10 hours in the Bekaa, 8 hours in the South, and for Beirut-Mount Lebanon 13 hours in winter, but only 2 hours in summer. There is not a single village or city in Lebanon that receives an uninterrupted residential supply of water. Especially in summer, water shortages are common. For example, in Nabatieh Governorate water reached customers only three times a week in 2007. In Greater Beirut, water supply drops to 3 hours per day during the summer. According to the above-mentioned 2008 survey, the average Lebanese household received 6 hours per day in summer and 9 hours in winter. Only one quarter of Lebanese households received water every day. The continuity of supply was best in the North where 59% said they received water every day in 2008. It was worst in Beirut where this share was only 10%. Poor water quality and intermittent supply impose high costs on households to cope with these deficiencies. Buying water from trucks and the purchase of bottled water are common. Water is also commonly stored in roof tanks, which imposes both an additional cost and jeopardizes water quality. Many households also use pumps to make sure that water reaches the upper floors of houses, which imposes more costs on households. Low pressure and intermittent water supply are caused, among others, by intermittent electricity supply.\n\nAccording to the World Bank, the Lebanese water supply and sanitation sector has not achieved service provision in line with the country’s level of economic development. The opportunity costs of inadequate public water supply provision amount to 1.3% of GDP every year. The environmental degradation caused by the discharge of untreated wastewater is estimated to cost an additional 1% of GDP every year.\n\nHowever, the failure to provide a continuous water supply does not appear to be a major bottleneck for the Lebanese, where water storage tanks are in common use. What matters is the water quality, which is often insufficient, and that households have enough water to keep the tanks supplied, which is not always the case.\n\nBecause of limited and contradictory data, it is difficult to accurately assess water resources availability in Lebanon. While Lebanon is water-rich compared to Jordan, Israel or the Damascus region in Syria, the country's per capita renewable water resources are below the threshold of water poverty set at 1,000 cubic meter per capita and year. Only part of the floodwater in rivers can be captured economically in dams, and some groundwater flows unused to the sea. Furthermore, 0.51 billion cubic meters of water flow to Syria in an average year, and 0.16 billion cubic meters to Israel. After subtraction of these amounts, 2.6 billion cubic meters of water are available in an average year, or about per capita. It is not clear if water from springs is counted as part of groundwater or surface water in the above estimate. There are over 2,000 springs with a flow of 1.15 billion cubic meters, sustaining a perennial flow for 17 of the total of 40 major streams in the country. Springs and groundwater are today by far the main sources for drinking water supply in Lebanon. For example, the city of Sidon has an abundance of natural wells supplying three times more water than the current needs of the city.\n\nThe main rivers that flow entirely inside Lebanon are the Litani river (average annual flow of 0.79 million cubic meter), the Ibrahim River (0.51), the Awali River and the Damour River (both 0.3). A large share of the Litani River is diverted through the Markaba tunnel for hydropower generation to the Awali River. Since the upper watershed of the Litani River is polluted and the Awali River is due to be tapped as a source of drinking water supply for Beirut, this water transfer has implications beyond its intended use for hydropower generation.\n\nTwo important rivers are shared with Syria and one with Israel. The Orontes River (0.48) that rises in Lebanon is shared with Syria. A 1994 agreement stipulates that Lebanon receives 80 million cubic meters of water per year \"if the river flow inside Lebanon is 400 million cubic meters per year or more\". This means that the risk of drought is borne by Lebanon. No new wells were allowed to be drilled in the Lebanese portion of the Orontes basin since the agreement has been signed. The El Kebir River (average flow of 0.19 million cubic meter per year) is also shared with Syria, the river itself forming part of the border between the two countries. The Hasbani River, a tributary of the Jordan River, also rises in Lebanon and is shared with Israel. Surface water flow into northern Israel from the Hasbani/Wazani complex is estimated at 160 million m3/year. There is no agreement about the sharing of the Jordan River between the two countries. When Lebanon diverted part of the Hasbani to supply a village in 2002, Israel stated that this could lead to war.\n\nWater resources are polluted by the discharge of untreated or insufficiently treated industrial and domestic wastewater, leaching from septic tanks, agricultural non-point sources such as pesticides and nitrates, hospital waste and domestic solid waste, as well as the discharge of motor oil. The Ghadir river in the South of Beirut is probably the most polluted river in the country, while the Wazzani River in South Lebanon may be the least polluted river because of limited economic activity in its basin. The discharge of untreated municipal and industrial effluents, the drainage from agricultural lands, and the uncontrolled discharge of solid wastes have considerably degraded the water quality of the Qaraoun Lake and the Litani River. Untreated industrial effluents are discharged into the lake and river from sugar-beet factories, paper factories, lead recovery plants, limestone crushers, agro-industries, poultry farms, tanneries and slaughterhouses. According to a 1998 study by the National Council of Scientific Research of Lebanon for UNICEF 60–70% percent of all natural sources were affected by bacterial contamination. An example is the Jeita spring, which has witnessed an increase in fecal coliform bacteria.\n\nData on water use in Lebanon are contradictory. Official estimates put total water use in 2010 at 1.59 billion m3, including 0.27 billion m3 (17%) from public wells for drinking water supply. In 2005, the FAO estimated water withdrawal was at 1.31 billion m3 or about 63% of economically exploitable water resources. Of this almost 60% was for agricultural purposes, 29% for municipal use and 11% for industry. The FAO does not provide the sources for these figures. Municipal use of 0.38 billion m3 would correspond to about 250 liter per capita per day based on these figures. An earlier estimate of the Ministry of Environment estimated water use at 1.29 billion m3 in 1994, including only 0.21 billion m3 for municipal use. This figure corresponds to 140 liter per capita per day, which fits well with a World Bank estimate of 150 liter per capita per day for municipal water use, ranging from 120 liter in Beirut-Mount Lebanon to 200 liter in the North.\n\nOf households connected to the public water system, only 53% drink it. The share is lowest in Nabatieh (27%) and highest in the Bekaa (77%). The most frequently cited reasons for not drinking public water are perception of safety relating to health and hygiene, and poor taste.\n\nThe level of non-revenue water was estimated at about 48% in 2010. It was estimated to be highest in the South (52%) and lowests in Beirut-Mount Lebanon (40%). This is high by international standards, but similar to the levels in Syria, Jordan and Turkey. Since there is little metering, it is difficult to estimate the level of non-revenue water. The share of metered connections was estimated at 16% in the Beirut-Mount Lebanon governorates in 2010, and was lower in other governorates. Most industrial and commercial water users were metered, while few residential users are metered.\n\nThe public water supply system in Greater Beirut receives its water from the Jeita springs (50 million m3/year) as well as well fields in the Damour region (30 million m3/year). The Jeita spring is the source of drinking water for about 1.5 million Lebanese. Water is treated in the Dbaiye water treatment plant north of the city with a capacity of 430,000m3/day (157 million m3/year). Besides the public network, around 1,000 mostly private wells are scattered in the area of Beirut. Their depth varies between 50 and 300m and their average individual discharge is 35 liters/second. Total water supply from these wells could be higher than through the public water supply, depending on how many hours the pumps run. Overpumping from wells in the Beirut area has led to seawater intrusion into aquifers.\n\nThe government plans to tap the Awali River to the Southeast of Beirut to provide the growing capital with 90 million m3/year of additional water, more than double the current resources. The project involves the construction of a dam at Bisri, a 3 km tunnel from the river to a new water treatment plant at Ouardaniye, and a second 22 km tunnel to Khalde south of Beirut, from where water will be transported through two twin pipelines, one going North to the center of Beirut and the second northeast to Baabda. The Islamic Development Bank has agreed to finance the construction of Bisri dam in 2008, while the World Bank has approved a US$200m loan in December 2010 to partly finance the transmission tunnels and pipelines. Lebanese critics of the project argue that the Awali River and especially the Litani River, from which water is diverted to the Awali River upstream of the planned intake, are highly polluted. They also say that less expensive alternatives, such as the less polluted Damour River that is also closer to Beirut, were not considered by the government and the World Bank. As of December 2013, less than 1 percent of the loan has been disbursed and no civil works contract has been awarded.\n\nThe Lebanese infrastructure has been badly scarred by the 1975–90 Civil War. After the war the water and sanitation infrastructure was rebuilt with substantial external financial assistance. In South Lebanon, which remained under Israeli occupation until 2000, the infrastructure was gradually rebuilt as the Israeli army withdrew. Compared to the substantial investment in infrastructure, little effort was made at building the capacity of sector institutions and at establishing policies that favor the sustainability and improve the quality of services provided. Also, wastewater treatment was neglected in terms of investments compared to water supply and sewerage. Untreated wastewater was thus discharged to the sea and to rivers. No efforts were made to conserve water. Still today, Lebanon is one of the few countries in the Middle East that has almost no water meters.\n\nExternal financing institutions were concerned with the insufficient capacity to operate and maintain the infrastructure they were financing in Lebanon. Until 2000 there were 21 water authorities in Lebanon who were financially and technically weak. The limited sewer networks, if they existed at all, were managed by the respective municipalities, which had often even less technical and financial capacity than the water authorities. In the absence of a sanitation tariff, municipalities lacked the financial resources to operate and maintain sanitation infrastructure. The experience with wastewater treatment plants is illustrative of the difficulties encountered. For example, the operating costs for the first wastewater treatment plant in Lebanon, the Al-Ghadir plant in Beirut completed in 1997, still have to be subsidized by the government because the municipal governments in the service area (the Beirut and Baabda districts) lack the resources to do so. Furthermore, incomplete infrastructure considerably reduces the development impact of the plant. Because the construction of sewers was delayed, most of the sewage of Southern Beirut still flowed into the Mediterranean without any treatment via both the Al Ghadir River and sea outlets. The Al Ghadir plant provides only preliminary treatment, followed by discharge through a 2.6 km marine outfall. The second wastewater treatment plant built in Lebanon, intended for the city of Baalbek and completed in 2001, could not be put into operation, because both the sewer system and the outfall main were not completed. Wastewater treatment plants in Tripoli and Sidon were inaugurated in 2009 and 2010 respectively, both long after they were due to be completed.\n\nAt the national level, policy-making was fragmented between the Ministry of Energy and Water in charge of drinking water supply and the Ministry of Interior in charge of sanitation, as well as other stakeholders such as the Ministry of Finance and the Ministry of Environment. The donors thus pressed for a sector reform that would create commercially oriented regional water and sanitation companies that would achieve economies of scale. In 2000 a new water law was passed that created four Regional Water Establishments. However, the transfer of actual responsibilities to them remained slow and the water authorities continued to remain in charge of operating infrastructure. The Council for Development and Reconstruction (CDR) also remained in charge of procuring works and consulting contracts, including service contracts to operate infrastructure despite the responsibilities bestowed on the new Establishments under the Water Law.\n\nAccording to a 2010 World Bank ten years after the Water Law has been passed it \"has not been fully enforced and implemented, thus creating institutional uncertainty over sector responsibilities\". Furthermore, \"the four RWEs severely lack managerial and financial autonomy and are impeded by limited inter-agency coordination and weak central government oversight. They have not been able to effectively operate and maintain water supply networks, fully engage with the private sector, recover costs and hire qualified staff\".\n\nIn 2003 the municipality of Tripoli signed the first and so far only management contract for water supply in Lebanon. This was done after four years of preparation that required passing a new law (Law 401) to allow public-private partnerships in water supply. The contract was awarded to the French company Ondéo‐Liban, a subsidiary of Suez Environnement, after a competitive bidding process. The cost of 20 million Euro was financed by the French Development Agency. The contract included the operation, maintenance, and installation of equipment, the organization of the billing system and collection of water tariffs, the management of human and financial resources, and the supervision of the construction of a tertiary water supply network and the expansion of a water treatment plant. The private company increased the billing efficiency from 30% to 60%, reduced water rationing, mapped the network, updated the customer inventory, computerized the accounting system and trained staff. Non-revenue water was reduced from 65% to 45% and the 10-year-long water rationing in the areas of Qalamoun, Qobbe and Abi Samra was eliminated, making Tripoli the only city in Lebanon that receives water 24 hours per day. Water quality and the customer service were also improved. However, cost recovery was not achieved despite an increase in tariffs because bill collection efficiency remained low. The company was unable to introduce metering, although 40,000 meters were acquired. The contract faced a number of challenges: According to a study by the French Institute for Public-Private Partnerships, the supervisory committee was composed of former employees of the public water company who were not convinced of the usefulness of private sector participation. Despite its achievements, the management contract ended in 2007 without being extended.\n\nWater infrastructure, especially in the South, was further damaged during the Israeli-Lebanese War of 2006. Israeli armed forces \"destroyed water tanks, springs and pipelines, leaving most of southern Lebanon totally cut off from mains water supply in the immediate aftermath of the war\", according to UN sources. The infrastructure was rebuilt after the war, partly by Hizbollah's construction company Jihad al-Bina. Foreign donors also played an important role in reconstruction, including UNICEF and Technisches Hilfswerk from Germany.\n\nThe Syrian Civil War has exacerbated Lebanon's water stress, as Syrian refugees have expanded Lebanon's population by a quarter. Humanitarian actors have sought to improve water infrastructure, but coordinated longer-term efforts will be needed to meet current needs and guard against water crises in the future.\n\nAmong the key public stakeholders in the Lebanese water and sanitation sector are the Ministry of Water and Energy, which is in charge of policy and regulation; the Ministry of Finance, which provides funding and coordinates external cooperation; the Ministry of Environment; the Council for Development and Reconstruction, which is in charge of most investments in the sector; and four Regional Water Establishments, which are in charge of service provision. The sector is characterized by a significant gap between legal responsibilities of stakeholders and their actual activities. The legal text to organize the work of MEW has not been developed as of 2012. MEW’s efforts are still dedicated to investment projects and not on policy and regulation. The Ministry still has units dedicated to investment studies, although these functions should have been transferred to the Water Establishments.\n\nWithin the Lebanese government the Ministry of Water and Energy is in charge of developing and implementing policies related to water supply and sanitation. As of 2010, there was no specific policy or strategy document outlining the government’s policy in the sector. The Ministry seems to focus on energy and to pay less attention to water, not to speak of sanitation.\n\nThe legal framework consists of the Water Law 221/2000 that reorganized the sector into four Regional Water Establishments. The law was amended twice shortly after it was passed: Law 241/2000 reduced the number of Regional Water Establishments from 5 to 4; and Law 337/2001 included wastewater treatment in the responsibilities of the Regional Water Establishments and of the Ministry of Water and Energy. In October 2005 some bylaws for the aforementioned laws were published.\n\nProvision of drinking water supply and wastewater treatment is the responsibility of the four Regional Water Establishments that were created by the 2000 Water Law:\n\n\nAlthough the establishments are legally responsible for irrigation and wastewater treatment, they are not engaged in these activities. There is no strategic or business planning, nor a focus on performance. There is a limited focus on IT and on asset management; customer service is fragmented. By law Lebanese water utilities should have 4,050 employees, but they actually had only 1,342 as of 2010. This is due to a hiring freeze imposed by the government. The number of employees has thus declined during the first decade of the 21st century. The gaps at the lower levels were partially filled with temporary laborers. But there are also important gaps in managerial positions. The average number of staff is less than 2 per 1000 connections, much below the regional average. The Beirut-Mount Lebanon utility has only 1.6 staff per 1000 connections. Utilities are thus unable to perform some of their basic functions. The Board members of the Water Establishments are nominated by the Cabinet upon the proposition of the Minister of Energy and Water. Municipalities have no say in the nomination of Board members. There have been only limited attempts to involve the private sector in operating water and sewer systems. A management contract for the city of Tripoli with a French firm has not been renewed after it expired (see history section).\n\nThe operation and maintenance of sewer systems remains under the responsibility of municipalities.\n\nThe Council for Development and Reconstruction (CDR) plays a major role in the sector, because it is responsible for the planning and construction of much of the public water investments and all wastewater investments in the country. It is also the implementing agency for most investment programs financed by external agencies. In addition, the Council of the South and the Central Fund for the Displaced have financed almost half of all investments in water supply in Lebanon during the late 1990s and early 2000s. The Council for the South, nominally under the Primer Minister's Office, is controlled by the mostly Shiite Amal Movement of Nabih Berri, the speaker of Lebanon's Parliament since 1992.\n\nTariffs are set at different levels for each of the four regional water establishments. Within each service area tariffs are the same, although costs differ significantly. For example, Beirut receives most of its water by gravity, while in some other localities water needs to be pumped. The following table shows residential water tariffs for the four regional utilities per year and per connection for 1m3/day, excluding VAT.\n\nThe level of consumption is limited to 1m3 per day by a gauge installed on all residential connections. However, actual consumption is typically lower because of intermittent supply and low water pressure. The price of water per cubic meter obviously depends on the level of consumption, which varies and is not well known. Assuming an average-size household with 4.5 members that receives 100 liter per capita per day, the price of water is almost US$1/m3 in Beirut and US$0.66/m3 in the Bekaa. Tariffs in Lebanon thus are higher than in Jordan (US$0.65/m3 including sanitation) and much higher than in Syria or in Egypt (US$0.05/m3).\n\nThe water bill has to be paid in full in advance for an entire year, which imposes a heavy burden on the poor. A household in the poorest quintile connected to the network paid an average of LBP 421,000 for water in 2008, corresponding to 3.7% of its income. More than half of these expenditures are for alternative water sources such as bottled water or water from trucks.\n\nCost recovery varies between utilities. The collection rate (i.e. the shares of bills actually paid) in Beirut-Mount Lebanon has been consistent at almost 90%, so that the utility had accumulated over US$170 million as cash surplus in 2010. However, as of 2010 it was estimated to be only 62%. In the three other Regional Water Establishments collection rates are lower at 58% in the North, 52% in the South and only 18% in the Bekaa. In the three Establishments not even operating costs are recovered. The Government often steps in to pay for operating expenses in addition to financing investments in water infrastructure. Cost recovery is lowest for the Bekaa water company. According to a World Bank report, \"there appears to be an informal understanding between water companies and households: many households don’t receive their water allotment, and the water companies often don’t pressure households to pay their bills.\" Given the current conditions and alternatives, households have stated in surveys that they are reluctant to pay more for better public service. Even where meters have been installed, there is no volumetric tariff. Flat fees are charged regardless of the existence of the meters. There thus is no financial incentive to save water. There is also no wastewater tariff.\n\nPublic investment for water and wastewater sector amounted to 0.4 percent of GDP in the late 90s and early 2000s. This includes US$97m for water supply and US$32m for sanitation every year. Investments are to a large extent financed by external grants and loans. For example, 73% of CDR-executed investments in the water sector were financed by external donors and 56% of its wastewater investments.\n\nMany external partners have supported and continue to support the Lebanese water and sanitation sector with financial and technical assistance. These include the Arab Fund for Economic and Social Development, the European Investment Bank (EIB), France, Germany, Italy, Japan, Kuwait, Saudi Arabia, the United States and the World Bank. The donors in the water and sanitation sector tend to focus on particular regions of Lebanon: The Arab Fund focuses on the South and Beirut, The EIB on Mount Lebanon and the North, France on the North and the South, Germany on Beirut and Mount Lebanon, Japan on Mount Lebanon and the South, and the U.S. on the South. The World Bank is one of the few donors active in the Bekaa, in addition to Beirut. Most external financial assistance is in the form of loans, while technical assistance is typically in the form of grants. In the aftermath of the 2006 Israeli-Lebanese war the country received substantial additional financial assistance, including grants from countries and agencies that normally provide only loans for infrastructure development in Lebanon, such as Germany and the World Bank. Most external assistance is channeled through the government, except for U.S. assistance, which is provided directly to consulting firms working in cooperation with the government or NGOs. The United Nations also plays an important role in the Lebanese water sector, particularly through UNICEF and the United Nations Development Program (UNDP).\n\nDonor coordination in Lebanon is the responsibility of a donor coordination unit in the Ministry of Finance, which itself is supported by UNDP. In many countries where multiple donors provide aid to the water and sanitation sector there is some form of a water-specific donor coordination mechanism. This does not seem to be the case in Lebanon.\n\nThe Arab Fund for Economic and Social Development financed a water project in Sidon and Sour (Kuwaiti Dinar 10m approved in 1996), Beirut (Kuwaiti Dinar 17m approved in 2002) and for water and wastewater in various other areas of Lebanon (Kuwaiti Dinar 25m in 2006).\n\nThe European Union supported a national water dialogue on Integrated Water Resources Management \nas part of the Mediterranean component of the EU Water Initiative. The dialogue, which included NGOs and the private sector in addition to government representatives and donors, was kicked off by a meeting in November 2005. Its numerous objectives included to \"identify insufficiencies and bottlenecks in key prerequisites posed by donors for national investments on the water sector\", the \"establishment of a permanent platform for cooperation between key involved partners at the national level including donor agencies\" and the endorsement of a \"national roadmap\". A second \"consultation seminar\" in April 2009 did not mention any more the objectives of the 2005 seminar, but instead offered numerous recommendations for the future, such as \"to plan together the follow-up steps that can constribute to an Integrated Water Resources Management Resources Management process in the country\".\n\nThe European Investment Bank financed a wastewater treatment plant in Tripoli and water treatment facilities in the touristic Keserwan District.\n\nThe French Development Agency (AFD) supports numerous water and sanitation projects in Lebanon. Under a 2m Euro loan the water distribution network in the Southern town of Jezzine was rehabilitated after the retreat of the Israeli army in 1999. Another 12m Euro loan was approved in 2001 to build an \"emergency\" bulk water supply line and to rehabilitate distribution networks in the Southern towns of Nabah El Tasseh and Jabal Amel. In 2007 AFD approved a small grant to rehabilitate the water network of the Southern town of Bkassine with co-financing provided by the French city Lille.\n\nIn Tripoli a 20m Euro project supported the extension of a water treatment plant and the strengthening of the distribution network since 2001, supporting the public-private partnership with the French company Ondeo initiated subsequently. A 30m Euro sanitation loan approved in 2004 allowed the construction of sewers in Tripoli. In October 2012 the Ministry of Water and AFD signed a US$90.7 million project to contribute to the financing of a US$200 million wastewater project in Keserwan District in Mount Lebanon.\n\nGermany has committed funds to improve sanitation in localities close to the Jeita springs to reduce bacteriological pollution of this important spring that is the main water source of Beirut and other localities. It also supported sanitation in Beirut and a reconstruction project in the South It also provides technical assistance to support water sector reform through a project that ran from 2008 to the end of 2013, implemented by GIZ (ex-GTZ). The project aimed to strengthen the regulatory capacity of MEW, the technical and management capacities of the four Water Establishments and\nto improve relations between customers and the Establishments. Among other activities, it systematically collected data on performance indicators (benchmarking), prepared business plans, valued fixed assets and identified all customers. The project also established water balances in pilot areas where customer meters had been installed, carried out customer satisfaction surveys in the same areas, and prepared the ground for the adoption for consumption-based tariffs. However, these tariffs are not yet applied. It also tried to prepare the Establishments for taking over their responsibilities in wastewater management through a “Declaration of Principles towards Sustainable Wastewater Management\". However, the Establishments have not yet taken over this responsibility.\n\nThe German public disaster relief organization Technisches Hilfswerk (THW), which works mainly through volunteers, provided emergency assistance in the South only days after the 2006 hostilities ended. It first installed a laboratory and carried out drinking water analyses. Afterwards it installed chlorination equipment in 30 tanks benefiting 15,000 people, constructed a water tower and repaired three other water towers. THW worked on behalf of the German government, the Humanitarian Aid department of the European Commission (ECHO) and UNICEF.\n\nThe Islamic Development Bank has agreed to finance the construction of Bisri dam in 2008. The dam on the Awali River will store water that is to be supplied as drinking water to Beirut.\n\nItaly supports the Lebanese water and sanitation sector through various technical assistance grants, including a US$1.8m grant approved in 2010 to create a \"Lebanese center for water management and preservation\" and a hydrological study in an unspecified area in cooperation with UNDP. The Center for Water Management and Preservation, to be located in the Ministry of Water and Energy and to be established with the help of UNDP and Italian funding over a 2-year period, is supposed to \"coordinate on-going water programmes\", \"develop an action plan on sustainable water policy\" and to achieve \"national public awareness raising\", among other things. Lebanon also received water monitoring equipment from Italy to be installed on the Orontes River, as well as the Hasbani River and the Wazzani spring. The two latter flow into Israel.\n\nJapan provided a soft loan (25 years maturity, 7 grace years, 2.5% interest) of about US$120m for wastewater collection and treatment in Sidon and water supply in Keserwan District in 1996. In Sidon the project was to finance a sewer network with a length of 38 km, a trunk sewer with a length of 7 km, two sewage pumping stations and a preliminary treatment plant with a capacity of 33,600m3/day. Later the design was changed to add the financing of a 2 km sea outfall, increase the capacity of the treatment plant to 45,000 m3/day, increase the number of pumping stations to 13 and to reduce the length of sewers financed. The construction of the wastewater treatment plant was finished in 2006, but it became operational only in 2010 when at least some of the trunk sewers were finally connected to the plant. In Keserwan District Japan finances the expansion of a water intake at the Al Madiq spring, 50 km of transmission mains, 13 pumping stations 22 service reservoirs and 202 km of distribution mains. The project will alleviate water scarcity in a number of villages where demand is twice as high as available supply. As of 2008, a centerpiece of the project—a 4 km tunnel with a diameter of almost 4m—was under construction.\n\nThe Kuwait Fund for Arab Economic Development has provided 55m Kuwaiti Dinar (US$187m) in soft loans (2.5% interest, 24–30 years maturity) for water supply and sanitation between 1993 and 2010. The projects are located in Beirut, the South and the Matn District in Mount Lebanon governorate. The latest water project supported by Kuwait in Lebanon is the Qaisamani Dam, which will provide 35 villages in Mount Lebanon with drinking water and for which a US$19m loan agreement was signed in 2010.\n\nUSAID provides US$8m technical assistance and training, limited-scale infrastructure activities, and specialized equipment for the Litani River Authority, transforming the Authority in a \"river basin agency\". It also provides US$19.5m to improve the management, operations and services of the four Regional Water Establishments, including a \"national strategic water and wastewater master plan\". Memoranda of understanding about both programs were signed in June 2010.\n\nThe first project builds on a previous U.S.-supported project that helped the South Lebanon Water Establishment to become—according to the consulting firm who works on the project, DAI—\"a model for the other water establishments in Lebanon.\" The project introduced a business plan and a financial model for the utility. It attempted to replicate the positive experience in the South to the Beirut/Mount Lebanon Water Establishment, but faced difficulties there because of a lack of support from management. The project also tried to promote public-private partnerships (PPPs) through the establishment of a PPP unit in the Ministry of Energy and Water. The work of the unit has had little impact and \"all activities related to PPP (were put) on hold due to the absence of a clear vision regarding PPP in the country\". The project also aimed to develop a new tariff strategy, but actually carried out an assessment of current revenues and scenarios for future revenues. Furthermore, substantial training was carried out and a South Lebanon Wastewater Master Plan was developed. Last but not least production and zone meters were installed in Sidon, the only city in the South and one of the few localities in the entire country that has customer meters. However, it is unclear if the meters are actually being read. The final report of the project concludes, among other things, that there is a lack of sufficient qualified staff in the regional water establishments, a lack of accurate operational and financial data, and a lack of local firms specialized in the development and implementation of financial and accounting systems.\n\nThe World Bank has supported the Lebanese water and sanitation sector since 1993 when it approved an Emergency Reconstruction and Rehabilitation Project. With the help of the project water systems in 97 communities were rehabilitated or built, as were 98 small sewerage systems. After the Israeli withdrawal from South Lebanon, 5 additional water and sewerage systems were rehabilitated benefiting 140 communities. The project also rehabilitated or expanded three large water productions and distribution systems and wastewater treatment plants Baalbek, Metn and Barouk. Because complementary works, to be financed by other sources, had not been completed on time, these facilities were inoperative as of 2006. In particular, the Baalbek wastewater treatment plant (13,000 m3/day capacity), completed in early 2002, was not connected to the sewerage system. The World Bank continued to support water supply and sanitation in Baalbek through a US$43.5m loan approved in 2002. This was followed by a US$15m emergency grant in 2007 to support the rehabilitation and expansion of water supply systems in five villages in the Western Bekaa Valley. In December 2010, the World Bank approved a US$200m loan to support the Greater Beirut Water Supply Project. The World Bank had to cancel a previous loan for submarine treated wastewater outfalls in Kesrouan and Sour approved in 1998 after the government had not ratified the corresponding loan agreements.\n\nA number of foreign and local non-governmental organizations (NGOs) are active in the Lebanese water and sanitation sector. For example, NGOs such as the YMCA, the Mercy Corps, CHF International and the Pontifical Mission built 13 small wastewater treatment plants throughout the country during the 1990s with funding from USAID.\n\n\n"}
{"id": "33959", "url": "https://en.wikipedia.org/wiki?curid=33959", "title": "Witchcraft", "text": "Witchcraft\n\nWitchcraft or witchery broadly means the practice of and belief in magical skills and abilities exercised by solitary practitioners and groups. \"Witchcraft\" is a broad term that varies culturally and societally, and thus can be difficult to define with precision, and cross-cultural assumptions about the meaning or significance of the term should be applied with caution. Witchcraft often occupies a religious divinatory or medicinal role, and is often present within societies and groups whose cultural framework includes a magical world view.\n\nThe concept of witchcraft and the belief in its existence have persisted throughout recorded history. They have been present or central at various times and in many diverse forms among cultures and religions worldwide, including both \"primitive\" and \"highly advanced\" cultures, and continue to have an important role in many cultures today. Scientifically, the existence of magical powers and witchcraft are generally believed to lack credence and to be unsupported by high-quality experimental testing, although individual witchcraft practices and effects may be open to scientific explanation or explained via mentalism and psychology.\n\nHistorically, the predominant concept of witchcraft in the Western world derives from Old Testament laws against witchcraft, and entered the mainstream when belief in witchcraft gained Church approval in the Early Modern Period. It posits a theosophical conflict between good and evil, where witchcraft was generally evil and often associated with the Devil and Devil worship. This culminated in deaths, torture and scapegoating (casting blame for human misfortune), and many years of large scale witch-trials and witch hunts, especially in Protestant Europe, before largely ceasing during the European Age of Enlightenment. Christian views in the modern day are diverse and cover the gamut of views from intense belief and opposition (especially from Christian fundamentalists) to non-belief, and in some churches even approval. From the mid-20th century, witchcraft – sometimes called contemporary witchcraft to clearly distinguish it from older beliefs – became the name of a branch of modern paganism. It is most notably practiced in the Wiccan and modern witchcraft traditions, and no longer practices in secrecy.\n\nThe Western mainstream Christian view is far from the only societal perspective about witchcraft. Many cultures worldwide continue to have widespread practices and cultural beliefs that are loosely translated into English as \"witchcraft\", although the English translation masks a very great diversity in their forms, magical beliefs, practices, and place in their societies. During the Age of Colonialism, many cultures across the globe were exposed to the modern Western world via colonialism, usually accompanied and often preceded by intensive Christian missionary activity \"(see \"Christianization\")\". Beliefs related to witchcraft and magic in these cultures were at times influenced by the prevailing Western concepts. Witch hunts, scapegoating, and killing or shunning of suspected witches still occurs in the modern era, with killings both of victims for their supposedly magical body parts, and of suspected witchcraft practitioners.\n\nSuspicion of modern medicine due to beliefs about illness being due to witchcraft also continues in many countries to this day, with tragic healthcare consequences. HIV/AIDS and Ebola virus disease are two examples of often-lethal infectious disease epidemics whose medical care and containment has been severely hampered by regional beliefs in witchcraft. Other severe medical conditions whose treatment is hampered in this way include tuberculosis, leprosy, epilepsy and the common severe bacterial Buruli ulcer. Public healthcare often requires considerable education work related to epidemology and modern health knowledge in many parts of the world where belief in witchcraft prevails, to encourage effective preventive health measures and treatments, to reduce victim blaming, shunning and stigmatization, and to prevent the killing of people and endangering of animal species for body parts believed to convey magical abilities.\n\nThe word \"witch\" is of uncertain origin. There are numerous etymologies that it could be derived from. One popular belief is that it is \"related to the English words wit, wise, wisdom [Germanic root *weit-, *wait-, *wit-; Indo-European root *weid-, *woid-, *wid-],\" so \"craft of the wise.\" Another is from the Old English wiccecræft, a compound of \"wicce\" (\"witch\") and \"cræft\" (\"craft\").\n\nIn anthropological terminology, witches differ from sorcerers in that they don't use physical tools or actions to curse; their maleficium is perceived as extending from some intangible inner quality, and one may be unaware of being a witch, or may have been convinced of his/her nature by the suggestion of others. This definition was pioneered in a study of central African magical beliefs by E. E. Evans-Pritchard, who cautioned that it might not correspond with normal English usage.\n\nHistorians of European witchcraft have found the anthropological definition difficult to apply to European witchcraft, where witches could equally use (or be accused of using) physical techniques, as well as some who really had attempted to cause harm by thought alone. European witchcraft is seen by historians and anthropologists as an ideology for explaining misfortune; however, this ideology has manifested in diverse ways, as described below.\n\nHistorically the witchcraft label has been applied to practices people believe influence the mind, body, or property of others against their will—or practices that the person doing the labeling believes undermine social or religious order. Some modern commentators believe the malefic nature of witchcraft is a Christian projection. The concept of a magic-worker influencing another person's body or property against their will was clearly present in many cultures, as traditions in both folk magic and religious magic have the purpose of countering malicious magic or identifying malicious magic users. Many examples appear in early texts, such as those from ancient Egypt and Babylonia. Malicious magic users can become a credible cause for disease, sickness in animals, bad luck, sudden death, impotence and other such misfortunes. Witchcraft of a more benign and socially acceptable sort may then be employed to turn the malevolence aside, or identify the supposed evil-doer so that punishment may be carried out. The folk magic used to identify or protect against malicious magic users is often indistinguishable from that used by the witches themselves.\n\nThere has also existed in popular belief the concept of white witches and white witchcraft, which is strictly benevolent. Many neopagan witches strongly identify with this concept, and profess ethical codes that prevent them from performing magic on a person without their request.\n\nWhere belief in malicious magic practices exists, such practitioners are typically forbidden by law as well as hated and feared by the general populace, while beneficial magic is tolerated or even accepted wholesale by the people – even if the orthodox establishment opposes it.\n\nProbably the most widely known characteristic of a witch was the ability to cast a spell, \"spell\" being the word used to signify the means employed to carry out a magical action. A spell could consist of a set of words, a formula or verse, or a ritual action, or any combination of these. Spells traditionally were cast by many methods, such as by the inscription of runes or sigils on an object to give it magical powers; by the immolation or binding of a wax or clay image (poppet) of a person to affect him or her magically; by the recitation of incantations; by the performance of physical rituals; by the employment of magical herbs as amulets or potions; by gazing at mirrors, swords or other specula (scrying) for purposes of divination; and by many other means.\n\nIn Christianity and Islam, sorcery came to be associated with heresy and apostasy and to be viewed as evil. Among the Catholics, Protestants, and secular leadership of the European Late Medieval/Early Modern period, fears about witchcraft rose to fever pitch and sometimes led to large-scale witch-hunts. The key century was the fifteenth, which saw a dramatic rise in awareness and terror of witchcraft, culminating in the publication of the \"Malleus Maleficarum\" but prepared by such fanatical popular preachers as Bernardino of Siena. Throughout this time, it was increasingly believed that Christianity was engaged in an apocalyptic battle against the Devil and his secret army of witches, who had entered into a diabolical pact. In total, tens or hundreds of thousands of people were executed, and others were imprisoned, tortured, banished, and had lands and possessions confiscated. The majority of those accused were women, though in some regions the majority were men. In early modern Scots, the word Warlock came to be used as the male equivalent of witch (which can be male or female, but is used predominantly for females). From this use, the word passed into Romantic literature and ultimately 20th-century popular culture. Accusations of witchcraft were often combined with other charges of heresy against such groups as the Cathars and Waldensians.\n\nThe \"Malleus Maleficarum,\" (Latin for \"Hammer of The Witches\") was a witch-hunting manual written in 1486 by two German monks, Heinrich Kramer and Jacob Sprenger. It was used by both Catholics and Protestants for several hundred years, outlining how to identify a witch, what makes a woman more likely than a man to be a witch, how to put a witch on trial, and how to punish a witch. The book defines a witch as evil and typically female. The book became the handbook for secular courts throughout Renaissance Europe, but was not used by the Inquisition, which even cautioned against relying on the work, and was later officially condemned by the Catholic Church in 1490.\n\nIn the modern Western world, witchcraft accusations have often accompanied the satanic ritual abuse moral panic. Such accusations are a counterpart to blood libel of various kinds, which may be found throughout history across the globe.\n\nThroughout the early modern period, the English term \"witch\" was not exclusively negative in meaning, and could also indicate cunning folk. As Alan McFarlane noted, \"There were a number of interchangeable terms for these practitioners, 'white', 'good', or 'unbinding' witches, blessers, wizards, sorcerers, however 'cunning-man' and 'wise-man' were the most frequent.\" The contemporary Reginald Scot explained, \"At this day it is indifferent to say in the English tongue, 'she is a witch' or 'she is a wise woman'\". Folk magicians throughout Europe were often viewed ambivalently by communities, and were considered as capable of harming as of healing, which could lead to their being accused as \"witches\" in the negative sense. Many English \"witches\" convicted of consorting with demons seem to have been cunning folk whose fairy familiars had been demonised; many French \"devins-guerisseurs\" (\"diviner-healers\") were accused of witchcraft, and over one half the accused witches in Hungary seem to have been healers.\n\nSome of the healers and diviners historically accused of witchcraft have considered themselves mediators between the mundane and spiritual worlds, roughly equivalent to shamans. Such people described their contacts with fairies, spirits often involving out-of-body experiences and travelling through the realms of an \"other-world\".\nBeliefs of this nature are implied in the folklore of much of Europe, and were explicitly described by accused witches in central and southern Europe. Repeated themes include participation in processions of the dead or large feasts, often presided over by a horned male deity or a female divinity who teaches magic and gives prophecies; and participation in battles against evil spirits, \"vampires\", or \"witches\" to win fertility and prosperity for the community.\n\nÉva Pócs states that reasons for accusations of witchcraft fall into four general categories:\n\nShe identifies three varieties of witch in popular belief:\n\"Neighbourhood witches\" are the product of neighbourhood tensions, and are found only in self-sufficient serf village communities where the inhabitants largely rely on each other. Such accusations follow the breaking of some social norm, such as the failure to return a borrowed item, and any person part of the normal social exchange could potentially fall under suspicion. Claims of \"sorcerer\" witches and \"supernatural\" witches could arise out of social tensions, but not exclusively; the supernatural witch in particular often had nothing to do with communal conflict, but expressed tensions between the human and supernatural worlds; and in Eastern and Southeastern Europe such supernatural witches became an ideology explaining calamities that befell entire communities.\n\nBelief in witchcraft continues to be present today in some societies and accusations of witchcraft are the trigger of serious forms of violence, including murder. Such incidents are common in places such as Burkina Faso, Ghana, India, Kenya, Malawi, Nepal and Tanzania. Accusations of witchcraft are sometimes linked to personal disputes, jealousy, and conflicts between neighbors or family over land or inheritance. Witchcraft-related violence is often discussed as a serious issue in the broader context of violence against women.\n\nIn Tanzania, about 500 older women are murdered each year following accusations against them of witchcraft or of being a witch. Apart from extrajudicial violence, there is also state-sanctioned violence in some jurisdictions. For instance, in Saudi Arabia practicing witchcraft and sorcery is a crime punishable by death and the country has executed people for this crime in 2011, 2012 and 2014.\n\nChildren in some regions of the world, such as parts of Africa, are also vulnerable to violence related to witchcraft accusations. Such incidents have also occurred in immigrant communities in the UK, including the much publicized case of the murder of Victoria Climbié.\n\nModern practices identified by their practitioners as \"witchcraft\" have grown dramatically since the early 20th century. Generally portrayed as revivals of pre-Christian European ritual and spirituality, they are understood to involve varying degrees of magic, shamanism, folk medicine, spiritual healing, calling on elementals and spirits, veneration of ancient deities and archetypes, and attunement with the forces of nature.\n\nThe first Neopagan groups to publicly appear, during the 1950s and 60s, were Gerald Gardner's Bricket Wood coven and Roy Bowers' Clan of Tubal Cain. They operated as initiatory secret societies. Other individual practitioners and writers such as Paul Huson also claimed inheritance to surviving traditions of witchcraft.\n\nDuring the 20th century, interest in witchcraft in English-speaking and European countries began to increase, inspired particularly by Margaret Murray's theory of a pan-European witch-cult originally published in 1921, since discredited by further careful historical research. Interest was intensified, however, by Gerald Gardner's claim in 1954 in \"Witchcraft Today\" that a form of witchcraft still existed in England. The truth of Gardner's claim is now disputed too, with different historians offering evidence for or against the religion's existence prior to Gardner.\n\nThe Wicca that Gardner initially taught was a witchcraft religion having a lot in common with Margaret Murray's hypothetically posited cult of the 1920s. Indeed, Murray wrote an introduction to Gardner's \"Witchcraft Today\", in effect putting her stamp of approval on it. Wicca is now practised as a religion of an initiatory secret society nature with positive ethical principles, organised into autonomous covens and led by a High Priesthood. There is also a large \"Eclectic Wiccan\" movement of individuals and groups who share key Wiccan beliefs but have no initiatory connection or affiliation with traditional Wicca. Wiccan writings and ritual show borrowings from a number of sources including 19th and 20th-century ceremonial magic, the medieval grimoire known as the Key of Solomon, Aleister Crowley's Ordo Templi Orientis and pre-Christian religions. Both men and women are equally termed \"witches.\" They practice a form of duotheistic universalism.\n\nSince Gardner's death in 1964, the Wicca that he claimed he was initiated into has attracted many initiates, becoming the largest of the various witchcraft traditions in the Western world, and has influenced other Neopagan and occult movements.\n\nWiccan literature has been described as aiding the empowerment of young women through its lively portrayal of female protagonists. Part of the recent growth in Neo-Pagan religions has been attributed to the strong media presence of fictional works such as the Buffy the Vampire Slayer and Harry Potter series with their depictions of witchcraft. Widespread accessibility to related material through internet media such as chat rooms and forums is also thought to be driving this development. Wiccan beliefs are currently often found to be compatible with liberal ideals such as the Green movement, and particularly with feminism by providing young women with means for empowerment and for control of their own lives. This is the case particularly in North America due to the strong presence of feminist ideals. The 2002 study Enchanted Feminism: The Reclaiming Witches of San Francisco suggests that Wiccan religion represents the second wave of feminism that has also been redefined as a religious movement.\n\nStregheria is an Italian witchcraft religion popularised in the 1980s by Raven Grimassi, who claims that it evolved within the ancient Etruscan religion of Italian peasants who worked under the Catholic upper classes.\n\nModern Stregheria closely resembles Charles Leland's controversial late-19th-century account of a surviving Italian religion of witchcraft, worshipping the Goddess Diana, her brother Dianus/Lucifer, and their daughter Aradia. Leland's witches do not see Lucifer as the evil Satan that Christians see, but a benevolent god of the Sun and Moon).\n\nThe ritual format of contemporary Stregheria is roughly similar to that of other Neopagan witchcraft religions such as Wicca. The pentagram is the most common symbol of religious identity. Most followers celebrate a series of eight festivals equivalent to the Wiccan Wheel of the Year, though others follow the ancient Roman festivals. An emphasis is placed on ancestor worship.\n\nTraditional witchcraft is a term used to refer to a variety of contemporary forms of witchcraft. Pagan studies scholar Ethan Doyle White described it as \"a broad movement of aligned magico-religious groups who reject any relation to Gardnerianism and the wider Wiccan movement, claiming older, more \"traditional\" roots. Although typically united by a shared aesthetic rooted in European folklore, the Traditional Craft contains within its ranks a rich and varied array of occult groups, from those who follow a contemporary Pagan path that is suspiciously similar to Wicca to those who adhere to Luciferianism\". According to British Traditional Witch Michael Howard, the term refers to \"any non-Gardnerian, non-Alexandrian, non-Wiccan or pre-modern form of the Craft, especially if it has been inspired by historical forms of witchcraft and folk magic\". Another definition was offered by Daniel A. Schulke, the current Magister of the Cultus Sabbati, when he proclaimed that \"traditional witchcraft\" \"refers to a coterie of initiatory lineages of ritual magic, spellcraft and devotional mysticism\". Some forms of traditional witchcraft are the Feri Tradition, Cochrane's Craft and the Sabbatic craft.\n\nSatanism is a broad term referring to diverse beliefs that share a symbolic association with, or admiration for, Satan, who is seen as a liberating figure. While it is heir to the same historical period and pre-Enlightenment beliefs that gave rise to modern witchcraft, it is generally seen as completely separate from modern witchcraft and Wicca, and has little or no connection to them.\n\nModern witchcraft considers Satanism to be the \"dark side of Christianity\" rather than a branch of Wicca: – the character of Satan referenced in Satanism exists only in the theology of the three Abrahamic religions, and Satanism arose as, and occupies the role of, a rebellious counterpart to Christianity, in which all is permitted and the self is central. (Christianity can be characterized as having the diametrically opposite views to these.) Such beliefs become more visibly expressed in Europe after the Enlightenment, when works such as Milton's \"Paradise Lost\" were described anew by romantics who suggested that they presented the biblical Satan as an allegory representing crisis of faith, individualism, free will, wisdom and enlightenment; a few works from that time also begin to directly present Satan in a less negative light, such as \"Letters from the Earth\". The two major trends are theistic Satanism and atheistic Satanism; the former venerates Satan as a supernatural patriarchal deity, while the latter views Satan as merely a symbolic embodiment of certain human traits.\n\nOrganized groups began to emerge in the mid 20th century, including the Ophite Cultus Satanas (1948) and The Church of Satan (1966). After seeing Margaret Murray's book \"The God of the Witches\" the leader of Ophite Cultus Satanas, Herbert Arthur Sloane, said he realized that the horned god was Satan (\"Sathanas\"). Sloane also corresponded with his contemporary Gerald Gardner, founder of the Wicca religion, and implied that his views of Satan and the horned god were not necessarily in conflict with Gardner's approach. However, he did believe that, while \"gnosis\" referred to knowledge, and \"Wicca\" referred to wisdom, modern witches had fallen away from the true knowledge, and instead had begun worshipping a fertility god, a reflection of the creator god. He wrote that \"the largest existing body of witches who are true Satanists would be the Yezedees\". Sloane highly recommended the book \"The Gnostic Religion\", and sections of it were sometimes read at ceremonies. It was estimated that there were up to 100,000 Satanists worldwide by 2006, twice the number estimated in 1990. Satanistic beliefs have been largely permitted as a valid expression of religious belief in the West. For example, they were allowed in the British Royal Navy in 2004, and an appeal was considered in 2005 for religious status as a right of prisoners by the Supreme Court of the United States. Contemporary Satanism is mainly an American phenomenon, although it began to reach Eastern Europe in the 1990s around the time of the fall of the Soviet Union.\n\nLuciferianism, on the other hand, is a belief system and does not revere the devil figure or most characteristics typically affixed to Satan. Rather, Lucifer in this context is seen as one of many morning stars, a symbol of enlightenment, independence and human progression. Madeline Montalban was an English witch who adhered to a specific form of luciferianism which revolved around the veneration of Lucifer, or Lumiel, whom she considered to be a benevolent angelic being who had aided humanity's development. Within her Order, she emphasised that her followers discover their own personal relationship with the angelic beings, including Lumiel. Although initially seeming favourable to Gerald Gardner, by the mid-1960s she had become hostile towards him and his Gardnerian tradition, considering him to be \"a 'dirty old man' and sexual pervert.\" She also expressed hostility to another prominent Pagan Witch of the period, Charles Cardell, although in the 1960s became friends with the two Witches at the forefront of the Alexandrian Wiccan tradition, Alex Sanders and his wife, Maxine Sanders, who adopted some of her Luciferian angelic practices. In contemporary times luciferian witches exist within traditional witchcraft.\n\nThe belief in sorcery and its practice seem to have been widespread in the Ancient Near East and Nile Valley. It played a conspicuous role in the cultures of ancient Egypt and in Babylonia. The latter tradition included an Akkadian anti-witchcraft ritual, the Maqlû. A section from the Code of Hammurabi (about 2000 B.C.) prescribes:\n\nAccording to the New Advent Catholic Encyclopedia: \n\nThe King James Version uses the words \"witch\", \"witchcraft\", and \"witchcrafts\" to translate the Masoretic \"kāsháf\" () and (\"qésem\"); these same English terms are used to translate \"pharmakeia\" in the Greek New Testament. Verses such as and (\"Thou shalt not suffer a witch to live\") thus provided scriptural justification for Christian witch hunters in the early modern period (see Christian views on magic).\n\nThe precise meaning of the Hebrew , usually translated as \"witch\" or \"sorceress\", is uncertain. In the Septuagint, it was translated as \"pharmakeía\" or \"pharmakous\". In the 16th century, Reginald Scot, a prominent critic of the witch trials, translated , φαρμακεία, and the Vulgate's Latin equivalent \"veneficos\" as all meaning \"poisoner\", and on this basis, claimed that \"witch\" was an incorrect translation and poisoners were intended. His theory still holds some currency, but is not widely accepted, and in is listed alongside other magic practitioners who could interpret dreams: magicians, astrologers, and Chaldeans. Suggested derivations of include \"mutterer\" (from a single root) or \"herb user\" (as a compound word formed from the roots \"kash\", meaning \"herb\", and \"hapaleh\", meaning \"using\"). The Greek φαρμακεία literally means \"herbalist\" or one who uses or administers drugs, but it was used virtually synonymously with \"mageia\" and \"goeteia\" as a term for a sorcerer.\n\nThe Bible provides some evidence that these commandments against sorcery were enforced under the Hebrew kings:\nNote that the Hebrew word \"ob\", translated as \"familiar spirit\" in the above quotation, has a different meaning than the usual English sense of the phrase; namely, it refers to a spirit that the woman is familiar with, rather than to a spirit that physically manifests itself in the shape of an animal.\n\nThe New Testament condemns the practice as an abomination, just as the Old Testament had (Galatians 5:20, compared with Revelation 21:8; 22:15; and Acts 8:9; 13:6). The word in most New Testament translations is \"sorcerer\"/\"sorcery\" rather than \"witch\"/\"witchcraft\".\n\nJewish law views the practice of witchcraft as being laden with idolatry and/or necromancy; both being serious theological and practical offenses in Judaism. Although Maimonides vigorously denied the efficacy of all methods of witchcraft, and claimed that the Biblical prohibitions regarding it were precisely to wean the Israelites from practices related to idolatry. It is acknowledged that while magic exists, it is forbidden to practice it on the basis that it usually involves the worship of other gods. Rabbis of the Talmud also condemned magic when it produced something other than illusion, giving the example of two men who use magic to pick cucumbers (Sanhedrin 67a). The one who creates the illusion of picking cucumbers should not be condemned, only the one who actually picks the cucumbers through magic.\n\nHowever, some of the rabbis practiced \"magic\" themselves or taught the subject. For instance, Rabbah created a person and sent him to Rav Zeira, and Hanina and Hoshaiah studied every Friday together and created a small calf to eat on Shabbat (Sanhedrin 67b). In these cases, the \"magic\" was seen more as divine miracles (i.e., coming from God rather than \"unclean\" forces) than as witchcraft.\n\nJudaism does make it clear that Jews shall not try to learn about the ways of witches (Book of Deuteronomy 18: 9–10) and that witches are to be put to death (Exodus 22:17).\n\nJudaism's most famous reference to a medium is undoubtedly the Witch of Endor whom Saul consults, as recounted in 1 Samuel 28.\n\nDivination, and magic in Islam, encompass a wide range of practices, including black magic, warding off the evil eye, the production of amulets and other magical equipment, evocation, casting lots, and astrology. Muslims do commonly believe in magic (\"sihr\") and explicitly forbid its practice. \"Sihr\" translates from Arabic as sorcery or black magic. The best known reference to magic in Islam is surah al-Falaq of the Qur'an, which is known as a prayer to God to ward off black magic:\nAlso according to the Qur'an:\nIslam distinguishes between God-given gifts, which can heal sickness, and possession, and sorcery. Good supernatural powers are therefore a \"special gift from God\", whereas sorcery or black magic is achieved through help of jinn and demons. In the Qurʾānic narrative, the Prophet Sulayman had the power to speak with animals and command jinn, and he thanks God for this نعمة (i.e. gift, privilege, favour, bounty), which is only given to him with God’s permission. The Prophet Muhammad was accused of being a magician by his opponents.\n\nIt is a common belief that jinn can possess a human, thus requiring exorcism (\"ruqya\") derived from the Prophet's \"sunnah\" to cast off the jinn or devils from the body of the possessed. The practice of seeking help from the jinn is prohibited and can lead to possession. The \"ruqya\" contains verses of the Qur'an as well as prayers specifically targeted against demons. The knowledge of which verses of the Qur'an to use in what way is what is considered \"magic knowledge.\"\n\nA \"hadith\" recorded in states: \"Seventy thousand people of my followers will enter Paradise without accounts, and they are those who do not practice Ar-Ruqya and do not see an evil omen in things, and put their trust in their Lord.\" Ibn Qayyim al-Jawziyya, a scholar, commented on this \"hadith\", stating: That is because these people will enter Paradise without being called to account because of the perfection of their Tawheed, therefore he described them as people who did not ask others to perform ruqyah for them. Hence he said \"and they put their trust in their Lord.\" Because of their complete trust in their Lord, their contentment with Him, their faith in Him, their being pleased with Him and their seeking their needs from Him, they do not ask people for anything, be it ruqyah or anything else, and they are not influenced by omens and superstitions that could prevent them from doing what they want to do, because superstition detracts from and weakens Tawheed\".\n\nIbn al-Nadim hold, exorcists gain their power by their obedience to God, while sorcerers please the demons by acts of disobedience and sacrifices and they in return do him a favor. Being pious and strictly following the teachings of the Qur'an can increase the probability to perform magic or miracles, that is distinguished from witchcraft, the latter practised in aid with demons.\n\nA \"hadith\" recorded in narrates that one who has eaten seven Ajwa dates in the morning will not be adversely affected by magic in the course of that day.\n\nStudents of the history of religion have linked several magical practises in Islam with pre-Islamic Turkish and East African customs. Most notable of these customs is the Zār.\n\nIn Southern African traditions, there are three classifications of somebody who uses magic. The \"tagati\" is usually improperly translated into English as \"witch\", and is a spiteful person who operates in secret to harm others. The \"sangoma\" is a diviner, somewhere on a par with a fortune teller, and is employed in detecting illness, predicting a person's future (or advising them on which path to take), or identifying the guilty party in a crime. She also practices some degree of medicine. The \"inyanga\" is often translated as \"witch doctor\" (though many Southern Africans resent this implication, as it perpetuates the mistaken belief that a \"witch doctor\" is in some sense a \"practitioner\" of malicious magic). The \"inyanga\"s job is to heal illness and injury and provide customers with magical items for everyday use. Of these three categories the \"tagati\" is almost exclusively female, the \"sangoma\" is usually female, and the \"inyanga\" is almost exclusively male.\n\nMuch of what witchcraft represents in Africa has been susceptible to misunderstandings and confusion, thanks in no small part to a tendency among western scholars since the time of the now largely discredited Margaret Murray to approach the subject through a comparative lens vis-a-vis European witchcraft. Okeja argues that witchcraft in Africa today plays a very different social role than in Europe of the past—or present—and should be understood through an African rather than post-colonial Western lens.\n\nComplimentary remarks about witchcraft by a native Congolese initiate: \"From witchcraft ... may be developed the remedy (\"kimbuki\") that will do most to raise up our country.\" \"Witchcraft ... deserves respect ... it can embellish or redeem (\"ketula evo vuukisa\").\" \"The ancestors were equipped with the protective witchcraft of the clan (\"kindoki kiandundila kanda\"). ... They could also gather the power of animals into their hands ... whenever they needed. ... If we could make use of these kinds of witchcraft, our country would rapidly progress in knowledge of every kind.\" \"You witches (\"zindoki\") too, bring your science into the light to be written down so that ... the benefits in it ... endow our race.\"\n\nIn eastern Cameroon, the term used for witchcraft among the Maka is \"djambe\" and refers to a force inside a person; its powers may make the proprietor more vulnerable. It encompasses the occult, the transformative, killing and healing.\n\nIn some Central African areas, malicious magic users are believed by locals to be the source of terminal illness such as AIDS and cancer. In such cases, various methods are used to rid the person from the bewitching spirit, occasionally physical and psychological abuse. Children may be accused of being witches, for example a young niece may be blamed for the illness of a relative. Most of these cases of abuse go unreported since the members of the society that witness such abuse are too afraid of being accused of being accomplices. It is also believed that witchcraft can be transmitted to children by feeding. Parents discourage their children from interacting with people believed to be witches.\n\nEvery year, hundreds of people in the Central African Republic are convicted of witchcraft.\n\nChristian militias in the Central African Republic have also kidnapped, burnt and buried alive women accused of being 'witches' in public ceremonies.\n\n, between 25,000 and 50,000 children in Kinshasa, Democratic Republic of the Congo, had been accused of witchcraft and thrown out of their homes. These children have been subjected to often-violent abuse during exorcisms, sometimes supervised by self-styled religious pastors. Other pastors and Christian activists strongly oppose such accusations and try to rescue children from their unscrupulous colleagues. The usual term for these children is \"enfants sorciers\" (child witches) or \"enfants dits sorciers\" (children accused of witchcraft). In 2002, USAID funded the production of two short films on the subject, made in Kinshasa by journalists Angela Nicoara and Mike Ormsby.\n\nIn April 2008, in Kinshasa, the police arrested 14 suspected victims (of penis snatching) and sorcerers accused of using black magic or witchcraft to steal (make disappear) or shrink men's penises to extort cash for cure, amid a wave of panic.\n\nAccording to one study, the belief in magical warfare technologies (such as \"bulletproofing\") in the Eastern Democratic Republic of the Congo serves a group-level function, as it increases group efficiency in warfare, even if it is suboptimal at the individual level. The authors of the study argue that this is one reason why the belief in witchcraft persists.\n\nIn Ghana, women are often accused of witchcraft and attacked by neighbours. Because of this, there exist six witch camps in the country where women suspected of being witches can flee for safety. The witch camps, which exist solely in Ghana, are thought to house a total of around 1000 women. Some of the camps are thought to have been set up over 100 years ago. The Ghanaian government has announced that it intends to close the camps.\n\nArrests were made in an effort to avoid bloodshed seen in Ghana a decade ago, when 12 alleged penis snatchers were beaten to death by mobs. While it is easy for modern people to dismiss such reports, Uchenna Okeja argues that a belief system in which such magical practices are deemed possible offer many benefits to Africans who hold them. For example, the belief that a sorcerer has \"stolen\" a man's penis functions as an anxiety-reduction mechanism for men suffering from impotence while simultaneously providing an explanation that is consistent with African cultural beliefs rather than appealing to Western scientific notions that are tainted by the history of colonialism (at least for many Africans).\n\nIt was reported on May 21, 2008 that in Kenya, a mob had burnt to death at least 11 people accused of witchcraft.\n\nIn Malawi it is also common practice to accuse children of witchcraft and many children have been abandoned, abused and even killed as a result. As in other African countries both African traditional healers and their Christian counterparts are trying to make a living out of exorcising children and are actively involved in pointing out children as witches. Various secular and Christian organizations are combining their efforts to address this problem.\n\nAccording to William Kamkwamba, witches and wizards are afraid of money, which they consider a rival evil. Any contact with cash will snap their spell and leave the wizard naked and confused. So placing cash, such as kwacha around a room or bed mat will protect the resident from their malevolent spells.\n\nIn Nigeria, several Pentecostal pastors have mixed their evangelical brand of Christianity with African beliefs in witchcraft to benefit from the lucrative witch finding and exorcism business—which in the past was the exclusive domain of the so-called witch doctor or traditional healers. These pastors have been involved in the torturing and even killing of children accused of witchcraft. Over the past decade, around 15,000 children have been accused, and around 1,000 murdered. Churches are very numerous in Nigeria, and competition for congregations is hard. Some pastors attempt to establish a reputation for spiritual power by \"detecting\" child witches, usually following a death or loss of a job within a family, or an accusation of financial fraud against the pastor. In the course of \"exorcisms\", accused children may be starved, beaten, mutilated, set on fire, forced to consume acid or cement, or buried alive. While some church leaders and Christian activists have spoken out strongly against these abuses, many Nigerian churches are involved in the abuse, although church administrations deny knowledge of it.\n\nAmong the Mende (of Sierra Leone), trial and conviction for witchcraft has a beneficial effect for those convicted. \"The witchfinder had warned the whole village to ensure the relative prosperity of the accused and sentenced ... old people. ... Six months later all of the people ... accused, were secure, well-fed and arguably happier than at any [previous] time; they had hardly to beckon and people would come with food or whatever was needful. ... Instead of such old and widowed people being left helpless or (as in Western society) institutionalized in old people's homes, these were reintegrated into society and left secure in their old age ... . ... Old people are 'suitable' candidates for this kind of accusation in the sense that they are isolated and vulnerable, and they are 'suitable' candidates for 'social security' for precisely the same reasons.\"\n\nIn Kuranko language, the term for witchcraft is \"suwa'ye\" referring to \"extraordinary powers\".\n\nIn Tanzania in 2008, President Kikwete publicly condemned witchdoctors for killing albinos for their body parts, which are thought to bring good luck. 25 albinos have been murdered since March 2007. In Tanzania, albinos are often murdered for their body parts on the advice of witch doctors in order to produce powerful amulets that are believed to protect against witchcraft and make the owner prosper in life.\n\nBrua is an Afro-Caribbean religion and healing tradition that originates in Aruba, Bonaire, and Curaçao, in the Dutch Caribbean. A healer in this culture is called a \"kurioso\" or \"kuradó\", a man or woman who performs \"trabou chikí\" (little works) and \"trabou grandi\" (large treatments) to promote or restore health, bring fortune or misfortune, deal with unrequited love, and more serious concerns, in which sorcery is involved. Sorcery usually involves reference to the \"almasola\" or \"homber chiki\", a devil-like entity. \"Transcultural Psychiatry\" published a paper called \"Traditional healing practices originating in Aruba, Bonaire, and Curaçao: A review of the literature on psychiatry and Brua\" by Jan Dirk Blom, Igmar T. Poulina, Trevor L. van Gellecum and Hans W. Hoek of the Parnassia Psychiatric Institute.\n\nIn 1645, Springfield, Massachusetts, experienced America's first accusations of witchcraft when husband and wife Hugh and Mary Parsons accused each other of witchcraft. At America's first witch trial, Hugh was found innocent, while Mary was acquitted of witchcraft but sentenced to be hanged for the death of her child. She died in prison. From 1645–1663, about eighty people throughout England's Massachusetts Bay Colony were accused of practicing witchcraft. Thirteen women and two men were executed in a witch-hunt that lasted throughout New England from 1645–1663.\n\nThe Salem witch trials followed in 1692–93. These witch trials were the most famous in British North America and took place in the coastal settlements near Salem, Massachusetts. Prior to the witch trials, nearly 300 men and women had been suspected of partaking in witchcraft, and 19 of these people were hanged, and one was “pressed to death”. The Salem witch trials were a series of hearings before local magistrates followed by county court trials to prosecute people accused of witchcraft in Essex, Suffolk and Middlesex Counties of colonial Massachusetts, between February 1692 and May 1693. Over 150 people were arrested and imprisoned, with even more accused who were not formally pursued by the authorities. The two courts convicted 29 people of the capital felony of witchcraft. Nineteen of the accused, 14 women and 5 men, were hanged. One man who refused to enter a plea was crushed to death under heavy stones in an attempt to force him to do so. At least five more of the accused died in prison.\n\nDespite being generally known as the \"Salem\" witch trials, the preliminary hearings in 1692 were conducted in a variety of towns across the province: Salem Village (now Danvers), Salem Town, Ipswich, and Andover. The best known trials were conducted by the Court of Oyer and Terminer in 1692 in Salem Town. All 26 who went to trial before this court were convicted. The four sessions of the Superior Court of Judicature in 1693, held in Salem Town, but also in Ipswich, Boston, and Charlestown, produced only 3 convictions in the 31 witchcraft trials it conducted. Likewise, alleged witchcraft was not isolated to New England. In 1706 Grace Sherwood the \"Witch of Pungo\" was imprisoned for the crime in Princess Anne County, Virginia.\n\nIn Maryland, there is a legend of Moll Dyer, who escaped a fire set by fellow colonists only to die of exposure in December 1697. The historical record of Dyer is scant as all official records were burned in a courthouse fire, though the county courthouse has on display the rock where her frozen body was found. A letter from a colonist of the period describes her in most unfavourable terms. A local road is named after Dyer, where her homestead was said to have been. Many local families have their own version of the Moll Dyer affair, and her name is spoken with care in the rural southern counties.\n\nAccusations of witchcraft and wizardry led to the prosecution of a man in Tennessee as recently as 1833. \"The Crucible\" by Arthur Miller is a dramatized and partially fictionalized story of the Salem witch trials that took place in the Massachusetts Bay Colony during 1692–93.\n\nIn Diné culture, witches are seen as the polar opposite of ceremonial people. While spiritual leaders perform \"sings\" for healing, protection and other beneficial purposes, all practices referred to as \"witchcraft\" are intended to hurt and curse. Witches are associated with harm to the community and transgression of societal standards, especially those relating to family and the dead.\n\nThe \"yee naaldlooshii\" is the type of witch known in English as a \"skin-walker\". They are believed to take the forms of animals in order to travel in secret and do harm to the innocent. In the Navajo language, ' translates to \"with it, he goes on all fours\". While perhaps the most common variety seen in horror fiction by non-Navajo people, the ' is one of several varieties of Navajo witch, specifically a type of \"\".\n\nCorpse powder or corpse poison (, literally \"witchery\" or \"harming\") is a substance made from powdered corpses. The powder is used by witches to curse their victims. The effect of the \"\" is a curse and disease, usually indicated by an immediate action to administration of the poison, like fainting, swelling of the tongue, or lockjaw. Sometimes, however, the victims simply wastes away, as from a normal disease.\n\nTraditional Navajos usually hesitate to discuss things like witches and witchcraft with non-Navajos.\n\nWitchcraft was also an important part of the social and cultural history of late-Colonial Mexico, during the Mexican Inquisition. Spanish Inquisitors viewed witchcraft as a problem that could be cured simply through confession. Yet, as anthropologist Ruth Behar writes, witchcraft, not only in Mexico but in Latin America in general, was a \"conjecture of sexuality, witchcraft, and religion, in which Spanish, indigenous, and African cultures converged.\" Furthermore, witchcraft in Mexico generally required an interethnic and interclass network of witches. Yet, according to anthropology professor Laura Lewis, witchcraft in colonial Mexico ultimately represented an \"affirmation of hegemony\" for women, Indians, and especially Indian women over their white male counterparts as a result of the casta system.\n\nIn modern history, notoriety has been awarded to a place called Catemaco, in the state of Veracruz, which has a history of witchcraft, and where the practice of witchcraft by contemporary \"brujos\" and \"brujas\" thrives.\n\nIn Mexico City, people who practice brujería, Santería, voodoo, ocultism and magic may find items, herbs and supplies at the \"mercado de Sonora\".\n\nIn Chile there is a tradition of the Kalku in Mapuche religion; and the Warlocks of Chiloé in the folklore and Chilote mythology.\n\nThe presence of the witch is a constant in the ethnographic history of colonial Brazil, especially during the several denunciations and confessions given to the Congregation for the Doctrine of the Faith of Bahia (1591–1593), Pernambuco and Paraíba (1593–1595).\n\nBelief in the supernatural is strong in all parts of India, and lynchings for witchcraft are reported in the press from time to time. Around 750 people were killed as witches in Assam and West Bengal between 2003 and 2008. Officials in the state of Chhattisgarh reported in 2008 that at least 100 women are maltreated annually as suspected witches. A local activist stated that only a fraction of cases of abuse are reported. In Indian mythology, a common perception of a witch is a being with her feet pointed backwards.\n\nApart from other types of Violence against women in Nepal, the malpractice of abusing women in the name of witchcraft is also really prominent. According to the statistics in 2013, there was a total of 69 reported cases of abuse to women due to accusation of performing witchcraft. The perpetrators of this malpractice are usually neighbors, so-called witch doctors and family members. The main causes of these malpractices are lack of education, lack of awareness and superstition. According to the statistics by INSEC, the age group of women who fall victims to the witchcraft violence in Nepal is 20–40.\n\nIn Japanese folklore, the most common types of witch can be separated into two categories: those who employ snakes as familiars, and those who employ foxes.\n\nThe fox witch is, by far, the most commonly seen witch figure in Japan. Differing regional beliefs set those who use foxes into two separate types: the \"kitsune-mochi\", and the \"tsukimono-suji\". The first of these, the \"kitsune-mochi\", is a solitary figure who gains his fox familiar by bribing it with its favourite foods. The \"kitsune-mochi\" then strikes up a deal with the fox, typically promising food and daily care in return for the fox's magical services. The fox of Japanese folklore is a powerful trickster in and of itself, imbued with powers of shape changing, possession, and illusion. These creatures can be either nefarious; disguising themselves as women in order to trap men, or they can be benign forces as in the story of \"The Grateful foxes\". However, once a fox enters the employ of a human it almost exclusively becomes a force of evil to be feared. A fox under the employ of a human can provide many services. The fox can turn invisible and find secrets its master desires. It can apply its many powers of illusion to trick and deceive its master's enemies. The most feared power of the \"kitsune-mochi\" is the ability to command his fox to possess other humans. This process of possession is called Kitsunetsuki.\n\nBy far, the most commonly reported cases of fox witchcraft in modern Japan are enacted by \"tsukimono-suji\" families, or \"hereditary witches\". The \"Tsukimono-suji\" is traditionally a family who is reported to have foxes under their employ. These foxes serve the family and are passed down through the generations, typically through the female line. \"Tsukimono-suji\" foxes are able to supply much in the way of the same mystical aid that the foxes under the employ of a \"kitsune-mochi\" can provide its more solitary master with. In addition to these powers, if the foxes are kept happy and well taken care of, they bring great fortune and prosperity to the \"Tsukimono-suji\" house. However, the aid in which these foxes give is often overshadowed by the social and mystical implications of being a member of such a family. In many villages, the status of local families as \"tsukimono-suji\" is often common, everyday knowledge. Such families are respected and feared, but are also openly shunned. Due to its hereditary nature, the status of being \"Tsukimono-suji\" is considered contagious. Because of this, it is often impossible for members of such a family to sell land or other properties, due to fear that the possession of such items will cause foxes to inundate one's own home. In addition to this, because the foxes are believed to be passed down through the female line, it is often nearly impossible for women of such families to find a husband whose family will agree to have him married to a \"tsukimono-suji\" family. In such a union the woman's status as a \"Tsukimono-suji\" would transfer to any man who married her.\n\nWitchcraft in the Philippines is often classified as malevolent, with practitioners of black magic called \"Mangkukulam\" in Tagalog and \"Mambabarang\" in Cebuano; there are also practitioners of benevolent, white magic, in addition to some who practise both. \"Mambabarang\" in particular are noted for their ability to command insects and other invertebrates to accomplish a task, such as delivering a curse to a target.\n\nMagic and witchcraft in the Philippines varies considerably across the different ethnic groups, and is commonly a modern manifestation of pre-Colonial spirituality interwoven with Catholic religious elements such as the invocation of saints and the use of pseudo-Latin prayers (\"oración\") in spells, and \"anting-anting\" (amulets).\n\nPractitioners of traditional herbal-based medicine and divination called \"albularyo\" are not considered witches. They are perceived to be either quack doctors or a quasi-magical option when western medicine fails to identify or cure an ailment that is thus suspected to be of supernatural, often malevolent, origin. Feng shui, an influence of Filipino Chinese culture, is also not classified as witchcraft as it is considered a separate realm of belief altogether.\n\nSaudi Arabia continues to use the death penalty for sorcery and witchcraft. In 2006 Fawza Falih Muhammad Ali was condemned to death for practicing witchcraft. There is no legal definition of sorcery in Saudi, but in 2007 an Egyptian pharmacist working there was accused, convicted, and executed. Saudi authorities also pronounced the death penalty on a Lebanese television presenter, Ali Hussain Sibat, while he was performing the \"hajj\" (Islamic pilgrimage) in the country.\n\nIn 2009 the Saudi authorities set up the Anti-Witchcraft Unit of their Committee for the Promotion of Virtue and the Prevention of Vice police.\n\nIn April 2009, a Saudi woman Amina Bint Abdulhalim Nassar was arrested and later sentenced to death for practicing witchcraft and sorcery. In December 2011, she was beheaded. A Saudi man has been beheaded on charges of sorcery and witchcraft in June 2012. A beheading for sorcery occurred in 2014.\n\nIn June 2015, Yahoo reported: \"The Islamic State group has beheaded two women in Syria on accusations of \"sorcery,\" the first such executions of female civilians in Syria, the Syrian Observatory for Human Rights said Tuesday.\"\nISIS decapitated a man in Iraq over sorcery.\n\nAn expedition sent to what is now the Xinjiang region of western China by the PBS documentary series \"Nova\" found a fully clothed female Tocharian mummy wearing a black conical hat of the type now associated with witches in Europe in the storage area of a small local museum, indicative of an Indo-European priestess.\n\nWitchcraft in Europe between 500–1750 was believed to be a combination of sorcery and heresy. While sorcery attempts to produce negative supernatural effects through formulas and rituals, heresy is the Christian contribution to witchcraft in which an individual makes a pact with the Devil. In addition, heresy denies witches the recognition of important Christian values such as baptism, salvation, Christ and sacraments. The beginning of the witch accusations in Europe took place in the 14th and 15th centuries; however as the social disruptions of the 16th century took place, witchcraft trials intensified. \nIn Early Modern European tradition, witches were stereotypically, though not exclusively, women. European pagan belief in witchcraft was associated with the goddess Diana and dismissed as \"diabolical fantasies\" by medieval Christian authors. Witch-hunts first appeared in large numbers in southern France and Switzerland during the 14th and 15th centuries. The peak years of witch-hunts in southwest Germany were from 1561 to 1670.\n\nIt was commonly believed that individuals with power and prestige were involved in acts of witchcraft and even cannibalism. Because Europe had a lot of power over individuals living in West Africa, Europeans in positions of power were often accused of taking part in these practices. Though it is not likely that these individuals were actually involved in these practices, they were most likely associated due to Europe’s involvement in things like the slave trade, which negatively affected the lives of many individuals in the Atlantic World throughout the fifteenth through seventeenth centuries.\n\nThe familiar witch of folklore and popular superstition is a combination of numerous influences. The characterization of the witch as an evil magic user developed over time.\n\nEarly converts to Christianity looked to Christian clergy to work magic more effectively than the old methods under Roman paganism, and Christianity provided a methodology involving saints and relics, similar to the gods and amulets of the Pagan world. As Christianity became the dominant religion in Europe, its concern with magic lessened.\n\nThe Protestant Christian explanation for witchcraft, such as those typified in the confessions of the Pendle witches, commonly involves a diabolical pact or at least an appeal to the intervention of the spirits of evil. The witches or wizards engaged in such practices were alleged to reject Jesus and the sacraments; observe \"the witches' sabbath\" (performing infernal rites that often parodied the Mass or other sacraments of the Church); pay Divine honour to the Prince of Darkness; and, in return, receive from him preternatural powers. It was a folkloric belief that a Devil's Mark, like the brand on cattle, was placed upon a witch's skin by the devil to signify that this pact had been made. Witches were most often characterized as women. Witches disrupted the societal institutions, and more specifically, marriage. It was believed that a witch often joined a pact with the devil to gain powers to deal with infertility, immense fear for her children's well-being, or revenge against a lover. They were also depicted as lustful and perverted, and it was thought that they copulated with the devil at the Sabbath.\n\nThe Church and European society were not always so zealous in hunting witches or blaming them for misfortunes. Saint Boniface declared in the 8th century that belief in the existence of witches was un-Christian. The emperor Charlemagne decreed that the burning of supposed witches was a pagan custom that would be punished by the death penalty. In 820 the Bishop of Lyon and others repudiated the belief that witches could make bad weather, fly in the night, and change their shape. This denial was accepted into Canon law . Other rulers such as King Coloman of Hungary declared that witch-hunts should cease because witches (more specifically, strigas) do not exist.\n\nThe Church did not invent the idea of witchcraft as a potentially harmful force whose practitioners should be put to death. This idea is commonplace in pre-Christian religions. According to the scholar Max Dashu, the concept of medieval witchcraft contained many of its elements even before the emergence of Christianity. These can be found in Bacchanalias, especially in the time when they were led by priestess Paculla Annia (188BC–186BC).\n\nPowers typically attributed to European witches include turning food poisonous or inedible, flying on broomsticks or pitchforks, casting spells, cursing people, making livestock ill and crops fail, and creating fear and local chaos.\n\nHowever, even at a later date, not all witches were assumed to be harmful practicers of the craft. In England, the provision of this curative magic was the job of a witch doctor, also known as a cunning man, white witch, or wise man. The term \"witch doctor\" was in use in England before it came to be associated with Africa. Toad doctors were also credited with the ability to undo evil witchcraft. (Other folk magicians had their own purviews. Girdle-measurers specialised in diagnosing ailments caused by fairies, while magical cures for more mundane ailments, such as burns or toothache, could be had from charmers.)\n\nHistorians Keith Thomas and his student Alan Macfarlane study witchcraft by combining historical research with concepts drawn from anthropology. They argued that English witchcraft, like African witchcraft, was endemic rather than epidemic. Older women were the favorite targets because they were marginal, dependent members of the community and therefore more likely to arouse feelings of both hostility and guilt, and less likely to have defenders of importance inside the community. Witchcraft accusations were the village's reaction to the breakdown of its internal community, coupled with the emergence of a newer set of values that was generating psychic stress.\nIn Wales, fear of witchcraft mounted around the year 1500. There was a growing alarm of women's magic as a weapon aimed against the state and church. The Church made greater efforts to enforce the canon law of marriage, especially in Wales where tradition allowed a wider range of sexual partnerships. There was a political dimension as well, as accusations of witchcraft were levied against the enemies of Henry VII, who was exerting more and more control over Wales.\n\nThe records of the Courts of Great Sessions for Wales, 1536–1736 show that Welsh custom was more important than English law. Custom provided a framework of responding to witches and witchcraft in such a way that interpersonal and communal harmony was maintained, Showing to regard to the importance of honour, social place and cultural status. Even when found guilty, execution did not occur.\n\nBecoming king in 1603, James I Brought to England and Scotland continental explanations of witchcraft. His goal was to divert suspicion away from male homosociality among the elite, and focus fear on female communities and large gatherings of women. He thought they threatened his political power so he laid the foundation for witchcraft and occultism policies, especially in Scotland. The point was that a widespread belief in the conspiracy of witches and a witches' Sabbath with the devil deprived women of political influence. Occult power was supposedly a womanly trait because women were weaker and more susceptible to the devil.\n\nIn 1944 Helen Duncan was the last person in Britain to be imprisoned for fraudulently claiming to be a witch.\n\nIn the United Kingdom children believed to be witches or seen as possessed by evil spirits can be subject to severe beatings, traumatic exorcism, and/or other abuse. There have even been child murders associated with witchcraft beliefs. The problem is particularly serious among immigrant or former immigrant communities of African origin but other communities, such as those of Asian origin are also involved. Step children and children seen as different for a wide range of reasons are particularly at risk of witchcraft accusations. Children may be beaten or have chilli rubbed into their eyes during exorcisms. This type of abuse is frequently hidden and can include torture. A 2006 recommendation to record abuse cases linked to witchcraft centrally has not yet been implemented. Lack of awareness among social workers, teachers and other professionals dealing with at risk children hinders efforts to combat the problem.\n\nThere is a 'money making scam' involved. Pastors accuse a child of being a witch and later the family pays for exorcism. If a child at school says that his/her pastor called the child a witch that should become a child safeguarding issue.\n\nAs in most European countries, women in Italy were more likely suspected of witchcraft than men. Women were considered dangerous due to their supposed sexual instability, such as when being aroused, and also due to the powers of their menstrual blood.\n\nIn the 16th century, Italy had a high portion of witchcraft trials involving love magic. The country had a large number of unmarried people due to men marrying later in their lives during this time. This left many women on a desperate quest for marriage leaving them vulnerable to the accusation of witchcraft whether they took part in it or not. Trial records from the Inquisition and secular courts discovered a link between prostitutes and supernatural practices. Professional prostitutes were considered experts in love and therefore knew how to make love potions and cast love related spells. Up until 1630, the majority of women accused of witchcraft were prostitutes. A courtesan was questioned about her use of magic due to her relationship with men of power in Italy and her wealth. The majority of women accused were also considered \"outsiders\" because they were poor, had different religious practices, spoke a different language, or simply from a different city/town/region. Cassandra from Ferrara, Italy, was still considered a foreigner because not native to Rome where she was residing. She was also not seen as a model citizen because her husband was in Venice.\n\nFrom the 16th-18th centuries, the Catholic Church enforced moral discipline throughout Italy. With the help of local tribunals, such as in Venice, the two institutions investigated a woman's religious behaviors when she was accused of witchcraft.\n\nFranciscan friars from New Spain introduced Diabolism, belief in the devil, to the indigenous people after their arrival in 1524.\nBartolomé de las Casas believed that human sacrifice was not diabolic, in fact far off from it, and was a natural result of religious expression.\nMexican Indians gladly took in the belief of Diabolism and still managed to keep their belief in creator-destroyer deities.\n\nIn pre-Christian times, witchcraft was a common practice in the Cook Islands. The native name for a sorcerer was \"tangata purepure\" (a man who prays). The prayers offered by the \"ta'unga\" (priests) to the gods worshiped on national or tribal \"marae\" (temples) were termed \"karakia\"; those on minor occasions to the lesser gods were named \"pure\". All these prayers were metrical, and were handed down from generation to generation with the utmost care. There were prayers for every such phase in life; for success in battle; for a change in wind (to overwhelm an adversary at sea, or that an intended voyage be propitious); that his crops may grow; to curse a thief; or wish ill-luck and death to his foes. Few men of middle age were without a number of these prayers or charms. The succession of a sorcerer was from father to son, or from uncle to nephew. So too of sorceresses: it would be from mother to daughter, or from aunt to niece. Sorcerers and sorceresses were often slain by relatives of their supposed victims.\n\nA singular enchantment was employed to kill off a husband of a pretty woman desired by someone else. The expanded flower of a Gardenia was stuck upright—a very difficult performance—in a cup (i.e., half a large coconut shell) of water. A prayer was then offered for the husbands speedy death, the sorcerer earnestly watching the flower. Should it fall the incantation was successful. But if the flower still remained upright, he will live. The sorcerer would in that case try his skill another day, with perhaps better success.\n\nAccording to Beatrice Grimshaw, a journalist who visited the Cook Islands in 1907, the uncrowned Queen Makea was believed to have possessed the mystic power called \"mana\", giving the possessor the power to slay at will. It also included other gifts, such as second sight to a certain extent, the power to bring good or evil luck, and the ability already mentioned to deal death at will.\n\nA local newspaper informed that more than 50 people were killed in two Highlands provinces of Papua New Guinea in 2008 for allegedly practicing witchcraft. An estimated 50–150 alleged witches are killed each year in Papua New Guinea.\n\nAmong the Russian words for \"witch\", ведьма (ved'ma) literally means \"one who knows\", from Old Slavic вѣдъ \"to know\"). Another frequent term is колдунья (koldun'ya), \"sorcerer\" being колдун (koldun).\n\nPagan practices formed a part of Russian and Eastern Slavic culture; the Russian people were deeply superstitious. The witchcraft practiced consisted mostly of earth magic and herbology; it was not so significant which herbs were used in practices, but how these herbs were gathered. Ritual centered on harvest of the crops and the location of the sun was very important. One source, pagan author Judika Illes, tells that herbs picked on Midsummer's Eve were believed to be most powerful, especially if gathered on Bald Mountain near Kiev during the witches' annual revels celebration. Botanicals should be gathered, \"During the seventeenth minute of the fourteenth hour, under a dark moon, in the thirteenth field, wearing a red dress, pick the twelfth flower on the right.\"\n\nSpells also served for midwifery, shape-shifting, keeping lovers faithful, and bridal customs. Spells dealing with midwifery and childbirth focused on the spiritual wellbeing of the baby. Shape-shifting spells involved invocation of the wolf as a spirit animal. To keep men faithful, lovers would cut a ribbon the length of his erect penis and soak it in his seminal emissions after sex while he was sleeping, then tie seven knots in it; keeping this talisman of knot magic ensured loyalty. Part of an ancient pagan marriage tradition involved the bride taking a ritual bath at a bathhouse before the ceremony. Her sweat would be wiped from her body using raw fish, and the fish would be cooked and fed to the groom.\n\nDemonism, or black magic, was not prevalent. Persecution for witchcraft, mostly involved the practice of simple earth magic, founded on herbology, by solitary practitioners with a Christian influence. In one case investigators found a locked box containing something bundled in a kerchief and three paper packets, wrapped and tied, containing crushed grasses. Most rituals of witchcraft were very simple—one spell of divination consists of sitting alone outside meditating, asking the earth to show one's fate.\n\nWhile these customs were unique to Russian culture, they were not exclusive to this region. Russian pagan practices were often akin to paganism in other parts of the world. The Chinese concept of \"chi\", a form of energy that often manipulated in witchcraft, is known as bioplasma in Russian practices. The western concept of an \"evil eye\" or a \"hex\" was translated to Russia as a \"spoiler\". A spoiler was rooted in envy, jealousy and malice. Spoilers could be made by gathering bone from a cemetery, a knot of the target's hair, burned wooden splinters and several herb Paris berries (which are very poisonous). Placing these items in sachet in the victim's pillow completes a spoiler. The Sumerians, Babylonians, Assyrians, and the ancient Egyptians recognized the evil eye from as early as 3,000 BCE; in Russian practices it is seen as a sixteenth-century concept.\n\nThe dominant societal concern those practicing witchcraft was not whether paganism was effective, but whether it could cause harm. Peasants in Russian and Ukrainian societies often shunned witchcraft, unless they needed help against supernatural forces. Impotence, stomach pains, barrenness, hernias, abscesses, epileptic seizures, and convulsions were all attributed to evil (or witchcraft). This is reflected in linguistics; there are numerous words for a variety of practitioners of paganism-based healers. Russian peasants referred to a witch as a \"chernoknizhnik\" (a person who plied his trade with the aid of a black book), \"sheptun\"/\"sheptun'ia\" (a \"whisperer\" male or female), \"lekar\"/\"lekarka\" or \"znakhar\"/\"znakharka\" (a male or female healer), or \"zagovornik\" (an incanter).\n\nIronically enough, there was universal reliance on folk healers – but clients often turned them in if something went wrong. According to Russian historian Valerie A. Kivelson, witchcraft accusations were normally thrown at lower-class peasants, townspeople and Cossacks. People turned to witchcraft as a means to support themselves. The ratio of male to female accusations was 75% to 25%. Males were targeted more, because witchcraft was associated with societal deviation. Because single people with no settled home could not be taxed, males typically had more power than women in their dissent.\n\nThe history of Witchcraft had evolved around society. More of a psychological concept to the creation and usage of Witchcraft can create the assumption as to why women are more likely to follow the practices behind Witchcraft. Identifying with the soul of an individual’s self is often deemed as \"feminine\" in society. There is analyzed social and economic evidence to associate between witchcraft and women.\n\nWitchcraft trials occurred frequently in seventeenth-century Russia, although the \"great witch-hunt\" is believed to be a predominately Western European phenomenon. However, as the witchcraft-trial craze swept across Catholic and Protestant countries during this time, Orthodox Christian Europe indeed partook in this so-called \"witch hysteria.\" This involved the persecution of both males and females who were believed to be practicing paganism, herbology, the black art, or a form of sorcery within and/or outside their community. Very early on witchcraft legally fell under the jurisdiction of the ecclesiastical body, the church, in Kievan Rus' and Muscovite Russia. Sources of ecclesiastical witchcraft jurisdiction date back as early as the second half of the eleventh century, one being Vladimir the Great's first edition of his State Statute or \"Ustav\", another being multiple references in the \"Primary Chronicle\" beginning in 1024.\n\nThe sentence for an individual found guilty of witchcraft or sorcery during this time, and in previous centuries, typically included either burning at the stake or being tested with the \"ordeal of cold water\" or \"judicium aquae frigidae\". The cold-water test was primarily a Western European phenomenon, but was used as a method of truth in Russia prior to, and post, seventeenth-century witchcraft trials in Muscovy. Accused persons who submerged were considered innocent, and ecclesiastical authorities would proclaim them \"brought back,\" but those who floated were considered guilty of practicing witchcraft, and burned at the stake or executed in an unholy fashion. The thirteenth-century bishop of Vladimir, Serapion Vladimirskii, preached sermons throughout the Muscovite countryside, and in one particular sermon revealed that burning was the usual punishment for witchcraft, but more often the cold water test was used as a precursor to execution.\n\nAlthough these two methods of torture were used in the west and the east, Russia implemented a system of fines payable for the crime of witchcraft during the seventeenth century. Thus, even though torture methods in Muscovy were on a similar level of harshness as Western European methods used, a more civil method was present. In the introduction of a collection of trial records pieced together by Russian scholar Nikolai Novombergsk, he argues that Muscovite authorities used the same degree of cruelty and harshness as Western European Catholic and Protestant countries in persecuting witches. By the mid-sixteenth century the manifestations of paganism, including witchcraft, and the black arts—astrology, fortune telling, and divination—became a serious concern to the Muscovite church and state.\n\nTsar Ivan IV (reigned 1547–1584) took this matter to the ecclesiastical court and was immediately advised that individuals practicing these forms of witchcraft should be excommunicated and given the death penalty. Ivan IV, as a true believer in witchcraft, was deeply convinced that sorcery accounted for the death of his wife, Anastasiia in 1560, which completely devastated and depressed him, leaving him heartbroken. Stemming from this belief, Ivan IV became majorly concerned with the threat of witchcraft harming his family, and feared he was in danger. So, during the Oprichnina (1565–1572), Ivan IV succeeded in accusing and charging a good number of boyars with witchcraft whom he did not wish to remain as nobles. Rulers after Ivan IV, specifically during the Time of Troubles (1598–1613), increased the fear of witchcraft among themselves and entire royal families, which then led to further preoccupation with the fear of prominent Muscovite witchcraft circles.\n\nAfter the Time of Troubles, seventeenth-century Muscovite rulers held frequent investigations of witchcraft within their households, laying the ground, along with previous tsarist reforms, for widespread witchcraft trials throughout the Muscovite state. Between 1622 and 1700 ninety-one people were brought to trial in Muscovite courts for witchcraft. Although Russia did partake in the witch craze that swept across Western Europe, the Muscovite state did not persecute nearly as many people for witchcraft, let alone execute a number of individuals anywhere close to the number executed in the west during the witch hysteria.\n\nWitches have a long history of being depicted in art, although most of their earliest artistic depictions seem to originate in Early Modern Europe, particularly the Medieval and Renaissance periods. Many scholars attribute their manifestation in art as inspired by texts such as \"Canon Episcopi\", a demonology-centered work of literature, and \"Malleus Maleficarum\", a \"witch-craze\" manual published in 1487, by Heinrich Kramer and Jacob Sprenger.\n\n\"Canon Episcopi\", a ninth-century text that explored the subject of demonology, initially introduced concepts that would continuously be associated with witches, such as their ability to fly or their believed fornication and sexual relations with the devil. The text refers to two women, Diana the Huntress and Herodias, who both express the duality of female sorcerers. Diana was described as having a heavenly body and as the \"protectress of childbirth and fertility\" while Herodias symbolized \"unbridled sensuality\". They thus represent the mental powers and cunning sexuality that witches used as weapons to trick men into performing sinful acts which would result in their eternal punishment. These characteristics were distinguished as Medusa-like or Lamia-like traits when seen in any artwork (Medusa's mental trickery was associated with Diana the Huntress's psychic powers and Lamia was a rumored female figure in the Medieval ages sometimes used in place of Herodias).\nOne of the first individuals to regularly depict witches after the witch-craze of the medieval period was Albrecht Dürer, a German Renaissance artist. His famous 1497 engraving \"The Four Witches\", portrays four physically attractive and seductive nude witches. Their supernatural identities are emphasized by the skulls and bones lying at their feet as well as the devil discreetly peering at them from their left. The women's sensuous presentation speaks to the overtly sexual nature they were attached to in early modern Europe. Moreover, this attractiveness was perceived as a danger to ordinary men who they could seduce and tempt into their sinful world. Some scholars interpret this piece as utilizing the logic of the \"Canon Episcopi\", in which women used their mental powers and bodily seduction to enslave and lead men onto a path of eternal damnation, differing from the unattractive depiction of witches that would follow in later Renaissance years.\nDürer also employed other ideas from the Middle Ages that were commonly associated with witches. Specifically, his art often referred to former 12th- to 13th-century Medieval iconography addressing the nature of female sorcerers. In the Medieval period, there was a widespread fear of witches, accordingly producing an association of dark, intimidating characteristics with witches, such as cannibalism (witches described as \"[sucking] the blood of newborn infants\") or described as having the ability to fly, usually on the back of black goats. As the Renaissance period began, these concepts of witchcraft were suppressed, leading to a drastic change in the sorceress' appearances, from sexually explicit beings to the 'ordinary' typical housewives of this time period. This depiction, known as the 'Waldensian' witch became a cultural phenomenon of early Renaissance art. The term originates from the 12th-century monk Peter Waldo, who established his own religious sect which explicitly opposed the luxury and commodity-influenced lifestyle of the Christian church clergy, and whose sect was excommunicated before being persecuted as \"practitioners of witchcraft and magic\".\n\nSubsequent artwork exhibiting witches tended to consistently rely on cultural stereotypes about these women. These stereotypes were usually rooted in early Renaissance religious discourse, specifically the Christian belief that an \"earthly alliance\" had taken place between Satan's female minions who \"conspired to destroy Christendom\".\n\nAnother significant artist whose art consistently depicted witches was Dürer's apprentice, Hans Baldung Grien, a 15th-century German artist. His chiaroscuro woodcut, \"Witches\", created in 1510, visually encompassed all the characteristics that were regularly assigned to witches during the Renaissance. Social beliefs labeled witches as supernatural beings capable of doing great harm, possessing the ability to fly, and as cannibalistic. The urn in \"Witches\" seems to contain pieces of the human body, which the witches are seen consuming as a source of energy. Meanwhile, their nudity while feasting is recognized as an allusion to their sexual appetite, and some scholars read the witch riding on the back of a goat-demon as representative of their \"flight-inducing [powers]\". This connection between women's sexual nature and sins was thematic in the pieces of many Renaissance artists, especially Christian artists, due to cultural beliefs which characterized women as overtly sexual beings who were less capable (in comparison to men) of resisting sinful temptation.\n\n\n\n"}
{"id": "41343618", "url": "https://en.wikipedia.org/wiki?curid=41343618", "title": "WorkSafe New Zealand", "text": "WorkSafe New Zealand\n\nWorkSafe is New Zealand’s primary workplace health and safety regulator.\n\nOver 550 staff based across New Zealand who are working to lift New Zealand’s health and safety performance and support workers to return home healthy and safe.\n\nAs the regulator of the workplace health and safety system, WorkSafe has three key roles:\n\nRegulatory confidence\nHarm prevention\nSystem leadership\nWorkSafe works collaboratively with businesses, undertakings, workers and their representatives to embed and promote good workplace health and safety practices. Some of WorkSafe’s functions include:\nThese responsibilities are defined in legislation, specifically by the Health and Safety at Work Act 2015.\n\nWorkSafe is implementing the most significant reforms to workplace health and safety in more than 20 years. These ‘Working Safer’ reforms are the Government’s response to the recommendations of the Independent Taskforce on Workplace Health and Safety, as articulated in Working Safer: A blueprint for health and safety at work. The social and economic cost of deaths, injuries and ill-health arising from work is estimated at $3.5 billion a year. However, the real toll is paid by the families, friends and co-workers of those who are killed, seriously injured or experience work-related ill-health.\n\nWorkSafe's goal is to transform New Zealand’s workplace health and safety performance and includes the Government’s target to reduce workplace fatalities and serious injuries by 25% by 2020.\n\nOther government agencies are also designated to carry out health and safety regulatory functions for certain work. They are:\n\nMaritime New Zealand for ships as workplaces and work aboard ships\n\nCivil Aviation Authority (CAA) for work preparing aircraft for imminent flight and aircraft in operation.\n\nEven today there are some who refer to WorkSafe by the title OSH. Occupational Safety and Health (OSH) was a name used for our health and safety functions in the Department of Labour. The name was taken out of use in 2005.\n\nThe Ministry of Business, Innovation and Employment is responsible for workplace health and safety strategy, policy, legislation and regulations.\n\n"}
