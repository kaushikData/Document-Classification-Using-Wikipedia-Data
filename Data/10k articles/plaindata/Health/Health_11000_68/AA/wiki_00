{"id": "33362431", "url": "https://en.wikipedia.org/wiki?curid=33362431", "title": "2006 North American E. coli O157:H7 outbreaks", "text": "2006 North American E. coli O157:H7 outbreaks\n\nIn 2006, there were several outbreaks of foodborne illness from spinach and lettuce contaminated by .\n\nThe initial outbreak occurred in September 2006 and its probable origin was an Angus cattle ranch that had leased land to a spinach grower (growing under organic practices). At least 205 consumer illnesses and 3 deaths have been attributed to the tainted produce.\n\nIn December 2006, Taco Bell restaurants in four Northeastern states emerged as a common link among 71 sickened people across five states, 52 of whom were ultimately confirmed by the Centers for Disease Control to have tested positive the same \"E. coli\" strain. A total of 33 people in New Jersey, 22 in New York, 13 in Pennsylvania, 2 in Delaware, and 1 in South Carolina fell ill, according to the CDC.\n\nThe four states with Taco Bell restaurants where these consumers were confirmed to have eaten were in New Jersey, New York, Pennsylvania, and Delaware. (The patient from South Carolina ate a Taco Bell restaurant in Pennsylvania).\n\nOf the 71 reported cases, 53 were hospitalized and 8 developed a type of kidney failure called hemolytic-uremic syndrome. According to the CDC, illness onset dates ranged from November 20 to December 6.\n\nOn December 7, 2006, an initial investigation attributed the outbreak to green onions, which had been supplied to the Taco Bell restaurants by a single McLane Company distribution center in Burlington Township, New Jersey.\n\nTainted green onions may have proven a ready culprit in part because of their involvement in at least one widely reported prior outbreak of \"E. coli\". In 2003, green onions were suspected as the cause of a foodborne illness involving the Chi-Chi's restaurant chain in western Pennsylvania that killed 4 people and sickened 660.\n\nAfter further investigation, Taco Bell determined that the cause of the problem was with lettuce, not green onions, and switched produce suppliers in the New York, New Jersey, Pennsylvania, and Delaware area. Company president Greg Creed stated in a press release that Taco Bell was cooperating with the CDC and the FDA in the controversy and he also stated that two of the people who claimed they got sick from eating Taco Bell actually did not eat there. Even though green onions were proven to not be the source of Taco Bell's \"E. coli\" outbreak, Taco Bell has no plans to put them back on the menu.\n\nBy mid-December 2006, both green onions and McLane Company had been eliminated as possible sources of the Taco Bell contamination. Taco Bell's tainted lettuce was later traced, via packaging, to farms in the Central Valley of California, although no specific sources have been made public.\n\nLater in December 2006, Iowa and Minnesota health officials investigated an \"E. coli\" outbreak that was traced to foods served at Taco John's restaurants in Cedar Falls, Iowa and Albert Lea and Austin, Minnesota. As of December 13, 2006, the Iowa Department of Health had confirmed that at least 50 Iowans had become ill with \"E. coli\" infections after eating at Taco John's. On December 18, 2006, the Minnesota Department of Health reported that 37 probable \"E. coli\" cases had been reported in connection with the Taco John's \"E. coli\" outbreak, nine people were confirmed ill with \"E. coli\", eight people were hospitalized, and one person had developed hemolytic-uremic syndrome.\n\nThe Taco John's \"E. coli\" outbreak was traced to contaminated lettuce sold in foods at Taco John's restaurants that were supplied by a Minneapolis lettuce supplier. In response to the Taco John's \"E. coli\" outbreak, Taco John's agreed to reimburse ill individuals for medical expenses, and hired a new fresh produce supplier. Taco John's president and CEO Paul Fisherkeller stated in an open letter that their restaurant food was safe to eat in the wake of the \"E. coli\" outbreak that closed three of their restaurants in Iowa and Minnesota.\n\nA report of a viral outbreak at an Olive Garden restaurant in Indianapolis, Indiana occurred in mid-December.\n\nSince the 2006 outbreaks, various legislative proposals have emerged and the state and federal levels to require stricter food production, processing and handling. Industry participants have also taken voluntary measures to improve food safety.\n\nFollowing the outbreak in 2006, the California Leafy Greens Handler Marketing Agreement (LGMA) was established in the spring of 2007. The LGMA, operating with oversight from the California Department of Food and Agriculture, provides a mechanism for verifying that farmers follow established food safety practices for lettuce, spinach and other leafy greens. Farmers, shippers and processors in California have demonstrated their willingness to follow a set of food safety practices by signing onto the LGMA. Once a company joins the LGMA, it becomes mandatory for that member company to sell and ship produce only from farmers who comply with the LGMA accepted food safety practices. The grocery stores and restaurants who buy California leafy greens products support the food safety program by only purchasing these products from the LGMA member companies who passed mandatory government inspections. The California LGMA has now become a model program for farmers in other states.\n\n"}
{"id": "787129", "url": "https://en.wikipedia.org/wiki?curid=787129", "title": "Abortion in Germany", "text": "Abortion in Germany\n\nAbortion in Germany is permitted in the first trimester upon condition of mandatory counseling, and is also permitted later in pregnancy in cases of medical necessity. In both cases, a waiting period of three days is required. The counseling, called ' (\"pregnancy-conflict counseling\"), must take place at a state-approved centre, which afterwards gives the applicant a ' (\"certificate of counseling\").\n\n, the abortion rate was 6.1 abortions per 1,000 women aged 15-44 years.\n\nLegalization of abortion was first widely discussed in Germany during the early 20th century. When Germany became a country in 1871, section 218 of the Constitution outlawed abortion, requiring a penal term for both the woman and the doctor involved. During the Weimar Republic, such discussion led to a reduction in the maximum penalty for abortion, and in 1926 a court's decision legalized abortion in cases of grave danger to the life of the mother. Nazi Germany's eugenics laws liberalized abortion for both Aryan and non-Aryan women. Aryan women could obtain an abortion simply by demonstrating that either parent had an hereditary defect, or that the child would be born with a congenital defect. Non-Aryan women were \"encouraged\" to utilize contraception and abortion in order to reduce their populations.\n\nIn Nazi Germany, the penalties for abortion were increased again. In 1943, providing an abortion to an Aryan woman became a capital offense. Abortion was permitted if the fetus was deformed or disabled.\n\nAfter World War II, abortion remained broadly illegal throughout both Germanys: West Germany retained the legal situation of 1927, while East Germany passed a slightly more encompassing set of exceptions in 1950. The legal requirements in the West were extremely strict, and often led women to seek abortions elsewhere, particularly in the Netherlands. It has been estimated that about 2 million women had abortions each year between 1945 and 1948, mostly in the Soviet zone. An abortion cost around 1000 marks and was performed without anaesthesia. 6000 Berlin women died each year in the Soviet zone from resulting complications.\n\nEast Germany legalized abortion on demand until 12 weeks of pregnancy in 1972, in the Volkskammer's only non-unanimous vote ever in the first 40 years of its existence. After West Germany followed suit in 1974, its new law was struck down in 1975 by the Constitutional Court as inconsistent with the human rights guarantee of the constitution. It held that the unborn has a right to life, that abortion is an act of killing, and that the fetus deserves legal protection throughout its development. Nevertheless, the legal opinion strongly hinted that increasing the number of situations in which abortion was legal might be constitutional.\n\nIn 1976, West Germany legalized abortion up until twelve weeks of pregnancy — for reasons of medical necessity, sexual crimes, or serious social or emotional distress — if approved by two doctors, and subject to counseling and a three-day waiting period. In 1989, a Bavarian doctor was sentenced to two and a half years in prison, and 137 of his patients were fined for failing to meet the certification requirements.\n\nThe two laws had to be reconciled after reunification. A new law was passed by the Bundestag in 1992, permitting first-trimester abortions on demand, subject to counseling and a three-day waiting period, and permitting late-term abortions when the physical or psychological health of the woman is seriously threatened. The law was quickly challenged in court by a number of individuals — including Chancellor Helmut Kohl — and by the State of Bavaria. The Constitutional Court decided a year later to maintain its earlier decision that the constitution protected the fetus from the moment of conception, but stated that it is within the discretion of parliament not to punish abortion in the first trimester, provided that the woman had submitted to state-regulated counseling intended to discourage termination and protect fetal life. Parliament passed such a law in 1995. Abortions are covered by public health insurance if the pregnancy was caused by sexual abuse, such as rape, or if the mother's health is seriously endangered by the pregnancy. For women with low income, the state governments pay for an abortion.\n\n"}
{"id": "24325940", "url": "https://en.wikipedia.org/wiki?curid=24325940", "title": "Alcohol in New Zealand", "text": "Alcohol in New Zealand\n\nAlcohol has been consumed in New Zealand since the arrival of European settlers. The most popular alcoholic beverages are beer and wine. New Zealand has no minimum consumption age for alcohol, however the minimum purchase age is 18.\n\nThere is no oral tradition or archaeological evidence of Māori brewing beer before the arrival of Europeans. Major ingredients of beer were not introduced to New Zealand until Europeans arrived in the late-18th century. Captain James Cook brewed a beer flavoured with local spruce tree needles while visiting New Zealand in 1773 in order to combat scurvy aboard ship. He brewed the beer while anchored in Ship Cove in the outer reaches of Queen Charlotte Sound in January 1770. Here he experimented with the use of young rimu branches as a treatment against scurvy. It was brewed on Saturday 27 March 1773 on Resolution Island, in Dusky Sound, Fiordland. The beer was brewed using wort with the addition of molasses and rimu bark and leaves. James Cook wrote:\n\n\"We also began to brew beer from the branches or leaves of a tree, which much resembles the American black-spruce. From the knowledge I had of this tree, and the similarity it bore to the spruce, I judged that, with the addition of inspissated juice of wort and molasses, it would make a very wholesome beer, and supply the want of vegetables, which this place did not afford; and the event proved that I was not mistaken.\"\n\nWine making and vine growing go back to colonial times in New Zealand. British Resident and keen oenologist James Busby was, as early as 1836, attempting to produce wine at his land in Waitangi. In 1851 New Zealand's oldest existing vineyard was established by French Roman Catholic missionaries at Mission Estate in Hawke's Bay. Due to economic (the importance of animal agriculture and the protein export industry), legislative (prohibition and the temperance) and cultural factors (the overwhelming predominance of beer and spirit drinking British immigrants), wine was for many years a marginal activity in terms of economic importance. Dalmatian immigrants arriving in New Zealand at the end of the nineteenth and beginning of the twentieth century brought with them viticultural knowledge and planted vineyards in West and North Auckland. Typically, their vineyards produced sherry and port for the palates of New Zealanders of the time, and table wine for their own community.\n\nThe three factors that held back the development of the industry simultaneously underwent subtle but historic changes in the late 1960s and early 1970s. In 1973, Britain entered the European Economic Community, which required the ending of historic trade terms for New Zealand meat and dairy products. This led ultimately to a dramatic restructuring of the agricultural economy. Before this restructuring was fully implemented, diversification away from traditional protein products to products with potentially higher economic returns was explored. Vines, which produce best in low moisture and low soil fertility environments, were seen as suitable for areas that had previously been marginal pasture. The end of the 1960s saw the end of the New Zealand institution of the \"six o'clock swill\", where pubs were open for only an hour after the end of the working day and closed all Sunday. The same legislative reform saw the introduction of BYO (bring your own) licences for restaurants.\n\nFinally, the late 1960s and early 1970s noted the rise of the \"overseas experience,\" where young New Zealanders travelled and lived and worked overseas, predominantly in Europe. As a cultural phenomenon, the overseas experience predates the rise of New Zealand's premium wine industry, but by the 1960s a distinctly New Zealand identity had developed and the passenger jet made the overseas experience possible for large numbers of New Zealanders who experienced first-hand the premium wine cultures of Europe.\n\nBetween 1836 and 1919, the New Zealand temperance movement became a powerful and popular lobby group, as similar movements did in the UK and the USA. In 1919 at a national referendum poll, prohibition gained 49% of the vote and was only defeated when the votes of returned servicemen were counted.\n\nWell known include William Fox, Frank Isitt, Leonard Isitt, Elizabeth McCombs, James McCombs, Kate Sheppard, Robert Stout and Tommy Taylor.\n\nThe liquor laws of New Zealand begin with the Colonisation of New Zealand and the implementation of English Common Law to New Zealand between 1840 and 1842, when New Zealand was jurisdictionally part of the Colony of New South Wales.\n\nLaws for Māori<br>\nThe first laws prohibiting Māori people from consuming alcohol in New Zealand were established between 1847 and 1878. Laws were passed due to the common belief the Māori were susceptible to alcohol abuse.\n\nFor over a century, from the 1847 laws to 1948, Māori were restricted to buying alcohol from off-licensed vendors. In 1948 Parliament repealed most discriminatory measures, in part due to pressure from Māori servicemen returning from war.\n\nThe King Country had an alcohol ban from when the predominantly Māori area was opened to pakeha in 1883 to 1953. \n\nLaws for Women<br>\nPrior to 1961, Women were generally restricted to private bars in hotels as legislation allowed licencees to refuse them service in the (cheaper) public bars.\n\nIn 1842 the first licensing system was introduced to New Zealand. This licensing system was mainly based on the then-provincial councils, however this changed in 1873 when legislature was passed to establish a national licensing system.\n\nUntil the 1990s off-licence alcohol sales where restricted to hotels, bottle shops, and private clubs were also allowed to sell alcohol for take home consumption. In 1990 supermarkets were granted permission to sell wine but not beer, but under amendments made in 1999, supermarkets and some smaller grocers now had permission to extend their liquor licences to sell beer as well as wine.\n\nThe 1999 legislation also legalized the sale of alcohol on Sundays for the first time in nearly 120 years.\n\nLicensing Act, 1881<br>\nThe Licensing Act of 1881 was enacted due to the dissolution of the Provincial Councils of New Zealand to centralize the inconsistent statutes of the former Provinces.\n\nThe Licensing Act of 1881 banned some entertainments, including dancing girls. Section 127 stated: ‘Whereas a practice exists in certain parts of the colony of hiring women and young girls to dance in rooms and places where liquors are sold: any contract by which any females shall be hired to dance in any such room or place shall be null and void.’ Proprietors risked having their establishment identified as a ‘disorderly house’ (a brothel), receiving a fine or losing their liquor license if they hired dancing girls.\n\nThe Act banned alcohol sales on Sundays, Christmas Day, and Good Friday.\n\nThe first registered consumption age limits were imposed for the first time meaning nobody under the age of 18 could drink in a public bar and nobody under the age of 13 could buy alcohol to take home.\n\nThe Licensing Act of 1881 created a minimum age of 16 to purchase alcohol in a bar, however did not impose a minimum age to purchase alcohol to be taken away.\n\nThe legal drinking age was again amended in 1910 when the legal age to drink in hotels was increased to 21 - however minors could still buy alcohol to take home until 1914 when the age for both on- and off-licence purchase was set at 21.\n\nIn 1969 the purchase age was lowered from 21 to 20. (although 18-year-olds were allowed to drink in bars from 1990 on certain conditions.) But in 1999 the legal purchasing age was lowered from 20 to 18 and despite several calls and legislation to raise the drinking age again, Lawmakers have overwhelmingly favoured the status quo and the age remains 18. It has never been illegal for a minor to drink alcohol in their own home on supervision of their parents or guardians however in 2013, minors consuming alcohol in a private setting other than their homes had to acquire parental permission before doing so.\n\nThe most significant piece of alcohol legislation introduced in New Zealand was the \"six o'clock swill\" in 1917. Intended to only be a temporary wartime measure through the remainder of World War One, this new law required all hotel bars to close at 6 pm nightly (and all day Sunday).\n\nThe swill was made permanent in 1919 owing to pressure from the then powerful temperance movement. The new law was supposed to curb drunkenness and crime and to send men home early to encourage family life, however six o'clock closing had the opposite effect. \nMen would finish work at 5 pm and had only one hour to drink as much alcohol (usually beer and from half gallon (2.2 litre) jugs) as possible before closing. This phenomenon created a culture of binge drinking.\n\nThe six o'clock swill also encouraged men to drive home from the hotels extremely drunk and car crashes were the most common between 6 pm and 8 pm especially on Friday and Saturday evenings. This was not helped by the fact New Zealand had no realistic Blood Alcohol limits for driving until 1969.\n\nThe swill ended on 9 October 1967 when pubs could stay open until 10 pm after a referendum on 26 September overwhelmingly saw voters favour change. A previous referendum in 1949 rejected later closing (due to economic rather than moral reasons).\n\nUnder New Zealand law, pubs looking to operate after the 3-4am liquor sales ban will have to apply for special licensing from their local board.\n\nLicensing trusts, under New Zealand law, are community-owned companies with a monopoly on the development of premises licensed for the sale of alcoholic beverages and associated accommodation in an area.\n\nThirty licencing trusts were established between 1944 and 1975. They were strongly supported by ministers Peter Fraser and Rex Mason. \n\nBeer is the most popular alcoholic drink in New Zealand, accounting for 63% of available alcohol for sale. New Zealand is ranked 21st in beer consumption per capita, at around 75.5 litres per person per annum. The vast majority of beer produced in New Zealand is a type of lager, either pale or amber in colour, and between 4%–5% alcohol by volume.\n\nThe first commercial brewery in New Zealand was established in 1835 by Joel Samuel Polack in Kororareka (now Russell) in the Bay of Islands. During the 19th century, New Zealand inherited the brewing traditions and styles of the United Kingdom and Ireland, being where the majority of European immigrants originated from during that time – thus the dominant beer styles would have been ales, porters & stouts.\nThe culture of the six o'clock swill was to have an influence on the styles of beer brewed and drunk in New Zealand. In the 1930s, the New Zealander Morton W. Coutts invented the continuous fermentation process. Gradually, beer production in New Zealand shifted from ales to lagers, using continuous fermentation. The style of beer made by this method has become known as New Zealand Draught and became the most popular beer during the 6 o'clock swill period.\n\nDuring the same period, there was a gradual consolidation of breweries, such that by the 1970s virtually all brewing concerns in New Zealand were owned by either Lion Breweries or Dominion Breweries. From the 1980s small boutique or microbreweries started to emerge, and consequently the range of beer styles being brewed increased. The earliest was Mac's Brewery, started in 1981 in Nelson. Some pubs operated their own small breweries, often housed within the pub itself.\n\nIn recent years, pale and amber lager, the largest alcoholic drinks sector in terms of volume sales, have been on a downward trend as a result of a declining demand for standard and economy products.\n\nConversely, ale production in New Zealand is primarily undertaken by small independent breweries & brewpubs, the Shakespeare Brewery in Auckland city being the first opened in 1986 for the 'craft' or 'premium' sector of the beer market. In 2010, this 'craft/premium' sector grew by 11%, to around 8% of the total beer market. This has been in a declining beer market, where availability of beer has dropped 7% by volume in the two previous years.\n\nCraft beer and microbreweries were blamed for a 15 million litre drop in alcohol sales overall in 2012, with Kiwis opting for higher-priced premium beers over cheaper brands.\n\nThe craft beer market in New Zealand is varied and progressive, with a full range of ale & lager styles of beer being brewed. New Zealand is fortunate in that it lies in the ideal latitude for barley and hops cultivation. A breeding programme had developed new hop varieties unique to New Zealand, many of these new hops have become mainstays in New Zealand craft beer.\n\nGiven the small market and relatively high number of breweries, many breweries have spare capacity. A recent trend has seen the rise of contract brewing, where a brewing company contracts to use space in existing breweries to bring the beer to the market. Examples of contract brewers include Funk Estate, Epic Brewing Company and Yeastie Boys.\n\nOver 2011 and 2012, New Zealand faced a shortage of hops, which affected several brewers countrywide, and was mainly due to a hop shortage in North America and an increase in demand for New Zealand hops overseas.\n\nIn the 1970s, Montana in Marlborough started producing wines which were labelled by year of production (vintage) and grape variety (in the style of wine producers in Australia). The first production of a Sauvignon blanc of great note appears to have occurred in 1977. Also produced in that year were superior quality wines of Muller Thurgau, Riesling and Pinotage.\nThe excitement created from these successes and from the early results of Cabernet Sauvignon from Auckland and Hawkes Bay launched the industry with ever-increasing investment, leading to more hectares planted, rising land prices and greater local interest and pride. Such was the boom that over-planting occurred, particularly in the \"wrong\" varietals that fell out of fashion in the early 1980s. In 1984 the then Labour Government paid growers to pull up vines to address a glut that was damaging the industry. Ironically many growers used the Government grant not to restrict planting, but to swap from less economic varieties (such as Müller Thurgau and other hybrids) to more fashionable varieties (Chardonnay and Sauvignon blanc), using the old root stock. The glut was only temporary in any case, as boom times returned swiftly.\n\nNew Zealand is home to a successful variety of sauvignon blanc. Oz Clarke, a well-known British wine critic wrote in the 1990s that New Zealand Sauvignon blanc was \"arguably the best in the world\" (Rachman). Historically, Sauvignon blanc has been used in many French regions in both AOC and Vin de Pays wine. The most famous had been France’s Sancerre. It is also the grape used to make Pouilly Fumé.\nFollowing Robert Mondavi's lead in renaming Californian Sauvignon blanc Fumé Blanc (partially in reference to Pouilly Fumé and partially to denote the smokiness of the wine produced due to flinty soil properties and partial oak barrel ageing) there was a trend for oaked Sauvignon blanc in New Zealand during the late 1980s. Later the fashion for strong oaky overtones and also the name waned.\n\nIn the 1980s, wineries in New Zealand, especially in the Marlborough region, began producing outstanding, some critics said unforgettable, Sauvignon blanc. \"New Zealand Sauvignon blanc is like a child who inherits the best of both parents—exotic aromas found in certain Sauvignon blancs from the New World and the pungency and limy acidity of an Old World Sauvignon blanc like Sancerre from the Loire Valley\" (Oldman, p. 152). One critic said that drinking one's first New Zealand Sauvignon blanc was like having sex for the first time (Taber, p. 244). \"No other region in the world can match Marlborough, the northeastern corner of New Zealand's South Island, which seems to be the best place in the world to grow Sauvignon blanc grapes\" (Taber, p. 244).\n\n\n\n\n"}
{"id": "3510108", "url": "https://en.wikipedia.org/wiki?curid=3510108", "title": "American Academy of Optometry", "text": "American Academy of Optometry\n\nThe American Academy of Optometry (AAO) is an organization of optometrists based in Orlando, Florida. Its goal is to maintain and enhance excellence in optometric practice, by both promoting research and the dissemination of knowledge.\n\nThe AAO holds an annual meeting, publishes a monthly scientific journal, creditials optometrists through the fellowship process and publishes position statements.\n\n\n"}
{"id": "3792782", "url": "https://en.wikipedia.org/wiki?curid=3792782", "title": "Aratrum terrae", "text": "Aratrum terrae\n\nThe term aratrum terræ, in ancient law books, meant as much land as can be tilled with one plough—\"Hoc manerium est 30 aratrorum.\"\n\nAratura terræ was an ancient service which the tenant was to do his lord, by ploughing his land.\n\n"}
{"id": "18353332", "url": "https://en.wikipedia.org/wiki?curid=18353332", "title": "Association for the History of Chiropractic", "text": "Association for the History of Chiropractic\n\nThe Association for the History of Chiropractic, founded in 1980, promotes the scholarly study and recording of the history of chiropractic. It publishes books and the journal \"Chiropractic History\", holds an annual meeting, and gives an annual award. Membership is open to anyone with an interest.\n"}
{"id": "34509774", "url": "https://en.wikipedia.org/wiki?curid=34509774", "title": "Avignone Chemists", "text": "Avignone Chemists\n\nAvignone Chemists was an American full service pharmacy located in New York's Greenwich Village. Avignone Chemists was founded in 1832 which made it the oldest apothecary in the United States. Avignone marketed itself as the Independent Anti-Chain Pharmacy. It closed in 2015.\n\nFounded in 1832 as Stock Pharmacy, the original location was at 59 Macdougal Street. Stock Pharmacy was purchased in 1898 by Francis Avignone who proceeded to change the name to Avignone Pharmacy. In 1929, Avignone Pharmacy moved to 281 6th Avenue, its current location, into a two-story building built by the Avignone family. Today, it is known as Avignone Chemists and is owned and operated by Andrew Fruchtman and his business partner John Duffy.\n\nAvignone was recognized as an important small business with the presentation of a Village Award by the Greenwich Village Society for Historic Preservation in 2013.\n\n"}
{"id": "12496608", "url": "https://en.wikipedia.org/wiki?curid=12496608", "title": "Bangladesh Red Crescent Society", "text": "Bangladesh Red Crescent Society\n\nBangladesh Red Crescent Society was established in 1973 as the Bangladesh Red Cross Society. It changed its name to Bangladesh Red Crescent Society in 1989. It has its headquarters in Dhaka. The society has played an instrumental role in relief and rehabilitation during floods, cyclones and other natural disasters which are frequent in various parts of Bangladesh.\n\n"}
{"id": "26696955", "url": "https://en.wikipedia.org/wiki?curid=26696955", "title": "Blue Cross Canada", "text": "Blue Cross Canada\n\nThe Canadian Association of Blue Cross Plans (CABCP) is an association of 7 regional not-for-profit health and travel insurance providers in Canada. The first Blue Cross Plan was offered to residents of Manitoba in 1939. The association is headquartered in Etobicoke, Ontario.\n\nBlue Cross Canada is linked to Blue Cross Blue Shield Association through International Federation of Health Funds.\n\n\n"}
{"id": "7662869", "url": "https://en.wikipedia.org/wiki?curid=7662869", "title": "Bosnalijek", "text": "Bosnalijek\n\nBosnalijek is the largest pharmaceutical company in Bosnia and Herzegovina. The organisation was established in 1951 and employs ~620 workers, out of which more than 50% have university level or higher qualifications. Its product portfolio consists of ~180 products. The company continues investment into R&D. Bosnalijek has established collaboration with several world-leading companies from the industry.\n\nBosnalijek is present in 22 countries worldwide: all neighbouring southeastern European countries, most eastern European countries, Libya and many French-speaking African countries, several countries from the Arabian peninsula and Caucasus, etc.\n\nIn 2005, International Finance Corporation provided Bosnalijek with a €7.5 million loan for the construction of an €18.5 million production and distribution center.\n\n"}
{"id": "32985025", "url": "https://en.wikipedia.org/wiki?curid=32985025", "title": "Brahma Kund", "text": "Brahma Kund\n\nBrahma Kund is a stepped temple tank in Sihor town of Bhavnagar district, Gujarat, India. It is located near the southern wall of the old town. It believed that it was constructed by Jayasimha Siddharaja.\n\nThe exact dates of Brahma Kund is unknown. It mentioned in \"Skanda Purana\".\n\nAccording to legend, Chaulukya king Jayasimha Siddharaja was suffering from skin disease following the curse from Ranakadevi, the queen whom he captured from Junagadh. He was cured after bathing in this tank so he refurbished the tank. The water of the tank is still considered miraculous. It is mentioned in \"Prabandh Chintamani\" written by Merutunga. The tank kept finding its reference and mentions citing Siddharaj since 12th century.\n\nIt is also mentioned in \"Ain-e-Akbari\". Poet Nanalal Dalpatram Kavi expresses and explains in his \"Hari Samhita\" that Krishna had visited the place.\n\nBrahma Kund, built in the style of medieval architecture, has a design of steps, small temples, metaphors, motifs and beliefs, idols of Hindu deities, stone work, some scientific entities, everything carved within and across the complex.\n\nThere is Neelkanth Mahadev temple near the tank. There is a lake known as \"Gautam Lake\" and Gautameshwar temple is located nearby.\n\nThe tank is the State Protected Monument (S-GJ-35). It is now poorly maintained.\n\nOn the last day of Shraavana month, called as \"Bhadarvi Amas\" or \"Bhadrapad Amavasya\", the fair is organised at the place which is attended by tens of thousands people.\n"}
{"id": "53300195", "url": "https://en.wikipedia.org/wiki?curid=53300195", "title": "Cannabis refugee", "text": "Cannabis refugee\n\nCannabis refugee (or marijuana refugee) is a term, primarily used in the United States and Canada, referring to people who have moved from one location to another due to cannabis prohibition laws, motivated either by a desire to have legal access to cannabis to treat medical conditions for themselves or their family, or to legally consume cannabis for any other reason.\n\n"}
{"id": "3692350", "url": "https://en.wikipedia.org/wiki?curid=3692350", "title": "Catuaba", "text": "Catuaba\n\nThe name Catuaba (pronounced [ka.two.'aba], a Guarani word that means \"what gives strength to the Indian\") is used for the infusions of the bark of a number of trees native to Brazil. The most widely used barks are derived from the trees \"Trichilia catigua\" and \"Erythroxylum vaccinifolium\". Other catuaba preparations use the bark of trees from the following genera or families: \"Anemopaegma\", \"Ilex\", \"Micropholis\", \"Phyllanthus\", \"Secondatia\", \"Tetragastris\" and species from the Myrtaceae.\n\nIt is often claimed that catuaba is derived from the tree \"Erythroxylum catuaba\", but this tree has been described only once, in 1904, and it is not known today to what tree this name referred. \"E. catuaba\" is therefore not a recognised species (Kletter et al.; 2004).\n\nLocal synonyms are Chuchuhuasha, Tatuaba, Pau de Reposta, Piratancara and Caramuru. A commercial liquid preparation, Catuama, contains multiple ingredients, one of these being catuaba from \"Trichilia catigua\".\n\nAn infusion of the bark is used in traditional Brazilian medicine as an aphrodisiac and central nervous system stimulant. These claims have not been confirmed in scientific studies. In catuaba is found a group of three alkaloids dubbed catuabine A, B and C.\n\nA study by Manabe et al. (1992) showed that catuaba extracts from Catuaba casca (\"Erythroxylum catuaba Arr. Cam.\") were useful in preventing potentially lethal bacterial infections and HIV infection in mice.\n\n"}
{"id": "12557622", "url": "https://en.wikipedia.org/wiki?curid=12557622", "title": "Counternull", "text": "Counternull\n\nIn statistics, and especially in the statistical analysis of psychological data, the counternull is a statistic used to aid the understanding and presentation of research results. It revolves around the effect size, which is the mean magnitude of some effect divided by the standard deviation.\n\nThe counternull value is the effect size that is just as well supported by the data as the null hypothesis. In particular, when results are drawn from a distribution that is symmetrical about its mean, the counternull value is exactly twice the observed effect size.\n\nThe null hypothesis is a hypothesis set up to be tested against an alternative. Thus the counternull is an alternative hypothesis that, when used to replace the null hypothesis, generates the same p-value as had the original null hypothesis of “no difference.”\n\nSome researchers contend that reporting the counternull, in addition to the \"p\"-value, serves to counter two common errors of judgment:\nThese arbitrary statistical thresholds create a discontinuity, causing unnecessary confusion and artificial controversy.\n\nOther researchers prefer confidence intervals as a means of countering these common errors.\n\n\n"}
{"id": "44093", "url": "https://en.wikipedia.org/wiki?curid=44093", "title": "Electroconvulsive therapy", "text": "Electroconvulsive therapy\n\nElectroconvulsive therapy (ECT), formerly known as electroshock therapy, and often referred to as shock treatment, is a psychiatric treatment in which seizures are electrically induced in patients to provide relief from mental disorders. The ECT procedure was first conducted in 1938 and is the only currently used form of shock therapy in psychiatry. ECT is often used with informed consent as a last line of intervention for major depressive disorder, mania, and catatonia. ECT machines have been placed in the Class III category by the United States Food and Drug Administration (FDA) since 1976.\n\nA round of ECT is effective for about 50% of people with treatment-resistant major depressive disorder, whether it is unipolar or bipolar. Follow-up treatment is still poorly studied, but about half of people who respond relapse within 12 months. Aside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia. Immediately following treatment, the most common adverse effects are confusion and memory loss. Among treatments for severely depressed pregnant women ECT is one of the least harmful to the gestating fetus.\n\nA usual course of ECT involves multiple administrations, typically given two or three times per week until the patient is no longer suffering symptoms. ECT is administered under anesthetic with a muscle relaxant. Electroconvulsive therapy can differ in its application in three ways: electrode placement, frequency of treatments, and the electrical waveform of the stimulus. These three forms of application have significant differences in both adverse side effects and symptom remission. Placement can be bilateral, in which the electric current is passed across the whole brain, or unilateral, in which the current is passed across one hemisphere of the brain. Bilateral placement seems to have greater efficacy than unilateral, but also carries greater risk of memory loss. After treatment, drug therapy is usually continued, and some patients receive maintenance ECT. \nECT appears to work in the short term via an anticonvulsant effect mostly in the frontal lobes, and longer term via neurotrophic effects primarily in the medial temporal lobe.\n\nECT is used with informed consent in treatment-resistant major depressive disorder, treatment-resistant catatonia, or prolonged or severe mania, and in conditions where \"there is a need for rapid, definitive response because of the severity of a psychiatric or medical condition (e.g., when illness is characterized by stupor, marked psycho-motor retardation, depressive delusions or hallucinations, or life-threatening physical exhaustion associated with mania).\"\n\nFor major depressive disorder, ECT is generally used only when other treatments have failed, or in emergencies, such as imminent suicide. ECT has also been used in selected cases of depression occurring in the setting of multiple sclerosis, Parkinson's disease, Huntington's chorea, developmental delay, brain arteriovenous malformations and hydrocephalus.\n\nA meta-analysis on the effectiveness of ECT in unipolar and bipolar depression was conducted in 2012. Results indicated that although patients with unipolar depression and bipolar depression responded to other medical treatments very differently, both groups responded equally well to ECT. Overall remission rate for patients given a round of ECT treatment was 51.5% for those with unipolar depression and 50.9% for those with bipolar depression. The severity of each patient’s depression was assessed at the same baseline in each group.\n\nThere is little agreement on the most appropriate follow-up to ECT for people with major depressive disorder. When ECT is followed by treatment with antidepressants, about 50% of people relapsed by 12 months following successful initial treatment with ECT, with about 37% relapsing within the first 6 months. About twice as many relapsed with no antidepressants. Most of the evidence for continuation therapy is with tricyclics; evidence for relapse prevention with newer antidepressants is lacking.\n\nIn 2004, a meta-analytic review paper found in terms of efficacy, \"a significant superiority of ECT in all comparisons: ECT versus simulated ECT, ECT versus placebo, ECT versus antidepressants in general, ECT versus TCAs and ECT versus MAOIs.\"\n\nIn 2003, The UK ECT Review group published a systematic review and meta-analysis comparing ECT to placebo and antidepressant drugs. This meta-analysis demonstrated a large effect size (high efficacy relative to the mean in terms of the standard deviation) for ECT versus placebo, and versus antidepressant drugs.\n\nCompared with transcranial magnetic stimulation for people with treatment-resistant major depressive disorder, ECT relieves depression about twice as well, reducing the score on the Hamilton Rating Scale for Depression by about 15 points, while TMS reduced it by 9 points.\n\nECT is generally a second-line treatment for people with catatonia who do not respond to other treatments, but is a first-line treatment for severe or life-threatening catatonia. There is a lack of clinical evidence for its efficacy but \"the excellent efficacy of ECT in catatonia is generally acknowledged\". For people with autism spectrum disorders who have catatonia, there is little published evidence about the efficacy of ECT; as of 2014 there were twelve case reports, and while ECT had \"life saving\" efficacy in some, results were mixed and temporary, and maintenance ECT was necessary to sustain any benefit.\n\nECT is used to treat people who have severe or prolonged mania; NICE recommends it only in life-threatening situations or when other treatments have failed and as a second-line treatment for bipolar mania.\n\nECT is rarely used in treatment-resistant schizophrenia, but is sometimes recommended for schizophrenia when short-term global improvement is desired, or the subject shows little response to antipsychotics alone. It is useful in the case of severe exacerbations of catatonic schizophrenia, whether excited or stuporous.\n\nAside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia; the U.S. Surgeon General's report says that there are \"no absolute health contraindications\" to its use. Immediately following treatment, the most common adverse effects are confusion and memory loss. It must be used very cautiously in people with epilepsy or other neurological disorders because by its nature it provokes small tonic-clonic seizures, and so would likely not be given to a person whose epilepsy is not well controlled. Some patients experience muscle soreness after ECT. This is due to the muscle relaxants given during the procedure and rarely due to muscle activity. ECT, especially if combined with deep sleep therapy, may lead to brain damage if administered in such a way as to lead to hypoxia or anoxia in the patient.\nThe death rate due to ECT is around 4 per 100,000 procedures. There is evidence and rationale to support giving low doses of benzodiazepines or else low doses of general anesthetics which induce sedation but not anesthesia to patients to reduce adverse effects of ECT.\n\nWhile there are no absolute contraindications for ECT, there is increased risk for patients who have unstable or severe cardiovascular conditions or aneurysms; who have recently had a stroke; who have increased intracranial pressure (for instance, due to a solid brain tumor), or who have severe pulmonary conditions, or who are generally at high risk for receiving anesthesia.\n\nIn adolescents, ECT is highly efficient for several psychiatric disorders, with few and relatively benign adverse effects.\n\nIn a study published in 2017 which involved 30 National Health Service (NHS) patients from Worcestershire, 80% said they would readily have the treatment again although 37% said it was frightening.\n\nCognitive impairment is sometimes noticed after ECT.\n\nRetrograde amnesia occurs to some extent in almost all ECT recipients. The American Psychiatric Association report (2001) acknowledges: “In some patients the recovery from retrograde amnesia will be incomplete, and evidence has shown that ECT can result in persistent or permanent memory loss”. It is the purported effects of ECT on long-term memory that give rise to much of the concern surrounding its use.\n\nHowever, the methods used to measure memory loss are generally poor, and their application to people with depression, who have cognitive deficits including problems with memory, have been problematic.\n\nThe acute effects of ECT can include amnesia, both retrograde (for events occurring before the treatment) and anterograde (for events occurring after the treatment). Memory loss and confusion are more pronounced with bilateral electrode placement rather than unilateral, and with outdated sine-wave rather than brief-pulse currents. The use of either constant or pulsing electrical impulses also varied the memory loss results in patients. Patients who received pulsing electrical impulses as opposed to a steady flow seemed to incur less memory loss. The vast majority of modern treatment uses brief pulse currents.\n\nRetrograde amnesia is most marked for events occurring in the weeks or months before treatment, with one study showing that although some people lose memories from years prior to treatment, recovery of such memories was \"virtually complete\" by seven months post-treatment, with the only enduring loss being memories in the weeks and months prior to the treatment. Anterograde memory loss is usually limited to the time of treatment itself or shortly afterwards. In the weeks and months following ECT these memory problems gradually improve, but some people have persistent losses, especially with bilateral ECT. One published review summarizing the results of questionnaires about subjective memory loss found that between 29% and 55% of respondents believed they experienced long-lasting or permanent memory changes. In 2000, American psychiatrist Sarah Lisanby and colleagues found that bilateral ECT left patients with more persistently impaired memory of public events as compared to RUL ECT.\n\nConsiderable controversy exists over the effects of ECT on brain tissue, although a number of mental health associations—including the American Psychiatric Association—have concluded that there is no evidence that ECT causes structural brain damage. A 1999 report by the U.S. Surgeon General states: \"The fears that ECT causes gross structural brain pathology have not been supported by decades of methodologically sound research in both humans and animals.\"\n\nMany expert proponents of ECT maintain that the procedure is safe and does not cause brain damage. Dr. Charles Kellner, a prominent ECT researcher and former chief editor of the \"Journal of ECT\", stated in a 2007 interview that, \"There are a number of well-designed studies that show ECT does not cause brain damage and numerous reports of patients who have received a large number of treatments over their lifetime and have suffered no significant problems due to ECT.\" Dr. Kellner cites a study purporting to show an absence of cognitive impairment in eight subjects after more than 100 lifetime ECT treatments. Dr. Kellner stated \"Rather than cause brain damage, there is evidence that ECT may reverse some of the damaging effects of serious psychiatric illness.\"\n\nIf steps are taken to decrease potential risks, ECT is generally accepted to be relatively safe during all trimesters of pregnancy, particularly when compared to pharmacological treatments. Suggested preparation for ECT during pregnancy includes a pelvic examination, discontinuation of nonessential anticholinergic medication, uterine tocodynamometry, intravenous hydration, and administration of a nonparticulate antacid. During ECT, elevation of the pregnant woman's right hip, external fetal cardiac monitoring, intubation, and avoidance of excessive hyperventilation are recommended. In many instances of active mood disorder during pregnancy, the risks of untreated symptoms may outweigh the risks of ECT. Potential complications of ECT during pregnancy can be minimized by modifications in technique. The use of ECT during pregnancy requires thorough evaluation of the patient’s capacity for informed consent.\n\nECT requires the informed consent of the patient.\n\nWhether psychiatric medications are terminated prior to treatment or maintained, varies. However, drugs that are known to cause toxicity in combination with ECT, such as lithium, are discontinued, and benzodiazepines, which increase seizure thresholds, are either discontinued, a benzodiazepine antagonist is administered at each ECT session, or the ECT treatment is adjusted accordingly.\n\nThe placement of electrodes, as well as the dose and duration of the stimulation is determined on a per-patient basis.\n\nIn unilateral ECT, both electrodes are placed on the same side of the patient's head. Unilateral ECT may be used first to minimize side effects such as memory loss.\n\nIn bilateral ECT, the two electrodes are placed on opposite sides of the head. Usually bitemporal placement is used, whereby the electrodes are placed on the temples. Uncommonly bifrontal placement in used; this involves positioning the electrodes on the patient's forehead, roughly above each eye.\n\nUnilateral ECT is thought to cause fewer cognitive effects than bilateral treatment, but is less effective unless administered at higher doses. Most patients in the US and almost all in the UK receive bilateral ECT.\n\nThe electrodes deliver an electrical stimulus. The stimulus levels recommended for ECT are in excess of an individual's seizure threshold: about one and a half times seizure threshold for bilateral ECT and up to 12 times for unilateral ECT. Below these levels treatment may not be effective in spite of a seizure, while doses massively above threshold level, especially with bilateral ECT, expose patients to the risk of more severe cognitive impairment without additional therapeutic gains. Seizure threshold is determined by trial and error (\"dose titration\"). Some psychiatrists use dose titration, some still use \"fixed dose\" (that is, all patients are given the same dose) and others compromise by roughly estimating a patient's threshold according to age and sex. Older men tend to have higher thresholds than younger women, but it is not a hard and fast rule, and other factors, for example drugs, affect seizure threshold.\n\nImmediately prior to treatment, a patient is given a short-acting anesthetic such as methohexital, etomidate, or thiopental, a muscle relaxant such as suxamethonium (succinylcholine), and occasionally atropine to inhibit salivation. In a minority of countries such as Japan, India, and Nigeria, ECT may be used without anesthesia. The Union Health Ministry of India recommended a ban on ECT without anesthesia in India's Mental Health Care Bill of 2010 and the Mental Health Care Bill of 2013. Some psychiatrists in India argued against the ban on unmodified ECT due to a lack of trained anesthesiologists available to administer ECT with anesthesia. The practice was abolished in Turkey's largest psychiatric hospital in 2008.\n\nThe patient's EEG, ECG, and blood oxygen levels are monitored during treatment.\n\nECT is usually administered three times a week, on alternate days, over a course of two to four weeks.\nMost modern ECT devices deliver a brief-pulse current, which is thought to cause fewer cognitive effects than the sine-wave currents which were originally used in ECT. A small minority of psychiatrists in the US still use sine-wave stimuli. Sine-wave is no longer used in the UK or Ireland.\nTypically, the electrical stimulus used in ECT is about 800 milliamps and has up to several hundred watts, and the current flows for between one and 6 seconds.\n\nIn the US, ECT devices are manufactured by two companies, Somatics, which is owned by psychiatrists Richard Abrams and Conrad Swartz, and Mecta. In the UK, the market for ECT devices was long monopolized by Ectron Ltd, which was set up by psychiatrist Robert Russell.\n\nDespite decades of research, the exact mechanism of action of ECT remains elusive. Neuroimaging studies in people who have had ECT, investigating differences between responders and nonresponders, and people who relapse, find that responders have anticonvulsant effects mostly in the frontal lobes, which corresponds to immediate responses, and neurotrophic effects primarily in the medial temporal lobe. The anticonvulsant effects are decreased blood flow and decreased metabolism, while the neurotrophic effects are opposite - increased perfusion and metabolism, as well as increased volume of the hippocampus.\n\nAs of 2001, it was estimated that about one million people received ECT annually.\n\nThere is wide variation in ECT use between different countries, different hospitals, and different psychiatrists. International practice varies considerably from widespread use of the therapy in many Western countries to a small minority of countries that do not use ECT at all, such as Slovenia.\n\nAbout 70 percent of ECT patients are women. This may be due to the fact that women are more likely to be diagnosed with depression. Older and more affluent patients are also more likely to receive ECT. The use of ECT is not as common in ethnic minorities.\n\nSarah Hall reports, \"ECT has been dogged by conflict between psychiatrists who swear by it, and some patients and families of patients who say that their lives have been ruined by it. It is controversial in some European countries such as the Netherlands and Italy, where its use is severely restricted\".\n\nECT became popular in the US in the 1940s. At the time, psychiatric hospitals were overrun with patients whom doctors were desperate to treat and cure. Whereas lobotomies would reduce a patient to a more manageable submissive state, ECT helped to improve mood in those with severe depression. A survey of psychiatric practice in the late 1980s found that an estimated 100,000 people received ECT annually, with wide variation between metropolitan statistical areas.\nAccurate statistics about the frequency, context and circumstances of ECT in the US are difficult to obtain because only a few states have reporting laws that require the treating facility to supply state authorities with this information. In 13 of the 50 states, the practice of ECT is regulated by law.\nOne state which does report such data is Texas, where, in the mid-1990s, ECT was used in about one third of psychiatric facilities and given to about 1,650 people annually.\nUsage of ECT has since declined slightly; in 2000–01 ECT was given to about 1500 people aged from 16 to 97 (in Texas it is illegal to give ECT to anyone under sixteen). ECT is more commonly used in private psychiatric hospitals than in public hospitals, and minority patients are underrepresented in the ECT statistics.\nIn the United States, ECT is usually given three times a week; in the United Kingdom, it is usually given twice a week. Occasionally it is given on a daily basis. A course usually consists of 6–12 treatments, but may be more or fewer. Following a course of ECT some patients may be given continuation or maintenance ECT with further treatments at weekly, fortnightly or monthly intervals. A few psychiatrists in the US use multiple-monitored ECT (MMECT), where patients receive more than one treatment per anesthetic. Electroconvulsive therapy is not a required subject in US medical schools and not a required skill in psychiatric residency training. Privileging for ECT practice at institutions is a local option: no national certification standards are established, and no ECT-specific continuing training experiences are required of ECT practitioners.\n\nIn the UK in 1980, an estimated 50,000 people received ECT annually, with use declining steadily since then to about 12,000 per annum in 2002. It is still used in nearly all psychiatric hospitals, with a survey of ECT use from 2002 finding that 71 percent of patients were women and 46 percent were over 65 years of age. Eighty-one percent had a diagnosis of mood disorder; schizophrenia was the next most common diagnosis. Sixteen percent were treated without their consent. In 2003, the National Institute for Health and Care Excellence, a government body which was set up to standardize treatment throughout the National Health Service in England and Wales, issued guidance on the use of ECT. Its use was recommended \"only to achieve rapid and short-term improvement of severe symptoms after an adequate trial of treatment options has proven ineffective and/or when the condition is considered to be potentially life-threatening in individuals with severe depressive illness, catatonia or a prolonged manic episode\".\n\nThe guidance received a mixed reception. It was welcomed by an editorial in the \"British Medical Journal\" but the Royal College of Psychiatrists launched an unsuccessful appeal. The NICE guidance, as the \"British Medical Journal\" editorial points out, is only a policy statement and psychiatrists may deviate from it if they see fit. Adherence to standards has not been universal in the past. A survey of ECT use in 1980 found that more than half of ECT clinics failed to meet minimum standards set by the Royal College of Psychiatrists, with a later survey in 1998 finding that minimum standards were largely adhered to, but that two-thirds of clinics still fell short of current guidelines, particularly in the training and supervision of junior doctors involved in the procedure. A voluntary accreditation scheme, ECTAS, was set up in 2004 by the Royal College, but as of 2006 only a minority of ECT clinics in England, Wales, Northern Ireland and the Republic of Ireland have signed up.\n\nThe Mental Health Act 2007 allows people to be treated against their will. This law has extra protections regarding ECT. A patient capable of making the decision can decline the treatment, and in that case treatment cannot be given unless it will save that patient's life or is immediately necessary to prevent deterioration of the patient's condition. A patient may not be capable of making the decision (they \"lack capacity\"), and in that situation ECT can be given if it is appropriate and also if there are no advance directives that prevent the use of ECT.\n\nECT was introduced in China in the early 1950s and while it was originally practiced without anesthesia, as of 2012 almost all procedures were conducted with it. As of 2012, there are approximately 400 ECT machines in China, and 150,000 ECT treatments are performed each year. Chinese national practice guidelines recommend ECT for the treatment of schizophrenia, depressive disorders, and bipolar disorder and in the Chinese literature, ECT is an effective treatment for schizophrenia and mood disorders. Although the Chinese government stopped classifying homosexuality as an illness in 2001, electroconvulsive therapy is still used by some establishments as a form of \"conversion therapy\".\n\nAs early as the 16th century, agents to induce seizures were used to treat psychiatric conditions. In 1785, the therapeutic use of seizure induction was documented in the \"London Medical Journal\". As to its earliest antecedents one doctor claims 1744 as the dawn of electricity's therapeutic use, as documented in the first issue of \"Electricity and Medicine\". Treatment and cure of hysterical blindness was documented eleven years later. Benjamin Franklin wrote that an electrostatic machine cured \"a woman of hysterical fits.\" In 1801, Giovanni Aldini used galvanism to treat patients suffering from various mental disorders. G.B.C. Duchenne, the mid-19th century \"Father of Electrotherapy\", said its use was integral to a neurological practice.\n\nIn the second half of the 19th century, such efforts were frequent enough in British asylums as to make it notable.\nConvulsive therapy was introduced in 1934 by Hungarian neuropsychiatrist Ladislas J. Meduna who, believing mistakenly that schizophrenia and epilepsy were antagonistic disorders, induced seizures first with camphor and then metrazol (cardiazol). Meduna is thought to be the father of convulsive therapy. In 1937, the first international meeting on convulsive therapy was held in Switzerland by the Swiss psychiatrist Muller. The proceedings were published in the \"American Journal of Psychiatry\" and, within three years, cardiazol convulsive therapy was being used worldwide. Italian Professor of neuropsychiatry Ugo Cerletti, who had been using electric shocks to produce seizures in animal experiments, and his colleague Lucio Bini developed the idea of using electricity as a substitute for metrazol in convulsive therapy and, in 1938, experimented for the first time on a person. It was believed early on that inducing convulsions aided in helping those with severe schizophrenia but later found to be most useful with affective disorders such as depression. Cerletti had noted a shock to the head produced convulsions in dogs. The idea to use electroshock on humans came to Cerletti when he saw how pigs were given an electric shock before being butchered to put them in an anesthetized state. Cerletti and Bini practiced until they felt they had the right parameters needed to have a successful human trial. Once they started trials on patients, they found that after 10-20 treatments the results were significant. Patients had much improved. A positive side effect to the treatment was retrograde amnesia. It was because of this side effect that patients could not remember the treatments and had no ill feelings toward it. ECT soon replaced metrazol therapy all over the world because it was cheaper, less frightening and more convenient. Cerletti and Bini were nominated for a Nobel Prize but did not receive one. By 1940, the procedure was introduced to both England and the US. In Germany and Austria, it was promoted by Friedrich Meggendorfer. Through the 1940s and 1950s, the use of ECT became widespread.\n\nIn the early 1940s, in an attempt to reduce the memory disturbance and confusion associated with treatment, two modifications were introduced: the use of unilateral electrode placement and the replacement of sinusoidal current with brief pulse. It took many years for brief-pulse equipment to be widely adopted. In the 1940s and early 1950s ECT, was usually given in \"unmodified\" form, without muscle relaxants, and the seizure resulted in a full-scale convulsion. A rare but serious complication of unmodified ECT was fracture or dislocation of the long bones. In the 1940s, psychiatrists began to experiment with curare, the muscle-paralysing South American poison, in order to modify the convulsions. The introduction of suxamethonium (succinylcholine), a safer synthetic alternative to curare, in 1951 led to the more widespread use of \"modified\" ECT. A short-acting anesthetic was usually given in addition to the muscle relaxant in order to spare patients the terrifying feeling of suffocation that can be experienced with muscle relaxants.\n\nThe steady growth of antidepressant use along with negative depictions of ECT in the mass media led to a marked decline in the use of ECT during the 1950s to the 1970s. The Surgeon General stated there were problems with electroshock therapy in the initial years before anesthesia was routinely given, and that \"these now-antiquated practices contributed to the negative portrayal of ECT in the popular media.\" \"The New York Times\" described the public's negative perception of ECT as being caused mainly by one movie: \"For Big Nurse in \"One Flew Over the Cuckoo's Nest,\" it was a tool of terror, and, in the public mind, \"shock therapy\" has retained the tarnished image given it by Ken Kesey's novel: dangerous, inhumane and overused\".\n\nIn 1976, Dr. Blatchley demonstrated the effectiveness of his constant current, brief pulse device ECT. This device eventually largely replaced earlier devices because of the reduction in cognitive side effects, although as of 2012 some ECT clinics still were using sine-wave devices. The 1970s saw the publication of the first American Psychiatric Association (APA) task force report on electroconvulsive therapy (to be followed by further reports in 1990 and 2001). The report endorsed the use of ECT in the treatment of depression. The decade also saw criticism of ECT. Specifically, critics pointed to shortcomings such as noted side effects, the procedure being used as a form of abuse, and uneven application of ECT. The use of ECT declined until the 1980s, \"when use began to increase amid growing awareness of its benefits and cost-effectiveness for treating severe depression\". In 1985, the National Institute of Mental Health and National Institutes of Health convened a consensus development conference on ECT and concluded that, while ECT was the most controversial treatment in psychiatry and had significant side-effects, it had been shown to be effective for a narrow range of severe psychiatric disorders.\n\nBecause of the backlash noted previously, national institutions reviewed past practices and set new standards. In 1978, the American Psychiatric Association released its first task force report in which new standards for consent were introduced and the use of unilateral electrode placement was recommended. The 1985 NIMH Consensus Conference confirmed the therapeutic role of ECT in certain circumstances. The American Psychiatric Association released its second task force report in 1990 where specific details on the delivery, education, and training of ECT were documented. Finally, in 2001 the American Psychiatric Association released its latest task force report. This report emphasizes the importance of informed consent, and the expanded role that the procedure has in modern medicine. By 2017, ECT was routinely covered by insurance companies for providing the \"biggest bang for the buck\" for otherwise intractable cases of severe mental illness, was receiving favorable media coverage, and was being provided in regional medical centers.\n\nSurveys of public opinion, the testimony of former patients, legal restrictions on the use of ECT and disputes as to the efficacy, ethics and adverse effects of ECT within the psychiatric and wider medical community indicate that the use of ECT remains controversial. This is reflected in the January 2011 vote by the FDA's Neurological Devices Advisory Panel to recommend that FDA maintain ECT devices in the Class III device category for high risk devices except for patients suffering from catatonia. This may result in the manufacturers of such devices having to do controlled trials on their safety and efficacy for the first time. In justifying their position, panelists referred to the memory loss associated with ECT and the lack of long-term data.\n\nThe World Health Organization (2005) advises that ECT should be used only with the informed consent of the patient (or their guardian if their incapacity to consent has been established).\n\nIn the US, this doctrine places a legal obligation on a doctor to make a patient aware of the reason for treatment, the risks and benefits of a proposed treatment, the risks and benefits of alternative treatment, and the risks and benefits of receiving no treatment. The patient is then given the opportunity to accept or reject the treatment. The form states how many treatments are recommended and also makes the patient aware that consent may be revoked and treatment discontinued at any time during a course of ECT. The US Surgeon General's Report on Mental Health states that patients should be warned that the benefits of ECT are short-lived without active continuation treatment in the form of drugs or further ECT, and that there may be some risk of permanent, severe memory loss after ECT. The report advises psychiatrists to involve patients in discussion, possibly with the aid of leaflets or videos, both before and during a course of ECT.\n\nTo demonstrate what he believes should be required to fully satisfy the legal obligation for informed consent, one psychiatrist, working for an anti-psychiatry organisation, has formulated his own consent form using the consent form developed and enacted by the Texas Legislature as a model.\n\nAccording to the US Surgeon General, involuntary treatment is uncommon in the US and is typically used only in cases of great extremity, and only when all other treatment options have been exhausted. The use of ECT is believed to be a potentially life-saving treatment.\n\nIn one of the few jurisdictions where recent statistics on ECT usage are available, a national audit of ECT by the Scottish ECT Accreditation Network indicated that 77% of patients who received the treatment in 2008 were capable of giving informed consent.\n\nIn the UK, in order for consent to be valid it requires an explanation in \"broad terms\" of the nature of the procedure and its likely effects. One review from 2005 found that only about half of patients felt they were given sufficient information about ECT and its adverse effects and another survey found that about fifty percent of psychiatrists and nurses agreed with them.\n\nA 2005 study published in the \"British Journal of Psychiatry\" described patients' perspectives on the adequacy of informed consent before ECT. The study found that \"About half (45–55%) of patients reported they were given an adequate explanation of ECT, implying a similar percentage felt they were not.\" The authors also stated:\n\nProcedures for involuntary ECT vary from country to country depending on local mental health laws.\n\nIn the US, ECT devices came into existence prior to medical devices being regulated by the Food and Drug Administration; when the law came into effect the FDA was obligated to retrospectively review already existing devices and classify them, and determine whether clinical trials were needed to prove efficacy and safety. While the FDA has classified the devices used to administer ECT as , as of 2011 the FDA had not yet determined whether the devices should be withdrawn from the market until clinical trials prove their safety and efficacy. The FDA considers ECT machinery to be experimental devices.\nIn most states in the US, a judicial order following a formal hearing is needed before a patient can be forced to undergo involuntary ECT. However, ECT can also be involuntarily administered in situations with less immediate danger. Suicidal intent is a common justification for its involuntary use, especially when other treatments are ineffective.\n\nUntil 2007 in England and Wales, the Mental Health Act 1983 allowed the use of ECT on detained patients whether or not they had capacity to consent to it. However, following amendments which took effect in 2007, ECT may not generally be given to a patient who has capacity and refuses it, irrespective of his or her detention under the Act. In fact, even if a patient is deemed to lack capacity, if they made a valid advance decision refusing ECT then they should not be given it; and even if they do not have an advance decision, the psychiatrist must obtain an independent second opinion (which is also the case if the patient is under age of consent). However, there is an exception regardless of consent and capacity; under Section 62 of the Act, if the treating psychiatrist says the need for treatment is urgent they may start a course of ECT without authorization. From 2003 to 2005, about 2,000 people a year in England and Wales were treated without their consent under the Mental Health Act. Concerns have been raised by the official regulator that psychiatrists are too readily assuming that patients have the capacity to consent to their treatments, and that there is a worrying lack of independent advocacy. In Scotland, the Mental Health (Care and Treatment) (Scotland) Act 2003 also gives patients with capacity the right to refuse ECT.\n\nA questionnaire survey of 379 members of the general public in Australia indicated that more than 60% of respondents had some knowledge about the main aspects of ECT. Participants were generally opposed to the use of ECT on depressed individuals with psychosocial issues, on children, and on involuntary patients. Public perceptions of ECT were found to be mainly negative.\n\nThough ECT has become a widely discouraged treatment, many people have recently pushed for the return of this controversial procedure. The 1975 film \"One Flew Over the Cuckoo's Nest\" has convinced viewers that ECT is a horrific procedure which only results in the patient's complete memory loss. Scientists have since debunked the notion that patients suffer acute memory loss after treatment, but the horrors of ECT present in the movie still remain a setback. In the last decade, patients have returned to using ECT to treat various mental illnesses including depression and bipolar disorder. Overcoming the looming controversy has proven difficult for doctors and scientists, and various campaigns to challenge negative stereotypes have gained popularity in the past few years. In 2014, the American Psychiatric Association launched a petition to reclassify ECT as a low-risk treatment. Though many people still believe ECT to be an inhumane procedure, many pro-ECT patients have publicly come forward with their positive response to the treatment. One patient by the name of Shelley Miller claims that \"medications have a success rate of 50-60% of patients getting better, while ECT succeeds at a rate of 70-90%.\"\n\nErnest Hemingway, an American author, died by suicide shortly after ECT at the Mayo Clinic in 1961. He is reported to have said to his biographer, \"Well, what is the sense of ruining my head and erasing my memory, which is my capital, and putting me out of business? It was a brilliant cure but we lost the patient...\" American surgeon and award-winning author Sherwin B. Nuland is another notable person who has undergone ECT. In his 40s, this successful surgeon's depression became so severe that he had to be institutionalized. After exhausting all treatment options, a young resident assigned to his case suggested ECT, which ended up being successful. Author David Foster Wallace also received ECT for many years, beginning as a teenager, before his suicide at age 46.\n\nAward-winning New Zealand author Janet Frame had ECT. She later wrote about this in her novel Faces in the Water.\n\nElectroconvulsive therapy has been depicted in fiction, including fictional works partly based on true experiences. These include Sylvia Plath's autobiographical novel, \"The Bell Jar\", Ken Loach's film Family Life, and Ken Kesey's novel \"One Flew Over the Cuckoo's Nest\"; Kesey's novel is a direct product of his time working the graveyard shift as an orderly at a mental health facility in Menlo Park, California.\n\nIn the 2000 film \"Requiem for a Dream\", Sarah Goldfarb receives \"unmodified\" electroconvulsive therapy after experiencing severe amphetamine psychosis following prolonged stimulant abuse. In the 2014 TV series \"Constantine\", the protagonist John Constantine is institutionalized and specifically requests electroconvulsive therapy as an attempt to alleviate or resolve his mental problems.\n\nThe musical \"Next to Normal\" centers around the family of a woman who undergoes the procedure.\n\nRobert Pirsig suffered a nervous breakdown and spent time in and out of psychiatric hospitals between 1961 and 1963. He was diagnosed with paranoid schizophrenia and clinical depression as a result of an evaluation conducted by psychoanalysts, and was treated with electroconvulsive therapy on numerous occasions, a treatment he discusses in his novel, \"Zen and the Art of Motorcycle Maintenance\".\n\nIn the HBO series \"Six Feet Under\" season 5, George undergoes an ECT treatment to deal with his increasing paranoia. The depiction is shown realistically, with an actual ECT machine.\n\nThroughout the history of ECT, women have received it two to three times as often as men. Currently, about 70 percent of ECT patients are women. This may be due to the fact that women are more likely to be diagnosed with depression. A 1974 study of ECT in Massachusetts reported that women made up 69 percent of those given ECT. The Ministry of Health in Canada reported that from 1999 until 2000 in the province of Ontario, women were 71 percent of those given ECT in provincial psychiatric institutions, and 75 percent of the total ECT given was given to women.\n\nECT treatment of severely autistic children with violent, sometimes self-harming behaviour first began in parts of the US during the early years of 21st century. Each session reportedly alleviates symptoms for up to 10 days at a time, but it is not claimed as a cure. One practitioner, Charles Kellner, ECT director at Mount Sinai Hospital in New York, is so convinced ECT is effective and safe that he allowed a parent to witness a procedure and the BBC to record the intervention.\n\n"}
{"id": "1455589", "url": "https://en.wikipedia.org/wiki?curid=1455589", "title": "Emergency management", "text": "Emergency management\n\nEmergency management is the organization and management of the resources and responsibilities for dealing with all humanitarian aspects of emergencies (preparedness, response, mitigation, and recovery). The aim is to reduce the harmful effects of all hazards, including disasters.\n\nThe World Health Organization defines an emergency as the state in which normal procedures are interrupted, and immediate measures need to be taken to prevent that state turning into a disaster. Thus, emergency management is crucial to avoid the disruption transforming into a disaster, which is even harder to recover from. Emergency management is a related term but should not be equated to disaster management.\n\nEmergency planning, a discipline of urban planning and design, first aims to prevent emergencies from occurring, and failing that, should develop a good action plan to mitigate the results and effects of any emergencies. As time goes on, and more data become available, usually through the study of emergencies as they occur, a plan should evolve. The development of emergency plans is a cyclical process, common to many risk management disciplines, such as business continuity and security risk management, as set out below:\n\n\nThere are a number of guidelines and publications regarding emergency planning, published by professional organizations such as ASIS, National Fire Protection Association (NFPA), and the International Association of Emergency Managers (IAEM). There are very few emergency management specific standards, and emergency management as a discipline tends to fall under business resilience standards.\n\nIn order to avoid or reduce significant losses to a business, emergency managers should work to identify and anticipate potential risks. In the event that an emergency does occur, managers should have a plan prepared to mitigate the effects of that emergency, as well as to ensure business continuity of critical operations after the incident. It is essential for an organization to include procedures for determining whether an emergency situation has occurred and at what point an emergency management plan should be activated. An emergency plan must be regularly maintained, in a structured and methodical manner, to ensure it is up-to-date in the event of an emergency. Emergency managers generally follow a common process to anticipate, assess, prevent, prepare, respond and recover from an incident.\n\nCleanup during disaster recovery involves many occupational hazards. Often these hazards are exacerbated by the conditions of the local environment as a result of the natural disaster. While individual workers should be aware of these potential hazards, employers are responsible for minimizing exposure to these hazards and protecting workers, when possible. This includes identification and thorough assessment of potential hazards, application of appropriate personal protective equipment (PPE), and the distribution of other relevant information in order to enable safe performance of the work. Maintaining a safe and healthy environment for these workers ensures that the effectiveness of the disaster recovery is unaffected.\n\nFlood-associated injuries: Flooding disasters often expose workers to trauma from sharp and blunt objects hidden under murky waters causing lacerations, as well as open and closed fractures. These injuries are further exacerbated with exposure to the often contaminated waters, leading to increased risk for infection. When working around water, there is always the risk of drowning. In addition, the risk of hypothermia significantly increases with prolonged exposure to water temperatures less than 75 degrees Fahrenheit. Non-infectious skin conditions may also occur including miliaria, immersion foot syndrome (including trench foot), and contact dermatitis.\n\nEarthquake-associated injuries: The predominant injuries are related to building structural components, including falling debris with possible crush injury, trapped under rubble, burns, and electric shock.\n\nChemicals can pose a risk to human health when exposed to humans at certain quantities. After a natural disaster, certain chemicals can be more prominent in the environment. These hazardous materials can be released directly or indirectly. Chemical hazards directly released after a natural disaster often occur concurrent with the event so little to no mitigation actions can take place for mitigation. For example, airborne magnesium, chloride, phosphorus, and ammonia can be generated by droughts. Dioxins can be produced by forest fires, and silica can be emitted by forest fires. Indirect release of hazardous chemicals can be intentionally released or unintentionally released. An example of intentional release is insecticides used after a flood or chlorine treatment of water after a flood. Unintentional release is when a hazardous chemical is not intentionally released. The chemical released is often toxic and serves beneficial purpose when released to the environment. These chemicals can be controlled through engineering to minimize their release when a natural disaster strikes. An example of this is agrochemicals from inundated storehouses or manufacturing facilities poisoning the floodwaters or asbestos fibers released from a building collapse during a hurricane. The flowchart to the right has been adopted from research performed by Stacy Young, et al., and can be found here.\n\nExposure limits\n\nBelow are TLV-TWA, PEL, and IDLH values for common chemicals workers are exposed to after a natural disaster.\nDirect release\n\nIntentional release\n\nUnintentional release\n\nExposure routes\n\nWhen a toxicant is prominent in an environment after a natural disaster, it is important to determine the route of exposure to worker safety for the disaster management workers. The three components are source of exposure, pathway of the chemical, and receptor. Questions to ask when dealing with chemical source is the material itself, how it’s used, how much is used, how often the chemical is used, temperature, vapor pressure, physical processes. The physical state of the chemical is important to identify. If working indoors, room ventilation, and volume of room needs to be noted to help mitigate health defects from the chemical. Lastly, to ensure worker safety, routes of entry for the chemical should be determined as well as relevant personal protective equipment needs to be worn.\n\nRespirators\n\nAccording to the CDC, “If you need to collect belongings or do basic clean up in your previously flooded home, you do not usually need to use a respirator (a mask worn to prevent breathing in harmful substances).” A respirator should be worn when performing an operation in an enclosed environment such as a house that creates ample amounts of dust. These activities could include sweeping dust, using power saws and equipment, or cleaning up mold. If you encounter dust, the CDC says to “limit your contact with the dust as much as possible. Use wet mops or vacuums with HEPA filters instead of dry sweeping and lastly wear a respirator that protects against dust in the air. A respirator that is approved by the CDC/NIOSH is the N95 respirator and can be a good personal protective equipment to protect from dust and mold in the air from the associated natural disaster.\n\nMold exposures: Exposure to mold is commonly seen after a natural disaster such as flooding, hurricane, tornado or tsunami. Mold growth can occur on both the exterior and interior of residential or commercial buildings. Warm and humid condition encourages mold growth; therefore, standing water and excess moisture after a natural disaster would provide an ideal environment for mold growth especially in tropical regions. While the exact number of mold species is unknown, some examples of commonly found indoor molds are Aspergillus, Cladosporium, Alternaria and Penicillium. Reaction to molds differ between individuals and can range from mild symptoms such as eye irritation, cough to severe life-threatening asthmatic or allergic reactions. People with history of chronic lung disease, asthma, allergy, other breathing problems or those that are immunocompromised could be more sensitive to molds and may develop fungal pneumonia.\n\nThe most effective approach to control mold growth after a natural disaster is to control moisture level. Some ways to prevent mold growth after a natural disaster include opening all doors and windows, using fans to dry out the building, positioning fans to blow air out of the windows and cleaning up the building within the first 24–48 hours. All wet items that cannot be properly cleaned and dried within the first 48 hours should be promptly removed and discarded from the building. If mold growth is found in the building, it is important to concurrently remove the molds and fix the underlying moisture problem. When removing molds, N-95 masks or respirators with a higher protection level should be used to prevent inhalation of molds into the respiratory system. Molds can be removed from hard surfaces by soap and water, a diluted bleach solution or commercial products.\n\nHuman remains: According to the Center for Disease Control and Prevention (CDC), \"There is no direct risk of contagion or infectious disease from being near human remains for people who are not directly involved in recovery or other efforts that require handling dead bodies.” Most viruses and bacteria perish along with the human body after death. Therefore, no excessive measures are necessary when handling human remains indirectly. However, for workers in direct contact with human remains, universal precautions should be exercised in order to prevent unnecessary exposure to blood-borne viruses and bacteria. Relevant PPE includes eye protection, face mask or shield, and gloves. The predominant health risk are gastrointestinal infections through fecal-oral contamination, so hand hygiene is paramount to prevention. Mental health support should also be available to workers who endure psychological stress during and after recovery.\n\nFlood-associated skin infections: Flood waters are often contaminated with bacteria and waste as well as chemicals on occasion. Prolonged, direct contact with these waters leads to an increased risk for skin infection, especially with open wounds in the skin or history of a previous skin condition, such as atopic dermatitis or psoriasis. These infections are exacerbated with a compromised immune system or an aging population. The most common bacterial skin infections are usually with Staphylococcus and Streptococcus. One of the most uncommon, but well-known bacterial infections is from Vibrio vulnificus, which causes a rare, but often fatal infection called necrotizing fasciitis. \nOther salt-water Mycobacterium infections include the slow growing M. marinum and fast growing M. fortuitum, M. chelonae, and M. abscessus. Fresh-water bacterial infections include aeromonas hydrophila, Burkholderia pseudomallei causing melioidosis, leptospira interrogans causing leptospirosis, and chromobacterium violaceum. Fungal infections may lead to chromoblastomycosis, blastomycosis, mucormycosis, and dermatophytosis. Numerous other arthropod, protozoal, and parasitic infections have been described. A worker can reduce the risk of flood-associated skin infections by avoiding the water if an open wound is present, or at minimum, cover the open wound with a waterproof bandage. Should contact with flood water occur, the open wound should be washed thoroughly with soap and clean water.\n\nProviding disaster recovery assistance is both rewarding and stressful. According to the CDC, \"Sources of stress for emergency responders may include witnessing human suffering, risk of personal harm, intense workloads, life-and-death decisions, and separation from family.\" These stresses need to be prevented or effectively managed in order to optimize assistance without causing danger to oneself. Preparation as an emergency responder is key, in addition to establishing care for responsibilities at home. During the recovery efforts, it is critical to understand and recognize burnout and sources of stress. After the recovery, it is vital to take time away from the disaster scene and slowly re-integrate back to the normal work environment. Substance Abuse and Mental Health Services Administration (SAMHSA) provides stress prevention and management resources for disaster recovery responders.\n\nThe Federal Emergency Management Agency (FEMA) advises those who desire to assist go through organized volunteer organizations and not to self-deploy to affected locations. The National Volunteer Organizations Active in Disaster (VOAD) serves as the primary point of contact for volunteer organization coordination. All states have their own state VOAD organization. As a volunteer, since an employer does not have oversight, one must be vigilant and protect against possible physical, chemical, biological, and psychosocial exposures. Furthermore, there must be defined roles with relevant training available. Proper tools and PPE may or may not be available, so safety and liability should always be considered.\n\nEvery employer is required to maintain a safe and healthy workplace for its employees. When an emergency situation occurs, employers are expected to protect workers from all harm resulting from any potential hazard, including physical, chemical, and biological exposure. In addition, an employer should provide pre-emergency training and build an emergency action plan.\n\nA written document about what actions employers and employees should take when responding to an emergency situation. According to OSHA regulations 1910.38, an employer must have an emergency action plan whenever an OSHA standard in this part requires one. To develop an emergency action plan, an employer should start from workplace evaluation. Typically, most of the occupational emergency management can be divided into worksite evaluation, exposure monitoring, hazard control, work practices, and training.\n\nWorksite evaluation is about identifying the source and location of the potential hazards such as fall, noise, cold, heat, hypoxia, infectious materials, and toxic chemicals that each of the workers may encounter during emergency situations.\n\nAfter identifying the source and location of the hazard(s), it is essential to monitor how employees may be exposed to these dangers. Employers should conduct task-specific exposure monitoring when they meet following requirements:\nTo effectively acquire the above information, an employer can ask workers how they perform the task or use direct reading instruments to identify the exposure level and exposure route.\n\nEmployers can conduct hazard control by:\n\nEmployers should train their employees annually before an emergency action plan is implemented. [https://www.osha.gov/pls/oshaweb/owadisp.show_document?p_table=STANDARDS&p_id=9726&p_text_version=FALSE#1910.38(f)(1) <nowiki>[29 CFR 1910.38(e)]</nowiki>] The purpose of training is to inform employees of their responsibilities and/or plan of action during emergency situations. The training program should include the types of emergencies that may occur, the appropriate response, evacuation procedure, warning/reporting procedure, and shutdown procedures. Training requirements are different depending on the size of workplace and workforce, processes used, materials handled, available resources and who will be in charge during an emergency.\n\nThe training program should address the following information:\nAfter the emergency action plan is completed, employer and employees should review the plan carefully and post it in a public area that is accessible to everyone. In addition, another responsibility of the employer is to keep a record of any injury or illness of workers according to OSHA/State Plan Record-keeping regulations.\n\nEmergency management plans and procedures should include the identification of appropriately trained staff members responsible for decision-making when an emergency occurs. Training plans should include internal people, contractors and civil protection partners, and should state the nature and frequency of training and testing.\n\nTesting of a plan's effectiveness should occur regularly. In instances where several business or organisations occupy the same space, joint emergency plans, formally agreed to by all parties, should be put into place.\n\nDrills and exercises in preparation for foreseeable hazards are often held, with the participation of the services that will be involved in handling the emergency, and people who will be affected. Drills are held to prepare for the hazards of fires, tornadoes, lockdown for protection, earthquakes, etc.\n\nCommunication is one of the key issues during any emergency, pre-planning of communications is critical. Miscommunication can easily result in emergency events escalating unnecessarily.\n\nOnce an emergency has been identified a comprehensive assessment evaluating the level of impact and its financial implications should be undertaken. Following assessment, the appropriate plan or response to be activated will depend on a specific pre-set criteria within the emergency plan. The steps necessary should be prioritized to ensure critical functions are operational as soon as possible. The critical functions are those that makes the plan untenable if not operationalized.\n\nThe communication policy must be well known and rehearsed, and all targeted audiences must be alert. All communication infrastructure must be as prepared as possible, with all information on groupings clearly identified.\n\nEmergency management consists of five phases: prevention, mitigation, preparedness, response and recovery. http://www.fema.gov/mission-areas\n\nIt focuses on preventing the human hazard, primarily from potential natural disasters or terrorist attacks. Preventive measures are taken on both the domestic and international levels, designed to provide permanent protection from disasters. also by doing this the risk of loss of life and injury can be mitigated with good evacuation plans, environmental planning and design standards. In January 2005, 167 Governments adopted a 10-year global plan for natural disaster risk reduction called the Hyogo Framework. \n\nPreventing or reducing the impacts of disasters on our communities is a key focus for emergency management efforts today. Prevention and mitigation also help reduce the financial costs of disaster response and recovery. Public Safety Canada is working with provincial and territorial governments and stakeholders to promote disaster prevention and mitigation using a risk-based and all-hazards approach. In 2009, Federal/Provincial/Territorial Ministers endorsed a National Disaster Mitigation Strategy.\n\nDisaster mitigation measures are those that eliminate or reduce the impacts and risks of hazards through proactive measures taken before an emergency or disaster occurs.\n\nPreventive or mitigation measures take different forms for different types of disasters. In earthquake prone areas, these preventive measures might include structural changes such as the installation of an earthquake valve to instantly shut off the natural gas supply, seismic retrofits of property, and the securing of items inside a building. The latter may include the mounting of furniture, refrigerators, water heaters and breakables to the walls, and the addition of cabinet latches. In flood prone areas, houses can be built on poles/stilts. In areas prone to prolonged electricity black-outs installation of a generator ensures continuation of electrical service. The construction of storm cellars and fallout shelters are further examples of personal mitigative actions.\n\nOn a national level, governments might implement large scale mitigation measures. After the monsoon floods of 2010, the Punjab government subsequently constructed 22 'disaster-resilient' model villages, comprising 1885 single-storey homes, together with schools and health centres.\n\nOne of the best known examples of investment in disaster mitigation is the Red River Floodway. The building of the Floodway was a joint provincial/federal undertaking to protect the City of Winnipeg and reduce the impact of flooding in the Red River Basin. It cost $62.7 million to build in the 1960s. Since then, the floodway has been used over 20 times. Its use during the 1997 Red River Flood alone saved an estimated $4.5 billion in costs from potential damage to the city. The Floodway was expanded in 2006 as a joint provincial/federal initiative.\n\nPreparedness focuses on preparing equipment and procedures for use when a disaster occurs. This equipment and these procedures can be used to reduce vulnerability to disaster, to mitigate the impacts of a disaster or to respond more efficiently in an emergency. The Federal Emergency Management Agency (FEMA) has set out a basic four-stage vision of preparedness flowing from mitigation to preparedness to response to recovery and back to mitigation in a circular planning process. This circular, overlapping model has been modified by other agencies, taught in emergency class and discussed in academic papers.\n\nFEMA also operates a Building Science Branch that develops and produces multi-hazard mitigation guidance that focuses on creating disaster-resilient communities to reduce loss of life and property.\nFEMA advises citizens to prepare their homes with some emergency essentials in the case that the food distribution lines are interrupted. FEMA has subsequently prepared for this contingency by purchasing hundreds of thousands of freeze dried food emergency meals ready to eat (MRE's) to dispense to the communities where emergency shelter and evacuations are implemented.\n\nSome guidelines for household preparedness have been put online by the State of Colorado, on the topics of water, food, tools, and so on.\n\nEmergency preparedness can be difficult to measure. CDC focuses on evaluating the effectiveness of its public health efforts through a variety of measurement and assessment programs.\n\nLocal Emergency Planning Committees (LEPCs) are required by the United States Environmental Protection Agency under the Emergency Planning and Community Right-to-Know Act to develop an emergency response plan, review the plan at least annually, and provide information about chemicals in the community to local citizens. This emergency preparedness effort focuses on hazards presented by use and storage of extremely hazardous and toxic chemicals. Particular requirements of LEPCs include\n\n\nAccording to the EPA, \"Many LEPCs have expanded their activities beyond the requirements of EPCRA, encouraging accident prevention and risk reduction, and addressing homeland security in their communities\", and the Agency offers advice on how to evaluate the effectiveness of these committees.\n\nPreparedness measures can take many forms ranging from focusing on individual people, locations or incidents to broader, government-based \"all hazard\" planning. There are a number of preparedness stages between \"all hazard\" and individual planning, generally involving some combination of both mitigation and response planning. Business continuity planning encourages businesses to have a Disaster Recovery Plan. Community- and faith-based organizations mitigation efforts promote field response teams and inter-agency planning. School-based response teams cover everything from live shooters to gas leaks and nearby bank robberies. Educational institutions plan for cyberattacks and windstorms. Industry specific guidance exists for horse farms, boat owners and more.\n\nFamily preparedness for disaster is fairly unusual. A 2013 survey found that only 19% of American families felt that they were \"very prepared\" for a disaster. Still, there are many resources available for family disaster planning. The Department of Homeland Security's Ready.gov page includes a Family Emergency Plan Checklist, has a whole webpage devoted to readiness for kids, complete with cartoon-style superheroes, and ran a Thunderclap Campaign in 2014. The Center for Disease Control has a Zombie Apocalypse website.\n\nDisasters take a variety of forms to include earthquakes, tsunamis or regular structure fires. That a disaster or emergency is not large scale in terms of population or acreage impacted or duration does not make it any less of a disaster for the people or area impacted and much can be learned about preparedness from so-called small disasters. The Red Cross states that it responds to nearly 70,000 disasters a year, the most common of which is a single family fire. \n\nPreparedness starts with an individual's everyday life and involves items and training that would be useful in an emergency. What is useful in an emergency is often also useful in everyday life. From personal preparedness, preparedness continues on a continuum through family preparedness, community preparedness and then business, non-profit and governmental preparedness. Some organizations blend these various levels. For example, the International Red Cross and Red Crescent Movement has a webpage on disaster training as well as offering training on basic preparedness such as Cardiopulmonary resuscitation and First Aid. Other non-profits such as Team Rubicon bring specific groups of people into disaster preparedness and response operations. FEMA breaks down preparedness into a pyramid, with citizens on the foundational bottom, on top of which rests local government, state government and federal government in that order.\n\nThe basic theme behind preparedness is to be ready for an emergency and there are a number of different variations of being ready based on an assessment of what sort of threats exist. Nonetheless, there is basic guidance for preparedness that is common despite an area's specific dangers. FEMA recommends that everyone have a three-day survival kit for their household. Because individual household sizes and specific needs might vary, FEMA's recommendations are not item specific, but the list includes:\n\nAlong similar lines, but not exactly the same, CDC has its own list for a proper disaster supply kit.\n\nChildren are a special population when considering Emergency preparedness and many resources are directly focused on supporting them. SAMHSA has list of tips for talking to children during infectious disease outbreaks, to include being a good listener, encouraging children to ask questions and modeling self-care by setting routines, eating healthy meals, getting enough sleep and taking deep breaths to handle stress. FEMA has similar advice, noting that \"Disasters can leave children feeling frightened, confused, and insecure\" whether a child has experienced it first hand, had it happen to a friend or simply saw it on television. In the same publication, FEMA further notes, \"Preparing for disaster helps everyone in the family accept the fact that disasters do happen, and provides an opportunity to identify and collect the resources needed to meet basic needs after disaster. Preparation helps; when people feel prepared, they cope better and so do children.\"\n\nTo help people assess what threats might be in order to augment their emergency supplies or improve their disaster response skills, FEMA has published a booklet called the \"Threat and Hazard Identification and Risk Assessment Guide.\" (THIRA) This guide, which outlines the THIRA process, emphasizes \"whole community involvement,\" not just governmental agencies, in preparedness efforts. In this guide, FEMA breaks down hazards into three categories: Natural, technological and human caused and notes that each hazard should be assessed for both its likelihood and its significance. According to FEMA, \"Communities should consider only those threats and hazards that could plausibly occur\" and \"Communities should consider only those threats and hazards that would have a significant effect on them.\" To develop threat and hazard context descriptions, communities should take into account the time, place, and conditions in which threats or hazards might occur.\n\nNot all preparedness efforts and discussions involve the government or established NGOs like the Red Cross. Emergency preparation discussions are active on the internet, with many blogs and websites dedicated to discussing various aspects of preparedness. On-line sales of items such as survival food, medical supplies and heirloom seeds allow people to stock basements with cases of food and drinks with 25 year shelf lives, sophisticated medical kits and seeds that are guaranteed to sprout even after years of storage.\n\nOne group of people who put a lot of effort in disaster preparations is called Doomsday Preppers. This subset of preparedness-minded people often share a belief that the FEMA or Red Cross emergency preparation suggestions and training are not extensive enough. Sometimes called survivalists, Doomsday Preppers are often preparing for The End Of The World As We Know It, abbreviated as TEOTWAWKI. With a motto some have that \"The Future Belongs to those who Prepare,\" this Preparedness subset has its own set of Murphy's Rules, including \"Rule Number 1: Food, you still don't have enough\" and \"Rule Number 26: People who thought the Government would save them, found out that it didn't.\"\n\nNot all emergency preparation efforts revolve around food, guns and shelters, though these items help address the needs in the bottom two sections of Maslow's hierarchy of needs. The American Preppers Network has an extensive list of items that might be useful in less apparent ways than a first aid kid or help add 'fun' to challenging times. These items include:\n\nEmergency preparedness goes beyond immediate family members. For many people, pets are an integral part of their families and emergency preparation advice includes them as well. It is not unknown for pet owners to die while trying to rescue their pets from a fire or from drowning. CDC's Disaster Supply Checklist for Pets includes:\n\nEmergency preparedness also includes more than physical items and skill-specific training. Psychological preparedness is also a type of emergency preparedness and specific mental health preparedness resources are offered for mental health professionals by organizations such as the Red Cross. These mental health preparedness resources are designed to support both community members affected by a disaster and the disaster workers serving them. CDC has a website devoted to coping with a disaster or traumatic event. After such an event, the CDC, through the Substance Abuse and Mental Health Services Administration (SAMHSA), suggests that people seek psychological help when they exhibit symptoms such as excessive worry, crying frequently, an increase in irritability, anger, and frequent arguing, wanting to be alone most of the time, feeling anxious or fearful, overwhelmed by sadness, confused, having trouble thinking clearly and concentrating, and difficulty making decisions, increased alcohol and/or substance use, increased physical (aches, pains) complaints such as headaches and trouble with \"nerves.\"\n\nSometimes emergency supplies are kept in what is called a Bug-out bag. While FEMA does not actually use the term \"Bug out bag,\" calling it instead some variation of a \"Go Kit,\" the idea of having emergency items in a quickly accessible place is common to both FEMA and CDC, though on-line discussions of what items a \"bug out bag\" should include sometimes cover items such as firearms and great knives that are not specifically suggested by FEMA or CDC. The theory behind a \"bug out bag\" is that emergency preparations should include the possibility of Emergency evacuation. Whether fleeing a burning building or hastily packing a car to escape an impending hurricane, flood or dangerous chemical release, rapid departure from a home or workplace environment is always a possibility and FEMA suggests having a Family Emergency Plan for such occasions. Because family members may not be together when disaster strikes, this plan should include reliable contact information for friends or relatives who live outside of what would be the disaster area for household members to notify they are safe or otherwise communicate with each other. Along with the contact information, FEMA suggests having well-understood local gathering points if a house must be evacuated quickly to avoid the dangers of re-reentering a burning home. Family and emergency contact information should be printed on cards and put in each family member's backpack or wallet. If family members spend a significant amount of time in a specific location, such as at work or school, FEMA suggests learning the emergency preparation plans for those places. FEMA has a specific form, in English and in Spanish, to help people put together these emergency plans, though it lacks lines for email contact information.\n\nLike children, people with disabilities and other special needs have special emergency preparation needs. While \"disability\" has a specific meaning for specific organizations such as collecting Social Security benefits, for the purposes of emergency preparedness, the Red Cross uses the term in a broader sense to include people with physical, medical, sensor or cognitive disabilities or the elderly and other special needs populations. Depending on the particular disability, specific emergency preparations might be required. FEMA's suggestions for people with disabilities includes having copies of prescriptions, charging devices for medical devices such as motorized wheel chairs and a week's supply of medication readily available LINK or in a \"go stay kit.\" In some instances, lack of competency in English may lead to special preparation requirements and communication efforts for both individuals and responders.\n\nFEMA notes that long term power outages can cause damage beyond the original disaster that can be mitigated with emergency generators or other power sources to provide an Emergency power system. The United States Department of Energy states that 'homeowners, business owners, and local leaders may have to take an active role in dealing with energy disruptions on their own.\" This active role may include installing or other procuring generators that are either portable or permanently mounted and run on fuels such as propane or natural gas or gasoline. Concerns about carbon monoxide poisoning, electrocution, flooding, fuel storage and fire lead even small property owners to consider professional installation and maintenance. Major institutions like hospitals, military bases and educational institutions often have or are considering extensive backup power systems. Instead of, or in addition to, fuel-based power systems, solar, wind and other alternative power sources may be used. Standalone batteries, large or small, are also used to provide backup charging for electrical systems and devices ranging from emergency lights to computers to cell phones.\n\nEmergency preparedness does not stop at home or at school. The United States Department of Health and Human Services addresses specific emergency preparedness issues hospitals may have to respond to, including maintaining a safe temperature, providing adequate electricity for life support systems and even carrying out evacuations under extreme circumstances. FEMA encourages all businesses to have businesses to have an emergency response plan and the Small Business Administration specifically advises small business owners to also focus emergency preparedness and provides a variety of different worksheets and resources.\n\nFEMA cautions that emergencies happen while people are travelling as well and provides guidance around emergency preparedness for a range travelers to include commuters, \"Commuter Emergency Plan\" and holiday travelers. In particular, Ready.gov has a number of emergency preparations specifically designed for people with cars. These preparations include having a full gas tank, maintaining adequate windshield wiper fluid and other basic car maintenance tips. Items specific to an emergency include:\n\nIn addition to emergency supplies and training for various situations, FEMA offers advice on how to mitigate disasters. The Agency gives instructions on how to retrofit a home to minimize hazards from a Flood, to include installing a Backflow prevention device, anchoring fuel tanks and relocating electrical panels. \nGiven the explosive danger posed by natural gas leaks, Ready.gov states unequivocally that \"It is vital that all household members know how to shut off natural gas\" and that property owners must ensure they have any special tools needed for their particular gas hookups. Ready.gov also notes that \"It is wise to teach all responsible household members where and how to shut off the electricity,\" cautioning that individual circuits should be shut off before the main circuit. Ready.gov further states that \"It is vital that all household members learn how to shut off the water at the main house valve\" and cautions that the possibility that rusty valves might require replacement.\n\nThe response phase of an emergency may commence with Search and Rescue but in all cases the focus will quickly turn to fulfilling the basic humanitarian needs of the affected population. This assistance may be provided by national or international agencies and organizations. Effective coordination of disaster assistance is often crucial, particularly when many organizations respond and local emergency management agency (LEMA) capacity has been exceeded by the demand or diminished by the disaster itself. The National Response Framework is a United States government publication that explains responsibilities and expectations of government officials at the local, state, federal, and tribal levels. It provides guidance on Emergency Support Functions that may be integrated in whole or parts to aid in the response and recovery process.\n\nOn a personal level the response can take the shape either of a \"shelter in place\" or an \"evacuation\". In a shelter-in-place scenario, a family would be prepared to fend for themselves in their home for many days without any form of outside support. In an \"evacuation\", a family leaves the area by automobile or other mode of transportation, taking with them the maximum amount of supplies they can carry, possibly including a tent for shelter. If mechanical transportation is not available, evacuation on foot would ideally include carrying at least three days of supplies and rain-tight bedding, a tarpaulin and a bedroll of blankets.\n\nDonations are often sought during this period, especially for large disasters that overwhelm local capacity. Due to efficiencies of scale, money is often the most cost-effective donation if fraud is avoided. Money is also the most flexible, and if goods are sourced locally then transportation is minimized and the local economy is boosted. Some donors prefer to send gifts in kind, however these items can end up creating issues, rather than helping. One innovation by Occupy Sandy volunteers is to use a donation registry, where families and businesses impacted by the disaster can make specific requests, which remote donors can purchase directly via a web site.\n\nMedical considerations will vary greatly based on the type of disaster and secondary effects. Survivors may sustain a multitude of injuries to include lacerations, burns, near drowning, or crush syndrome.\n\nThe recovery phase starts after the immediate threat to human life has subsided. The immediate goal of the recovery phase is to bring the affected area back to normalcy as quickly as possible. During reconstruction it is recommended to consider the location or construction material of the property.\n\nThe most extreme home confinement scenarios include war, famine and severe epidemics and may last a year or more. Then recovery will take place inside the home. Planners for these events usually buy bulk foods and appropriate storage and preparation equipment, and eat the food as part of normal life. A simple balanced diet can be constructed from vitamin pills, whole-meal wheat, beans, dried milk, corn, and cooking oil. Vegetables, fruits, spices and meats, both prepared and fresh-gardened, are included when possible.\n\nProfessional emergency managers can focus on government and community preparedness, or private business preparedness. Training is provided by local, state, federal and private organizations and ranges from public information and media relations to high-level incident command and tactical skills.\n\nIn the past, the field of emergency management has been populated mostly by people with a military or first responder background. Currently, the field has become more diverse, with many managers coming from a variety of backgrounds other than the military or first responder fields. Educational opportunities are increasing for those seeking undergraduate and graduate degrees in emergency management or a related field. There are over 180 schools in the US with emergency management-related programs, but only one doctoral program specifically in emergency management.\n\nProfessional certifications such as Certified Emergency Manager (CEM) and Certified Business Continuity Professional (CBCP) are becoming more common as professional standards are raised throughout the field, particularly in the United States. There are also professional organizations for emergency managers, such as the National Emergency Management Association and the International Association of Emergency Managers.\n\nIn 2007, Dr. Wayne Blanchard of FEMA's Emergency Management Higher Education Project, at the direction of Dr. Cortez Lawrence, Superintendent of FEMA's Emergency Management Institute, convened a working group of emergency management practitioners and academics to consider principles of emergency management. This was the first time the principles of the discipline were to be codified. The group agreed on eight principles that will be used to guide the development of a doctrine of emergency management. Below is a summary:\n\n\nA fuller description of these principles can be found at\n\nIn recent years the continuity feature of emergency management has resulted in a new concept, Emergency Management Information Systems (EMIS). For continuity and inter-operability between emergency management stakeholders, EMIS supports an infrastructure that integrates emergency plans at all levels of government and non-government involvement for all four phases of emergencies. In the healthcare field, hospitals utilize the Hospital Incident Command System (HICS), which provides structure and organization in a clearly defined chain of command.\n\nPractitioners in emergency management come from an increasing variety of backgrounds. Professionals from memory institutions (e.g., museums, historical societies, etc.) are dedicated to preserving cultural heritage—objects and records. This has been an increasingly major component within this field as a result of the heightened awareness following the September 11 attacks in 2001, the hurricanes in 2005, and the collapse of the Cologne Archives.\n\nTo increase the potential successful recovery of valuable records, a well-established and thoroughly tested plan must be developed. This plan should emphasize simplicity in order to aid in response and recovery: employees should perform similar tasks in the response and recovery phase that they perform under normal conditions. It should also include mitigation strategies such as the installation of sprinklers within the institution. Professional associations hold regular workshops to keep individuals up to date with tools and resources in order to minimize risk and maximize recovery.\n\nIn 2008, the U.S. Agency for International Development created a web-based tool for estimating populations impacted by disasters. Called Population Explorer the tool uses land scan population data, developed by Oak Ridge National Laboratory, to distribute population at a resolution 1 km for all countries in the world. Used by USAID's FEWS NET Project to estimate populations vulnerable and or imd by food insecurity, Population Explorer is gaining wide use in a range of emergency analysis and response actions, including estimating populations impacted by floods in Central America and the Pacific Ocean tsunami event in 2009.\n\nIn 2007, a checklist for veterinarians was published in the Journal of the American Veterinary Medical Association, it had two sets of questions for a professional to ask themselves before assisting with an emergency:\n\nAbsolute requirements for participation:\n\nIncident participation:\n\nWhile written for veterinarians, this checklist is applicable for any professional to consider before assisting with an emergency.\n\nThe International Emergency Management Society (TIEMS), is an international non-profit NGO, registered in Belgium. TIEMS is a Global Forum for Education, Training, Certification and Policy in Emergency and Disaster Management. TIEMS' goal is to develop and bring modern emergency management tools, and techniques into practice, through the exchange of information, methodology innovations and new technologies.\n\nTIEMS provides a platform for stakeholders to meet, network and learn about new technical and operational methodologies. TIEMS focuses on cultural differences to be understood and included in the society's events, education and research programs. This is achieved by establishing local chapters worldwide. Today, TIEMS has chapters in Benelux, Romania, Finland, Italy, Middle East and North Africa (MENA), Iraq, India, Korea, Japan and China.\n\nThe International Association of Emergency Managers (IAEM) is a non-profit educational organization aimed at promoting the goals of saving lives and property protection during emergencies. The mission of IAEM is to serve its members by providing information, networking and professional opportunities, and to advance the emergency management profession.\n\nIt has seven councils around the world: Asia, Canada, Europa, International, Oceania, Student and USA.\n\nThe Air Force Emergency Management Association, affiliated by membership with the IAEM, provides emergency management information and networking for U.S. Air Force Emergency Management personnel.\n\nThe International Recovery Platform (IRP) was conceived at the World Conference on Disaster Reduction (WCDR) in Kobe, Hyogo, Japan in January 2005, as part of the \"Hyogo Framework for Action (HFA) 2005–2015\". The HFA is a global plan for disaster risk reduction adopted by 168 governments.\n\nThe key role of IRP is to identify gaps in post disaster recovery and to serve as a catalyst for the development of tools and resources for recovery efforts.\n\nThe International Federation of Red Cross and Red Crescent Societies (IFRC) works closely with National Red Cross and Red Crescent societies in responding to emergencies, many times playing a pivotal role. In addition, the IFRC may deploy assessment teams, e.g. Field Assessment and Coordination Teams (FACT), to the affected country if requested by the national society. After assessing the needs, Emergency Response Units (ERUs) may be deployed to the affected country or region. They are specialized in the response component of the emergency management framework.\n\nBaptist Global Response (BGR) is a disaster relief and community development organization. BGR and its partners respond globally to people with critical needs worldwide, whether those needs arise from chronic conditions or acute crises such as natural disasters. While BGR is not an official entity of the Southern Baptist Convention, it is rooted in Southern Baptist life and is the international partnership of Southern Baptist Disaster Relief teams, which operate primarily in the US and Canada.\n\nThe United Nations system rests with the Resident Coordinator within the affected country. However, in practice, the UN response will be coordinated by the UN Office for the Coordination of Humanitarian Affairs (UN-OCHA), by deploying a UN Disaster Assessment and Coordination (UNDAC) team, in response to a request by the affected country's government. Finally UN-SPIDER designed as a networking hub to support disaster management by application of satellite technology\n\nSince 1980, the World Bank has approved more than 500 projects related to disaster management, dealing with both disaster mitigation as well as reconstruction projects, amounting to more than US$40 billion. These projects have taken place all over the world, in countries such as Argentina, Bangladesh, Colombia, Haiti, India, Mexico, Turkey and Vietnam.\n\nPrevention and mitigation projects include forest fire prevention measures, such as early warning measures and education campaigns; early-warning systems for hurricanes; flood prevention mechanisms (e.g. shore protection, terracing, etc.); and earthquake-prone construction. In a joint venture with Columbia University under the umbrella of the ProVention Consortium the World Bank has established a Global Risk Analysis of Natural Disaster Hotspots.\n\nIn June 2006, the World Bank, in response to the HFA, established the Global Facility for Disaster Reduction and Recovery (GFDRR), a partnership with other aid donors to reduce disaster losses. GFDRR helps developing countries fund development projects and programs that enhance local capacities for disaster prevention and emergency preparedness.\n\nIn 2001 the EU adopted Community Mechanism for Civil Protection, to facilitate co-operation in the event of major emergencies requiring urgent response actions. This also applies to situations where there may be an imminent threat as well.\n\nThe heart of the Mechanism is the Monitoring and Information Center (MIC), part of the European Commission's Directorate-General for Humanitarian Aid & Civil Protection. Accessible 24 hours a day, it gives countries access to a one-stop-shop of civil protections available amongst all the participating states. Any country inside or outside the Union affected by a major disaster can make an appeal for assistance through the MIC. It acts as a communication hub, and provides useful and updated information on the actual status of an ongoing emergency.\n\n\nNaers are part of life in Australia. Heatwaves have killed more Australians than any other type of natural disaster in the 20th century. Australia's emergency management processes embrace the concept of the prepared community. The principal government agency in achieving this is Emergency Management Australia.\n\nPublic Safety Canada is Canada's national emergency management agency. Each province is required to have both legislation for dealing with emergencies, and provincial emergency management agencies, typically called \"Emergency Measures Organizations\" (EMO). Public Safety Canada co-ordinates and supports the efforts of federal organizations as well as other levels of government, first responders, community groups, the private sector, and other nations. The Public Safety and Emergency Preparedness Act defines the powers, duties and functions of PS are outlined. Other acts are specific to individual fields such as corrections, law enforcement, and national security.\n\nIn Germany the Federal Government controls the German \"Katastrophenschutz\" (disaster relief), the Technisches Hilfswerk (\"Federal Agency for Technical Relief\", THW), and the \"Zivilschutz\" (civil protection) programs coordinated by the \"Federal Office of Civil Protection and Disaster Assistance\". Local fire department units, the German Armed Forces (Bundeswehr), the German Federal Police and the 16 state police forces (Länderpolizei) are also deployed during disaster relief operations.\n\nThere are several private organizations in Germany that also deal with emergency relief. Among these are the German Red Cross, Johanniter-Unfall-Hilfe (the German equivalent of the St. John Ambulance), the Malteser-Hilfsdienst, and the Arbeiter-Samariter-Bund. As of 2006, there is a program of study at the University of Bonn leading to the degree \"Master in Disaster Prevention and Risk Governance\" As a support function radio amateurs provide additional emergency communication networks with frequent trainings.\n\nThe National Disaster Management Authority is the primary government agency responsible for planning and capacity-building for disaster relief. Its emphasis is primarily on strategic risk management and mitigation, as well as developing policies and planning. The National Institute of Disaster Management is a policy think-tank and training institution for developing guidelines and training programs for mitigating disasters and managing crisis response.\n\nThe National Disaster Response Force is the government agency primarily responsible for emergency management during natural and man-made disasters, with specialized skills in search, rescue and rehabilitation. The Ministry of Science and Technology also contains an agency that brings the expertise of earth scientists and meteorologists to emergency management. The Indian Armed Forces also plays an important role in the rescue/recovery operations after disasters.\n\nAniruddha's Academy of Disaster Management (AADM) is a non-profit organization in Mumbai, India with 'disaster management' as its principal objective.\n\nIn Malaysia, The National Disaster Management Agency (NADMA Malaysia) under the Prime Minister's Department was established on 2 October 2015 following the Flood Disaster in 2014 and taken over the roles previously National Security Council. NADMA Malaysia is the focal point in managing disaster in Malaysia. Ministry of Home Affairs Malaysia, Ministry of Health Malaysia and Ministry of Housing, Urban Wellbeing and Local Government Malaysia are also having responsibility in managing emergency. Several agencies are involved in emergency managements are Royal Malaysian Police, Malaysian Fire and Rescue Department, Malaysian Civil Defence Force, Ministry of Health Malaysia and Malaysian Maritime Enforcement Agency. There were also some voluntary organisation who involved themselves in emergency/ disaster management such as St. John Ambulance of Malaysia, Malaysian Red Crescent Society and so on.\n\nThe Nepal Risk Reduction Consortium (NRRC) is based on hyogo Framework and Nepal's National Strategy for Disaster Risk Management. This arrangement unites humanitarian and development partners with Government of Nepal and had identified 5 flagship priorities for sustainable disaster risk management.\n\nIn New Zealand, depending on the scope of the emergency/disaster, responsibility may be handled at either the local or national level. Within each region, local governments are organized into 16 Civil Defence Emergency Management Groups (CMGs). If local arrangements are overwhelmed, pre-existing mutual-support arrangements are activated. Central government has the authority to coordinate the response through the National Crisis Management Centre (NCMC), operated by the Ministry of Civil Defence & Emergency Management (MCDEM). These structures are defined by regulation, and explained in \"The Guide to the National Civil Defence Emergency Management Plan 2006\", roughly equivalent to the U.S. Federal Emergency Management Agency's National Response Framework.\n\nNew Zealand uses unique terminology for emergency management. Emergency management is rarely used, many government publications retaining the use of the term civil defence. For example, the Minister of Civil Defence is responsible for the MCDEM. Civil Defence Emergency Management is a term in its own right, defined by statute. And disaster rarely appears in official publications, emergency and incident being the preferred terms, with the term event also being used. For example, publications refer to the Canterbury Snow Event 2002.\n\n\"4Rs\" is the emergency management cycle used in New Zealand, its four phases are known as:\n\nDisaster management in Pakistan revolves around flood disasters focusing on rescue and relief.\n\nFederal Flood Commission was established in 1977 under Ministry of Water and Power to manage the issues of flood management on country-wide basis.\n\nThe National Disaster Management Ordinance, 2006 and National Disaster Management Act, 2010 were enacted after 2005 Kashmir earthquake and 2010 Pakistan floods respectively to deal with disaster management. \nThe primary central authority mandated to deal with whole spectrum of disasters and their management in the country is National Disaster Management Authority.\n\nIn addition each province along with FATA, Gilgit Baltistan and Pakistani administered Kashmir has its own provincial disaster management authority responsible for implementing policies and plans for Disaster Management in the Province.\n\nEach District has its own District Disaster Management Authority for planning, coordinating and implementing body for disaster management and take all measures for the purposes of disaster management in the districts in accordance with the guidelines laid down by the National Authority and the Provincial Authority.\n\nIn the Philippines, the National Disaster Risk Reduction and Management Council is responsible for the protection and welfare of people during disasters or emergencies. It is a working group composed of various government, non-government, civil sector and private sector organizations of the Government of the Republic of the Philippines. Headed by the Secretary of National Defense (under the Office of Civil Defense, the NDRRMCs implementing organization), it coordinates all the executive branches of government, presidents of the leagues of local government units throughout the country, the Armed Forces of the Philippines, Philippine National Police, Bureau of Fire Protection (which is an agency under the Department of Interior and Local Government, and the public and private medical services in responding to natural and manmade disasters, as well as planning, coordination, and training of these responsible units. Non-governmental organizations such as the Philippine Red Cross also provide manpower and material support for NDRRMC.\n\nRegional, provincial, city, municipal, and barangay emergency management are handled by Local Disaster Risk Reduction Management Councils (LDRRMCs), which are the functional arm of the local government unit (LGU). Each LDRRMC is headed by a Chief DRRM Officer, and each Office is tasked to organize their own emergency teams and command-and-control centers when activated at times of local emergencies (identified on the regional, provincial, city, municipal, and/or barangay level).\n\nIn Russia, the Ministry of Emergency Situations (EMERCOM) is engaged in fire fighting, civil defense, and search and rescue after both natural and human-made disasters.\n\nIn Somalia, the Federal Government announced in May 2013 that the Cabinet had approved draft legislation on a new Somali Disaster Management Agency (SDMA), which had originally been proposed by the Ministry of Interior. According to the Prime Minister's Media Office, the SDMA will lead and coordinate the government's response to various natural disasters. It is part of a broader effort by the federal authorities to re-establish national institutions. The Federal Parliament is now expected to deliberate on the proposed bill for endorsement after any amendments.\n\nIn the Netherlands the Ministry of Security and Justice is responsible for emergency preparedness and emergency management on a national level and operates a national crisis centre (NCC). The country is divided into 25 safety regions (veiligheidsregio). In a safety region, there are four components: the regional fire department, the regional department for medical care(ambulances and psycho-sociological care etc.), the regional dispatch and a section for risk- and crisis management. The regional dispatch operates for police, fire department and the regional medical care. The dispatch has all these three services combined into one dispatch for the best multi-coordinated response to an incident or an emergency. And also facilitates in information management, emergency communication and care of citizens. These services are the main structure for a response to an emergency. It can happen that, for a specific emergency, the co-operation with an other service is needed, for instance the Ministry of Defence, water board(s) or Rijkswaterstaat. The veiligheidsregio can integrate these other services into their structure by adding them to specific conferences on operational or administrative level.\n\nAll regions operate according to the Coordinated Regional Incident Management system.\n\nFollowing the 2000 fuel protests and severe flooding that same year, as well as the foot-and-mouth crisis in 2001, the United Kingdom passed the Civil Contingencies Act 2004 (CCA). The CCA defined some organisations as Category 1 and 2 Responders, setting responsibilities regarding emergency preparedness and response. It is managed by the Civil Contingencies Secretariat through Regional Resilience Forums and local authorities.\n\nDisaster Management training is generally conducted at the local level, and consolidated through professional courses that can be taken at the Emergency Planning College. Diplomas, undergraduate and postgraduate qualifications can be gained at universities throughout the country. The Institute of Emergency Management is a charity, established in 1996, providing consulting services for the government, media and commercial sectors. There are a number of professional societies for Emergency Planners including the Emergency Planning Society and the Institute of Civil Protection and Emergency Management.\n\nOne of the largest emergency exercises in the UK was carried out on 20 May 2007 near Belfast, Northern Ireland: a simulated plane crash-landing at Belfast International Airport. Staff from five hospitals and three airports participated in the drill, and almost 150 international observers assessed its effectiveness.\n\nDisaster management in the United States has utilized the functional All-Hazards approach for over 20 years, in which managers develop processes (such as communication & warning or sheltering) rather than developing single-hazard or threat focused plans (e.g., a tornado plan). Processes are then mapped to specific hazards or threats, with the manager looking for gaps, overlaps, and conflicts between processes.\n\nGiven these notions, emergency managers must identify, contemplate, and assess possible man-made threats and natural threats that may affect their respective locales. Because of geographical differences throughout the nation, a variety of different threats affect communities among the states. Thus, although similarities may exist, no two emergency plans will be completely identical. Additionally, each locale has different resources and capacities (e.g., budgets, personnel, equipment, etc.) for dealing with emergencies. Each individual community must craft its own unique emergency plan that addresses potential threats that are specific to the locality.\n\nThis creates a plan more resilient to unique events because all common processes are defined, and it encourages planning done by the stakeholders who are closer to the individual processes, such as a traffic management plan written by a public works director. This type of planning can lead to conflict with non-emergency management regulatory bodies, which require the development of hazard/threat specific plans, such as the development of specific H1N1 flu plans and terrorism-specific plans.\n\nIn the United States, all disasters are initially local, with local authorities, with usually a police, fire, or EMS agency, taking charge. Many local municipalities may also have a separate dedicated office of emergency management (OEM), along with personnel and equipment. If the event becomes overwhelming to the local government, state emergency management (the primary government structure of the United States) becomes the controlling emergency management agency. Federal Emergency Management Agency (FEMA), part of the Department of Homeland Security (DHS), is the lead federal agency for emergency management. The United States and its territories are broken down into ten regions for FEMA's emergency management purposes. FEMA supports, but does not override, state authority.\n\nThe Citizen Corps is an organization of volunteer service programs, administered locally and coordinated nationally by DHS, which seek to mitigate disasters and prepare the population for emergency response through public education, training, and outreach. Most disaster response is carried out by volunteer organizations. In the US, the Red Cross is chartered by Congress to coordinate disaster response services. It is typically the lead agency handling shelter and feeding of evacuees. Religious organizations, with their ability to provide volunteers quickly, are usually integral during the response process. The largest being the Salvation Army, with a primary focus on chaplaincy and rebuilding, and Southern Baptists who focus on food preparation and distribution, as well as cleaning up after floods and fires, chaplaincy, mobile shower units, chainsaw crews and more. With over 65,000 trained volunteers, Southern Baptist Disaster Relief is one of the largest disaster relief organizations in the US. Similar services are also provided by Methodist Relief Services, the Lutherans, and Samaritan's Purse. Unaffiliated volunteers show up at most large disasters. To prevent abuse by criminals, and for the safety of the volunteers, procedures have been implemented within most response agencies to manage and effectively use these 'SUVs' (Spontaneous Unaffiliated Volunteers).\n\nThe US Congress established the Center for Excellence in Disaster Management and Humanitarian Assistance (COE) as the principal agency to promote disaster preparedness in the Asia-Pacific region.\n\nThe National Tribal Emergency Management Council (NEMC) is a non-profit educational organization developed for Tribal organizations to share information and best practices, as well as to discuss issues regarding public health and safety, emergency management and homeland security, affecting those under Indian sovereignty. NTMC is organized into Regions, based on the FEMA 10 region system. NTMC was founded by the Northwest Tribal Emergency Management Council (NWTEMC), a consortium of 29 Tribal Nations and Villages in Washington, Idaho, Oregon, and Alaska.\n\nIf a disaster or emergency is declared to be terror related or an \"Incident of National Significance,\" the Secretary of Homeland Security will initiate the National Response Framework (NRF). The NRF allows the integration of federal resources with local, country, state, or tribal entities, with management of those resources to be handled at the lowest possible level, utilizing the National Incident Management System (NIMS).\n\nThe Centers for Disease Control and Prevention offer information for specific types of emergencies, such as disease outbreaks, natural disasters and severe weather, chemical and radiation accidents, etc. The Emergency Preparedness and Response Program of the National Institute for Occupational Safety and Health develops resources to address responder safety and health during responder and recovery operations.\n\nThe Emergency Management Institute (EMI) serves as the national focal point for the development and delivery of emergency management training to enhance the capabilities of state, territorial, local, and tribal government officials; volunteer organizations; FEMA's disaster workforce; other Federal agencies; and the public and private sectors to minimize the impact of disasters and emergencies on the American public. EMI curricula are structured to meet the needs of this diverse audience with an emphasis on separate organizations working together in all-hazards emergencies to save lives and protect property. Particular emphasis is placed on governing doctrine such as the National Response Framework (NRF), National Incident Management System (NIMS), and the National Preparedness Guidelines. EMI is fully accredited by the International Association for Continuing Education and Training (IACET) and the American Council on Education (ACE).\n\nApproximately 5,500 participants attend resident courses each year while 100,000 individuals participate in non-resident programs sponsored by EMI and conducted locally by state emergency management agencies under cooperative agreements with FEMA. Another 150,000 individuals participate in EMI-supported exercises, and approximately 1,000 individuals participate in the Chemical Stockpile Emergency Preparedness Program (CSEPP).\n\nThe \"independent study\" program at EMI consists of free courses offered to United States citizens in Comprehensive Emergency Management techniques. Course IS-1 is entitled \"Emergency Manager: An Orientation to the Position\" and provides background information on FEMA and the role of emergency managers in agency and volunteer organization coordination. The EMI Independent Study (IS) Program, a Web-based distance learning program open to the public, delivers extensive online training with approximately 200 courses. It has trained more than 2.8 million individuals. The EMI IS Web site receives 2.5 to 3 million visitors a day.\n\nIn emergency or disaster management the SMAUG model of identifying and prioritizing risk of hazards associated with natural and technological threats is an effective tool. SMAUG stands for Seriousness, Manageability, Acceptability, Urgency and Growth and are the criteria used for prioritization of hazard risks. The SMAUG model provides an effective means of prioritizing hazard risks based upon the aforementioned criteria in order to address the risks posed by the hazards to the avail of effecting effective mitigation, reduction, response and recovery methods.\n\nSeriousness can be defined as \"The relative impact in terms of people and dollars.\" This includes the potential for lives to be lost and potential for injury as well as the physical, social and as mentioned, economic losses that may be incurred\n\nManageability can be defined as \"the relative ability to mitigate or reduce the hazard (through managing the hazard, or the community or both)\". Hazards presenting a high risk and as such requiring significant amounts of risk reduction initiatives will be rated high.\n\nAcceptability – The degree to which the risk of hazard is acceptable in terms of political, environmental, social and economic impact\n\nUrgency – This is related to the probability of risk of hazard and is defined in terms of how imperative it is to address the hazard \n\nGrowth – This is the potential for the hazard or event to expand or increase in either probability or risk to community or both. Should vulnerability increase, potential for growth may also increase.\n\nAn example of the numerical ratings for each of the four criteria is shown below:\n\nNGOs:\n\n\n"}
{"id": "18109641", "url": "https://en.wikipedia.org/wiki?curid=18109641", "title": "Familial renal amyloidosis", "text": "Familial renal amyloidosis\n\nFamilial renal amyloidosis (or familial visceral amyloidosis, or hereditary amyloid nephropathy) is a form of amyloidosis primarily presenting in the kidney.\n\nIt is associated most commonly with congenital mutations in the fibrinogen alpha chain and classified as a dysfibrinogenemia (see Hereditary Fibrinogen Aα-Chain Amyloidosis). and, less commonly, with congenital mutations in apolipoprotein A1 and lysozyme.\n\nIt is also known as \"Ostertag\" type, after B. Ostertag, who characterized it in 1932 and 1950.\n"}
{"id": "16567745", "url": "https://en.wikipedia.org/wiki?curid=16567745", "title": "Feline vaccination", "text": "Feline vaccination\n\nPrograms supporting regular feline vaccination have contributed both to the health of cats and to public health.\n\nCurrently, there are geographically defined \"core vaccines\" and individually chosen \"non-core vaccine\" recommendations for cats. A number of controversies surrounding adverse reactions to vaccines have resulted in authorities revising their guidelines for feline vaccination.\n\nIn 2006 and 2010, revised guidelines addressed concerns about adverse vaccine reactions by altering the recommended frequency, type, methods, and locations for administration of core and non-core cat vaccines.\n\nMost vaccination protocols recommend a series of vaccines for kittens, with vaccine boosters given at one year of age. Frequency of vaccination thereafter varies depending on the lifestyle of the individual cat, including:\n\nBecause these factors may change over time, many professional organizations recommend routine annual examinations, where a vaccination plan for each individual feline can be decided during a discussion between the veterinarian and cat owner.\n\nIn their 2010 recommendations, WSAVA (World Small Animal Veterinary Association) emphasized the importance of administering \"non-adjuvanted\" vaccines whenever possible, as vaccines that included these immune-stimulating agents were shown to increase adverse vaccine reactions in pets.\n\nWSAVA also prefers serological testing over unnecessary boosters or re-vaccination doses of core vaccines after the initial 12-month booster that follows the kitten series of modified live virus [MLV] vaccines. This is because core vaccines show an excellent correlation between the presence of antibody and protective immunity to a disease, and have a long DOI (Duration of Immunity). Antibody tests can be used to demonstrate the DOI after vaccination with core vaccines, though not for non-core vaccines.\n\nMost vaccines are given by subcutaneous (under the skin) or intramuscular (into the muscle) injection. Respiratory tract disease vaccination may be given intra-nasally (in the nose) in some cases.\n\nMany recent protocols indicate that vaccines should be given in specific areas in order to: ease identification of which vaccine caused an adverse reaction, and ease removal of any vaccine-associated sarcoma.\n\nIn North America, vets adopted the practice of injecting specific limbs as far from the body as possible, for example the rear \"right for rabies\", rear \"left for leukemia\", and others in the right front shoulder - being careful to avoid the midline or interscapular space.\n\nThis set of locations was not widely adopted outside of North America, and WSAVA's international group made new recommendations that vaccines be administered:\n\nCore vaccines are defined as those vaccines which all cats, regardless of circumstances, should receive. Core vaccines protect animals from severe, life-threatening diseases which have global distribution.\n\nThe latest (2006) North American recommendation still includes rabies in the core vaccines. Likewise, the National Association of State Public Health Veterinarians (NASPHV) in the U.S. gives detailed instructions on how to deal with what they describe as a serious public health problem, and includes a useful table, summarizing all the rabies vaccines sold in the U.S.\n\nHowever, the 2010 international WSAVA recommendation generally considers the rabies vaccine a non-core vaccine, except in areas where the disease is endemic or where required by law.\n\nIn many locations, the rabies vaccine is accompanied by a single combined FVRCP vaccine shot which protects against feline viral rhinotracheitis, calicivirus, and panleukopenia.\n\n\nNon-core vaccines are those that are required by only those animals whose geographical location, local environment or lifestyle places them at risk of contracting specific infections.\n\nThe following vaccines are not recommended due either to lack of evidence of effectiveness or to a high chance of adverse reaction.\n\nIn recent years, vaccination has become a controversial topic among veterinarians and pet owners. Studies citing specific adverse reactions and general consequences for long-term health and immunity are both causing professional bodies to recommend reduced frequency in feline vaccination.\n\nIn 2010, the American Veterinary Medical Association (AVMA) and American Association of Feline Practitioners (AAFP) developed vaccination guidelines recommending that FVRCP vaccinations generally be administered every 3 years, after completion of the kitten series of shots (which is needed due to maternal antibody interference).\n\nInternationally, the 2010 The World Small Animal Veterinary Association (WSAVA) vaccination guidelines reduce the number of vaccines which should be considered core for felines, as well as recommending less frequent vaccine administration.\n\nHowever, in an open letter to WSAVA, an Australian pet owner and long-time consumer advocate has created a detailed critique of these guidelines, with numerous scholarly citations, arguing that the 3-year booster or re-vaccination recommendations are either arbitrary or influenced by vaccine manufacturers. She cites the scientific findings of both WSAVA's and other leading researchers, which indicate that, similar to humans, the duration of immunity (DOI) for cats vaccinated early in life with MLV (modified live viruses) is many years, if not the entirety of adulthood, despite the common practice of \"boosting\" vaccines every 1 to 3 years.\n\nIn the executive summary section, the WSAVA guidelines do argue against needless vaccination and in support of \"the development and use of simple in-practice tests for determination of seroconversion (antibody) following vaccination.\" In addition, they also note that \"Vaccines should not be given needlessly. Core vaccines should not be given any more frequently than every three years after the 12 month booster injection following the puppy/kitten series, because the duration of immunity (DOI) is many years and may be up to the lifetime of the pet.\" The open letter critique focuses on the less-nuanced summary of these recommendations in the Tables given for vaccination guidelines, which could imply that re-vaccination should occur every 3 years.\n\nVets and owners should also consider factors that have been shown to increase the risk of adverse vaccine reactions. Examples of such factors include: \n\n\n"}
{"id": "44212999", "url": "https://en.wikipedia.org/wiki?curid=44212999", "title": "Female genital mutilation in Sierra Leone", "text": "Female genital mutilation in Sierra Leone\n\nFemale genital mutilation in Sierra Leone (also known as female genital cutting) is the common practice of removing all or part of the female’s genitalia for cultural and religious initiation purposes, or as a custom to prepare them for marriage. Sierra Leone is one of 28 countries in Africa where female genital mutilation (FGM) is known to be practiced.\n\nFGM is regularly performed in Sierra Leone. The reason that FGM is common in Sierra Leone is because FGM is practiced in a ‘secret society’ called the bondo secret society. The bondo society is an all-female society (also known as the sande) in West Africa. Secret societies are ancient cultural institutions that play a major role in West Africa and have existed for hundreds of years. The purpose of this secret society is to help young women earn the rites of passage into adulthood. In order, to receive these rites of passage, a girl must undergo their cultural rituals including FGM. \n\nThe initiation into the society occurs in the bondo bush which is a private enclosure constructed near their village. Time spent in the bondo bush for initiation into womanhood used to take about a month, but as the generations have gone by, the time has significantly reduced.\nOnce a woman becomes a member of the bondo, she is able to go to the bondo without her husband’s permission. The bondo becomes the only place women are allowed to go to without permission from their husband. Thus, women who are a part of the bondo have an increased freedom of movement.\n\nIn regard to society, members of the bondo are regarded as having a higher standing than other women. The cost of FGM and initiation into the bondo society is quite expensive, and so parents are proud when their daughters are initiated because it shows they are financially stable and able to afford this. Initiation can cost anywhere from 200,000 to 600,000 Leones, which converts to 62–185 dollars. Soweis, the leader of the bondo, tend to raise the price of the initiation into the society if the woman is not a virgin. FGM is so expected in society that when a husband discovers upon marriage that his wife has not undergone FGM, it is common for him to pay for her to undergo the initiation.\n\nWoman’s initiation is synonymous with women’s power in Sierra Leone, and the act of excision is a reminder that women are from which all human creation is derived. Bondo elders believed that excision improves sexual satisfaction as it removes focus from the clitoris onto the hidden g-spot inside the vaginal canal which they believe has more satisfying and intense orgasms. It is also thought to enhance the appearance of a women’s genitalia and make it easier to penetrate. \n\nIn Sierra Leone, FGM usually consists of removing the clitoris as a major part in preparing the young women for marriage and motherhood through this initiation ceremony. The procedure is usually performed by an elderly woman of the village who has been especially designated for this task, by a village barber or by a traditional birth attendant. FGM can be broken down into three types. Type I removes the tissue protecting the head of the clitoris. Type II removes the tissue protecting the head of the clitoris, the clitoris itself, and part of or all of the labia minora. Type III, the most extreme case, involves removing all or part of the external genitalia and stitching the vaginal opening closed.\n\nFGM is mainly performed in Africa as well as a few countries in Asia and the Middle East. The worldwide estimation of how many women have undergone FGM is anywhere from 130 to 140 million. In the MICS conducted by UNICEF, the prevalence of FGM in Sierra Leone, Gambia, Burkina Faso and Mauritania was 94%, 79%, 74%, and 72% respectively. While in other countries in western Africa such as Ghana, Niger and Togo, the prevalence of FGM was less than 6%. \n\nRoughly 3 million girls in Africa undergo FGM every single year and Sierra Leone is one of the only countries in western Africa where the rate of prevalence is over 90%. Sierra Leone is the only country in southern western Africa with such a high rate of FGM. There is a decline in prevalence of FGM in Sierra Leone in younger age groups.\n\nThere are no health benefits associated with FGM. The severity of the medical risks varies according to the extent of the cutting. Type III is very common in Sierra Leone and has the greatest health consequences associated with it. Short-term effects of FGM include excessive bleeding, local infections, and incomplete healing. Long-term effects include scarring, genital ulcers, dermoid inclusion cysts, lower abdominal pain, and infertility. But the worst effect is death at delivery, the rate of which is excessively high in Sierra Leone\n\nPeople in Sierra Leone believe that abandoning FGM would be an abandonment of cultural tradition. They believe that FGM is similar to male circumcision which is widely acceptable across the globe. FGM supporters in Sierra Leone believe that females who do not receive the circumcision will have trouble conceiving, suffer psychological trauma, have bad luck, or be considered unworthy of marriage. Women who are pro-FGM state that it does not oppress female sexuality and instead it celebrates it through these ritual practices.\n\nThey also state that the supposed consequences of excision (which include menstrual problems, painful sex, infections, et cetera) were not specific to women who underwent FGM. The rate for infertility is ten percent for both groups. They also argue that the reason for increase of still births in circumcised women is not because of the FGM they underwent but because they delay receiving prenatal care and visiting hospitals because they fear being stigmatized by the medical staff because of their circumcision. \n\nFGM supporters believe that FGM prevents prostitution by decreasing a woman’s sexual desire, and is more hygienic. According to a five-year research done by Hanny Lightfoot-Klein, an anti-FGM activist, 94% of circumcised women reported being satisfied by their sex lives and had sex between three and four times a week.\n\nAnti-FGM advocates state that more than 80% of women who experience it reported suffering a minimum of one health complication. People against FGM widely refer to it as mutilation which is a controversial term that is rejected by members of communities who practice it. The World Health Organization has adopted this term and it is widely used to describe the injury made to the women’s genitalia even though the intent was not to mutilate.\n\nThe Amazonian Initiative Movement is one of several nongovernmental organizations in West Africa against FGM. The aim of the group is to educate women who perform FGM and set them up with another job besides performing this procedure. The World Health Organization has consistently condemned this traditional practice as “willful damage to healthy organs for non-therapeutic reasons” and they have stated that the practice of female genital mutilation can result in infertility, pregnancy and childbirth complications, and psychological problems through inability to experience sexual pleasure. Supporters of the eradication of all forms of nonconsented genital cutting believe that it violates the human right to bodily integrity. However, Sierra Leone does not have an explicit law against the practice of FGM.\n\n"}
{"id": "21955305", "url": "https://en.wikipedia.org/wiki?curid=21955305", "title": "Food history", "text": "Food history\n\n\"Food history\" is an interdisciplinary field that examines the history of food and nutrition, and the cultural, economic, environmental, and sociological impacts of food. Food history is considered distinct from the more traditional field of culinary history, which focuses on the origin and recreation of specific recipes.\n\nThe first journal in the field, \"Petits Propos Culinaires\" was launched in 1979 and the first conference on the subject was the 1981 Oxford Food Symposium.\n\nEnglish cooking has been influenced by foreign ingredients and cooking styles since the Middle Ages. Traditional meals have ancient origins, such as bread and cheese, roasted and stewed meats, meat and game pies, boiled vegetables and broths, and freshwater and saltwater fish. The 14th-century English cookbook, \"The Forme of Cury\" contains recipes for these, and dates from the royal court of Richard II.\n\nIn the European Middle Ages, breakfast was not usually considered a necessary and important meal, and was practically nonexistent during the earlier medieval period. Monarchs and their entourages would spend lots of time around a table for meals. Only two formal meals were eaten per day—one at mid-day and one in the evening. The exact times varied by period and region, but this two-meal system remained consistent throughout the Middle Ages. \nBreakfast in some places was solely granted to children, the elderly, the sick, and to working men. Anyone else did not speak of or partake in eating in the morning. Eating breakfast meant that one was poor, was a low-status farmer or laborer who truly needed the energy to sustain his morning’s labor, or was too weak to make it to the large, midday dinner. Because medieval people saw gluttony as a sin and a sign of weakness, men were often ashamed of eating breakfast.\n\nNoble travelers were an exception, as they were also permitted to eat breakfast while they were away from home. For instance, in March 1255 about 1512 gallons of wine were delivered to the English King Henry III at the abbey church at St. Albans for his breakfast throughout his trip. If a king were on religious pilgrimage, the ban on breakfast was completely lifted and enough supplies were compensated for the erratic quality of meals at the local cook shops during the trip.\n\nIn the 13th century, breakfast when eaten sometimes consisted of a piece of rye bread and a bit of cheese. Morning meals would not include any meat, and would likely include ¼ gallon (1.1 L; 0.30 US gal) of low alcohol-content beers. Uncertain quantities of bread and ale could have been consumed in between meals.\n\nBy the 15th century breakfast often included meat. By this time, noble men were seen to indulge in breakfast, making it more of a common practice, and by the early 16th century, recorded expenses for breakfast became customary. The 16th-century introduction of caffeinated beverages into the European diet was part of the consideration to allow breakfast. It was believed that coffee and tea aid the body in “evacuation of superfluities,” and was consumed in the morning.\n\nThe potato was first domesticated in the region of modern-day southern Peru and extreme northwestern Bolivia It has since spread around the world and become a staple crop in many countries.\n\nAccording to conservative estimates, the introduction of the potato was responsible for a quarter of the growth in Old World population and urbanization between 1700 and 1900. Following the Spanish conquest of the Inca Empire, the Spanish introduced the potato to Europe in the second half of the 16th century, part of the Columbian exchange. The staple was subsequently conveyed by European mariners to territories and ports throughout the world. The potato was slow to be adopted by distrustful European farmers, but soon enough it became an important food staple and field crop that played a major role in the European 19th century population boom. However, lack of genetic diversity, due to the very limited number of varieties initially introduced, left the crop vulnerable to disease. In 1845, a plant disease known as late blight, caused by the fungus-like oomycete \"Phytophthora infestans\", spread rapidly through the poorer communities of western Ireland as well as parts of the Scottish Highlands, resulting in the crop failures that led to the Great Irish Famine.\n\nRice probably originated in Korea or Australia and was widely grown in Asia 3000 years ago. Muslims brought rice to Sicily with cultivation starting in the 9th century. After the 15th century, rice spread throughout Italy and then France, later propagating to all the continents during the age of European exploration. As a cereal grain, today it is the most widely consumed staple food for Asia and elsewhere. It is the #3 agricultural commodity (rice, 741.5 million tonnes in 2014), after sugarcane (1.9 billion tonnes) and maize (\"corn\" in the United States, 1.0 billion tonnes).\n\nToday, the majority of all rice produced comes from China, India, Indonesia, Bangladesh, Vietnam, Thailand, Myanmar, Pakistan, Philippines, Korea and Japan. Asia accounts for 87% of the world's total rice production.\n\nGrain and livestock have long been the center of agriculture in France and England. After 1700, innovative farmers experimented with new techniques to increase yield, and looked into entirely new products such as hops, oilseed rape, artificial grasses, vegetables, fruit, dairy foods, commercial poultry, rabbits, and freshwater fish.\n\nSugar began as an upper-class luxury product, but by 1700 Caribbean sugar plantations worked by African slaves expanded production and lowered the price. By 1800 sugar was a staple of working-class diets. For them it symbolized increasing economic freedom and status.\n\nLaborers in Western Europe in the 18th century ate bread and gruel, often in a soup with greens and lentils, a little bacon, and occasionally potato or a bit of cheese. They washed it down with beer (Water was too contaminated), and a sip of milk. Three fourths of the food was derived from plants; fats came from plant oils. Meat was much more attractive, but very expensive. By 1870 the West European diet at about 16 kilos per person per year of meat, rising to 50 kilos by 1914, and 77 kilos in 2010. Milk, and cheese, was seldom in the diet-- even in the early 20th century, it was still uncommon in Mediterranean diets.\n\nIn the immigrant neighborhoods of fast-growing American industrial cities, housewives purchased ready-made food through street peddlers, hucksters, push carts, and small shops operated from private homes. This opened the way for the rapid entry of entirely new items such as pizza, spaghetti with meatballs, bagels, hoagies, pretzels, and pierogies into American eating habits, and firmly established fast food in the American culinary experience.\n\nThe first half of the 20th century was characterized by two world wars with very high degrees of hunger and strict rationing, with the starvation of the civilian populations used as a powerful new weapon. In Germany during World War I the rationing system in urban areas virtually collapsed, with people eating animal fodder to survive the \"Turnip winter.\" In Allied countries, meat was diverted first to the soldiers, then to urgent civilian needs in Italy, Britain, France and Greece. Meat production was stretched to the limit in the United States, Australia, New Zealand, Canada and Argentina, with Oceanic shipping closely controlled by the British. \n\nIn the first years of peace after the war ended in 1918, most of eastern and central Europe suffered severe food shortages. Outside help was on the way. The American Relief Administration (ARA) was set up under the American wartime food czar Herbert Hoover, and was charged with providing emergency food rations across Central and Eastern Europe. The ARA fed millions, including the inhabitants of Germany and the Soviet Union. After U.S. government funding for the ARA expired in the summer of 1919, the ARA became a private organization, raising millions of dollars from private donors. Under the auspices of the ARA, the European Children's Fund fed millions of starving children. \n\nThe 1920s saw the introduction of new foodstuffs, especially fruit, transported from around the globe. After the World War many new food products became available to the typical household, with branded foods advertised for their convenience. Now instead of an experienced cook spending hours on difficult custards and puddings the housewife could purchase instant foods in jars, or powders that could be quickly mixed. Upscale households now had ice boxes or electric refrigerators, which made for better storage and the convenience of buying in larger quantities.\n\nIn World War II, Nazi Germany made sure that its population was very well fed by seizing food supplies from occupied countries, and deliberately cutting off food to Jews, Poles, Russians and the Dutch.\n\nAs part of the Marshall Plan 1948-1950, the United States provided taking logical expertise and financing for high productivity large-scale agribusiness operations in postwar Europe. Poultry was a favorite choice, with the rapid expansion in production, a sharp fall in prices, and widespread acceptance of the many ways to serve chicken. \n\nThe Green Revolution was a technological breakthrough in plant productivity that increased agricultural production worldwide, particularly in the developing world. Research began in the 1930s and dramatic improvements in output became important in the late 1960s, and continue into the 21st century. The initiatives resulted in the adoption of new technologies, including:\n\n\n\n\n\nJournals\nOther languages\n\n"}
{"id": "2684023", "url": "https://en.wikipedia.org/wiki?curid=2684023", "title": "Geriatric dentistry", "text": "Geriatric dentistry\n\nGeriatric dentistry is the delivery of dental care to older adults involving diagnosis, prevention, management and treatment of problems associated with age related diseases. The mouth is referred to as a mirror of overall health, reinforcing that oral health is an integral part of general health. In the elderly population poor oral health has been considered a risk factor for general health problems. Older adults are more susceptible to oral conditions or diseases due to an increase in chronic conditions and physical/mental disabilities. Thus, the elderly form a distinct group in terms of provision of care.\n\nThe world’s population is currently ageing with the number and proportion of elderly people growing substantially. Between the years of 2000-2005 to 2010-2015 life expectancy at birth rose from 67.2 to 70.8 years. By 2045-2050 it is projected to continue increase to 77 years. This increasing longevity can be majorly attributed to advances in modern medicine and medical technology. As a result, the population of people aged 60 and over is growing faster than any other younger age group and it is expected to more than double by 2050 globally. This will have a profound effect on society’s ability to support the needs of this growing crowd including their dental needs.\n\nOlder people have become a major focus for the oral health industry. Due to the increasing number and proportion of elderly people, age related dental problems have become more common. This is largely due to success in dental treatment and prevention of gum disease and caries at a young age, thereby leading to people retaining more of their own natural teeth. As they get older, the retained teeth are at risk of developing and accumulating oral diseases that are more extensive and severe.\n\nIn Australia geriatric dentistry is falls under the ‘Special needs dentistry’ specialty which is recognised by the Dental Board of Australia. This is because often age related problems and medication can make oral health disease and conditions much more serious and complicated to treat. As a result, they require specialized and individualized treatment and considerations. It is however, important to recognize that, contrary to popular belief, ageing is not synonymous with disease and should not be considered pathologic, and rather a natural and inevitable physiological process.\n\nIn the United Kingdom the General Dental Council has as total of thirteen specialties, however, geriatrics is not one of them. Special care dentistry is however recognised as an area of specialty and focuses on the prevention and management of oral health conditions for people who have physical, sensory, intellectual, mental, emotional or social impairment or disability. Mostly for adults and adolescents and therefore older people.\n\nIn America, geriatrics is not currently formally recognised by the American Dental Association as an area of specialty. The Harvard Dental School of Medicine however, does offer a further two-year study for a certificate in geriatric dentistry. This program trains dentist in the specialised care for the population group of older people who often experience disparity.\n\nThe Royal College of Dentists of Canada does not recognise geriatrics as one of its nine specialties.\n\nThe elderly can be classified into many criteria. Classifying them allows for a more detailed and accurate analysis of the diversity within this age group and makes diagnosis and treatment planning more personalised. The following is a common classification of the eldelry according to age group.\n\nThe dental classification of ageing however is more useful if it is based on the patient’s ability to seek dental care independently.\n\n\nThe geriatric population are an ever growing section of the community with rapidly changing dental needs. In 2020 it is predicted that more than 25% of the population in developed countries will be over the age of 65. Due to improvements in oral health over the past 60 years, a decrease in the rate of edentulism is evident and therefore an increase in the number of natural teeth present is present \n\nIn 1979, 60% of Australians over the age of 65 had no natural teeth. In 1989, 44% had no teeth and it is expected by 2019, this figure will drop to 20%. This prediction was exceeded in 2013, with 19% of those over the age of 65 had no natural teeth.\n\nAlthough there is a decrease in the rate of edentulism, geriatric patients typically have high levels of plaque, calculus and debris, as they are functionally dependent on others or have lost the capacity to complete tasks such as toothbrushing thoroughly. Consequently, this results in an increased caries prevalence. Dental caries is a process in which enamel is dissolved by acid producing bacteria. In 2004-2006, the average DMFT (decayed, missing and filled teeth) for adults in Australia over the age of 65 was found to be 23.7%. An individual’s caries risk is influenced by their sugar intake, frequency of eating, oral hygiene levels, saliva flow and function and recession. Gingival recession is a significant finding in older adults because the exposed root surface is more susceptible to root caries and therefore increases the risk for the patient. In 2015, 95.2% of Australians over the age of 75 had at least one site with gingival recession. Additionally, periodontal disease prevalence was also great as 26.0% of the geriatric population was diagnosed with active periodontal disease.\n\nA number of physiological changes happen to the geriatric population with age. The gastrointestinal, renal, cardiovascular, respiratory, and immune systems often decrease in efficiency, and this impacts upon the entire body, including oral health.\n\nAlong with physiological changes, physical ones involve reduced bone and muscle mass Mobility can be decreased due to osteoarthritis, and a variety of audio and visual changes such as cataracts, macular degeneration, and hearing loss can make communication, patient education and oral health care increasingly difficult to maintain.\n\nThe majority of elderly people have at least one chronic condition, with many having multiple. The most common of these include hypertension, arthritis, heart disease, cancers and diabetes. Other prevalent conditions include dementia, depression, hearing loss, cataracts, back and neck pain, and chronic obstructive pulmonary disease.\n\nGeriatric patients may demonstrate a spectrum of cognitive acuity, and dementia is categorised by a progressive deterioration in cognition that eventually affects an individual’s capability to function independently. More often than not, this is diagnosed in the elderly population. Unfortunately this disease impacts upon the ability to manage their medications, systemic conditions, and oral hygiene. As the severity of the impairment increases, the elderly become much more susceptible to develop dental caries, periodontal disease and oral infection, primarily because of the reduced capability to maintain good oral health at home.\n\nThe elderly usually develop a decrease in appetite, leading to a lower intake of vitamins and minerals. However, many nutrients are recommended at the same amounts as younger people. Another reason why inadequate nutrition levels are more prominent with elders is if their dental status is poor, with missing teeth or ill fitting dentures, it can negatively affect their taste and ability to chew on food. Even well-fitted dentures are less efficient than natural teeth in terms of chewing, so changes in diet to softer foods often happen. Such foods often contain more fermentable carbohydrates, which raise individuals’ risk to developing dental caries.\n\nThe most common oral conditions in geriatric patients are tooth loss, dental caries, periodontitis, dry mouth and oral cancer. Each can affect the quality of life.\n\nPolypharmacy is common in geriatric patients, which can cause a multitude of symptoms. Xerostomia is amongst the most common, commonly linked to antidepressants, psycholeptics, inhaled medications such as Salbutamol and the slight degeneration of salivary gland function with aging. Chronic dry mouth is prevalent in a high proportion of the elderly population, affecting roughly one fifth of the group. There has been a link between dry mouth and comorbid diseases including diabetes, Alzheimer’s or Parkinson’s disease Additionally, xerostomia can arise from general dehydration. A dry mouth can be associated with caries, cracked lips, fissured tongue and oral mucositis. It can impact heavily on the patient’s quality of life, affecting taste, speaking, enjoyment and ingestion of food, and fitting dentures.\n\nChanges to the oral mucous membrane including the epithelium and connective tissue, result in decreased immunity against pathogens. There is a loss of elasticity and stippling, with a general thinning over time. Diseases such as oral thrush can become more prevalent, and the healing rate lowers. Geriatric patients are more likely to develop oral cancers too, which often start on the side of the tongue, floor of mouth or lips.\n\nWith continued chewing, talking, and general use, the tooth eventually wears down with attrition and dental erosion most commonly seen. The outermost translucent layer, enamel, does not regenerate, so as it thins down the underlying yellowish layer, dentine, can show through or even become exposed. Aesthetically, teeth may look more yellow than white, and can become stained more easily. Dentine continues to be produced, resulting in the formation of secondary dentine. Gradually however, the tubules obturate and lead to dentinal sclerosis. The innermost layer containing the nerves, pulp, develops more fibres and less cells leading to shrinkage. A reduced blood supply means that an elderly patient’s pulp does not have the same capacity to heal itself compared with younger patients. Calcification of the pulp with the root canals narrowing increases in frequency with the geriatric population too. This can often lead to decreased sensitivity to stimuli, e.g. cold or sweet foods. Cementum on the tooth roots is continually produced; however with age the rate this happens slows down, leaving the geriatric patient at a higher risk for developing root caries.\n\nThe instance of periodontal disease increases with age, however it is not due to the nature of the condition, but rather indicates the patient’s cumulative oral history. Due to the aging process and certain health conditions of the geriatric population; they can be more susceptible to pathogenic anaerobic bacteria infecting the periodontium and initiating inflammation. Age increases the risk of periodontal disease but does not cause it. Most of the geriatric community have moderate levels of attachment loss, with less having advanced stages of the disease. Active periodontitis is a risk factor for certain systemic diseases as well, including cardiovascular disease, stroke and aspiration pneumonia.\n\nElderly people in residential care facilities are considered to have some of the poorest oral health in Australia, and are some of our most vulnerable and disadvantaged population groups.\n\nElderly people who are functionally dependant and residing in residential care facilities, are particularly vulnerable to oral health issues such as periodontal disease, dental caries, particularly root caries and other oral health issues. \nTheir dependence on staff to assist them with daily oral hygiene care often results in minimal hygiene being provided. Oral health requirements are often unfortunately overshadowed by more important things such as feeding, toileting and bathing. Other barriers that care staff in residential aged care facilities experience to providing oral care included lack of oral health policies, and ongoing education and training.\n\nHistorically there has been a reluctance with dental professionals to attend residential aged-care facilities. When combined with the difficulty experienced for residents to access dental care themselves, their options have been limited. Therefore, the need for regular onsite professional dental care is urgently required, to address early detection, prevention and treatment of oral health problems.\n\nMaintaining the oral health of residents in residential care facilities requires a multidisciplinary approach to address these issues. The incorporation of the oral health therapist into the residential aged care facility, as part of a multidisciplinary approach with nursing staff, is suggested to demonstrate an effective and efficient use of health resources. The oral health therapist can provide individualized oral hygiene care plans, routine dental care, and help provide education, preventative programmes and ongoing support and motivation to nursing staff.\n\nHaving the oral health therapist implement and manage an oral health training programme that is then executed by a registered nurse, who is the oral health leader, and who has received oral health education by the oral health therapist. They are then able to carry out and enforce the programme whilst the oral health therapist is not there. This would encourage better integration, education and motivation of nurses and care staff into oral hygiene care delivery. Increasing the ability and confidence of staff when performing oral health care for residents and being able to identify oral health care problems when they arise.\nThe emphasis needs to be on good end of life oral care, through prevention and maintenance rather than advanced dental treatments. This is where the oral health therapist could fill that niche in residential care facilities.\n\nAn ageing population involving an increased retention of teeth, often with complex restorations, is expected to increase the demand for dental care in older people. As people age they attend dental services less frequently, and face a number of barriers to accessing dental care. This involves clinics not being easily accessible for frail, disabled or functionally dependant elderly who have limited mobility, and are wheelchair dependant and/or cognitively impaired. Access is often even more difficult for elderly residing in residential aged care facilities.\n\nAs people age and become frail, disabled or functionally dependant, their oral health is put at great risk, due to a variety of health problems or disabilities that impact on the ability for them to provide their own oral cares. This may be related to issues that are associate with:\n\n\nEdentulism is the result of a mostly preventable oral disease process that is a worldwide public health concern. The loss of the permanent dentition is a multi-factorial process resulting from the impact of dental caries, periodontal disease and social factors. People who have lost teeth are referred to as (either partially or completely) edentulous (edentate), however those who have not lost teeth are referred to as dentate.\n\n\n\n\nDentures are prosthetic appliances fabricated to fill the gaps of missing teeth. Conventional style dentures are removable appliances and are designed to be either a complete denture or a partial denture anchoring to adjacent teeth. There are many denture designs, some which rely on chemical bonding or clasping onto teeth or attached via dental implants known as fixed prosthodontics.\n\n\n\nPeople are now living longer and retaining their teeth for longer due to the preventive focused approach to dentistry. Although the rates of edentulism are rapidly declining, this is resulting in the number of natural teeth retained in the dentition. The impact of this is especially apparent in the residential care setting, as Personal Care Assistant staff are often time poor as a high resident to PCA ratio, oral care is often not adequately attended too or not at all. Residential care facilities will continue to encounter residents retaining their own natural teeth as the population is growing and living for longer periods so an oral health intervention will be required to combat this area of care that is severely lacking in many facilities. Utilising Oral Health Therapists in this sector would provide some assistance in closing the gap.\n\n\n"}
{"id": "6261834", "url": "https://en.wikipedia.org/wiki?curid=6261834", "title": "Half-value layer", "text": "Half-value layer\n\nA material's half-value layer (HVL), or half-value thickness, is the thickness of the material at which the intensity of radiation entering it is reduced by one half. HVL can also be expressed in terms of air kerma rate (AKR), rather than intensity: the half-value layer is the thickness of specified material that, \"attenuates the beam of radiation to an extent such that the AKR is reduced to one-half of its original value. In this definition the contribution of all scattered radiation, other than any [...] present initially in the beam concerned, is deemed to be excluded.\" Rather than AKR, measurements of air kerma, exposure, or exposure rate can be used to determine half value layer, as long as it is given in the description.\n\nHalf-value layer refers to the first half-value layer, where subsequent (i.e. second) half-value layers refer to the amount of specified material that will reduce the air kerma rate by one-half after material has been inserted into the beam that is equal to the sum of all previous half-value layers.\n\nQuarter-value layer is the amount of specified material that reduces the air kerma rate (or exposure rate, exposure, air kerma, etc...) to one fourth of the value obtained without any test filters. The quarter-value layer is equal to the sum of the first and second half-value layers.\n\nThe homogeneity factor (HF) describes the polychromatic nature of the beam and is given by:\n\nformula_1\n\nThe HF for a narrow beam will always be less than or equal to one (it is only equal to one in the case of a monoenergetic beam). In case of a narrow polychromatic beam, the HF is less than one because of beam hardening.\n\nHVL is related to Mean free path, however the mean free path is the average distance a unit of radiation can travel in the material before being absorbed, whereas HVL is the average amount of material needed to absorb 50% of all radiation (i.e., to reduce the intensity of the incident radiation by half).\n\nIn the case of sound waves, HVL is the distance that it takes for the intensity of a sound wave to be reduced to one-half of its original value. The HVL of sound waves is determined by both the medium through which it travels, and the frequency of the beam. A \"thin\" half-value layer (or a quick drop of -3 dB) results from a high frequency sound wave and a medium with a high rate of attenuation, such as bone. HVL is measured in units of length.\n\nA similar concept is the tenth-value layer or TVL. The TVL is the average amount of material needed to absorb 90% of all radiation, i.e., to reduce it to a tenth of the original intensity. 1 TVL is greater than or equal to log(10) or approximately 3.32 HVLs, with equality achieved for a monoenergetic beam.\n\nHere are example approximate half-value layers for a variety of materials against a source of gamma rays (Iridium-192):\n\n"}
{"id": "12036964", "url": "https://en.wikipedia.org/wiki?curid=12036964", "title": "Health and Safety Commission", "text": "Health and Safety Commission\n\nThe Health and Safety Commission (HSC) was a United Kingdom non-departmental public body. The HSC was created by the Health and Safety at Work etc. Act 1974 (HSWA). It was formally established on 31 July 1974. The Commission consisted of a chairman and between six and nine other people, appointed by the Secretary of State for Employment, latterly the Secretary of State for Work and Pensions, after consultation. The first meeting of the HSC took place on 1 October 1974. Its responsibilities covered England and Wales and Scotland. In Northern Ireland, its functions were carried out by the Health and Safety Executive for Northern Ireland. It merged with the Health and Safety Executive on 1 April 2008.\n\nThe Commission's duties were to:\n\nThe Commission was further obliged keep the Secretary of State informed of its plans and ensure alignment with the policies of the Secretary of State, giving effect to any directions given to it. The Secretary of State could give directions to the Commission.\n\nOn 1 April 2006, the Commission ceased to have responsibility for railway safety.\n\nThe Health and Safety Commission had five chair persons in its 34-year existence \n\nCommission members included:\n\nIn practice, the Commission delegated its responsibilities to the Health and Safety Executive (HSE).\n\nIn August 2007, the Department for Work and Pensions started consultation on merger of the HSC and HSE to a largely positive response. On 18 March 2008, government minister Lord McKenzie of Luton announced that the merger would be completed during spring 2008. The merger was completed on 1 April 2008.\n\n"}
{"id": "3187173", "url": "https://en.wikipedia.org/wiki?curid=3187173", "title": "Health effects of wine", "text": "Health effects of wine\n\nThe health effects of wine are mainly determined by its active ingredient alcohol. Some studies found that drinking small quantities of alcohol (up to one standard drink per day for women and one to two drinks per day for men) is associated with a decreased risk of heart disease, stroke, diabetes mellitus, metabolic syndrome and early death. However, other studies found no such effect. Drinking more than the standard drink amount increases the risk of heart disease, high blood pressure, atrial fibrillation, stroke and cancer. Mixed results are also observed in light drinking and cancer mortality.\n\nRisk is greater in younger people due to binge drinking which may result in violence or accidents. About 88,000 deaths in the US are estimated to be due to alcohol each year. Alcoholism reduces a person's life expectancy by around ten years and excessive alcohol use is the third leading cause of early death in the United States. According to systematic reviews and medical associations, people who are nondrinkers should not start drinking wine.\nWine has a long history of use as an early form of medication, being recommended variously as a safe alternative to drinking water, an antiseptic for treating wounds, a digestive aid, and as a cure for a wide range of ailments including lethargy, diarrhea and pain from child birth. Ancient Egyptian papyri and Sumerian tablets dating back to 2200 BC detail the medicinal role of wine, making it the world's oldest documented human-made medicine. Wine continued to play a major role in medicine until the late 19th and early 20th century, when changing opinions and medical research on alcohol and alcoholism cast doubt on its role as part of a healthy lifestyle.\n\nNearly all research into the positive medical benefits of wine consumption makes a distinction between moderate consumption and heavy or binge drinking. Moderate levels of consumption vary by the individual according to age, gender, genetics, weight and body stature, as well as situational conditions, such as food consumption or use of drugs. In general, women absorb alcohol more quickly than men due to their lower body water content, so their moderate levels of consumption may be lower than those for a male of equal age. Some experts define \"moderate consumption\" as less than one glass of wine per day for women and two glasses per day for men.\n\nThe view of consuming wine in moderation has a history recorded as early as the Greek poet Eubulus (360 BC) who believed that three bowls (kylix) were the ideal amount of wine to consume. The number of three bowls for moderation is a common theme throughout Greek writing; today the standard 750 ml wine bottle contains roughly the volume of three kylix cups (250 ml or 8 fl oz each). However, the kylix cups would have contained a diluted wine, at a 1:2 or 1:3 dilution with water. In his circa 375 BC play \"Semele or Dionysus\", Eubulus has Dionysus say:\n\nHeavy alcohol consumption has been shown to have a damaging effect on the cellular processes that create bone tissue, and long-term alcoholic consumption at high levels increases the frequency of fractures. Epidemiological studies (studies done by interviewing subjects and studying their health records) have found a positive association between moderate alcohol consumption and increased bone mineral density (BMD). Most of this research has been conducted with postmenopausal women, but one study in men concluded that moderate consumption of alcohol may also be beneficial to BMD in men.\n\nThe International Agency for Research on Cancer of the World Health Organization has classified alcohol as a Group 1 carcinogen.\n\nStudies have shown that heavy drinkers put themselves at greater risk for heart disease and developing potentially fatal cardiac arrhythmias. Excessive alcohol consumption can cause higher blood pressure, increase cholesterol levels and weakened heart muscles. Studies have shown that moderate wine drinking can improve the balance of low-density lipoprotein (LDL or \"bad\" cholesterol) to high-density lipoprotein (HDL or \"good\" cholesterol), which has been theorized as to clean up or remove LDL from blocking arteries. The main cause of heart attacks and the pain of angina is the lack of oxygen caused by blood clots and atheromatous plaque build up in the arteries. The alcohol in wine has anticoagulant properties that limits blood clotting by making the platelets in the blood less prone to stick together and reducing the levels of fibrin protein that binds them together.\n\nProfessional cardiology associations recommend that people who are currently nondrinkers should not start drinking alcohol.\n\nOne of the short-term effects of alcohol is impaired mental function, which can cause behavioral changes and memory impairment. Long-term effects of heavy drinking can inhibit new brain cell development and increase the risk for developing major depressive disorders. Studies have linked moderate alcohol consumption to lower risk of developing Alzheimer's and dementia though wine's role in this link is not yet fully understood. A 2009 study by Wake Forest University School of Medicine suggest that moderate alcohol consumption may help healthy adults ward off the risks of developing dementia but can accelerate declining memory for those already suffering from cognitive impairment. The reason for the potential positive benefit of moderate consumption is not yet identified and may even be unrelated to the alcohol but rather other shared lifestyle factors of moderate drinkers (such as exercise or diets). If it is the moderate consumption, researchers theorize that it may be alcohol's role in promoting the production of \"good cholesterol\" which prevents blood platelets from sticking together. Another potential role of alcohol in the body may be in stimulating the release of the chemical acetylcholine which influences brain function and memory.\n\nResearch has shown that moderate levels of alcohol consumed with meals does not have a substantial impact on blood sugar levels. A 2005 study presented to the American Diabetes Association suggest that moderate consumption may lower the risk of developing Type 2 diabetes.\n\nThe anti-bacterial nature of alcohol has long been associated with soothing stomach irritations and ailments like traveler's diarrhea where it was a preferred treatment to the less palatable bismuth treatments. The risk of infection from the bacterium \"Helicobacter pylori\", strongly associated with causing gastritis and peptic ulcers as well as being closely linked to stomach cancer, appears to lessen with moderate alcohol consumption. A German study conducted in the late 1990s showed that non-drinkers had slightly higher infection rates of \"Helicobacter pylori\" than moderate wine and beer drinkers.\n\nWine's positive effects on the metabolism of cholesterol has been suggested as a link to lower occurrences of gallstones among moderate drinkers since cholesterol is a major component of gallstones.\n\nThere are several potential causes of so-called \"red wine headaches\", including histamines/tyramines and the breakdown of some phenolic compounds in wine that carry the chemical messenger for serotonin. One culprit that is regularly dismissed by allergists as an unlikely cause of red wine headaches is sulfites which are used as a preservative in wine. Wine, like other alcoholic beverages, is a diuretic which promotes dehydration that can lead to headaches (such as the case often experienced with hangovers). In 2006, researchers from the University of California, Davis announced finding from genetic mapping that amino acids in wine that have been slightly modified by the fermentation process may be the cause of wine-related headaches. The research suggest changes in fermentation techniques may help alleviate the risk for wine drinkers sensitive to these amino acids.\n\nCompared to many beers and non-diet sodas, a serving of wine has a moderate amount of calories. A standard 5 fl oz (150 ml) serving of red wine (based on an average alcohol content of 13%) contains approximately 106 calories and 2.51 g of carbohydrates. A similar serving of white wine contains approximately 100 calories and 1.18 g of carbohydrates.\n\nDanish epidemiological studies suggest that a number of psychological health benefits are associated with drinking wine. In a study testing this idea, Mortensen et al. (2001) measured socioeconomic status, education, IQ, personality, psychiatric symptoms, and health related behaviors, which included alcohol consumption. The analysis was then broken down into groups of those who drank beer, those who drank wine, and then those who did and did not drink at all. The results showed that for both men and women drinking wine was related to higher parental social status, parental education and the social status of the subjects. When the subjects were given an IQ test, wine drinkers consistently scored higher IQs than their counterpart beer drinkers. The average difference of IQ between wine and beer drinkers was 18 points. In regards to psychological functioning, personality, and other health-related behaviors, the study found wine drinkers to operate at optimal levels while beer drinkers performed below optimal levels. As these social and psychological factors also correlate with health outcomes, they represent a plausible explanation for at least some of the apparent health benefits of wine.\n\nIn 2008, researchers from Kingston University in London discovered red wine to contain high levels of toxic metals relative to other beverages in the sample. Although the metal ions, which included chromium, copper, iron, manganese, nickel, vanadium and zinc, were also present in other plant-based beverages, the sample wine tested significantly higher for all metal ions, especially vanadium. Risk assessment was calculated using \"target hazard quotients\" (THQ), a method of quantifying health concerns associated with lifetime exposure to chemical pollutants. Developed by the Environmental Protection Agency in the US and used mainly to examine seafood, a THQ of less than 1 represents no concern while, for example, mercury levels in fish calculated to have THQs of between 1 and 5 would represent cause for concern.\n\nThe researchers stressed that a single glass of wine would not lead to metal poisoning, pointing out that their THQ calculations were based on the average person drinking one-third of a bottle of wine (250 ml) every day between the ages of 18 and 80. However the \"combined THQ values\" for metal ions in the red wine they analyzed were reported to be as high as 125. A subsequent study by the same university using a meta analysis of data based on wine samples from a selection of mostly European countries found equally high levels of vanadium in many red wines, showing combined THQ values in the range of 50 to 200, with some as high as 350.\n\nThe findings sparked immediate controversy due to several issues: the study's reliance on secondary data; the assumption that all wines contributing to that data were representative of the countries stated; and the grouping together of poorly understood high-concentration ions, such as vanadium, with relatively low-level, common ions such as copper and manganese. Some publications pointed out that the lack of identifiable wines and grape varieties, specific producers or even wine regions, provided only misleading generalizations that should not be relied upon in choosing wines.\n\nIn a news bulletin following the widespread reporting of the findings, the UK's National Health Service (NHS) were also concerned that \"the way the researchers added together hazards from different metals to produce a final score for individual wines may not be particularly meaningful\". Commentators in the US questioned the relevance of seafood-based THQ assessments to agricultural produce, with the TTB, responsible for testing imports for metal ion contamination, have not detected an increased risk. George Solas, quality assessor for the Canadian Liquor Control Board of Ontario (LCBO) claimed that the levels of heavy metal contamination reported were within the permitted levels for drinking water in tested reservoirs.\n\nWhereas the NHS also described calls for improved wine labeling as an \"extreme response\" to research which provided \"few solid answers\", they acknowledged the authors call for further research to investigate wine production, including the influence that grape variety, soil type, geographical region, insecticides, containment vessels and seasonal variations may have on metal ion uptake.\n\nAlthough red wine contains many chemicals under basic research for their potential health benefits, resveratrol has been particularly well studied and evaluated by regulatory authorities, such as the European Food Safety Authority and US Food and Drug Administration which identified it and other such phenolic compounds as not sufficiently understood to confirm their role as physiological antioxidants.\n\nCinnamates have been shown to have more antioxidant activity when exposed in vitro to the Fenton reaction (catalytic Fe(II) with hydrogen peroxide) than the other natural phenols present in wine.\n\nResearch on potential health effects of resveratrol is in its infancy and the long-term effects of supplementation in humans are not known.\n\nResveratrol is a stilbenoid phenolic compound found in wine produced in the grape skins and leaves of grape vines. It has received considerable attention in both the media and medical research community for its potential health benefits which remain unproven in humans.\n\nThe production and concentration of resveratrol is not equal among all the varieties of wine grapes. Differences in clones, rootstock, \"Vitis\" species as well as climate conditions can affect the production of resveratrol. Also, because resveratrol is part of the defence mechanism in grapevines against attack by fungi or grape disease, the degree of exposure to fungal infection and grape diseases also appear to play a role. The Muscadinia family of vines, which has adapted over time through exposure to North American grape diseases such as phylloxera, has some of the highest concentrations of resveratrol among wine grapes. Among the European \"Vitis vinifera\", grapes derived from the Burgundian Pinot family tend to have substantially higher amounts of resveratrol than grapes derived from the Cabernet family of Bordeaux. Wine regions with cooler, wetter climates that are more prone to grape disease and fungal attacks such as Oregon and New York tend to produce grapes with higher concentrations of resveratrol than warmer, dry climates like California and Australia.\n\nAlthough red wine and white vine varieties produce similar amounts of resveratrol, red wine contains more than white, since red wines are produced by maceration (soaking the grape skins in the mash). Other winemaking techniques, such as the use of certain strains of yeast during fermentation or lactic acid bacteria during malolactic fermentation, can have an influence on the amount of resveratrol left in the resulting wines. Similarly the use of certain fining agents during the clarification and stabilization of wine can strip the wine of some resveratrol molecules.\n\nThe prominence of resveratrol in the news and its association with positive health benefits has encouraged some wineries to highlight it in their marketing. In the early 21st century, the Oregon producer Willamette Valley Vineyards sought approval from the Alcohol and Tobacco Tax and Trade Bureau (TTB) to state on their wine labels the resveratrol levels of their wines which ranged from 19 to 71 micromoles per liter (higher than the average 10 micromoles per liter in most red wines). The TTB gave preliminary approval to the winery, making it the first to use such information on its labels. While resveratrol is the most widely publicized, there are other phenolic components in wine that have been the focus of medical research for potential health benefits, including the compounds catechin and quercetin, none of which has been proven to have any health value in humans.\n\nRed grapes are high in anthocyanins which are the source of the color of various fruits, such as red grapes. The darker the red wine, the more anthocyanins present.\n\nFollowing dietary ingestion, anthocyanins undergo rapid and extensive metabolism that makes the biological effects presumed from in vitro studies unlikely to apply in vivo.\n\nAlthough anthocyanins are under basic and early-stage clinical research for a variety of disease conditions, there exists no sufficient evidence that they have any beneficial effect in the human body. The US FDA has issued warning letters, e.g., to emphasize that anthocyanins are not a defined nutrient, cannot be assigned a dietary content level and are not regulated as a drug to treat any human disease.\n\nEarly medicine was intimately tied with religion and the supernatural, with early practitioners often being priests and magicians. Wine's close association with ritual made it a logical tool for these early medical practices. Tablets from Sumeria and papyri from Egypt dating to 2200 BC include recipes for wine based medicines, making wine the oldest documented human-made medicine.\n\nWhen the Greeks introduced a more systematized approach to medicine, wine retained its prominent role. The Greek physician Hippocrates considered wine a part of a healthy diet, and advocated its use as a disinfectant for wounds, as well as a medium in which to mix other drugs for consumption by the patient. He also prescribed wine as a cure for various ailments ranging from diarrhea and lethargy to pain during childbirth.\n\nThe medical practices of the Romans involved the use of wine in a similar manner. In his 1st-century work \"De Medicina\", the Roman encyclopedist Aulus Cornelius Celsus detailed a long list of Greek and Roman wines used for medicinal purposes. While treating gladiators in Asia Minor, the Roman physician Galen would use wine as a disinfectant for all types of wounds, and even soaked exposed bowels before returning them to the body. During his four years with the gladiators, only five deaths occurred, compared to sixty deaths under the watch of the physician before him.\n\nReligion still played a significant role in promoting wine's use for health. The Jewish Talmud noted wine to be \"the foremost of all medicines: wherever wine is lacking, medicines become necessary.\" In his first epistle to Timothy, Paul the Apostle recommended that his young colleague drink a little wine every now and then for the benefit of his stomach and digestion. While the Islamic Koran contained restrictions on all alcohol, Islamic doctors such as the Persian Avicenna in the 11th century AD noted that wine was an efficient digestive aid but, because of the laws, were limited to use as a disinfectant while dressing wounds. Catholic monasteries during the Middle Ages also regularly used wine for medical treatments. So closely tied was the role of wine and medicine, that the first printed book on wine was written in the 14th century by a physician, Arnaldus de Villa Nova, with lengthy essays on wine's suitability for treatment of a variety of medical ailments such dementia and sinus problems.\n\nThe lack of safe drinking water may have been one reason for wine's popularity in medicine. Wine was still being used to sterilize water as late as the Hamburg cholera epidemic of 1892 in order to control the spread of the disease. However, the late 19th century and early 20th century ushered in a period of changing views on the role of alcohol and, by extension, wine in health and society. The Temperance movement began to gain steam by touting the ills of alcoholism, which was eventually defined by the medical establishment as a disease. Studies of the long- and short-term effects of alcohol caused many in the medical community to reconsider the role of wine in medicine and diet. Soon, public opinion turned against consumption of alcohol in any form, leading to Prohibition in the United States and other countries. In some areas, wine was able to maintain a limited role, such as an exemption from Prohibition in the United States for \"therapeutic wines\" that were sold legally in drug stores. These wines were marketed for their supposed medicinal benefits, but some wineries used this measure as a loophole to sell large quantities of wine for recreational consumption. In response, the United States government issued a mandate requiring producers to include an emetic additive that would induce vomiting above the consumption of a certain dosage level.\n\nThroughout the mid to early 20th century, health advocates pointed to the risk of alcohol consumption and the role it played in a variety of ailments such as blood disorders, high blood pressure, cancer, infertility, liver damage, muscle atrophy, psoriasis, skin infections, strokes, and long-term brain damage. Studies showed a connection between alcohol consumption among pregnant mothers and an increased risk of mental retardation and physical abnormalities in what became known as fetal alcohol syndrome, prompting the use of warning labels on alcohol-containing products in several countries.\n\nThe 1990s and early 21st century saw a renewed interest in the health benefits of wine, ushered in by increasing research suggesting that moderate wine drinkers have lower mortality rates than heavy drinkers or teetotalers. In November 1991, the U.S. news program \"60 Minutes\" aired a broadcast on the so-called \"French Paradox\". Featuring the research work of Bordeaux scientist Serge Renaud, the broadcast dealt with the seemingly paradoxical relationship between the high fat/high dairy diets of French people and the low occurrence of cardiovascular disease among them. The broadcast drew parallels to the American and British diets which also contained high levels of fat and dairy but which featured high incidences of heart disease. One of the theories proposed by Renaud in the broadcast was that moderate consumption of red wine was a risk-reducing factor for the French and that wine could have more positive health benefits yet to be studied. Following the \"60 Minutes\" broadcast, sales of red wine in the United States jumped 44% over previous years.\n\nThis changing view of wine can be seen in the evolution of the language used in the U.S. Food and Drug Administration Dietary Guidelines. The 1990 edition of the guidelines contained the blanket statement that \"wine has no net health benefit\". By 1995, the wording had been changed to allow moderate consumption with meals providing the individual had no other alcohol-related health risk. From a research perspective, scientists began differentiating alcohol consumption among the various classes of beverages – wine, beer, and spirits. This distinction allowed studies to highlight the positive medical benefits of wine apart from the mere presence of alcohol. However wine drinkers tend to share similar lifestyle habits – better diets, regular exercise, non-smoking – that may in themselves be a factor in the supposed positive health benefits compared to drinkers of beer and spirits or those who abstain completely.\n"}
{"id": "16079224", "url": "https://en.wikipedia.org/wiki?curid=16079224", "title": "Health in the Comoros", "text": "Health in the Comoros\n\nAfter independence in 1975, the French withdrew their medical teams, leaving the three islands' already rudimentary health care system in a state of severe crisis. French assistance was eventually resumed, and other nations also contributed medical assistance to the young republic. Despite improvements in life expectancy and the infant mortality rate, the Comoros in 1993 continued to face public health problems characteristic of developing countries.\n\nThe 2010 maternal mortality rate per 100,000 births for the Comoros is 340. This is compared with 225.3 in 2008 and 449.9 in 1990. The under 5 mortality rate, per 1,000 births is 105 and the neonatal mortality as a percentage of under 5's mortality is 35. In the Comoros the number of midwives per 1,000 live births is 9 and the lifetime risk of death for pregnant women 1 in 71.\n\nLife expectancy at birth was estimated at fifty-six years in 1990, up from fifty-one years in 1980. The crude birthrate was forty-eight per 1,000 and the crude death rate, twelve per 1,000 according to 1989 statistics. All three of these figures were close to the averages for sub-Saharan Africa. The rate of infant mortality per 1,000 live births was eighty-nine in 1991, down from 113 in 1980. The 1990 average rate for sub-Saharan Africa was 107.\n\nMalaria was ubiquitous in the islands, with 80 to 90 percent of the population said to be affected by the disease. Other prevalent maladies included tuberculosis, leprosy, and parasitic diseases. In 1989 about half of all children one year old or younger had been immunized against tuberculosis, diphtheria, pertussis, tetanus, polio, and measles, a proportion roughly comparable to the rate of immunization among other states in sub-Saharan Africa. \n\nPer capita daily caloric intake in 1988 was 2,046, about average for sub-Saharan Africa but only a little better than 90 percent of daily requirements. Children were most often the victims of malnutrition. Their generally poor diets were deficient in protein in part because local custom discouraged the feeding of fish to children. The scarcity of safe drinking water—available to about one in three Comorans—made intestinal parasites a problem and compounded malnutrition, with children again being the main victims.\n\nThe World Bank estimated that in 1993 the Comoros had one physician per 6,582 Comorans, a marked improvement over the ratio of one to 13,810 reported in 1983. Comparable data for sub-Saharan Africa as a whole were not available; however, it appeared that Comorans enjoyed a more favorable ratio than many of their neighbors in East Africa and the Indian Ocean.\n\nDespite improvements in life expectancy, infant mortality, and the number of physicians, the overall quality of care remained poor. About 80 percent of the population lives within one hour's walk of a health facility, usually headed by a trained nurse, but paramedical staff are in short supply and many health facilities are in poor condition. Some international medical aid has been provided, mostly by France and the World Health Organization (WHO).\n\nAlthough the Comoros lacks homegrown narcotics, the islands are used as a transit site for drugs coming mainly from Madagascar. In view of international concern about drug trafficking, in 1993 France began providing technical expertise in this field to the Comoros. In addition, the World Bank in a 1994 report pointed out the \"high prevalence of sexually transmitted diseases and the low use of condoms\" as a significant health threat with regard to the spread of acquired immune deficiency syndrome (AIDS), which already affected the islands. However, in the period prior to 1990 and extending through 1992, the WHO reported that the Comoros had a very low incidence of AIDS—a total of three cases with no case reported in 1992, or an overall case rate of 0.1 per 100,000 population.\n\n"}
{"id": "3877626", "url": "https://en.wikipedia.org/wiki?curid=3877626", "title": "Healthcare in Venezuela", "text": "Healthcare in Venezuela\n\nAfter the Bolivarian Revolution, extensive inoculation programs and the availability of low- or no-cost health care provided by the Venezuelan Institute of Social Security made Venezuela's health care infrastructure one of the more advanced in Latin America. However, by 2015, the Venezuelan health care system had collapsed.\n\nVenezuelan state governments operated only 5 facilities in 1979, down from about 60 hospitals in 1970 since the Ministry of Health and Social Assistance (MSAS) took over many of the hospitals.\n\nIn 1978, a presidential election year, medical sales in Venezuela hit an all-time high at the time and dropped in 1979. In 1979, there were approximately 250 hospitals in Venezuela with MSAS operating the majority of 58%. Venezuela had a shortage of medical professionals and hospital beds in the late 1970s due to highly increasing population and the lack of specializing in being a specific medical technician. The lack of both professionals and beds was higher in rural areas compared to more populated areas. Between 1978 and 1980, Venezuela had 14,771 doctors, 8,805 nurses and 28,04 nursing auxiliaries.\n\nUnder the Sixth National Plan of Luis Herrera Campins, the Campins government planned to increase medical funding by 9.7% annually between 1981 and 1985, with medical expenditures planned to reach $2.1 billion in 1985. $1.2 billion were designated to the construction of new facilities to combat bed shortages, with a main focus on establishing clinics in order to avoid inefficiency of larger hospitals. Rehabilitation of handicapped individuals and the concentration on heart disease, the leading cause of death in Venezuela, were also focused on in the Sixth National Plan. Medical professionals in Venezuela were \"extremely U.S. oriented\", with most doctors attending post-graduate work in the United States, were able to speak English, read U.S. medical journals and attended gatherings of United States medical experts. In 1981, over 70% of healthcare services were government administered.\n\nForeign medical equipment developed abroad was quickly adopted and shipped to Venezuela with most of the country's medical goods needing to be imported. In 1980, Venezuela imported 47% of medical goods from the United States, 13% from Germany, 8% from Japan and 3% from the United Kingdom. The majority of medical equipment was distributed by a conglomerate of about 45 distributors known as Associacion Venezolana de Distribuidores de Equips Medicos (AVEDEM) while 15% of medical products were distributed by smaller entities.\n\nFollowing the Bolivarian Revolution and the establishment of the Bolivarian government, initial healthcare practices were promising with the installation of free healthcare and the assistance received from Cuban medical professionals providing aid. The Bolivarian government's failure to concentrate on healthcare for Venezuelans, the reduction of healthcare spending and government corruption eventually affected medical practices in Venezuela; causing avoidable deaths along with an emigration of medical professionals to other countries. Venezuela's reliance of imported goods and its complicated exchange rates initiated under Hugo Chávez led to increasing shortages during the late-2000s and into the 2010s that affected the availability of medicines and medical equipment in the country.\n\nThroughout Hugo Chávez's presidency, the Health Ministry changed ministers multiple times. According to a high-ranking official of Venezuela's Health Ministry, the ministers were treated as scapegoats whenever issues with public health arose in Venezuela. The official also explained how Health Ministry officials would also perform illicit acts in order to enrich themselves by selling goods designated to public healthcare to others.\n\nThe Venezuelan government stopped publishing medical statistics in 2010.\n\nIn 2014 when Venezuela's economy was facing difficulties, Venezuela's medical atmosphere deteriorated. The Bolivarian government did not supply enough dollars for medical supplies among healthcare providers; with doctors saying that 9 of 10 of large hospitals had only 7% of required supplies with private doctors reporting many patients that are \"impossible\" to count are dying from easily treated illnesses due to the \"downward sliding economy\" in 2014. Due to such complications, many Venezuelans died avoidable deaths with medical professionals having to use limited resources to use methods that were replaced decades ago. In February 2014, doctors at University of Caracas Medical Hospital stopped performing surgeries due to the lack of supplies, even though nearly 3,000 people require surgery.\n\nIn March 2014, the executive director of the Venezuelan Association of Hospitals and Clinics explained how in less than a month, shortages of 53 medical products rose to 109 products and explained how the CADIVI system is to blame since 86% of supplies are imported with private sector hospitals claiming they owe suppliers billions of dollars in order to pay for debts.\n\nIn early 2015, only 35% of hospital beds were available and 50% of operating rooms could not function due to the lack of resources. In March 2015, a Venezuelan NGO, Red de Medicos por la Salud, reported that there was a 68% shortage of surgical supplies and a 70% shortage of medicines in Venezuelan pharmacies. In May 2015, the Venezuelan Medical Federation said that 15,000 doctors had left the public health care system because of shortages of drugs and equipment and poor pay. In August 2015 Human Rights Watch said “We have rarely seen access to essential medicines deteriorate as quickly as it has in Venezuela except in war zones.”\nBy the end of 2015, the Bolivarian government reported that of all Venezuelans visiting public hospitals in the year, one-of-three patients died. Also in 2015 Venezuela had 30% of all reported malaria cases in the Americas and more even than Brazil, which has a much larger population.\n\nIn 2018 Venezuela is suffering from acute shortages of food and medicines.\n\nPrivate hospitals and clinics and the qualifications of their medical personnel are comparable to U.S. standards. Private health services are costly and \"full to bursting.\"\nThe Venezuelan government has accused private hospitals of profiteering. 2,000 doctors left the country between 2006 and 2008.\nOverall roughly 1 in 5 Venezuelans have private health insurance.\n\n"}
{"id": "10810477", "url": "https://en.wikipedia.org/wiki?curid=10810477", "title": "Hereditary breast–ovarian cancer syndrome", "text": "Hereditary breast–ovarian cancer syndrome\n\nHereditary breast–ovarian cancer syndromes (HBOC) are cancer syndromes that produce higher than normal levels of breast cancer and ovarian cancer in genetically related families (either one individual had both, or several individuals in the pedigree had one or the other disease). The hereditary factors may be proven or suspected to cause the pattern of breast and ovarian cancer occurrences in the family.\n\nA number of genes are associated with HBOC. The most common of the known causes of HBOC are:\n\nOther identified genes include:\n\n\nApproximately 45% of HBOC cases involve unidentified genes, or multiple genes.\n\nPeople with \"BRCA1\" and \"BRCA2\" mutations are recommended to have a transvaginal ultrasound 1-2 times per year. Screening with CA-125 is also recommended. Prophylactic salpingo-oophorectomy (removal of the ovaries and Fallopian tubes to prevent cancer) is recommended at age 35-40 for people with \"BRCA1\" mutations and at age 40-45 for people with \"BRCA2\" mutations.\n"}
{"id": "27176146", "url": "https://en.wikipedia.org/wiki?curid=27176146", "title": "Hospicio de San Jose", "text": "Hospicio de San Jose\n\nHospicio de San José is a Roman Catholic welfare institution in the City of Manila, the Philippines. It is the first social welfare agency in the country, and as a foster care institution has been a home for orphans, the abandoned, special needs, and the elderly.\n\n\"Hospicio de San José\" is located on Isla de Convalecencia (Spanish, \"Island of convalescence\"), an eyot in the middle of the Pasig River, and can only be accessed via Ayala Bridge. It was formerly located in the Pandacan district. From there, it was transferred to Intramuros, Binondo, Nagtahan, and Echague. In 1810, the \"Hospicio\" was permanently relocated to Isla de Convalecencia.\n\nInitially named the Hospicio General (General Hospice), \"Hospicio de San José\" was established during the Spanish Era in October 1778 by Don Francisco Gómez Enríquez and his wife Doña Barbara Verzosa. After being cured of a fever, Don Gómez Enríquez donated the sum of ₱ 4,000 to found the hospice that would take care of Manila’s “poor and unwanted children”, the physically and mentally handicapped, and aging people. The initiative and example of Don Gómez Enríquez was followed by other charitable people of Manila.\n\nFrom 27 December 1810 and by Royal Decree, the hospice was governed by a Board of Directors chaired by the Archbishop of Manila. On 1 June 1866, through the suggestion to the Governor-General of the Philippines by a benefactor named Doña Margarita Róxas, the operation of the hospice became the responsibility of the Daughters of Charity of St. Vincent de Paul.\n\nThe hospice provides an outreach programme and a Christian, social and work-oriented formation programme. It is committed to assisting abandoned people to experience quality life with the aim of making them “agents of social transformation”.\n\nHospicio de San Jose has two historical markers. The first, in English, was from the Historical Research and Markers Committee and was unveiled on October 17, 1939. In 1977, a second historical marker was given from the National Historical Institute and is in Tagalog. \n\nThe first historical marker of Hospicio de San Jose was installed in October 17, 1939 at Ayala Boulevard, San Miguel, Manila. It was installed by Historical Research and Markers Committee.\n\nThe second historical marker of Hospicio de San Jose was installed in 1977 at Hospicio de San Jose, San Miguel, Manila. It was installed by National Historical Institute.\n\n\n"}
{"id": "7196927", "url": "https://en.wikipedia.org/wiki?curid=7196927", "title": "Hysteroid dysphoria", "text": "Hysteroid dysphoria\n\nHysteroid dysphoria is a name given to repeated episodes of depressed mood in response to feeling rejected.\n\nHysteroid dysphoria has been described in outpatient populations and is thought to be a subtype of atypical depression involving rejection sensitivity and therapeutic response to monoamine oxidase inhibitors.\n"}
{"id": "43377867", "url": "https://en.wikipedia.org/wiki?curid=43377867", "title": "Iknife", "text": "Iknife\n\nOnkoknife, iKnife, or intelligent scalpel (English: Jedi knife, onkoknife; Hungarian: onkokés, intelligens sebészi kés) is a surgical knife, which tests tissue as it contacts it during an operation, and immediately gives information as to whether that tissue contains cancer cells. During a surgery this information is given continuously to the surgeon, significantly accelerating biological tissue analysis and enabling removal of virtually all cancer cells. Electroknives have been in use since the 1920s and smart knife surgery is not limited only to cancer diseases, but the iKnife is limited to cancer cell detection in the vapor given off, however, since it can not properly detect and identify the type of bacteria found in tissues so well.\n\nZoltán Takáts, Ph.D., a Hungarian research chemist associated with Semmelweis University, in Budapest, invented the \"intelligent surgical knife\". He currently is Professor of Analytical Chemistry at Imperial College London (UK). His \"iKnife\" has been tested in three hospitals from 2010 through 2012. Following laboratory analysis of tissue samples in 302 patients that were included in a data base, they included 1624 of cancer and 1309 of non-cancer samples.\n\nThe current pilot version for the iKnife cost the creating Hungarian scientist, MediMass Ltd. (\"Old Buda\" based company) participating in the research, colleagues at Imperial College, and the Hungarian government approximately £200 thousand (68 million HUF). According to Takáts, the investments will have been worth it, however, as the device is on a likely path to marketing.\n\nThe instrument has been acquired by the Massachusetts Waters Corporation for development by \"MediMass Ltd.\", which identifies it as substantive innovative technology labelled, \"Intelligent late\" and \"REIMS\", according to their press release on 23 July 2014. The business transaction included all \"MediMass\" innovation, including patents, software, databases, and human resources related to the technology.\n\nDirect examination of biological tissue by mass spectrometry (MS) began in the 1970s, but at that time the next advance in technical conditions did not exist. The method did not provide any useful information on the chemical composition of the samples tested. The first breakthrough came with desorption ionisation methods (secondary ionization mass spectrometry - SIMS, matrix-assisted laser desorption ionization - MALDI) a release said. Using these methods, after appropriate sample preparation, chemical biological tissue imaging analysis may be achieved. From the end of the 1990s, it became apparent that mass spectrometry data in imaging studies showed a high degree of tissue specificity, that tissue histology could determine mass spectral information, and vice versa.\n\nIn the case of the detected protein and peptide components, tissue-specific expression of the proteins is known commonly. Precise immunohistochemical methods are based on this phenomenon. The mass spectrometer detection, mainly from cell membranes and similar tissue, specifically, of complex lipids from similar tissue, however, yields surprising results. Since the distribution of proteins are in good agreement with the distribution patterns obtained by immunohistochemical methods, the distribution of the lipid components of the direct ionization mass spectrometric, previously were relative methods leading to the appearance of a new era in the study of biological specimens. The desorption electrospray ionization (DESI) was the first-MS technique, which allowed non-invasive testing of any objects (or organisms) without sample preparation, regardless of their shape or mechanical properties.\n\nDuring the summer of 2009, rapid evaporative ionization mass spectrometry (REIMS) was described. This is the second generation method. Primarily, lipid components of tissues provide the information, but different metabolite molecules and certain proteins also allow detection. The most important advantage of the specificity of mass spectrometry data is at the histological level, providing the opportunity to identify biological tissue based on chemical composition. The REIMS method is unique, in that, while the above-described mass spectrometry techniques specific to the particular method developed ion sources should be used, but it is difficult in the case of ion source devices used in surgical practice. With the operation of a variety of tissue-cutting tools, such as a diathermy knife, a surgical laser, or an ultrasonic tissue atomizer, an aerosol is formed having a composition characteristic of the tissue cut, which also contains ionized cell constructs.\n\nAmong them, in terms of using the REIMS method, the intact membrane-forming phospholipids are important, which easily are detectable by mass spectrometry on the one hand, and on the other hand, contain the combination of the characteristics of the particular tissue type. Mass spectrometric analysis is just one implementation of an effective extraction system development that was needed to cut the surgical site at the time of running the generated aerosol mass spectrometer. For this purpose, a so-called Venturi-tube serves, as well as the above-mentioned surgical hand pieces, being modified to smoke the aerosols through them. Analysis of the flue gas in the mass spectrometer is realized instantaneously, within a few tenths of a second, resulting in a tissue-specific phospholipid mass spectra being obtained, allowing a response by the surgeon in less than two seconds. The analysis of the collected spectra is made of special-evaluation software, which was developed for this purpose. The software continuously compares the incoming data during surgery, validates mass spectra stored in a database, assigns the appropriate class, and the result is displayed visually to the surgeon. It also may provide information to the surgeon via an audio signal. It is estimated that the tissue identification accuracy during operation is higher than 92%.\n\nTherefore, the method is suitable for use in a surgical environment for carrying out measurements, as well as for being a part of a complex tissue identification system used during surgical tumor removal, and it can assist the surgeon in the operating surgical site with accurate histological mapping. The rapid evaporative ionization mass spectrometry (REIMS) is a novel technique that allows electrosurgery cuts with near real-time characterization of human tissue in vivo analysis through analysis of the vapors released during the process of tissue and aerosols. The REIMS technology and electro-surgical procedure adds tissue diagnosis to the intelligent knife iKnife operating principle.\n\n\n\n\n"}
{"id": "1673941", "url": "https://en.wikipedia.org/wiki?curid=1673941", "title": "Institute for Systems Biology", "text": "Institute for Systems Biology\n\nInstitute for Systems Biology (ISB) is a non-profit research institution located in Seattle, Washington, United States. The ISB concentrates on systems biology, the study of relationships and interactions between various parts of biological systems, and advocates an interdisciplinary approach to biological research.\n\nSystems biology attempts to study biological systems in a holistic manner by integrating data at all levels of the biological information hierarchy, from global down to the individual organism, and below down to the molecular level. The vision of ISB has been to integrate these concepts using a cross-disciplinary approach combining the efforts of biologists, chemists, computer scientists, engineers, mathematicians, physicists, and physicians.\n\nOn its website, ISB has defined four areas of focus: \n\nLeroy Hood co-founded the Institute with Alan Aderem and Ruedi Aebersold in 2000.\n\nHowever, the story of how ISB got started actually begins in 1990. Lee Hood was the director of a large molecular biotechnology lab at the California Institute of Technology in Pasadena, and was a key advisor in the Human Genome Project, having overseen development of machines that were instrumental to its later success. The University of Washington (UW), like many other universities, was eager to recruit Hood, but had neither the space nor the money to accommodate Hood's large laboratory.\n\nLee Huntsman, director of UW's Center for Bioengineering, was attending a UW football game, sharing a luxury box with Bill Gates, the former CEO and current chairman of Microsoft. Huntsman took the opportunity to tell Gates about Hood. Bill Gates already had a considerable interest in biotechnology, both as a philanthropist and as an investor, and after meeting Hood, donated $12 million to UW to enable him to head a new department of molecular biotechnology, where Hood continues to hold a faculty position as the Gates Professor of Molecular Biotechnology.\n\nISB represents a spin-off of Hood's labs at UW.\n\nISB is in the top ranks of scientific institutions worldwide. In 2012, the SCImago Research Group, based in Spain, ranked ISB 4th worldwide on its Excellence Rate scale.\n\nISB currently hosts 10 research groups with expertise ranging across genetics, microbial genetics, complex molecular machines, macromolecular complexes, gene regulatory networks, immunology, molecular and cell biology, cancer biology, genomics, proteomics, protein chemistry, computational biology and biotechnology. The ISB web site lists 985 peer-reviewed publications for the years 2000 through early 2012. \nIn late 2005, the ISB began to emphasize the application of systems biology to P4 medicine (predictive, preventive, personalized, participatory), \"i.e.\" the development of techniques for predicting and preventing disease, possibly before patients even know they are sick. The \"P4 Medicine institute\" was co-founded in 2010 by ISB and Ohio State University.\n\nThe Education and Outreach efforts of ISB include creating the Logan Center for Education whose mission is to enable educators to produce STEM literate students. ISB offers paid research internships for high school and undergraduate students, and offers advanced systems science courses throughout the year.\n\nISB has partnered in several high-profile research projects, the most significant one thus far being with the Grand Duchy of Luxembourg to create the \"Center for Systems Biology Luxembourg\" and the \"Seattle Proteome Center\".\n\nISB faculty members have launched five companies: Cytopeia (acquired by BD in 2008), Integrated Diagnostics, Macrogenics, NanoString Technologies, and Accelerator Corporation. Accelerator Corporation, in particular, is an investment company that provides venture capital funding and management for biotech startup companies. Its portfolio companies and graduates have focused on improved biotherapeutics, vaccines, biomarkers and other such products.\n\n\n"}
{"id": "41581096", "url": "https://en.wikipedia.org/wiki?curid=41581096", "title": "Intersex Trust Aotearoa New Zealand", "text": "Intersex Trust Aotearoa New Zealand\n\nFounded by Mani Mitchell in 1996, Intersex Trust Aotearoa New Zealand, also known as Intersex Awareness New Zealand is a national advocacy and peer support organisation for intersex people in New Zealand.\n\nITANZ is a charitable trust that provides education, information and training on intersex issues for organisations and individual professionals. Executive Director Mani Mitchell is known as New Zealand's first \"out\" intersex person.\n\nThe Trust works with the Human Rights Commission, Rainbow Youth in Auckland, Whanganui Women's Health Collective, and Working it Out in Tasmania.\n\nTrust members have participated in, and jointly held, roundtable events with the Human Rights Commission, including on the human rights implications of intersex medical interventions, shame and secrecy. Following a joint round table event with the Human Rights Commission, the Commission proposed to the UN Committee on the Rights of the Child that the New Zealand government enact legal and regulatory safeguards to protect the rights of intersex children, and ensure that children's rights to bodily integrity, autonomy and self-determination are respected. In October 2016, the UN Committee on the Rights of the Child issued observations on practices in New Zealand, including recommendations to ensure \"that no one is subjected to unnecessary medical or surgical treatment during infancy or childhood, guaranteeing the rights of children to bodily integrity, autonomy and self-determination\". The recommendations of the Committee on the Rights of the Child have been illustrated by ITANZ and Intersex Youth Aotearoa.\n\nIn March 2017, representatives of Intersex Trust Aotearoa New Zealand participated in an Australian and Aotearoa/New Zealand consensus \"Darlington Statement\" by intersex community organizations and others. The statement calls for legal reform, including the criminalization of deferrable intersex medical interventions on children, an end to legal classification of sex, and improved access to peer support.\n\nExecutive Director Mani Mitchell provides counselling for individuals and families.\n\nA youth project, Intersex Youth Aotearoa, was launched in September 2015, to provide information and support to youth with intersex conditions.\n\nMitchell, and other board members, have given presentations to a range of audiences, including the National College of Midwives biennial conference and the University of the Third Age. The Trust have supported the filming of award-winning documentary Intersexion (2012).\n\nMitchell co-organized the third International Intersex Forum in Malta, 2013.\n\nITANZ a member of the International Lesbian, Gay, Bisexual, Trans and Intersex Association.\n\n"}
{"id": "28683613", "url": "https://en.wikipedia.org/wiki?curid=28683613", "title": "Jimione Samisoni", "text": "Jimione Samisoni\n\nJimione (Jimmie) Isimeli Samisoni was the late former Dean of the Fiji School of Medicine (FSM).\n\nSamisoni attended Lelean Memorial School in 1949, passed his Senior Cambridge exams and matriculated to the then Central School of Medicine. The Central School of Medicine was later renamed the Fiji School of Medicine.\n\nAfter receiving a fellowship from the World Health Organization (WHO), he went on to study at the Otago University where he graduated in 1959 with a Bachelor of Medicine. Later he continued post-graduate studies at the University of Queensland where he graduated with a Masters of Science degree.\n\nWhilst studying for his Bachelor of Medicine and Bachelor of Surgery degree (MBBS), Jimmie Samisoni was also working towards his Doctorate (PhD)which he received in 1973.\n\nFrom the mid to late 1970s, Dr Samisoni worked as a house surgeon in Queensland. He also worked as a senior lecturer at the Griffith University before returning to Fiji in 1980 where he joined the FSM.\n\nDuring the year of the first military coup in Fiji (1987), Dr Jimmie Samisoni left Fiji and joined the University of Hawaii's medical faculty as an assistant clinical professor.\n\nDr Samisoni was appointed the academic dean of the FSM when he came back to Fiji in 1990.\n\nHe retired from the FSM in 1998.\n\nDr Jimione Samisoni died in April 2007. He was married to Dr Mere Samisoni (DBA) and they had four children. DrMere Samisoni is the Chairperson of the popular Hot Bread chain of stores in Fiji.\n\n"}
{"id": "57825155", "url": "https://en.wikipedia.org/wiki?curid=57825155", "title": "Jorge Alcocer Varela", "text": "Jorge Alcocer Varela\n\nJorge Alcocer Varela (born 8 February 1946) is a Mexican healthcare professional. He is a former researcher at the Salvador Zubirán National Institute of Health Sciences and Nutrition. He is expected to be appointed as the Mexican Minister of Public Health by President Andrés Manuel López Obrador.\n"}
{"id": "51680342", "url": "https://en.wikipedia.org/wiki?curid=51680342", "title": "Lebanese Order of Physicians", "text": "Lebanese Order of Physicians\n\nFounded on December 7, 1946, the Lebanese Order of Physicians in Beirut is the largest medical organization and physician group in Lebanon. \nIts membership of 12,000 aims to pursue and promote optimal healthcare system and policies in Lebanon thus the region. Physicians are specialists who apply scientific knowledge and clinical expertise to the diagnosis, treatment, and compassionate care of adults across the spectrum from health to complex illness.\n\nThe Lebanese Order of Physicians’ mission is a medical, healthy, scientific, administrative, and a guiding mission that aims to:\n\n\n\nMedia & Communication Committee\n\nScientific Committee\n\nAdministrative Committee\n\n\n"}
{"id": "32852822", "url": "https://en.wikipedia.org/wiki?curid=32852822", "title": "Mercy Hospital (Miami)", "text": "Mercy Hospital (Miami)\n\nMercy Hospital is a 488-bed acute care U.S. hospital located in Coconut Grove, Miami, Florida. It is Miami-Dade County's only Catholic hospital.\n\nMercy Hospital was established in 1950. It was a member of the Catholic Health East, and formerly sponsored by the Sisters of St. Joseph of St. Augustine, Florida until it was sold to HCA. The hospital has 2,300 full-time employees.\n\n\n\n\n"}
{"id": "1955806", "url": "https://en.wikipedia.org/wiki?curid=1955806", "title": "New Valley Project", "text": "New Valley Project\n\nThe New Valley Project or Toshka Project consists of building a system of canals to carry water from Lake Nasser to irrigate part of the sandy wastes of the Western Desert of Egypt, which is part of the Sahara Desert. In 1997 the Egyptian government decided to develop a new valley (as opposed to the existing Nile Valley) where agricultural and industrial communities would develop. It has been an ambitious project which was meant to help Egypt cope with its rapidly growing population.\n\nThe canal inlet starts from a site 8 km to the north of Toshka Bay (Khor) on Lake Nasser. The canal is meant to continue westwards until it reaches the Darb el-Arbe'ien route, then northwards along the Darb el- Arbe'ien to the Baris Oasis, covering a distance of 310 km. But as of April 2012 the canal is still 60 km short of the Baris Oasis. The Mubarak Pumping Station in Toshka is the centerpiece of the project and was inaugurated in March 2005. It pumps water from Lake Nasser to be transported by way of a canal through the valley, with the idea of transforming 2340 km² (588,000 acres) of desert into agricultural land. The Toshka Project has now been revived by President Abdel Fattah el-Sisi. Half of the land will be given to college graduates, 1 acre each, funded by the Long Live Egypt Fund.\n\nThe essential problem is that the Western Desert's high saline levels and the presence of underground aquifers in the area act as a major obstacle to any irrigation project. As the land is irrigated, the salt would mix with the aquifers and would reduce access to potable water. There is also the difficulty that the clay minerals found in the soil are posing technical problems to the big wheeled structures moving around autonomously to irrigate the land. Often their wheels get stuck in a little bowl created by wet clay that dried, and the irrigation machines come to a standstill. The only objective met up to April 2012 is the diversion of water from Lake Nasser into what little of the Sheikh Zayed Canal has been built.\n\nThe Toshka Lakes are a by-product of the rising level of Lake Nasser and lie in the same general region as much of the New Valley Project.\n\n\n"}
{"id": "33103053", "url": "https://en.wikipedia.org/wiki?curid=33103053", "title": "Paraveterinary workers in Ireland", "text": "Paraveterinary workers in Ireland\n\nParaveterinary workers in Ireland, such as veterinary nurses, assist veterinary physicians, or carry out animal health procedures autonomously. Paraveterinary workers in Ireland have been represented by the Irish Veterinary Nursing Association (IVNA) since 2002, and prior to this were represented by the British Veterinary Nursing Association (BVNA) from the 1960s. The title \"veterinary nurse\" can only be used by those registered with the Veterinary Council of Ireland. The post-nominal letters used in Ireland are RVN (Registered Veterinary Nurse).\n\nVeterinary nursing became a regulated profession in Ireland from January 2008, under the Veterinary Practice Act 2005. When the act was implemented in January 2008, unqualified staff working in veterinary practices before 2004 had a period of six months to apply for provisional registration which conferred the same rights and responsibilities as full membership. The provisional registration category ended on 31 December 2012. \n\nFollowing the implementation of the Veterinary Practice Act in January 2008, no individual can legally perform veterinary nursing duties unless listed on the Register or is currently undertaking a course of formal education approved by the Veterinary Council.\n\nRegistered veterinary nurses must complete the required amount of continuing professional education each year to maintain their registration.\n\nA 2016 survey found that the majority of registered veterinary nurses were women, and that the average age was 32.\n\nThere are five programmes of study which qualify one to become a veterinary nurse in Ireland, each sanctioned by the Veterinary Council of Ireland: the 2-year diploma course at St. John's Central College in Cork, the 3-year ordinary Bachelor of Science degrees in Athlone, Dundalk and Letterkenny Institutes of Technology and the 4-year higher (honours level) Bachelor of Science degree at University College Dublin. Qualifications gained outside of Ireland may be recognised by the Veterinary Council as being equivalent to Ireland's veterinary nursing qualifications.\n\n"}
{"id": "1577501", "url": "https://en.wikipedia.org/wiki?curid=1577501", "title": "Pedro Arrupe", "text": "Pedro Arrupe\n\nPedro Arrupe (14 November 1907 – 5 February 1991) was a Spanish Basque Jesuit priest who served as the twenty-eighth Superior General of the Society of Jesus (1965–83). Stationed as novice master outside Hiroshima in 1945, he used his medical background as a first responder to the atomic bombing of Hiroshima. He led the Jesuits in the implementation of the Second Vatican Council, especially with regard to a faith that does justice and preferential option for the poor.\n\nPedro Arrupe attended school at the Santiago Apostol High School in Bilbao. Later he moved to Madrid to attend the Medical School of the Universidad Complutense. There he met Severo Ochoa, who later won the Nobel Prize in Medicine. One of his teachers was Juan Negrín, a pioneer in physiology, who would become Prime Minister of the Spanish Republic during the Civil War (1936–1939). Arrupe received the top prize in the first year anatomy course.\n\nAfter some years of medical training, Pedro Arrupe joined the Jesuits in 1927 but was unable to pursue his studies for the priesthood in Spain, since the Order had been expelled by the Spanish Republican government (1931-1939). Accordingly, the young Arrupe did his studies in the Netherlands and Belgium and at St. Louis University School of Divinity in St. Marys, Kansas, where he was ordained in 1936. Arrupe then completed a doctorate in Medical Ethics.\n\nAfter his doctorate, Arrupe was sent to work as a missionary in Japan. His early years as missionary were very frustrating for him. No matter what he did, what he organised, people did not attend, and few if any converted to Christianity. When the attack on Pearl Harbor occurred in Hawaii on 7 December 1941, it was 8 December in Japan. Arrupe was celebrating the Eucharist for the Solemnity of the Immaculate Conception when he was arrested and imprisoned for a time, being suspected of espionage. On Christmas Eve, Arrupe heard people gathering outside his cell door and presumed that the time for him to be executed had arrived. However, to his utter surprise, he discovered that some fellow Catholics, ignoring all danger, had come to sing him Christmas carols. Upon this realization, Arrupe recalled that he burst into tears. His attitude of profound prayer and his lack of offensive behaviour gained him the respect of his jailers and judges, and he was set free within a month. \n\nArrupe was appointed Jesuit superior and novice master in Japan in 1942, and was living in suburban Hiroshima when the atomic bomb fell in August 1945. He was one of 8 Jesuits who were within the blast zone of the bomb, and all 8 survived the destruction. Arrupe described that event as \"a permanent experience outside of history, engraved on my memory.\" Father Arrupe used his medical skills to help those who were wounded or dying. The Jesuit novitiate was converted into a makeshift hospital where between 150 and 200 people received care. Arrupe recalled, \"The chapel, half destroyed, was overflowing with the wounded, who were lying on the floor very near to one another, suffering terribly, twisted with pain.\" In 1958, Arrupe was appointed the first Jesuit provincial for Japan, a position he held until being elected Father General in 1965.\n\nPrior to being elected Father General, Arrupe made a visit to Latin America and, on one occasion, was celebrating the Eucharist in a suburban slum. He was deeply moved at the devotion and respect the people had for Christ in the midst of their abject poverty. After the service, a man invited Arrupe to his hovel, where he told him that he was so grateful for his visit and that he wanted to share the only gift he had, that of watching the setting sun together. Arrupe reflected, \"He gave me his hand. As I was leaving, I thought: 'I have met very few hearts that are so kind.'\"\n\nAt the thirty-first General Congregation of the Society of Jesus in 1965, Arrupe was elected twenty-eighth Superior General of the Jesuits, and served in that post until 1983. He was only the second Basque to be Father General, the first being the founder Saint Ignatius of Loyola himself. Jesuit Vincent O'Keefe, a friend and advisor to Arrupe, said Arrupe was \"a second Ignatius of Loyola, a refounder of the Society in the light of Vatican II.\" At his election Moscow radio spoke of an unusual man who would bring the Society of Jesus to its powers of the past.\n\nAfter the changes following Vatican II (1962–1965), there was tension within the Society as to how the life of a Jesuit was to be lived. While some religious groups in the Catholic church have limits on the works they take on, the Society of Jesus encourages its members to follow their interest and talents and the needs of the times into a whole range of ministries – as theologians, missionaries, retreat directors, teachers, artists, writers, musicians, counselors, scientists, and pastors – to bring glory to God in all areas of human endeavor. This is in line with the crowning contemplation of Ignatius' Spiritual Exercises through which Jesuits learn to find God in all things (#236). As Arrupe's biographer said of him, he \"saw the hand of God in everything.\"\n\nArrupe warned of repeating the answers of yesterday for tomorrow's problems, saying: \"If we speak a language no longer appropriate to the hearts of people, we speak only to ourselves because no one will listen to us or try to understand what we say.\" Arrupe was \"hailed as a prophet of our time,\" not unlike Jesuit Pope Francis who was in theological studies, learning, when Arrupe became Superior General and began speaking his \"prophetic\" words. The Union of Superior Generals of religious, seeing Arrupe as the right man for our time, elected him five times as their president.\n\nAt the thirty-second General Congregation which convened in 1975, Arrupe's dream of working for the poor was crystallised in the document \"Our Mission Today: the Service of Faith and the Promotion of Justice.\" It stated: \"Our faith in Jesus Christ and our mission to proclaim the Gospel demand of us a commitment to promote justice and enter into solidarity with the voiceless and the powerless.\" Thus, the decree basically defined all the work of the Jesuits as having an essential focus on the promotion of social justice as well as the Catholic faith. Arrupe was keenly aware that in the political climate of the 1970s, the Jesuits’ commitment to working for social justice would bring great hardship and suffering, particularly in those Latin American countries ruled by military juntas.\n\nIn a speech to European educators Arrupe made it clear where he stood on matters of faith and justice, saying: \"I take very seriously the words of Gandhi, 'I love Christ but I despise Christians because they do not live as Christ lived.' Without a doubt Christian love of neighbor entails a duty to care for the wounds of those that have fallen victim to robbers and are left bleeding by the wayside.\" In the late 1960s and into the 1980s some theologians in Latin America became increasingly involved in the political sphere, adopting Marxist rhetoric. Many Jesuits were at the forefront of the movement which was called liberation theology and concentrated on seeing Christ as the liberator not only from sin but from all forms of oppression. In its extreme manifestations, liberation theology seemed to subordinate the message of the Gospel to political revolution, with a wholesale acceptance of Marxism. But Arrupe's strong support for relieving the burden of the poor in Latin America enables one to see his \"cautionary statements about liberation theology... as efforts to impose self-discipline to fend off more severe sanctions from outside the order.\"\n\nOn 20 June 1977 the White Warriors Union death squad threatened to kill all 47 Jesuits serving in El Salvador unless they abandoned their work with the poor and left the country within a month. After consulting with the Jesuit community in El Salvador, Arrupe replied \"They may end up as martyrs, but my priests are not going to leave because they are with the people.\" A few months earlier, Jesuit Father Rutilio Grande, a proponent of liberation theology, was assassinated in El Salvador. On 16 November 1989, six Jesuits (Ignacio Ellacuría, Armando Lopez, Joaquin Lopez y Lopez, Ignacio Martín-Baró, Segundo Montes and Juan Ramon Moreno, along with their housekeeper (Julia Elba Ramos) and her daughter (Celina), would be murdered at the Jesuit University of Central America. Others also suffered martyrdom: the chief bishop in El Salvador Archbishop Óscar Romero (though conservative in respect to religion) was gunned down whilst celebrating the Eucharist on 24 March 1980. Lay missionary Jean Donovan, Ursuline sister Dorothy Kazel and Maryknoll sisters Maura Clarke and Ita Ford were beaten, raped and murdered by non-uniformed members of the Salvadoran National Guard on 2 December 1980. They joined some 75,000 Salvadorans who were killed during this troubled period. All the while, Arrupe continued to support and pray for those people who were willing to lay down their lives to help the poor initiate change.\n\nTouched by the plight of the \"Vietnamese boat people\" in 1979, Pedro Arrupe sent cable messages to some 20 Jesuit major superiors throughout the world sharing his distress at the suffering of these people. He asked them what they could do to help bring relief to refugees and displaced persons in their own regions. He received a positive response, with numerous offers of personnel, medicine, and funding. The next year in 1980 Arrupe founded the Jesuit Refugee Service to coordinate the Society's refugee work. In a speech launching the service he said \"Saint Ignatius called us to go anywhere where we are most needed for the greater glory of God. The spiritual as well as the material need of more than 16 million refugees throughout the world today could scarcely be greater. God is calling us through these helpless people.\" In 2017 JRS listed 47 countries where its 10 regional offices were currently serving nearly 950,000 individuals. Over the years JRS had served an estimated 40 million refugees.\n\nOn 7 August 1981, after a long and tiring trip throughout the Far East, Arrupe suffered a stroke just after his aeroplane landed at Rome's Fiumicino Airport. He was paralysed on his right side and was able to speak only a few words. This ability gradually deteriorated until he was completely mute. From that time on he lived in the infirmary at the Jesuit headquarters in Rome. He was the first Jesuit Superior-General to resign instead of remaining in office until his death. Pope John Paul II appointed Paolo Dezza as his personal delegate and interim Father General of the Society, passing over Arrupe's own choice (his vicar general). There was a wave of resentment in the Society as this was seen as unwarranted papal interference in Jesuit affairs. For his part, Arrupe never expressed any disagreement or resentment. In 1983, Dezza called the thirty-third General Congregation to deal with the resignation of Arrupe and the election of a successor. Arrupe's resignation was accepted on 3 September 1983 during the Congregation and it proceeded to elect Peter Hans Kolvenbach as Father General. During the opening Session of the Congregation, Arrupe was wheeled into the hall, and a prayer which he had written was read aloud:\nDuring his ten years in the infirmary, praying for and with the Society, Arrupe received many and frequent well-wishers, including Pope John Paul II. Arrupe had earlier expressed what some regard as the key to his life: \"Nowadays the world does not need words but lives that cannot be explained except through faith and love for Christ's poor.\"\n\nArrupe died on 5 February 1991. His funeral was held in the Church of the Gesu, Rome, and was attended by crowds that filled the piazza outside the church. Also in attendance were 10 cardinals, 20 bishops, Giulio Andreotti the Prime Minister of Italy, as well as other religious and civil dignitaries. His body, first interred in the Jesuit mausoleum at Campo Verano, was brought back into the Church of the Gesù where it lies in a side chapel.\n\nOn 11 July 2018, the Father General of the Society of Jesus, Arturo Sosa, announced the beginning of the process for his beatification. By 14 November 2018 a website was established with the life, testimonials, and archive on Pedro Arrupe. \n\nNumerous buildings, schools and Jesuit communities have been named after Pedro Arrupe. They include:\n\n"}
{"id": "59041435", "url": "https://en.wikipedia.org/wiki?curid=59041435", "title": "Pelvic massage", "text": "Pelvic massage\n\nPelvic massage is a gynecological treatment first recorded as being used by doctors in the 19th century. An early practitioner was Thure Brandt, whose method was described in the \"New York Medical Journal\" and the \"Journal of the American Medical Association\".\n\n"}
{"id": "20330732", "url": "https://en.wikipedia.org/wiki?curid=20330732", "title": "Permanent Representative of Croatia to the United Nations", "text": "Permanent Representative of Croatia to the United Nations\n\nThe Permanent Representative of Croatia to the United Nations is Croatia's foremost diplomatic representative to the United Nations. The position of permanent representative holds the equivalent rank to that of an ambassador and is appointed by President of Croatia.\n\n\n"}
{"id": "18661130", "url": "https://en.wikipedia.org/wiki?curid=18661130", "title": "Public Employees Federation", "text": "Public Employees Federation\n\nThe Public Employees Federation (PEF) is an American union representing 54,000 professional, scientific, and technical public employees in the state of New York. The union is one of the largest local white-collar unions in the United States and is New York's second-largest state-employee union. PEF also represents employees who work in private-sector jobs and local government agencies. The union publishes \"The Communicator\", online newsletter with a 2007 distribution of 70,000, on a monthly basis.\n\nAccording to PEF's Department of Labor records, the union is composed of three categories of members: \"administrative,\" \"institutional,\" and \"private/public sector.\" Of the total membership, these comprise around 69%, 28% and 3%, or 35,088, 14,065, and 1,443 members, respectively. The first two of these classifications cover two types of labor in \"the Professional, Technical, and Scientific Titles [...] as designated by NYS and Civil Service.\" The third, smallest, portion covers several other employers. PEF contracts also cover some non-members, known as agency fee payers, which number comparatively about one twentieth of the size of the union's membership, or 2,790 non-members.\n\nIn 1971, 61-year-old George Hardy was elected president of the Service Employees International Union (SEIU). Under Hardy, SEIU's health care and public employee divisions saw rapid growth. Much of the membership growth, however, came through affiliation rather than new member organizing. Hardy viewed the fast-growing American Federation of State, County and Municipal Employees (AFSCME) as SEIU's chief competitor. AFSCME had grown from a mere 100,000 members in 1951 to 500,000 members in 1972, and had elected a dynamic and aggressive new leader, 45-year-old Jerry Wurf, in 1964. Not only was AFSCME's growth substantial, its demographics matched those of SEIU's: At least two-thirds of the rival union's members were blue-collar workers, and a fifth of them worked in hospitals and nursing homes. To counter AFSCME's rapid growth, Hardy adopted a strategy of affiliating existing unions rather than organizing unorganized workers. Between 1971 and 1980, SEIU affiliated 22 independent unions. Merger and affiliation accounted for 230,000 new members from 1971 to 1985, and virtually all of the union's growth from 1980 to 1984.\n\nOne of SEIU's major growth spurts came in 1978, when it raided the Civil Service Employees Association (CSEA). In existence since 1910, CSEA had won representation rights for New York State's 140,000 public employees after the state passed a public employee collective bargaining law in 1968. Structured like an association rather than a union, CSEA hesitated to engage in militant labor action or strike, and yet it had a rocky relationship with the state: The union struck for two days at the beginning of April 1972 and won a 5.5 percent pay hike. But the strike and dissatisfaction with CSEA's leadership led some CSEA members to ask for representation by SEIU. With Hardy's strong backing, the newly formed union was able to gather enough signatures on petitions to trigger a representational vote in two of the four units where workers were represented by CSEA, but SEIU lost the vote by a 3-to-1 margin in December 1972. A second strike planned by CSEA leaders was called off after delegates overwhelmingly repudiated a strike resolution supported by the union's leaders. The internal strife led SEIU to once again challenge CSEA for a large unit of New York State public employees. In an election held December 5, 1975, an SEIU-led coalition which included the American Federation of Teachers (AFT), the Laborers' International Union of North America, the International Brotherhood of Teamsters, and several building trades unions was defeated by CSEA, 10,858 to 10,348 with 1,015 voting for neither union. With neither side winning a majority, a second election was held the first week of February 1976, which CSEA won (14,321 to 10,184).\n\nBut Hardy continued to raid CSEA. CSEA leaders initially sought protection by affiliating with AFSCME. Article 20 of the AFL-CIO constitution prohibits affiliates from raiding one another's members, and an affiliation with AFSCME would have won CSEA relief from the raids. But CSEA delegates formally barred their leaders from seeking an affiliation with AFSCME in March 1976. CSEA's contract with the state of New York expired in 1977. Although CSEA leaders once more proposed a strike, the union settled for a 14 percent pay raise in April 1977. Hardy, convinced SEIU could successfully raid CSEA, conducted secret polls which showed that deep unrest in the professional, scientific, and technical (PS&T) unit. Working only with the AFT, SEIU once more obtained enough petitions to challenge CSEA representation in the PS&T unit. The raid was successful, and the coalition (known as the Public Employees Federation) won, 15,062 to 12,259. Hardy and AFT leader Albert Shanker hoped to raid CSEA further, but CSEA affiliated with AFSMCE on April 21, 1978. The affiliation made AFSCME the largest affiliate in the AFL-CIO.\n\nCSEA challenged the SEIU/AFT coalition's victory, however. CSEA attorneys alleged that nearly 5,000 of the signatures on the petition forcing an election were fraudulent. A New York Supreme Court (the state's trial court of general jurisdiction) initially dismissed the suit, but it was reinstated by a state appellate court. As the lawsuit progressed, CSEA won a new three-year contract which included a 7 percent pay hike in the first year. But the new union, now called the Public Employees Federation, ultimately prevailed in the New York Court of Appeals (the highest court in the state of New York) on March 28, 1979. PEF subsequently negotiated a controversial contract which gave union members a 36 percent pay increase over three years. Submitted to the members without the approval of PEF's executive council, the contract was overwhelmingly approved by PEF members on December 6, 1979.\n\nPEF's first president, John J. Kraemer, served a single, turbulent term in office. He was accused of being a \"no-show\" employee at his previous position with the New York State Department of Labor, but was exonerated of the charges. He also had been accused and found innocent of being paid a salary from both PEF and state. As his legal troubles continued, Kraemer focused on negotiating the union's second contract. Pensions were a major issue for the union. In 1976, the state enacted a new pension plan under which state employees paid income taxes on their mandatory contribution to the state pension plan, which PEF claimed forced workers to pay taxes on income they may never receive. Although the agreement ratified in March 1982 did not address the pension issue, the contract negotiated by Kraemer won pay raises of 9 percent the first year and 8 percent the next two years in exchange for a reduction in the number of sick days given to employees.\n\nKraemer lost re-election in 1982 to Elizabeth Hoke. The 1,100-member Statewide Coalition for a Democratic Union (SCDU), at the time PEF's only organized \"political party,\" had formed to challenge Kraemer and support Hoke. The election was a bitter one, with Hoke accusing Kraemer of poor leadership.\n\nWhen Hoke assumed the presidency, she found the union was more than $400,000 in debt. An investigation found that Kraemer had embezzled funds from the union. Kraemer pleaded guilty to the charges in early 1987.\n\nHoke's presidency was in some ways dissimilar to Kraemer's. Unlike Kraemer, Hoke took a low-key approach to the PEF presidency, rarely seeking the media spotlight or public attention. But her presidency suffered several scandals as well. In 1984, Hoke revoked the union leave of PEF's three statewide vice presidents, a move which was very controversial among PEF members. Later that year, she was accused of using her PEF credit card for personal expenses. Hoke also sued to sever PEF's dual affiliation with the AFT and SEIU, claiming the two unions held too much power over PEF and provided little services in return. The suit was unsuccessful.\n\nContract negotiations in 1985 were particularly contentious. PEF was especially critical of a state proposal to restructure the state employee health insurance program. Mediators had to be called in to help settle the contract. PEF settled for 5 percent pay raises in each of the contract's three years and an accidental-death benefit. Hoke failed to win re-election in 1985 due to member dissatisfaction with 1985 contract. SCDU withdrew its support for Hoke and actively supported challenger Rand Condell.\n\nRand Condell struggled to bring some organizational stability to PEF. In 1986, he settled a lawsuit against PEF by the New York State United Teachers (NYSUT) and the AFT. NYSUT and the AFT had claimed that PEF had underpaid dues for half its membership since its inception, leading to a $10 million to $12 million underpayment. In the settlement, PEF withdrew as an affiliate of NYSUT (AFT's state federation in New York) and the AFT agreed to reimburse NYSUT for the services NYSUT had rendered to PEF. In return, PEF agreed to pay increase per capita dues payments for half its members by 71 percent (to $72 from $42) and remit the higher dues payments to the AFT. The NYSUT disaffiliation saved PEF $3.5 million a year, but increased PEF's dues to the AFT by $600,000 a year.\n\nTo cover the cost of the higher payments to the AFT, Condell sought a large dues increase from PEF members. Condell proposed raising dues on a sliding scale, with its lowest-paid members incurring a 14 percent dues increase while its highest-paid members saw a 55 percent dues increase. The dues hikes would be the first since the last year of Kraemer's presidency. Although Condell expected easy passage of the dues hike, the proposal did not win the 60 percent majority needed at the PEF convention in October 1986. Condell immediately resubmitted the dues proposal to members two days later, and it easily passed (leading to an average increase of $4.08 per member per month, giving the union about $2.8 million more each year). The extra dues allowed PEF to build a new headquarters in Latham, New York.\n\nDuring his first term in office, Condell fought the state on a number of issues. The need for higher pensions continued to rank high on the union's agenda. The union also fought large layoffs of state workers, particularly at the New York State Department of Labor. But much of the union's attention was focused on a major battle in 1987 over pay equity. The governor had proposed and the state legislature had approved a plan to give more than 42,600 state workers (about 5,000 of whom were PEF members) retroactive pay increases to make up for disparities with private-sector pay, lower wages given to women, and work in hazardous occupations. PEF filed a grievance against the pay plan, arguing that it downgraded some of the occupational titles of its members. PEF reacted angrily when the pay equity increase subsequently went through for all state workers except those belonging to PEF. Condell then negotiated an agreement preventing any job title downgrades, and the pay increase for PEF members went through in September 1987.\n\nAs Condell's first term ended, he promised to push for \"substantial\" pay raises in the union's upcoming contract negotiations even as his opponents attacked him for concentrating authority in staff hands and for poor leadership. Nonetheless, he was challenged for the SCDU endorsement by Michael Keenan, president of PEF's largest division. Condell defeated Keenan, 388 to 275. Nonetheless, a new political party, the Committee for Independent Officers, arose and successfully contended for four of the six seats for state vice president, regional coordinator, and trustee (including among its winning candidates future PEF presidents Howard Shafer and Roger Benson). To firm up his political position, Condell called for a two- rather than three-year contract, with a 7 percent pay rise in each year. Even when CSEA settled for a three-year agreement with salary increases of 5 percent, 5.5 percent, and 5.5 percent in each of its three years, Condell continued to push for 7 percent. But health insurance, not pay, ended up being the biggest stumbling block. The state declared an impasse in mid June (10 weeks after PEF's contract had expired), and mediators were called in. Without the mediators' help, however, Condell reached a three-year agreement on July 11 with the same pay structure achieved by CSEA and no improvements in health benefits.\n\nOn July 20, 1988, PEF won its first private-sector representation election (for workers at the New York City branch of Narcotic and Drug Research Inc.—a contractor for the state).\n\nCondell barely survived a serious political challenge to his presidency in 1989. PEF spent much of the year fighting layoffs. Convinced that PEF would be fighting layoffs the following year as well, Condell proposed raising dues 26.6 percent ($5.28 a month) to build a public relations and legal war chest. But PEF leaders balked at submitting the dues increase to the membership. PEF's 127-member executive board refused to recommend Condell's dues hike to the membership, but agreed to submit the plan to a vote anyway. The leadership of PEF's Capitol District (its largest region) floated their own plan for a dues increase at a much lower level, and observers concluded that if Condell lost the dues vote at the upcoming PEF convention in October he would probably not be able to win re-election in 1991. PEF members did indeed reject Condell's proposal for a dues increase (twice), but also refused to approval six other plans for a dues increase offered by leaders of the Capitol District as well as others. After extensive parliamentary maneuvering (which some PEF members claimed was illegal), Condell was able to win approval of his original dues proposal.\n\nCondell's support within the union evaporated throughout 1990, and Condell fought the state over early retirement, hiring freezes, large layoffs, furloughs, and a state plan which withheld a week's pay from workers until they retired. In this difficult employment environment, the PEF contract expired. Negotiations with the state stalemated in March 1991, the state declared an impasse, and an arbitrator was named in April.\n\nCondell was challenged for the PEF presidency by Howard Shafer. Shafer, supported by the Team for a Stronger Membership caucus, ran a full slate of candidates and accused Condell of poor leadership and embracing Governor Mario Cuomo too strongly. The election was a bitter one, and Shafer contended Condell was using the union's monthly newsmagazine to promote his candidcacy On June 26, 1991, after record turnout, Shafer defeated Condell 3 to 1 (12,948 to 7,963, a margin of victory that surprised both candidates), and Shafer's entire ticket was swept into office.\n\nScandal struck the union again in Condell's final days in office. Condell signed an agreement which would give his senior aides lucrative severance payments worth thousands of dollars each if they were fired by Shafer. After a half hour of debate, the PEF executive board overturned the severance agreements on Shafer's first day in office.\n\nAt first, the expired contract Shafer inherited did not seem an intractable problem. In December 1991, PEF members ratified a contractual change to their health plan which was seen as a referendum on Shafer's leadership. But negotiations for the expiring PEF contract soon broke down, a legislative fact-finding panel was imposed on the talks, and the state proposed eliminating nearly 14,000 public sector jobs. Finally, the governor set a June 25 deadline for resolving any contract talks. PEF held out. But when other unions settled their contracts, PEF wanted the same deal and didn't get it. The state legislature adjourned without enacting any PEF contract, although it was on the verge of passing a law requiring binding arbitration between the state and PEF. The lack of a contract created a crisis for many PEF members. Nearly 153,000 PEF workers and their family members lost their prescription drug, dental care, and vision care benefits in September 1992. The governor urged both sides to bargain as the benefits crisis worsened, although a state judge later ordered the benefits restored through the end of calendar year 1992.\n\nAs the state laid off public workers, PEF's membership dropped from 59,000 to 55,000 members, depriving the union of $1 million in dues revenue. Vacant positions on PEF's staff were eliminated or went unfilled (angering members, who felt the brunt of the grievance and service cuts), and officers took salary cuts. PEF members accused Shafer of playing politics with the staff cuts by jettisoning staff positions filled by his political opponents, and the PEF executive board retaliated by dismissing Roger Benson (one of Shafer's closest aides). The internal dissent became so bad that alleged assaults, racially inflammatory fliers, and accusations of financial fraud occurred at the SEIU Convention which PEF delegates attended in May 1992. Some PEF members began circulating decertification petitions, and Shafer's political opponents formed a new caucus (Members United for a Responsible Union) to run a slate of candidates against him in 1994.\n\nThe bargaining atmosphere deteriorated throughout the remainder of 1992. The state's chief negotiator said he would wait for the legislative fact-finding panel's recommendation, Shafer implied he might oppose a proposed bond measure which would help fund state jobs, and Shafer accused the governor of releasing private confidential negotiating information to PEF members without the union's consent. At PEF's convention in October 1992, Members United for a Responsible Union leafletted against Shafer, accused him of neglecting members' needs and trying to curry favor with the AFT. Although the legislature passed a mandatory binding arbitration bill, the governor vetoed the legislation. Now looking at two years without a new contract, Shafer hired Theodore W. Kheel, a well-known labor negotiator, to help the union win a new pact.\n\nPEF reached a new contract with the state in March 1993. Although the state's chief negotiation withdrew the state's last contract offer at the end of February, the governor personally put it back on the table. Shafer quickly agreed to the pact, which included a 9.5 percent salary increase over four years that was retroactive to April 1, 1991; moved PEF members into the state's health insurance pool; and ended PEF's lawsuit over the state's decision to defer a week's pay until each member retired. Although the PEF executive board voted to recommend the contract to PEF's members, those who voted \"no\" on the pact argued that PEF had achieved less than other unions, that the deal traded concessions for pay increases, and that the money spent on Kheel's consulting contract had gotten the union nothing better than what had been offered months before. The board meeting was a raucous one, with alleged physical confrontations, a \"Dump Shafer\" movement hanging banners near the entrance, rumors of decertification, and proposals for PEF to abandon its independence and join either SEIU or AFT. Members of PEF voted 28,774 to 7,281 to ratify the new four-year contract on May 12, 1993.\n\nShafer was defeated for re-election as PEF president by James Sheedy in June 1994. Although Shafer and Sheedy had originally been on the same political slate three years earlier, the relationship between the two men had deteriorated into a chilly civility in which they communicated with one another largely via memo (despite having offices next door to one another). The margin of victory was 388 votes, the slimmest margin in the union's 15-year history. Sheedy's entire slate also narrowly edged out the Shafer slate's candidates.\n\nSheedy spent much of his first two years in office as his predecessors did—fighting large layoffs of state workers. Governor George Pataki vetoed legislation improving pensions, threatened to shut down state government and furlough all non-essential workers if the legislature didn't approve his budget, attempted to close state-run health care facilities, and cut more than 5,500 state jobs. In this difficult negotiating climate, Sheedy re-negotiated PEF's expiring contract in April 1995. He agreed to the same financial package won by CSEA a month earlier: A four-year contract with a 3.5 percent salary increase in 1997 and 1998, and one-time bonuses in 1996 and 1997; a change in civil service definitions which would permit PEF workers to transfer more easily to other jobs and retain their salary levels; and no expiration date for the union's benefit packages. Additional job cuts occurred in 1996 and 1997, totalling 20,000 state workers. The state offered early retirement again to many employees. When the state pension fund showed a surplus, Sheedy found himself caught between two opposing factions of PEF members: Use the funds to lower pension contribution costs from current members, or give the surplus to retiree members as a cost-of-living increase.\n\nSheedy was more successful on other issues. He signed the union's first agreement with the state to provide domestic partner benefits in September 1994. He fiercely fought a move to consolidate state information technology workers at sites the union felt were hazardous. PEF also won a federal lawsuit requiring the state to pay millions of dollars in overtime to PEF members, and reinstated the lawsuit in state court after the state appealed.\n\nSheedy also undertook the union's first large-scale organizing campaigns since its formation. AFT, one of PEF's parent unions, assigned a full-time national organizer to help PEF organize health care workers in the private sector who worked for potential state contractors. But this plan backfired politically. In 1996, PEF won an election for 42 paraprofessional health care workers working for a private contractor at the Coxsackie Correctional Facility. This organizing drive was highly criticized by Sheedy's political opponents, who claimed the union's executive board did not approve the organizing effort and who argued that PEF should only be organizing professional (not paraprofessional) workers.\n\nSheedy also fought openly with the PEF staff union. Ninety-six of PEF's 120 staff belonged to Local 9265 of the United Steelworkers of America and had been working without a contract for nine months by March 1996. The staff union complained that PEF refused to negotiate over layoffs and downsizing, demanded a 10 percent pay raise (with differential pay for downstate workers), and several position upgrades. Roger Benson, former chief of staff under PEF President Howard Shafer, supported the staff union publicly and strongly criticized Sheedy for his poor labor relations. PEF and its staff union finally settled their contract dispute in June 1996. The staff union won 3.5 percent pay increases in 1998 and 1999 and lump-sum bonuses paid in 1996 and 1997, enhancements to the dental plan, and concessions on the prescription drug plan and seniority rights.\n\nSheedy's re-election campaign was a difficult, and ultimately unsuccessful, one. Beginning in the spring of 1996, Roger Benson began putting together a statewide organization (\"Members First\") and publishing an alternative newsletter. Benson put together a full slate of officers and formally launched his campaign at PEF's October 1996 convention. Benson announced a four-part platform: 1) Establishment of a PEF department focused on protecting employment security; 2) Budgeting substantial resources to enforce the Civil Service merit system; 3) Employment of a full-time professional contract negotiator; and 4) Elimination of officer perks. A third candidate, Jim Israel (a PEF shop steward), entered the race in January 1997 but withdrew when he was unable to obtain enough signatures to secure his nomination. Benson's slate of candidates included Jane Hallum (a computer programmer) for secretary-treasurer and future PEF president Kenneth Brynien as an executive board member. Sheedy and Benson battled over the state pension surplus, and engage in a letter-to-the-editor war in the newspapers. Benson promised not to raise dues and re-open union offices, while Sheedy admitted a dues hike might be necessary in 1999. In June 1997, Benson defeated Sheedy by a vote of 11,407 to 8,956.\n\nRoger Benson made immediate changes in the way PEF conducted its business. He dismissed six staff members and returned to having two administrators share duties over the daily operation of the union. He also named two close associates to the staff, and criticized the decision of the Sheedy-led executive board for enhancing the staff's severance packages. Local newspapers called the changes \"bloodletting\", and reported that additional layoffs were likely to come.\n\nAmong PEF's major political initiatives at this time were a cost-of-living increase for worker pensions. Benson also said he would seek improvements to job security; accrual (rather than use-or-lose) for overtime, sick leave, and vacation; eliminate tiers in the pension plan; seek an end to penalties for early retirement; new workplace safety protections; an increase in the size of the state workforce; and new restrictions on contracting out. The state replied that it would seek a four-year wage freeze. Angered by the state's response in a time of budget surpluses, Benson led PEF workers in an extensive lobbying effort. He also said PEF would seek a three-year rather than four-year contract, and 5 percent per year wage increases. Benson also replaced the union's top negotiator in order to adopt a more aggressive stand with the state. The state countered with a 3 percent per year salary increase over four years, coupled with new restrictions on time off for union business, higher health care costs, and new worktime reporting requirements (all of which PEF rejected). At a rally at the state capital on January 5, 2000, some 5,000 (state estimate) to 25,000 (PEF estimate) workers peacefully confronted 25 Albany police and 300 New York State troopers. PEF revised its wage offer to 12 percent over three years. Benson accused the state in March 2000 of dragging out the negotiations, and began a statewide radio advertising campaign against the governor. In April, PEF accepted a contract with the New York State Canal Corporation with a 3 percent per year salary hike. Days later, after another state union accepted a contract containing a 13.6 percent raise over four years, about 2,000 PEF members held a noisy rally outside the governor's offices demanding faster negotiations. Two weeks afterward, PEF agreed to end its advertising campaign and rallies as a spur to negotiations. A week later, Governor George Pataki agreed to wage and pension COLAs. A tentative agreement reached on June 10, 2000, incorporated a 13 percent wage hike over four years, rejected the new working time data collection methods, and imposed slight increases in member health care payments. Union members approved the contract by a vote of 33,899 to 2,876.\n\nBenson revealed a financial scandal in the union during his first term in office. In July 1999, PEF sued former president James Sheedy and other former officers for allegedly embezzling more than $62,000 from the union. The union's lawsuit said the officers reimbursed themselves financially for sick leave they never took. But the PEF executive board retroactively approved the sick leave buybacks in a private meeting in August 1999, forcing Benson to drop the lawsuit. Nonetheless, former PEF Secretary-Treasurer Patricia Ford was convicted of bribery in June 2003.\n\nBenson was re-elected without opposition in late 2000. He and his slate of officers were easily renominated, while an opponent received only 17 of the necessary 4,998 signatures needed to run for office. During Benson's second term, several PEF members died during the September 11 attacks on New York City. Of the 300 PEF members who worked in the World Trade Center, 34 were killed in the attack.\n\nOne of PEF's larger campaigns during Benson's time in office was fighting health care cutbacks in New York state. For several years, the union protested against staff layoffs and the closure of hospitals and other health care facilities. PEF also sought increases in the number of health care workers on staff, an end to mandatory overtime, and minimum worker-to-patient staffing ratios.\n\nBenson was re-elected without opposition to a third term in 2003, the first time any PEF president had been elected to a third term.\n\nBenson immediately entered into negotiations for a new contract after his re-election. Initially, PEF had hopes for easier contract negotiations after Governor Pataki fulfilled a promise to give PEF members three additional days of sick leave per year. But after working without a contract for a year, PEF members found that Pataki proposed contract concessions in order to bring the state's budget into balance. In March 2004, after CSEA agreed to a four-year contract with an average 2.85 percent wage increase each year, Benson denounced Pataki's offer of 1 percent per year to PEF members and a cap on state contributions to the employee pension fund. Once again, methods for accounting for working time became a major sticking point in the negotiations, with Benson characterizing this as a \"deal-breaker.\" But in July 2004, PEF agreed to a new four-year contract which included salary increases of $800 in the first year; 2.5 percent, 2.75 percent, and 3 percent salary increases in the last three years; and a new \"locality pay\" increase for workers in the mid-Hudson Valley region (where the cost of living was significantly higher than surrounding areas).\n\nIn February 2005, Benson declined to run for a fourth term in 2006.\n\nOne of the final achievements of the Benson presidency was enactment of legislation requiring the state to disclose the number and amount of money spent on private contractors. PEF began its campaign in the fall of 2005, and Governor Pataki signed the legislation in March 2006.\n\nKenneth Brynien was elected PEF president over Michael Del Piano on June 27, 2006, by a vote of 7,874 to 7,024 (a margin of 850 votes, or 5.8 percent). Brynien said a major goal of his presidency would be to enhance PEF's legislative efforts in the state capital.\n\nBrynien and the union confronted a state proposal to close or merge several state-owned hospitals and other health care facilities during his first year in office. A state commission first proposed the plan in November 2006. Brynien and PEF strongly opposed the plan, claiming it would harm patients and lead to lower levels of care. PEF's parent union, SEIU, said it would not oppose the plan. PEF began a series of public protests and a legislative lobbying effort to prevent the closures and mergers. It also sued to prevent the plan from being implemented.\n\nBrynien negotiated a new collective bargaining agreement for PEF in 2008. Negotiations for the new contract were short and generated almost no public notice. The four-year contract's terms, which were retroactive to April 2007 (the date the old agreement expired), included an average 4 percent wage increase per year, higher pay for employees working in or near New York City, new health insurance benefits, and improved educational benefits. About two-thirds of PEF members voted in contract approval balloting, with the pact receiving 97 approval for those who did vote.\n\nDuring Brynien's first term as president, PEF also won a long-sought ban on mandatory overtime. Legislation on the issue was introduced in May 2007, and on June 18, 2008, Governor David Paterson signed into law a ban on mandatory overtime in state facilities.\n\nThree months later, PEF successfully lobbied the state legislature to provide for permanent collection of union dues and a \"fair share\" provision in the dues structure. Under prior New York State law, the state was required to collect dues on PEF's behalf (through the state's payroll system) and forward these monies to the union. Non-members were not required to pay dues to the union, even though the union was required by law to represent these workers. This law required renewal every two years. PEF had long sought a permanent version of the law, one which enacted a \"fair share\" provision requiring non-members to pay a portion of dues (for the services they received). The state legislature finally passed just such a law in July 2008, and it was signed into law by Governor Paterson.\n\nPEF also became embroiled in major battles with Governor Paterson over the state budget, which occupied much of the remainder of Brynien's first term and the first few years of his second. When the late-2000s recession severely depressed New York state tax revenues, Paterson demanded that PEF and other state employee unions re-open their contracts and adopt a wage freeze and other concessions to help the state balance its budget. PEF refused. PEF countered by suggesting a program of early retirement, which lawmakers began discussing. PEF also demanded that the state cut the number of independent contractors working for the state, arguing that New York could save up to $700 million by reducing the number of contractors or reducing payments to them. PEF also urged the state to adopt higher taxes on the very wealthy and for-profit health maintenance organizations, which the legislature did. Governor Paterson, determined to achieve spending cuts, ordered the layoff of more than 8,900 state workers on March 24, 2009. Brynien and other PEF leaders were deeply angered by Paterson's proposal. Led by PEF, the state's public employee unions produced television commercials and newspaper advertisements depicting Paterson with his fingers in his ears and unwilling to listen to voters. \"The New York Times\" said that attacks were some \"of the nastiest and most personal against a governor in memory ... rare even by Albany's relaxed standards of political decorum.\" Brynien said Paterson should be faulted for forcing the unions into such an aggressive stand. Brynien also announced PEF would sue the state to prevent the layoffs from occurring. In response, Paterson said he would not lay off any workers if the state's unions agreed to a pension plan (\"Tier V\") for new workers that would provide much lower benefits. PEF reached an agreement with the governor under which Paterson agreed not to lay off workers in exchange for a $20,000 bonus to 4,000 highly paid workers if they retired early within the next year; the abolition of 2,500 vacant jobs; the creation of a new tier in the pension system which would save $440 million over two years; and the introduction of a plan for workers to voluntarily cut back their working hours.\n\nBrynien was re-elected as PEF's president in June 2009 after no opposition candidate emerged.\n\nIn October 2009, PEF also fought a campaign to prevent the state from ordering the mandatory vaccination of thousands of state health care workers against the H1N1 flu virus (popularly known as the \"swine flu\"). The state ordered the mandatory vaccinations on September 30, 2009. Brynien and other PEF leaders demanded that the state make the vaccinations voluntary, arguing that the mass vaccination plan did not provide for exemptions for worker safety, such as pregnant women or those with severe allergies; the vaccine had not yet been properly tested for safety; and the vaccine did not provide enough protection to outweigh the invasion of civil rights. PEF sued, and on October 15 a state court agreed and imposed a temporary injunction preventing implementation of the plan. The state withdrew its plan a week later.\n\nSix months after the pension deal was reached, however, Governor Paterson announced he would seek to prevent PEF members from receiving their scheduled 4 percent salary increase and seek furloughs of state workers to help close yet another budget deficit. Paterson raised the issues of furloughs in mid-August, just two months after the pension deal was reached. PEF countered once again by arguing that the state spent $3 billion a year on 23,000 consultants at a cost that was 62 percent higher than hiring a permanent worker. On April 1, 2010, Paterson demanded that PEF forgo its scheduled wage hike, but PEF refused to do so. About a week later, Paterson withheld the pay increase unilaterally, leading to strong denunciations by the union. Two weeks later, Paterson announced he would seek to furlough half the state's workforce one day a week for the rest of the year in addition to the wage freeze, and the state legislature appeared ready to agree to the plan. PEF began a legislative lobbying effort, but the legislature approved the furloughs. PEF and other unions sued to overturn the pay freeze and furloughs, and a federal district court temporarily prevented the state from implementing the furlough plan on May 11, 2010. The court also ordered the state to restore the wage increase. The court made the injunction permanent about two weeks later.\n\nGovernor Paterson then proposed laying off 10,000 state workers on January 1, 2011 (the day after his no-layoff pledge with the unions expired)—a plan PEF also opposed.\n\nOn June 1, 2010, during the height of the tension created by the fiscal crisis, \"The New York Post\" ran an article revealing that Ken Brynien had enjoyed an increase in salary of $25,000 annually from $112,440 in 2008 to $137,622 in 2010.\n\nOn June 25, 2012, Susan Kent, a credentialing specialist at the New York State Education Department, defeated Ken Brynien, 8,739 to 7,562. Roughly a third of all eligible PEF members cast votes. Carlos Garcia, a member of Kent's \"NY Union Proud\" slate, defeated PEF Secretary-Treasurer Joe Fox, 8,111 to 8,063. A number of NY Union Proud members also won election to the PEF executive board. Kent pledged during the campaign to be tougher in negotiations with the state.\n\nAlthough PEF was politically active in the first eight years of its existence, it was not notably so. That changed in 1986, the first time the Public Employees Federation engaged in an organized, statewide legislative lobbying effort (it sought passage of a \"toxic tort\" bill which would permit individuals harmed by exposure to toxic substances a longer period of time to file a lawsuit to recover damages). PEF also contributed $150,000 to state political campaigns in the first six months of 1986, ranking it among the top PACs in the state. This was more money than PEF had contributed in all of 1984 (the previous election cycle). PEF quickly became noted for the amount of money it spent on election efforts and on campaigns to oppose legislation it disagreed with. In 1987, PEF spent $36,822 on state political party-building efforts, more than any other group in New York State. In 1988, PEF spent $570,841 on political campaigns—behind only the New York State AFL-CIO ($1 million), the Civil Service Employees Association ($704,875), and the Medical Society of the State of New York ($695,275). PEF spent $25,000 on an advertising campaign in the spring of 1990 to fight a plan to privatize state mental health services. In 1991, PEF spent $200,000 on an advertising campaign to defeat reductions in the state workforce and another $150,000 to support incumbents in state legislative election campaigns. It also spent at least $1 million that year on television ads urging the state legislature to pass higher state income and sales taxes. In 1995, PEF ranked third among PACs in spending on state-level elections in New York, pumping $419,928 into these races. In 2006, newly elected PEF President Kenneth Brynien, who had been a PEF vice-president for three years and chairman of PEF's political action committee for nine years, pledged to further boost PEF's political influence.\n\nPEF has also been active in endorsing candidates for political office. But some of these endorsements have proven highly contentious within the union. In 1990, PEF endorsed Mario Cuomo for governor, but the endorsement was bitterly debated within the union and the support PEF pledged to Cuomo's re-election effort was considered \"tepid\". PEF remained neutral in Cuomo's 1994 re-election campaign. Cuomo was defeated for re-election by George Pataki. PEF remained neutral again during Pataki's successful 1998 re-election bid. But in 2002, PEF supported Pataki for election to a third term. According to PEF President Roger Benson, the endorsement was a \"quid pro quo\" for Pataki's promise to add three days of paid sick leave to the union's collective bargaining agreement and for a promise not to lay off any state workers in the following budget year. Some PEF members were deeply angered by the union's endorsement, however, and an internal union poll of the union's health care division showed they overwhelmingly supported Pataki's opponent (New York Comptroller H. Carl McCall). Pro-McCall members of the union submitted a resolution to the union's annual convention which would have rescinded the endorsement. PEF members voted down the resolution on October 8, 2002. In 2006, PEF endorsed New York State Attorney General Eliot Spitzer in his successful run for governor. That same year, Andrew Cuomo ran to replace Spitzer as New York State Attorney General. PEF declined to endorse Cuomo, instead backing New York City Public Advocate Mark J. Green in his unsuccessful bid for that office. On July 21, 2009, PEF leaders indicated they might not support David Paterson in the Democratic primary if he chooses to run for re-election as governor.\n\nThe following is a list of PEF presidents:\n\n"}
{"id": "8713557", "url": "https://en.wikipedia.org/wiki?curid=8713557", "title": "Quantum satis", "text": "Quantum satis\n\nQuantum satis (abbreviation q.s. or Q.S.) is a Latin term meaning the amount which is enough. It has its origins as a quantity specification in medicine and pharmacology, where a similar term \"quantum sufficit\" (\"as much as is sufficient\") has been used (abbreviated Q.S.). \"Quantum satis\" is also used in the same function in food regulations and food safety laws in the European Community (EC/EU).\n\nThe specification of \"quantum satis\" for an ingredient essentially means \"Add as much of this ingredient as is needed to achieve the desired result, but not more.\"\n\nIn food safety regulations in the EU it is a catch-all restriction for artificial food ingredients (especially food additives) which are harmless enough to have no specific quantity restriction.\n\nIt serves to protect consumers from the addition of excessive and unnecessary amounts of such artificial food additives in their foodstuffs and compels producers to:\n\n\nFor example, European Union directive 94/36/EC (which regulates the use of food colors) explains in Article 2 (7): \"In the Annexes to this Directive\" 'quantum satis' \"means that no maximum level is specified. However, coloring matters shall be used according to good manufacturing practice at a level not higher than is necessary to achieve the intended purpose and provided that they do not mislead the customer\". The words \"quantum satis\" are used with reference to a number of substances in the Annexes III and IV to the EU directive 94/36/EC.\n"}
{"id": "58331338", "url": "https://en.wikipedia.org/wiki?curid=58331338", "title": "Rosalind Gibson", "text": "Rosalind Gibson\n\nRosalind Susan Gibson is a New Zealand nutrition academic. She is currently a full professor at the University of Otago.\n\nAfter a 1965 MSc titled \" 'The inter-relationship of vitamins B₆ and E.' \" at the University of California, and a 1979 PhD from University of London titled \" 'Use of hair as a biopsy material for the assessment of trace metal status in Canadian low birthweight infants' \", she moved to the University of Otago, rising to full professor.\n\nIn 2002, Gibson was elected a Fellow of the Royal Society of New Zealand.\n\nGibson was awarded the 2013 Kellogg International Prize in Nutrition.\n\n\n"}
{"id": "46895003", "url": "https://en.wikipedia.org/wiki?curid=46895003", "title": "Sexuality after spinal cord injury", "text": "Sexuality after spinal cord injury\n\nAlthough spinal cord injury (SCI) often causes sexual dysfunction, many people with SCI are able to have satisfying sex lives. Physical limitations acquired from SCI affect sexual function and sexuality in broader areas, which in turn has important effects on quality of life. Damage to the spinal cord impairs its ability to transmit messages between the brain and parts of the body below the level of the lesion. This results in lost or reduced sensation and muscle motion, and affects orgasm, erection, ejaculation, and vaginal lubrication. More indirect causes of sexual dysfunction include pain, weakness, and side effects of medications. Psycho-social causes include depression and altered self-image. Many people with SCI have satisfying sex lives, and many experience sexual arousal and orgasm. People with SCI employ a variety of adaptations to help carry on their sex lives healthily, by focusing on different areas of the body and types of sexual acts. Neural plasticity may account for increases in sensitivity in parts of the body that have not lost sensation, so people often find newly sensitive erotic areas of the skin in erogenous zones or near borders between areas of preserved and lost sensation.\n\nDrugs, devices, surgery, and other interventions exist to help men achieve erection and ejaculation. Although male fertility is reduced, many men with SCI can still father children, particularly with medical interventions. Women's fertility is not usually affected, although precautions must be taken for safe pregnancy and delivery. People with SCI need to take measures during sexual activity to deal with SCI effects such as weakness and movement limitations, and to avoid injuries such as skin damage in areas of reduced sensation. Education and counseling about sexuality is an important part of SCI rehabilitation but is often missing or insufficient. Rehabilitation for children and adolescents aims to promote healthy development of sexuality and includes education for them and their families. Culturally inherited biases and stereotypes negatively affect people with SCI, particularly when held by professional caregivers. Body image and other insecurities affect sexual function, and have profound repercussions on self-esteem and self-concept. SCI causes difficulties in romantic partnerships, due to problems with sexual function and to other stresses introduced by the injury and disability, but many of those with SCI have fulfilling relationships and marriages. Relationships, self-esteem, and reproductive ability are all aspects of sexuality, which encompasses not just sexual practices but a complex array of factors: cultural, social, psychological, and emotional influences.\n\nSexuality is an important part of each person's identity, although some people might have no interest in sex. Sexuality has biological, psychological, emotional, spiritual, social, and cultural aspects. It involves not only sexual behaviors but relationships, self-image, sex drive, reproduction, sexual orientation, and gender expression. Each person's sexuality is influenced by lifelong socialization, in which factors such as religious and cultural background play a part, and is expressed in self-esteem and the beliefs one holds about oneself (identifying as a woman, or as an attractive person).\n\nSCI is extremely disruptive to sexuality, and it most frequently happens to young people, who are at a peak in their sexual and reproductive lives. Yet the importance of sexuality as a part of life is not diminished by a disabling injury. Although for years people with SCI were believed to be asexual, research has shown sexuality to be a high priority for people with SCI and an important aspect of quality of life. In fact, of all abilities they would like to have return, most paraplegics rated sexual function as their top priority, and most tetraplegics rated it second, after hand and arm function. Sexual function has a profound impact on self-esteem and adjustment to life post-injury. People who are able to adapt to their changed bodies and to have satisfying sex lives have better overall quality of life.\n\nSCI usually causes sexual dysfunction, due to problems with sensation and the body's arousal responses. The ability to experience sexual pleasure and orgasm are among the top priorities for sexual rehabilitation among injured people.\n\nMuch research has been done into erection. By two years post-injury, 80% of men recover at least partial erectile function, though many experience problems with the reliability and duration of their erections if they do not use interventions to enhance them. Studies have found that half or up to 65% of men with SCI have orgasms, although the experience may feel different than it did before the injury. Most men say it feels weaker, and takes longer and more stimulation to achieve.\n\nCommon problems women experience post-SCI are pain with intercourse and difficulty achieving orgasm. Around half of women with SCI are able to reach orgasm, usually when their genitals are stimulated. Some women report the sensation of orgasm to be the same as before the injury, and others say the sensation is reduced.\n\nThe severity of the injury is an important aspect in determining how much sexual function returns as a person recovers. According to the American Spinal Injury Association grading scale, an incomplete SCI is one in which some amount of sensation or motor function is preserved in the rectum. This indicates that the brain can still send and receive some messages to the lowest parts of the spinal cord, beyond the damaged area. In people with incomplete injury, some or all of the spinal tracts involved in sexual responses remain intact, allowing, for example, orgasms like those of uninjured people. In men, having an incomplete injury improves chances of being able to achieve erections and orgasms over those with complete injuries.\nEven people with complete SCI, in whom the spinal cord cannot transmit any messages past the level of the lesion, can achieve orgasm. In 1960, in one of the earliest studies to look at orgasm and SCI, the term \"phantom orgasm\" was coined to describe women's perception of orgasmic sensations despite SCI—but subsequent studies have suggested the experience is not merely psychological. Men with complete SCI report sexual sensations at the time of ejaculation, accompanied by physical signs normally found at orgasm, such as increased blood pressure. Women can experience orgasm with vibration to the cervix regardless of level or completeness of injury; the sensation is the same as uninjured women experience.\n\nThe peripheral nerves of the parasympathetic nervous system that carry messages to the brain (afferent nerve fibers) may explain why people with complete SCI feel sexual and climactic sensations. One proposed explanation for orgasm in women despite complete SCI is that the vagus nerve bypasses the spinal cord and carries sensory information from the genitals directly to the brain. Women with complete injuries can achieve sexual arousal and orgasm through stimulation of the clitoris, cervix, or vagina, which are each innervated by different nerve pathways, which suggests that even if SCI interferes with one area, function might be preserved in others. In both injured and uninjured people, the brain is responsible for the way sensations of climax are perceived: the qualitative experiences associated with climax are modulated by the brain, rather than a specific area of the body.\n\nIn addition to completeness of injury, the location of damage on the spinal cord influences how much sexual function is retained or regained after injury. Injuries can occur in the cervical (neck), thoracic (back), lumbar (lower back), or sacral (pelvic) levels. Between each pair of vertebrae, spinal nerves branch off of the spinal cord and carry information to and from specific parts of the body. The location of injury to the spinal cord maps to the body, and the area of skin innervated by a specific spinal nerve, is called a dermatome. All dermatomes below the level of injury to the spinal cord may lose sensation.\n\nAn injury at a lower point on the spine does not necessarily mean better sexual function; for example, people with injuries in the sacral region are less likely to be able to orgasm than those with injuries higher on the spine. Women with injuries above the sacral level have a greater likelihood of orgasm in response to stimulation of the clitoris than those with sacral injuries (59% vs 17%). In men, injuries above the sacral level are associated with better function in terms of erections and ejaculation, and fewer and less severe reports of dysfunction. This may be due to reflexes that do not require input from the brain, which sacral injuries might interrupt.\n\nThe body's physical arousal response (vaginal lubrication and engorgement of the clitoris in women and erection in men) occurs due to two separate pathways which normally work together: psychogenic and reflex. Arousal due to fantasies, visual input, or other mental stimulation is a psychogenic sexual experience, and arousal resulting from physical contact to the genital area is reflexogenic. In psychogenic arousal, messages travel from the brain via the spinal cord to the nerves in the genital area. The psychogenic pathway is served by the spinal cord at levels T11–L2. Thus people injured above the level of the T11 vertebra do not usually experience psychogenic erection or vaginal lubrication, but those with an injury below T12 can. Even without these physical responses, people with SCI often feel aroused, just as uninjured people do. The ability to feel the sensation of a pinprick and light touch in the dermatomes for T11–L2 predicts how well the ability to have psychogenic arousal is preserved in both sexes. Input from the psychogenic pathway is sympathetic, and most of the time it sends inhibitory signals that prevent the physical arousal response; in response to sexual stimulation, excitatory signals are increased and inhibition is reduced. Removing the inhibition that is normally present allows the spinal reflexes that trigger the arousal response to take effect.\n\nThe reflexogenic pathway activates the parasympathetic nervous system in response to the sensation of touch. It is mediated by a reflex arc that goes to the spinal cord (not to the brain) and is served by the sacral segments of the spinal cord at S2–S4. A woman with a spinal cord lesion above T11 may not be able to experience psychogenic vaginal lubrication, but may still have reflex lubrication if her sacral segments are uninjured. Likewise, although a man's ability to get a psychogenic erection when mentally aroused may be impaired after a higher-level SCI, he may still be able to get a reflex or \"spontaneous\" erection. These erections may result in the absence of psychological arousal when the penis is touched or brushed, e.g. by clothing, but they do not last long and are generally lost when the stimulus is removed. Reflex erections may increase in frequency after SCI, due to the loss of inhibitory input from the brain that would suppress the response in an uninjured man. Conversely, an injury below the S1 level impairs reflex erections but not psychogenic erections. People who have some preservation of sensation in the dermatomes at the S4 and S5 levels and display a bulbocavernosus reflex (contraction of the pelvic floor in response to pressure on the clitoris or glans penis) are usually able to experience reflex erections or lubrication. Like other reflexes, reflexive sexual responses may be lost immediately after injury but return over time as the individual recovers from spinal shock.\n\nMost people with SCI have problems with the body's physical sexual arousal response. Problems that result directly from impaired neural transmission are called \"primary sexual dysfunction\". The function of the genitals is almost always affected by SCI, by alteration, reduction, or complete loss of sensation. Neuropathic pain, in which damaged nerve pathways signal pain in the absence of any noxious stimulus, is common after SCI and interferes with sex.\n\nSecondary dysfunction results from factors that follow from the injury, such as loss of bladder and bowel control or impaired movement. The main barrier to sexual activity that people with SCI cite is physical limitation; e.g. balance problems and muscle weakness cause difficulty with positioning. Spasticity, tightening of muscles due to increased muscle tone, is another complication that interferes with sex. Some medications have side effects that impede sexual pleasure or interfere with sexual function: antidepressants, muscle relaxants, sleeping pills and drugs that treat spasticity. Hormonal changes that alter sexual function may take place after SCI; levels of prolactin heighten, women temporarily stop menstruating (amenorrhea), and men experience reduced levels of testosterone. Testosterone deficiency causes reduced libido, increased weakness, fatigue, and failure to respond to erection-enhancing drugs.\n\nTertiary sexual dysfunction results from psychological and social factors. Reduced libido, desire, or experience of arousal could be due to psychological or situational factors such as depression, anxiety, and changes in relationships. Both sexes experience reduced sexual desire after SCI, and almost half of men and almost three quarters of women have trouble becoming psychologically aroused. Depression is the most common cause of problems with arousal in people with SCI. People frequently experience grief and despair initially after the injury. Anxiety and drug and alcohol abuse may increase after discharge from a hospital as new challenges occur, which can exacerbate sexual difficulties. Drug and alcohol abuse increase unhealthy behaviors, straining relationships and social functioning.\n\nSCI can lead to significant insecurities, which have repercussions for sexuality and self-image. SCI often affects body image, either due to the host of changes in the body that affect appearance (e.g. unused muscles in the legs become atrophied), or due to changes in self-perception not directly from physical changes. People frequently find themselves less attractive and expect others not to be attracted to them after SCI. These insecurities cause fear of rejection and deter people from initiating contact or sexual activity or engaging in sex. Feelings of undesirability or worthlessness even lead some to suggest to their partners that they find someone able bodied.\n\nMen with SCI rank the ability to father children among their highest concerns relating to sexuality. Male fertility is reduced after SCI, due to a combination of problems with erections, ejaculation, and quality of the semen. As with other types of sexual response, ejaculation can be psychogenic or reflexogenic, and the level of injury affects a man's ability to experience each type. As many as 95% of men with SCI have problems with ejaculation (anejaculation), possibly due to impaired coordination of input from different parts of the nervous system. Erection, orgasm, and ejaculation can each occur independently, although the ability to ejaculate seems linked to the quality of the erection, and the ability to orgasm is linked to the ejaculation facility. Even men with complete injuries may be able to ejaculate, because other nerves involved in ejaculation can effect the response without input from the spinal cord. In general, the higher the level of injury, the more physical stimulation the man needs to ejaculate. Conversely, premature or spontaneous ejaculation can be a problem for men with injuries at levels T12–L1. It can be severe enough that ejaculation is provoked by thinking a sexual thought, or for no reason at all, and is not accompanied by orgasm.\nMost men have a normal sperm count, but a high proportion of sperm are abnormal; they are less motile and do not survive as well. The reason for these abnormalities is not known, but research points to dysfunction of the seminal vesicles and prostate, which concentrate substances that are toxic to sperm. Cytokines, immune proteins which promote an inflammatory response, are present at higher concentrations in semen of men with SCI, as is platelet-activating factor acetylhydrolase; both are harmful to sperm. Another immune-related response to SCI is the presence of a higher number of white blood cells in the semen.\n\nThe numbers of women with SCI giving birth and having healthy babies are increasing. Around a half to two-thirds of women with SCI report they might want to have children, and 14–20% do get pregnant at least once. Although female fertility is not usually permanently reduced by SCI, there is a stress response that can happen immediately post-injury that alters levels of fertility-related hormones in the body. In about half of women, menstruation stops after the injury but then returns within an average of five months—it returns within a year for a large majority. After menstruation returns, women with SCI become pregnant at a rate close to that of the rest of the population.\nPregnancy is associated with greater-than-normal risks in women with SCI, among them increased risk of deep vein thrombosis, respiratory infection, and urinary tract infection. Considerations exist such as maintaining proper positioning in a wheelchair, prevention of pressure sores, and increased difficulty moving due to weight gain and changes in center of balance. Assistive devices may need to be altered and medications changed.\n\nFor women with injuries above T6, a risk during labor and delivery that threatens both mother and fetus is autonomic dysreflexia, in which the blood pressure increases to dangerous levels high enough to cause potentially deadly stroke. Drugs such as nifedipine and captopril can be used to manage an episode if it occurs, and epidural anesthesia helps although it is not very reliable in women with SCI. Anesthesia is used for labor and delivery even for women without sensation, who may only experience contractions as abdominal discomfort, increased spasticity, and episodes of autonomic dysreflexia. Reduced sensation in the pelvic area means women with SCI usually have less painful delivery; in fact, they may fail to realize when they go into labor. If there are deformities in the pelvis or spine caesarian section may be necessary. Babies of women with SCI are more likely to be born prematurely, and, premature or not, they are more likely to be small for their gestational time.\n\nAlthough erections are not necessary for satisfying sexual encounters, many men see them as important, and treating erectile dysfunction improves their relationships and quality of life. Whatever treatment is used, it works best in combination with talk-oriented therapy to help integrate it into the sex life.\n\nOral medications and mechanical devices are the first choice in treatment because they are less invasive, are often effective, and are well tolerated. Oral medications include sildenafil (Viagra), tadalafil (Cialis), and vardenafil (Levitra).\n\nPenis pumps induce erections without the need for drugs or invasive treatments. To use a pump, the man inserts his penis into a cylinder, then pumps it to create a vacuum which draws blood into the penis, making it erect. He then slides a ring from the outside of the cylinder onto the base of the penis to hold the blood in and maintain the erection. A man who is able to get an erection but has trouble maintaining it for long enough can use a ring by itself. The ring cannot be left on for more than 30 minutes and cannot be used at the same time as anticoagulant medications.\nIf oral medications and mechanical treatments fail, the second choice is local injections: medications such as papaverine and prostaglandin that alter the blood flow and trigger erection are injected into the penis. This method is preferred for its effectiveness, but can cause pain and scarring.\n\nAnother option is to insert a small pellet of medication into the urethra, but this requires higher doses than injections and may not be as effective. Topical medications to dilate the blood vessels have been used, but are not very effective or well tolerated. Electrical stimulation of efferent nerves at the S2 level can be used to trigger an erection that lasts as long as the stimulation does.\n\nSurgical implants, either of flexible rods or inflatable tubes, are reserved for when other methods fail because of the potential for serious complications, which occur in as many as 10% of cases. They carry the risk of eroding penile tissue (breaking through the skin). Although satisfaction among men who use them is high, if they do need to be removed implants make other methods such as injections and vacuum devices unusable due to tissue damage.\n\nIt is also possible for erectile dysfunction to exist not as a direct result of SCI but due to factors such as major depression, diabetes, or drugs such as those taken for spasticity. Finding and treating the root cause may alleviate the problem. For example, men who experience erectile problems as the result of a testosterone deficiency can receive androgen replacement therapy.\n\nWithout medical intervention, the male fertility rate after SCI is 5–14%, but the rate increases with treatments. Even with all available medical interventions, fewer than half of men with SCI can father children. Assisted insemination is usually required. As with erection, therapies used to treat infertility in uninjured men are used for those with SCI.\n\nFor anejaculation in SCI, the first-line method for sperm retrieval is penile vibratory stimulation (PVS). A high-speed vibrator is applied to the glans penis to trigger a reflex that causes ejaculation, usually within a few minutes. Reports of efficacy with PVS range from 15–88%, possibly due to differences in vibrator settings and experience of clinicians, as well as level and completeness of injury. Complete lesions strictly above Onuf's nucleus (S2–S4) are responsive to PVS in 98%, but complete lesions of the S2–S4 segments are not.\n\nIn case of failure with PVS, spermatozoa are sometimes collected by electroejaculation: an electrical probe is inserted into the rectum, where it triggers ejaculation. The success rate is 80–100%, but the technique requires anaesthesia and does not have the potential to be done at home that PVS has. Both PVS and electroejaculation carry a risk of autonomic dysreflexia, so drugs to prevent the condition can be given in advance and blood pressure is monitored throughout the procedures for those who are susceptible. Massage of the prostate gland and seminal vesicles is another method to retrieve stored sperm. If these methods fail to cause ejaculation or do not yield sufficient usable sperm, sperm can be surgically removed by testicular sperm extraction or percutaneous epididymal sperm aspiration. These procedures yield sperm in 86–100% of cases, but nonsurgical treatments are preferred.\n\nPremature or spontaneous ejaculation is treated with antidepressants including selective serotonin reuptake inhibitors, which are known to delay ejaculation as a side effect.\n\nCompared with the options available for treating sexual dysfunction in men (for whom results are concretely observable), those available for women are limited. For example, PDE5 inhibitors, oral medications for treating erectile dysfunction in men, have been tested for their ability to increase sexual responses such as arousal and orgasm in women—but no controlled trials have been done in women with SCI, and trials in other women yielded only inconclusive results. In theory, women's sexual response could be improved using a vacuum device made to draw blood into the clitoris, but few studies on treatments for sexual function in women with SCI have been carried out. There is a particular paucity of information outside the area of reproduction.\n\nCounseling about sex and sexuality by medical professionals, psychologists, social workers, and nurses is a part of most SCI rehabilitation programs. Education is part of the follow-up treatment for people with SCI, as are psychotherapy, peer mentorship, and social activities; these are helpful for improving skills needed for socializing and relationships. Rather than addressing sexual dysfunction strictly as a physical problem, appropriate sexual rehabilitation care takes into account the individual as a whole, for example addressing issues with relationships and self-esteem. Sexual counseling includes teaching techniques to manage depression and stress, and to increase attention to preserved sensations during sexual activity. Education includes information about birth control or assistive devices such as those for positioning in sex, or advice and ideas for addressing problems such as incontinence and autonomic dysreflexia.\nMany SCI patients have received misinformation about the effects of their injury on their sexual function and benefit from education about it. Although sexual education shortly after injury is known to be helpful and desired, it is frequently missing in rehabilitation settings; a common complaint from those who go through rehabilitation programs is that they offer insufficient information about sexuality. Longer-term education and counseling on sex after discharge from a hospital setting are especially important, yet sexuality is one of the most often neglected areas in long-term SCI rehabilitation, particularly for women. Care providers may refrain from addressing the topic because they feel intimidated or unequipped to handle it. Clinicians must be circumspect in bringing up sexual matters since people may be uncomfortable with or unready for the subject. Many patients wait for providers to broach the topic even if they do want the information.\nA person's experience in managing sexuality after the injury relies not only on physical factors like severity and level of the injury, but on aspects of life circumstances and personality such as sexual experience and attitudes about sex. As well as evaluating physical concerns, clinicians must take into account factors that affect each patient's situation: gender, age, cultural, and social factors. Aspects of patients' cultural and religious backgrounds, even if unnoticed before the injury caused sexual dysfunction, affect care and treatments—particularly when cultural attitudes and assumptions of patients and care providers conflict. Health professionals must be sensitive to issues of sexual orientation and gender identity, showing respect and acceptance while communicating, listening, and emotionally supporting. Providers who treat SCI have been found to assume their patients are heterosexual or to exclude LGBTQ patients from their awareness, potentially resulting in substandard care. Academic research on sexuality and disability under-represents LGBTQ perspectives as well.\nAs well as the patient, the partner of an injured person frequently needs support and counseling. It can help with adjustment to a new relationship dynamic and self-image (such as being placed in the role of caretaker) or with stresses that arise in the sexual relationship. Frequently, partners of injured people must contend with feelings like guilt, anger, anxiety, and exhaustion while dealing with the added financial burden of lost wages and medical expenses. Counseling aims to strengthen the relationship by improving communication and trust.\n\nNot only does SCI present children and adolescents with many of the same difficulties adults face, it affects the development of their sexuality. Although substantial research exists on SCI and sexuality in adults, very little exists on the ways in which it affects development of sexuality in young people. Injured children and adolescents need ongoing, age-appropriate sex education that addresses questions of SCI as it relates to sexuality and sexual function. Very young children become aware of their disabilities before their sexuality, but as they age they become curious just as able-bodied children do, and it is appropriate to provide them with increasing amounts of information. Caregivers help the child and family prepare for transition into adulthood, including in sexuality and social interaction, beginning early and intensifying during adolescence. Parents need education about the effects of SCI on sexual function so that they can answer their children's questions.\n\nOnce patients reach their teens, they need more specific information about pregnancy, birth control, self-esteem, and dating. Teenagers with lost or reduced genital sensation benefit from education about alternative ways to experience pleasure and satisfaction from sexual acts. The teen years are often particularly difficult for those with SCI, in terms of body image and relationships. Given the importance they place on sexuality and privacy, adolescents may experience humiliation when parents or caregivers bathe them or take care of bowel and bladder needs. They can benefit from sexuality counseling, support groups, and mentoring by adults with SCI who can share experiences and lead discussions with peers. With the right care and education from family and professionals, injured children and adolescents can develop into sexually healthy adults.\n\nPeople make a variety of sexual adaptations to help adjust to SCI. They often change their sexual practices, moving away from genital stimulation and intercourse and toward greater emphasis on touching above the level of injury and other aspects of intimacy such as kissing and caressing. It is necessary to discover new sexual positions if ones used previously have become too difficult. Other factors that enhance sexual pleasure are positive memories, fantasies, relaxation, meditation, breathing techniques, and most importantly, trust with a partner. People with SCI can make use of visual, auditory, olfactory, and tactile stimuli. It is possible to train oneself to be more mindful of the cerebral aspects of sex and of feeling in areas of the body that have sensation; this increases chances of orgasm. The importance of desire and comfort is the reasoning behind the quip \"the most important sexual organ is the brain.\"\n\nAdjusting to post-injury changes in the body's sensation is difficult enough to cause some to give up on the idea of satisfying sex at first. But changes in sensitivity above and at the level of injury occur over time; people may find erogenous zones like the nipples or ears have become more sensitive, enough to be sexually satisfying. They may discover new erogenous zones that were not erotic before the injury; care providers can help direct this discovery. These erogenous areas can even lead to orgasm when stimulated. Such changes may result from \"remapping\" of sensory areas in the brain due to neuroplasticity, particularly when sensation in the genitals is completely lost.\n\nCommonly there is an area on the body between the areas where sensation is lost and those where is preserved called a \"transition zone\" that has increased sensitivity and is often sexually pleasurable when stimulated. Also known as a \"border zone\", this area may feel the way the penis or clitoris did before injury, and can even give orgasmic sensation. Due to such changes in sensation, people are encouraged to explore their bodies to discover what areas are pleasurable. Masturbation is a useful way to learn about the body's new responses.\nTests exist to measure how much sensation a person has retained in the genitals after an injury, which are used to tailor treatment or rehabilitation. Sensory testing helps people learn to recognize the sensations associated with arousal and orgasm. Injured people who are able to achieve orgasms from stimulation to the genitals may need stimulation for a longer time or at a greater intensity. Sex toys such as vibrators are available, e.g. to enhance sensation in areas of reduced sensitivity, and these can be modified to accommodate disabilities. For example, a hand strap can be added to a vibrator or dildo to assist someone with poor hand function.\n\nSCI presents extra needs to consider for sexual activity; for example muscle weakness and movement limitations restrict options for positioning. Pillows or devices such as wedges can be placed to help achieve and maintain a desired position for people affected by weakness or movement limitations. Assistive devices exist to aid in motion, such as sliding chairs to provide pelvic thrust. Spasticity and pain also create barriers to sexual activity; these changes may require couples to use new positions, such as seated in a wheelchair. A warm bath can be taken prior to sex, and massage and stretching can be incorporated into foreplay to ease spasticity.\nAnother consideration is loss of sensation, which puts people at risk for wounds such as pressure sores and injuries that could become worse before being noticed. Friction from sexual activity may damage the skin, so it is necessary after sex to inspect areas that could have been hurt, particularly the buttocks and genital area. People who already have pressure sores must take care not to make the wounds worse. Irritation to the genitals increases risk for vaginal infections, which get worse if they go unnoticed. Women who do not get sufficient vaginal lubrication on their own can use a commercially available personal lubricant to decrease friction.\nAnother risk is autonomic dysreflexia (AD), a medical emergency involving dangerously high blood pressure. People at risk for AD can take medications to help prevent it before sex, but if it does occur they must stop and seek treatment. Mild signs of AD such as slightly high blood pressure frequently do accompany sexual arousal and are not cause for alarm. In fact, some interpret the symptoms of AD that occur during sexual activity as pleasant or arousing, or even climactic.\nA concern for sexual activity that is not dangerous but that can be upsetting for both partners is bladder or bowel leakage due to urinary or fecal incontinence. Couples can prepare for sex by draining the bladder using intermittent catheterization or placing towels down in advance. People with indwelling urinary catheters must take special care with them, removing them or taping them out of the way.\nBirth control is another consideration: women with SCI are usually not prescribed oral contraceptives since the hormones in them increase the risk of blood clots, for which people with SCI are already at elevated risk. Intrauterine devices could have dangerous complications that could go undetected if sensation is reduced. Diaphragms that require something to be inserted into the vagina are not usable by people with poor hand function. An option of choice for women is for partners to use condoms.\n\nIn the first months after an injury, people commonly prioritize other aspects of rehabilitation over sexual matters, but in the long term, adjustment to life with SCI necessitates addressing sexuality.\n\nAlthough physical, psychological and emotional factors militate to reduce the frequency of sex after injury, it increases after time. As years go by, the odds that a person will become involved in a sexual relationship increase. Difficulties adjusting to a changed appearance and physical limitations contribute to reduced frequency of sexual acts, and improved body image is associated with an increase. Like frequency, sexual desire and sexual satisfaction often decrease after SCI. The reduction in women's sexual desire and frequency may be in part because they believe they can no longer enjoy sex, or because their independence or social opportunities are reduced. As time goes by people usually adjust sexually, adapting to their changed bodies. Some 80% of women return to being sexually active,\n\nand the numbers who report being sexually satisfied range from 40–88%. Although women's satisfaction is usually lower than before the injury, it improves as time passes. Women report higher rates of sexual satisfaction than men post-SCI for as many as 10–45 years. More than a quarter of men have substantial problems with adjustment to their post-injury sexual functioning. Sexual satisfaction depends on a host of factors, some more important than the physical function of the genitals: intimacy, quality of relationships, satisfaction of partners, willingness to be sexually experimental, and good communication. Genital function is not as important to men's sexual satisfaction as are their partners' satisfaction and intimacy in their relationships. For women, quality of relationships, closeness with partners, sexual desire, and positive body image, as well as the physical function of the genitals, contribute sexual satisfaction. For both sexes, long-term relationships are associated with higher sexual satisfaction.\n\nA catastrophic injury such as SCI puts strain on marriages and other romantic relationships, which in turn has important implications for quality of life. Partners of injured people often feel out of control, overwhelmed, angry, and guilty while having added work related to the injury, less help with responsibilities like parenting, and loss of wages. Relationship stress and excessive dependence in relationships increases risk of depression for the person with SCI; supportive relationships are protective.\n\nRelationships change as partners take on new roles, such as that of caregiver, which may conflict with the role of partner and require substantial sacrifice of time and self-care. These changes in responsibilities may mean a reverse in societally determined gender roles within relationships; inability to fulfil these roles affects sexuality in general.\n\nSexual dysfunction is a stressor in relationships. People are often as concerned about failing to keep a partner satisfied as they are about meeting their own sexual needs. In fact, two of the top reasons people with SCI cite for wanting to have sex are for intimacy and to keep a partner. The frequency of sex correlates with the desire of the uninjured partner.\n\nAlthough problems with sexual function that result from SCI play a part in some divorces, they are not as important as emotional maturity in determining the success of a marriage. People with SCI get divorced more often than the rest of the population, and marriages that took place before the injury fail more often than those that took place after (33% vs. 21%). People married before the injury report less happy marriages and worse sexual adjustment than those married after, possibly indicating that spouses had difficulty adjusting to the new circumstances. For those who chose to become involved with someone after an injury, the disability was an accepted part of the relationship from the outset. Understanding and acceptance of the limitations that result from the injury on the part of the uninjured partner is an important factor in a successful marriage. Many divorces have been found to be initiated by the injured partner, sometimes due to the depression and denial that often occurs early after the injury. Thus counseling is important, not just for managing changes in self-perception but in perceptions about relationships.\nDespite the stresses that SCI places on people and relationships, studies have shown that people with SCI are able to have happy and fulfilling romantic relationships and marriages, and to raise well-adjusted children. People with SCI who wish to be parents may question their ability to raise children and opt not to have them, but studies have shown no difference in parenting outcomes between injured and uninjured groups. Children of women with SCI do not have worse self-esteem, adjustment, or attitudes toward their parents. Women who have children post-SCI have a higher quality of life, even though parenting adds demands and challenges to their lives.\nFor those who are single when injured or who become single, SCI causes difficulties and insecurities with respect to one's ability to meet new partners and start relationships. In some settings, beauty standards cause people to view disabled bodies as less attractive, limiting the options for sexual and romantic partners of people with disabilities like SCI. Furthermore, physical disabilities are stigmatized, causing people to avoid contact with disabled people, particularly those with highly visible conditions like SCI. The stigma may cause people with SCI to experience self-consciousness and embarrassment in public. They can increase their social success by using impression management techniques to change how they are perceived and create a more positive image of themselves in others' eyes. Physical limitations create difficulties; with lowered independence comes reduced social interaction and fewer opportunities to find partners. Difficulties with mobility and the lack of disabled accessibility of social spaces (e.g. lack of wheelchair ramps) create a further barrier to social activity and limit the ability to meet partners. Isolation and its associated risk of depression can be limited by participating in physical activities, social gatherings, clubs, and online chat and dating.\n\nNegative societal attitudes and stereotypes about people with disabilities like SCI affect interpersonal interactions and self-image, with important implications for quality of life. In fact, for women, psychological factors have a more important impact on sexual adjustment and activity than physical ones. Negative attitudes about disability (along with relationships and social support) are more predictive of outcome than even the level or completeness of injury. Stereotypes exist that people with SCI (particularly women) are uninterested in, unsuitable for, or incapable of sexual relationships or encounters. \"People think we can only date people in wheelchairs, that we're lucky to get any guy, that we can't be picky\", remarked Mia Schaikewitz, who is profiled in \"Push Girls\", a 2012 reality series about four women with SCI.\n\nNot only do they affect injured people's self-image, these stereotypes are particularly harmful when held by counselors and professionals involved in rehabilitation. Caregivers affected by these culturally transmitted beliefs may treat their patients as asexual, particularly if the injury occurred at a young age and the patient never had sexual experiences. Failure to recognize injured people's sexual and reproductive capacity restricts their access to birth control, information about sexuality, and sexual health-related medical care such as annual gynecological exams. Another common belief that affects sexual rehabilitation is that sex is strictly about genital function; this could cause caregivers to discount the importance of the rest of the body and of the individual.\nCultural attitudes toward gender roles have profound effects on people with SCI. The injury can cause insecurities surrounding sexual identity, particularly if the disability precludes fulfilment of societally taught gender norms.\n\nFemale beauty standards propagated by mass media and culture portray the ideal woman as able bodied: as one fashion model with a SCI commented, \"when you have a devastating injury or disability, you're not often thought of as sensual or pretty because you don't look like the women in the magazines.\" Inability to meet these standards can lower self-esteem, even if these ideals are also unattainable for most able-bodied women. Poorer self-esteem is associated with worse sexual adjustment and quality of life, and higher rates of loneliness, stress, and depression.\n\nMales are also affected by societal expectations, such as notions about masculinity and sexual prowess. Men from some traditional backgrounds may feel performance pressure that emphasizes the ability to have erections and sexual intercourse. Men who have strong sexual desire but who are not able to perform sexually may be at increased risk for depression, particularly when they believe strongly in traditional masculine gender norms with sexual function as core to the male identity. Men who strongly believe in these traditional roles may feel sexually inadequate, unmanly, insecure, and less satisfied with life. Since sexual dysfunction has this negative impact on self-esteem, treatment of erectile dysfunction can have a psychological benefit even though it does not help with physical sensation. SCI may necessitate reappraisal and rejection of assumptions about gender norms and sexual function in order to adjust healthily to the disability: those who are able to change the way they think about gender roles may have better life satisfaction and outcomes with rehabilitation. Counseling is helpful in this reassessment process.\n\n"}
{"id": "5195602", "url": "https://en.wikipedia.org/wiki?curid=5195602", "title": "St. Matthew's University", "text": "St. Matthew's University\n\nSt. Matthew's University (SMU) is a for-profit university located in Grand Cayman, Cayman Islands in the Caribbean. SMU has a School of Medicine and a School of Veterinary Medicine, which confer M.D. and D.V.M. degrees, respectively. St. Matthew's University is owned by R3 Education, Inc.\n\nSMU was founded in Belize in 1997 by Dr. Michael Harris and other medical doctors. In 2001, the board of directors changed the university's administration. In 2002, the school moved to the Cayman Islands under interim president Dr. B.D. Owens. Dr. Michael Harris was named President in 2003 and the Medical University gained full accreditation.\n\nThe School of Veterinary Medicine was established in 2005 under the direction of Dr. Scott Harris, DVM . The school was acquired by Greenwich, Connecticut-based Equinox Capital in conjunction with Chicago-based Prairie Capital in 2005.\n\nSMU is chartered by the government of the Cayman Islands.\n\nSMU School of Medicine is accredited by the Accreditation Commission of Colleges of Medicine, an accrediting agency listed in the FAIMER Directory of Organizations that Recognize/Accredit Medical Schools (DORA). The School of Medicine has been accredited for 14 years with accreditation extending until June 30, 2019. Since 2002 the United States Department of Education’s National Committee on Foreign Medical Education and Accreditation (NCFMEA) has recognized SMU’s accreditor as using standards that are comparable to the standards used to accredit medical schools in the United States. \n\nSt. Matthew's University School of Medicine is approved by the New York State Education Department (NYSED) to allow students to complete more than 12 weeks of clinical clerkships in New York State. SMU is one of only seven Caribbean medical schools so approved by NYSED. \n\nSt. Matthew's University School of Medicine is licensed by the Florida Department of Education's Commission for Independent Education (CIE) for the purpose of providing clinical rotations in Florida. SMU is one of only seven Caribbean medical schools so approved by the Florida Department of Education's CIE. \n\nThe University is listed in the World Directory of Medical Schools.\n\nIn June 2018, access to the Federal Direct Student Loan Program was granted to students at SMU School of Medicine, who are either American citizens or permanent residents.\nThe MD program at SMU is a 10-semester course of study that consists of 3 semesters per calendar year. Semesters 1-5 are basic science semesters that are completed at the university’s Grand Cayman (Cayman Islands) campus. Semesters 6-10 consist of 72 weeks of clinical training at rural hospitals in United States, Canada, or the United Kingdom.\n\nOn February 8, 2005, the Division of Licensing, Medical Board of California reviewed, and determined that St. Matthew's University graduates are ineligible for licensure. This was due to attrition rates above 80%, low USMLE pass rate, and unorganized clinical rotations in remote locations.\n\nIn the United States, the medical boards of the following states have banned St. Matthew's University graduates from obtaining licensure::\n\n\nA future approval would still bar physicians from obtaining a licensure, unless if they start basic sciences after the approval date.\n\nIn the United Kingdom, the General Medical Council has listed St. Matthew's University as an institution whose graduates from the Belize campus are ineligible for licensure. Graduates from the current Cayman Islands campus are eligible for licensure.\n\nThe residence hall is an old Sleep Inn hotel. The rent for a small room is $4245-4800 USD for almost 4 months. The high speed internet provided is 3.25 Mbps. Students who plan on studying with contemporary media standards usually buy a high speed modem on their own, or use the hotspot from their smart phones. This is by far the cheapest housing available on the island.\n\nSt. Matthew's University School of Veterinary Medicine (SMUSVM) is listed by the American Veterinary Medical Association, and its graduates qualify for entrance into the Educational Commission for Foreign Veterinary Graduates (ECFVG) or the Program for the Assessment of Veterinary Education Equivalence (PAVE) certification programs.\n\nThe PAVE program is a foreign licensing program that allows students to qualify to take the North American Veterinary Licensing Examination (NAVLE). The PAVE qualifying exam is written or online and intended to test the knowledge of students in foreign veterinary schools. It covers material learned in the first three (pre-clinical) years of AVMA-accredited veterinary schools. The PAVE program is recognized in 39 states currently, as well as Australia and New Zealand.\n\nThe ECFVG is a program that assesses the overall knowledge of veterinary students from non-AVMA-accredited schools to ensure they have sufficient knowledge to practice veterinary medicine within the United States. The program contains four steps and is recognized by all 50 states to allow those that receive a certificate the ability to practice within those states.\n\nThe Dean of the School of Veterinary Medicine is Karen Rosenthal, DVM. Dr. Rosenthal has received awards in her work as an advocate for exotic animals and her dedication toward advancing the field of companion exotic animal medicine. Dr. Rosenthal has received the Oxbow Exotic Mammal Health Award for her work in the field of exotic companion animal medicine on October 24, 2012. \n\nDr. Rosenthal has also been an associate professor and section chief of special species medicine at the University of Pennsylvania School of Veterinary Medicine, where she also served as the medical director of University of Pennsylvania's veterinary hospital; and previously, she was the founding and national director of Avian and Exotic Animal Services for Antech Diagnostics and a staff member for five years on the Avian and Exotic Service at New York City's Animal Medical Center.\n\nStudents at the School of Veterinary Medicine complete their pre-clinical education in 28 months (7 semesters), with three more semesters (12 months) completed in either the United States or Canada as the clinical year. The incoming class size is limited to 35 students and the faculty to student ratio is 1:5.\n\nThe requirements for applying to St. Matthew's University School of Veterinary Medicine are: 8 credits (and lab) of General Biology and General Chemistry, 4 credits (and lab) of Organic Chemistry, 3 credits of Biochemistry, 6 credits of Language Arts (English), 3 credits of College Math or Computer Science, 4 credits of Physics (Recommended), and 6 credits of Social Science (Recommended). \n\nThere is a concurrent dual degree program available for students to receive their Master of Business Administration degree from Davenport University, which is offered completely online. Members of the dual degree program receive benefits that include qualification for Title IV federal student aid (for U.S. citizens and eligible non-citizens), receiving partnership tuition rates for the entire program, advancing the student's career with two degrees as a doctor of veterinary medicine and an MBA, and the ability to apply up to 15 transferable graduate credits.\n\nSMUSVM has clinical year programs with Purdue University, University of Pennsylvania, University of Minnesota, North Carolina State University, Oklahoma State University, and University of Illinois.\n\n\n\n"}
{"id": "22097104", "url": "https://en.wikipedia.org/wiki?curid=22097104", "title": "Subareolar abscess", "text": "Subareolar abscess\n\nAlso called Zuska's disease (only nonpuerperal case), subareolar abscess is a subcutaneous abscess of the breast tissue beneath the areola of the nipple. It is a frequently aseptic inflammation and has been associated with squamous metaplasia of lactiferous ducts.\n\nThe term is usually understood to include breast abscesses located in the retroareolar region or the periareolar region, but not those located in the periphery of the breast.\n\nSubareolar abscess can develop both during lactation or extrapuerperal, the abscess is often flaring up and down with repeated fistulation.\n\n90% of cases are smokers, however only a very small fraction of smokers appear to develop this lesion. It has been speculated that either the direct toxic effect or hormonal changes related to smoking could cause squamous metaplasia of lactiferous ducts. It is not well established whether the lesion regresses after smoking cessation.\n\nExtrapuerperal cases are often associated with hyperprolactinemia or with thyroid problems. Also diabetes mellitus may be a contributing factor in nonpuerperal breast abscess.\n\nTreatment is problematic unless an underlying endocrine disorder can be successfully diagnosed and treated.\n\nA study by Goepel and Panhke provided indications that the inflammation should be controlled by bromocriptine even in absence of hyperprolactinemia.\n\nAntibiotic treatment is given in case of acute inflammation. However, this alone is rarely effective, and the treatment of a subareaolar abscess is primarily surgical. In case of an acute abscess, incision and drainage are performed, followed by antibiotics treatment. However, in contrast to peripheral breast abscess which often resolves after antibiotics and incision and drainage, subareaolar breast abscess has a tendency to recur, often accompanied by the formation of fistulas leading from inflammation area to the skin surface. In many cases, in particular in patients with recurrent subareolar abscess, the excision of the affected lactiferous ducts is indicated, together with the excision of any chronic abscess or fistula. This can be performed using radial or circumareolar incision.\n\nThere is no universal agreement on what should be the standard way of treating the condition. In a recent review article, antibiotics treatment, ultrasound evaluation and, if fluid is present, ultrasound-guided fine needle aspiration of the abscess with an 18 gauge needle, under saline lavage until clear, has been suggested as initial line of treatment for breast abscess in puerperal and non-puerperal cases including central (subareolar) abscess (see breast abscess for details). Elsewhere, it has been stated that treatment of subareolar abscess is unlikely to work if it does not address the ducts as such.\n\nDuct resection has been traditionally used to treat the condition; the original Hadfield procedure has been improved many times but long term success rate remains poor even for radical surgery. Petersen even suggests that damage caused by previous surgery is a frequent cause of subareolar abscesses. Goepel and Pahnke and other authors recommend performing surgeries only with concomitant bromocriptine treatment.\n\nSquamous metaplasia of lactiferous ducts - abbreviated SMOLD is a change where the normal double layer cuboid epithelium of the lactiferous ducts is replaced by squamous keratinizing cell layers. The resulting epithelium is very similar to normal skin, hence some authors speak of epidermalization. SMOLD is rare in premenopausal women (possibly 0.1-3%) but more frequent (possibly up to 25%) in postmenopausal women where it does not cause any problems at all.\n\nSMOLD appears to be a completely benign lesion and may exist without causing any symptoms. In principle it ought to be completely reversible as the classification as metaplasia would suggest. Because of difficulties in observing the actual changes and rare incidence of the lesion this does not appear to be documented.\n\nThe last section of the lactiferous ducts is always lined with squamous keratinizing epithelium which appears to have important physiological functions. For example, the keratin forms plugs sealing the duct entry and has bacteriostatic properties. In SMOLD the keratinizing lining which is supposed to form only the ends of the lactiferous ducts extends deep into the ducts.\n\nSMOLD is distinct from squamous metaplasia that may occur in papilomatous hyperplasia. It is believed to be unrelated to squamous cell carcinoma of the breast which probably arises from different cell types.\n\nThe keratin plugs (debris) produced by SMOLD have been proposed as the cause for recurrent subareolar abscesses by causing secretory stasis. The epidermalized lining has also different permeability than the normal lining, hindering resorption of glandular secretions. The resorption is necessary to dispose of stalled secretions inside the duct - and at least equally important it affects osmotic balance which in turn is an important mechanism in the control of lactogenesis (this is relevant both in puerperal and nonpuerperal mastitis).\n\nWhile in lactating women this would appear to be a very plausible pathogenesis, there is some uncertainty about the pathogenesis in non-lactating women where breast secretions should be apriori minimal. It appears pathologic stimulation of lactogenesis must be present as well to cause subareolar abscess and treatment success with bromocriptin appears to confirm this as compared to poor success rate of the usual antibiotic and surgical treatments documented by Hanavadi et al.\n\nFurther uncertainty in the relation of SMOLD and the subareolar abscess is that squamous metaplasia is very often caused by inflammatory processes. SMOLD could be the cause of the inflammation – or the result of a previous or longstanding inflammation.\n\nSMOLD usually affects multiple ducts and frequently (relative to extremely low absolute prevalence) both breasts hence it is very likely that systemic changes such as hormonal interactions are involved.\n\nAt least the following factors have been considered in the aetiology of SMOLD: reactive change to chronic inflammation, systemic hormonal changes, smoking, dysregulation in beta-catenin expression, changes in retinoic acid and vitamin D metabolism or expression.\n\nVitamin A deficiency may cause epidermilization of the ducts and squamous metaplasia and likely also contributes to infection. Vitamin A deficiency has been observed to cause squamous metaplasia in many types of epithelia. However supplementation with Vitamin A would be beneficial only in exceptional cases because normally the local catabolism of vitamin A will be the regulating factor.\n\nSquamous metaplasia of breast epithelia is known to be more prevalent in postmenopausal women (where it does not cause any problems at all). Staurosporine, a nonspecific protein kinase C inhibitor can induce squamous metaplasia in breast tissue while other known PKC inhibitors did not show this effect. cAMP stimulation can also induce squamous metaplasia.\n\nMultiple imaging modalities may be necessary to evaluate abnormalities of the nipple-areolar complex.\n\nIn two studies performed in Japan, high-resolution MRI with a microscopy coil yielding 0.137-mm in-plane resolution has been used to confirm the presence of abscesses, isolated fistulas and inflammation and to reveal their position in order to guide surgery.\n"}
{"id": "6145624", "url": "https://en.wikipedia.org/wiki?curid=6145624", "title": "Vion Pharmaceuticals, Inc.", "text": "Vion Pharmaceuticals, Inc.\n\nVion Pharmaceuticals, Inc. was a New Haven, Connecticut based pharmaceutical company founded in March 1992 to commercialize several discoveries made in the biomedical laboratories at Yale University.\n\nTwo anticancer agents, Onrigin (laromustine), formerly cloretazine (VNP40101M), and Triapine, a ribunucloetide reductase inhibitor similar to hydroxyurea, were in human clinical trials. A novel alkylating agent, Onrigin was evaluated in a Phase 2 trial in elderly \"de novo\" poor-risk acute myeloid leukemia (AML). In addition, several trials of Onrigin were conducted in elderly patients with AML and myelodysplastic syndrome (MDS) in combination with cytarabine, and in patients with brain tumors in combination with temozolomide. After Onrigin was rejected by the Food and Drug Administration for an AML indication in 2009 due to an unfavorable risk-benefit profile, the company became defunct.\n\nThe company declared bankruptcy in December 2009.\n"}
{"id": "33862840", "url": "https://en.wikipedia.org/wiki?curid=33862840", "title": "WHO regions", "text": "WHO regions\n\nThe World Health Organization (WHO) divides the world into six WHO regions, for the purposes of reporting, analysis and administration.\n\nAlgeria, Angola, Benin, Botswana, Burkina Faso, Burundi, Cameroon, Cape Verde, Central African Republic, Chad, Comoros, Côte d’Ivoire, Democratic Republic of the Congo, Equatorial Guinea, Eritrea, Ethiopia, Gabon, Gambia, Ghana, Guinea, Guinea-Bissau, Kenya, Lesotho, Liberia, Madagascar, Malawi, Mali, Mauritania, Mauritius, Mozambique, Namibia, Niger, Nigeria, Republic of the Congo, Rwanda, Sao Tome and Principe, Senegal, Seychelles, Sierra Leone, South Africa, Swaziland, Togo, Uganda, United Republic of Tanzania, Zambia, Zimbabwe.\n\nAntigua and Barbuda, Argentina, Bahamas, Barbados, Belize, Bolivia (Plurinational State of), Brazil, Canada, Chile, Colombia, Costa Rica, Cuba, Dominica, Dominican Republic, Ecuador, El Salvador, Grenada, Guatemala, Guyana, Haiti, Honduras, Jamaica, Mexico, Nicaragua, Panama, Paraguay, Peru, Saint Kitts and Nevis, Saint Lucia, Saint Vincent and the Grenadines, Suriname, Trinidad and Tobago, United States of America, Uruguay, Venezuela (Bolivarian Republic of).\n\nBangladesh, Bhutan, Democratic People’s Republic of Korea, India, Indonesia, Maldives, Myanmar, Nepal, Sri Lanka, Thailand, Timor-Leste.\n\nAlbania, Andorra, Armenia, Austria, Azerbaijan, Belarus, Belgium, Bosnia and Herzegovina, Bulgaria, Croatia, Cyprus, Czech Republic, Denmark, Estonia, Finland, France, Georgia, Germany, Greece, Hungary, Iceland, Ireland, Israel, Italy, Kazakhstan, Kyrgyzstan, Latvia, Lithuania, Luxembourg, Malta, Monaco, Montenegro, Netherlands, Norway, Poland, Portugal, Republic of Moldova, Romania, Russian Federation, San Marino, Serbia, Slovakia, Slovenia, Spain, Sweden, Switzerland, Tajikistan, The former Yugoslav Republic of Macedonia, Turkey, Turkmenistan, Ukraine, United Kingdom, Uzbekistan.\n\nAfghanistan, Bahrain, Djibouti, Egypt, Iran (Islamic Republic of), Iraq, Jordan, Kuwait, Lebanon, Libyan Arab Jamahiriya, Morocco, Oman, Pakistan, Qatar, Saudi Arabia, Somalia, Sudan, Syrian Arab Republic, Tunisia, United Arab Emirates, Yemen.\n\nAustralia, Brunei Darussalam, Cambodia, China, Cook Islands, Fiji, Japan, Kiribati, Lao People’s Democratic Republic, Malaysia, Marshall Islands, Micronesia (Federated States of), Mongolia, Nauru, New Zealand, Niue, Palau, Papua New Guinea, Philippines, Republic of Korea, Samoa, Singapore, Solomon Islands, Taiwan, Tonga, Tuvalu, Vanuatu, Viet Nam.\n\nThis list is derived from World Health Statistics 2011, issued under the auspices of the United Nations by the World Health Organization.\nYou can find the latest WHO statistical reports here. The 2017 Annex listing countries by region can be found here.\n"}
{"id": "19110984", "url": "https://en.wikipedia.org/wiki?curid=19110984", "title": "Water supply and sanitation in the Netherlands", "text": "Water supply and sanitation in the Netherlands\n\n\"This article was written in 2008 with some updates in 2012. Please feel free to further update it, if need be.\"\nWater supply and sanitation in the Netherlands is provided in good quality and at a reasonable price to the entire population. Water consumption is one of the lowest in developed countries at 128 litres per capita per day and water leakage in the distribution network is one of the lowest in the world at only 6%.\n\nA large array of institutions is responsible for providing water and sanitation services: 10 regional water companies provide drinking water, 431 municipalities are in charge of sewers, and 27 water boards treat wastewater. Two Ministries share responsibility for policy-making in the sector. A large number of knowledge institutes, NGOs and two business associations – VEWIN representing the interests of the water companies and UVW representing the water boards - complete the institutional landscape of the sector.\n\nAn interesting feature of the Dutch water sector is a performance benchmarking system for water companies first introduced in 1997, which has inspired similar efforts in other European countries. The Dutch parliament passed a law in 2004 banning private sector provision of water supply. However, while the water companies themselves remain publicly owned, they contract many services - such as customer service and repairs - out to the private sector.\n\nThe Dutch have universal access to the water supply and sanitation at very good quality. The drinking water network is in such good shape that treated water typically does not need to be chlorinated to prevent recontamination in the network, so that water reaches the consumer without a taste or smell of chlorine.\n\n60% of Dutch drinking water comes from groundwater, mainly in the eastern part of the Netherlands. The remaining 40% comes from surface water, mainly in the West where water utilities pump from the Rhine and the Meuse because groundwater is brackish. The government encourages the use of surface water by charging a groundwater abstraction levy. Average municipal water use is among the lowest in developed countries at only 128 litre/capita/day in 2004. 96% of water users are metered and a portion of their bill - typically about one half - is based on actual consumption.\n\nInfrastructure. There are 116,000 km of water pipes in the Netherlands.\n\nHuman Resources. The ten regional water companies had 4,938 full-time equivalent employees in 2008. This figures does not include private sector employees working for companies to which the water companies contract out services. They also do not include employees of municipalities working on sewerage. About 11,000 people work at water boards, an unknown share of which operate and maintain wastewater treatment plants.\n\nConsolidation of water companies. In 1945 the Dutch water sector was highly fragmented with more than 200 water companies. Their number gradually declined to 10 five decades later. One reason was a transition from groundwater to surface water, and the need to construct capital-intensive and relatively complex treatment plants which required the cooperation of many municipalities. Another reason was that the national government encouraged the creation of larger public limited companies through a law enacted in 1975. However, since the 1990s consolidation has not been driven by the government, but rather by a desire of water companies themselves to reach economies of scale and to be \"competitive\" in a more liberalized European market.\n\nBenchmarking. Since 1997 the Dutch water companies have engaged in a voluntary exercise to benchmark their performance against each other, in order to improve their efficiency and increase transparency. Initially, the benchmarking was undertaken to forestall a government proposal by the Ministry of Economic Affairs to establish a regulatory agency following the British model. Later on, when the regulatory agency did not materialize, benchmarking was pursued more and more for its intrinsic benefits. The Dutch benchmarking exercise covers four areas: water quality; service; environment; and finance and efficiency. The Dutch benchmarking program was the first nationwide benchmarking exercise in the water supply sector in continental Europe. Since then it has inspired similar water and sanitation benchmarking exercises in other European countries, including Denmark, Finland, Norway, Sweden and Germany. Most of these exercises are coordinated since 2004 in the North European Benchmarking Co-operation.\n\nBan of private companies from providing drinking water. In 2004 the Netherlands passed a law which prevents any privately owned company from providing drinking water services to the public. The law is a follow-up to a 1997 government paper, which made clear that water supply concessions would only be given to government-owned companies. It had been introduced in 2000 by the Dutch Environment Minister at the time (1998–2002), Jan Pronk. The bill only covers drinking water provision to households, not sewerage and wastewater treatment. Since almost all water companies in the Netherlands are public and they contract out many services to the private sector, which the law allows, the law has not had any practical consequences.\n\nResponsibilities in the Dutch drinking water and sanitation sector are spread over a number of institutions at different levels of regional aggregation and with specific functions. At the national level two Ministries share responsibility for the sector, and there is no autonomous regulatory agency as it is the case in England, states of the US or Portugal. At the regional level there are 10 water companies in charge of drinking water supply and 27 water boards, which are in charge of wastewater treatment, among other tasks. At the local level, municipalities are in charge of sewerage. Knowledge institutions and NGOs play an active role in the sector. While the sector may appear institutionally fragmented, cooperation between the various stakeholders is usually strong, minimizing frictions and conflicts.\n\nThe legal framework of the Dutch water sector consists of the Water Supply Act of 2005 and a corresponding Decree on Water Supply, as well as the Water Boards Act of 1995.\n\nWithin the government two Ministries share responsibility for the sector. The Ministry of Housing, Spatial Planning and the Environment (called VROM, using its Dutch acronym) is in charge of water supply and regulates public health.\nThe Ministry of Transport, Public Works and Water Management is in charge of water resources management. Its Directorate-General for Public Works and Water Management (\"Rijkswaterstaat\") is in charge of water resources policy and managing surface water, such as the IJsselmeer, and the rivers Rhine and Maas, in cooperation with the Water Boards (see below). The Ministry’s Inspectorate for Transport, Public Works and Water Management is in charge of monitoring compliance with regulations.\n\nThe 12 provinces of the Netherlands are responsible for groundwater management, for example through licenses for groundwater extraction. They usually delegate their water-related functions to the Water Boards (see below).\n\nPublic regional water companies. Ten Dutch water companies are responsible for drinking water supply in the Netherlands. The Association of Dutch Water Companies (Vewin) represents them. Many of their services, such as customer relations and repairs, are contracted out to the private sector. Their 6-year joint research programme is contracted to KWR (see 'Knowledge institutes' below).\n\nPrivate sector. The small private company NV Bronwaterleiding Doorn provides drinking water to the municipality of Doorn and a neighboring municipality. As per the provision of the law banning private sector participation in the provision of water services, the company is slated to be taken over by the much larger regional public water company VITENS which operates in the surrounding area.\n\nMunicipalities. 431 municipalities are responsible for collecting wastewater via the sewer system.\n\nWater Boards. The 24 water boards (\"Waterschappen\") are key institutions in charge of water resources management in the Netherlands. They are decentralised public authorities with their own legal personality and financial resources. Water boards are based on the Dutch Constitution. Their responsibilities are outlined in the Water Boards Act of 1995. Water boards are responsible for flood control, management of regional water resources (quantity and quality) and treatment of urban wastewater. The oldest water boards date from the 13th century, making them the oldest democratic structure in the Netherlands. The umbrella organisation of the water boards is the Association of Dutch Water Boards (\"Unie van Waterschappen\"). Many water boards contract out services to the private sector, such as through DBFO (Design, Build, Finance, Operate) contracts for wastewater treatment plants involving private operation for a period of 30 years.\n\nWaternet In the case of Amsterdam, the local water supply company and the local Water Board DWR merged in January 2006 to form Waternet, thus forming the first integrated water and sanitation company in the Netherlands.\n\n is the coordinator and principal implementor of the joint research programme for the Dutch water companies, De Watergroep from Belgium, and Vewin. Nowhere else in the world do water companies work so closely with each other and their knowledge institute. KWR stems from Kiwa, established in 1948. In 2006, Kiwa Water Research became an independent entity, with the Dutch water companies (and in 2016 De Watergroep in Belgium) as its shareholders. In 2008 it changed its name into KWR Watercycle Research Institute.\n\nAccording to the Netherlands Water Information Network, the Netherlands has “developed a coherent knowledge infrastructure in the water sector, comprising government and private research centres, technological and educational institutes (such as Alterra, UNESCO-IHE, ITC, Deltares) and several universities”. These institutes carry out a broad range of basic and applied research, from hydraulic engineering to integrated water management. The institutes have formed close connections with internationally oriented private sector companies. The institutes “have built up considerable networks and experience in water-related issues at international level”. Lessons learned abroad have also been successfully applied in the Netherlands. For example, the results of research into the natural processes of undisturbed water systems (which are now rare in the Netherlands), are used as points of reference for the ecological restoration of water systems.\n\nStill according to the Netherlands Water Information Network, many Dutch non-governmental organizations (NGOs) engaged in the water sector “have a solid institutional and financial base, as well as an international focus”. They participate in UN organizations, sessions of the Global Biodiversity Forum (with inputs from the World Conservation Union, IUCN), the Ramsar Bureau and Convention, and the World Water Forum. The international NGOs Wetland International and Bird Life International are based in Wageningen. Their presence has “not only helped to improve the interactions between Dutch ministries, knowledge institutes and NGOs, but has also strengthened the effectiveness and scope of Dutch protection strategies”.\n\nUsing established indicators for the technical operational efficiency of water utilities, the Dutch water companies are highly efficient. For example, according to the association of Dutch water utilities, leakage losses are below 6%. According to the same source, the number of employees per 1,000 connections (water only, without sanitation) is less than 1. Both these figures are among the lowest in the world.\n\nTariffs. According to the consulting firm NUS the average water tariff for the five largest cities in the Netherlands in 2007 for a monthly consumption of 10m³ was slightly higher than the national average indicated by VEWA, at €1.77/m³. The average sanitation tariff was €2.09/m³. The total water and sanitation tariff of €3.87/m³. According to the study, it is the third-highest tariff among 11 European countries included in the study after Germany and Denmark.\n\nAccording to VEWIN, the association of water companies, the average water tariff for all cities in the Netherlands in 2008 was slightly lower at €1.49/m³ but without sanitation. This includes €0.20/m³ of tap water tax and VAT, provincial groundwater levies, distribution and concession reimbursements. Tariffs vary between €1.17 and €2.01 per m³. The tariff structure is binomial with a fixed portion and a variable portion. Tariffs can vary within the service area of a water company, depending on local costs. The International Water Association estimated that the average residential water bill in the Netherlands for a consumption of 200m³ per year in 2007 was €250.00.\n\nWater board finances and wastewater treatment levy. Water boards have the authority to levy taxes and finance their activities mostly with revenues from these taxes. The three main taxes levied by the water boards are a charge for flood protection, a water resources management charge, and a water pollution levy for wastewater treatment. The pollution levy is based on the principle that a polluter must pay for the pollution that he causes. Every household in the Netherlands pays the pollution levy. Companies and organizations pay a rate linked to the quantity and composition of their waste water. The revenues from these taxes provide a budget of €1.9 billion in 2004. The total costs in the same year are estimated at around €2.3 billion, including a share for wastewater treatment. On average around 95% of all annual investment costs and management and maintenance costs by the Water Boards are covered by their revenues.\n\nInvestment. €323m was invested in water supply in 2008. There is no information on investments in sanitation, making international comparisons difficult.\n\nEU water policy\n\n"}
