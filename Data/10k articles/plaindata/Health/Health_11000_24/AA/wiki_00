{"id": "38578972", "url": "https://en.wikipedia.org/wiki?curid=38578972", "title": "1964 Aberdeen typhoid outbreak", "text": "1964 Aberdeen typhoid outbreak\n\nIn 1964 there was an outbreak of typhoid in the city of Aberdeen, Scotland. The first two cases were identified on 20 May 1964; eventually over 400 cases were diagnosed and the patients were quarantined at the City Hospital in Urquhart Road and Woodend Hospital in Eday Road, but no fatalities resulted. Dr Ian MacQueen, the Medical Officer of Health for Aberdeen, became well known in the media for his twice-daily briefings.\n\nThe outbreak was eventually traced to contaminated tinned corned beef from South America made by Fray Bentos and sold in the city's branch of the Scottish grocery chain William Low. Pollution from the waters of the Uruguay River (which flows into the Río de la Plata) appeared to be the source of the contamination, probably through water entering a defective tin through a small puncture. The infected meat then contaminated a meat slicing machine within the William Low shop, leading to the spread of the disease.\n\nThe reputation of Aberdeen as a safe city to visit, live in and work in was briefly harmed by the media coverage of the outbreak. In July 1964, following the end of the outbreak, the Queen made a high-profile visit to boost morale and to help rehabilitate the city's reputation.\n\nAn official enquiry and report into the outbreak was commissioned by the Secretary of State for Scotland. The enquiry was headed by Sir David Milne and his published findings became known as the Milne Report.\n\nThe reputation of William Low was irrevocably damaged within Aberdeen and the city's store, the source of the outbreak, closed three years later. Dundee-based William Low subsequently opened many other stores around Scotland but remained absent from Aberdeen. William Low was taken over by Tesco in 1994. Public perceptions of the safety of Fray Bentos tinned meats also contributed to significantly diminished income.\n\nThe outbreak was successfully handled, given the absence of fatalities. The outbreak drew attention to the need for better standards of hygiene, notably in the cleaning of food processing machinery. The University of Aberdeen went to on to develop an international reputation in the field of disease control, notably in the appointment of Professor Hugh Pennington to the post of Professor of Bacteriology from 1979 until his retirement in 2003.\n\nThe typhoid outbreak may have encouraged replacement of traditional laundered roller towels in public toilets, which allowed bacterial cross-infection from person to person, by disposable paper towels and warm air hand driers.\n\n\n"}
{"id": "22100436", "url": "https://en.wikipedia.org/wiki?curid=22100436", "title": "1997 Indonesian forest fires", "text": "1997 Indonesian forest fires\n\nThe 1997 group of forest fires in Indonesia that lasted well into 1998 were probably among the two or three, if not \"the\" largest, forest fires group in the last two centuries of recorded history.\n\nIn the middle of 1997 forest fires burning in Indonesia began to affect neighbouring countries, spreading thick clouds of smoke and haze to Malaysia and Singapore. Then Malaysian Prime Minister Mahathir bin Mohamad searched desperately for a solution, and based on a plan by the head of the Malaysian fire and rescue department sent a team of Malaysian firefighters across to Indonesia under code name Operation Haze. This is to mitigate the effect of the Haze to Malaysia economy. The value of the Haze damage to Malaysian GDP is estimated to be 0.30 per cent. \n\nSeasonal rains in early December brought a brief respite but soon after the dry conditions and fires returned. By 1998 Brunei and to a lesser extent Thailand, Vietnam and the Philippines had also felt the haze from the smoke of the forest fires. By the time the 1997-98 forest fires were finally over some 8 million hectares of land had burned while countless millions of people suffered from air pollution.\n\nThe 1997 Indonesian forest fires were caused by changing land use which made the tropical forest vulnerable to fire during a drought associated with that year's El Niño. Indonesian forests have historically been resistant to burning even during long dry seasons and despite the use of fire to clear land for swidden agriculture. The land use changes that led to the fires were a combination of industrial-scale logging, draining peatlands for conversion to oil palm and fast-growing tree plantations, and a massive government program to drain swamps and convert them to rice paddies. A total of 240 people perished in the wildfires.\n\nThe total economic value of the damages are conservatively estimated to be US$4.47 billion, of which by far the largest share was borne by Indonesia. This figure excludes a number of damages that are especially difficult to measure or to value in monetary terms, such as loss of human life, long term health impacts, and some biodiversity losses.\n\nForest fires in Indonesia in 1997 were estimated to have released between 0.81 and 2.57 gigatonnes of carbon into the atmosphere, which is between 13-40% of the annual carbon dioxide emissions from burning fossil fuels.,\n\nAs part of steps taken to avoid the recurring of the Haze, the Association of Southeast Asian Nations (ASEAN) approved the need for an early warning system in the Regional Haze Action Plan (RHAP) in 1998 to prevent forest fires and the resulting haze through improved management policies and enforcements, example via Fire Danger Rating System (FDRS)\n\n\n\nGeneral:\n\n"}
{"id": "5419835", "url": "https://en.wikipedia.org/wiki?curid=5419835", "title": "Abdelsalam al-Majali", "text": "Abdelsalam al-Majali\n\nAbdelsalam al-Majali ( ; ; born April 1925) is a Jordanian physician and politician who served twice as the prime minister of Jordan.\n\nMajali was born in Al Karak, Emirate of Transjordan (now Jordan) in April 1925. He received his medical degree from Syrian University in Damascus in 1949. He also holds a diploma of Laryngology and Otology from the Royal College of Physicians in London, which he obtained in 1953. He was awarded a fellowship by the American College of Surgeons in 1960. In 1974, he received the degree of Doctor Honoris Causa from Hacettepe University.\n\nMajali was director of medical services for the Jordanian Armed Forces from 1960 to 1969. He also served as minister of health (1969–1971), minister of state for prime ministerial affairs (1970–1971 and 1976–1979) and also, minister of education (1976–1979). He was then named as president of the University of Jordan (1971–1976 and 1980–1989). In 1973, Majali was promoted to be a professor of medicine at the University of Jordan. He served as advisor to King Hussein starting in the late 1980s.\n\nMajali was prime minister from May 1993 to January 1995, during which time he signed the 1994 Israel–Jordan peace treaty. When he was appointed prime minister, he was also given the portfolio of foreign minister. On 5 January 1995, he resigned from office. He again was prime minister from 1997 to 1998, after which he was appointed to the Jordanian senate.\n\nIn January 2003 Majali was named as a member to the committee of patrons of the Anglo-Arab Organisation. As of 2013, Majali is chairman of the Islamic World Academy of Sciences.\n\n\n"}
{"id": "13343202", "url": "https://en.wikipedia.org/wiki?curid=13343202", "title": "Aging-associated diseases", "text": "Aging-associated diseases\n\nAn aging-associated disease is a disease that is most often seen with increasing frequency with increasing senescence. Essentially, aging-associated diseases are complications arising from senescence. Age-associated diseases are to be distinguished from the aging process itself because all adult animals age, save for a few rare exceptions, but not all adult animals experience all age-associated diseases. Aging-associated diseases do not refer to age-specific diseases, such as the childhood diseases chicken pox and measles. \"Aging-associated disease\" is used here to mean \"diseases of the elderly\". Nor should aging-associated diseases be confused with accelerated aging diseases, all of which are genetic disorders.\n\nExamples of aging-associated diseases are atherosclerosis and cardiovascular disease, cancer, arthritis, cataracts, osteoporosis, type 2 diabetes, hypertension and Alzheimer's disease. The incidence of all of these diseases increases rapidly with aging (increases exponentially with age, in the case of cancer). \nOf the roughly 150,000 people who die each day across the globe, about two thirds—100,000 per day—die of age-related causes.<ref name=\"doi10.2202/1941-6008.1011\"></ref> In industrialized nations, the proportion is higher, reaching 90%.\n\nBy age 3 about 30% of rats have had cancer, whereas by age 85 about 30% of humans have had cancer. Humans, dogs and rabbits get Alzheimer's disease, but rodents do not. Elderly rodents typically die of cancer or kidney disease, but not of cardiovascular disease. In humans, the relative incidence of cancer increases exponentially with age for most cancers, but levels off or may even decline by age 60–75 (although colon/rectal cancer continues to increase).\n\nPeople with the so-called segmental progerias are vulnerable to different sets of diseases. Those with Werner's syndrome suffer from osteoporosis, cataracts, and cardiovascular disease, but not neurodegeneration or Alzheimer's disease; those with Down syndrome suffer type 2 diabetes and Alzheimer's disease, but not high blood pressure, osteoporosis or cataracts. In Bloom syndrome, those afflicted most often die of cancer.\n\nAging (senescence) increases vulnerability to age-associated diseases, whereas genetics determines vulnerability or resistance between species and individuals within species. Some age-related changes (like graying hair) are said to be unrelated to an increase in mortality. But some biogerontologists believe that the same underlying changes that cause graying hair also increase mortality in other organ systems and that understanding the incidence of age-associated disease will advance knowledge of the biology of senescence just as knowledge of childhood diseases advanced knowledge of human development.\n\nStrategies for Engineered Negligible Senescence (SENS) is a research strategy which aims to repair a few \"root causes\" for age-related illness and degeneration, as well as develop medical procedures to periodically repair all such damage in the human body, thereby maintaining a youth-like state indefinitely. So far, the SENS programme has identified seven types of aging-related damage, and feasible solutions have been outlined for each. However, critics argue that the SENS agenda is optimistic at best, and that the aging process is too complex and little-understood for SENS to be scientific or implementable in the foreseeable future.\n\n\n"}
{"id": "241376", "url": "https://en.wikipedia.org/wiki?curid=241376", "title": "Agricultural fencing", "text": "Agricultural fencing\n\nIn agriculture, fences are used to keep animals in or out of an area. They can be made from a wide variety of materials, depending on terrain, location and animals to be confined. Most agricultural fencing averages about high, and in some places, the height and construction of fences designed to hold livestock is mandated by law.\n\nHistorically throughout most of the world, domesticated livestock would roam freely and were fenced out of areas, such as gardens or fields of crops, where they were unwanted. Over time, especially where crop agriculture became dominant and population density of both humans and animals was significant, livestock owners were made to fence their animals in.\n\nThe earliest fences were made of available materials, usually stone or wood, and these materials are still used for some fences today. In areas where field stones are plentiful, fences have been built up over the years as the stones are removed from fields during tillage and planting of crops. The stones were placed on the field edge to get them out of the way. In time, the piles of stones grew high and wide.\n\nIn other areas, fences were constructed of timber. Log fences or split-rail fences were simple fences constructed in newly cleared areas by stacking log rails. Earth could also be used as a fence; an example was what is now called the sunken fence, or \"ha-ha,\" a type of wall built by digging a ditch with one steep side (which animals cannot scale) and one sloped side (where the animals roam).\nThe tradition of fencing out unwanted livestock prevails even today in some sparsely populated areas. For example, until the mid-20th century, most states in the American West were called \"open range\" (\"fence out\") states, in contrast to Eastern and Midwestern states which long had \"fence in\" laws where livestock must be confined by their owners. Though the open range was part of the western tradition, over time, open range was limited long before it was eliminated completely; first came an obligation to keep cattle from roaming onto state and federal highways, where collisions with fast-moving cars and trucks created a public safety hazard. In addition, voters could voluntarily choose to make certain heavily farmed areas a \"herd district,\" where livestock needed to be fenced in, a process that also became popular in areas where development of hobby farms created conflicts between large and small landowners. Over time, court cases steadily limited the application of open range law until the present day, where it is the exception rather than the rule in many parts of the American West.\n\nIn the United Kingdom, the law is different for private land and common land. On private land it is the owner's responsibility to fence livestock in, but it is the responsibility of landowners bordering a common to fence the common's livestock out.\n\nThe principle of wire fences is that they are supported mainly by tension, being stretched between heavy strutted or guy-wired posts at ends, corners, and ideally at intervals in longer stretches (every 50 to 300 metres, 150 to 1000 feet). Between these braced posts are additional smaller wooden or metal posts which keep the wires spaced and upright, usually 3 to 6 metre (10 to 20 feet) apart, depending on the style of fencing used.\n\nTraditionally, wire fencing material is made of galvanized mild steel, but galvanized high-tensile steel is now also used in many places. To prevent sagging of the fence, which raises the risk of entanglement or escape, the wire is tensioned as much as the material will safely allow during construction by various means, including a hand-operated \"wire stretcher\" or \"fence stretcher\" (called a \"monkey strainer\" in some areas) or other leverage devices, a winch, or even by carefully pulling with a tractor or other vehicle.\n\nWire fences are typically run on wooden posts, either from trees commercially grown in plantations or (particularly in the American West) cut from public lands. When less expensive or more readily available than wood, steel T-posts or star posts are used, usually alternating every 2 to 5 steel posts with a more stable wood post. Non-electrified wire is attached to wooden posts using fencing staples (for intermediate posts, these are fitted loosely, not gripping the wire). Non-electrified wire is held on T-posts by means of wire \"clips\" made of smooth galvanized wire that wrap around the back of the post and hook onto the wire on either side of the post.\n\nOther than in a truly desert climate, use of rot-resistant wooden posts or steel posts is advised. In the United States, wood with natural rot resistance, such as oak and juniper, was often used until it became in short supply in the 1950s. Then, chemically treated pine and spruce posts became prevalent, and these are also widely used in Britain, together with chestnut. Creosote, pentachlorophenol, and chromated copper arsenate are all widely used in the US and elsewhere for treatment (although some of these chemicals are subject to legal controls).\n\nThe Industrial Revolution brought the first barbed wire (also \"barbwire\" or just \"barb\") fences, which were widely used after their introduction in the mid-19th century. This technology made it economically feasible to fence rangeland for the first time. In the United States, introduction of barbed wire contributed to the range wars of that century, as various ranch interests attempted to use barbed wire fences to claim exclusive access to the best pasture and water resources, including those lands in the public domain. It also exacerbated tensions between cattle ranchers and crop farmers, partly when access to water was involved.\n\nBarbed wire has been made by many manufacturers in an almost endless variety of styles. For the most part these were functionally identical. The differences reflected peculiarities of each manufacturing process rather than deliberate design of the end product. Sections of unusual barbed wire are collected by some enthusiasts.\n\nThe traditional barbed wire used since the late 19th century and into the present day was made from two mild steel wires twisted together, usually of about 12 or 14 gauge, with about 15-30 twists per metre. Steel barbs were attached every 10–20 cm. Barbs had either two or four points, with the two point design using somewhat heavier and longer barbs. The relative merits of two point vs. four point barbed wire are the subject of deeply held views among many farmers and ranchers, to the extent that both types are still made today.\n\nTypically four strands of barbed wire, with the lowest strand no more than from the ground and the top strand at least 48 inches above the ground, make up a legal fence in the western United States. Better-quality fences have five strands, older fences often had only three strands, and just two strands is widely used in Britain if only adult cattle are being contained. Other variations exist, depending on local laws and the purpose of the fence.\n\nBarbed wire is particularly effective for containing cattle. In pastures containing both cattle and sheep, one or two strands of barbed wire is used in conjunction with woven wire to both discourage cattle from reaching over the top of a fence and to keep sheep from crawling under. Though often used in many areas for horses, barbed wire is not advised; its use is considered poor management. There is very high risk of injury occurring when a thin-skinned, fast-moving animal with long legs runs into it or puts a leg through the strands.\n\nSmooth (or plain) wire is essentially the same product as barbed wire with no barbs – either a two-wire twist or a single strand. Its primary advantage is that it is less likely to cause lacerations and cuts if an animal becomes entangled in it or rubs against it. However, animals will readily lean on mild steel smooth wire, stretching it out of shape or loosening it from the posts, and for this reason it is often used in high-tensile form, which more easily springs back to its original length. Smooth wire fencing is often used as an inexpensive material to safely contain horses and other animals that run a high risk of entanglement, usually in conjunction with a line of electric fence. Smooth wire is also used in securing fence-post braces and other uses where barbed wire is not recommended\n\nHigh tensile (H-T or HT) fencing is a special hard, springy steel wire that was introduced in the 1970s and has slowly gained acceptance. The wire may be a single strand plain or barbed wire, or woven mesh, and is capable of much higher tension than mild steel. It permits the use of wider post spacings and is neither stretched easily by animals, nor by fallen trees or branches. It can be insulated and electrified. Because of the wide spacing of the posts, thin metal or wood spacers (or \"droppers\") may be attached to the wires between posts to maintain their spacing.\n\nJoining HT wire is difficult because of its stiffness and its reduction in strength when bent sharply. However, it may be joined effectively with proprietary clips. HT wire is more expensive than mild steel, but because of the need for fewer posts, the overall cost of the fencing is usually comparable.\n\nBecause it does not stretch, animals are less likely to become entangled in HT wire. However, for the same reason, if an animal does become entangled or runs into a few strands at a high speed, it can be deadly, and is sometimes referred to as having a \"cheese slicer\" effect on the animal.\n\nTrellising for horticultural purposes is generally constructed from HT wire as it is able to withstand a higher crop load without breaking or stretching.\n\nBarbed wire cannot effectively contain pigs, goats or sheep. Where these animals are to be fenced, woven wire (called sheep or pig netting in Britain, sheep fence or hog fence in the United States) is used instead, often with one or more strands of barbed wire at the top. For swine, a ground-level barbed wire strand or electrified wire is used as well to prevent them digging beneath the fence.\n\nAgricultural woven wire is identifiable by wire \"knots\" wrapped around each intersecting wire. Cheaper forms of wire used in residential fences are often spot welded at junctions and as such are less sturdy and may break, creating a hazard for enclosed animals. Woven wire is more costly to purchase and time-consuming to install than is basic wire, but is often safer and less expensive than wood, pipe, or other materials.\n\nWoven wire with large openings (known as \"sheep fence\" in the western United States and \"Ringlock\" in Australia) has some potential hazards. Animals contained inside the fence can easily put a foot through the wide squares while grazing along the edge of the fenceline or while reaching over it, and then become tangled in the fence. It is also dangerous for wild animals, such as deer, kangaroos or wallabies that attempt to jump such fences. These can become trapped when their back feet clip the fencing and get caught. While they can be cut out, they are often seriously injured and must be euthanized. A variation, called \"field fence,\" has narrower openings at the bottom and wider openings at the top, which prevents animals from getting their feet entangled while grazing close to the fence, though is of little help if an animal becomes tangled in the openings higher up.\n\nHorses and ponies in particular are safer kept inside woven wire fence with squares of smaller dimensions, such as \"no climb\" fence with squares that are approximately two inches by four inches. This type of wire is also more effective for containing goats.\n\nAnother variant on woven wire is the \"hog panel,\" which consists of heavy welded wire approximately or more in diameter. It resembles field fence in appearance, but is sold in panels rather than rolls and is not easily wrapped or bent. However, larger livestock such as horses or cattle can easily deform hog panels, so if used to contain large animals, it requires supporting rails or pipe on both the top and sides. It has some of the same strengths and weaknesses as field fence. Though animals are less likely to become entangled in it, the wire is far harder to cut if they do.\n\nChain link fencing is, arguably a form of woven wire, and is occasionally used for some livestock containment. However, due to cost, it is not particularly common for fencing large areas where less-expensive forms of woven wire are equally suitable. When used in small enclosures, it is easily deformed by livestock, resulting in high ongoing maintenance costs.\n\nDeer and many goats can easily jump an ordinary agricultural fence, and so special fencing is needed for farming goats or deer, or to keep wild deer out of farmland and gardens. Deer fence is often made of lightweight woven wire netting nearly 2 metres (about six feet) high on lightweight posts, otherwise made like an ordinary woven wire fence.\n\nIn areas where such a tall fence is unsuitable (for example, on mountains subject to very high winds), deer may be excluded (or contained) by a fence of ordinary height (about 1.5 metres, four feet), with a smaller one of about one metre (three feet) high, about one metre away from it, on the same side as the deer. The additional width prevents deer approaching the fence close enough to jump it.\n\nElectric fencing became widely available in the 1950s and has been widely used both for temporary fences and as a means to improve the security of fences made of other materials. It is most commonly made using lightweight steel wire (usually 14-17 gauge) attached to posts with insulators made of porcelain or plastic. Synthetic web or rope with thin steel wires interwoven to carry the electrical charge has become popular in recent years, particularly where additional visibility is desired.\n\nA fence charger places an electrical pulse from ground to the wire about once per second. The pulse is narrow and usually around 5-20 kV. Animals receive an uncomfortable but harmless shock when contacting the wire, and learn to stay away from it.\n\nSynthetic fences encompass a wide range of products. Vinyl-coated wire fence is usually based on high-tensile wire with a vinyl coating. Some forms are non-electric, others embed layers of graphite to carry a current from the wire to the outside of the coated product so that it can be electrified. It can be of any color, with white particularly common in the United States so that the fencing is visible to livestock. Most forms can be installed on either wood posts or steel t-posts.\n\nA variant, sometimes called \"vinyl rail\" or \"strap fencing\" consists of two or more vinyl-encased wires with vinyl or other synthetic between them to create a \"rail\" that is anywhere from wide. Some forms may be electrified by use of a special coating on the top wire of the \"rail.\"\n\nVinyl fence is installed in a manner similar to plain high-tensile fence and must be stretched tight. Strong bracing of posts at corners and in the middle of long fencelines is required. Like other wire fences, keeping vinyl fencing tightened on a regular basis is key to safety and appearance.\n\nA mesh form of vinyl fencing without internal wires is marketed as \"deer fence\" and used in some locations to augment other fencing to keep out wild animals. There are also some forms of vinyl fencing that look similar to vinyl-coated wire, but do not contain an internal wire, that are marketed to livestock owners. They are marketed as particularly safe, but their strength in containing animals is under debate. These products are very new to the market.\n\nFences of wood, stranded cable, and pipe are used where cost is less of a consideration, particularly on horse farms, or in pens or corrals where livestock are likely to challenge the fence. Synthetic materials with wood-like qualities are also used, though they are the most expensive option in most situations. In some areas, these types of fencing materials can be cost-effective if plentiful. For example, scrap pipe is often easily obtained at a low price if oil fields are nearby, and wooden rails can sometimes be harvested from the owner's own land if it contains suitable standing timber.\n\nFladry lines, made of cloth, metal and/or other materials, are sometimes used on fences to discourage predators from entering a livestock enclosure. (also see: Cattle grid)\n\nAll types of agricultural fencing require regular maintenance to ensure their effectiveness. Cattle and horses are strong enough to go through most types of fence by main force, and occasionally do so when frightened or motivated by hunger, thirst, or sex drive. Weather, flood, fire, and damage from vandals or motor vehicle accidents can do similar damage and may allow livestock to escape.\n\n\n"}
{"id": "51577460", "url": "https://en.wikipedia.org/wiki?curid=51577460", "title": "Anastasie Fătu", "text": "Anastasie Fătu\n\nAnastasie Fătu (originally Năstase Fêtu or Fĕtu, also known as Anastasius Fétul, Anastasie Fĕtul or Anastase Fătul; January 2, 1816 – March 15, 1886) was a Moldavian and Romanian physician, naturalist, philanthropist and political figure, a titular member of the Romanian Academy and founder of Iași's Botanical Garden. Of lowly origins, he benefited from the meritocratic program instituted by Moldavia's government in the 1830s, and went on to study law at the University of Vienna, with hopes of becoming a political economist. After graduating, he changed his professional path, and trained in medicine at the University of Paris. Recognized for pioneering contributions in cardiology, pediatrics, obstetrics and balneotherapy, he was also an early speaker for public health and social medicine, as well as an educational theorist and textbook author. Fătu's career as a professor of natural sciences took him to the Gregorian Institute, the Socola Monastery school, and ultimately Iași University, where he took steps to create a regional medical school.\n\nIn parallel to his career in science, Fătu served one term in the ad-hoc Divan (1857–1858), then several in the Parliament of Romania, initially its Assembly of Deputies; he was Assembly Chairman in 1868, and an associate of the Free and Independent Faction during the late 1860s and 1870s, espousing a platform of radical economic antisemitism. By 1878, he was part of the Factionalist chapter which caucused with the National Liberal Party.\n\nInducted into the Academy in 1871, he became one of its main sponsors, and thus a patron of hard science in Romania. While there, he helped standardize scientific references, and, siding with the partisans of phonemic orthography, participated in the creation of a specialized Romanian vocabulary. Criticized by his adversaries at \"Junimea\" society for his accumulation of offices, and for collecting a large salary as curator of Sfântul Spiridon Hospital, Fătu nevertheless donated most of his money to the Academy. The rest of his estate was at the center of legal disputes which lasted into the 1890s.\n\nWhile he remains fundamentally associated with the city of Iași, Fătu was actually born just to the south of it, at Mușata, Fălciu County—presently Vaslui County—on January 2, 1816 (Old Style: December 21, 1815). He had a younger brother, Iacob, who worked alongside Costache Conachi as a translator of literature. Their father, born into a peasant family, was a parson of the Moldavian Orthodox Metropolis. After finishing primary school in Huși, at the school maintained by the Orthodox bishopric, Anastasie passed an examination and received a scholarship for Iași's Vasilian Gymnasium, thus profiting from a meritocratic shift in Moldavian society. As noted by historian A. D. Xenopol, Moldavian Prince Mihail Sturdza and his adviser Gheorghe Asachi were tacitly encouraging \"people from the lower strata of society\" to acquire and education, and then to take up employment in the state apparatus, at the expense of boyardom. Scholar V. A. Urechia also records the \"great diversity of origin\" at the Vasilian boarding school, arguing that it was a positive contribution to Romania's culture.\n\nFrom 1834, one of six Moldavians to have qualified for a scholarship from the banker-philanthropist Hagi Constantin Popp, Fătu was sent abroad, on condition that, upon graduating, he would return the favor by teaching a public \"course in philosophy, law and political economy\". He went on to study in the Austrian Empire at the University of Vienna. Another scholarship recipient was Anton Velini, who remained his friend in later years, and with whom he studied law, physics and mathematics as an undergraduate. It was also here that Fătu met ethnic Romanians from the Austrian Duchy of Bukovina—Constantin Wassilko and the Hurmuzachi brothers, and, to some degree, also associated with students from Transylvania; together, they established a pan-Romanian club. After taking his Doctorate of Law, and also auditing courses at Vienna Medical Faculty (1839–1841), Fătu received permission from the Moldavian government to continue his studies in France; he enlisted at the University of Paris medical school, but remained in contact with the Vienna expatriates. By August 1846, he was friends with two other Moldavian youths in Paris, all three active politically: Alexandru Ioan Cuza, Scarlat Vârnav, and Nicolae Ionescu. His friends at home included fellow naturalist Ion Ionescu de la Brad, who noted admiringly that Fătu was \"enamored with his studies\", and an inspiration to the other Moldavians.\n\nFătu became a Doctor of Medicine in 1847, with a thesis on cardiac examination (including the study of menstruation flow), published under the name Anastasius Fétul (\"Des signes des maladies du coeur en général\"). He was invited to remain in Paris and practice there, but, after a series of European travels, he returned to Moldavia. He was appointed by Prince Grigore Alexandru Ghica to serve as head physician of Iași, and also as surgeon-general of the Moldavian Militia, with the boyar title of \"Aga\".\n\nIn 1850, Fătu contributed a monograph on the prevention of malaria; he also focused his activity on obstretics, balneotherapy and dietetics, with \"Învățătură dietetică relativă la scrofule\" (\"A Dietary Instruction against Scrofulae\"), followed by \"Descrierea și întrebuințarea apeĭ simple și a apelor minerale din Moldova\" (\"Description and Use of Plain and Mineral Water in Moldavia\", 1851) and \"Manualu pentru învățĕtura móșelor\" (\"A Textbook of Midwife Instructions\", 1852). At the time, he insisted, against religious observance and popular superstition, that women wash themselves as often as possible; he also began advocating a government-sponsored program of spa tourism, but his proposal was casually ignored. Fătu's hypothesis that sulfur baths could work against syphilis was more reserved than other claims to the same effect from his contemporaries, but nonetheless contributed to a prevailing mythology in later folk medicine.\nIn 1852, \"Aga\" Fătu established the Gregorian Institute (named for the patron-prince Ghica), which included a midwives' school that was at some point co-headed by Nicolae Negură. Within this institution, doctors Fătu and Gheorghe Cuciureanu also pioneered pediatrics, and ran Moldavia's only pre-kindergarten for abandoned children. Fătu also created the Society for the Encouragement of Young Romanians to Study Abroad on March 22, 1855, providing it with a capital of 1,000 ducats from his own estate, and publishing its statutes as a brochure. The following year, he set up on his property at Râpa Galbenă the Iași Botanical Garden, celebrated as the very first one in the two Danubian Principalities (Moldavia and Wallachia). The collection, Fătu asserted, was meant to both improve the environment and educate the youth; upon inauguration, it comprised 2,500 plant species from several continents, as well as artificial ponds and greenhouses.\n\nWhen the Crimean War toppled the \"Regulamentul Organic\" regime, placing the Danubian Principalities under the shared tutelage of Great Powers, Fătu became marginally involved in the liberal and Romanian nationalist movement. By June 1856, he was a member of the enlarged Unionist Committee, which openly called for union between Moldavia and Wallachia. In February 1857, he joined a deputation sent by the Moldavian printers, asking the powers to lift censorship laws—other envoys were Vasile Alecsandri, Constantin Hurmuzachi, and Alecu Donici. He then ran in the elections of September, taking a seat for Iași in the ad-hoc Divan. This new legislature, sanctioned by the Great Powers, replaced a Divan elected fraudulently in July.\n\nThe new chambers inaugurated a process whereby Fătu's Paris friend, Cuza, was elected the new prince of Moldavia and then \"Domnitor\" of the United Principalities (the basis for modern Romania); Fătu is known to have supported Cuza's National Party, and to have kept a portrait of the \"Domnitor\". He returned to publishing in 1863 with \"Proiectu de Organisarea Policieĭ Sanitarĭâ in Romania\" (\"A Project for Instituting Romania's Sanitary Police\"), which also functioned as Romania's first attempt at a sanitary code. The same text pioneered medical jurisprudence, including the basics of mental health law and forensic science, sketched out food safety codes, regulated the creation of public toilets, and standardized the depth of graves. It also called for a ban on open-casket church funerals, proposing to isolate dead bodies under the close watch of specialized bailiffs. As social historian Constanța Vintilă-Ghițulescu remarks, Fătu's law integrated well within the \"hygienist wave\" of \"civilized Europe\", with doctors emerging as \"key figures in the construction of the modern state.\" However, according to fellow hygienist Iacob Felix, the project was simply ignored by the government of Nicolae Crețulescu, and the Assembly of Deputies consulted it only for laws establishing county councils.\n\nFătu returned to politics after \"Domnitor\" Cuza's ouster. By the time of the April 1866 election, he supported a project to remake the centralized state into a federal Romania, with separate Moldavian institutions. Drafted by lawyer Gheorghe Cigaras, it was endorsed by members of an emergent regional party, the Free and Independent Faction. Overall, Fătu sided with the Factionalists, who came to be headed by Nicolae Ionescu, and with Ion C. Brătianu's \"Red\" radicals, against moderate liberals and \"White\" conservatives. In Moldavia in particular, the central issue dividing society was that of Jewish emancipation: Factionalists, motivated by economic antisemitism, opposed the integration of Romanian Jews, whereas conservatives supported it. In May 1866, antisemitic riots implicating Faction members erupted in Iași, Bârlad, Roman and Botoșani. The clampdown by the authorities resulted in the temporary arrest of various Factionalists and allies: Fătu was picked up alongside Vasile Gheorghian, Alexandru Gheorghiu, Alecu D. Holban and Petru Poni.\n\nFătu then helped organize the November 1866 election, during which he proposed Cuciureanu, his former associate, as a candidate for the Senate. He himself won a deputy seat for the 2nd College of Iași County, and, in December, was elected one of four vice presidents of the Assembly, seconding Assembly Chairman Lascăr Catargiu. Reelected for the Iași 2nd College in December 1867, and propelled by an understanding between the \"Reds\" and the Factionalists, Fătu then became house chairman, elected with 80 votes of 105 on January 27, 1868. In this capacity, he notably abstained during the vote on railway concessions.\n\nBy April 1868, with anti-Jewish pogroms occurring at Bacău and elsewhere, Fătu and 30 other deputies presented an antisemitic law proposal, one radical enough to be criticized by Brătianu, who deemed it uncivilized. Claiming to be a law on \"the regularization of the state of Jews in Romania\", Fătu's project notably banned Jews from settling anywhere in the countryside, and also from purchasing land. Indirectly responsible for the fall of the Ștefan Golescu cabinet and a rift between the \"Reds\" and the Faction, this proposed legislation was at the center of an international scandal—not just because it discriminated against Jews, but also because it was retroactive in nature.\n\nWith General Nicolae Golescu succeeding his brother as head of the \"Red\" cabinet, the Faction began moving closer to the opposition \"Whites\". Fătu, however, remained friendly toward the \"Reds\". During May, as Ionescu took up filibustering in Senate, all Factionalist deputies but Fătu showed up to express their support. In June, going against the Factionalist party line, Fătu abstained from the Assembly's vote to depose Golescu—the Assembly went against the Senate, prompting a senatorial recall in early elections. Such developments also signaled Fătu's removal from the Assembly presidency, although, in November 1869, he was again elected as vice president (seconding Brătianu, alongside Grigore Arghiropol, Panait Donici, and C. A. Rosetti).\n\nTaking up medical teaching at Socola Monastery seminary in 1869, by 1870 Fătu was editing the country's most prestigious research journal, \"Revista Șciințifică\", with C. F. Robescu and Grigoriu Ștefănescu as fellow directors. This hosted his inventory of species in the Botanical Garden, which also came out as a standalone book in 1871. Also that year, he published at Socola a \"Manualu de medicină practică\" (\"Textbook of Applied Medicine\"). Reviewing the work in \"Revista Șciințifică\", agronomist Petre S. Aurelian recorded as a \"calamity\" news that Fătu had been sacked from the seminary, by order of Christian Tell, the Education Minister in Dimitrie Ghica's \"White\" cabinet.\n\nWith the Free and Independent Faction, Fătu and Ionescu formed the more radical opposition to the \"Whites\", led at the time by Manolache Epureanu. Fătu ran in the elections of May 1870, one of 34 Factionalists to win Assembly seats: not enough to topple the Epureanu cabinet, but causing a great upset in national politics. Continuing to serve several terms in both the Assembly and Senate, Fătu remained an inconsistent Factionalist, only allied with the movement for part of his life; the movement itself was amorphous and notoriously opportunistic.\n\nOn September 11, 1871, Fătu, Aurelian and Crețulescu were elected to the Romanian Academy, or, as it was known back then, the \"Romanian Academic Society\", and thus founded a section for natural sciences. This honored the academicians' pledge of giving humanities and hard sciences equal exposure, after some 5 years of inactivity in that field; up to then, only Petrache Poenaru had been representing hard science at the Academy. His inaugural address, received for the Academy by Urechia and published in 1873, was titled \"Încercările pentru dezvoltarea sciintielorŭ naturale în România\" (\"Attempts to Develop Natural Sciences in Romania\"). According to a later review by geologist Ion Th. Simionescu, the speech was infused with Fătu's \"love for his country\". Fătu castigated \"the inactivity and wrong direction\" of Romanian scientific learning, and demanded direct intervention by the state—while praising private individuals who had compensated the lack of such support.\nAlthough Factionalist politics had brought Fătu into conflict with another Iași-based institution, the conservative club \"Junimea\", \"Încercările...\" included polite references to \"Junimism\", honored for its commitment to the scientific method and to freedom of thought. At the Academy, Fătu and Alexandru Odobescu were coming to question the competence of its two leaders, August Treboniu Laurian and I. C. Massim. Fătu supported Odobescu and the \"Junimists\" plea for phonemic orthography, and voted to audit Laurian's project for the \"Romanian Language Dictionary\". He was spotted at \"Junimea\" meetings, one of the \"caracudă\" (\"small game\") section, who attended without participating. Alongside the \"Junimist\" Vasile Pogor, who was cashier of his Society for the Encouragement of Young Romanians to Study Abroad, Fătu also contributed money for Vasile Conta's tuition at Antwerp Business Institute; Conta, also a \"Junimea\" man, later sent him his manuscript collection of Romanian folklore.\n\nDespite overcoming initial setbacks, the Academic Society was experiencing a financial impasse, which were felt especially hard by the science section. Partly in order to remedy this, in August 1872, Fătu donated 10,000 \"new lei\" for the creation of his eponymous fund, with prizes going to Romania's best scientific cartography, and also the entire collection of \"Revista Științifică\". For a long time, however, no researcher applied to collect his prize. Also in August 1872, with Crețulescu replacing Laurian as Academy chairman, Fătu became its vice president, in succession to Massim. On September 19, he was also elected president of the scientific section (serving to 1876). On the occasion, his fund was split into prizes for botany, agronomy, geology, chemical engineering, and balneotherapy. Moreover, Fătu and Petru Poni insisted on sponsoring a meteorological sub-section, which became operational in September 1874 and employed Ionescu de la Brad as one of the main surveyors. Fătu also helped Ionescu de la Brad set up his own (since lost) botanical garden, at Negri.\n\nFrom 1872, Fătu was also president and re-organizer of the Iași Medical and Naturalist Society, which was working to establish a natural museum. Alongside fellow naturalist Dimitrie Brândză, he created a second, much smaller, botanical garden, near the museum building at Roset House, on Hagoaiei Street. At around the same time, he supported scholar Bonifaciu Florescu's short-lived project to set up an adult high school, also co-founding with him a Society for Teaching the Romanian People. As a senator, he helped Felix promote a new project of sanitary law, which was eventually passed by both chambers in May 1874. It made sanitary inspection a function of Internal Affairs.\n\nIn 1875, Fătu produced \"Elemente de Botanica\" (\"Elementary Botany\"), Romania's first college textbook in that field, putting it up for Academy review. This was a groundbreaking initiative, because it standardized and affixed botanical notions in modern Romanian vocabulary. Eventually published as two volumes in 1878 and 1880, with Botanical Garden staff as editors, it was followed in 1885 by \"Elemente de Zoologie\" (\"Elementary Zoology\"). By then, Fătu had replaced Brândză as titular professor at the new Iași (Alexandru Ioan Cuza) University, where he simultaneously taught botany, physiology, and zoology.\n\nAt the time, Fătu also functioned as one of Iași's head physicians and curator (\"epitrop\") of Sfântul Spiridon Hospital, publishing in 1873 a report on the foundation, its furnishings, and its work. This activity of his was coming under scrutiny from \"Junimea\". The club's doyen, Titu Maiorescu, noted in 1875 that most of Fătu's contributions were not fully philanthropic, as he claimed and expected others to perform: \"To work for money only, now there is something Dr. Fătu knows how to do, with those 2,800 francs he picks up at the botanical garden, and a similar sum from the Academic Society, and so much more from Sfântul Spiridon etc., and then he presents himself as a great patriot.\" Ultimately, in 1876, with Ion Ghica taking over as Academy chairman, Fătu was also replaced as vice president by George Bariț. In July of that year, selected by Poni and voted in by other inductees, he became a \"special member\" of the Medical and Naturalist Society, charged with curating its botanical fund.\n\nFollowing the Romanian War of Independence, during elections for the Senate which opposed \"Junimea\" to a local chapter of the federated National Liberal Party, Fătu was one of the Factionalists who joined the latter. He thus ran on a list headed by Vasile Alecsandri, directly against Petre P. Carp. In his last years of activity, alongside Carol Davila, Fătu also contributed greatly to the consolidation of a Iași public Medical Faculty—nucleus of the Grigore T. Popa University of Medicine and Pharmacy. From 1881, he was a member of the Senckenberg Nature Research Society. In the new Kingdom of Romania, he still maintained an interest in other social and economic matters, and, in 1884, he was among the main contributors to Iași's first credit cooperative, founded by Xenopol. In September 1885, he played host to King Carol I, who visited the Medical and Naturalist Society.\n\nFătu withdrew from Sfântul Spiridon in 1885. Before his death, which came on March 15 (Old Style: March 3), 1886, he was working with a commission to organize the Iași Medical Congress. On March 21, he was buried at Iași, with funeral orations by doctors Emanoil Riegler, Alexandru A. Suțu, and Eugen Rizu; he had left the Academy \"almost his entire fortune\". In his own admission speech in 1887, replacement Grigore Cobălcescu, his \"heart filled with sorrow\", paid homage to \"the late Anastasie Fetu\".\n\nHowever, his overall pedagogical work had inconclusive results: in 1900, Simionescu noted that very little had been done to address the issues raised by Fătu in his 1873 speech, and that the speaker himself was \"forgotten\". Although Fătu was known affectionately to his fellow citizens as \"Dr. Buruienescu\" (\"Dr. Weeds\"), his garden was left in near-complete disrepair in the months after his death. The Medical and Naturalist Society was also in disarray: Fătu had kept its records and funds in his private home, and his widow Ecaterina and family would not return them. A legal dispute followed, and the Fătus were forced to relinquish control—although, reportedly, some manuscripts were never returned. By March 1892, Ecaterina Fătu and her two minor children had also lost ownership of the family estate in Drăgușeni, Dorohoi County, as Anastasie had died without reimbursing a credit worth 200,000 lei.\n"}
{"id": "7748561", "url": "https://en.wikipedia.org/wiki?curid=7748561", "title": "Apicoplast", "text": "Apicoplast\n\nAn apicoplast is a derived non-photosynthetic plastid found in most Apicomplexa, including \"Toxoplasma gondii\", \"Plasmodium falciparum\" and other \"Plasmodium\" spp. (parasites causing malaria), but not in others such as \"Cryptosporidium\". It originated from an alga (there is debate as to whether this was a green or red alga) through secondary endosymbiosis. The apicoplast is surrounded by four membranes within the outermost part of the endomembrane system. The apicoplast hosts important metabolic pathways like Fatty acid synthesis; Isoprenoid precursor synthesis and parts of the Heme biosynthesis pathway \n\nApicoplasts are a relict, nonphotosynthetic plastid found in most protozoan parasites belonging to the phylum Apicomplexa. Among the most infamous Apicomplexan parasites is \"Plasmodium falciparum\", a causative agent of severe malaria. Because apicoplasts are vital to parasite survival, they provide an enticing target for antimalarial drugs. Specifically, apicoplasts' plant-like properties provide a target for herbicidal drugs. And, with the emergence of malarial strains resistant to current treatments it is paramount that novel therapies, like herbicides, are explored and understood. Furthermore, herbicides may be able to specifically target the parasite's plant-like apicoplast and without any noticeable effect on the mammalian host's cells.\n\nEvidence suggests that the apicoplast is a product of secondary endosymbiosis, and that the apicoplast may be homologous to the secondary plastid of the closely related dinoflagellate algae. An ancient cyanobacterium was first engulfed by a eukaryotic cell but was not digested. The bacterium escaped being digested because it formed a symbiotic relationship with the host eukaryotic cell; both the eukaryote and the bacterium mutually benefited from their novel shared existence. The result of the primary endosymbiosis was a photosynthetic eukaryotic alga. A descendent of this eukaryotic alga was then itself engulfed by a heterotrophic eukaryote with which it formed its own symbiotic relationship and was preserved as a plastid. The apicoplast evolved in its new role to preserve only those functions and genes necessary to beneficially contribute to the host-organelle relationship. The ancestral genome of more than 150 kb was reduced through deletions and rearrangements to its present 35 kb size. During the reorganization of the plastid the apicoplast lost its ability to photosynthesize. These losses of function are hypothesized to have occurred at an early evolutionary stage in order to have allowed sufficient time for the complete degradation of acknowledged photosynthetic relicts and the disappearance of a nucleomorph.\n\nMost Apicomplexa contain a single ovoid shaped apicoplast that is found at the anterior of the invading parasitic cell. The apicoplast is situated in close proximity to the cell's nucleus and often closely associated with a mitochondrion. The small plastid, only 0.15-1.5 μm in diameter, is surrounded by four membranes. The two inner membranes are derived from the algal plastid membranes; the next membrane out is called the periplastid membrane and is derived from the algal plasma membrane; Finally the outermost membrane belongs to the host endomembrane system. Within the apicoplast's stroma is a 35 kb long circular DNA strand that codes for approximately 30 proteins, tRNAs and some RNAs. Particles suspected to be bacterial ribosomes are present. The plastid, at least in the Plasmodium species, also contains \"tubular whorls\" of membrane that bear a striking resemblance to the thylakoids of their chloroplast relatives. The import of proteins into the apicoplast through the four membranes occurs through translocation complexes that originate from the algal plastid (for example: ) or from a duplication of the Endoplasmic-reticulum-associated protein degradation (for example: ).\n\nThe apicoplast is a vital organelle to the parasite's survival. Tetracycline, an antibiotic also used to combat malaria infections, is thought to function by targeting the apicoplast. It hosts four main metabolic pathways: \n\nThe destruction of the apicoplast does not immediately kill the parasite but instead prevents it from invading new host cells. This observation suggests that the apicoplast may be involved in lipid metabolism. If unable to synthesize sufficient fatty acids the parasite is unable to form the parasitophorous vacuole (PV) that is imperative to a successful invasion of host cells. This conclusion is supported by the discovery of Type II Fatty Acid Synthase (FAS) machinery in the apicoplast.\n\nThe apicoplast is also thought to have a role in isoprenoid synthesis, which are prosthetic groups on many enzymes and also act as precursors to ubiquinones (involved in electron transport) and dolichols (involved in glycoprotein formation). The apicoplast contains the MEP pathway for isoprenoid precursor synthesis and is the sole site for such synthesis in the \"Plasmodium\" cell.\n\nThe apicoplast has also been implicated with heme synthesis and amino acid synthesis. It is also suggested to have a role in cell development. These functions, however, are merely postulations and are not yet conclusively supported by experimentation.\n\nVarious iron-sulphur cluster biosynthetic enzymes including SufB or Orf470 have been identified in the apicoplast genome.\n"}
{"id": "38540053", "url": "https://en.wikipedia.org/wiki?curid=38540053", "title": "Aqueduct (bridge)", "text": "Aqueduct (bridge)\n\nBridges for conveying water, called aqueducts or water bridges, are constructed to convey watercourses across gaps such as valleys or ravines. The term \"aqueduct\" may also be used to refer to the entire watercourse, as well as the bridge. Large navigable aqueducts are used as transport links for boats or ships. Aqueducts must span a crossing at the same level as the watercourses on each end. The word is derived from the Latin ' (\"water\") and ' (\"to lead\"). A modern version of an aqueduct is a pipeline bridge.They may take the form of underground tunnels, networks of surface channels and canals, covered clay pipes or monumental bridges.\n\nAlthough particularly associated with the Romans, aqueducts were likely first used by the Minoans around 2000 BCE. The Minoans had developed what was then an extremely advanced irrigation system, including several aqueducts.\n\nIn the seventh century BCE, the Assyrians built an 80 km long limestone aqueduct, which included a 10 m high section to cross a 300 m wide valley, to carry water to their capital city, Nineveh.\n\nBridges were a distinctive feature of Roman aqueducts which were built in all parts of the Roman Empire, from Germany to Africa, and especially in the city of Rome, where they supplied water to public baths and for drinking. Roman aqueducts set a standard of engineering that was not surpassed for more than a thousand years.\n\nNavigable aqueducts, also called water bridges, are water-filled bridges to allow vessels on a waterway to cross ravines or valleys. During the Industrial Revolution of the 18th century, navigable aqueducts were constructed as part of the boom in canal-building. A notable revolving aqueduct has been made on the Bridgewater Canal. This allowed vessels to cross at high and low levels while conserving water that would be lost in the operation of locks.\n\n\n\n\n"}
{"id": "214763", "url": "https://en.wikipedia.org/wiki?curid=214763", "title": "Black Elk", "text": "Black Elk\n\nHeȟáka Sápa (Black Elk) (December 1, 1863 – August 19, 1950) was a famous \"wičháša wakȟáŋ\" (medicine man and holy man) and heyoka of the Oglala Lakota (Sioux) who lived in the present-day United States, primarily South Dakota. He was a second cousin of the war chief Crazy Horse.\n\nNear the end of his life, Black Elk met with amateur ethnologist John Neihardt and recounted to him his religious vision, events from his life, and details of Lakota culture. Neihardt edited a translated record and published \"Black Elk Speaks\" in 1932. The words of Black Elk have since been published in numerous editions, most recently in 2008. There has been great interest in his work among members of the American Indian Movement since the 1970s and by others who have wanted to learn more about a Native American religion.\n\nBlack Elk's first wife Katie converted to Roman Catholicism, and they had their three children baptized as Catholics. After Katie's death, in 1904 Black Elk, then in his 40s, converted to Catholicism. He also became a catechist, teaching others about Christianity. He married again and had more children with his second wife; they were also baptized and reared as Catholic. He said his children \"had to live in this world.\" In August 2016, the Roman Catholic Diocese of Rapid City opened an official cause for his beatification within the Roman Catholic Church.\n\nBlack Elk was born into an Oglala Lakota family in December 1863 along the Little Powder River (at a site thought to be in the present-day state of Wyoming). According to the Lakota way of measuring time (referred to as Winter counts), Black Elk was born in \"the Winter When the Four Crows Were Killed on Tongue River\".\n\nWhen Black Elk was nine years old, he was suddenly taken ill; he lay prone and unresponsive for several days. During this time he had a great vision in which he was visited by the Thunder Beings (\"Wakinyan\"), and taken to the Grandfathers — spiritual representatives of the six sacred directions: west, east, north, south, above, and below. These \"... spirits were represented as kind and loving, full of years and wisdom, like revered human grandfathers.\" When he was seventeen, Black Elk told a medicine man, Black Road, about the vision in detail. Black Road and the other medicine men of the village were \"astonished by the greatness of the vision.\"\n\nBlack Elk had learned many things in his vision to help heal his people. He had come from a long line of medicine men and healers in his family; his father was a medicine man, as were his paternal uncles. Late in his life as an elder, he related to John G. Neihardt the vision that occurred to him. Among other things he saw a great tree that symbolized the life of the earth and all people. Neihardt recorded his account in great detail, later publishing it as \"Black Elk Speaks.\" Since the late twentieth century, Black Elk's words have received renewed attention, including from non-Lakota. An annotated edition was published by the State University of New York in 2008.\n\nIn his vision, Black Elk is taken to the center of the earth, and to the central mountain of the world. Mythologist Joseph Campbell explains this recurring symbol among religions as \"the \"axis mundi,\" the central point, the pole around which all revolves ... the point where stillness and movement are together ...\" Black Elk was residing at the axis of the six sacred directions. Campbell viewed Black Elk's statement as key to understanding myth and symbols.\n\nAs Black Elk related:\n\nBlack Elk had many visions throughout his life, which reinforced what he had seen and felt as a boy. He worked among his people as a healer and medicine man.\n\nBlack Elk was present at the Battle of the Little Bighorn. He spoke about the battle to writer John Neihardt:\n\nIn 1887, Black Elk traveled to England with \"Buffalo Bill's Wild West\", an experience he described in chapter twenty of \"Black Elk Speaks.\" On May 11, 1887, the troupe put on a command performance for Queen Victoria, whom they called \"Grandmother England.\" Black Elk was among the crowd at her Golden Jubilee.\n\nIn spring 1888, \"Buffalo Bill's Wild West\" set sail for the United States. Black Elk became separated from the group and the ship left without him, stranding him with three other Lakota. They subsequently joined another wild west show and he spent the next year touring in Germany, France, and Italy. When Buffalo Bill arrived in Paris in May 1889, Black Elk obtained a ticket to return home to Pine Ridge, arriving in autumn of 1889. During his sojourn in Europe, Black Elk was given an \"abundant opportunity to study the white man's way of life,\" and he learned to speak rudimentary English.\n\nBlack Elk participated in the fighting at the Wounded Knee Massacre in 1890. While on horseback, he charged soldiers and helped to rescue some of the wounded. He arrived after many of Spotted Elk's (Big Foot's) band of people had been shot, and he was grazed by a bullet to his hip.\n\nFor at least a decade, beginning in 1934, Black Elk returned to work related to his performances earlier in life with Buffalo Bill. He organized an Indian show to be held in the sacred Black Hills. But, unlike the Wild West shows, used to glorify Native American warfare, Black Elk created a show to teach tourists about Lakota culture and traditional sacred rituals, including the Sun Dance.\n\nBlack Elk married his first wife, Katie War Bonnet, in 1892. She converted to Catholicism, and all three of their children were baptized as Catholics.\n\nHis son, Benjamin Black Elk (1899–1973), became known as the \"Fifth Face of Mount Rushmore\", posing in the 1950s and 1960s for tourists at the memorial. Benjamin played an uncredited role in the 1962 film \"How the West Was Won\".\n\nAfter Katie's death in 1903, Black Elk became a Catholic the next year in 1904, when he was in his 40s. He was christened with the name of Nicholas and later served as a catechist in the church. After this, other medicine men, including his nephew Fools Crow, referred to him both as Black Elk and Nicholas Black Elk.\n\nThe widower Black Elk married again in 1905 to Anna Brings White, a widow with two daughters. Together they had three more children, whom they also had baptized as Catholic. As he later said, his children had to live in \"this world.\" (See below, account by Hilda Neihardt.) The couple were together until her death in 1941.\n\nBlack Elk was a leader in the revival of the Sun Dance (an important religious ceremony among several tribes) and its reinstatement in Lakota life. Lakota traditionalists now follow his version of the dance.\n\nIn the early 1930s, Black Elk revealed the story of his life, and a number of sacred Sioux rituals to John Neihardt and Joseph Epes Brown for publication. Black Elk worked with Neihardt to give a first-hand account of his experiences and that of the Lakota people. His son Ben translated Black Elk's stories into English as he spoke. Neihardt's daughter Enid recorded these accounts. She later arranged them in chronological order for Neihardt's use. Thus the process had many steps and more people than Black Elk and Neihardt were involved in the recounting and recording.\n\nAfter Black Elk told Neihardt his vision over the course of several days, Neihardt asked why Black Elk had \"put aside\" his old religion. According to [Neihardt's daughter] Hilda, Black Elk replied, \"My children had to live in this world.\" In her 1995 memoir, Hilda Neihardt wrote that just before his death, Black Elk took his pipe and told his daughter Lucy Looks Twice, \"The only thing I really believe is the pipe religion.\"\n\nSince the 1970s, the book \"Black Elk Speaks\" has become an important source for studying Native spirituality. With the rise of Native American activism, there was increasing interest among many in their traditional religions. Within the American Indian Movement, for instance, \"Black Elk Speaks\" was an important source for those seeking religious and spiritual inspiration. They also sought out Black Elk's nephew Frank Fools Crow, also a medicine man, for information on Native traditions.\nIn the same period, there has been rising interest among non-Native Americans in Native culture and religions.\n\nOn August 11, 2016, the US Board on Geographic Names officially renamed Harney Peak, the highest point in South Dakota, Black Elk Peak in honor of Nicholas Black Elk and in recognition of the significance of the mountain to Native Americans.\n\nOn October 21, 2017, the cause for canonization for Nicholas Black Elk was formally opened by the Catholic Diocese of Rapid City, South Dakota, paving the way for the possibility of him one day being recognized as a saint. He is now designated as a \"Servant of God.\" His work to share the Gospel with Native and non-Native people and harmonize the faith with Lakota culture were noted at the Mass.\n\n\n\n"}
{"id": "1185183", "url": "https://en.wikipedia.org/wiki?curid=1185183", "title": "Calcutta School of Tropical Medicine", "text": "Calcutta School of Tropical Medicine\n\nCalcutta School of Tropical Medicine (CSTM) is a medical institute from Kolkata, India dedicated in the field of tropical disease. It was established in 1914 by Leonard Rogers (1868-1962) of the Indian Medical Service, professor of pathology at the Calcutta Medical College. It was, till 2003, affiliated with the University of Calcutta. Now it is under the West Bengal University of Health Sciences.\n\nProminent researchers like U. N. Bramhachari, Ronald Ross, Rabindra Nath Chaudhuri, Ram Narayan Chakravarti and Jyoti Bhusan Chatterjea worked in this institute.\n\n\n"}
{"id": "43095580", "url": "https://en.wikipedia.org/wiki?curid=43095580", "title": "Causes of cancer pain", "text": "Causes of cancer pain\n\nCancer pain can be caused by pressure on, or chemical stimulation of, specialised pain-signalling nerve endings called nociceptors (nociceptive pain), or by damage or illness affecting nerve fibers themselves (neuropathic pain).\n\nInfection of a tumor or its surrounding tissue can cause rapidly escalating pain, but is sometimes overlooked as a possible cause. One study found that infection was the cause of pain in four percent of nearly 300 cancer patients referred for pain relief. Another report described seven patients, whose previously well-controlled pain escalated significantly over several days. Antibiotic treatment produced pain relief in all patients within three days.\n\nTumors can cause pain by crushing or infiltrating tissue, or by releasing chemicals that make nociceptors responsive to stimuli that are normally non-painful (\"cf.\" allodynia).\n\n\nBetween 40 and 80 percent of patients with cancer pain experience neuropathic pain.\n\nBrain\n\nMeninges\n\nSpinal cord compression\n\nNerve infiltration or compression\n\nDorsal root ganglion inflammation\n\nBrachial plexopathy\n\nInvasion of bone by cancer is the most common source of cancer pain. About 70 percent of breast and prostate cancer patients, and 40 percent of those with lung, kidney and thyroid cancers develop bone metastases. It is commonly felt as tenderness, with constant background pain and instances of spontaneous or movement-related exacerbation, and is frequently described as severe. Tumors in the marrow instigate a vigorous immune response which enhances pain sensitivity, and they release chemicals that stimulate nociceptors. As they grow, tumors compress, consume, infiltrate or cut off blood supply to body tissues, which can cause pain.\n\nFracture\n\nSkull\n\nPain produced by cancer within the pelvis varies depending on the affected tissue, but it frequently radiates diffusely to the upper thigh, and may refer to the lumbar region. Lumbosacral plexopathy is often caused by recurrence of cancer in the presacral space, and may refer to the external genitalia or perineum. Local recurrence of cancer attached to the side of the pelvic wall may cause pain in one of the iliac fossae. Pain on walking that confines the patient to bed indicates possible cancer adherence to or invasion of the iliacus muscle. Pain in the hypogastrium (between the navel and pubic bone) is often found in cancers of the uterus and bladder, and sometimes in colorectal cancer especially if infiltrating or attached to either uterus or bladder.\n\nVisceral pain is diffuse and difficult to locate, and is often referred to more distant, usually superficial, sites.\n\nLiver\nKidneys and spleen\nAbdominal and urogenital hollow organs\nGastrointestinal\nRespiratory system\nPancreas\nRectum\n\nCarcinosis of the peritoneum may cause pain through inflammation, disordered visceral motility, or pressure of the metastases on nerves. Once a tumor has penetrated or perforated hollow viscera, acute inflammation of the peritoneum appears, inducing severe abdominal pain. Pleural carcinomatosis is normally painless.\n\nInvasion of soft tissue by a tumor can cause pain by inflammatory or mechanical stimulation of nociceptors, or destruction of mobile structures such as ligaments, tendons and skeletal muscles.\n\nSome diagnostic procedures, such as venipuncture, paracentesis, and thoracentesis can be painful.\n\nLumbar puncture\nPost-dural-puncture headache\n\nPotentially painful cancer treatments include immunotherapy which may produce joint or muscle pain; radiotherapy, which can cause skin reactions, enteritis, fibrosis, myelopathy, bone necrosis, neuropathy or plexopathy; chemotherapy, often associated with mucositis, joint pain, muscle pain, peripheral neuropathy and abdominal pain due to diarrhea or constipation; hormone therapy, which sometimes causes pain flares; targeted therapies, such as trastuzumab and rituximab, which can cause muscle, joint or chest pain; angiogenesis inhibitors like bevacizumab, known to sometimes cause bone pain; and surgery, which may produce post-operative pain, post-amputation pain or pelvic floor myalgia.\n\nChemotherapy may cause mucositis, muscle pain, joint pain, abdominal pain caused by diarrhea or constipation, and peripheral neuropathy\n\nChemotherapy-induced peripheral neuropathy\n\nMucositis\n\nMuscle and joint pain\n\nRadiotherapy may affect the connective tissue surrounding nerves, and may damage or kill white or gray matter in the brain or spinal cord.\n\nFibrosis around the brachial or lumbosacral plexus\nSpinal cord damage\n"}
{"id": "13624029", "url": "https://en.wikipedia.org/wiki?curid=13624029", "title": "Caving in New Zealand", "text": "Caving in New Zealand\n\nCaving in New Zealand is an established hobby as well as being a part of commercial tourism.\n\nRecreational caving is practised by several hundred members of caving associations all over New Zealand, who take advantage of the widespread limestone karst cave systems present in the country, especially in the Waitomo District of the North Island and in the Nelson-Tasman region of the South Island. There are also several hundred thousands of visitors to various tourist caves in New Zealand per year, though a majority of these trips would not properly be called caving.\n\nNew Zealand caving as an exploratory sport is thought to have started with a group of Auckland-area people who started to explore the lava caves in the volcanic cones of the area in the 1940s (though commercialised trips through caves at Waitomo Caves had actually already existed for several decades). The group quickly progressed to exploring caves in the Waikato and King Country areas, and the New Zealand Speleological Society was founded in 1949 by Henry Lambert, with the first rough facilities at Waitomo being established in 1955.\n\nIn 1957, the discovery of Harwood's Hole in the South Island was to fully establish New Zealand as a country with extremely promising cave systems, and the cave with its 183 metre deep vertical entry shaft, and its passages extending for many hundreds of meters into the depths, was for a long time the deepest and most famous non-commercial cave in New Zealand. The area around Nelson also contains most of New Zealand's deepest caves (most discovered in the following decades), including Bulmer Cavern, a 70 km long cave system.\n\nNew Zealand's cavers are mostly organised in the New Zealand Speleological Society (NZSS), with 9 affiliated caving clubs with a total of 300 members all over the country.\n\nThere have been a number of notable caving accidents since the 1940s, and at least four deaths . On 4 January 1960, Peter Lambert was killed by falling rocks while being winched out of Harwoods hole, and in 1995, Dave Weaver drowned while cave diving in Pearse Resurgence near Nelson.\n\nIn 1998, one of the most active cavers of the country, Kieran McKay, broke his jaw in Bulmer Cavern on Mt Owen. While the cavern has few squeezes and crawls, the operation to retrieve him from deep within the cave occupied around 80 cavers (in direct position or as support) from all over the country for several days.\n\nIn 2007, Michael Brewer, another experienced caver, was struck by falling rock deep within the Greenlink-Middle Earth cave, in an incident which attracted widespread media attention in the country. Brewer suffered cracked ribs, concussion, and a broken pelvis. It took about 3 days to get him to the surface (a 3 km distance normally taking 5 hours), and while most of the distance was covered with Brewer on a stretcher, and several tight squeezes were widened with explosives, he had to be pushed and pulled through some sections. The effort involved more than 50 cavers and cost around NZ$100,000.\n\nIn 2008, Jane Furket, a 28-year-old experienced recreational caver and member of the Nelson Caving Club, fell in the Luckie Strike cave west of Waitomo. She broke her hip and lost three teeth.\n\nNew Zealand cave rescues are undertaken by SAR teams composed of experienced cavers who have also undergone specialised training courses and exercises.\n\nAs well as lava caves in the Auckland volcanic field there are numerous limestone caves in the North Island, with the most well known being the Waitomo Caves. The longest and deepest caves are in the Kahurangi National Park in the South Island\n\nNew Zealand offers a number of adventure tourism activities and one of them is caving. Most of the commercial caving is done in the Waitomo area, but there are also tours offered in Fiordland and on the West Coast. Black water rafting, where the participants float through caves on tyre inner tubes, was an early tourism venture and has become extremely popular.\n\n\n"}
{"id": "31156984", "url": "https://en.wikipedia.org/wiki?curid=31156984", "title": "Channel 4's Comedy Gala (2011)", "text": "Channel 4's Comedy Gala (2011)\n\nChannel 4's Comedy Gala of 2011 is a British comedy benefit show organised by Channel 4. It is the second Channel 4 Comedy Gala, an annual charity event held O2 Arena in London in aid of the Great Ormond Street Children's Hospital. It was filmed live on 24 May 2011, then broadcast on Channel 4 on 10 June 2011. The first Comedy Gala was held 30 March 2010 and broadcast on 5 April 2010. Billed by Channel 4 as \"the biggest live stand up show in UK history\", it featured seventeen comedians performing stand-up, as well as a number of others performing live and pre-recorded sketches. The first gala raised money for a new anaesthetic room, while the second aims to raise money for a new operating theatre.\n\nAs with the 2010 gala, the 2011 performance was in aid of the Great Ormond Street Children's Hospital. The 2011 proceeds were to go towards funding a new 24-hour operating theatre, costing £5 million. The new theatre would reduce waiting times at the hospital for the children treated from across the UK with life-saving heart, brain and spinal surgery. As with the 2010 show, the performers were to give their time for free for the gala.\n\nOn 10 March 2011, Michael McIntyre and John Bishop visited a cardiac ward of the hospital with the \"Daily Mirror\", who announced a second comedy gala at the O2 in aid of the hospital was to be held on 24 May 2011. To be filmed and broadcast on Channel 4 at a later date, tickets were due to go on sale the next day, at 9am. Channel 4 confirmed this with an announcement on its Comedy Gala website the next day. While tickets went on general sale that day at 9am, a pre-sale begun at 9am the day before.\n\nAs with the 2010 gala, the 2011 show was commissioned by the Channel 4 commissioning editor Syeda Irtizaali, the promoter was Off the Kerb Productions and it was to be filmed by Open Mike Productions.\n\nThe gig at the O2 was to open at 6.30pm.\n\nWhen the second gala was announced, the confirmed line-up included the following performers:\n\n\nPromoters Off the Kerb also listed the following acts:\n\nVideo Appearances listed by the following:\n\nAs with the 2010 show, the filming of the 2011 was to have a DVD release by Universal Pictures.\n\n\n"}
{"id": "1509191", "url": "https://en.wikipedia.org/wiki?curid=1509191", "title": "Cohort (statistics)", "text": "Cohort (statistics)\n\nIn statistics, marketing and demography, a cohort is a group of subjects who share a defining characteristic (typically subjects who experienced a common event in a selected time period, such as birth or graduation).\n\nCohort data can oftentimes be more advantageous to demographers than period data. Because cohort data is honed to a specific time period, it is usually more accurate. It is more accurate because it can be tuned to retrieve custom data for a specific study.\n\nIn addition, cohort data is not affected by tempo effects, unlike period data. On the contrary; cohort data can be disadvantageous in the sense that it can take a long amount of time to collect the data necessary for the cohort study. Another disadvantage of cohort studies is that it can be extremely costly to carry out, since the study will go on for a long period of time, demographers often require sufficient funds to fuel the study.\n\nDemography often contrasts cohort perspectives and period perspectives. For instance, the total cohort fertility rate is an index of the average completed family size for cohorts of women, but since it can only be known for women who have finished child-bearing, it cannot be measured for currently fertile women. It can be calculated as the sum of the cohort's age-specific fertility rates that obtain as it ages through time. In contrast, the total period fertility rate uses current age-specific fertility rates to calculate the completed family size for a notional woman, were she to experience these fertility rates through her life.\n\nA study on a cohort is a cohort study.\n\nTwo important aspects of cohort studies are: \n\n\n"}
{"id": "46610630", "url": "https://en.wikipedia.org/wiki?curid=46610630", "title": "Dell Medical School", "text": "Dell Medical School\n\nThe Dell Medical School is the graduate medical school of The University of Texas at Austin in Austin, Texas. The school opened to the inaugural class of 50 students in the summer of 2016 as the newest of 18 colleges and schools on the UT Austin campus. S. Claiborne \"Clay\" Johnston, M.D., Ph.D., was named as the medical school's inaugural dean in January 2014.\n\nIn accordance with the Medical District Master Plan released in 2013, the University's portion of the medical district is being constructed in three phases. The new medical campus will sit on existing University property at the southeastern corner of the central campus, adjacent to the existing UT School of Nursing and to the Dell Seton Medical Center at The University of Texas—the new $295 million, 211-bed teaching hospital that Seton Healthcare is building.\n\nIn late 2011, Texas Senator Kirk Watson created a list of ten health-care centered goals he hoped to achieve within ten years for his Central Texas district. Number one on that list was to build a medical school. In May 2012, the Board of Regents allocated $25 million of annual funding to a UT Austin medical school, plus another $40 million spread over eight years for faculty recruiting. In November 2012, Travis County voters approved a proposition to raise property tax revenue in support of health care initiatives for Central Texas, including $35 million annually for a medical school.\n\nThe medical school is named after the Michael & Susan Dell Foundation, which has pledged $50 million over ten years to the school.\n\n"}
{"id": "59017968", "url": "https://en.wikipedia.org/wiki?curid=59017968", "title": "Diving regulations", "text": "Diving regulations\n\nDiving regulations are the stipulations of the delegated legislation regarding the practice of underwater diving.\n\nThe scope of diving regulations is generally defined in each specific set of regulations and the statutory law which empowers them, which can vary considerably across jurisdictions.\n\nDiving regulations apply within the national territorial waters of the country.\n\nDiving regulations apply within the national territorial waters of the country. In general they do not apply in international waters, but the commercial diving industry operates in international waters, in what is generally known as the offshore diving industry. In these waters the industry is largely self-regulated through voluntary membership of organisations such as the International Marine Contractors Association (IMCA). Members of these organisations are required as a condition of membership to comply with their Codes of Practice.\n\nIn some jurisdictions specific exemptions and exceptions may be stipulated. For example:\n\nAustralia \n\nCanada\n\nSouth Africa – Diving regulations to the Occupational Health and Safety Act, authorised by the Minister of Labour. \nThe South African diving regulations regulate professional diving using breathing apparatus, and specifically exclude instruction of recreational divers and recreational dive leadership. They apply only where the Occupational Health and Safety Act applies, so do not cover diving in minerals and energy industries, which have different safety legislation.\n\nUnited Kingdom – The diving at Work Regulations 1997, Statutory Instruments 1997 No. 2776 Health and Safety \n\nUnited States\n\n[["}
{"id": "30537035", "url": "https://en.wikipedia.org/wiki?curid=30537035", "title": "Firearm malfunction", "text": "Firearm malfunction\n\nA firearm malfunction is the failure of a firearm to operate as intended for causes other than user error. Malfunctions range from temporary and relatively safe situations, such as a casing that didn't eject, to potentially dangerous occurrences that may permanently damage the gun and cause injury or death. Improper handling of certain types of malfunctions can be very dangerous. The basic rules of firearms safety should be followed at all times to minimize the risk to shooters and bystanders. Proper cleaning and maintenance of a firearm plays a big role in preventing malfunctions. \n\nCase head separation occurs when the walls of the casing become thin or fatigued. Upon firing the round, the case separates into two pieces near the head. It is not uncommon with brass that has been reloaded several times.\n\nA dud (also a misfire or failure to fire) occurs when the trigger is pulled but the primer or powder in the cartridge malfunctions, causing the firearm not to discharge. Dud rounds can still be dangerous and should be deactivated and disposed of properly. \n\nA hang fire (also delayed discharge) is an unexpected delay between the triggering of a firearm and the ignition of the propellant. Whenever a firearm fails to fire, but has not clearly malfunctioned, a hang fire should be suspected. When this occurs, the correct procedure is to keep the firearm pointed downrange or in a safe direction for thirty to sixty seconds, then remove and safely discard the round (which is now a dud as explained above if the primer was struck, otherwise the gun itself may have malfunctioned). The reason for this is that a round functioning outside of the firearm, or in the firearm with the action open (out-of-battery discharge), could cause a serious fragmentation hazard.\n\nA squib load (also squib round, squib, squib fire, insufficient discharge, incomplete discharge) is an extremely dangerous malfunction that happens when a fired projectile does not carry enough force and becomes stuck in the gun barrel instead of exiting it. In the case of semi-automatic or automatic weapons, this can cause subsequent rounds to impact the projectile obstructing the barrel, which can cause a catastrophic failure of the structural integrity of the firearm, posing a threat to the operator or bystanders. The bullet from a squib stuck in the barrel must never be cleared by subsequently attempting to fire a live or blank round into an obstructed barrel. Blank rounds use a type of powder different from that of other rounds, and generate much more pressure, which, combined with the presence of the projectile obstructing the barrel may cause the firearm to fail catastrophically.\n\nMechanical malfunctions of a firearm (commonly called jams) include failures to feed, extract, or eject a cartridge; failure to fully cycle after firing; and failure of a recoil- or gas-operated firearm to lock back when empty (largely a procedural hazard, as \"slide lock\" is a visual cue that the firearm is empty). In extreme cases, an overloaded round, blocked barrel, poor design and/or severely weakened breech can result in an explosive failure of the receiver, barrel, or other parts of the firearm.\n\nFailure to Feed (FTF) is when a firearm fails to feed the next round into the firing chamber. Failure to feed is common when the shooter does not hold the firearm firmly (known as limp wristing), when the slide is not fully cycled by the preceding round, or due to problems with the magazine. It can also be caused by worn recoil springs, buffer springs, or simply a dirty feed ramps.\n\nHammer follow occurs when the disconnector allows the hammer to follow the bolt and firing pin into battery, sometimes causing the firing mechanism to function without pulling the trigger. This is usually a result of extreme wear or outright breakage of firing mechanism components, and can result in uncontrollable \"full-auto\" operation, in which multiple rounds are discharged following a single pull of the trigger.\n\nA slamfire is a premature, unintended discharge of a firearm that occurs as a round is being loaded into the chamber, when the bolt \"slams\" forward (hence the name), as a result of the firing pin having not been retracted into the bolt, or from the firing pin being carried forward by the momentum of returning to battery. Similarly to a hammer follow malfunction, this can result in uncontrollable \"full-auto\" operation.\n\nA failure to extract occurs when the casing of the just-fired round is not successfully extracted from the chamber. This can be caused by an overly-dirty chamber, broken extractor claw, case rim failures, or several other causes.\n\nA failure to eject (FTE) occurs when the casing of the just-fired round is extracted from the chamber, but is not ejected from the firearm, causing the next round to fail to feed, or the slide/bolt to fail to return to battery. A stovepipe is common type of FTE.\n\nA stovepipe or smokestack typically occurs in pump action, semi-automatic, and fully automatic firearms that fire from a closed bolt, when an empty cartridge case gets caught partway out of the ejection port instead of being thrown clear. Stovepipes can be caused by a malfunctioning or defective extractor or ejector, or when the shooter does not hold the firearm firmly enough for the action to function fully, known as limp wristing, or due to reloads that are not sufficiently powerful to fully cycle the action, etc.\n\nA double feed occurs when an expended round is in the chamber AND the slide picks up a second round from the magazine mashing it into the first. This can be caused by a broken extractor or a broken casing left behind in the chamber, and to be cleared could require simple tools.\n\nA firearm is \"in-battery\" when the slide/bolt is in the normal firing position. A firearm is \"out-of-battery\" when the slide/bolt/action is not fully seated in the normal firing position, typically because it did not cycle fully after firing (called \"returning to battery\"). Most modern firearms are designed to not be capable of firing when significantly out-of-battery. As such, a firearm that is out-of-battery typically cannot be fired, which is why this is a type of firearm malfunction.\n\nA dangerous situation can occur when a chambered round fires when the firearm is out-of-battery (called an out-of-battery discharge). The cartridge casing is not sufficiently strong to contain the pressure of firing by itself; it relies on the walls of the chamber and the bolt face to help contain the pressure. When the firearm is out-of-battery, the round is not fully chambered, or the bolt face is not against the rear of the cartridge, and if the round is fired in this situation, the case will fail, causing high-pressure hot gasses, bits of burning powder, and fragments of the casing itself to be thrown at high-speed from the firearm. This can be a serious hazard to the operator of the firearm, and any bystanders.\n\nSome mechanical malfunctions are caused by poor design and cannot easily be avoided. Some malfunctions with cartridges can be attributed to poor quality or damaged ammunition (often due to improper storage, exposure to moisture). Many malfunctions, however, can be prevented by proper cleaning and maintenance of the firearm.\n"}
{"id": "7128600", "url": "https://en.wikipedia.org/wiki?curid=7128600", "title": "Gray baby syndrome", "text": "Gray baby syndrome\n\nGray baby syndrome (also termed Gray or Grey syndrome) is a rare but serious side effect that occurs in newborn infants (especially premature babies) following the accumulation of antibiotic chloramphenicol.\n\nToxic levels of chloramphenicol after 2–9 days result in:\n\nTwo pathophysiologic mechanisms are thought to play a role in the development of gray baby syndrome after exposure to the anti-microbial drug chloramphenicol. This condition is due to a lack of glucuronidation reactions occurring in the baby, thus leading to an accumulation of toxic chloramphenicol metabolites:\nDue to these two reasons the chloramphenicol level in blood is increased, at higher concentration chloramphenicol blocks electron transport in the liver, myocardium, and skeletal muscles, resulting the above symptoms.\nThe condition can be prevented by using chloramphenicol at the recommended doses and monitoring blood levels, or alternatively, third generation cephalosporins can be effectively substituted for the drug, without the associated toxicity.\n\nChloramphenicol therapy should be stopped immediately. Exchange transfusion may be required to remove the drug. Sometimes, phenobarbital (UGT induction) is used.\n"}
{"id": "34447223", "url": "https://en.wikipedia.org/wiki?curid=34447223", "title": "Homeopathy in New Zealand", "text": "Homeopathy in New Zealand\n\nHomeopathy practice is unregulated in New Zealand and homeopathic remedies are available at pharmacies, although there are calls to have them removed from sale.\n\nA small-scale survey of homeopathic practitioners of New Zealand in 2008 showed that they all claimed to be able to treat asthma and ear infections, and statements such as \"hundreds of remedies for ear infections and asthma\" and \"homeopaths have a success rate nearing 80%\" were made.\n\nThough large scale studies conducted across the world show that homeopathy is a pseudoscience and its remedies have been found to be no more effective than placebo., the New Zealand Medical Association does not oppose the use of alternative medical practices such as homeopathy if it can be shown that the patient can make an informed choice; however, this stance has been called unethical and may be in contravention of medical regulations.\n\nThe New Zealand Skeptics organisation took part in the international campaign in 2011. Protests were held in Auckland, Wellington and Christchurch.\n\nA 2012 survey showed that 51% of the New Zealand population had some degree of belief that homeopathic remedies were scientifically proven.\nThe Auckland Homeopathic Hospital, with Carl Fisher as superintendent, operated from 1858 to 1862. For a half-yearly report of 1859 a total of 34 patients out of 55 were claimed to have been cured.\n\nThere are a number of training providers that teach homeopathy, and the New Zealand Qualifications Authority issues credits for homeopathy courses.\n\nThe New Zealand Council of Homeopaths, formed in 1999, acts as an representative for the industry. It was formed by the amalgamation of New Zealand Homoeopathic Society, the New Zealand Institute of Classical Homeopathy and the New Zealand Accreditation Board of Natural Therapies.\n\nThe Commerce Commission, which administers the Fair Trading Act, has prosecuted companies for misleading claims about homeopathic products.\n\nIn 1997 SCI Natural (NZ) Ltd was to be prosecuted for claims that the Soft Seaweed Soap product would help people to lose weight. The Commerce Commission decided not to go ahead with the prosecution since a key individual had left New Zealand and the company went into liquidation. A Tauranga-based couple who specialised in homoeopathic remedies pleaded guilty to 19 charges under the Fair Trading Act in 2008 for making misleading claims.\n\n\n"}
{"id": "25405300", "url": "https://en.wikipedia.org/wiki?curid=25405300", "title": "Hoshizuka Keiaien Sanatorium", "text": "Hoshizuka Keiaien Sanatorium\n\nHoshizuka Keiaien Sanatorium, (National Sanatorium Hoshizuka Keiaien) is a sanatorium for leprosy patients or ex-leprosy patients in Kanoya-shi, kagoshima-ken, Japan which was established in 1935.\nFollowing the establishment of prefectural sanatoriums, the Japanese government decided to increase sanatoriums, first with National Sanatorium Nagashoma Airakuen in 1930. Hoshizuka Keiaien was the 4th sanatorium which was established in 1935. Unlike other areas, resistance to the establishment of this sanatorium was small.\n\n\nThe number of in-patients is the sum of patients which changed not only by the newly diagnosed hospitalized and those who died among in-patients, by other factors such as the number of patients who escaped or were discharged, depending on the condition of the times. Recently they were encouraged to be discharged, but the long period of the segregation policy causing leprosy stigma might influence the number of those who went into the society. \n\nIt was at the congress of the Japanese Leprosy Association held in the Keiaien Sanatorium on November 2 and 3, 1947 that the effects of promin were first reported. At first it did not attract attention since cepharanthin, a new drug for leprosy which had been tested earlier proved disappointing. Promin use started in November 1948, and the effects of promin were amazing. \"Give us promin\" movement began. The first patient cleared with promin was discharged in April, 1953. \n\nLeprosy in earlier days has been associated with scabies, and this has been pointed out by Kensuke Mitsuda. There were many cases of scabies.\n\n\n"}
{"id": "26634144", "url": "https://en.wikipedia.org/wiki?curid=26634144", "title": "Ibn Sina Academy of Medieval Medicine and Sciences", "text": "Ibn Sina Academy of Medieval Medicine and Sciences\n\nIbn Sina Academy of Medieval Medicine and Sciences (IAMMS) () is a trust registered under the Indian Trusts Act, 1882. Mohammad Hamid Ansari, former vice-chancellor of Aligarh Muslim University, Aligarh, formally inaugurated it on 21 April 2001. Department of AYUSH, Ministry of Health and Family Welfare, Government of India gave accreditation to the academy in 2004 and promoted it as 'centre of excellence' in 2008. Membership of the academy is open to anyone who has an interest in the academy's activities particularly on history of medicine and history of science. Being a charitable organization, donations to the Academy are also exempted from Income Tax under section 80G of the Income Tax Act 1961.\n\nThe founder president is Hakim Syed Zillur Rahman.\n\nIbn Sina Academy is a part of signatories related to various health issues in the world.\n\nIbn Sina Academy of Medieval Medicine and Sciences is an extension of Majlis Ibn Sina, which was formed in 1965 under the aegis of Tibbi Academy. Majlis Ibn Sina was a sort of monthly discussion group. For instance, the first meeting of that Majlis was held to discuss typhoid.\n\nTibbi Academy was itself formed in 1963 at Bhopal. In a note on page 4, of the first book of Tibbi Academy, on \"Modern Times and Unani Medicine\" the author Hakim Syed Zillur Rahman announced the establishment of Tibbi Academy with its clear objective: \"to publicise the theoretical principles and practical ideas of Unani medicine, to publish the text of standard works of Unani medicine and also their translations… further, a learned and research oriented monthly journal\".\n\nFrom 1965 to 1970, a monthly journal with the title \"Al-Hikmat\" (in Urdu) from Delhi was published under the auspices of Tibbi Academy under the editorship of Syed Zillur Rahman Nadvi. The editor stated in the introduction of the first issue (May 1965, page 2) that the journal is being issued.\n\nFurther, besides the above-mentioned objectives, the editor listed a couple of additional objectives, e.g., \"the search of manuscripts of the Unani medicine, their edition and publication, … to excite the feeling of the pressing need of Unani medicine literature, and to publish a standard book every year\". He lamented that despite the publication of 30-40 Tibbi magazines in India, no learned journal of Unani medicine is being published. He stressed that \"Al-Hikmat\" would be a purely scholarly journal not confined to Unani medicine: It would include some articles on basic sciences, that is, zoology, botany, chemistry, physics, astronomy and philosophy.\n\nIn 1970, Hakim Syed Zillur Rahman renamed the Tibbi Academy as Shifaul Mulk Memorial Committee after his teacher, Shifaul Mulk Hakim Abdul Latif (29 April 1900 – 14 November 1970), former professor and principal of Ajmal Khan Tibbiya College, Aligarh Muslim University. The purpose of this memorial committee was the same as Tibbi Academy formed in 1963, except the widened scope of publications.\n\nAll these past establishments — Tibbi Academy (1963), Majlis Ibn Sina (1965) and Shifaul Mulk Memorial Committee (1970) — merged and came under one trustee organisation, i.e., Ibn Sina Academy of Medieval Medicine and Sciences in 2000. It was formally inaugurated on 21 April 2001.\n\nThe library houses one of the most precious and valuable collection of 20,000 printed books, 500 manuscripts, some rare books, microfilms, compact discs and a large number of periodicals. Books in many languages like Arabic, Persian, Urdu, Sanskrit and English on subjects like History of Medicine and Sciences, Unani, Medieval medicine, Ilmul Advia (Pharmacology), Urdu Literature with special reference to Ghalib, Iqbal, Aligarh and Sir Syed Ahmad Khan, besides thousands of bound volumes of magazines are extant in this library.\n\nThe library is listed in the Directory of History of Medicine Collections, United States Department of Health and Human Services, National Library of Medicine, NIH.\n\nKaram Husain Museum on History of Medicine and Sciences is an academic unit with collections and exhibitions. The main theme is the history of health and disease in a cultural perspective, with focus on the material and iconographic culture of medieval medicine and sciences. The museum has categorically the illustrations and busts of physicians belonging to Mesopotamia, Babylonian, Egyptians, Greeks, Arab and Indian civilizations. In addition, medical manuscripts, catalogues, medical philately, medical souvenirs, memoirs of physicians including Nobel laureates, etc., are preserved and exhibited.\n\nThe museum is listed in the 'World's 10 weirdest medical museums', as per CNN Travel.\n\nThis museum is located on the 2nd Floor and has 4 main galleries. The Crockery Gallery has a large collection of oriental and British India utensils, plates, bowls, tea-set belonged to many prominent personalities like Hakim Ajmal Khan, Nawab Yusef Ali Khan, Kaikhusrau Jahan, Begum of Bhopal, Sultan Shah Jahan, Begum of Bhopal, etc. The Textile Gallery consists of attires, garments, calico of gold and silver studded stones and many other oriental clothes. The Picture Gallery has pictures, drawings, watercolors, photographic print and paintings especially of people belonged to Aligarh and Aligarh Muslim University. Miscellaneous Gallery has many objects of coins, postage stamps, gemstones, engravings including vintage cameras, clocks, busts, pens, memoirs and relics of some prominent personalities. In the same gallery, there are separate family collections that belong to Prof. Syed Mahmood Husain, Roohi Mabud Hasan, Hakim Syed Fazlur Rahman, etc. In addition, there is a separate \"Skins and Taxidermy Collection\" displayed on the ground floor.\n\n1. \"Newsletter of Ibn Sina Academy (NISA)\", a quarterly newsletter since 2001 (68 issues published).\n2. \"International Journal of Medical Research Professionals (IJMRP)\".\n3. \"International Archives of BioMedical and Clinical Research (IABCR)\".\n\nThe academy has published a number of books on the history of medicine and sciences including pharmacology and literature.\n\nBefore the existence of Ibn Sina Academy, publications were done under the aegis of Tibbi Academy, formed in 1963. The first book of the Tibbi Academy was \"Daur Jadeed aur Tibb\" (Modern Times and Unani Medicine). From 1965 to 1970, a monthly Urdu journal, \"Al-Hikmat\", was published under the auspices of Tibbi Academy. Under the Shifaul Mulk Memorial Committee many more publications came into existence and are known to the world of history of medicine. The Memorial Committee and Tibbi Academy are now a part of the Publication Division of Ibn Sina Academy.\n\nAIDS Cell of IAMMS was established in the year 2002 with Dr Imran Sabri as the founder Incharge of this prestigious institute. The Main AIM of the AIDS Cell is to spread awareness about AIDS in common population and newly graduated doctors.\nAIDS Cell of the academy is dedicated to improving lives, knowledge, and understanding worldwide through a highly diversified programme of research, education, and services in HIV/AIDS screening and prevention, care and treatment, reproductive health and infectious diseases. AIDS Cell is a partner member of Global Health Council (USA) and the AIDS-Care-Watch Campaign (Thailand).\nIt has a separate library of documents relevant to HIV/AIDS project management, research, and reproductive health issues apart from CD-ROMs, poster and books in several languages.\nAIDS Cell of IAMMS claims responsibility of holding Symposium on Medico-Social implication of the emerging epidemic of HIV/AIDS on India, Free Health check-up and Drug Distribution camp.\n\nFor clinical studies of indigenous drugs, IAMMS is engaged in research and development in its clinical set-up, Ibn Sina Shifakhana, at Okhla Vihar, New Delhi.\n\nThe academy took a novel task of improving the use of Indian originated drugs and their adverse reaction monitoring under the establishment of Centre for Safety & Rational Use of Indian Systems of Medicine (CSRUISM) in 2005. CSRUISM receives many adverse drug reactions of herbs, which were never reported earlier. These reactions for their causal relationships are assessed according to Naranjo algorithm and WHO causality categories. The Centre has organised many CMEs on Pharmacovigilance in association with Society of Pharmacovigilance, India\n\nThis centre was set up to study Urdu poetry particularly of Mirza Ghalib. The centre has a largest collection on 'Ghalibiat' (things related to poet Ghalib). It has several books and periodicals especially ‘Ghalib Numbers’ issued particularly as a part of his birth centenary observed all over the world in 1969. In addition, there are hundreds of other poets’ collection, memoirs and writings. The Centre is famous for organising Mushaira and till now has published two books on Mirza Ghalib.\n\n\nSeries of Ibn Sina Memorial Lecture:\n- First Ibn Sina Memorial Lecture (2006) by Saiyid Hamid (Delhi)\n- Second Ibn Sina Memorial Lecture (2007) by Syed Mushirul Hasan (Delhi)\n- Third Ibn Sina Memorial Lecture (2008) by Syed Shahid Mehdi (Delhi)\n- Fourth Ibn Sina Memorial Lecture (2009) by Irfan Habib (Aligarh)\n- Fifth Ibn Sina Memorial Lecture (2010) by Sadiqur Rahman Kidwai (Delhi)\n- Sixth Ibn Sina Memorial Lecture (2011) by Dr. Ahmad Abdul Hai (Patna)\n- Seventh Ibn Sina Memorial Lecture (2012) by Moosa Raza (Villupuram, Tamil Nadu)\n- Eight Ibn Sina Memorial Lecture (2013) by Muhammad Zakaria Virk (Ontario, Canada)\n- Ninth Ibn Sina Memorial Lecture (2015) by Dr. (Maulana) Kalbe Sadiq (Lucknow)\n- Tenth Ibn Sina Memorial Lecture (2016) by Dr. Ather Farouqui (Delhi)\n- Tenth Ibn Sina Memorial Lecture (2016) by Dr. Ather Farouqui (Delhi)\n- Tenth Ibn Sina Memorial Lecture (2016) by Dr. Ather Farouqui (Delhi)\n- Eleventh Ibn Sina Memorial Lecture (2017) by Dr. Naresh (Panchkula, Haryana)\n\nSeries of Prof. M. Nasim Ansari Oration:\n- First Lecture (2007) by Dr. Md. Tauheed Ahmad (Aligarh)\n- Second Lecture (2008) by Dr. M. Habib Raza (Aligarh)\n- Third Lecture (2009) by Dr. D. P. Singh Toor (Delhi)\n- Fourth Lecture (2010) by Dr. Syed Badrul Hasan (Aligarh / Bhopal)\n- Fifth Lecture (2011) by Prof. M. Hanif Beg (Aligarh)\n- Sixth Lecture (2012) by Dr. Syed Badrul Hasan (Aligarh / Bhopal)\n- Seventh Lecture (2013) by Prof. Arshad Hafeez Khan (Aligarh)\n- Eighth Lecture (2014) by Prof. Saeeduzzafar Chaghtai (Aligarh)\n- Ninth Lecture (2015) by Prof. Mohd Zaheer (Aligarh)\n- Tenth Lecture (2016) by Prof. Dipti Tripathi (Former Director, National Mission for Manuscripts, Delhi)\n- Eleventh Lecture (2017) by Dr. Vandana Roy (Professor Director and Head, Department of Pharmacology, Maulana Azad Medical College, Delhi)\n- Twelfth Lecture (2018) by Prof. O. P. Kalra (Vice Chancellor, Pandit Bhagwat Dayal Sharma University of Health Sciences, Rohtak)\n\n"}
{"id": "2114869", "url": "https://en.wikipedia.org/wiki?curid=2114869", "title": "Ideal Marriage: Its Physiology and Technique", "text": "Ideal Marriage: Its Physiology and Technique\n\nIdeal Marriage: Its Physiology and Technique is a famous popular scientific treatise and self-help book published in London in 1926 by Dutch gynecologist Theodoor Hendrik van de Velde, retired director of the Gynecological Clinic in Haarlem, and \"one of the major writers on human sexuality during the early twentieth century\" (Frayser & Whitby, p. 300). It was the best-known work on its subject for several decades, and was reprinted 46 times in the original edition. After World-War Two, it sold over a half-million copies. A revised edition was published in 1965. and a subsequent one in 2000 (Melody & Pearson, p. 96).\n\nIt proclaimed the \"critical goal of marriage consists of sexual pleasure shared by husband and wife\" (Melody and Person, p. 93). A 2000 edition of the book described itself as concentrating \"on the cultivation of the technique of eroticism as an art in marriage.\"\n\nFrederica Mathewes-Green, in the \"National Review\", described it as\n\nThe first printing had an insert: \"The sale of this book is strictly limited to members of the medical profession, Psychoanalysts, Scholars, and to such adults as may have a definite position in the field of Physiological, Psychological, or Social Research.\" It was placed on the Index Librorum Prohibitorum in 1931.\n\n\n\n"}
{"id": "1925921", "url": "https://en.wikipedia.org/wiki?curid=1925921", "title": "John Gofman", "text": "John Gofman\n\nJohn William Gofman (September 21, 1918 – August 15, 2007) was an American scientist and advocate. He was Professor Emeritus of Molecular and Cell Biology at University of California at Berkeley.\n\nGofman pioneered the field of clinical lipidology, and was honoured with the title of \"Father of Clinical Lipidology\" by the Journal of Clinical Lipidology in 2007. With Frank T. Lindgren and other research associates, Gofman discovered and described three major classes of plasma lipoproteins, fat molecules that carry cholesterol in the blood. The team he led at the Donner Laboratory went on to demonstrate the role of lipoproteins in the causation of heart disease.\nGofman was instrumental in inducing the health physics scientific community both to acknowledge the cancer risks of ionizing radiation and to adopt the Linear No-Threshold (LNT) model as a means of estimating actual cancer risks from low-level radiation and as the foundation of the international guidelines for radiation protection.\n\nGofman's earliest research was in nuclear physics and chemistry, in close connection to the Manhattan Project. He co-discovered several radioisotopes, notably uranium-233 and its fissionability ; he was the third person ever to work with plutonium, and, having devised an early process for separating plutonium from fission products at J. Robert Oppenheimer’s request, he was the first chemist ever to try and isolate milligram quantities of plutonium.\n\nIn 1963, Gofman established the Biomedical Research Division for the Livermore National Laboratory, where he was on the cutting edge of research into the connection between chromosomal abnormalities and cancer.\n\nLater in life, Gofman took on a role as an advocate warning of dangers involved with nuclear power. From 1971 onward, he was the Chairman of the Committee for Nuclear Responsibility. He was awarded the Right Livelihood Award for his work on the effects of the Chernobyl disaster's low-level radiation exposure on the population.\n\nJohn Gofman graduated from Oberlin College with a bachelor's in chemistry in 1939, and received a doctorate in nuclear and physical chemistry from Berkeley in 1943, where he worked as a graduate student under Glenn T. Seaborg, the discoverer of plutonium and later a chairman of the US Atomic Energy Commission. In his PhD dissertation, Gofman described the discovery of radioisotopes protactinium-232, uranium-232, protactinium-233, as well as uranium-233 and the characterization of its fissionability. Seaborg had a very high opinion of Gofman : he called Gofman one of his \"most brilliant students\" when, in 1963, he appointed him to head the Biomedical Research Division at the Lawrence Livermore Laboratory; he wrote that his PhD dissertation was \"very brilliant\".\n\nGofman shared three patents with collaborators on their discoveries :\n\nGofman later became the group co-leader of the Plutonium Project, an offshoot of the Manhattan Project.\n\nDr. Gofman earned his medical degree from the University of California, San Francisco, in 1946. After that, he and his collaborators investigated the body’s lipoproteins, which contain both proteins and fats, and their circulation within the bloodstream. The researchers described low-density and high-density lipoproteins and their roles in metabolic disorders and coronary disease. This work continued throughout the late 1940s and early 1950s.\n\nAt the request of Ernest Lawrence, Gofman established the Medical Department at the Lawrence Livermore National Laboratory (LLNL) in early 1954 and acted as the Medical Director until 1957 roughly two days a week while teaching at Berkeley the rest of the time.\n\nIn 1962, the US had resumed atmospheric tests of nuclear weapons at the Nevada test site in 1962. The State of Utah had set up its own network of monitoring facilities to test milk for radioiodine, since \"data pertaining to the safety of the citizens of Utah was not forthcoming from the AEC\", and the levels of radioactivity were found to be close to the limits prescribed by the Federal Radiation Council. The Commissioners of the AEC were \"on the hot seat\" and announced \"a comprehensive, long-range program\" to explore the effects of man-made radioactivity \"upon plants, animals and human beings\". At the request of the US Atomic Energy Commission and of LLNL's director John Foster, Gofman reluctantly accepted to establish the Biomedical Research Division for the LLNL in 1963. He served as the first director of the LLNL biomedical research division from 1963 to 1965 and as one of the nine associate directors of the entire lab until 1969.\n\nThe AEC had acted too fast in response to public outcry : one of the five Commissioners, James T. Ramey, had not been consulted before announcing the establishment of the Biomedical Research Division. Gofman reported that \"Apparently it would have been too embarrassing, with the extensive AEC publicity about the program, to cancel it outright. Instead, the budget was cut even from the low starting value and we were given to understand, in no uncertain terms, that the program was not going to be supported at the level required to do the tasks outlined originally.\" However, Gofman and colleagues \"accepted the reduced program, knowing that [they] could certainly still do much of the important work on radiation hazards.\"\n\nAfter the atmospheric test ban treaty was signed in June 1963 and the public pressure on AEC was released, \"[t]he Joint Committee on Atomic Energy struck from the AEC budget the funds that were to be used to construct a Bio-Medical complex at Livermore. This was tantamount to the JCAE stating that the Livermore Bio-Medical Program was unnecessary, for without facilities to work in it was hard to envision much of a program being possible.\" LLNL's director John Foster and Gofman had to struggle to obtain the initially promised funds.\n\nIn 1959, the geneticist Edward B. Lewis computed that children exposed to fallout from nuclear tests may have received very high doses of radioactivity from iodine-131 in cow milk. His estimates prompted the Joint Committee on Atomic Energy to request that the AEC produce a report on the risks of short-lived isotopes. In 1960, Harold A. Knapp, a mathematician working within the AEC Division of Biology and Medicine's Fallout Studies Branch, authored this report, but since it was finished during an international moratorium on atmospheric nuclear tests, it had no notable impact. Then, in 1962, while the USSR and the USA had resumed nuclear tests and the Limited Test Ban Treaty was being prepared in response to huge international pressure, Knapp took on the task of estimating the radioiodine exposure of Americans before 1958, at a time when milk was not monitored. Knapp conclusions were alarming, and blatantly departed from preceding AEC's reassurances that the public had never been exposed to harmful levels of radioactivity. He \"showed that, from just one 1953 test, infants who had been living in a radiation hotspot around St. George, Utah, might well have received I-131 doses anywhere from 150 to 750 times existing annual permissible doses.\" \n\nBeginning in fall 1962, the AEC resorted to diverse pretexts to block the publication of Knapp's findings. In spring 1963, Gofman, was solicited to participate in a so-called \"Ad Hoc Working Group on Radioiodine and the Environment\" assembled by AEC's Division of Operational Safety's director, Gordon Dunning. Gofman reported that \"In essence, the message to [this] Committee […] was « How can we stop this report - a report which will, in effect, make the AEC reports over the past 10 years look untrue? »\". In spite of AEC's Headquarters' objections, the committee recommended publication of Knapp's report, which was finally published by the AEC in June 1963, followed by a summary in \"Nature\".\n\nIn 1964, Gofman raised questions about a lack of data on low-level radiation and also proposed a wide-ranging study of exposure in medicine and the workplace at a symposium for nuclear scientists and engineers. This helped start a national inquiry into the safety of atomic power. With his colleague Dr. Arthur R. Tamplin, Dr. Gofman then looked at health studies of the survivors of Hiroshima and Nagasaki, as well as other epidemiological studies, and conducted research on radiation’s influences on human chromosomes. The two scientists suggested that federal safety guidelines for low-level exposures be reduced by 90 percent in 1969. The Atomic Energy Commission contested the findings, and \"the furor made Dr. Gofman a reluctant figurehead of the anti-nuclear movement\" according to \"The New York Times\". In 1970, he testified in favor of a bill to ban commercial nuclear reactors in New York City and told the City Council that a reactor in an urban environment would be \"equal in the opposite direction to all the medical advances put together in the last 25 years.\"\n\nGofman and Tamplin were instrumental in inducing the health physics scientific community both to acknowledge the somatic (i.e. leukemia and cancer) risks of ionizing radiation, at a time when only the genetic risks were considered of significant concern, and to adopt the so-called Linear No-Threshold (LNT) model \"as a means of numerically estimating actual cancer risks from low-level radiation\", which \"was a watershed event in radiation-safety science and politics\". The LNT model has since become the foundation of the international guidelines for radiation protection.\n\nIndeed, it was Gofman and Tamplin's argumented opposition to the Federal Radiation Council (FRC) radiation-safety guidelines who prompted the National Academy of Sciences (NAS), on the recommendation made in December 1969 by Victor Bond, \"a prominent health physicist and chairman of the NAS-NRC Subcommittee on Radiobiology of the Committee on Nuclear Science\", to gather its first BEIR (Biological Effects of Ionizing Radiation) committee. According to an internal memo cited by Semendeferi, the BEIR I committee was to \"thoroughly digest and carefully analyze various pertinent controversial models (Gofman and Tamplin)\".\n\nAfter two years of study, the BEIR I committee published its famous BEIR I report in November 1972. Although departing from Gofman and Tamplin's work on significant aspects, it nevertheless vindicated their arguments to a large extent. Semendeferi notes that \"[t]he report's long bibliography cited almost all of Gofman and Tamplin's work. Echoing Gofman and Tamplin, the BEIR I Committee emphasized that the cancer effects of low-level radiation were of much greater concern than leukemia or genetic effects. The current radiation limit was \"based on genetic considerations,\" and the committee concluded that the FRC limit was therefore \"unnecessarily high\" and could safely be much lower.\"\n\nSemendeferi reports that, according to the radiobiologist and environmental health specialist Edward Radford, who was a member of the BEIR I committee and the chairman of the BEIR III committee, \"Gofman deserved credit for raising the issue of the somatic ris's of low-level radiation as early as he did\", but \"never received the recognition he deserved for his contributions to radiation-safety science\" because he was \"stigmatized as an extreme antinuclear scientist\".\nGofman retired as a teaching professor in 1973 and became a professor emeritus of molecular and cell biology.\n\nGofman testified on the behalf of Samuel Lovejoy at Lovejoy's 1974 trial. Lovejoy was charged with malicious destruction of property for toppling a weather tower in Montague, Massachusetts, owned by Northeast Utilities. Lovejoy's actions were an act of protest against a proposed nuclear power plant, Montague Nuclear Power Plant, to be built on Montague Plains. Lovejoy was inspired by Gofman's book, \"Poisoned Power\".\n\nGofman used his low-level radiation health model to predict 333 excess cancer or leukemia deaths from the 1979 Three Mile Island accident. Studies of the health effects of the Three Mile Island accident have so far (by 2013) not observed any excess mortality. A retrospective study of Pennsylvania Cancer Registry found an increased incidence of thyroid cancer in counties south of TMI and in high-risk age groups. The Talbott lab at the University of Pittsburgh reported finding only a few, small, mostly statistically non-significant, increased cancer risks within the TMI population. However, excess leukemia among males was observed. The ongoing TMI epidemiological research has been accompanied by a discussion of epidemiological methodology, such as problems in dose and illness classifications.\n\nThree months after the Chernobyl disaster, Gofman predicted that Chernobyl would cause \"475,000 fatal cancers plus about \nan equal number of additional non-fatal cases, occurring over time both inside and outside the ex-Soviet Union\". In contrast, even some 19 years later in September 2005, an official UN IAEA report claimed 4,000 deaths as the final estimated toll from Chernobyl. In their 2006 book Alexey V. Yablokov and other Russian and East European researchers estimated that Chernobyl caused a million deaths through 2004, nearly 170,000 of them in North America. The book's English translation was published by the New York Academy of Sciences in 2009. The book cites \"5,000 mainly Slavic-language scientific papers the IAEA overlooked\", notwithstanding the fact that 13 of the authors of the Chernobyl Forum were from Ukraine, Russia or Belarus. M. I. Balonov criticized the methodology of the book. M. I. Balonov criticized the methodology of the book's estimation of Chernobyl's excess deaths and radiation-induced health effects and claimed the numbers were exaggerations which \"could lead quite unnecessarily to a panic reaction\". Rosalie Bertell has asserted the above estimates of Gofman (1986) and Yablokov (2006) are too conservative.\n\nAfter a speech Gofman gave on nuclear waste at a national conference of activists in the summer of 1990, Charles Butler approached him for help. Butler was a retired physicist living in the Mojave Desert town of Needles, California, and was looking for help to stop the proposed low-level nuclear waste facility at Ward Valley. Gofman referred him to the Abalone Alliance Clearinghouse in San Francisco. With less than two weeks before the closure of the Environmental Impact Statement, the Alliance was able to mount a letter writing campaign that helped delay the EIS for an additional 90 days. This initial delay gave activists the time to form Don't Waste California and build a grassroots campaign that eventually stopped Ward Valley from opening.\n\nGofman also did work on the Diablo Canyon Power Plant.\n\nGofman considered that \"nuclear deterrence is important\", for he did not believe that comprehensive test bans were enforceable ; thus he favored underground atomic bomb tests while acknowledging that \"They are harmful, a little will leak out. A small number of people will get hurt.\" He claimed \"I don't understand the disarmament movement\". More precisely, he was of the opinion that if the US were to disarm unilaterally, \"the Soviet leaders may well try to make [the US] a slave state. […] There will surely never be a solution to human problems by any coercion or force. But there will also never be a solution through unarmed freedom as long as powerful bullies exist who will \"use\" force.\"\n\nGofman was born in Cleveland, Ohio to Jewish parents, David and Sarah Gofman, who immigrated to the USA from czarist Russia in about 1905. His father had been \"involved in some of the early revolutionary activities against the Czar.\" Gofman died of heart failure at age 88 on August 15, 2007 in his home in San Francisco.\n\n\n\n\n\n"}
{"id": "13749868", "url": "https://en.wikipedia.org/wiki?curid=13749868", "title": "John Macias", "text": "John Macias\n\nJohn Macías, O.P. (\"Spanish\" San Juan Macias \"alt. sp\" Massias) (2 March 1585 Ribera del Fresno, Extremadura, Spain – September 16, 1645, Lima, Viceroyalty of Peru), was a Spanish-born Dominican Friar who evangelized in Peru in 1620. He was canonized in 1975 by Pope Paul VI. His main image is located at the main altar of the Basilica of Our Lady of the Rosary of Lima and is venerated by the local laity in Peru. A church was built in his honor in 1970 in San Luis, Lima, Peru.\n\nHe was born Juan de Arcas y Sánchez on March 2, 1585 in the small town of Ribera del Fresno, Extremadura which was under the jurisdiction of the Palencia Diocese, to Pedro de Arcas and Juana Sánchez. His parents were poor farmers; both died when Juan and his sister Mary were young. Juan was but four years old. The two children were raised by their uncle whose last name, “Macias,” they took as their own. His uncle trained him as a shepherd. Juan would pass the long hours saying the rosary.\n\nWhen he was about 16 years old, Macias met a Dominican friar while attending Mass in a neighboring village, and he began to consider the possibility of becoming a Dominican. It is said that as he began to seek God’s will for his life; he was frequently visited by the Blessed Virgin Mary and by his patron, St. John the Evangelist.\n\nAt the age of 25, Macias then started working with a wealthy businessman who offered him an opportunity to travel to South America. He set out for the Americas in 1619, arriving first at Cartagena de Indias, Colombia, then Reino de Nueva Granada, before stopping by Pasto and then Quito, Ecuador, and eventually arriving in Lima, Perú where he would remain for the rest of his life. Juan Macias was young when he set off as an emigrant for the new world. The ships which crossed the seas in those days carried all sorts of people: soldiers led by the lure of gold or glory; missionaries going to preach the Gospel; merchants and those seeking adventure; and also the poverty stricken hoping to find better luck.\n\nAccording to Father Vincent de Couesnongle, O.P., \"[h]e knew what it meant to be uprooted and torn away from his natural surroundings, from everything he was used to. He knew what it is like to plunge into the unknown. He experienced the normal mixture of hopes and fears, and the difficulty of putting down roots and adapting to new ways. He was one of those millions of people who down through the ages have been shuttled from one country to another, not for the fun of it, or for adventure's sake, but because they had to.\"\n\nOn 23 January 1622, Macias entered the Dominican Priory of St. Mary Magdalene in Lima. He entered as a lay brother, a non-ordained friar who, instead of preaching, would do the manual labor necessary in the monastery. One year later on 25 January 1623 he took his final vows. Macias was a contemporary of St. Martin de Porres who was in the Priory of Santo Domingo, (otherwise known as Holy Rosary). Juan was the assistant porter (doorkeeper) at St. Mary Magdalene and lived in the gatehouse.\n\nJohn Macias was well known mainly for two things during his life. First, he was known to love the rosary, which he began to pray as a child in Spain while he shepherded his uncle’s flock of sheep. Secondly, he was known for his generosity to the poor, 200 of whom he fed every day. He was greatly aided in this by a little donkey that he sent through Lima. He had a small sign put on it asking for donations for the poor. The donkey, knowing his route perfectly, would travel through the streets and come back with benefactions for the city’s poor. Often the donkey would stop at certain locations and make loud noises so that the people inside would come out to make their donations.\n\nAt the priory, Macías's life was filled with fervent prayer, frequent penance and charity. As a result of his austerity, he quickly fell ill and had to have a risky surgery. Nevertheless, he continued to care for other sick and needy as they waited at the friary gates. Beggars, disabled people and other disadvantaged people were commonplace throughout Lima where they flocked to him at the monastery gates for counsel and comfort. The poor came for food, and the rich for advice.\n\nMacias, however, expressed a greater desire to spend more time in contemplative solitude rather than engage in conversational activities with others. He confessed this to Father Abbot Ramírez who said, “If he were to never follow his vow of obedience, nobody would have ever seen his face.\" But his official position as the priory's porter, which he held for over 20 years and went against his natural inclinations of solitude, served to continue disciplining his vow of obedience. This filled him with a joyful sense of fulfillment. He died of natural causes in 1645.\n\nSeveral miracles were attributed to Macias during his life and after his death which led to his canonization. He was beatified, along with Martin de Porres, in 1837 by Pope Gregory XVI and canonized in 1975 by Pope Paul VI. His feast day is September 18.\nAn annual public procession also takes place in Peru every third Sunday of November in Lima. Macias' image, along with that of the more famous saint, Martin de Porres, (his friend and fellow Dominican laybrother) are paraded around the streets and venerated by the faithful of Peru.\n\n"}
{"id": "16013592", "url": "https://en.wikipedia.org/wiki?curid=16013592", "title": "Kerry Vincent", "text": "Kerry Vincent\n\nKerry Vincent (née Flynn; 1 June 1945), is the Australian director and co-founder of the annual \"Oklahoma Sugar Art Show\", author, and freelance writer. She was also a judge on \"Food Network Challenge\".\n\nVincent is a specialist Cake Designer. She wrote the book \"Romantic Wedding Cakes\" which was published by Merehurst Press in 2002. She was inducted into the International Cake Exploration Societé (ICES) Sugarcraft Hall of Fame in Washington, D.C. in 2004.\n\nVincent regularly appeared as one of the judges on the reality series \"Food Network Challenge\" on the Food Network Cable television network. She was also the show host for four one-hour specials for the Food Network, highlighting the skill of winning contestants in the Grand National Wedding Cake Competition.\n\nVincent has taught at the \"El Atelier Del Azucar Bakery School\" in Santa Rosa District, Lima Province, Peru. In May 2004, she taught at the Macomb Culinary Institute in Warren, Michigan part of the Macomb Community College.\n\nAfter the Wedding Style Director of \"Brides magazine\" was a guest judge at the \"Oklahoma Sugar Art Show\", Vincent was selected for a special feature in the March–April 2008 issue of the magazine entitled \"America's 50 Most Beautiful Cakes.\"\n\nIn 2013 Vincent was a judge at \"The Great Australian Bake Off\" an Australian reality television baking competition.\n\nIn 2014, Kerry Vincent hosted nine episodes of a show on the Food Network called \"Save My Bakery\", in which she helped out struggling bakeries.</ref>\n\n\"Romantic Wedding and Celebration Cakes\" (2001)\n\n"}
{"id": "88003", "url": "https://en.wikipedia.org/wiki?curid=88003", "title": "Menstrual cycle", "text": "Menstrual cycle\n\nThe menstrual cycle is the regular natural change that occurs in the female reproductive system (specifically the uterus and ovaries) that makes pregnancy possible. The cycle is required for the production of oocytes, and for the preparation of the uterus for pregnancy. Up to 80% of women report having some symptoms during the one to two weeks prior to menstruation. Common symptoms include acne, tender breasts, bloating, feeling tired, irritability and mood changes. These symptoms interfere with normal life and therefore qualify as premenstrual syndrome in 20 to 30% of women. In 3 to 8%, they are severe.\nThe first period usually begins between twelve and fifteen years of age, a point in time known as menarche. They may occasionally start as early as eight, and this onset may still be normal. The average age of the first period is generally later in the developing world and earlier in developed world. The typical length of time between the first day of one period and the first day of the next is 21 to 45 days in young women and 21 to 35 days in adults (an average of 28 or 29 days). Menstruation stops occurring after menopause which usually occurs between 45 and 55 years of age. Bleeding usually lasts around 2 to 7 days.\nThe menstrual cycle is governed by hormonal changes. These changes can be altered by using hormonal birth control to prevent pregnancy. Each cycle can be divided into three phases based on events in the ovary (ovarian cycle) or in the uterus (uterine cycle). The ovarian cycle consists of the follicular phase, ovulation, and luteal phase whereas the uterine cycle is divided into menstruation, proliferative phase, and secretory phase.\n\nStimulated by gradually increasing amounts of estrogen in the follicular phase, discharges of blood (menses) flow stop, and the lining of the uterus thickens. Follicles in the ovary begin developing under the influence of a complex interplay of hormones, and after several days one or occasionally two become dominant (non-dominant follicles shrink and die). Approximately mid-cycle, 24–36 hours after the luteinizing hormone (LH) surges, the dominant follicle releases an ovocyte, in an event called ovulation. After ovulation, the ovocyte only lives for 24 hours or less without fertilization while the remains of the dominant follicle in the ovary become a corpus luteum; this body has a primary function of producing large amounts of progesterone. Under the influence of progesterone, the uterine lining changes to prepare for potential implantation of an embryo to establish a pregnancy. If implantation does not occur within approximately two weeks, the corpus luteum will involute, causing a sharp drop in levels of both progesterone and estrogen. The hormone drop causes the uterus to shed its lining in a process termed menstruation. Menstruation also occurs in closely related primates (apes and monkeys).\n\nThe average age of menarche is 12–15. They may occasionally start as early as eight, and this onset may still be normal. This first period often occurs later in the developing world than the developed world.\n\nThe average age of menarche is approximately 12.5 years in the United States, 12.7 in Canada, 12.9 in the UK and 13.1 years in Iceland. Factors such as genetics, diet and overall health can affect timing.\n\nThe cessation of menstrual cycles at the end of a woman's reproductive period is termed menopause. The average age of menopause in women is 52 years, with anywhere between 45 and 55 being common. Menopause before age 45 is considered \"premature\" in industrialised countries. Like the age of menarche, the age of menopause is largely a result of cultural and biological factors; however, illnesses, certain surgeries, or medical treatments may cause menopause to occur earlier than it might have otherwise.\n\nThe length of a woman's menstrual cycle typically varies somewhat, with some shorter cycles and some longer cycles. A woman who experiences variations of less than eight days between her longest cycles and shortest cycles is considered to have regular menstrual cycles. It is unusual for a woman to experience cycle length variations of more than four days. Length variation between eight and 20 days is considered as moderately irregular cycles. Variation of 21 days or more between a woman's shortest and longest cycle lengths is considered very irregular. \n\nThe average menstrual cycle lasts 28 days. The variability of menstrual cycle lengths is highest for women under 25 years of age and is lowest, that is, most regular, for ages 25 to 39. Subsequently, the variability increases slightly for women aged 40 to 44.\n\nThe luteal phase of the menstrual cycle is about the same length in most individuals (mean 14.13 days, standard deviation 1.41 days) whereas the follicular phase tends to show much more variability (log-normally distributed with 95% of individuals having follicular phases between 10.3 and 16.3 days). The follicular phase also seems to get significantly shorter with age (geometric mean 14.2 days in women aged 18–24 vs. 10.4 days in women aged 40–44).\n\nSome women with neurological conditions experience increased activity of their conditions at about the same time during each menstrual cycle. For example, drops in estrogen levels have been known to trigger migraines, especially when the woman who suffers migraines is also taking the birth control pill. Many women with epilepsy have more seizures in a pattern linked to the menstrual cycle; this is called \"catamenial epilepsy\". Different patterns seem to exist (such as seizures coinciding with the time of menstruation, or coinciding with the time of ovulation), and the frequency with which they occur has not been firmly established. Using one particular definition, one group of scientists found that around one-third of women with intractable partial epilepsy has catamenial epilepsy. An effect of hormones has been proposed, in which progesterone declines and estrogen increases would trigger seizures. Recently, studies have shown that high doses of estrogen can cause or worsen seizures, whereas high doses of progesterone can act like an antiepileptic drug. Studies by medical journals have found that women experiencing menses are 1.68 times more likely to attempt suicide.\n\nMice have been used as an experimental system to investigate possible mechanisms by which levels of sex steroid hormones might regulate nervous system function. During the part of the mouse estrous cycle when progesterone is highest, the level of nerve-cell GABA receptor subtype delta was high. Since these GABA receptors are inhibitory, nerve cells with more delta receptors are less likely to fire than cells with lower numbers of delta receptors. During the part of the mouse estrous cycle when estrogen levels are higher than progesterone levels, the number of delta receptors decrease, increasing nerve cell activity, in turn increasing anxiety and seizure susceptibility.\n\nEstrogen levels may affect thyroid behavior. For example, during the luteal phase (when estrogen levels are lower), the velocity of blood flow in the thyroid is lower than during the follicular phase (when estrogen levels are higher).\n\nAmong women living closely together, it was once thought that the onsets of menstruation tend to synchronize. This effect was first described in 1971, and possibly explained by the action of pheromones in 1998. Subsequent research has called this hypothesis into question.\n\nResearch indicates that women have a significantly higher likelihood of anterior cruciate ligament injuries in the pre-ovulatory stage, than post-ovulatory stage.\n\nThe most fertile period (the time with the highest likelihood of pregnancy resulting from sexual intercourse) covers the time from some 5 days before until 1 to 2 days after ovulation. In a 28‑day cycle with a 14‑day luteal phase, this corresponds to the second and the beginning of the third week. A variety of methods have been developed to help individual women estimate the relatively fertile and the relatively infertile days in the cycle; these systems are called fertility awareness.\n\nThere are many fertility testing methods, including urine test kits that detect the LH surge that occurs 24 to 36 hours before ovulation; these are known as ovulation predictor kits (OPKs). Computerized devices that interpret basal body temperatures, urinary test results, or changes in saliva are called fertility monitors. Fertility awareness methods that rely on cycle length records alone are called calendar-based methods. Methods that require observation of one or more of the three primary fertility signs (basal body temperature, cervical mucus, and cervical position) are known as symptoms-based methods.\n\nA woman's fertility is also affected by her age. As a woman's total egg supply is formed in fetal life, to be ovulated decades later, it has been suggested that this long lifetime may make the chromatin of eggs more vulnerable to division problems, breakage, and mutation than the chromatin of sperm, which are produced continuously during a man's reproductive life. However, despite this hypothesis, a similar paternal age effect has also been observed.\n\nAs measured on women undergoing in vitro fertilization, a longer menstrual cycle length is associated with higher pregnancy and delivery rates, even after age adjustment. Delivery rates after IVF have been estimated to be almost doubled for women with a menstrual cycle length of more than 34 days compared with women with a menstrual cycle length shorter than 26 days. A longer menstrual cycle length is also significantly associated with better ovarian response to gonadotropin stimulation and embryo quality.\n\nThe different phases of the menstrual cycle correlate with women's moods. In some cases, hormones released during the menstrual cycle can cause behavioral changes in females; mild to severe mood changes can occur. The menstrual cycle phase and ovarian hormones may contribute to increased empathy in women. The natural shift of hormone levels during the different phases of the menstrual cycle has been studied in conjunction with test scores. When completing empathy exercises, women in the follicular stage of their menstrual cycle performed better than women in their midluteal phase. A significant correlation between progesterone levels and the ability to accurately recognize emotion was found. Performances on emotion recognition tasks were better when women had lower progesterone levels. Women in the follicular stage showed higher emotion recognition accuracy than their midluteal phase counterparts. Women were found to react more to negative stimuli when in midluteal stage over the women in the follicular stage, perhaps indicating more reactivity to social stress during that menstrual cycle phase. Overall, it has been found that women in the follicular phase demonstrated better performance in tasks that contain empathetic traits.\n\nFear response in women during two different points in the menstrual cycle has been examined. When estrogen is highest in the preovulatory stage, women are significantly better at identifying expressions of fear than women who were menstruating, which is when estrogen levels are lowest. The women were equally able to identify happy faces, demonstrating that the fear response was a more powerful response. To summarize, menstrual cycle phase and the estrogen levels correlates with women’s fear processing.\n\nHowever, the examination of daily moods in women with measuring ovarian hormones may indicate a less powerful connection. In comparison to levels of stress or physical health, the ovarian hormones had less of an impact on overall mood. This indicates that while changes of ovarian hormones may influence mood, on a day-to-day level it does not influence mood more than other stressors do.\n\nSexual feelings and behaviors change during the menstrual cycle. Before and during ovulation, high levels of estrogen and androgens result in women having an increased interest in sexual activity. Unlike other animal species, women show interest in sex across all days of the menstrual cycle, regardless of fertility.\n\nBehavior towards potential mating partners changes during different phases of the menstrual cycle. Near ovulation, women may have increased physical attraction and interest in attending social gatherings with men. During the fertile phase of the cycle, women appear to prefer males who are more masculine. The intensity of mate guarding differs across the phases of the cycle, with increased mate guarding occurring when woman are fertile.\n\nDuring the fertile phase, many women experience more attraction, fantasies and sexual interest for extra pair men but not for the primary partner. They also engage in extra-pair flirtations and demonstrate a preference for extra pair copulation.\n\nPreferences for voice pitch change across the cycle. When seeking a short term mating partner, women may prefer a male with a low voice pitch, particularly during the fertile phase. During the late follicular phase, it is common for women demonstrate a preference for mates with a masculine, deep voice. Research has also been conducted on the attractiveness of the female voice throughout the cycle. During their most fertile phase of the menstrual cycle, there is some evidence that female voices are rated as significantly more attractive. This effect is not found with women on the birth control pill.\n\nWomen's preference for male's body odor can change across the menstrual cycle. Males who score highly on dominance have been rated as sexier by females during the fertile phase of the menstrual cycle. Additionally, during their most fertile phase of the menstrual cycle, women may show preference for the odor of symmetrical men. This effect is not found for women on the birth control pill. Also, during the late follicular and ovulatory phases, women prefer the scent of masculine men. The scent of androsterone (responsible for testosterone levels) is highly preferred by women during the peak of their fertility in the menstrual cycle. Moreover, women may demonstrate preference for men with a scent that indicates developmental stability.\n\nWith regard to women's smell across the cycle, some evidence indicates that men use olfactory cues in order to know if a woman is ovulating. Using a rating of women's odors, women who are ovulating have been rated as more attractive by men. Men demonstrate preferences for the scent of fertile women.\n\nPreferences for facial features in mates can also change across the cycle. There has been no difference found in preference for long-term mating partners during the menstrual cycle; however, those seeking a short-term relationship were more likely to choose a partner with more masculine features than usual. This was found to be the case especially during the woman's high conception risk stage and when salivary testosterone was high. However, when women are in the luteal (non-fertile) phase, they tend to prefer men (and females) with more feminine faces. A preference is also shown for self-resembling faces and apparent health in faces during the luteal phase of the cycle. Apparent health preferences were found to be strongest when progesterone levels were high. Additionally, during the fertile phase, many women show a preference for men with darker skin pigmentation. Research on facial symmetry is mixed.\n\nPreferences for body features can change during the fertile phase of the cycle. Women seeking a short-term partner demonstrate a preference for taller and muscular males. Women also show preferences of males with masculine bodies at peak fertility. Mixed research has been found regarding body symmetry preferences throughout different phases of the cycle.\n\nIn short term mates, during the fertile phase, women may show more attraction to dominant men who display social presence. For long-term mates, shifts in desired trait preferences do not occur throughout the cycle.\n\nFemales have been found to experience different eating habits at different stages of their menstrual cycle, with food intake being higher during the luteal phase than the follicular phase. Food intake increases by approximately 10% during the luteal phase compared to the follicular phase.\n\nVarious studies have shown that during the luteal phase woman consume more carbohydrates, proteins and fats and that 24-hour energy expenditure shows increases between 2.5-11.5%. The increasing intake during the luteal phase may be related to higher preferences for sweet and fatty foods, which occurs naturally and is enhanced during the luteal phases of the menstrual cycle. This is due to the higher metabolic demand during this phase. In particular, women tend to show a cravings for chocolate, with higher cravings during the luteal phase.\n\nFemales with premenstrual syndrome (PMS) report changes in appetite across the menstrual cycle more than non-sufferers of PMS, possibly due to their oversensitivity to changes in hormone levels. In women with PMS, food intake is higher in the luteal phase than follicular. The remaining symptoms of PMS, including mood changes and physical symptoms, also occur during the luteal phase. No difference for preference of food types has been found between PMS sufferers and non-sufferers.\n\nThe different levels of ovarian hormones at different stages of the cycle have been used to explain eating behaviour changes. Progesterone has been shown to promote fat storage, causing a higher intake of fatty foods during the luteal phase when progesterone levels are higher. Additionally, with a high estrogen level dopamine is ineffective in converting to noradrenaline, a hormone which promotes eating, therefore decreasing appetite. In humans, the level of these ovarian hormones during the menstrual cycle have been found to influence binge eating.\n\nIt is theorized that the use of birth control pills should affect eating behaviour as they minimise or remove the fluctuations in hormone levels. The neurotransmitter serotonin is also thought to play a role in food intake. Serotonin is responsible for inhibiting eating and controlling meal size, among other things, and is modulated in part by ovarian hormones.\n\nA number of factors affect whether dieting will affect these menstrual processes: age, weight loss and the diet itself. First, younger women are likely to experience menstrual irregularities due to their diet. Second, menstrual abnormalities are more likely with more weight loss. For example, anovulatory cycles can occur as a result of adopting a restricted diet, as well as engaging in a high amount of exercise. Finally, the cycle is affected more by a vegetarian diet compared to a non-vegetarian diet.\n\nStudies investigating effects of the menstrual cycle on alcohol consumption have found mixed evidence. However, some evidence suggests that individuals consume more alcohol during the luteal stage, especially if these individuals are heavy drinkers or have a family history of alcohol abuse.\n\nThe level of substance abuse increases with PMS, mostly with addictive substances such as nicotine, tobacco and cocaine. One theory behind this suggests this higher level of substance abuse is due to decreased self-control as a result of the higher metabolic demands during the luteal phase.\n\nInfrequent or irregular ovulation is called \"oligoovulation\". The absence of ovulation is called \"anovulation\". Normal menstrual flow can occur without ovulation preceding it: an anovulatory cycle. In some cycles, follicular development may start but not be completed; nevertheless, estrogens will be formed and stimulate the uterine lining. Anovulatory flow resulting from a very thick endometrium caused by prolonged, continued high estrogen levels is called \"estrogen breakthrough bleeding\". Anovulatory bleeding triggered by a sudden drop in estrogen levels is called withdrawal bleeding. Anovulatory cycles commonly occur before menopause (perimenopause) and in women with polycystic ovary syndrome.\n\nVery little flow (less than 10 ml) is called \"hypomenorrhea\". Regular cycles with intervals of 21 days or fewer are \"polymenorrhea\"; frequent but irregular menstruation is known as \"metrorrhagia\". Sudden heavy flows or amounts greater than 80 ml are termed \"menorrhagia\". Heavy menstruation that occurs frequently and irregularly is \"menometrorrhagia\". The term for cycles with intervals exceeding 35 days is \"oligomenorrhea\". Amenorrhea refers to more than three to six months without menses (while not being pregnant) during a woman's reproductive years.\nThe term for painful periods is \"Dysmenorrhea\".\n\nThe menstrual cycle can be described by the ovarian or uterine cycle. The ovarian cycle describes changes that occur in the follicles of the ovary whereas the uterine cycle describes changes in the endometrial lining of the uterus. Both cycles can be divided into three phases. The ovarian cycle consists of the follicular phase, ovulation, and the luteal phase, whereas the uterine cycle consists of menstruation, proliferative phase, and secretory phase.\n\nThe follicular phase is the first part of the ovarian cycle. During this phase, the ovarian follicles mature and get ready to release an egg. The latter part of this phase overlaps with the proliferative phase of the uterine cycle.\n\nThrough the influence of a rise in follicle stimulating hormone (FSH) during the first days of the cycle, a few ovarian follicles are stimulated. These follicles, which were present at birth and have been developing for the better part of a year in a process known as folliculogenesis, compete with each other for dominance. Under the influence of several hormones, all but one of these follicles will stop growing, while one dominant follicle in the ovary will continue to maturity. The follicle that reaches maturity is called a tertiary or Graafian follicle, and it contains the ovum.\n\nOvulation is the second phase of the ovarian cycle in which a mature egg is released from the ovarian follicles into the oviduct. During the follicular phase, estradiol suppresses release of luteinizing hormone (LH) from the anterior pituitary gland. When the egg has nearly matured, levels of estradiol reach a threshold above which this effect is reversed and estrogen stimulates the production of a large amount of LH. This process, known as the LH surge, starts around day 12 of the average cycle and may last 48 hours.\n\nThe exact mechanism of these opposite responses of LH levels to estradiol is not well understood. In animals, a gonadotropin-releasing hormone (GnRH) surge has been shown to precede the LH surge, suggesting that estrogen's main effect is on the hypothalamus, which controls GnRH secretion. This may be enabled by the presence of two different estrogen receptors in the hypothalamus: estrogen receptor alpha, which is responsible for the negative feedback estradiol-LH loop, and estrogen receptor beta, which is responsible for the positive estradiol-LH relationship. However, in humans it has been shown that high levels of estradiol can provoke abrupt increases in LH, even when GnRH levels and pulse frequencies are held constant, suggesting that estrogen acts directly on the pituitary to provoke the LH surge.\n\nThe release of LH matures the egg and weakens the wall of the follicle in the ovary, causing the fully developed follicle to release its secondary oocyte. If it is fertilized by a sperm, the secondary oocyte promptly matures into an ootid and then becomes a mature ovum. If it is not fertilized by a sperm, the secondary oocyte will degenerate. The mature ovum has a diameter of about 0.2 mm.\n\nWhich of the two ovaries—left or right—ovulates appears essentially random; no known left and right co-ordination exists. Occasionally, both ovaries will release an egg; if both eggs are fertilized, the result is fraternal twins.\n\nAfter being released from the ovary, the egg is swept into the fallopian tube by the fimbria, which is a fringe of tissue at the end of each fallopian tube. After about a day, an unfertilized egg will disintegrate or dissolve in the fallopian tube.\n\nFertilization by a spermatozoon, when it occurs, usually takes place in the ampulla, the widest section of the fallopian tubes. A fertilized egg immediately begins the process of embryogenesis, or development. The developing embryo takes about three days to reach the uterus and another three days to implant into the endometrium. It has usually reached the blastocyst stage at the time of implantation.\n\nIn some women, ovulation features a characteristic pain called \"mittelschmerz\" (German term meaning \"middle pain\"). The sudden change in hormones at the time of ovulation sometimes also causes light mid-cycle blood flow.\n\nThe luteal phase is the final phase of the ovarian cycle and it corresponds to the secretory phase of the uterine cycle. During the luteal phase, the pituitary hormones FSH and LH cause the remaining parts of the dominant follicle to transform into the corpus luteum, which produces progesterone. The increased progesterone in the adrenals starts to induce the production of estrogen. The hormones produced by the corpus luteum also suppress production of the FSH and LH that the corpus luteum needs to maintain itself. Consequently, the level of FSH and LH fall quickly over time, and the corpus luteum subsequently atrophies. Falling levels of progesterone trigger menstruation and the beginning of the next cycle. From the time of ovulation until progesterone withdrawal has caused menstruation to begin, the process typically takes about two weeks, with 14 days considered normal. For an individual woman, the follicular phase often varies in length from cycle to cycle; by contrast, the length of her luteal phase will be fairly consistent from cycle to cycle.\n\nThe loss of the corpus luteum is prevented by fertilization of the egg. The syncytiotrophoblast, which is the outer layer of the resulting embryo-containing structure (the blastocyst) and later also becomes the outer layer of the placenta, produces human chorionic gonadotropin (hCG), which is very similar to LH and which preserves the corpus luteum. The corpus luteum can then continue to secrete progesterone to maintain the new pregnancy. Most pregnancy tests look for the presence of hCG.\n\nThe uterine cycle has three phases: menses, proliferative, secretory.\n\nMenstruation (also called menstrual bleeding, menses, catamenia or a period) is the first phase of the uterine cycle. The flow of menses normally serves as a sign that a woman has not become pregnant. (However, this cannot be taken as certainty, as a number of factors can cause bleeding during pregnancy; some factors are specific to early pregnancy, and some can cause heavy flow.)\n\n\"Eumenorrhea\" denotes normal, regular menstruation that lasts for a few days (usually 3 to 5 days, but anywhere from 2 to 7 days is considered normal). The average blood loss during menstruation is 35 milliliters with 10–80 ml considered normal. Women who experience Menorrhagia are more susceptible to iron deficiency than the average person. An enzyme called plasmin inhibits clotting in the menstrual fluid.\n\nPainful cramping in the abdomen, back, or upper thighs is common during the first few days of menstruation. Severe uterine pain during menstruation is known as dysmenorrhea, and it is most common among adolescents and younger women (affecting about 67.2% of adolescent females). When menstruation begins, symptoms of premenstrual syndrome (PMS) such as breast tenderness and irritability generally decrease. Many sanitary products are marketed to women for use during their menstruation.\n\nThe proliferative phase is the second phase of the uterine cycle when estrogen causes the lining of the uterus to grow, or proliferate, during this time. As they mature, the ovarian follicles secrete increasing amounts of estradiol, and estrogen. The estrogens initiate the formation of a new layer of endometrium in the uterus, histologically identified as the proliferative endometrium. The estrogen also stimulates crypts in the cervix to produce fertile cervical mucus, which may be noticed by women practicing fertility awareness.\n\nThe secretory phase is the final phase of the uterine cycle and it corresponds to the luteal phase of the ovarian cycle. During the secretory phase, the corpus luteum produces progesterone, which plays a vital role in making the endometrium receptive to implantation of the blastocyst and supportive of the early pregnancy, by increasing blood flow and uterine secretions and reducing the contractility of the smooth muscle in the uterus; it also has the side effect of raising the woman's basal body temperature.\n\nWhile some forms of birth control do not affect the menstrual cycle, hormonal contraceptives work by disrupting it. Progestogen negative feedback decreases the pulse frequency of gonadotropin-releasing hormone (GnRH) release by the hypothalamus, which decreases the release of follicle-stimulating hormone (FSH) and luteinizing hormone (LH) by the anterior pituitary. Decreased levels of FSH inhibit follicular development, preventing an increase in estradiol levels. Progestogen negative feedback and the lack of estrogen positive feedback on LH release prevent a mid-cycle LH surge. Inhibition of follicular development and the absence of a LH surge prevent ovulation.\n\nThe degree of ovulation suppression in progestogen-only contraceptives depends on the progestogen activity and dose. Low dose progestogen-only contraceptives—traditional progestogen only pills, subdermal implants Norplant and Jadelle, and intrauterine system Mirena—inhibit ovulation in about 50% of cycles and rely mainly on other effects, such as thickening of cervical mucus, for their contraceptive effectiveness. Intermediate dose progestogen-only contraceptives—the progestogen-only pill Cerazette and the subdermal implant Nexplanon—allow some follicular development but more consistently inhibit ovulation in 97–99% of cycles. The same cervical mucus changes occur as with very low-dose progestogens. High-dose, progestogen-only contraceptives—the injectables Depo-Provera and Noristerat—completely inhibit follicular development and ovulation.\n\nCombined hormonal contraceptives include both an estrogen and a progestogen. Estrogen negative feedback on the anterior pituitary greatly decreases the release of FSH, which makes combined hormonal contraceptives more effective at inhibiting follicular development and preventing ovulation. Estrogen also reduces the incidence of irregular breakthrough bleeding. Several combined hormonal contraceptives—the pill, NuvaRing, and the contraceptive patch—are usually used in a way that causes regular withdrawal bleeding. In a normal cycle, menstruation occurs when estrogen and progesterone levels drop rapidly. Temporarily discontinuing use of combined hormonal contraceptives (a placebo week, not using patch or ring for a week) has a similar effect of causing the uterine lining to shed. If withdrawal bleeding is not desired, combined hormonal contraceptives may be taken continuously, although this increases the risk of breakthrough bleeding.\n\nBreastfeeding causes negative feedback to occur on pulse secretion of gonadotropin-releasing hormone (GnRH) and luteinizing hormone (LH). Depending on the strength of the negative feedback, breastfeeding women may experience complete suppression of follicular development, but no ovulation, or normal menstrual cycle may resume. Suppression of ovulation is more likely when suckling occurs more frequently. The production of prolactin in response to suckling is important to maintaining lactational amenorrhea. On average, women who are fully breastfeeding whose infants suckle frequently experience a return of menstruation at fourteen and a half months postpartum. There is a wide range of response among individual breastfeeding women, however, with some experiencing return of menstruation at two months and others remaining amenorrheic for up to 42 months postpartum.\n\nThe word \"menstruation\" is etymologically related to \"moon\". The terms \"menstruation\" and \"menses\" are derived from the Latin \"mensis\" (month), which in turn relates to the Greek \"mene\" (moon) and to the roots of the English words \"month\" and \"moon\".\n\nEven though the average length of the human menstrual cycle is similar to that of the lunar cycle, in modern humans there is no relation between the two. The relationship is believed to be a coincidence. Light exposure does not appear to affect the menstrual cycle in humans. A meta-analysis of studies from 1996 showed no correlation between the human menstrual cycle and the lunar cycle, nor did data analysed by period-tracking app Clue, submitted by 1.5m women, of 7.5m menstrual cycles.\n\nDogon villagers did not have electric lighting and spent most nights outdoors, talking and sleeping, so they were apparently an ideal population for detecting a lunar influence; none was found.\n\nIn a number of countries, mainly in Asia, legislation or corporate practice has introduced formal menstrual leave to provide women with either paid or unpaid leave of absence from their employment while they are menstruating. Countries with policies include Japan, Taiwan, Indonesia, and South Korea. The practice is controversial due to concerns that it bolsters the perception of women as weak, inefficient workers, as well as concerns that it is unfair to men.\n\n"}
{"id": "29718829", "url": "https://en.wikipedia.org/wiki?curid=29718829", "title": "OHSAS 18001", "text": "OHSAS 18001\n\nOHSAS 18001, Occupational Health and Safety Assessment Series, (officially BS OHSAS 18001) is a British Standard for occupational health and safety management systems. Compliance with it enables organizations to demonstrate that they have a system in place for occupational health and safety. BS OHSAS 18001 is being replaced by ISO 45001, which was published in March 2018 by the International Organization for Standardization. Organizations which are certified to BS OHSAS 18001 should migrate to ISO 45001 by March 2021 if they want to retain a recognized certification. \n\nOrganizations worldwide recognize the need to control and improve health and safety performance and do so with occupational health and safety management systems (OHSMS). However, before 1999 there was an increase of national standards and proprietary certification schemes to choose from. This caused confusion and fragmentation in the market and undermined the credibility of individual schemes.\n\nRecognising this deficit, an international collaboration called the Occupational Health and Safety Assessment Series (OHSAS) Project Group was formed to create a single unified approach. The Group comprised representatives from national standards bodies, academic bodies, accreditation bodies, certification bodies and occupational safety and health institutions, with the UK’s national standards body, BSI Group, providing the secretariat.\n\nDrawing on the best of existing standards and schemes, the OHSAS Project Group published the OHSAS 18000 Series in 1999. The Series consisted of two specifications: 18001 provided requirements for an OHS management system and 18002 gave implementation guidelines. As of 2005, around 16,000 organizations in more than 80 countries were using the OHSAS 18001 specification. By 2009 more than 54,000 certificates had been issued in 116 countries to OHSAS or equivalent OHSMS standards.\n\nThe OHSAS 18001 specification was updated in July 2007. Among other changes, the new specification was more closely aligned with the structures of ISO 9000 and ISO 14000 so that organizations could more easily adopt OHSAS 18001 alongside existing management systems. Additionally, the \"health\" component of \"health and safety\" was given greater emphasis.\nLater, the BSI Group decided to adopt OHSAS 18001 as a British standard. BSI Group subsequently adopted the updated 18002 guidance specification for publication as BS OHSAS 18002 in 2008.\n\nIts supporters claim that an occupational health and safety management system (OHSMS) promotes a safe and healthy working environment by providing a framework that helps organizations to:\n\nThe OHSAS 18000 standards provide organizations with the elements of an effective safety management system which can be integrated with other management systems and help organizations achieve better occupational health and safety performance and economic objectives.\n\nBS OHSAS 18001 specifies requirements for an OH&S management system to help an organization develop and implement a policy and objectives, which take into account legal requirements and information about OH&S risks. It applies to all types and sizes of organizations and accommodates diverse geographical, cultural and social conditions.\n\nBS OHSAS 18002 provides guidance for establishing, implementing or improving a management system which is based on OHSAS 18001 and demonstrating successful implementation of OHSAS 18001.\n\nOHSAS 18001 can be aligned with existing ISO 9001 and ISO 14001 management systems. Historically many organizations start with the quality management system ISO 9001, then add the environment management requirements from ISO 14001. Many organizations now look at implementing all three standards at once which can minimize costs and disruption. The standards can be integrated using a standard such as BSI’s PAS 99.\n\nThe OHSAS 18000 standards were written and published wholly outside of the International Organization for Standardization (ISO) framework. To avoid confusion, ISO 18000 does exist – but it is a radio-frequency identification standard.\n"}
{"id": "23495580", "url": "https://en.wikipedia.org/wiki?curid=23495580", "title": "Obesity in Australia", "text": "Obesity in Australia\n\nAccording to 2007 statistics from the World Health Organization (WHO), Australia has the third-highest prevalence of overweight adults in the English-speaking world.Obesity in Australia is an \"epidemic\" with \"increasing frequency.\" \"The Medical Journal of Australia\" found that obesity in Australia more than doubled in the two decades preceding 2003, and the unprecedented rise in obesity has been compared to the same health crisis in America. The rise in obesity has been attributed to poor eating habits in the country closely related to the availability of fast food since the 1970s, sedentary lifestyles and a decrease in the labour workforce.\n\nWeight is measured by using the Body Mass Index scale (BMI). This is determined by dividing weight in kilograms by height in metres, squared. If someone is overweight their BMI will be at 25 or more. If someone is obese their BMI will be at 30 or more.\n1 in 4 children are overweight (25%) and 2 in 3 adults are overweight (63%)\n\nIn a study published in 2015 by the US Journal of Economics and Human Biology, obesity is found to have the largest impact on men aged over 75, and women aged between 60-74.\n\nIn 2005, a study was conducted by the Australian Bureau of Statistics that compared the results of a 2004-05 survey with those conducted in the preceding 15 years. The results showed an increase in the number and proportion of adults who are overweight or obese. Over the four surveys, the number of overweight or obese adults increased from 4.6 million in 1989-90 to 5.4 million in 1995, 6.6 million in 2001 and 7.4 million in 2004-05.\n\nIn 2007, the World Health Organization (WHO) found that 67.4% of Australian adults are overweight, ranking 21st in the world, and third out of the major countries in the English-speaking world, behind the United States (ranked 9th) and New Zealand (ranked 17th). A 2005 WHO study found that just over 20% of Australian adults are obese, which is expected to rise to roughly 29% in 2010 if current trends continue. (Update) about 29 to 30% of Australians are obese in 2017.\n\nIn the 2005 National Health Survey, 53.6% of Australians reported being overweight with 18% falling into the \"obese\" category. Those numbers rose to 65% overweight and 29% obese in 2016. This is nearly double the reported number from 1995, when 30% of adults were overweight and 11% were obese. Such representations would be skewed downward as people tend to overestimate their height and under-report their weight, the two key criteria to determine a BMI reading. In the National Health Survey, obesity reports were fairly common across the board, with no major outliers. Victoria had the lowest incidence of obesity, at 17.0% of the population, with South Australia reporting the highest numbers at 19.6%. By 2014, Canberra recorded an obesity rate of 25% which was placing significant strain on ageing health care infrastructure.\n\nIn a study conducted by The Obesity Society, between 2001 and 2025, the adult population prevalence of normal healthy weight will decrease from 40.6% to 22.9%. In conjunction with this, the prevalence of obesity will increase from 20.5% to 33.9%. It is also estimated that by the time 25- to 29-year-olds of 2000 reach the age of 60-64 (2040), over one third will be obese.\n\nA recent study reported that based on figures from the National Health Survey and/or Australian Health Survey the prevalence of overweight and obesity increased from 56.3% in 1995 to 61.2% in 2007–2008 and 62.8% in 2011–2012. This was attributed largely to an increase in the level of obesity from 18.7% to 27.5% over the period, with the proportion of overweight adults remaining similar (35.3–37.6%). The study argues for preventive health measures to be gender-specific and specific to socioeconomic disadvantage within populations.\n\nAge-standardization of the 2011-12 Australian Health Survey was done in a recent study which reported 28.3% of Australian adults to be obese with 63.4% adults being overweight or obese. A subsequent analysis published in 2016 reported that despite of obesity and overweight together being the second highest contributor to the burden of disease in Australia the regular screening and recording of measures of obesity and overweight in primary care setting especially within regional Australian catchments was much lower than optimal.\n\nIndigenous Australians have Australia's highest level of obesity. A 2001 study showing that 31% of Aboriginal Australians and Torres Strait Islanders were obese, nearly double the national average at that time.\n\nThe health and well being of Australian Indigenous youth is becoming increasingly concerning. A cross sectional study (Valery, Moloney, Cotterill, Harris, Sinha & Green, 2009) found that 46% of the total population, of participants, were overweight or obese. Of that population, 38% had enlarged waist circumferences, 43% had acanthosis nigricans present and 27% had hypertension. With this high population of overweight and obese Indigenous youth, it puts major implications on the public health system.\n\nA University of Alberta study, conducted in 2006, noted that 60% of Aboriginal Australians over the age of 35 in Western Australia tested positive for diabetes. Health issues such as heart disease, obesity, and diabetes have lowered the life expectancy for Aboriginal Australians to 17 years below the national life expectancy, a gap that continues to grow.\n\nProfessor Paul Zimmet at Monash University, who conducted the aforementioned study of diabetes rates amongst Asian immigrants, released figures at the Diabetes in Indigenous People Forum in Melbourne, estimating the rate of diabetes from poor diet at 24% of all Torres Strait Islanders and remarked that unless extra steps are taken with these groups, Aboriginals and Torres Strait Islanders will die out within 100 years.\n\nIndividuals who migrate to Australia moving from a low income nation, have a greater tendency to undergo an increase in weight. A study done by Delavari et al. (2012) suggested that many immigrant groups showed signs of obesogenic lifestyle behaviours after migrating from low-HDI to high-HDI. It has also been found that Sudanese refugees in Australia have an increased risk of obesity compared to the general population. (Rezaho et al. 2014) \n\nFirst-generation immigrants to Australia are more obese and have higher rates of obesity-related behaviours than white Australians or Australians of foreign ancestry whose families have been in the country at least two generations. A study conducted by the International Diabetes Institute at Monash University showed that Asians, Pacific Islanders, and Middle Eastern immigrants who moved to Australia were diagnosed with diabetes at a higher level than the average. The increase was explained by the adoption of a Western diet in place of a more healthy \"traditional\" diet more common in their native countries, as well as adopting a more sedentary lifestyle which is ubiquitous in developed countries.\n\nThe percentage of overweight and obese children in Australia, despite rapid increases in the 1980s and the first half of the 1990s, have remained mostly steady for the past 10 years, with 23 to 24% of Australians under the age of 18 classified as overweight, and 5 to 6% of the same demographic classified as obese.\n\nA study done by Nichols et al. (2011) found there has been a decreasing trend in overweight and obese preschool children, in Victoria, between 1999 and 2007. Among 2-year-old children, there was a decrease in the obesity of these children from 13.5% in 1999 to 12.4% in 2007 and in the 3.5-year-old children a substantial decrease from 18.5% in 1999 to 15.4% in 2007.\n\nIncreased media attention on childhood obesity, in 2007 and 2008 especially, caused many researchers to print findings that the rate of obesity for children has reached a plateau or that the claims are simply \"exaggerated.\" The reports caused Dr. Rosanna Capolingua, President of the Australian Medical Association, to issue a statement admonishing people and media outlets for \"trivialising\" the issue.\n\nA Western Australian study (Bell et al. 2011) showed that overweight and obese primary school children have greater medical complications due to their weight status. Overweight and obese children were more likely to complain and suffer from depression, anxiety, bullying, headaches, enuresis and musculoskeletal pain. The most common site of the musculoskeletal pain was in the knees with overweight children 1.3 times and obese children 3 times more likely to complain about it than the control children. Overweight and obese children also had significantly higher levels of hypertension (control 3.4%, overweight 7.3%, obese 19%), impaired glucose tolerance (control: normal, overweight 1.3%, obese 5.3%) and hyperinsulinism (control 8%, overweight 19.5%, obese 38.9%).\n\nThe implementation of public health interventions in child care services has been recommended in Australia as a key strategy in the prevention of children becoming overweight or obese, especially in rural and remote areas of Australia. Quantifying the prevalence of obesity among children attending child care from non-metropolitan areas throughout Australia may be particularly important as the access to obesity prevention resources and professional development opportunities for child care service staff is limited. Financial constraints often experienced by smaller rural and remote child care services may limit their capacity to promote and encourage physical activity and health care to children participating in the child care services provided to them.\n\nThe study conducted by Wolfenden et al. found that approximately 17% of all children and 25% of indigenous children attending rural and regional child care services in the study area were overweight or obese. Such prevalence rates remain unacceptably high and confirm the need of prevention interventions targeting obesity in this setting.\n\nFor childhood obesity, the influence of broader parental and community contexts needs to be considered. Studies have found that young overweight boys spent significantly less time away from their parents than non-overweight boys, this potentially relates to the socio-economic status of the parents, as children residing from parents with a lower education level are at a higher risk of suffering from being overweight. It is possible that this is because young boys that spent a lot of their time with their parents were more likely to participate in sedentary activities, such as watching television or playing video games, than they were to participate in any kind of physical activity.\n\nJones et al. (2010) study found that early school years may be the time when child, parent and community characteristics begin to differ between overweight and non-overweight children, and may be an ideal time to target broader parental and community contexts influencing overweight and obese children.\n\nA recent study conducted by The Swiss School of Public Health in 2014, found a clear association between the prevalence of obesity in low socio-economic standing school children within Australia. In 2006, it was found that children of low socio-economic standing were 2.22 times more likely to be obese compared to their high socio-economic standing counterparts. It was also discovered that these children of low socio-economic standing were 2.20 times more likely to be obese in 2012.\n\nIn May 2008, Diabetes Australia, the national body for diabetes awareness and prevention, told the House of Representatives that the cost of obesity on the country's health system in 2005 was an estimated A$25 billion (US$20 billion), In August 2008, Diabetes Australia's estimation more than doubled to $58 billion ($46 billion USD), this time taking into account not just health care but job productivity and other related quality of living costs.\n\nIn 2003, the number of Australians with type 2 diabetes rose to nearly a million for the first time. In addition, the number of type 2 diabetes patients who were diagnosed solely on their weight was calculated at 242,000 in 2007, a 137% increase in cases in the previous three years.\n\nIn 2008 using the Body Mass Index scale, obese Australians (indirectly and directly) cost the nation $8.3 billion. Out of the $8.3 billion, $2.0 billion was the cost of the health system.\n\nIn April 2008, the Australian Federal Government added obesity to its list of \"national health priorities\", officially elevating it to the same standard of attention given to other deadly ailments such as cancer, heart disease and diabetes. On 1 June 2009, the first Parliamentary comment on obesity in Australia was published, with the Standing Committee on Health and Ageing recommending 20 acts for the Federal Government to consider, including tax incentives to make healthier fruits and vegetables more affordable for Australians, and pressing the government to work with the food industry to lower fat and sugar levels in existing processed food. These recommendations covered a range of issues affecting obesity in Australia. The government agreed to the majority of the recommendations including to continue supporting the Active After-School communities program which lead more children to have more positive attitude towards physical activity and agreeing to develop consistent urban planning guidelines that focus on creating environments that encourage Australians to be healthy and active.\n\nThe former ALP government under Prime Minister Julia Gillard wanted to tackle the obesity problem in Australia by giving tax subsidies which would fund gym memberships to people who wish to lose weight. Her watchdog group, the National Preventative Health Taskforce, also wants to target childhood obesity by banning ads for junk food during the daytime when most children's television programs air.\n\nIn August 2008, the government of New South Wales announced that it would pay for morbidly obese patients to receive weight loss surgery, the first state to make such an announcement. Most Australians who wish to have such surgery have to go to a private hospital and pay for the procedure themselves, which costs $10,000 ($10,000 USD). A survey in Western Australia suggests that the number of patients who have undergone weight loss surgery has increased 20-fold in the past 20 years, with nine out of ten patients opting for the lap band procedure.\n\nAccording to The Obesity Society Australia, if obesity rates continue to grow in Australia at this current rate over the next few decades, it is conceivable that the health and economic cost due to obesity will also grow to overwhelming portions.\n\n\nGeneral:\n"}
{"id": "56604298", "url": "https://en.wikipedia.org/wiki?curid=56604298", "title": "Oregon Museum Tavern shooting", "text": "Oregon Museum Tavern shooting\n\nThe Oregon Museum Tavern Shooting occurred on May 7, 1981, at Oregon Museum Tavern in Salem, Oregon.\n\nLawrence William Moore, 25, of Scio, Oregon, an unemployed mill worker\nwalked into the crowded Oregon Museum Tavern on Front Street NE which was hosting a Ladies' night and without saying a word started to fire his 9mm Browning handgun.\nMoore first fired at the bar, before turning the weapon at patrons who began to flee.\n\nOnce the magazine had run out he reloaded and continued firing.\nOne of the times he was reloading several patrons at the tavern overpowered him, wrestled him to ground and held him waiting of the police to arrive.\n\nThe killing spree ended with the killing 3 people at the scene and injuring 20 others; one of these died in hospital later that night, and Dennis Scharf died nearly 32 years later from injuries sustained.\n\n\nAt trial, beginning on October 6, 1981, he pleaded innocent to the murder charges, citing mental disease or defect as a defense; however, he admitted to being the gunman.\nMoore stated the reason for the shooting that he was trying to get members of a 'syndicate' of millionaires, Jews and criminals who had been trying to poison him.\n\nMoore was subsequently found guilty of four counts of aggravated murder and sentenced to four life terms in prison.\n\nThe names of the deceased victims are included in a joint memorial wall at Oregon City's Mountain View Cemetery that memorializes some 390 people that were murdered. The memorial was dedicated by The Greater Portland Area Chapter of Parents of Murdered Children.\n\n"}
{"id": "54241566", "url": "https://en.wikipedia.org/wiki?curid=54241566", "title": "Orlando factory shooting", "text": "Orlando factory shooting\n\nOn June 5, 2017, John Robert Neumann Jr., a 45-year-old former employee of Fiamma, killed five former colleagues and himself. Orange County Sheriff Jerry Demings said Neumann did not appear to belong to any kind of subversive or terrorist group.\n\nJohn Robert Neumann Jr. let himself into the building through a rear entrance and was armed with a handgun and a large hunting knife. He singled out his five victims and shot them in their heads. He then fatally shot himself as deputies responded to the scene. Eight other employees who worked at the company and were present during the shooting escaped without injury.\n\nThe shooting occurred nearly one year after another mass shooting in the same city, which had been the deadliest mass shooting in U.S. history at the time.\n\nThe five victims were Robert Snyder, 69, lead manager at the factory; Brenda Montanez-Crespo, 44; Kevin Clark, 53; Jeffrey Roberts, 57; and Kevin Lawson, 46. A local youth sports league raised money for the children of Kevin Clark, who were orphaned, as their mother had died nine years earlier.\n\nJohn Robert Neumann Jr. (1971 – June 5, 2017) received an honorable discharge from the U.S. Army in 1999. He did not have a concealed weapons permit. He had a history of minor crimes before the shooting, mostly associated with traffic.\n\nNeumann once worked for Fiamma, which made awnings for recreational vehicles and campervans. He was fired in April 2017 for starting fights with people. The lead manager who fired him later feared he would return for revenge. Police dealt with him in 2014 when he was accused of battering a coworker at the factory.\n"}
{"id": "20849900", "url": "https://en.wikipedia.org/wiki?curid=20849900", "title": "Patients' Welfare Association", "text": "Patients' Welfare Association\n\nEstablished in 1979, by three students of Dow Medical College, it soon transformed from being a small student based organization to a much larger movement with much coverage of their humanitarian deeds being publicized by means of local Television channels, Newspaper, Radio as well as their own newsletter which is circulated in their locality.\n\nPatients' Welfare Association was established as a small student based organization by three students of Dow Medical College in 1979, with simple services such as free of cost drugs for needy patients. In the years to come the organization gained much popularity and by 1982 it had gained enough funds and volunteer force to form a blood bank and a Thalassemia Follow-up Clinic. With their influence spreading, in 1986 a diagnostic laboratory was set up.\n\nWith the slogan \"\"We feel, We serve\",\" their existence depends on service to the underprivileged segment of society. The organization achieves this by means of several departments which have been built within the vicinity of Civil Hospital, Karachi.\n\nThe Blood bank provides more than 350 units of blood daily on exchange basis not only to patients of Civil Hospital Karachi, but also extends its services to patients all over the city. All units dispatched are screened for Hepatitis B, Hepatitis C, HIV, Syphilis and Malarial Parasite, thus ensuring patient safety. The blood bank also provides blood components such as packed cells, platelets and fresh frozen plasma.\nThe Blood Bank has also started the service of providing mega unit of platelets to patients of Civil Hospital Karachi, free of cost.\n\nPreviously working under the 'Follow Up Clinics', PWA Thalassemia Services was upgraded to a separate department with the start of transfusion facility for registered Thalassemia patients in 2011. The department has got 260 registered patients suffering from Thalassemia, a hereditary blood disorder. These patients are receiving regular blood transfusions and consultations by a qualified Haematologist along with regular diagnostic investigations, Due to shortage of funds, only 60 registered patients are currently being provided with Iron chelation therapy. efforts are under-way to collect funds and start provision of Iron chelation therapy to all registered patients. The cost of treatment of one patients suffering from this lifelong disease is Pakistani Rs. 300,000 - Rs. 500,000 per annum depending upon the age and blood transfusion needs of the patient. PWA Thalassemia Services is providing all these facilities completely free of charge.\n\nThe Patients' Welfare Association holds many events; from fund raising activities to seminars concerning local medical issues. One of their main fund raising events is an annual ‘Food Mela', a bake sale of colossal magnitude, where funds more than one million rupees have been gathered in recent years.\n"}
{"id": "21687159", "url": "https://en.wikipedia.org/wiki?curid=21687159", "title": "Preauricular sinus and cyst", "text": "Preauricular sinus and cyst\n\nA preauricular sinus (also known as a congenital auricular fistula, a congenital preauricular fistula, a Geswein hole, an ear pit, or a preauricular cyst) is a common congenital malformation characterized by a nodule, dent or dimple located anywhere adjacent to the external ear. Frequency of preauricular sinus differs depending the population: 0.1–0.9% in the US, 0.9% in the UK, and 4–10% in Asia and parts of Africa.\n\nPreauricular sinuses are inherited features, and most often appear unilaterally. They are present bilaterally in 25–50% of cases.\n\nOccasionally a preauricular sinus or cyst can become infected.\n\nMost preauricular sinuses are asymptomatic, and remain untreated unless they become infected too often. Preauricular sinuses can be excised surgically, but often present a high risk of recurrence.\nPreauricular sinuses and cysts result from developmental defects of the first and second pharyngeal arches. This and other congenital ear malformations are sometimes associated with renal anomalies. In rare circumstances these pits may be seen in genetic conditions such as branchio-oto-renal syndrome; however these conditions are always concurrent with other health concerns.\n\nCourses of treatment typically include the following:\n\n\n"}
{"id": "33499233", "url": "https://en.wikipedia.org/wiki?curid=33499233", "title": "Radiation-induced thyroiditis", "text": "Radiation-induced thyroiditis\n\nRadiation-induced thyroiditis is a form of painful, acute thyroiditis resulting from radioactive therapy to treat hyperthyroidism or from radiation to treat head and neck cancer or lymphoma. It affects 1% of those who have received radioactive iodine (I-131) therapy for Graves' Disease, typically presenting between 5 and 10 days after the procedure. Stored T and T are released as rapid destruction of thyroid tissue occurs, resulting in pain, tenderness, and exacerbation of hyperthyroidism.\n"}
{"id": "13332727", "url": "https://en.wikipedia.org/wiki?curid=13332727", "title": "Radiation Effects Research Foundation", "text": "Radiation Effects Research Foundation\n\nThe Radiation Effects Research Foundation (RERF) is a joint U.S.-Japan research organization responsible for studying the medical effects of radiation and associated diseases in humans for the welfare of the survivors and all humankind. The organization is located in Hiroshima, Japan.\n\nThe studies have been going on for 70 years, which makes RERF the only institution that has been conducting epidemiological studies on a population of more than 120,000 individuals for this long. RERF continues to conduct research until this day because the effects of A-bomb radiation on human health have not been fully elucidated.\n\nRERF conducts research in multiple fields of science including epidemiology, clinical medicine, genetics, and immunology. Findings from RERF’s studies have been used not only for the medical care and welfare of the A-bomb survivors but also for the establishment of international radiation protection standards.\n\nThe preceding organization to RERF was the Atomic Bomb Casualty Commission which was established in 1948 by the U.S National Academy of Sciences. It was established to determine how, over long-term, exposure to radiation affected the health of A-bomb survivors.\n\nAn extensive interview survey was conducted in the 1950s, based on which records were compiled for each A-bomb survivor. These records concerned location and structure of the building the survivor may have been at the time of the bombing. Based on these records, radiation doses were calculated for most A-bomb survivors.\n\nRERF was established on April 1, 1975, as a nonprofit foundation under the jurisdiction of the Japan Ministry of Foreign Affairs and Ministry of Health and Welfare. On April 1, 2012, RERF transitioned to a public interest incorporated foundation upon authorization by Japan’s Prime Minister.\n\nRERF studies the effects of radiation on the survivors of the atomic bombings in Japan.\n\nThis study gathers samples from the general population of both sexes and all ages. It is the most informative epidemiological study in the world, because of its long duration. It provides information about cancer incidence, cancer mortality and non-cancer effects on the survivors. RERF wants to continue the studies for complete lifetimes of the participants.\n\nThis is a clinical study of a sub-cohort of the Life Span Study, conducted every two years. It is investigating age and radiation-related physiological changes.\n\nThe study’s goal is to determine whether genetic effects may appear in the children of the atomic bomb survivors. RERF has observed no radiation effects in the study of birth defects, chromosome abnormalities, and serum proteins. Currently, molecular studies on DNA are being conducted.\n\nThis study investigates the effects of radiation on the people who were in utero at the time of the bombing (about 3,600 persons).\n\nRadiation biology studies seek to understand the result of physical phenomena involved in radiation response. The studies are directed to DNA indications that cause breast and thyroid cancer.\n\nThis study focuses on the changes in the immune system of people exposed to atomic-bomb radiation.\n\nThis is a newly emerging field of study at RERF, which investigates the radiation effects by looking at molecular changes in DNA. It is used to understand the mechanisms and causes of disease better.\n\nCytogenetics helps assess radiation exposure (biological dosimetry) by evaluating the structural damage in chromosomes.\n\nThis study assesses the risks through the application of mathematical models to rates of disease occurrence or death to identify radiation effects. The statisticians also take part in other studies done at RERF to develop better methods for analysis of data.\n\nThis study provides survivors with radiation exposure dose estimates, based on the knowledge of physics and sensitive measurements that detect minute traces of the atomic bomb radiation in various materials. The information is also combined with historical interview data.\n\nRERF has 2 facilities: one based in Hiroshima and one in Nagasaki.\n\n"}
{"id": "1732409", "url": "https://en.wikipedia.org/wiki?curid=1732409", "title": "Raymond Pearl", "text": "Raymond Pearl\n\nRaymond Pearl (3 June 1879 – 17 November 1940) was an American biologist, regarded as one of the founders of biogerontology. He spent most of his career at Johns Hopkins University in Baltimore. Pearl was a prolific writer of academic books, papers and articles, as well as a committed populariser and communicator of science. At his death, 841 publications were listed against his name.\n\nPearl was born into an upper-middle class in Farmington, New Hampshire on June 3, 1879. At an early age, Pearl was exposed to the classics. His parents and grandparents wanted him to study Greek and Latin. However, when he attended Dartmouth College at 16 years old, he became fascinated by biology and graduated with a B.A. as the youngest in his class. At Dartmouth, he was known to be an exceptional student as well as a skilled musician. He was capable of playing almost every wind instrument, and he planned amateur music performances with his friends and colleagues. In 1899, Pearl attended the University of Michigan where he received his PhD in zoology for his work on the behavior of planarians. He also was involved in studying the variation of fish for the Biological Survey of the Great Lakes. While working in a zoological laboratory, he met his future wife, Maude M. De Witt. In 1903, they married, and together in 1905 and 1906, they traveled abroad and worked at the University of London, University of Leipzig, and Marine Biological Station in Naples.\n\nIn 1906, he spent a year studying under Karl Pearson at University College, London. During this year he discovered biometry, which seemed to offer a solution to the problems he was concerned with in biology, zoology and eugenics. On his return to the US he continued his interests, but was converted from biometry to Mendelian genetics.\n\nPearl’s interest in statistical methods in biology began at the University of London, where he worked alongside Karl Pearson. He stayed as an instructor at the University of Michigan until 1906, and that same year, he went to the University of Pennsylvania to be an instructor in zoology. A year later, he became the head of the Department of Biology of the Main Agricultural Experiment Station at the University of Maine in Orono where he studied the genetics of poultry and other domestic animals. From 1917 to 1919, Pearl was the Chief of the Statistical Division of the United States Food Administration. In 1918, Pearl developed a department of laboratory statistics when he was recruited by Johns Hopkins University to be the Professor of Biometry and Vital Statistics.\n\nIn 1920 he was elected as a Fellow of the American Statistical Association,\nwhich he also served as president.\n\nIn 1929, Pearl’s friend William Morton Wheeler was about to retire as the Dean of the Bussey Institution at Harvard University. At this time, there were plans to alter the current biological departments and create a field of human biology at Harvard. Due to his connections at Harvard, Pearl was mentioned as a possible candidate to succeed Wheeler and had many supporters there. However, Edwin Bidwell Wilson, a Harvard mathematician, was a critic of Pearl and did not believe he was fit for this position. Wilson believed that great detail and attention should be used when dealing with the math of biological data and thought that Pearl had been messy with his handling and reasoning of math in the field of biology. Wilson’s first issue with Pearl was his study of population growth in the 1920s. Pearl stated that he discovered the law of population that represented an S-shaped curve of growth, but Wilson thought that his data was insufficient and did not support this assertion.\n\nDespite his criticism of Pearl, in 1925, Wilson reached out to Pearl for help on his cancer research. Pearl was unaware of Wilson’s criticism of him at the time. He did not help Wilson because he thought that he did not have a sufficient understanding of the biological and medical fields, which further ignited Wilson's distaste of Pearl. In 1929, Pearl conducted research on the correlation between tuberculosis and cancer and published a paper that claimed that there is a negative correlation. This research had mistakes in its data analysis, so Wilson saw this study as an opportunity to attack Pearl and prevent him from becoming the new dean. Wilson denounced Pearl’s use of mathematics in the cancer study to different departments at Harvard and published about it as well. His efforts paid off as the Board of Overseers at Harvard rejected Pearl’s nomination by a vote of ten to nine. Pearl continued his scientific pursuits at Hopkins until his death.\n\nPearl was a eugenicist who held traditional Galtonian beliefs. He wanted to use eugenics and biometry in medicine and public health in order to gain knowledge of human heredity.\n\nPearl founded the Constitutional Clinic at the Johns Hopkins Hospital. He believed in constitutional medicine, which focuses on examining the soil on which a seed falls. He later became the director of a new Institute of Biological Research at Johns Hopkins in 1925 that was aimed at examining the genetics and environmental factors of disease. This research institute combined biometry, genetics, and medicine to investigate the hereditary predisposition of tuberculosis and hypertension. When conducting his research of these diseases, Pearl recorded the height, weight, handedness, measurements of different body parts, and physical descriptions. Just like Galton, he believed that race was an important factor in human characteristics and believed in using biology and genetics to improve the long-term health of the population. Although he tried to be quantitative, objective, and systematic, his classifications of different races were influenced by social norms and prejudices.\n\nHowever, in the late 1920s, Pearl condemned eugenics. Pearl criticized the use of race in eugenics despite conducting research that recognized racial differences. He believed that eugenics was doing the right thing badly and that human biology was eugenics done right if it consisted of reliable statistics, objectivity, a liberal social agenda, and medical affiliations. In 1927, he published the landmark article \"The Biology of Superiority\", which attacked the basic assumptions of eugenics. The article was the first general attack on eugenics by someone perceived as being within the movement. It also contributed to the emergence of reform eugenics and the population control movement. Pearl was an influential member of the Advisory Committee of the World Population Conference, after which Pearl helped found the International Union for the Scientific Study of Population Problems.\n\nDespite his apparent rejection of eugenics, Pearl maintained relatively good relations with key eugenicists and expressed classist views. He made statements which have been interpreted as being anti-Semitic. From 1927-1932, Pearl and his colleague Alan Meyer were important figures of one of the first birth control clinics in the United States called Baltimore’s Bureau for Contraceptive Advice. Pearl was a supporter of birth control, but had a more conservative and scientific approach when compared to the ideologies of Margaret Sanger. The clinic performed a eugenic medicine study that looked at how the distribution of birth control information that was provided by a clinic affected society.\n\nPearl's main focus of interest was in biostatistics. As one of the first biostatisticians to use mathematics as a way to interpret population genetics, Pearl published a book called \"Modes of Research in Genetics\" in 1915 and another book called \"Introduction to Medical Biometry and Statistics\" in 1923. They were both widely read and were influential in showing the importance of statistics in the genetic and medical fields.\n\nEven though many of his books were well-received, some of his beliefs still caused controversy. One such belief was that when a brother and sister reproduce, there would not be an increase in homozygosity. Pearl believed that with brother-sister breeding and no selection past the F3 generation, heterozygosity would not fall below 50%.\n\nEven though his main interest was biostatistics, Pearl had a wide range of interests in biology and was known for his broad knowledge of the subject. He published works on animal behavior, population growth, food and prices, Jewish and Christian marriages, and vegetarianism. In the 1920s and 1930s, Pearl focused on the effect that the environment, which included disease, alcohol, and tobacco, has on longevity. He published a book called \"Alcohol and Longevity\" in 1926, where he claimed that moderate consumption of alcohol could be beneficial for cardiovascular health, which was met with much debate due to prohibition. Controversy continued when Pearl conducted a study on tobacco in which he demonstrated that smoking decreases longevity while drinking does not.\n\nPearl is regarded as one of founders of biogerontology. In 1908 Max Rubner observed that mammals of different size and longevity had equal mass specific metabolic output. Partly based on the observation that the longevity of fruit flies varies inversely with ambient temperature, Pearl (like Rubner) also asserted that maximum life span is inversely proportional to basal metabolic rate. Pearl accepted Alexis Carrel's erroneous ideas that normal somatic cells don't age, and that aging must therefore be due to dysfunction at the body level. Pearl speculated that lifespan was limited by vital cell components that were depleted or damaged more rapidly in animals with faster metabolisms. Denham Harman's free-radical theory of aging later provided a plausible causal mechanism for Pearl's hypothesis.\n\nThe \"Rate of Living Hypothesis\" enjoyed prominence as one of the foremost theories of aging for nearly 50 years. The \"Rate of Living Hypothesis\" is undermined by the observation that a rat and a bat have similar metabolic rate, but a bat lives several times longer. More recently, further doubts have been raised on the \"Rate of Living Hypothesis\" by the demonstration that, when modern statistical methods for correcting for the effects of body size and phylogeny are employed, metabolic rate does not correlate with longevity in mammals or birds. (For a critique of the \"Rate of Living Hypothesis\" see \"Living fast, dying when?\".)\n\nPearl was widely known for his lust for life and his love of food, drink, music and parties. He was a key member of the Saturday Night Club which also included H. L. Mencken. Prohibition made no dent in Pearl's drinking habits (which were legendary).\n\nRaymond Pearl is, also, known for his population biology work, as in his 1928 volume, \"The Rate of Living: Being an Account of Some Experimental Studies on the Biology of Life Duration.\" In this book, he presents extensive research regarding population density effects on life duration in fruit flies, demonstrating that an optimal population density existed for that insect in his experimental model. This raised the question of whether or not the same effect might not occur in other species, including humans. His work demonstrating longer lifespans for flies with lower metabolic rates, also, raised the question of whether or not a similar phenomenon might be found in other species, including humans. Thus, he became a mentor to John B. Calhoun, famous for his ecological studies of rodent populations and their possible importance for modern humans. Population density effects on duration of life is thought, by population biologists, to be Raymond Pearl's greatest contribution to biological science.\n\nIn November 1940, Pearl was in apparently good health and paid a visit to the Baltimore Zoo. He cut his trip short complaining of chest pains and died later that day.\n\n\n\n"}
{"id": "8573961", "url": "https://en.wikipedia.org/wiki?curid=8573961", "title": "Roman Tsepov", "text": "Roman Tsepov\n\nRoman Igorevich Tsepov (Russian: Роман Игоревич Цепов, (July 22, 1962, Kolpino, Leningrad Oblast, USSR – September 24, 2004, Saint-Petersburg) was a Saint Petersburg businessman and confidant to Vladimir Putin during Putin's work at the Saint Petersburg City Administration. Born Belinson, Tsepov changed his surname upon marriage to Tsepova. Tsepov was suspected of criminal and corruption activity.\n\nUpon graduation from the Supreme Political school of the Ministry of Internal Affairs of the USSR, Tsepov served in the Internal Troops as a political commissar. In 1990, he retired from the Ministry of Internal Affairs at the rank of captain.\n\nIn 1992, Tsepov founded the security firm \"Baltik-Eskort\". The idea to create this agency belonged to the future Putin's bodyguard Viktor Zolotov who later oversaw this agency as a member of the active reserve. The firm provided protection to high ranking Saint Petersburg officials, including the city mayor Anatoly Sobchak and his family, as well as the vice-mayor Vladimir Putin. In this role, Tsepov also acted as an \"intermediary between Putin and business\". At the same time, \"Baltik-Eskort\" rendered security services to a number of criminal leaders, in particular Aleksandr Malyshev, the leader of \"Malyshev's gang\" and his family and several figures of the Tambov Gang.\n\nIn 1994, Tsepov was arrested on charges of illegal storage of weapons and drugs. It is rumored that the real reason for arrest was gathering of \"protection\" money to secure gambling licenses from city office of Vladimir Putin.\n. Starting in 1993, there were five unsuccessful attempts on Roman Tsepov's life. His name appears in several criminal investigations, the last one being in March 1998 on charges of extortion of 70 thousand dollars .\nTsepov went into hiding and fled to Czech Republic\n\nUpon Vladimir Putin's coming to power, Tsepov became one of the most influential figures in the financial and political life of Saint Petersburg. He took part in the first presidential inaugural ceremony of Vladimir Putin. Tsepov's power and influence were attributed to his close association with then Minister of Internal Affairs Rashid Nurgaliyev, the chief of Presidential Security Service Viktor Zolotov (Zolotov attended Tsepov's funeral) and deputy head of presidential administration Igor Sechin.He was also affiliated with Saint Petersburg branches of the Russian Ministry of Internal Affairs and FSB\n\n. Journalists named Roman Tsepov \"a security oligarch\"]\n. Regarding all this real or rumored activity, Tsepov stated: \"For some reason all the time Tsepov appeared to be the most convenient figure for rumors. Elections - Tsepov. Criminal investigations, tranches, credits, fuel business, security, a casino - Tsepov. Personnel rearrangements - me too. The grey cardinal necessarily should exist at a king's court\". In the summer of 2004, Tsepov was rumored to attempt to mediate between the government and YUKOS.\n\nOn 11 September 2004, Tsepov visited colleagues at a local FSB office where he had a cup of tea. On the same day, he felt unwell after which a very serious disease developed with symptoms such as vomiting, diarrhoea and sudden drop of white blood cells. Treated in Hospital 31 in Saint Petersburg, he died on 24 September. A postmortem investigation found a poisoning by an unspecified radioactive material. He had symptoms similar to Aleksander Litvinenko.\n\nAfter playing a small part in Vladimir Bortko's mini-series \"\" (2000) Tsepov co-produced the Vladimir Bortko's mini-series \"My Honor\" (2004). The series was awarded a TEFI, the highest television award in Russia, as best film.\n\n\n"}
{"id": "3473743", "url": "https://en.wikipedia.org/wiki?curid=3473743", "title": "Réveillon riots", "text": "Réveillon riots\n\nThe Réveillon riots occurred between 26–29 April 1789 centered in the St. Antoine district of Paris where a factory which produced luxury wallpaper was owned by Jean-Baptiste Réveillon. The factory employed around 300 people. The riots were one of the first instances of violence during the French Revolution. The factory where the riot took place was unusual in pre-revolutionary France as the factory was guild-free in an era where guilds controlled quality standards. \n\nProtests began after rumors spread that the owner had made a speech stating that workers, many of whom were highly skilled, were to be paid lower wages and, as a result, there would be lower prices. Workers were concerned with food shortages, high unemployment, and low wages after a difficult winter in 1789. However, Réveillon was known for his benevolence towards the poor and actually stated that bread prices should be brought down to those that people could afford (below 15 sous a day) but his comments were misinterpreted as wage restrictions. He made the comments on 21 April when the assembly of the Saint-Marguerite was discussing its \"Cahier\" which all Estates drew up before the Estates-General was to be called. \n\nAfter informal protests on Sunday 26 April, groups of protesters congregated on the Ile de la Cité and in the Faubourg Saint-Marcel, Marais, and Faubourg Saint-Antoine the next day for a series of protest-marches. Though the first three marches - one of which targeted the Third Estate's Assembly of Electors - were resolved peacefully, confrontations between troops and participants in the fourth demonstration led to the outbreak of violence in the Faubourg Saint-Antoine that evening. \n\nWhile the protesters did not manage to destroy the factory as it was being guarded by a group of around fifty troops, a factory owned by the saltpetre manufacturer Henriot was destroyed after he made similar comments. However Réveillon’s factory was destroyed a day later as was his home The riot killed 25 people and wounded around the same number although rumour caused the casualty figures to be exaggerated. The French Guard were used to restore order.\n\n\n"}
{"id": "49260592", "url": "https://en.wikipedia.org/wiki?curid=49260592", "title": "Salvatore Calabrese", "text": "Salvatore Calabrese\n\nSalvatore Calabrese (Campi Salentina, 6 January 1903 – Bologna 30 November 1973) was an Italian physician, scholar of Anatomical pathology and specialized in Gastroenterology. He promoted the construction of the Hospital Padre Pio da Pietrelcina in Campi Salentina. He is also the founder of the orphanage and homeless shelter “Mamma Bella”.\n\nSalvatore Calabrese was born on 6 January 1903 in Campi Salentina (Lecce). In 1928 he graduated in Medicine and Surgery at the University of Naples Federico II. After that he moved to Genoa where he worked as volunteer assistant in the department of internal medicine at the Civil Hospital; then he became the medical director of the industrial company “Ansaldo”. During this period he dedicated his studies to Anatomical pathology and he also wrote various and popular scientific publications. In 1939 he specialized in Gastroenterology at the University of Pavia. During the Second World War he took part in the Italian Resistance against the fascists and he also participated in military operations for the liberation of Genova. In 1945 Calabrese came back to Campi Salentina where he founded the orphanage and homeless shelter “Mamma Bella”, dedicated to his three sons died prematurely. Five years later he gave impetus to the foundation of the Hospital Padre Pio da Pietrelcina, where he became medical director in 1951. He died in Bologna on 30 November 1973 after a myocardial infarction.\n\n"}
{"id": "57786285", "url": "https://en.wikipedia.org/wiki?curid=57786285", "title": "Simon Ourian", "text": "Simon Ourian\n\nSimon Ourian, M.D founded Epione Beverly Hills in 1998 in Beverly Hills, California. Ourian is credited for developing the Coolaser and Coolbeam procedures. His clients include celebrities like the Kardashian-Jenner family, Victoria’s Secret supermodels, Hollywood actors and musicians.\n\nOurian was born in Iran and moved the Los Angeles in the 1980s with his parents. His inclination towards cosmetic dermatology started at a young age when he saw the effect of plastic surgery on movie actors.\n\nHe received his undergraduate degree in the field of molecular biology from the California State University, Northridge, and his medical degree from Wayne State University in Michigan. Ourian did his residency at UCLA.\n\nHe is married to Sharon Naim Ourian.\n\nAfter completing his education, Ourian started his own practice. He worked on his techniques and tested non-invasive procedures on himself. Ourian worked with the Fibonacci sequence to study facial elements and patterns. \nIn 1998, he founded the Epione Beverly Hills. He developed Coolaser for clearing acne and discoloration for darken skin tone and Coolbeam to get rid of stretch marks. He also created my Vibrata, a tool for minimizing pain, which is used by doctors around the globe. Ourian uses various laser technology and non-invasive aesthetic procedures for the correction or reversal of a variety of conditions.\n\nOurian developed the Coolaser technology, and it has been used by celebrities such as Olivia Culpo and Kim Kardashian. It involves cooling the treatment area with a special device that emits a series of light pulses across the surface of the skin to stimulate cell repair and collagen growth.\n\nOurian is the doctor for the entire Kardashian-Jenner clan. He gained popularity when Kim Kardashian acknowledged him as her cosmetic dermatologist. Ourian has performed several procedures on her sister Kylie Jenner. He has also worked on Malika Haqq, Brandi Maxiell, Miss Colombia, Meghan James, Lady Gaga, beauty YouTuber Nikkie, and Lisa Vanderpump\n"}
{"id": "13327372", "url": "https://en.wikipedia.org/wiki?curid=13327372", "title": "Sleep–wake activity inventory", "text": "Sleep–wake activity inventory\n\nThe sleep–wake activity inventory (SWAI) is a subjective multidimensional questionnaire intended to measure sleepiness.\n\nThe SWAI consists of 59 items that provide six subscale scores: excessive daytime sleepiness, nocturnal sleep, ability to relax, energy level, social desirability, and psychic distress. Each item is rated on a 1 to 9 semicontinuous Likert type scale from \"always\" to \"never\", based on the previous seven days. The SWAI was normed on 554 subjects in the early 1990s and is currently being validated or has been validated in multiple languages, including Spanish, French and Dutch.\n\nFor the \"excessive daytime sleepiness\" subscale (SWAI-EDS), a score of 40 or below indicates excessive sleepiness, a score of between 40 and 50 indicates possible sleepiness and a score of greater than 50 is normal.\n\nA short form of the SWAI exists that contains items for the \"excessive daytime sleepiness\" and \"nocturnal sleep\" subscales only.\n\nThe SWAI has been compared to the multiple sleep latency test (MSLT), which is an objective measure that is considered the gold standard of sleepiness assessment; it measures sleep onset latency during several daytime opportunities. The SWAI-EDS has been found to correlate moderately to highly with average MSLT scores.\n\nOther sleepiness scales, including the Stanford sleepiness scale and the Epworth sleepiness scale (ESS), exist. However, the ESS does not correlate as highly with the MSLT as the SWAI. The ESS is currently the most prevalent measure of excessive sleepiness.\n\nThe SWAI was developed by Drs. Leon Rosenthal, Timothy Roehrs and Tom Roth at the Sleep Disorders and Research Center at the Henry Ford Hospital in Detroit, Michigan.\n"}
{"id": "39058673", "url": "https://en.wikipedia.org/wiki?curid=39058673", "title": "Spiral plater", "text": "Spiral plater\n\nA spiral plater is an instrument used to dispense a liquid sample onto a Petri dish in a spiral pattern. Commonly used as part of a CFU count procedure for the purpose of determining the number of microbes in the sample. In this setting, after spiral plating, the Petri dish is incubated for several hours after which the number of colony forming microbes (CFU) is determined. Spiral platers are also used for research, clinical diagnostics and as a method for covering a Petri dish with bacteria before placing antibiotic discs for AST.\n\nThe spiral plater rotates the dish while simultaneously dispensing the liquid and either linearly moving the dish or the dispensing tip. This creates the common spiral pattern. If all movements are done in constant speed, the spiral created would have a lower concentration on the outside of the plate than on the inside. More advanced spiral platers provide different options for spiral patterns such as constant concentration (by slowing down the spinning and / or the lateral movements) or exponential concentration (by speeding up the spinning and / or the lateral movements).\n\nSpiral plating is used extensively for microbiological testing of food, milk and milk products and cosmetics. It is an approved method by the FDA. The advantage of spiral plating is less plates used versus plating manually because different concentrations are present on each plate. This also makes it harder to count the colonies and requires special techniques and equipment.\n\nSpiral platers are either available as stand-alone instruments that are fed manually with plates and samples or fed automatically using dedicated stackers. Alternatively spiral platers are available as integrated devices as part of larger automated platforms. In this case a larger workflow is often automated, e.g. plating, incubation and counting.\n"}
{"id": "15196313", "url": "https://en.wikipedia.org/wiki?curid=15196313", "title": "Sylhet MAG Osmani Medical College", "text": "Sylhet MAG Osmani Medical College\n\nSylhet MAG Osmani Medical College (SOMC) () is a government medical school in Bangladesh, established in 1962. It is located in Sylhet. Originally named \"Sylhet Medical College\", it was renamed in 1986 in honour of General Muhammad Ataul Gani Osmani, Commander-in-chief of Bangladesh Army during the Bangladesh Liberation War of 1971. The college is affiliated with Shahjalal University of Science and Technology under the School of Medical Sciences.\n\nIt offers a five-year course of study leading to a Bachelor of Medicine, Bachelor of Surgery (MBBS) degree. A one-year internship after graduation is compulsory for all graduates. The degree is recognised by the Bangladesh Medical and Dental Council. It admits approximately 200 undergraduate and a good number of postgraduate students every year.\n\nIt also offers 4 year's course on Bachelor Of Dental Surgery. (BDS)\n\nThe college and hospital extends over an area of 206,355 sq m divided into new site and old site. The Sylhet MAG Osmani Medical college situated in the new site covers an area of 191,977 sq M.\n\n\nMain campus comprises individual facilities of:\n\nOther many nearby hospitals are also affiliated with main academic schedule. These include:\n\nThere are five hostels for boys' & four for the girls'.\n\nBoys' hostels includes -\n1. Shahid Dr.Shamsuddin Ahmed Hostel\n2. Abu Sina Hostel\n3. Colonel Zia Hostel\n4. Hazrat Shahjalal Hostel \n5. Shahid Dr. Milon Intern Hostel.\n\nGirls' hostels includes -\n1. Dr. Dilruba Begum Hostel\n2. Dr. Shayamol Kanti Lala Hostel \n3. Hazrat Shahporan Hostel\n4. Intern Hostel ( female)\n\nSylhet MAG Osmani Medical College now offer 20 postgraduate courses. The presently available courses are M.D. (Internal medicine, Pediatrics and Cardiology), M.S. (|General Surgery, Obstetrics & Gynaecology, Ophthalmology, Pediatric surgery and Orthopaedics), M.Phil (Anatomy, Biochemistry, Pharmacology, Microbiology, Pathology and Psychiatry), one year Diploma (Forensic Medicine, Clinical Pathology, Child Health, Anesthesia, Dermatology & Venereal Disease and Obstetrics Gynaecology). The college now has more than 150 faculty members, around 350 staffs for 1000 undergraduate students and around 400 postgraduate students. All the courses are certified by Shahjalal University of Science and Technology (both undergraduate and postgraduate courses) are recognized by the National regulatory agency Bangladesh Medical and Dental Council.\n\n\nTwo journals are published. Both are BMDC recognized. These are\n\n"}
{"id": "36527709", "url": "https://en.wikipedia.org/wiki?curid=36527709", "title": "Tatsudaryo Incident", "text": "Tatsudaryo Incident\n\nThis became national news. The issues were the right of children to attend public school despite their parents illness, the right of the general public to avoid contagion, the accuracy of the predictions made by the medical community, and the rights of the local community over national control of education.\n\nWhen leprosy sanatoriums were constructed in 1909, the question arose concerning the care of children born to leprosy patients. In the Kyushu Sanatorium, now the Kikuchi Keifuen Sanatorium, healthy, non-resident relatives of the family were directed to care for the children of leprosy patients. Another option was to allow the Tairo-in Sanatorium, or Tairoin Hospital take care of the children with funding provided by the leprosy prevention association.\n\nThe following is a sample list of fees for children boarded out.\n\nIn 1935, Keifūen Home was constructed within the campus of Kyushu Sanatorium by the Leprosy Prevention Association for the children of patients with leprosy. In 1941, the Kaishun Byōin, a leper hospital established by Hannah Riddell was disbanded. To replace it, Tatsuda Ryo (dormitory) was constructed with 19,800 yen donated by the hospital. Those patients in the Keifuen Home were transferred to the Tatsuda Ryo.\n\nA school was created within the dormitory. There was one teacher. Education was limited. Patients' children of high school and junior high school age were attending local public schools, but primary school-age students were not.\n\nIn 1942,　the Kikuchi Keifuen Sanatorium insisted that Kumamoto City should integrate the primary school students, as well. While the city officials agreed, the public school officials declined.\n\nTwenty-three primary aged children were involved:\n\nMatsuki Miyazaki was a physician, leprosy specialist, and Director of the Kyushu Sanitorium. In December 1953, he met with the principal of the Kurokami Primary School to ask him to consider admitting children of leprosy patients. He requested an answer by April 1954.\n\nThe school principal said he would agree if their Parent Teacher Association (PTA) would agree. Ryunosuke Seguchi was president of the PTA. He was a physician and chairman of the Kyushu Prefectural Assembly. Seguchi said that the problem should be handled cautiously but offered no definitive answer. Miyazaki then sent a formal request to the Kumamoto District Legal Affairs Bureau asking that discrimination in schooling should be halted. Seguchi publicly disagreed with this request. The issue became national news.\n\nOn December 9, 1953, there was an annual meeting of the PTA of the Kurokami Primary School. Participants included Miyazaki, Seguchi, members of the city educational committee, and local representatives of the city.\n\nA questionnaire had been sent out to parents. The results of the questionnaire were made public. Those in favor of schooling were 420 (34%), against schooling were 795 (64%) and 14 (2%) were neutral. The Kumamoto District Legal Affairs Bureau expressed the opinion that 1) In four other leprosy sanatoriums, there had been no trouble integrating students without infection. 2) Tadao Toda, a Professor of Bacteriology at Kyushu University and Professor Kentaro Higuchi, a Professor of Dermatology, Kyushu University had expressed the view that non-infected students infecting other pupils with leprosy was inconceivable.\n\nThe three ministries of Japan of Education, Justice and Welfare expressed the view that denial of schooling would be illegal. The Ministry of Welfare stated that proper health maintenance could not lead to the infection of leprosy. The ministry of education thought that pupils should attend the school without discrimination, since there was no possibility of infection. The Ministry of Justice stated that the pupils should attend the school.\n\nOn March 1, the following policy was established by the Kumamoto District Legal Affairs Bureau that 1) the city education committee should ensure that the pupils attend the public school starting April 1, 1954; 2) the Kikuchi Keifuen Sanatorium should give more strict health maintenance to the pupils. The meeting was attended by the Legal Affairs Bureau staff, the city education committee members and the Kikuchi Keifuen staff.\n\nOn March 1, 1954, the citizens of the Kurokami Primary School held a meeting on the school grounds. Protestors claimed that although the pupils in the Tatsuda Ryo were said to be not infected, five pupils had been isolated. The protestors did not believe that there was no danger of infection. They were not convinced of the method of treatment.\n\nThe rate of developing leprosy among pupils was 0.7%. Based on that statistic, the protestors felt that they could not endanger their 1,800 students. On March 10, Okamoto, the chairman of the city education committee stated at the city assembly that they had reached the conclusion that the pupils should attend the school. This was broadcast on the radio the following day. Members of the PTA intensified their opposition. On March 12, they announced that they would stage a strike.\n\nSome of the members of PTA stated that they would favor integration if a third party would guarantee that the prospective attendees had not been infected. On April 2, a health examination of the four pupils, under question, was conducted at the Department of Dermatology, Kumamoto University. This revealed that the pupils were not infected. On April 7, the city education committee declared that the pupils would attend the school. Dissatisfied, the opposition members went on strike April 8. They displayed a large poster that pupils should not go to school with pupils with leprosy. Initially the strike was a success. Only four pupils attended the school with a kindergarten teacher. 76 pupils went to school out of 1928 registered. On the 5th day, 312 pupils attended the school. The opposition movement side started a type of Terakoya education, namely unofficial private schools at 17 sites.　On April 27, there was another examination of the four pupils under question at the Department of Dermatology, Kumamoto University. They announced that one girl needed further examination. This strengthened the opposition movement. Because of the conflict, the principal of the school retired and Toko Kozaki assumed the post of the principal on May 1.\n\nOn June 15, 1954, the opposition movement requested the abolishment of the Tatsuda Dormitory. A conflict started between the two lobbyist groups. Japanese Education Minister Oodate heard from both sides when he visited Kumamoto on October 7.\n\nThe group who favored integration of primary students stated that the attitude of the Kurokami Primary School was deplorable, since graduating primary students go from the Tatsuda Ryo to local secondary schools and high schools. Miyazaki said that the prevention of leprosy was a national policy. Children born of leprosy patients live in the Tatsuda Ryo in order not to infect children. The problem should be solved from the standpoint of equal right of education. In other parts of Japan, children born of leprosy patients were welcomed.\n\nThe opposition said that they heard the explanation from Dr. Miyazaki, but it was pressure from the law and science. They had heard that three persons had developed leprosy from the Tatsuda Ryo. In the case of Sakurayama High School, they admitted a student secretly. The president of the PTA said that enlightenment should come first; if the local inhabitants became convinced. Otherwise, the children cannot feel safe.\n\nMeetings of both sides were frequently held in the small community. When the city education committee sent a letter allowing the children to go to school, three members of the opposition movement went on a hunger strike before the city education committee.\n\nThe hunger strike continued over 155 hours when it was stopped by the mediation of Morio Takahashi, the President of the Kumamoto College of Commerce. He would take care of the questioned children (one boy and two girls) at his house and let them go to the school.\n\nA commencement ceremony took place on April 18, 1955. The children went to school accompanied by a female teacher of another school. The incident appeared to be solved but the school had taken special precautions. The children were encircled by classmates of the pro-schooling movement and special attention was given to school lunch. Starting in the fall of 1955, the children of the Tatsuda Ryo were secretly sent to various institutions and homes and relatives. In October 1957, the Tatsuda Ryo was formally abolished.\n\n"}
{"id": "30865454", "url": "https://en.wikipedia.org/wiki?curid=30865454", "title": "Tidal Model", "text": "Tidal Model\n\nThe Tidal Model is a recovery model for the promotion of mental health developed by Professor Phil Barker, Poppy Buchanan-Barker and their colleagues. The Tidal Model focuses on the continuous process of change inherent in all people. It seeks to reveal the meaning of people's experiences, emphasising the importance of their own voice and wisdom through the power of metaphor. It aims to empower people to lead their own recovery rather than being directed by professionals.\n\nThe philosophy underpinning the model initially was inspired by a five year research into what people need for care in mental health carried out by Prof. Barker and Dr. Chris Stevenson at the University of Newcastle, UK. Since 2000, it has been put into practice in a number of settings in the UK and abroad.\n\nDue to the work of Phil Barker in this area, he is frequently cited as being a prominent contemporary theorist in mental health nursing.\n\nThe tidal model is applied through six key philosophical assumptions:\n\nIn order for the practitioner to begin the process of engagement using the Tidal Model, the following needs to be accepted:\n\nThe process of engaging with the person in distress takes place in three discrete domains. With the Tidal Model, the practitioner explores these dimensions to be aware of the situation in the \"present\" time and determine what needs to happen \"now\".\n\n\nThe Tidal Model uses the metaphor of water and describes how people in distress can become emotionally, physically and spiritually \"shipwrecked\". It sees the experience of health and illness as a \"fluid, rather than a stable phenomenon\", and life as a journey undertaken on an \"ocean of experience\". It proposes that in mental health, the factors associated with a psychiatric crisis, or its more enduring consequences, can be diverse as well as cumulative. It states that by appreciating this metaphor, nurses or other helpers will gain a greater understanding of the person's current situation and the inevitability of change. With this, the helper may, in time, be guided to \"care with\" the person beginning their journey from the state of being \"washed ashore\", \"drowning\" or being otherwise \"marooned\" by their life problems. Following the rescue, exploration can then begin as to what caused the \"storm\" in the first place and what needs to be done immediately to \"set sail\" again.\n\nThe values of the Tidal Model can be distilled into Ten Commitments.\n\nThe Twenty Competencies were introduced to assist with the auditing of recovery practice by generating practice-based evidence for the model. They focus on competencies in practice and there are two related to each of the commitments above.\n\nIn 2000, the Tidal Model was first implemented in Newcastle-upon-Tyne, UK in the adult mental health programme covering nine acute admission wards. Almost 100 different Tidal Model projects were established in the UK, Ireland, New Zealand, Canada, Japan and Australia. However, it has yet to be broadly adopted.\n\n\n"}
{"id": "51080253", "url": "https://en.wikipedia.org/wiki?curid=51080253", "title": "Toilet plume", "text": "Toilet plume\n\nA toilet plume is the dispersal of microscopic particles as a result of flushing a toilet. The term refers to both the contamination of nearby surfaces through droplets ejected from the toilet, and the formation of smaller, dry particles that stay in the air for long periods, although the former appears to be of more concern.\n\nWhile there is indirect evidence that aerosols containing pathogens could potentially be spread by a toilet plume, as of 2013 no direct experimental studies had clearly demonstrated or refuted actual disease transmission from toilet aerosols, and the risk had not been well characterized. It has been hypothesized that dispersal of pathogens may be reduced by closing the toilet lid before flushing, and by using toilets with lower flush energy.\n\nThere is indirect evidence that toilet aerosol can be a vector for diseases that involve acute gastroenteritis with the shedding of large numbers of pathogens through feces and vomit, with normal use of a toilet unlikely to be a major health risk. For example, some epidemiological studies indicate transmission of norovirus in passenger airplanes and ships, and SARS coronavirus through a contaminated building sewage system, via contaminated toilets rather than other routes. The feces and vomit of infected people can contain high concentrations of pathogens, many of which are known to survive on surfaces for weeks or months, and toilets may continue to produce contaminated toilet plumes over multiple successive flushes. Some other pathogens speculatively identified as being of potential concern for these reasons include gram-positive MRSA, \"Mycobacterium tuberculosis\", and the pandemic H1N1/09 virus commonly known as \"swine flu\".\n\nThere is no direct experimental evidence on disease transmission by toilet aerosols. Whether or not aerosols can contain norovirus, SARS coronavirus, or other pathogens has not been directly measured as of 2015. The combination of cleaning and disinfecting surfaces is usually effective at removing contamination, although some pathogens such as norovirus have an apparent resistance to these techniques.\n\nAerosol droplets produced by flushing the toilet can enter the air of the room. Larger droplets will settle on a surface before they can dry, and can contaminate surfaces such as the toilet seat and handle which can then be contacted by hands. Smaller aerosol particles can become droplet nuclei as a result of evaporation of the water in the droplet, which have negligible settling velocity and are carried by natural air currents. Disease transmission through droplet nuclei is not a concern for many pathogens, because they are not excreted in feces or vomit, or are susceptible to drying. The critical size dividing these depends on the evaporation rate and vertical distance between the toilet and the surface.\n\nExperiments to test bioaerosol production usually involve seeding a toilet with bacteria or virus particles, or fluorescent microparticles, and then testing for their presence on nearby surfaces and in the air after varying amounts of time. The amount of bioaerosol varies with the type of flush toilet. Older wash-down toilet designs produce more bioaerosol than modern siphoning toilets. Among modern toilets, bioaerosol production increases as qualitative flush energy increases, from low-flush gravity-flow toilets common in residences, to pressure-assisted toilets, to flushometer toilets often found in public restrooms.\n\nOne study found that lowering the toilet lid prevented dispersion of large droplets and reduced the airborne bacteria concentrations by a factor of 12. The study recommended discouraging the use of lidless toilets, which contradicts the U.S. Uniform Plumbing Code specifications for public toilets.\n\nExperiments on the bioaerosol content of toilet plumes were first performed in the 1950s. A 1975 study by Charles P. Gerba popularized the concept of disease transmission through toilet plumes. The term \"toilet plume\" was in use before 1999.\n"}
{"id": "44633434", "url": "https://en.wikipedia.org/wiki?curid=44633434", "title": "Trengestone", "text": "Trengestone\n\nTrengestone, sold under the brand names Reteroid, Retroid, and Retrone, is a progestin medication which was formerly used to treat menstrual disorders but is now no longer marketed. It is taken by mouth.\nSide effects of trengestone include headache, fatigue, and breast tenderness among others. Trengestone is a progestin, or a synthetic progestogen, and hence is an agonist of the progesterone receptor, the biological target of progestogens like progesterone. It is not androgenic or estrogenic.\nTrengestone was introduced for medical use in 1974. It is no longer available.\n\nTrengestone was used in the treatment of menstrual disorders. It has also been used to induce ovulation, with about a 50% success rate on average.\n\nSide effects of trengestone include headache, fatigue, and breast tenderness among others. It is not androgenic and does not cause masculinization.\n\nTrengestone is a progestogen, or an agonist of the progesterone receptor. It is an atypical progestogen similarly to dydrogesterone. For instance, unlike other progestogens, trengestone and dydrogesterone do not increase body temperature (i.e., have no hyperthermic effect). In addition, whereas other progestogens are antigonadotropic and inhibit ovulation, dydrogesterone is neither antigonadotropic nor progonadotropic and does not affect ovulation, and trengestone appears to be progonadotropic and can be used to induce ovulation. Similarly to dydrogesterone and progesterone, trengestone has no androgenic or estrogenic activity.\n\nTrengestone appears to be a prodrug of 20α-dihydrotrengestone (20α-DHTG), as it is largely transformed into this major metabolite upon oral administration. 20α-DHTG has potent progestogenic activity, with peak levels of this metabolite occurring at 2 to 4 hours following administration of trengestone and with a biological half-life of 8 to 14 hours. Trengestone is excreted 41 to 46% in urine and up to 30% unchanged in feces, suggesting that a significant portion of the medication is not absorbed from the gastrointestinal tract. The metabolism and pharmacokinetics of trengestone have been reviewed.\n\nTrengestone, also known as 1,6-didehydro-6-chlororetroprogesterone or as 6-chloro-9β,10α-pregna-1,4,6-triene-3,20-dione, is a synthetic pregnane steroid and a derivative of progesterone and retroprogesterone. Retroprogesterone derivatives like trengestone are analogues of progesterone in which the hydrogen atom at the 9th carbon has been switched from the α-position (below the plane) to the β-position (above the plane) and the methyl group at the 10th carbon has been switched from the β-position to the α-position. This results in a \"bent\" configuration in which the plane of rings A and B is orientated at a 60° angle below the rings C and D. Analogues of trengestone include dydrogesterone (6-dehydroretroprogesterone) and Ro 6-3129 (16α-ethylthio-6-dehydroretroprogesterone).\n\nTrengestone was synthesized in 1964 and was introduced for medical use by Roche in 1974.\n\n\"Trengestone\" is the generic name of the drug and its . It is also known by its former developmental code name \"Ro 4-8347\".\n\nTrengestone was marketed under the brand names Reteroid, Retroid, and Retrone.\n\nTrengestone is no longer marketed and hence is no longer available in any country.\n"}
{"id": "57726031", "url": "https://en.wikipedia.org/wiki?curid=57726031", "title": "Unaccompanied Alien Children", "text": "Unaccompanied Alien Children\n\nUnaccompanied Alien Children (or UAC, also referred to as unaccompanied alien minors or UAMs or inadmissibles) are unaccompanied minors who are aliens. They are classified by the United States Department of Health and Human Services as illegal immigrants under 18 without legal guardians in the United States.\n\nMost UAC are over 14 years old. The younger minority are assumed unable to make decisions independently. In 2009-2010, 41% of children under 14 were either 13 or 14. In 2013, 24% of apprehended child arrivals were 14 or younger, meaning 76% were 15-17.\n\nWhen the U.S. Border Patrol apprehends a potential minor, the agency determines age based on biographical data collected from the child and \"multiple forms of evidence, including interview statements, documentation (such as birth certificates) or professional medical opinion based on radiographs (or x-rays), if necessary.\"\n\nThe Office of Refugee Resettlement took over the supervision of unaccompanied minors in 2003. In the first nine years of its operations, it was charged with fewer than 8,000 children per year.\n\nThe number of apprehended UAC doubled from 2009 to 2013.\n\nIn 2014 the Obama administration classified UAC influx as an urgent situation.\n\nAfter a 2015 dip, in 2016 the number of apprehended UAC rose back to high levels similar to 2014. The Border Patrol reports that it apprehended 32,372 unaccompanied minors from October 1, 2017 to May 31, 2018. There was a 4% increase in the Southwest in FY2018 compared to FY2017.\n\nIn 2018 the Trump administration reported tens of thousands of UAC were released annually and only 3.5% had been removed from the United States. In 2017 and 2018, under a zero tolerance policy, children who were separated from arrested adults they were traveling with are treated as UAC.\n\nThe ORR coordinates a network of over 100 facilities in seventeen states housing over ten thousand children within the UAC program. Approximately, 11,400 children were in ORR custody in mid-June 2018. The largest share of these children—5,129—are held in facilities managed by Southwest Key Programs, an Austin-based non-profit with facilities in Texas, Arizona, and California. On average, as of June 15, 2018, children stay in these facilities for 57 days. According to spokesperson Wolfe, the Tornillo Port of Entry is being used as a temporary shelter for UAC.\n\n"}
{"id": "37032581", "url": "https://en.wikipedia.org/wiki?curid=37032581", "title": "University of Montenegro Faculty of Medicine", "text": "University of Montenegro Faculty of Medicine\n\nThe University of Montenegro Faculty of Medicine (Montenegrin: Medicinski fakultet Univerziteta Crne Gore \"Медицински факултет Универзитета Црне Горе\") is one of the educational institutions of the University of Montenegro. The Faculty's main building is located in Podgorica, near the Clinical Center of Montenegro. \n\nThe Podgorica Medical School was officially established in 1997. In 2005, as part of the Faculty, the postgraduate High School for Nurses was founded in Berane.\n\nThe Faculty is a teaching-scientific institution which organizes the practical part of teaching in the teaching-scientific bases: Clinical Center of Montenegro, Public Health Institute, Institute \"Dr Simo Milošević\" in Igalo, Hospital for Pulmonary Diseases Brezovik and various health centers. Five study groups are currently being provided at the Faculty:\n"}
{"id": "35486864", "url": "https://en.wikipedia.org/wiki?curid=35486864", "title": "Vitiligo Research Foundation", "text": "Vitiligo Research Foundation\n\nThe Vitiligo Research Foundation (VRF) is a New York-based 501(c)3 non-profit organization focused on the skin disease Vitiligo.\n\nThe Vitiligo Research Foundation was founded in 2010 by Russian entrepreneur Dmitry Aksenov, whose daughter suffers from vitiligo, after he found that there was a lack of quality research into the disease.\n\nThe VRF is managed by a small team of permanent staff. They are assisted by a Board of Directors chaired by Professor Torello Lotti (Professor of the Dermatology Division at University of Rome “Guglielmo Marconi”. A Scientific Advisory Board advises on scientific issues, while a Public Advisory Board that includes members such as reporter and author Lee Thomas, advises on aspects of living with vitiligo and how best to support those affected by the condition. The members of all three Boards are volunteers.\n\nThe VRF receives no funding from government or the pharmaceutical industry and is entirely reliant on public donations.\n\nInitiatives instigated and/or supported by the VRF:\n\nThe Vitiligo BioBank is a federated network of biobanks in nine different countries that store genetic material and health records from both vitiligo patients and their unaffected relatives. All participating biobanks share common Standard Operating Procedures, as well as a standardized data set (Vitiligo Patient Record) developed by the VRF. Bio samples are collected and stored locally, while accompanying anonymous clinical records are stored in the Vitiligo CloudBank.\n\nThe Vitiligo Cloudbank is a secure online system that holds information on vitiligo patients from across the world. This includes vitiligo patient records, laboratory analysis data and, in some cases, associated genomic data. In 2014, the VRF also invited patients to use CloudBank as a personal vitiligo health record while participating anonymously in collaborative research.\n\nThe VRF sponsors and promotes June 25 as World Vitiligo Day – a date where people across the world come together to increase awareness of vitiligo, fight prejudice and raise funds for research, support and education. Signatures are currently being collected through 25June.org to petition the UN Secretary General to officially designate the date as World Vitiligo Day.\n\nThe World Vitiligo Map is an international directory that provides global information on vitiligo research centers, patient support groups and healthcare providers experienced in treating vitiligo and supporting sufferers. It is free to use and, in general, the medical professionals who appear in the directory are not affiliated with the VRF.\n\nIn late 2014, the VRF introduced an innovative approach to research funding by setting up a crowdfunding scheme for selected research projects. This allows supporters to donate directly to vitiligo research projects and programs that are typically too small to apply for a grant but too big to be funded directly from the VRF budget.\n"}
{"id": "13400390", "url": "https://en.wikipedia.org/wiki?curid=13400390", "title": "Vladivostok State Medical University", "text": "Vladivostok State Medical University\n\nPacific State Medical University (), formerly known as VSMU (Vladivostok State Medical University) is a university in Vladivostok in the Far East of Russia.\n\nAt the beginning, since 1956 VSMU was the Medical Faculty of the Far Eastern State University, but in 2 years it became Vladivostok State Medical Institute (VSMI). Institute was reorganized into the University in 1995, in 2013 the University was renamed and reorganized into Pacific State Medical University.\n\nFaculties of the Pacific State Medical University:\n\nAmong the medical Universities of the Far East, PSMU - the only institution that trains doctors at Faculty Medical Prophylactic , providing preventive measures for healthy living of the population of Khabarovsk, Primorsky and Kamchatka Territories, Amur, Sakhalin and Magadan regions, the Republic of Sakha and Chukotka.\n\nToday PSMU - is a various scientific and educational institution that includes 10 faculties and 67 departments, employing 85 doctors and 285 candidates of science. The university held an internship, residency, graduate school, the system of pre-university training and post-graduate special education improving system, that make possible to obtain any medical profession. Sufficiently extensive links established with the universities of China, Japan, South Korea and the U.S.A., allow to take preparing courses for students and teachers that enrich the learning process and intensify the research activities of the university.\n\n\n"}
