{"id": "18401212", "url": "https://en.wikipedia.org/wiki?curid=18401212", "title": "7,12-Dimethylbenz(a)anthracene", "text": "7,12-Dimethylbenz(a)anthracene\n\n7,12-Dimethylbenz[\"a\"]anthracene (DMBA) is an immunosuppressor and a powerful organ-specific laboratory carcinogen. DMBA is widely used in many research laboratories studying cancer. DMBA serves as a tumor initiator. Tumor promotion can be induced with treatments of 12-\"O\"-tetradecanoylphorbol-13-acetate (TPA) in some models of two-stage carcinogenesis. This allows for a greatly accelerated rate of tumor growth, making many cancer studies possible.\n"}
{"id": "39702905", "url": "https://en.wikipedia.org/wiki?curid=39702905", "title": "Abortion in Latvia", "text": "Abortion in Latvia\n\nAbortion in Latvia is legal and is available on request within the first 12 weeks of pregnancy; and for medical reasons until 22 weeks. While Latvia was a republic of the Soviet Union, abortions were regulated by the Government of the Soviet Union. The Government of Latvia has a \"surveillance system\" which allows it to collect information on the numbers of abortions performed.\n\nFrom 21 July 1940, Latvia was known as the Latvian Soviet Socialist Republic and followed the abortion laws of the Soviet Union (USSR). On 27 June 1936, the USSR banned abortions unless there was a danger to the life of the mother or the child would inherit a serious disease from the parents. Under this law, abortions were meant to be performed in maternity homes and hospitals, and physicians who disregarded this risked one to two years' imprisonment.\n\nOn 23 November 1955, the Government of the Soviet Union issued a decree which allowed abortions to be available on request. Later that year, abortion was restricted so that it could only be performed in the first three months of pregnancy, unless the birth would endanger the mother. Physicians had to perform abortions in hospitals, and unless the mother was in danger, a fee was charged. If the abortion was not performed in a hospital, the physician would be imprisoned for one year. If the person who performed the abortion did not have a medical degree, then they would be imprisoned for two years. If serious injuries or death were caused to a pregnant woman, there would be up to eight years of imprisonment.\n\nThe Government of the USSR was concerned about the rate of illegal abortions, and attempted to decrease their occurrence. On 31 December 1987, the Soviet Union announced that it would permit many medical institutions to perform abortions until the twenty-eighth week of pregnancy. Abortions occurred more frequently and in 1996, 44.1 abortions per 1,000 births occurred in Latvia.\n\nThe Fertility and Family Survey in 1995 found that 30% of women at age 25 had had an abortion. Due to the high abortion rate, Latvia's government is encouraging more births. As of 2013, an abortion can be performed without request up to the twelfth week of pregnancy, and can be requested up to the twenty-eighth.\n\nA campaign named \"For Life\" (\"Par dzīvību\" in Latvian) has been set up to reduce the number of abortions in Latvia. In 1991, there were 34,633 births and 44,886 abortions, but this number has been falling since 1999. In 2011, around 7,000 abortions were performed.\n\n, the abortion rate was 15.6 abortions per 1,000 women aged 15 to 44 years.\n\nMifepristone (medical abortion) was registered in 2002.\n\n"}
{"id": "49373614", "url": "https://en.wikipedia.org/wiki?curid=49373614", "title": "Aisha Abubakar Abdulwahab", "text": "Aisha Abubakar Abdulwahab\n\nDr. Aisha Abubakar Abdulwahab (born c.1971) was a Nigeria policewoman who won a UNESCO fellowship award to study tuberculosis.\n\nAisha Abubakar Abdulwahab was born in c.1971 and she joined the Nigerian police force in 1995. She has a degree in veterinary science and a doctorate.\n\nIn 2005 she won a UNESCO fellow award for her proposal to use DNA to identify the link between human and bovine tuberculosis. By taking samples from cows and people she could evaluate the risk that Nigerians made when they drank unpasteurized milk. The award was to enable her to complete the research at any university. Adbulwahab was married with two children.\n"}
{"id": "12503398", "url": "https://en.wikipedia.org/wiki?curid=12503398", "title": "Alcoholic cardiomyopathy", "text": "Alcoholic cardiomyopathy\n\nAlcoholic cardiomyopathy is a disease in which the chronic long-term abuse of alcohol (i.e., ethanol) leads to heart failure. Alcoholic cardiomyopathy is a type of dilated cardiomyopathy. Due to the direct toxic effects of alcohol on heart muscle, the heart is unable to pump blood efficiently, leading to heart failure. It can affect other parts of the body if the heart failure is severe. It is most common in males between the ages of 35–50.\n\nSigns and symptoms presented by the occurrence of alcoholic cardiomyopathy are the result of the heart failing and usually occur after the disease has progressed to an advanced stage. Therefore, the symptoms have a lot in common with other forms of cardiomyopathy. These symptoms can include the following:\n\n\nAbnormal heart sounds, murmurs, ECG abnormalities, and enlarged heart on chest x-ray may lead to the diagnosis. Echocardiogram abnormalities and cardiac catheterization or angiogram to rule out coronary artery blockages, along with a history of alcohol abuse can confirm the diagnosis.\n\nTreatment for alcoholic cardiomyopathy involves lifestyle changes, including complete abstinence from alcohol use, a low sodium diet, and fluid restriction, as well as medications. Medications may include ACE inhibitors, beta blockers, and diuretics which are commonly used in other forms of cardiomyopathy to reduce the strain on the heart. Persons with congestive heart failure may be considered for surgical insertion of an ICD or a pacemaker which can improve heart function. In cases where the heart failure is irreversible and worsening, heart transplant may be considered.\n\nTreatment will possibly prevent the heart from further deterioration, and the cardiomyopathy is largely reversible if complete abstinence from alcohol is maintained.\n"}
{"id": "23591127", "url": "https://en.wikipedia.org/wiki?curid=23591127", "title": "British Geriatrics Society", "text": "British Geriatrics Society\n\nThe British Geriatrics Society (BGS) is the professional body of specialists in the health care of older people in the United Kingdom. Membership is drawn from doctors, nurses, allied health professionals, scientists and others practicing geriatric medicine and with a particular interest in the care of older people and the promotion of better health in old age. It has over 3000 members worldwide and is the only society in the UK which draws together experts from all the relevant disciplines in the field. The current president is Dr Eileen Burns.\n\nThe Society was founded in 1947 for “the relief of suffering and distress amongst the aged and infirm by the improvement of standards of medical care for such persons, the holding of meetings and the publication and distribution of the results of such research”.\n\nThe BGS achieves these purposes by holding scientific meetings, producing clinical guidance, sharing best practice and acting as an ‘expert voice’ on the care of older people and promoting better health in older age. Members lead several national clinical audits in collaboration with other professional bodies such as Royal Colleges, and specialist clinical associations organizations. \n\n\"Age and Ageing\", which is published by Oxford University Press, is the official journal of the British Geriatrics Society, publishing refereed original articles and commissioned reviews on geriatric medicine and gerontology. Its range includes research on ageing and the clinical, epidemiological and psychological aspects of later life. Its impact factor of 3.816 is among the highest in the field of clinical ageing.\n\n"}
{"id": "54516494", "url": "https://en.wikipedia.org/wiki?curid=54516494", "title": "Cancer in the United Kingdom", "text": "Cancer in the United Kingdom\n\nThe passing of the Cancer Act 1939 marked the political significance of cancer treatment. It envisaged a system of co-ordination of diagnosis and treatment under the control of County Councils and County Borough Councils which preceded the establishment of the NHS. The outbreak of war prevented most of its provisions from coming into effect.\n\nThere were 361,216 cancer diagnoses in 2014 in the United Kingdom.\nCancer Research UK publishes detailed statistics of the incidence of and mortality from cancer in the UK. Three quarters of cancers were related to smoking and drinking.\n\nTreatment of cancer has been a recurring issue in the National Health Service. Official guidelines state that no one in England should have to wait more than 62 days for cancer treatment after a referral from their general practitioner. However, press reports in 2015 indicated that some patients had to wait longer. On 4 September 2015, the NHS announced it would no longer pay for 17 different cancer medications. The Telegraph reported that over 5,000 patients with breast, bowel, skin, and pancreatic cancers would be affected.\n\nA five-year Cancer Strategy Implementation Plan was published by NHS England in 2015. It promises considerable investment in linear accelerators There have been some improvements in cancer care but too many patients are waiting too long for diagnosis and treatment. Sir Harpal Kumar criticised the government's child obesity strategy. He said the report was not tough enough on the food industry, given the number of cancers which are linked to lifestyle. The increased investment does not appear to be sufficient to meet the rise in the number of cancer patients, and there are shortages of radiologists, specialist nurses and other key staff.\n\nNational cancer waiting times standards were established by NHS England in 2009 (and the same targets have been set by NHS Scotland).\nIn 2017 the targets are\nThe targets are monitored monthly and in the period from 2014 to 2016 were only met in 4 months out of 36.\n\nSara Hiom of Cancer Research UK said, ‘The state of NHS diagnostic services is deeply concerning – and new GP referral guidelines from NICE mean that even more patients will be waiting for these tests. There aren’t enough trained staff, they’re often reliant on outdated equipment and in many cases they’re already operating services seven days a week.' Dr Giles Maskell of the Royal College of Radiologists said, ‘Well-resourced testing services are crucial to the early diagnosis of cancer, which in turn is vital to increase survival from the disease.' Cancer Research UK is calling on the government to provide funding for earlier diagnosis of cancer as prompt diagnosis increases the chances the patient will survive.\n\nMany physicians in the United Kingdom are at least tolerant of alternative treatments and some might recommend them.\n\n"}
{"id": "13778447", "url": "https://en.wikipedia.org/wiki?curid=13778447", "title": "Capital punishment in Bosnia and Herzegovina", "text": "Capital punishment in Bosnia and Herzegovina\n\nCapital punishment in Bosnia and Herzegovina was abolished \"de-facto\" for all crimes in November 1998 in the Federation of Bosnia and Herzegovina (last execution though to be carried there out in 1977 for murder) and on in the Republika Srpska. The death penalty still remains present in statutes, specifically in Article 11 of Republika Srpska, but the current constitution forbids it from being carried out.\n\nSource: SPSK Database\n\n"}
{"id": "3626922", "url": "https://en.wikipedia.org/wiki?curid=3626922", "title": "Clinical Data Interchange Standards Consortium", "text": "Clinical Data Interchange Standards Consortium\n\nThe Clinical Data Interchange Standards Consortium (CDISC) is an open, multidisciplinary, neutral, 501(c)(3) non-profit standards developing organization (SDO) that has been working through productive, consensus-based collaborative teams, since its formation in 1997, to develop global standards and innovations to streamline medical research and ensure a link with healthcare. The CDISC mission is \"to develop and support global, platform-independent data standards that enable information system interoperability to improve medical research and related areas of healthcare\". The CDISC Vision is \"informing patient care and safety through higher quality medical research\". The CDISC suite of standards supports medical research of any type from protocol through analysis and reporting of results. They have been shown to decrease resources needed by 60% overall and 70–90% in the start-up stages when they are implemented at the beginning of the research process.\n\nThey are harmonized through a model that is now not only a CDISC standard but also an HL7 standard on the path to becoming an ISO/CEN standard, thus giving the CDISC standards (harmonized together through BRIDG) international status and accreditation.\n\n\n\nThe CDISC Operational Data Model (ODM) is designed to facilitate the regulatory-compliant acquisition, archive and interchange of metadata and data for clinical research studies. ODM is a vendor-neutral, platform-independent format for interchange and archive of clinical study data. The model includes the clinical data along with its associated metadata, administrative data, reference data and audit information. \nODM was first introduced in 1999, and the latest version, 1.3.2, was released in 2012. ODM extensions have been developed to create a number of additional CDISC standards, including Define-XML, Dataset-XML, SDM-XML, and CTR-XML and future planned standard Protocol-XML.\n\nODM is an XML based standard and it is an XML schema that provides number of constructs for modeling electronic Case Report Forms (CRFs). ODM is often combined with Study Data Model standard to more fully model trial arms or trial activities. ODM is also used in sending forms data from a clinical trial system to an electronic health record (EHR) system.\n\nDefine-XML supports the interchange of dataset metadata for clinical research applications in a machine-readable format. An important use case for Define-XML is to support the submission of clinical trials data in CDISC SDTM, SEND or ADaM format to regulatory authorities. The key metadata components to support submissions are:\n\nDefine-XML can also be used to describe proprietary, non-CDISC dataset structures. The Define-XML model is implemented using extensions to the CDISC Operational Data Model (ODM) XML schema. The current version is 2.0 published on the CDISC web site.\n\nClinical Trial Representation allows representing basic characterstic of a clinical trial, such as study sponsor, study name, size of the trial (number of participants). The standard was first introduced in 2016.\n\nCDISC BRIDG model is a unifying model of the domain of clinical research and research studies. It defines basic elements such as investigator, subject, study, intervention. It is used to keep all standards consistent. It was first introduced in 2006 with version 2 released in 2008. It can be obtained as UML model as well as .OWL format.\n\nCDISC SHARE (Shared Health and Clinical Research Electronic Library) is a metadata repository that supports the development, governance, publishing, and consumption of CDISC standards in human and machine-readable formats. SHARE helps users find, understand, and use rich metadata (i.e., research concepts, data elements and attributes, relationship among data elements, properties in relationship, and controlled terminologies) relevant to clinical studies more efficiently and consistently. With all these information in a single repository, SHARE will improve integration and traceability of clinical data end-to-end, from protocol through analysis. SHARE will provide a collaborative standards development environment that will improve quality, integration, and consistency across CDISC standards.\n\nCDISC maintains a list of solutions providers, subject matter experts and consultants deemed to have sufficient knowledge and experience implementing the various CDISC standards.\n\nElectronic data capture (EDC) systems can be certified as compliant with the Operational Data Model (ODM) by CDISC. There are two main types of integration, ODM Import and ODM Export.\n\nFull import allows importing of ODM-formatted clinical data (MetaData and Data).\nMetaData only import allows only the importing of MetaData. This is useful for setting up the EDC system to capture data. Basically allows third party software to define the forms, variables etc. used in the EDC system. This provides an EDC vendor-neutral system for defining a study.\n\nThe EDC system will generate ODM data files for further processing. For example, REDCap data capture system allows export of a study in ODM.\n\n"}
{"id": "2368154", "url": "https://en.wikipedia.org/wiki?curid=2368154", "title": "Clinical decision support system", "text": "Clinical decision support system\n\nA clinical decision support system (CDSS) is a health information technology system that is designed to provide physicians and other health professionals with clinical decision support (CDS), that is, assistance with clinical decision-making tasks. A working definition has been proposed by Robert Hayward of the Centre for Health Evidence: \"Clinical decision support systems link health observations with health knowledge to influence health choices by clinicians for improved health care\". CDSSs constitute a major topic in artificial intelligence in medicine.\n\nThe evidence of the effectiveness of CDSS is mixed. A 2014 systematic review did not find a benefit in terms of risk of death when the CDSS was combined with the electronic health record. There may be some benefits, however, in terms of other outcomes.\n\nA 2005 systematic review concluded that CDSSs improved practitioner performance in 64% of the studies. The CDSSs improved patient outcomes in 13% of the studies. Sustainable CDSSs features associated with improved practitioner performance include the following:\nBoth the number and the methodological quality of studies of CDSSs increased from 1973 through 2004.\n\nAnother 2005 systematic review found... \"Decision support systems significantly improved clinical practice in 68% of trials.\" The CDSS features associated with success include the following:\n\nHowever, other systematic reviews are less optimistic about the effects of CDS, with one from 2011 stating \"There is a large gap between the postulated and empirically demonstrated benefits of [CDSS and other] eHealth technologies ... their cost-effectiveness has yet to be demonstrated\".\n\nA 5-year evaluation of the effectiveness of a CDSS in implementing rational treatment of bacterial infections was published in 2014; according to the authors, it was the first long term study of a CDSS.\n\nA clinical decision support system has been defined as an \"active knowledge systems, which use two or more items of patient data to generate case-specific advice.\" This implies that a CDSS is simply a decision support system that is focused on using knowledge management in such a way so as to achieve clinical advice for patient care based on multiple items of patient data.\n\nThe main purpose of modern CDSS is to assist clinicians at the point of care. This means that clinicians interact with a CDSS to help to analyse, and reach a diagnosis based on, patient data.\n\nIn the early days, CDSSs were conceived of as being used to literally make decisions for the clinician. The clinician would input the information and wait for the CDSS to output the \"right\" choice and the clinician would simply act on that output. However, the modern methodology of using CDSSs to assist means that the clinician interacts with the CDSS, utilizing both their own knowledge and the CDSS, to make a better analysis of the patient's data than either human or CDSS could make on their own. Typically, a CDSS makes suggestions for the clinician to look through, and the clinician is expected to pick out useful information from the presented results and discount erroneous CDSS suggestions.\n\nThere are two main types of CDSS:\nas detailed below.\n\nAn example of how a clinical decision support system might be used by a clinician is a specific type of CDSS, a DDSS (diagnosis decision support systems). A DDSS requests some of the patients data and in response, proposes a set of appropriate diagnoses. The doctor then takes the output of the DDSS and determines which diagnoses might be relevant and which are not, and if necessary orders further tests to narrow down the diagnosis.\n\nAnother example of a CDSS would be a case-based reasoning (CBR) system. A CBR system might use previous case data to help determine the appropriate amount of beams and the optimal beam angles for use in radiotherapy for brain cancer patients; medical physicists and oncologists would then review the recommended treatment plan to determine its viability.\n\nAnother important classification of a CDSS is based on the timing of its use. Doctors use these systems at point of care to help them as they are dealing with a patient, with the timing of use being either pre-diagnosis, during diagnosis, or post diagnosis. Pre-diagnosis CDSS systems are used to help the physician prepare the diagnoses. CDSS used during diagnosis help review and filter the physician's preliminary diagnostic choices to improve their final results. Post-diagnosis CDSS systems are used to mine data to derive connections between patients and their past medical history and clinical research to predict future events. It has been claimed that decision support will begin to replace clinicians in common tasks in the future.\n\nAnother approach, used by the National Health Service in England, is to use a DDSS (either, in the past, operated by the patient, or, today, by a phone operative who is not medically-trained) to triage medical conditions out of hours by suggesting a suitable next step to the patient (e.g. call an ambulance, or see a general practitioner on the next working day). The suggestion, which may be disregarded by either the patient or the phone operative if common sense or caution suggests otherwise, is based on the known information and an implicit conclusion about what the \"worst-case\" diagnosis is likely to be (which is not always revealed to the patient, because it might well be incorrect and is not based on a medically-trained person's opinion - it is only used for initial triage purposes).\n\nMost CDSSs consist of three parts: the knowledge base, an inference engine, and a mechanism to communicate. The knowledge base contains the rules and associations of compiled data which most often take the form of IF-THEN rules. If this was a system for determining drug interactions, then a rule might be that IF drug X is taken AND drug Y is taken THEN alert user. Using another interface, an advanced user could edit the knowledge base to keep it up to date with new drugs. The inference engine combines the rules from the knowledge base with the patient's data. The communication mechanism allows the system to show the results to the user as well as have input into the system.\n\nCDSSs that do not use a knowledge base use a form of artificial intelligence called machine learning, which allow computers to learn from past experiences and/or find patterns in clinical data. This eliminates the need for writing rules and for expert input. However, since systems based on machine learning cannot \"explain\" the reasons for their conclusions (they are so-called \"black boxes\", because no meaningful information about how they work can be discerned by human inspection), most clinicians do not use them directly for diagnoses, for reliability and accountability reasons. Nevertheless, they can be useful as post-diagnostic systems, for suggesting patterns for clinicians to look into in more depth.\n\nThree types of non-knowledge-based systems are support vector machines, artificial neural networks and genetic algorithms.\n\n\nWith the enactment of the American Recovery and Reinvestment Act of 2009 (ARRA), there is a push for widespread adoption of health information technology through the Health Information Technology for Economic and Clinical Health Act (HITECH). Through these initiatives, more hospitals and clinics are integrating electronic medical records (EMRs) and computerized physician order entry (CPOE) within their health information processing and storage. Consequently, the Institute of Medicine (IOM) promoted usage of health information technology including clinical decision support systems to advance quality of patient care. The IOM had published a report in 1999, \"To Err is Human\", which focused on the patient safety crisis in the United States, pointing to the incredibly high number of deaths. This statistic attracted great attention to the quality of patient care.\n\nWith the enactment of the HITECH Act included in the ARRA, encouraging the adoption of health IT, more detailed case laws for CDSS and EMRs are still being defined by the Office of National Coordinator for Health Information Technology (ONC) and approved by Department of Health and Human Services (HHS). A definition of \"Meaningful use\" is yet to be published.\n\nDespite the absence of laws, the CDSS vendors would almost certainly be viewed as having a legal duty of care to both the patients who may adversely be affected due to CDSS usage and the clinicians who may use the technology for patient care. However, duties of care legal regulations are not explicitly defined yet.\n\nWith recent effective legislations related to performance shift payment incentives, CDSS are becoming more attractive.\n\nMuch effort has been put forth by many medical institutions and software companies to produce viable CDSSs to support all aspects of clinical tasks. However, with the complexity of clinical workflows and the demands on staff time high, care must be taken by the institution deploying the support system to ensure that the system becomes a fluid and integral part of the clinical workflow. Some CDSSs have met with varying amounts of success, while others have suffered from common problems preventing or reducing successful adoption and acceptance.\n\nTwo sectors of the healthcare domain in which CDSSs have had a large impact are the pharmacy and billing sectors. There are commonly used pharmacy and prescription ordering systems that now perform batch-based checking of orders for negative drug interactions and report warnings to the ordering professional. Another sector of success for CDSS is in billing and claims filing. Since many hospitals rely on Medicare reimbursements to stay in operation, systems have been created to help examine both a proposed treatment plan and the current rules of Medicare in order to suggest a plan that attempts to address both the care of the patient and the financial needs of the institution.\n\nOther CDSSs that are aimed at diagnostic tasks have found success, but are often very limited in deployment and scope. The Leeds Abdominal Pain System went operational in 1971 for the University of Leeds hospital, and was reported to have produced a correct diagnosis in 91.8% of cases, compared to the clinicians' success rate of 79.6%.\n\nDespite the wide range of efforts by institutions to produce and use these systems, widespread adoption and acceptance has still not yet been achieved for most offerings. One large roadblock to acceptance has historically been workflow integration. A tendency to focus only on the functional decision making core of the CDSS existed, causing a deficiency in planning for how the clinician will actually use the product in situ. Often CDSSs were stand-alone applications, requiring the clinician to cease working on their current system, switch to the CDSS, input the necessary data (even if it had already been inputted into another system), and examine the results produced. The additional steps break the flow from the clinician's perspective and cost precious time.\n\nClinical decision support systems face steep technical challenges in a number of areas. Biological systems are profoundly complicated, and a clinical decision may utilize an enormous range of potentially relevant data. For example, an electronic evidence-based medicine system may potentially consider a patient's symptoms, medical history, family history and genetics, as well as historical and geographical trends of disease occurrence, and published clinical data on medicinal effectiveness when recommending a patient's course of treatment.\n\nClinically, a large deterrent to CDSS acceptance is workflow integration, as mentioned above.\n\nAnother source of contention with many medical support systems is that they produce a massive number of alerts. When systems produce high volume of warnings (especially those that do not require escalation), aside from the annoyance, clinicians may pay less attention to warnings, causing potentially critical alerts to be missed.\n\nOne of the core challenges facing CDSS is difficulty in incorporating the extensive quantity of clinical research being published on an ongoing basis. In a given year, tens of thousands of clinical trials are published. Currently, each one of these studies must be manually read, evaluated for scientific legitimacy, and incorporated into the CDSS in an accurate way. In 2004, it was stated that the process of gathering clinical data and medical knowledge and putting them into a form that computers can manipulate to assist in clinical decision-support is \"still in its infancy\".\n\nNevertheless, it is more feasible for a business to do this centrally, even if incompletely, than for each individual doctor to try to keep up with all the research being published.\n\nIn addition to being laborious, integration of new data can sometimes be difficult to quantify or incorporate into the existing decision support schema, particularly in instances where different clinical papers may appear conflicting. Properly resolving these sorts of discrepancies is often the subject of clinical papers itself (see meta-analysis), which often take months to complete.\n\nIn order for a CDSS to offer value, it must demonstrably improve clinical workflow or outcome. Evaluation of CDSS is the process of quantifying its value to improve a system's quality and measure its effectiveness. Because different CDSSs serve different purposes, there is no generic metric which applies to all such systems; however, attributes such as consistency (with itself, and with experts) often apply across a wide spectrum of systems.\n\nThe evaluation benchmark for a CDSS depends on the system's goal: for example, a diagnostic decision support system may be rated based upon the consistency and accuracy of its classification of disease (as compared to physicians or other decision support systems). An evidence-based medicine system might be rated based upon a high incidence of patient improvement, or higher financial reimbursement for care providers.\n\nImplementing electronic health records (EHR) was an inevitable challenge. The reasons behind this challenge are that it is a relatively uncharted area, and there are many issues and complications during the implementation phase of an EHR. This can be seen in the numerous studies that have been undertaken. However, challenges in implementing electronic health records (EHRs) have received some attention, but less is known about the process of transitioning from legacy EHRs to newer systems.\n\nWith all of that said, electronic health records are the way of the future for healthcare industry. They are a way to capture and utilise real-time data to provide high-quality patient care, ensuring efficiency and effective use of time and resources. Incorporating EHR and CDSS together into the process of medicine has the potential to change the way medicine has been taught and practiced. It has been said that \"the highest level of EHR is a CDSS\".\n\nSince \"clinical decision support systems (CDSS) are computer systems designed to impact clinician decision making about individual patients at the point in time that these decisions are made\", it is clear that it would be beneficial to have a fully integrated CDSS and EHR.\n\nEven though the benefits can be seen, to fully implement a CDSS that is integrated with an EHR has historically required significant planning by the healthcare facility/organisation, in order for the purpose of the CDSS to be successful and effective. \nThe success and effectiveness can be measured by the increase in patient care being delivered and reduced adverse events occurring. In addition to this, there would be a saving of time and resources, and benefits in terms of autonomy and financial benefits to the healthcare facility/organisation.\n\nA successful CDSS/EHR integration will allow the provision of best practice, high quality care to the patient, which is the ultimate goal of healthcare.\n\nErrors have always occurred in healthcare, so trying to minimise them as much as possible is important in order to provide quality patient care. Three areas that can be addressed with the implementation of CDSS and Electronic Health Records (EHRs), are:\nCDSSs will be most beneficial in the future when healthcare facilities are \"100% electronic\" in terms of real-time patient information, thus simplifying the number of modifications that have to occur to ensure that all the systems are up to date with each other.\n\nThe measurable benefits of clinical decision support systems on physician performance and patient outcomes remain the subject of ongoing research, as noted in the section above.\n\nImplementing electronic health records (EHR) in healthcare settings incurs challenges; none more important than maintaining efficiency and safety during rollout, but in order for the implementation process to be effective, an understanding of the EHR users' perspectives is key to the success of EHR implementation projects. In addition to this, adoption needs to be actively fostered through a bottom-up, clinical-needs-first approach. The same can be said for CDSS.\n\nThe main areas of concern with moving into a fully integrated EHR/CDSS system are:\n\n\nas well as the key aspects of data entry that need to be addressed when implementing a CDSS to avoid potential adverse events from occurring. These aspects include whether:\nA service oriented architecture has been proposed as a technical means to address some of these barriers.\n\nAs of July 2015, the planned transition to EHRs in Australia is facing difficulties. The majority of healthcare facilities are still running completely paper-based systems, and some are in a transition phase of scanned EHRs, or are moving towards such a transition phase.\n\nVictoria has attempted to implement EHR across the state with its HealthSMART program, but due to unexpectedly high costs it has cancelled the project.\n\nSouth Australia (SA) however is slightly more successful than Victoria in the implementation of an EHR. This may be due to all public healthcare organisations in SA being centrally run. (However, on the other hand, the UK's National Health Service is also centrally administered, and its National Programme for IT in the 2000s, which included EHRs in its remit, was an expensive disaster.)\n\nSA is in the process of implementing \"Enterprise patient administration system (EPAS)\". This system is the foundation for all public hospitals and health care sites for an EHR within SA and it was expected that by the end of 2014 all facilities in SA will be connected to it. This would allow for successful integration of CDSS into SA and increase the benefits of the EHR.\nBy July 2015 it was reported that only 3 out of 75 health care facilities implemented EPAS.\n\nWith the largest health system in the country and a federated rather than centrally administered model, New South Wales is making consistent progress towards statewide implementation of EHRs. The current iteration of the state's technology, eMR2, includes CDSS features such as a sepsis pathway for identifying at-risk patients based upon data input to the electronic record. As of June 2016, 93 of 194 sites in-scope for the initial roll-out had implemented eMR2\n\n\n"}
{"id": "2939687", "url": "https://en.wikipedia.org/wiki?curid=2939687", "title": "Council for International Organizations of Medical Sciences", "text": "Council for International Organizations of Medical Sciences\n\nThe Council for International Organizations of Medical Sciences (CIOMS) is an international nongovernmental organization established jointly by WHO and UNESCO in 1949. CIOMS represents a substantial proportion of the biomedical scientific community through its member organizations. The mission of CIOMS is to advance public health through guidance on health research including ethics, medical product development and safety.\n\n\n\n\n1949: The \"Council for Coordination of International Medical Congresses\" was formally constituted at a jointly-sponsored conference in Brussels. The Council’s original objective was to coordinate and support the work of international organizations of medical sciences through information exchange and financial assistance to organizers of congresses and to the individuals attending them. The scope of activities was gradually broadened to include other forms of international collaboration in medical sciences.<br>\n\n1952: The name of the Council was changed to Council for International Organisations of Medical Sciences (CIOMS), and its statutes were revised.<br>\n\n1959: CIOMS organised a meeting in Vienna under the joint auspices of UNESCO and WHO, “to discuss the principles, organization and scope of “controlled clinical trials”, which must be carried out if new methods or preparations used for the treatment of disease are to be accurately assessed clinically”. This meeting was a methodological landmark in clinical research.<br>\n1966: CIOMS reduced its financial assistance towards congresses on purely scientific medical subjects, as it was felt that this was an unnecessary duplication of the large number of scientific meetings being held. <br>\n\nIn the years that followed, CIOMS changed its main activities to address some of the social and cultural implications resulting from the rapid progress in biomedical science and the emergence of a new world order with a large number of newly-independent countries. CIOMS started to convene multi-disciplinary international conferences concerned with bioethics, health policy, medical education and health services research. \nOver the next 20 years these working modalities evolved and gradually led to convening specialized international Working Groups with the aim of publishing well balanced reports on topics related to research ethics, drug development and safe use of medicines.<br>\n\n2016: CIOMS joined the International Council for Harmonisation of Technical Requirements for Pharmaceuticals for Human Use (ICH) as an observer. \n\nThe \"International Ethical Guidelines for Biomedical Research Involving Human Subjects\", sometimes informally referred to as\n\"CIOMS Guidelines\", is a set of ethical principles regarding human experimentation created in 1993 by CIOMS and updated in 2002. These 21 guidelines (15 in the original report) address issues including Informed consent, standards for external review, recruitment of participants, and more. The Guidelines are general instructions and principles of ethical biomedical research.. \nIn 2016 new CIOMS ethical Guidelines titled \"International ethical guidelines for health-related research involving humans\" were published. These guidelines were prepared in collaboration with WHO and address additional topics. They stress the need for research that has scientific and social value, provide special guidance for health-related research in low-resource settings, detail the provisions for involving vulnerable groups in research, and describe under what conditions biological samples and health-related data can be used for research.\n\nThe first systematic international efforts to address medicines safety issues started after 1961, when thalidomide, a medication given to pregnant women to alleviate nausea, led to many thousands of infants being born with deformities. It is not an exaggeration to say that CIOMS guidelines have formed the basis of modern pharmacovigilance, and several CIOMS guidelines were the basis of creating respective ICH guidelines. Some examples: <br>\n\n\"ICH-E2A (1994): Clinical Safety Data Management – Definitions and Standards for Expedited Reporting\" was based on the reports of CIOMS Working Groups (WG) I and II for marketed medicinal products (published 1990 and 1992). <br>\n\n\"ICH-E2C (1996):’Clinical Safety Data Management – Periodic Benefit-Risk Evaluation Reports\" described the specifications for format and content of periodic safety update reports (PSURs) and was based on the reports of CIOMS WG II and III (published in 1992, 1995). <br>\n\n\"ICH-E2D (2003): Post-Approval Safety Management – Definitions and Standards for Expedited reporting\" formalized the application of relevant elements of ‘’ICH-E2A’’ in the post-authorization phase and was based on the reports of CIOMS WG V (2001). <br>\n\n\"ICH-E2F (2010): Development Safety Update Reports\" was based on the report of CIOMS WG VIII (published 2006) and describes the specifications for format and content of development safety update reports (DSURs).<br>\n\nMore recently, the CIOMS Working Group on Vaccine Safety has completed published guidance on safety surveillance for new vaccines, especially those introduced early or exclusively to countries with limited pharmacovigilance experience and infrastructure, and on how to communicate information around vaccine safety issues to the public. \n\nThe Council has also issued \"International Guiding Principles for Biomedical Research Involving Animals\".\n\n\n"}
{"id": "982883", "url": "https://en.wikipedia.org/wiki?curid=982883", "title": "Dental surgery", "text": "Dental surgery\n\nDental surgery is any of a number of medical procedures that involve artificially modifying dentition; in other words, surgery of the teeth and jaw bones.\n\nSome of the more common are:\n\n\nMore frequent than usual cleaning and examination may be necessary during the treatment of many different dental/oral disorders or due to recent surgical procedures such as dental implants. The American Dental Association (ADA) stresses that the frequency of dental visits necessary is dependent upon the needs of each individual with some able to go once or twice a year and others needing to go more often. This may include yearly, select dental X-rays. See also dental plaque identification procedure and removal.\n\nDentists inject anesthetic to block sensory transmission by the alveolar nerves. The superior alveolar nerves are not usually anesthetized directly because they are difficult to approach with a needle. For this reason, the maxillary teeth are usually anesthetized locally by inserting the needle beneath the oral mucosa surrounding the teeth. The inferior alveolar nerve is probably anesthetized more often than any other nerve in the body. To anesthetize this nerve, the dentist inserts the needle somewhat posterior to the patient’s last molar.\n"}
{"id": "24546490", "url": "https://en.wikipedia.org/wiki?curid=24546490", "title": "Facultative lagoon", "text": "Facultative lagoon\n\nFacultative lagoons are a type of waste stabilization pond used for biological treatment of industrial and domestic wastewater. Sewage or organic waste from food or fiber processing may be catabolized in a system of constructed ponds where adequate space is available to provide an average waste retention time exceeding a month. A series of ponds prevents mixing of untreated waste with treated wastewater and allows better control of waste residence time for uniform treatment efficiency.\n\nThe facultative lagoon in the pond sequence functions like the primary clarifier of a conventional sewage treatment system. Heavy solids will settle to the bottom of the lagoon, and lighter solids will float. This facultative lagoon lacks the sludge removal capability of a primary clarifier, so a population of anaerobic organisms will colonize accumulated sludge on the bottom of the lagoon. The surface area of the lagoon should be large enough to provide an atmospheric oxygen transfer rate adequate to prevent anaerobic conditions on the lagoon surface. Intermediate depths of the lagoon support facultative micro-organisms capable of oxidizing both the dissolved and suspended organics from the original wastewater and the products of anaerobic catabolism on the bottom of the lagoon.\n\nAreas with a consistently cool, but frost-free, climate may sustain facultative conditions in the first stabilization pond when treating lightly polluted water at low temperatures favorable to high concentrations of dissolved oxygen with low metabolic rates. Facultative pond stratification becomes unstable during cold weather increasing release of malodorous gas when water temperatures drop below 4 degrees Celsius (39 degrees Fahrenheit); and formation of ice on the pond surface will effectively prevent transfer of atmospheric oxygen to the pond biome. Stabilization ponds in climates with significant seasonal temperature variation may release malodorous gas during the season of rising temperatures as the pond biome consumes wastes accumulated during cold weather with increasing metabolic rates exceeding the atmospheric oxygen transfer rate at the pond surface.\n\nOverflow from the facultative lagoon may be routed through one or more polishing ponds supporting lower populations of anaerobic micro-organisms and a higher proportion of aerobic organisms adapted to survival in lower concentrations of organic material. Effluent from the final polishing pond may be suitable for discharge to natural receiving waters.\n\nObjectionable odors are likely when the rate of oxygen transfer from the lagoon surface is less than the rate of oxygen consumption in the lower levels of the lagoon. A facultative lagoon might provide 50 pounds of oxygen per day (5 grams of oxygen per square meter per day) for biochemical catabolism. Biological activity within a facultative lagoon varies directly with temperature. Warm weather will require large oxygen transfer rates, and waste accumulation during cold weather can cause short-term warm weather oxygen requirements to exceed long-term waste loading rates. Algae can provide surface oxygen during daylight hours, but algal respiration can require additional oxygen during darkness. Ice or scum mats can reduce the oxygen transfer surface. Some facultative lagoons use mechanical surface aerators to increase atmospheric oxygen transfer, but aerator mixing depth should not re-suspend anaerobic sludge from the bottom of the lagoon. Aerator operation may be limited to periods of heavy waste loads, high temperatures, darkness, low wind velocity, or other conditions threatening to cause anaerobic conditions on the lagoon surface.\n\nFacultative stabilization ponds stratify with an aerobic surface layer and an anaerobic layer below the surface. The aerobic surface layer limits release of malodorous gas from the anaerobic benthic zone. Algae and cyanobacteria typically grow in the aerobic zone and provide bacteria in the pond with plenty of oxygen during the daytime. However, algal photorespiration may consume oxygen during night time when it is dark. Waste tabilization ponds with large algal populations may show significant diurnal fluctuation in oxygen concentrations with a peak in the late afternoon, and a minimum at dawn. \n\nKinds of algae growing in treatment ponds include green, red and brown algae.the environment.\n\nVertical stratification including an aerobic surface layer, an anaerobic bottom layer, and a facultative intermediate layer is essential to proper functioning of a facultative lagoon ecosystem. Stratification is maintained by a thermal gradient of cool, dense water at the bottom of the lagoon overlain by warmer, less dense water on the surface. This thermal gradient becomes unstable when water reaches its maximum density at 4 degrees Celsius (39 degrees Fahrenheit). Facultative lagoons are impractical in cold climates, because the lagoons become non-functional when cooler air temperatures depress water temperatures below this critical value.\n\nInert solids in wastewater will accumulate on the bottom of the lagoon and gradually reduce depth until there is inadequate room for the facultative zone. Lagoon depths between 2 and 5 feet (60 to 150 cm) are preferred for effective treatment. Parallel facultative lagoons with common polishing ponds allow wastewater treatment to continue while one lagoon is out of service for sludge removal.\n\nPrecipitation falling on the surface of the lagoons and polishing ponds will increase the volume of wastewater requiring disposal. Conversely, the volume of wastewater may be reduced by evaporation from the water surface in arid climates.\n\nWastewater nutrients may cause continuing growth of algae in the polishing ponds after the original wastes have been catabolized. Algae may cause measurable contribution to biochemical oxygen demand (BOD) and total suspended solids (TSS) concentrations where discharge regulations include limitations on those concentrations. The TSS contribution of algae tends to peak in the summer months, but the long-term BOD of decomposing algae may not be evident within the typical 5-day test. United States Environmental Protection Agency regulations describe facultative lagoons as providing \"treatment equivalent to secondary treatment\" when 65 percent of influent BOD and TSS are removed and effluent BOD and TSS concentrations do not exceed a 7-day average of 65 mg/L and a 30-day average of 45 mg/L. Individual States may establish alternative effluent limitations.\n\nThe facultative lagoon may be replaced by an aerated lagoon as the first pond of the series. Aerated lagoons have mechanical aerators which minimize anaerobic zones by completely mixing the lagoon to achieve catabolism through a process called extended aeration.\n\n\n"}
{"id": "51136334", "url": "https://en.wikipedia.org/wiki?curid=51136334", "title": "Football (Disorder) Act 2000", "text": "Football (Disorder) Act 2000\n\nThe Football (Disorder) Act 2000 is an Act of the Parliament of the United Kingdom enacted during the premiership of Tony Blair. It served as an amendment to the Football Spectators Act 1989, and strengthened football banning orders (FBOs), a civil order imposed to those convicted of football-related offences. FBOs may be issued by courts in the United Kingdom, or following a complaint from a local police force.\n\nThe Act was \"rushed through Parliament\" by then-Home Secretary Jack Straw following violent clashes during UEFA Euro 2000 in France. It allows police in England and Wales to arrest those suspected of travelling abroad to participate in hooliganism at international games, and to withhold their passports up to five days before an international fixture. Straw stated during an opposition day for his Bill that he was keen to enact the new laws in time for England's next international game against France in September 2000.\n\nFBOs, introduced by Football Spectators Act 1989, may ban an individual from football grounds in the United Kingdom for two to ten years, with provisions for individual cases. Supporters may also be barred from using public transport on matchdays, and from town centres and built-up, high-risk areas prior to and following matches.\n\nThe Act has been criticised by civil liberties campaigners for being \"draconian\", fearing it may result in profiling based on fan appearance.\n\nMore than 450 supporters were prevented from travelling to Greece for a World Cup qualifier in 2001 under the Act.\n\n"}
{"id": "16489034", "url": "https://en.wikipedia.org/wiki?curid=16489034", "title": "Fort Worth Dallas Birthing Project", "text": "Fort Worth Dallas Birthing Project\n\nThe Fort Worth/Dallas Birthing Project is a project which connects volunteers, called \"SisterFriends\", with high-risk, pregnant teenagers in North Texas, with the aim of reducing the area's infant mortality rate. Volunteers provide emotional and practical support during pregnancy and for one year after birth.\nSince the program began in 1997, it has helped more than 140 mothers, mainly in the African-American and Hispanic communities of Tarrant County, Texas, where the infant mortality rate is higher than the state and national averages.\n\nThe project also runs the Aintie-Tia Program which trains volunteers to support African-American women between 18 and 35 during and after pregnancy with pre- and post-natal education and assistance during labor. Funding is provided by the University of North Texas Health Science Center at Fort Worth and the Amon G. Carter Foundation.\n\nIn 2008, the National Institutes of Health funded a study into the effects of the program on birth outcomes.\n\n"}
{"id": "6342698", "url": "https://en.wikipedia.org/wiki?curid=6342698", "title": "Frank H. Netter", "text": "Frank H. Netter\n\nFrank Henry Netter (25 April 1906 – 17 September 1991) was an American surgeon and medical illustrator. The first edition of his \"Atlas of Human Anatomy\" — his \"personal Sistine Chapel\" — was published in 1989; he was a Fellow of the New York Academy of Medicine where he was first published in 1957.\n\nFrank Henry Netter was born in Manhattan at 53rd Street and Seventh Avenue, and grew up wanting to be an artist. In high school, he obtained a scholarship to study at the National Academy of Design, doing so at night while continuing high school. After further studying at the Art Students League of New York and with private teachers, he began a commercial art career, quickly achieving success and doing work for the \"Saturday Evening Post\" and \"The New York Times\". However, his family disapproved of a career as an artist and he agreed to study medicine. After getting a degree at the City College of New York, he completed medical school at New York University and a surgical internship at Bellevue Hospital and attempted to begin practicing medicine. However, as Netter put it: \"This was in 1933—the depths of the Depression—and there was no such thing as medical practice. If a patient ever wandered into your office by mistake, he didn't pay.\"\n\nHaving continued doing freelance art during his medical training, including some work for his professors, he fell back on medical art to supplement his income. In particular, pharmaceutical companies began seeking Netter for illustrations to help sell new products, such as Novocain. Soon after a misunderstanding wherein Netter asked for $1,500 for a series of 5 pictures and an advertising manager agreed to and paid $1,500 each - $7,500 for the series - Netter gave up the practice of medicine.\n\nIn 1936, the CIBA Pharmaceutical Company commissioned a small work from him, a fold-up illustration of a heart to promote the sale of digitalis. This proved hugely popular with physicians, and a reprint without the advertising copy was even more popular.\n\nQuickly following on the success of the fold-up heart, fold-up versions of other organs were produced. Netter then proposed that a series of pathology illustrations be produced. These illustrations were distributed to physicians as cards in a folder, with advertising for CIBA products on the inside of the folder, and were also popular with physicians. CIBA then collected these illustrations in book form, producing the \"CIBA Collection of Medical Illustrations\", which ultimately comprised 8 volumes (13 books).\n\nBeginning in 1948, CIBA also re-used illustrations by Netter in another series of materials to be given to physicians, the \"Clinical Symposia\" series. These were small magazine-like brochures that typically featured an extensive article on a medical condition, commonly with about a dozen of Netter's illustrations. This series was produced until at least the early 1990s. In 1989, Netter's \"Atlas of Human Anatomy\" was published, assembled from his previous paintings and correlated by updated diagrams.\n\nCIBA's Medical Education Department (East Orange, NJ) filtered the paintings for printing, in an effort that The Big Green Books \"might appear more 'even' over time.\" This sometimes resulted in a considerable reduction of color variation from the truly-unique originals. Digital re-scanning of the originals continue to be published by the current copyright owner to the collection, Elsevier Medical Publishing. Selected original paintings have been showcased internationally.\n\nNetter's career was presented in a commemorative video by Ciba-Geigy in 1988.\n\nNetter was skeptical of the claims of alternative medicine and fad diets. He wrote \"Fad Diets Can Be Deadly\" (1975) which debunked the misleading claims of fad diets.\n\nIn all, Netter produced nearly 4,000 illustrations, which have been included in countless publications. In perspective, that number represents an image researched, sketched, and completely painted for every three business days for over 50 years.\n\nThe vast bulk of Netter's illustrations were produced for and owned by CIBA Pharmaceutical Company and its successor, CIBA-Geigy, which has since merged with Sandoz Laboratories to become Novartis. In June 2000, Novartis sold its interest in Netter's works to MediMedia USA's subsidiary Icon Learning Systems, which in turn has sold the portfolio to Elsevier, which continues to make his work available in various formats. His \"Atlas of Human Anatomy\" and other atlases have become a staple of medical education.\n\nThe Frank H. Netter M.D. School of Medicine at Quinnipiac University in North Haven, Connecticut opened its doors in 2013.\n\n\n\n\n"}
{"id": "4949420", "url": "https://en.wikipedia.org/wiki?curid=4949420", "title": "Glaucoma valve", "text": "Glaucoma valve\n\nA glaucoma valve is a medical shunt used in the treatment of glaucoma to reduce the eye's intraocular pressure (IOP).\n\nThe device works by bypassing the trabecular meshwork and redirecting the outflow of aqueous humour through a small tube into an outlet chamber or bleb. The IOP generally decreases from around 33 to 10 mmHg by removing aqueous on average 2.75 microliters/min.\n\nProfessor Anthony Molteno developed the first glaucoma drainage implant, in Cape Town in 1966. Following on the success of the Molteno implant, several varieties of device have been developed from the original, the Baerveldt tube shunt, or the valved implants, such as the Ahmed glaucoma valve implant and the later generation pressure ridge Molteno implants. These are indicated for glaucoma patients not responding to maximal medical therapy, with previous failed guarded filtering surgery (trabeculectomy). The flow tube is inserted into the anterior chamber of the eye and the plate is implanted underneath the conjunctiva to allow flow of aqueous fluid out of the eye into a chamber called a bleb.\n\nThe ExPress Mini Shunt is a newer, non-valved device that was originally designed to provide a direct conduit from the anterior chamber to the sub-conjunctival space or bleb. In this position it was unstable and tended to erode through the conjunctiva. Now the more common use is as a modification of the trabeculectomy procedure, placed under a scleral flap, replacing the sclerostomy step (see trabeculectomy).\n\nIn comparison to the glaucoma drainage devices that use an ab externo procedure, ab interno implants, such as the Xen Gel Stent, are transscleral implants to channel aqueous humor into the non-dissected Tenon's space, creating a subconjunctival drainage area similar to a bleb. The implants are transscleral and different from more other ab interno implants that do not create a transscleral drainage, such as iStent, CyPass, or Hydrus.\n\nA Cochrane Review of various aqueous shunts and modifications found that the Baerveldt implant may result in lower IOP than the Ahmed implant, but it was unclear if the difference in IOP reduction was clinically significant. The review suggests that practitioners should operate with the devices that they are most comfortable with, and have the most experience using.\n\nThe glaucoma valve implant is indicated for glaucoma patients not responding to maximal medical therapy, with previous failed guarded filtering surgery (trabeculectomy) or in cases where conventional drainage surgery is unlikely to succeed. Common situations where the use of a glaucoma implant as a primary procedure is indicated include\n\nThe flow tube is inserted into the anterior chamber of the eye and the plate is implanted underneath the conjunctiva to allow flow of aqueous fluid out of the eye. \n\nThe majority of complications occur shortly after surgery. These are generally related to high pressure (due to inflammation following surgery) or low pressure (too much aqueous flow through the tube). Periods of low pressure which are more associated with non-valved shunts, can cause retinal detachments, maculopathy or haemorrhages. Periods of high pressures, which are more associated with valved shunts, are detrimental to the optic nerve. Long term complications of this surgery include diplopia and corneal oedema.\n\nThere are also device related complications, which will require surgical revision. For example, erosion, where the conjunctiva erodes over the shunt leaving it exposed, the condition of which may be revised or prevented in advance by the use of amniotic membrane, The ologen collagen matrix facilitates tissue regeneration and its application over the site of device implantation can strengthen tissue recovery, reducing possibility of erosion.\n\nWhen the device malfunctions it may need to be replaced. Possible scenarios include blockage, where a particle becomes logged in the tube line blocking flow; retraction, where the tube line slips out of correct position such that flow is inhibited or halted; valve failure, where the valve stops working blocking flow completely.\n\nSurgical failure occurs due to the ongoing scarring over the conjunctival dissipation segment of the shunt may become too thick for the aqueous humor to filter through. This may require preventive measures using anti-fibrotic medication like 5-fluorouracil (5FU) or Mitomycin-C (during the procedure), or creating a necessity for revision surgery with the sole or combinative use of biodegradable spacer or collagen matrix implant.\n\n\n"}
{"id": "2361772", "url": "https://en.wikipedia.org/wiki?curid=2361772", "title": "Good clinical practice", "text": "Good clinical practice\n\nGood clinical practice (GCP) is an international quality standard that is provided by ICH, an international body that defines a set of standards, which governments can then transpose into regulations for clinical trials involving human subjects. A similar guideline for clinical trials of medical devices is the international standard ISO 14155, which is valid in the European Union as a harmonized standard. These standards for clinical trials are sometimes referred to as ICH-GCP or ISO-GCP to differentiate between the two and the lowest grade of recommendation in clinical guidelines.\n\nGCP follows the International Conference on Harmonisation of Technical Requirements for Registration of Pharmaceuticals for Human Use (ICH) of GCP guidelines. GCP enforces tight guidelines on ethical aspects of a clinical study. High standards are required in terms of comprehensive documentation for the clinical protocol, record keeping, training, and facilities, including computers and software. Quality assurance and inspections ensure that these standards are achieved. GCP aims to ensure that the studies are scientifically authentic and that the clinical properties of the investigational product are properly documented.\n\nGCP guidelines include protection of human rights for the subjects and volunteers in a clinical trial. It also provides assurance of the safety and efficacy of the newly developed compounds.\n\nGCP guidelines include standards on how clinical trials should be conducted, define the roles and responsibilities of institutional review boards, clinical research investigators, clinical trial sponsors, and monitors. In the pharmaceutical industry monitors are often called clinical research associates.\n\nA series of unsuccessful and ineffective clinical trials in the past were the main reason for the creation of ICH (The International Council for Harmonisation) and GCP guidelines in the US and Europe. Such was the case with the Elixir Sulphanilamide disaster in 1937 or the Thalidomide incident of the 1960s. These discussions ultimately led to the development of certain regulations and guidelines, which evolved into the code of practice by which all those involved in clinical research now work. This code is known as International Conference on Harmonisation of Good Clinical Practice\n\nThe first indicator in the regulation of drugs is the Food and Drugs Act established in the US in 1906. It is considered to be the result of very dangerous and even deadly drugs that could have been sold legally just like any other medical goods. For example, such drugs were ‘Grandma’s Secret’ and ‘Kopp’s Baby’s Friend’, which contained a huge amount of morphine. ‘Dr King’s Consumption Cure’ and ‘Dr Bull’s Cough Syrup‘ are examples of drugs which had large doses of morphine and chloroform as well.\n\nAlthough ICH GCP guidelines are recommended by the FDA, they are not statutory in the United States.\n\n\nGCP has been called 'a less morally authoritative document' than the Declaration of Helsinki, lacking moral principles and guidance in the following areas:\n\nIn the book \"Bad Pharma\", Ben Goldacre mentions these criticisms and notes that the GCP rules \"aren't terrible... [they are] more focused on procedures, while Helsinki clearly articulates moral principles\".\n\n\n"}
{"id": "21367287", "url": "https://en.wikipedia.org/wiki?curid=21367287", "title": "Gulf Diabetes Specialist Center", "text": "Gulf Diabetes Specialist Center\n\nGulf Diabetes Specialist Center is a medical center located in Manama, Kingdom of Bahrain. It is primarily devoted to the treatment of diabetes and its related complications. It is an outpatient medical center that provides diabetes prevention programs and education and treatment for people with diabetes and their families. The facilities cover a range of functions including the management and treatment of adult and pediatric diabetes and metabolic disorders. The center was opened under the patronage of the Bahraini prime minister Khalifa Bin Salman Al Khalifa.\n\nAccording to the medical director of GDSC, Bahrain's diabetes rate dropped in the year 2011 to 19.9%\n\n\n\n\n"}
{"id": "16969080", "url": "https://en.wikipedia.org/wiki?curid=16969080", "title": "Harold Homer Anderson", "text": "Harold Homer Anderson\n\nHarold Homer Anderson (October 23, 1897 – February 9, 1990) was an American research professor of psychology at Michigan State University, who published on child psychology, clinical psychology, personality, and cross-national research.\n\nAnderson was the son of a minister from Nebraska, who studied at the Northwestern University. In 1933 he accepted a position as professor of psychology and head of the department at Michigan State College. In 1951 Harald H. Anderson was rewarded the Alumni Medal of the Northwestern University. In the 1950s he was among the first members of the Society for General Systems Research.\n\nOne of the earliest systematic studies of \"climate\" in the classroom was undertaken by Harold H. Anderson and Helen M. Brewer. These are reported in several papers and collected in the 1946 publication \"Studies of Teachers' Classroom Personalities\". These researches were carried out in many schools and different classes from kindergarten to children in early adolescence. The aim was to make certain that behavior, as analysed into different categories, could in fact be observed objectively.\n\nTheir recording of \"dominative\" and \"integrative\" actions of teachers and pupils in classroom interaction clearly demonstrated that acts of the teachers set behavior patterns that were reflected in classroom interaction generally.\n\nIn 1957-1958 an Interdisciplinary Symposia on Creativity was held on the Michigan State University. Contributions were made by Erich Fromm, Harold D. Lasswell, Margaret Mead, Abraham Maslow, R. May, Edmund Ware Sinnott, Harold H. Anderson himself and others. Harold H. Anderson edited the symposium report with the main title: \"Creativity and its cultivation\".\n\n\n"}
{"id": "16541258", "url": "https://en.wikipedia.org/wiki?curid=16541258", "title": "Health in Israel", "text": "Health in Israel\n\nHealth in Israel is generally considered good.\n\nInfant mortality is low. Life expectancy, 82.1 years is high. There is good management of chronic disease and excellent primary care. Expenditure on healthcare is 7.2% of Gross Domestic Product, compared with an average of 9.2% in the OECD.\n\nThere are high levels of smoking among Arab Israeli men, and high levels of obesity among Arab Israeli women. The overall rate of smoking among the entire population was just under 20% in 2014.\n\nIsrael has the second highest rate of skin cancer in the world.\n\nObesity rates were below the average for OECD nations, with an obesity rate of 14% for adults in 2009. Socioeconomic status was one factor that impacted overweight and obesity percentages, particularly for women. Women in lower classes were four times as likely to be overweight or obese as women in upper classes. Only 20.2% of the entire population reported that they exercise for twenty minutes or more three times a week.\n\nThe frequency of exercise among the Jewish Israeli population was twice as high as that for the Arab population. Men and women of Arab descent are more likely to be of an unhealthy weight than Israeli men and women.\n\nSmoking prevalence among males remained relatively constant at 30% in the years 1994–2004. Among females the prevalence declined slightly from 25% in 1998 to 18% in 2003. For youth, 14% smoked at least once per week in a 2001 publication.\n\nIn 2005 Israeli youths have begun to use bidis and hookah, as alternative methods of tobacco use. In 1990, smoking was the cause of about 1,800 male deaths in Israel which was around 12% of all male deaths. Smoking has not been found to be significant cause of death among Israeli women. The average number of cigarettes smoked per Israeli stands at 2162 (6).\n\nThere are several anti-tobacco use legislations in effect. For instance, advertising is prohibited in youth publications and is forbidden on television and radio. in addition to substantial increases in tobacco taxes, although comparatively the prices are still among the lowest compared to all of the European countries. Until 2004, there was no minimum age requirement for buying tobacco products in Israel, however, an amendment to the tobacco marketing and advertisement law that became effective at 2004 has limited the sale of tobacco to people above the age of 18.\n\nAccording to Israel Central Bureau of Statistics, the smoking rate in the Israeli adult population in 2009 was 20.9%, down from 34% in 2000. A Ministry of Health nationwide survey conducted in 2011 found that 20.6% of the population aged 21 and older were smokers. The highest percentage of smokers was among Arab males, 44% percent of whom smoked, though this figure is down from 50% in 1996.\n\nIn 2014 19.8% of adult Israelis smoked, 26.3% in the Arab population and 18.4% in the Jewish population. 35% of non-smoking respondents to the World Health Survey reported that they had been exposed to passive smoking. Smoking is responsible for about 8,000 deaths in Israel every year, about 700 among passive smokers. The cost of the damage of smoking to the health system is estimated at NIS 1.7 billion (about $440 million) a year. The annual loss of working capacity and paid sick days in the wider economy is estimated at NIS 1.9 billion ($490 million). About NIS 8.2 billion ($2.12 billion) is spent on tobacco products each year. 40 tons of tobacco worth some NIS 24 million ($6.2 million) and about 1.3 million cigarette packs were intercepted at the border crossing between Israel and the Palestinian Authority in 2014.\n\n"}
{"id": "43400275", "url": "https://en.wikipedia.org/wiki?curid=43400275", "title": "Jeffrey E. Harris", "text": "Jeffrey E. Harris\n\nJeffrey E. Harris, an economist and physician, has been on the faculty of the Economics Department of the Massachusetts Institute of Technology since 1977. He received an AB (summa cum laude, 1969) from Harvard University, as well as an MD (1974) and PhD in Economics (1975) from the University of Pennsylvania. Having trained in internal medicine at the Massachusetts General Hospital (1974-1977), he maintained a medical practice at that institution until 2006. Since then, he has continued to practice as an internist at federally sponsored community health centers in Rhode Island, where the majority of his patients have poverty-level incomes and are not fluent in English.\n\nHarris has published widely on smoking and health, the economics of smoking and public policy toward the tobacco industry, HIV/AIDS, health economics, as well as economics and statistics generally. He is author of \"Deadly Choices: Coping with Health Risks in Everyday Life\".\n\nAs a graduate student, Harris collaborated with his doctoral thesis adviser, Oliver E. Williamson (Nobel Memorial Prize in Economic Sciences, 2008), in an article entitled \"Understanding the Employment Relation: The Analysis of Idiosyncratic Exchange\". This article (294 Web of Science (WoS) citations, 928 Google Scholar (GS) citations) was subsequently reproduced in several collections, including Williamson’s \"Markets and Hierarchies\" (1975). The article has been described as \"the first explicit application of the new institutional economics to internal labor markets.\"\n\nBased upon Harris' training in the economics of organization and his experiences as a medical resident, this article (149 WoS citations, 411 GS citations) has been listed as one of the top articles in the last four decades of scholarship in health economics. Reproduced in several collections, the article was cited in the first generation of health economics textbooks as the Harris Model: \"The hospital, under Harris' account, is the scene of continual conflict within an organization inherently split into two parts, what Harris describes as a noncooperative oligopoly game.\"\n\nBased upon his participation in the Diesel Impacts Study Committee of the National Academy of Sciences, Harris collaborated with William H. DuMouchel in an article entitled \"Bayes Methods for Combining the Results of Cancer Studies in Humans and Other Species\" (181 WoS citations, 228 GS citations). As recounted by Sharon Bertsch McGrayne in \"The Theory That Would Not Die\", \"Several civilian researchers tackling hitherto intractable problems concerning public health, sociology, epidemiology, and image restoration did experiment during the 1980s with computers for Bayes. A major controversy about the effect of diesel engine emissions on air quality and cancer inspired the first attempt. By the 1980s cancer specialists had solid data about the effects of cigarette smoke on people, laboratory animals, and cells but little accurate information about diesel fumes. William H. DuMouchel from MIT’s mathematics department and Jeffrey E. Harris from its economics department and Massachusetts General Hospital teamed up in 1983 to ask, 'Could you borrow and extrapolate and take advantage of information from non-human species for humans?' ... Thanks to mice and hamster studies, DuMouchel and Harris were able to conclude that even if light-duty diesel vehicles captured a 25% market share over 20 years, the risk of lung cancer would be negligible for the typical urban resident compared to the typical pack-a-day cigarette smoker. ... Today, Bayesian meta-analyses are statistically old hat, but DuMouchel and Harris made Bayesians salivate for more big-data methods—and for the computing power to deal with them.\"\n\nMotivated by his contributions to the 1979 and 1980 Surgeon General’s Reports, Harris developed a method to reconstruct the smoking rates of successive birth cohorts of men and women throughout the 20th century, based upon individual smoking histories reported in large-scale cross-section surveys. The resulting article, published in the Journal of the National Cancer Institute in 1983 (148 Wos citations, 210 GS citations), spawned a series of studies tracking the birth cohort-specific relationships between smoking rates and disease incidence.\n\nIn an article entitled \"Improved Short-Term Survival of AIDS Patients Initially Diagnosed with Pneumocystis carinii Pneumonia, 1984 through 1987\" (101 WoS citations, 131 GS citations), Harris was one of the first investigators to report a significant gain in life expectancy for AIDS patients, which he attributed to the introduction in 1986 of zidovudine, the first antiretroviral agent.\n\nHarris collaborated with Dr. Michael Thun and his colleagues at the American Cancer Society to study the relationship between cigarette tar yield and the risk of cancer in the Cancer Prevention Study II (CPS-II) cohort (57 WoS citations, 136 GS citations, 36,000 downloads from British Medical Journal website). This prospective cohort study of over 900,000 men and women remains the standard citation for the conclusion that, while cigarette smoking increases the risk of lung cancer compared to nonsmokers, there is no difference in lung cancer risk between those who smoke medium tar cigarettes, low tar cigarettes and very low tar cigarettes.\n\nHarris has served as Consulting Scientific Editor, Contributor, and Senior Reviewer to numerous U.S. Surgeon General's Reports on Smoking and Health (1979–1983, 1986, 1988, 1989, 1996). He has served as a member of several committees of the National Academy of Sciences and the Institute of Medicine, including the Diesel Impacts Study Committee, the Committee to Study the Prevention of Low Birth Weight, the Committee on National Strategies toward Acquired Immunodeficiency Syndrome, the Committee on Risk Characterization, and the Committee on Reducing Tobacco Use. Harris has served as consultant to numerous governmental agencies, including the U.S. National Cancer Institute, U.S. Department of Energy, U.S. Environmental Protection Agency, U.S. Department of Agriculture, U.S. Federal Trade Commission, U.S. Department of Veterans Affairs, U.S. Department of Justice, U.S. Internal Revenue Service, Massachusetts Department of Public Health, Minnesota Attorney General, New York City Department of Health, New Hampshire Association of Counties, the Attorney General of Canada, and the Australian Competition and Consumer Safety Commission. He has consulted for numerous nonprofit public interest organizations, including the American Cancer Society. He has also served as a physician member of the Massachusetts Board of Registration in Medicine (1978-1980).\n\nHarris has given invited testimony before the Committee on Ways and Means, U.S. House of Representatives; the Committee of the Judiciary, U.S. House of Representatives; the U.S. Senate Judiciary Committee; the U.S. Senate Committee on Agriculture; the U.S. Senate Democratic Task Force; and the Massachusetts Department of Public Health. In 2003, he gave expert testimony in , a class-action lawsuit alleging fraud in the marketing and sale concerning light cigarettes, in which the trial court entered a $10.1 billion judgment against the defendant. In 2004, he gave expert testimony in \"United States v. Philip Morris et al.\", in which the trial court found that tobacco manufacturers had violated the Racketeer Influenced and Corrupt Organizations (RICO) Act. Harris has offered expert testimony in numerous other cases involving the tobacco and pharmaceutical industries.\n\nHarris’ role as an expert witness at trial in Cipollone v. Liggett, the first lawsuit in which a jury held the tobacco industry responsible for an individual smoker’s death, has been subject to numerous reviews. As recounted by Richard Kluger in his Pulitzer Prize-winning \"Ashes to Ashes\": \"Harris tellingly contrasted the tobacco companies' conduct with that of the canning industry, which had adopted new sterilizing methods when botulism was traced to its careless procedures, and the pharmaceutical industry, which had put a skull-and-crossbones warning on preparations found to be toxic when ingested. Such measures were in marked contrast to the conduct of Philip Morris, Harris said, which in the 'Thirties had introduced the humectant diethylene glycol-- a compound later found to be harmful to the kidneys-- based on a minimum of testing...\" Harris' unpublished \"Expert Report on the State of the Art\", which was submitted in the Cipollone litigation, itself spawned an inquiry into the role of historians as experts in tobacco-related litigation. As recounted by Robert Proctor in \"Golden Holocaust\", \"In a memo titled 'Witness Development,' Arnold & Porter's Janet L. Johnson emphasized to STIC's State-of-the-Art Subcomittee their need to develop a 'storyteller' to tell 'our version' of the history of the recognition of tobacco hazards. Jeffrey Harris's expert report for Cipollone had presented a detailed chronicle of the discovery of lung cancer hazard, identifying evidence from the 1930's and the strong case for proof by 1957. The industry wanted to counter the testimony without having to address when a link had actually been established. 'Instead of trying to defend the issue of whether and when a link between cigarette smoking and lung cancer was established, we should consider focusing our testimony on defending 1954, attacking Harris' 1957 date on which a link was 'proven,' and demonstrate that it was not proven in 1957 with post-57 statements by medical experts about the existence of a controversy'.\"\n\nSince he spent the summer of 2005 in a community health center in Guatemala, Harris has developed numerous connections with researchers and policy makers throughout the Spanish-speaking world. He has served as visiting faculty and has given lectures, principally in Spanish, in Guatemala (Universidad Francisco Marroquin), Mexico (Instituto Nacional de Salud Pública), the Dominican Republic (Pontificia Universidad Católica Madre y Maestra, Universidad Tecnológica de Santiago), Spain (University of Las Palmas de Gran Canaria, University of La Laguna, University of Salamanca, Pompeu Fabra University), Costa Rica (Instituto Costarricense de Investigación y Enseñanza en Nutrición y Salud, University of Costa Rica), Uruguay (Fondo Nacional de Recursos, University of the Republic) and Chile (University of Chile, Pontifical Catholic University of Chile). In 2008, Harris was named Huésped Distinguido (Distinguished Guest and Honorary Citizen), City of Salamanca, Spain. In 2011, he received a Fulbright Specialist Award from the U.S. Department of State to establish collaborative connections with academic colleagues in Uruguay.\nHis recent collaborative research work includes studies of physician specialty choice in Spain and the evaluation of Uruguay's tobacco control campaign. Since 2013, he has embarked on a series of collaborative projects in Chile sponsored by the MIT Sloan Latin America Office and the MIT MISTI/Chile Program.\n"}
{"id": "1540434", "url": "https://en.wikipedia.org/wiki?curid=1540434", "title": "John Scott Haldane", "text": "John Scott Haldane\n\nJohn Scott Haldane (; 2 May 1860 – 14/15 March 1936) was a Scottish physiologist famous for intrepid self-experimentation which led to many important discoveries about the human body and the nature of gases. He also experimented on his son, the equally famous J. B. S. Haldane (both for extending his father's interest in diving and as a key figure in population genetics and the development of the modern synthesis), even when he was quite young. Haldane locked himself in sealed chambers breathing potentially lethal cocktails of gases while recording their effect on his mind and body.\n\nHaldane visited the scenes of many mining disasters and investigated their causes. When the Germans used poison gas in World War I, Haldane went to the front at the request of Lord Kitchener and attempted to identify the gases being used. One outcome of this was his invention of the first respirator.\n\nHaldane was born in Edinburgh to Robert Haldane, whose father was Scottish evangelist James Alexander Haldane, and Mary Elizabeth Burdon-Sanderson, daughter of Richard Burdon-Sanderson and the granddaughter of Sir Thomas Burdon. His maternal uncle was the physiologist John Scott Burdon-Sanderson. He was the brother of Elizabeth Haldane, William Stowell Haldane and Richard Burdon Haldane, 1st Viscount Haldane.\n\nHaldane attended Edinburgh Academy, Edinburgh University and the Friedrich Schiller University of Jena. He graduated in medicine from Edinburgh University Medical School in 1884.\n\nOn 12 December 1891 he married Louisa Kathleen Coutts Trotter (1863–1961), daughter of Coutts Trotter FRGS and Harriet Augusta Keatinge. They had two children: the scientist J. B. S. Haldane and the author Naomi Mitchison.\n\nHaldane was Gifford Lecturer in the University of Glasgow, Fellow of New College, Oxford, from October 1901, and Honorary Professor of the University of Birmingham. Haldane received numerous honorary degrees. He was also President of the English Institution of Mining Engineers, a Companion of Honor of the British Court, a Fellow of the Royal Society, a member of the Royal College of Physicians and of the Royal Society of Medicine.\n\nHaldane died in Oxford at midnight on the night of 14 March/15 March 1936. He had just returned from a trip he had undertaken to investigate cases of heat stroke in the oil refineries in Persia.\n\nSir Henry Newbolt wrote a poem called \"For J. S. Haldane\", published in his anthology \"A Perpetual Memory and other Poems\" in 1939.\n\nHaldane was an international authority on ether and respiration and the inventor of the Black Veil Respirator, or early gas mask, during World War I.\n\nHaldane helped determine the regulation of breathing, and discovered the Haldane effect in haemoglobin. He was the founder of \"The Journal of Hygiene\". In 1907 Haldane made a decompression chamber to help make deep-sea divers safer and produced the first decompression tables after extensive experiments with animals. He was also an authority on the effects of pulmonary diseases, such as silicosis caused by inhaling silica dust. After being forced out of combatting poison gases in World War I, through alleged German sympathies, he shifted into working with victims of gas warfare and developed oxygen treatment including the oxygen tent.\n\nHe investigated the principle of action of many different gases. He investigated numerous mine disasters, especially the toxic gases which killed most miners after firedamp and coal dust explosions. The toxic mixtures of gases found in mines included afterdamp, blackdamp and whitedamp. His description of the way a flame safety lamp can be used to detect firedamp by the increase in height of the flame, and chokedamp by the dying of the flame, is a classic exposition in his textbook, \"Respiration\". Although electronic gas detectors are now used widely in all coal mines, flame lamps are still used extensively for their ease and simplicity of operation. Electronic gas detectors rely on a catalytic chip which can be poisoned by atmospheric impurities.\n\nHe identified carbon monoxide as the lethal constituent of afterdamp, the gas created by combustion, after examining many bodies of miners killed in pit explosions. Their skin was coloured cherry-pink from carboxyhaemoglobin, the stable compound formed in the blood by reaction with the gas. It effectively displaces oxygen, and so the victim dies of asphyxia. As a result of his research, he was able to design respirators for rescue workers. He tested the effect of carbon monoxide on his own body in a closed chamber, describing the results of his slow poisoning. In the late 1890s, he introduced the use of small animals for miners to detect dangerous levels of carbon monoxide underground, either white mice or canaries. With a faster metabolism, they showed the effects of poisoning before gas levels became critical for the workers, and so gave an early warning of the problem. The canary in British pits was replaced in 1986 by the electronic gas detector.\n\nHaldane pioneered study of the reaction of the body to low air pressures, such as that experienced at high altitudes. He led an expedition to Pike's Peak in 1911, which examined the effect of low atmospheric pressure on respiration.\n\nIn addition to his work on mine atmospheres, he investigated the air in enclosed spaces such as wells and sewers. One surprising result of his analysis of the air in the sewers beneath the House of Commons was to show that the level of bacterial contamination was relatively low. During this research, he investigated fatalities of workmen in a sewer, and showed that hydrogen sulfide gas was the culprit.\n\n\n\n"}
{"id": "1160623", "url": "https://en.wikipedia.org/wiki?curid=1160623", "title": "John Snow", "text": "John Snow\n\nJohn Snow (15 March 1813 – 16 June 1858) was an English physician and a leader in the adoption of anaesthesia and medical hygiene. He is considered one of the fathers of modern epidemiology, in part because of his work in tracing the source of a cholera outbreak in Soho, London, in 1854. His findings inspired fundamental changes in the water and waste systems of London, which led to similar changes in other cities, and a significant improvement in general public health around the world.\n\nSnow was born on 15 March 1813 in York, England, the first of nine children born to William and Frances Snow in their North Street home, and was baptised at All Saints' Church, North Street, York. His father was a labourer who worked at a local coal yard, by the Ouse, constantly replenished from the Yorkshire coalfield by barges, but later was a farmer in a small village to the north of York.\n\nThe neighbourhood was one of the poorest in the city, and was frequently in danger of flooding because of its proximity to the River Ouse. Growing up, Snow experienced unsanitary conditions and contamination in his hometown. Most of the streets were unsanitary and the river was contaminated by runoff water from market squares, cemeteries and sewage.\nFrom a young age, Snow demonstrated an aptitude for mathematics. In 1827, when he was 14, he obtained a medical apprenticeship with William Hardcastle in Newcastle-upon-Tyne. In 1832, during his time as a surgeon-apothecary apprentice, he encountered a cholera epidemic for the first time in Killingworth, a coal-mining village. Snow treated many victims of the disease and gained a lot of experience. Additionally, while he was an apprentice, Snow could not drink, gamble or marry. Eventually he adjusted to teetotalism and led a life characterized by abstinence, signing an abstinence pledge in 1835. Snow was also a vegetarian and tried to only drink distilled water that was “pure”. Between 1833 and 1836 Snow worked as an assistant to a colliery surgeon, first in Burnopfield, County Durham, and then in Pateley Bridge, West Riding of Yorkshire. In October 1836 he enrolled at the Hunterian school of medicine on Great Windmill Street, London.\n\nIn 1837, Snow began working at the Westminster Hospital. Admitted as a member of the Royal College of Surgeons of England on 2 May 1838, he graduated from the University of London in December 1844 and was admitted to the Royal College of Physicians in 1850. In 1850 he was also one of the founding members of the Epidemiological Society of London, formed in response to the cholera outbreak of 1849.\n\nIn 1857, Snow made an early and often overlooked contribution to epidemiology in a pamphlet, \"On the adulteration of bread as a cause of rickets\".\n\nJohn Snow was one of the first physicians to study and calculate dosages for the use of ether and chloroform as surgical anaesthetics, allowing patients to undergo surgical and obstetric procedures without the distress and pain they would otherwise experience. He designed the apparatus to safely administer ether to the patients and also designed a mask to administer chloroform. He personally administered chloroform to Queen Victoria when she gave birth to the last two of her nine children, Leopold in 1853 and Beatrice in 1857, leading to wider public acceptance of obstetric anaesthesia. Snow published an article on ether in 1847 entitled \"On the Inhalation of the Vapor of Ether\". A longer version entitled \"On Chloroform and Other Anaesthetics and Their Action and Administration\" was published posthumously in 1858.\n\nAfter finishing his medical studies in the University of London, he earned his MD in 1844. Snow set up his practice at 54 Frith Street in Soho as a surgeon and general practitioner. John Snow contributed to a wide range of medical concerns including anaesthesiology. He was a member of the Westminster Medical Society, an organisation dedicated to clinical and scientific demonstrations. Snow gained prestige and recognition all the while being able to experiment and pursue many of his scientific ideas. He was a speaker multiple times at the society’s meetings and he also wrote and published articles. He was especially interested on patients with respiratory diseases and tested his hypothesis through animal studies. In 1841, he wrote, \"On Asphyxiation, and on the Resuscitation of Still-Born Children\", which is an article that discusses his discoveries on the physiology of neonatal respiration, oxygen consumption and the effects of body temperature change. Therefore, his interest in anaesthesia and breathing was evident since 1841 and beginning in 1843, Snow experimented with ether to see its effects on respiration. Only a year after ether was introduced to Britain, in 1847, he published a short work titled, \"On the Inhalation of the Vapor of Ether,\" which served as a guide for its use. At the same time, he worked on various papers that reported his clinical experience with anaesthesia, noting reactions, procedures and experiments.\n\nThough he thoroughly worked with ether as an anaesthetic, he never attempted to patent it; instead he continued to work and publish written works on his observations and research. Within two years after ether was introduced, Snow was the most accomplished anaesthetist in Britain. London’s principal surgeons suddenly wanted his assistance.\n\nJohn Snow also studied chloroform, as much as he studied ether, which was introduced in 1847 by James Young Simpson, a Scottish obstetrician. He realised that chloroform was much more potent and required more attention and precision when administering it. Snow first realised this with Hannah Greener, a 15-year-old patient, who died on 28 January 1848 after a surgical procedure that required the cutting of her toenail. She was administered chloroform by covering her face with a cloth dipped in the substance. However, she quickly lost pulse and died. After investigating her death and a couple of deaths that followed, he realized that chloroform had to be administered carefully and published his findings in a letter to \"The Lancet\".\n\nSnow’s work and findings were related to both anaesthesia and the practice of childbirth. His experience with obstetric patients was extensive and used different substances including ether, amylene and chloroform to treat his patients. However, chloroform was the easiest drug to administer. He treated 77 obstetric patients with chloroform. He would apply the chloroform at the second stage of labour and controlled the amount without completely putting the patients to sleep. Once the patient was delivering the baby they would only feel the first half of the contraction and be on the border of unconsciousness but not fully there. Regarding administration of the anaesthetic, Snow believed that it would be safer if another person that was not the surgeon applied it.\n\nThe use of chloroform as an anaesthetic for childbirth was seen as unethical by many physicians and even the Church of England. However, on 7 April 1853, Queen Victoria asked John Snow to administer chloroform during the delivery of her eighth child. He then repeated the procedure for the delivery of her daughter, three years later. Medical and religious acceptance of obstetrical anaesthesia came after in the 19th century.\n\nSnow was a skeptic of the then-dominant miasma theory that stated that diseases such as cholera and bubonic plague were caused by pollution or a noxious form of \"bad air\". The germ theory of disease had not yet been developed, so Snow did not understand the mechanism by which the disease was transmitted. His observation of the evidence led him to discount the theory of foul air. He first publicised his theory in an 1849 essay, \"On the Mode of Communication of Cholera\", followed by a more detailed treatise in 1855 incorporating the results of his investigation of the role of the water supply in the Soho epidemic of 1854.\n\nBy talking to local residents (with the help of Reverend Henry Whitehead), he identified the source of the outbreak as the public water pump on Broad Street (now Broadwick Street). Although Snow's chemical and microscope examination of a water sample from the Broad Street pump did not conclusively prove its danger, his studies of the pattern of the disease were convincing enough to persuade the local council to disable the well pump by removing its handle (force rod). This action has been commonly credited as ending the outbreak, but Snow observed that the epidemic may have already been in rapid decline:\n\nSnow later used a dot map to illustrate the cluster of cholera cases around the pump. He also used statistics to illustrate the connection between the quality of the water source and cholera cases. He showed that the Southwark and Vauxhall Waterworks Company was taking water from sewage-polluted sections of the Thames and delivering the water to homes, leading to an increased incidence of cholera. Snow's study was a major event in the history of public health and geography. It is regarded as the founding event of the science of epidemiology.\n\nSnow wrote:\n\nResearchers later discovered that this public well had been dug only from an old cesspit, which had begun to leak faecal bacteria. The cloth nappy of a baby, who had contracted cholera from another source, had been washed into this cesspit. Its opening was originally under a nearby house, which had been rebuilt farther away after a fire. The city had widened the street and the cesspit was lost. It was common at the time to have a cesspit under most homes. Most families tried to have their raw sewage collected and dumped in the Thames to prevent their cesspit from filling faster than the sewage could decompose into the soil.\n\nThomas Shapter had conducted similar studies and used a point-based map for the study of cholera in Exeter, seven years before John Snow, although this did not identify the water supply problem that was later held responsible.\n\nAfter the cholera epidemic had subsided, government officials replaced the Broad Street pump handle. They had responded only to the urgent threat posed to the population, and afterward they rejected Snow's theory. To accept his proposal would have meant indirectly accepting the fecal-oral route of disease transmission, which was too unpleasant for most of the public to contemplate.\n\nIt wasn't until 1866 that William Farr, one of Snow's chief opponents, realized the validity of his diagnosis when investigating another outbreak of cholera at Bromley by Bow and issued immediate orders that unboiled water was not to be drunk.\n\nFarr denied Snow's explanation of how exactly the contaminated water spread cholera, although he did accept that water had a role in the spread of the illness. In fact, some of the statistical data that Farr collected helped promote John Snow's views.\n\nPublic health officials recognise the political struggles in which reformers have often become entangled. During the Annual Pumphandle Lecture in England, members of the John Snow Society remove and replace a pump handle to symbolise the continuing challenges for advances in public health.\n\nIn 1830 Snow became a member of the Temperance Movement, and lived for a decade or so as a vegetarian and teetotaler. In the mid-1840s his health deteriorated, and he returned to meat-eating and drinking wine. He continued drinking pure water (via boiling) throughout his adult life. He never married.\n\nSnow lived at 18 Sackville Street, London, from 1852 to his death in 1858.\n\nSnow suffered a stroke while working in his London office on 10 June 1858. He was 45 years old at the time. He never recovered, dying on 16 June 1858. He was buried in Brompton Cemetery.\n\n\n\n"}
{"id": "21528428", "url": "https://en.wikipedia.org/wiki?curid=21528428", "title": "Kramatorsk radiological accident", "text": "Kramatorsk radiological accident\n\nThe Kramatorsk radiological accident was a radiation accident that happened in Kramatorsk, Ukrainian SSR from 1980 to 1989. In 1989, a small capsule containing highly radioactive caesium-137 was found inside the concrete wall of an apartment building, with a surface gamma radiation exposure dose rate of 1800 R/year.\n\nIt is believed that the source, originally a part of a measurement device (most likely a level meter), was lost in the late 1970s and ended up mixed with material used to construct the building in 1980.\n\nOver 9 years, two families lived in the apartment. By the time the capsule was discovered, 6 residents of the building had died from leukemia and 17 more had received varying doses of radiation. The accident was detected only after the residents requested that the level of radiation be measured in the apartment by a health physicist.\n\nThe address where the accident occurred is Gvardeytsiv Kantemirovtsiv Street, Building 7, Apartment 85, between apartments 85 and 52.\n"}
{"id": "37023859", "url": "https://en.wikipedia.org/wiki?curid=37023859", "title": "Kyriazis Medical Museum", "text": "Kyriazis Medical Museum\n\nThe Kyriazis Medical Museum in Larnaca, Cyprus was established in 2011. It displays medical items, books, and framed documents relating to the practice of Cypriot medicine and the history of medicine in Cyprus, from antiquity to the 20th century. It is sometimes referred to as a Medical Museum—the only one in Cyprus.\n\nA sign on the facade says: \"Larnaka Cultural Walk - Kyriazis Medical Museum - A unique in its kind museum in Cyprus which presents the medical, healing and health history of the island.\" It is located on Karaolis and Dimitriou Street. It is open on Wednesdays and Saturdays from 9 AM to 12.30. Entrance is free.\n\nThe Museum organises cultural events, lectures for the public and activities with medical interest. It also functions as a 'health hangout' for healthcare professionals and the general public alike.\n\nIt was opened by Cyprus Health Minister Stavros Malas in October 2011.\n\nIts founder is Marios Kyriazis, a descendant of four generations of doctors and pharmacists in Larnaca. It is housed in a traditional restored and listed town mansion, donated by Kyriazis. Kyriazis has donated items including items and books inherited from his grandfather Neoclis Kyriazis (1878–1956) and from his great grandfather Antonios Tsepis (1843–1905) both of whom practiced in Larnaca. The collections of the museum begun in 1990 but due to lack of suitable space the items remained stored, although occasionally, these were exhibited within other medical or historical exhibitions.\nDocuments with old Cypriot poems and curses with medical content, and a number of virtually forgotten sayings and poems with medical slant of Byzantian, Frankish, Venetian or Ottoman origins are exhibited on walls. The sayings and poems were shaped by a history of lack of medical facilities, inadequate treatments and absence of health prevention.\n\nThe walls of the main entrance hall (Iliakos) are lined with framed pictures displaying the history of medicine from antiquity, through the Middle Ages and early 1800s. Examples include depictions of operations without anaesthetic, treatment of cholera or the plague, and treatments in monasteries.\n\nThis is the first room encountered on the left of the main entrance. There are Pharmacist’s cupboards displaying original bottles, tablets, injections, and doctor’s prescriptions. Items include a bullet extractor and a spring-loaded device for physiotherapy of muscles in the hand (where each finger's movement—of a hand that is closing—is counteracted by the force of separate springs, as the springs are stretched). Among other exhibits are a phallic item believed to have been used in the treatment of female hysteria in ancient times, and a rare find: oil from the Larnaka salt lake which was used in skin wounds and insect bites. In this room there is also a display of many old traditional Cypriot poems or sayings with medical content.\n\nAn X-ray machine, an electronic EKG measuring instrument, an ob/gynaecological bench and a surgical table are among exhibits in room two. The display information on the gynaecological bench states that it was used by nearly half of the original population of Larnaka. There is also a pharmacist’s display unit with several medical items from the 1850s including cupping material, leeches, a tonsil extractor, a Victorian magneto-electric device and cautery items.\nAlthough there are several medical and pharmaceutical items exhibited, this room is served mainly as a study/research facility. A medical library with books in Greek, Cypriot, French and English is available to students or academic researchers. A pharmaceutical display unit contains items for making hand-made pills.\n\nOriginal surgical amputation instruments and a trough with wood shavings (to absorb blood) with a mock amputated hand are among exhibits in room four. There is a replica of the Hippocratic Ladder, a wooden ladder used to treat dislocations of the hip or of the neck. The injured leg was pulled by a ceramic pot full of stones or water. A medical partition donated by the old Larnaca Hospital serves as a poster display unit with medical cartoons or information about traditional Cypriot therapies. Other items include a doctor's examination couch and equipment for treating tuberculosis.\n\nBooks are in all the four rooms. On request, permission to manipulate exhibits can be informally granted.\n\nThe garden is a traditional urban residential area where meetings or public events are being held. There is a collection of some Cypriot healing herbs such as mint, basil, lavender, sage, melissa and marjoram. The garden is accessible to the public, as this is used also as a health hub, where herbal and other health drinks are served. A covered area has a further display facility where outdoors exhibitions have taken place.\n\nThe museum has a neoclassic-type façade with blue window shutters, high ceilings, wooden floors in the rooms, and the obligatory decorated ceramic pattern in the ‘iliakos’ floor complete the picture. The house used to be a private residence, but the street where the museum is located had an unusually high number of doctors, nurses or pharmacists living there. Approximately 50% of all local residents had a medical connection.\n\nThe aim is to safeguard the medical cultural heritage of Cyprus for future generations of medical scientists and to identify facts of sociological, scientific, medical or literary interest. The museum aims to reach any member of the public, of any age, and to facilitate exchange of information, learning and discussion on current health practices based on the past.\n\nThe Medical Museum has organised the following cultural events:\n\nApril 2012: ‘Strange Traditional Cypriot Treatments’, under the auspices of the Mayor of Larnaca, also broadcast on Cyprus Broadcasting Corporation channel 1\n\nSeptember 2013: ‘World Tourism Day’ events and practical demonstrations\n\nMay 2013: ‘2000 years from the death of Apollonios of Kition’ under the auspices of the Cyprus Health Minister. This event included Ancient Greek wrestling (Pankration), medical theatre and presentations.\n\n12 September 2013: Exhibition of medical cartoons, under the auspices of the Mayor of Larnaca.\n\n26 September 2013: ‘Medical Saints of Cyprus’ under the auspices of the Bishop of Kition. Presentations from Kalogera Primary School students and other lectures.\n\n22 May 2014: An evening of Cypriot medicine, in association with the Larnaca Doctors Association, and the Larnaca Municipality.\n\nThree main research projects are currently being undertaken:\n\n1. A compilation of a Cypriot medical dictionary. The aim is to collect and publish all Cypriot words with a medical meaning. Several interested parties are now collaborating in order to prepare a complete collection of all Cypriot medical terms including anatomy, pharmacology and nursing.\n\n2. A study of ‘strange’ traditional healing practices. This includes anything unusual or weird used in the past in order to heal or ameliorate illness. Examples include baked lizards and gunpowder used in baldness, donkey manure in infections, and live mice in a variety of health recipes.\n\n3. The collection, display and subsequent publication of medieval, Byzantian or early Cypriot literature with medical content. This includes poems and ballads, wishes and curses, folk stories, and couplets.\n"}
{"id": "11139555", "url": "https://en.wikipedia.org/wiki?curid=11139555", "title": "Lactation room", "text": "Lactation room\n\nLactation room (or Lactorium) is an American English term for a private space where a nursing mother can use a breast pump. The development is mostly confined to the United States, which is unique among developed countries in providing minimal maternity leave. Historian Jill Lepore argues that the \"non-bathroom lactation room\" and breast pumps generally are driven by corporate need for workers rather than mothers' wishes or babies' needs.\n\nLactation rooms provide breastfeeding mothers with a private space to pump or nurse. While lactation spaces existed prior to the 2010 Patient Protection and Affordable Care Act, the amended Section 4207 of the Fair Labor Standards Act requires employers with 50 employees or more to provide a private space for nursing mothers that's not a bathroom. \n\nOver the past decade, lactation rooms have become widely popular in the US business setting. The reason for this development is that\n\n“mothers are the fastest-growing segment of the U.S. labor force. Approximately 70% of employed mothers with children younger than 3 years work full time. One-third of these mothers return to work within 3 months after giving birth and two-thirds return within 6 months. Working outside the home is related to a shorter duration of breastfeeding, and intentions to work full-time are significantly associated with lower rates of breastfeeding initiation and shorter duration”. \n\nIn addition, breastfeeding benefits employers as breastfeeding results in decreased health claims, increased productivity, and fewer days missed from work to care for sick children. \n\nOne example of the benefits provided to businesses and employees by establishing a corporate lactation program is that of CIGNA, the national employee benefits company. In 1995, CIGNA established the “Working Well Moms” program, which provided lactation education program and lactation rooms. In 2000, CIGNA and the UCLA conducted a study of 343 breastfeeding women who were taking part in CIGNA’s program. The study revealed a savings of $240,000 annually in health care expenses for breastfeeding mothers and their children, and a savings of $60,000 annually through reduced absenteeism among breastfeeding mothers at CIGNA. In addition, the study found that\n“breastfeeding duration for women enrolled in the Working Well Moms program is 72.5% at six months compared to a 21.1 percent national average of employed new mothers.” \nGenerally, a lactation room includes a refrigerator, sink, cleaning supplies, table, and comfortable chair. The ability to pump throughout the day allows mothers to keep up their milk supply and enables them to save and take home the nutrient-rich milk they have pumped.\n\nA variety of resources exist for breastfeeding mother and employers on how to establish and promote a lactation room or lactation support program. The following are currently available:\n\nIn addition, the US Department of Health and Human Services, Maternal and Child Health Bureau is currently developing a toolkit to promote breastfeeding in the workplace called “The Business Case for Breastfeeding”.\n"}
{"id": "12262626", "url": "https://en.wikipedia.org/wiki?curid=12262626", "title": "Lipoatrophy", "text": "Lipoatrophy\n\nLipoatrophy is the term describing the localized loss of fat tissue. This may occur as a result of subcutaneous injections of insulin in the treatment of diabetes, from the use of human growth hormone or from subcutaneous injections of copaxone used for the treatment of multiple sclerosis. In the latter case, an injection may produce a small dent at the injection site. Lipoatrophy occurs in HIV-associated lipodystrophy, one cause of which is an adverse drug reaction that is associated with some antiretroviral medications.\n\nA more general term for an abnormal or degenerative condition of the entire body's adipose tissue is \"lipodystrophy\".\n"}
{"id": "5736285", "url": "https://en.wikipedia.org/wiki?curid=5736285", "title": "List of UK hill-walking guide writers", "text": "List of UK hill-walking guide writers\n\nThis list is a collection of the main guidebook writers for the hill-walking areas of the UK.\n\n"}
{"id": "37780521", "url": "https://en.wikipedia.org/wiki?curid=37780521", "title": "List of medical triads and pentads", "text": "List of medical triads and pentads\n\nA medical triad is a group of three signs or symptoms, the result of injury to three organs, which characterise a specific medical condition. The appearance of all three signs conjoined together in another patient, points to that the patient has the same medical condition, or diagnosis. \n\nA medical pentad is a group of five.\n\n\n2- “Mais-Nadim-Nasser Triad”, A Useful Marker for Leukodystrophies\nDiagnosis\nNasser Nadim*Genetic Syndromes & Gene Therapy Nadim, J Genet Syndr Gene Ther 2014, 5:5\nhttp://dx.doi.org/10.4172/2157-7412.1000242\nJ Genet Syndr Gene Ther Volume 5 • Issue 5 • 1000242\nISSN: 2157-7412 JGSGT, an open access journal\n\n"}
{"id": "43022118", "url": "https://en.wikipedia.org/wiki?curid=43022118", "title": "Lists of killings by law enforcement officers", "text": "Lists of killings by law enforcement officers\n\nFollowing are lists of killings by law enforcement officers.\n\n\n"}
{"id": "1645752", "url": "https://en.wikipedia.org/wiki?curid=1645752", "title": "Mean opinion score", "text": "Mean opinion score\n\nMean opinion score (MOS) is a measure used in the domain of Quality of Experience and telecommunications engineering, representing overall quality of a stimulus or system. It is the arithmetic mean over all individual “values on a predefined scale that a subject assigns to his opinion of the performance of a system quality”. Such ratings are usually gathered in a subjective quality evaluation test, but they can also be algorithmically estimated.\n\nMOS is a commonly used measure for video, audio, and audiovisual quality evaluation, but not restricted to those modalities. ITU-T has defined several ways of referring to a MOS in Recommendation P.800.1, depending on whether the score was obtained from audiovisual, conversational, listening, talking, or video quality tests.\n\nThe MOS is expressed as a single rational number, typically in the range 1–5, where 1 is lowest perceived quality, and 5 is the highest perceived quality. Other MOS ranges are also possible, depending on the rating scale that has been used in the underlying test. The Absolute Category Rating scale is very commonly used, which maps ratings between \"Bad\" and \"Excellent\" to numbers between 1 and 5, as seen in below table.\n\nOther standardized quality rating scales exist in ITU-T recommendations (such as P.800 or P.910). For example, one could use a continuous scale ranging between 1–100. Which scale is used depends on the purpose of the test. In certain contexts there are no statistically significant differences between ratings for the same stimuli when they are obtained using different scales.\n\nThe MOS is calculated as the arithmetic mean over single ratings performed by human subjects for a given stimulus in a subjective quality evaluation test. Thus:\n\nWhere are the individual ratings for a given stimulus by subjects.\n\nThe MOS is subject to certain mathematical properties and biases. In general, there is an ongoing debate on the usefulness of the MOS to quantify Quality of Experience in a single scalar value.\n\nWhen the MOS is acquired using a categorical rating scales, it is based on – similar to Likert scales – an ordinal scale. In this case, the ranking of the scale items is known, but their interval is not. Therefore, it is mathematically incorrect to calculate a mean over individual ratings in order to obtain the central tendency; the median should be used instead. However, in practice and in the definition of MOS, it is considered acceptable to calculate the arithmetic mean.\n\nIt has been shown that for categorical rating scales (such as ACR), the individual items are not perceived equidistant by subjects. For example, there may be a larger “gap” between \"Good\" and \"Fair\" than there is between \"Good\" and \"Excellent\". The perceived distance may also depend on the language into which the scale is translated. However, there exist studies that could not prove a significant impact of scale translation on the obtained results.\n\nSeveral other biases are present in the way MOS ratings are typically acquired. In addition to the above-mentioned issues with scales that are perceived non-linearly, there is a so-called “range-equalization bias”: subjects, over the course of a subjective experiment, tend to give scores that span the entire rating scale. This makes it impossible to compare two different subjective tests if the range of presented quality differs. In other words, the MOS is never an absolute measure of quality, but only relative to the test in which it has been acquired.\n\nFor the above reasons – and due to several other contextual factors influencing the perceived quality in a subjective test – a MOS value should only be reported if the context in which the values have been collected in is known and reported as well. MOS values gathered from different contexts and test designs therefore should not be directly compared. ITU-T Recommendation P.800.2 prescribes how MOS values should be reported. Specifically, P.800.2 says:it is not meaningful to directly compare MOS values produced from separate experiments, unless those experiments were explicitly designed to be compared, and even then the data should be statistically analysed to ensure that such a comparison is valid.\n\nMOS historically originates from subjective measurements where listeners would sit in a \"quiet room\" and score a telephone call quality as they perceived it. This kind of test methodology had been in use in the telephony industry for decades and was standardized in ITU-T recommendation P.800. It specifies that “the talker should be seated in a quiet room with volume between 30 and 120 dB and a reverberation time less than 500 ms (preferably in the range 200–300 ms). The room noise level must be below 30 dBA with no dominant peaks in the spectrum.” Requirements for other modalities were similarly specified in ITU recommendations later.\n\nObtaining MOS ratings may be time-consuming and expensive as it requires the recruitment of human assessors. For various use cases such as codec development or service quality monitoring purposes – where quality should be estimated repeatedly and automatically – MOS scores can also be predicted by objective quality models, which typically have been developed and trained using human MOS ratings. A question that arises from using such models is whether the MOS differences produced are noticeable to the users. For example, when rating images on a five point MOS scale, an image with a MOS equal to 5 is expected to be noticeably better in quality than one with a MOS equal to 1. Contrary to that, it is not evident whether an image with a MOS equal to 3.8 is noticeably better in quality than one with a MOS equal to 3.6. Research conducted on determining the smallest MOS difference that is perceptible to users for digital photographs showed that a MOS difference of approximately 0.46 is required in order for 75% of the users to be able to detect the higher quality image. Nevertheless, image quality expectation, and hence MOS, changes over time with the change of user expectations. As a result, minimum noticeable MOS differences determined using analytical methods such as in may change over time.\n\n"}
{"id": "33206618", "url": "https://en.wikipedia.org/wiki?curid=33206618", "title": "Merle Leland Youngs", "text": "Merle Leland Youngs\n\nMerle Leland Youngs (December 2, 1886 - October 8, 1958) was the manufacturer of Trojan condoms in Trenton, New Jersey at Youngs Rubber. He was chairman of the board, treasurer and director. He was one of the first to advertise condoms to pharmacists and doctors. The brands were sold to Carter-Wallace and in 2001 to Church and Dwight.\n\nHe was born on December 2, 1886 in New York.\nHe died on October 8, 1958.\n"}
{"id": "48633932", "url": "https://en.wikipedia.org/wiki?curid=48633932", "title": "Neve Avot", "text": "Neve Avot\n\nNeve Avot (), also known as the Shoham Combined Centre for Geriatric Medicine (), is a geriatric hospital in Israel. The center is located on the northern outskirts of Pardes Hanna-Karkur, but is recognized as a separate locality. In 2015 it had a population of 141.\n\nThe hospital was established in 1948.\n\n"}
{"id": "5759277", "url": "https://en.wikipedia.org/wiki?curid=5759277", "title": "Ningishzida", "text": "Ningishzida\n\nNingishzida (\"sum: nin-g̃iš-zid-da\") is a Mesopotamian deity of vegetation and the underworld. Thorkild Jacobsen translates \"Ningishzida\" as Sumerian for \"lord of the good tree\".\n\nIn Sumerian mythology, he appears in Adapa's myth as one of the two guardians of Anu's celestial palace, alongside Dumuzi. He was sometimes depicted as a serpent with a human head.\n\nLagash had a temple dedicated to Ningishzida, and Gudea, \"patesi\" of Lagash in the 21st century BC (short chronology), was one of his devotees. In the Louvre, there is a famous green steatite vase carved for King Gudea of Lagash, dedicated by its inscription: \"To the god Ningiszida, his god Gudea, Ensi (governor) of Lagash, for the prolongation of his life, has dedicated this\".\n\nNingishzida is sometimes the son of Ninazu and Ningiridda, even though the myth Ningishzida's journey to the netherworld suggests he is the son of Ereshkigal. Following an inscription found at Lagash, he was the son of Anu, the heavens.\n\nHis wife is Azimua and also Geshtinanna, while his sister is Amashilama. In some texts Ningishzida is said to be female, which means \"Nin\" would then refer to Lady, which is mostly how the word is used by the Sumerians. He or she was one of the ancestors of Gilgamesh.\n\nThe Adapa myth mentions Ningishzida.\n\nThe death of vegetation is associated with the travel to the underworld of Ningishzida.\n\n\n\n\n"}
{"id": "6394976", "url": "https://en.wikipedia.org/wiki?curid=6394976", "title": "Nugent score", "text": "Nugent score\n\nThe Nugent Score is a Gram stain scoring system for vaginal swabs to diagnose bacterial vaginosis. The Nugent score is calculated by assessing for the presence of large Gram-positive rods (\"Lactobacillus\" morphotypes; decrease in \"Lactobacillus\" scored as 0 to 4), small Gram-variable rods (Gardnerella vaginalis morphotypes; scored as 0 to 4), and curved Gram-variable rods (Mobiluncus spp. morphotypes; scored as 0 to 2). A score of 7 to 10 is consistent with bacterial vaginosis without culture. The Nugent Score is now rarely used by physicians due to the time it takes to read the slides and requires the use of a trained microscopist. Bacterial vaginosis diagnosis is done by evaluating the pH, the presences of \"Lactobacillus spp.\" versus a mixed flora consisting of \"Gardnerella vaginalis, Bacteroides spp, Mobiluncus spp, and Mycoplasma hominis.\" Nugent's test for bacterial vaginosis is performed by measuring the pH, evaluating the presence of clue cells, white discharge an odor of amines after mixing with KOH. Prior to the development of Nugent's test, assessment of bacterial vaginosis was based on culturing \"G. vaginalis,\" examining a gram stain of vaginal discharge and gas chromatography.\n\nA score of 0-10 is generated from combining three other scores. The scores are as follows:\nAt least 10–20 high power (1000× oil immersion) fields are counted and an average determined.\n\nThe scoring system was proposed by R P Nugent in 1991. In the study, vaginal swabs were obtained from pregnant women.\n\n"}
{"id": "2872544", "url": "https://en.wikipedia.org/wiki?curid=2872544", "title": "Pain disorder", "text": "Pain disorder\n\nPain disorder is chronic pain experienced by a patient in one or more areas, and is thought to be caused by psychological stress. The pain is often so severe that it disables the patient from proper functioning. Duration may be as short as a few days or as long as many years. The disorder may begin at any age, and occurs more frequently in girls than boys. This disorder often occurs after an accident or during an illness that has caused pain, which then takes on a 'life' of its own.\n\nThe DSM-IV-TR specifies three coded subdiagnoses: pain disorder associated with psychological factors, pain disorder associated with both psychological factors and a general medical condition and pain disorder associated with a general medical condition (although the latter subtype is not considered a mental disorder and is coded separately within the DSM-IV-TR). Conditions such as dyspareunia, somatization disorder, conversion disorder, or mood disorders can eliminate pain disorder as a diagnosis. Diagnosis depends on the ability of physicians to explain the symptoms and on psychological influences.\n\nThere are, however, authors who propose that the diagnosis for unexplained pain should be adjustment disorder because it does not pathologize individuals with this medical condition. This is proposed to avoid the stigma of such illness classification.\n\nCommon symptoms of pain disorder are: negative or distorted cognition, such as feelings of despair or hopelessness; inactivity and passivity, in some cases disability; increased pain, sometimes requiring clinical treatment; sleep disturbance and fatigue; disruption of social relationships; depression and/or anxiety. Acute conditions last less than six months while chronic pain disorder lasts six or more months. There is no neurological or physiological basis for the pain. Pain is reported as more distressing than it should be had there been a physical explanation.\n\nPain behavior highlights the psychological aspect of pain disorder. This can be demonstrated how moderate pain symptoms become more painful when rewarded in the form of solicitous and attentive behavior of others, by monetary gain, or by the successful avoidance of distasteful activities. The same can be said about excessive worry. A minor physical symptom can be aggravated or become more harmful and threatening if the person suffering engages in a constant body and symptom appraisal, which can lead to stress and maladaptive behavior when coping with the physical symptom.\n\nAt least once a week, 10-30% of those under 18 years of age suffer from unexplainable headaches and abdominal pains in the United States, and the number is rising. People from collectivistic countries such as Japan, China, and Mexico are more likely to suffer from pain disorder than individualistic countries such as the US and Sweden.\n\nEthnicities show differences in how they express their discomfort and on how acceptable shows of pain and its tolerance are.\nMost obvious in adolescence, females suffer from this disorder more than males, and females reach out more.\nMore unexplainable pains occur as people get older. Typically, younger children complain of only one symptom, commonly abdominal pains or headaches. The older they get, the more varied the pain location as well as more locations and increasing frequency.\n\n\nThe prognosis is worse when there are more areas of pain reported. Treatment may include psychotherapy (with cognitive-behavioral therapy or operant conditioning), medication (often with antidepressants but also with pain medications), and sleep therapy. According to a study performed at the Leonard M. Miller School of Medicine, antidepressants have an analgesic effect on patients suffering from pain disorder. In a randomized, placebo-controlled antidepressant treatment study, researchers found that \"antidepressants decreased pain intensity in patients with psychogenic pain or somatoform pain disorder significantly more than placebo\". Prescription and nonprescription pain medications do not help and can actually hurt if the patient suffers side effects or develops an addiction. Instead, antidpressants and talk therapy are recommended. CBT helps patients learn what worsens the pain, how to cope, and how to function in their life while handling the pain. Antidepressants work against the pain and worry. Unfortunately, many people do not believe the pain \"is all in their head,\" so they refuse such treatments. Other techniques used in the management of chronic pain may also be of use; these include massage, transcutaneous electrical nerve stimulation, trigger point injections, surgical ablation, and non-interventional therapies such as meditation, yoga, and music and art therapy.\n\nThere are also interventions called pain control programs that involve the removal of patients from their usual settings to a clinic or facility that provides inpatient or outpatient treatments. These include multidisciplinary or multimodal approaches, which use combinations of cognitive, behavior, and group therapies.\n\nBefore treating a patient, a psychologist must learn as many facts as possible about the patient and the situation. A history of physical symptoms and a psychosocial history help narrow down possible correlations and causes. Psychosocial history covers the family history of disorders and worries about illnesses, chronically ill parents, stress and negative life events, problems with family functioning, and school difficulties (academic and social).\nThese indicators may reveal whether there is a connection between stress-inducing events and an onset or increase in pain, and the removal in one leading to the removal in the other. They also may show if the patient gains something from being ill and how their reported pain matches medical records.\nPhysicians may refer a patient to a psychologist after conducting medical evaluations, learning about any psychosocial problems in the family, discussing possible connections of pain with stress, and assuring the patient that the treatment will be a combination between medical and psychological care. Psychologists must then do their best to find a way to measure the pain, perhaps by asking the patient to put it on a number scale. Pain questionnaires, screening instruments, interviews, and inventories may be conducted to discover the possibility of somatoform disorders. Projective tests may also be used.\n\nEarly intervention when pain first occurs or begins to become chronic offers the best opportunity for prevention of pain disorder.\n\n"}
{"id": "40693962", "url": "https://en.wikipedia.org/wiki?curid=40693962", "title": "Ploughing match", "text": "Ploughing match\n\nA ploughing match is a contest between people who each plough part of a field. Nowadays there are usually classes for horse-drawn ploughs and for tractor ploughing. Points are awarded for straightness and neatness of the resulting furrows..\n\nThe annual 3-day long Irish National Ploughing Championships has grown into one of the largest outdoor events in the world, with commercial exhibits and a significant national media presence.\n\nIn Ontario, the International Plowing Match is an important rural event.\n\n"}
{"id": "46218821", "url": "https://en.wikipedia.org/wiki?curid=46218821", "title": "Polish Medical Association", "text": "Polish Medical Association\n\nPolish Medical Association (Polish: \"Polskie Towarzystwo Lekarskie\") is a scientific society created in 1951, bringing together physicians of different specialties. The society refers to the tradition of medical societies in Vilnius (\"Towarzystwo Lekarskie Wileńskie\", from 1805) and Warsaw (\"Towarzystwo Lekarskie Warszawskie\", from 1820).\n\nThe president of Polish Medical Association is Professor Waldemar Kostewicz. In the structure of the Society, there are branches, circles and sections and the main seat is in Warsaw.\n\n"}
{"id": "2190913", "url": "https://en.wikipedia.org/wiki?curid=2190913", "title": "Prenatal development", "text": "Prenatal development\n\nPrenatal development () is the process in which an embryo and later fetus develops during gestation. Prenatal development starts with fertilization, the first stage in embryogenesis which continues in fetal development until birth.\n\nIn human pregnancy, prenatal development, also known as antenatal development, is the development of the embryo following fertilization, and continued as fetal development. By the end of the tenth week of gestational age the embryo has acquired its basic form and is referred to as a fetus. The next period is that of fetal development where many organs become fully developed. This fetal period is described both topically (by organ) and chronologically (by time) with major occurrences being listed by gestational age.\n\nIn other animals the very early stages of embryogenesis are the same as those in humans. In later stages, development across all taxa of animals and the length of gestation vary.\n\nDifferent terms are used to describe prenatal development, meaning development before birth. A term with the same meaning is the \"antepartum\" (from Latin \"ante\" \"before\" and \"parere\" \"to give birth\") Sometimes \"antepartum\" is however used to denote the period between the 24th/26th week of gestational age until birth, for example in antepartum hemorrhage.\n\nThe perinatal period (from Greek \"peri\", \"about, around\" and Latin \"nasci\" \"to be born\") is \"around the time of birth\". In developed countries and at facilities where expert neonatal care is available, it is considered from 22 completed weeks (usually about 154 days) of gestation (the time when birth weight is normally 500 g) to 7 completed days after birth. In many of the developing countries the starting point of this period is considered 28 completed weeks of gestation (or weight more than 1000 g).\n\nWhen semen is released into the vagina, the spermatozoa travel through the cervix and body of the uterus and into the Fallopian tubes. Fertilization of the egg cell (ovum), usually takes place in one of the Fallopian tubes. Many sperm are released with the possibility of just one sperm cell managing to adhere to and enter the thick protective shell-like layer surrounding the ovum. The first sperm that penetrates fully into the egg donates its genetic material (DNA). The egg then polarizes, repelling any additional sperm. The resulting combination is called a zygote, a new and genetically unique organism. The term \"conception\" refers variably to either fertilization or to formation of the conceptus after its implantation in the uterus, and this terminology is controversial.\n\nPrior to fertilization, each ovum, as a gamete, contains half of the genetic material that will fuse with the male gamete, which carries the other half of the genetic material (DNA). The ovum only carries the X female sex chromosome whilst the sperm carries a single sex chromosome of either an X or a male Y chromosome. The resulting human zygote is similar to the majority of somatic cells because it contains two copies of the genome in a diploid set of chromosomes. One set of chromosomes came from the nucleus of the ovum and the second set from the nucleus of the sperm.\n\nThe zygote is male if the egg is fertilized by a sperm that carries a Y chromosome, and it is female if the egg is fertilized by a sperm that carries an X chromosome. The Y chromosome contains a gene, SRY, which will switch on androgen production at a later stage, leading to the development of a male body type. In contrast, the mitochondrial genetic information of the zygote comes entirely from the mother via the ovum.\n\nThe embryonic period in humans begins at fertilization (penetration of the egg by the sperm) and continues until the end of the 10th week of gestation (8th week by embryonic age). The period of two weeks from fertilization is also referred to as the germinal stage.\n\nThe embryo spends the next few days traveling down the Fallopian tube. It starts out as a single cell zygote and then divides several times to form a ball of cells called a morula. Further cellular division is accompanied by the formation of a small cavity between the cells. This stage is called a blastocyst. Up to this point there is no growth in the overall size of the embryo, as it is confined within a glycoprotein shell, known as the zona pellucida. Instead, each division produces successively smaller cells.\n\nThe blastocyst reaches the uterus at roughly the fifth day after fertilization. It is here that lysis of the zona pellucida occurs. This process is analogous to zona hatching, a term that refers to the emergence of the blastocyst from the zona pellucida, when incubated in vitro. This allows the trophectoderm cells of the blastocyst to come into contact with, and adhere to, the endometrial cells of the uterus. The trophectoderm will eventually give rise to extra-embryonic structures, such as the placenta and the membranes. The embryo becomes embedded in the endometrium in a process called implantation. In most successful pregnancies, the embryo implants 8 to 10 days after ovulation. The embryo, the extra-embryonic membranes, and the placenta are collectively referred to as a conceptus, or the \"products of conception\".\n\nRapid growth occurs and the embryo's main features begin to take form. This process is called differentiation, which produces the varied cell types (such as blood cells, kidney cells, and nerve cells). A spontaneous abortion, or miscarriage, in the first trimester of pregnancy is usually due to major genetic mistakes or abnormalities in the developing embryo. During this critical period (most of the first trimester), the developing embryo is also susceptible to toxic exposures, such as:\n\n\nFrom the 10th week of gestation (8th week of development), the developing organism is called a fetus.\n\nAll major structures are already formed in the fetus, but they continue to grow and develop.\n\nSince the precursors of all the major organs are created by this time, the fetal period is described both by organ and by a list of changes by weeks of gestational age.\n\nBecause the precursors of the organs are now formed, the fetus is not as sensitive to damage from environmental exposure as the embryo was. Instead, toxic exposure often causes physiological abnormalities or minor congenital malformation.\n\nDevelopment continues throughout the life of the embryo and fetus and through into life after birth. Significant changes occur to many systems in the period after birth as they adapt to life outside the uterus.\n\nFetal hematopoiesis first takes place in the yolk sac. The function is transferred to liver by 10th week of gestation and to spleen and bone marrow beyond that. The total blood volume is about 125 ml/kg fetal body weight near term.\n\nFetus produces megaloblastic red blood cells early in development, which become normoblastic near term. Life span of fetal RBCs is 80 days. Rh antigen appears at about 40 days of gestation.\n\nFetus starts producing leukocytes at 2 months gestation mainly from thymus and spleen. Lymphocytes derived from thymus are called T lymphocytes, whereas the ones derived from bone marrow are called B lymphocytes. Both these populations of lymphocytes have short-lived and long-lived groups. Short-lived T lymphocytes usually reside in thymus, bone marrow and spleen; whereas long-lived T lymphocytes reside in blood stream. Plasma cells are derived from B lymphocytes and their life in fetal blood is 0.5 to 2 days.\n\nThyroid gland is the first to develop in fetus at 4th week of gestation. Insulin secretion in fetus starts around 12th week of gestation.\n\nInitial knowledge of the effects of prenatal experience on later neuropsychological development originates from the Dutch Famine Study, which researched the cognitive development of individuals born after the Dutch famine of 1944–45. The first studies focused on the consequences of the famine to cognitive development, including the prevalence of mental retardation. Such studies predate David Barker's hypothesis about the association between the prenatal environment and the development of chronic conditions later in life. The initial studies found no association between malnourishment and cognitive development, but later studies found associations between malnourishment and increased risk for schizophrenia, antisocial disorders, and affective disorders.\n\nThere is evidence that the acquisition of language beings in the prenatal stage. After 26 weeks of gestation, the peripheral auditory system is already fully formed. Also, most low-frequency sounds (less than 300 HZ) can reach the fetal inner ear in the womb of mammals. Those low-frequency sounds include pitch, rhythm, and phonetic information related to language. Furthermore, there is evidence of language learning during gestation. Studies have indicated that fetuses react to and recognize differences between sounds. Such ideas are further reinforced by the fact that newborns present a preference for their mother’s voice, present behavioral recognition of stories only heard during gestation, and (in monolingual mothers) present preference for their native language. A more recent study with EEG demonstrated different brain activation in newborns hearing their native language compared to when they were presented with a different language, further supporting the idea that language learning starts while in gestation.\n\nThe fetus passes through 3 phases of acquisition of nutrition from the mother:\n\nGrowth rate of fetus is linear up to 37 weeks of gestation, after which it plateaus. The growth rate of an embryo and infant can be reflected as the weight per gestational age, and is often given as the weight put in relation to what would be expected by the gestational age. A baby born within the normal range of weight for that gestational age is known as appropriate for gestational age (AGA). An abnormally slow growth rate results in the infant being small for gestational age, and, on the other hand, an abnormally large growth rate results in the infant being large for gestational age. A slow growth rate and preterm birth are the two factors that can cause a low birth weight. Low birth weight (below 2000 grams) can ultimately increase the likelihood of schizophrenia by almost four times. \n\nThe growth rate can be roughly correlated with the fundal height which can be estimated by abdominal palpation. More exact measurements can be performed with obstetric ultrasonography.\n\nIntrauterine growth restriction is one of the causes of low birth weight associated with over half of neonatal deaths.\nPoverty has been linked to poor prenatal care and has been an influence on prenatal development. Women in poverty are more likely to have children at a younger age, which results in low birth weight. Many of these expecting mothers have little education and are therefore less aware of the risks of smoking, drinking alcohol, and drug use – other factors that influence the growth rate of a fetus. \n\nWomen between the ages of 16 and 35 have a healthier environment for a fetus than women under 16 or over 35. Women between this age gap are more likely to have fewer complications. Women over 35 are more inclined to have a longer labor period, which could potentially result in death of the mother or fetus. Women under 16 and over 35 have a higher risk of preterm labor (premature baby), and this risk increases for women in poverty, African Americans, and women who smoke. Young mothers are more likely to engage in high risk behaviors, such as using alcohol, drugs, or smoking, resulting in negative consequences for the fetus. Premature babies from young mothers are more likely to have neurological defects that will influence their coping capabilities – irritability, trouble sleeping, constant crying for example. There is a risk of Down syndrome for infants born to those aged over 40 years. Young teenaged mothers (younger than 16) and mothers over 35 are more exposed to the risks of miscarriages, premature births, and birth defects.\n\nAn estimated 5 percent of fetuses in the United States are exposed to illicit drug use during pregnancy. Maternal drug use occurs when drugs ingested by the pregnant woman are metabolized in the placenta and then transmitted to the fetus. When using drugs (narcotics), there is a greater risk of birth defects, low birth weight, and a higher rate of death in infants or stillbirths. Drug use will influence extreme irritability, crying, and risk for SIDS once the fetus is born. The chemicals in drugs can cause an addiction in the babies once they are born. Marijuana will slow the fetal growth rate and can result in premature delivery. It can also lead to low birth weight, a shortened gestational period and complications in delivery. Heroin will cause interrupted fetal development, stillbirths, and can lead to numerous birth defects. Heroin can also result in premature delivery, creates a higher risk of miscarriages, result in facial abnormalities and head size, and create gastrointestinal abnormalities in the fetus. There is an increased risk for SIDS, dysfunction in the central nervous system, and neurological dysfunctions including tremors, sleep problems, and seizures. The fetus is also put at a great risk for low birth weight and respiratory problems. Cocaine use results in a smaller brain, which results in learning disabilities for the fetus. Cocaine puts the fetus at a higher risk of being stillborn or premature. Cocaine use also results in low birthweight, damage to the central nervous system, and motor dysfunction.\n\nMaternal alcohol use leads to disruptions of the fetus's brain development, interferes with the fetus's cell development and organization, and affects the maturation of the central nervous system. Even small amounts of alcohol use can cause lower height, weight and head size at birth and higher aggressiveness and lower intelligence during childhood. Fetal alcohol spectrum disorder is a developmental disorder that is a consequence of heavy alcohol intake by the mother during pregnancy. Children with FASD have a variety of distinctive facial features, heart problems, and cognitive problems such as developmental disabilities, attention difficulties, and memory deficits. \n\nWhen a mother smokes during pregnancy the fetus is exposed to nicotine, tar, and carbon monoxide. Nicotine results in less blood flow to the fetus because it constricts the blood vessels. Carbon monoxide reduces the oxygen flow to the fetus. The reduction of blood and oxygen flow may result in miscarriage, stillbirth, low birth weight, and premature births. Exposure to secondhand smoke leads to higher risks of low birth weight and childhood cancer.\n\nIf a mother is infected with a disease, the placenta cannot always filter out pathogens. Viruses such as rubella, chicken pox, mumps, herpes, and human immunodeficiency (HIV) are associated with increased risk of miscarriage, low birth weight, and prematurity, physical malformations, and intellectual disabilities. The human immunodeficiency virus can lead to acquired immune deficiency syndrome (AIDS). Untreated HIV infected expectant mothers pass the virus to their developing offspring between 10 and 20 percent of the time. . Expectant mothers infected with bacterial or parasitic diseases may also pass the diseases on to the fetus. Examples of diseases include chlamydia, syphilis, tuberculosis, malaria, and toxoplasmosis. One of the most common of these diseases is toxoplasmosis. A pregnant female may become infected through contact with contaminated soil, such as through gardening, eating raw or undercooked meat or unwashed vegetables or fruits, or contact with the feces of infected cats. If the exposure occurs during the first trimester, eye and brain damage may result. Exposure later in pregnancy may result in mild visual and cognitive impairments. \n\nAdequate nutrition is needed for a healthy fetus. Mothers who gain less than 20 pounds during pregnancy are at increased risk for having a preterm or low birth weight infant. . Iron and iodine are especially important during prenatal development. Mothers who are deficient in iron are at risk for having a preterm or low birth weight infant. Iodine deficiencies increase the risk of miscarriage, stillbirth, and fetal brain abnormalities Adequate prenatal care gives an improved result in the newborn.\n\nLow birth weight increases an infants risk of long-term growth and cognitive and language deficits. It also results in a shortened gestational period and can lead to prenatal complications.\n\nStress during pregnancy can impact the development of the embryo. Reilly (2017) states that stress can come from many forms of life events such as community, family, financial issues, and natural causes. While a woman is pregnant, stress from outside sources can take a toll on the growth in the womb that may affect the child’s learning and relationships when born. For instance, they may have behavioral problems and might be antisocial. The stress that the mother experiences affects the fetus and the fetus’ growth which can include the fetus’ nervous system (Reilly, 2017). Stress can also lead to low birth weight. Even after avoiding other factors like alcohol, drugs, and being healthy, stress can have its impacts whether families know it or not. Many women who deal with maternal stress do not seek treatment.\nSimilar to stress, Reilly stated that in recent studies, researchers have found that pregnant women who show depressive symptoms are not as attached and bonded to their child while it is in the womb (2017). \n\nExposure to environmental toxins in pregnancy lead to higher rates of miscarriage, sterility, and birth defects. Toxins include fetal exposure to lead, mercury, and ethanol or hazardous environments. Prenatal exposure to mercury may lead to physical deformation, difficulty in chewing and swallowing, and poor motoric coordination. Exposure to high levels of lead prenatally is related to prematurity, low birth weight, brain damage, and a variety of physical defects. Exposure to persistent air pollution from traffic and smog may lead to reduced infant head size, low birth weight, increased infant death rates, impaired lung and immune system development. \n\n\n\n"}
{"id": "11456995", "url": "https://en.wikipedia.org/wiki?curid=11456995", "title": "Public health intervention", "text": "Public health intervention\n\nA public health intervention is any effort or policy that attempts to improve mental and physical health on a population level. Public health interventions may be run by a variety of organizations, including governmental health departments and non-governmental organizations (NGOs). Common types of interventions include screening programs, vaccination, food and water supplementation, and health promotion. Common issues that are the subject of public health interventions include obesity, drug, tobacco, and alcohol use, and the spread of infectious disease, e.g. HIV.\n\nA policy may meet the criteria of a public health intervention if it prevents disease on both the individual and community level and has a positive impact on public health.\n\nHealth interventions may be run by a variety of organizations, including health departments and private organizations. Such interventions can operate at various scales, such as on a global, country, or community level. The whole population can be reached via websites, audio/video messages and other mass media, or specific groups can be affected by administrative action, such as increasing the provision of healthy food at schools.\n\nScreening refers to the practice of testing a set of individuals who meet a certain criteria (such as age, sex, or sexual activity) for a disease or disorder. Many forms of screening are public health interventions. For example, mothers are routinely screened for HIV and Hepatitis B during pregnancy. Detection during pregnancy can prevent maternal transmission of the disease during childbirth.\n\nVaccination programs are one of the most effective and common types of public health interventions. Typically programs may be in the form of recommendations or run by governmental health departments or nationalised health care systems. For instance, in the U.S., the Center for Disease Control decides on a vaccination schedule, and most private health insurers cover these vaccinations. In the UK, the NHS both decides and implements vaccination protocols. NGOs may also may be involved in funding or implementing vaccination programs; for instance Bill and Melinda Gates Foundation assists governments in Pakistan, Nigeria and Afghanistan with the administration of polio vaccination.\n\nSupplementation of food or water of nutrients can reduce vitamin deficiency and other diseases. Supplementation may be required by law or voluntary. Some examples of interventions include:\n\n\nInterventions intended to change the behaviour of individuals can be especially challenging. One such form is health promotion, where education and media may be used to promote healthy behaviours, such as eating healthy foods (to prevent obesity), using condoms (to prevent the transmission of STDs), or stopping open defecation in developing countries (see for example in India the campaign Swachh Bharat mission).\n\nThe use of laws to criminalise certain behaviours can also be considered a public health intervention, such as mandatory vaccination programs and criminalisation of HIV transmission. However, such measures are typically controversial, particularly in the case of HIV criminalisation where there is evidence it may be counter productive. Laws which tax certain unhealthy products may also be effective, although also not without controversy, and are sometimes called a \"sin tax\". Examples include the taxation of tobacco products in the U.S. and New Zealand, and sugared drinks in the UK.\n\nEvaluating and predicting the efficacy of a public health intervention, as well as calculating cost effectiveness, is essential. An intervention should ideally lower morbidity and mortality. Several systematic protocols exist to assist developing such interventions, such as Intervention Mapping.\n\n"}
{"id": "25825448", "url": "https://en.wikipedia.org/wiki?curid=25825448", "title": "Rita Pitka Blumenstein", "text": "Rita Pitka Blumenstein\n\nRita Pitka Blumenstein (born 1936) was the first certified traditional doctor in Alaska. She works for the Alaska Native Tribal Health Consortium. Blumenstein has been a member of the International Council of 13 Indigenous Grandmothers—a group of spiritual elders, medicine women and wisdom keepers—since its founding in 2004.\n\nBorn to her recently widowed mother who lived in the village of Tununak, Nelson Island, Alaska, Blumenstein was born while her mother was in a fishing boat. Blumenstein felt angry not having her father around when she was a girl, because he died a month before she was born.\n\nBlumenstein was given a Yup'ik name means 'Tail End Clearing of the Pathway to the Light'—Rita sees the poetry in the name as she regards herself as being born during \"the tail end of the old ways\".\n\nBlumenstein's healing abilities were recognised by the wise elders (grandmothers) of her tribe from an early age. Blumenstein began healing at the age of 4.\n\nAt the age of 9, Blumenstein's great-grandmother gave her thirteen eagle feathers and thirteen stones to give to the International Council of 13 Indigenous Grandmothers. Years later, when the International Council of 13 Indigenous Grandmothers convened for the first time, Blumenstein passed out these precious objects to the rest of the members with tears in her eyes.\n\nBlumenstein was married to her husband, a Jewish man, for 43 years. Five of Blumenstein's 6 children have also died. Blumenstein's own health has not always been good and in 1995, she found that she had cancer. Blumenstein saw that being diagnosed with cancer made her realise that she needed to heal herself at a 'deeper' level—concluding that the cancer was due to being angry that her father had not been present in her early years. Blumenstein is training her granddaughter to follow in her footsteps in order to be a healer and to know their Yup'ik traditions.\n\nAfter Blumenstein started healing people from the age of 4. She \"worked at many hospitals delivering babies as a doctor's aide in Bethel and Nome\". Rita carried on learning from her elders to become the first certified traditional doctor in Alaska and presently works for the Alaska Native Tribal Health Consortium.\n\nBlumenstein has taught in over 150 countries on cultural issues, basket weaving, song, and dance, \"earning money for Native American Colleges\". Her teachings about the \"Talking circle\" have been published.\n\nIn 2004, Blumenstein was approached by The Center for Sacred Studies to serve on the International Council of 13 Indigenous Grandmothers. The Council has been active in protecting indigenous rights and medicines, and traditional teachings on wisdom.\n\nShe was interviewed on her work with the Council by the Women Rising Radio Project in 2011.\n\nIn 2006 both Blumenstein's tribe, the Yup'ik and her mayor declared the 18 February to be Rita Pitka Blumenstein day.\n\nIn 2009, Blumenstein was one of fifty women inducted into the inaugural class of the Alaska Women's Hall of Fame.\n\n\n"}
{"id": "1028100", "url": "https://en.wikipedia.org/wiki?curid=1028100", "title": "Sit-up", "text": "Sit-up\n\nThe sit-up (or curl-up) is an abdominal endurance training exercise to strengthen and tone the abdominal muscles. It is similar to a crunch (crunches target the rectus abdominis and also work the external and internal obliques), but sit-ups have a fuller range of motion and condition additional muscles.\n\nIt begins with lying with the back on the floor, typically with the arms across the chest or hands behind the head and the knees bent in an attempt to reduce stress on the back muscles and spine, and then elevating both the upper and lower vertebrae from the floor until everything superior to the buttocks is not touching the ground. Some argue that situps can be dangerous due to high compressive lumbar load and may be replaced with the crunch in exercise programs.\n\nStrength exercises such as sit-ups and push-ups do not cause the spot reduction of fat. Gaining a \"six pack\" requires both abdominal muscle hypertrophy training and fat loss over the abdomen—which can only be done by losing fat from the body as a whole.\n\nThe movement can be made easier by placing the arms further down away from the head. Typical variations to achieve this include crossing the arms to place the palms on the front of the shoulders and extending the arms down to the sides with palms on the floor. The 'arms on shoulders' variation is also used to make the incline sit-up easier.\n\nMore intense movement is achieved by doing weighted sit-ups, incline sit-ups with arms behind neck and even harder by doing the weighted incline sit-up.\n\nFull sit-ups may cause back pain and arching of the lower back, increasing the risk of back injury. Many experts advise against doing sit-ups.\n\n"}
{"id": "6760075", "url": "https://en.wikipedia.org/wiki?curid=6760075", "title": "Social therapy", "text": "Social therapy\n\nSocial therapy is an activity-theoretic practice developed outside of academia at the East Side Institute for Group and Short Term Psychotherapy in New York. Its primary methodologists are cofounders of the East Side Institute, Fred Newman and Lois Holzman. In evolution since the late 1970s, the social therapeutic approach to human development and learning is informed by a variety of intellectual traditions especially the works of Karl Marx, Lev Vygotsky and Ludwig Wittgenstein. \n\nRecently, however, the idea of social therapy is being challenged by an organization called Project Toe. Co-founder Mike Bardi challenges the assumption that social therapy is strictly group therapy. He argues that social therapy is more about, \"empowering people to help one another.\" Group therapy is a form of social therapy, but with the evolution of technology, social therapy is evolving into other forms. These forms include Internet, online therapy, non-professional therapy, and many other forms that redefine the therapeutic process.\n\nAlternatively, the term \"social therapy, as used in the Camphill Movement at Camphill communities, is used to label a professional discipline inspired by Rudolf Steiner, a philosopher, teacher and the founder of anthroposophy, and put into practice by Karl König. At its heart is the concept that a healthy social environment is essential for adults with developmental disabilities to live productive, independent, and joyful lives. A healthy social environment is cultivated through community where all members make a contribution according to their ability. Establishing necessary spiritual, social and physical conditions for this form of community to thrive is the art and science of social therapy.\n\nThe training in social therapy provides practical, emotional, psychological and spiritual tools and insights necessary for living and working with developmentally disabled adults.\n\nSocial therapy is primarily a group-oriented approach. Its practitioners relate to the group, rather than individuals, as the fundamental unit of development. Social therapy is also premised on an understanding of human beings as fundamentally performers. This is in contrast to more traditional forms of therapy that relate to and understand human beings through the lens of behavior. Social therapy shares family resemblances with narrative therapy and the postmodern therapies.\n\nIn 1977, Dennis King, writing for \"Heights and Valley News\", penned an article which alleged Newman was the leader of a \"therapy cult.\"[30] \"The Public Eye\" magazine also carried an article in late 1977 making this claim, though it was primarily directed at Lyndon LaRouche's NCLC (with which Newman was no longer affiliated).[31] At the time, Newman responded that, \"it is of the greatest importance that the entire community of social scientists insist that there be open and critical discussion and dialogue towards the advancement and development of the human sciences; that as scientists and as professionals we do not quiver and shake under the socio-pathological and essentially anti-communist rampages of a Dennis King or others like him.\"[32] Cult allegations arose again a few years later in the \"Village Voice\".[33]\n\nWhen political researcher Chip Berlet became editor of \"The Public Eye\" magazine in 1984, he first announced that the magazine no longer held to that characterization:\n\n\"As you will learn from a forthcoming article on Fred Newman and the IWP, the Public Eye no longer feels it is accurate to call Newman's political network a cult. We do feel that at one point in its development it was fair to characterize the group as a cult, and we still have strong criticisms of the group's organizing style and the relationship between Newman's Therapy Institute and his political organizing.\" (Editor's Note, Public Eye, 1984; Vol. 4, Nos. 3-4)\n\nSocial therapy has influenced youth development, most notably supplemental education. The All Stars Project, founded by social therapist Fred Newman and developmental psychologist Lenora Fulani in 1981 produced a variety of programs inspired by social therapy. The All Stars Talent Show Network, an anti-violence program in cities around the United States and in Europe, engages young people in the production of talents shows. Social therapy has also influenced youth development in the arena of school mental health. Social therapy can be considered psychotherapy.\n\n\n\n\n\n"}
{"id": "6730884", "url": "https://en.wikipedia.org/wiki?curid=6730884", "title": "St John Ambulance (England)", "text": "St John Ambulance (England)\n\nSt John Ambulance is a volunteer-led, charitable non-governmental organisation dedicated to the teaching and practice of first aid in England. Along with St John Cymru Wales and St John Ambulance Northern Ireland, St John Ambulance is one of three affiliates of the international St John movement in the United Kingdom.\n\nThe St John Ambulance Association was founded in 1877 to provide first aid training. In 1887, the St John Ambulance Brigade was founded to provide uniformed medics at public events. In 1968, the two were merged into the present foundation. The organisation is a subsidiary of the England and the Islands priory (i.e. branch) of the Order of St John. Until 2012, it also managed St John Ambulance services in the Isle of Man and Channel Islands.\n\nThe St John Ambulance Association was set up in 1877 by the Venerable Order of Saint John to teach industrial workers first aid, so that they could provide on-the-spot treatment in emergencies. Workers rarely had ready access to a doctor in 19th century workplaces, and since accidents were frequent, death or disability from injuries were common. The St John Ambulance Association set up training sessions across the country, particularly in workplaces in areas of heavy industry, but also in villages, seaside towns and suburban areas.\n\nIn 1887, trained volunteers were organised into a uniformed Brigade to provide a first aid and ambulance service at public events. In many parts of England (and in parts of Scotland, until 1908), St John Ambulance was the first and only provider of an ambulance service right up to the middle of the 20th century, when the National Health Service was founded. When there were far fewer doctors and hospital beds than today, St John Ambulance nurses looked after the sick and injured in their own homes.\n\nThe St John Ambulance Brigade and St John Ambulance Association merged in 1968 to form St John Ambulance, a single organisation providing both training and first aid cover.\n\nDuring 2013, St John Ambulance trained approximately 278,000 adults through its workplace and community first aid programmes, and directly trained 91,000 schoolchildren. St John Ambulance personnel attended 45,000 public events, treating approximately 102,000 individuals. It also distributed 100,000 free first aid guides nationwide and its free smartphone app was downloaded by 148,000 people.\n\n\nSt John Ambulance provides first aid cover at thousands of events every year. This service is provided free at the point of delivery, although a charge may be made to the event organiser for provision of the service at their event.\n\nIn addition to providing volunteer first aiders for events, where necessary St John Ambulance can provide paramedics, doctors, nurses and cycle responders, as well as mobile treatment centres, ambulances and other medical provision. Alongside support functions including command & control vehicles and incident catering units.\n\nThe organisation covers many major events across England including the London Marathon and Hyde Park concerts, as well as smaller and charitable events such as fetes and local fairs.\n\nSt John Ambulance runs courses in first aid and health & safety for members of the public, training 254,000 people in 2013. Its \"First aid at work\" course is used by many companies to train designated individuals as first-aiders, as required by employment laws; specialist training is also available, including courses for schools staff and people working with children, and professional drivers.\n\nCharitable \"Community first aid\" courses also offer people of all ages the chance to learn basic first aid skills at little or no charge. In 2013, 24,000 people attended these courses.\n\nSt John Ambulance teaches first aid to thousands of young people, through programmes including Badgers (for seven- to ten-year-olds), Cadets (10 to 17-year-olds), LINKS (based in colleges and universities) and RISE, a specialist project aimed at those not in education, employment or training. \n\nCadets volunteer alongside their adult counterparts on events, making St John Ambulance the only youth organisation to have their young people utilizing their skills in the \"real world\" with real patients.\n\nIn 2013, 91,000 schoolchildren were trained in first aid by St John Ambulance's schools team, while hundreds of thousands more had access to the organisation's training materials for schools, which are available to download for free from its \"Teach the difference\" website.\n\nIn 2014, the organisation also launched The Big First Aid Lesson, a free first aid lesson, which was streamed live into classrooms across England. 32,384 students took part in the inaugural event. Events took place the following 3 years. The Big First Aid Lesson was not held in 2018, to allow the team to focus on promoting first aid as part of the national curriculum.\n\nSt John Ambulance Badgers work towards the 'Super Badger Award'. This award consists of members completing 12 subjects, such as 'Creative', 'Global' and 'Wild' Badger. The award is split into five sections, where Badgers advance through completing more subjects. Badgers who achieve their Super Badger receive a ceramic trophy of Bertie Badger, the Badger mascot, dressed in the original Badger uniform. The programme was completely reviewed, redesigned in 2016 and was launched in 2017, coinciding with the 30th anniversary of the formation of Badgers.\n\nThe Grand Prior Award is the primary award designed for cadets. The award is an essential part of Cadet life, and consists of completion of 24 subject areas over the period of Cadet membership, until the age of 18. The programme started being reviewed and updated in early 2017 and is due for release in mid-2019.\n\nThe Amalfi Award was open to all Cadets and adult volunteers aged 16 to 25. The structure of the award focussed on personal task set by the individual. These tasks were categorised into service, relationships, society and challenge. Each participant had to undertake 12 tasks and at completion of 4, 8 and 12 subjects a badge was awarded. The Amalfi Challenge is discontinued in England.\n\nThe Sovereign’s Award is the premier achievement for young people, 16-25, within the Order of St John worldwide. The award, which includes a certificate personally signed by the Sovereign Head of the Order, Her Majesty Queen Elizabeth II, is given to young St John Ambulance volunteers in recognition of outstanding work in the areas of personal development, benefit to St John, and benefit to their community. The award is awarded to a maximum of 10 people worldwide, annually.\n\nThe awards are presented at the Young Achievers' Reception hosted by Her Royal Highness The Princess Royal, Commandant-in-Chief for Youth. The event is also attended by the National Cadet of the Year for England and the Islands, National Cadet of the Year for Cymru-Wales, Regional Cadets of the Year from England and the Islands, Deputy Cadet of the Year for Cymru-Wales, District Cadets of the Year and nominated young people, aged 7-17.\n\nSt John Ambulance units dedicated to meeting the needs of student and university communities can be found at many institutes of higher education across England. These units, known as LINKS units, were originally established at universities to form a 'link' between Cadets and adult volunteering, allowing people to stay affiliated to the organisation and maintain their skills while in higher education. However, LINKS units have become integral parts of the student community and the 90% of LINKS members are new to St John Ambulance at the point of joining, as students that are new to university look for societies to join.\n\nSt John Ambulance campaigns to raise awareness of the importance of first aid, and equip more people with life-saving skills. Its 2013 Save the Boy campaign, which featured an interactive element, demonstrating how to put a casualty in the recovery position, reached 15 million people through television and online media.\n\nIn January 2015, it launched a new campaign, The Chokeables, designed to teach parents how to treat a choking infant. The animated film featured the voices of actors John Hurt, David Walliams, Johnny Vegas and David Mitchell.\n\nDuring the annual Save a Life September campaign, St John Ambulance trainers hold free first aid demonstrations in public spaces around the country, handing out first aid guides to attendees. A free first aid app for smartphones is also available to download.\n\nBetween 9-16 October 2018, St John Ambulance was a nationwide-leader in the promotion of Restart A Heart Day 2018, overseen by the Resuscitation Council UK, on behalf of the European Resuscitation Council and the International Liaison Committee on Resuscitation. Alongside partner organisations, St John Ambulance trained over 200,000, over the two weeks, in emergency resuscitation.\n\nSt John Ambulance is a leading supplier of ambulance services in England, providing patient transport services to over 100,000 people year, and working in partnership with NHS trusts, private healthcare groups, local authorities and individuals.\n\nServices offered include A&E support, patient transport, bariatric transfer, paediatric and neonatal services, high-dependency transfers, planned journeys, repatriations, community first response and emergency response and major incident support.\n\nIn 2010, St John Ambulance was awarded the Private Ambulance Service Team of the Year Award by the Ambulance Services Institute for the work it carried out with the CATS (Great Ormond Street) and the South Thames Retrieval Service (Evelina Children's Hospital).\n\nSt John Ambulance Supplies (often abbreviated to SJS) is a trading sub-division of St John Ambulance providing first aid and medical equipment and consumables, training equipment, publications, health and safety equipment and clothing. Where a profit is made, surplus from sales are diverted into supporting the charitable work of the Order of St John and the St John Ophthalmic Hospital in Jerusalem.\n\nSJS opened its doors at St John’s Gate in Clerkenwell on 12 February 1879 and was originally known as The Stores Depot. It is now a major commercial operation supplying to the public, private and voluntary sector. The store is now only available online.\n\nAs individual (local) Divisions of St John Ambulance have historically been responsible for providing their own vehicles, these have taken many and varied forms, beginning with horse-drawn ambulances. Even into the late twentieth century, with some centralisation of control and classification of vehicle types such as Motor Ambulance Units (the title arising historically as a distinction from horse-drawn units), First Aid Posts and Rapid Deployment Vehicles, there remained within the organisation an enormous range of deployed vehicles of different types and even assorted local vehicle liveries. Some ambulances were donated second-hand from industrial plants, some were purchased (from different suppliers) and some were local conversions of commercial vehicles. At the start of the twenty-first century, new legislation regarding emergency ambulances effectively rendered a significant proportion of the then current St John Ambulance fleet redundant. The solution was the development of a specialist St John Ambulance vehicle, which was designed jointly by the organisation and vehicle manufacturer Renault. The result was the Crusader 900 ambulance.\n\nAn early assessment suggested that 100 of the Crusader ambulances (costing, at that time, £40,000 each) would be required immediately, representing an investment of £4 million. In 2000, St John Ambulance committed itself to raising £2 million by public subscription, whilst English and Welsh Freemasons committed a further £2 million, supplying 50 Crusader ambulances which were handed over in local ceremonies across the country during 2000 and 2001. This very large donation allowed the rapid transformation of the national St John Ambulance fleet of front-line ambulances within a much shorter time-scale than could otherwise have been possible. Subsequently, many local Provinces of Freemasons have maintained relations with their local St John Ambulance County units and supported the running costs of these vehicles or even donated further (additional) Crusader ambulances.\n\nBy 2004, the national St John Ambulance emergency vehicle fleet was in a standard corporate livery, with standard vehicle types:\n\n\nSt John Ambulance also maintains specialist response options in particular locations, such as Cycle Response Units, control and command units, as well as larger vehicles or trailers used as static first aid posts.\n\nThe majority of St John Ambulance's volunteers deliver first aid at events and as Community First Responders or work with young people as youth leaders. Other specialist roles are available for healthcare professionals, volunteer managers and in safeguarding, human resources, quality and assurance and health and safety.\n\nVolunteers receive training according to the role they fulfill. Those volunteering to provide Event First Aid services are offered a number of first aid qualifications, ranging from a basic emergency life support course and the further first aid modules, which deal with common injuries and ailments, through to Emergency Transport Attendant training which covers some of the competencies of the National Health Service Ambulance Technicians. \n\nThe training for those delivering Youth Services comprises emergency life support training, coupled with training from the organisation's own youth leader training suite including Essential skills in youth work and Leadership skills in youth work, depending on the volunteer's role.\n\nIn addition to medical training offered, members have the opportunity to carry out other operational roles. These include event planning, event management, radio communications/control, plus other support roles.\n\nQualified healthcare professionals may also volunteer their time in St John Ambulance including nurses, paramedics and doctors. All healthcare professionals have their qualifications and professional status checked with the appropriate regulatory body before practising in St John Ambulance. Professionals can carry out any skill appropriate to their type, level of training, competence and when relevant to the situation or patient. Healthcare professionals wear coloured rank slides to distinguish them from internally trained first aiders and ambulance personnel. \n\nWith the exception of Paramedics, any HCP wishing to work on an ambulance though must become a Patient Transport Attendant / Emergency Trasport Attendant, but parts of the training may be omitted if the candidate can attain accreditation of prior learning. This is dependent on the HCP's professional training already undertaken. This is to ensure that the HCP is prepared for working in an ambulance/emergency environment (which they may never have done).\n\nStudent HCPs who are on duty with an Event HCP (nurse, doctor or paramedic) may be mentored/supervised by that Event HCP to provide out of hospital care. However, they must undertake the same training in operational clinical practice as all other volunteers through First Aider to Emergency Trasport Attendant and can only operate on duty at events to the scope of their SJA training when working unsupervised, in absence of an event HCP.\n\nIn 2012, St John Ambulance was reorganised into a regional structure, with the goal of increasing accountability and maximising charitable outputs. Up until that point the organisation had been divided into 42 semi-autonomous counties.\n\nAs part of the reorganisation, a more streamlined structure was introduced, with fewer layers of management between the front-line and the St John Ambulance Board.\n\nThe current 4 regions are:\n\nEach region is managed by a paid regional director, and is responsible for the delivery of programmes developed and overseen by National Headquarters. All regions are accountable to the Care Quality Commission and are independently inspected by the CQC against 14 different outcomes, such as care and welfare of people who use the services, cleanliness and infection control and supporting workers.\n\nDuring regionalisation in 2012, St John Ambulance in Guernsey, Jersey and the Isle of Man became separate from England.\n\nThe region is divided into a number of districts. A district may contain one or more former \"counties\" from the previous structure and may only have part of a county in. Each district is managed by a district manager (volunteer), and area managers report to them. District managers are in overall charge of all activities in their district, assisted by the area managers. They have a support team of district specialists in place coordinating functions such as event cover and youth provision, but they have no line management responsibility and report to their respective regional departmental manager. Each district usually contains 3–6 areas.\n\nDistricts are further divided into geographic areas, led by an area manager (volunteer). Unit managers report to the area manager, and the area manager is in overall charge of the activities of the units in their area, within the boundaries of policies etc. set by Regional Headquarters (RHQ) and NHQ. They are assisted/advised by district specialists to provide the day-to-day functions of the organisation, such as member training and event cover. Each area contains about 8–15 units.\n\nA unit (formerly a \"division\") is the smallest administrative division of St John Ambulance. Most volunteers are managed within a unit and by a unit manager (volunteer). Units traditionally were ambulance divisions (for men), nursing divisions (for women) and ambulance cadet divisions and nursing cadet divisions for boys and girls respectively. \n\nIn modern times, no single-sex divisions remain and most are either historically termed 'combined division' or 'quadrilateral division'.\n\nOther types of local units exist, such as Badger Setts (for 5- to 10-year-olds) and specialised units such as cycle response units, LINKS units within universities and sometimes informal social groups, each with a distinctive command, management or leadership structure. Specilised units are sometimes \"virtual units\" meaning the unit doesn't physically meet on a regular basis, but works over the internet etc.\n\nThe unit manager may have one or more assistant unit managers to assist them. The unit usually has a weekly meeting where members train, practice their skills, and occasionally have visits from guest speakers. Youth units (badgers and cadets) follow the St John Ambulance youth programme. Units plan and execute the cover of most of the events requested of the organisation, supported by their area and district managers, district specialists and regional events team. Units are where most people start their time in the organisation.\n\nSt John Ambulance first aid personnel wear a service delivery uniform consisting of a green shirt; black combat trousers; and either a green and black Parka Jacket, a reversible fleece, or green and black softshell jacket with appropriate black footwear. Epaulettes on the shirts vary in colour dependent on the profession of the volunteer: Black for first aid personnel, green for registered paramedics, grey for registered nurses, and red for registered doctors. Healthcare professionals' (HCPs) epaulettes don't show specialism such as midwives. Student HCPs wear black epaulettes until they're qualified in their respective profession. \n\nOn the service delivery uniform, a role bar is worn to denote the wearer's role on that event. High-visibility two-tone yellow-and-green tabards (accepted to denote medical personnel) are only worn when the risk assessment of the event calls for it. \n\nBadgers wear a branded black polo-shirt and a branded black jumper, where they can wear the badges they earn through the Super Badger programme. \n\nCadets wear the same uniform as their adult counterparts, though are permitted to wear a brassard on their left arm where they're able to show their current/highest Grand Prior Award badge at the top-centre; up to three badges, including duty hours, Duke of Edinburgh Award, Sovereign's Award, national competitons winners badge, Amalfi Challenge (discontinued) or Diana Award (if won for services to St John Ambulance); and the Super Badger award (if achieved) at the bottom of the brassard. \n\nA ceremonial uniform still exists for adult volunteers, consisting of a peaked cap, tailored jacket, white shirt, black trousers, black shoes and clip-on tie. All rank insignia are worn on the outer layer of the jacket.\n\nA section of St John Ambulance, St John Ambulance British Forces Overseas (SJABFO), has British units running where there are a large amount of British servicemen and women with their families overseas. These are namely in Cyprus, with units in Germany beginning to close in preparation for the British withdrawal from Germany in 2019. The divisions are directly linked to the UK and national headquarters so that members can transfer to another unit or region/district/area as they would be able to do at home. Cyprus and Germany are a part of St John Ambulance as two districts, unattached to any region, within the organisational structure. The uniform reflects the current service delivery uniform in England.\n\nVolunteers can receive training in the full range of St John Ambulance qualifications.\n\nThe overseas forces units (then \"divisions\") were founded in 1980. They remained very strong for several years, however, as the forces in Germany were reduced many divisions closed. Since the final withdrawal of forces in Germany is expected in the next few years, the role for St John Ambulance will end. However the two units in Cyprus founded in 1991 will continue to provide a service to the community there.\n\nAs well as providing medical cover at events, St John Ambulance British Forces provides first-aid training for people of all ages.\n\nSt John Ambulance British Forces Overseas works closely with the German Ambulance Services, particularly the sister organisation, Die Johanniter, in providing first aid and ambulance cover German public events where many British or English Speakers are expected to attend. Members can occasionally be seen on their non-emergency \"and\" emergency vehicles responding to public calls. St John Ambulance can also be seen working with Malteser, the German Red Cross and local fire brigades which provide ambulance services. The German Emergency Services also assist St John Ambulance at British events on military areas where many German civilians are expected to attend. With the planned withdrawral of British forces from Germany in 2019, this partnership, in this aspect at least, will be discontinued.\n\nAlthough the Order of St John is largely seen as a Christian organisation for historical reasons, St John Ambulance does not restrict membership to nor promote any particular religion or denomination. Technically, it falls under the sovereignty of The Queen, and thus is linked to the Church of England; however, this relationship is more tradition than authority, and adult members are not required to pledge allegiance to or support either the monarchy or the Christian faith. Historically, Cadet members made a pledge upon joining to the monarch and to God, though was reviewed and no longer a requirement.\n\nSt John Ambulance works alongside St John organisations across the world as part of St John International.\n\nAfrica\n\n\nAmericas\n\n\nAsia, Australasia and Pacific\n\n\nEurope and Western Asia\n\n\nOther organisations recognised by St John International for sharing a history and similar values, though governed and/or formed separately and performing different functions within their respective countries\n\n\nSt John Ambulance personnel serve alongside the British Red Cross, whose members also undergo advanced training in first aid and event cover. Both organisations work support the statutory services in times of civil emergency or crisis. In peacetime, St John Ambulance is senior to the Red Cross however during wartime, the Red Cross would become senior due to an agreement with the International Red Cross and Red Crescent Movement.\n\nSt John Ambulance, St. Andrew's First Aid in Scotland and the British Red Cross co-author and authorize the official First Aid Manual, the \"de facto\" UK guide for emergency first aid.\n\n\n"}
{"id": "28476395", "url": "https://en.wikipedia.org/wiki?curid=28476395", "title": "Strange Sex", "text": "Strange Sex\n\nStrange Sex (Stylized as \"{strange}SEX\") is a 6-part TLC documentary television series produced by Sirens Media about sexual dysfunction that premiered on 18 July 2010.\n\nBefore the 6-part (half-hour each) series, \"Strange Sex\" was an hour-long documentary that originally aired on Discovery Health on 4 November 2009 that dealt with sex allergy, sex addiction, Persistent Genital Arousal Disorder, and sexomnia.\n\n\n"}
{"id": "255475", "url": "https://en.wikipedia.org/wiki?curid=255475", "title": "Stress management", "text": "Stress management\n\nStress management is a wide spectrum of techniques and psychotherapies aimed at controlling a person's level of stress, especially chronic stress, usually for the purpose of improving everyday functioning. In this context, the term 'stress' refers only to a stress with significant negative consequences, or distress in the terminology advocated by Hans Selye, rather than what he calls eustress, a stress whose consequences are helpful or otherwise.\n\nStress produces numerous physical and mental symptoms which vary according to each individual's situational factors. These can include physical health decline as well as depression. The process of stress management is named as one of the keys to a happy and successful life in modern society. Although life provides numerous demands that can prove difficult to handle, stress management provides a number of ways to manage anxiety and maintain overall well-being.\n\nDespite stress often being thought of as a subjective experience, levels of stress are readily measurable, using various physiological tests, similar to those used in polygraphs.\n\nMany practical stress management techniques are available, some for use by health professionals and others, for self-help, which may help an individual reduce their levels of stress, provide positive feelings of control over one's life and promote general well-being. Other stress reducing techniques involve adding a daily exercise routine, finding a hobby, writing your thoughts, feelings, and moods down and also speaking with a trusted one about what is bothering you. It is very important to keep in mind that not all techniques are going to work the same for everyone, that is why trying different stress managing techniques is crucial in order to find what techniques work best for you. An example of this would be, two people on a roller coaster one can be screaming grabbing on to the bar while the other could be laughing while their hands are up in the air (Nisson). This is a perfect example of how stress effects everyone differently that is why they might need a different treatment. These techniques do not require doctors approval but seeing if a doctors technique works better for you is also very important. \n\nEvaluating the effectiveness of various stress management techniques can be difficult, as limited research currently exists. Consequently, the amount and quality of evidence for the various techniques varies widely. Some are accepted as effective treatments for use in psychotherapy, while others with less evidence favoring them are considered alternative therapies. Many professional organizations exist to promote and provide training in conventional or alternative therapies.\n\nThere are several models of stress management, each with distinctive explanations of mechanisms for controlling stress. Much more research is necessary to provide a better understanding of which mechanisms actually operate and are effective in practice.\n\nWalter Cannon and Hans Selye used animal studies to establish the earliest scientific basis for the study of stress. They measured the physiological responses of animals to external pressures, such as heat and cold, prolonged restraint, and surgical procedures, then extrapolated from these studies to human beings.\n\nSubsequent studies of stress in humans by Richard Rahe and others established the view that stress is caused by distinct, measurable life stressors, and further, that these life stressors can be ranked by the median degree of stress they produce (leading to the Holmes and Rahe stress scale). Thus, stress was traditionally conceptualized to be a result of external insults beyond the control of those experiencing the stress. More recently, however, it has been argued that external circumstances do not have any intrinsic capacity to produce stress, but instead their effect is mediated by the individual's perceptions, capacities, and understanding.\n\nThe generalized models are:\n\nRichard Lazarus and Susan Folkman suggested in 1981 that stress can be thought of as resulting from an \"imbalance between demands and resources\" or as occurring when \"pressure exceeds one's perceived ability to cope\". Stress management was developed and premised on the idea that stress is not a direct response to a stressor but rather one's resources and ability to cope mediate the stress response and are amenable to change, thus allowing stress to be controllable.\n\nAmong the many stressors mentioned by employees, these are the most common:\n\nIn order to develop an effective stress management program it is first necessary to identify the factors that are central to a person controlling his/her stress, and to identify the intervention methods which effectively target these factors. Lazarus and Folkman's interpretation of stress focuses on the transaction between people and their external environment (known as the Transactional Model). The model contends that stress may not be a stressor if the person does not perceive the stressor as a threat but rather as positive or even challenging. Also, if the person possesses or can use adequate coping skills, then stress may not actually be a result or develop because of the stressor. The model proposes that people can be taught to manage their stress and cope with their stressors. They may learn to change their perspective of the stressor and provide them with the ability and confidence to improve their lives and handle all of types of stressors.\n\nThe health realization/innate health model of stress is also founded on the idea that stress does not necessarily follow the presence of a potential stressor. Instead of focusing on the individual's appraisal of so-called stressors in relation to his or her own coping skills (as the transactional model does), the health realization model focuses on the nature of thought, stating that it is ultimately a person's thought processes that determine the response to potentially stressful external circumstances. In this model, stress results from appraising oneself and one's circumstances through a mental filter of insecurity and negativity, whereas a feeling of well-being results from approaching the world with a \"quiet mind\".\n\nThis model proposes that helping stressed individuals understand the nature of thought—especially providing them with the ability to recognize when they are in the grip of insecure thinking, disengage from it, and access natural positive feelings—will reduce their stress.\n\nHigh demand levels load the person with extra effort and work. A new time schedule is worked up, and until the period of abnormally high, personal demand has passed, the normal frequency and duration of former schedules is limited.\n\nMany techniques cope with the stresses life brings. Some of the following ways reduce a lower than usual stress level, temporarily, to compensate the biological issues involved; others face the stressor at a higher level of abstraction:\n\nTechniques of stress management will vary according to the philosophical paradigm.\n\nAlthough many techniques have traditionally been developed to deal with the consequences of stress, considerable research has also been conducted on the prevention of stress, a subject closely related to psychological resilience-building. A number of self-help approaches to stress-prevention and resilience-building have been developed, drawing mainly on the theory and practice of cognitive-behavioral therapy.\n\nLevels of stress can be measured. One way is through the use of psychological testing: \"The Holmes and Rahe Stress Scale\" [two scales of measuring stress] is used to rate stressful life events, while the DASS [Depression Anxiety Stress Scales] contains a scale for stress based on self-report items. Changes in blood pressure and galvanic skin response can also be measured to test stress levels, and changes in stress levels. A digital thermometer can be used to evaluate changes in skin temperature, which can indicate activation of the fight-or-flight response drawing blood away from the extremities. Cortisol is the main hormone released during a stress response and measuring cortisol from hair will give a 60- to 90-day baseline stress level of an individual. This method of measuring stress is currently the most popular method in the clinic.\n\nStress management has physiological and immune benefits.\n\nPositive outcomes are observed using a combination of non-drug interventions:\n\nAcute stress is the most common form of stress among humans worldwide.\n\nAcute stress deals with the pressures of the near future or dealing with the very recent past. This type of stress is often misinterpreted for being a negative connotation. While this is the case in some circumstances, it is also a good thing to have some acute stress in life. Running or any other form of exercise is considered an acute stressor. Some exciting or exhilarating experiences such as riding a roller coaster is an acute stress but is usually very enjoyable. Acute stress is a short term stress and as a result, does not have enough time to do the damage that long term stress causes.\n\nChronic stress is unlike acute stress. It has a wearing effect on people that can become a very serious health risk if it continues over a long period of time. Chronic stress can lead to memory loss, damage spatial recognition and produce a decreased drive of eating. The severity varies from person to person and also gender difference can be an underlying factor. Women are able to take longer durations of stress than men without showing the same maladaptive changes. Men can deal with shorter stress duration better than women can but once males hit a certain threshold, the chances of them developing mental issues increases drastically.\n\nStress in the workplace is a commonality throughout the world in every business. Managing that stress becomes vital in order to keep up job performance as well as relationship with co-workers and employers. For some workers, changing the work environment relieves work stress. Making the environment less competitive between employees decreases some amounts of stress. However, each person is different and some people like the pressure to perform better.\n\nSalary can be an important concern of employees. Salary can affect the way people work because they can aim for promotion and in result, a higher salary. This can lead to chronic stress.\n\nCultural differences have also shown to have some major effects on stress coping problems. Eastern Asian employees may deal with certain work situations differently from how a Western North American employee would.\n\nIn order to manage stress in the workplace, employers can provide stress managing programs such as therapy, communication programs, and a more flexible work schedule.\n\nA study was done on the stress levels in general practitioners and hospital consultants in 1999. Over 500 medical employees participated in this study done by R.P Caplan. These results showed that 47% of the workers scored high on their questionnaire for high levels of stress. 27% of the general practitioners even scored to be very depressed. These numbers came to a surprise to Dr. Caplan and it showed how alarming the large number of medical workers become stressed out because of their jobs. Managers stress levels were not as high as the actual practitioners themselves. An eye opening statistic showed that nearly 54% of workers suffered from anxiety while being in the hospital. Although this was a small sample size for hospitals around the world, Caplan feels this trend is probably fairly accurate across the majority of hospitals.\n\nMany businesses today have begun to use stress management programs for employees who are having trouble adapting to stress at the workplace or at home. Some companies provide special equipments adapting to stress at the workplace to their employees, like coloring diaries and stress relieving gadgets. Many people have spill over stress from home into their working environment. There are a couple of ways businesses today try to alleviate stress on their employees. One way is individual intervention. This starts off by monitoring the stressors in the individual. After monitoring what causes the stress, next is attacking that stressor and trying to figure out ways to alleviate them in any way. Developing social support is vital in individual intervention, being with others to help you cope has proven to be a very effective way to avoid stress. Avoiding the stressors altogether is the best possible way to get rid of stress but that is very difficult to do in the workplace. Changing behavioral patterns, may in turn, help reduce some of the stress that is put on at work as well.\n\nEmployee assistance programs can include in-house counseling programs on managing stress. Evaluative research has been conducted on EAPs that teach individual stress control and inoculation techniques such as relaxation, biofeedback, and cognitive restructuring. Studies show that these programs can reduce the level of physiological arousal associated with high stress. Participants who master behavioral and cognitive stress-relief techniques report less tension, fewer sleep disturbances, and an improved ability to cope with workplace stressors.\n\nAnother way of reducing stress at work is by simply changing the workload for an employee. Some may be too overwhelmed that they have so much work to get done, or some also may have such little work that they are not sure what to do with themselves at work. Improving communications between employees also sounds like a simple approach, but it is very effective for helping reduce stress. Sometimes making the employee feel like they are a bigger part of the company, such as giving them a voice in bigger situations shows that you trust them and value their opinion. Having all the employees mesh well together is a very underlying factor which can take away much of workplace stress. If employees fit well together and feed off of each other, the chances of lots of stress is very minimal. Lastly, changing the physical qualities of the workplace may reduce stress. Changing things such as the lighting, air temperature, odor, and up to date technology.\n\nIntervention is broken down into three steps: primary, secondary, tertiary. Primary deals with eliminating the stressors altogether. Secondary deals with detecting stress and figuring out ways to cope with it and improving stress management skills. Finally, tertiary deals with recovery and rehabbing the stress altogether. These three steps are usually the most effective way to deal with stress not just in the workplace, but overall.\n\nAviation is a high-stress industry, given that it requires a high level of precision at all times. Chronically high stress levels can ultimately decrease performance and compromise safety. To be effective, stress measurement tools must be specific to the aviation industry, given its unique working environment and other stressors. Stress measurement in aviation seeks to quantify the psychological stress experienced by aviators, with the goal of making needed improvements to aviators' coping and stress management skills.\n\nTo more precisely measure stress, aviators' many responsibilities are broken down into \"workloads.\" This helps to categorise the broad concept of \"stress\" by specific stressors. Additionally, since different workloads may pose unique stressors, this method may be more effective than measuring stress levels as a whole. Stress measurement tools can then help aviators identify which stressors are most problematic for them, and help them improve on managing workloads, planning tasks, and coping with stress more effectively.\n\nTo evaluate workload, a number of tools can be used. The major types of measurement tools are:\n\nImplementation of evaluation tools requires time, instruments for measurement, and software for collecting data.\n\nThe most commonly used stress measurement systems are primarily rating scale-based. These systems tend to be complex, containing multiple levels with a variety of sections, to attempt to capture the many stressors present in the aviation industry. Different systems may be utilised in different operational specialties.\n\n\nEarly pilot stress report systems were adapted and modified from existing psychological questionnaires and surveys. The data from these pilot-specific surveys is then processed and analyzed through an aviation-focused system or scale. Pilot-oriented questionnaires are generally designed to study work stress or home stress. Self-report can also be used to measure a combination of home stress, work stress, and perceived performance. A study conducted by Fiedler, Della Rocco, Schroeder and Nguyen (2000) used Sloan and Cooper's modification of the Alkov questionnaire to explore aviators' perceptions of the relationship between different types of stress. The results indicated that pilots believed performance was impaired when home stress carried over to the work environment. The degree of home stress that carried over to work environment was significantly and negatively related to flying performance items, such as planning, control, and accuracy of landings. The questionnaire was able to reflect pilots' retroactive perceptions and the accuracy of these perceptions.\n\nAlkov, Borowsky, and Gaynor started a 22-item questionnaire for U.S. Naval aviators in 1982 to test the hypothesis that inadequate stress coping strategies contributed to flight mishaps. The questionnaire consists of items related to lifestyle changes and personality characteristics. After completing the questionnaire, the test group is divided into two groups: \"at-fault\" with mishap, and \"not-at-fault\" in a mishap. Then, questionnaires from these two groups were analyzed to examine differences. A study of British commercial airline pilots, conducted by Sloan and Cooper (1986), surveyed 1,000 pilot members from the British Airline Pilots' Association (BALPA). They used a modified version of Alkov, Borowsky, and Gaynor's questionnaire to collect data on pilots' perceptions of the relationship between stress and performance. Being a subjective measure, this study's data was based on pilots' perceptions, and thus rely on how accurately they recall past experiences their relationships to stress. Despite relying on subjective perceptions and memories, the study showed that pilot reports are noteworthy.\n\nBeck Depression Inventory (BDI) is another scale used in many industries, including the mental health professions, to screen for depressive symptoms.\nParsa and Kapadia (1997) used the BDI to survey a group of 57 U.S. Air Force fighter pilots who had flown combat operations. The adaptation of the BDI to the aviation field was problematic. However, the study revealed some unexpected findings. The results indicated that 89% of the pilots reported insomnia; 86% reported irritability; 63%, dissatisfaction; 38%, guilt; and 35%, loss of libido. 50% of two squadrons and 33% of another squadron scored above 9 on the BDI, suggesting at least low levels of depression. Such measurement may be difficult to interpret accurately.\n"}
{"id": "20789412", "url": "https://en.wikipedia.org/wiki?curid=20789412", "title": "Sustainable seafood advisory lists and certification", "text": "Sustainable seafood advisory lists and certification\n\nSustainable seafood advisory lists and certification are programs aimed at increasing consumer awareness of the environmental impact and sustainability of their seafood purchasing choices. \n\nCalifornia-based Seafood Watch and Marine Conservation Society's \"fish online\" are some of the best-known guides. One of the best-known certification programs is Marine Stewardship Council's scheme for consumer seafood products.\n\nOther programs include regional guides, such as that produced by the Australian Marine Conservation Society (AMCS). In Canada, SeaChoice produces assessments and recommendations using the traffic light system, while recommendation of restaurants is done by Vancouver Aquarium's Ocean Wise.\n\n\n\n\n"}
{"id": "33103088", "url": "https://en.wikipedia.org/wiki?curid=33103088", "title": "Veterinary medicine in the United Kingdom", "text": "Veterinary medicine in the United Kingdom\n\nVeterinary medicine in the United Kingdom is the performance of veterinary medicine by licensed professionals, and strictly regulated by statute law, notably the Veterinary Surgeons Act of 1966. Veterinary medicine is led by veterinary physicians, termed 'veterinary surgeons' (with a different meaning to how it is used in some other anglophone countries, where it denotes a surgical specialist), normally referred to as 'vets'.\n\nVets are often assisted by registered veterinary nurses, who are able to both assist the vet and to autonomously practice a range of skills of their own, including minor surgery under direction from a responsible vet.\n\nOther professionals are also permitted to perform some animal treatment, through exemptions in the law, and these include manipulation techniques such as physiotherapy, chiropractic and osteopathy. Other alternative medicine therapies, such as homeopathy, acupuncture, phytotherapy and aromatherapy may only be performed by a licensed veterinary surgeon.\n\nThe practice of veterinary medicine in the United Kingdom is regulated by the Royal College of Veterinary Surgeons (RCVS), who licence both veterinary surgeons and veterinary nurses.\n\nIn order to practice veterinary medicine in the UK, a veterinary surgeon must hold a current registration with the RCVS. This requires a qualifying degree, usually in veterinary science or veterinary medicine. From March 2015, veterinary surgeons registered with the RCVS in the UK may optionally use the courtesy title \"Dr\". This makes it the third clinical degree in the UK, after medicine and dentistry, to allow the use of the title Dr. The origins of veterinary surgeons parallel to human surgery are reflected in human medicine where qualified surgeons also drop their Dr designation and revert to their original title.\n\nVeterinary medicine degree courses are usually five years in length, although Cambridge University's degree takes six, and in some cases, a four-year accelerated course is available. There are a limited number of places on veterinary courses each year, with only eight British Universities offering the degree (Bristol, Cambridge, Edinburgh, Glasgow, Liverpool, Nottingham, the Royal Veterinary College, London, and Surrey).\n\nContinuing professional development (CPD) is a mandatory and key part of career development. The RCVS recommends a minimum of 105 hours CPD over a three-year period. The RCVS Professional Development Phase (PDP) that was launched for new graduates in 2007 provides a structured approach to guide the new graduate towards the professional competences they need to develop in either small animal, equine or production animal practice.\n\nVets may choose to specialise in various areas of veterinary medicine, through certificate qualifications, modular certificates or diplomas, with each speciality taking around two years to complete. Certificates cover a wide range of areas, including small animal medicine, small animal surgery, large animal medicine, welfare ethics and law, public health, cardiology, orthopaedics and advanced veterinary practice (Cert AVP).\n\nThere is a large and potentially confusing array of post-nominal titles in the UK veterinary profession. Levels of credibility vary. In particular, Certificate level qualification does not qualify a veterinary surgeon as a specialist. With further training, extensive professional experience and by publishing articles in a particular subject area, it is possible to gain Royal College of Veterinary Surgeons (RCVS) Recognised Specialist Status. In 2012, the ruling council of the RCVS adopted a report from the Calman Committee into specialisation in the UK veterinary profession, accepting that only those veterinary surgeons recognised by the RCVS as specialists and placed on a register held by the RCVS could be truly held up as \"Specialist\". Members of the public looking for an appropriately accredited specialist veterinary surgeon in the UK should therefore primarily seek those that carry the post-nominal description of \"RCVS Recognised Specialist in...\" after their name. No other accolade carries authority from the appropriate regulatory body.\n\nVets may undertake the training to become an Official Veterinarian (OV) which authorises them to carry out tasks on behalf of the Department for Environment, Food and Rural Affairs, such as testing cattle for tuberculosis or issuing of documentation for the export of animals and animal products.\n\nMost veterinary surgeons work in private practice, either in a general practice, or specialising in one type of animal (small animal, equine, zoo animal etc.). Newly qualified veterinary surgeons usually work as assistants for some time before being offered the opportunity to become a partner or a principal. Becoming a partner involves increased responsibility, the need for more business and management skills and a financial input into the practice.\n\nSome vets are also employed by animal welfare charities who offer treatment to the public, such as Royal Society for the Prevention of Cruelty to Animals (RSPCA), the People's Dispensary for Sick Animals (PDSA) and The Blue Cross.\n\nThere are also opportunities to work for government services, including APHA (the Animal and Plant Health Agency) who are responsible for the control and eradication of major notifiable diseases, animal welfare, promotion of international trade and certain public health functions related to residues in meat and investigation of food safety incidents, and scanning surveillance, or the Veterinary Medicines Directorate (VMD) who licence veterinary medicines.\n\nIt is also possible to pursue a research and/or teaching career within universities or research bodies.\n\nVeterinary Nurses are the primary paraveterinary workers in the United Kingdom and work alongside vets. Veterinary Nurses must be registered and follow a strict code of conduct. Veterinary Nurses have a scope of autonomous practice within which they can act for the animals they treat. Under schedule 3 of the Veterinary Surgeons act they can perform many complex procedures include minor surgery, admission of intravenous fluid therapy and parenteral nutrition, performing diagnostic imaging and monitoring anaesthesia.\n\nPreventative medicine is also an important part of the veterinary nurse’s role with nurse clinics and consultations becoming increasingly common. Nurse led clinics may cover such areas as nutrition and weight management, management of the diabetic or senior patient, parasite control, vaccinations, puppy and kitten socialisation, dental care and wound care.\n\nAll veterinary nurses must be registered with the Royal College of Veterinary Surgeons (RCVS). Registered Veterinary Nurses have dispensations in law [the Veterinary Surgeons Act of 1966 amended in 2002)] to undertake certain procedures to include minor surgery and anaesthesia on animals under veterinary direction. Registered Veterinary Nurses (RVNs) are bound by a code of professional conduct and are obliged to maintain their professional knowledge and skills through ongoing CPD. Those VN's listed after 2002 are automatically registered.\n\nRVNs train for the Register through either a two to three year further education diploma programme or via a qualifying foundation or honours degree which can be three to four years. All student nurses must complete a minimum of 2100 hours of work experience in general veterinary practice during their training.\n\nRCVS badges are engraved with the nurse's personal badge number, and as of 2012 are available with the additional engraving ‘registered’ for RVNs.\n\nVN's can further their formal training and gain additional postnominal letters by completing one of many specialist certificates and/or by achieving the RCVS Diploma in Advanced Veterinary Nursing (DipAVN) by following a course of study in one or more of three pathways: Small animal nursing, Equine nursing, and Veterinary nursing education. The streamlined RCVS DipAVN replaced the DipAVN(Medical) and DipAVN(Surgical) formerly administered by the BVNA up until 2005. The DipAVN is offered through Myerscough College in Lancashire since 2007 and more recently through Harper Adams University, some modules are also available from the Royal Veterinary College in conjunction with the University of London.\n\nUK Veterinary Nurses are represented by the British Veterinary Nursing Association (BVNA).\n\nPrior to 1979, the term \"nurse\" was reserved for members of the General Nursing Council, but it was not until 1984 that the term \"veterinary nurse\" was permitted to be used.\n\nLay staff, without formal qualification or status may be called animal nursing assistants (the BVNA approved term) or veterinary care assistants. These lay staff have usually undertaken some basic veterinary nurse training but are limited by law as to the procedures they may undertake on animals. They work alongside qualified vets and veterinary nurses to provide care and support to animal patients and their owners.\n\n\n"}
{"id": "47488215", "url": "https://en.wikipedia.org/wiki?curid=47488215", "title": "Waruga", "text": "Waruga\n\nWaruga are a type of sarcophagus or above ground tomb traditionally used by the Minahasans of North Sulawesi, Indonesia. They are made of stone and consist or a ridged upper part and a box shaped lower section.\n\nDead Minahasans were originally wrapped in woka, a type of leaf. Woka is the leaf of the fan palm, Livistona. Then they were put in wooden coffins. In the 9th century the Minahasa started using waruga.\n\nBodies are put in a position facing north. They seated with heel and toe attaches to the buttocks and the head \"kissing\" the knees. The Minhasa believe their ancestors came from the north.\n\nIn 1828 the Dutch banned the use of waruga and the Minahasa started making coffins. Disease outbreak, including typhoid and cholera, was feared. And Christian practice is to bury the dead.\n\nWaruga in Tonsea have carvings and reliefs showing how the bodies are stored in their respective waruga and illustrating livelihoods.\n\nThere are about 370 Warugas (waruga-waruga) in Rap-Rap (15), Airmadidi Down (211) and Sawangan, North Sulawesi (144). They are a tourist attraction and were listed as a UNESCO World Heritage Site since 1995 in the waruga archaeological park in Sawangan. At Taman Purbakala Waruga-Waruga, the sarcophagi have been collected from surrounding areas and at a nearby museum porcelain, armbands, axes and bone fragments are exhibited. Most of the waruga have been looted for valuable contents.\n\n\n"}
{"id": "3981519", "url": "https://en.wikipedia.org/wiki?curid=3981519", "title": "Water fasting", "text": "Water fasting\n\nWater fasting is a type of fasting in which the practitioner consumes only water. One may water fast for a variety of reasons, including medical and religious requirements.\n\nJains maintain a strict water-only fast for 8 to 10 (digambar & Swetambar) days, during the days of Paryushan.\n\nRoman Catholics must engage in the eucharistic fast before receiving the Eucharist during the Mass. While no nutritional or caloric sustenance is permitted, practitioners may take medicine if required, and those whose health problems impede them from fasting are dispensed of the obligation.\n\nUp until the reforms of the Second Vatican Council, this fast was required from the previous midnight, as it is in various Orthodox Churches. However, under Pope Paul VI, the obligatory fast was reduced to only one hour before receiving the Eucharist.\n\nThe Catholic Church has also promoted a Black Fast, in which in addition to water, bread is consumed. Typically, this form of fasting was only used by monks and other religious individuals who practice mortifications and asceticism, but all Catholics are invited to take part in it with the advice and consent of their spiritual director.\n\n"}
