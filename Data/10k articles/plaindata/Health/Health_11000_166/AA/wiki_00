{"id": "37687241", "url": "https://en.wikipedia.org/wiki?curid=37687241", "title": "Against Medical Advice: A True Story", "text": "Against Medical Advice: A True Story\n\nAgainst Medical Advice: A True Story is a New York Times Bestselling non-fiction book by James Patterson and Hal Friedman, detailing the illness and medical struggles of Cory Friedman and his family. The book was published on October 20, 2008, by Little, Brown and Company.\n\n\"Against Medical Advice\" begins with a seventeen-year-old Cory arriving at the Dressler Psychiatric Hospital for alcohol abuse, with him detailing the various medications he is on and how he feels that they do nothing for him. Cory expresses frustration over giving the appearance of being insane, despite his not feeling as if he was. The book shows how Cory began exhibiting uncontrollable urges to perform body tics and say various things at the age of five years. As he grew up, he was put through several different treatments, which contributed to his feelings of helplessness. Since he is unable to control his actions due to having OCD, Tourette syndrome, and an anxiety disorder, Cory experienced ridicule in his life and had troubles living the everyday life of a child, which is exacerbated by ill medical treatment.\n\nIn 2010, Cory Friedman published a young adult version of \"Against Medical Advice\" with Patterson, entitled \"Med Head: My Knock-Down Drag-Out Drugged-Up Battle with My Brain\". The book was released on April 1, 2010, and received a positive review from TeenReads and Kirkus Reviews, who called it a \"perfect prescription for misery-memoir maniacs\".\n\nDiário Digital gave a positive review for \"Against Medical Advice\", calling it \"a touching story of courage, determination and the ultimate triumph of a family facing a desperate situation\". The Carlsbad Current-Argus also praised the book, stating that it was a \"success\".\n\n"}
{"id": "29193705", "url": "https://en.wikipedia.org/wiki?curid=29193705", "title": "Ali S. Khan", "text": "Ali S. Khan\n\nRear Admiral Ali S. Khan is an American practicing physician and former Director of the Office of Public Health Preparedness and Response (PHPR) at the Centers for Disease Control and Prevention. Since July 2014, he has served as Dean of the College of Public Health and Retired Assistant Surgeon General at the University of Nebraska Medical Center in Omaha, Nebraska.\n\nAli Khan received his Doctor of Medicine from the State University of New York Downstate Medical Center in Brooklyn, NY, and completed a joint residency in internal medicine and pediatrics at the University of Michigan. He later went on to pursue a Masters of Public Health (MPH) from Emory University.\n\nKhan’s federal career began in 1991 when he joined CDC and the U.S. Public Health Service Commissioned Corps as an Epidemic Intelligence Service (EIS) officer. Dr. Khan has focused his career on bioterrorism, global health, and emerging infectious diseases. While serving as the interim Director for CDC’s global infectious disease activities, he designed CDC’s joint global field epidemiology and laboratory training program. Dr. Khan helped design and implement the President's Malaria Initiative, a $1.2 billion, five-year project to reduce the burden of malaria and relieve poverty in Africa. He has also been engaged in polio and guinea worm eradication. Additionally, Khan proposed the BioPHusion program as a new public health initiative to improve knowledge exchange for all public health practitioners. BioPHusion was used during the H1N1 pandemic to identify emerging cases and plan response actions.\n\nKhan’s initial work in emergency preparedness started in 1999 when he helped establish CDC’s bioterrorism program, which upgraded local, state, and national public health systems to detect and rapidly respond to bioterrorism. As deputy director of the bioterrorism program, Khan created the Critical Agent list, which has remained the basis for all biological terrorism preparedness. Dr. Khan also published the first national public health preparedness plan, initiated syndrome based surveillance, and designed key focus areas to improve local and State capacities to respond to emergencies. Khan used these preparedness efforts during the first anthrax attack in 2001, during which he directed the CDC operational response in Washington, D.C.\n\nPrior to becoming Director of PHPR in August 2010, Dr. Khan served as Deputy Director of CDC’s National Center for Emerging and Zoonotic Infectious Diseases (NCEZID). He has responded to and led numerous domestic and international public health emergencies, including hantavirus pulmonary syndrome, Ebola hemorrhagic fever, monkeypox, Rift Valley fever, avian influenza, severe acute respiratory syndrome (SARS), the Asian tsunami, and the initial public health response to Hurricane Katrina in New Orleans.\n\nIn 2016 Khan published \"The Next Pandemic\" (with William Patrick). In it he recounts some of his experiences responding to outbreaks all over the world, including many of those mentioned above. Besides his personal experiences, he also provides a great deal of background information for readers interested in public health and emerging diseases.\n\n"}
{"id": "2995171", "url": "https://en.wikipedia.org/wiki?curid=2995171", "title": "Chillcuring", "text": "Chillcuring\n\nChillcuring is a grain ventilating process, especially of fresh-harvested shelled corn.\n\nAs described in inventions of Sylvester L. Steffen, chillcuring is an electrical ventilating process that facilitates the photoelectric after-ripening of bulk stored seeds. The ventilation process is controlled by monitoring the wet-bulb temperature of air around the grain (as measured by evaporative cooling), by which the grain is brought to equilibrium moisture and temperature with atmospheric air. Seed dormancy is better maintained at cooler (chill) atmospheric temperatures, and grain weight and seed vigor are better preserved. The after-ripening of seeds is a biochemical process of carbohydrate/protein stabilization associated with the chemical release of water (H:OH), a reverse process of hydrolysis. The triatomic molecules of water and carbon dioxide are especially reactive in attenuating infrared light-spectrum waves, which provides energy necessary in photosynthesis and (curing) after-ripening. Infrared electrical heat is supplied by “grainlamps” so as to energize water vapor in the air under high humidity conditions.\n\nThe Steffen Patents were at issue in federal lawsuits in Minnesota, Indiana and Iowa. The validity of the Steffen Process Patents was upheld. The chillcuring process was marketed from the 1960s into the late 1990s by Harvestall Industries, Inc., an agribusiness of the former and now deceased Speaker of the Iowa House of Representatives, Vincent B. Steffen.\n"}
{"id": "38148951", "url": "https://en.wikipedia.org/wiki?curid=38148951", "title": "Clinical Social Work Journal", "text": "Clinical Social Work Journal\n\nThe Clinical Social Work Journal is a quarterly, peer-reviewed academic journal that publishes articles, commentaries, and book reviews relevant to contemporary clinical social work practice, research, theory, and policy. It is currently published by Springer Science+Business Media. The editor-in-chief is Carol Tosone. The journal was established in 1973. According to the \"Journal Citation Reports\", the journal has a 2012 impact factor of 0.494.\n"}
{"id": "22706929", "url": "https://en.wikipedia.org/wiki?curid=22706929", "title": "Cobb syndrome", "text": "Cobb syndrome\n\nCobb syndrome is a rare congenital disorder characterized by visible skin lesions with underlying spinal angiomas or arteriovenous malformations (AVMs). The skin lesions of Cobb syndrome typically are present as port wine stains or angiomas, but reports exist of angiokeratomas, angiolipomas, and lymphangioma circumscriptum. The intraspinal lesions may be angiomas or AVMs and occur at levels of the spinal cord corresponding to the affected skin dermatomes. They may in turn produce spinal cord dysfunction and weakness or paralysis.\n\nThe disorder was first described by Berenbruch in 1890, but became widely known only after Cobb's report in 1915. Cobb syndrome is thought to have no sex predilection, but there have been less than 100 cases reported in the literature. It is believed to be due to a sporadic mutation, since parents of affected children usually have no evidence of the disease.\n\nThe disease is present at birth, but clinical manifestations are often not seen until later in life. Patients typically experience the sudden onset of pain, numbness, or weakness in their extremities as children or young adults. These symptoms may remit or remain stable and often can be localized below a specific dermatome. Symptoms tend to worsen over time either by discrete steps or continuously. Early development of weakness may portend a more aggressive course. Less commonly, weakness or bowel and bladder dysfunction may be presenting symptoms.\n\nThe major debility from Cobb syndrome is the onset of weakness, paresis, sensory loss, and loss of bowel and bladder control. A possible complication if treatment is delayed is Foix-Alajouanine syndrome or subacute necrotic myelopathy due to thrombosis in the spinal angioma.\n\nCutaneous lesions may be distributed anywhere in the dermatome, from midline back to abdomen. Midline back lesions may be associated with spina bifida. The cutaneous lesion may be very faint and may be more pronounced when the patient performs a Valsalva maneuver which increases abdominal pressure and causes preferential filling of the cutaneous angioma. Neurological examination will reveal weakness or paralysis and numbness or decreased sensation with a sharp upper cutoff.\nCobb Syndrome is diagnosed by MRI, supplemented by medullary angiography.\n\n"}
{"id": "9398622", "url": "https://en.wikipedia.org/wiki?curid=9398622", "title": "Doctor of Public Health", "text": "Doctor of Public Health\n\nThe Doctor of Public Health (abbr. DrPH or DPH; Latin \"\") is a doctoral degree awarded in the field of Public Health. DrPH is the highest, and terminal, professional degree in the field of public health. It prepares its recipients for a leadership career in advanced public health practice and administration. Some of the DrPH holders also pursue academia including teaching and research. DrPH holders often occupy executive leadership roles in private and public sectors along with, non-profit and international health entities such as the WHO. \n\nA DrPH is a leadership-centered, interdisciplinary degree that equips its holders with the skill set necessary for public health practice as opposed to a Ph.D. which is purely a research-based degree only focusing on one topic within a certain field. The DrPH degree is categorized as a terminal professional degree on a par with, a Ph.D., doctor of education, doctor of social work, doctor of medicine, doctor of business administration, and doctor of psychology degrees. \n\nAdmission into a DrPH program usually requires a master of public health degree as a prerequisite. Furthermore, a DrPH requires several years of public health leadership and practice experience (generally, 5 years or more) for an admission. In contrast, one may enter a Ph.D. or ScD program after completing a bachelor (undergrad) degree with no experience or advanced academic training.\n\nDrPH: Leadership and public health practice, applied research, and academia to a lesser extent.\nPh.D.: Research and academia.\n\nA typical accredited DrPH program requires roughly a two-year long intensive multidisciplinary coursework in advanced research methodology - similar to a Ph.D. Additionally, as a distinction and addition to a Ph.D., DrPH students also take advanced courses to gain analytical skills in leadership, management, systems thinking, communications, and health policy.\n\nDrPH students are also required to complete a public health practice experience as a critical part of their DrPH program. Students apply the skills learned in public health practice to gain leadership experience and hone their skills through hands-on experience.\n\nMost universities require a rigorous comprehensive exam at the end of first two-years of coursework and public health residency before a candidate may be advanced to the dissertation phase. Some DrPH programs, such as the Tufts University, require a Qualifying Exam - taken at the end of the first year -, along with the comprehensive exam, taken at the end of the second year. \n\nDrPH students are required to complete and defend an applied public health practice-related dissertation during their candidacy phase, usually after the comprehensive exams, in order to complete the program. \n\nThe average time to complete a DrPH is roughly 4-7 years. \n\nSome of the universities offering DrPH in the USA are listed below. \n\n\n\n\n\nSara Josephine Baker - American physician notable for making contributions to public health, especially in the immigrant communities of New York City. \n\nSandro Galea - Dean of the Boston University School of Public Health. \n\nCheryl Healton - Dean of the College of Global Public Health at New York University. \n\nVicenç Navarro - Spanish sociologist and political scientist currently holding a chair in Social Sciences at the Pompeu Fabra University in Barcelona.\n\nMary Pittman - President and chief executive officer of the Public Health Institute in Oakland, California. \n\nBarbara Rimer - Dean of the University of North Carolina at Chapel Hill Gillings School of Global Public Health. \n\nHenry F. Vaughan - Founder and former Dean of the University of Michigan School of Public Health. Past president of the American Public Health Association. \n\nCharles-Edward Amory Winslow - American bacteriologist and founder of Yale University's Department of Public Health (which subsequently became the Yale School of Public Health).\n\n"}
{"id": "37063005", "url": "https://en.wikipedia.org/wiki?curid=37063005", "title": "Effects of global warming on human health", "text": "Effects of global warming on human health\n\nThe effects of global warming include its effects on human health. The observed and projected increased frequency and severity of climate related impacts will further exacerbate the effects on human health. This article describes some of those effects on individuals and populations.\n\nA good example of the impact of global warming on health can be seen in the disease erythromelalgia. This is a vascular disease that is commonly triggered by the involvement of change in temperature, which leads to syndromes including (first and second degree) burning pain, increased temperature, erythema and swelling, of mainly the hands and feet that are affected.\n\nIn a Chinese study, epidemic Erythromelalgia appears quite common in southern China, most likely due to a sharp decline in temperature following by a rapid increase of temperature and the effects this has on the body. The acral small superficial arteries intensely constrict and dilate during the sharp decline of temperature, whereas a sharp increase of temperature, the intense expansion of capillaries irritate the nerve endings around, and thus lead to symptoms including burning pain, increased temperature, erythema and swelling.\nAs climate change proceeds, more Erythromelalgia outbreaks may occur because of the extreme weather events that are projected to increase in coming decades.\n\nWarming oceans and a changing climate are resulting in extreme weather patterns which have brought about an increase of infectious diseases—both new and re-emerging. These extreme weather patterns are creating extended rainy seasons in some areas, and extended periods of drought in others, as well as introducing new climates to different regions. These extended seasons are creating climates that are able to sustain vectors for longer periods of time, allowing them to multiply rapidly, and also creating climates that are allowing the introduction and survival of new vectors.\n\nMosquito-borne diseases are probably the greatest threat to humans as they include malaria, elephantiasis, Rift Valley fever, yellow fever, and dengue fever. Studies are showing higher prevalence of these diseases in areas that have experienced extreme flooding and drought. Flooding creates more standing water for mosquitoes to breed; as well, shown that these vectors are able to feed more and grow faster in warmer climates. As the climate warms over the oceans and coastal regions, warmer temperatures are also creeping up to higher elevations allowing mosquitoes to survive in areas they had never been able to before. As the climate continues to warm there is a risk that malaria will make a return to the developed world.\n\nTicks are also thriving in the warmer temperatures allowing them to feed and grow at a faster rate. The black legged tick, a carrier of Lyme disease, when not feeding, spends its time burrowed in soil absorbing moisture. Ticks die when the climate either becomes too cold or when the climate becomes too dry, causing the ticks to dry out. The natural environmental controls that used to keep the tick populations in check are disappearing, and warmer and wetter climates are allowing the ticks to breed and grow at an alarming rate, resulting in an increase in Lyme disease, both in existing areas and in areas where it has not been seen before.\n\nAnother impact that the warming global temperature has had is on the frequency and severity of heat waves. In addition to dehydration and heat stroke, these heat waves have also resulted in epidemics of Chronic Kidney Disease (CKD). Recent studies have shown that prolonged heat exposure, physical exertion, and dehydration are sufficient factors to developing CKD. These cases are occurring across the world congruently with heat stress nephropathy.\n\nOther diseases on the rise due to extreme weather include hantavirus, schistosomiasis, onchocerciasis (river blindness), and tuberculosis. It also causes the rise in hay fever, as when the weather gets warmer there is a rise in pollen levels in the air.\n\nProjected increases in temperature would make parts of southwest Asia uninhabitable, when temperature combined with high humidity reaches a wet-bulb temperature of 35 °C, the threshold for a fit human to survive in well-ventilated conditions.\n\nWarmer temperatures may also lead an increase in aggression levels. Research has shows links between higher temperatures and increased aggressive and criminal behaviour. Which can be seen by the rise in the rate of criminality during the warmer summer months.\n\nThe warming oceans are becoming a breeding ground for toxic algae blooms (also known as red tides) and cholera. As the nitrogen and phosphorus levels in the oceans increase, the cholera bacteria that lives within zooplankton emerge from their dormant state. The changing winds and changing ocean currents push the zooplankton toward the coastline, carrying the cholera bacteria, which then contaminate drinking water, causing cholera outbreaks. As flooding increases there is also an increase in cholera epidemics as the flood waters that are carrying the bacteria are infiltrating the drinking water supply. El Nino has also been linked with cholera outbreaks because this weather pattern warms the shoreline waters, causing the cholera bacteria to multiply rapidly.\n\nMalaria is a mosquito-borne parasitic disease that infects humans and other animals caused by microorganisms in the Plasmodium family. It begins with a bite from an infected female mosquito, which introduces the parasite through its saliva and into the infected host's circulatory system. It then travels through the bloodstream into the liver where it can mature and reproduce. The disease causes symptoms that typically include fever, headache, shaking chills, anemia, and in severe cases can progress to coma or death.\n\n'About 3.2 billion people – nearly half of the world's population – are at risk of malaria. In 2015, there were roughly 214 million malaria cases and an estimated 438,000 malaria deaths.' \n\nClimate is an influential driving force of vector-borne diseases such as malaria. Malaria is especially susceptible to the effects of climate change because mosquitoes lack the mechanisms to regulate their internal temperature. This implies that there is a limited range of climatic conditions within which the pathogen (malaria) and vector (a mosquito) can survive, reproduce and infect hosts. Vector-borne diseases, such as malaria, have distinctive characteristics that determine pathogenicity. These include the survival and reproduction rate of the vector, the level of vector activity (i.e. the biting or feeding rate), and the development and reproduction rate of the pathogen within the vector or host. Changes in climate factors substantially affect reproduction, development, distribution and seasonal transmissions of malaria.\n\nMosquitoes have a small window for preferential conditions for breeding and maturation. The ultimate breeding and maturing temperature for mosquitoes range from sixteen to eighteen degrees Celsius. If the temperature is decreased by two degrees, most of the insects will succumb to death. This is why malaria is unsustainable in places with cool winters. If a climate with an average of approximately 16 degrees Celsius experiences an increase of about two degrees, the mature bugs and the larvae flourish. Female mosquitoes will need more food (human/animal blood) to sustain life and to stimulate production of eggs. This increases the chance of spread of malaria due to more human contact and a higher number of the blood sucking insects surviving and living longer. Mosquitoes are also highly sensitive to changes in precipitation and humidity. Increased precipitation can increase mosquito population indirectly by expanding larval habitat and food supply. These prime temperatures are creating large breeding grounds for the insects and places for the larvae to mature. Increased temperature is causing snow to melt and stagnant pools of water to become more common. Bugs that are already carrying the disease are more likely to multiply and infect other mosquitoes causing a dangerous spread of the deadly disease.\n\nClimate change has a direct impact on people's health in places where Malaria is not prevalent. In communities of higher altitudes in Africa and South America, people are at higher risk for developing malaria in recent years because of an increase temperature. Mosquitos are sensitive to temperature changes and the warming of their environment will boost their rates of production. A fluctuation of two or three degrees is creating exceptional breeding grounds for mosquitoes, for larvae to grow and mature mosquitoes carrying the virus to infect people that have never been exposed before. This is a severe problem because people in these communities have never been exposed to this disease causing an increased risk for complications from malaria such as cerebral malaria (a type of malaria that causes mental disability, paralysis and has a high mortality rate) and death by the disease. Residents of these communities are being hit hard by malaria because they are unfamiliar with it; they do not know the signs and symptoms and have little to no immunity.\n\nThe population at risk of malaria in the absence of climate change is projected to double between 1990 and 2080 to 8820 million, however; unmitigated climate change would, by the 2080s, further increase the population at risk of malaria by another 257 to 323 million. Therefore, reducing the effects of climate change in the present would reduce the total by about 3.5%, saving tens of thousands of lives worldwide.\n\nIf there is a slight discrepancy in the normal temperature, the perfect conditions for the insects to multiply are created. People that have never been infected before are unknowingly at risk for this deadly disease and do not have the immunity to combat it. An increase in temperature has the potential to cause a widespread epidemic of the disease that has the capacity to wipe out entire populations of people. It is important to track the prevalence, species and number of insects carrying the disease as well as the number of humans infected in countries and places that have never seen malaria before. It is simple for the slightest of fluctuation in temperature to cause a catastrophic epidemic that has the possibility to end the lives of many innocent and unsuspecting people.\n\nDengue fever is an infectious disease caused by dengue viruses known to be in the tropical regions. It is transmitted by the mosquito Aedes, or A. aegypti.\n\nThe cases of dengue fever have increased dramatically since the 1970s and it continues to become more prevalent. The greater incidence of this disease is believed to be due to a combination of urbanization, population growth, increased international travel, and global warming. The same trends also led to the spread of different serotypes of the disease to new areas, and to the emergence of dengue hemorrhagic fever. There are four different types of viruses in dengue fever. If someone is infected with one type of dengue virus, he or she will have permanent immunity to that type of dengue virus, but will have short term immunity to the other type of dengue fever. Some of the symptoms of dengue fever are fever, headache, muscle and joint pains and skin rash. There is no vaccine for dengue fever right now and there is no true treatment to get rid of it, but there are treatments to assist with some of the work of dengue, such as the use of oral or intravenous fluids for rehydration.\n\nDengue fever used to be considered a tropical disease, but climate change is causing dengue fever to spread. Dengue fever is transmitted by certain types of mosquitoes, which have been spreading further and further north. This is because some of the climate changes that are occurring are increased heat, precipitation and humidity which create prime breeding grounds for mosquitoes. The hotter and wetter a climate is, the faster the mosquitoes can mature and the faster the disease can develop. Another influence is the changing El Nino effects that are affecting the climate to change in different areas of the world, causing dengue fever to be able to spread.\n\nThere are many things that can be done, both on a governmental level and on an individual basis. One improvement would be having a better system of detecting when dengue outbreaks may happen. This can be done by monitoring environments, such as temperatures, rainfall and humidity that would be attractive to these types of mosquitoes and help them to flourish. Another useful plan is to educate the public by letting them know when a dengue outbreak is occurring and what they can do to protect themselves. For example, people should create a living environment that is not attractive to mosquitoes (no standing water), dress in appropriate clothing (light colours, long sleeves), and wear insect repellent.\n\nA high humidity of greater than 85% is the best condition for a tick to start and finish its life cycle. Studies have indicated that temperature and vapor play a significant role in determining the range for tick population. More specifically, maximum temperature has been found to play the most influential variable in sustaining tick populations. Higher temperatures augment both hatching and developmental rates while hindering overall survival. Temperature is so important to overall survival that an average monthly minimum temperature of below -7°C in the winter can prevent an area from maintaining established populations.\n\nThe effect of climate on the tick life cycle is one of the more difficult projections to make in relation to climate and vector-borne disease. Unlike other vectors, tick life cycles span multiple seasons as they mature from larva to nymph to adult. Further, infection and spread of diseases such as Lyme disease happens across the multiple stages adding additional variables to consider. Infection of ticks happen in the larval/nymph stage (after the first blood meal) when they are exposed to borrelia burgdorferi (the spirochete responsible for Lyme disease), but transmission to humans doesn’t occur until the adult stages. \n\nThe expansion of tick populations are concurrent with global climatic change. Species distribution models of recent years indicate that the deer tick, known as \"I. scapularis,\" is pushing its distribution to higher latitudes of the Northeastern United States and Canada, as well as pushing and maintaining populations in the South Central and Northern Midwest regions of the United States. Climate models project further expansion of tick habit north into Canada as progressing Northwest from the Northeastern United States. Additionally, however, tick populations are expected to retreat from the Southeastern coast of the U.S., but this has not yet been observed. It's estimated that coinciding with this expansion, increased average temperatures may double tick populations by 2020 as well as bring an earlier start to the tick exposure season.\n\nTick populations are not only spreading wider, but moving to higher elevations. In Colorado, the Rocky Mountain wood tick known as \"D. andersoni\" is found along the front range and is want to feed, and consequently infect, human populations with tularemia (\"Francisella tularensis\"), Rocky Mountain spotted fever (\"Rickettsia rickettsii\"), and Colorado tick fever (CTF virus). A case study testing climatic interaction affecting tick vector (\"D. andersoni\") populations in Larimer County, Colorado indicated that an estimated increase of 1.2–2.0 °C in summer temperatures would increase tick populations moving 100m upwards in elevation, increasing the range and susceptibility of tick-borne illnesses along the front range.\n\nInitial symptoms of tick-borne infections are generally quite similar to that of other viral illnesses. This includes fever, headache, fatigue, and general malaise. This group of diseases can further be difficult to distinguish early on in the disease process due to these general symptoms in addition to most people (reported around 75%) not realizing they have been bitten or exposed to the tick vector. Unique to early Lyme disease is the development of the classic erythema migrans skin rash, also known as the “bull’s eye” or “target” rash, which occurs in about 80% of people diagnosed with Lyme disease. This symptom can be an important distinguishing factor helping to make the diagnosis early. If Lyme disease is unrecognized, misdiagnosed, or improperly treated it can lead to much more severe and serious consequences with the spread of the spirochete to joints, heart, and nervous system causing arthritis, carditis, cranial nerve palsies or encephalopathy and cognitive dysfunction.\n\nRegardless of the specific diagnosis (Lyme, Rocky Mountain Spotted Fever, Colorado Tick Fever, Babesiosis etc.) the key to management and prevention of sequelae is early identification of disease and initiation of appropriate antibiotic therapy. With regard to the effects of a warming world and the expansion of tick populations to previously unexposed areas, adaptive keys to prevention will include expansion of health care infrastructure and pharmacologic availability, as well as education of people and providers as to the risks of disease and preventative measures they can take.\n\nIn the face of these expanding threats, strong collaboration between government officials and environmental scientists is necessary for advancing preventative and reactive response measures. Without acknowledging the climate changes that make environments more habitable for disease carriers, policy and infrastructure will lag behind vector borne disease spread. The human cost associated with denying climate change science is one that concerns many governments. In the United States, the Centers for Disease Control and Prevention (CDC) is conducting a grant program called Building Resilience Against Climate Effects (BRACE) which details a 5 step process for combating climate effects like tick borne disease spread. As is the case when responding to other vectors and effects of climate change, vulnerable populations including children and the elderly will need to be prioritized by any intervention. Productive policies in the U.S. and the world need to accurately model changes in vector populations as well as the burden of disease, educate the public on ways to mitigate infection, and prepare health systems for the increasing disease load.\n\nWhile the physical health impacts of climate change are well known, the impact on mental health has only begun to be recognized in the last decade. According to 2011 in \"American Psychologist\" Clayton & Doherty, concluded that global climate change is bound to have substantial negative impacts on mental health and wellbeing, effects which will primarily be felt by vulnerable populations and those with pre-existing serious mental illness. Research done by Berry, Bowen, and Kjellstrom in 2008 found that climate change exposes populations to trauma, which negatively impacts mental health in very serious ways.\nBoth the Clayton study and the Berry study identify three classes of psychological impacts from global climate change: direct, indirect, and psychosocial. The Clayton study claims that in order to appreciate these impacts on psychological wellbeing, a basic understanding of certain aspects is required. One must recognize the multiple meanings and cultural narratives associated with climate change, as well as how climate change, global phenomena like increased population, are interrelated. Climate change does not impact everyone equally; those of lower economic and social status are at greater risk and experience more devastating impacts. A 2018 study of CDC data connected temperature rise to increased numbers of suicides. The study revealed that hotter days could increase suicide rates and could cause approximately 26,000 more suicides in the U.S. by 2050.\n\nDirect impacts on mental health happen when a community experiences extreme weather and changed environment. \nDirect impacts like landscape changes, impaired place attachment, and psychological trauma are all immediate and localized problems resulting from extreme weather events and environmental changes. Extreme weather events cause negative changes to landscape and agriculture. This leads to communities facing economic aspects, especially for communities that use agriculture as a main source of income. After economic fall, communities face loss of livelihoods and poverty. Many communities will also face isolation, alienation, grief, bereavement, and displacement from these effects. Individuals will have an increased rate of anxiety and emotional stress. The rate of effects on mental health increases in already-vulnerable communities. Clayton reinforces that the more powerful the extreme weather event, and the more frequent these weather events are, the more damage is done to the mental health of the community.\nSome of the extreme weather events responsible for these mental health changes include wildfires, earthquakes, hurricanes, fires, floods, and extreme heat.\n\nIndirect impacts on mental health occur via impacts on physical health and community wellbeing. Physical health and mental health have a reciprocal relationship. If the physical health of an individual is negatively impacted, the decline in mental health will soon follow. These impacts are more gradual and cumulative. They are threats to emotional wellbeing through concern and uncertainly about future risks. They are also large-scale community and social effects, like conflicts related to migration and subsequent shortages or adjustment after a disaster. Extreme weather events play a major role here; their impacts can be indirect, not just direct. This is due to the effect on physical health from extreme weather events. Each extreme weather event effects humans in different ways, but they all lead to the decline of mental health.\nHeat indirectly causes mental health issues through physical health issues. The World Health Organization presents the fact that high extreme heat is directly related to certain ailments like cardiovascular disease, respiratory disease, and asthma. One piece of their evidence is that in summer 2003, during Europe's big heat wave, there were 70,000 recorded deaths related to the heat. Heat exhaustion also occurs during extreme heat. As climate change continues, heat will continue to rise and these problems will exacerbate. These physical problems lead to mental health problems. As physical health worsens and is less curable, mental stability starts to deteriorate.\n\nAs extreme heat makes landscapes dry, nature is more prone to fire. Research shows that rising heat due to climate change has caused an increase in fires around the United States. Burns and smoke inhalation from the increasing number of fires lead to a decline in physical health, which leads to mental health problems. Deaths of family and friends cause individuals to suffer from stress and other conditions. Many suffering from loss of family and friends will internalize their emotions, feel extreme guilt and helplessness, and become paranoid. Others will develop fear of future loss and have an overall displacement of feelings that could last for years. Anderson published research in the American Psychological Association that shows the increase in murders in the United States directly correlates with the temperature increase. For every one-degree Fahrenheit, there will be nine more murders in the country, which leads to an additional 24,000 murders or assaults per year in the United States.\n\nThere is also an increased risk in suicide in communities that suffer from extreme weather events. Studies show that suicide rates increase after extreme weather events. This is evidence for the decline in mental health. The increased suicide risk has been demonstrated in Australia, where drought has resulted in crop failures and despair to the Australian countryside. After the event, farmers were left with almost nothing. They were forced to sell their belongings, reduce their stock, and borrow large sums of money to plant crops at the start of the next season. These consequences have caused a growing increase in depression, domestic violence, and suicide. More than one hundred farmers in the Australian countryside had committed suicide by 2007. An individual's suicide often leads to mental health problems of loved ones. They face issues like those who have lost loved ones due to fire: grief, sadness, anger, paranoia, and others.\n\nSome impacts pertaining to mental health are even more gradual and cumulative than the others, like social interaction, media, and communication. The social interaction between communities and within communities is greatly affected by migration. Communities choose to migrate, or are forced to migrate, due to stressors on limited resources. This is worsened by extreme weather events caused by climate change. Common mental health conditions associated indirectly from these extreme weather events include acute traumatic stress, post-traumatic stress disorder, depression, complicated grief, anxiety disorders, sleep difficulties, and sexual dysfunction. Drug abuse and alcohol abuse are also common aftereffects, and can lead to both physical and mental issues, addiction and substance reliance being the most common.\n\nThe effects of Hurricane Katrina, a past extreme weather event in New Orleans, lead to a variety of mental health problems due to the destruction of resources Many people impacted by Hurricane Katrina were left homeless, disenfranchised, stressed, and suffering physical illness. This strain on the public health system decreased access and availability of medical resources. Some climate change adaptation measures may prevent the need for displacement. However, some communities may be unable to implement adaptation strategies, and this will create added stress, further exacerbating already existing mental health issues. Extreme weather events and population displacement lead to limited availability of medications, one of the primary resources required to meet psychological and physical needs of those affected by such events. Less medication and medical resources means fewer people can get the help they need to recover. Slowed recovery and lack of recovery worsen overall mental health.\n\nPsychological impacts are the effects that heat, drought, migrations, and climate-related conflicts have on social life and community life. This includes post-disaster adjustment. Most of these effects are indirect instead of direct, but Clayton and Berry place them in a separate category because they deal with the relationships within a community. Many of the results are from how people use and occupy territory. Human migration of large communities causes discord within those communities because the already scarce resources are even more limited during migration. Agriculture and aquaculture are severely impacted by the extreme weather events of climate change, the suitability of territory being the most notable kind of change. During and after migration, the geographical distribution of populations is altered. Children and parents may be separated at these times. The early separation of kids from their parents can cause symptoms of grieving, depression, and detachment in both the young and old. The loss in resources can also lead to inter-community violence and aggression. Two groups may fight over remaining natural resources. A community may choose to migrate to find better resources, and encroach on another community's territory, either accidentally or purposefully. Civil unrest can occur when governments fail to adequately protect communities against the extreme weather events that cause these effects. When this happens, individuals lose confidence and trust in their government. A loss in trust can be the beginning of oncoming mental health problems. The disruption of a community when they are forced to relocate results in the deterioration of geographic and social connections. This leads to grief, anxiety, and an overall sense of loss.\n\nPermafrost is an important part of our environment and plays an important role in maintaining the stability of many ecosystems around the world. \nPermafrost is integral to soil stability in arctic regions. Melting permafrost causes the surrounding soil to become unstable and settle. Settlement of surface soil associated with melting permafrost leads to significant infrastructure instability and damage to roads, bridges, buildings, homes, pipelines and airstrips in affected areas.\n\nIn rural Africa and the Middle East, when droughts dry up the regular water supply, rural and impoverished families are forced to resort to drinking the dirty, sediment-and-parasite-laden water that sits in puddles and small pools on the surface of the earth. Many are aware of the presence of contamination, but will drink from these sources nonetheless in order to avoid dying of dehydration. It has been estimated that up to 80% of human illness in the world can be attributed to contaminated water.\n\nWhen there is an adequate amount of drinking water, humans drink from different sources than their livestock. However, when drought occurs and drinking water slowly disappears, catchment areas such as streams and depressions in the ground where water gathers are often shared between people and the livestock they depend on for financial and nutritional support, and this is when humans can fall seriously ill. Although some diseases that are transferred to humans can be prevented by boiling the water, many people, living on just a litre or two of water per day, refuse to boil, as it loses a certain percentage of the water to steam.\n\nThe sharing of water between livestock and humans is one of the most common factors in the transmission of non-tuberulosis mycobacteria (NTM). NTM is carried in cattle and pig feces, and if this contaminates the drinking water supply, it can result in pulmonary disease, disseminated disease or localized lesions in humans with both compromised and competent immune systems. During drought, water supplies are even more susceptible to harmful algal blooms and microorganisms. Algal blooms increase water turbidity, suffocating aquatic plants, and can deplete oxygen, killing fish. Some kinds of blue-green algae create neurotoxins, hepatoxins, cytotoxins or endotoxins that can cause serious and sometimes fatal neurological, liver and digestive diseases in humans. Cyanobacteria grow best in warmer temperatures (especially above 25 degrees Celsius), and so areas of the world that are experiencing general warming as a result of climate change are also experiencing harmful algal blooms more frequently and for longer periods of time. During times of intense precipitation (such as during the “wet season” in much of the tropical and sub-tropical world, including Australia and Panama), nutrients that cyanobacteria depend on are carried from groundwater and the earth's surface into bodies of water. As drought begins and these bodies gradually dry up, the nutrients are concentrated, providing the perfect opportunity for algal blooms.\n\nAs the climate warms, it changes the nature of global rainfall, evaporation, snow, stream flow and other factors that affect water supply and quality. Freshwater resources are highly sensitive to variations in weather and climate. Climate change is projected to affect water availability. In areas where the amount of water in rivers and streams depends on snow melting, warmer temperatures increase the fraction of precipitation falling as rain rather than as snow, causing the annual spring peak in water runoff to occur earlier in the year. This can lead to an increased likelihood of winter flooding and reduced late summer river flows. Rising sea levels cause saltwater to enter into fresh underground water and freshwater streams. This reduces the amount of freshwater available for drinking and farming. Warmer water temperatures also affect water quality and accelerate water pollution.\n\nClimate change is beginning to lead the global population into a food shortage, greatly affecting our livestock supply. Although the change in our climate is causing us to lose food, these sources are also contributing to climate change, essentially, creating a feedback loop. Greenhouse gases, specifically from livestock, are one of the leading sources furthering global warming; these emissions, which drastically effect climatic change, are also beginning to harm our livestock in ways we could never imagine.\n\nOur agricultural food system is responsible for a significant amount of the greenhouse-gas emissions that are produced.\n\nAccording to the IPCC, it makes up between, at least, 10-12% of the emissions, and when there are changes in land due to the agriculture, it can even rise as high as 17%. More specifically, emissions from farms, such as nitrous oxide, methane and carbon dioxide, are the main culprits, and can be held accountable for up to half of the greenhouse-gases produced by the overall food industry, or 80% of all emissions just within agriculture.\n\nThe types of farm animals, as well as the food they supply can be put into two categories: monogastric and ruminant. Typically, beef and dairy, in other words, ruminant products, rank high in greenhouse-gas emissions; monogastric, or pigs and poultry-related foods, are low. The consumption of the monogastric types, therefore, yield less emissions. This is due to the fact that these types of animals have a higher feed-conversion efficiency, and also do not produce any methane.\n\nAs lower-income countries begin, and continue, to develop, the necessity for a consistent meat supply will increase. This means the cattle population will be required to grow in order to keep up with the demand, producing the highest possible rate of greenhouse-gas emissions.\n\nThere are many strategies that can be used to help soften the effects, and the further production of greenhouse-gas emissions. Some of these strategies include a higher efficiency in livestock farming, which includes management, as well as technology; a more effective process of managing manure; a lower dependence upon fossil-fuels and nonrenewable resources; a variation in the animals' eating and drinking duration, time and location; and a cutback in both the production and consumption of animal-sourced foods.\n\nHeat stress on livestock has a devastating effect on not only their growth and reproduction, but their food intake and production of dairy and meat. Cattle require a temperature range of 5-15 degrees Celsius, but upwards to 25 °C, to live comfortably, and once climate change increases the temperature, the chance of these changes occurring increases. Once the high temperatures hit, the livestock struggle to keep up their metabolism, resulting in decreased food intake, lowered activity rate, and a drop in weight. This causes a decline in livestock productivity and can be detrimental to the farmers and consumers. Obviously, the location and species of the livestock varies and therefore the effects of heat vary between them. This is noted in livestock at a higher elevation and in the tropics, of which have a generally increased effect from climate change. Livestock in a higher elevation are very vulnerable to high heat and are not well adapted to those changes.\n\nClimate change has many potential impacts on the production of food crops—from food scarcity and nutrient deficiency to possible increased food production because of elevated carbon dioxide () levels—all of which directly affect human health. Part of this variability in possible outcomes is from the various climate change models used to project potential impacts; each model takes into account different factors and so come out with a slightly different result. A second problem comes from the fact that projections are made based on historical data which is not necessarily helpful in accurate forecasting as changes are occurring exponentially. As such, there are many different possible impacts—both positive and negative—that may result from climate change affecting global regions in different ways.\n\nFood scarcity is a major key for many populations and is one of the prominent concerns with the changing climate. Currently, 1/6 of the global population are without adequate food supply. By 2050, the global population is projected to reach 9 billion requiring global food productions to increase by 50% to meet population demand. In short, food scarcity is a growing concern that, according to many researchers, is projected to worsen with climate change because of a number of factors including extreme weather events and an increase in pests and pathogens.\n\nAs the temperature changes and weather patterns become more extreme, areas which were historically good for farmland will no longer be as amicable. The current prediction is for temperature increase and precipitation decrease for major arid and semi-arid regions (Middle East, Africa, Australia, Southwest United States, and Southern Europe). In addition, crop yields in tropical regions will be negatively affected by the projected moderate increase in temperature (1-2 °C) expected to occur during the first half of the century. During the second half of the century, further warming is projected to decrease crop yields in all regions including Canada and Northern United States. Many staple crops are extremely sensitive to heat and when temperatures rise over 36 °C, soybean seedlings are killed and corn pollen loses its vitality. Scientists project that an annual increase of 1 °C will in turn decrease wheat, rice and corn yields by 10%.\n\nThere are, however, some positive possible aspects to climate change as well. The projected increase in temperature during the first half of the century (1-3 °C) is expected to benefit crop and pasture yields in the temperate regions. This will lead to higher winter temperatures and more frost-free days in these regions; resulting in a longer growing season, increased thermal resources and accelerated maturation. If the climate scenario results in mild and wet weather, some areas and crops will suffer, but many may benefit from this.\n\nExtreme weather conditions continue to decrease crop yields in the form of droughts and floods. While these weather events are becoming more common, there is still uncertainty and therefore a lack of preparedness as to when and where they will take place. In extreme cases, floods destroy crops, disrupting agricultural activities and rendering workers jobless and eliminating food supply. On the opposite end of the spectrum, droughts can also wipe out crops. It is estimated that 35-50% of the world's crops are at risk of drought. Australia has been experiencing severe, recurrent droughts for a number of years, bringing serious despair to its farmers. The country's rates of depression and domestic violence are increasing and as of 2007, more than one hundred farmers had committed suicide as their thirsty crops slipped away. Drought is even more disastrous in the developing world, exacerbating the pre-existing poverty and fostering famine and malnutrition.\n\nDroughts can cause farmers to rely more heavily on irrigation; this has downsides for both the individual farmers and the consumers. The equipment is expensive to install and some farmers may not have the financial ability to purchase it. The water itself must come from somewhere and if the area has been in a drought for any length of time, the rivers may be dry and the water must be transported from further distances. With 70% of “blue water” currently being used for global agriculture, any need over and above this could potentiate a water crisis. In Sub-Saharan Africa, water is used to flood rice fields to control the weed population; with the projection of less precipitation for this area, this historical method of weed control will no longer be possible.\n\nWith more costs to the farmer, some will no longer find it financially feasible to farm. Agriculture employs the majority of the population in most low-income countries and increased costs can result in worker layoffs or pay cuts. Other farmers will respond by raising their food prices; a cost which is directly passed on to the consumer and impacts the affordability of food. Some farms do not export their goods and their function is to feed a direct family or community; without that food, people will not have enough to eat. This results in decreased production, increased food prices, and potential starvation in parts of the world.\n\nSome research suggests that initially climate change will help developing nations because some regions will be experiencing more negative climate change effects which will result in increased demand for food leading to higher prices and increased wages. However, many of the projected climate scenarios suggest a huge financial burden. For example, the heat wave that passed through Europe in 2003 cost 13 billion euros in uninsured agriculture losses. In addition, during El Nino weather conditions, the chance of the Australian farmer's income falling below average increased by 75%, greatly impacting the country's GDP. The agriculture industry in India makes up 52% of their employment and the Canadian Prairies supply 51% of Canadian agriculture; any changes in the production of food crops from these areas could have profound effects on the economy. This could negatively affect the affordability of food and the subsequent health of the population.\n\nCurrently, levels are 40% higher than they were in pre-industrial times. This diminishes nutritional content for both human and insect consumption. Studies have shown that when levels rise, soybean leaves are less nutritious; therefore plant-eating beetles have to eat more to get their required nutrients. In addition, soybeans are less capable of defending themselves against the predatory insects under high . The diminishes the plant's jasmonic acid production, an insect-killing poison that is excreted when the plant senses it's being attacked. Without this protection, beetles are able to eat the soybean leaves freely, resulting in a lower crop yield. This is not a problem unique to soybeans, and many plant species’ defense mechanisms are impaired in a high environment.\n\nCurrently, pathogens take 10-16% of the global harvest and this level is likely to rise as plants are at an ever-increasing risk of exposure to pests and pathogens. Historically, cold temperatures at night and in the winter months would kill off insects, bacteria and fungi. The warmer, wetter winters are promoting fungal plant diseases like soybean rust to travel northward. Soybean rust is a vicious plant pathogen that can kill off entire fields in a matter of days, devastating farmers and costing billions in agricultural losses. Another example is the Mountain Pine Beetle epidemic in BC, Canada which killed millions of pine trees because the winters were not cold enough to slow or kill the growing beetle larvae. The increasing incidence of flooding and heavy rains also promotes the growth of various other plant pests and diseases. On the opposite end of the spectrum, drought conditions favour different kinds of pests like aphids, whiteflies and locusts.\n\nThe competitive balance between plants and pests has been relatively stable for the past century, but with the rapidly shifting climate, there is a change in this balance which often favours the more biologically diverse weeds over the monocrops most farms consist of. Currently, weeds claim about one tenth of global crop yields annually as there are about eight to ten weed species in a field competing with crops. Characteristics of weeds such as their genetic diversity, cross-breeding ability, and fast-growth rates put them at an advantage in changing climates as these characteristics allow them to adapt readily in comparison to most farm's uniform crops, and give them a biological advantage. There is also a shift in the distribution of pests as the altered climate makes areas previously uninhabitable more uninviting. Finally, with the increased levels, herbicides will lose their efficiency which in turn increases the tolerance of weeds to herbicides.\n\n Another area of concern is the effect of climate change on the nutritional content of food for human consumption. Studies show that increasing atmospheric levels of have an unfavourable effect on the nutrients in plants. As the carbon concentration in the plant's tissues increase, there is a corresponding decrease in the concentration of elements such as nitrogen, phosphorus, zinc and iodine. Of significant concern is the protein content of plants, which also decreases in relation to elevating carbon content. \nIrakli Loladze explains that the lack of essential nutrients in crops contributes the problem of micronutrient malnutrition in society, commonly known as “hidden hunger”; despite adequate caloric intake, the body still is not nutritionally satisfied and therefore continues to be “hungry”. This problem is aggravated by the rising cost of food, resulting in a global shift towards diets which are less expensive, but high in calories, fats, and animal products. This results in undernutrition and an increase in obesity and diet-related chronic diseases.\nCountries worldwide are already impacted by deficiencies in micronutrients and are seeing the effects in the health of their populations. Iron deficiency affects more than 3.5 billion people; increasing maternal mortality and hindering cognitive development in children, leading to education losses. Iodine deficiency leads to ailments like goitre, brain damage and cretinism and is a problem in at least 130 different countries. Even though these deficiencies are invisible, they have great potential to impact human health on a global scale.\nIt must also be noted that small increases in levels can cause a fertilization effect where the growth and reproduction abilities of C plants such as soybeans and rice are actually enhanced by 10-20% in laboratory experiments. This does not take into account, however, the additional burden of pests, pathogens, nutrients and water affecting the crop yield.\n\nWhile researchers acknowledge there are possible benefits of global warming, most agree that the negative consequences of climate change will outweigh any potential benefits and instead the shifting climate will result in more benefits to developed countries and more detriments to developing countries; exacerbating the discrepancy between wealthy and impoverished nations. By thoughtful and proactive efforts, climate change can be mitigated by addressing these issues with a multidisciplinary approach that works on a global, national and community basis that recognizes the uniqueness of each country's situation. \nAccording to a study of East Africa’s smallholder farms, impacts of climate change on agriculture are already being seen there resulting in changes to farming practices such as intercropping, crop, soil, land, water and livestock management systems, and introduction of new technologies and seed varieties by some of the farmers. Some other suggestions such as eliminating supply chain and household food waste, encouraging diverse and vegetable-rich diets, and providing global access to foods (food aid programs) have been suggested as ways to adapt. Many researchers agree that agricultural innovation is essential to addressing the potential issues of climate change. This includes better management of soil, water-saving technology, matching crops to environments, introducing different crop varieties, crop rotations, appropriate fertilization use, and supporting community-based adaptation strategies. On a government and global level, research and investments into agricultural productivity and infrastructure must be done to get a better picture of the issues involved and the best methods to address them. Government policies and programs must provide environmentally sensitive government subsidies, educational campaigns and economic incentives as well as funds, insurance and safety nets for vulnerable populations. In addition, providing early warning systems, and accurate weather forecasts to poor or remote areas will allow for better preparation; by using and sharing the available technology, the global issue of climate change can be addressed and mitigated by the global community.\n\nPerhaps one of the most recent adverse effects of climate change to be explored is that of ocean acidification. Our oceans cover approximately 71 percent of the Earth's surface and support a diverse range of ecosystems, which are home to over 50 percent of all the species on the planet. Oceans regulate climate and weather as well as providing nutrition for a vast variety of species, humans included. Covering such an extensive part of the planet has allowed the oceans to absorb a large portion of the carbon dioxide () from the atmosphere. This process is part of the carbon cycle in which the fluxes of carbon dioxide () in Earth's atmosphere, biosphere and lithosphere are described. Humans have drastically added to the amount of carbon dioxide () in the atmosphere through the burning of fossil fuels and the process of deforestation. Oceans work as a sink absorbing excess anthropogenic carbon dioxide (). As the oceans absorb anthropogenic carbon dioxide () it breaks down into carbonic acid, a mild acid, this neutralizes the normally alkaline ocean water. As a result, the pH in the oceans is declining. In the research surrounding global climate change we are only just beginning to realize that our oceans can sequester a finite amount of before we start seeing impacts on marine life that could lead to devastating losses. Acidification of our oceans has the potential to drastically alter life as we know it - from extreme weather patterns and food scarcity to a loss of millions of species from the planet - all of these consequences hold the potential to directly affect human health.\n\nWith degradation of protective coral reefs through acidic erosion, bleaching and death, salt water is able to infiltrate fresh ground water supplies that large populations depend on. Nowhere is this more evident than atoll islands. These islands possess limited freshwater supplies, namely ground water lenses and rain fall. When the protective coral reefs surrounding them erodes due to higher temperatures and acidic water chemistry, salt water is able to infiltrate the lens and contaminate the drinking water supply. In coastal Bangladesh it has been demonstrated that seasonal hypertension in pregnant women is connected with such phenomenon due to high sodium intake from drinking water. Reef erosion, coupled with sea level rise, tends to flood low-lying areas more frequently during storm surges and weather events. Warming ocean waters generate larger and more devastating weather events that can decimate coastal populations especially without the protection of coral reefs.\n\nThe health of our oceans has a direct effect on the health humans. According to Small and Nicholls, they estimated that 1.2 billion people worldwide, lived in the near-coastal region (within 100 km and 100m of the shoreline). This data was collected in 1990 and therefore is a conservative estimate in modern terms. In the U.S. alone 53% of the population lives within 50 miles of the coastal shoreline. Humans rely heavily on oceans for food, employment, recreation, weather patterns and transportation. In the U.S. alone the lands adjacent to the oceans contribute over $1 trillion annually through these various activities not to mention pharmaceutical and medicinal discoveries. In all, the oceans are very important for our survival as a species.\n\nOur insatiable appetite for seafood of all types has led to overfishing and has already significantly strained marine food stocks to the point of collapse in many cases. With seafood being a major protein source for so much of the population, there are inherent health risks associated with global warming. As mentioned above increased agricultural runoff and warmer water temperature allows for eutrophication of ocean waters. This increased growth of algae and phytoplankton in turn can have dire consequences. These algal blooms can emit toxic substances that can be harmful to humans if consumed. Organisms, such as shellfish, marine crustaceans and even fish, feed on or near these infected blooms, ingest the toxins and can be consumed unknowingly by humans. One of these toxin producing algae is Pseudo-nitzschia fraudulenta. This species produces a substance called domoic acid which is responsible for amnesic shellfish poisoning. The toxicity of this species has been shown to increase with greater concentrations associated with ocean acidification. Some of the more common illnesses reported from harmful algal blooms include; Ciguatera fish poisoning, paralytic shellfish poisoning, azaspiracid shellfish poisoning, diarrhetic shellfish poisoning, neurotoxic shellfish poisoning and the above-mentioned amnesic shellfish poisoning.\n\nInfectious disease often accompanies extreme weather events, such as floods, earthquakes and drought. These local epidemics occur due to loss of infrastructure, such as hospitals and sanitation services, but also because of changes in local ecology and environment. For example, malaria outbreaks have been strongly associated with the El Niño cycles of a number of countries (India and Venezuela, for example). El Niño can lead to drastic, though temporary, changes in the environment such as temperature fluctuations and flash floods. Because of global warming there has been a marked trend towards more variable and anomalous weather. This has led to an increase in the number and severity of extreme weather events. This trend towards more variability and fluctuation is perhaps more important, in terms of its impact on human health, than that of a gradual and long-term trend towards higher average temperature.\n\nArguably one of the worst effects that drought has directly on human health is the destruction of food supply. Farmers who depend on weather to water their crops lose tons of crops per year due to drought. Plant growth is severely stunted without adequate water, and plant resistance mechanisms to fungi and insects weaken like human immune systems. The expression of genes is altered by increased temperatures, which can also affect a plant's resistance mechanisms. One example is wheat, which has the ability to express genes that make it resistant to leaf and stem rusts, and to the Hessian fly; its resistance declines with increasing temperatures.\nA number of other factors associated with lack of water may actually attract pestilent insects, as well- some studies have shown that many insects are attracted to yellow hues, including the yellowing leaves of drought-stressed plants.\nDuring times of mild drought is when conditions are most suitable to insect infestation in crops; once the plants become too weakened, they lack the nutrients necessary to keep the insects healthy. This means that even a relatively short, mild drought may cause enormous damage- even though the drought on its own may not be enough to kill a significant portion of the crops, once the plants become weakened, they are at higher risk of becoming infested.\n\nThe results of the loss of crop yields affect everyone, but they can be felt most by the poorest people in the world. As supplies of corn, flour and vegetables decline, world food prices are driven up. Malnutrition rates in poor areas of the world skyrocket, and with this, dozens of associated diseases and health problems. Immune function decreases, so mortality rates due to infectious and other diseases climb. For those whose incomes were affected by droughts (namely agriculturalists and pastoralists), and for those who can barely afford the increased food prices, the cost to see a doctor or visit a clinic can simply be out of reach. Without treatment, some of these diseases can hinder one's ability to work, decreasing future opportunities for income and perpetuating the vicious cycle of poverty.\n\nHealth concerns around the world can be linked to floods. With the increase in temperatures worldwide due to climate change the increase in flooding is unavoidable. Floods have short and long term negative implications to peoples' health and well being. Short term implications include mortalities, injuries and diseases, while long term implications include non-communicable diseases and psychosocial health aspects.\n\nMortalities are not uncommon when it comes to floods. The Countries with lower incomes are more likely to have more fatalities, because of the lack of resources they have and the supplies to prepare for a flood. This does depend on the type and properties of the flood. For example, if there is a flash flood it would not matter how prepared you are. Fatalities connected directly to floods are usually caused by drowning; the waters in a flood are very deep and have strong currents. Deaths do not just occur from drowning, deaths are connected with dehydration, heat stroke, heart attack and any other illness that needs medical supplies that cannot be delivered. Due to flooding mud, grit or sand particles can be deposited into the lakes and rivers. These particles cause the water to become dirty and this becomes a problem as the dirty water leads to water related diseases. For example, cholera and guinea worm disease are caused by dirty water.\n\nInjuries can lead to an excessive amount of morbidity when a flood occurs. Victims who already have a chronic illness and then sustain a non-fatal injury are put at a higher risk for that non-fatal injury to become fatal. Injuries are not isolated to just those who were directly in the flood, rescue teams and even people delivering supplies can sustain an injury. Injuries can occur anytime during the flood process; before, during and after. Before the flood people are trying to evacuate as fast as they can, motor vehicle accidents, in this case, are a primary source of injuries obtained post flood. During floods accidents occur with falling debris or any of the many fast moving objects in the water. After the flood rescue attempts are where large numbers injuries can occur.\n\nCommunicable diseases are increased due to many pathogens and bacteria that are being transported by the water. In floods where there are many fatalities in the water there is a hygienic problem with the handling of bodies, due to the panic stricken mode that comes over a town in distress. There are many water contaminated diseases such as cholera, hepatitis A, hepatitis E and diarrheal diseases, to mention a few. There are certain diseases that are directly correlated with floods they include any dermatitis and any wound, nose, throat or ear infection. Gastrointestinal disease and diarrheal diseases are very common due to a lack of clean water during a flood. Most of clean water supplies are contaminated when flooding occurs. Hepatitis A and E are common because of the lack of sanitation in the water and in living quarters depending on where the flood is and how prepared the community is for a flood.\n\nRespiratory diseases are a common after the disaster has occurred. This depends on the amount of water damage and mold that grows after an incident. Vector borne diseases increase as well due to the increase in still water after the floods have settled. The diseases that are vector borne are malaria, dengue, West Nile, and yellow fever.\n\nNon-communicable diseases are a long-term effect of floods. They are either caused by a flood or they are worsened by a flood; they include cancer, lung disease and diabetes. Floods have a huge impact on victims' psychosocial integrity. People suffer from a wide variety of losses and stress. One of the most treated illness in long-term health problems are depression caused by the flood and all the tragedy that flows with one.\n\nAnother result of the warming oceans are stronger hurricanes, which will wreak more havoc on land, and in the oceans, and create more opportunities for vectors to breed and infectious diseases to flourish. Extreme weather also means stronger winds. These winds can carry vectors tens of thousands of kilometers, resulting in an introduction of new infectious agents to regions that have never seen them before, making the humans in these regions even more susceptible.\n\nA glacier is a mass of ice that has originated from snow that has been compacted via pressure and have definite lateral limits and movements in definite directions. They are found in areas where the temperatures do not get warm enough to melt annual snow accumulation, thus resulting in many layers of snow piling up over many years, creating the pressure needed to make a glacier. Global climate change and fluctuation is causing an increasingly exponential melting of Earth's glaciers. These melting glaciers have many social and ecological consequences that directly or indirectly impact the health and well-being of humans. The recession of glaciers change sea salt, sediment, and temperature ratios in the ocean which changes currents, weather patterns, and marine life. The melt also increases ocean levels and decreases the availability of water for human consumption, agriculture, and hydroelectricity. This aggravates and increases the likelihood of issues such as sanitation, world hunger, population shifts, and catastrophic weather such as flooding, drought, and worldwide temperature fluctuations.\n\n“Glacier mass-balances show consistent decreases over the last century in most regions of the world and retreat may be accelerating in many locations\" with an average loss of ten meters per year, nearly twice as fast as ten years ago. Glaciers currently cover ~10% of the Earth's surface, or ~15 million km² and holds ~75% of Earth's fresh water supply. Glacial retreat first gained the attention of alpinists and the tourist industry shortly after 1940 – when the globe warmed ~0.5 °C. Even with 62 years of awareness, climate change is just becoming an issue for some parts of society. Over this time period the cirque and steep alpine glaciers were able to acclimatize to the new temperatures posed by climate change; large valley glaciers have not yet made this adjustment. This means the large valley glaciers are rapidly retreating, as their mass is attempting to achieve equilibrium with the current climate. If regional snow lines stay constant, then the glaciers remain constant. Today this is clearly not the case as global warming is causing mountain snow lines to rapidly retreat. Even the United States’ famous Glacier National Park is receding. More than two-thirds of its glaciers have disappeared and it is expected for them to be nonexistent in the park by the year 2030.\n\nGlacial melt will affect low-lying coastal wetlands via sea level rise, change key drivers of fresh-water ecosystems, shift the timing of snow packs, and alter the unique character of associated fresh water streams off of snow pack. It has also been stated that the sea level will rise 28–43 cm by 2100; if all the ice on Earth melts, it is predicted that the ocean level will increase 75 meters, destroying many coastal cities. In addition, the freshwater swaps in northern areas are already affected by the intrusion of salt water. “Sea level rise will cause a change of state from freshwater to marine or estuarine ecosystems, radically altering the composition of biotic communities\".\n\nNot only are glaciers causing a rise in sea level, they are causing an increase in El Niño Southern Oscillation (ESNO) and global temperature itself. Glacier loss adds to global heat rise through a decrease in what is called ice-albedo feedback. As more ice melts, there is less solar reflectivity and less heat is reflected away from the Earth, causing more heat to be absorbed, and retained in the atmosphere and soil In addition to the El Niño events, glacial melt is contributing to the rapid turnover of sea surface temperatures and ocean salt content by diluting the ocean water and slowing the Atlantic conveyor belt's usually swift dive because of a top layer of buoyant, cold, fresh water that slows the flow of warm water to the north.\n\nFifty percent of the world's fresh water consumption is dependent glacial runoff. Earth's glaciers are expected to melt within the next forty years, greatly decreasing fresh water flow in the hotter times of the year, causing everyone to depend on rainwater, resulting in large shortages and fluctuations in fresh water availability which largely effects agriculture, power supply, and human health and well-being. Many power sources and a large portion of agriculture rely on glacial runoff in the late summer. “In many parts of the world, disappearing mountain glaciers and droughts will make fresh, clean water for drinking, bathing, and other necessary human (and livestock) uses scarce\" and a valuable commodity.\n\nThe upper limit for heat stress humans can adapt to is called into question with a 7 °C temperature rise, quantified by the wet-bulb temperature, regions of Earth would lose their habitability.\n\nEnvironmental changes such as deforestation could increase local temperatures in the highlands thus could enhance the vectorial capacity of the anopheles. Anopheles mosquitoes are responsible for the transmission of a number of diseases in the world, such as, malaria, lymphatic filariasis and viruses that can cause such ailments, like the O'nyong'nyong virus.\nEnvironmental changes, climate variability, and climate change are such factors that could affect biology and ecology of Anophelse vectors and their disease transmission potential. Climate change is expected to lead to latitudinal and altitudinal temperature increases. Global warming projections indicate that the best estimate of surface air warming for a “high scenario” is 4 C, with a likely range of 2.4-6.4 C by 2100. A temperature increase of this size would alter the biology and the ecology of many mosquito vectors and the dynamics of the diseases they transmit such as malaria. Anopheles mosquitoes in highland areas are to experience a larger shift in their metabolic rate due to the climate change. This climate change is due to the deforestation in the highland areas where these mosquitoes dwell. When temperature rises, the larvae take a shorter time to mature and, consequently, there is a greater capacity to produce more offspring. In turn this could potentially lead to an increase in malaria transmission when infected humans are available.\n\nDeforestation is directly linked with a decrease in plant biodiversity. This decrease in biodiversity has several implications for human health. One such implication is the loss of medicinal plants. The use of plants for medicinal purposes is extensive, with ~70 to 80% of individuals worldwide relying solely on plant-based medicine as their primary source of healthcare. This dependency on plants for medicinal purposes is especially rife in developing countries that only consume 15% of manufactured pharmaceutical drugs, many of which are fake. Local knowledge surrounding medicinal plants is useful for screening for new herbal medicines that may be useful for treating disease. Villages and communities which reside continually in a single geographic area over time, create, transmit and apply widespread information surrounding the medicinal resources in the area. Formal scientific methods have been useful in identifying the active ingredients used in ethnopharmacy and applying them to modern medicines. However, it is important that medicinal resources are managed appropriately as they become globally traded in order to prevent species endangerment.\n\nDeforestation is also a primary cause of dislocation and in some cases, extinction of indigenous people. The Malaysian state Sarawak is an example where rampant deforestation has overrun many Dayak groups. The indigenous Sarawakians relied on shifting agriculture, hunting and gathering in order to sustain their relatively low population density. With the advent of modern logging technology the Sarawak forests entered 'mainstream' economic development. This has led to massive forced evacuations and relocation of the Dayak people causing a loss of their traditions and culture.\n\nClimate change and the associated changing weather patterns occurring worldwide have a direct effect on biology, population ecology, and the population of eruptive insects, such as the mountain pine beetle (MPB). This is because temperature is a factor which determines insect development and population success. Mountain Pine Beetle are a species native to Western North America. Prior to climatic and temperature changes, the mountain pine beetle predominately lived and attacked lodgepole and ponderosa pine trees at lower elevations, as the higher elevation Rocky Mountains and Cascades were too cold for their survival. Under normal seasonal freezing weather conditions in the lower elevations, the forest ecosystems that pine beetles inhabit are kept in a balance by factors such as tree defense mechanisms, beetle defense mechanisms, and freezing temperatures. It is a simple relationship between a host (the forest), an agent (the beetle) and the environment (the weather & temperature). However, as climate change causes mountain areas to become warmer and drier, pine beetles have more power to infest and destroy the forest ecosystems, such as the whitebark pine forests of the Rockies. This is a forest so important to forest ecosystems that it is called the “rooftop of the rockies”. Climate change has led to a threatening pine beetle pandemic, causing them to spread far beyond their native habitat. This leads to ecosystem changes, forest fires, floods and hazards to human health.\n\nThe whitebark pine ecosystem in these high elevations plays many essential roles, providing support to plant and animal life. They provide food for grizzly bears and squirrels, as well as shelter and breeding grounds for elk and deer; protects watersheds by sending water to parched foothills and plains; serves as a reservoir by dispensing supplies of water from melted snowpacks that are trapped beneath the shaded areas; and creates new soil which allows for growth of other trees and plant species. Without these pines, animals do not have adequate food, water, or shelter, and the reproductive life cycle, as well as quality of life, is affected as a consequence. Normally, the pine beetle cannot survive in these frigid temperatures and high elevation of the Rocky Mountains. However, warmer temperatures means that the pine beetle can now survive and attack these forests, as it no longer is cold enough to freeze and kill the beetle at such elevations. Increased temperatures also allow the pine beetle to increase their life cycle by 100%: it only takes a single year instead of two for the pine beetle to develop. As the Rockies have not adapted to deal with pine beetle infestations, they lack the defenses to fight the beetles. Warmer weather patterns, drought, and beetle defense mechanisms together dries out sap in pine trees, which is the main mechanism of defense that trees have against the beetle, as it drowns the beetles and their eggs. This makes it easier for the beetle to infest and release chemicals into the tree, luring other beetles in an attempt to overcome the weakened defense system of the pine tree. As a consequence, the host (forest) becomes more vulnerable to the disease-causing agent (the beetle).\n\nThe whitebark forests of the Rockies are not the only forests that have been affected by the mountain pine beetle. Due to temperature changes and wind patterns, the pine beetle has now spread through the Continental Divide of the Rockies and has invaded the fragile boreal forests of Alberta, known as the “lungs of the Earth”. These forests are imperative for producing oxygen through photosynthesis and removing carbon in the atmosphere. But as the forests become infested and die, carbon dioxide is released into the environment, and contributes even more to a warming climate. Ecosystems and humans rely on the supply of oxygen in the environment, and threats to this boreal forest results in severe consequences to our planet and human health. In a forest ravaged by pine beetle, the dead logs and kindle which can easily be ignited by lightning. Forest fires present dangers to the environment, human health and the economy. They are detrimental to air quality and vegetation, releasing toxic and carcinogenic compounds as they burn. Due to human induced deforestation and climate change, along with the pine beetle pandemic, the strength of forest ecosystems decrease. The infestations and resulting diseases can indirectly, but seriously, effect human health. As droughts and temperature increases continue, so does the frequency of devastating forest fires, insect infestations, forest diebacks, acid rain, habitat loss, animal endangerment and threats to safe drinking water.\n\nClimate change increases wildfire potential and activity. Climate change leads to a warmer ground temperature and its effects include earlier snowmelt dates, drier than expected vegetation, increased number of potential fire days, increased occurrence of summer droughts, and a prolonged dry season.\n\nWarming spring and summer temperatures increase flammability of materials that make up the forest floors. Warmer temperatures cause dehydration of these materials, which prevents rain from soaking up and dampening fires. Furthermore, pollution from wildfires can exacerbate climate change by releasing atmospheric aerosols, which modify cloud and precipitation patterns.\n\nWood smoke from wildfires produces particulate matter that has damaging effects to human health. The primary pollutants in wood smoke are carbon monoxide and nitric oxide. Through the destruction of forests and human-designed infrastructure, wildfire smoke releases other toxic and carcinogenic compounds, such as formaldehyde and hydrocarbons. These pollutants damage human health by evading the mucociliary clearance system and depositing in the upper respiratory tract, where they exert toxic effects. Research by Naeher and colleagues. found that physician visits for respiratory diseases increased by 45-80% during wildfire activity in urban British Columbia.\n\nThe health effects of wildfire smoke exposure include exacerbation and development of respiratory illness such as asthma and chronic obstructive pulmonary disorder; increased risk of lung cancer, mesothelioma and tuberculosis; increased airway hyper-responsiveness; changes in levels of inflammatory mediators and coafulation factors; and respiratory tract infection. It may also have intrauterine effects on fetal development, resulting in low birth weight newborns. Because wildfire smoke travels and is often not isolated to a single geographic region, the health effects are widespread among populations.\nThe suppression of wild fires also takes up a large amount of a country's gross domestic product which directly affects the country's economy. In the United States, it was reported that approximately $6 million was spent between 2004-2008 to suppress wildfires in the country.\n\nClimate change causes displacement of people in several ways, the most obvious—and dramatic—being through the increased number and severity of weather-related disasters which destroy homes and habitats causing people to seek shelter or livelihoods elsewhere. Slow onset phenomena, including effects of climate change such as desertification and rising sea levels gradually erode livelihoods and force communities to abandon traditional homelands for more accommodating environments. This is currently happening in areas of Africa's Sahel, the semi-arid belt that spans the continent just below its northern deserts. Deteriorating environments triggered by climate change can also lead to increased conflict over resources which in turn can displace people.\n\nExtreme environmental events are increasingly recognized as a key driver of migration across the world. According to the Internal Displacement Monitoring Centre, more than 42 million people were displaced in Asia and the Pacific during 2010 and 2011, more than twice the population of Sri Lanka. This figure includes those displaced by storms, floods, and heat and cold waves. Still others were displaced drought and sea-level rise. Most of those compelled to leave their homes eventually returned when conditions improved, but an undetermined number became migrants, usually within their country, but also across national borders.\n\nAsia and the Pacific is the global area most prone to natural disasters, both in terms of the absolute number of disasters and of populations affected. It is highly exposed to climate impacts, and is home to highly vulnerable population groups, who are disproportionately poor and marginalized. A recent Asian Development Bank report highlights “environmental hot spots” that are particular risk of flooding, cyclones, typhoons, and water stress.\n\nTo reduce migration compelled by worsening environmental conditions, and to strengthen resilience of at-risk communities, governments should adopt policies and commit financing to social protection, livelihoods development, basic urban infrastructure\ndevelopment, and disaster risk management. Though every effort should be made to ensure that people can stay where they live, it is also important to recognize that migration can also be a way for people to cope with environmental changes. If properly managed, and efforts made to protect the rights of migrants, migration can provide substantial benefits to both origin and destination areas, as well as to the migrants themselves. However, migrants – particularly low-skilled ones – are among the most vulnerable people in society and are often denied basic protections and access to services.\n\nThe links between the gradual environmental degradation of climate change and displacement are complex: as the decision to migrate is taken at the household level, it is difficult to measure the respective influence of climate change in these decisions with regard to other influencing factors, such as poverty, population growth or employment options. This situates the debate on environmental migration in a highly contested field: the use of the term 'environmental refugee', although commonly used in some contexts, is disrecommended by agencies such as the UNHCR who argue that the term 'refugee' has a strict legal definition which does not apply to environmental migrants. Neither the UN Framework Convention on Climate Change nor the Kyoto Protocol, an international agreement on climate change, includes any provisions concerning specific assistance or protection for those who will be directly affected by climate change.\n\n\n"}
{"id": "39598998", "url": "https://en.wikipedia.org/wiki?curid=39598998", "title": "Electronic health record confidentiality", "text": "Electronic health record confidentiality\n\nElectronic health record medical healthcare systems are developing widely. Things are being moved from the manual ways to automation and the patient records and health records are also being recorded electronically. One important aspect of any health record system is to ensure the confidentiality of the patient information because of its importance in the medical field.\n\nIn the recent times, the individual patient’s and population’s health information is recorded in form of electronically accessible files known as electronic health records (EHR). These are digital records which can be easily transferred across the internet.\nA multitude of information is contained within the electronic health including billing information, patient’s weight, age, vital signs, radiology images, laboratory test results, immunization status, allergies, medication, medical history and demographics etc.\n\nRegardless of being in a paper form or electronic form, a medical health record is a tool of communication which helps in making clinical decisions, designing regulatory processes, accreditation, education, legal protection, research purposes, service coordination and evaluation of the efficacy and quality of healthcare provided.\n\nIn order to ensure the safe and secure usage of the Electronic Health Records, the Australian government introduced the Personally Controlled Electronic Health Records Act in 2012. The act provides information regarding the rights of patients, obligatory information protection steps by the medical staff and organizations and the steps of registration with reference to the usage of patient’s Personally Controlled Electronic Health Record.\n\nSince Electronic Health Records have more of a virtual existence than a physical one, protecting them also requires usage of appropriate technological tools and techniques. The following measures regarding the protection of Electronic Health Records are worth highlighting:\n\nEnsuring the prevention of confidentiality breakage requires the provision of authorized access to the patient’s healthcare information. In order to do so, the following steps could be taken:\n\nData theft and alteration has been a major problem in the recent times. Moreover, as far as patient health records are concerned, there are always potential threats of information leakages, data hacking, information destruction, manipulation or even blackmailing of patients by the external or internal users. Since the consequences of Information leaks are comparatively high in contrast to information alterations, one possible way to have information regarding the user of information is to audit information trails.\nAudit trails refer to keeping information about who had recently used or accessed patient records. Through the usage of audit trails and the above-mentioned security steps, Electronic Health Records could most probably be made the best way of collecting, storing, retaining and using patient health information.\n"}
{"id": "2618839", "url": "https://en.wikipedia.org/wiki?curid=2618839", "title": "Emergency (1959 TV series)", "text": "Emergency (1959 TV series)\n\nEmergency is an Australian television series produced by GTV-9 in 1959.\n\nThe series was set in the busy casualty department of a major Melbourne hospital, and is notable for being one of the first-ever dramas shown on Australian television.\n\nMade by Melbourne's GTV-9 in co-operation with the Royal Melbourne Hospital, and based on Britain's \"Emergency Ward 10\", \"Emergency\" starred Brian James as Dr. Geoffrey Thompson, Syd Conabere as orderly George Rogers, and Judith Godden as Nurse Jill Adamson. Moira Carleton also featured as Matron Evans.\n\nThe series was produced primarily in the GTV-9 studio, with brief (usually pre-credit) exterior sequences shot on 35mm film by newsreel cameramen. The episodes were not broadcast live, but were kinescoped to meet programming requirements, and facilitate later screening in Sydney.\n\nThe series' premise was simple: a basic dramatic exploration of cases passing through the Casualty ward. Scripts were written by GTV staffers Roland Strong (series producer) and Denzil Howson (series director) under pseudonyms.\n\nSponsorship came from British Petroleum, and a contract was signed for 52 half-hour episodes. The series debuted on GTV-9 on 16 February 1959, and on Sydney's ATN-7 a week later. Critics initially appeared fairly neutral, however a highly negative article on the series in a Sydney newspaper caused BP to withdraw sponsorship 16 weeks into the series run. Faced with having to carry the production expenses alone, GTV-9 discontinued production, with the final episode airing in Melbourne on 1 June 1959.\n\nFollowing the series demise, Brian James went on to lead roles in the ABC serial \"Stormy Petrel\" in 1960, and ATN-7's period drama \"Jonah\" in 1962, later appearing as George Tippit in the drama serial \"Skyways\" (1979–81).\n\nConabere and Carleton appeared in guest roles in most of the Australian TV dramas on the 1960s and 1970s.\n\n\n"}
{"id": "39924959", "url": "https://en.wikipedia.org/wiki?curid=39924959", "title": "Environmental health ethics", "text": "Environmental health ethics\n\nEnvironmental health ethics is a field of study that combines environmental health policies and ethical consideration towards a mutually acceptable goal. Given the myriad of environmental issues facing society today a sound ethical background can be applied in an attempt to reach a compromise between conflicting interests, like anthropocentrism, global stewardship, religious values, economic development, and public health. A small sample of the scientific disciplines involved in environmental health ethics include: ecology, toxicology, epidemiology, and exposure biology.\n\nEnvironmental health embodies a wide range of topics with which there are many ethical issues. Many of these issues can be traced back to a moral obligation towards to life forms and other units of biological organization, like ecosystems, and the nature of that obligation. Humanity's place within any given ecosystem must be weighed against the importance of regional, and global health of the environment as a whole. Human and animal rights, property use, and other freedoms can be combined with other factors like to form an ethical dilemma social justice, equality, sustainability, and globalism to form ethical dilemmas. In response to difficulties with using moral theories to resolve ethical dilemmas various approaches can be used. A case-by-case approach may be too slow when considering the volume of issues at present, so an alternative may be better suited to the task. Taking into account commonly accepted moral virtues can guide conduct and address conflicts between values, rules, and obligations. Most, if not all, of these generally held principles can be found in the ethical approaches listed above, an example of which may be 'respect human rights'. This Principle-Based Method for ethical decision making can be viewed below.\n\n\nAfter settling on a methodology for analyzing different ethical situations we can turn to a broad survey of some of the most relevant issues which face humanity today.\n\nPesticides are used throughout the world in an attempt to control, repel, or kill pest species. Though many species of insect can be commonly identified throughout the world, others may harm human health and well-being while providing a benefit to the overall environment of an area. One example of the phenomenon is a bee's ability to sting an individual who may have a serious allergic reaction, though they also play a crucial role in the pollination of an ecosystem. A further example would be various species of bat, which though they can transmit rabies, also help to control mosquito populations.\nPerhaps the biggest event in the history of pesticide use is the widespread use of DDT to control various pests, including mosquitoes and lice. Its long-term effects had not been sufficiently documented and thus it was assumed to be of low toxicity. Over time the widespread use of DDT began to have serious environmental and human health consequences. Organisms further up the food chain showed significant amounts of DDT in their tissues and this presence had adverse health effects, for example, the weakening of predatory bird eggshells and fish kills. Adverse effects among humans included endocrine system disruption which can lead to reproductive complications.\n\nAmong the most disruptive pesticides are those dubbed Persistent organic pollutants (POPs) which do not break down easily in the environment, or if they do they become something equally harmful. Because POPs represent such a threat to organisms within an environment, especially those higher on a food chain, specific international legislation referred to as the Stockholm Convention banned several of them being used. Some of these pollutants are DDT, aldrin, chlordane, dieldrin, endrin, heptachlor, hexachlorobenzene, and toxaphene.\n\nWith these considerations in place it falls onto lawmakers to regulate responsible use of pesticides, and ethics can provide a starting point to consider the best option. Extensive use of pesticides would improve life in the short-term but be harmful in the long-term, and completely banning their use would likewise be detrimental to overall environmental and human health. One strategy to encourage is called Integrated Pest Management (IPM), in which pesticides are responsibly used to limit agricultural loss but also watched for growing resistance and environmental toxicity. The Center for Disease Control (CDC) have also taken measured to educate clinicians and the public about relevant issues and the best ways to manage pesticide use.\n\nGenetic engineering concerns the application of scientific alteration of plant and animal DNA in order to combat pests, disease, drought, and other factors which can adversely harm the organism. Objections to genetically modified organisms (GMOs) include theological (playing God) and economic (GMOs can be costly) viewpoints. Genetic engineering of both plants and animals must pass through FDA legislation, which may include public labeling of the product or otherwise marking it as genetically modified.\n\nFood and nutrition also fall under the category of things regulated by the FDA, however, the ethics of this regulation are not always clear. Health consequences of unsafe food, eating in overlarge quantities, are well documented yet in all societies there is no legislation against over-consumption. Ethical properties of utilitarianism and social justice conflict with humanity's freedom of choice in the determining of access to healthy, safe food.\n\nAir, water, and solid waste pollution are environmental health issues which can adversely affect people, plants, and animals. From an ethical standpoint many things about pollutants can be studied, like questions of disposal, storage, recycling, and responsibility. A few examples of air pollutants include particulate matter, sulfur dioxide, nitrogen oxides, carbon oxides, chlorofluorocarbons, and heavy metals (e.g. mercury). Perhaps the largest ethical debate concerning air pollution is how to balance economic development against the interests of the public health, safety, and cleanliness. With both sides offering benefits and drawbacks it can be difficult to establish an acceptable compromise. Legislation enacted to prevent widespread use of chlorofluorocarbons, which cause significant environmental damage, can be seen as one instance of economic development taking a lower priority to public health.\n\nWater pollution is another type of widespread contaminant which has ethical implications in mitigating the source and balancing conflicting priorities. The two types of water contaminants are anthropogenic compounds (generally referred to as pollutants, such as disinfection products, metals, municipal and agricultural waste, and petroleum and coal hydrocarbons) and natural contaminants (such as microorganisms or chemicals like arsenic and nitrogen, which are naturally present in the soil). the common misconception is that chemicals leaking into the soil will be diluted over time and rendered harmless. This theory does not take into account persistent organic pollutants, which do not break down easily, and sometimes break down into more harmful constituents. Most industrialized nations have legislation in place to protect the public from impure drinking water. The Safe Drinking Water Act of 1974 established maximum levels of pollutants in public drinking water, however its power to regulate private sources of bottled water or wells is severely limited. An additional issue regarding water pollution is the relative scarcity of clean fresh water on the earth, an issue which acutely presents itself in areas prone to drought. Agriculture uses a great deal of water, so much so that shortages in drought-prone areas can significantly affect crop yield. The main ethical issues with water pollution is whether growth should be restricted in order to preserve public health. An additional issue is the regulation of private corporations, whose activities may put populations of citizens at risk for groundwater contamination.\n\nSolid waste pollution includes pollutants like agricultural waste, construction waste, electronic waste, hazardous waste, medical, and mining waste. The two prevailing strategies for solid waste management are prevention and treatment/disposal. Waste prevention is the preferable, both economically and environmentally, as it does not necessitate costly removal and storage. Many of the same ethical issues related above manifest themselves with the handling and storage of solid waste, as well as an additional social justice issue of exactly where the storage area for solid waste should be located.\n\nChemical regulation, including carbon particles and nanotubes and nanotechnology, are very new technologies whose long-term effects have not been satisfactorily studied. This lack of research argues that cautionary use of these products is warranted, especially when short-term effects include harmful symptoms. In opposition to this caution is the nanotechnology industry which is growing very rapidly and may be able to alleviate many of the problems facing society today, like selective cancer treatment and the energy crisis. Perhaps the largest obstacle to testing occurs with the sheer diversity of nanoparticles, of which the only unifying factor is their minuscule size.\n\n\n\n\n"}
{"id": "53307021", "url": "https://en.wikipedia.org/wiki?curid=53307021", "title": "Fitness fashion", "text": "Fitness fashion\n\nWhile fitness is defined as and fashion is a strictly correlated with the wish of appearing as a well-accepted member of contemporary society,\nfitness fashion is the result of a trend that consists in combining physical activities and health lifestyles with the interest and use of sportswear fashion.\n\nThere is a connection between sportswear and self-affirmation, that exists because of the care for fashion. The action of buying sportswear is led to the feel of being part of a community, assessing its rules and culture. People get involved in a process in which the major aim is to appear.\nWith regard to fitness fashion, the ritual is a ceremony which consists in the activities that take place in a fitness centre or in a gym and which are the acts of undressing, dressing, exercising, undressing, showering, grooming and dressing again. This ritual also implies a psychological dimension in which the individual is involved in a process of self-affirmation. What people want to wear is limited by a pre-existing, yet always evolving, ideal, which is the image of fashion itself.\n\nChanging rooms, usually situated in the most internal part of the gym, represent the connection between the outside world and the world of fitness, because While the exercise places are usually filled with information such as posters and images of fit bodies, changing rooms are always unadorned, since they represent \n\nAlso sportswear has become part of the ritual. Being fit is not just exercising and eating well but also wearing fashionable clothes and showing it also through social media. Clothing comfort is defined by Lauren Slater (1985) as \n\nAs a matter of fact, fitness fashion requires people to identify with a model. People start buying the same sportswear of the chosen icon they want to imitate, and then chose to act like him/her.\nSportswear is strictly correlated with fashion not only because of a trend, but also for the so-called social learning theory, which \nIt is also for this reason that Nike and other retailers specialized in sportswear are experiencing an increase in profits (Nike saw an increase of 8 million dollars capital in just three months, that is a 15% more than 2014’s revenue, when the soccer World Cup took place).\nSince fitness fashion icons wear expensive and colorful sportswear (which represents the most visible part of the message, acting as the main instrument of the symbolic meaning delivering), and also show how happy and self-confident they are in it. Furthermore, fitness influencers are showing lifestyles that involve health-care and appearance-care as well, especially through social media.\n\nEven the most important sportswear companies are involved in social media campaigns, first of all Nike, that give the possibility to their Nike+ app users to share on Instagram their fitness achievements and progress. In fact, the app has been downloaded over 17 millions of times from all over the world users.\n\nSocial learning theory suggests that females learn stereotypes and expectations through observing images through the media. Since social media are the most used instrument for information resources and connection among people, everyone can easily find a new inspiration through them. Every fitness influencer uses social media because of the direct contact with fans that the web offers. Sharing fitness goals and motivation is now a spread phenomenon that people begin to appreciate and concur. It follows that a simple photo on a social media becomes easily a form of advertisement, because who posted it wanted to promote his/her lifestyle, that is represented in a direct way from the sportswear he/she is wearing.\n\nOn the other hand, \nSociety and media emphasize athletic women's physical appearance and sexual attractiveness, through representing them as women first and athletes second. Thus, the feminine athletic ideal consists of an attractive appearance, thin body, and sexual appeal, which is conveyed also through clothing: women sportswear must fit snugly, but, most important must be sheath, exaggerating the female shape. In health/fitness magazines are included four stereotypes for masculinity: physical action, power, stance, and muscles. While for female it included three stereotypes: thin ideal, glistening/”wet” look, and feminine face. Thus, the health/fitness magazines tended to used the masculine and feminine ideals through stereotypes more than fashion magazines. Thus, who practice health-fitness tend to be less dressed or used close-fitting with the intention to emphasize the appeal.\n\n\n"}
{"id": "1251006", "url": "https://en.wikipedia.org/wiki?curid=1251006", "title": "Flexner Report", "text": "Flexner Report\n\nThe Flexner Report is a book-length study of medical education in the United States and Canada, written by Abraham Flexner and published in 1910 under the aegis of the Carnegie Foundation. Many aspects of the present-day American medical profession stem from the \"Flexner Report\" and its aftermath.\n\nThe \"Report\" (also called Carnegie Foundation Bulletin Number Four) called on American medical schools to enact higher admission and graduation standards, and to adhere strictly to the protocols of mainstream science in their teaching and research. The report talked about the need for revamping and centralizing medical institutions. Many American medical schools fell short of the standard advocated in the \"Flexner Report\" and, subsequent to its publication, nearly half of such schools merged or were closed outright. Colleges in electrotherapy were closed.\n\nHomeopathy and natural medicines were derided; some doctors were jailed.\n\nThe Report also concluded that there were too many medical schools in the United States, and that too many doctors were being trained. A repercussion of the \"Flexner Report\", resulting from the closure or consolidation of university training, was reversion of American universities to male-only admittance programs to accommodate a smaller admission pool. Universities had begun opening and expanding female admissions as part of women's and co-educational facilities only in the mid-to-latter part of the 19th century with the founding of co-educational Oberlin College in 1833 and private colleges such as Vassar College and Pembroke College.\n\nIn 1904 the American Medical Association (AMA) created the Council on Medical Education (CME) whose objective was to restructure American medical education. At its first annual meeting, the CME adopted two standards: one laid down the minimum prior education required for admission to a medical school, the other defined a medical education as consisting of two years training in human anatomy and physiology followed by two years of clinical work in a teaching hospital. Generally speaking, the council strove to improve the quality of medical students, looking to draw from the society of upperclass, educated students. In 1908, the CME asked the Carnegie Foundation for the Advancement of Teaching to survey American medical education, so as to promote the CME's reformist agenda and hasten the elimination of medical schools that failed to meet the CME's standards. The president of the Carnegie Foundation, Henry Pritchett, a staunch advocate of medical school reform, chose Abraham Flexner to conduct the survey. Flexner was not a physician, scientist, or a medical educator, although he held a bachelor of arts degree and operated a for-profit school in Louisville, Kentucky.\n\nAt that time, the 155 medical schools in North America differed greatly in their curricula, methods of assessment, and requirements for admission and graduation. Flexner visited all 155 schools and generalized about them as follows: \"Each day students were subjected to interminable lectures and recitations. After a long morning of dissection or a series of quiz sections, they might sit wearily in the afternoon through three or four or even five lectures delivered in methodical fashion by part-time teachers. Evenings were given over to reading and preparation for recitations. If fortunate enough to gain entrance to a hospital, they observed more than participated.\" The Report became notorious for its harsh description of certain establishments, for example describing Chicago's 14 medical schools as \"a disgrace to the State whose laws permit its existence... indescribably foul... the plague spot of the nation.\"\n\nNevertheless, several schools received praise for excellent performance, including Western Reserve (now Case Western Reserve), Michigan, Wake Forest, McGill, Toronto, and especially Johns Hopkins, which was described as the 'model for medical education'.\n\nTo help with the transition and change the minds of other doctors and scientists, Rockefeller gave more than $100 million to colleges, hospitals and founded a philanthropic front group called \"General Education Board\" (GEB).\n\nWhen Flexner researched his report, many American medical schools were small \"proprietary\" trade schools owned by one or more doctors, unaffiliated with a college or university, and run to make a profit. A degree was typically awarded after only two years of study. Laboratory work and dissection were not necessarily required. Many of the instructors were local doctors teaching part-time, whose own training left something to be desired. The regulation of the medical profession by state governments was minimal or nonexistent. American doctors varied enormously in their scientific understanding of human physiology, and the word \"quack\" flourished.\n\nFlexner carefully examined the situation. Using the Johns Hopkins School of Medicine as the ideal, he issued the following recommendations:\n\nFlexner even expressed that he found Hopkins to be a \"small but ideal medical school, embodying in a novel way, adapted to American conditions, the best features of medical education in England, France, and Germany.\" In his efforts to ensure that Hopkins was the standard to which all other medical schools in United States were compared, Flexner went on to claim that all the other medical schools were subordinate in relation to this \"one bright spot.\" Flexner believed that admission to a medical school should require, at minimum, a high school diploma and at least two years of college or university study, primarily devoted to basic science. When Flexner researched his report, only 16 out of 155 medical schools in the United States and Canada required applicants to have completed two or more years of university education. By 1920, 92 percent of U.S. medical schools required this of applicants. Flexner also argued that the length of medical education should be four years, and its content should be what the CME agreed to in 1905. Flexner recommended that the proprietary medical schools should either close or be incorporated into existing universities. Medical schools should be part of a larger university, because a proper stand-alone medical school would have to charge too much in order to break even financially.\n\nLess known is Flexner's recommendation that medical schools appoint full-time clinical professors. Holders of these appointments would become \"true university teachers, barred from all but charity practice, in the interest of teaching.\" Flexner pursued this objective for years, despite widespread opposition from existing medical faculty.\n\nFlexner was the child of German immigrants, and had studied and traveled in Europe. He was well aware that one could not practice medicine in continental Europe without having undergone an extensive specialized university education. In effect, Flexner demanded that American medical education conform to prevailing practice in continental Europe.\n\nBy and large, medical schools in Canada and the United States have followed Flexner's recommendations down to the present day. Recently, however, schools have increased their emphasis on public health matters.\n\nTo a remarkable extent, the following present-day aspects of the medical profession in North America are consequences of the \"Flexner Report\":\n\nThe Report is now remembered because it succeeded in creating a single model of medical education, characterized by a philosophy that has largely survived to the present day. \"An education in medicine,\" wrote Flexner, \"involves both learning and learning how; the student cannot effectively know, unless he knows how.\" Although the report is over 100 years old, many of its recommendations are still relevant—particularly those concerning the physician as a \"social instrument... whose function is fast becoming social and preventive, rather than individual and curative.\"\n\nFlexner sought to reduce the number of medical schools in the U.S. to 31, and to cut the annual number of medical graduates from 4,400 to 2,000. A majority of American institutions granting MD or DO degrees as of the date of the Report (1910) closed within two to three decades. (In Canada, only the medical school at Western University was deemed inadequate, but none were closed or merged subsequent to the Report.) In 1904, there were 160 M.D. granting institutions with more than 28,000 students. By 1920, there were only 85 M.D. granting institutions, educating only 13,800 students. By 1935, there were only 66 medical schools operating in the USA.\n\nBetween 1910 and 1935, more than half of all American medical schools merged or closed. This dramatic decline was in some part due to the implementation of the Report's recommendation that all \"proprietary\" schools be closed, and that medical schools should henceforth all be connected to universities. Of the 66 surviving MD-granting institutions in 1935, 57 were part of a university. An important factor driving the mergers and closures of medical schools was that all state medical boards gradually adopted and enforced the Report's recommendations. In response to the Report, some schools fired senior faculty members as part of a process of reform and renewal.\n\nFlexner viewed blacks as inferior and advocated closing all but two of the historically black medical schools. His opinions were followed and only Howard and Meharry were left open, while five other schools were closed. His perspective was that black doctors should only treat black patients and should serve roles subservient to white physicians. The closure of these schools and the fact that black students were not admitted to many medical schools in the US for 50 years after Flexner has contributed to the low numbers of American born physicians of color and the ramifications are still felt more than a century later.\n\nFurthermore, given his adherence to germ theory, he argued that, if not properly trained and treated, African-Americans posed a health threat to middle/upper class whites.\n\nWhen Flexner researched his report, \"modern\" medicine faced vigorous competition from several quarters, including osteopathic medicine, chiropractic medicine, electrotherapy, eclectic medicine, naturopathy and homeopathy. Flexner clearly doubted the scientific validity of all forms of medicine other than that based on scientific research, deeming any approach to medicine that did not advocate the use of treatments such as vaccines to prevent and cure illness as tantamount to quackery and charlatanism. Medical schools that offered training in various disciplines including electromagnetic field therapy, phototherapy, eclectic medicine, physiomedicalism, naturopathy, and homeopathy, were told either to drop these courses from their curriculum or lose their accreditation and underwriting support. A few schools resisted for a time, but eventually all either complied with the Report or shut their doors.\n\nAlthough almost all the alternative medical schools listed in Flexner's report were closed, the American Osteopathic Association (AOA) was able to bring a number of osteopathic medical schools into compliance with Flexner's recommendations and produce an evidence-based practice. The curricula of DO and MD awarding medical schools are now nearly identical, the chief difference being the additional instruction in osteopathic schools of osteopathic manipulative medicine[citation needed].\n\n\n\n"}
{"id": "50205529", "url": "https://en.wikipedia.org/wiki?curid=50205529", "title": "Fumigatory box", "text": "Fumigatory box\n\nFumigatory boxes were described in the 19th century as prophylactic or curative medical devices designed to use smoke or vapor to restore health or help prevent the spread of infectious or contagious diseases.\n\nFumigatory boxes were sometimes used to combat the spread of infectious diseases such as the plague. One version used in 1837 in Turkey was described as a wooden box approximately 8 feet tall by 3 feet wide (about 2.4 m by 1 m). At the bottom was a one-foot (30 cm) tall chamber in which the ingredients of the prophylactic were burned in a dish. Before entering a residence or public building, the clothed subject was to stand inside the box with his or her face protruding through an opening to avoid suffocation, while the rest of his or her body and clothing were engulfed in the smoke produced by the burning disinfectant. Its purpose was to inhibit the spread of the virulent epidemic then decimating Constantinople and its environs. Although the government ordered such devices installed outside all government buildings, they were often ignored by the populace.\n\nAnother version was designed by Dr. Gales, an apothecary at the Hospital St. Louis in Paris, in 1812 or shortly thereafter. It had the naked subject seated on a chair in a wooden box, with the patient's entire head exposed through an opening at the box's top. The opening around the patient's neck was sealed so fumes could not escape. There were three chambers at the bottom of this box, the top one containing sulfur which was heated by a fire in a chamber below. A bottom chamber caught the ashes. The sulfurous fumes rose through many small holes drilled through the floor of the patient compartment. If necessary, fumes could be applied directly to the head or face by means of a flexible hose attached to the main compartment. The purpose of this type of fumigatory box was curative or palliative rather than prophylactic, used as a treatment for ailments including rheumatism and psoriasis, not to prevent the spread of disease.\n\nA third type of fumigatory box was described at the turn of the 20th century as being used to fumigate imported plants on their arrival in Jamaica, to prevent the importation of plant diseases or pests. Plants were placed in the box for one hour and one vial of cyanide was released per 300 cubic feet (8.5 cubic meters) of space inside the fumigatory box. For delicate plants, one half the dose for one half-hour was recommended. Similar devices, often called fumigation chambers, are still sometimes used.\n\n"}
{"id": "1648607", "url": "https://en.wikipedia.org/wiki?curid=1648607", "title": "Global Infectious Disease Epidemiology Network", "text": "Global Infectious Disease Epidemiology Network\n\nGlobal Infectious Diseases and Epidemiology Online Network (GIDEON) is a web-based program for decision support and informatics in the fields of Infectious Diseases and Geographic Medicine. As of 2005, more than 300 generic infectious diseases occur haphazardly in time and space and are challenged by over 250 drugs and vaccines. 1,500 species of pathogenic bacteria, viruses, parasites and fungi have been described. Printed media can no longer follow the dynamics of diseases, outbreaks and epidemics in \"real time\".\n\nGIDEON consists of four modules. The first Diagnosis module generates a Bayesian ranked differential diagnosis based on signs, symptoms, laboratory tests, country of origin and incubation period – and can be used for diagnosis support and simulation of all infectious diseases in all countries. Since the program is web-based, this module can also be adapted to disease and bioterror surveillance.\n\nThe second module follows the epidemiology of individual diseases, including their global background and status in each of 205 countries and regions. All past and current outbreaks of all diseases, in all countries, are described in detail. The user may also access a list of diseases compatible with any combination of agent, vector, vehicle, reservoir and country (for example, one could list all the mosquito-borne flaviviruses of Brazil which have an avian reservoir). Over 30,000 graphs display all the data, and are updated in \"real time\". These graphs can be used for preparation of PowerPoint displays, pamphlets, lecture notes, etc. Several thousand high-quality images are also available, including clinical lesions, roentgenograms, Photomicrographs and disease life cycles.\n\nThe third module is an interactive encyclopedia which incorporates the pharmacology, usage, testing standards and global trade names of all antiinfective drugs and vaccines.\n\nThe fourth module is designed to identify or characterize all species of bacteria, mycobacteria and yeasts. The database includes 50 to 100 taxa which may not appear in standard texts and laboratory databases for several months.\n\nAdditional options allow users to add data (in their own font / language) relevant to their own institution, electronic patient charts, material from the internet, important telephone numbers, drug prices, antimicrobial resistance patterns, etc. This form of custom data is particularly useful when running GIDEON on institutional networks. The data in GIDEON are derived from:\n\n\n\n"}
{"id": "5022727", "url": "https://en.wikipedia.org/wiki?curid=5022727", "title": "Hamlagrøvatnet", "text": "Hamlagrøvatnet\n\nHamlagrøvatnet is a lake on the border of the municipalities of Voss and Kvam in Hordaland county, Norway. The lake is the largest lake in all of Hordaland county. The lake is located about southeast of the village of Dalekvam and about south of the village of Evanger.\n\nThe lake sits at the eastern end of the Bergsdalen valley and it is regulated at elevation of above sea level. The lake is a reservoir on the river Bergsdalselvi which has four hydroelectric power stations on it. The lake is surrounded by many holiday cottages.\n\n"}
{"id": "35324572", "url": "https://en.wikipedia.org/wiki?curid=35324572", "title": "Health in Lesotho", "text": "Health in Lesotho\n\nLife expectancy at birth in Lesotho in 2016 was 51 years for men and 55 for women. Infant mortality is about 8.3%. In 2006 life expectancy was estimated at 42 years for men and women.\n\nThe country has the highest incidence of tuberculosis in the world.\n\nThere are five physicians per 100,000 persons.\n\nThe Queen Elizabeth II Hospital in Maseru, the main secondary care centre, was closed in 2011 and replaced by a newly built hospital, the Queen Mamohato Memorial Hospital, with 425 beds, constructed on a public–private partnership basis. This has produced considerably better health outcomes and more advanced medical technologies than were previously available. It has also attracted patients who could have been dealt with in primary care. More than 27,000 inpatients and nearly 350,000 outpatients were treated in 2015. The scheme absorbed an average of 34.8% of the total government recurrent budget for the health sector for 2012-15. All invasive cardiac care and cancer treatment is referred to public hospitals in Bloemfontein.\n\nLesotho is severely afflicted by HIV/AIDS and has one of the highest infection rates in the world. The rate has hovered around 25 percent since 2005, although recent trends show new infections decreasing. In 2005 there were 30,000 new infections compared to 21,000 new infections in 2016. In urban areas, about 50 percent of women under 40 have HIV. \n\nThe country regards HIV as one of its most important development issues, and the government is addressing the pandemic through its HIV/AIDS National Strategic Plan. Coverage of some key HIV/AIDS interventions has improved, including prevention of mother to child transmission and antiretroviral therapy. Prevention of mother to child transmission coverage increased from about 5 percent in 2005, to 31 percent in 2007. The roll-out of antiretroviral therapy has made good progress, with 38,586 people receiving treatment by 2008.\n\nThe \"Know Your Status\" campaign boosted the number of people being tested for HIV to 229,092 by the end of 2007, 12 percent of the population and three times the number tested in 2005. The program is funded by the Clinton Foundation and started in June 2006. Bill Clinton and Microsoft chairman Bill Gates visited Lesotho in July 2006 to assess its fight against AIDS. As a result, the annual rate at which adults in the population who are HIV-negative become HIV-positive declined from 2.9 percent in 2005 to 2.3 percent in 2007, lowering the estimated annual number of new infections from 26,000 to 21,560. \nThese are the first signs of a decline in the HIV epidemic.\n\nThe Apparel Lesotho Alliance to Fight AIDS is an industry-wide program providing prevention and treatment, including ARVs when these are necessary, for the 46,000 mainly women workers in the Lesotho apparel industry. It was launched in May 2006. The program is helping to combat two of the key drivers of the HIV/AIDS epidemic: poverty and gender inequality. Surveys within the industry by ALAFA show that 43 percent of employees have HIV.\n\nPrince Harry of UK co-founded the charity Sentebale in Lesotho, for children with HIV/AIDS. The other co-founder is the Prince of Lesotho.\n"}
{"id": "50835353", "url": "https://en.wikipedia.org/wiki?curid=50835353", "title": "Health systems strengthening", "text": "Health systems strengthening\n\nHealth systems strengthening (also health system strengthening, abbreviated HSS) is a term used in global health that roughly means to improve the health care system of a country. Within this general definition, it can mean increasing funding for health infrastructure, improving health policy, trying to achieve universal healthcare, or any number of other health measures.\n\nThere has been some effort to use a systems thinking approach to health systems strengthening.\n\nVarious health organizations have claimed to use health systems strengthening (while not necessarily agreeing on the definition). Some of these are:\n\n\nBoth the idea of health systems strengthening and the term itself have received attention.\n\nEven advocates of health systems strengthening admit that it can often seem like a \"distant, even abstract aim\".\n\nMarchal et al., writing in 2009, called the term \"vague\" and argued that \"most current HSS strategies are selective (i.e., they target a specific disease), and their effects may undermine progress towards the long-term goal of effective, high-quality, and inclusive health systems.\"\n\nPeter Berman, who was the lead health economist at the World Bank, has pointed out that \"Almost any support to health interventions can be considered HSS\".\n\n"}
{"id": "3616449", "url": "https://en.wikipedia.org/wiki?curid=3616449", "title": "Health visitor", "text": "Health visitor\n\nHealth visitors are professional individuals engaged in public health work within the domestic setting, predominantly found in countries with state-funded health systems. They are distinct from district nurses, who provide clinical healthcare, domestically. \n\nHealth visitors are mainly concerned with helping to ensure that people's domestic behaviour is sanitary, hygienic, and beneficial to the welfare of themselves and their families, particularly to their children. As their name suggests, they fulfill their role in the community, by visiting family homes, to give advice and support to all age groups. \n\nThey have a key role with regard to safeguarding vulnerable people, as they are often the first experts to enter the homes of individuals at risk of abuse and neglect, especially children.\n\nA check at two years of age is now a major part of the standard provision. If the health visitor suspects that matters were serious enough to warrant child protection measures, it is their responsibility to initiate the process of intervention. The dual role of advice and inspection has made some families wary of health visitors, despite being appreciative of their potential for assistance.\n\nIn addition to their early years work, health visitors have now started to run health promotion schemes such as stop-smoking services, and to deliver certain vaccination programmes.\n\nMany health visitors are represented professionally by the Community Practitioners and Health Visitors Association, which is part of Unite the Union. \n\nAt the time the health visiting profession began, living conditions for the urban poor were often cramped and extremely insanitary, leading to many business owners sending women around to workers' homes to educate their wives about sanitation and nutrition. The initial focus of health visiting was on families with young children. Visits would cover topics such as sanitation, feeding, nutrition, care, and support to both infants and parents. Typically there would be regular visits throughout a child's early years, to provide routine child development checks. Issues of hygiene, malnutrition, or disease, would be corrected with suitable advice, and reported to the relevant authorities where appropriate\n\nThe role of Health visitors was formalised with the establishment of the \"Ladies Sanitary Reform Association\" in 1862. By 1890 some local councils were paying the salaries of Health Visitors. \n\nThe role of Health Visitors was given greater weight following the Notification of Births Acts 1907 and 1915 and the Maternity and Child Welfare Act 1918 which empowered local authorities to establish maternal and child welfare services and led to the first training courses for health visitors. In 1929, health visitors began to be employed by local councils on a statutory basis and since 1974 they have been employed by the National Health Service.\n\nBeginning in 1945, health visitors operating in the UK were required to be Registered Nurses or Midwives who had undertaken further training to work as part of a primary health care team.\n\nIn the 1950s, their interventions were made more extensive to ensure they could provide a cradle-to-grave service, working also with the elderly and chronically ill.\n\nIn 1962, the Health Visiting and Social Work (Training) Act established the Council for the Training of Health Visitors (CTHV) and the Council for Training in Social Work (CTSW). The CTHV comprised 31 members of whom 14 were appointed by the Minister of Health. In 1970 the title of the CTHV was changed to the Council for the Education and Training of Health Visitors (CETHV). \n\nUnder the Blair Ministry, rising case-loads were considered to be affecting the potential quality of interventions in young families. As a result, their work was refocused back to young families; the reduced intervention in elderly care has been accompanied by a commensurate rise in admissions of elderly patients to A+E departments and care homes.\n\nAfter Sure Start was introduced, to provide general early years support to families, the refocusing on young families lead many health visitors to use Sure Start centres as their base. The Healthy Child Programme, published in October 2009, influences the core service available to families, breaking it down into two age groups : firstly the first 5 years, and secondly 5-19 year olds. The latter age group are traditionally dealt with by \"school nurses\" - a public health nurse embedded within, or frequenting a school - with health visitors handing over responsibility to them, for a child's development and welfare, once the child starts to attend school.\n\nThe 2010 Coalition Government sought to reverse the move towards reducing the scope of health visitors by giving a commitment to recruit more health visitors, to ensure that their caseloads were not negatively impacted. The Government's reorganisation of the NHS returned responsibility for public health, at a local level, to local councils once again, with national issues and oversight being provided by Public Health England. Health visitor services will therefore now be commissioned by local councils, in partnership with clinical commissioning groups.\n\nIn 1977 there were 10,623 health visitors in the UK. In 2015 there were 12,292 in England and Wales, an increase from 10,046 in 2000. \n\nIn 2000 there were 297 children under 5 per health visitor, a figure which rose to 419 in 2011.\n\nIn the early days of statutory health visiting, training in the UK was overseen by the Royal Sanitory Institute, who later evolved into the Royal Society of Public Health. This was later taken over by the government's Ministry of Health, and they are now regulated by the Nursing and Midwifery Council.\n\nPost-qualification, a 1-year full-time (or equivalent part-time) degree or masters level course.\n\nThe Journal of Health Visiting, launched in January 2013, is a monthly peer-reviewed journal for health visitors.\n\nResearchers interested in the history of health visitors may be interested in consulting the Welcome Trust's \"London's Pulse\" collection, which provides a digital archive of London's Medical Officer of Health reports, for the period 1848-1972. These reports often referred to the activities of health visitors.\n\n"}
{"id": "23358105", "url": "https://en.wikipedia.org/wiki?curid=23358105", "title": "HealthyWomen", "text": "HealthyWomen\n\nHealthyWomen is an American non-profit organization which seeks to provide women with in-depth, medical-organization-sanctioned information on a wide range issues important to women's health and to increase awareness of those issues via education and advocacy. It was founded as the National Women's Health Resource Center in 1988 by Dr. Violet Bowen-Hugh, and was originally associated with the Columbia Hospital for Women in Washington, D.C. It has since located to Red Bank, New Jersey. Some of the center's funding comes from consumer product and pharmaceutical companies. The organization has put out a newsletter, \"National Women's Health Report\". It changed its name to HealthyWomen in 2009. HealthyWomen works closely with companies such as Health Advocate to plan and conduct health- and wellness-related webinars, brochures, and articles targeted to employers and individuals. \n\n"}
{"id": "25817687", "url": "https://en.wikipedia.org/wiki?curid=25817687", "title": "Journal of Interprofessional Care", "text": "Journal of Interprofessional Care\n\nThe Journal of Interprofessional Care is a bimonthly peer-reviewed medical journal that covers education, practice, and research in health and social care.\n\nThe Journal of Interprofessional Care aims to disseminate research and new developments in the field of interprofessional education and practice. We welcome contributions containing an explicit interprofessional focus, and involving a range of settings, professions, and fields. Areas of practice covered include primary, community and hospital care, health education and public health, and beyond health and social care into fields such as criminal justice and primary/elementary education. Papers introducing additional interprofessional views, for example, from a community development or environmental design perspective, are welcome. The Journal is disseminated internationally and encourages submissions from around the world.\n\nThe Journal publishes the following types of manuscripts:\n\n1. Peer-reviewed Original Articles (research studies, systematic/analytical reviews, theoretical papers) that focus on interprofessional education and/or practice, and add to the conceptual, empirical or theoretical knowledge of the interprofessional field.\n\n2. Peer-reviewed Short Reports that describe research plans, studies in progress or recently completed, or an interprofessional innovation.\n\n3. Peer-reviewed Interprofessional Education and Practice (IPEP) Guides that offer practical advice on successfully undertaking various interprofessional activities.\n\n4. Guest Editorials that discuss a salient issue related to interprofessional education and practice.\n\n5. Book and Report Reviews that offer summaries of recently published books and reports (published on the Journal’s Blog - see below).\n\nThe Journal was established in 1986 and is published by Taylor & Francis. The editor-in-chief is Professor Scott Reeves (Kingston University and St George's, University of London). The Journal of Interprofessional Care is supported by an international editorial board.\n\n\n\nAllied Health; Community Health; Community Social Work; Health Education and Promotion; Health and Social Care; Public Health Policy and Practice; Social Work and Social Policy\n\nThe journal is abstracted and indexed in:\n2016 Journal Citation Reports® Ranks \"Journal of Interprofessional Care\" 22nd out of 77 journals in Health Care Sciences & Services (S) and 36th out of 74 journals in the Health Policy & Services (Ss) with a 2016 Impact Factor of 2.205\n\nTaylor & Francis Website: Official Journal Website\n\nTwitter: JIC Twitter\n\nBlog: JIC Blog\n\nLinkedIn: JIC LinkedIn\n\nFacebook: JIC Facebook\n\n"}
{"id": "22523658", "url": "https://en.wikipedia.org/wiki?curid=22523658", "title": "Kayhausen Boy", "text": "Kayhausen Boy\n\nThe Kayhausen Boy is a mummy, naturally preserved in a sphagnum bog in Lower Saxony, Germany. He is one of the few recorded bog children discovered.\n\nThe body, of a boy believed to have been approximately seven to ten years of age at the time of his death, was found in 1922. The boy is estimated to have died between 300 and 400 BCE. His arms and feet were bound together with cloth torn from clothing and a fur cape. Examination concluded that he had been stabbed three to four centimeters deep, three times in the neck and once on his left arm. It is thought that the wound on the boy's arm had happened when the boy may have raised his arm in an act of self-defense towards his attacker. A recent examination of the body shows that the weapon used to kill the child was a dagger with a four centimeter blade. A possible reason for the boy's demise is that he had suffered from an infected socket at the top of his femur, and hence would not have been able to walk without assistance. Because of the high incidence of deformities among bog bodies, such as the Yde Girl, anthropologists have suggested that the disabled were sacrificed because they were considered to be unfavored by their gods. The boy's body is preserved in a formalin solution and is not displayed.\n\n"}
{"id": "18517438", "url": "https://en.wikipedia.org/wiki?curid=18517438", "title": "LIVERight", "text": "LIVERight\n\nLIVERight is the first 5K run/walk to raise awareness about hepatitis B and liver cancer.\nThe goal of LIVERight was not only to raise money for outreach efforts, but more importantly to educate and increase awareness of this pressing public health issue. Educational displays, informational booths and of course signs were unique and significant components to the event. The education allowed participants to learn more about hepatitis B prevention and treatment, as well as hear the real stories about the lives lost and won to liver cancer.\n\nThe LIVERight concept began at the 2nd annual Youth Leadership Conference on Asian and Pacific Islander Health in 2004, a CDC funded event organized by the Asian Liver Center at Stanford University. High school students were given a Team Challenge to create a campaign/event for raising awareness about hepatitis B, and LIVERight was born. The words \"Liver\" and \"Right\" together emphasize the importance of liver health. From this concept, LIVERight bracelets and the LIVERight 5K run/walk emerged.\n\nAdrian Elkins inspired the Asian Liver Center at Stanford University to start LIVERight, a 5K Run/Walk to raise awareness about hepatitis B and liver cancer in the Asian Pacific Islander community.\n\nOn 30 April 2005 in San Francisco's Golden Gate Park, the Asian Liver Center and the Answer to Cancer Foundation hosted LIVERight.\n\nOn 11 November 2006, the 2nd annual LIVERight on the go! was held at Stanford's Sand Hill Fields. The community event had 700 registered participants and 100 volunteers, and raised over $135,000.\n\nLIVERight '09 was held on Saturday, May 2, 2009 at Golden Gate Park in San Francisco, California. Over 400 runners registered and raised over $100,000 to fight liver cancer and hepatitis B.\n\nIn November 2010, LIVERight returns to Stanford University with the hottest new dance fitness craze that's taking over the world. Fusing hypnotic Latin rhythms with easy to follow dance moves, Zumba Fitness is a Latin-inspired cardio dance fitness workout. The LIVERight Zumbathon at Stanford will be held on Saturday, November 13, 2010 in partnership with the Asian Liver Center at Stanford University, Answer to Cancer, Be Well @ Stanford and the Stanford Department of Physical Education. Zumba is all about having fun and no experience is necessary. This family-friendly event is open to the public and all of the Stanford community. As in the past, donations benefit the Jade Ribbon Campaign and the fight against liver cancer. Enthusiastic Zumba Fitness Instructors, prizes and games, and two hours of Latin rhythms will keep participants sweating and having fun.\n\nThe Answer to Cancer (A2C) run was founded by Adrian Elkins, a 20-year-old student at Southern Oregon University who was diagnosed with liver cancer in 2002. Had he known during his childhood that his ethnicity and chronic hepatitis B infection increased his chance of developing liver cancer by 100%, he would have been regularly monitored for liver damage. He had no idea that hepatitis B—a disease he contracted at birth in Calcutta, India—causes 80% of the world's liver cancer cases. Adrian battled his disease for ten months, working tirelessly to organize an event to raise money for liver cancer research. Adrian saw the first-ever A2C run take place on 8 August 2003. Thanks to the generous support of friends, families and numerous companies, the 2003 Answer to Cancer Race was able to raise more than $20,000 for three charities and reach out to more than 240 participants. Adrian died only eight days after this first race.\n\n"}
{"id": "24398406", "url": "https://en.wikipedia.org/wiki?curid=24398406", "title": "Landeros v. Flood", "text": "Landeros v. Flood\n\nLanderos v. Flood was a 1976 court case in the state of California involving child abuse and alleged medical malpractice.\n\nIn 1971, Gita Landeros, a minor, was seen in the emergency room by Dr. Flood for injuries inflicted by her mother and the mother's common law husband. Dr. Flood failed to diagnose \"battered child syndrome\" and also did not report the injuries to proper civil authorities in violation of California law. The child was released to the custody of her mother and the mother's common law husband, where she experienced further injury at their hands. The parents fled the state, but were apprehended and convicted of criminal child abuse. Gita Landeros brought a civil suit in tort for damages against Dr. Flood. The trial court dismissed her case as a matter of law. The case was appealed and decided in 1976 by the California Supreme Court.\n\nGITA LANDEROS, Appellant, a minor, sought review of a judgment of the Superior Court of Santa Clara County (California), which sustained general demurrers and dismissed her medical malpractice action against appellees, a physician and a hospital, for injuries sustained when they failed to properly diagnose and treat the condition from which she was suffering.\n\nAppellant minor argued trial court error in sustaining the demurrer of appellees, doctor and hospital, to her malpractice suit against them, because issues existed as to whether they had a duty to recognize a case of battered child syndrome that was to be reported to authorities, and whether their conduct proximately caused appellant's injuries. The court agreed, noting first that appellant was returned to parental custody after having been treated for injuries not appearing to be accidental, and that she then was traumatically abused. Because it was unclear whether treating physicians should have recognized the syndrome for treatment purposes, appellant was entitled to prove by expert testimony the standard of care against which appellees were to be held. And as appellees could not escape liability if it was foreseeable that appellant would suffer further injury, appellant was entitled to prove that appellees' conduct proximately caused her injuries, even if the parent's intervening act was the actual cause. Finally, appellant was entitled to show that appellees failed to exercise due care in not reporting her injuries to authorities who would have shielded her from further harm.\n\n\n\nPlaintiff brought the action by her guardian ad litem against A. J. Flood, a physician, and The San Jose Hospitals & Health Center, Inc. (hereinafter called the San Jose Hospital). The amended complaint purports to allege four \"causes of action.\" of recovery alleged in support of a single cause of action for compensatory damages for personal injuries caused by defendants' negligence in failing to properly diagnose and treat the condition from which plaintiff was suffering; the fourth \"cause of action\" merely adds a claim for punitive damages on allegations that defendants' conduct in this respect was wilful and wanton. Defendants filed general demurrers. The court sustained the demurrers as to the first and second \"causes of action\" with leave to amend, and as to the third and fourth \"causes of action\" without leave to amend. Plaintiff elected to stand on her complaint as previously amended, and a judgment dismissing the entire action was therefore entered. On this appeal plaintiff has expressly abandoned her claim of punitive damages.\n\nThe material factual allegations of the amended complaint are as follows. Plaintiff was born on May 14, 1970. On repeated occasions during the first year of her life she was severely beaten by her mother and the latter's common law husband, one Reyes. On April 26, 1971, when the plaintiff was eleven months old, her mother took her to the San Jose Hospital for examination, diagnosis, and treatment. The attending physician was defendant Dr. Flood, acting on his own behalf and as agent of the defendant San Jose Hospital. At the time, the plaintiff was suffering from a comminuted spiral fracture of the right tibia and fibula, which gave the appearance of having been caused by a twisting force. Plaintiff's mother had no explanation for this injury. Plaintiff had bruises over her entire body. In addition, she had a non-depressed linear skull fracture which was then in the process of healing. Plaintiff demonstrated fear and apprehension when approached. Inasmuch as all plaintiff's injuries gave the appearance of having been intentionally inflicted by other persons, she exhibited the medical condition known as the battered child syndrome.\n\nIt is alleged that proper diagnosis of plaintiff's condition would have included taking X-rays of her entire skeletal structure, and that such procedure would have revealed the fracture of her skull. Defendants negligently failed to take such X-rays, and thereby negligently failed to diagnose her true condition. It is further alleged that proper medical treatment of plaintiff's battered child syndrome would have included reporting her injuries to local law enforcement authorities or juvenile probation department. Such a report would have resulted in an investigation by the concerned agencies, followed by a placement of plaintiff in protective custody until her safety was assured. Defendants negligently failed to make such report.\n\nThe complaint avers that as a proximate result of the foregoing negligence plaintiff was released from the San Jose Hospital without proper diagnosis and treatment of her battered child syndrome, and was returned to the custody of her mother and Reyes who resumed physically abusing her until she sustained traumatic blows to her right eye and back, puncture wounds over her left lower leg and across her back, severe bites on her face, and second and third degree burns on her left hand.\n\nOn July 1, 1971, plaintiff was again brought in for medical care, but to a different doctor and hospital. Her battered child syndrome was immediately diagnosed and reported to local police and juvenile probation authorities, and she was taken into protective custody. Following hospitalization and surgery she was placed with foster parents, and the latter subsequently undertook proceedings to adopt her. Plaintiff's mother and Reyes fled the state, but were apprehended, returned for trial, and convicted of the crime of child abuse.\n\nWith respect to damages the complaint alleges that as a proximate result of defendants' negligence plaintiff suffered painful permanent physical injuries and great mental distress, including the probable loss of use or amputation of her left hand.\n\nThe second and third \"causes of action\" are predicated on defendants' failure to comply with three related sections of the Penal Code. Section 11160 provides in relevant part that every hospital to which any person is brought who is suffering from any injuries inflicted \"in violation of any penal law of this State\" must report that fact immediately, by telephone and in writing, to the local law enforcement authorities. Section 11161 imposes the identical duty on every physician who has under his care any person suffering from any such injuries. Section 11161.5 deals specifically with child abuse, and declares in pertinent part that in any case in which a minor is under a physician's care or is brought to him for diagnosis, examination or treatment, and \"it appears to the physician\" from observation of the minor that the latter has any physical injuries \"which appear to have been inflicted upon him by other than accidental means by any person,\" he must report that fact by telephone and in writing to the local law enforcement authorities and the juvenile probation department. All three sections require the report to state the name of the victim, if known, together with his whereabouts and the character and extent of his injuries; and a violation of any of the sections is a misdemeanor (§ 11162).\n\nAmong such laws are the statutes penalizing child abuse.\nThe statute imposes the same duty on certain other health care professionals, school officials and teachers, child care supervisors, and social workers.\n\nThe trial court did not allow Gita Landeros to present expert testimony supporting her allegations of negligence against Dr. Flood. The trial court also dismissed the complaint of Gita Landeros as a matter of law. The decision is appealed to the California Supreme Court.\n\nOpinion written by Chief Judge Mosk: By means of allegations phrased largely in the statutory language plaintiff undertakes to charge defendants with a duty to comply with section 11161.5 (second \"cause of action\") and sections 11160 and 11161 (third \"cause of action\"), and avers that they failed to make the reports thus required by law. Her allegations of proximate cause and damages on these counts are essentially identical to those of the first count.\n\nWe have found no case directly in point, but the issues may be decided by reference to well settled principles. Succinctly stated, the rules governing our consideration of this appeal are \"that a general demurrer admits the truth of all material factual allegations in the complaint [citation]; that the question of plaintiff's ability to prove these allegations, or the possible difficulty in making such proof does not concern the reviewing court [citations here omitted]; and that plaintiff need only plead facts showing that [may be shown to be relevant during the trial.]\n\nThe standard of care in malpractice cases is also well known. With unimportant variations in phrasing, we have consistently held that a physician is required to possess and exercise, in both diagnosis and treatment, etc. In this medical malpractice action plaintiff Gita Landeros, a minor, appeals from a judgment of dismissal entered upon an order sustaining general demurrers to her amended complaint. As will appear, we have concluded that the complaint states a cause of action and hence that the judgment must be reversed.\n\nPlaintiff brought the action by her guardian ad litem against A. J. Flood, a physician, and The San Jose Hospitals & Health Center, Inc. (hereinafter called the San Jose Hospital). The amended complaint purports to allege four \"causes of action.\" of recovery alleged in support of a single cause of action for compensatory damages for personal injuries caused by defendants' negligence in failing to properly diagnose and treat the condition from which plaintiff was suffering; the fourth \"cause of action\" merely adds a claim for punitive damages on allegations that defendants' conduct in this respect was wilful and wanton. Defendants filed general demurrers. The court sustained the demurrers as to the first and second \"causes of action\" with leave to amend, and as to the third and fourth \"causes of action\" without leave to amend. Plaintiff elected to stand on her complaint as previously amended, and a judgment dismissing the entire action was therefore entered.\n\nOn this appeal plaintiff has expressly abandoned her claim of punitive damages. It is alleged that proper diagnosis of plaintiff's condition would have included taking X-rays of her entire skeletal structure, and that such procedure would have revealed the fracture of her skull. Defendants negligently failed to take such X-rays, and thereby negligently failed to diagnose her true condition. It is further alleged that proper medical treatment of plaintiff's battered child syndrome would have included reporting her injuries to local law enforcement authorities or juvenile probation department. Such a report would have resulted in an investigation by the concerned agencies, followed by a placement of plaintiff in protective custody until her safety was assured. Defendants negligently failed to make such report.\nThe complaint avers that as a proximate result of the foregoing negligence plaintiff was released from the San Jose Hospital without proper diagnosis and treatment of her battered child syndrome, and was returned to the custody of her mother and Reyes who resumed physically abusing her until she sustained traumatic blows to her right eye and back, puncture wounds over her left lower leg and across her back, severe bites on her face, and second and third degree burns on her left hand.\n\nOn July 1, 1971, plaintiff was again brought in for medical care, but to a different doctor and hospital. Her battered child syndrome was immediately diagnosed and reported to local police and juvenile probation authorities, and she was taken into protective custody. Following hospitalization and surgery she was placed with foster parents, and the latter subsequently undertook proceedings to adopt her. Plaintiff's mother and Reyes fled the state, but were apprehended, returned for trial, and convicted of the crime of child abuse.\n\nWith respect to damages the complaint alleges that as a proximate result of defendants' negligence plaintiff suffered painful permanent physical injuries and great mental distress, including the probable loss of use or amputation of her left hand. The second and third \"causes of action\" are predicated on defendants' failure to comply with three related sections of the Penal Code. Section 11160 provides in relevant part that every hospital to which any person is brought who is suffering from any injuries inflicted \"in violation of any penal law of this State\" n4 must report that fact immediately, by telephone and in writing, to the local law enforcement authorities. Section 11161 imposes the identical duty on every physician who has under his care any person suffering from any such injuries. Section 11161.5 deals specifically with child abuse, and declares in pertinent part that in any case in which a minor is under a physician's care or is brought to him for diagnosis, examination or treatment, and \"it appears to the physician\" from observation of the minor that the latter has any physical injuries \"which appear to have been inflicted upon him by other than accidental means by any person,\" he must report that fact by telephone and in writing to the local law enforcement authorities and the juvenile probation department. All three sections require the report to state the name of the victim, if known, together with his whereabouts and the character and extent of his injuries; and a violation of any of the sections is a misdemeanor.\n\nAmong such laws, of course, are the statutes penalizing child abuse. The statute imposes the same duty on certain other health care professionals, school officials and teachers, child care supervisors, and social workers. By means of allegations phrased largely in the statutory language plaintiff undertakes to charge defendants with a duty to comply with section 11161.5 (second \"cause of action\") and sections 11160 and 11161 (third \"cause of action\"), and avers that they failed to make the reports thus required by law. Her allegations of proximate cause and damages on these counts are essentially identical to those of the first count.\n\nWe have found no case directly in point, but the issues may be decided by reference to well settled principles. Succinctly stated, the rules governing our consideration of this appeal are \"that a general demurrer admits the truth of all material factual allegations in the complaint; that the question of plaintiff's ability to prove these allegations, or the possible difficulty in making such proof does not concern the reviewing court; and that plaintiff need only plead facts showing that he may be.\n\nThe standard of care in malpractice cases is also well known. With unimportant variations in phrasing, we have consistently held that a physician is required to possess and exercise, in both diagnosis and treatment. The first question presented, accordingly, is whether the foregoing standard of care includes a requirement that the physician know how to diagnose and treat the battered child syndrome.\n\nIt appears from the literature that the battered child syndrome was first tentatively identified and reported to the medical profession in the early 1950s. Further surveys and analyses of the syndrome followed, culminating in a landmark article published in 1962 in the Journal of the American Medical Association. Since that date numerous additional studies of the condition have been undertaken, and their results and recommendations publicized in the medical journals. A typical article in the field recites case histories of child abuse, points out the distinguishing signs and symptoms of the battered child syndrome, and advises the practicing physician how to detect and treat the condition. For a detailed survey of the medical literature on the topic from its beginning until 1965, A selection of the later articles is cited in Grumet, The Plaintive Plaintiffs: Victims of the Battered Child Syndrome \n\nWhile helpful, the foregoing general history of the battered child syndrome is not conclusive on the precise question in the case at bar. The question is whether a reasonably prudent physician examining this plaintiff in 1971 would have been led to suspect she was a victim of the battered child syndrome from the particular injuries and circumstances presented to him, would have confirmed that diagnosis by ordering X-rays of her entire skeleton, and would have promptly reported his findings to appropriate authorities to prevent a recurrence of the injuries. There are numerous recommendations to follow each of these diagnostic and treatment procedures in the medical literature cited above.\n\nFor example, the leading article by Kempe et al., op. cit., supra, states that \"A physician needs to have a high initial level of suspicion of the diagnosis of the battered-child syndrome in instances of subdural hematoma, multiple unexplained fractures at different stages of healing, failure to thrive, when soft tissue swelling or skin bruising are present, or in any other situation where the degree and type of injury is at variance with the history given regarding its occurrence . . . .\" (Id., at p. 20.) Of the different types of fractures exhibited, an arm or leg fracture caused by a twisting force is particularly significant because \"The extremities are the 'handles' for rough handling\" of the child by adults. (Id., at p. 22.) The article also contains numerous recommendations to conduct a \"radiologic examination of the entire skeleton\" for the purpose of confirming the diagnosis, explaining that \"To the informed physician, the bones tell a story the child is too young or too frightened to tell.\" (Id., at p. 18.) Finally, on the subject of management of the case it is repeatedly emphasized that the physician \"should report possible willful trauma to the police department or any special children's protective service that operates in his community\" (id., at p. 23) in order to forestall further injury to the child: \"All too often, despite the apparent cooperativeness of the parents and their apparent desire to have the child with them, the child returns to his home only to be assaulted again and suffer permanent brain damage or death.\" (Id., at p. 24.)\n\nInasmuch as the \"common knowledge\" exception to the foregoing rule does not apply on the facts here alleged, the trial court could not properly conclude as a matter of law that defendants' standard of professional care did not include the diagnostic and treatment procedures outlined in the complaint. Plaintiff is therefore entitled to the opportunity to prove by way of expert testimony that in the circumstances of this case a reasonably prudent physician would have followed those procedures. Whether the physician would have followed the procedure of reporting plaintiff's injuries to the authorities, however, is not solely a question of good medical practice. The above-cited reporting statutes (Pen. Code, § 11160- 11161.5) were in force in 1971. They evidence a determination by the Legislature that in the event a physician does diagnose a battered child syndrome, due care includes a duty to report that fact to the authorities. In other words, since the enactment of these statutes a physician who diagnoses a battered child syndrome will not be heard to say that other members of his profession would not have made such a report. The same is true of each of the persons and entities covered by this legislation. Accordingly, although expert testimony on the issue of a duty to report is admissible, it is not mandatory.\n\nThe statute also lays to rest defendant Flood's concern that if he were required to report his findings to the authorities he might be held liable for violation of the physician-patient privilege. Section 11161.5 specifically exempts the physician from any civil or criminal liability for making a report pursuant to its terms.\n\nDefendants complain that the first \"cause of action\" is nevertheless fatally defective because it assertedly fails to allege certain specific facts, i.e., that Dr. Flood negligently treated plaintiff's leg fracture, that proper treatment of that fracture or the bruises on plaintiff's back included taking an X-ray of her skull, and that Dr. Flood negligently failed to ask plaintiff's mother for an explanation of the cause of the fracture. None of these allegations is necessary, however, because they are irrelevant to the gist of the complaint. Plaintiff's theory is that in the circumstances of this case the fracture, the bruises, and the lack of an explanation offered by her mother are themselves indicia of the underlying battered child syndrome of which plaintiff was the victim, and it was that condition which defendants negligently failed to diagnose and treat. For the reasons stated, the complaint adequately alleges the facts necessary to support such a theory. A third person may act in a particular manner is the hazard or one of the hazards which makes the actor negligent, such an act whether innocent, negligent, intentionally tortious, or criminal does not prevent the actor from being liable for harm caused thereby.\" \n\nAs we recently observed with respect to a determination of duty, however, \"foreseeability is a question of fact for the jury.\" The same rule applies when the issue is whether the intervening act of a third person was foreseeable and therefore did not constitute a superseding cause: in such circumstances \"The foreseeability of the risk generally frames a question for the trier of fact\" Restatement the fact that the risk eventuates does not relieve him of responsibility.\n\nAccordingly, the trial court in the case at bar could not properly rule as a matter of law that the defendants' negligence was not the proximate cause of plaintiff's injuries. Plaintiff is entitled to prove by expert testimony that defendants should reasonably have foreseen that her caretakers were likely to resume their physical abuse and inflict further injuries on her if she were returned directly to their custody. Again defendant Flood presses only a technical point of pleading, claiming the allegation of proximate cause is fatally defective because the foreseeability of the intervening conduct of plaintiff's mother and Reyes is not specifically set forth. It is asserted that under the case law such an allegation is mandatory if the foreseeability of the intervening act does not clearly appear from the pleaded facts of negligence and injury. As shown above, however, here the occurrence of the intervening act is the precise hazard to which defendants' conduct is alleged to have negligently exposed plaintiff, and the injuries pleaded are those which a reasonably prudent physician would have foreseen as likely to ensue from that negligence. In these circumstances \"The allegations of the complaint are sufficient to present the issue\" of proximate cause.\n\nPursuant to our duty to liberally construe pleadings with a view to achieving substantial justice we therefore treat the second and third \"causes of action\" as alternative counts setting forth plaintiff's theory of statutory liability. The purpose of that theory is manifestly to raise a presumption that by omitting to report plaintiff's injuries to the authorities as required by law, defendants failed to exercise due care—a presumption now codified in Evidence Code section 669. Defendant Flood correctly concedes that the complaint alleges facts showing compliance with the first, third and fourth of the conditions specified of rebutting that presumption.\n\nInsofar as relevant here, section 669 provides:\n\"(a) The failure of a person to exercise due care is presumed if:\n\"(1) He violated a statute, ordinance, or regulation of a public entity;\n\"(2) The violation proximately caused death or injury to person or property;\n\"(3) The death or injury resulted from an occurrence of the nature which the statute, ordinance, or regulation was designed to prevent; and\n\"(4) The person suffering the death or the injury to his person or property was one of the class of persons for whose protection the statute, ordinance, or regulation was adopted.\n\"(b) This presumption may be rebutted by proof that:\n\"(1) The person violating the statute, ordinance, or regulation did what might reasonably be expected of a person of ordinary prudence, acting under similar circumstances, who desired to comply with the law; . . .\"\nA number of recent commentators support this theory of liability.\nFinally, defendants raise two questions of statutory interpretation. They contend that even if plaintiff may rely on Penal Code section 11161.5 in this case, she cannot invoke sections 11160 and 11161 because the latter are \"general\" statutes which have assertedly been superseded by the former as a \"special\" statute on the same topic. But such supersession occurs only when the provisions are \"inconsistent\" which is not here the case. Sections 11160 and 11161.5 are directed to different classes of persons, and hence are not inconsistent but complementary. Sections 11161 and 11161.5, on the other hand, are duplicative of each other to the extent that the former deals with physical injuries unlawfully inflicted on minors and the latter deals with the observation of such injuries by a physician. But inasmuch as the same penalty is provided for a violation of each section they do not present an irreconcilable conflict requiring one to give way to the other. There is nothing to prevent the Legislature from imposing a reporting requirement on physicians in two separate statutes, even if their coverage apparently overlaps.\n\nDefendants next contend that plaintiff can rely on section 11161.5 only if she can prove that Dr. Flood in fact observed her various injuries and in fact formed the opinion they were caused by other than accidental means and by another person—in other words, that his failure to comply with the reporting requirement of the statute was intentional rather than negligent. We first note that the complaint in effect so alleges, thereby mooting the issue at this pleading stage. For the guidance of the court at the trial, however, we briefly address the point of proof. The provision of section 11161.5 is ambiguous with respect to the required state of mind of the physician. It has been suggested that for the purposes of a criminal prosecution \"the more reasonable interpretation of the statutory language is that no physician can be convicted unless it is shown that it actually appeared to him that the injuries were inflicted injuries and formed the opinion they were intentionally inflicted on her.\n\nBy parity of reasoning, the same rule will apply if plaintiff elects to rely at trial on sections 11160 and 11161 as well.\nThis does not mean, of course, that plaintiff can meet her burden only by extracting damaging admissions from defendant Flood. \"The knowledge a person may have when material to an issue in a judicial proceeding is a fact to be proven as any other fact. It differs from physical objects and phenomena in that it is a state of mind like belief or consciousness and cannot be seen, heard or otherwise directly observed by other persons. It may be evidenced by the affirmative statement or admission of the possessor of it. If he is silent or says he did not have such knowledge, it may be evidenced in other ways,\" i.e., by circumstantial evidence and the inferences which the trier of fact may draw therefrom. Plaintiff will therefore be entitled to introduce proof of facts alleged in her complaint as circumstantial evidence that defendant Flood possessed the requisite state of mind, and any conflict between such evidence and direct testimony of defendant Flood will be for the trier of fact to resolve.\n\nThe judgment is reversed.\n\nJudges Wright, C. J., McComb, J., Tobriner, J., Sullivan, J., Clark, J., and Richardson, J., concurred.\n\nA diagnosis of battered child syndrome essentially means that serious injuries inflicted on a child were done by another person, by other than accidental means, and it had become an accepted medical diagnosis by the early 1970s. Many states have enacted penal statutes prohibiting child abuse, and many have enacted statutes of a general nature, or specifically applicable to cases of child abuse, imposing reporting requirements on physicians, and others in a professional position to recognize abuse.\n\nThe decision in Landeros v. Flood was the first time that a cause of action was established to exist in favor of a battered child against a physician who negligently failed to diagnose the battered child syndrome or to comply with an applicable reporting statute. Such failure was found to be the cause of further similar injury to the child. The causal chain was not broken by the fact that the subsequent injury was inflicted by the same third persons, namely the child's mother and her common-law husband who were responsible for the original injuries. The court held that no physician could be convicted for failure to make the necessary reports to the civil authorities as required by California statute, unless it was shown that it actually appeared to him that the injuries were inflicted on the child, so that his failure to report was intentional and not merely negligent. If the child wished to satisfy the requirements of the statute, it would be necessary to persuade the trier of fact that the physician actually observed her injuries and formed the requisite opinion that they were intentionally inflicted on her. The court also held that even if the trial court found the child experienced further beatings at the hands of her mother and the latter's husband, it constituted an \"intervening act\" and not a \"superseding cause\", thereby relieving the defendants of liability. This was predicated on the finding (at the trial court level) that the foreseeability arose directly from the risk created by the original negligence. This would be the risk created by the original failure of the physician to diagnose and report the injuries. This was a question of fact for the jury, and could not be dismissed by the trial court as a matter of law.\n\nChild abuse, or battered child syndrome was first reported in the medical literature in 1946 by Caffey. By the 1960s, the medical literature was rife with reports and discussions of both the syndrome, and the need for health care professionals to report it when diagnosed or suspected.\n\nSimilarly, there was copious discussion of the problem of child abuse in the sociological literature of the day.\n\nIt became apparent that before social and legal institutions can improve the home environment of a physically abused child, or remove the child from the harmful environment where necessary, the child must be identified. It is generally recognized that the physician is the primary means of identifying the abused child. Despite existing legislation requiring, as a matter of law, the reporting of suspicious cases, many physicians remained reluctant to report cases to civil authorities. Physicians reluctance to report has been traced to these factors :\n\n\nLanderos v. Flood was a landmark case in which tort law was used to purposely change the behavior of physicians and encourage them to report suspected child abuse. Otherwise, they would face the threat of civil action for damages in tort proximately flowing from the failure to report the suspected injuries.\n"}
{"id": "403159", "url": "https://en.wikipedia.org/wiki?curid=403159", "title": "List of health departments and ministries", "text": "List of health departments and ministries\n\nMost executive governments in the world are divided into departments or ministries. In most such cases, there is a department or ministry responsible for health.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "4198660", "url": "https://en.wikipedia.org/wiki?curid=4198660", "title": "Marcos Aguinis", "text": "Marcos Aguinis\n\nMarcos Aguinis (born 13 January 1935) is an Argentine writer. Trained in medical studies, music and psychoanalysis, his work and his thoughts are focused on the notions of independence, democracy and rejection of authoritarianism. He is a proponent of political liberalism, and participates in seminars and conferences from the Freedom Foundation organized by Mario Vargas Llosa.\n\nAguinis was born in Cruz del Eje, Córdoba, Argentina on January 13, 1935. He is an author with extensive international training in literature, neurosurgery, psychoanalysis, the arts and history. “I have traveled the world, but I have also traveled across different professions.” The son of Jewish immigrants, he was seven years old when the news came that the Nazis had killed his grandfather and the rest of his family that had remained in Europe. He describes this as the foundational moment of his life, and one that ultimately drove him to write in an effort to close that wound, to repair the “broken mechanism of humanity”.\n\nHe published his first book in 1963, and since then he has written fourteen novels, seventeen essay collections, four short story collections, and two biographies. Most of them have become bestsellers and have generated enthusiasm and controversy. Mr. Aguinis was the first author outside of Spain to receive the prestigious Planeta Award for his book “La Cruz Invertida” and his bestselling novel “Against the Inquisition (La Gesta del Marrano)” has been translated to several languages and praised by Nobel Prize Laureate Mario Vargas Llosa as a “stirring song of freedom”. He has written articles on a wide variety of topics for Latin American, U.S. and European newspapers and magazines. Marcos Aguinis has given hundreds of lectures and seminars at educational, artistic, scientific and political organizations in Germany, Spain, the U.S., Israel, Russia, Italy and practically every Latin American country.\n\nWhen democracy was reinstated in Argentina in December 1983, Marcos Aguinis was designated Vice-secretary and, eventually, Secretary of Culture; in this capacity, he sponsored the renowned “cultural renaissance” that inspired the country at the time. He created the National Program for Democratization of Culture (PRONDEC), sponsored by UNESCO and the United Nations. Mr. Aguinis promoted strong actions towards participation activities aimed at raising individual awareness of the rights, duties and potentialities that a true democracy fosters. His work was recognized with two nominations for the UNESCO Education for Peace Award.\n\nIn the field of human rights, he risked his life by courageously addressing controversial issues. During the last dictatorship, the circulation of his books was restricted, but some of them were successfully smuggled. Many of his readers admire his prophetic vision of the Arab-Israeli conflict, the internal struggles within the Catholic Church, the authoritarian political trends, and the resurgence of ethnic and religious fundamentalism.\n\nMarcos Aguinis, has received, among others, the Premio Planeta (Spain), Fernando Jeno Award (Mexico), Meritorious Award for Culture of the Academy of Arts and Communication Sciences, National Award for Sociology, Hispanic Literature and Culture Institute of California Award (USA), National Book Award, Argentina Society of Writers Honor Award, Pranavananda Swami Award, the Annual Silver Plaque EFE Agency for his contribution to the strengthening of Latin American culture and language, Esteban Echeverría Award (Free People), J. Award B. Alberdi (Hispanic American Center for Economic Research) and was appointed by France Chevalier of Arts and Letters. He was awarded the title of Doctor Honoris Causa of Tel Aviv University (2002), the Hebrew University of Jerusalem (2010) and he was named a Distinguished Writer in Residence at the American University in Washington, D.C. and Public Policy Scholar by the Wilson Center (Washington, USA). In 1995 Argentina's Writers Society conferred on him the Grand Prize of Honor for his work.\n\n\n\n\n\n\n"}
{"id": "1540142", "url": "https://en.wikipedia.org/wiki?curid=1540142", "title": "Martha Beck", "text": "Martha Beck\n\nMartha Nibley Beck (born November 29, 1962) is an American sociologist, life coach, best-selling author, and speaker who specializes in helping individuals and groups achieve personal and professional goals. She holds a bachelor's degree in East Asian Studies and master's and Ph.D. degrees in sociology, both from Harvard University. Beck is the daughter of deceased LDS Church scholar and apologist, Hugh Nibley. She received national attention after publication in 2005 of her best-seller, \"Leaving the Saints: How I Lost the Mormons and Found My Faith\" in which she recounts her experiences of surviving sexual abuse. In addition to authoring several books, Beck is a columnist for \"O, The Oprah Magazine\".\n\nMartha Nibley was born in Provo, Utah, in 1962, the seventh of eight children of Hugh Nibley and Phyllis Nibley, and raised LDS in a prominent Utah family. Her father was a professor at Brigham Young University. She received a BA degree in East Asian studies, along with an MA and a Ph.D. in sociology from Harvard University.\n\nDuring her academic career, Beck worked as a research associate at Harvard Business School, studying career paths and life-course changes. Before becoming a life coach, she taught sociology, social psychology, organizational behavior, and business management at Harvard and the American Graduate School of International Management. She has published academic books and articles on a variety of social science and business topics.Her non-academic books include the \"New York Times\" bestsellers \"Expecting Adam\" and \"Leaving the Saints\", as well as \"Finding Your Own North Star: Claiming the Life You Were Meant to Live\", \"Steering by Starlight\", and \"Finding Your Way in a Wild New World: Reclaiming Your True Nature\".\n\nBeck has also been a contributing editor for popular magazines, including \"Real Simple\" and \"Redbook\", and has been a columnist for \"O, the Oprah Magazine\" since July 2001. Her latest book, \"The Martha Beck Collection: Essays on Creating Your Right Life, Volume 1\", includes essays from her \"O, the Oprah Magazine\" column. Beck is president of Martha Beck, Inc., which offers a life coach training and certification program based on Beck's books and experience for individuals looking to acquire life coaching skills and tools. In addition to life coach training, Martha Beck, Inc., offers live events, products, and resources related to life coaching strategies.\n\nBeck met John Christen Beck, a fellow Mormon from Utah, during her undergraduate studies at Harvard. They married in the LDS Salt Lake Temple on June 21, 1983, in Salt Lake City, Utah, and they eventually had three children together.\n\nAfter the birth of their second child, Adam, who had been diagnosed with Down Syndrome prior to his birth, Beck returned with her husband and children to Utah to be closer to family and support. \"Expecting Adam: A True Story of Birth, Rebirth and Everyday Magic\" is Beck's story about her decision to give birth to and raise Adam.\n\nIn 1990, soon after the birth of her third child, Beck, as a part-time faculty member at Brigham Young University (BYU) in Provo, Utah, taught a course on the sociology of gender in the Department of Social Science. During her time as part-time faculty member at BYU, five faculty members were excommunicated from the LDS Church as a consequence of public writings that were deemed critical of the church; the group became known as the September Six. She and husband John Beck also made critical public statements about both the excommunications and other church and BYU matters, which led to first John, then Martha herself, leaving the LDS Church in 1993.\n\nSince leaving the LDS Church, both Martha Beck and her now ex-husband subsequently came out publicly as gay. In 2003, Beck separated from her husband, divorcing him in 2004. She now lives with her partner Karen Gerdes, a social worker and professor, and her son, Adam, on her North Star Ranch in San Luis Obispo County, California.\n\nBeck's first book, coauthored with her husband, John Beck, \"Breaking the Cycle of Compulsive Behavior,\" treated homosexuality as one of several \"compulsive behaviors,\" like bulimia. However, both Martha Beck and her now-ex-husband subsequently came out publicly as gay and have stated that they no longer consider homosexuality a form of compulsive behavior.\n\nIn 2005, she received national attention for her bestselling book, \"Leaving the Saints: How I Lost the Mormons and Found My Faith\". According to Sunstone magazine, the book may have originally been conceived as a novel, loosely based on her life (with a male main character), but was changed to recount her personal experiences, with the encouragement of her publishers. Ultimately released in March 2005, the book is a narrative in which Beck describes recovered memories of alleged sexual abuse by her father, prominent LDS academician Hugh Nibley; her experiences teaching at Brigham Young University; cultural dissonance and anomalies in Utah; her spiritual journey leaving the LDS Church.\n\nArticles were published in response to the book, including a critical essay by the Mormon author, Boyd Jay Petersen. Petersen, Beck's brother-in-law and Nibley's biographer, stated: \"Throughout this book, as with her other books, it is obvious that she distorts the record as much as or more than she reports it, jumps to conclusions more than provides evidence leading to conclusions, and blurs fact and fantasy.\" Beck responded to some of these criticisms by stating that she began having memories of her traumatic events prior to the use of any therapy (including hypnosis), that her vagina had scarring that may have been the result of sexual abuse, and that her memories were vivid and intrusive.\n\nSome members of Nibley's surviving family also challenge Beck's allegations by pointing out inconsistencies in her descriptions of events to various media sources and her use of self-hypnosis to intentionally recover the memories. Rebecca Nibley, Beck's sister, reported that Marsha Beck encouraged her to attempt to recover her own memories of abuse, without success. Beck acknowledged consulting recovered-memory therapist and self-hypnosis advocate Lynne Finney, although only after recovering her memories of abuse. Hugh Nibley's family claimed that Beck's experiences of sexual abuse recounted in her book were false and expressed \"outrage\" after the book's publishing. They furthermore expressed their dismay that Martha Beck has refused to speak with them, while claiming the reverse was true.\n\nAlthough most of the criticism from LDS church members in support of Nibley centered around Beck's allegations of sexual abuse, a substantial portion of the book involves a discussion of the LDS Church and its policies. BYU professor Robert L. Millet criticized Beck's portrayals of Nibley as \"nonsense,\" \"ludicrous,\" and \"paranoia,\" saying that she \"seems to be a magnet for improbable happenings\" and \"equate[s] weird anomalies in Mormon culture with the norm.\" Kent P. Jackson describes her description of Mormon culture as \"outlandish\", saying \"Beck's depictions of the church and BYU are so far removed from reality that it is clear that from the start she ruled out BYU faculty, other academics, and informed Latter-day Saints as potential readers. There was obviously no attempt made to establish credibility with those groups. ... this book was written for those who like stories about people victimized by powerful men and powerful institutions. Yet those who really know what she has written about will have a very hard time believing anything in the book.\" He proceeds to list a number of claims Beck made in the book which he asserts can be verified as false with readily available public information. Dan Wotherspoon, editor of the independent Mormon magazine Sunstone, similarly states \"She says a lot of things in there that anyone who lives in Utah will just know is wrong.\"\n\n\n\nBeck is also creator of a number of non-book products, primarily digital recording services that offer education and various life coaching strategies.\n\n"}
{"id": "3209367", "url": "https://en.wikipedia.org/wiki?curid=3209367", "title": "Maxillary lateral incisor", "text": "Maxillary lateral incisor\n\nThe maxillary lateral incisors are a pair of upper (maxillary) teeth that are located laterally (away from the midline of the face) from both maxillary central incisors of the mouth and medially (toward the midline of the face) from both maxillary canines. As with all incisors, their function is for shearing or cutting food during mastication, commonly known as chewing. There are generally no cusps on the teeth, but the rare condition known as talon cusps are most prevalent on the maxillary lateral incisors. The surface area of the tooth used in eating is called an incisal ridge or incisal edge. Though relatively the same, there are some minor differences between the deciduous (baby) maxillary lateral incisor and that of the permanent maxillary lateral incisor. The maxillary lateral incisors occlude in opposition to the mandibular lateral incisors.\n\nIn the universal system of notation, the deciduous maxillary lateral incisors are designated by a letter written in uppercase. The right deciduous maxillary lateral incisor is known as \"D\", and the left one is known as \"G\". The international notation has a different system of notation. Thus, the right deciduous maxillary lateral incisor known as \"52\", and the left one is known as \"62\".\n\nIn the universal system of notation, the permanent maxillary lateral incisors are designated by a number. The right permanent maxillary lateral incisor is known as \"7\", and the left one is known as \"10\". In the Palmer notation, a number is used in conjunction with a symbol designating in which quadrant the tooth is found. For this tooth, the left and right lateral incisors would have the same number, \"2\", but the right one would have the symbol, \"┘\", underneath it, while the left one would have, \"└\". The FDI notation has a different numbering system than the previous two, and the right permanent maxillary lateral incisor is known as \"12\", and the left one is known as \"22\".\n\nThe primary tooth will begin to show signs of development between 14 weeks and 16 weeks in utero, at an average of 16 weeks.\n\nThe permanent tooth typically will erupt between when the child is 8 or 9 years old, while the root will continue to mineralize until around 11 years old.. The tooth's crown will conclude its development around the age of 4 or 5.\n\nThere are two maxillary lateral incisors in the deciduous dentition. The teeth have a more curved distoincisal angle than the primary maxillary central incisor. The tooth is longer cervicoincisally than it is mesiodistally. The average length of the primary lateral incisor is 15.8 mm, with the average crown length being 5.6 mm and the root length average being 11.4 mm.\n\nAll primary teeth have several characteristics that are different when compared to the permanent dentition. The primary lateral incisor crown is wider mesiodistally than the permanent tooth and the roots of the primary lateral incisors are longer than the permanent tooth. The cervical ridges in all of anterior teeth are more prominent than in the \n\nThere are two maxillary lateral incisors in the permanent dentition, which begin to show signs of development at 10 to 12 months after birth. The maxillary lateral incisor resembles the maxillary central incisor, but is smaller in every dimension aside from root length. The root of the lateral incisor is around 1.5 times the length of the crown. The tooth has the most variability in crown shape in the mouth except the maxillary third molar. The two lateral incisors can also be congenitally missing. The teeth are less pigmented and are whiter in appearance than the permanent teeth.\n\nCompared to the maxillary central incisor, the maxillary lateral incisor has more rounded mesial and distal incisal angles. The distal outline is always more rounded. The root is often tapered distally, often with a sharp curve distally and to an apex; however, the curve can be absent. The mesial and distal contacts are more cervical than the central incisor. The surface is smooth. The labial view of the lateral incisor fits into the geometric shape of a trapezoid.\n\nThe distal and mesial marginal ridges are evident and the cingulum is prominent. The lingual fossa is more concave than the central incisor. The cingulum will often have a deep developmental groove on the distal side that can continue well into the root. The lingual view of the lateral incisor fits into the geometric shape of a trapezoid.\n\nThe curvature of the cementoenamel junction (CEJ) sharply inclines towards the incisal ridge. The mesial view of the lateral incisor fits into the geometric shape of a triangle.\n\nCompared to the tooth's mesial view of the cervical line, the distal cervical line is slightly more cervical by close to a millimeter. There may be a developmental groove present for all or most of the length. The distal view of the lateral incisor fits into the geometric shape of a triangle.\n\nCitations\nBibliography\n"}
{"id": "49284935", "url": "https://en.wikipedia.org/wiki?curid=49284935", "title": "Medical Association of Georgia", "text": "Medical Association of Georgia\n\nThe Medical Association of Georgia (MAG) is an organization in Georgia that advocates for physicians in the state. Established in 1849, it is an affiliate of the American Medical Association, and it has over 7,800 members. Since 1911, the MAG has published a quarterly journal, the Journal of the Medical Association of Georgia.\n\nThe MAG conducts regular annual sessions where the officers, members and delegates meet over several days. Between 1880 and 1910, most of these sessions were held in Atlanta, Augusta and Macon.\n"}
{"id": "10604681", "url": "https://en.wikipedia.org/wiki?curid=10604681", "title": "Medical home", "text": "Medical home\n\nThe medical home, also known as the patient-centered medical home (PCMH), is a team-based health care delivery model led by a health care provider to provide comprehensive and continuous medical care to patients with a goal to obtain maximal health outcomes. It is described in the \"Joint Principles\" (see below) as \"an approach to providing comprehensive primary care for children, youth and adults.\"\n\nThe provision of medical homes is intended to allow better access to health care, increase satisfaction with care, and improve health.\n\nThe \"Joint Principles\" that popularly define a PCMH were established through the efforts of the American Academy of Pediatrics (AAP), American Academy of Family Physicians (AAFP), American College of Physicians (ACP), and American Osteopathic Association (AOA) in 2007. Care coordination is an essential component of the PCMH. Care coordination requires additional resources such as health information technology and appropriately-trained staff to provide coordinated care through team-based models. Additionally, payment models that compensate PCMHs for their functions devoted to care coordination activities and patient-centered care management that fall outside the face-to-face patient encounter may help encourage further coordination.\n\nThe concept of the \"medical home\" has evolved since the first introduction of the term by the American Academy of Pediatrics in 1967. At the time, it was envisioned as a central source for all the medical information about a child, especially those with special needs. Efforts by Calvin C.J. Sia, MD, a Honolulu-based pediatrician, in pursuit of new approaches to improve early childhood development in Hawaii in the 1980s laid the groundwork for an Academy policy statement in 1992 that defined a medical home largely the way Sia conceived it: a strategy for delivering the family-centered, comprehensive, continuous, and coordinated care that all infants and children deserve. In 2002, the organization expanded and operationalized the definition.\n\nIn 2002, seven U.S. national family medicine organizations created the \"Future of Family Medicine\" project to \"transform and renew the specialty of family medicine.\" Among the recommendations of the project was that every American should have a \"personal medical home\" through which they could receive acute, chronic, and preventive health services. These services should be \"accessible, accountable, comprehensive, integrated, patient-centered, safe, scientifically valid, and satisfying to both patients and their physicians.\"\n\nAs of 2004, one study estimated that if the \"Future of Family Medicine\" recommendations were followed (including implementation of personal medical homes), \"health care costs would likely decrease by 5.6 percent, resulting in national savings of 67 billion dollars per year, with an improvement in the quality of the health care provided.\" A review of this assertion, published later the same year, determined that medical homes are \"associated with better health... with lower overall costs of care and with reductions in disparities in health.\"\n\nBy 2005, the American College of Physicians had developed an \"advanced medical home\" model. This model involved the use of evidence-based medicine, clinical decision support tools, the Chronic Care Model, medical care plans, \"enhanced and convenient\" access to care, quantitative indicators of quality, health information technology, and feedback on performance. Payment reform was also recognized as important to the implementation of the model.\n\nIBM and other organizations started the Patient-Centered Primary Care Collaborative in 2006 to promote the medical home model. As of 2009, its membership included \"some 500 large employers, insurers, consumer groups, and doctors\".\n\nIn 2007, the American Academy of Family Physicians, American Academy of Pediatrics, American College of Physicians, and American Osteopathic Association—the largest primary care physician organizations in the United States—released the \"Joint Principles of the Patient-Centered Medical Home\". Defining principles included: \n\nA survey of 3,535 U.S. adults released in 2007 found that 27 percent of the respondents reported having \"four indicators of a medical home.\" Furthermore, having a medical home was associated with better access to care, more preventive screenings, higher quality of care, and fewer racial and ethnic disparities.\n\nImportant developments concerning medical homes between 2008 and 2010 included:\n\nThe Accreditation Association for Ambulatory Health Care (AAAHC) in 2009 introduced the first accreditation program for medical homes to include an onsite survey. Unlike other quality assessment programs for medical homes, AAAHC Accreditation also mandates that PCMHs meet the Core Standards required of all ambulatory organizations seeking AAAHC Accreditation.\nAAAHC standards assess PCMH providers from the perspective of the patient. The onsite survey is conducted by surveyors who are qualified professionals – physicians, registered nurses, administrators and others – who have first-hand experience with ambulatory health care organizations. The onsite survey process gives them an opportunity to directly observe the quality of patient care and the facilities in which it is delivered, review medical records and assess patient perceptions and satisfaction.\n\nThe AAAHC Accreditation Handbook for Ambulatory Health Care includes a chapter specifically devoted to medical home standards, including assessment of the following characteristics: \n\nIn addition, electronic data management must be continually assessed as a tool for facilitating the Accreditation Association medical home.\n\nAAAHC Medical Home Accreditation also requires that core standards required of all ambulatory organizations seeking AAAHC Accreditation be met, including: Standards for rights of patients; governance; administration; quality of care; quality management and improvement; clinical records and health information; infection prevention and control, and safety; and facilities and environment. Depending on the services provided, AAAHC-Accredited medical homes may also have to meet adjunct standards such as for anesthesia, surgical, pharmaceutical, pathology and medical laboratory, diagnostic and other imaging, and dental services, among others.\n\nIn addition to its accreditation program for medical homes, the AAAHC is conducting a pilot \"Medical Home Certification\" program, which includes an onsite survey to evaluate an organization against their standards for medical homes. Full accreditation requires that organizations also be evaluated against all AAAHC core standards.\n\nThe National Committee for Quality Assurance's (NCQA) \"Physician Practice Connections and Patient Centered Medical Home\" (PPC-PCMH) Recognition Program emphasizes the systematic use of patient-centered, coordinated care management processes. It is an extension of the Physician Practice Connections Recognition Program, which was initiated in 2003 with support from organizations such as The Robert Wood Johnson Foundation, The Commonwealth Fund and Bridges to Excellence. The PPC-PCMH enhances the quality of patient care through the well known and empirically validated Wagner Chronic Care Model, which encourages the health care system to use community resources to effectively care for patients with chronic illnesses through productive interactions between activated patients and a prepared practice team. Furthermore, it recognizes practices that successfully use systematic processes and technology leading to improved quality of patient care.\n\nWith the guidance from the ACP, the AAFP, the AAP and the AOA the NCQA launched PPC-PCMH and\nbased the program on the medical home joint principles developed by these organizations.\n\nIf practices achieve NCQA's PCMH Recognition they can take advantage of financial incentives that health plans, employers, federal and state-sponsored pilot programs offer and they may qualify for additional bonuses or payments.\n\nIn order to attain PPC-PCMH Recognition, specific elements must be met. Included in the standards are ten \"must-pass\" elements:\n\n\nRecent peer-reviewed literature that examines the prevalence and effectiveness of medical homes includes:\n\nIn a study of 10 countries, the authors wrote that in most of the countries \"health promotion is usually separate from acute care, so the notion[] of a... medical home as conceptualized in the United States... does not exist.\" Nevertheless, the seven-country study of Schoen et al. found that the prevalence of medical homes was highest in New Zealand (61%) and lowest in Germany (45%).\n\nSome suggest that the medical home mimics the managed care \"gatekeeper\" models historically employed by HMOs; however, there are important distinctions between care coordination in the medical home and the \"gatekeeper\" model. In the medical home, the patient has open access to see whatever physician they choose. No referral or permission is required. The personal physician of choice, who has comprehensive knowledge of the patient's medical conditions, facilitates and provides information to subspecialists involved in the care of the patient. The gatekeeper model placed more financial risk on the physicians resulting in rewards for less care. The medical home puts emphasis on medical management rewarding quality patient-centered care.\n\nThe medical home model has its critics, including the following major organizations:\n\nClinics compliant with principles of the patient-centered medical home may be associated with more operating costs.\n\nOne notable implementation of medical homes has been Community Care of North Carolina (CCNC), which was started under the name \"Carolina Access\" in the early 1990s. CCNC consists of 14 community health networks that link approximately 750,000 Medicaid patients to medical homes. It is funded by North Carolina's Medicaid office, which pays $3 per member per month to networks and $2.50 per member per month to physicians. CCNC is reported to have improved healthcare for patients with asthma and diabetes. Non-peer-reviewed analyses cited in a peer-reviewed article suggested that CCNC saved North Carolina $60 million in fiscal year 2003 and $161 million in fiscal year 2006. However, an independent analysis asserted that CCNC cost the state over $400 million in 2006 instead of producing savings. More recent analyses show that the program improved the quality of care for asthma and diabetes patients significantly, reducing emergency department and hospital use that produced savings of $150 million in 2007 alone.\n\nThe Rhode Island Chronic Care Sustainability Initiative (CSI-RI) is a community-wide collaborative effort convened in 2006 by the Office of the Health Insurance Commissioner to develop a sustainable model of primary care that will improve the care of chronic disease and lead to better overall health outcomes for Rhode Islanders. CSI-RI is focused on improving the delivery of chronic illness care and supporting and sustaining primary care in the state of Rhode Island through the development and implementation of the patient-centered medical home. The CSI-RI Medical Home demonstration officially launched in October 2008 with 5 primary care practices and was expanded in April 2010 to include an additional 8 sites. Thirteen primary care sites, 66 providers, 39 Family Medicine residents, 68,000 patients (46,000 covered lives), and all Rhode Island payers are participating in the demonstration. Further, its selection to participate in the Centers for Medicare and Medicaid Services' Multi-Payer Advanced Primary Care Practice demonstration, CSI-RI is one few medical home demonstrations in the nation with virtually 100% payer participation. Since the start of the demonstration, CSI-RI sites have implemented a series of delivery system reforms in their practices, aimed at becoming patient-centered medical homes, and in turn receive a supplemental per-member-per-month payment from all of Rhode Island's insurers. Each participating practice site also receives funding from participating payers for an on-site nurse care manager, who can work with all patients in the practice, regardless of insurance type or status. All 5 original pilot sites achieved NCQA level 1 PPC-PCMH recognition in 2009, and all 8 expansion sites achieved at least level 1 PPC-PCMH recognition in 2010. As of December 2010, all of the pilot sites and two of the expansion sites have been recognized by NCQA as level 3 patient-centered medical homes.\n\nThe Agency for Healthcare Research and Quality offers grants to primary care practices in order for them to become patient-centered medical homes. The grants are designed to increase the evidence base for these types of transformations.\n\nAs of December 31, 2009, there were at least 26 pilot projects involving medical homes with external payment reform being conducted in 18 states. These pilots included over 14,000 physicians caring for nearly 5 million patients. The projects are evaluating factors such as clinical quality, cost, patient experience/satisfaction, and provider experience/satisfaction. Some of the projects underway are:\n\n\nIn 2006, TransforMED announced the launch of the National Demonstration Project aimed at transforming the way primary care is delivered in our country. The practice redesign initiative, funded by the AAFP, ran from June 2006 to May 2008. It was the first and largest \"proof-of-concept\" project to determine empirically whether the TransforMED Patient-Centered Medical Home model of care could be implemented successfully and sustained in today's health care environment. More specifically, the project served as a learning lab to gain better insight into the kinds of hands-on technical support family physicians want and need to implement the PCMH model of care. Learn more about National Demonstration Project\n\nBetween 2002 and 2006, Group Health Cooperative made reforms to increase efficiency and access at 20 primary care clinics in western Washington. These reforms had an adverse impact, increasing physician workload, fatigue, and turnover. Negative trends in quality of care and utilization also appeared. As a result, the Group Health Research Institute developed a patient-centered medical home model in one of the clinics. By increasing staff, patient outreach and care management, the clinic reduced emergency department visits and improved patient perceptions of care quality.\n\nThere are four core functions of primary care as conceptualized by Barbara Starfield and the Institute of Medicine. These four core functions consist of providing \"accessible, comprehensive, longitudinal, and coordinated care in the context of families and community\".\n\nIn the PCMH model, the integration of diverse services that a patient may need is encouraged. This integration which also involves the patient in interpreting the streams of information and working together to find a plan that fits with the patient's values and preferences is under-recognized and under-appreciated.\n\nAppropriate coordinated care depends on the patient or the population of patients and to a large extent, the complexity of their needs. The challenges involved with facilitating the delivery of care increases as the complexity of their needs increase. These complexities include chronic or acute health conditions, the social vulnerability of the patient, and the environment of the patient including the number of providers involved in their care. Other factors that may play a role in the patient's coordination of care include their preferences and their ability to organize their own care. The increases in complexity may overwhelm informal coordinating functions requiring a care team that can explicitly provide coordinated care and assume responsibility for the coordination of a particular patient's care.\n\nAccording to the ACO, care coordination achieves two critical objectives—high-quality and high-value care. ACOs can build on the coordinated care provided by the PCMHs and ensure and incentivize communications between teams of providers that operate in various settings. ACOs can facilitate transitions and align the resources needed to meet the clinical and coordinated care needs of the population. They can develop and support systems for the coordination of care of patients in non-ambulatory care settings. Furthermore, they can monitor health information systems and the timeliness and completeness of information transactions between primary care physicians and specialists. The tracking of this information can be used to incentivize higher levels of responsiveness and collaborations.\n\n\n"}
{"id": "36653684", "url": "https://en.wikipedia.org/wiki?curid=36653684", "title": "Mikhail Morosov", "text": "Mikhail Morosov\n\nMikhail Fyodorovich Morozov (born 1955) is the director of Durakovo's “Russian/American Center for Treatment of Alcoholics and Drug Addicts”, established using his own funds.\n\nMorozov is an alcoholic. He was marked at the age of 24 by the trauma from witnessing the death of his uncle, who drowned in the Moscow River while swimming drunk.\n\nOnce visiting a friend in early recovery in 1993, Mr. Morozov drove through the fields of Durakovo and found an Orthodox shrine, its cupola smashed and filled with a stork’s nest. He took it as a sign from God, built a small cottage, and launched a business in a nearby town, building a factory to mass-produce Russian Orthodox icons. As he brought friends and acquaintances with alcohol problems to the cottage for increasingly longer visits, he transformed the place into an informal treatment center. \"Rumors spread\", he says. \"That’s how people learned about us\".\n\nIn 2008, Nino Kirtadze made a documentary film entitled \"For God, Tsar and the Fatherland\" (alternative title: \"Durakovo: Village of Fools\"), regarding the rehabilitation centre in Đurakovo. Mr. Morozov was a central figure of the film, being suggested his authoritarian views of power, his sympathy towards president Vladimir Putin, his anti-democracy conceptions and profound mistrust towards the West.\n"}
{"id": "43781228", "url": "https://en.wikipedia.org/wiki?curid=43781228", "title": "Ministry of Health and Social Welfare, Liberia", "text": "Ministry of Health and Social Welfare, Liberia\n\nThe Ministry of Health and Social Welfare is a government ministry of the Republic of Liberia. In June 2015 Bernice Dahn became the Health Minister. Dahn succeeded Dr. Walter Gwenigale.\n\n, the ministry is engaged in a major public health campaign to control the Ebola virus epidemic in Liberia.\n\n"}
{"id": "54337892", "url": "https://en.wikipedia.org/wiki?curid=54337892", "title": "Online social support", "text": "Online social support\n\nOnline social support is a new form of social support that produced by development of internet, the more people are engaging to express and discuss with other via online community, the more online community getting similar with the social community and have the similar relation between social support and subjective well being. According to Robbins and Rosenfeld (2001), traditionally, listening\nsupport, confirmation, and appreciation are sources of subjective well-being. And Liu\nand Yu (2013) have stated validation, compliment, and encouragement are the most\ncommon types of support from the online community. Also, online friends can be an\nimportant source of social support (Ybarra, Mitchell, Palmer, & Reisner, 2015).\n\nMoreover, the number of Facebook friends associated with stronger perceptions of social support, which in turn associated with reduced stress, and in turn less physical illness and greater well-being which found by Nabi and So (2013).\n\nRozzell, et al. (2014) said that social media tools may allow for social support to be obtained from non-close as well as close relationships, with access to a significant proportion of non-close relationships. Moreover, social support derived from new information and communication technology counteracts the adverse effect of being unemployed (Fieseler, Meckel, & Müller, 2014).\n"}
{"id": "52602760", "url": "https://en.wikipedia.org/wiki?curid=52602760", "title": "Osstell AB", "text": "Osstell AB\n\nOsstell AB is a company headquartered in Gothenburg, Sweden that develops, manufactures, and sells devices and accessories used to measure dental implant stability. It was founded in 1999 with the aim of developing and commercializing a device that utilized resonance frequency analysis (RFA) to determine the level of stability of a dental implant.\n\nIn a dental implant procedure, a hole is drilled into the jawbone and a titanium implant is inserted. If and when the implant has proven to be stable in the jawbone, a prosthetic tooth is then affixed to the implant.\n\nOsstell’s patented RFA device (the most recent generation called Osstell IDx) helps dentists assess the stability of the implant, without having to physically disturb it. A small aluminum rod, called a SmartPeg, is placed in the implant. The RFA device prompts vibration in the rod by initiating magnetic pulses of varying frequencies. The RFA device detects the resonance frequency of the rod (called SmartPeg) while attached to the implant. The resonance frequency is converted to a numeric scale from 1 to 100, with higher numbers indicating higher stability.\n\nThis scale, called the Implant Stability Quotient (ISQ), corresponds with kHz frequency range of 3500–8500 kHz. The ISQ scale was developed by Osstell in order to give an immediately comprehensible indicator of implant stability and is now the global standard for implant stability measurement.\n\nThe instruments are manufactured in factories in Kungsbacka and Vänersborg, Sweden.\n"}
{"id": "1889064", "url": "https://en.wikipedia.org/wiki?curid=1889064", "title": "Pharmacogenetics", "text": "Pharmacogenetics\n\nPharmacogenetics is the study of inherited genetic differences in drug metabolic pathways (and other pharmacological principles, like enzymes, messengers and receptors) which can affect individual responses to drugs, both in terms of therapeutic effect as well as adverse effects. The term \"pharmacogenetics\" is often used interchangeably with the term \"pharmacogenomics\" which also investigates the role of acquired and inherited genetic differences in relation to drug response and drug behaviour through a systematic examination of genes, gene products, and inter- and intra-individual variation in gene expression and function.\n\nIn oncology, \"pharmacogenetics\" historically is the study of germline mutations (e.g., single-nucleotide polymorphisms affecting genes coding for liver enzymes responsible for drug deposition and pharmacokinetics), whereas \"pharmacogenomics\" refers to somatic mutations in tumoral DNA leading to alteration in drug response (e.g., KRAS mutations in patients treated with anti-Her1 biologics). Pharmacogenetics is believed to account for inter-ethnic differences (e.g., between patients of Asian, Caucasian and African descent) in adverse events and efficacy profiles of many widely used drugs in cancer chemotherapy.\n\nMuch of current clinical interest is at the level of pharmacogenetics, involving variation in genes involved in drug metabolism with a particular emphasis on improving drug safety. The wider use of pharmacogenetic testing is viewed by many as an outstanding opportunity to improve prescribing safety and efficacy. Driving this trend are the 106,000 deaths and 2.2 Million serious events caused by adverse drug reactions in the US each year. As such ADRs are responsible for 5-7% of hospital admissions in the US and Europe, lead to the withdrawal of 4% of new medicines, and cost society an amount equal to the costs of drug treatment.\n\nComparisons of the list of drugs most commonly implicated in adverse drug reactions with the list of metabolizing enzymes with known polymorphisms found that drugs commonly involved in adverse drug reactions were also those that were metabolized by enzymes with known polymorphisms (see Phillips, 2001).\n\nScientists and doctors are using this new technology for a variety of things, one being improving the efficacy of drugs. In psychology, we can predict quite accurately which anti-depressant a patient will best respond to by simply looking into their genetic code. This is a huge step from the previous practice of adjusting and experimenting with different medications to get the best response. Antidepressants also have a large percentage of unresponsive patients and poor prediction rate of ADRs (adverse drug reactions). In depressed patients, 30% are not helped by antidepressants. In psychopharmacological therapy, a patient must be on a drug for 2 weeks before the effects can be fully examined and evaluated. For a patient in that 30%, this could mean months of trying medications to find an antidote to their pain. Any assistance in predicting a patient’s drug reaction to psychopharmacological therapy should be taken advantage of. Pharmacogenetics is a very useful and important tool in predicting which drugs will be effective in various patients. The drug Plavix blocks platelet reception and is the second best selling prescription drug in the world, however, it is known to warrant different responses among patients. GWAS studies have linked the gene CYP2C19 to those who cannot normally metabolize Plavix. Plavix is given to patients after receiving a stent in the coronary artery to prevent clotting.\n\nStent clots almost always result in heart attack or sudden death, fortunately it only occurs in 1 or 2% of the population. That 1 or 2% are those with the CYP2C19 SNP. This finding has been applied in at least two hospitals, Scripps and Vanderbilt University, where patients who are candidates for heart stents are screened for the CYP2C19 variants.\n\nAnother newfound use of pharmacogenetics involves the use of Vitamin E. The Technion Israel Institute of Technology observed that vitamin E can be used to in certain genotypes to lower the risk of cardiovascular disease in patients with diabetes, but in the same patients with another genotype, vitamin E can raise the risk of cardiovascular disease. A study was carried out, showing vitamin E is able to increase the function of HDL in those with the genotype haptoglobin 2-2 who suffer from diabetes. HDL is a lipoprotein that removes cholesterol from the blood and is associated with a reduced risk of atherosclerosis and heart disease. However, if you have the misfortune to possess the genotype haptoglobin 2-1, the study shows that this same treatment can drastically decrease your HDL function and cause cardiovascular disease.\n\nPharmacogenetics is a rising concern in clinical oncology, because the therapeutic window of most anticancer drugs is narrow and patients with impaired ability to detoxify drugs will undergo life-threatening toxicities. In particular, genetic deregulations affecting genes coding for DPD, UGT1A1, TPMT, CDA and CYP2D6 are now considered as critical issues for patients treated with 5-FU/capecitabine, irinotecan, mercaptopurine/azathioprine, gemcitabine/capecitabine/AraC and tamoxifen, respectively. The decision to use pharmacogenetic techniques is influenced by the relative costs of genotyping technologies and the cost of providing a treatment to a patient with an incompatible genotype. When available, phenotype-based approaches proved their usefulness while being cost-effective.\n\nIn the search for informative correlates of psychotropic drug response, pharmacogenetics has several advantages:\n\nThe first observations of genetic variation in drug response date from the 1950s, involving the muscle relaxant suxamethonium chloride, and drugs metabolized by N-acetyltransferase. One in 3500 Caucasians has less efficient variant of the enzyme (butyrylcholinesterase) that metabolizes suxamethonium chloride. As a consequence, the drug’s effect is prolonged, with slower recovery from surgical paralysis. Variation in the N-acetyltransferase gene divides people into \"slow acetylators\" and \"fast acetylators\", with very different half-lives and blood concentrations of such important drugs as isoniazid (antituberculosis) and procainamide (antiarrhythmic). As part of the inborn system for clearing the body of xenobiotics, the cytochrome P450 oxidases (CYPs) are heavily involved in drug metabolism, and genetic variations in CYPs affect large populations. One member of the CYP superfamily, CYP2D6, now has over 75 known allelic variations, some of which lead to no activity, and some to enhanced activity. An estimated 29% of people in parts of East Africa may have multiple copies of the gene, and will therefore not be adequately treated with standard doses of drugs such as the painkiller codeine (which is activated by the enzyme). The first study using Genome-wide association studies (GWAS) linked age-related macular degeneration (AMD) with a SNP located on chromosome 1 that increased one’s risk of AMD. AMD is the most common cause of blindness, affecting more than seven million Americans. Until this study in 2005, we only knew about the inflammation of the retinal tissue causing AMD, not the genes responsible.\n\nOne of the earliest tests for a genetic variation resulting in a clinically important consequence was on the enzyme thiopurine methyltransferase (TPMT). TPMT metabolizes 6-mercaptopurine and azathioprine, two thiopurine drugs used in a range of indications, from childhood leukemia to autoimmune diseases. In people with a deficiency in TPMT activity, thiopurine metabolism must proceed by other pathways, one of which leads to the active thiopurine metabolite that is toxic to the bone marrow at high concentrations.\nDeficiency of TPMT affects a small proportion of people, though seriously. One in 300 people have two variant alleles and lack TPMT activity; these people need only 6-10% of the standard dose of the drug, and, if treated with the full dose, are at risk of severe bone marrow suppression. For them, genotype predicts clinical outcome, a prerequisite for an effective pharmacogenetic test. In 85-90% of affected people, this deficiency results from one of three common variant alleles. \nAround 10% of people are heterozygous – they carry one variant allele – and produce a reduced quantity of functional enzyme. Overall, they are at greater risk of adverse effects, although as individuals their genotype is not necessarily predictive of their clinical outcome, which makes the interpretation of a clinical test difficult. Recent research suggests that patients who are heterozygous may have a better response to treatment, which raises whether people who have two wild-type alleles could tolerate a higher therapeutic dose. \nThe US Food and Drug Administration (FDA) have recently deliberated the inclusion of a recommendation for testing for TPMT deficiency to the prescribing information for 6-mercaptopurine and azathioprine. The information previously carried the warning that inherited deficiency of the enzyme could increase the risk of severe bone marrow suppression. It now carries the recommendation that people who develop bone marrow suppression while receiving 6-mercaptopurine or azathioprine be tested for TPMT deficiency.\n\nA polymorphism near a human interferon gene is predictive of the effectiveness of an artificial interferon treatment for Hepatitis C. For genotype 1 hepatitis C treated with Pegylated interferon-alpha-2a or Pegylated interferon-alpha-2b (brand names Pegasys or PEG-Intron) combined with ribavirin, it has been shown that genetic polymorphisms near the human IL28B gene, encoding interferon lambda 3, are associated with significant differences in response to the treatment. Genotype 1 hepatitis C patients carrying certain genetic variant alleles near the IL28B gene are more probable to achieve sustained virological response after the treatment than others, and demonstrated that the same genetic variants are also associated with the natural clearance of the genotype 1 hepatitis C virus.\n\nDespite the many successes, most drugs are not tested using GWAS. However, it is estimated that over 25% of common medication have some type of genetic information that could be used in the medical field. If the use of personalized medicine is widely adopted and used, it will make medical trials more efficient. This will lower the costs that come about due to adverse drug side effects and prescription of drugs that have been proven ineffective in certain genotypes. It is very costly when a clinical trial is put to a stop by licensing authorities because of the small population who experiences adverse drug reactions. With the new push for pharmacogenetics, it is possible to develop and license a drug specifically intended for those who are the small population genetically at risk for adverse side effects.\nThe ability to test and analyze an individual’s DNA to determine if the body can break down certain drugs through the biochemical pathways has application in all fields of medicine. Pharmacogenetics gives those in the health care industry a potential solution to help prevent the significant number of deaths that occur each year due to drug reactions and side effects. The companies or laboratories that perform this testing can do so across all categories or drugs whether it be for high blood pressure, gastrointestinal, urological, psychotropic or anti-anxiety drugs. Results can be presented showing which drugs the body is capable of breaking down normally versus the drugs the body cannot break down normally. This test only needs to be done once and can provide valuable information such as a summary of an individual’s genetic polymorphisms, which could help in a situation such as being a patient in the emergency room. As pharmacogenetics continues to gain acceptance in clinical practice, when to utilize pharmacogenetics will be of importance in advancing patient care.\n\nAs the cost per genetic test decreases, the development of personalized drug therapies will increase. Technology now allows for genetic analysis of hundreds of target genes involved in medication metabolism and response in less than 24 hours for under $1,000. This a huge step towards bringing pharmacogenetic technology into everyday medical decisions. Likewise, companies like deCODE genetics, MD Labs Pharmacogenetics, Navigenics and 23andMe offer genome scans. The companies use the same genotyping chips that are used in GWAS studies and provide customers with a write-up of individual risk for various traits and diseases and testing for 500,000 known SNPs. Costs range from $995 to $2500 and include updates with new data from studies as they become available. The more expensive packages even included a telephone session with a genetics counselor to discuss the results.\n\nPharmacogenetics has become a controversial issue in the area of bioethics. It's a new topic to the medical field, as well as the public. This new technique will have a huge impact on society, influencing the treatment of both common and rare diseases. As a new topic in the medical field the ethics behind it are still not clear. However, ethical issues and their possible solutions are already being addressed.\n\nThere are three main ethical issues that have risen from pharmacogenetics. First, would there be a type equity at both drug development and the accessibility to tests. The concern of accessibility to the test is whether it is going to be available directly to patients via the internet, or over the counter. The second concern regards the confidentiality of storage and usage of genetic information. \nThirdly, would patients have the control over being tested.\n\nOne concern that has risen is the ethical decision health providers must take with respect to educating the patient of the risks and benefits of medicine developed by this new technology. Pharmacogenetics is a new process that may increase the benefits of medicine while decreasing the risk. However clinicians have been unsuccessful in educating patients regarding the concept of benefits over risk. The Nuffield Council reported that patients and health professionals have adequate information about pharmacogenetics tests and medicine. \nHealth care providers will also encounter an ethical decision in deciding to tell their patients that only certain individuals will benefit from the new medicine due to their genetic make-up. Another ethical concern is that patients who have not taken the test be able to have access to this type of medicine. If access is given by the doctor the medicine could negatively impact the patient's health. The ethical issues behind pharmacogenetics tests, as well as medicine, are still a concern and policies will need to be implemented in the future.\n\n\n"}
{"id": "14539602", "url": "https://en.wikipedia.org/wiki?curid=14539602", "title": "Private health services plan", "text": "Private health services plan\n\nA Private Health Services Plan in Canada is Health and/or Dental Care, as part of an insured Group Insurance Plan or a self-insured plan, such as a Health Spending Account, Cost-Plus Plan or one of the three options under a Health and Welfare Trust. \n\nHealth and Welfare Trusts are divided into three sections, one of which is a Private Health Services Plan. Private Health Services Plans can be Insured (by an Insurance Company) or Self-insured (through an Insurer or Administrator). Self-insured Private Health Services Plans are often referred to as Health Spending Accounts. The Canada Revenue Agency states that Self-insured Private Health Services Plans (Health Spending Accounts) are NOT AVAILABLE to any self-employed unincorporated employers without arms-length employees. Their only option is an Insured Plan with an Insurer. This can be confirmed by contacting CRA at itrulingsdirectorate@cra-arc.gc.ca\n\nIn 1986, the Canada Revenue Agency introduced an interpretation bulletin entitled IT-85R2 - Health & Welfare Trusts for Employees. This bulletin provided the basics for what would be known as a Health Spending Account or HSA to most Canadians. The original 1986 bulletin provided a tax-free vehicle for incorporated professionals and companies. Three years later in 1989, after pressure from non-incorporated entities, Canada Revenue Agency released another bulletin, IT-339R2 (\"Meaning of Private Health Services Plan\"), providing details on the concept of a Private Health Services Plan or PHSP for non-incorporated businesses in Canada.\n\nThe Canada Revenue Agency, in the annual Guides it publishes for those reporting self-employment income from a business or a profession, or from farming, provides instructions for deducting Private Health Services Plan premiums.\n\nThere is no confusion or controversy, just a lack of understanding of the CRA IT Bulletins. The funds in a PHSP, as outlined in the guidelines set in interpretation bulletin IT-339R2, \"CANNOT\" revert to the employer. Canada Revenue Agency released another bulletin in 1998 indicating that the funds could revert to the employer but \"ONLY\" in the case of a notional credit program tied to a flex benefits or cafeteria style plan. The \"notional credit\" model, outlined in the Canada Revenue Agency IT-bulletin entitled IT-529 was designed to allow companies to add an HSA to a Flex Benefits Plan as an additional benefit for items not covered under the traditional group benefits plan. The bulletin provided the accounting rules for flex benefit programs and using notional credits for the employer.\n\nToday, the major insurers offer Health Spending Accounts with a core group health insurance program. Several HSA Providers also offer Health Spending Accounts as stand-alone benefit solutions with carry-forward of deposited funds or incurred expenses - but not both - for a period of 12 months.\n\nThe employer can make contributions to an insured PHSP (like group insurance) with monthly premiums, or to a self-insured PHSP (like a Health Spending Account) on a periodic basis, or set a calendar year maximum for a plan with no prior contributions.\n\nNote: This is for an Insured Plan with an Insurer, and NOT for a Self-insured PHSP (a Health Spending Account)\n\nExample: A household with 1 sole-proprietor, a spouse, and one child under 18 years old would be eligible for 2 X $1,500 PLUS $750, for a total of $3,750.\n\nThe business owner may have the same spending limit assigned to full-time staff.\n\n Example: Executives $10,000/year, Managers $5,000/year, Employees $2,500/year\n\nForfeiture of Funds - Any funds must be used within 12 months from the date of deposit, with a 12 month carry-forward available as an optional selection. Deposit are NEVER forfeited to the administrator, as this would be theft of the Employer's funds.\n\nA sole-proprietor can establish a PHSP with an Insurer only. If the sole-proprietor has arms-length employees, they can provide a Health Spending Account for Employees and the same benefits for themselves.\n\nThe most common definition of a medical expense is a payment made to a licensed medical practitioner qualified to practice under the provincial laws of the place where the expenses were incurred. Medical expenses eligible to be paid out of the PHSP are expenses which would otherwise qualify as medical expenses within section 118.2(2) of the Income Tax Act. Some of the basic healthcare expenditures covered by an HSA include...\n\nDrugs prescribed by a Licensed Practitioner and dispensed by a Registered Pharmacist are eligible.\nVitamins and supplements (even if prescribed by a Licensed Medical Practitioner) are not an eligible medical expense.\n\nEyeglasses, if prescribed, are eligible medical expenses.\n\nAn amount paid to a dentist, dental hygienist, dental surgeon or dental mechanic for dental services provided to the patient (to the extent that the fees are for diagnostic, therapeutic or rehabilitative services) are eligible medical expenses.\n\nAn amount paid to a licensed medical practitioner is an eligible medical expense. They can include depending on the provincial jurisdiction:\n\n• Chiropractor\n• Audiologist\n• Chiropodist\n• Christian Science Practitioner\n• Dentist\n• Dental Hygienist\n• Dental Technician\n• Denturist\n• Dietician\n• Osteopath\n• Physiotherapist\n• Podiatrist\n• Psychiatrist\n• Psychoanalyst\n• Physician and Surgeon\n• Psychologist\n• Radiologist\n• Massage Therapist\n• Midwife\n• Neurologist\n• Occupational Therapist\n• Optician\n• Speech Therapist\n• Registered Nurse\n• Respiratory Therapist\n• Naturopath\n\nAll medical doctors, medical practitioners, dentists, pharmacists, nurses or optometrists must be authorized to practice under the laws of the provincial jurisdiction where the service is rendered, in order for the medical expenses to be eligible.\n\nIt has generally been accepted that an amount paid to a medical practitioner for surgery of any kind, whether cosmetic or elective generally qualifies as a medical expense. It is presumed that such surgery is carried out for a valid medical reason.\n\nCRA has however qualified that expenses for purely cosmetic procedures, including any related services and other expenses such as travel, incurred after March 4, 2010, are no longer an eligible expense. Both surgical and non-surgical procedures purely aimed at enhancing one’s appearance are a non-eligible expense.\n\nExamples of expenses that are non-eligible include the following:\n• liposuction;\n• hair replacement procedures;\n• botulinum injections; and\n• teeth whitening.\n\nAn expense, including those identified above, will continue to qualify if it is necessary for medical or reconstructive purposes, such as surgery to address a deformity related to a congenital abnormality, a personal injury resulting from an accident or trauma, or a disfiguring disease.\n\nIn addition to ambulance charges to and from hospitals, eligible medical expenses include any commercial transport service transporting a patient and an attendant (if medically necessary to accompany the patient) to a clinic/hospital/doctor’s office. The distance traveled must be in excess of 40 km to obtain such equivalent service not readily available closer to home. If the distance traveled is in excess of 80 km, the eligible costs would include meals and accommodation, in addition to transportation expenses.\n\nPremiums paid to a non-government medical or hospital care group plan are eligible medical expenses.\n\nThe employee can submit medical claims for him/herself and any of his/her dependents that are defined as:\n\n\nFor years, PHSPs have been a part of Canadian group health and dental plans. The PHSP can be set up as the primary health and dental plan by using a Health Spending Account, as a cost effective alternative to a traditional insured benefits plan.\n\nAccountable Value Financial Services, Assureflex, Helethan Benefits,Aquilian, Brock Health, Canada Smart Plan, Cost Plus, CustomCare, Health Plus Plan, HealthSmart, Neo Plan Plus, Smartin Benefits, Olympia Benefits, Promedent Plan, and The Health Plan, are among specialized providers of Health Spending Accounts (Self-insured PHSPs) in the form of pre-paid or notional credit programs. Major insurers such as Manulife, Sun Life, and Great-West Life Assurance offer Health Spending Accounts supplementary to group insurance (insured employee benefit plans) only.\n\nNote: Self-insured PHSP (Employer provided for Employees) are Health Spending Accounts.\n\nNote: HSAs for unincorporated owners without arms-length employees,are not acceptable to CRA.\n"}
{"id": "50500706", "url": "https://en.wikipedia.org/wiki?curid=50500706", "title": "Protein quality", "text": "Protein quality\n\nProtein quality is the digestibility and quantity of essential amino acids for providing the proteins in correct ratios for human consumption. There are various methods that rank the quality of different types of protein, some of which are outdated and no longer in use, or not considered as useful as they once were thought to be. The Protein Digestibility Corrected Amino Acid Score (PDCAAS), which was recommended by the Food and Agriculture Organization of the United Nations (FAO), became the industry standard in 1993. FAO has recently recommended the newer Digestible Indispensable Amino Acid Score (DIAAS) to supersede PDCAAS. The dairy industry is in favor of this, because while PDCAAS truncates all protein types that exceed the essential amino acid (EAA) requirements to 1.0, DIAAS allows a higher than 1.0 ranking: while for example both soy protein isolate and whey isolate are ranked 1.0 according to PDCAAS, in the DIAAS system, whey has a higher score than soy.\n\nThe main limitations of PDCAAS is that it doesn't take into account anti-nutrient factors like phytic acid and trypsin inhibitors, which limit the absorption of protein among other nutrients. For this reason, DIAAS is promoted as the superior method and preferable over the PDCAAS. Other older methods like BV, PER, NPU and nitrogen balance may not reveal much about the amino acid profile and digestibility of the protein source in question, but can still be considered useful in that they determine other aspects of protein quality not taken into account by PDCAAS and DIAAS.\n\nBelow follows a table that compares various proteins based on their rankings. Some of these results may differ and vary significantly depending on if it is soybeans or soy protein isolate, and so on. For example, while soybeans have a PDCAAS score of 0.91, many soy protein isolates (though not all) typically get a PDCAAS score of 1.0. Likewise, the amino acid profile may differ from crop to crop depending on the soil, and between different breeds of soy. Generally speaking, however, soybeans rarely outperform whey protein isolate in PDCAAS rankings.\n\nBelow follows a table that compares the complete amino acid profiles of various proteins. The amino acid score is based on the prevalence of the essential amino acids and depends on if they reach sufficient quantity. PDCAAS scores do not take into account the quantity of the non-essential amino acids. \n\n<nowiki>*</nowiki>Semi-essential, under certain conditions\n\n<nowiki>**</nowiki>Branched-chain amino acid (BCAA)\n"}
{"id": "24654349", "url": "https://en.wikipedia.org/wiki?curid=24654349", "title": "Rannasee", "text": "Rannasee\n\nThe Rannasee (or Rannastausee) is an artificial freshwater lake in Austria and in Germany. The reservoir is located along the Ranna River (which forms this part of the border between the two countries) and is the largest lake in the Bavarian Forest\n\nThe Rannasee was created in 1983 by damming the southeast corner (at the cost of 6.4 million Deutschmarks) both as a tourist resort and to generate hydro-electric power. The reservoir spans and reaches a maximum depth of , directly behind the dam. The village of Meierhof occupies the east shore north of the dam.\n\n"}
{"id": "31370137", "url": "https://en.wikipedia.org/wiki?curid=31370137", "title": "Romanian Red Cross", "text": "Romanian Red Cross\n\nThe Romanian Red Cross (CRR), also known as the National Society of Red Cross from Romania (\"Societatea Naționalǎ de Cruce Roșie din România\"), is a volunteer-led, humanitarian organization that provides emergency assistance, disaster relief and education inside Romania. It is the designated national affiliate of the International Federation of Red Cross and Red Crescent Societies.\n\nRomania became a signatory to the First Geneva Convention of 1864 and ratified it in 1874. Two years later, on July 4, 1876, the Romanian Red Cross Society was founded in Romania and began work in the present headquarters of the Colțea Hospital in Bucharest.\nAmong the signatories of the founding document of the Romanian Red Cross, there were important personalities of the time, such as: Nicolae Cretzulescu, George Gr. Cantacuzino, C.A. Rosetti, Ion Ghica, Dimitrie Sturza, Gr. G. Cantacuzino and Dr. Carol Davila.\n\nThe first president of the Romanian Red Cross was Prince Dimitrie Ghica, between 1876-1897.\n\nIn less than three weeks after the establishment, on July 20, 1876, the first Romanian Red Cross ambulance went on a humanitarian mission on the Serbian-Turkish front, south of the Danube. On the basis of solidarity that unites National Societies, the first mission of the Romanian Red Cross was meant to provide medical help to wounded soldiers, regardless of belligerent state they belonged to.\n\nDuring the War of Independence of 1877-1878, the Romanian Red Cross has stepped in with medical personnel, ambulances and sanitary trains in supporting the campaign. A hospital was founded in Bucharest and medical settlements in different cities all over the country. Red Cross Societies from Germany, Italy, Belgium, Sweden and France have sent material aid and medical personnel. On the front near Rahova, the Red Cross volunteers fought to limit the ravages of typhoid fever.\n\nIn 1885, the first Balkan war broke out, and the Romanian Red Cross proposed to the governments of two countries - Bulgaria and Serbia to accept an ambulance to cary the wounded. Immediately after receiving the agreement, two Romanian Red Cross ambulances had left the country, providing medical assistance to a total of 625 wounded and sick. Romanian sanitary formations deployed in Serbia and took care of three hospitals with a total of 110 beds. Material effort of the Romanian Red Cross amounted to 40 000 lei at the time.\n\nThe proven skill and care of the Romanian doctors, have been particularly appreciated by the governments of both belligerent countries.\n\nBetween 1888 and 1892, the Romanian Red Cross has expanded its activities by organizing special courses to prepare nurses. In 1891, a permanent school for nurses was established, and a year later a teaching hospital with 10 beds was founded. Taking advantage of a brief period of peace, the Romanian Red Cross has continued to organize and prepare, both in material terms, but also in terms of staff, to be able to act more effectively in case of necessity.\n\nIn 1913, during the second Balkan War, the Romanian Red Cross mobile hospital staff provided assistance to soldiers suffering from cholera on Bulgarian territory.\n\nWith the return of troops in the country, cholera spread in Romania, affecting a large number of people in the counties of Romanati, Teleorman and Dolj. The Red Cross intervened after it was requested this time by the national authorities and so large tents, medical supplies and medical teams managed to nurture and save thousands of cholera infected patients. In a letter of gratitude to the President of the Romanian Red Cross Alexandru Marghiloman, dr. Laugier, chief physician of the county of Dolj, wrote: \"With gratitude I find that the cholera epidemic was completely extinguished in the shortest possible time, giving conscientious and skilled care to patients\". The Red Cross medical teams had only mobile units at the time, but also a bacteriology laboratory, where they were performed more than 7,000 medical tests, \"reaching out to 44 communes with people infected with cholera\".\n\nBy the statute of the Red Cross, adopted in 1876, women were not part of the leadership of the Society. Therefore, in 1906, the 'Ladies Red Cross Society in Romania \", was established and its first elected president was Irina Campineanu. The society was operating in parallel with the one established in 1876 and it dealt with raising funds to help in time of war and disaster, preparing volunteers, co-opted devoted ladies in almost all cities around the country. In 1915, the General Assembly of the National Red Cross Society approved the merger of these two entities. On this occasion, Queen Marie, under whose patronage the Red Cross was at that time, the Romanian people was sent the following message: \"The Red Cross, our hope in case of peace as in war, should not perish. Everyone of us, small to large should support it with devotion, enthusiasm and infinite love. \"\n\nWith the support of a large number of volunteers, the Romanian Red Cross passed the fire test of the First World War. The mission of the RNRC was to assist the military by organizing 58 Hospitals both Bucharest and whole Romania. At the call of the Red Cross National Society, women belonging to various social groups have volunteered to work in hospitals and canteens run by the organization. Queen Marie herself was involved in operations, in support of those wounded. \n\nDuring these difficult years for the country, the Romanian Red Cross assisted more than 150,000 wounded in own hospitals, provided food for soldiers, refugees and people affected by conflict, facilitated the exchange of correspondence between the POWs and their families, supported Romanian prisoners held in enemy camps with food and clothing. Funds for these operations have been mobilized by the Red Cross from public donations, from the population and from external sources.\n\nAfter stopping the cholera, another epidemic broke out throughout the full scale armed conflict: typhus. In early 1917, the Romanian Red Cross cared for the wounded evacuated from the front, and patients affected by the two serious infectious diseases. The RNRC had to face this difficult situation, given that the occupying army requisitioned the best medical establishments of the Red Cross and took to benefit their own troops, for a good part of the materials and drugs that were bought with huge efforts by the RNRC. Only in the occupied capital over 7,000 patients were cared for. The RNRC branches were active in over 40 cities, taking care of thousands of wounded and sick.\n\n\nThe RNRC is the only humanitarian organization in the country which has clear duties as auxiliary to public authorities, especially in the field of prevention and intervention in case of disaster.\n\nBasic First Aid is only a temporary relief granted in an emergency case to save lives, prevent suffering further complications and improve until an appropriate medical service can intervene.The Romanian Red Cross has an unbroken tradition of over 134 years in giving basic first aid training and volunteer Red Cross nurses. The first courses on proper \"bandaging\" was organized in 1877, at the Colțea Hospital in Bucharest. Since then, thousands have graduated from first aid courses or Red Cross volunteer sisters courses. Romanian personalities wore throughout white uniforms with the emblem of the Red Cross. During World War I, Queen Marie, dressed in Red Cross nurse's uniform, inspected the front or rear front of hospitals campaign and actively took part in assisting those injured.\n\nThe RNRC organizes regular courses on basic first aid at each county branch. These courses are given by medics, which are attested as trainers of paramedical assistance. The RNRC always offers its trainees all the necessary equipment, materials and tools. This course is finalised with an exam which proves that the person who took part in these courses is qualified in giving basic first aid.\n\nIf a century ago the RNRC run campaigns against malaria and typhus, today the Romanian Red Cross is working to prevent and combat HIV/AIDS, TB and avian flu, each time getting involved in public health priority issues. Drug use, maternal health, combating non-communicable diseases, respiratory, cardio-vascular diseases - are special problems that are also in the RNRCs attention.\n\nThe program addresses the entire population, in general, and in particular reaches out to youth, and the shares are held in partnership with governmental institutions and NGOs. Health Programs are developed with the support of volunteers trained in seminars organized by the Romanian Red Cross.\n\nRNRC prepares and distributes information materials: leaflets, brochures, educational and health-themed campaigns and actions on specific themes. Also, the Romanian Red Cross marks annually, through public events, today's global health issues, and those of the World Health Organization schedule.\n\nThe Romanian Red Cross social program is aimed at improving the living conditions of vulnerable people.For the Romanian Red Cross, \"vulnerable people\" are those who are at risk, due to situations that threaten their survival or their ability to live in conditions of minimum material security and human dignity. These actions aimed at improving the quality of life of those in need are generally developed in three main directions:\n\nThe group - which is the target and address of the RNRC social program consists of: persons residing in Romania and, for economic, physical, mental or social reasons are unable to ensure social needs. If the basic social needs have not been met, such as food, shelter, clothing, health - where the most vulnerable people are; the main focus most certainly are those living in extreme poverty - under a dollar a day.\n\nPeople search service is a special and unique service of the Red Cross, at an international level, in the humanitarian field.\n\nBeing nearly a century old, the Red Cross people search service has a range of action in 186 countries worldwide. This service can restore and maintain ties between family members, due to international armed conflicts, internal national disturbances, natural disasters or special social situations, of a humanitarian nature, that were separated.\n\nRomanian Red Cross responds to all requests of citizens who meet the following search criteria:\n\n- interruption of contact with relatives abroad\n- locate missing relatives during international conflicts\n- mediation to obtain certificates of detention, imprisonment, deportation, death\n- transmission of Red Cross messages (to/from) conflict areas, where normal communication channels have been discontinued\n- assistance to unaccompanied minors, following an armed conflict, to restore family links\n\nIn Romania, the RNRC has 47 branches, 1,996 sub-branches and 1,207 committees is making benefit of a single and unique structure, established over 130 years ago.\nThere exists a county branch in each of the counties of Romania, plus one for each sector of the city of Bucharest. The sub-branches are organised as one for each, city, town, commune and village.\n"}
{"id": "3581407", "url": "https://en.wikipedia.org/wiki?curid=3581407", "title": "Select agent", "text": "Select agent\n\nUnder United States law, \"Biological Select Agents or Toxins\" (BSATs) — or simply select agents for short — are bio-agents which since 1997 have been declared by the U.S. Department of Health and Human Services (HHS) or by the U.S. Department of Agriculture (USDA) to have the \"potential to pose a severe threat to public health and safety\". The agents are divided into (1) HHS select agents and toxins affecting humans; (2) USDA select agents and toxins affecting agriculture; and (3) overlap select agents and toxins affecting both.\n\nThe U.S. Centers for Disease Control and Prevention (CDC) regulates the laboratories which may possess, use, or transfer select agents within the United States in its Select Agent Program (SAP) — also called the Federal Select Agent Program (FSAP) — since 2001. The SAP was established to satisfy requirements of the USA PATRIOT Act of 2001 and the Public Health Security and Bioterrorism Preparedness and Response Act of 2002, which were enacted in the wake of the September 11, 2001 attacks and the subsequent 2001 anthrax attacks.\n\nUsing BSATs in biomedical research prompts concerns about dual use. The federal government created the National Science Advisory Board for Biosecurity which promotes biosecurity in life science research. It is composed of government, education and industry experts who provide policy recommendations on ways to minimize the possibility that knowledge and technologies emanating from biological research will be misused to threaten public health or national security.\n\nThe CDC has regulated the laboratories which may possess, use, or transfer select agents within the United States under the SAP since 2001. The SAP was established to satisfy requirements of the USA PATRIOT Act of 2001 and the Public Health Security and Bioterrorism Preparedness and Response Act of 2002, which were enacted in the wake of the September 11, 2001 attacks and the subsequent 2001 anthrax attacks.\nUsing select agents in biomedical research prompts concerns about dual use. The federal government created the National Science Advisory Board for Biosecurity to promote biosecurity in life science research. It is composed of government, education and industry experts who provide policy recommendations on ways to minimize the possibility that knowledge and technologies emanating from biological research will be misused to threaten public health or national security.\n\nIn July 2015, Gregory E. Demske, chief counsel to the inspector general in the HHS Office of Inspector General (OIG), testified that 30 civil violations of the SAP rules had been identified in the past 13 years, and that violators had paid about $2.4 million in fines. He explained that when the CDC's Division of Select Agents and Toxins detects possible SAP misconduct by an HHS worker, it coordinates with the OIG to gather facts; if it concludes that a civil violation might have occurred, it turns the case over to the OIG for possible enforcement. But if it suspects a crime, it pursues the matter with the FBI. Since passage of the Bioterrorism Act of 2002, the OIG had received 68 referrals from the CDC for possible Select Agent enforcement and found violations in 30 of those cases. Notices of violation were sent to 5 federal entities, 3 universities, and 2 other private organizations, all unnamed in his testimony. Demske remarked that no federal agencies had been fined for SAP violations.\n\n\n\n\n\n\n\n\n\n\nSelect agent regulations were revised in October 2012 to remove 19 BSATs from the list (7 Human and Overlap Agents and 12 Animal Agents).\n\n\n\n\n"}
{"id": "21219199", "url": "https://en.wikipedia.org/wiki?curid=21219199", "title": "Skevos Zervos", "text": "Skevos Zervos\n\nSkevophylax Georges Zervos, also known as Skevos Zervos (, 1875–1966) was a prominent Greek Professor; a pioneer surgeon in Transplants and Telemedicine, who became a local and national benefactor in Greece.\n\nSkevos was born and raised in Kalymnos City or Pothia, the capital of the island Kalymnos, Greece. Skevos was a member of a local wealthy, influential, distinguished and aristocratic family on the island. The family of Skevos had built the local hospital and local orphanage on the island, and through this they became local benefactors.\n\nHis brother was a local prominent citizen called Kleanthes Zervos and his nephew was the local Christian Bishop of Kalymnos, Nikephoros Zervos whom in 1905 founded and established the Nikephoros High School, the first high school set up in Kalymnos. In front of the high school, there is a statue bust dedicated to Nikephoros Zervos.\n\nSkevos in his student years was a traditional free naked sponge diver in Kalymnos. Skevos dived with a traditional and multi-purpose tool called a Skandalopetra, which was used as a steering wheel/base tied as a line of communication with the boat. Diving for sponges is a part of the traditional diving heritage of Greece and the Aegean Sea.\n\nIn 1910, Skevos was the first surgeon to perform the testicle transplantation from an ape to a man. This operation was successful. In 1934, this surgery was officially recognised by the Russian Surgeon Serge Voronoff.\n\nIn 1919, Skevos assisted the Greek Politician Eleftherios Venizelos who traveled to the Paris Peace Conference in regaining the Dodecanese as a part of the modern state of Greece. On March 7, 1948, he was a paragon of the Central Dodecanese Committee and was present in Rhodes, when the United Nations, returned the Dodecanese region to the then government of Greece.\n\nSkevos was a Medical Professor of the School of Medicine at the National and Kapodistrian University of Athens. There Skevos developed a system that allowed him to examine a patient from a distance. This examination was concerning auscultation and cardiac pulses. The data could be transmitted in any place around the world. Virtues of the system were demonstrated in several experiments conducted in plenary sessions of the Athens Medical Society at the National University of Athens, at the National Technical University of Athens and at the Athens Academy during the signals were transmitted from several Athens hospitals and various Greek cities. His scientific research was published in the \"Annals of the Athens Medical Society\" (1946–1956). His system was proposed to be used on board of the Greek Ships that were offering regular service between Piraeus and New York City. The communication at this time could not be afforded and the system was not used.\n\nSkevos in his elder years married, however he had no children. In his honor the \"disease of the naked sponge divers\" was named \"Skevos Zervos disease\". As a posthumous honor, the local Kalymnian Government erected a life-size statue of him.\n\n"}
{"id": "4515987", "url": "https://en.wikipedia.org/wiki?curid=4515987", "title": "Social effects of H5N1", "text": "Social effects of H5N1\n\nThe social impact of H5N1 is the effect or influence of H5N1 in human society; especially the financial, political, social, and personal responses to both actual and predicted deaths in birds, humans, and other animals. Billions of dollars are being raised and spent to research H5N1 and prepare for a potential avian influenza pandemic. Over ten billion dollars have been lost and over two hundred million birds have been killed to try to contain H5N1. People have reacted by buying less chicken causing poultry sales and prices to fall. Many individuals have stockpiled supplies for a possible flu pandemic.\n\nOn November 1, 2005 President George W. Bush unveiled the National Strategy To Safeguard Against The Danger of Pandemic Influenza backed by a request to Congress for $7.1 billion to begin implementing the plan.\n\nOn January 18, 2006 donor nations pledged two billion US dollars to combat bird flu at the two-day International Pledging Conference on Avian and Human Influenza held in China. Over ten billion dollars have been spent and over two hundred million birds have been killed to try to contain H5N1.\n\nAccording to \"The New York Times\", due to the H5N1 threat, as of March 2006: \"governments worldwide have spent billions planning for a potential influenza pandemic: buying medicines, running disaster drills, [and] developing strategies for tighter border controls.\"\n\nInvestment strategies are being altered to manage the effects of H5N1. This changes the valuations of trillions of dollars' worth of stocks worldwide as investors move assets in accordance with both fears and hopes.\n\nPoultry farming practices have changed due to H5N1:\n\nFor example, after nearly two years of using mainly culling to control the virus, the Vietnam government in 2005 adopted a combination of mass poultry vaccination, disinfecting, culling, information campaigns and bans on live poultry in cities.\n\nThe cost of poultry farming has increased, while the cost to consumers has gone down due to fears from H5N1 driving demand below supply, resulting in devastating losses for many poultry farmers. Poor poultry farmers can't afford mandated measures keeping their bird livestock from contact with wild birds (and other measures) thus risking losing their livelihood altogether. Multinational poultry farming is increasingly becoming a profit loser as H5N1 achieves status as endemic in wild birds worldwide.\n\nFinancial ruin for poor poultry farmers, that can be as severe as threatening starvation, has caused some to commit suicide and many others to stop cooperating with efforts to deal with H5N1; further increasing the human toll, the spread of the disease and the chances for a pandemic mutation.\n\nUS HHS Secretary Michael O. Leavitt has said \"Everything you say in advance of a pandemic is alarmist; anything you do after it starts is inadequate.\"\n\nH5N1, like everything else, is subject to political spin; wherein every interest group picks and chooses among the facts to support their favorite cause resulting in a distortion of the overall picture, the motivations of the people involved and the believability of the predictions.\n\nDonald Rumsfeld, formerly United States Secretary of Defense, is a past board member and current minor shareholder of Gilead Sciences which owns intellectual property rights to Oseltamivir (also called \"Tamiflu\"). In November 2005, George W. Bush urged Congress to pass 7.1 billion in emergency funding to prepare for the possible bird flu pandemic, of which one billion is solely dedicated to the purchase, and distribution of Tamiflu.\n\nSome believe \"The deadly H5N1 strain of bird flu is essentially a problem of industrial poultry practices.\"\n\nOthers have a more nuanced position. According to the CDC article \"H5N1 Outbreaks and Enzootic Influenza\" by Robert G. Webster et al.:\"Transmission of highly pathogenic H5N1 from domestic poultry back to migratory waterfowl in western China has increased the geographic spread. The spread of H5N1 and its likely reintroduction to domestic poultry increase the need for good agricultural vaccines. In fact, the root cause of the continuing H5N1 pandemic threat may be the way the pathogenicity of H5N1 viruses is masked by cocirculating influenza viruses or bad agricultural vaccines.\" Dr. Robert Webster explains: \"If you use a good vaccine you can prevent the transmission within poultry and to humans. But if they have been using vaccines now [in China] for several years, why is there so much bird flu? There is bad vaccine that stops the disease in the bird but the bird goes on pooping out virus and maintaining it and changing it. And I think this is what is going on in China. It has to be. Either there is not enough vaccine being used or there is substandard vaccine being used. Probably both. It's not just China. We can't blame China for substandard vaccines. I think there are substandard vaccines for influenza in poultry all over the world.\" In response to the same concerns, Reuters reports Hong Kong infectious disease expert Lo Wing-lok saying that \"The issue of vaccines has to take top priority\", and Julie Hall, in charge of the WHO's outbreak response in China, saying that China's vaccinations could be \"masking\" the virus. The BBC reported that Dr Wendy Barclay, a virologist at the University of Reading, UK said: \"The Chinese have made a vaccine based on reverse genetics made with H5N1 antigens, and they have been using it. There has been a lot of criticism of what they have done, because they have protected their chickens against death from this virus but the chickens still get infected; and then you get drift - the virus mutates in response to the antibodies - and now we have a situation where we have five or six 'flavours' of H5N1 out there.\"\n\nSome have called for tax breaks due to H5N1. A May 7, 2006 report from India E-News states that: \"Pakistani poultry farmers have sought a 10-year tax exemption to support their dwindling business after the detection of the H5N1 strain of bird flu triggered a fall in demand and prices, a poultry trader said. \"We have asked the government to give us tax exemption on income from the poultry business for at least 10 years to meet losses caused by the bird flu scare\", Abdul Basit told DPA. Basit, vice president of the Chamber of Commerce and Industry (LCCI) in the country's commercial hub of Lahore, was part of a delegation of the Pakistan Poultry Association, which met food ministry officials to present their demand. The federal poultry board of the food ministry is to meet on May 9 to consider the tax-cut demand for the poultry business in the upcoming national budget due in mid-June.\"\n\nReuters reported that WHO expert Hassan al-Bushra said:\nEven now, we remain unsure about Tamiflu's real effectiveness. As for a vaccine, work cannot start on it until the emergence of a new virus, and we predict it would take six to nine months to develop it. For the moment, we cannot by any means count on a potential vaccine to prevent the spread of a contagious influenza virus, whose various precedents in the past 90 years have been highly pathogenic. However, it is crucial that countries in the Middle East invest and start developing their own research and technical facilities, where they can produce their own drugs when the time comes rather than wait to import expensive medicines from abroad at the risk of their population.\n\nIf a pandemic occurs, local response will be more important than national or international response, as every community will have its own resources swamped dealing with its own problems. International groups, nations, local governments, corporations, schools, and groups of all kinds have made plans and run drills to prepare for an H5N1 pandemic.\n\nOnline avian flu forums have received increasing attention. Self-help groups have organized to provide news and information about resources, aid and relief efforts in preparation for avian flu.\n\nBritish reports warn that in response to an influenza pandemic local groups will not be able to rely on the armed forces, widespread infection could occur in days not months, an effective vaccine can not be counted on, and the huge death toll could swamp mortuaries so \"A key point for local planning is likely to be the identification of potential sites for the location of facilities for the temporary storage of bodies\".\n\nMany individuals have stockpiled supplies (Tamiflu, food, water, etc.) for a possible flu pandemic.\n\nIndividuals have started web sites and companies using interest and ignorance in H5N1 to sell information, cures, and advertising space. Some even use concern over H5N1 to find victims for their malware.\n\nA significant effect of H5N1 has been personal fear concerning the unknown, even by those most in-the-know. Dr. David Nabarro, chief avian flu coordinator for the United Nations, describes himself as \"quite scared\"; says avian flu has too many unanswered questions; and if the disease starts spreading to humans, borders will close, airports will shut down, and travelers everywhere will be stranded. With evaluations of the threat ranging from those who say it is a hoax to those who warn of billions of humans dying, uncertainty and fear motivate personal behaviors around the world affecting many people even before the threat becomes reality.\n\nThe 1998 chart-topping hit song \"One Week\" by Barenaked Ladies includes the lines \"Chickity China the Chinese chicken / Have a drumstick and your brain stops tickin'\", a reference to the outbreaks of H5N1 in Hong Kong around the time the song was written.\n\nThe annual flu season deaths and costs caused by viruses other than H5N1 provide a point of contrast - something to compare against. According to the United States Government, the annual flu in the United States:\nresults in approximately 36,000 deaths and more than 200,000 hospitalizations each year. In addition to this human toll, influenza is annually responsible for a total cost of over $10 billion in the United States. A pandemic, or worldwide outbreak of a new influenza virus, could dwarf this impact by overwhelming our health and medical capabilities, potentially resulting in hundreds of thousands of deaths, millions of hospitalizations, and hundreds of billions of dollars in direct and indirect costs.\n\nThe \"New England Journal of Medicine\" reported that: \"A study by the Congressional Budget Office estimates that the consequences of a severe pandemic could, in the United States, include 200 million people infected, 90 million clinically ill, and 2 million dead. The study estimates that 30 percent of all workers would become ill and 2.5 percent would die, with 30 percent of workers missing a mean of three weeks of work — resulting in a decrease in the gross domestic product of 5 percent. Furthermore, 18 million to 45 million people would require outpatient care, and economic costs would total approximately $675 billion.\" One study concludes that a pandemic that reduced the available dock workers by 28% would cut the throughput capacity for containers arriving at American ports on the West coast by 45%.\n\n"}
{"id": "10995583", "url": "https://en.wikipedia.org/wiki?curid=10995583", "title": "Tirso del Junco Jr.", "text": "Tirso del Junco Jr.\n\nTirso del Junco Jr. (born Tirso del Junco-Bobadilla in Washington) is a Cuban-American surgeon.\n\nHe is the son of surgeon, Tirso del Junco-Mesa and Celia Bobadilla.\n\nDel Junco graduated from medical school from the Universidad Autónoma de Guadalajara in 1980. He did his internship at the Queen of Angels Medical Center in Los Angeles, California. In 1997 he was appointed Commissioner to the California State Athletic Commission and was a member if the Oversight Committee of the Department of Health Service for California. He served as Chairman of the Department of Surgery at Santa Marta Hospital and later as Chief of Staff there. Since January 2007, he has been the Chief of Surgery at Temple Community Hospital.\n\n\n"}
{"id": "2535940", "url": "https://en.wikipedia.org/wiki?curid=2535940", "title": "Tsimlyansk Reservoir", "text": "Tsimlyansk Reservoir\n\nTsimlyansk Reservoir or Tsimlyanskoye Reservoir () is an artificial lake on the Don River in the territories of Rostov and Volgograd Oblasts at . Completed in 1952, the reservoir is one of the largest in Russia, providing power ( ) and irrigation to the Rostov and Volgograd regions. Crops grown around the lake include wheat, rice, cotton, maize, alfalfa, fruit, grapes, and vegetables.\n\nThe reservoir, together with the Volga-Don Canal and the lower course of the Don, provides an important waterway between the Volga River / Caspian Sea basin and the Sea of Azov. The Tsimlyansk Dam also provides flood control for the lower Don River basin.\n\nCompletion of the lake resulted in strong local industrial growth. In particular, the city of Volgodonsk owes its existence to the Tsimlyansk Dam project.\n\nUnder the waters lies the ancient Khazar fortress town of Sarkel.\n\nAlong with the Volga-Don Canal, the reservoir forms part of a waterway for the shipping of raw materials from the upper Don and Volga-Caspian basins to the lower Don River - Sea of Azov basin and vice versa. According to the federal agency responsible for the maintenance of this waterway (Федеральное Государственное Учреждение \"Волго-Донское ГБУВПиС\"), guaranteed depth of the main navigable waterway through the reservoir in the navigation season of 2007 was to be maintained at no less than 3.6 meters, with the width of the navigable waterway no less than 50 meters. It was to be available for navigation for 233 days, from April 5 to November 23, 2007.\n\nTo descend from the reservoir to the lower Don, ships have to pass two ship locks: the lock in the Tsimlyansky Dam itself (), known as Lock No. 14, followed by Lock No. 15 () a couple of kilometers farther west. The locks are assigned these numbers because they are considered part of the same sequence of locks as the 13 locks on the Volga-Don Canal itself. During the navigation seasons of 2008 through 2010, the two locks are scheduled to operate from April 2 through December 8.\n\n"}
{"id": "45039216", "url": "https://en.wikipedia.org/wiki?curid=45039216", "title": "Washington Apple Health", "text": "Washington Apple Health\n\nWashington Apple Health is the Medicaid and State Children's Health Insurance Programs offered in Washington state. The program was initiated January 1, 2014. It was preceded in 2008 by a children's health plan run by the Washington State Department of Social and Health Services called \"Apple Health for Kids\". In 2016, the plan was ordered by a Federal district court judge to include a coverage treatment with a certain drug for Hepatitis C to all 28,000 patients with the disease, not only those who qualified based on degree of liver damage. \n"}
{"id": "23817469", "url": "https://en.wikipedia.org/wiki?curid=23817469", "title": "Water fluoridation in the United States", "text": "Water fluoridation in the United States\n\nAs with some other countries, water fluoridation in the United States is a contentious issue. As of May 2000, 42 of the 50 largest U.S. cities had water fluoridation. On January 25, 1945, Grand Rapids, Michigan, became the first community in the United States to fluoridate its drinking water to prevent tooth decay.\n\nFluoridation became an official policy of the U.S. Public Health Service by 1951, and by 1960 water fluoridation had become widely used in the U.S., reaching about 50 million people. By 2006, 69.2% of the U.S. population on public water systems were receiving fluoridated water, amounting to 61.5% of the total U.S. population. Near the end of 2012, 67.1% of the U.S. population were getting water from community water systems (CWS) supplying water that had fluoride at or above recommended levels. Those included the 3.5% of the population that were on CWS with naturally occurring fluoride at or above recommended levels. 74.6% of those on CWS were receiving water with fluoride at or above recommended levels.\n\nU.S. regulations for bottled water do not require disclosing fluoride content. A survey of bottled water in Cleveland and in Iowa, published in 2000, found that most had fluoride levels well below the 1 mg/L level common in tap waters.\n\nCommunity water fluoridation in the United States is partly due to the research of Dr. Frederick McKay, who pressed the dental community for an investigation into what was then known as \"Colorado Brown Stain.\" The condition, now known as dental fluorosis, when in its severe form is characterized by cracking and pitting of the teeth. Of 2,945 children examined in 1909 by Dr. McKay, 87.5% had some degree of stain or mottling. All the affected children were from the Pikes Peak region. Despite the negative impact on the physical appearance of their teeth, the children with stained, mottled and pitted teeth also had fewer cavities than other children. McKay brought this to the attention of Greene Vardiman Black, and Black's interest was followed by greater interest within the dental profession.\n\nInitial hypotheses for the staining included poor nutrition, overconsumption of pork or milk, radium exposure, childhood diseases, or a calcium deficiency in the local drinking water. In 1931, researchers from the Aluminum Company of America (ALCOA) concluded that the cause of the Colorado stain was a high concentration of fluoride ions in the region's drinking water (ranging from 2 to 13.7 mg/L) and areas with lower concentrations had no staining (1 mg/L or less). Pikes Peak's rock formations contained the mineral cryolite, one of whose constituents is fluorine. As the rain and snow fell, the resulting runoff water dissolved fluoride which made its way into the water supply.\n\nDental and aluminum researchers then moved toward determining a relatively safe level of fluoride to be added to water supplies. The research had two goals: (1) to warn communities with a high concentration of fluoride of the danger, initiating a reduction of the fluoride levels in order to reduce incidences of fluorosis, and (2) to encourage communities with a low concentration of fluoride in drinking water to add fluoride in order to help prevent tooth decay. By 2006, 69.2% of the U.S. population on public water systems were receiving fluoridated water, amounting to 61.5% of the total U.S. population; 3.0% of the population on public water systems were receiving naturally occurring fluoride.\n\nIn April 2015, fluoride levels in the United States were lowered for the first time in 50 years, to the minimum recommended levels of 0.7ppm, because too much fluoride exposure has become a common issue for children teeth, visible in the form of white splotches. The basis were the results of two national surveys (1999–2004 NHANES) which assessed the prevalence of dental fluorosis, and found that two out of five adolescents had tooth streaking or spottiness on their teeth - an increase of mostly very mild or mild forms.\n\nA study of varying amounts of fluoride in water was led by Dr. H. Trendley Dean, a dental officer of the U.S. Public Health Service. In 1936 and 1937, Dr. Dean and other dentists compared statistics from Amarillo, which had 2.8 – 3.9 mg/L fluoride content, and low fluoride Wichita Falls. The data is alleged to show fewer cavities in Amarillo children, but the studies were never published. Dr. Dean's research on the fluoride-dental caries relationship, published in 1942, included 7,000 children from 21 cities in Colorado, Illinois, Indiana, and Ohio. The study concluded that the optimal amount of fluoride which minimized the risk of severe fluorosis but had positive benefits for tooth decay was 1 mg per day, per adult. Although fluoride is more abundant in the environment today, this was estimated to correlate with the concentration of 1 mg/L.\n\nIn 1937, dentists Henry Klein and Carroll E. Palmer had considered the possibility of fluoridation to prevent cavities after their evaluation of data gathered by a Public Health Service team at dental examinations of Native American children. In a series of papers published afterwards (1937–1941), yet disregarded by his colleagues within the U.S.P.H.S., Klein summarized his findings on tooth development in children and related problems in epidemiological investigations on caries prevalence.\n\nIn 1939, Dr. Gerald J. Cox conducted laboratory tests using rats that were fed aluminum and fluoride. Dr. Cox suggested adding fluoride to drinking water (or other media such as milk or bottled water) in order to improve oral health.\n\nIn the mid-1940s, four widely cited studies were conducted. The researchers investigated cities that had both fluoridated and unfluoridated water. The first pair was Muskegon, Michigan and Grand Rapids, Michigan, making Grand Rapids the first community in the world to add fluoride to its drinking water to try to benefit dental health on January 25, 1945. Kingston, New York was paired with Newburgh, New York. Oak Park, Illinois was paired with Evanston, Illinois. Sarnia, Ontario was paired with Brantford, Ontario, Canada.\nIn 1952 Nebraska Representative A.L. Miller complained that there had been no studies carried out to assess the potential adverse health risk to senior citizens, pregnant women, or people with chronic diseases from exposure to the fluoridation. A decrease in the incidence of tooth decay was found in some of the cities which had added fluoride to water supplies. The early comparison studies would later be criticized as, \"primitive,\" with a, \"virtual absence of quantitative, statistical methods...nonrandom method of selecting data and...high sensitivity of the results to the way in which the study populations were grouped...\" in the journal \"Nature\".\n\nAs of May 2000, 42 of the 50 largest U.S. cities had water fluoridation. According to a 2002 study, 67% of U.S. residents were living in communities with fluoridated water at that time.\n\nThe U.S. Centers for Disease Control has identified community water fluoridation as one of ten great public health achievements of the 20th century. The CDC recommends water fluoridation at a level of 0.7–1.2 mg/L, depending on climate. The CDC also advises parents to monitor use of fluoride toothpaste, and use of water with fluoride concentrations above 2 mg/L, in children up to age 8. There is a CDC database for researching the water fluoridation status of neighborhood water.\n\nIn 1998, 70% of people polled in a survey conducted by the American Dental Association (ADA) believed community water should be fluoridated, with 18% disagreeing and the rest undecided. In November 2006, the ADA began recommending to parents that infants from 0 through 12 months of age should have their formula prepared with water that is fluoride-free or contains low levels of fluoride to reduce the risk of fluorosis.\n\nThe issue of whether or not to fluoridate water supplies frequently arises in local governments. For example, on November 8, 2005, citizens of Mt. Pleasant, Michigan voted 63% to 37% in favor of reinstating fluoridation in public drinking water after a 2004 ballot initiative ceased water fluoridation in the city. At the same time, voters in Xenia, Ohio; Springfield, Ohio; Bellingham, Washington; and Tooele City, Utah all rejected water fluoridation.\n\nIn Skagit County in the state of Washington, the county commissioners in 2007 voted 2 to 1 to order the local public utility district to begin fluoridating the public water supply by Jan. 2009. $1.2 million was to be provided by the privately funded Washington Dental Service Foundation to begin building the equipment needed to add fluoride to the Judy Reservoir, which supplies the majority of Skagit Valley's water customers. The source and type of fluoride to be added to the drinking water of more than 70,000 citizens had not been disclosed. However, in February 2009, Skagit County commissioners rescinded the 2007 order, citing costs and possible lawsuits.\n\nThe cost of adding fluoridation to the water of 44 Florida communities has been researched by the State Health Office in Tallahassee. In communities with a population of over 50,000 people, fluoridation costs were estimated at 31 cents per person per year. The estimated cost rises to $2.12 per person in areas with a population below 10,000. Unintended consequences, such as equipment malfunction, can substantially raise the financial burden, as well as the health risks, to the consumer.\n\nIn the U.S., Hispanic and Latino Americans are significantly more likely to consume bottled instead of tap water, and the use of bottled and filtered water grew dramatically in the late 1990s and early 2000s.\n\nMany political and popular entities and activities determine whether fluoride is added to water supplies. Those include courts, local governments, popular referenda, and water authorities.\n\nFluoridation has been the subject of many court cases wherein activists have sued municipalities, asserting that their rights to consent to medical treatment and due process are infringed by mandatory water fluoridation. Individuals have sued municipalities for a number of illnesses that they believe were caused by fluoridation of the city's water supply. In most of these cases, the courts have held in favor of cities, finding no or only a tenuous connection between health problems and widespread water fluoridation. To date, no federal appellate court or state court of last resort (i.e., state supreme court) has found water fluoridation to be unlawful.\n\nA flurry of cases were heard in numerous state courts across the U.S. in the 1950s during the early years of water fluoridation. State courts consistently held in favor of allowing fluoridation to continue, analogizing fluoridation to mandatory vaccination and the use of other chemicals to clean the public water supply, both of which had a long-standing history of acceptance by courts.\n\nIn 1952, a Federal Regulation was adopted that stated in part, \"The Federal Security Agency will regard water supplies containing fluorine, within the limitations recommended\nby the Public Health Service, as not actionable under the Federal Food, Drug, and Cosmetic Act.\" \n\nThe Supreme Court of Oklahoma analogized water fluoridation to mandatory vaccination in a 1954 case. The court noted, \"we think the weight of well-reasoned modern precedent sustains the right of municipalities to adopt such reasonable and undiscriminating measures to improve their water supplies as are necessary to protect and improve the public health, even though no epidemic is imminent and no contagious disease or virus is directly involved ... To us it seems ridiculous and of no consequence in considering the public health phase of the case that the substance to be added to the water may be classed as a mineral rather than a drug, antiseptic or germ killer; just as it is of little, if any, consequence whether fluoridation accomplishes its beneficial result to the public health by killing germs in the water, or by hardening the teeth or building up immunity in them to the bacteria that causes caries or tooth decay. If the latter, there can be no distinction on principle between it and compulsory vaccination or inoculation, which, for many years, has been well-established as a valid exercise of police power.\"\n\nIn the 1955 case \"Froncek v. City of Milwaukee\", the Wisconsin Supreme Court affirmed the ruling of a circuit court which held that \"the fluoridation is not the practice of medicine, dentistry, or pharmacy, by the City\" and that \"the legislation is a public health measure, bearing a real, substantial, and reasonable relation to the health of the city.\"\n\nThe Supreme Court of Ohio, in 1955's \"Kraus v. City of Cleveland\", said, \"Plaintiff's argument that fluoridation constitutes mass medication, the unlawful practice of medicine and adulteration may be answered as a whole. Clearly, the addition of fluorides to the water supply does not violate such principles any more than the chlorination of water, which has been held valid many times.\"\n\nIn 1973, as cases continued to be brought in state courts, a consensus developed that fluoridation, at least from a legal standpoint, was acceptable. In 1973's \"Beck v. City Council of Beverly Hills\", the California Court of Appeal, Second District, said, \"Courts through the United States have uniformly held that fluoridation of water is a reasonable and proper exercise of the police power in the interest of public health. The matter is no longer an open question.\"\n\nMuch of the contemporary debate on water fluoridation revolves around questions of how consumer demand for fluoride is determined and processed, which fluoridation costs and benefits are considered, how conflicts over its provision and production are addressed or resolved, and how the merits of relevant health policies can be equally recast in terms of their presumed demerits.\nAdvocates continue to make contemporary challenges to the spread of fluoridation. For instance, in 2002, the city of Watsonville, California, chose to disregard a California law mandating fluoridation of water systems with 10,000 or more hookups, and the dispute between the city and the state ended up in court. The trial court and the intermediate appellate court ruled in favor of the state and its fluoridation mandate, and the Supreme Court of California declined to hear the case in February 2006. Since 2000, courts in Washington, Maryland, and Texas have reached similar conclusions.\n\nSan Diego, California began water fluoridation in February 2011, despite its Municipal Code Section 67.0101, which prohibits the city from fluoridating. The local ordinance was preempted by California law that requires fluoridation when an outside funding source is available. In 2008, First 5 Commission of San Diego County, a state-funded child advocacy organization, provided nearly $4 million to San Diego, for fluoridation equipment and operating costs for the first two years of fluoridation. That organization is funded with tobacco taxes instituted by California Proposition 10 (1998). San Diego raises the fluoride level of its water to 0.7 mg/L, as recommended by CDC.\n\nIn 2012, New Hampshire began requiring public water systems that fluoridate to post the following notice in their consumer confidence reports: \"Your public water supply is fluoridated. According to the Centers for Disease Control and Prevention, if your child under the age of 6 months is exclusively consuming infant formula reconstituted with fluoridated water, there may be an increased chance of dental fluorosis. Consult your child's health care provider for more information.\" The law was passed with overwhelming majorities in the legislature and took effect August 4.\n\nOn September 22, 2011, The city council of College Station, Texas voted, 6–1, against fluoridating city water supplies. ending 22 years of fluoridation.\n\nIn 2011 the Pinellas County, Florida commissioners voted to stop adding fluoride to the county's public drinking water. \"Tampa Bay Times\" editor Tim Nickens and columnist Daniel Ruth then published a joint series of ten editorials challenging the decision in 2012, and two of the commissioners who had voted to stop fluoridation were voted out of office and replaced with candidates who had pledged to add it back. In March 2013, after a 6–1 vote, the county resumed the addition of fluoride, which the \"Times\" characterized as being \"long considered the most effective method to prevent tooth decay\". Nickens and Ruth were awarded the 2013 Pulitzer Prize for Editorial Writing for their series.\n\nThe Board of County Commissioners of Hernando County, Florida voted, 4–1, on February 25, 2014 not to begin fluoridating the county's water.\n\nOn May 21, 2013, voters in Portland, Oregon decided 61–39% not to commence fluoridation of Portland's water, which is supplied to 900,000 people. It was the fourth defeat of fluoridation proposals in Portland, the first being in 1956. On September 12, 2012, the Portland City Council unanimously passed Ordinance No. 185612, authorizing and directing the Portland Water Bureau to begin fluoridating. Those opposing the ordinance immediately began a petition process to hold a referendum that could reverse the ordinance. In October, it was revealed that four city council members had had undisclosed meetings with pro-fluoridation lobbyists. Public calendars of those four did not mention the meetings, except that one meeting was mentioned with a vague title. This was in violation of a city ordinance requiring the disclosure of such meetings. Over 33,000 signatures were gathered for the petition, which led to the referendum that defeated fluoridation. In the campaign, the pro-fluoridation side out-raised opponents $850,000 to $270,000.\n\n\n"}
{"id": "3244102", "url": "https://en.wikipedia.org/wiki?curid=3244102", "title": "Watermaker", "text": "Watermaker\n\nA watermaker is a device used to obtain potable water by reverse osmosis of seawater. In boating and yachting circles, desalinators are often referred to as \"watermakers\".\n\nMany versions are used by long-distance ocean cruisers. The devices can be expensive to buy and maintain, but are a huge advantage because of the reduced need to have large water tanks for a long passage. \n\nDepending on the design, watermakers can be powered by electricity from the battery bank, an engine, an AC generator or hand operated. There is a portable, towed, water-powered watermaker available which converts to hand operation in an emergency.\n\nThere is great variation in the amount of water consumed.\n\nAt home in the United States, each person uses about 55 gallons (208 liters) of water per day on average. Where supplies are limited, and in emergencies, much less may be used.\n\nTypical cruising yachts use from 4 to 20 litres (1.05 to 5.28 gallons) per person per day, the average probably being about 6 litres (1.59 gallons). The minimum water intake required to maintain body hydration is 1.5 litres (0.4 gallons) per day. The maintenance of comfort under normal circumstances requires 3% of mass body weight or typically about 2.3 litres (0.61 gallons) per person of drinking water per day.\n\nPopular brands of yacht watermakers typically make from 2 to 150 litres per hour of operation (0.53 to 41 gallons) depending on the model.\n\nThere are strong opinions among small boat cruisers about the usefulness of these devices. The arguments may be summarised as:\n\n\n\nSome manufacturers of electrically powered watermakers have energy recovery systems in their design which reduce the power consumption; however, these are typically some 50% more expensive for any similar size due to their additional complexity. As a guideline, assuming a 12V DC system, the energy recovery incorporated in those watermakers have the effect of reducing the electric current used from perhaps typically 20A to about 8A. Like any piece of equipment, it is bound to fail at some time and cause expense/anxiety.\n\nAll watermakers designed for small boats and yachts rely on essentially the same technology, exploiting the principle of \"reverse osmosis\": a high pressure pump forcing seawater through a membrane that allows water but not salt to pass.\n\nThe common comparison is that of a filter; however, as the holes in the membrane are smaller than molecules of sodium chloride (salt) and indeed smaller than bacteria, and pressures in the nature of 45-50 bar are required, the process is much more complex than the common water filter or the oil filter found in automobile engines.\n\nThe term watermaker may also refer to an atmospheric water generator, a machine that extracts potable water from the humidity in air using a refrigeration or a desiccant. Condensing moisture by refrigeration requires a minimum ambient temperature of about 10-15°C (50-60˚F), while desiccant adsorbers have no such restriction. Either method is suitable for a desert climate, where water production is dependent on ambient humidity. The Negev desert in Israel, for example, has a significant average relative humidity of 64%.\n\nContrary to some online sources, a 1922 article in \"Popular Science\" cites an average relative humidity of 30% for the Sahara Desert, about half the humidity in an air-conditioned home. Moreover, the effect of the dew point causes early mornings to have higher humidity, so that atmospheric water generation is possible even in the harshest climates.\n"}
{"id": "52987989", "url": "https://en.wikipedia.org/wiki?curid=52987989", "title": "Women's Health Protective Association", "text": "Women's Health Protective Association\n\nWomen's Health Protective Association (sometimes, Woman's Health Protective Association; original parent body, Ladies' Health Protective Association) was a US women's organization focused on improving a city's public health and protecting the immediate neighborhood. It was founded in New York City in November 1884 as the Ladies' Health Protective Association. \n\nThe impetus for the association occurred when a few women were annoyed by a nuisance maintained in the immediate neighborhood of their homes. They assembled in the parlor of one of the women to talk over the situation and devise some plan of concerted effort that could be brought to bear upon the New York City Metropolitan Board of Health to induce it to abate this nuisance. The result led to the formation of \"The Ladies' Health Protective Association.\" It commanded public attention because its work was public and for the public. The meetings became important enough to have reporters assigned from the daily papers attend them, and reports appeared. \n\nAssociations were formed in other cities on the same general principles. The newer associations substituted the word \"woman,\" or \"women,\" for \" ladies,\" although the original charter granted by New York State was to \"The Ladies' Health Protective Association.\" By 1895, the parent body decided, in view of the prejudices against the use of the word \"lady\", to change its name to The Woman's Health Protective Association.\n\nIn November, 1884, eleven women residing on Beekman Hill, whose houses were located on a high bluff overlooking the East River, were so outraged at the continuance of the foul odors which polluted the atmosphere of the entire neighborhood, causing them to keep windows closed in the hottest weather, and depriving them of their right to pure air, that they resolved to investigate the cause of this nuisance. Accordingly, they made a tour of the neighborhood, in that section of the city known as the abattoir district, which extends on First Avenue from Forty-third Street to 47th Street. Their first visit was a revelation, and while they returned to their homes ill from the inspection and the discovery of the nuisance, they decided that some action must be taken to better the conditions. The following morning their number was increased to fifteen, and it was resolved that these women should form themselves into an organization, to be known as the Ladies' Health Protective Association.\n\nThey found that relief would require more than protests, and probably a struggle of some months, at least, with official greed and public indifference. For efficiency, they formed an association afterwards christened “The Ladies Health Protective Association of New York”. Only after ten years of persistent effort was their original purpose accomplished. In the meantime, however, they accomplished other things no less important. They demonstrated woman's power and fitness to cope with these questions. They formed committees to investigate the water supply, gas houses, school hygiene, street cleaning, garbage disposal, sewer system, sanitation of prisons and tenements, and in several instances influenced the legislature to pass sanitary laws. The group's first convention occurred May 14-15, 1896 at the New York Academy of Medicine.\n\nA marble stele and drinking fountain, designed by Bruno Louis Zimm were placed at Riverside Drive and 116th Street in 1909 to commemorate the 25th anniversary of the organization.<ref name=\"nycgovparks.org/\"></ref>\n\nThe Brooklyn association was organized in March, 1890, and incorporated April 2,1890, with a voluntary secretary. Annual dues of US$1 supported the society. There 25 members of the board of directors, with an executive committee of seven, meeting once a month. The departments of work were: municipal, legal, lecture, press, and house. The Association had no organ of its own, but came in touch with its workers, who could attend the monthly meetings of the board of directors. The society was non-partisan and had neighborhood or branch associations in election districts. \n\nSome of its accomplishments were: cleaner streets, because of boxes for waste placed on the street-corners; cleaner cars, due to placards prohibiting spitting on the floor; increased interest in the cleanliness and health of the city on the part of the women; and the initial movement resulting in the overthrow of the ring rule in 1893. In 1893, they played an important role in the election of Hon. Charles A. Schieren for mayor.\n\nThe Association originated in the thought of its president, who desired to see Brooklyn made a cleaner and more attractive city, through a more patriotic interest on the part of the women. A meeting was called to consider to what extent women are responsible for the condition of the streets, and that conference led to the organization of the Women's Health Protective Association of Brooklyn, somewhat on the lines of the older Association of the same name in New York. It grew steadily in four years, numbering 450 paying members, while a much larger number were actively engaged in extending its influence and carrying out its principles. In 1896, there were 1,000 members with five local branches.\n\nThe Woman's Health Protective Association of Philadelphia organized in 1893 as a committee of the New Century Club. This association seems to have established its work on a broader and more comprehensive basis and extended its influence along longer lines than others. \n\nThe first committee to get to work was that on contagious diseases, whose activities included the endorsement of a bill in the state legislature providing for inspection of all cattle farms in the state, with reference to their sanitary condition and the prevention of tuberculosis; also, the establishment of a pay hospital for contagious diseases. The street cleaning and garbage committee personally visited the slum districts every week. Other committees included water supply and a sweating system. A trolley committee urged the importance to public health of running more cars, to avoid overcrowding, of vestibules for protection of motormen, the adopting of fenders, longer straps to accommodate women and children, and conspicuous signs forbidding expectoration. A literature committee studied the literature of the day for all matters pertaining to sanitary subjects.\n\nA national convention was held in Philadelphia May 3, 1897, with delegates from forty clubs and societies, the majority representing health protective or village improvement associations. The Woman's Health Protective Association of the United States was formed, with Olive Pond Amies as president.\n\n\n"}
{"id": "37066329", "url": "https://en.wikipedia.org/wiki?curid=37066329", "title": "Yellow flag (contagion)", "text": "Yellow flag (contagion)\n\nIn International maritime signal flags, plain yellow, green, and even black flags have been used to symbolize disease in both ships and ports, with the color yellow having a longer historical precedent, as a color of marking for houses of infection, previous to its use as a maritime marking color for disease.\n\nThe present flag used for the purpose is the \"Lima\" (L) flag, which is a mixture of yellow and black flags previously used. It is sometimes called the \"yellow jack\", which became a name for yellow fever. Cholera ships also used a yellow flag.\n\nThe plain yellow flag (\"Quebec\" or Q in international maritime signal flags), perhaps derives its letter symbol for its initial use in quarantine, but this flag in modern times indicates the opposite—a ship that declares itself free of quarantinable disease, and requests boarding and inspection by Port State Control to allow the grant of \"free pratique\".\n\nPlain yellow flags are still commonly used to mark a recent death in a neighborhood in cities such as Jakarta, regardless of the cause. They are placed in intersections leading to the home of the recently deceased as direction markers for mourners, and to mark the funeral convoy so that it is given the right of way.\n\n"}
