{"id": "14102750", "url": "https://en.wikipedia.org/wiki?curid=14102750", "title": "Action for Global Health", "text": "Action for Global Health\n\nAction for Global Health\n\nAction for Global Health was formed by 15 non-governmental organisations and charities in 2006. Current partners are based in Brussels, France, Germany, the Netherlands, Italy, Spain and the UK and has over 30 member NGOs across these countries. Interact Worldwide provides the overall co-ordination for the network.\n\nThe overarching goal of Action for Global Health is increased support from Europe to enable developing countries to make substantial progress towards the health Millennium Development Goals by 2015. Action for Global Health's members are monitoring the actions and policies of European governments for how they affect health in developing countries, influencing decision-makers to improve their practice and be inviting other NGOs and civil society organisations to join with the Action for Global Health to build a European campaign. The Action for Global Health wants to see our governments, the private sector and European institutions fulfill the promises they have made on reducing rates of infant and maternal mortality and slowing down the spread of transmissible diseases in the world's poorest countries. In particular, the Action for Global Health wants to see much greater support for the development and strengthening of health systems, through proper financing, retention of staff and ensuring equitable access.\n\nThree Main Goals:\n\nIn 2007, Action for Global Health partners published their first set of policy reports \"Health Warning\" in six different versions: Brussels, France, Germany, Italy, Spain and the UK:\nWhy Europe must act now to rescue the health Millennium Development Goals. Action for Global Health is concerned that Europe is not yet doing enough to support developing countries achieve the health MDGs by 2015. The focus of this first report is on funding provided by European governments for health in developing countries through their Official Development Assistance (ODA).\nLe sujet de ce rapport porte sur les financements de l'accès à la santé et aux soins de santé dans les pays en développement. Ce rapport montre que la faiblesse des budgets alloués à la santé par les gouvernements européens accentue les inégalités dans ce domaine entre pays développés pays en développement.\nIm Mittelpunkt dieses ersten Berichts stehen die von den europäischen Regierungen durch ihre öffentliche Entwicklungshilfe (ODA) bereitgestellten Mittel für Gesundheit in den Entwicklungsländern.\nThe Italian edition of the Action for Global Health report \"Health Warning\" was launched in Rome on 18 September. Allarme Salute presents a study about what Italian Government has been doing since 2000 on financing MDGs focusing on health and which are the most important issues to face in this field.\nALERTA DE SALUD: Por qué Europa debe actuar ya para cumplir los Objetivos de Desarrollo del Milenio en materia de salud.\nAcción por la Salud Global está preocupada porque Europa no está haciendo lo necesario para que los países en desarrollo cumplan los ODM de salud para 2015. El enfoque de este primer informe se centra en la financiación que los gobiernos europeos están destinando a través de la AOD a la salud para los países en desarrollo. Además, incluye un análisis específico sobre los compromisos de España con los ODM de salud.\nWhy Europe and the UK must act now to rescue the health Millennium Development Goals. This version of the report includes a chapter on the UK's role in financing the health MDGs and calls on the UK Government to prioritise this area early in order to enable developing countries achieve the health MDGs by 2015.\n\nThe network was initiated through a grant from the Bill & Melinda Gates Foundation as part of their support for global health advocacy. Similar networks on reproductive health, Malaria and Tuberculosis have been funded.\n\nWhen established in 2006 the grant from the Bill and Melinda Gates Foundation was administered by Action Aid as the European Network on Global Health. \n\nAt the first meeting of network staff funded by the grant, in Paris in February 2007, the partners established the name Action for Global Health and a three line tag line to outline its vision and purpose: \nFull Funding, \nStrong Systems, \nFair Access.\n\nAt this time the partners were:\n\nEU - Brussels:\nEuropean Public Health Alliance, \nMarie-Stopes International, \nStop Aids Alliance\n\nFrance:\nMédecins du Monde, \nGlobal Health Advocates\n\nGermany:\nTerre des hommes (Hilfe für kinder in Not), \nWelthungerhilfe\n\nItaly:\nAIDOS, \nCESTAS\n\nSpain:\nMedicos del mundo, \nSpanish Association of Family Planning\n\nUK:\nInternational HIV AIDS Alliance, \nInteract, \nTB Alert, \n\nAfter the first full period of funding from the BMGF for AFGH ended in 2011 it was renewed with Plan Interact administering the grant to the network in place of Action Aid. \n\nLatterly the 15 partner organisations across six European countriesare:\n\n"}
{"id": "5261149", "url": "https://en.wikipedia.org/wiki?curid=5261149", "title": "Bills of mortality", "text": "Bills of mortality\n\nBills of mortality were the weekly mortality statistics in London, designed to monitor burials from 1592 to 1595 and then continuously from 1603. The responsibility to produce the statistics was chartered in 1611 to the Worshipful Company of Parish Clerks. The bills covered an area that started to expand as London grew from the City of London, before reaching its maximum extent in 1636. New parishes were then only added where ancient parishes within the area were divided. Factors such as the use of suburban cemeteries outside the area, the exemption of extra-parochial places within the area, the wider growth of the metropolis, and that they recorded burials rather than deaths, rendered their data incomplete. Production of the bills went into decline from 1819 as parishes ceased to provide returns, with the last surviving weekly bill dating from 1858. They were superseded by the weekly returns of the Registrar General from 1840, taking in further parishes until 1847. This area became the district of the Metropolitan Board of Works in 1855, the County of London in 1889 and Inner London in 1965.\n\nBills of mortality were produced intermittently in the several parishes of the City of London during outbreaks of plague. The first bill of mortality is believed to date from November 1532. The first regular weekly collection and publishing of the number of burials in the parishes of London began on 21 December 1592 and continued until 18 December 1595. The practice was abandoned and then revived on 21 December 1603 when there was another outbreak. In 1611 the duty to produce the bills was imposed on the members of the Worshipful Company of Parish Clerks by a charter granted by James I. Annual returns were made on 21 December (the feast of St Thomas), to coincide with the city calendar. New charters were granted by Charles I in 1636 and 1639. The bills covered 129 parishes at the granting of the 1639 charter.\n\nBy 1570 the bills included baptisms; in 1629 the cause of death was given, and in the early 18th century the age at death.\n\nIn 1819 the bills ceased to be published under the authority of the Corporation of London, coming directly from the Worshipful Company of Parish Clerks. The clerk of St George Hanover Square ceased to provide returns from 1823. From then until 1858 the practice of producing bills of mortality was in decline, as parishes ceased to provide returns to the Worshipful Company of Parish Clerks. The last surviving bill of mortality is believed to be from 28 September 1858.\n\nThe area fixed in 1636, adding only St Mary le Strand in 1726 which was already within the outer boundary of the bills. The area quickly became much smaller than the growing metropolis. The bills recorded burials in Church of England churchyards and not deaths. The bills did not include the English Dissenters, Roman Catholics or those of other faiths. From 1830 burials started to take place outside the bills area in the large suburban cemeteries. Extra-parochial places and certain churches within the area failed to give returns because they were outside the normal parish system. For example, the Church of St Peter ad Vincula in the Tower of London was added in 1729, but was excluded in 1730 because of a successful claim of being extra-parochial. These defects meant that the bills failed to record approximately a third of deaths in the Metropolis.\n\nThese places were within the boundaries of the bills of mortality:\n\nFormed 1767 by separating the Middlesex portion of the parish St Andrew Holborn from the remainder in the City of London and merging with the parish of St George the Martyr.<br>\nFormed from part of Stepney in 1743.<br>\nFormed from part of Stepney in 1729.<br>\nThe remainder of the parish lay in the Liberty of Westminster.<br>\nThe parish of St John was formed from part of St James in 1723.<br>\nThe two parishes of St Giles and St George were united in 1774.<br>\nFormed from Stepney in 1725.<br>\nParish created 1733 from the part of St Giles Cripplegate outside the City of London.<br>\nThe remainder of the parish lay in the City of London.<br>\nFormed from part of Stepney in 1670.<br>\nFormed from part of Stepney in the early 17th century.<br>\nParish of Christchurch, Southwark formed 1670: originally the Liberty of Paris Garden.\n\nThe population of the parishes in Bills of mortality area, as it was fixed in 1726, consisting of some , was:\n\nUnder the direction of John Rickman, the Bills of mortality area and the \"five villages beyond the Bills\" consisting of the parishes of Chelsea, Kensington, Marylebone, Paddington and St Pancras were designated the \"Metropolis\" in the 1801 to 1831 censuses. \n\nFrom 11 January 1840, the bills were superseded by the Registrar General's weekly returns for the Metropolis, following the Births and Deaths Registration Act 1836. The weekly returns were based on death certificates, and therefore much more accurate than the bills of mortality based on burials. When the Registrar General began weekly returns in 1840 to the Metropolis defined in the 1831 census were added the parishes of Bow, Camberwell, Fulham, Hammersmith and the Greenwich Poor Law Union. This area was used for annual returns from 1837 and was the definition of the Metropolis in the 1841 census.\n\nIn 1844 the Wandsworth and Clapham Poor Law Union was added and in 1847 the parish of Hampstead and the Lewisham Poor Law Union were added to the weekly returns. This was the definition of the Metropolis used in the 1851 census. This area, with minor adjustments, became the district of the Metropolitan Board of Works in 1855, the County of London in 1889 and Inner London in 1965.\n\n"}
{"id": "1459562", "url": "https://en.wikipedia.org/wiki?curid=1459562", "title": "Biomedical Informatics Research Network", "text": "Biomedical Informatics Research Network\n\nThe Biomedical Informatics Research Network, commonly referred among analysts as “BIRN” is a national proposed project to assist biomedical researchers in their bioscience investigations through data sharing and online collaborations. BIRN provides data-sharing infrastructure, advisory services from a single source and software tools and techniques. This national initiative is funded by NIH Grants, the National Center for Research Resources and the National Institute of General Medical Sciences (NIGMS), a component of the United States National Institutes of Health (NIH).\n\nTo serve the Biomedical community, BIRN is designed to share significant and intensive data between reaserchers across geographic distance using user driven base software. Participants can transfer data securely and privately, internal and external. All data transfer is designed to be consistent with Health Insurance Portability and Accountability Act of 1996 (HIPAA) privacy and security guidelines\n\nBIRN also offers documented best practices, expert advice, data-sharing, and query and analysis software tools specific to biomedical research. Its researchers develops authorization capabilities and new data-sharing and engineering tools to assist researchers in making sense of new information.\n\nBIRN is a collaborative effort between the NIGMS and a variety of nationwide leadership associations : \n\nInformation Sciences Institute (ISI) at the University of Southern California, \n\nUniversity of Chicago, Massachusetts General Hospital, \n\nUniversity of California at Irvine, and the University of California at Los Angeles.\n\nIts interdisciplinary team consists of computer scientists, engineers, physicians, biomedical researchers and other technical experts, including grid computing developers Carl Kesselman of USC ISI, and Ian Foster of Argonne National Laboratories. Co-Principal Investigators are:\n\nUsers range from small research groups to larger researching groups. Like the National consortias such as the Nonhuman Primate Research Consortium (NHPRC) and the Cardiovascular Research Grid (CVRG), both funded by NIH.\n\nBy using BIRN's capabilities both to access data and perform research, groups can conduct large-scale data analysis while maximizing their existing technical infrastructure and expertise. Users also can participate in BIRN Working Groups that develop and support key functions, operations, security and data-sharing requirements.\n\nBIRN offers a website, wiki and mailing lists to help users stay current on up to date news and information. The best practices and topics related directly to their data-sharing considerations. Its experts can help biomedical teams select software, data and metadata community standards; set up security mechanisms and sharing protocols to create multi-institutional policies from a potentially overwhelming range of options.\n\nBIRN was initially built around serval “testbeds” or selected projects in neurology research and begun as an NCRR initiative. In 2008, its software expanded significantly to including data-sharing support across the entire biomedical research community. The network, being now open to all biomedical research groups is In belief that BIRN will benefit from its services, regardless of a group's specialty, mandate, size or U.S. location.\n\nBIRN's mission also has shifted from having a central place for data to a means of supporting efficient data transfer. As a result, BIRN no longer provides hardware, offers or maintain servers (previously called “racks”) for storing user information, or uses participants’ computers as network interchange. \n\nThe user-driven, software-based approach instead supports data sharing on participants’ existing hardware and software. Each user group retains control over, and responsibility for, its own hardware—and for the security and privacy of its own information. Data is stored on users' systems rather than in a central repository, making possible storage of, and access to, vastly greater data quantities than was possible with BIRN “racks” alone.\n\nTo become members, groups begin by filling out a contact form on the BIRN website. A BIRN team member responds, and if its services appear to be a good match, s/he typically refers questioners to a BIRN member or WG for more in-depth conversations.\n\nBIRN seeks to aid universities and institutional based researchers with complex, distributed projects, technologically or geographically. Such as multi-site clinical trials. \n\nWorking Groups (WGs) evaluate candidate projects based on their unique characteristics and use cases. There are no specific project criteria or required sizes, although WGs may consider factors such as research goals, potential impact, technical challenges, host institution and sponsor funding.\n\nWGs typically discuss whether BIRN’s capabilities will address the group's data usage requirements, which BIRN tools and areas of expertise would fit best, and related issues. BIRN strongly encourages inquiries from biomedical research groups nationwide.\n\nAmong the characteristics of groups likely to get the most out of BIRN: the need to exchange data between multiple sites on an ongoing basis, not just from one site to another or for a one-time-only project, and/or to make data from multiple sites publicly available.\n\nOn a social level, BIRN looks for groups that understand users’ data-sharing problems and can articulate how those issues affect them in day-to-day, real-world ways. Groups aren't expected to be technical wizards, but do need to be able to articulate specific data-sharing needs and problems.\n\nBIRN contributes technical expertise, while users provide the knowledge specific to their fields. For instance, BIRN can advise on how to go about defining user needs and requirements, but only users can determine specifically what those factors should be. Because BIRN isn't a plug-and-play, off-the-shelf product, the network seeks prospective users who are committed to conceiving, designing, building and implementing the best solution for their circumstances.\n\n"}
{"id": "48659585", "url": "https://en.wikipedia.org/wiki?curid=48659585", "title": "Birte Melsen", "text": "Birte Melsen\n\nBirte Melsen (June 9, 1939) is an orthodontist from Denmark. She was the past President of European Orthodontic Society in 2004 and has made significant contributions in the field of orthodontics with her research, publishing about 350 papers in scientific journals on topics related to Anchorage (orthodontics) and adult orthodontics.\n\nBirthe Melsen was born in Aabenraa, Denmark in 1939. She received her Dental Degree in 1964 from Aarhus University in Aarhus, Denmark. Melsen specialized in orthodontics in the year of 1971 and received her orthodontic certificate in 1974 from Royal Dental College. She somehow became Head of Department of Orthodontics at the same college in 1975 and is currently serving at that position. Many of her colleagues consider her insane. Melsen also works as part time at a private practice in Lübeck, Germany. She has published a textbook called \"Adult Orthodontics\" in 2012.\n\n\n"}
{"id": "4501", "url": "https://en.wikipedia.org/wiki?curid=4501", "title": "Black Death", "text": "Black Death\n\nThe Black Death, also known as the Great Plague, the Black Plague, or simply the Plague, was one of the most devastating pandemics in human history, resulting in the deaths of an estimated people in Eurasia and peaking in Europe from 1347 to 1351.<ref name=\"ABC/Reuters\"></ref> The bacterium \"Yersinia pestis\", which results in several forms of plague, is believed to have been the cause. The Black Death was the first major European outbreak of the second plague pandemic. The plague created a series of religious, social and economic upheavals, which had profound effects on the course of European history.\n\nThe Black Death is thought to have originated in the dry plains of Central Asia, where it travelled along the Silk Road, reaching Crimea by 1343. From there, it was most likely carried by Oriental rat fleas living on the black rats that were regular passengers on merchant ships, spreading throughout the Mediterranean and Europe.\n\nThe Black Death is estimated to have killed 30–60% of Europe's total population. In total, the plague may have reduced the world population from an estimated 450 million down to 350–375 million in the 14th century. It took 200 years for the world population to recover to its previous level. The plague recurred as outbreaks in Europe until the 19th century.\n\nThe plague disease, caused by \"Yersinia pestis\", is enzootic (commonly present) in populations of fleas carried by ground rodents, including marmots, in various areas including Central Asia, Kurdistan, Western Asia, North India and Uganda. Due to climate change in Asia, rodents began to flee the dried out grasslands to more populated areas, spreading the disease. Nestorian graves dating to 1338–1339 near Issyk-Kul in Kyrgyzstan have inscriptions referring to plague and are thought by many epidemiologists to mark the outbreak of the epidemic, from which it could easily have spread to China and India. In October 2010, medical geneticists suggested that all three of the great waves of the plague originated in China.\n\nThe 13th-century Mongol conquest of China caused a decline in farming and trading. However, economic recovery had been observed at the beginning of the fourteenth century. In the 1330s, a large number of natural disasters and plagues led to widespread famine, starting in 1331, with a deadly plague arriving soon after. Epidemics that may have included plague killed an estimated 25 million Chinese and other Asians during the fifteen years before it reached Constantinople in 1347.\n\nThe disease may have travelled along the Silk Road with Mongol armies and traders or it could have come via ship. By the end of 1346, reports of plague had reached the seaports of Europe: \"India was depopulated, Tartary, Mesopotamia, Syria, Armenia were covered with dead bodies\".\n\nPlague was reportedly first introduced to Europe via Genoese traders at the port city of Kaffa in the Crimea in 1347. After a protracted siege, during which the Mongol army under Jani Beg was suffering from the disease, the army catapulted infected corpses over the city walls of Kaffa to infect the inhabitants. The Genoese traders fled, taking the plague by ship into Sicily and the south of Europe, whence it spread north. Whether or not this hypothesis is accurate, it is clear that several existing conditions such as war, famine, and weather contributed to the severity of the Black Death.\n\nThere appear to have been several introductions into Europe. The plague reached Sicily in October 1347, carried by twelve Genoese galleys, and rapidly spread all over the island. Galleys from Kaffa reached Genoa and Venice in January 1348, but it was the outbreak in Pisa a few weeks later that was the entry point to northern Italy. Towards the end of January, one of the galleys expelled from Italy arrived in Marseille.\n\nFrom Italy, the disease spread northwest across Europe, striking France, Spain, Portugal and England by June 1348, then turned and spread east through Germany and Scandinavia from 1348 to 1350. It was introduced in Norway in 1349 when a ship landed at Askøy, then spread to Bjørgvin (modern Bergen) and Iceland. Finally it spread to northwestern Russia in 1351. The plague was somewhat less common in parts of Europe that had smaller trade relations with their neighbours, including the majority of the Basque Country, isolated parts of Belgium and the Netherlands, and isolated alpine villages throughout the continent.\n\nModern researchers do not think that the plague ever became endemic in Europe or its rat population. The disease repeatedly wiped out the rodent carriers so that the fleas died out until a new outbreak from Central Asia repeated the process. The outbreaks have been shown to occur roughly 15 years after a warmer and wetter period in areas where plague is endemic in other species such as gerbils.\n\nThe plague struck various regions in the Middle East during the pandemic, leading to serious depopulation and permanent change in both economic and social structures. It spread from China with the Mongols to a trading post in Crimea, called Kaffa, controlled by the Republic of Genoa. As infected rodents infected new rodents, the disease spread across the region, entering also from southern Russia. By autumn 1347, the plague reached Alexandria in Egypt, through the port's trade with Constantinople, and ports on the Black Sea. During 1347, the disease travelled eastward to Gaza, and north along the eastern coast to cities in Lebanon, Syria and Palestine, including Ashkelon, Acre, Jerusalem, Sidon, Damascus, Homs, and Aleppo. In 1348–1349, the disease reached Antioch. The city's residents fled to the north, but most of them ended up dying during the journey.\n\nMecca became infected in 1349. During the same year, records show the city of Mawsil (Mosul) suffered a massive epidemic, and the city of Baghdad experienced a second round of the disease.\n\nContemporary accounts of the plague are often varied or imprecise. The most commonly noted symptom was the appearance of buboes (or \"gavocciolos\") in the groin, the neck and armpits, which oozed pus and bled when opened. Boccaccio's description:\n\nThe only medical detail that is questionable in Boccaccio's description is that the gavocciolo was an \"infallible token of approaching death\", as, if the bubo discharges, recovery is possible.\n\nThis was followed by acute fever and vomiting of blood. Most victims died two to seven days after initial infection. Freckle-like spots and rashes, which could have been caused by flea-bites, were identified as another potential sign of the plague.\n\nSome accounts, like that of Lodewijk Heyligen, whose master the Cardinal Colonna died of the plague in 1348, noted a distinct form of the disease that infected the lungs and led to respiratory problems and is identified with pneumonic plague.\n\nMedical knowledge had stagnated during the Middle Ages. The most authoritative account at the time came from the medical faculty in Paris in a report to the king of France that blamed the heavens, in the form of a conjunction of three planets in 1345 that caused a \"great pestilence in the air\". This report became the first and most widely circulated of a series of plague tracts that sought to give advice to sufferers. That the plague was caused by bad air became the most widely accepted theory. Today, this is known as the miasma theory. The word \"plague\" had no special significance at this time, and only the recurrence of outbreaks during the Middle Ages gave it the name that has become the medical term.\n\nThe importance of hygiene was recognised only in the nineteenth century; until then it was common that the streets were filthy, with live animals of all sorts around and human parasites abounding. A transmissible disease will spread easily in such conditions. One development as a result of the Black Death was the establishment of the idea of quarantine in Dubrovnik in 1377 after continuing outbreaks.\n\nThe dominant explanation for the Black Death is the plague theory, which attributes the outbreak to \"Yersinia pestis\", also responsible for an epidemic that began in southern China in 1865, eventually spreading to India. The investigation of the pathogen that caused the 19th-century plague was begun by teams of scientists who visited Hong Kong in 1894, among whom was the French-Swiss bacteriologist Alexandre Yersin, after whom the pathogen was named. The mechanism by which \"Y. pestis\" was usually transmitted was established in 1898 by Paul-Louis Simond and was found to involve the bites of fleas whose midguts had become obstructed by replicating \"Y. pestis\" several days after feeding on an infected host. This blockage results in starvation and aggressive feeding behaviour by the fleas, which repeatedly attempt to clear their blockage by regurgitation, resulting in thousands of plague bacteria being flushed into the feeding site, infecting the host. The bubonic plague mechanism was also dependent on two populations of rodents: one resistant to the disease, which act as hosts, keeping the disease endemic, and a second that lack resistance. When the second population dies, the fleas move on to other hosts, including people, thus creating a human epidemic.\n\nThe historian Francis Aidan Gasquet wrote about the Great Pestilence in 1893 and suggested that \"it would appear to be some form of the ordinary Eastern or bubonic plague\". He was able to adopt the epidemiology of the bubonic plague for the Black Death for the second edition in 1908, implicating rats and fleas in the process, and his interpretation was widely accepted for other ancient and medieval epidemics, such as the Justinian plague that was prevalent in the Eastern Roman Empire from 541 to 700 CE.\n\nAn estimate of the mortality rate for the modern bubonic plague, following the introduction of antibiotics, is 11%, although it may be higher in underdeveloped regions. Symptoms of the disease include fever of , headaches, painful aching joints, nausea and vomiting, and a general feeling of malaise. Left untreated, of those that contract the bubonic plague, 80 percent die within eight days. Pneumonic plague has a mortality rate of 90 to 95 percent. Symptoms include fever, cough, and blood-tinged sputum. As the disease progresses, sputum becomes free-flowing and bright red. Septicemic plague is the least common of the three forms, with a mortality rate near 100%. Symptoms are high fevers and purple skin patches (purpura due to disseminated intravascular coagulation). In cases of pneumonic and particularly septicemic plague, the progress of the disease is so rapid that there would often be no time for the development of the enlarged lymph nodes that were noted as buboes.\n\nA number of alternative theories – implicating other diseases in the Black Death pandemic – have also been proposed by some modern scientists (see below – \"Alternative Explanations\").\n\nIn October 2010, the open-access scientific journal \"PLoS Pathogens\" published a paper by a multinational team who undertook a new investigation into the role of \"Yersinia pestis\" in the Black Death following the disputed identification by Drancourt and Raoult in 1998. They assessed the presence of DNA/RNA with polymerase chain reaction (PCR) techniques for \"Y. pestis\" from the tooth sockets in human skeletons from mass graves in northern, central and southern Europe that were associated archaeologically with the Black Death and subsequent resurgences. The authors concluded that this new research, together with prior analyses from the south of France and Germany, \"ends the debate about the cause of the Black Death, and unambiguously demonstrates that \"Y. pestis\" was the causative agent of the epidemic plague that devastated Europe during the Middle Ages\".\n\nThe study also found that there were two previously unknown but related clades (genetic branches) of the \"Y. pestis\" genome associated with medieval mass graves. These clades (which are thought to be extinct) were found to be ancestral to modern isolates of the modern \"Y. pestis\" strains \"Y. p. orientalis\" and \"Y. p. medievalis\", suggesting the plague may have entered Europe in two waves. Surveys of plague pit remains in France and England indicate the first variant entered Europe through the port of Marseille around November 1347 and spread through France over the next two years, eventually reaching England in the spring of 1349, where it spread through the country in three epidemics. Surveys of plague pit remains from the Dutch town of Bergen op Zoom showed the \"Y. pestis\" genotype responsible for the pandemic that spread through the Low Countries from 1350 differed from that found in Britain and France, implying Bergen op Zoom (and possibly other parts of the southern Netherlands) was not directly infected from England or France in 1349 and suggesting a second wave of plague, different from those in Britain and France, may have been carried to the Low Countries from Norway, the Hanseatic cities or another site.\n\nThe results of the Haensch study have since been confirmed and amended. Based on genetic evidence derived from Black Death victims in the East Smithfield burial site in England, Schuenemann et al. concluded in 2011 \"that the Black Death in medieval Europe was caused by a variant of \"Y. pestis\" that may no longer exist.\" A study published in \"Nature\" in October 2011 sequenced the genome of \"Y. pestis\" from plague victims and indicated that the strain that caused the Black Death is ancestral to most modern strains of the disease.\n\nDNA taken from 25 skeletons from the 14th century found in London have shown the plague is a strain of \"Y. pestis\" that is almost identical to that which hit Madagascar in 2013.\n\nThe plague theory was first significantly challenged by the work of British bacteriologist J. F. D. Shrewsbury in 1970, who noted that the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague, leading him to conclude that contemporary accounts were exaggerations. In 1984, zoologist Graham Twigg produced the first major work to challenge the bubonic plague theory directly, and his doubts about the identity of the Black Death have been taken up by a number of authors, including Samuel K. Cohn, Jr. (2002 and 2013), David Herlihy (1997), and Susan Scott and Christopher Duncan (2001).\n\nIt is recognised that an epidemiological account of the plague is as important as an identification of symptoms, but researchers are hampered by the lack of reliable statistics from this period. Most work has been done on the spread of the plague in England, and even estimates of overall population at the start vary by over 100% as no census was undertaken between the time of publication of the Domesday Book and the year 1377. Estimates of plague victims are usually extrapolated from figures from the clergy.\n\nIn addition to arguing that the rat population was insufficient to account for a bubonic plague pandemic, sceptics of the bubonic plague theory point out that the symptoms of the Black Death are not unique (and arguably in some accounts may differ from bubonic plague); that transference via fleas in goods was likely to be of marginal significance; and that the DNA results may be flawed and might not have been repeated elsewhere or were not replicable at all, despite extensive samples from other mass graves. Other arguments include the lack of accounts of the death of rats before outbreaks of plague between the 14th and 17th centuries; temperatures that are too cold in northern Europe for the survival of fleas; that, despite primitive transport systems, the spread of the Black Death was much faster than that of modern bubonic plague; that mortality rates of the Black Death appear to be very high; that, while modern bubonic plague is largely endemic as a rural disease, the Black Death indiscriminately struck urban and rural areas; and that the pattern of the Black Death, with major outbreaks in the same areas separated by 5 to 15 years, differs from modern bubonic plague—which often becomes endemic for decades with annual flare-ups.\n\nMcCormick has suggested that earlier archaeologists were simply not interested in the \"laborious\" processes needed to discover rat remains. Walløe complains that all of these authors \"take it for granted that Simond's infection model, black rat → rat flea → human, which was developed to explain the spread of plague in India, is the only way an epidemic of \"Yersinia pestis\" infection could spread\", whilst pointing to several other possibilities. Similarly, Green has argued that greater attention is needed to the range of (especially non-commensal) animals that might be involved in the transmission of plague.\n\nA variety of alternatives to \"Y. pestis\" have been put forward. Twigg suggested that the cause was a form of anthrax, and Norman Cantor thought it may have been a combination of anthrax and other pandemics. Scott and Duncan have argued that the pandemic was a form of infectious disease that they characterise as \"hemorrhagic\" plague similar to Ebola. Archaeologist Barney Sloane has argued that there is insufficient evidence of the extinction of a large number of rats in the archaeological record of the medieval waterfront in London and that the plague spread too quickly to support the thesis that \"Y. pestis\" was spread from fleas on rats; he argues that transmission must have been person to person. This theory is supported by research in 2018 which suggested transmission was more likely by body lice and human fleas during the second plague pandemic.\n\nHowever, no single alternative solution has achieved widespread acceptance. Many scholars arguing for \"Y. pestis\" as the major agent of the pandemic suggest that its extent and symptoms can be explained by a combination of bubonic plague with other diseases, including typhus, smallpox and respiratory infections. In addition to the bubonic infection, others point to additional septicemic (a type of \"blood poisoning\") and pneumonic (an airborne plague that attacks the lungs before the rest of the body) forms of the plague, which lengthen the duration of outbreaks throughout the seasons and help account for its high mortality rate and additional recorded symptoms. In 2014, Public Health England announced the results of an examination of 25 bodies exhumed in the Clerkenwell area of London, as well as of wills registered in London during the period, which supported the pneumonic hypothesis.\n\nThere are no exact figures for the death toll; the rate varied widely by locality. In urban centres, the greater the population before the outbreak, the longer the duration of the period of abnormal mortality. It killed some people in Eurasia. According to medieval historian Philip Daileader in 2007:\n\nThe trend of recent research is pointing to a figure more like 45–50% of the European population dying during a four-year period. There is a fair amount of geographic variation. In Mediterranean Europe, areas such as Italy, the south of France and Spain, where plague ran for about four years consecutively, it was probably closer to 75–80% of the population. In Germany and England ... it was probably closer to 20%.\n\nA death rate as high as 60% in Europe has been suggested by Norwegian historian Ole Benedictow:\n\nDetailed study of the mortality data available points to two conspicuous features in relation to the mortality caused by the Black Death: namely the extreme level of mortality caused by the Black Death, and the remarkable similarity or consistency of the level of mortality, from Spain in southern Europe to England in north-western Europe. The data is sufficiently widespread and numerous to make it likely that the Black Death swept away around 60 per cent of Europe's population. It is generally assumed that the size of Europe's population at the time was around 80 million. This implies that around 50 million people died in the Black Death.\n\nThe most widely accepted estimate for the Middle East, including Iraq, Iran and Syria, during this time, is for a death rate of about a third. The Black Death killed about 40% of Egypt's population. Half of Paris's population of 100,000 people died. In Italy, the population of Florence was reduced from 110,000–120,000 inhabitants in 1338 down to 50,000 in 1351. At least 60% of the population of Hamburg and Bremen perished, and a similar percentage of Londoners may have died from the disease as well. In London approximately 62,000 people died between 1346 and 1353. While contemporary reports account of mass burial pits being created in response to the large numbers of dead, recent scientific investigations of a burial pit in Central London found well-preserved individuals to be buried in isolated, evenly spaced graves, suggesting at least some pre-planning and Christian burials at this time. Before 1350, there were about 170,000 settlements in Germany, and this was reduced by nearly 40,000 by 1450. In 1348, the plague spread so rapidly that before any physicians or government authorities had time to reflect upon its origins, about a third of the European population had already perished. In crowded cities, it was not uncommon for as much as 50% of the population to die. The disease bypassed some areas, and the most isolated areas were less vulnerable to contagion. Monks and priests were especially hard-hit since they cared for victims of the Black Death.\n\nRenewed religious fervour and fanaticism bloomed in the wake of the Black Death. Some Europeans targeted \"various groups such as Jews, friars, foreigners, beggars, pilgrims\", lepers, and Romani, thinking that they were to blame for the crisis. Lepers, and other individuals with skin diseases such as acne or psoriasis, were singled out and exterminated throughout Europe.\n\nBecause 14th-century healers were at a loss to explain the cause, Europeans turned to astrological forces, earthquakes, and the poisoning of wells by Jews as possible reasons for the plague's emergence. The governments of Europe had no apparent response to the crisis because no one knew its cause or how it spread. The mechanism of infection and transmission of diseases was little understood in the 14th century; many people believed the epidemic was a punishment by God for their sins. This belief led to the idea that the cure to the disease was to win God's forgiveness.\n\nThere were many attacks against Jewish communities. In February 1349, the citizens of Strasbourg murdered 2,000 Jews. In August 1349, the Jewish communities in Mainz and Cologne were annihilated. By 1351, 60 major and 150 smaller Jewish communities had been destroyed. These massacres eventually died out in Western Europe, only to continue on in Eastern Europe. During this period many Jews relocated to Poland, where they received a warm welcome from King Casimir the Great.\n\nThe plague repeatedly returned to haunt Europe and the Mediterranean throughout the 14th to 17th centuries. According to Biraben, the plague was present somewhere in Europe in every year between 1346 and 1671. The was particularly widespread in the following years: 1360–1363; 1374; 1400; 1438–1439; 1456–1457; 1464–1466; 1481–1485; 1500–1503; 1518–1531; 1544–1548; 1563–1566; 1573–1588; 1596–1599; 1602–1611; 1623–1640; 1644–1654; and 1664–1667. Subsequent outbreaks, though severe, marked the retreat from most of Europe (18th century) and northern Africa (19th century). According to Geoffrey Parker, \"France alone lost almost a million people to the plague in the epidemic of 1628–31.\"\n\nIn England, in the absence of census figures, historians propose a range of pre-incident population figures from as high as 7 million to as low as 4 million in 1300, and a post-incident population figure as low as 2 million. By the end of 1350, the Black Death subsided, but it never really died out in England. Over the next few hundred years, further outbreaks occurred in 1361–1362, 1369, 1379–1383, 1389–1393, and throughout the first half of the 15th century. An outbreak in 1471 took as much as 10–15% of the population, while the death rate of the plague of 1479–1480 could have been as high as 20%. The most general outbreaks in Tudor and Stuart England seem to have begun in 1498, 1535, 1543, 1563, 1589, 1603, 1625, and 1636, and ended with the Great Plague of London in 1665.\n\nIn 1466, perhaps 40,000 people died of the plague in Paris. During the 16th and 17th centuries, the plague was present in Paris around 30 per cent of the time. The Black Death ravaged Europe for three years before it continued on into Russia, where the disease was present somewhere in the country 25 times between 1350 and 1490. Plague epidemics ravaged London in 1563, 1593, 1603, 1625, 1636, and 1665, reducing its population by 10 to 30% during those years. Over 10% of Amsterdam's population died in 1623–1625, and again in 1635–1636, 1655, and 1664. Plague occurred in Venice 22 times between 1361 and 1528. The plague of 1576–1577 killed 50,000 in Venice, almost a third of the population. Late outbreaks in central Europe included the Italian Plague of 1629–1631, which is associated with troop movements during the Thirty Years' War, and the Great Plague of Vienna in 1679. Over 60% of Norway's population died in 1348–1350. The last plague outbreak ravaged Oslo in 1654.\n\nIn the first half of the 17th century, a plague claimed some 1.7 million victims in Italy, or about 14% of the population. In 1656, the plague killed about half of Naples' 300,000 inhabitants. More than 1.25 million deaths resulted from the extreme incidence of plague in 17th-century Spain. The plague of 1649 probably reduced the population of Seville by half. In 1709–1713, a plague epidemic that followed the Great Northern War (1700–1721, Sweden v. Russia and allies) killed about 100,000 in Sweden, and 300,000 in Prussia. The plague killed two-thirds of the inhabitants of Helsinki, and claimed a third of Stockholm's population. Europe's last major epidemic occurred in 1720 in Marseille.\n\nThe Black Death ravaged much of the Islamic world. Plague was present in at least one location in the Islamic world virtually every year between 1500 and 1850. Plague repeatedly struck the cities of North Africa. Algiers lost 30,000–50,000 inhabitants to it in 1620–1621, and again in 1654–1657, 1665, 1691, and 1740–1742. Plague remained a major event in Ottoman society until the second quarter of the 19th century. Between 1701 and 1750, thirty-seven larger and smaller epidemics were recorded in Constantinople, and an additional thirty-one between 1751 and 1800. Baghdad has suffered severely from visitations of the plague, and sometimes two-thirds of its population has been wiped out.\n\nThe third plague pandemic (1855–1859) started in China in the mid-19th century, spreading to all inhabited continents and killing 10 million people in India alone. Twelve plague outbreaks in Australia between 1900 and 1925 resulted in well over 1,000 deaths, chiefly in Sydney. This led to the establishment of a Public Health Department there which undertook some leading-edge research on plague transmission from rat fleas to humans via the bacillus \"Yersinia pestis\".\n\nThe first North American plague epidemic was the San Francisco plague of 1900–1904, followed by another outbreak in 1907–1908.\n\nModern treatment methods include insecticides, the use of antibiotics, and a plague vaccine. The plague bacterium could develop drug resistance and again become a major health threat. One case of a drug-resistant form of the bacterium was found in Madagascar in 1995. A further outbreak in Madagascar was reported in November 2014. In October 2017 the deadliest outbreak of the plague in modern times hit Madagascar, killing 170 people and infecting thousands.\n\nThe phrase (') was used in 1350 by Simon de Covino or Couvin, a Belgian astronomer, who wrote the poem \"On the Judgment of the Sun at a Feast of Saturn\" ('), which attributes the plague to a conjunction of Jupiter and Saturn. \nIn 1908, Gasquet claimed that use of the name ' for the 14th-century epidemic first appeared in a 1631 book on Danish history by J. I. Pontanus: \"Commonly and from its effects, they called it the black death\" ('). The name spread through Scandinavia and then Germany, gradually becoming attached to the mid 14th-century epidemic as a proper name. \nHowever, ' is used to refer to a pestilential fever (') already in the 12th-century \"On the Signs and Symptoms of Diseases\" () by French physician Gilles de Corbeil. In English, the term was first used in 1755. Writers contemporary with the plague described the event as \"great plague\" or \"great pestilence\". \n\n\n"}
{"id": "2794170", "url": "https://en.wikipedia.org/wiki?curid=2794170", "title": "Brief intervention", "text": "Brief intervention\n\nBrief intervention is a technique used to initiate change for an unhealthy or risky behaviour such as smoking, lack of exercise or alcohol misuse. As an alcohol intervention it is typically targeted to non-dependent drinkers whose drinking may still be harmful. It is a prevention approach typically carried out by health roles helping at-risk drinkers make an informed choice about their alcohol use.\n\nCrucially brief intervention includes 'screening' or 'identification' whereby a persons drinking risk level is assessed using a validated tool such as the Alcohol Use Disorders Identification Test (AUDIT). Brief intervention may often be referred to as Screening and Brief Intervention (SBI), or in England, 'Identification and Brief Advice' (IBA).\n\nIt works in two ways:\n\nFor alcohol misuse, the following elements have been identified as particularly important, and forming the acromym \"FRAMES\":\n\nBrief interventions are based on motivational interviewing techniques.\n\nMotivational interviewing is a technique which aims to be both non-judgmental and non-confrontational. Its success depends largely on the presentation of objective feedback based on information provided by an individual. The technique involves acknowledgement that individuals who attend a counselling session, assessment or prevention program may be at different levels of readiness to change their alcohol consumption patterns, including:\n\n\nThe technique attempts to increase a person's awareness of the potential problems caused, consequences experienced, and risks faced as a result of patterns of alcohol consumption. As feedback is presented, the clinician or program provider may foster the development of discrepancies between the perception that someone has of themselves and the reality of that person's situation.\n\nThis technique acknowledges that people may come to a counseling session, an assessment, or a prevention program at different levels of readiness to change their drinking behavior. Some people may have never thought of making changes in their drinking, others may have thought about it but not taken steps to change it, some may be actively trying to cut down, and others may have already cut down, and succeeded in maintaining reduced consumption. Motivational Interviewing attempts to address the specific issues that people are facing at any particular stage.\n\nIn short, the strategy seeks to prompt individuals to think differently about their use of alcohol and ultimately consider what might be gained through change.\n\nWhen the assessment is complete, people receive personalized feedback about their alcohol consumption and related behaviors. For instance, 'feedback' highlights that the person's drinking may be placing their health at risk, and is above recommended consumption guidelines. In groups (e.g., a social fraternity or sorority), feedback can be given based on data collected from group members prior to an intervention program. Some researchers have used mailed feedback after collecting data on a questionnaire such that no face-to-face interaction actually occurs.\n\nSkills training programs develop skills for consuming alcohol in a safer way. One of the limitations of information-only programs is that they may raise awareness and information about the effects of a substance, but leave the individual to make behaivoural changes themselves.\n\nSkills training programs can work well with motivational interviewing techniques, as skills training programs work to provide the individual with the skills to make these changes in their drinking behavior, as the motivational interviewing simultaneously works to make the individual aware of their behaviour.\n\nIn doing so, they provide harm reduction strategies for those who choose to drink. This means that moderate drinking goals may also be considered, recognising that any steps toward safer alcohol consumption are steps in the right direction. Consequently, while abstinence may be the optimal outcome for some people, skills for drinking in a way that will minimize harm can be considered if abstinence is not viewed as realistic, attainable, or attractive. For example, blood alcohol concentration level estimation training enables people to set limits for moderate goals that are unique to their gender, weight, and time spent drinking. Teaching practical strategies for reaching these limits, such as spacing one's drinks, pacing oneself, alternating alcoholic and non-alcoholic drinks, consuming food before drinking and drinking for promote success.\n\n"}
{"id": "57524681", "url": "https://en.wikipedia.org/wiki?curid=57524681", "title": "Camel spongiform encephalopathy", "text": "Camel spongiform encephalopathy\n\ncamel spongiform encephalopathy (CSE) commonly known as mad camel disease This disease, similar to mad cow disease, was discovered by two Algerian researchers, among them Dr Baaissa Babelhadj, veterinarian of the slaughter of the city of Ouargla in coordination with Italian researchers, This infection is a new form of prion disease and a type of Transmissible spongiform encephalopathy that affects for the first time non-ruminant mammals (camels) and is associated with mad cow disease in the characteristics of the ability to move to other animal species and to human consumers. \n\nThe research that led to this discovery was published electronically on April 5, 2018 in the Emerging Infectious Diseases Journal, published by the American Society for Disease Control and Prevention, and in the paper version of Volume 24, No. 6, 2018.\n"}
{"id": "14112236", "url": "https://en.wikipedia.org/wiki?curid=14112236", "title": "Cedric Stanton Hicks", "text": "Cedric Stanton Hicks\n\nSir Cedric Stanton Hicks (2 June 1892 - 7 February 1976) was an Australian Professor of Human Physiology and Pharmacology at the University of Adelaide. During World War II Hicks founded the Australian Army Catering Corps and served as its commander from 1943. Hicks worked closely with the Australian Army Catering Corps as an adviser on nutrition and was on the Defence Department's Scientific Advisory Committee as its advisor on foodstuffs.\n\nHicks was born in Mosgiel, New Zealand; his grandmother, Adelaide Hicks, was a community midwife and nurse in the area. He was educated first in New Zealand and after being awarded a Beit medical research fellowship in 1923, he travelled to England and studied at Trinity College, Cambridge. Under the fellowship he also carried out research in Switzerland, Germany and the United States of America. He took up a fellowship and lectureship at the University of Adelaide in 1926. In January 1927 he was appointed to a new chair of physiology and pharmacology at the University, a post he held until 1957.\n\nIn 1972 he published a book on his wartime catering experience under the title, \"Who called the cook a bastard?\" He died in Glen Osmond, South Australia.\n\n"}
{"id": "3255644", "url": "https://en.wikipedia.org/wiki?curid=3255644", "title": "Cell Computing", "text": "Cell Computing\n\nCell Computing is a now-defunct distributed computing project that was operated by NTT Data to perform biomedical research. \n\nIt used the Berkeley Open Infrastructure for Network Computing (BOINC) platform; however, it was initially launched using the United Devices Grid MP platform in 2002.\n\nThe project ended in 2008 due to lack of popularity.\n\n"}
{"id": "38622206", "url": "https://en.wikipedia.org/wiki?curid=38622206", "title": "Chargemaster", "text": "Chargemaster\n\nIn the United States, the chargemaster, also known as charge master, or charge description master (CDM), is a comprehensive listing of items billable to a hospital patient or a patient's health insurance provider. In practice, it usually contains highly inflated prices at several times that of actual costs to the hospital. The chargemaster typically serves as the starting point for negotiations with patients and health insurance providers of what amount of money will actually be paid to the hospital. It is described as \"the central mechanism of the revenue cycle\" of a hospital.\n\nThe chargemaster may be alternatively referred to as the \"charge master\", \"hospital chargemaster\", or the \"charge description master\" (CDM). It is a comprehensive listing of items billable to a hospital patient or a patient's health insurance provider. It is described as \"the central mechanism of the revenue cycle\" of a hospital. Chargemasters include thousands of hospital services, medical procedures, equipment fees, drugs, supplies, and diagnostic evaluations such as imaging and blood tests. Each item in the chargemaster is assigned a unique identifier code and a set price that are used to generate patient bills. Every hospital system maintains its own chargemaster. Usually, hospitals regard their chargemaster, alongside the medical codes that catalogue the billing items, as a trade secret that is central to their business, and state laws and courts have often accepted the view that these are proprietary information.\n\nThe procedure of developing, maintaining, and monitoring the chargemaster and its pricing scheme often necessitates multiple hospital employees working under the supervision of a \"chargemaster coordinator\", a \"charge master manager\", or others in the health care system's operations or administrative support areas frequently called a \"charge master team\". Ultimate responsibility for ensuring accuracy of the chargemaster rests with each hospital's chief financial officer, compliance officer, and hospital Board. Approximately forty percent of hospitals pay outside companies to help create and then adapt their chargemasters on a yearly basis. According to \"Essentials of Managed Health Care\", as of 2012 the chargemaster file typically included between 20,000 and 50,000 price definitions. The Lewin Group analyzed utilization of the chargemaster and found that a low proportion of hospitals carried out regular reviews of their chargemaster implementation. Costs for patients maintained on the chargemaster differ greatly from hospital to hospital.\n\nAuthors J. Patrick Rooney and Dan Perrin note in their book \"America's Health Care Crisis Solved\", \"Charge-master rates, in reality, serve as nothing more than the starting point for negotiations\" with the payer. The impact of the chargemaster is such that those with good insurance or better access to means to afford quality healthcare pay the least for that care, whereas conversely uninsured, and others who pay out-of-pocket for healthcare pay the full chargemaster listed price for the same services.\n\nIn California, a regulation known as the \"Payers' Bill of Rights\" (which is unique to the state) requires all hospitals to provide their chargemaster to the state, which then posts them online for the public.\n\nThe chargemaster procedure is generally only regulated in Maryland; author Peter Reid Kongstvedt notes in \"Essentials of Managed Care\", \"Of particular importance, other than in Maryland, hospitals are generally free to charge whatever they want in their chargemaster.\"\n\nChargemasters gained national attention in early 2013, when in short succession, there were two important publications made. First, there was a \"Time\" magazine cover story published February 20, 2013, titled \"Bitter Pill: Why Medical Bills Are Killing Us\", in which reporter Steven Brill examined the overlooked role that chargemasters played in the American health care system's cost crisis, asserting that they routinely listed extremely high prices \"devoid of any calculation related to cost\", and were generally regarded as \"fiction\" in the healthcare industry, despite their significant role in setting prices for both insured and uninsured patients alike. Then, a couple months later, the Centers for Medicare and Medicaid Services published inpatient prices for hospitals across the country in a publicly available format.\n\n\"The 'full charges' reflected on hospital Charge Masters are unconscionable\", wrote George A. Nation III in a 2005 piece for the \"Kentucky Law Journal\". Health care economist scholar Uwe Reinhardt noted in a 2006 article for \"Health Affairs\" that the approach to chargemasters by hospitals would have to be modified to become more transparent, in order to encourage a form of consumer-driven health care to help improve the system. University of California, Berkeley professor of health economics James C. Robinson pointed out prior criticism of the chargemaster, \"Much ink has been spilt bemoaning that incomprehensible foundation of hospital cost accounting and prices, the redoubtable chargemaster.\" Robinson called for greater transparency as well as increased price standardization as steps to help remedy the situation.\n\nIn a 2007 article for \"Health Affairs\", Gerard F. Anderson observed, \"Without knowing what services they will use in advance, it is impossible for patients to comparison shop.\" Anderson also noted the esoteric nature of the language on the chargemaster made it difficult for patients and anyone other than hospital administrators to understand. Anderson emphasized the difficulty of patients' ability to interpret the chargemaster in a subsequent 2012 article: \"Furthermore, most of the items on the charge master file are written in code so that only the hospital administrators and a few experts in the field can interpret their meanings.\"\n\n\n\n"}
{"id": "7521201", "url": "https://en.wikipedia.org/wiki?curid=7521201", "title": "Compounding", "text": "Compounding\n\nPharmaceutical compounding (done in compounding pharmacies) is the creation of a particular pharmaceutical product to fit the unique need of a patient. To do this, compounding pharmacists combine or process appropriate ingredients using various tools. This may be done for medically necessary reasons, such as to change the form of the medication from a solid pill to a liquid, to avoid a non-essential ingredient that the patient is allergic to, or to obtain the exact dose(s) needed or deemed best of particular active pharmaceutical ingredient(s). It may also be done for more optional reasons, such as adding flavors to a medication or otherwise altering taste or texture. Compounding is most routine in the case of intravenous/parenteral medication, typically by hospital pharmacists, but is also offered by privately owned compounding pharmacies and certain retail pharmacies for various forms of medication. Whether routine or rare, intravenous or oral, etc., when a given drug product is made or modified to have characteristics that are specifically prescribed for an individual patient, it is known as \"traditional\" compounding.\n\nDue to the rising cost of compounding and the shortage of drugs, many hospitals have shown a tendency to rely more upon large-scale compounding pharmacies to meet their regular requirement, particularly of sterile-injectable medications. When compounding is done on bulk production of a given formulation rather than patient-specific production, it is known as \"non-traditional\" compounding (which, as discussed below, is arguably not \"compounding\" but rather \"manufacturing\"). This development raises concerns about patient safety and makes a case for proper regulatory control and monitoring.\n\nBefore mass production of medications became widespread, compounding was a routine activity among pharmacists. Community pharmacists who have experience with compounding techniques are now less common.\n\nPharmaceutical compounding has ancient roots. Hunter-gatherer societies had some knowledge of the medicinal properties of the animals, plants, molds, fungus and bacteria as well as inorganic minerals within their environment. Ancient civilizations used pharmaceutical compounding for religion, grooming, keeping the healthy well, treating the ill and preparing the dead. These ancient compounders produced the first oils from plants and animals. They discovered poisons and the antidotes. They made ointments for wounded patients and perfumes for customers.\n\nThe earliest chemists were familiar with various natural substances and their uses. These drug artisans compounded a variety of preparations such as medications, dyes, incense, perfumes, ceremonial compounds, preservatives and cosmetics. Drug compounders seeking gold and the fountain of youth drove the alchemy movement. Alchemy eventually contributed to the creation of modern pharmacy and the principles of pharmacy compounding. In the medieval Islamic world in particular, Muslim pharmacists and chemists developed advanced methods of compounding drugs. The first drugstores were opened by Muslim pharmacists in Baghdad in 754.\n\nThe modern age of pharmacy compounding began in the 19th century with the isolation of various compounds from coal tar for the purpose of producing synthetic dyes. From this one natural product came the earliest antibacterial sulfa drugs, phenolic compounds made famous by Joseph Lister, and plastics.\n\nDuring the 1800s, pharmacists specialized in the raising, preparation and compounding of crude drugs. Crude drugs, like opium, are from natural sources and usually contain several chemical compounds. The compounding pharmacist often extracted these crude drugs using water or alcohol to form extracts, concoctions and decoctions.\n\nPharmacists began isolating and identifying the active ingredients contained within these crude drug concoctions. Using fractionation or recrystallization, the compounding pharmacist would separate the active ingredients, like morphine, and use it in place of the crude drug. During this time modern medicine began.\n\nWith the isolation of medications from the raw materials or crude drugs came the birth of the modern pharmaceutical company. Pharmacists were trained to compound the preparations made by the drug companies, but they could not do it efficiently on a small scale. So economies of scale, not lack of skill or knowledge, produced the modern pharmaceutical industry.\n\nWith the turn of the 20th century came greater government regulation of the practice of medicine. These new regulations forced the drug companies to prove that any new medication they brought to market was safe. With the discovery of penicillin, modern marketing techniques and brand promotion, the drug manufacturing industry came of age. Pharmacists continued to compound most prescriptions until the early 1950s when the majority of dispensed drugs came directly from the large pharmaceutical companies.\n\nPharmaceutical compounding is a branch of pharmacy that continues to play the crucial role of drug development. Compounding pharmacists and medicinal chemists develop and test combinations of active pharmaceuticals and delivery systems for new pharmaceutical formulations so that the active ingredients are effective, stable, easy to use, and acceptable to patients. However, for actual clinical trials, production of drug products is generally considered \"manufacturing\" because \"compounding\" is typically defined as being for small batch or single individual patient production only.\n\nPhysicians may prescribe an individually compounded medication for a patient with an unusual health need. This allows the physician to tailor a prescription to each individual. Compounding preparations are especially prevalent for:\n\n\nWhile the regulatory boundaries are not always clear (see \"Regulation\"), there is general acceptance of the need for physicians to have wide discretion to prescribe customized drug products containing unique drug-dosage combinations and/or formulations thereof specifically for individual patients. Most mass-produced drugs often have only one or two readily available dosage levels (except the most dominant drugs), and fixed-dose combination products – despite their many benefits – are even less likely to have the optimal combination of drugs and respective dosages for any given patient. Hence, the opportunity to tailor the drug(s)/dosage(s) in a given drug product as specifically contemplated for individual patients (as deemed optimal by one's physician) is an application of the classic principles underlying compounding.\n\nSome kinds or compositions of \"polypills\" or other drug products are more amenable to custom-compounding than others, and most retail pharmacies no longer offer compounding services at all, although hospital pharmacies still commonly compound intravenous medications. But while fewer pharmacists are trained and experienced in the relevant skills anymore; especially regarding oral dosage forms, which are almost always mass-produced now instead; such compounding pharmacies nevertheless can be found and utilized via mail-order (if not available locally) with sufficient notice and planning.\n\nTechnologies are under development to facilitate production of customized polypills, such as for example by the use of ink-jet printing mechanisms to precisely deposit selected drug substance(s) onto sheets which can then be inserted into capsules, enabling \"individualized dosing and automated fabrication of medicines containing multiple drugs,\" in addition to custom single-drug products. Similar technology can also be used to print tablets, more directly. Ink-jet or fluid-jet approaches do require each drug substance to be dissolved in a liquid solvent, but they can be particularly conducive to custom formulation with various possible excipients, in addition to custom drug/dose selections.\n\nIn Australia the Pharmacy Board of Australia is responsible for registration of pharmacists and professional practice including compounding. Although almost all pharmacies are able to prepare at least simple compounded medicines, some pharmacies undertake further training and education to be able to prepare more complex products. Although pharmacists who have undertaken further training to do complex compounding are not yet easily identified, the Board has been working to put a credentialing system in place. In 2011 the Pharmacy Board convened a Compounding Working Party to advise on revised compounding standards. Draft compounding guidelines for comment were released in April 2014. However it should be noted that pharmacists are required to comply with the current Board requirements and if this is not happening the Board can be notified.\n\nBoth sterile and non-sterile compounding are legal provided the medicines are provided for a particular patient for therapeutic application to that patient, and the compounded product is supplied on or from the compounding pharmacy premises. There are additional requirements for sterile compounding. Not only must a laminar flow cabinet [laminar flow hood] be used, but the environment in which the hood is located must be strictly controlled for microbial and particulate contamination and all procedures, equipment and personnel must be validated to ensure the safe preparation of sterile products. In non-sterile compounding, a powder containment hood is required when any hazardous material (e.g. hormones) are prepared or when there is a risk of cross-contamination of the compounded product. Pharmacists preparing compounded products must comply with these requirements and others published in the Australian Pharmaceutical Formulary & Handbook.\n\nIn the United States, compounding pharmacies are licensed and regulated by their respective states like all other pharmacies. National standards have been created by Pharmacy Compounding Accreditation Board (PCAB). However, accreditation is not mandatory and inspections for compliance occur only every three years. As mentioned, some confusion has arisen when the traditionally patient-specific nature of compounding gets blurred by the making the multi-product \"batches\" such as in anticipation of similar orders. Notably, the Food and Drug Administration (FDA) has always had authority to regulate \"manufacturing\" – which is when drug products are not made or modified as to be \"tailored in some way to the individual patient\" – regardless of whether this is done at a factory or at a pharmacy. And conversely, truly legitimate/traditional compounding does not cease to be so merely by having a high \"frequency\" or occurrence – indeed, progressing towards \"more\" prevalent drug product customization is an appealing aspect of personalized medicine (see above).\n\nIn the Drug Quality and Security Act (DQSA) of 2013 (H.R. 3204), Congress amended the Federal Food, Drug, and Cosmetic Act (FFDCA) to clarify some limits of FDA jurisdiction over traditional (i.e., patient-specific) compounding, and to provide a regulated (albeit optional) pathway for \"non-traditional\" compounders to operate. So now, Section 503A essentially establishes that pharmacies compounding only \"patient-specific\" drug products made in response to each prescription (among certain other related situations) cannot be required to obtain FDA approval for such products, as they will remain exclusively under state-level pharmacy regulation. At the same time, Section 503B creates a new category of facilities called \"outsourcing facilities\" - by which non-traditional compounding facilities (i.e., those whose products include \"non-patient-specific\" batches) can be explicitly authorized by the Food and Drug Administration under specified circumstances, while being exempted from certain requirements otherwise imposed on mass-producers. Notably, in both cases the compounding cannot encompass a drug product that is \"essentially a copy\" of a mass-produced drug product, but in 503B the definition of \"essentially a copy\" is broader than in 503A. (In earlier DQSA drafts the definitions were kept the same for both sections, but the final version goes further for \"outsourcing facilities\" in subsection (d)(2)(B) of 503B, by deeming a compounded drug a \"copy\" even if it just has an active ingredient that is also present in any mass-produced product.) However, this definition is indicated at the beginning of subsection (d) as applying only for section 503B. For traditional/patient-specific compounding, 503A's definition of \"copy\" retains its original focus on drug \"products\" or ultimate dosage forms rather than drug substances or active ingredients, and in any event it explicitly excludes from its definition any compounded drug product that a given patient's prescribing practitioner determines makes a \"significant difference\" for the patient. (503B's definition includes a similar but narrower \"safe harbor\" exclusion from the definition; that definition, which applies only to the \"outsourcing facilities,\" defines \"copy\" based on the active ingredient(s) a drug product contains, rather than the overall drug product or dosage form, and it explicitly excludes situations where the prescribing practitioner determines that the change/difference makes a \"clinical difference\" for the patient.)\n\nIn general, to whatever extent the Food and Drug Administration ever has authority to regulate compounding, the FDA weighs the following (non-exhaustive) mix of factors in deciding whether to \"exercise its discretion\" to require approval for a custom-compounded drug product, from its 2002 Compliance Policy Guide on the matter:\nHence, making truly patient-customized products with particular drug(s)/dosage(s) upon receiving valid prescriptions from a physician is likely to be acceptable, especially if the ingredients are FDA approved, etc.\n\nThe DQSA amends the FFDCA to create a new class of FDA-regulated entities known as \"outsourcing facilities\" whose compounded drug products notably \"may \"or\" may not\" be patient-specific based on individualized prescriptions. Registered \"outsourcing facilities\", unlike traditional compounding facilities, are subject to the FDA's oversight. Currently this is a voluntary program.\n\nIn addition to being subjected to Food and Drug Administration inspections, registration, fees, and specified reporting requirements, other notable requirements of outsourcing facilities include that:\n\n\nRegarding traditional/patient-specific compounding, the practice of \"off-label use\" can be considered a related analogous point regarding the \"broad professional discretion to customize patient care.\" About 20–30% of prescription medications in the US are estimated to be used \"off-label,\" meaning the physician believes the drug to be beneficial for a patient despite its not being approved for that particular use/condition. This too is perfectly legal, subject only to state regulations on the practice of medicine, etc.\n\nThe appropriateness of prescribing approved drugs for uses not included in their official labeling is sometimes a cause of concern and confusion among physicians. This has been addressed by the American Society of Health-System Pharmacists in their Statement on the Use of Medications for Unlabeled Uses:\nUnder the Federal Food, Drug and Cosmetic (FD&C) Act, a drug approved for marketing may be labeled, promoted, and advertised by the manufacturer only for those uses for which the drug's safety and effectiveness has been established and which the FDA has approved. These are commonly referred to as \"approved uses.\" This means that adequate and well-controlled clinical trials have documented these uses, and the results of the trials have been reviewed and approved by the FDA.\n\nThe FFDCA does not, however, limit the manner in which a physician may use an approved drug. Once a product has been approved for marketing, a physician may prescribe it for uses or in treatment regimens or patient populations that are not included in the above labeling. Such \"unapproved\" or more precisely, \"unlabeled\" uses may be appropriate and rational in certain circumstances, and, may, in fact, reflect approaches to drug therapy that have been extensively reported in medical literature. Thus the term \"unapproved uses\" is, to some extent, misleading. Valid new uses for drugs already on the market are often first discovered through serendipitous observations and therapeutic investigations. Before such advances can be added to the approved labeling, however, data substantiating the effectiveness of a new use or regimen must be submitted by the manufacturer to the Food and Drug Administration for evaluation. This may take time, and without the initiative of the drug manufacturer whose product is involved, and physicians who are persuaded that a given usage is valid before there is broad scientific consensus, it may never otherwise occur. For that reason, accepted medical practice often includes so-called \"off label\" uses.\n\nPoor practices on the part of drug compounders can result in contamination or in products that don't possess the strength, quality, and purity required. Unless a complaint is filed or a patient is harmed, drugs made by compounders are seldom tested, In Texas, one of only two states that does random testing, significant problems have been found. Random tests by the state’s pharmacy board over the last several years have found that as many as one in four compounded drugs was either too weak or too strong. In Missouri, the only other state that does testing, potency varied by as much as 300 percent.\n\nIn 2002, the Food and Drug Administration, concerned about the rising number of accidents related to compounded medications, identified \"red flag\" factors and issued a guide devoted to human pharmacy compounding, These factors include instances where pharmacists are:\n\n\nThe DQSA of 2013 recognized and authorized certain non-traditional compounders to operate as \"outsourcing facilities,\" who register with the FDA and become subject to various reporting requirements - including adverse events and supply chain matters.\n\nIn October 2012 news reports surfaced of an outbreak of fungal meningitis tied to the New England Compounding Center.\n\nIn August 2013 further reports tied to the New England compounding center said that about 750 people were sickened, including 63 deaths, and that infections were linked to more than 17,600 doses of methylprednisolone acetate steroid injections used to treat back and joint pain that were shipped to 23 states. At that time, another incident was reported after at least 15 people at two Texas hospitals developed bacterial infections. All lots of medications dispensed since May 9, 2013, made by Specialty Compounding, LLC of Cedar Park, Texas were recalled. The hospitals reported affected were Corpus Christi Medical Center Bay Area and Corpus Christi Medical Center Doctors Regional. The patients had received intravenous infusions of calcium gluconate, a drug used to treat calcium deficiencies and too much potassium in the blood. Implicated in these cases is the Rhodococcus bacteria, which can cause symptoms such as fever and pain.\n\nThe DQSA of 2013 implements certain statutory changes and clarifications to the authority of the Food and Drug Administration, based in part on growing concerns about \"non-traditional\" or non-patient-specific compounding—particularly of sterile injectable drug products. Traditional, patient-specific compounding remains essentially unaffected and continues to fall under the domain of state pharmacy practice regulation without controversy.\n\nThe FDA and others say that some larger compounding pharmacies were acting like drug manufacturers and yet circumventing FDA regulations under the banner of compounding. Drugs from compounding pharmacies can be cheaper or alleviate shortages, but can pose greater risk of contamination due in part to the lack of oversight. Compounding pharmacies had been regulated by laws that were developed when they solely made custom prescriptions for individual patients, but the FDA has sought additional authority to regulate what they term \"non-traditional\" compounders who in essence are more like \"miniature drug manufacturers\" than true pharmacies. Such \"non-traditional\" compounders behave like manufacturers in various ways – such as by having sales teams that market non-personalized drug products or production capability to doctors, and by making drugs that are essentially the same as commercially available mass-produced drug products, and most importantly by \"pre-making large batches of a given drug product in anticipation of additional same prescriptions but before actually receiving them\" (the latter being directly the opposite of patient-specific tailoring).\n\nAn FDA spokesperson stated, \"The methods of these companies seem far more consistent with those of drug manufacturers than with those of retail pharmacies. Some firms make large amounts of compounded drugs that are copies or near copies of FDA-approved, commercially available drugs. Other firms sell to physicians and patients with whom they have only a remote professional relationship.\" The head of the FDA has recently requested the following authority from Congress:\n\n\"Nontraditional compounding should, because of the higher risk presented, be subject to a greater degree of oversight. Sterile products produced in advance of or without a prescription and\nshipped interstate should be subject to the highest level of controls, established by FDA and appropriate to the activity, similar to cGMP standards applicable to conventional drug manufacturers. In addition, FDA believes that with noted exceptions, certain products are not appropriate for compounding under any circumstances. These products would include: 1) what are essentially copies of FDA-approved drugs, absent a shortage justification based on the drug appearing on FDA’s shortage list; and 2) complex dosage forms such as extended release products; transdermal patches; liposomal products; most biologics; and other products as designated by FDA. Producing complex dosage forms would require an approved application and compliance with cGMP standards, along with other requirements applicable to manufactured drug products.\"\n\nThis statement also went on to advocate certain auditing and testing powers, record-keeping and reporting obligations, etc. While the first part (regarding a lack of prior prescription) is indeed consistent with limiting compounding to its traditional domain of \"customization\", it would however be unprecedented for the Food and Drug Administration to regulate truly individualized drug products solely on the basis of their formulation's \"complexity\" (although Congress could preempt the states traditional role in this regard). At the same time, this position statement does suggest perhaps some willingness by the FDA to embrace the occasional \"non-traditional compounding\" of \"copies\" of FDA-approved drug products – albeit with greater regulation – in cases of specified shortages.\n\nVarious ideas have been proposed to continue strengthening federal US regulation in this area, including new laws making it easier to identify misuse or misnomered-use and/or stricter enforcement of the longstanding distinction between \"compounding\" versus \"manufacturing\". Also, some US states have taken initiatives to strengthen their own oversight of compounding pharmacies.\n\nA major source of opposition to new Food and Drug Administration regulation on compounding stems from certain dietary supplement makers.\n\n\n"}
{"id": "30274709", "url": "https://en.wikipedia.org/wiki?curid=30274709", "title": "Consumer–resource interactions", "text": "Consumer–resource interactions\n\nConsumer–resource interactions are the core motif of ecological food chains or food webs, and are an umbrella term for a variety of more specialized types of biological species interactions including prey-predator (see predation), host-parasite (see parasitism), plant-herbivore and victim-exploiter systems. These kinds of interactions have been studied and modeled by population ecologists for nearly a century. Species at the bottom of the food chain, such as algae and other autotrophs, consume non-biological resources, such as minerals and nutrients of various kinds, and they derive their energy from light (photons) or chemical sources. Species higher up in the food chain survive by consuming other species and can be classified by what they eat and how they obtain or find their food.\n\nVarious terms have arisen to define consumers by what they eat, such as meat-eating carnivores, fish-eating piscivores, insect-eating insectivores, plant-eating herbivores, seed-eating granivores, and fruit-eating frugivores and omnivores are meat eaters and plant eaters. An extensive classification of consumer categories based on a list of feeding behaviors exists. \n\nAnother way of categorizing consumers, proposed by the American ecologist Wayne Getz, is based on a biomass transformation web (BTW) formulation that organizes resources into five components: live and dead animal, live and dead plant, and particulate (i.e. broken down plant and animal) matter. It also distinguishes between consumers that gather their resources by moving across landscapes from those that mine their resources by becoming sessile once they have located a stock of resources large enough for them to feed on during completion of a full life history stage.\n\nIn Getz's scheme, words for miners are of Greek etymology and words for gatherers are of Latin etymology. Thus a bestivore, such as a cat, preys on live animals (Latin: bestia=animal) while a sarcophage, such as a botfly larva mines live flesh and a zontanophage (Greek: zontanos=alive), such as a leaf miner, mines live plant material. A carcasivore (Latin: carcasium=carcass), such as white-backed vulture, scavenge animal carcasses while a necrophage (Greek: nekros=dead body), such as a blowfly, mines dead flesh. Victivores (Latin: victus=living) gather live plant material and thus include frugivores, nectivores, graminivores, granivores and folivores as subcategories. Lectivores, such as many termites, gather dead plant material (Latin: lectus=bed which is the root of the word litter, as in leaf-litter) and thanatophages (Greek: thanatos=death), such as pillbugs mine piles of dead plant material. Carnivore and herbivore are generic multigroup categories for gathers respectively of animal and plant material, irrespective of whether live or dead. Croppers, scavengers, and detritivores are gatherers respectively of live, dead, and particulate material. Parasites, saprophages, and decomposers are miners respectively of live, dead, and particulate material.\n\n\n\n"}
{"id": "1054247", "url": "https://en.wikipedia.org/wiki?curid=1054247", "title": "Dermatomyositis", "text": "Dermatomyositis\n\nDermatomyositis (DM) is a long-term inflammatory disorder which affects muscles. Its symptoms are generally a skin rash and worsening muscle weakness over time. These may occur suddenly or develop over months. Other symptoms may include weight loss, fever, lung inflammation, or light sensitivity. Complications may include calcium deposits in muscles or skin.\nThe cause is unknown. Theories include that it is an autoimmune disease or a result of a viral infection. It is a type of inflammatory myopathy. Diagnosis is typically based on some combination of symptoms, blood tests, electromyography, and muscle biopsies.\nWhile there is no cure for the condition, treatments generally improve symptoms. Treatments may include medication, physical therapy, exercise, heat therapy, orthotics, and assistive devices, and rest. Medications in the corticosteroids family are typically used with other agents like methotrexate or azathioprine recommended if steroids are not working well. Intravenous immunoglobulin may also improve outcomes. Most people improve with treatment and in some the condition resolves completely.\nAbout 1 per 100,000 people per year are newly affected. The condition usually occurs in those in their 40s and 50s with women being affected more often than men. People of any age, however, may be affected. The condition was first described in the 1800s.\n\nThe main symptoms include several kinds of skin rash along with muscle weakness in both upper arms or thighs.\n\nOne form the rashes take is called \"heliotrope\" (a purplish color) or lilac, but may also be red. It can occur around the eyes along with swelling, but also occurs on the upper chest or back what is called the \"shawl\" (around the neck) or \"V-sign\" above the breasts and may also occur on the face, upper arms, thighs, or hands. Another form the rash takes is called \"Gottron's sign\" which are red or violet, sometimes scaly, slightly raised papules that erupt on any of the finger joints (the metacarpophalangeal joints or the interphalangeal joints). Gottron's papules may also be found over other bony prominences including the elbows, knees, or feet. All these rashes are made worse by exposure to sunlight, and are often very itchy, painful, and may bleed.\n\nIf a person exhibits only skin findings characteristic of DM, without weakness or abnormal muscle enzymes, then he or she may be experiencing amyopathic dermatomyositis (ADM, formerly known as \"dermatomyositis sine myositis\".\n\nPeople with DM experience progressively worsening muscle weakness in the proximal muscles (for example, the shoulders and thighs). Tasks that use these muscles: standing from sitting, lifting, and climbing stairs, can become increasingly difficult for people with dermatomyositis.\n\nAround 30% of people have swollen, painful joints, but this is generally mild.\n\nIn some people the condition affects the lungs, and they may have a cough or difficulty breathing. If the condition affects the heart, there may be arrhythmias. If it affects the blood vessels in the stomach or intestines, which is more common in juvenile DM, the person might vomit blood, have black tarry bowel movements, or may develop a hole somewhere in their GI tract.\n\nThe cause is unknown, but it may result from an initial viral infection or cancer, either of which could raise an autoimmune response.\n\nBetween 7 and 30% of dermatomyositis arise from cancer, probably as an autoimmune response. The most common associated cancers are ovarian cancer, breast cancer, and lung cancer. 18 to 25% of people with amyopathic DM also have cancer. Malignancy in association with dermatomyositis is more prevalent after age 60.\n\nSome cases are inherited, and HLA subtypes HLA-DR3, HLA-DR52, and HLA-DR6 seem to create a disposition to autoimmune dermatomyositis.\n\nThe diagnosis of dermatomyositis is based on five criteria which are also used to differentially diagnose with respect to polymyositis:\n\n\nThe fifth criterion is what differentiates dermatomyositis from polymyositis; the diagnosis is considered definite for dermatomyositis if three of items 1 through 4 are present in addition to 5, probable with any two in addition to 5, and possible if just one is present in addition to 5.\n\nDermatomyositis is associated with autoantibodies, especially antinuclear antibodies (ANA). Around 80% of people with DM test positive for ANA and around 30% of people have myositis-specific autoantibodies which include antibodies to aminoacyl-tRNA synthetases (anti-synthetase antibodies), including antibodies against histidine—tRNA ligase (also called Jo-1); antibodies to signal recognition particle (SRP); and anti-Mi-2 antibodies.\n\nMagnetic resonance imaging may be useful to guide muscle biopsy and to investigate involvement of internal organs; X-ray may be used to investigate joint involvement and calcifications.\n\nA given case of dermatomyositis may be classified as amyopathic dermatomyositis if only skin is affected and there is no muscle weakness for longer than 6 months according to one 2016 review, or two years according to another.\n\nDermatomyositis is a form of systemic connective tissue disorder, a class of diseases that often involve autoimmune dysfunction.\n\nIt has also been classified as an idiopathic inflammatory myopathy along with polymyositis, necrotizing autoimmune myositis, cancer-associated myositis, and sporadic inclusion body myositis.\n\nThere is a form of this disorder that strikes children, known as juvenile dermatomyositis (JDM).\n\nThere is no cure for dermatomyositis, but the symptoms can be treated. Options include medication, physical therapy, exercise, heat therapy (including microwave and ultrasound), orthotics and assistive devices, and rest. The standard treatment for dermatomyositis is a corticosteroid drug, given either in pill form or intravenously. Immunosuppressant drugs, such as azathioprine and methotrexate, may reduce inflammation in people who do not respond well to prednisone. Periodic treatment using intravenous immunoglobulin can also improve recovery. Other immunosuppressive agents used to treat the inflammation associated with dermatomyositis include cyclosporine A, cyclophosphamide, and tacrolimus. Physical therapy is usually recommended to prevent muscle atrophy and to regain muscle strength and range of motion. Many individuals with dermatomyositis may need a topical ointment, such as topical corticosteroids, for their skin disorder. They should wear a high-protection sunscreen and protective clothing. Surgery may be required to remove calcium deposits that cause nerve pain and recurrent infections.\n\nAntimalarial medications, especially hydroxychloroquine and chloroquine, are used to treat the rashes, as they are in similar conditions.\n\nRituximab is used when people don't respond to other treatments.\n\nAs of 2016, treatments for amyopathic dermatomyositis in adults did not have a strong evidence base; published treatments included antimalarial medications, steroids, taken or orally or applied to the skin, calcineurin inhibitors applied to the skin, dapsone, Intravenous immunoglobulin (IVIG), methotrexate, azathioprine, and mycophenolate mofetil. None appear to be very effective but among them, IVIG has had the best outcomes.\n\nBefore the advent of modern treatments such as prednisone, intravenous immunoglobulin, plasmapheresis, chemotherapies, and other drugs, the prognosis was poor.\n\nThe cutaneous manifestations of dermatomyositis may or may not improve with therapy in parallel with the improvement of the myositis. In some people, the weakness and rash resolve together. In others, the two are not linked, with one or the other being more challenging to control. Often, cutaneous disease persists after adequate control of the muscle disease.\n\nThe risk of death from the condition is much higher if the heart or lungs are affected.\n\nIncidence of DM peaks at ages 40–50, but the disease can affect people of all ages. It tends to affect more women than men. The prevalence of DM ranges from 1 to 22 per 100,000 people.\n\nThe diagnostic criteria were proposed in 1975 and became widely adopted. Amyopathic DM, also called DM sine myositis, was named in 2002.\n\n\nAs of 2016, research was ongoing into causes for DM, as well as biomarkers; clinical trials were ongoing for use of the following drugs in DM: ajulemic acid (Phase II), adrenocorticotropic hormone gel (Phase IV, open label), IMO-8400, an antagonist of Toll-like receptor 7,8 and 9 (Ph II), abatacept (Phase IV, open label), and sodium thiosulfate (Phase II).\n"}
{"id": "50500819", "url": "https://en.wikipedia.org/wiki?curid=50500819", "title": "Digestible Indispensable Amino Acid Score", "text": "Digestible Indispensable Amino Acid Score\n\nDigestible Indispensable Amino Acid Score (DIAAS) is a protein quality method, proposed in March 2013 by the Food and Agriculture Organization to replace the current protein ranking standard, the Protein Digestibility Corrected Amino Acid Score (PDCAAS).\n"}
{"id": "44102865", "url": "https://en.wikipedia.org/wiki?curid=44102865", "title": "Disability in China", "text": "Disability in China\n\nDisability in China is common, and according to the United Nations, approximately 83 million people in China are estimated to have a disability.\n\nOf the total number of disabled individuals, men account for 42.77 million (51.55%) and women account for 40.19 million (48.45%), making the gender ratio 106.42 disabled men for every 100 disabled women. Furthermore, 20.71 million (25.96%) individuals of the disabled community reside in urban areas, whereas 62.25 million (75.04%) in rural areas.\n\nAccording to the China Disabled Persons' Federation, approximately 12.33 million (14.86%) people have visual disabilities, 20.04 million (24.16%) have a hearing disability, 1.27 million (1.53%) have a speech disability, 24.12 million (29.07%) have a physical disability, 5.54 million (6.68%) have an intellectual disability, 6.14 million (7.40%) have a mental disability, and 13.52 million (16.30%) have multiple disabilities.\n\nThere are currently only two published national sample surveys on disability conducted in China. The First National Sample Survey on Disability was published in 1987, and the Second was published in 2006. Over the past 19 years, there has been an increase in the total number of disabled individuals and in the proportion of disabled people to the total population.\n\nUsing the data from the two surveys, researchers found that the crude disability rate increased 1.5% from 1987 (4.89%) to 2006 (6.39%). However, once the data was adjusted to accommodate modified age structures and the change in population pyramid with the higher proportion of elderly in 2006, the adjusted disability rate increased by 0.5% over the time period. Although the frequency of visual, hearing, speech, physical, and intellectual disabilities did not depend on sex or place of residence (urban vs. rural) over time, there was an increase of mental disability across males, females, and rural residents that did not occur among urban inhabitants.\n\nThere has been a shift in the language used to describe individuals with disabilities, reflecting a gradual increase in social acceptance of disabilities in China. Historically, the general term for people with disabilities was \"can fei\" (残废), which means \"crippled and useless\". Currently, the widely used term is \"can ji\" (残疾), which means \"deformed\", although the China Disabled Persons' Federation is advocating the use of \"can zhang\" (残障), which means \"incomplete and obstructed\", as a more neutral term. However, many derogatory terms are still utilized in common vernacular to describe people with disabilities, such as \"sha zi\" (傻子), which means idiot.\n\nThe Law of the People's Republic of China on the Protection of Disabled Persons (1990) states that \"a disabled person refers to one who suffers from abnormalities or loss of a certain organ or function, psychologically or physiologically, or in anatomical structure and who has lost wholly or in part the ability to engage in activities in a normal way.\" This includes individuals with \"visual, hearing, speech or physical disabilities, mental retardation, mental disorder, multiple disabilities and/or other disabilities.\" The Law of the People's Republic of China on the Protection of Disabled Persons upholds the rights of individuals with disabilities in regards to employment opportunities, educational access, legal liability, and sufficient care.\n\nEnacted in 1982 (and later amended), the Constitution of the People's Republic of China ensured protection for individuals with disabilities: \"Citizens of the People's Republic of China have the right to material assistance from the State and society when they are old, ill or disabled. The State develops social insurance, social relief and medical and health services that are required for citizens this right… The State and society help make arrangement for the work, livelihood and education of the blind, deaf-mutes, and other handicapped citizens.\"\n\nIn 2008, the Regulations on the Employment of People with Disabilities promoted the employment of disabled individuals and safeguarded against their discrimination. It stated that the proportion of disabled employees should be at least 1.5%, although the number differed between provinces. Failure to meet this proportion would result in a fee to the employment security fund for disabled persons.\n\nIn 1986, the Compulsory Education Law mandated that every child is given the right to nine years of free public education: six years of elementary school and three years of secondary school.\n\nIn 1994, the Regulations on the Education of Persons with Disabilities aimed to promote access to education for individuals with disabilities, although according to Human Rights Watch, it \"failed to make adequate progress on mainstreaming children with disabilities into regular schools as required by international law.\"\n\nIn 2007, the United Nations Convention on the Rights of Persons with Disabilities was signed in China and outlined increased educational opportunity for children who had disabilities. The Convention emphasizes a human rights approach to disability and asserts that \"inclusive education\" is a fundamental human right.\n\nIn 1990, the Law on the Protection of the Disabled Persons stated that families and the community share the responsibility for taking care of individuals with disabilities.\n\nIn 1999, the World Health Organization (WHO) conducted an official mental health seminar with the Chinese government after which the government pledged to \"improve their leadership for and support of mental health care, strengthen inter-sectoral collaboration and cooperation, establish a mental health strategy and action plan, facilitate the enactment of a national mental health law, and protect patients' rights.\"\n\nIn 2002, the first National Mental Health Plan (2002-2010) was signed by the Ministries of Health, Public Security, and Civil Affairs and China Disabled Persons' Federation. The aims were: \"a) establishing an effective system of mental health care led by the government with the participation and cooperation of other sectors; b) acceleration the process of mental health legislation development and implementation; c) improving the knowledge and raising the awareness of mental health among all citizens; d) strengthening mental health services to decrease burden and disability; and e) developing human resources for mental health services and enhancing the capacity of current psychiatric hospitals.\"\n\nIn 2004, the Proposal on Further Strengthening Mental Health Word was passed and it explicitly outlines means of intervention for psychological issues, treatment for mental disorders, and protecting the rights of disabled individuals. It currently serves as the \"de facto Chinese mental health national policy.\"\n\nIn 2012, the Mental Health Law standardized mental health services, required hospitals to have services for counseling, and protected people from being treated against their will in psychiatric wards.\n\nIn 2005, the 5th National Five Year World Program for People with Disabilities (2005-2010) aimed to improve the accessibility of the Olympic and Paralympic Games in Beijing and increase convenience for individuals with disabilities in \"100 barrier free model cities\".\n\nSince the establishment of the People's Republic of China in 1949, the government has provided special education services, and the first schools for the blind and deaf were founded at this time. In 1980, the first training for special education teachers was started. In the 1990s, courses on special education were mandatory offerings in teacher training schools.\nThe majority (75.04%) of individuals with disabilities live in rural areas and it is difficult to access funds for these areas. Thus, the \"Learning in the Regular Classroom\" model, which integrates children with disabilities in classroom with children without disabilities, has become more popular and in 2003, approximately 67% of individuals with disabilities are in such schools. However, students with disabilities have been \"observed sitting alone, isolated from classroom activities, or have even remained at home, despite the fact that their names are on the registration list.\" Additionally, teachers in rural areas were not generally trained to teach students with disabilities. Vocational education for children with disabilities is limited to \"painting for students with hearing impairment, massage and weaving for students with visual impairments, and sewing for those with mental retardation.\"\n\nPresently, there are special schools set aside for children with disabilities. According to the China Disabled Persons' Federation, in 2009, there were 1,697 special schools for blind, deaf and intellectually disabled children. There were also 2,801 special classes in public schools. In total, 545,000 students are enrolled in special education.\n\nFamilies with children with disabilities face unique circumstances in raising their children. Parents have reported experiencing blatantly discriminatory behavior from outsiders due to their child's disability. Furthermore, public schools have been known to not accept children with disabilities, thus denying them the opportunity to access their right to education. It is also more expensive to raise children with disabilities compared to children without, and the annual cost burden varied across types of disabilities: around 6,400 RMB more for children with a mental disability, around 16,500 RMB for children with a physical disability, and around 20,000 more RMB for children with autism. A study shows that families with disabled children spend more money on medical and caring costs and less money on education, clothing, and amusement costs when compared with families without children with disabilities. Parents of children with disabilities also report high levels of stress due to meeting the daily needs of their child, interacting with the rest of society, and dealing with pessimism.\n\nTraditionally, disabled individuals in China were discriminated against and did not have access to assistance.\n\nThe 1980s and 1990s were a period of disability reform as the United Nations took an international stand on this topic. According to the College of William and Mary, \"these preliminary efforts in turn were advanced by support from Deng Pufang.\" Deng Pufang is the son of Deng Xiaoping, who is credited for implementing the Chinese economic reform to raise the living standards of individuals and reduce poverty in China. In 1968, Deng Pufang was detained by the Red Guards because his father was considered to be a political critic of Chairman Mao Zedong. After months of abuse and interrogation, \"Deng attempted suicide by throwing himself out of a third-story window.\" Although the fall did not kill him, he became paraplegic and relied on a wheelchair for mobility.\n\nHowever, due to his family's position of power, in 1988, Deng Pufang was able to advance the agenda for disabled individuals with the formation of the quasi-governmental organization, China Disabled Persons' Federation. He stated, \"My work has certainly been made more convenient as a consequence of my father. One of the most important ways has been that, whenever I've asked to meet with high-ranking officials, they've met with me. Whereas an average disabled person would not get an audience, I've been able to. That had to do with my father.\"\n\nChina Disabled Persons' Federation's mission is to promote development for disabled individuals, maintain equal and full participation in social life for disabled individuals, and allow individuals with disabilities to participate in social, material, and cultural achievements. In 2008, Deng Pufang won the UN Human Rights Prize for his work in promoting the rights for disabled individuals in China. , Deng Pufang remains the Honorary Chairperson on the Presidium of China Disabled Persons' Federation.\n\nChina has been one of the most successful nations at the Paralympic Games has it topped the Paralympics medal table from the 2004 Summer Paralympics.China has a medal tally of over 1000 at Paralympics history.\n\nThe 2008 Summer Olympics and 2008 Summer Paralympics were hosted in Beijing, China. Through this event, China modified existing infrastructure to be more convenient for individuals with disabilities, such as adding wheelchair lifts at subway stations, which was a part of a broader shift in attitude to be more accepting of individuals with disabilities. According to Qian Zhiling, professor of special education at Beijing Normal University, \"Thanks to the Paralympics, the Chinese public are now actively learning about disabled people, rather than, as previously, being horrified by and rejecting them. I think the impact will be long term: the public has realized they are able to do things and have rights just as everyone else does.\"\n\nChina's participation in the 2010 Asian Games and 2010 Asian Para Games led to similar changes. Because the Asian Para Games were held in Guangzhou in 2010, the stadiums were renovated to satisfy accessibility requirements and to be barrier-free for individuals with disabilities. According to Wang Xinxian, the president of the National Paralympic Committee of China, the Asian Para Games \"promote awareness of how disabled people take part in social and sports affairs,\" and also increased the public's awareness to the needs of individuals with disabilities for adequate treatment and political rights.\n\nChina has been participating at the Deaflympics regularly and has been one of the successful nations at the Deaflympics and has bagged 99 medals.\n"}
{"id": "44565754", "url": "https://en.wikipedia.org/wiki?curid=44565754", "title": "Dorothea of Mansfeld", "text": "Dorothea of Mansfeld\n\nCountess Dorothea of Mansfeld (1493–8 June 1578) was a German noblewoman and healer. She was well known around Germany for her medical recipes, mentorship, and generosity towards people of all social classes.\n\nDorothea of Mansfeld was a noblewoman, and one of the most famous female healers in Germany. She was born around 1493 and died in 1578. She was one of twelve children born to Count Philip of Solms-Lich and Adriana of Hanua Munzenberg. Dorothea's passion for medicine was influenced by her elder brother, Count Reinhard I of Solms-Lich, who was educated in medicine. Many of her family members were medical healers. This included her daughter (Dorothea of Schönberg), her niece (Anna of Hohenlohe), her daughter-in-law (Agnes of Solms), and her niece by marriage (Agnes of Solms). Dorothea married in 1512 to Count Ernst II of Mansfeld-Vorderort and had thirteen children. She became a widow at the age of 38 in 1531. Dorothea lived in the Mansfeld Castle with most of her family and children. While there, she possessed a well-stocked apothecary, a distilling house, and full garden of herbs and plants for her various recipes. The Mansfeld castle is located in Saxony-Anha, Germany. Before her move to Saxony, her location, much like information on her early life, is unknown. Most documentation on the Mansfeld region before the 19th century has been lost.\n\nDorothea was commonly known for her selfless service to people of all social classes. The most important aspect of her medical care was her altruistic acts of kindness towards the poor. She was a very charitable healer and her medical recipes were known to heal thousands of people from near and far. Despite being a widow, and therefore economically unstable, she used her healing abilities to heal both rich and poor people. She gave many gifts, and would often perform medical healing as an act of charity. With a humanist upbringing by her father, she learned to create relationships with noble people of both Catholic and Protestant background, she was also supportive to the Jewish community that tried to make a home in the Mansfeld area.\n\nIt was expected for noblewomen to have basic medical knowledge in order to provide assistance to anyone living on their estates. However, Dorothea extensively researched medical practices, and developed a knowledge that surpassed these narrow expectations. Her work gained fame when she was almost 80 years old. Many of Dorothea's recipes were referenced in medical recipe books, and her medical advice was sought out by many German princes and noblemen. Her most prized recipes were for two types of aqua vitae a white and a yellow version. Both were strong alcoholic beverages, the yellow slightly sweeter. These drinks were very popular because they could be used to treat multiple ailments. These recipes made use of distilled water, which was a popular medical treatment for the elite. The distillation process for any medicine took long periods of time from months to years. Dorothea was one of the earliest to create a distilling house on her property, and after her example many noblewomen followed. These distilleries were not only present on private properties but also at churches, monasteries, and other public locations. The garden at the Mansfeld castle grew many of the common ingredients that Dorothea used for her recipes such as herbs, flowers, fruits, and other plants.\n\nDorothea’s recipe books and any other copied works of hers were treasured not only because of her medical knowledge, but also because she had uniquely beautiful penmanship. The act of making books during this time period is described as a painstakingly long process that was done with patience, money, and practice. To write a book an author must have the time and resources to obtain all necessary supplies.\n\nExample recipe: Plague treatment recipes [Summer 1572]\n\nDorothea's relationship with Anna of Saxony was a noteworthy partnership. The two elite women are commonly known for their extensive experimentation with medical remedies Letters reveal this close relationship, and highlight that the two women in addition to creating medical recipes together, practiced other skills and visited often Anna of Saxony was the wife of a politician, and this relationship helped Dorothea financial situation immensely. Dorothea acted as a mentor and assistant to Anna, in turn Anna helped Dorothea’s recipes live on by passing them on to her children and sharing them long after Dorothea's death. Both noblewomen possessed their own personal distillation houses and gardens in which they grew the necessary herbs to create their medical remedies.\n\nDorothea's medical facility was very impressive at the time, and deserving of a detailed description in a book by Cyriacus Spangenber Spangenber talked highly of Dorothea's garden, library, and heavily stocked apothecary. Many of Dorothea's recipes were referenced in medical recipe books and she extended her medical expertise to German princes and other male medical professionals. Additionally, Anna of Saxony notes that Dorothea passed her medical knowledge on to a small group of female medical healers that included Dorothea of Schönberg, Anna of Hohenlohe, Agnes of Solms, and Magdlena of Mansfeld This group of women commonly visited Mansfeld Castle and referred to Dorothea as the \"mother of Mansfeld\" Medicine was often viewed as a feminine practice, therefore creating medical recipes was an acceptable activity for these noblewomen.\n\nAnother noteworthy relationship Dorothea had was with Martin Luther. Martin Luther had the best care available to him, yet he sought out the medical advice of Dorothea. By the time of her death, her medical practices were widely known throughout Germany.\n\n"}
{"id": "31426118", "url": "https://en.wikipedia.org/wiki?curid=31426118", "title": "Gaza Community Mental Health Programme", "text": "Gaza Community Mental Health Programme\n\nThe Gaza Community Mental Health Programme (GCMHP) is the leading Palestinian non-governmental organization which provides mental health services to the inhabitants of the Gaza Strip. The organization's stated purpose is committed to aid women, children, and victims of violence, torture, and human rights violations. The organization has over 135 employees, is involved with 18 international, regional and local coalitions and networks, and has treated over 20,000 clients.\n\nGCMHP was founded in 1990 by Eyad al-Sarraj. The head office is located in the Sheikh Ejleen neighborhood, across from the Gaza Municipality Beach Club. In 2008, the premises were damaged by Israeli shelling of a nearby Palestinian police station, forcing GCMHP to relocate temporarily to the Gaza Community Center.\n\nGCMHP's vision is to secure a Palestinian society that respects human rights and in which people are able to live in freedom and with dignity.\n\nGCMHP runs three community centers in Gaza City, Deir al-Balah and Khan Younis. The community centers offer psychotherapy for referred cases, rehabilitation, occupational therapy, EEG scans, physiotherapy, intelligence testing and crisis intervention.\n\nGCMHP research has shown that Palestinian children have developed feelings of hostility, anger, fear and frustration which has led to an increase of violence among school students. In response to this, GCMHP has implemented a school mediation program which aims to reduce the level of violence and to educate children in peaceful conflict resolution techniques. The programme also trains school counselors, teachers and parents in mediation techniques.\n\nGCMHP is active in the organization of psychosocially oriented summer camps for children, as well as recreational trips throughout the year.\n\nGCMHP enables Palestinian patients to receive medical treatment abroad by coordinating with Israeli associations that work in the human rights field. The organization also offers free telephone counseling.\n\nGCMHP offers a postgraduate diploma in Community Mental Health and Human Rights, as well as a diploma in Counseling and Psychological Support. Graduates of the diploma are equipped to facilitate the provision of mental health services in Gaza.\n\nIn addition to a number of awareness-raising brochures and leaflets, GCMHP publishes a bimonthly magazine called 'Amwaj'. The magazine focuses on mental health issues and is distributed to local organizations in the Gaza strip.\n\nThe Research Department is the first specialized center for research and documentation in the field of mental health in the Gaza Strip. The department has conducted over 68 research studies examining trauma and a variety of psychosocial phenomena. Research papers published in international journals include \"The Relations between Traumatic Experiences, Activity, and Cognitive and Emotional Responses Among Palestinian Children,\" \"Relationships between Traumatic Events, Children's Gender, and Political Activity, and Perceptions of Parenting Styles,\" \"Home Demolition and Mental Health: Victims and Witnesses,\" and \"Mental Health of Palestinian Women.\"\n\nGCMHP is funded by a consortium of overseas donors including the Swiss Agency for Development and Cooperation, the Ministry of Foreign Affairs of the Netherlands, the Rehabilitation and Research Centre for Torture Victims – Denmark (RCT), and the Swedish International Development Cooperation Agency (SIDA). There are also a number of other non-consortium donors including the Gaza Mental Health Foundation, founded in the USA in 2001 and Grassroots International (http://www.GrassrootsOnline.org), founded in 1983.\n\n"}
{"id": "23295366", "url": "https://en.wikipedia.org/wiki?curid=23295366", "title": "Health in Angola", "text": "Health in Angola\n\nHealth in Angola is rated among the worst in the world. Only a fraction of the population receives even rudimentary medical attention.\n\nFrom 1975 to 1992, there were 300,000 civil war-related deaths. The overall death rate was estimated at 240 per 1,000 in 2002. \n\nThe HIV/AIDS prevalence was 3.90 per 100 adults in 2003. As of 2004, there were approximately 240,000 people living with HIV/AIDS in the country. There were an estimated 521,000 deaths from AIDS in 2003. \n\nUSAID has reported that the Angolan government has not had much success in developing an effective health care system since the end of the 27-year-long Angolan Civil War in 2002. According to USAID, during the War as many as 1 million people were killed, 4.5 million people became internally displaced, and 450,000 fled the country as refugees. Due to lack of infrastructure and rapid urbanization, the government has been unable to promote programs that effectively address some of the basic needs of the people. Health care, specifically, is not available for many of the people in the country.\n\nSome improvements have been made regarding the health care system in Angola since the end of the Civil War. However, many problems continue to exist. According to UNICEF reports in 2005, 2 percent of the nation's public expenditures were allotted to health care. That number has increased since 2005. Larger problems include the shortage of doctors, the destruction of health care facilities throughout the country, and disparities between rural and urban primary care availability. \n\nCensus data reported by the CIA reveals that Angola has very few physicians to attend to the medical needs of its population. It is estimated that there are about 0.08 physicians per 1,000 people in Angola. \nDue to the length of the Angolan Civil War, nearly an entire generation of Angolans was not given the opportunity to receive any education. This has led to a dramatic decrease of health workers and added to the poor maternal health problem. In response to the shortage of health workers, Cuban physicians are currently working in the country to improve health overall, as well as to focus on improving maternal health.\n\nThe health care system has felt the social effects of the War. Due to the large number of people who were unable to receive an education during the War, today, educated medical personnel, administrators, and other needed positions in the governmental system are not able to be filled. The population of Angola has lost nearly an entire generation of educated personnel. This education gap has repercussions that have been felt throughout the society and especially in the health field.\n\nAs of 2012, 54% of the population had access to an improved water source and 60% had access to improved/shared sanitation.\n\nIn September 2014, the Angolan Institute for Cancer Control (IACC) was created by presidential decree, and it will integrate the National Health Service in Angola. The purpose of this new center is to ensure the health and medical care in oncology, policy implementation, programs and plans for prevention and specialized treatment. This cancer institute will be assumed as a reference institution in the central and southern regions of Africa.\n\nThe 2014 CIA estimated average life expectancy in Angola was 51 years.\n\nSource: \"UN World Population Prospects\"\n\nAngola lies in the yellow fever endemic zone. Cholera incidence is low.\n\nMalaria in Angola is very prevalent in the northern part of the country due to the climate and appears more seasonally in the south. The majority of the population lives in the northern areas, in cities such as Lunada. Malaria is a huge concern for maternal health, contributing about 25 percent of the total maternal mortality alone. In 2009, UNICEF, NMCP, WHO, and other organizations partnered together in an effort to reduce the malaria burden.\n\nIn 2008, the President of the United States Obama announced the Global Health Initiatives. One of these Initiatives includes the Malaria Operational Plan, which is a program that allocates funds to be used in order to improve health in Angola and other African countries afflicted with malaria. In Angola, the Malaria Operational Plan was implemented to decrease the number of women suffering from malaria and improve maternal health. Angola was one of the first countries to receive aid and to have programs implemented to reduce the risk of malaria, as well as increase the number of healthy pregnancies.\n\nDue to Angola's location, the climate is ideal for many tropical diseases. Angola has a narrow coastal plain that rises into a high plateau in the country's interior. Rain forests are prevalent in the north, and in the south, the land is dry. The CIA reports that malaria and schistosomiasis are prevalent in the country.\n\nThese diseases and others, such as tuberculosis and especially HIV/Aids, increase the complications and dangers faced by women during pregnancy. The incidence of tuberculosis in 1999 was 271 per 100,000 people.\n\nIn 2014, Angola launched a national vaccination campaign against measles, extended to every child under ten years old in all 18 provinces in the country. The measure is part of the Strategic Plan for the Elimination of Measles 2014–2020 created by the Angolan Ministry of Health which includes strengthening routine immunization, proper dealing with measles cases, national campaigns, introducing a second dose of vaccination in the national routine vaccination calendar and active epidemiological surveillance for measles. This campaign took place together with the vaccination against polio and vitamin A supplementation.\n\nAngola has a large HIV/AIDS infected population. The Joint United Nations Programme on HIV/AIDS (UNAIDS) estimated adult prevalence at the end of 2003 at 3.9% – over 420,000 infected people. Angola's 27-year civil war (1975–2002), deterred the spread of HIV by making large portions of the country inaccessible. Angola was thus cut off from most contact with neighboring countries that had higher HIV infection rates. With the end of the war, transportation routes and communication are reopening, therefore enabling a greater potential for the spread of HIV/AIDS. Current statistics indicate that the border provinces, especially certain areas bordering Namibia and the Democratic Republic of the Congo, currently have higher prevalence than the rest of the country.\n\nUnhealthy individuals and populations pose a higher risk of infections when exposed to pathogens. Sexually transmitted diseases, including HIV/AIDS, are no exception to this rule. Stillwaggon states that many of the populations in Sub-Saharan Africa have a high prevalence of malnutrition, malaria, parasite infections, and schistosomiasis. These health conditions increase an individual's susceptibility of contracting HIV/AIDS. In that region, social conditions also play a major role in HIV transmission. Poverty, inadequate nutrition, unclean water, poor sanitation, and unsafe health care all play a major role in the prevalence of AIDS.\n\nAngola represents one of the highest maternal death rates in the world. Results vary, but the estimated maternal mortality ratio (MMR) toward the end of the Civil War was between 1,281-1,500 maternal deaths to 100,000 live births. Despite the improvements that have been made, the Human Development Index for 2011 shows a poor level of maternal health in Angola. A high level of adolescent fertility and low use of contraceptives for women of all ages was reported. This is observed by the high total fertility rate. These factors contribute to an elevated risk of health problems during pregnancy and childbirth.\n\nIn 2004 the infant mortality was estimated at 187.49 per 1,000 live births, the highest in the world. Immunization rates for one-year-old children in 1999 were estimated at 22% for diphtheria, pertussis, and tetanus and 46% for measles. Malnutrition affected an estimated 53% of children under five years of age as of 1989. \n"}
{"id": "16541240", "url": "https://en.wikipedia.org/wiki?curid=16541240", "title": "Healthcare in Indonesia", "text": "Healthcare in Indonesia\n\nGovernment expenditure on healthcare in Indonesia is about 3.1 percent of its total gross domestic product.\n\nAccording to data from the Ministry of Health of Indonesia, there are 2454 hospitals around the country, with a total of 305,242 beds - a very low figure of 0.9 bed per 1,000 inhabitants. Most hospitals are in urban areas. Among these, 882 of these hospitals are government owned and 1509 are private hospitals. According to the Worldbank data in 2012, there are 0.2 physicians per 1,000 people, with 1.2 Nurses and Midwives per 1,000 people in Indonesia. Out of all the 2454 hospitals in Indonesia, 20 have been accredited by Joint Commission international (JCI) as of 2015. In addition, there are 9718 government financed Puskesmas (Health Community Centre) listed by the Ministry of Health of Indonesia, which provide comprehensive healthcare and vaccination for the population in the sub-district level. Both traditional and modern health practices are employed. \n\nIndonesia's community health system are organised in three tiers: on top of the chart is Community Health Centre (Puskesmas), followed by Health Sub-Centres on the second level, and Village-Level Integrated Posts at the third level.\n\nIn 2010, an estimated 56 percent of Indonesians, mainly state employees, low-income earners, and those with private coverage had some form of health insurance. The rate is expected to reach 100 percent by 2019, following the implementation of a system of universal social health insurance coverage that was launched in 2014. The aim is to grant free services for all hospitalisations in basic (class-3 hospital beds).\n\nHealthcare provision in Indonesia has traditionally been fragmented, with private insurance provision for those able to pay for it alongside basic public coverage for the poorest in society and NGOs working in specialised areas providing services to those not covered by public or private schemes. In January 2014, the Indonesian government launched Jaminan Kesehatan Nasional (JKN), a scheme to implement universal health care in Indonesia. It is expected that spending on healthcare will increase by 12% a year and reach US$46 billion a year by 2019. Under JKN, all Indonesians will receive coverage for a range of treatments via health services from public providers as well as those private organisations that have opted to join the scheme. The formally employed pay a premium worth five percent of their salary, with one percent being paid by the employee and four percent being paid by their employer. Informal workers and the self-employed pay a fixed monthly premium of between 25,500 and 59,500 IDR (£1.34-£3.12). However, the scheme has been criticised for being over-ambitious, a lack of competency in administration, and a failure to address the need for improving healthcare infrastructure in remote areas. An official for the programme's administering organisation, the social security agency Badan Penyelenggara Jaminan Sosial Kesehatan, has stated that JKN exceeded its target for enrolling members in its first year (registering 133.4 million members compared to a target of 121.6 million) and that, according to an independent survey, the customer satisfaction rate was 81 percent, awareness of JKN was 95 percent, and that complaints had been resolved within one and a half days on average. JKN is expected to be implemented in stages. When the initial stages came into effect in January 2014, 48% of the country's population became covered. As of April 2018, the scheme had 195 million enrollees (75% of the population). It is expected that the entire population will be covered in 2019.\n\nEleven percent of the country’s population suffers from mental disorders, with over 19 million of the people of age 15 or older. The neuropsychiatric disorders in Indonesia are estimated to contribute to 10.7% of global burden disease. There are definitely gaps in the mental health department that cannot be overlooked, with many of them are representative of the mental health gaps in Southeast Asia as a whole. The mental health policy in Indonesia was most recently revised in 2001. Since then, the nation has gone through enormous changes in all aspects as a country. Indonesia’s economy has been steadily growing in the past decade. Health wise, Indonesia has suffered numerous H5N1 outbreaks, with the highest number of recorded human cases of this virus in the world. The nation was severely affected by the tsunami tragedy in 2004. There are still many factors that have altered Indonesians’ lives, ultimately affecting the mental health status of the people greatly since 2001, calling for a more updated mental health policy.\n\nThere is very little amount of funding dedicated to mental health. The total health expenditure is 2.36%, and less than 1% of that goes towards mental health. Indonesia’s mental health legislation has the same issues mentioned above that Southeast Asia faces as a region. The legislation is far from what can be considered complete and fair, and the articles included are not well practised and reinforced. In 1966, Indonesia was well ahead of other countries in the region by having a mental health law separated from general health laws, providing potentials for expansion of the mental health system. However, the law was repealed in 1993 and integrated into general health laws. Mental health now only occupies four articles in the current health law. The articles are too general, causing difficulties to apply and implement. Article 26 states that almost anybody can request treatment and hospitalisation for persons with mental disorder, yet has no mention of the person's consent. By doing so, Article 26 creates an impression that mentally ill individuals are generally considered dangerous to the community because they need to be forced into treatment. This goes along with the negative stigmas associated with mental disorders mentioned above and elaborated later in this paper. Also, Article 27 states that the government will provide a presidential decree for regulations and management of mental health, yet nothing has been done.\n\nThere are also issues with accessibility and quality of mental health care. Official in-service training is not widely provided to the primary care professionals. WHO (2011) reports that between 2006 and 2011, the majority of primary care doctors and nurses have not received such training. There is also only one mental health hospital per five million people and one psychiatrist working in the mental health sector in ten million people. In addition to the unbalanced number of psychiatrists among population, the psychiatrists are also not well distributed in the country. Up until 2011, there were no psychiatrists in the rural area of Indonesia, while half of them are concentrated in the capital city, Jakarta, and the rest in the old capital city, Yogyakarta, and the second largest city, Surabaya. This creates a great barrier for mental health patients seeking official help.\n\nSee also Health in Indonesia\n"}
{"id": "9152302", "url": "https://en.wikipedia.org/wiki?curid=9152302", "title": "Hunter B. Shirley", "text": "Hunter B. Shirley\n\nHunter B. Shirley (December 25, 1927 – November 1, 2010) born Hunter Barentine Shirley, was a longtime licensed clinical psychologist and a former Associate Professor at Wisconsin State University where he headed a psychological research laboratory devoted to evaluating the world's first analog model of the mind. He was most recently the Director of the International Division of the American Institute of Applied Behavioral Research and Human Relations Training. Formerly Director of Behavior Analysis, Inc. of St. Louis subsequently he was director of the Counseling and Testing Center at the University of Louisiana at Lafayette, and later served as the Chief Clinical Psychologist of the Lafayette Institute of Behavior Therapy and Crisis Management. Author of a number of books, including the trail-blazing book \"Mapping the Mind\", and the popular self-help book \"Your Mind May Be Programmed Against You!\". He is credited with having developed the most sophisticated model of the human mind currently in existence. With offices in Staré Splavy near Prague, Shirley was in charge of a \"Think tank\" performing behavioral science research for NGOs and government agencies. His final work \"The Human Mind: A Guided Tour\", a comprehensive compilation of his theories on the emotional system and the human mind developed over a lifetime of clinical and field studies, is in the final phases of editing in preparation for publication. This book includes over 300 diagrams of the emotional system based on a cybernetics approach as he first presented in his book \"Mapping The Mind\" and in numerous published articles.\n\n\nHunter B. Shirley married Anne Shirley. He had three children Faustine, Remy and Raphaele Shirley. In 1995 he moved from Lafayette, Louisiana, where he held a private practice for over 15 years, to Central Europe. There he remarried Ava Shirley with whom he lived for the last ten years of his life until he died in 2010 in Česká Lípa in the Czech Republic.\n"}
{"id": "31696844", "url": "https://en.wikipedia.org/wiki?curid=31696844", "title": "International Journal of Computer Assisted Radiology and Surgery", "text": "International Journal of Computer Assisted Radiology and Surgery\n\nThe International Journal of Computer Assisted Radiology and Surgery (IJCARS) is a journal for cross-disciplinary research, development and applications of Computer Assisted Radiology and Surgery (CARS). The Journal promotes interdisciplinary research and development in an international environment with a focus on the development of digital imaging and computer-based diagnostic and therapeutic procedures as well enhance the skill levels of health care professionals.The International Society for Computer Aided Surgery (ISCAS) is involved in the publication of the IJCARS\n\n"}
{"id": "56845610", "url": "https://en.wikipedia.org/wiki?curid=56845610", "title": "Karadaiyan Nonbu", "text": "Karadaiyan Nonbu\n\nKaradaiyan Nonbu is a festival of special moment to married women across South India. It is celebrated on the first day of Pisces in the southern calendar as it represents the fish like shape of the eyes of Goddess Parvati. Her Birthday falls on the same day.\n\nThey worship Goddess Gowri and pray for longevity and well-being of husbands. Women try to echo the devotion and love shown by Savitri for her husband Satyavan. Married women fast that day. Before the auspicious time Women put Kolam before their pooja room, take bath and do the ceremony.They prepare a bhog made out of rice powder and jaggery and offer it to Goddess.Savitri's bakthi towards Goddess Gowri gave her the strength and wisdom to win back her Husband's life from Yama, the Lord of death. She won the battle not by arms or ammunition, but by her clever arguments.When Yama asked her to seek boons, she prayed for a thousand sons.After he agreed, Savitri sought the life of her dead Husband back to fulfill this wish.\n\nBhog is a special ada prepared out of riceflour, cowpea, jaggery and coconut. It is eaten with hot butter.\n"}
{"id": "20789967", "url": "https://en.wikipedia.org/wiki?curid=20789967", "title": "Linda Bartoshuk", "text": "Linda Bartoshuk\n\nLinda May Bartoshuk (born 1938) is an American psychologist. She is a Presidential Endowed Professor of Community Dentistry and Behavioral Science at the University of Florida. She is an internationally known researcher specializing in the chemical senses of taste and smell.\n\nBartoshuk grew up in Aberdeen, South Dakota. She received her B.A. from Carleton College and her PhD from Brown University.\nHer research explores the genetic variations in taste perception and how taste perception affects overall health. Bartoshuk was the first to discover that burning mouth syndrome, a condition predominantly experienced by postmenopausal women, is caused by damage to the taste buds at the front of the tongue and is not a psychosomatic condition. She was employed at Yale University prior to accepting a position at the University of Florida in 2005. She was elected a Fellow of the American Academy of Arts and Sciences in 1995. In 2003, she was elected to the National Academy of Sciences.\n\n"}
{"id": "27100562", "url": "https://en.wikipedia.org/wiki?curid=27100562", "title": "Lipozene", "text": "Lipozene\n\nLipozene is a brand name dietary supplement sold by Obesity Research Institute, LLC. The primary ingredient in Lipozene is glucomannan.\n\nLipozene contains a single ingredient, glucomannan, a water-soluble, fermentable dietary fiber extracted from the tuber or root of the elephant yam, also known as Konjac (\"Amorphophallus konjac\" or \"A. rivieri\").\n\nClinical trials examining the use of glucomannan for weight loss have produced mixed results. A 2014 systematic review and meta-analysis of clinical trials failed to show that glucomannan supplementation generated statistically significant weight loss. Obesity Research Foundation, LLC was fined $1.5 million by the Federal Trade Commission in 2005 for misleading statements about weight-loss results from a similar glucomannan-containing product.\n\nAdverse events include abdominal discomfort, diarrhea, and constipation.\n"}
{"id": "58609793", "url": "https://en.wikipedia.org/wiki?curid=58609793", "title": "List of anatomy mnemonics", "text": "List of anatomy mnemonics\n\nThis is a list of human anatomy mnemonics, categorized and alphabetized. For mnemonics in other medical specialities, see this list of medical mnemonics.\n\nAfferent connection arrives\" and an \"efferent connection exits\".\n\n\"The Hospitals Are Not Dirty Places\"\n\n\nRemember To Drink Cold Beer - Roots, Trunks, Divisions, Cords, Branches \n\n\"Dow Jones Industrial Average Closing Stock Report\"\n\nFrom proximal to distal:\n\nI See 10 CC's in the IV:\n\n\nO TOM CAT:\n\nO TOM are lateral wall components, in order from superior to inferior.\n\nCA are the components within the sinus, from medial to lateral. CA ends at the level of T from O TOM.\n\n\nLeft Hand Side (LHS):\n\n\n\n\"I Like To Rise So High\"\n\nStructures passing through greater sciatic foramen below piriformis (S.N.I.P. N.I.P.)\n\nStructures passing through lesser sciatic foramen: (P.I.N.T.) \n\na mnemonic to remember the contents of the Tarsal tunnel from anterior to posterior is \"Tom, Dick and Harry\". or alternatively \"Tom, Dick (and very nervous) Harry\" if the artery, vein, and nerve are included.\n\nThe branches of the subclavian artery can be remembered using VITamin C and D.\n\nThe contents of posterior mediastinum can be remembered using the mnemonic, \"DATES\"\n\n\"Standing room only\" can be used to remember that:\n\nContents of the foramen magnum: VAMPS-ATM\n\nDeep cerebellar nuclei and their positions relative to the midline: \"Fat Guys Eat Donuts,\" where each letter indicates the medial to lateral location in the cerebellar white matter\n\nA mnemonic to remember the muscles that contribute tendons to the pes anserinus and the innervations of these muscles is SGT FOT (sergeant FOT)\nNotice the order of the muscles (S, G, T) follows the order of the innervating nerves which correspond to those muscles (F, O, T)\n\nThe femoral triangle is shaped like the sail of a sailing ship and hence its boundaries can be remembered using the mnemonic, \"SAIL\":\n\nThe order of structures in the femoral triangle is important in the embalming of bodies, as the femoral artery is often exposed and used to pump embalming fluids into the body. The order of this neurovascular bundle can be remembered using the mnemonic, \"NAVY\":\n\nAn alternate to this mnemonic is \"NAVEL\" for Nerve, Artery, Vein, Empty Space and Lymph, to include the deep inguinal lymph nodes located medial to the Femoral vein.\n\nA useful mnemonic to remember popliteal fossa anatomy (medial-to-lateral arrangement) is: Serve And Volley Next Ball. \n\nThere are many mnemonics for the names of the cranial nerves, e.g.\n\n\n\nMany mnemonics are used for diaphragm apertures including:\n\n\n\"Counting 1 to 4 but staggered\":\n\nThe major glands of the endocrine system, excluding ovaries and testes: \"T-A-P.\" (T2, A3, P4)\n\nA good mnemonic to remember which muscles are innervated by what nerve is to paraphrase it as a molecular equation: LRSOR. \n\nAnother way to remember which nerves innervate which muscles is to understand the meaning behind all the Latin words.\n\n\n\nA simple mnemonic for remembering is \"See I? I see, I see,\" with \"see\" representing the C in \"contralateral,\" and \"I\" representing the I in \"ipsilateral.\" Another is \"Emily and Pete meet eye to eye\" as in \"M and P meet I to I,\" or again, Magno and Parvo meet Ipsi to Ipsi.\n\nAnother way of remembering is 2+3=5, which is correct, so ipsilateral side, and 1+4 doesn't equal 6, so contralateral.\n\nWANT My Hot Dog\n\n\nA mnemonic to remember the layers of the retina:\n\"My boyfriend's name is STEVE\":\n\nFor structures lying at the level of the sternal angle, the following mnemonic can be used:\n\nis a more detailed mnemonic including:\n\n\nSome Lovers Try Positions That They Can't Handle:\nScaphoid, Lunatum, Triquetrum, Pisiforme, Trapezium, Trapezoid, Capitate and Hamate\n\nShe Looks Too Pretty Try To Catch Her:\nScaphoid, Lunate, Triquetrum, Pisiforme, Trapezium, Trapezoid, Capitate and Hamate\n\nScabby Lucy Tried Pissing Hours after Copulating Two Twins:\nScaphoid, Lunate, Triquetrum, Pisiforme, Hamate, Capitate, Trapezoid, and Trapezium:\nIn clockwise order from Scaphoid-remember zoids do not touch each other. M. Hall\n\nSo Long To Pinky Here Comes The Thumb:\nStraight Line To Pinky Here Comes The Thumb:\nScaphoid, Lunatum, Triquetrum, Pisiforme, Hamate, Capitate, Trapezoid, Trapezium\n\nI Like Going Places Using My Very Own Unmanned Vehicle\n\nPosterior division:\n\nAnterior division:\n\n\"In Extremis, Cannibals Eat People's Globus Pallidi Instead of Their Hearts\":\n\nFrom insula to midline:\n\n"}
{"id": "55269694", "url": "https://en.wikipedia.org/wiki?curid=55269694", "title": "Lithuania at the Deaflympics", "text": "Lithuania at the Deaflympics\n\nLithuania has been participating at the Deaflympics since 1993 and has earned a total of 49 medals.\n\n\n"}
{"id": "19041370", "url": "https://en.wikipedia.org/wiki?curid=19041370", "title": "Living Human Project", "text": "Living Human Project\n\nThe Living Human Project (LHP) is a project that begun in 2002 to develop a distributed repository of anatomo-functional data and simulation algorithms for the human musculoskeletal apparatus used to create the physiome of the human musculoskeletal system. In 2006 the BEL was merged with Biomed Town, a Internet community for those who have a professional interest in biomedical research.\n\nThe LHDL project was ended in January 2009, and soon after the LHDL consortium released a biomedical data management and sharing service called \"Physiome Space\". Physiome Space lets individual researchers as well as for large consortia to share with their peers large collections of biomedical data, including medical imaging and computer simulations.\n\n\n"}
{"id": "22707918", "url": "https://en.wikipedia.org/wiki?curid=22707918", "title": "Medical cannabis in the United States", "text": "Medical cannabis in the United States\n\nIn the United States, the use of cannabis for medical purposes is legal in 33 states, plus the territories of Guam, Puerto Rico, and the Northern Mariana Islands, and the District of Columbia, as of November 2018. Fourteen other states have more restrictive laws limiting THC content, for the purpose of allowing access to products that are rich in cannabidiol (CBD), a non-psychoactive component of cannabis. There is considerable variation in medical cannabis laws from state to state, including how it is produced and distributed, how it can be consumed, and what medical conditions it can be used for.\n\nThe first state to effectively legalize medical cannabis was California in 1996, when voters approved Proposition 215 by a 56–44 margin. Several states followed with successful ballot initiatives in 1998, and in 2000 Hawaii became the first to legalize through an act of state legislature. By 2016, legalization of medical cannabis had spread to a majority of states.\n\nAt the federal level, cannabis remains a prohibited substance by way of the Controlled Substances Act of 1970. Under the CSA, the Drug Enforcement Administration classifies cannabis as a Schedule I drug, determined to have a high potential for abuse and no accepted medical use – thereby prohibiting its use for any purpose. The Justice Department has enforced this policy through various means, including criminal prosecutions, civil asset forfeiture, and paramilitary-style raids targeting medical cannabis providers, and various penalties threatened or initiated against other individuals involved in state-legal medical cannabis activities (doctors, landlords, state officials and employees). In December 2014, however, the Rohrabacher–Farr amendment was signed into law, prohibiting the Justice Department from spending funds to interfere with the implementation of state medical cannabis laws.\n\nPublic support for allowing the medical use of cannabis has remained strong since Gallup first polled the subject in 1999, finding 73% in favor. An August 2017 Quinnipiac poll found national support at 94%.\n\nThe medical use of cannabis dates back thousands of years, to ancient China, India, and Egypt. It was popularized in Western medicine by the Irish physician William Brooke O'Shaughnessy, who was introduced to the drug in the 1830s while living abroad in India. O'Shaughnessy documented a number of medical applications for cannabis from the experiments he conducted, noting in particular its analgesic and anticonvulsant effects. He returned to England with a supply of cannabis in 1842, after which its use as medicine quickly spread throughout Europe and the United States.\nCannabis was entered into the United States Pharmacopeia in 1850, as a treatment for neuralgia, tetanus, typhus, cholera, rabies, dysentery, alcoholism, opiate addiction, anthrax, leprosy, incontinence, snakebite, gout, convulsive disorders, tonsillitis, insanity, excessive menstrual bleeding, and uterine bleeding. It was widely available in pharmacies and even grocery stores during the latter half of the 19th century, priced affordably relative to other drugs with no requirement for a doctor's prescription. Cannabis was commonly sold in tincture form by Parke-Davis, Eli Lilly, E. R. Squibb & Sons, and other drug manufacturers.\n\nBy the end of the 19th century, the use of cannabis in medicine had declined due to a number of factors, including difficulty in controlling dosages and the rise in popularity of synthetic and opium-derived drugs. The advent of the hypodermic syringe also allowed these drugs to be injected for immediate effect, in contrast to cannabis which is not water-soluble and therefore cannot be injected. Additionally, as fears regarding the recreational use of cannabis began to take hold (prompted by sensationalist media reports and government propaganda campaigns), states began passing legislation to restrict the sale and possession of cannabis, eliminating its availability as an over-the-counter drug. By 1936, every state had passed a law of this manner.\n\nThe use of cannabis as medicine further declined with the passage of the Marihuana Tax Act of 1937. The purpose of the act was to prohibit all non-medical use of cannabis in the U.S.; however, it also had the effect of severely curtailing medical use of the drug, due to new fees and regulatory requirements put in place that imposed a significant burden on doctors prescribing cannabis. For this reason the American Medical Association opposed the Marihuana Tax Act of 1937, but to no avail. Cannabis was removed from the U.S. Pharmacopeia in 1941, at the urging of famed anti-cannabis crusader Harry Anslinger.\n\nDuring the 1960s, as large numbers of people began to use cannabis recreationally, the medical utility of cannabis was rediscovered by some as anecdotes began to appear about its effectiveness in treating a variety of medical conditions. It was officially banned for even medical use, however, following the passage of the Controlled Substances Act in 1970. Despite the strict federal prohibition in place, cannabis continued to gain renewed interest as medicine in the 1970s and 1980s, in particular due to the testimonials of cancer and AIDS patients who reported significant relief from the effects of chemotherapy and wasting syndrome. The smoking method of consumption – popularized by recreational users of the drug – offered particular aid to patients who had trouble keeping down oral medication (without vomiting), and also offered advantages in terms of rapid onset of action and the ability to more carefully control dosages.\n\nOn October 27, 1970, the Comprehensive Drug Abuse Prevention and Control Act of 1970 was signed into law by President Richard Nixon. Title II of the act – the Controlled Substances Act – established a system under which all controlled substances are categorized, varying from Schedule I (the strictest classification) to Schedule V (the least strict). Cannabis was placed in the Schedule I category, assumed to have a high potential for abuse and no accepted medical use – thereby prohibiting its use for any purpose. This placement was intended only as a temporary measure, however, pending the results of a commission formed under decree of the CSA to study the dangers of cannabis. Formally known as the National Commission on Marihuana and Drug Abuse, the Shafer Commission – led by former Pennsylvania governor Raymond P. Shafer – determined in its March 1972 report to the President and Congress that the societal harms caused by cannabis were limited, and recommended removal of criminal penalties for possession and distribution of small amounts of the drug. Although the report did not specifically address the scheduling of cannabis, it did not contain any findings that supported continued placement in the Schedule I category, and members of the commission acknowledged that cannabis did not meet the Schedule I criteria. This was of no consequence, however, as President Nixon firmly rejected the findings of the commission, and no action was taken to move cannabis into a less restrictive category. The Schedule I classification of cannabis remains in place today, alongside other drugs such as heroin, LSD, MDMA, DMT, and peyote – none of which can be prescribed. Schedule II drugs – determined to have a high potential for abuse but also some accepted medical use (thus able to be prescribed) – include cocaine, PCP, methamphetamine, oxycodone, and fentanyl.\n\nSince enactment of the Controlled Substances Act, there have been a number of efforts seeking to have cannabis placed in a less restrictive category, but none have succeeded. The Drug Enforcement Administration is granted authority under the CSA to change the classification of any drug, based upon the recommendation of the Food and Drug Administration which evaluates all drugs for safety and efficacy. As recently as 2016, the FDA has determined that cannabis has \"no currently accepted medical use in treatment in the United States\", in response to a petition filed with the DEA in 2011 by the governors of Washington and Rhode Island. Previous efforts to petition the DEA for rescheduling have also been unsuccessful, spanning the years 1972–1994, 1995–2001, and 2002–2013. Congressional attempts to reschedule have failed as well, including a 1981 bill introduced by Reps. Stewart McKinney and Newt Gingrich that grew to 84 cosponsors but never received a floor vote.\n\nThe classification of cannabis as a Schedule I drug was first challenged by the National Organization for the Reform of Marijuana Laws (NORML) in a 1972 petition to the Bureau of Narcotics and Dangerous Drugs (which was merged with other agencies to form the DEA in 1973). After a decade of legal battles in which the DEA refused to consider the petition, public hearings were finally held on the matter beginning in 1986. In September 1988, after two years of extensive public hearings, DEA Chief Administrative Law Judge Francis L. Young ruled in favor of moving cannabis to a Schedule II classification, finding that \"Marijuana, in its natural form, is one of the safest therapeutically active substances known to man.\" Young concluded: \"The evidence in this record clearly shows that marijuana has been accepted as capable of relieving the distress of great numbers of very ill people, and doing so with safety under medical supervision. It would be unreasonable, arbitrary and capricious for [the] DEA to continue to stand between those sufferers and the benefits of this substance in light of the evidence in this record.\" As Young's ruling was only a non-binding recommendation, however, it was rejected by DEA Administrator John Lawn in December 1989. In February 1994, a final ruling on the original 1972 petition was issued when a U.S. Court of Appeals upheld the decision to keep cannabis a Schedule I drug.\n\nDespite an official policy denying the medical value of cannabis, the federal government began providing the drug to a limited number of patients through the Compassionate Investigational New Drug program in 1978. The program was created following a lawsuit filed by Robert Randall, a Washington, D.C. resident who was arrested for cultivating cannabis in 1975. Citing the glaucoma that threatened to take his eyesight, Randall employed a medical necessity defense at trial to justify his use of cannabis. The charges against Randall were dismissed, and as a result of an ensuing petition filed with the FDA, Randall became the first person to receive cannabis from the federal government in 1976. After his supply was cut off in 1978, he filed a lawsuit to have it restored, setting in motion the creation of the Compassionate Investigational New Drug program shortly thereafter. The program allowed patients with serious medical conditions to receive a regular supply of cannabis from the federal government; however, only 13 patients ended up participating due to the very complicated and drawn-out application process involved.\n\nThe Compassionate IND program was closed to new patients in 1992, due to a flood of new applications from AIDS patients and concerns that the program undercut Bush administration efforts to discourage illegal drug use. James O. Mason, the head of U.S. Public Health Service, explained that keeping the program in place created the perception that \"this stuff can't be so bad\", and noted that AIDS patients provided with cannabis would be more likely to engage in unsafe sex. Twenty-eight applications that had recently been approved were rescinded, and only the 13 patients who were already receiving cannabis were allowed to do so moving forward. As of 2016, most of the original 13 patients had perished, but at least two were still known to be receiving cannabis from the federal government.\n\nConcurrent with the re-election of President Bill Clinton in November 1996, California voters approved Proposition 215 to legalize the medical use of cannabis, and a similar (but ultimately ineffective) measure was passed in Arizona. In response, the Clinton administration reiterated its firm opposition to the medical use of cannabis, and threatened to revoke the prescription-writing abilities of doctors who recommend or prescribe the drug. Additionally, threats were made to criminally prosecute physicians, and ban them from participating in Medicare and Medicaid. A group of physicians challenged this policy as a violation of First Amendment rights, and in September 2000 prevailed in the case \"Conant v. McCaffrey\", which affirmed the right of physicians to recommend (but not prescribe) cannabis. Prior to the ruling, an April 1997 preliminary injunction prevented the administration from taking these actions.\n\nApart from the threatened crackdown on physicians, the administration conducted raids on a number of medical cannabis providers, leading to the filing of civil and criminal charges. At trial, prosecutors were set to easily secure convictions, as jurors could not be informed that the cannabis was for medical use authorized under state law. Drug czar Barry McCaffrey also railed strongly against the medical use of cannabis – deriding it as \"Cheech & Chong medicine\" – and worked behind closed doors to coordinate a media campaign to sway public opinion against approving further initiatives.\n\nDespite previously speaking in support of states' rights on the issue of medical cannabis, President George W. Bush escalated efforts to enforce federal law during his 8 years in office, with more than 260 raids conducted and 84 individuals prosecuted by his administration. Heavy use of paramilitary tactics and gear was common in execution of the raids, along with the frequent use of civil forfeiture, allowing cash and property to be seized without need for criminal conviction. In 2007, the administration began targeting landlords renting to medical cannabis facilities, informing property owners that they faced up to 20 years in prison for violating the \"crack house statute\" of the CSA, in addition to seizure of their properties. Drug czar John P. Walters was particularly active in opposing the medical use of cannabis, campaigning against initiatives in a number of states in what medical cannabis advocates charged was an inappropriate use of taxpayer dollars and a violation of the Hatch Act. During Bush's second term, in June 2005, the Supreme Court ruled in favor of the federal government's ability to enforce federal law in states that have legalized medical cannabis, in the case \"Gonzales v. Raich\".\n\nThe presidency of Barack Obama was noted for a strong federal crackdown on medical cannabis during his first term in office, despite early indications that his administration would take a more hands-off approach. During his 2008 campaign for president, Obama expressed support for allowing states to implement their own medical cannabis policies, stating: \"I'm not going to be using Justice Department resources to try to circumvent state laws on this issue.\" These comments were then echoed by the administration in March 2009 when Attorney General Eric Holder stated that only medical cannabis providers \"who violate both federal and state law\" would be targeted for prosecution. Additionally, an October 2009 memo from Deputy Attorney General David Ogden laid out further guidelines for federal enforcement that largely affirmed this earlier-stated hands-off approach. Despite these pronounced intentions of lessened enforcement from the Obama administration, however, an increasing number of raids were conducted during Obama's first two years in office, surpassing even the Bush administration in frequency.\nFederal enforcement efforts against medical cannabis were further escalated in early 2011, as a campaign of coercing state and local governments was initiated by the Justice Department. Letters were sent out by U.S. Attorneys to a number of state and city officials, threatening to criminally prosecute these individuals if the implementation of new medical cannabis laws moved forward. Some letters also threatened prosecution of state employees, or even the seizure of state administrative buildings (such as those used for the processing of medical cannabis licenses). In response to outcry and requests for clarification from numerous officials, a new memo was issued by Deputy Attorney General James M. Cole in June 2011. The Cole memo insisted that the 2009 Ogden memo was being adhered to, and that the Ogden memo's protections applied only to individual patients and not commercial operations. As the raids continued following release of the Cole memo, U.S. Attorneys sent out hundreds more letters over the next two years, threatening landlords with criminal prosecution and seizure of property for renting to medical cannabis providers. By June 2013, the total cost of the Obama administration crackdown on medical cannabis had climbed to $289 million, surpassing the previous 8 years of the Bush administration by $100 million. And the number of raids conducted during Obama's first 4 1/2 years had reached 270, in contrast to 260 during Bush's 8 years.\n\nEarly in President Obama's second term, in August 2013, the Justice Department issued a new Cole memo setting forth the conditions under which federal law would be enforced. The memo was prompted in particular by the recent legalization of non-medical cannabis in Washington and Colorado, but also addressed enforcement in medical cannabis states. Regarding the medical use of cannabis, the memo was considered to take a significantly more deferential approach towards the states (compared to the 2011 Cole memo), similar in nature to how the 2009 Ogden memo was originally widely interpreted. Federal enforcement efforts were further scaled back with the enactment of the Rohrabacher–Farr amendment in December 2014, although the Justice Department initially continued with a number of prosecutions until a pair of court rulings determined it was interpreting the amendment incorrectly.\n\nOn December 16, 2014, a landmark victory was achieved for medical cannabis at the federal level with the signing into law of the Rohrabacher–Farr amendment. Initially introduced by Rep. Maurice Hinchey in 2001, the amendment prohibits the Justice Department from spending funds to interfere with the implementation of state medical cannabis laws. It failed 152–273 upon its initial vote in 2003, and was defeated five more times over the next decade until it passed the House by a 219–189 margin on May 30, 2014, as an attachment to the CJS Appropriations bill for fiscal year 2015. It did not receive a vote in the Senate, but was inserted into the $1.1 trillion \"cromnibus\" spending bill during final negotiations, which became law with President Obama's signature on December 16, 2014. The Rohrabacher–Farr amendment passed the House by an even larger margin (242–186) in June 2015, then won approval in a 21–9 Senate Appropriations Committee vote, and was signed into law as part of the FY 2016 omnibus appropriations bill on December 18, 2015. The amendment was subsequently included in a series of spending bills with the most recent extension effective through December 7, 2018.\n\nAlthough the Rohrabacher–Farr amendment offers important protections for state-legal medical cannabis activities, it does not change the legal status of cannabis, and must be renewed each fiscal year in order to remain in effect. The Justice Department has also interpreted the amendment in a manner vastly different from the authors' intent, which it has used to justify a number of raids and prosecutions after the law's enactment. U.S. District Judge Charles Breyer ruled against the Justice Department in October 2015, however, stating that the DOJ interpretation \"defies language and logic\" and \"tortures the plain meaning of the statute\", and was \"counterintuitive and opportunistic\". The Ninth Circuit Court of Appeals similarly rejected the DOJ's arguments in an August 2016 ruling.\n\nDue to increasing public awareness of the medical benefits of cannabis, and in anticipation of forthcoming changes to federal policy, a number of states passed laws in the late 1970s and early 1980s addressing the medical use of cannabis. New Mexico was the first to do so in 1978, and by the end of 1982 over thirty states had followed suit. The majority of these laws sought to provide cannabis through federally-approved research programs administered by the states, using cannabis supplied by the National Institute on Drug Abuse. Only seven states ended up implementing the programs, however, due to the large bureaucratic and regulatory obstacles imposed by the federal government. Other states passed legislation allowing doctors to prescribe cannabis, or reclassifying cannabis in a state's internal drug scheduling system. These laws were largely ineffectual though, due to the continued prohibition of medical cannabis at the federal level. A few states passed laws affirming the right of individuals to present a medical necessity defense at trial. By the mid-80s, however, efforts to pass new medical cannabis laws had ground to a halt, and a number of existing laws were either repealed or allowed to expire.\n\nMedical cannabis advocates began to gain ground in the early 1990s with a series of legislative achievements in the state of California. Proposition P was approved by 79% of San Francisco voters in November 1991, calling on state lawmakers to pass legislation allowing the medical use of cannabis. Additionally, the city board of supervisors passed a resolution in August 1992 urging the police commission and district attorney to \"make lowest priority the arrest or prosecution of those involved in the possession or cultivation of [cannabis] for medicinal purposes\" and to \"allow a letter from a treating physician to be used as prima facia evidence that marijuana can alleviate the pain and suffering of that patient's medical condition\". The resolution allowed the open distribution of cannabis to AIDS patients and others throughout the city, most notably through the San Francisco Cannabis Buyers Club which was operated by medical cannabis activist Dennis Peron (who spearheaded Proposition P and later the statewide Proposition 215). Similar clubs appeared outside San Francisco in the ensuing years as other cities passed legislation to support the medical use of cannabis. The Wo/Men's Alliance for Medical Marijuana was founded in 1993 after 75% of Santa Cruz voters approved Measure A in November 1992. And the Oakland Cannabis Buyers' Cooperative was founded in 1995 shortly before the city council passed multiple medical cannabis resolutions.\n\nFollowing the lead of San Francisco and other cities in California, state lawmakers passed Senate Joint Resolution 8 in 1993, a non-binding measure calling on the federal government to enact legislation allowing physicians to prescribe cannabis. In 1994, Senate Bill 1364 was approved by state legislators, to reclassify cannabis as a Schedule II drug at the state level. And Assembly Bill 1529 was approved in 1995, to create a medical necessity defense for patients using cannabis with a physician's recommendation, for treatment of AIDS, cancer, glaucoma, or multiple sclerosis. Both SB 1364 and AB 1529 were vetoed by Governor Pete Wilson, however, paving the way for the passage of Proposition 215 in 1996.\n\nFrustrated by vetoes of medical cannabis bills in successive years, medical cannabis advocates in California took the issue directly to the voters, collecting 775,000 signatures for qualification of a statewide ballot initiative in 1996. Proposition 215 – the Compassionate Use Act of 1996 – was subsequently approved with 56% of the vote, legalizing the use, possession, and cultivation of cannabis by patients with a physician's recommendation, for treatment of cancer, anorexia, AIDS, chronic pain, spasticity, glaucoma, arthritis, migraine, or \"any other illness for which marijuana provides relief\". The law also allowed patient caregivers to cultivate cannabis, and urged lawmakers to facilitate the \"safe and affordable distribution of marijuana\".\n\nAlso in 1996, 65% of Arizona voters approved Proposition 200, a drug policy reform initiative containing a provision allowing the use of cannabis with a doctor's prescription. The medical cannabis portion of the initiative was then essentially repealed by state legislators a few months later, but the change was rejected by Arizona voters in a 1998 veto referendum. Ultimately the medical cannabis provision was ineffective, however, due to language that created significant conflict with federal law (use of the word \"prescribe\" instead of \"recommend\").\n\nIn 1998, medical cannabis initiatives were voted on in the states of Washington, Oregon, Alaska, and Nevada – all of which passed. Also, in Washington, D.C., Initiative 59 to legalize the medical use of cannabis passed with 69% of the vote, but a series of amendments introduced by Rep. Bob Barr and approved by Congress prevented its implementation for over a decade. The initial Barr amendment was enacted prior to the November 1998 election but after ballots had been printed, thereby allowing D.C. residents to vote on the initiative but preventing the results from being made public. The amendment was challenged in court by the American Civil Liberties Union on grounds that it violated First Amendment rights, and in September 1999 U.S. District Court Judge Richard W. Roberts agreed, overturning the Barr amendment. Rep. Barr then introduced a similar amendment which became law in November 1999, setting off a long legal battle until finally in December 2009 the Barr amendment was removed from the annual D.C. appropriations bill, allowing the original 1998 ballot initiative to move forward.\nFollowing the approval of several ballot measures in 1998, Maine voters passed a medical cannabis initiative in 1999 that was expanded by both state legislature and another ballot initiative in subsequent years. In 2000, medical cannabis initiatives were passed in the states of Colorado and Nevada, with Nevada's initiative passing for a second consecutive election as required to amend the state's constitution. Also in 2000, Hawaii became the first state to legalize medical cannabis through an act of state legislature.\n\nIn the following years, medical cannabis was legalized by ballot measure in Montana (2004), Michigan (2008), Arizona (2010), Massachusetts (2012), Arkansas (2016), Florida (2016), North Dakota (2016), Oklahoma (2018), Missouri (2018), and Utah (2018) and by state legislature in Vermont (2004), Rhode Island (2006), New Mexico (2007), New Jersey (2010), Delaware (2011), Connecticut (2012), New Hampshire (2013), Illinois (2013), Maryland (2014), Minnesota (2014), New York (2014), Pennsylvania (2016), Louisiana (2016), Ohio (2016), and West Virginia (2017). Seventeen states have legalized by ballot measure and 16 have by state legislature, for a total of 33 states according to the National Conference of State Legislatures (although some dispute the effectiveness of Louisiana's law, thus considering there to be only 32). The U.S. territories of Guam (2014 – ballot measure), Puerto Rico (2015 – executive order), and the Northern Mariana Islands (2018 – legislature) have also legalized the medical use of cannabis.\n\nIn addition to states that have passed comprehensive medical cannabis laws, a number of states have passed more restrictive laws that limit the allowable concentration of tetrahydrocannabinol (THC), the main psychoactive component of cannabis. The purpose of these laws is to allow for the use of cannabidiol (CBD), a non-psychoactive cannabinoid that has been shown to be effective in the treatment of seizure disorders, particularly in children. The use of CBD to treat seizure disorders gained increased attention with a number of media reports in 2012 and 2013, and by the end of 2015 sixteen states had \"low-THC, high-CBD\" laws in effect. Additionally, two states (Indiana and Kansas) have since passed laws to allow the use of CBD without need for a doctor's consultation.\n\nCurrently, all but three states explicitly allow the legal use of CBD in some form, whether through doctor's recommendation, doctor's prescription (Epidiolex), or without the need for either.\n\nAs a Schedule I drug in the U.S., clinical research on cannabis must be approved by the Food and Drug Administration, and a license (also referred to as a \"registration\") must be obtained from the Drug Enforcement Administration specific to conducting research on Schedule I drugs. The petition to the FDA is submitted in the form of an Investigational New Drug application, which the FDA has 30 days to respond to. DEA research registrations are issued for Schedule I and Schedule II–V drugs, with the Schedule I registration mandating stricter compliance requirements such as the manner in which substances are stored and secured. The DEA licensing process can take over a year to complete.\n\nIn addition to FDA approval and DEA registration, other requirements have been imposed for cannabis research that do not exist for any other drug, which has had a significant effect in limiting the amount of research conducted. One such requirement was established in 1999 when it was mandated that all proposed research be submitted to the U.S. Public Health Service for approval. This was of particular burden to researchers as there was no timeline in which PHS was required to respond, with some reviews taking years to complete. In June 2015 the PHS review was eliminated, however, to better streamline the process for approving medical cannabis research.\n\nClinical research on cannabis also requires approval from the National Institute on Drug Abuse, which has had an additional effect in impeding medical cannabis research. The stated mission of NIDA is to support research on the causes, consequences, prevention, and treatment of drug abuse and drug addiction, and not the medicinal uses of drugs. Consequently, many studies on the therapeutic benefits of cannabis are either denied or altered to comply with the limited scope and mission of NIDA. There is also no timeline in which NIDA is required to respond to proposals (as with the PHS review), which has resulted in delays in getting research approved ranging from months to years. Additionally, the cannabis provided by NIDA has been criticized as being inferior to that which is commonly used by medical cannabis patients in states where it is legal. Criticisms of NIDA-supplied cannabis include high amounts of stems and seeds, high mold and yeast levels, low THC content, and low diversity of strains available.\n\nSince the agency's inception in 1974, NIDA has been the sole provider of cannabis for research purposes in the U.S., contracting with the University of Mississippi for cultivation of the cannabis. The monopoly has been maintained by the refusal of the Drug Enforcement Administration to issue additional licenses for the cultivation and distribution of cannabis, which the DEA has claimed is consistent with the terms of the U.N. Single Convention on Narcotic Drugs that was ratified in 1961. Others have disputed this interpretation of the treaty however (including the U.S. State Department), and the DEA's interpretation is not consistent with the fact that multiple licenses have been issued for the production of other Schedule I drugs. The DEA has also cited the possibility of diversion from cultivation facilities as justification for not issuing additional licenses.\n\nCritics of the NIDA monopoly have pointed to the case of University of Massachusetts Amherst professor Lyle Craker as an example of the DEA's undue resistance to granting additional cultivation licenses. Professor Craker's endeavor to obtain a license began in June 2001, when he submitted an application to the DEA, which, later in 2001, the DEA claimed to have lost. After a photocopy was resubmitted, the DEA rejected the application in February 2002 because it did not have an original signature. In July 2002, the original application was returned to Professor Craker unprocessed, with a date stamp showing it had been received in June 2001. The application was then resubmitted in August 2002, upon which the DEA confirmed receipt. On July 24, 2003, a notice regarding Craker's application was filed in the Federal Register, with a public comment period ending on September 23, 2003. In October 2003, U.S. Senators John Kerry and Ted Kennedy wrote a letter to DEA Administrator Karen Tandy expressing support for granting Professor Craker a license. On December 10, 2004, however, following a lawsuit filed over unreasonable delay in responding to the application, the DEA rejected Craker's application. Professor Craker then filed another lawsuit in response to the rejection, and also requested a hearing on the matter from a DEA Administrative Law Judge, which was granted. On February 12, 2007, after almost two years of extensive public testimony and evidence gathering, DEA Administrative Law Judge Ellen Bittner issued an 87-page opinion in favor of granting Professor Craker a license. Additionally, 45 members of Congress wrote to DEA Administrator Karen Tandy in September 2007 urging that the decision be upheld. In January 2009, however, Acting DEA Administrator Michele Leonhart rejected the recommended ruling of Judge Bittner and declined to issue a license. In response, 16 members of Congress wrote to Attorney General Eric Holder in February 2009, asking that the Leonhart ruling be withdrawn. An additional letter was sent by Sens. John Kerry and Ted Kennedy in April 2009. The ruling was upheld by Leonhart in an August 2011 decision, however, and again by the First Circuit Court of Appeals in April 2013.\n\nOn August 11, 2016, the DEA announced intention to issue additional licenses for the cultivation of research-grade cannabis, which would end the decades-long monopoly held by NIDA and the University of Mississippi. As of July 2017, however, 25 applications have been submitted to the DEA and none have been approved, with no timeline given by the DEA for approval of any licenses.\n\nAmericans for Safe Access is the leading advocacy group in the U.S. dedicated to medical cannabis policy reform. Founded in 2002 by medical cannabis patient Steph Sherer, it has grown to over 100,000 members in 50 states. Other groups include the National Organization for the Reform of Marijuana Laws, Marijuana Policy Project, and Drug Policy Alliance, although these focus more broadly on policy reform regarding both medical and non-medical use.\n\nMedical organizations that have issued statements in support of allowing patient access to medical cannabis include the American Nurses Association, American Public Health Association, American Medical Student Association, National Multiple Sclerosis Society, Epilepsy Foundation, Leukemia & Lymphoma Society, National Women's Health Network, , and several AIDS advocacy organizations.\n\nReligious denominations in the U.S. that have voiced support for allowing the medical use of cannabis include the Episcopal Church, Presbyterian Church (USA), United Church of Christ, United Methodist Church, Union for Reform Judaism, and the Unitarian Universalist Association.\n\nAmerican Legion, the nation's largest military veterans organization, passed a resolution at their September 2016 annual convention calling on Congress to remove cannabis from the list of Schedule I drugs. In December 2016, the organization lobbied the incoming Trump administration to reclassify cannabis as a Schedule III drug.\n\nThe National Conference of State Legislatures, National League of Cities, and U.S. Conference of Mayors have all called for cannabis to be removed from the list of Schedule I drugs. The National Association of Counties has called on Congress to \"enact legislation that promotes the principles of federalism and local control of cannabis businesses ... under state law\".\n\nDelegates at the 2016 Democratic National Convention voted to approve a party platform calling for cannabis to be removed from the list of Schedule I drugs.\n\nIndividuals who have been particularly active in efforts to support the medical use of cannabis include Robert Randall, Dennis Peron, Ed Rosenthal, Steve Kubby, Steve DeAngelo, Richard Lee, Jon Gettman, Brownie Mary, and Tod H. Mikuriya. Former talk show host Montel Williams is a well-known advocate who uses cannabis to treat his multiple sclerosis, a topic he has testified about in a number of states considering medical cannabis legislation. Former U.S. Surgeon General Joycelyn Elders has also testified in support of medical cannabis legislation in several states.\n\nMembers of Congress who have introduced legislation to allow the medical use of cannabis include Ron Paul, Barney Frank, Maurice Hinchey, Sam Farr, Dana Rohrabacher, Steve Cohen, Don Young, Jared Polis, Earl Blumenauer, Tom Garrett, Rand Paul, and Bernie Sanders. Rep. Rohrabacher (R–CA) has been particularly active in congressional reform efforts, introducing multiple medical cannabis bills including the Rohrabacher–Farr amendment for a number of years until it became law in 2014. He also uses a cannabis-based drug to relieve the symptoms of his arthritis.\n\nEugene Monroe, Derrick Morgan, Kyle Turley, and Jim McMahon are among a group of NFL players that have advocated for allowing the use of cannabis in the league, as a treatment option for concussions and a pain reliever that can reduce reliance on addictive opioid drugs. NBA head coach Steve Kerr has also voiced support for the medical use of cannabis in professional sports.\n\nDr. Sanjay Gupta, neurosurgeon and chief medical correspondent for CNN, has produced a four-part documentary series for the network – titled \"Weed\" – arguing in favor of the medical benefits of cannabis. Gupta was initially dismissive toward the medical use of cannabis, but upon researching further he changed his mind and wrote a column apologizing for his past views. Filmmaker Jed Riffe has also explored the subject in his 2006 documentary \"Waiting to Inhale\".\n\nThe American Academy of Pediatrics, American Psychiatric Association, and American Society of Addiction Medicine oppose the legalization of medical cannabis outside the FDA approval process. However, the AAP also supports rescheduling of cannabis for the purpose of facilitating research.\n\nIndividuals who have been particularly active in opposing the medical use of cannabis include Barry McCaffrey, John Walters, Andrea Barthwell, Bill Montgomery, Mark Souder, Sheldon Adelson, Mel Sembler, and Kevin Sabet.\n\nFormer U.S. Rep. Bob Barr was a particularly ardent opponent of medical cannabis in Congress, introducing the \"Barr amendment\" which blocked implementation of a 1998 Washington, D.C. ballot initiative legalizing the medical use of cannabis. After leaving Congress, however, Barr rescinded his earlier views and joined Marijuana Policy Project to lobby for repeal of the legislation he originally authored.\n\nThe American Medical Association and American College of Physicians do not take a position on the legalization of medical cannabis, but have called for the Schedule I classification to be reviewed. The American Academy of Family Physicians similarly does not take a position, but does support rescheduling in order to facilitate research. The American Cancer Society and American Psychological Association have noted the obstacles that exist for conducting research on cannabis, and have called on the federal government to better enable scientific study of the drug.\n\nThere are currently four cannabinoid drugs (Marinol, Syndros, Cesamet, and Epidiolex) available for prescription use in the United States. Non-Epidiolex CBD is also available for purchase from many online retailers, though the legality of these products is disputed.\n\nDronabinol is synthetically manufactured THC. It has been approved by the FDA in pill form as Marinol and in oral solution form as the drug Syndros.\n\nMarinol is a sesame oil suspension of dronabinol encapsulated in a gelatin shell. It received FDA approval in 1985 for the treatment of nausea and vomiting associated with chemotherapy, and additionally in 1992 as an appetite stimulant for the treatment of AIDS-related weight loss. Marinol was classified as a Schedule II drug upon its initial introduction, and was moved to Schedule III in 1999. Marinol was developed by Unimed Pharmaceuticals, although initial research on the drug was mostly funded by the U.S. government. Unimed Pharmaceuticals was acquired by Solvay Pharmaceuticals in 1999.\n\nSyndros is a liquid oral formulation of dronabinol approved for treatment of chemotherapy-induced nausea and vomiting as well as AIDS-related weight loss. Syndros received FDA approval in July 2016, and was assigned a Schedule II classification by the DEA in March 2017. Syndros is manufactured by Insys Therapeutics, which received attention in 2016 for contributing heavily to the defeat of a cannabis legalization measure in Arizona, in an apparent attempt to protect market share for the newly developed drug. Syndros became available for prescription use in July 2017.\n\nNabilone is a synthetic cannabinoid similar in molecular structure to THC. It is sold in pill form only as the drug Cesamet.\n\nCesamet received FDA approval in 1985 for treatment of chemotherapy-induced nausea and vomiting. It was discontinued by its manufacturer Eli Lilly in 1989 for commercial reasons, and U.S. rights to the drug were sold to Valeant Pharmaceuticals in 2004. In 2006, Valeant received FDA approval to resume sales of the drug. Cesamet has remained a Schedule II drug since it was first introduced for prescription use.\n\nCannabidiol (CBD) is a non-psychoactive cannabinoid that is extracted from the cannabis plant. It has been approved by the FDA as the drug Epidiolex.\n\nEpidiolex is a liquid oral formulation of cannabidiol approved for the treatment of Dravet syndrome and Lennox–Gastaut syndrome. It received FDA approval in June 2018, and was assigned a Schedule V classification by the DEA in September 2018. Epidiolex is manufactured by Greenwich Biosciences, a U.S. subsidiary of the British firm GW Pharmaceuticals. Epidiolex became available for prescription use in November 2018.\n\nIn addition to its use for treatment of seizure disorders, cannabidiol is used by some individuals under the belief that it possesses a number of other medical properties – but these claims have yet to be thoroughly studied and proven. Accordingly, the FDA has not approved CBD for any other medical use, and the DEA's current position is that it considers non-Epidiolex CBD to be a Schedule I drug. Despite the Schedule I classification, a number of online retailers sell CBD products to all 50 states, claiming such products are legal because they are derived from industrial hemp plants. The federal government has yet to take action against these retailers.\n\nA 2016 study found significant drops in violent crime in states that have legalized medical cannabis. A 2017 study similarly found that introduction of medical cannabis laws caused a reduction in violent crime in American states that border Mexico.\n\nA 2013 study found that medical cannabis legalization is associated with an 8-11% reduction in traffic fatalities.\n\nSeveral studies have found decreased rates of opioid use and abuse in states that have legalized medical cannabis.\n\nSeveral studies have found no increase in teen use in states that have legalized cannabis for medical purposes. A 2018 meta-analysis in the journal \"Addiction\" similarly found no increase.\n\nBelow is a comparison of medical conditions that doctors can recommend cannabis for in each state. The table is not comprehensive and could include out-of-date information. Low-THC, high-CBD states are not listed.\n\nData additionally obtained from Leafly and ProCon.org.\n\n\n"}
{"id": "22562470", "url": "https://en.wikipedia.org/wiki?curid=22562470", "title": "Multicenter AIDS Cohort Study", "text": "Multicenter AIDS Cohort Study\n\nThe Multicenter AIDS Cohort Study (MACS) is an ongoing cohort study involving over 6,000 men, including both those infected with HIV, as well as HIV-negative men. The Los Angeles component of the MACS is called the Los Angeles Mens Study or LAMS. LAMS affiliated with UCLA and is supervised by Dr Roger Detels, MD & John Oishi.\n\nThe study, a program of the Division of Acquired Immunodeficiency Syndrome, has been ongoing for over 30 years and has resulted in over 1,000 scientific publications. It helped to establish that AIDS was a viral illness and how it was spread. Participants were quizzed in detail about their sexual behaviour. \"They ask you for numbers, how many times did you do what.\" Some participants who had many sexual partners were not infected, and this led to the realisation that some people had genetic resistance to the virus.\n\n"}
{"id": "196997", "url": "https://en.wikipedia.org/wiki?curid=196997", "title": "National Council Against Health Fraud", "text": "National Council Against Health Fraud\n\nThe National Council Against Health Fraud (NCAHF) was a not-for-profit, US-based organization, run by Dr. Stephen Barrett, a retired American psychiatrist and author, that described itself as a \"private nonprofit, voluntary health agency that focuses upon health misinformation, fraud, and quackery as public health problems.\" The NCAHF has been criticized by the supporters of the treatments it opposes, including practitioners of alternative medicine.\n\nAccording to its official website, the NCAHF evolved from three separate organizations. The Lehigh Valley Committee Against Health Fraud, Inc. (LVCAHF, now called Quackwatch) was founded in 1969 by Stephen Barrett and H. William Gross, D.D.S. in Allentown, Pennsylvania. The Southern California Council Against Health Fraud (SCCAHF) had its origin in 1976 at Loma Linda University with academic colleagues William T. Jarvis and Gordon Rick as co-founders. Thomas H. Jukes of University of California, Berkeley founded the third organization, an unnamed group in northern California.\n\nFor a time between 1998 and 2000, the NCAHF operated under the name National Council for Reliable Health Information (NCRHI). The organization effectively ceased operations in 2002, and its legal entity was formally dissolved in 2011.\n\nAccording to NCAHF's mission statement, its activities and purposes include:\n\n\nNCAHF's positions on consumer health issues are based on what they consider ethical and scientific principles that underlie consumer protection law. Required are:\n\n\nNCAHF states that its funding is primarily derived from membership dues, newsletter subscriptions, and consumer information services. Membership is open to everyone, with members and consultants located all over the world. NCAHF's officers and board members serve without compensation. NCAHF states they unite consumers with health professionals, educators, researchers, attorneys, and others.\n\nThe NCAHF asserts that acupuncture is scientifically unproven as a modality of treatment. The NCAHF says (as of 1990) that research during the past twenty years has failed to demonstrate that acupuncture is effective against any disease. Perceived effects of acupuncture are, argues the NCAHF, probably due to a combination of expectation, suggestion and other psychological mechanisms. The NCAHF points out that acupuncture was banned in China in 1929 but underwent a resurgence in the 1960s. The organization also advocates that insurance companies should not be required to cover acupuncture treatment, and that licensure of lay acupuncturists should be phased out.\n\nThere has long been controversy regarding the use of amalgam fillings by dentists, because the amalgam contains mercury. Some forms of mercury are toxic to humans, but the NCAHF cites the CDC in stating that there is no evidence that \"the health of the vast majority of people with amalgam is compromised\" or that \"removing amalgam fillings has a beneficial effect on health\". The NCAHF criticizes those who they believe exploit unfounded public fears for financial gain. NCAHF asserts that breath, urine and blood testing for mercury are inaccurate. Other tests for mercury exposure described by the NCAHF as invalid can include skin testing, stool testing, hair analysis and electrodermal testing.\n\nThe NCAHF contends that chiropractic can be dangerous and lead to injury or permanent disability. However, the NCAHF does not categorically oppose the practice. NCAHF differentiates between chiropractors who promote what it considers good and bad chiropractic practices. The former promote methods of diagnosis and treatment which have a scientific basis. For example, NCAHF claims there is no scientific support for vertebral subluxation. Their view is that chiropractors should restrict their scope of practice to neuromusculoskeletal problems such as muscle spasms, strains, sprains, fatigue, imbalance of strength and flexibility, stretched or irritated nerve tissue, and so forth. Chiropractors should refer cases involving pathology to qualified medical practitioners.\n\nIn contrast, what the NCAHF considers bad are those chiropractors who believe the spinal adjustment will cure or alleviate a variety of diseases, such as infection, arthritis, cancer, diabetes, nutritional deficiencies or excesses, appendicitis, blood disorders, or kidney disease. These practitioners may use unproven, disproven, or questionable methods, devices, and products such as adjusting machines, applied kinesiology, chelation therapy, colonic irrigation, computerized nutrition deficiency tests, cranial osteopathy, cytotoxic food allergy testing, DMSO, Gerovital, glandular therapy, hair analysis, herbal crystallization analyses, homeopathy, internal managements, iridology, laser beam acupuncture, laetrile, magnetic therapy,and so forth.\n\nThe NCAHF is opposed to dietary recommendations and practices not supported by scientific evidence, including behavior-related claims. Unverified assessment methods such as iridology, applied kinesiology, and routine hair analysis for assessment of nutritional status are criticized. NCAHF and some of its members have long opposed implementation of beliefs that they characterize as unfounded or unscientific.\n\nNCAHF also questions the health claims, marketing, safety, efficacy and labeling of herbal supplements. Herbal preparations are regulated as foods, rather than as drugs, in the United States. The NCAHF advocates regulations for a special OTC category called \"Traditional Herbal Remedies\" (THRs) with an adverse reaction surveillance program, product batches marked for identification and tracking, package label warnings about proposed dangers of self-treatment, oversight requirements from outside of the herbal industry, and strong penalties for unapproved changes in herbal product formulations.\n\nThe NCAHF claims that many unqualified practitioners are able to mislead the public by using diploma mills or \"degree mills\" to get \"specious degrees\". Diploma mills are not accredited, and frequently engage in \"pseudoscience and food faddism\". NCAHF also alleges that \"at least some of the 'faculty' or 'academic' advisors at several of these schools have criminal convictions in the area of health fraud\". NCAHF considers diploma mills harmful to the \"students\" and to the public.\n\nThe National Council Against Health Fraud is mentioned as a useful source for information by\nthe United States Department of Agriculture, the 2003 edition of \"Cancer Medicine,\" published by the American Cancer Society, and many other organizations and libraries.\n\nThe journal \"Dynamic Chiropractic\", while highly critical of NCAHFs views on chiropractic, has written: \"The National Council Against Health Fraud is considered a valuable information source for many agencies nationwide. They are well networked and, as demonstrated by their past history, are able to influence the efforts of various agencies and insurance carriers. The NCAHF's ability to publish its opinions and hold these types of conferences does make them a substantial \"player\" in the area of health fraud.\"\n\nIn 1998, the AMA's Council on Scientific Affairs used NCAHF board member John Renner as a contributing source for some of the content in their \"Report 12.\"\n\nThe American Chiropractic Association (ACA) criticised a 2002 PBS broadcast which included an episode about chiropractic in which the NCAHF was involved. ACA president, Daryl D. Wills, responded to PBS officials stating (in part): \"I find it ironic that a program titled 'Scientific American Frontiers' would completely ignore the scientific foundation of the chiropractic profession. The chiropractic portion of the June 4 episode titled 'A Different Way to Heal?' irresponsibly characterized chiropractic care -- a legitimate, research-based form of health care -- as a fraudulent hoax.\" and that \"[t]he producers of your program could not have expected objectivity\" from the NCAHF. The producer of the program replied in detail and explicitly denied these allegations: \"The segment did not claim that chiropractic is fraudulent and did not attempt to prove or disprove that chiropractic \"works,\" but it does state that chiropractic has no basis in science. This conclusion is entirely justified by both current research and generally accepted views of human anatomy.\"\n\n\n"}
{"id": "429680", "url": "https://en.wikipedia.org/wiki?curid=429680", "title": "National Institute for Health and Care Excellence", "text": "National Institute for Health and Care Excellence\n\nThe National Institute for Health and Care Excellence (NICE) is an executive non-departmental public body of the Department of Health in the United Kingdom, which publishes guidelines in four areas: \n\nThese appraisals are based primarily on evaluations of efficacy and cost-effectiveness in various circumstances.\n\nIt serves both the English NHS and the Welsh NHS. It was set up as the National Institute for Clinical Excellence in 1999, and on 1 April 2005 joined with the Health Development Agency to become the new National Institute for Health and Clinical Excellence (still abbreviated as NICE). Following the Health and Social Care Act 2012, NICE was renamed the National Institute for Health and Care Excellence on 1 April 2013 reflecting its new responsibilities for social care, and changed from a special health authority to an Executive Non-Departmental Public Body (ENDPB).\n\nNICE was established in an attempt to end the so-called postcode lottery of healthcare in England and Wales, where treatments that were available depended upon the NHS Health Authority area in which the patient happened to live, but it has since acquired a high reputation internationally as a role model for the development of clinical guidelines. One aspect of this is the explicit determination of cost–benefit boundaries for certain technologies that it assesses. NICE also plays an important role in pioneering technology assessment in other healthcare systems through NICE International, established in May 2008 to help cultivate links with foreign governments.\n\nThe notion of an Institute to determine the clinical effectiveness of interventions first emerged at the end of John Major's Conservative Government as moves elsewhere were being made to set professionally agreed standards for clinical care. In 1996, the UK National Screening Committee (NSC) had been established by Sir Kenneth Calman and Muir Gray (now Sir Muir Gray) by the Policy Team led by Dr Tim Riley and latterly Sir Charles Nightingale for the Department of Health. The NSC aimed to ensure that evidence-based medicine informed policy making on what national screening programmes were approved for funding and what quality assurance mechanisms should be in place. This was a timely action as concerns over screening quality had emerged in breast cancer screening services came under question at Exeter in 1997 and followed in the wake of the 1995 Calman-Hine Report.\n\nThe idea of what was originally termed a National Institute for Clinical Excellence took root when Labour came to power having in 1997. Frank Dobson became Secretary of State and was supported by a team of Ministers keen on introducing clinical and health outcome measures to achieve improvements in the quality and delivery of care. The team included Alan Milburn, Baroness Margaret Jay, and Tessa Jowell. The name and mission was agreed in a meeting between the Ministerial team, Dr Tim Riley and Dr Felicity Harvey shortly after the election and it was agreed that NICE should be described in the first policy white paper, The New NHS: Modern, Dependable 1997. Riley led the team that developed the policy for NICE and which managed the legislation through Parliament in addition to formalising the new institute as a Special Health Authority. Riley joined Sir Michael Rawlins (the then recently appointed Chair of NICE) at the Health Select Committee in February 1999 where questions were raised as to whether NICE was just a means to \"ration\" healthcare. Sir Michael Rawlins presented a compelling case that positioned NICE as a standards setting body first and foremost. \nHowever, the reality was that although NICE was principally aimed at aligning professional standards through clinical guidelines and audit, the acceptability of drugs, devices and technological interventions in defining those standards, could not be ignored and so the concept of a \"fourth hurdle\" for drugs accessing the NHS market was invoked. This controversial policy shift meant that NICE was critical for decisions on drug reimbursement. Indeed, the first drug appraisal by NICE was on the drug Relenza which was turned down amidst criticisms from Glaxo-Wellcome that the appraisal had been fast tracked. Later, this policy development whereby the criteria for decision making, the role of costs, and the degree to which decisions of NICE and the secretary of state would be binding on clinicians was analysed by Andrew Dillon, Trevor Gibbs, Tim Riley, and Trevor A. Sheldon.\n\nSince January 2005, the NHS in England and Wales has been legally obliged to provide funding for medicines and treatments recommended by NICE's technology appraisal board. This was at least in part as a result of well-publicised postcode lottery anomalies in which certain less-common treatments were funded in some parts of the UK but not in others due to local decision making in the NHS.\n\nBefore an appraisal, the Advisory Committee on Topic Selection (ACTS) draws up a list of potential topics of clinical significance for appraisal. The Secretary of State for Health or the Welsh Assembly must then refer any technology so that the appraisal process can be formally initiated. Once this has been done NICE works with the Department of Health to draw up the scope of the appraisal.\n\nNICE then invites consultee and commentator organisations to take part in the appraisal. A consultee organisation would include patient groups, organisations representing health care professionals and the manufacturers of the product undergoing appraisal. Consultees submit evidence during the appraisal and comment on the appraisal documents. Commentator organisations include the manufacturers of products to which the product undergoing appraisal is being compared. They comment on the documents that have been submitted and drawn up but do not actually submit information themselves.\n\nAn independent academic centre then draws together and analyses all of the published information on the technology under appraisal and prepares an assessment report. This can be commented on by the Consultees and Commentators. Comments are then taken into account and changes made to the assessment report to produce an evaluation report. An independent Appraisal Committee then looks at the evaluation report, hears spoken testimony from clinical experts, patient groups and carers. They take their testimony into account and draw up a document known as the 'appraisal consultation document'. This is sent to all consultees and commentators who are then able to make further comments. Once these comments have been taken into account the final document is drawn up called the 'final appraisal determination'. This is submitted to NICE for approval.\n\nThe process aims to be fully independent of government and lobbying power, basing decisions fully on clinical and cost-effectiveness. There have been concerns that lobbying by pharmaceutical companies to mobilise media attention and influence public opinion are attempts to influence the decision-making process. A fast-track assessment system has been introduced to reach decisions where there is most pressure for a conclusion.\n\nNICE carries out assessments of the most appropriate treatment regimes for different diseases. This must take into account both desired medical outcomes (i.e. the best possible result for the patient) and also economic arguments regarding differing treatments.\n\nNICE has set up several National Collaborating Centres bringing together expertise from the royal medical colleges, professional bodies and patient/carer organisations which draw up the guidelines. The centres are the National Collaborating Centre for Cancer, the National Clinical Guideline Centre, the National Collaborating Centre for Women and Children´s Health, and the National Collaborating Centre for Mental Health.\n\nThe National Collaborating Centre appoints a Guideline Development Group whose job it is to work on the development of the clinical guideline. This group consists of medical professionals, representatives of patient and carer groups and technical experts. They work together to assess the evidence for the guideline topic (e.g. clinical trials of competing products) before preparing a draft guideline. There are then two consultation periods in which stakeholder organisations are able to comment on the draft guideline. After the second consultation period, an independent Guideline Review Panel reviews the guideline and stakeholder comments and ensures that these comments have been taken into account. The Guideline Development Group then finalises the recommendations and the National Collaboration Centre produces the final guideline. This is submitted to NICE to formally approve the guideline and issue the guidance to the NHS. To date NICE has produced more than 200 different guidelines.\n\nIn October 2014 Andy Burnham said that a Labour government could reduce variation in access to drugs and procedures by making it mandatory for commissioners to follow NICE clinical guidelines. \"We need to look at how you strengthen NICE. Where they have said something is effective and affordable, on what basis does a local commissioner withhold that from somebody? I’m not comfortable with that. I don’t support that.\"\n\nNICE has a service called Clinical Knowledge Summaries (CKS) which provides primary care practitioners with a readily accessible summary of the current evidence base and practical guidance.\n\nUnder the Health and Social Care Act 2012, NICE was given responsibility for developing guidance and quality standards for social care, using an evidence-based model. This is being delivered by the NICE Collaborating Centre for Social Care (NCCSC), which is hosted by the Social Care Institute for Excellence (SCIE) and 4 partner organisations - Research in Practice, Research in Practice for Adults, Personal Social Services Research Unit and the EPPI-Centre.\n\nNICE receives referrals for social care guidance from the Department of Health and the Department for Education, and commission the guidance from the NCCSC. NICE, along with the NCCSC, carries out a scoping exercise with a scoping group and with input from key stakeholders, at both a workshop and a public consultation, to ensure the guidance to be produced is focused and achievable. A chairperson and members of the Guidance Development Group are appointed, and pose review questions which will enable systematic evidence reviews to take place, thus delivering the guidance and subsequent recommendations. Service user and carer involvement takes place throughout, as well as public consultation on the draft guidance.\n\nThe Guidance Development Group then finalises the recommendations and the NCCSC produces the final guideline. This is submitted to NICE for formal approval and publication. The entire process from pre-scoping to publication takes approximately 24 months. The guidance is then available to NICE standing committees to develop a quality standard on the topic. The quality standard is developed using the guidance and other accredited sources, to produce high-level concise statements that can be used for quality improvement by social care providers and commissioners, as well as setting out what service users and carers can expect of high quality social care services.\n\nThe NCCSC is unique within NICE, in that it is the only collaborating centre to have responsibility for the adoption and dissemination support for guidance and quality standards in the social care arena. Drawing on the expertise of SCIE and their partners within the sector, each of the guidance products and quality standards have a needs assessment carried out to determine the requirements for tools to help embed the guidance and quality standards within the sector. These can include tailored versions of guidance for specific audiences, costing and commissioning tools and even training and learning packages.\n\nAs of August 2013, NICE and the NCCSC had scheduled guidance delivery for five topics: domiciliary care, older adults with long-term conditions, transition between health and social care settings, transition from children's to adults' services and child abuse and neglect.\n\nAs with any system financing health care, the NHS has a limited budget and a vast number of potential spending options. Choices must be made as to how this limited budget is spent. Economic evaluations are carried out within a health technology assessment framework to compare the cost-effectiveness of alternative activities and to consider the opportunity cost associated with their decisions. By choosing to spend the finite NHS budget upon those treatment options that provide the most efficient results, society can ensure it does not lose out on possible health gains through spending on inefficient treatments and neglecting those that are more efficient.\n\nNICE attempts to assess the cost–effectiveness of potential expenditures within the NHS to assess whether or not they represent 'better value' for money than treatments that would be neglected if the expenditure took place. It assesses the cost–effectiveness of new treatments by analysing the cost and benefit of the proposed treatment relative to the next best treatment that is currently in use.\n\nNICE guidance supports the use of quality-adjusted life years (QALY) as the primary outcome for quantifying the expected health benefits associated with a given treatment regime. By comparing the present value (see discounting) of expected QALY flows with and without treatment, or relative to another treatment, the net/relative health benefit derived from such a treatment can be derived. When combined with the relative cost of treatment, this information can be used to estimate an incremental cost-effectiveness ratio (ICER), which is considered in relation to NICE's threshold willingness-to-pay value.\n\nAs a guideline rule, NICE accepts as cost-effective those interventions with an incremental cost-effectiveness ratio of less than £20,000 per QALY and that there should be increasingly strong reasons for accepting as cost-effective interventions with an incremental cost-effectiveness ratio of over a threshold of £30,000 per QALY.\n\nOver the years, there has been great controversy as to what value this threshold should be set at. Initially, there was no fixed number. But the appraisal teams created a consensus amount of about £30,000. However, in November 2008 Alan Johnson, the then Secretary of State, announced that for end-of-life cancer drugs the threshold could be increased above £30,000. \nThe first drug to go through the new process was Lenalidomide, whose ICER was £43,800.\n\nThe following example from NICE explains the QALY principle and the application of the cost per QALY calculation.\n\nA patient has a life-threatening condition and is expected to live on average for 1 year receiving the current best treatment which costs the NHS £3,000. A new drug becomes available that will extend the life of the patient by three months and improve his or her quality of life, but the new treatment will cost the NHS more than three times as much at £10,000. Patients score their perceived quality of life on a scale from 0 to 1 with 0 being worst possible health and 1 being best possible health. On the standard treatment, quality of life is rated with a score of 0.4 but it improves to 0.6 with the new treatment. Patients on the new treatment on average live an extra 3 months, so 1.25 years in total. The quality of life gained is the product of \"life span\" and \"quality rating\" with the new treatment less the same calculation for the old treatment, i.e. (1.25 x 0.6) less (1.0 x 0.4) = 0.35 QALY. The marginal cost of the new treatment to deliver this extra gain is £7,000 so the cost per quality life year gained is £7000/0.35 or £20,000. This is within the £20,000-£30,000 that is suggested by NICE to be the limit for drugs to be cost-effective.\n\nIf the patient was expected to live only one month extra and instead of three then NICE would issue a recommendation not to fund. The patient's Primary Care Trust could still decide to fund the new treatment, but if not, the patient would then have two choices. He or she could opt to take the free NHS standard treatment, or he or she may decide to pay out of pocket to obtain the benefit of the new treatment from a different health care provider. If the person has a private health insurance policy the person could check to see whether the private insurance provider will fund the new treatment. About 8% of the population has some private health insurance from an employer or trade association and 2% pay from their own resources.\n\nTheoretically, it might be possible to draw up a table of all possible treatments sorted by increasing the cost per quality-adjusted life year gained. Those treatments with lowest cost per quality-adjusted life year gained would appear at the top of the table and deliver the most benefit per value spent and would be easiest to justify funding for. Those where the delivered benefit is low and the cost is high would appear at the bottom of the list. Decision makers would, theoretically, work down the table, adopting services that are the most cost effective. The point at which the NHS budget is exhausted would reveal the shadow price, the threshold lying between the CQG gained of the last service that is funded and that of the next most cost effective service that is not funded.\n\nIn practice this exercise is not done, but an assumed shadow price has been used by NICE for many years in its assessments to determine which treatments the NHS should and should not fund. NICE states that for drugs the cost per QALY should not normally exceed £30,000 but that there is not a hard threshold, though research has shown that any threshold is \"somewhat higher\" than being in the range £35,000 - £40,000.\n\nThe House of Commons Health Select Committee, in its report on NICE, stated in 2008 that \"the (...) cost-per-QALY it uses to decide whether a treatment is cost-effective is of serious concern. The threshold it employs is not based on empirical research and is not directly related to the NHS budget, nor is it at the same level as that used by Primary Care Trusts (PCTs) in providing treatments not assessed by NICE, which tends to be lower. Some witnesses, including patient organisations and pharmaceutical companies, thought NICE should be more generous in the cost per QALY threshold it uses, and should approve more products. On the other hand, some PCTs struggle to implement NICE guidance at the current threshold and other witnesses argued that a lower level should be used. However, there are many uncertainties about the thresholds used by PCTs.\" It went on to recommend that \"an independent body should determine the threshold used when making judgements of the value of drugs to the NHS.\"\n\nThe work that NICE is involved in attracts the attention of many groups, including doctors, the pharmaceutical industry, and patients. NICE is often associated with controversy, because the need to make decisions at a national level can conflict with what is (or is believed to be) in the best interests of an individual patient.\n\nApproved cancer drugs and treatments such as radiotherapy and chemotherapy are funded by the NHS without any financial contribution being taken from the patient. Where NICE has approved a treatment, the NHS must fund it. But not all treatments have been assessed by NICE and these treatments are usually dependent on local NHS decision making. In the case of cancer the Cancer Drugs Fund was set up in 2011 after complaints about NICE decisions on new and expensive cancer drugs with limited benefits. Treatment for fertility problems are approved but not always funded by clinical commissioning groups and they may cap the number of rounds.\n\nNICE has been criticised for being too slow to reach decisions. On one occasion, the Royal National Institute of Blind People said it was outraged over its delayed decision for further guidance regarding two drugs for macular degeneration that are already approved for use in the NHS. However the Department of Health said that it had 'made it clear to PCTs that funding for treatments should not be withheld simply because guidance from NICE is unavailable'.\n\nSome of the more controversial NICE decisions have concerned donepezil, galantamine, rivastigmine (review) and memantine for the treatment of Alzheimer's disease and bevacizumab, sorafenib, sunitinib and temsirolimus for renal cell carcinoma. All these are drugs with a high cost per treatment and NICE has either rejected or restricted their use in the NHS on the grounds that they are not cost-effective.\n\nA Conservative shadow minister once criticized NICE for spending more on communications than assessments. In its defence, NICE said the majority of its communications budget was spent informing doctors about which drugs had been approved and new guidelines for treatments and that the actual cost of assessing new drugs for the NHS includes money spent on NICE's behalf by the Department of Health. When these were added to NICE's own costs, the total cost of the technology appraisal programme far outstrips the cost of NICE communications.\n\nA report from the University of York Centre for Health Economics written by Karl Claxton in February 2015 suggested that the maximum threshold, currently around £30,000 a year, for judging a medicine cost-effective should be more than halved. They found that any intervention costing more than £13,000 per Quality-adjusted life year risked causing more harm than good by denying cost effective treatment to other patients.\n\nThe institute's approach to the introduction of new oral therapy for Hepatitis C has been criticised. Sofosbuvir was approved in 2015. It costs about £30,000 for 12 weeks treatment. NHS England established 22 Operational Delivery Networks to roll out delivery and proposes to fund 10,000 courses of treatment in 2016-17. Each has been given a “run rate” of how many patients they are allowed to treat. This is the NHS’ single biggest new treatment investment this year. In the North East London network patients with cirrhosis or fibrosis go to the front of the queue and three new patients at the Grahame Hayton Unit at the Royal London Hospital start treatment each month. Those without such complications may faced considerable delays before they start treatment.\n\n\n"}
{"id": "294533", "url": "https://en.wikipedia.org/wiki?curid=294533", "title": "Nephritis", "text": "Nephritis\n\nNephritis is inflammation of the kidneys and may involve the glomeruli, tubules, or interstitial tissue surrounding the glomeruli and tubules.\n\n\nNephritis is often caused by infections, and toxins, but is most commonly caused by autoimmune disorders that affect the major organs like kidneys.\n\n\nNephritis can produce glomerular injury, by disturbing the glomerular structure with inflammatory cell proliferation. This can lead to reduced glomerular blood flow, leading to reduced urine output (oliguria) and retention of waste products (uremia). As a result, red blood cells may leak out of damaged glomeruli, causing blood to appear in the urine (hematuria).\n\nLow renal blood flow activates the renin–angiotensin–aldosterone system (RAAS), causing fluid retention and mild hypertension. As the kidneys inflame, they begin to excrete needed protein from the affected individual's body into the urine stream. This condition is called proteinuria.\n\nLoss of necessary protein due to nephritis can result in several life-threatening symptoms. The most serious complication of nephritis can occur if there is significant loss of the proteins that keep blood from clotting excessively. Loss of these proteins can result in blood clots, causing sudden stroke.\n\nThe diagnosis depends on the cause of the nephritis, in the case of lupus nephritis, blood tests, X-rays and an ultrasound can help ascertain if the individual has the condition.\n\nTreatment (or management) of nephritis depends on what has provoked the inflammation of the kidney(s). In the case of lupus nephritis, hydroxychloroquine could be used.\nNephritis represents the ninth most common cause of death among all women in the US (and the fifth leading cause among non-Hispanic black women).\n\nWorldwide the highest rates of nephritis are 50-55% for African or Asian descent, then Hispanic at 43% and Caucasian at 17%.\n\nThe average age of this inflammation(lupus nephritis in this case) is about 28.4 years old for an individual who has been so diagnosed with the condition\n"}
{"id": "6780123", "url": "https://en.wikipedia.org/wiki?curid=6780123", "title": "Non-communicable disease", "text": "Non-communicable disease\n\nA non-communicable disease (NCD) is a disease that is not transmissible directly from one person to another. NCDs include parkinson's disease autoimmune diseases, strokes, most heart diseases, most cancers, diabetes, chronic kidney disease, osteoarthritis, osteoporosis, Alzheimer's disease, cataracts, and others. NCDs may be chronic or acute. Most are non-infectious, although there are some non-communicable infectious diseases, such as parasitic diseases in which the parasite's life cycle does not include direct host-to-host transmission. \n\nNCDs are the leading cause of death globally. In 2012, they caused 68% of all deaths (38 million) up from 60% in 2000. About half were under age 70 and half were women. Risk factors such as a person's background, lifestyle and environment increase the likelihood of certain NCDs. Every year, at least 5 million people die because of tobacco use and about 2.8 million die from being overweight. High cholesterol accounts for roughly 2.6 million deaths and 7.5 million die because of high blood pressure.\n\nRisk factors such as a person's background; lifestyle and environment are known to increase the likelihood of certain non-communicable diseases. They include age, gender, genetics, exposure to air pollution, and behaviors such as smoking, unhealthy diet and physical inactivity which can lead to hypertension and obesity, in turn leading to increased risk of many NCDs. Most NCDs are considered preventable because they are caused by modifiable risk factors.\n\nThe WHO's \"World Health Report 2002\" identified five important risk factors for non-communicable disease in the top ten leading risks to health. These are raised blood pressure, raised cholesterol, tobacco use, alcohol consumption, and overweight. The other factors associated with higher risk of NCDs include a person's economic and social conditions, also known as the \"[social determinants of health].\"\n\nIt has been estimated that if the primary risk factors were eliminated, 80% of the cases of heart disease, stroke and type 2 diabetes and 40% of cancers could be prevented. Interventions targeting the main risk factors could have a significant impact on reducing the burden of disease worldwide. Efforts focused on better diet and increased physical activity have been shown to control the prevalence of NCDs .\n\nNCDs include many environmental diseases covering a broad category of avoidable and unavoidable human health conditions caused by external factors, such as sunlight, nutrition, pollution, and lifestyle choices. The diseases of affluence are non-infectious diseases with environmental causes. Examples include:\n\nGenetic disorders are caused by errors in genetic information that produce diseases in the affected people.\nThe origin of these genetic errors can be:\n\nCystic fibrosis is an example of an inherited disease that is caused by a mutation on a gene. The faulty gene impairs the normal movement of sodium chloride in and out of cells, which causes the mucus-secreting organs to produce abnormally thick mucus. The gene is recessive, meaning that a person must have two copies of the faulty gene for them to develop the disease. Cystic fibrosis affects the respiratory, digestive and reproductive systems, as well as the sweat glands. The mucus secreted is very thick and blocks passageways in the lungs and digestive tracts. This mucus causes problems with breathing and with the digestion and absorption of nutrients.\n\nReferred to as a \"lifestyle\" disease, because the majority of these diseases are preventable illnesses, the most common causes for non-communicable diseases (NCD) include tobacco use (smoking), alcohol abuse, poor diets (high consumption of sugar, salt, saturated fats, and trans fatty acids) and physical inactivity. Currently, NCD kills 36 million people a year, a number that by some estimates is expected to rise by 17–24% within the next decade.\n\nHistorically, many NCDs were associated with economic development and were so-called a \"diseases of the rich\". The burden of non-communicable diseases in developing countries has increased however, with an estimated 80% of the four main types of NCDs — cardiovascular diseases, cancers, chronic respiratory diseases and diabetes — now occurring in low- and middle-income countries. Action Plan for the Global Strategy for the Prevention and Control of non-communicable Diseases and with two-thirds of people who are affected by diabetes now residing in developing nations, NCD can no longer be considered just a problem affecting affluent estimation of the economic impact of chronic non-communicable diseases in selected countries. New WHO report: deaths from non-communicable diseases are on the rise, with developing world hit hardest. As previously stated, in 2008 alone, NCD's were the cause of 63% of deaths worldwide; a number that is expected to rise considerably in the near future if measures are not taken.\n\nIf present growth trends are maintained, by 2020, NCDs will attribute to 7 out of every 10 deaths in developing countries, killing 52 million people annually worldwide by 2030. With statistics such as these, it comes as no surprise that international entities such as the World Health Organization & World Bank Human Development Network have identified the prevention and control of NCDs as an increasingly important discussion item on the global health agenda.\n\nThus, should policy makers and communities mobilize \"and make prevention and targeted treatment of such diseases a priority,\" sustainable measures can be implemented to stagnate (and eventually even reverse) this emerging global health threat. Potential measures currently being discussed by the(World Health Organization)-Food and Agriculture Organization includes reducing the levels of salt in foods, limiting inappropriate marketing of unhealthy foods and non-alcoholic beverages to children, imposing controls on harmful alcohol use, raising taxes on tobacco, and curbing legislation to curb smoking in public places.\n\nThe World Health Organization is the specialized agency of the United Nations (UN) that acts as coordinating authority on international public health issues, including NCDs. In May 2008, the 193 Member States of the WHO approved a six-year plan to address non-communicable diseases, especially the rapidly increasing burden in low- and middle-income countries. The plan calls for raising the priority given to NCDs in international development work'.\n\nDuring the 64th session of the United Nations General Assembly in 2010, a resolution was passed to call for a high-level meeting of the General Assembly on the prevention and treatment NCDs with the participation of heads of state and government. The resolution also encouraged UN Member States to address the issue of non-communicable diseases at the 2010 Review Summit for the Millennium Development Goals.\n\nIn order to better coordinate efforts around the globe, in 2009 the WHO announced the launch of the \"Global Non-communicable Disease Network\" (NCDnet). NCDnet will consist of leading health organizations and experts from around the world in order to fight against diseases such as cancer, cardiovascular disease, and diabetes. Ala Alwan, assistant director-general for Non-communicable Diseases and Mental Health at the WHO, said: \"integrating the prevention of non-communicable diseases and injuries into the national and global development agendas is not only achievable but also a priority for developing countries.\"\n\nThe NCD Alliance is a global partnership founded in May 2009 by four international federations representing cardiovascular disease, diabetes, cancer, and chronic respiratory disease. The NCD Alliance brings together roughly 900 national member associations to fight non-communicable disease. Long term aims of the Alliance include:\n\nThe United Nations Interagency Task Force on the Prevention and Control of Non-communicable Diseases (UNIATF) was established by the United Nations Secretary-General in 2013 in order to provide scaled up action across the UN system to support governments, in particular in low- and middle-income countries, to tackle non-communicable diseases (NCDs).\n\nThe Young Professionals Chronic Disease Network, or commonly referred to as YP-CDN, is a global network of roughly 5000 young professionals across 157 countries. The organization aims to mobilize these young people \"to take action against social injustice driven by NCDs.\".\n\nPreviously, chronic NCDs were considered a problem limited mostly to high income countries, while infectious diseases seemed to affect low income countries. The burden of disease attributed to NCDs has been estimated at 85% in industrialized nations, 70% in middle income nations, and nearly 50% in countries with the lowest national incomes. In 2008, chronic NCDs accounted for more than 60% (over 35 million) of the 57 million deaths worldwide. Given the global population distribution, almost 80% of deaths due to chronic NCDs worldwide now occur in low and middle income countries, while only 20% occur in higher income countries.\n\nNational economies are reportedly suffering significant losses because of premature deaths or inability to work resulting from heart disease, stroke and diabetes. For instance, China is expected to lose roughly $558 billion in national income between 2005 and 2015 due to early deaths. In 2005, heart disease, stroke and diabetes caused an estimated loss in international dollars of national income of 9 billion in India and 3 billion in Brazil.\n\nThe burden of chronic NCDs including mental health conditions is felt in workplaces around the world, notably due to elevated levels of absenteeism, or absence from work because of illness, and presenteeism, or productivity lost from staff coming to work and performing below normal standards due to poor health. For example, the United Kingdom experienced a loss of about 175 million days in 2006 to absence from illness among a working population of 37.7 million people. The estimated cost of absences due to illness was over 20 billion pounds in the same year. The cost due to presenteeism is likely even larger, although methods of analyzing the economic impacts of presenteeism are still being developed. Methods for analyzing the distinct workplace impacts of NCDs versus other types of health conditions are also still being developed.\n\nFor the vast majority of cancers, risk factors are environmental or lifestyle-related, thus cancers are mostly preventable NCD. Greater than 30% of cancer is preventable via avoiding risk factors including: tobacco, being overweight or obesity, low fruit and vegetable intake, physical inactivity, alcohol, sexually transmitted infections, and air pollution. Infectious agents are responsible for some cancers, for instance almost all cervical cancers are caused by human papillomavirus infection.\n\nThe first studies on cardiovascular health were performed in 1949 by Jerry Morris using occupational health data and were published in 1958. The causes, prevention, and/or treatment of all forms of cardiovascular disease remain active fields of biomedical research, with hundreds of scientific studies being published on a weekly basis. A trend has emerged, particularly in the early 2000s, in which numerous studies have revealed a link between fast food and an increase in heart disease. These studies include those conducted by the Ryan Mackey Memorial Research Institute, Harvard University and the Sydney Center for Cardiovascular Health. Many major fast food chains, particularly McDonald's, have protested the methods used in these studies and have responded with healthier menu options.\n\nA fairly recent emphasis is on the link between low-grade inflammation that hallmarks atherosclerosis and its possible interventions. C-reactive protein (CRP) is a common inflammatory marker that has been found to be present in increased levels in patients at risk for cardiovascular disease. Also osteoprotegerin which involved with regulation of a key inflammatory transcription factor called NF-κB has been found to be a risk factor of cardiovascular disease and mortality.\n\nType 2 Diabetes Mellitus is a chronic condition which is largely preventable and manageable but difficult to cure. Management concentrates on keeping blood sugar levels as close to normal (\"euglycemia\") as possible without presenting undue patient danger. This can usually be with close dietary management, exercise, and use of appropriate medications (insulin only in the case of type 1 diabetes mellitus. Oral medications may be used in the case of type 2 diabetes, as well as insulin).\n\nPatient education, understanding, and participation is vital since the complications of diabetes are far less common and less severe in people who have well-managed blood sugar levels.\nWider health problems may accelerate the deleterious effects of diabetes. These include smoking, elevated cholesterol levels, obesity, high blood pressure, and lack of regular exercise.\n\nAlthough chronic kidney disease (CKD) is not currently identified as one of WHO's main targets for global NCD control, there is compelling evidence that CKD is not only common, harmful and treatable but also a major contributing factor to the incidence and outcomes of at least three of the diseases targeted by WHO (diabetes, hypertension and CVD).\nCKD strongly predisposes to hypertension and CVD; diabetes, hypertension and CVD are all major causes of CKD; and major risk factors for diabetes, hypertension and CVD (such as obesity and smoking) also cause or exacerbate CKD. In addition, among people with diabetes, hypertension, or CVD, the subset who also have CKD are at highest risk of adverse outcomes and high health care costs. Thus, CKD, diabetes and cardiovascular disease are closely associated conditions that often coexist; share common risk factors and treatments; and would benefit from a coordinated global approach to prevention and control.\n\n\"Main Article: Chronic respiratory disease\"\n\nChronic Respiratory Diseases (CRDs) are diseases of the lungs and airways. According to the World Health Organization (WHO) hundreds of millions of people suffer daily from CRDs. Common CRDs are: Asthma, Chronic obstructive pulmonary disease, Occupational lung disease, and Pulmonary hypertension. While CRDs are not curable, various treatments are available to help improve quality of life for individuals who have them. Most treatments involve dilating major airways to improve shortness of breath among other symptoms. The main risk factors for developing CRDs are: tobacco smoking, indoor and outdoor air pollution, allergens, and occupational risks.\n\nWHO helped launch the Global Alliance against Chronic Respiratory Diseases (GARD) in 2006. GARD is voluntarily composed of national and international organizations and works toward \"reducing the global burden of chronic respiratory diseases\" and focus mainly on vulnerable populations and low and middle-income countries.\n\n\n"}
{"id": "16013170", "url": "https://en.wikipedia.org/wiki?curid=16013170", "title": "Osteo-odonto-keratoprosthesis", "text": "Osteo-odonto-keratoprosthesis\n\nOsteo-odonto-keratoprosthesis (OOKP) (also known as \"tooth in eye\" surgery) is a medical procedure to restore vision in the most severe cases of corneal and ocular surface patients. It includes removal of a tooth from the patient or a donor. After removal, a lamina of tissue cut from the tooth is drilled and the hole is fitted with optics. The lamina is grown in the patients' cheek for a period of months and then is implanted upon the eye. The procedure was pioneered by the Italian ophthalmic surgeon Professor Benedetto Strampelli in the early 1960s. Strampelli was a founder-member of the International Intra-Ocular Implant Club (IIIC) in 1966.\n\nAn operation to graft the OOKP is undertaken in severe pemphigoid, chemical burns, Stevens–Johnson syndrome, trachoma, Lyell syndrome and multiple corneal graft failure.\n\nThere is a significant risk of anatomical failure of lamina in the long term, estimated at about 19% in a small study, with the main risks being laminar resorption, particularly in allografts, and glaucoma.\n\nAnother, bigger study comparing OOKP with the lesser known osteo-keratoprosthesis (OKP) in 145 and 82 patients and follow-up terms up to 10 years yielded following statistics:\n\n\nwith functional survival defined as best corrected visual acuity above 0.05.\n\nAnother long-term study of 181 patients puts the chances of retaining an intact OOKP after 18 years at 85%.\n\nOOKP is a two-stage operation:\n\nStage 1 of the surgery involves five separate procedures:\n\n\nStage 2 (about 4 months later) involves two separate procedures:\n\n\nAt the end of the procedure, light can now enter through the plastic cylinder, and the patient is able to see through this cylinder with good vision.\n\nThe procedure was pioneered by the Italian ophthalmic surgeon Professor in Rome in the early 1960s.\n\nThe son of the geneticist and agronomist Nazareno Strampelli, Benedetto Strampelli held the chair of ophthalmic surgery at Rome's Ospedale di San Giovanni in Laterano where he was one of the first surgeons in Italy to transplant cornea. In 1953 he was the first Italian to implant intraocular lens which were manufactured to his own design by Rayners in UK. Strampelli was a founder-member with Harold Ridley and Peter Choyce of the International Intra-Ocular Implant Club (IIIC) in 1966.\n\n"}
{"id": "242157", "url": "https://en.wikipedia.org/wiki?curid=242157", "title": "Outline of organic gardening and farming", "text": "Outline of organic gardening and farming\n\nThe following outline is provided as an overview of and topical guide to organic gardening and farming:\n\nOrganic farming – alternative agricultural system that relies on fertilizers of organic origin such as compost, manure, green manure, and bone meal and places emphasis on techniques such as crop rotation and companion planting. Biological pest control, mixed cropping and the fostering of insect predators are encouraged. In general, organic standards are designed to allow the use of naturally occurring substances while prohibiting or strictly limiting synthetic substances.\n\n\n\n\n\nHistory of organic farming\n\n\n\n\n\n\n"}
{"id": "24036991", "url": "https://en.wikipedia.org/wiki?curid=24036991", "title": "Pagophagy", "text": "Pagophagy\n\nPagophagy or pagophagia is eating of ice.\n\nThe term has the two major usages: \n\nThe pagophagic disorder is among the unexplained clinical signs of iron deficiency anemia.\n\n"}
{"id": "30699296", "url": "https://en.wikipedia.org/wiki?curid=30699296", "title": "Pakistan Heart Foundation", "text": "Pakistan Heart Foundation\n\nThe Pakistan Heart Foundation (PHF 1974) which originated from the Muhammadi Hospital (MH 1970), and merged with the International Medical Research Centre (IMRC 1988), provides non-profit cardiac care through the MH, and coordinates training for medics and paramedic, mobile health programs, clinical research and publications through the IMRC.\n\nNon-invasive cardiac diagnostic service and medical management is provided to patients from Khyber Pakhtunkhwa (NWFP), FATA and Afghanistan. Preventive community based activities include the School Health Program (SHP), and Man, Mountain and Medicine (MMM).\n\nOver the last 35 years, out outreach projects have built a data-base of cardiac patients, which with Afghanistan, is one of the world's largest backlog of operable pediatric cardiac cases.\n\nIn order to enhance its humanitarian service a charitable cardiac center is on the anvil, on 1.2 acres plot of land, along with the existing block of building of the MH-IMRC. This project is located on the main boulevard of the new town of Hayatabad, outside the main City of Peshawar, next to the Jamrud Town, on way to the Pak-Afghan border.\n\nThe teaching multi-media resource (free downloads and online publications) are in use for professional training programs, with willingness to actively associate with other communities and welfare organizations across the world.\n\nPakistan Heart Foundation is the National Member of the\nWorld Heart Federation, Geneva. is an International Medical Research Centre, a School Health Program, a Mountain Medicine Program and a proposed Mountain Medicine Markaz, Chitral.\n\n"}
{"id": "21002520", "url": "https://en.wikipedia.org/wiki?curid=21002520", "title": "Pediatric intensive care unit", "text": "Pediatric intensive care unit\n\nA pediatric intensive care unit (also paediatric), usually abbreviated to PICU (), is an area within a hospital specializing in the care of critically ill infants, children, and teenagers. A PICU is typically directed by one or more pediatric intensivists or PICU consultants and staffed by doctors, nurses, and respiratory therapists who are specially trained and experienced in pediatric intensive care. The unit may also have nurse practitioners, physician assistants, physiotherapists, social workers, child life specialists, and clerks on staff, although this varies widely depending on geographic location. The ratio of professionals to patients is generally higher than in other areas of the hospital, reflecting the acuity of PICU patients and the risk of life-threatening complications. Complex technology and equipment is often in use, particularly mechanical ventilators and patient monitoring systems. Consequently, PICUs have a larger operating budget than many other departments within the hospital.\n\nGoran Haglund is credited with establishing the first pediatric ICU in 1955. The PICU was located at Children’s Hospital of Goteburg in Sweden. The first PICU in the united states, although commonly thought to be the unit at the Children’s Hospital of Philadelphia in 1967 by John Downes, was established at Kings County Hospital, East Flatbush, Brooklyn, NY by Dr. Ramon Rodriguez-Torres in 1966.The establishment of these units would eventually lead to hundreds of PICUs being developed across North American and Europe. This number is still increasing in present day.\n\nThere were a variety of factors that lead to the development of PICUs. John Downes identified five specialties of medicine that aided in the development. These specialties included adult respiratory ICUs, neonatal intensive care, pediatric general surgery, pediatric cardiac surgery, and pediatric anesthesiology.\n\nBetween 1930 and 1950 the poliomyelitis epidemic had created a greater need for adult respiratory intensive care, including the iron lung. There were times when children would contract polio and would have to be treated in these ICUs as well. This contributed to the need for a unit where critically ill children could be treated. Respiratory issues were also increasing in children because neonatal intensive care units were increasing the survival rates of infants. This was due to advances in mechanical ventilation. However, this resulted in children developing chronic lung diseases, but there was not a specific unit to treat these diseases.\n\nAdvancements in pediatric general surgery, cardiac surgery, and anesthesiology were also a driving factor in the development of the PICU. The surgeries that were being performed were becoming more complicated and required more extensive postoperative monitoring. This monitoring could not be performed on the regular pediatric unit, which led to Children’s Hospital of Philadelphia’s development of the first PICU. Advancements in pediatric anesthesiology resulted in anesthesiologist treating pediatric patients outside of the operating room. This caused pediatricians to obtain skills in anesthesiology in order to make them more capable of treating critically ill pediatric patients. These pediatric anesthesiologists eventually went on to develop run PICUs.\n\nThere are a variety of PICU characteristics that allow the healthcare providers to deliver the most optimal care possible. The first of these characteristics is the physical environment of the PICU. The layout of the unit should allow the staff to constantly observe the patients they are caring for. The staff should also be able to rapidly respond to the patients if there is any change in the patient’s clinical status.\n\nCorrect staffing is the next vital component to a successful PICU. The nursing staff is highly experienced in providing care to the most critical patients. The nurse to patient ratio should remain low, meaning that the nurses should only be caring for 1-2 patients depending on the clinical status of the patients. If the patient's clinical status is critical, then they will require more monitoring and interventions than a patient that is stable.\n\nIn most cases, the nurses and physicians are caring for the same patients for a long period of time. This allows the providers to build rapport with the patients, so that all of the patient’s needs are fulfilled. The nurses and physicians must work together as a collaborative team to provide optimal care. The successful collaboration between nurses and physician has resulted in lower mortality rates not just in PICUs, but all intensive care units.\n\nAs medicine has matured over time, the development of the pediatrics intensive care unit has expanded to maintain a level one and a level two PICU. Among these two different levels, they are able to provide critical care and stabilization for each child before transferring to a different acuity.\n\nIn the level one PICU, health care team members must be capable of providing a wide variety of care that typically involves intensive, rapidly changing, and progressive approach. In the level two PICU, patients will present with less complex acuity and will be more stable.\n\nRespiratory issues including acute respiratory distress syndrome (ARDS), asthma, apnea, sepsis, trauma (may include abuse), congenital heart defects, mechanical ventilation, and complications of diabetes ketoacidosis. Gastrointestinal conditions include gastrointestinal perforations, cancer / chemotherapy, organ transplants (kidney, heart), seizures, and poisoning.\n\nAs a PICU nurse, extended knowledge and certifications may be required. Recognition and interpretation are two of the many required skills for a PICU nurse. This allows nurses to be able to detect any changes in the patient's condition and to respond accordingly. Other skills may include route of administration, resuscitation, respiratory and cardiac interventions, preparation and maintenance of patient monitors, and psycho-social skills to ensure comfort of patient and family.\n\nThere are a variety of certificates that are required for registered nurses to acquire in order to work in the PICU. One of these certifications is the Critical Care Registered Nurse (pediatric) certificate. This certificate allows nurses to care for critically ill pediatric patients in any setting, not just the PICU. Other certificates include cardiopulmonary resuscitation, pediatric basic life support, and pediatric advance life support.\n\nIn the PICU, it is important that all team members hold a wide variability of training and experience in order to provide high quality care. Due to different priorities among inter-professionals, the PICU care team includes many different roles. (physicians, nurses, pharmacists, respiratory therapists, child life, intensivists, cardiologists, physical / occupational therapists, social workers) Each member of the inter-professional team are highly skilled and trained to deliver the best care for each and every child. It is important for each one to introduce themselves to the family and to explain their role to hopefully expand understanding to family members.\n\nThe patients in the PICU are the most critically ill children in the hospital setting. There are times where these children do not have the best outcomes, which may result in permanent deficits or even death. There are times where nothing more could have been done to improve the outcome for these patients. However, there are times where care could have differed and the end result may have been better.\n\nThere are a variety of factors that have led to poor outcomes in PICU patients. The main factor that leads to inadequate care for PICU patients is improper health assessment by the healthcare providers. This may include not observing a change in the patient’s clinical status, delayed resuscitation efforts, delayed decision making, or a combination of any of these factors. If any of these factors do occur, it may result in permanent deficits in the most critical patients.\n\nMeasures may be taken to prevent improper assessments from occurring. Proper education on how to conduct a proper assessment and how to recognize a critically ill pediatric patient can improve patient outcomes. This includes being able to recognize signs of deteriorating clinical status and perform proper triage of patients. This education is not only for the PICU staff, but also for emergency medical services, the emergency department staff, and staff of the pediatric unit.\n\n== Challenges of Working ]working in the PICU result may in emotional stress and/or occupational burnout of the staff. For patients that do get discharged from the unit, often times they are not free of chronic conditions or disabilities. There are other factors that lead to stressful work conditions for the staff of the PICU. The staff often work for long periods of time in order to stabilize the most critically ill pediatric patients. They must collaborate with other members the healthcare team in order to develop the best plan of care. Once a plan of care is developed, then the staff must communicate the plan with the patient's family in order to see if it matches their beliefs. If the plan of care does not match the family's beliefs, then it must be modified the plan causing more stress on the staff. All of this causes the staff a great deal of stress and each member of the unit must develop their own coping mechanisms in order to prevent burnout.\n\n\n"}
{"id": "38162538", "url": "https://en.wikipedia.org/wiki?curid=38162538", "title": "Permanent Representative of the Philippines to the United Nations", "text": "Permanent Representative of the Philippines to the United Nations\n\nThe Ambassador and Permanent Representative of the Philippines to the United Nations () is the head of the diplomatic mission of the government of the Philippines to the United Nations.\n\n"}
{"id": "21980158", "url": "https://en.wikipedia.org/wiki?curid=21980158", "title": "Pollin Prize for Pediatric Research", "text": "Pollin Prize for Pediatric Research\n\nThe Pollin Prize for Pediatric Research was an annual award given to physicians who contributed important advances to the field of pediatrics, and was the only existing international pediatric award. The prize was created in 2002 by Irene and Abe Pollin, and funded by the Linda and Kenneth Pollin Foundation. It was administered by the NewYork-Presbyterian Hospital, and as of 2003, Dr. Rudolph Leibel was chairman of the selection panel. \n\nThe prize is no longer awarded.\n\n"}
{"id": "4185273", "url": "https://en.wikipedia.org/wiki?curid=4185273", "title": "Protection against Accidents (Dockers) Convention, 1929 (shelved)", "text": "Protection against Accidents (Dockers) Convention, 1929 (shelved)\n\nProtection against Accidents (Dockers) Convention, 1929 (shelved) is an International Labour Organization Convention.\n\nIt was established in 1929:\nHaving decided upon the adoption of certain proposals with regard to the protection against accidents of workers employed in loading or unloading ships...\n\nThe concepts contained in the convention were revised and included in ILO Convention C32, Protection against Accidents (Dockers) Convention (Revised), 1932, and again in ILO Convention C152, Occupational Safety and Health (Dock Work) Convention, 1979.\n\nPrior to it being shelved, the convention had been ratified by four states.\n\n"}
{"id": "1978571", "url": "https://en.wikipedia.org/wiki?curid=1978571", "title": "Registered Accessibility Specialist", "text": "Registered Accessibility Specialist\n\nA Registered Accessibility Specialist (RAS) is a professional licensed with the U.S. state of Texas to determine if a part of the built environment (building, park, sidewalk, parking lot) is compliant with Americans with Disabilities Act and state laws. An RAS reviews construction documents to determine accessible design and inspects finished buildings to verify accessible construction.\n\n"}
{"id": "38670017", "url": "https://en.wikipedia.org/wiki?curid=38670017", "title": "Restroom Access Act", "text": "Restroom Access Act\n\nThe Restroom Access Act, also known as Ally's Law, is legislation passed by several U.S. states that requires retail establishments that have toilet facilities for their employees to also allow customers to use the facilities if the customer has an inflammatory bowel disease or other medical condition requiring immediate access to a toilet.\n\nThe law is named for Ally Bain, a 14-year-old girl from Illinois who had a flare-up of her Crohn's disease while shopping at a large retail store and was subsequently denied use of the employee-only restroom, causing her to soil herself. Bain's mother vowed it would never happen to anyone else. The two met with Illinois State Representative Kathy Ryg, helped her draft a bill, and testified before a committee at the state capital. The bill was signed into law in August 2005, making Illinois the first U.S. state to do so.\n\nAs of April 2013, at least 14 U.S. states had passed versions of the law. They include Colorado, Connecticut, Illinois, Kentucky, Maryland, Massachusetts, Michigan, Minnesota, Ohio, Oregon, Tennessee, Texas, Wisconsin, and Washington. A Virginia bill, which would have levied fines of $100 for non-compliance, was shelved due to concerns about exposing businesses to lawsuits, as well as concerns about security and intellectual property.\n\nThere is support for a federal version of the act, but some small-business people object to the public using their employee bathrooms.\n\nIn general, each state requires that the customer present a document signed by a medical professional attesting that the customer uses an ostomy device or has Crohn's disease, ulcerative colitis, or other inflammatory bowel disease or medical condition requiring access to a toilet facility without delay. In at least two states, Oregon and Tennessee, the customer can present an identification card issued by a national organization advocating for the eligible medical condition.\n\nSome states also include pregnancy as a covered medical condition.\n\nThe Restroom Access Act of Illinois states:\n\nIn Australia, the association Crohn's & Colitis Australia (CCA) encourages businesses to support people with such medical conditions by recognizing the Can't Wait Card issued by the CCA. The CCA states:\n\nOther countries including the UK have similar programs of voluntary participation by businesses, one such program in the UK is the Bladder & Bowel Community's Just Can't Wait Card \n\nA card with no country specific indications is available through www.theibdlife.com/access explaining the possibility of legislation and the gravity of the card holders disability and need for restroom access.\n\n"}
{"id": "2352376", "url": "https://en.wikipedia.org/wiki?curid=2352376", "title": "Riding for the Disabled Association", "text": "Riding for the Disabled Association\n\nThe Riding for the Disabled Association, also known as the RDA is a United Kingdom based charity focused on providing horse-riding and carriage driving lessons to people with both developmental and physical disabilities.\n\nIn addition to running international operations, the RDA is also a member of the international umbrella group, the Federation Riding for the Disabled International. In the UK, the association is one of 16 members that make up the British Equestrian Federation.\n\nThe Ancient Greeks as early as 600 B.C. and later the Romans recognised the therapeutic value of horseback riding. In Europe, France in particular, had documented the therapeutic use of horse riding as early as 1875. More recently, in the United Kingdom, Dame Agnes Hunt at the Orthopaedic Hospital at Oswestry during 1901 employed similar techniques. Later Miss Olive Sands MCSP took her horses to the Oxford Hospital to provide riding for the rehabilitation of Soldiers wounded in the trenches during the First World War.\n\nThe achievements of Lis Hartel of Denmark are generally regarded as the impetus for the formation of therapeutic horseback riding centres throughout Europe. Polio had impaired Hartel’s mobility but not her spirit. In 1952 she won the silver medal for Individual Dressage during the Helsinki Olympics. Medical and equine professionals took notice and very soon centres for therapeutic horseback riding began to form throughout the United Kingdom and Europe.\n\nIn 1951 Elsbet Bodtker, having met Liz Hartel, was inspired to give lessons to young patients on her son’s ponies. She was uniquely qualified as an international rider and a Mensendieck physiotherapist, and so had the respect and approval of the doctors.\n\nIn the United Kingdom Mrs. Norah Strang, a member of the British Polio Fellowship, organized riding for children disabled by polio, at a local riding centre. Her riders won the first national competition at Stoke Mandeville Hospital sports centre. In 1957 another remarkable lady, Mrs. Jacques, made contact with a physiotherapist in Copenhagen. By this time she had organized a team of helpers and ponies, and was offering riding to a local orthopaedic hospital. She also met Mrs. Regester who had returned from Malaya where she had been teaching disabled children to ride for some years at the request of their doctors.\n\nAlthough the British medical profession was still cautious, after watching a demonstration by Mrs. Jacques and her riders at the Knightsbridge Barracks, the senior physiotherapist at St. Thomas’ Hospital was impressed. This was the start of a long and successful partnership.\n\nMrs. Jacques had so many enquiries that she was convinced they should start their own riding centre. The result was Grange Farm in Chigwell. A number of groups were set up by the British Red Cross Society, all of these eventually coming under the RDA umbrella.\n\nThe Princess Anne opened Hadleigh RDA on 13 June 1985. The original formation of the organisation came about during 1965, but the Charity, The Riding for the Disabled Association did not come into being until 1969. At that time Lavinia, Duchess of Norfolk was president, with HRH The Princess Anne as Patron. The RDA became a Limited Company during 2004.\n\nThe RDA is in effect a Federation of some 500 small independent groups, such as The Shelley Centre, and currently supports over 26,500 adults and children by providing riding, carriage driving and vaulting each year.\n\nIn 1996 equestrian became a Paralympic sport at the Games in Atlanta\n. It was the largest event in Paralympics history, with 122 countries participating and it is now possible for those coming into the RDA who have the right ability and skill to eventually represent their Country as Paralympic competitors by progression through organised RDA events both regionally and nationally with the likes of Competitions held annually at Hartpury College.\n\nFrom simple beginnings the organisation has progressed in sophistication and has benefited greatly from the advice, training and guidance given by specialist Physiotherapists where planning and treatment programmes are developed for individuals, both children and adults alike. This, together with the introduction and evolution of special Saddles, Stirrups and Reins and the use of formal and protective riding clothing have added further to the development process and professionalism of the organisation. The organisation, at a few locations, now has in place sophisticated computerised mechanical horses, one of which is at The Shelley Centre, which can emulate the walk, trot and canter paces of a real horse thus enabling riders who for various reasons cannot ride an actual horse to experience the therapeutic benefits of horse riding.\n\nThe Riding for the Disabled Association is not confined to the UK. That vision has spread around the world. \nRDA Centres now operate in over 45 countries in Europe, Asia, The Americas, and Oceania. Countries include: Australia (130 centres), Brasil, Canada (80 centres), Ireland, France, Germany, Italy, Japan, Mexico, New Zealand (55 centres), Singapore, South Africa, Sweden, UAE, and USA to name a few.\n\n\n"}
{"id": "58794451", "url": "https://en.wikipedia.org/wiki?curid=58794451", "title": "Salah Mohammed Tubaigy", "text": "Salah Mohammed Tubaigy\n\nSalah Mohammed Abdah Tubaigy (, born 20 August 1971), also spelled Tubaiqi, is the head of the Saudi Scientific Council of Forensics and Colonel in the armed forces of Saudi Arabia.\n\nTubaigy is a professor in the criminal evidence department at Naif Arab University for Security Sciences in Riyadh, and is known for pioneering rapid and mobile autopsies. He has taught and published papers on gathering DNA evidence and dissecting human bodies and has had a prominent role in Saudi Arabia’s state security apparatus and scientific community for around 20 years. He designed a mobile autopsy lab to accompany Muslims on the hajj to Mecca, and said it can \"provide the dissection service to the security authorities in a record time.\"\n\nIn 2018 Al Jazeera reported that Tubaigy was involved in the murder and dismembering of Jamal Khashoggi. A source said \"Tubaigy began to cut Khashoggi’s body up on a table in the study while he was still alive... As he started to dismember the body, Tubaigy put on earphones and listened to music. He advised other members of the squad to do the same.\" Tubaigy was traveling under a special(S052512) passport issued by the Kingdom Of Saudi Arabia Ministry Of Foreign Affairs according to the 2D barcode provided by Turkish authorities. \n\nAn official cited by \"The New York Times\" reportedly described a quick assassination, and dismemberment by a team of Saudi agents, with a bone saw brought for the purpose. \"It is like \"Pulp Fiction,\"\" the official said.\n\nTubaigy served on the editorial board to the King Fahd Security College. In late October 2018, his name was removed from the publication’s website.\n\n"}
{"id": "8510553", "url": "https://en.wikipedia.org/wiki?curid=8510553", "title": "Serving suggestion", "text": "Serving suggestion\n\nServing suggestion is a disclaimer used on food packaging. The phrase is used as legal fine print with a picture of the product. The picture attempts to portray the manufacturer's food in the most favorable or appetizing way possible, sometimes including other foods that the package does not contain. For example, the labeling on a box of cereal may feature a picture of a cereal bowl filled with that cereal, milk and a fruit garnish, or a jar of mustard may picture a hot dog in a bun with mustard on it. The serving suggestion may portray the serving size of the food used, but just as often a much larger serving is shown as part of the marketing of the item. As a disclaimer a serving suggestion also serves to remove any legal obligation on the part of the manufacturer to provide the other items pictured with their product.\nIn Ireland this is an illegal practice.\n\nWhen used with a cooking recipe, it is a recommendation from the author as a way to serve the dish.\n"}
{"id": "36261577", "url": "https://en.wikipedia.org/wiki?curid=36261577", "title": "Smoking in Brazil", "text": "Smoking in Brazil\n\nBrazil has some of the strictest smoking laws in the Americas. Smoking in Brazil is forbidden in all enclosed public spaces except for specifically designated smoking areas. Since 15 December 2011, Federal Law 12546 (article 49) forbids smoking in enclosed spaces in the entire country, including restaurants and bars.\n\nIn Brazil, the legal age for sale and consumption of tobacco is 18. Tobacco advertising is restricted to posters in shops, and is banned on television and radio. All cigarette packs contain advertisements against smoking and government warnings about possible adverse health effects of smoking.\n\nIn 2001, Brazil is one of the first countries to outlaw the usage of descriptors, such as \"light\", \"low tar\" and \"ultra-light\". In 2012, Brazil also became the first country to outlaw flavored cigarettes, including menthol cigarettes, although such prohibition has been revogued in 2013 by Rosa Weber, a judge of the Supreme Court.\n\nSão Paulo became the first state in Brazil to adopt the most comprehensive ban, being followed by Rio de Janeiro and Minas Gerais. Under the new regulation there are no smoking sections in any place around the state. The law became effective from 7 August 2009 with smoking forbidden in all indoor and enclosed public spaces such as bars and restaurants, clubs, shopping malls, movie theatres, banks, supermarkets, bakeries, chemist shops, health places, government offices and schools.\n\nSmoking is also no longer allowed in São Paulo in work and study places, libraries, buses, cabs, commercial and residential common areas, hotels and inns.\n\nThe São Paulo government has trained 500 specialised agents to make sure the rule is respected at all times. The first team was trained to measure ambient smoke in an area and to warn smokers about the risks for their health.\n\nAnybody violating the law is charged with a fine. Public sites can be punished with a maximum fine of R$ 1,585 (Brazilian currency, ~$USD 478). If there is a second infraction the site is closed. According to surveys, 88% of São Paulo’s inhabitants support the smoke-free law.\n"}
{"id": "3299540", "url": "https://en.wikipedia.org/wiki?curid=3299540", "title": "Sukkur Barrage", "text": "Sukkur Barrage\n\nSukkur Barrage (, ) is a barrage on the River Indus near the city of Sukkur in the Sindh province of Pakistan. The Barrage was built during the British Raj from 1923 to 1932 and was named Lloyd Barrage. The Sukkur Barrage, is the pride of Pakistan’s Irrigation system as it is the largest single Irrigation network of its kind in the world. It irrigates from Sukkur District in the North, to Mirpurkhas/ Tharparkar and Hyderabad districts in the South of Sindh, almost all parts of the Province except few. It is situated about 300 miles North East of Karachi, 3 miles below the Railway Bridge, or the Sukkur Gorge. The introduction of barrage-controlled irrigation system resulted in more timely water supplies for the existing cultivated areas of Sindh Province of Pakistan. \n\nSindh survives almost entirely on the water of the River Indus as there is very limited groundwater available. Rainfall in the province averages between 100 and 200 mm per year, while the evaporation rate is between 1,000 and 2,000 mm. Thus, Sindh is arid and it is only the Indus which irrigates otherwise barren lands of Sindh. Regular surveys have not been carried out to assess the availability of groundwater in the province. Various sources estimate that its volume is between three and five MAF scattered in 28 per cent of the geographical area of Sindh. However, some experts suggest it to be less than these estimates. This water is found mainly along the Indus water channels and in the few natural underground streams.\n\nThe idea of Sukkur Barrage was conceived by Mr. C.A. Fife, in the year 1868. However, the project was finally sanctioned in 1923. It was constructed under the overall direction of Sir Charlton Harrison, CIE, as chief engineer, while Sir Arnold Musto, CIE, was the architect and engineer of the scheme. The Head Works and Canals were completed by 1932. On its completion it was opened by His Excellency The 1st Earl of Willingdon, Viceroy of India. The scheme had been launched by the Governor of Bombay, Sir George Lloyd (later known as Lord Lloyd), and it was named in his honour. Syed Ghulam Mustafa of the Imperial Service also played an instrumental role in the design and construction of the barrage. \n\nTo revitalise its water storage capacity and distribution efficiency, the Government of Pakistan embarked upon a massive rehabilitation work of Sukkur Barrage. The work was started by Pakistan Army Engineering Corps and Frontier Works Organisation (FWO) on 22 November 2004, and was completed ahead of the deadline in July 2005, with the cost of just 15 million US$ (US Dollars). Experts believe that the rehabilitation of the barrage has enhanced its efficiency for another 60 to 70 years.\n\nSukkur Barrage is used to control water flow in the River Indus for the purposes of irrigation and flood control. This Barrage which is the backbone of the economy of the entire Country enables water to flow through what was originally a network of seven canals long, feeding the largest irrigation system in the world, with more than 7.63 million acres of irrigated land which forms approximately 25% of total canal irrigated area of the country. The retaining wall of the Barrage has 66 spans (outfall gates), each wide and weighing 50 tons. \n\nThe Nara canal which is one of the 7 Canals off taking from this Barrage is the longest canal of this country, carrying discharge almost equal to that of Thames River at London and its bed width which is 346 ft. is 1 ½ (one and half) times as big as of Suez Canal. In fact Nara Canal is not a man-made canal as it was the southernmost part of Hakro River which emanated from the foot hills of Sutlej which after traversing through the Punjab and Bhawalpur Plains joined Nara through Raini River, the remnants of which are still exiting in Ghotki Taluka. This Canal caters for an area of 2.3 million acres.\n\nThe next largest canal is Rohri Canal which though slightly shorter in length than Nara Canal is yet taking discharge much more than the former. It has cultivable area of 2.6 million acres settled for Irrigation. Cotton, wheat and sugar-cane are the main crops grown on this canal system. All the four canals on the left and two canals on the right bank of River Indus are perennial canals, delivering Irrigation supplies all the year round. The seventh canal namely, Rice Canal on the right side is a seasonal canal which flows only in Kharif Season and is designed for rice cultivation. The N.W. Canal on the right bank provides perennial Irrigation for an area of 965,000 (0.965 million) acres out of which 184,000 acres are situated in Baluchistan Province.\n\nIndus River dolphins are occasionally seen upstream of the barrage.\n"}
{"id": "22836947", "url": "https://en.wikipedia.org/wiki?curid=22836947", "title": "Wellbeing of Women", "text": "Wellbeing of Women\n\nWellbeing of Women is a charity dedicated to improving the health of women and babies. It raises money to invest in medical research and the development of specialist doctors and nurses working in the field of reproductive health. Every year the charity invests in research projects and allocates funds towards the training of doctors and midwives. The charity also disseminates information on women's reproductive health.\n\nThe charity is based in London, and consists of: a team of staff and volunteers; a board of trustees headed up by Sir Victor Blank; and a Research Advisory Committee.\n\nThe charity was established in 1964 by eminent obstetrician Professor Will Nixon, who was touched by the grief of a young man whose wife died during childbirth. It was originally called The Childbirth Research Centre. He gathered a group of illustrious founder members including Lord Brain, a neurologist who cared for Winston Churchill on his deathbed in 1965; Sir John Peel, the surgeon-gynaecologist to the Queen; Professor Dugald Baird and Sir George Pinker, an obstetrician who delivered nine royal babies including Princes William and Harry. The founders’ aim was to reduce the number of women and babies who died during pregnancy and childbirth.\n\nAn early donation established that a deficiency in folic acid was a factor in malformed babies. Pregnant women across the world now take folic acid supplements.\n\nThe charity also funded crucial research into epidurals which means that millions of women now benefit from a relatively pain-free birth.\n\nIn 1972 the charity was renamed Birthright.\n\nResearch projects they funded created the ground rules that mean many thousands of women have safe laser treatment to treat cervical cancer. They also enabled breakthroughs into monitoring babies in the womb. One early pieces of research into the diagnosis of Down’s Syndrome in pregnant women helped make the amniocentesis test more accurate. The charity also discovered a link between smoking and pre-eclampsia and babies being born underweight.\n\nHRH Diana, Prince of Wales, became the patron of Birthright in 1984.\n\nShe was devoted to the charity, explaining: \"To long for a baby and not to be able to have one must be devastating. I don't know how I would cope with that. And if my work for Birthright can alleviate that suffering for just one couple, it will have been all worthwhile.\"\n\nDuring her time as patron, the charity funded work into IVF and also investigated HPV, the virus that causes cervical cancer leading to the cervical cancer screening programme. The charity’s research into recurrent miscarriage also meant that, out of a research group of 2000 women who had been told they would never have children, 79% went on to have babies. Professor Stuart Campbell of King’s College, London, received funding from the charity for a project that developed an ultrasound that would identify babies at risk of stillbirth by finding out if they had abnormal blood flow.\n\nDuring the 1990s, the charity funded research which discovered that ultrasound could be used to detect abnormalities in early pregnancy. This resulted in pre-natal screening for Down's Syndrome. The charity enabled breakthroughs in IVF, by funding research into the optimum time for embryo transfer, and by looking at how eggs mature in the ovary. This was described at the time as ‘the biggest advance in fertility treatment’. They also funded research into gynaecological cancers; contraception; and the bone density of post-menopausal women.\n\nThe charity was renamed ‘Wellbeing of Women’, in 2004.\n\nWellbeing of Women partnered with 100 Women in Hedge Funds to fund a project which advanced our understanding of the genetics of Cerebral Palsy. The charity also funded research that helped reverse brain damage in newborn babies and a project that helped women suffering from recurrent miscarriage go on to have a successful pregnancy, by identifying ‘Natural Killer cells’ in the mother’s immune system.\n\nIn 2007, then British Prime Minister's wife Sarah Brown became patron of Wellbeing of Women.\n\nIn 2008, Wellbeing of Women was announced as one of the beneficiary charities of the Lord Mayor’s Appeal, along with ORBIS. Prince William was Patron of the appeal. Funds raised from the appeal enabled Wellbeing of Women to establish the Baby Bio Bank, a unique international resource storing genetic data from ‘family trios’ of mother, father and baby. This bank of genetic information will facilitate on-going research into the persistent complications of pregnancy and birth, including miscarriage, premature birth and pre-eclampsia.\n\nIn March 2013, Wellbeing of Women launched a major new partnership with PwC. PwC are long term sponsors of two of Wellbeing of Women's flagship events - the Annual Women's Lunch Debate and Annual Celebrity Cricket Match – but in 2013 broadened and increased their support of the charity, by supporting two Wellbeing of Women funded researchers.\n\nWellbeing of Women has an ongoing partnership with BHS. Karren Brady designed a collection of workwear dresses to be sold at BHS in aid of the charity in 2012, and in 2013, Emma Forbes launched another collection of dresses to be sold in aid of the charity.\n\nIn December 2011, in the run-up to the 2012 Summer Olympics in Stratford, London, Clara Maidment shot a charity calendar in aid of Wellbeing of Women. Twelve British female sporting celebrities who posed in the lingerie of Nichole de Carle, wearing jewellery by Salima Hughes and Coster Diamonds.\n\nWellbeing of Women runs a series of Literary Lunches at Fortnum & Mason, which feature a prominent author in conversation with Eve Pollard OBE or Baroness Jenkin of Kennington. Previous authors have included PD James, Barbara Taylor Bradford, Penny Vincenzi, Julian Fellowes and Ffion Hague.\n\nThey also run a series called 'An Audience with...' at Fortnum and Mason.\n\nWellbeing of Women is the beneficiary charity of the Inspirational Women of the Year Awards, which are run in association with the Daily Mail, and in 2012 were sponsored by Sanctuary Spa.\n\nOn 12 October 2011, the Right Reverened Vincent Nichols gave the first annual Sir George Pinker Memorial Address.\n\n"}
{"id": "1767101", "url": "https://en.wikipedia.org/wiki?curid=1767101", "title": "World Federation for Mental Health", "text": "World Federation for Mental Health\n\nThe World Federation for Mental Health (WFMH) is an international, multi-professional non-governmental organization (NGO), including citizen volunteers and former patients. It was founded in 1948 in the same era as the United Nations (UN) and the World Health Organization (WHO).\n\nThe goal of this international organization includes; \n\nThe Federation, through its members and contacts in more than 94 countries on six continents, has responded to international mental health crises through its role as the only worldwide grassroots advocacy and public education organization in the mental health field. Its organizational and individual membership includes mental health workers of all disciplines, consumers of mental health services, family members, and concerned citizens. At its very outset the WFMH was concerned with educating both the public and influential professionals, and with human relations, with a view both to the health of individuals and that of groups and nations. The WFMH founding document, \"Mental Health and World Citizenship\", understood \"world citizenship\" in terms of a \"common humanity\" respecting individual and cultural differences, and declared that \"the ultimate goal of mental health is to help [people] live with their fellows in one world. Members include mental health service providers and service users. In 2009, the World Fellowship for Schizophrenia and Allied Disorders, an international network of families of people with serious mental illness, merged with the World Federation. The World Federation has close ties with the World Health Organization. For many years after its founding, the WFMH was the only NGO of its kind with a close working relationship with UN agencies, particularly the WHO. In recent decades, though, a number of international mental health organizations, often limited to members of particular professions, have developed. In varying degree they have filled needs formerly addressed mainly by WFMH The WFMH envisions a world in which mental health is a priority for all people. Public policies and programs reflect the crucial importance of mental health in the lives of individuals. \nThe first Director General of the WHO, G. Brock Chisholm, who was a psychiatrist, was one of the leaders in forming the federation with the goal of creating a representative organization that could consult with the UN on mental health issues.\n\nThe mission of the World Federation for Mental Health is to promote the advancement of mental health awareness, prevention of mental disorders, advocacy, and best practice recovery focused interventions worldwide. Mental health day is celebrated at the initiative of the World Federation of Mental Health and WHO supports this initiative through raising awareness on mental health issues using its strong relationships with the Ministries of health and civil society organizations across the globe. Mental Illness Awareness Week (MIAW) is an annual national public education campaign designed to help open the eyes of Canadians to the reality of mental illness. The week was established in 1992 by the Canadian Psychiatric Association, and is now coordinated by the Canadian Alliance on Mental Illness and Mental Health (CAMIMH) in cooperation with all its member organizations and many other supporters across Canada.\n\n\n\n\n"}
