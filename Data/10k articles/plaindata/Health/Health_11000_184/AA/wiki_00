{"id": "58516158", "url": "https://en.wikipedia.org/wiki?curid=58516158", "title": "2018 Australian rockmelon listeriosis outbreak", "text": "2018 Australian rockmelon listeriosis outbreak\n\nThe 2018 Australian rockmelon listeriosis outbreak was an outbreak of Listeriosis, caused by the bacteria \"Listeria monocytogenes\", later traced to rockmelon (also known as cantaloupe) grown by Rombola Family Farms in the Riverina region of New South Wales, Australia.\n\nThe outbreak killed six people and infected a further 16 in Australia and infected two more in Singapore, who had consumed rockmelon imported from Australia. \n\nThe NSW Food Authority began investigating a link between an outbreak of Listeriosis and the consumption of rockmelon in January 2018. NSW Health first issued a public warning on 28 February. This prompted the Australian Melon Association to warn consumers to either dispose of, or return the place of purchase, any rockmelons purchased prior to 28 February. \n\n"}
{"id": "3041004", "url": "https://en.wikipedia.org/wiki?curid=3041004", "title": "Adaptive rowing", "text": "Adaptive rowing\n\nAdaptive rowing is a category of rowing race for those with physical disabilities. Under FISA rules there are three categories for adaptive rowers:\n\n\nAt FISA events there are 5 boat events (standard nomenclature is used):\n\nRacing was held over 1,000 m (rather than the standard 2,000 m), but from 2017 the distance was changed to the standard 2,000m. In mixed events half the crew must be male and other half female (coxswain may be of either gender and may be able bodied). Single shells for the PR1 category must have stabilising pontoons attached to the riggers.\n\nAdaptive events were added to the World Rowing Championships in 2002 and took place at the 2008 Summer Paralympics in Beijing, China.\n\n"}
{"id": "4452237", "url": "https://en.wikipedia.org/wiki?curid=4452237", "title": "Allegations of CIA drug trafficking", "text": "Allegations of CIA drug trafficking\n\nThe United States Central Intelligence Agency (CIA) has been accused of involvement in drug trafficking. Books and investigations on the subject that have received general notice include works by historian Alfred McCoy; professor and diplomat Peter Dale Scott; and journalists Gary Webb, Michael C. Ruppert and Alexander Cockburn, as well as by writer Larry Collins. These claims have led to investigations by the United States government, including hearings and reports by the United States House of Representatives, Senate, Department of Justice, and the CIA's Office of the Inspector General. The subject remains controversial.\n\nFollowing is a summary of some of the main claims made by geographical area.\n\nDuring the Korean War, the first allegations of CIA drug trafficking surfaced after 1949, stemming from a deal whereby arms were supplied to Chiang Kai-shek's defeated generals in exchange for intelligence. Later in the same region, while the CIA was sponsoring a \"Secret War\" in Laos from 1961 to 1975, it was openly accused of trafficking heroin in the area then known as the Golden Triangle.\n\nTo fight its \"Secret War\" against the Pathet Lao communist movement of Laos, the CIA used the Miao/Meo (Hmong) population. Because of the war, the Hmong depended upon opium poppy cultivation for hard currency. The Hmong were very important to CIA operations and the CIA was very concerned with their well-being. The Plain of Jars had been captured by Pathet Lao fighters in 1964, which resulted in the Royal Lao Air Force being unable to land its C-47 transport aircraft on the Plain of Jars for opium transport. The Royal Laotian Air Force had almost no light planes that could land on the dirt runways near the mountaintop poppy fields. Having no way to transport their opium, the Hmong were faced with economic ruin. The CIA front Air America was, therefore, the only airline available in northern Laos. \"According to several unproven sources, Air America began flying opium from mountain villages north and east of the Plain of Jars to CIA asset Hmong General Vang Pao's headquarters at Long Tieng.\"\n\nLarry Collins' sources alleged that, \"During the Vietnam War, US operations in Laos were largely a CIA responsibility. The CIA's surrogate there was a Laotian general, Vang Pao, who commanded Military Region 2 in northern Laos. He enlisted 30,000 Hmong tribesmen in the service of the CIA. These tribesmen continued to grow, as they had for generations, the opium poppy. Before long, someone--there were unproven allegations that it was a Mafia family from Florida--had established a heroin drug refinery lab in Region Two. The lab's production was soon being ferried out on the planes of the CIA's front airline, Air America. A pair of BNDD [the predecessor of the US Drug Enforcement Agency] agents tried to seize an Air America.\"\n\nFurther documentation of CIA-connected Laotian opium trade was provided by Rolling Stone magazine in 1968, and by Alfred W. McCoy in 1972.\n\nThe CIA's front company, Air America was alleged to have profited from transporting opium and heroin on behalf of Hmong leader Vang Pao, or of \"turning a blind eye\" to the Laotian military doing it. This allegation has been supported also by former Laos CIA paramilitary Anthony Poshepny (aka Tony Poe), former Air America pilots, and other people involved in the war. It is portrayed in the movie \"Air America\". However, historian William M. Leary, writing on behalf of Air America, claimed that the opium transportation was done without the active participation of airline employees and that the airline did not trade in drugs. Curtis Peebles denies that Air America employees actively participated in opium transportation, citing Leary's study as evidence.\n\nHistorian Alfred W. McCoy stated that:\nThe CIA made its own internal inquiries of its staff and clients in Laos concerning the drug trade, but never denied the essential allegation. Rather, the CIA took the position that trading in opium was legal in Laos until 1971. The CIA explained that opium served the isolated Lao hill tribes as their sole cash crop and that opium was one of the few medicines available in the primitive living circumstances.\n\nThe CIA had its own internal security agents investigating possible commercial opium exports mid-1968 onward. Air America, the CIA's airline was barred from CIA airfields on suspicion of drug smuggling. One Hmong guerrilla commanding officer was pressured into giving up dealing in opium. The CIA concluded that small amounts of opium might have been smuggled via Air America, given wartime conditions. The Agency's case officers even staged a couple of impromptu raids on drug refineries, but were reined in by the CIA Office of General Counsel.\n\nA number of allegations have been written about and several local, state, and federal investigations have taken place related to the alleged use of the Mena Intermountain Municipal Airport as a CIA drop point in large scale cocaine trafficking beginning in the early 1980s. Some conspiracy theories regarding the airport extend to alleging the involvement of figures such as Oliver North and former presidents George H. W. Bush and Bill Clinton.\n\nThe CIA's self-investigation, overseen by the CIA's inspector general, concluded that the CIA had no involvement in or knowledge of any illegal activities that may have occurred in Mena. The report said that the agency had conducted a training exercise at the airport in partnership with another Federal agency and that companies located at the airport had performed \"routine aviation-related services on equipment owned by the CIA\".\n\nA film about these events called \"American Made\" focusing on the notorious pilot and Medellin cartel drug smuggler Barry Seal, portrayed by Tom Cruise, was released on September 29, 2017.\n\nIn October 2013, two former federal agents and an ex-CIA contractor told an American television network that CIA operatives were involved in the kidnapping and murder of DEA covert agent Enrique Camarena, because he was a threat to the agency's drug operations in Mexico. According to the three men, the CIA was collaborating with drug traffickers moving cocaine and marijuana to the United States, and using its share of the profits to finance Nicaraguan Contra rebels attempting to overthrow Nicaragua's Sandinista government. A CIA spokesman responded, calling it \"ridiculous\" to suggest that the Agency had anything to do with the murder of a US federal agent or the escape of his alleged killer.\n\nThe Honduran drug lord Juan Matta-Ballesteros was the owner of SETCO, an airline which the Nicaraguan Contras used to covertly transport military supplies and personnel in the early 1980s. Writers such as Peter Dale Scott and Jonathan Marshall have suggested that the U.S. government's desire to conceal or protect these clandestine shipments led it to close the DEA office in Honduras when an investigation began into SETCO, allowing Matta-Ballesteros to continue and expand his trafficking.\n\nIn 1986, the United States Senate Committee on Foreign Relations began investigating drug trafficking from Central and South America and the Caribbean to the United States. The investigation was conducted by the Sub-Committee on Terrorism, Narcotics, and International Operations, chaired by Senator John Kerry, so its final 1989 report was known as the Kerry Committee report. The Report concluded that \"it is clear that individuals who provided support for the Contras were involved in drug trafficking, the supply network of the Contras was used by drug trafficking organizations, and elements of the Contras themselves knowingly received financial and material assistance from drug traffickers.\"\n\nIn 1996 Gary Webb wrote a series of articles published in the \"San Jose Mercury News\", which investigated Nicaraguans linked to the CIA-backed Contras who had smuggled cocaine into the U.S. which was then distributed as crack cocaine into Los Angeles and funneled profits to the Contras. His articles asserted that the CIA was aware of the cocaine transactions and the large shipments of drugs into the U.S. by the Contra personnel and directly aided drug dealers to raise money for the Contras. The \"Los Angeles Times\", \"The New York Times\", and \"The Washington Post\" launched their own investigations and rejected Webb's allegations. In May 1997, \"The Mercury News\" executive editor Jerry Ceppos, who had approved the series, published a column that acknowledged shortcomings in the series reporting, editing, and production, while maintaining the story was correct \"on many important points.\" Webb later published a book based on the series, \"Dark Alliance: The CIA, the Contras, and the Crack Cocaine Explosion\".\n\nThe 2014 movie \"Kill the Messenger\" depicted actor Jeremy Renner as Gary Webb.\n\nIn 1989, the United States invaded Panama as part of Operation Just Cause, which involved 25,000 American troops. General Manuel Noriega, head of government of Panama, had been giving military assistance to Contra groups in Nicaragua at the request of the U.S.—which, in exchange, allowed him to continue his drug-trafficking activities—which they had known about since the 1960s. When the DEA tried to indict Noriega in 1971, the CIA prevented them from doing so. The CIA, which was then directed by future president George H. W. Bush, provided Noriega with hundreds of thousands of dollars per year as payment for his work in Latin America. However, when CIA pilot Eugene Hasenfus was shot down over Nicaragua by the Sandinistas, documents aboard the plane revealed many of the CIA's activities in Latin America, and the CIA's connections with Noriega became a public relations \"liability\" for the U.S. government, which finally allowed the DEA to indict him for drug trafficking, after decades of allowing his drug operations to proceed unchecked. Operation Just Cause, whose ostensible purpose was to capture Noriega, pushed the former Panamanian leader into the Papal Nuncio where he surrendered to U.S. authorities. His trial took place in Miami, where he was sentenced to 45 years in prison.\n\nNoriega's prison sentence was reduced from 30 years to 17 years for good behavior. After serving 17 years in detention and imprisonment, his prison sentence ended on September 9, 2007. He was held in U.S. custody before being extradited to France where he was sentenced to 7 years for laundering money from Colombian drug cartels. Noriega was extradited to Panama on December 11, 2011 (incarcerated at El Renacer prison, in Gamboa), but hospitalized on February 5, 2012 (diagnosed with a brain tumor), and sent back to prison shortly thereafter. On January 23, 2017 he was released from prison and placed under house arrest (to prepare for surgery). On March 7, 2017 he suffered a brain hemorrhage during surgery which left him in critical condition, to which he succumbed to death on May 29, 2017 (at the age of 83).\n\nA failed CIA anti-drug operation in Venezuela resulted in at least a ton of cocaine being smuggled into the United States and sold on the streets. The incident, which was first made public in 1993, was part of a plan to assist an undercover agent to gain the confidence of a Colombian drug cartel. The plan involved the unsupervised shipment of hundreds of pounds of cocaine from Venezuela. The drug in the shipments was provided by the Venezuelan anti-drug unit which was working with the CIA, using cocaine seized in Venezuela. The shipments took place despite the objections of the U.S. DEA. When the failed plan came to light, the CIA officer in charge of the operation resigned, and his supervisor was transferred.\n\nIn addition, the former Venezuelan anti-narcotics chief General Ramon Guillen Davila and his chief civilian aide were both indicted in connection with the shipments. Because Venezuela does not extradite its citizens, Guillen was not tried in the U.S., but his civilian aide was arrested while in the United States and sentenced to 20 years.\n\n\n\n\n"}
{"id": "3402316", "url": "https://en.wikipedia.org/wiki?curid=3402316", "title": "Baycrest Health Sciences", "text": "Baycrest Health Sciences\n\nBaycrest Health Sciences is a research and teaching hospital for the elderly in the North York district of Toronto, Ontario, Canada. It is fully affiliated with the University of Toronto. Baycrest was originally founded in 1918 as the Toronto Jewish Old Folks Home in a semi-detached Victorian house at 29 Cecil Street in Downtown Toronto. It expanded to neighbouring homes from the 1920s to 1930s. While Baycrest serves all elderly persons, it was founded by and for the Jewish community of Toronto and thus caters specifically to the needs of Jewish elderly persons, including Holocaust survivors. Baycrest's facilities include a full-service hospital, the \"Apotex Centre, Jewish Home for the Aged\" long-term care home, the \"Terraces of Baycrest Retirement Residence\", and the \"Reuben Cipin Healthy Living Community\".\n\nSlova Greenberg, president of the Ezras Noshem Society, identified the need to provide health care for elderly Jewish people in Toronto in 1913. The \"Toronto Jewish Old Folks Home\" opened at 29 Cecil Street, Toronto in 1918. The original location on Cecil street was demolished in 1954 and is now home to the United Steelworkers Larry Sefton Hall (c. 1972 at 25 Cecil Street) and Toronto Labour Lyceum (c. 1971 33 Cecil Street).\n\nIn 1954, the new \"Jewish Home for the Aged\" moved to Bathurst Street. It expanded to a new building in 1968 at Baycrest's present location at 3560 Bathurst Street in North York. The entire Bathurst Street complex became known collectively as \"Baycrest\".\n"}
{"id": "48814326", "url": "https://en.wikipedia.org/wiki?curid=48814326", "title": "Beth Haller", "text": "Beth Haller\n\nBeth Haller (born 1961) is a professor of mass communication and communication studies at Towson University, specializing in the handling of disability in news and new media. She serves on the advisory board of the National Center on Disability and Journalism, and traveled in Australia as a Fulbright Scholar in 2015.\n\nBeth A. Haller was born in Fort Worth, Texas. She attended Baylor University as an undergraduate, as a journalism major, and graduated in 1983. She earned a master's degree in journalism at the University of Maryland College Park, and completed doctoral studies in mass media at Temple University in 1995, with a dissertation titled \"Disability rights on the public agenda: Elite news media coverage of the Americans with Disabilities Act.\"\n\nHaller joined the faculty at Towson University in 1996. She became a full professor in 2008.\n\nBooks by Haller include \"Representing Disability in an Ableist World\" (2010) and \"Byline of Hope: The Newspaper and Magazine Writing of Helen Keller\" (2015). Haller was co-editor of \"Disability Studies Quarterly\" from 2003 to 2006. In 2012, Haller was admitted into the Fulbright Specialists Program, and traveled in Australia as a Fulbright scholar in early 2015. While in Australia she spoke on such topics as disability in reality television, film portrayals of disabled people, and disability in science fiction.\n\nBeyond academic publications, Haller is frequently interviewed on disability topics by fellow journalists.\n\n"}
{"id": "297558", "url": "https://en.wikipedia.org/wiki?curid=297558", "title": "Birthing center", "text": "Birthing center\n\nA birthing center or centre is a healthcare facility, staffed by nurse-midwives, midwives and/or obstetricians, for mothers in labor, who may be assisted by doulas and coaches. By attending the laboring mother, the doulas can assist the midwives and make the birth easier. The midwives monitor the labor, and well-being of the mother and fetus during birth. Should additional medical assistance be required the mother can be transferred to a hospital. Some hospitals are now adding birth centers to their facilities as an alternative to the high tech maternity wards commonly found at most hospitals.\n\nA birth center presents a more home-like environment than a hospital labor ward, typically with more options during labor: food/drink, music, and the attendance of family and friends if desired. Other characteristics can also include non-institutional furniture such as queen-sized beds, large enough for both mother and father and perhaps birthing tubs or showers for water births. The decor is meant to emphasize the normality of birth. In a birth center, women are free to act more spontaneously during their birth, such as squatting, walking or performing other postures that assist in labor. Active birth is encouraged. The length of stay after a birth is shorter at a birth center; sometimes just 6 hours after birth the mother and infant can go home.\n\nA 2012 Cochrane review compared traditional hospital births with alternative, home-like settings in or near conventional hospital labor wards. In comparison with traditional hospital wards, home-like settings had a trend towards an increase in spontaneous vaginal birth, continued breastfeeding at six to eight weeks, and a positive view of care. The review also found that having a birth at an alternative birth center decreased the likelihood of medical intervention during labor, without increasing risk to mother or child.\n\nLike clinics, birth centers arose on the coasts of the U.S. in the 1970s, as alternatives to heavily institutionalized health care. Today, use of birthing centers is generally covered by health insurance. Several of the practices which were innovated in birth centers are beginning to enter the mainstream hospital labor and delivery floors including:\n\n\nThere are certain requirements that a woman needs to meet in order to be able to birth at a birth center. First, the mother must have an uncomplicated, low-risk pregnancy, such as a singleton pregnancy (no twins) and that the baby is positioned head down. \n\nFree-standing birth centers require hospital backup in case complications arise during labor that require more complex care. However, even if a delivery can not happen at the birth center due to a high-risk pregnancy, birth center midwives might provide prenatal care up to a certain week of gestation or at the hospital alongside an obstetrician.\n\nThe nationwide organization supporting and promoting birth centers is the American Association of Birth Centers (AABC). Many birth centers nationwide, like hospitals, chose to become accredited through the Commission for the Accreditation of Birth Centers (CABC). There are strict guidelines for this accreditation to support birth centers as a place for normal birth. These include things such as no continuous fetal monitoring in labor to allow women full mobility.\n\nThere has been much research in recent years to support out of hospital birth—especially birth center birth—as not just safe but at times safer than hospital birth because of its judicious use of technology, licensed professionals and connection to the health care system.\n\nThe Amish, known for their great respect for tradition, usually have homebirths or give birth at birthing centers. Most Amish women only go to a hospital to give birth when there is a known medical risk for her or the child, but some Amish women choose to go the hospital during labor for peace of mind. Two books have been written about Amish medical issues including their birthing practices: \"Dr. Frau: A Woman Doctor among the Amish\" by Grace Kaiser and \"House calls and hitching posts: stories from Dr. Elton Lehman's career among the Amish\" by Elton Lehman\".\" Lehman is known for his work in founding a freestanding Amish birthing center. The Mount Eaton Care Center, Ohio's first such center, was established in 1984. In her book, \"Kaiser\" recounts the private nature of birthing among the Amish. She points out the practice of Amish women keeping labor a secret to all except their own husbands and midwife or obstetrician, as well as the practice of women waiting till active labor before summoning a midwife or OB. Due to the latter practice, fathers occasionally end up delivering their own children before the midwife or OB can arrive if a homebirth is selected. Amish women who choose a homebirth often continue with household duties until they are no longer physically able to continue. If birthing in a birth center, they are free to labor similar to that of homebirths: eating, drinking, visiting with their family members, etc.\n\nIn a response to the National Maternity Action Plan, State and Territory Governments in 2002 started to respond to consumer demand for an increased number of birth centers to be made available to women. Whilst most birth centers are attached to hospitals, some are being established as free-standing centers much further away from hospital back-up. As long as they are within 90 minutes of a hospital, they are considered 'safe'. Most birth centers are now being run solely by midwives, with obstetric back-up only used when there are complications.\n\nSome birth centers in Australia are moving away from the 'low-risk' model and are moving to an \"All risk model\" where women with medical complications are accepted into the birth center but extra care is provided to them where necessary.\n\nBirthing centers remain a controversial issue in Canada, but using one is an option for Canadian women.\n\nHospitals do offer this option, and it is available at special clinics.\n\nThe Netherlands has seen a growth in the number of locations for giving birth that fall outside of the traditional methods of giving birth at home or giving birth in a obstetric unit at a hospital. In these facilities the birth is overseen by a midwife, typically in a homelike environment. In the Netherlands, most community midwives work in group practices and only refer patients to hospital obstetric units for labor complications. \n\n\n"}
{"id": "13938138", "url": "https://en.wikipedia.org/wiki?curid=13938138", "title": "Capital punishment in Hungary", "text": "Capital punishment in Hungary\n\nCapital punishment was completely abolished in Hungary on 24 October 1990 by the Constitutional Court (Decision 23/1990). A month later on 1 December 1990 protocol No. 6 to the ECHR came into force. Hungary later adopted the Second Optional Protocol to the ICCPR as well. The last condemned man to be executed was hanged for the crime of murder on the 31 May 1988.\n\nIn April 2015, following the murder of a woman in southern Hungary, Prime Minister Viktor Orbán suggested that Hungary must reinstate capital punishment. This statement caused a strong reaction by EU officials, and Orbán had to retract it. \n\nIn the parliamentary debate on capital punishment Orbán stated that the EU attacked the implementation of real life prison sentences arguing against having habitual offenders being let back into society. The Civil Liberties Committee held a debate on Thursday, May 7th on how to take action with the suggestion of reintroducing the notion of capital punishment. The debate is discussed with Viktor Orbán on reintroducing the death penalty and it showed a perspective of Hungary which are tired of habitual criminals going back into society. Hungary's number of executions was tied with the countries Poland and Namibia with 1,988 executions before it was abolished. As time had passed, the notion of capital punishment was slowly but surely being put down as a negative in public opinion in Hungary but in different situations. Recently, there has been a significant decrease in homicides from 2016 to 2017, but residential crimes are still a significant issue and remain a concern However, ever since crimes of corrupt police officers has only been increasing over time and is now ranked 32nd in the top 86 countries that are having a problem with police officer crimes. These crimes have been prominent even when the death penalty was not abolished, in fact it seems there have been a decrease in the crime rate. Hungary is not the only country to be denounced by the European Union on the topic of capital punishment. The European Union had denounced the decision made by the parliament of Papua New Guinea to bring back the death penalty. The European Union has shown its stance on the topic of death penalty, which is thinking that the country is better off without the death penalty. Many citizens and officials in Hungary do not agree with this notion and the reintroduction by Viktor Orbán had not only stirred up EU officials but other countries as well. The EU had stated themselves that they regretted paving the way for the death penalty in Papua New Guinea with the adoption of amendments to the Criminal Code Act. The EU further stated that worldwide capital punishment has been demonstrated with the prohibition of capital punishment. The EU often shows its stance on the death penalty like the fifth World Day against the death penalty, and stated that the abolition of the notion contributes to human integrity and morality. The EU state that abolishing capital punishment was a progressive development of human rights, and should be considered in the progress of the right of life given to humans. \n"}
{"id": "10177535", "url": "https://en.wikipedia.org/wiki?curid=10177535", "title": "Central Remedial Clinic", "text": "Central Remedial Clinic\n\nThe Central Remedial Clinic (), commonly known and referred to as the CRC, is a non-residential national centre for the care, treatment and development of children and adults with physical disabilities in Ireland. The Clinic treats over 5,000 clients annually on a free-of-charge basis. Services are provided for people with physical conditions ranging from the very rare to the more familiar, such as cerebral palsy, spina bifida, muscular dystrophy and arthrogryposis.\n\nThe clinic was founded by Lady Valerie Goulding and Kathleen O'Rourke in 1951 as a small non-residential treatment centre in a house on Upper Pembroke Street in Dublin's city centre. It quickly developed paramedical and educational services for people with disabilities. It later became known as the Central Remedial Clinic, and began operations as a legal company in October 1953. In 1968, it moved into a purpose-built facility in Clontarf. In the 1970s, Lady Goulding hired Charles Haughey to head up its fund-raising arm. Accountant to Haughey, Des Peelo, was chairman for a period. While Lady Goulding ensured continuing finance from State and philanthropic sources, its medical development was under the direction of Dr Ciaran Barry, who also worked at the Mater Hospital. In 2001, the CRC opened a centre in Waterford, providing a regional assessment service for children in the south-east of Ireland. The Chief Executive Officer of the Clinic is Stephanie Manahan who was appointed in July 2014. \nServices at the Clinic include clinical assessment, physiotherapy, hydrotherapy, speech therapy, occupational therapy, social work, psychology, nursing, dietetics, orthotics, technical services, seating services, orthopaedics, paediatrics, parent support, vision and hearing specialists, transport and catering. \n\nThe Clinic has four Dublin-based Day Activity Centres located in Clontarf, Coolock, Firhouse and Hartstown. These centres provide social, physical, educational and recreational activities for adults whose disabilities prevent them from participating in other training or work programmes. \n\nVocational training, commonly referred to as VT, is provided in Clontarf and aims to equip young adults with disabilities to take responsibility for and have control over their own lives, and to set and achieve their own goals. This includes independence and the ability to pursue further training, further education or possibly employment. Training is certified by FETAC and accredited by the National Accreditation Committee (NAC).\n\nThe CRC also operates two schools in Dublin: the CRC school in Clontarf and Scoil Mochua in Clondalkin. Both schools cater for children with physical disabilities from the ages of 3 – 18 years who need a high level of support to reach their potential educationally. They also meet the needs of those children who will transfer to mainstream schools. \n\nThe CRC also provides training and education for adults through the workshop, vocational training, and the Diploma in Assistive Technology.\n\nIn 1990, the CRC established a state-of-the-art clinical gait analysis laboratory, one of a few in Europe and the only one in Ireland. \n\nIn 1995, Scoil Mochua came under the patronage of the Central Remedial Clinic. Located in Clondalkin, it is a school for children and young people with physical disabilities who live in West Dublin, Kildare and West Wicklow. The Clinic is a registered charity in the Republic of Ireland, (Reg. No: 4998), with a Board of Governors and a Management Committee.\n\n"}
{"id": "5812996", "url": "https://en.wikipedia.org/wiki?curid=5812996", "title": "Charles Hudson (climber)", "text": "Charles Hudson (climber)\n\nCharles Hudson (4 October 1828 – 14 July 1865) was an Anglican chaplain and mountain climber from Skillington, Lincolnshire, England.\n\nHudson was one of the most important climbers of the golden age of alpinism. An immensely strong walker, amongst his climbs were the first ascent of Monte Rosa in 1855, the first official ascent of Mont Blanc du Tacul in 1855, the first completed passage of the Mönchjoch in 1858, the first ascent of Mont Blanc by the Goûter route (incomplete) in 1859 with E. S. Kennedy and party, and the second ascent of the Aiguille Verte (the first by the Moine ridge) in 1865 (with T. S. Kennedy and Michel Croz). He is also considered a pioneer of English guideless climbing in the western Alps, having made the first guideless ascent of Mont Blanc in 1855 and a guideless ascent of the Breithorn. \n\nDuring the first ascent of the Matterhorn on 14 July 1865 Hudson was killed in a notorious accident during the descent. Edward Whymper was planning to climb the mountain with Lord Francis Douglas, when he heard that Hudson (together with Michel Croz) had the same objective. Whymper wrote:\n\nThe accident occurred because Hadow slipped on the descent not far from the summit, pulling Croz, Hudson and Douglas down the north face of the mountain; the rope between these four and the other three members of the party (Whymper and the two Zermatt guides named Peter Taugwalder, father and son), snapped, saving them from the same fate. Some have blamed Hudson for insisting on the presence of the inexperienced Hadow in the party, and for not checking the quality of the rope or the boots Hadow was wearing.\n\nHudson's body was retrieved from the Matterhorn glacier and was buried in the Zermatt churchyard.\n\n"}
{"id": "7393379", "url": "https://en.wikipedia.org/wiki?curid=7393379", "title": "Clinical data management system", "text": "Clinical data management system\n\nA clinical data management system or CDMS is a tool used in clinical research to manage the data of a clinical trial. The clinical trial data gathered at the investigator site in the case report form are stored in the CDMS. To reduce the possibility of errors due to human entry, the systems employ various means to verify the data. Systems for clinical data management can be self-contained or part of the functionality of a CTMS. A CTMS with clinical data management functionality can help with the validation of clinical data as well as helps the site employ for other important activities like building patient registries and assist in patient recruitment efforts.\n\nThe CDMS can be broadly divided into paper-based and electronic data capturing systems.\n\nCase report forms are manually filled at site and mailed to the company for which trial is being performed. The data on forms is transferred to the CDMS tool through data entry.The most popular method being double data entry where two different data entry operators enter the data in the system independently and both the entries are compared by the system. In case the entry of a value conflicts, system alerts and a verification can be done manually. Another method is Single Data Entry.\n\nThe data in CDMS are then transferred for the data validation. Also, in these systems during validation the data clarification from sites are done through paper forms, which are printed with the problem description and sent to the investigator site and the site responds by answering on forms and mailing them back.\n\nIn such CDMSs, the investigators directly upload the data on CDMS, and the data can then be viewed by the data validation staff. Once the data are uploaded by site, the data validation team can send the electronic alerts to sites if there are any problems. Such systems eliminate paper usage in clinical trial validation of data.\n\nOnce data have been screened for typographical errors, the data can be validated to check for logical errors. An example is a check of the subject's date of birth to ensure that they are within the inclusion criteria for the study. These errors are raised for review to determine if there are errors in the data or if clarifications from the investigator are required.\n\nAnother function that the CDMS can perform is the coding of data. Currently, the coding is generally centered around two areas — adverse event terms and medication names. With the variance on the number of references that can be made for adverse event terms or medication names, standard dictionaries of these terms can be loaded into the CDMS. The data items containing the adverse event terms or medication names can be linked to one of these dictionaries. The system can check the data in the CDMS and compare them to the dictionaries. Items that do not match can be flagged for further checking. Some systems allow for the storage of synonyms to allow the system to match common abbreviations and map them to the correct term. As an example, ASA (acetylsalicylic acid) could be mapped to aspirin, a common notation. Popular adverse event dictionaries are MedDRA and WHOART and popular Medication dictionaries are COSTART and WHO Drug Dictionary.\n\nAt the end of the clinical trial the data set in the CDMS is extracted and provided to statisticians for further analysis. The analysed data are compiled into clinical study report and sent to the regulatory authorities for approval.\n\nMost of the drug manufacturing companies are using Web-based systems for capturing, managing and reporting clinical data. This not only helps them in faster and more efficient data capture, but also speeds up the process of drug development. Perceptive Informatics, Medidata RAVE and Forte Research Systems' OnCore eClinical, Aetiol EDC [Jade Global Solutions {JGS}] and IBM Watson Health's IBM Clinical Development are examples of Web-based data capture systems. In such systems, studies can be set up for each drug trial. In-built edit checks help in removing erroneous data. The system can also be connected to other external systems. For example, RAVE can be connected to an IVRS (Interactive Voice Response System) facility to capture data through direct telephonic interviews of patients. Although IRT (Interactive Response Technology) systems (IVRS/IWRS) are most commonly associated to the enrollment of a patient in a study thus the system defining the arm of the treament that the patient will take and the treatment kit numbers allocated to this arm (if applicable). Besides rather expensive commercial solutions, there are more and more open source clinical data management systems available on the market.<ref name=\"Raptis/Mettler\"></ref>\n\n\n\n"}
{"id": "47275104", "url": "https://en.wikipedia.org/wiki?curid=47275104", "title": "Comparative medicine", "text": "Comparative medicine\n\nComparative medicine is a distinct discipline of experimental medicine that uses animal models of human and animal disease in translational and biomedical research. In other words it relates and leverages biological similarities and differences among species to better understand the mechanism of human and animal disease. It has also been defined as a study of similarities and differences between human and veterinary medicine including the critical role veterinarians, animal resource centers, and Institutional Animal Care and Use Committees play in facilitating and ensuring humane and reproducible lab animal care and use. The discipline has been instrumental in many of humanity's most important medical advances.\n\nThe first documented mention of comparative pathology comes from Hippocrates (460 - 370 BCE) in \"Airs, Waters, Places\" where he describes relevant case histories for horse herds and human populations. He insists that diagnosis be based on experience, observation, and logic. Aristotle (384 - 322 BCE) hypothesized about interspecies transmission of disease. The anatomy and physiology schools opened in Alexandria by Erasistratus (404 - 320 BCE) and Herophilus (330 - 255 BCE) were directly inspired by Aristotle's work. Although most of the documents were destroyed when the Library of Alexandria burned.\n\nIn his \"Disciplinarum Libri IX\", Marcus Terentius Varro (c. 100 BCE) made early indications of the germ theory of disease with his conception that tiny invisible animals carried with the air caused disease by entering through the nose and mouth. He also warned people against establishing homes near swamplands. Aulus Cornelius Celsus (25 BCE - 50 CE) wrote of experimental physiology in \"De Medicini Libri Octo\" detailing numerous dissections and vivisections he performed and pointed out specific interventions as well, such as cupping to remove the poison of a dog's bite.\n\nBy the time of Claudius Galen (129 - 200 CE), whose name lives on in the term \"Galenic formulation\", human dissection was no longer acceptable and his vivisection studies of comparative anatomy relied mostly on the use of Barbary macaques. This resulted in several persistent misunderstandings of human anatomy. Another key early contributor to early comparative medicine through publication of his \"Digestorum Artis Mulomedicinae libri\" in 500 CE was Publius Flavius Vegetius Renatus. A work that continued to be published and used in medicine as late as the 16th century.\n\nThe post-antique European world gave rise to a dominant monotheistic culture and with it a de facto ban on human dissection. As such, there was a slow down in comparative medicine's progress through the middle ages. This was to be codified in 1637 CE with René Descartes manuscript \"Discourse on the Method\". The Persian physician Muhammad ibn Zakariya al-Razi (865 - 925 CE) was the first to describe smallpox and measles and prescribe treatments, making his discoveries largely through animal dissection.\n\nDue to the far flung nature of their travels the Crusaders imported the Oriental rat flea carrying the bacterium Yersinia pestis and eventually initiating the Black Death. The massive deleterious effect of the pandemic brought on serious consideration of inoculation and transmission chiefly through the work of Albertus Magnus (1206 - 1280 CE). In the book \"Liber de Animalibus\" he discussed human and animal plagues in addition to narrowing down the method of transmission to bites, contact with animals, or respiration of sick air from the diseased.\n\nGirolamo Fracastoro (1478 - 1553 CE) outlined a concept for rapidly multiplying minute bodies (germs) transmitting infection in \"De contagione et contagiosis morbis\". The theory was widely praised but fell into disuse until Louis Pasteur and Robert Koch developed an empirical version. The beginnings of microbiology, and thus serious use of comparative medicine, were finally enabled by Antonie Philips van Leeuwenhoek's refinement of the microscope and subsequent observation of \"animalcules\".\n\nThe first real basis for the structured and regular exchange of knowledge of science and medicine in the western world was established with the 1660 founding of the Royal Society in London. Robert Doyle (1627 - 1691) published key experiments in their classical journal \"Philosophical Transactions\" among them interspecies blood transfusion, including from sheep into men.\n\nThe 18th century brought new plagues and faster communications to Europe creating a fruitful environment for a comparative approach to transfer and contagion. Along with the technology of transference as an experimental in vivo approach to medicine. At this stage it was already established in China that it was possible to use pox crusts as an effective treatment for smallpox infections. Emanuel Timone (1665 - 1741) was the first westerner to publish anything on inoculation, which he called grafting, although it's unclear if he developed it de novo (as new) or inferred it from previous work.\n\nAt this point animal medicine was generally absent from Europe. Bernado Ramazzini (1633 - 1714) and Giovanni Maria Lancisi (1654 - 1720) were the first to draw attention to the danger the general population faced from animal plagues. This and other work paved the way for Mortimer Cromwell, a secretary of the Royal Society, to raise plagues as a national health issue enabling a general policy of quarantine, isolation, fumigation, and slaughter. Erasmus Darwin was also impacted by the tragedy of the plagues and it resulted in the publication of his \"Zoonomia\" where he discusses infectious disease of both humans and animals.\n\nIn 1802 French physiologist François Magendie (1783 - 1855) became the first person to prove interspecies transmission of disease by inoculating a dog from rabies using human spittle. He also experimented with the injection of putrid fish into animals and was an advocate for experimentation in a time before anesthetics were developed.\n\nWith their usefulness to human health and respectable scientific standing established there were veterinary colleges founded in France, Austria, Sweden, Denmark, Netherlands, and Germany throughout the 18th century. It was Claude Bourgelat, the founder of the first veterinary college in Lyon France in 1761, who, prior to the existence of the veterinary profession, coined the term “comparative pathobiology”. When the Royal Veterinary College was established in London in 1790 many students from France moved to England. Among them were John Hunter (1728 - 1793) an anatomist and surgeon that had an interest in comparative anatomy and animal physiology. His teaching on infectious disease was influential on subsequent generations.\n\nA most prominent student of Hunter's was Edward Jenner (1749 - 1823). He introduced animal models for rabies and showed that dogs could be inoculated with the spittle of infected animals. Jenner is most famously remembered for his historic 1796 experiment where he demonstrated inoculation from smallpox by exposure to and transmission of the milder cowpox. Jenner's work, a breakthrough in vaccinology and an important precursor to immunology in general, is generally credited as the very beginning of modern medicine. The experiments of Jenner and others set the stage for certain inoculation programs to be introduced to the general public. The first of such programs was directed by Jean-Baptist Edouard Bousquet (1794 - 1872) laid out guidelines for advisability, inoculation, and re-inoculation.\n\nThe first university chair of comparative medicine was established in 1862 resultant to the vision of Émile Littré a French politician and former student of medicine.\n\nRobert Koch (1843 - 1910) was a truly notable contributor to comparative medicine. He had many achievements such as the discovery of the pathogens responsible for anthrax, tuberculosis, and cholera, as well as a Nobel Prize in physiology or medicine in 1905 All the result of experimental work using animal models to compliment knowledge of human biology.\n\nIn 1863 John Gamgee (1831 - 1894) organized the first conference of what would evolve into the World Veterinary Association. Subsequent conferences, such as one on animal vaccination in 1880, led George Fleming to propose in \"The Lancet\" that a chair of comparative pathology be established in all medical schools.\n\nRudolf Virchow (1821 - 1902) initiated modern pathology with his studies of dogs that lead to distinguishing between pyemia, septicemia, thrombosis, and embolisms. He made observations based on experiments in animals that led to specific medical interventions for humans, a hallmark of comparative medicine.\n\nAuguste Chauveau (1827 - 1917) experimented on sepsis, and chaired a commission that was responsible for anticipating that smallpox itself could be attenuated by passage through cattle.\n\nA major contributor to vaccine science via comparative medicine was Louis Pasteur (1822 - 1895). He was able to inoculate against rabies in several animal species and, perhaps most famously, able to cure a young boy of the disease. There was much controversy surrounding Pasteur's work after his death when his lab notebooks revealed questionable reporting techniques and the suppresion of the work of others in his field such as Pierre Paul Émile Roux.\n\nSalomon Stricker (1834 - 1898) founded \"The Institute of Experimental Pathology\" in 1872, which in 2010 was renamed the \"Institute of Pathophysiology and Allergy Research\" to conform to modern nomenclature. From its inception the institute was devoted to laboratory experimentation involving animals.\n\nWilliam H. Welch (1850 - 1934) was the founding president of the \"Rockefeller Institute of Medical Research\" in 1901. It was the first American equivalent to the Pasteur and Koch institutes in Europe. In addition to establishing an institute for animal pathology they began publishing the \"Journal of Experimental Medicine\" (JEM) which is still a respected journal today. They are dedicated to the study on intact organisms and prioritize human studies.\n\nComparative medicine in the form of experimentation on rhesus monkeys was key to one of the crowning achievements of modern medical science: Jonas Salk's development of the polio vaccine. In fact the typing portion of the studies - crucial for determining what type of vaccine was needed - required some 17,000 monkeys for the research. This lead Julius Youngner, one of the researchers on Salk's team to say, \"The monkeys were the real heroes of this thing,\"\n\nComparative medicine, particularly through the use of macaque and rhesus monkeys as animal models, has been absolutely essential to the development of treatment for HIV and AIDS. This is particularly so in the ongoing - and as yet unsuccessful - struggle to find a vaccine, although there are severe limitations due to the uniqueness of Simian immunodeficiency virus (SIV) compared to the human virus and a better animal model is needed.\n\nThe concept of One Medicine is an idea from the 1970's and can be attributed to Calvin Schwabe (1927 – 2006) from his book \"Veterinary Medicine and Human Health\". The idea takes the existing interdisciplinary nature of comparative medicine a step further and considers veterinary and human healthcare to be sufficiently overlapped as to be different aspects of the same thing. These concepts are carried into the 21st century in works such as \"Zoobiquity\" and in developments in research for heart transplants, management of psychiatric disorders, prosthetic limbs, cancer treatments and vaccine development. Despite the potential of this emergent field it has thus far failed to realize its full potential due to the limited interaction of veterinary and medical sciences.\n\nDespite the usefulness of a comparative approach to medicine and the utility of animal models the literature is fraught with many examples of promising \"in vivo\" research failing to translate effectively from animals to humans. This has raised concerns about reliability, predictive value, and the potential harm that inadequate measures can cause people. Some researchers have noted that a distinction between exploratory and confirmatory approaches can improve translation.\n\nA few examples:\n\nThere is a current focus in the research community on using the proper context for interpreting animal models and developing better ones.\n\nReproducibility has been defined as the ability of a result to be replicated through independent experiments within the same or different laboratories. There are serious concerns about the repeatability of pre-clinical trials with published estimates of irreproducibility ranging from 51% to 89%. These concerns are part of the larger reproducibility crisis in science.\n\nSome of the reasons for the lack of reproducibility in many studies are:\n\nThe theory of utilitarianism and the concept of \"greater good\" is most often used as a rationale for animal research in comparative medicine and elsewhere. The basic idea is that the actions that produce the greatest good for the greatest number are moral actions, meaning that new drugs and therapies along with the decreased suffering of humans and animals justifies the use of some animals in research. There are concerns that animal experimentation that has no translational benefit or reproducibility is likely unethical.\n\nThere are philosophers that believe that animal testing violates an animal’s dignity and is ethically wrong. Until a better alternative is found though the majority of the scientific community continue to take the utilitarian approach.\n\nAnimal testing regulations are laws and/or guidelines that permit and control the use of animals for experimentation. They are of interest to comparative medicine given the overlap of the discipline and animal experimentation. The regulations vary around the world, but most governments aim to control the number of times animals are used; numbers used; and degree of pain.\n\n\n"}
{"id": "56587464", "url": "https://en.wikipedia.org/wiki?curid=56587464", "title": "Digital leisure studies", "text": "Digital leisure studies\n\nDigital leisure studies is an academic interdisciplinary sub-discipline of leisure studies that focuses on the study of digital leisure cultures, including digital leisure practices, experiences, spaces, communities, institutions, and subjectivities. It is an area of scholarship aimed at making sense of the place of digital leisure “in understandings of embodiment, power relations, social inequalities, social structures and social institutions”. To do so, leisure scholars use theoretical and methodological approaches from within leisure studies as well as from other academic disciplines such as political science, history, communication studies, cultural studies, philosophy, sociology, geography, anthropology, and others. Scholars in this field also focus on how to engage digital practices to make their research accessible, and focus on exposing, examining, and challenging social inequalities and injustices related to digital leisure.\n\nDigital leisure, similar to leisure, is a contentious term. Leisure has traditionally been defined in three main ways, as time (that which is not work), as activity (freely chosen), and as a state of mind (denoted by such things as intrinsic motivation, perceived freedom, and positive affect). Digital leisure practices and spaces are intertwined with work in ways that physical leisure spaces are not. Widespread surveillance of digital leisure practices and spaces allows companies to benefit monetarily from the data collected during the users’ leisure experiences (hence, the user is indeed working during their leisure time). Therefore, digital leisure is time spent engaged in digital practices and spaces while in a leisurely state of mind.\n\nTraditionally, leisure scholars have focused on analogue leisure cultures such as sports, outdoor activities, fandom, and summer camps. In a digital age, there are very few (if any) pure analogue leisure spaces in existence. Most leisure cultures have been digitized in some way. With wearable fitness trackers digitizing every aspect of our leisure (even our sleep) and smartphones-turned-watches, our very leisured bodies have become digital assemblages. Lupton noted how the metaphor of entanglement is commonly used to explain our relationship with digitization, as it “emphasizes the inextricably intertwined relationships of human subjects with material objects” (p. 41). As such, digital leisure cultures refer to the digitization of previous analogue areas of leisure research . Digital leisure cultures “covers some of the following technologies and practices which have built cultures around them: namely apps (applications), smartphones, online games, interaction on some form of social media, and the downloading of films, live televised sports events and music”.\n\nBrabazon has identified two systemic ways in which analogue leisure cultures and digital cultures differ: deterritorialization and disintermediation. Deterritorilization refers to the ways digitization is post-territory. As a concept, it captures “how particular media platforms and communicative systems de-emphasize our position in analogue space and time in favour of virtual space and time”. For example, Brabazon used the example of social media. We can join Pinterest, Twitter, Facebook – and we can be involved in and share content in each of these distinct spaces with each other, even if we do not share physical space with each other.\n\nDisintermediation refers to the ways in which digital leisure cultures involve “peer-to-peer networks where links are removed from the traditional supply chain” . As part of these networks, the producer can also be the consumer (prosumer). In this way, material in digital leisure cultures can be created and disseminated much more quickly than in analogue leisure cultures.\n\nLeisure studies (and academia in general) currently exists in the age of the “digital turn.” The digital turn refers to the different ways digitization influences our lives, including our behaviors, social interactions, environments, economies, and politics. The digital turn signifies a new period in leisure scholarship and demands a conceptual change, one in which leisure scholars turn to new resources and ways of capturing what digitization means for our lives and leisure Redheadnoted, leisure scholars “need to produce sustained theorizing of the “digital turn” in Leisure Studies and with it more satisfactory theoretically informed empirical studies of digital leisure cultures” (p. 828) to engage in broader scholarly conversations.\n\nTo do so, it has been suggested leisure scholars shift the ways they are thinking about leisure and draw on different disciplines and theories as resources to begin to shape digital leisure theory and theorizing. For example, Redhead has recommended that digital leisure theory be shaped by critical theory and critical theorists from other disciplines such as philosophers, including Braudrillard, Badiou, Zizek, and Virilio. Redhead presented two concepts to guide digital leisure theory: accelerated culture and claustropolitanism.\n\nKarl Spracklen has presented a theory of communicative and instrumental digital leisure drawing on theorists such as Habermas, Catells, Urry, and Bauman. He argued that digital leisure is more communicative given its possibilities for interactivity and resisting power disparities, but despite these possibilities, it is not immune to instrumental structures that shape traditional (non-digitized) popular leisure. In this way, digital leisure should not be seen as something novel, but as “just another leisure space.” In his work, he has also emphasized the work of leisure theorists, such as Rojek, Stebbins, Aitchison, Blackshaw, Giulianotti and Crouch, who have focused attention towards understanding and critically engaging with digital leisure.\n\nWith the digital turn in research, also comes the need to consider methodologies and methods used to effectively study digital leisure cultures. Digital leisure scholars are still actively working to envision new methodologies and methods and retool existing ones. Netnography, virtual ethnography /cyberethnography/digital ethnography, digital storytelling , digital and visual methodologies , digital media methodologies , and critical technocultural discourse analysis are some examples of such methodologies and methods.\n"}
{"id": "23830527", "url": "https://en.wikipedia.org/wiki?curid=23830527", "title": "Equivalence (trade)", "text": "Equivalence (trade)\n\nEquivalence is a term applied by the Uruguay Round Agreement on the Application of Sanitary and Phytosanitary Measures. WTO Member countries shall accord acceptance to the Sanitary and Phytosanitary (SPS) measures of other countries (even if those measures differ from their own or from those used by other Member countries trading in the same product) if the exporting country demonstrates to the importing country that its measures achieve the importer’s appropriate level of sanitary and phytosanitary protection.\n"}
{"id": "1930464", "url": "https://en.wikipedia.org/wiki?curid=1930464", "title": "Erotic humiliation", "text": "Erotic humiliation\n\nErotic humiliation is consensual psychological humiliation performed in order to produce erotic excitement or sexual arousal. This can be for either the person(s) being humiliated and demeaned or the person(s) humiliating, or both. It is sometimes performed before spectators, including pornography and webcam viewers. It may be part of BDSM and other sexual roleplay, or accompanied by the sexual stimulation of the genitals (or other erotic region) of one or both parties in the activity.\n\nHumiliation is a subjective issue, and is dependent on context. It does not need to be sexual in nature; as with many other sexual activities, it is the feelings that are obtained from the experience that are desired, regardless of the nature of the actual activity. Usually there is a feeling of submission for the person being humiliated, and dominance, for the person implementing the humiliation. Erotic humiliation can be done verbally and/or physically, and can take place privately or publicly. Some individuals assume an acting role and others prefer to be spoken to in a degrading way. A classic technique that can be used to put the submissive into a bottom mind space is to humiliate them while also providing them with sexual stimulation. Select individuals who desire this form of humiliation also use it to acquire emotional release. Humiliation can become ritualized, and unlike some sexual variations, it can also be easily carried out over a long distance (such as online).\n\nWhile fantasy and fascination with erotic humiliation is a prevalent part of BDSM and other sexual roleplay, relatively little has been written on it. Humiliation play can, however, be taken to a point where it becomes emotionally or psychologically distressing to one or the other partner, especially if it is public humiliation. Erotic humiliation can become extreme enough to be considered a form of edgeplay, which some consider may best be approached with advance negotiation and use of a safeword.\n\nThe most common name for the individual being humiliated is the \"bottom\", and the opposite individual who humiliates the bottom is often called the \"top\". However, these terms are standard ones that are used in general dominant/submissive roleplay and are not specific to humiliation interests.\n\n\nWhile elements of erotic humiliation may be part of a number of domination and submission-based activities, humiliation is not the same as submission. The recipient does not necessarily seek to be ordered about. Humiliation comes into its own as a sexual force when the recipient seeks the humiliation over and above means. For example, being spanked is primarily valued because of the belittlement involved. Humiliation therefore encompasses a range of paraphilia, including foot fetish, breast fetish, shoe fetish, body worship, spanking, bondage, and most BDSM styles. It can be as basic as the desire to kiss and massage feet as a precursor to sex; and it can be complex, involving roleplay and public displays of subservience. It can also be for a set period of time (a \"scene\") or an ongoing facet of a relationship. The \"humiliation\" is not intrinsic to the act or the object. Rather, it is semiotically charged by the shared attitude of the partners engaged in the act. They invest specific acts, objects, or body parts with a humiliating aspect.\n\nMany scenarios may give rise to sexual humiliation. Some scenarios may be based on verbal abuse and others on physical aspects.\n\n\n\nSome sexual humiliation involves physical inflicting pain, but much of it is far more concerned with ridicule, mocking, degradation, and embarrassment.\n\nSexual roleplaying can involve humiliation. For example, one person might play the part of a dog because they enjoy being mock-forced into it, and the top might emphasize the lowness of the bottom's status as an animal, whereas another person might play the role of the dog without any element of humiliation, simply as an expression of an inner animal or playful spirit.\n\nHumiliation in general stimulates the same brain regions that are associated with physical pain, the inference being that humans evolved to remember social rewards and punishments as strongly as they recall physical reward or pain in response to their environment. As with any form of pain experimentation in a sexual context, consent and (paradoxically) a high degree of awareness and communication are needed to ensure that the result is desirable, rather than abusive. For example, a submissive may enjoy being insulted in some ways but would be genuinely crushed and devastated if humiliated or insulted in other ways.\n\nHumiliation play is also connected to sexual fetishism, in that non-sexual activities may become sexualised by association with arousal, and also may be associated with exhibitionism in the sense of wanting others to witness (or being aroused by others witnessing) one's sexual degradation.\n\nFor some people, activities such as name-calling are a way of achieving ego reduction or getting over sexual inhibitions. For example, between gay people, terms usually associated with homophobia may be used, such as \"faggot\" and \"dyke\".\n\nAs with all sexual activities, some people have sexual fantasies about humiliation, and others actually undertake it as a lifestyle or in a scene. Sexual fantasies relating to mild humiliation are common. Some humiliation roleplay (pup-play and age play in particular) is combined with loyalty and care-giving to the extent that these fetishes can be seen as exercises in trust rather than primarily a humiliation fetish. The desire to be beneath the other partner during intercourse, the idea of \"getting caught\" (as in having sex in the garden or woods), and simulated rape are emotional games that emphasise status, vulnerability, and control. However, for most people such ideas remain fantasies; the people would have strong reservations about the fantasies' being made public, or engaged in with a partner in real life, however erotic the idea may be. When someone reveals a fetish to a partner, this usually is a result of great trust. However, the desire to be humiliated may be a motivating cause for confession, in that the act of confessing can itself be humiliating. Many people worry about being ridiculed for their fetishes, and such ridicule from their partners could be psychologically catastrophic. Therefore, many people use online humiliation (in which the humiliator and others are involved via the Internet, using chat, email, websites, etc.) as a compromise between exhibitionism and reality on the one hand, and safety and anonymity on the other.\n\nOnline humiliation is the desire to be seen in a sexually embarrassing context on the Internet. This practice allows the submissive to seek fetish partners from across the world. As the Internet has grown and continues to grow, so does online humiliation. Anecdotal reports indicate that the proportion of men being dominated by women on the Internet, through some type of personal service provided for a fee by the woman, vastly exceeds the instances of a woman being dominated online by a man, or another woman.\n\nCommon methods of online humiliation:\n\n\nThese practices can be conducted through chat, webcam, e-mail, BDSM contact websites, and proprietary virtual spaces such as \"Second Life\" or FetLife.\n\n\nNotes\n\n"}
{"id": "30174951", "url": "https://en.wikipedia.org/wiki?curid=30174951", "title": "Europac", "text": "Europac\n\nEUROPAC, the European Registry of Hereditary Pancreatic Diseases was established in 1997 by a collaboration of pancreas surgeons from Liverpool, UK.\n\nThe study is supported by grants from Cancer Research UK, The European Union and the National Institute for Health Research (NIHR).\n\nPatients who have a family history of pancreatic cancer or pancreatitis may be eligible to join the study, Referrals are made via genetic counsellors, GPs, other Consultants or directly via email (see website).\n\nThe current research team based in Liverpool includes Sara Harrison (Data Manager) and James Nicholson (Clinical Research Fellow).\n\nSince 2007 EUROPAC have been co-ordinating a secondary screening study for patients considered to be at high risk of pancreas cancer.\n\n"}
{"id": "40419859", "url": "https://en.wikipedia.org/wiki?curid=40419859", "title": "Evidence-based toxicology", "text": "Evidence-based toxicology\n\nThe discipline of evidence-based toxicology (EBT) strives to transparently, consistently, and objectively assess available scientific evidence in order to answer questions in toxicology, the study of the adverse effects of chemical, physical, or biological agents on living organisms and the environment, including the prevention and amelioration of such effects. EBT has the potential to address concerns in the toxicological community about the limitations of current approaches to assessing the state of the science. These include concerns related to transparency in decision making, synthesis of different types of evidence, and the assessment of bias and credibility.\n\nBy analogy to evidence-based medicine (EBM), the umbrella term evidence-based toxicology (EBT) has been coined to group all approaches intended to better implement the above-mentioned evidence-based principles in toxicology in general and in toxicological decision-making in particular. Besides systematic reviews, the core evidence-based tool, such approaches include \"inter alia\" the establishment and universal use of a common ontology, justified design and rigorous conduct of studies, consistently structured and detailed reporting of experimental evidence, probabilistic uncertainty and risk assessment, and the development of synthesis methodology to integrate evidence from diverse evidence streams, e.g. from human observational studies, animal studies, in vitro studies and in silico modeling. A main initial impetus for translating evidence-based approaches to toxicology was the need to improve the performance assessment of toxicological test methods. The U.S. National Research Council (NRC) concurs that new means of assessment are needed to keep pace with recent advances in the development of toxicological test methods, capitalizing on enhanced scientific understanding through modern biochemistry and molecular biology. \nA key tool in evidence-based medicine that holds promise for EBT is the systematic review. Historically, authors of reviews assessing the results of toxicological studies on a particular topic have searched, selected, and weighed the scientific evidence in a non-systematic and non-transparent way. Due to their narrative nature, these reviews tend to be subjective, potentially biased, and not readily reproducible. Two examples highlighting these deficiencies are the risk assessments of trichloroethylene and bisphenol A (BPA). Twenty-seven different risk assessments of the evidence that trichloroethylene causes cancer have come to substantially different conclusions. Assessments of BPA range from low risk of harm to the public to potential risks (for some populations), leading to different political decisions. Systematic reviews can help reducing such divergent views. In contrast with narrative reviews, they reflect a highly structured approach to reviewing and synthesizing the scientific literature while limiting bias. The steps to carrying out a systematic review include framing the question to be addressed; identifying and retrieving relevant studies; determining if any retrieved studies should be excluded from the analysis; and appraising the included studies in terms of their methodological quality and risk of bias. Ultimately the data should be synthesized across studies, if possible by a meta-analysis. A protocol of how the review will be conducted is prepared ahead of time and ideally should be registered and/or published.\n\nScientists have made progress in their efforts to apply the systematic review framework to evaluating the evidence for associations between environmental toxicants and human health risks. To date, researchers have shown that important elements of the framework established in evidence-based medicine can be adapted to toxicology with little change, and some studies have been attempted. Researchers using the systematic review methodology to address toxicological concerns include a group of scientists from government, industry, and academia in North America and the European Union (EU) who have joined together to promote evidence-based approaches to toxicology through the nonprofit Evidence-based Toxicology Collaboration (EBTC). The EBTC brings together the international toxicology community to develop EBT methodology and facilitate the use of EBT to inform regulatory, environmental and public health.\n\nEvidence-based approaches were first conceived as a means of anchoring policy decisions, not to current practices or the beliefs of experts, but to experimental evidence. Evidence-based medicine (EBM) was launched slightly later. Its rise as a distinct discipline is generally credited to the work and advocacy of Scottish epidemiologist Archie Cochrane. The Cochrane Collaboration named in his honor was launched at Oxford University in 1993 to promote evidence-based reviews of clinical medical literature. More recently, EBM expanded to encompass evidence-based health care (EBHC).\n\nEBM/HC involves the conscientious, explicit, and judicious use of current best evidence in making decisions about the care of individual patients taking patients' preferences into account. Prior to EBM, medical decisions about diagnosis, prevention, treatment or harm were often made without a rigorous evaluation of the alternatives. Research in the 1970s and 1980s showed that different physicians regularly recommended different treatments and tests for patients with ailments that were essentially the same, and that large proportions of procedures being performed by physicians were considered inappropriate by the standards of medical experts.\nEBM/HC supporters stress that while evidence always has been important to the practice of medicine, EBM/HC provides an enhanced approach of identifying, assessing, and summarizing evidence. EBT's supporters make a similar argument.\n\nThe idea of translating evidence-based approaches from medicine to toxicology has been percolating for two decades, with proponents in both medicine and toxicology. Three research papers published in 2005 and 2006 catalyzed what eventually became known as EBT by suggesting that EBM's established tools and concepts might serve as a prototype of evidence-based decision-making in toxicology.\n\nThe First International Forum Toward Evidence-Based Toxicology was held in 2007. The forum was organized by the European Commission and attended by 170 scientists from more than 25 European, American, and Asian countries. The goal was to explore the available concepts of EBT, and to launch an initiative to formally implement evidence-based assessment methods in toxicology.\n\nThe starting point for the discussions were two research papers suggesting that the tools and concepts established in evidence-based medicine could serve as a prototype of evidence-based decision-making for evaluating toxicological data. Apparent fundamental differences between medicine and toxicology were carefully considered during these discussions. Forum participants attempted to bridge the two disciplines in order to make use of the accrued wisdom and apply this approach to toxicology. (See http://www.ebtox.org/resources/evidence-based-toxicology-explained/ .)\n\nThe proceedings of this forum were published as a special issue in \"Human & Experimental Toxicology\".\n\nEBT's proponents include experts in EBM, public health, and toxicology who believe that EBT can help toxicologists to better serve the goals of health protection and safety assurance. They argue that EBT's methodologies for collecting, appraising, and pooling evidence can help ensure that all available information on a given topic is evaluated in a transparent, unbiased, and reproducible manner. They contend that EBT's concept of the systematic review could prove particularly helpful for the standardization and quality assurance of novel methodologies for evaluating toxicity, as well as for their formal validation. In this regard, EBT may prove particularly useful for assessing the performance of newer non-animal “21st century” toxicology tools. EBT can also help scientists integrate new toxicological test methods into test strategies being implemented across the globe.\n\nIn 2010, a group of EBT supporters joined together to convene a workshop titled “21st Century Validation for 21st Century Tools.” The session on the potential for evidence-based approaches to assess the performance of the new generation of non-animal test methods inspired the formation of the EBTC. The EBTC was officially launched in the U.S. in 2011 at a Society of Toxicology conference and convened its first workshop in 2012. The EBTC's EU branch was officially opened during the 2012 Eurotox conference.\n\nIn 2014, the EBTC hosted a workshop on ‘The Emergence of Systematic Review and Related Evidence-based Approaches in Toxicology“ with speakers representing US and European organizations that are implementing and promoting the use of systematic reviews for toxicological questions. The experts noted that the structured approach of systematic reviews increases objectivity and transparency but also made clear that the approach requires a substantial time investment, which is a challenge to its more widespread adoption. Consequently, the participants called for close collaboration of interested organizations, which they determined to be a pre-requisite for the broad and efficient introduction of systematic reviews in toxicology.\n\nSome scientists and policymakers would like EBT to help them combine information from various sources. Toxicological evidence can be assigned to evidence streams, sets of studies representing the same type or level of evidence, such as human (observational) studies, animal studies, in vitro or mechanistic studies. EBT can be applied both within one evidence stream, and it is especially well-suited to be applied across multiple evidence streams. Regulators often designate one study as “the lead study,” then use later studies as additional information. Many perceive this as unsatisfying, but objective approaches to combine study results are lacking. The EBM concept of the systematic review has promise for this application, and some structured reviews serve as forerunners for this approach.\n\nThe U.S. National Toxicology Program's Office of Health Assessment and Translation (OHAT) has started to use systematic review methodology for the program's evaluations. The first systematic review was completed in 2016, reviewing the effects of fluoride on learning and memory in animal studies. OHAT’s approach is tailored to its mandate, but its seems especially appropriate for substances with substantial yet conflicting literature, and hence the need for a systematic reviews to sort out somewhat confusing situations.\n\nOne application of EBT focuses on causation. It addresses the challenge of tracing a health effect back to a toxicant, such as lung cancer to smoking. This approach is similar to legal arguments Some experts warn that this approach could increase the evidence burden for proving causation, and thereby increase the difficulty involved in banning toxic substances.\n\nPractitioners of clinical toxicology, which is concerned with the treatment of patients known to be exposed to toxic substances, are also beginning to use an EBM-style approach. Guidance documents based on this approach have already been published.\n\nThe National Research Council's (NRC) landmark 2007 publication, Toxicity Testing in the 21st Century, has also been an impetus for EBT. EBT provides new tools for assessing test method performance. Also, as the focus of 21st century toxicology shifts from animal biology to human biology, EBT provides a method for comparatively evaluating the results gleaned from new methods of investigating the effects of chemical exposure.\n\nThe specific differences between toxicology and medicine/health care cause challenges for implementing EBT. Evidence-based methodology of clinical research has been focused on a single type of study—randomized, controlled clinical trials, which are a direct measure of the effectiveness of the health care intervention under scrutiny. In contrast, toxicology employs a variety of different kinds of studies in three distinct evidence streams: human (observational) studies, animal studies, and non-animal studies. Because human evidence is frequently lacking, most evidence is obtained by using animal and non-animal models, which—by definition—is more difficult to generalize and extrapolate to humans. This methodological heterogeneity complicates evidence integration within an evidence stream, such as when inconsistent evidence is obtained from different animal species, but even more so across evidence streams. Adding to the difficulty is the reality that much toxicological evidence, more so than in medicine and health care, is not readily accessible in the literature. Moreover, the role of expert judgment, especially in systematic reviews, needs to be clearly defined, as it is a common misperception that evidence-based approaches leave no room for it. Systematic reviews should strive to make expert judgments clear along with the scientific basis for those judgments in developing conclusions for a systematic review. Further issues to be worked out include exposures to multiple substances, the multitude of outcomes observed in some animal studies, and challenges in improving the experimental designs and reporting of studies.\n\n"}
{"id": "1043263", "url": "https://en.wikipedia.org/wiki?curid=1043263", "title": "Excitotoxicity", "text": "Excitotoxicity\n\nExcitotoxicity is the pathological process by which nerve cells are damaged or killed by excessive stimulation by neurotransmitters such as glutamate and similar substances. This occurs when receptors for the excitatory neurotransmitter glutamate (glutamate receptors) such as the NMDA receptor and AMPA receptor are overactivated by glutamatergic storm. Excitotoxins like NMDA and kainic acid which bind to these receptors, as well as pathologically high levels of glutamate, can cause excitotoxicity by allowing high levels of calcium ions (Ca) to enter the cell. Ca influx into cells activates a number of enzymes, including phospholipases, endonucleases, and proteases such as calpain. These enzymes go on to damage cell structures such as components of the cytoskeleton, membrane, and DNA.\n\nExcitotoxicity may be involved in spinal cord injury, stroke, traumatic brain injury, hearing loss (through noise overexposure or ototoxicity), and in neurodegenerative diseases of the central nervous system (CNS) such as multiple sclerosis, Alzheimer's disease, amyotrophic lateral sclerosis (ALS), Parkinson's disease, alcoholism or alcohol withdrawal and especially over-rapid benzodiazepine withdrawal, and also Huntington's disease. Other common conditions that cause excessive glutamate concentrations around neurons are hypoglycemia. Blood sugars are the primary glutamate removal method from inter-synaptic spaces at the NMDA and AMPA receptor site. Persons in excitotoxic shock must never fall into hypoglycemia. Patients should be given 5% glucose (dextrose) IV drip during excitotoxic shock to avoid a dangerous build up of glutamate around NMDA and AMPA neurons. When 5% glucose (dextrose) IV drip is not available high levels of fructose are given orally. Treatment is administered during the acute stages of excitotoxic shock along with glutamate antagonists. Dehydration should be avoided as this also contributes to the concentrations of glutamate in the inter-synaptic cleft and \"status epilepticus can also be triggered by a build up of glutamate around inter-synaptic neurons.\"\n\nThe harmful effects of glutamate on the central nervous system (CNS) were first observed in 1954 by T. Hayashi, a Japanese scientist who noted that direct application of glutamate to the CNS caused seizure activity, though this report went unnoticed for several years. D. R. Lucas and J. P. Newhouse, after noting that \"single doses of 20-30gm [of sodium glutimate in humans] have ... been administered intravenously without permanent ill-effects\", observed in 1957 that a subcutaneous dose described as \"a little less than lethal\", destroyed the neurons in the inner layers of the retina in newborn mice. In 1969, John Olney discovered that the phenomenon was not restricted to the retina, but occurred throughout the brain, and coined the term excitotoxicity. He also assessed that cell death was restricted to postsynaptic neurons, that glutamate agonists were as neurotoxic as their efficiency to activate glutamate receptors, and that glutamate antagonists could stop the neurotoxicity.\n\nExcitotoxicity can occur from substances produced within the body (endogenous excitotoxins). Glutamate is a prime example of an excitotoxin in the brain, and it is also the major excitatory neurotransmitter in the mammalian CNS. During normal conditions, glutamate concentration can be increased up to 1mM in the synaptic cleft, which is rapidly decreased in the lapse of milliseconds. When the glutamate concentration around the synaptic cleft cannot be decreased or reaches higher levels, the neuron kills itself by a process called apoptosis.\n\nThis pathologic phenomenon can also occur after brain injury and spinal cord injury. Within minutes after spinal cord injury, damaged neural cells within the lesion site spill glutamate into the extracellular space where glutamate can stimulate presynaptic glutamate receptors to enhance the release of additional glutamate. Brain trauma or stroke can cause ischemia, in which blood flow is reduced to inadequate levels. Ischemia is followed by accumulation of glutamate and aspartate in the extracellular fluid, causing cell death, which is aggravated by lack of oxygen and glucose. The biochemical cascade resulting from ischemia and involving excitotoxicity is called the ischemic cascade. Because of the events resulting from ischemia and glutamate receptor activation, a deep chemical coma may be induced in patients with brain injury to reduce the metabolic rate of the brain (its need for oxygen and glucose) and save energy to be used to remove glutamate actively. (The main aim in induced comas is to reduce the intracranial pressure, not brain metabolism).\n\nIncreased extracellular glutamate levels leads to the activation of Ca permeable NMDA receptors on myelin sheaths and oligodendrocytes, leaving oligodendrocytes susceptible to Ca influxes and subsequent excitotoxicity. One of the damaging results of excess calcium in the cytosol is initiating apoptosis through cleaved caspase processing. Another damaging result of excess calcium in the cytosol is the opening of the mitochondrial permeability transition pore, a pore in the membranes of mitochondria that opens when the organelles absorb too much calcium. Opening of the pore may cause mitochondria to swell and release reactive oxygen species and other proteins that can lead to apoptosis. The pore can also cause mitochondria to release more calcium. In addition, production of adenosine triphosphate (ATP) may be stopped, and ATP synthase may in fact begin hydrolysing ATP instead of producing it.\n\nInadequate ATP production resulting from brain trauma can eliminate electrochemical gradients of certain ions. Glutamate transporters require the maintenance of these ion gradients to remove glutamate from the extracellular space. The loss of ion gradients results in not only the halting of glutamate uptake, but also in the reversal of the transporters. The Na-glutamate transporters on neurons and astrocytes can reverse their glutamate transport and start secreting glutamate at a concentration capable of inducing excitotoxicity. This results in a buildup of glutamate and further damaging activation of glutamate receptors.\n\nOn the molecular level, calcium influx is not the only factor responsible for apoptosis induced by excitoxicity. Recently, it has been noted that extrasynaptic NMDA receptor activation, triggered by both glutamate exposure or hypoxic/ischemic conditions, activate a CREB (cAMP response element binding) protein shut-off, which in turn caused loss of mitochondrial membrane potential and apoptosis. On the other hand, activation of synaptic NMDA receptors activated only the CREB pathway, which activates BDNF (brain-derived neurotrophic factor), not activating apoptosis.\n\nExogenous excitotoxins refer to neurotoxins that also act at postsynaptic cells but are not normally found in the body. These toxins may enter the body of an organism from the environment through wounds, food intake, aerial dispersion etc. Common excitotoxins include glutamate analogs that mimic the action of glutamate at glutamate receptors, including AMPA and NMDA receptors.\n\nThe L-alanine derivative β-methylamino-L-alanine (BMAA) has long been identified as a neurotoxin which was first associated with the amyotrophic lateral sclerosis/parkinsonism–dementia complex (ALS/PDC) in the Chamorro people of Guam. The widespread occurrence of BMAA can be attributed to cyanobacteria which produce BMAA as a result of complex reactions under nitrogen stress. Following research, excitotoxicity appears to be the likely mode of action for BMAA which acts as a glutamate agonist, activating AMPA and NMDA receptors and causing damage to cells even at relatively low concentrations of 10 μM. The subsequent uncontrolled influx of Ca then leads to the pathophysiology described above. Further evidence of the role of BMAA as an excitotoxin is rooted in the ability of NMDA antagonists like MK801 to block the action of BMAA. More recently, evidence has been found that BMAA is misincorporated in place of L-serine in human proteins. It should be noted that a considerable portion of the research relating to the toxicity of BMAA has been conducted on rodents. A study published in 2016 with vervets (Chlorocebus sabaeus) in St. Kitts, which are homozygous for the apoE4 gene (a condition which in humans is a risk factor for Alzheimer's disease), found that vervets orally administered BMAA developed hallmark histopathology features of Alzheimer's Disease including amyloid beta plaques and neurofibrillary tangle accumulation. Vervets in the trial fed smaller doses of BMAA were found to have correlative decreases in these pathology features.This study demonstrates that BMAA, an environmental toxin, can trigger neurodegenerative disease as a result of a gene/environment interaction. While BMAA has been detected in brain tissue of deceased ALS/PDC patients, further insight is required to trace neurodegenerative pathology in humans to BMAA.\n\n\n"}
{"id": "29165314", "url": "https://en.wikipedia.org/wiki?curid=29165314", "title": "FaceBase", "text": "FaceBase\n\nFaceBase is an NIH-supported initiative that began in September 2009. Funded by the National Institute of Dental and Craniofacial Research, the FaceBase Consortium is a five-year initiative that systematically compiles the biological instructions to construct the middle region of the human face and precisely define the genetics underlying its common developmental disorders such as cleft lip and palate. A range of genetic and environmental factors are thought to contribute to facial clefting and FaceBase is designed to enhance investigations into these causes and their outcomes.\n\nThe FaceBase Biorepository is a collection or bank of DNA samples and information from families around the world to be used in research studies. Individuals with birth defects that involve the head, face, and eye can participate along with their family members. DNA is collected through blood or saliva and combined with information about the subject's family history and pregnancy history. The goal of the biorepository is to collect samples and data from 5,000 people to drive research studies on the genetic and environmental factors that contribute to craniofacial birth defects. \n\nSo far, a number of genes have been found to play a role in craniofacial development and the FaceBase project is continuing to research these genes to better understand craniofacial birth defects such as cleft lip and palate. These genes include AXIN2, BMP4, FGFR1, FGFR2, FOXE1, IRF6, MAFB (gene), MMP3, MSX1, MSX2 (Msh homeobox 2), MSX3, PAX7, PDGFC, PTCH1, SATB2, SOX9, SUMO1 (Small ubiquitin-related modifier 1), TBX22, TCOF (Treacle protein), TFAP2A, VAX1, TP63, ARHGAP29, NOG, NTN1, WNT genes, and locus 8q24. \n\nA key part of the initiative is the Hub, which intends to provide easily accessible craniofacial research data. The FaceBase Hub aims to allow scientists to more rapidly and effectively generate hypotheses and accelerate the pace of their research.\n\n"}
{"id": "384000", "url": "https://en.wikipedia.org/wiki?curid=384000", "title": "Game call", "text": "Game call\n\nA game call is a device that is used to mimic animal noises to attract or drive animals to a hunter. Animal species attracted to game calls include deer, turkey, ducks, geese, moose, elk, raccoons, wild pigs, coyotes, and crows.\n"}
{"id": "51235653", "url": "https://en.wikipedia.org/wiki?curid=51235653", "title": "Global Open Data for Agriculture and Nutrition", "text": "Global Open Data for Agriculture and Nutrition\n\nGlobal Open Data for Agriculture and Nutrition (GODAN) is an initiative that seeks to \"support global efforts to make agricultural and nutritionally relevant data available, accessible, and usable for unrestricted use worldwide. The initiative focuses on building high-level policy as well as public and private institutional support for open data.\"\n\nThe initiative was launched in 2013, one year after the G8 summit in 2012 where G-8 leaders \"committed to the New Alliance for Food Security and Nutrition as the next phase of a shared commitment to achieving global food security.\"\n\nAccording to the Open Data Institute, farmers and other stakeholders on the agriculture supply chain can make more informed decisions resulting in improved yields and efficiency – from farm to fork, when they have free access to useful information on agriculture and nutrition.\n\nGODAN and its partners aim to support the open data revolution and hosted the 2016 GODAN summit in New York in September. GODAN has over 400 partners from government, international and private organisations around the world. In the bid to support the open data revolution, the UK Department for Environment, Food and Rural Affairs made over 8,000 data sets available for free use in June 2015.\n\nThe GODAN secretariat has been hosted by CABI in Wallingford, UK since 2014. Its research and partnerships offices are based in Wageningen, Netherlands and Rome, Italy.\n\n\"The GODAN Secretariat states that it has an estimated five year budget of $8.5 million, with five full time employees. GODAN also states that its activities and Secretariat are financially supported by the US Government, the UK Department for International Development (maximum of £2.5 over 5 years), the Government of the Netherlands, the UN Food and Agriculture Organization (FAO), Technical Centre for Agricultural and Rural Cooperation ACP-EU (CTA), Global Forum on Agricultural Research (GFAR), The Open Data Institute (ODI), the Consultative Group for International Agricultural Research (CGIAR) and the CABI.\"\n\nThe GODAN Secretariat is governed by a group of GODAN partners including the US Government, the UK's DFID, the Netherlands Government, the Open Data Institute, FAO, CTA, CABI, CGIAR and GFAR.\n\nIn September 2016, GODAN held a two-day summit in New York described as “the largest event of its kind”, with the aim of raising awareness of the call for making agricultural and nutrition data open. The event featured high profile guests including then U.S. Agriculture Secretary Tom Vilsack and Willy Bett, Kenyan Minister of Agriculture, Livestock, and Fisheries. \n\n"}
{"id": "53099086", "url": "https://en.wikipedia.org/wiki?curid=53099086", "title": "H.D. Chalke", "text": "H.D. Chalke\n\nHerbert Davis Chalke OBE (Mil), TD, FRCP, MRCS, MA (Cantab) (June 15, 1897—October 8, 1979) was a British physician known for his work in the fields of social medicine and medical history. He was the founding editor-in-chief of the medical journal \"Alcohol and Alcoholism\".\n\nChalke was educated at Porth County School, the University of Wales, Cambridge University, and St. Bartholomew's Hospital. He later served in the Royal Flying Corps during part of World War I and all of World War II, retiring as a colonel. In the 1930s, the King Edward VII Welsh National Memorial Association appointed him to study tuberculosis mortality in Wales. He played a major role in a campaign to control a typhus epidemic in Naples, Italy during the 1940s, for which he received the Typhus Commission Medal from the United States government.\n\nHe is survived by his son David John Chalke, now a leading social analyst in Australia. \n\n"}
{"id": "47811841", "url": "https://en.wikipedia.org/wiki?curid=47811841", "title": "Haus \"Graf Anton Günther\"", "text": "Haus \"Graf Anton Günther\"\n\nThe Haus \"Graf Anton Günther\" (aka Hotel Graf Anton Günther) is a historic house in central Oldenburg, Germany, dating from 1682.\n\nCount Anton Günther is depicted riding a horse on the facade, which was redesigned in the neo-Renaissance style in 1894. The house was used by merchants and tobacco manufacturers.\n\nAfter the great fire in Oldenburg, the building was constructed in 1682 as a merchant's house on the Lange Straße. For 135 years it belonged to the Grovermann family. In 1828, it was bought by Hinrich Lebrecht Kirchhoff. In 1838, the tobacco manufacturer Johann Karl Propping acquired the property. Propping built a tobacco factory designed by the architect Klingenberg. The house changed hands several times in the 1890s until it was bought by the Hoyer brewery. The house became a restaurant and hotel in 1894 and was named \"Graf Anton Günther\". Professor August Oetken created the large exterior fresco of Count Anton Günther on his horse, Kranich.\n\n"}
{"id": "31460576", "url": "https://en.wikipedia.org/wiki?curid=31460576", "title": "Health and Social Care Act 2012", "text": "Health and Social Care Act 2012\n\nThe Health and Social Care Act 2012 (c 7) is an Act of the Parliament of the United Kingdom. It provides for the most extensive reorganisation of the structure of the National Health Service in England to date. It removed responsibility for the health of citizens from the Secretary of State for Health, which the post had carried since the inception of the NHS in 1948. It abolished NHS primary care trusts (PCTs) and Strategic Health Authorities (SHAs) and transferred between £60 billion and £80 billion of \"commissioning\", or health care funds, from the abolished PCTs to several hundred \"clinical commissioning groups\", partly run by the general practitioners (GPs) in England but a major point of access for private service providers. A new executive agency of the Department of Health, Public Health England, was established under the Act on 1 April 2013.\n\nThe proposals are primarily the result of policies of the then Secretary of State for Health, Andrew Lansley. Writing in the \"BMJ\", Clive Peedell (co-chairman of the NHS Consultants Association and a consultant clinical oncologist) compared the policies with academic analyses of privatisation and found \"evidence that privatisation is an inevitable consequence of many of the policies contained in the Health and Social Care Bill\". Lansley said that claims that the government is attempting to privatise the NHS are \"ludicrous scaremongering\".\n\nThe proposals contained in the Act are some of the coalition government's most controversial. Although glanced at in the Conservative Party's manifesto in 2010, they were not discussed during the general election campaign that year and were not contained in the Conservative – Liberal Democrat coalition agreement, which mentioned the NHS only to commit the coalition to a real-term funding increase every year. Within two months of the election a white paper was published, outlining what the \"Daily Telegraph\" called the \"biggest revolution in the NHS since its foundation\". The bill was introduced in the House of Commons on 19 January 2011. In April 2011 the government announced a \"listening exercise\", halting the Bill's legislative progress until after the May local elections. The \"listening exercise\" finished by the end of that month. The Bill received Royal Assent on 27 March 2012.\n\nThe proposals in the Act were not discussed during the general election campaign in 2010 and were not contained in the Conservative – Liberal Democrat coalition agreement of 20 May 2010, which declared an intention to \"stop the top-down reorganisations of the NHS that have got in the way of patient care\". However, within two months a white paper outlined what the \"Daily Telegraph\" called the \"biggest revolution in the NHS since its foundation\". The white paper, \"Equity and Excellence: Liberating the NHS\", was followed in December 2010 by an implementation plan in the form of \"Liberating the NHS: legislative framework and next steps\". McKinsey & Company who have been influential in the British Department of Health for many years was heavily involved in the discussions around the Bill. The bill was introduced into the House of Commons on 19 January 2011 and received its second reading, a vote to approve the general principles of the Bill, by 321-235, a majority of 86, on 31 January 2011.\n\nThe Act had implications for the entire NHS. NHS primary care trusts (PCTs) and Strategic Health Authorities (SHAs) were abolished, with projected redundancy costs of £1 billion for around 21,000 staff. £60 to £80 billion worth of commissioning will be transferred from PCTs to several hundred clinical commissioning groups, partly run by GPs. Around 3,600 facilities owned by PCTs and SHAs will transfer to NHS Property Services, a limited company owned by the Department of Health.\n\nWhen the white paper was presented to Parliament the Secretary of State for Health, Andrew Lansley, told MPs of three key principles:\n\nThe white paper set out the following timetable. By April 2012 it proposed to:\n\nThe Bill foresaw all NHS trusts becoming, or being amalgamated into, foundation trusts. The Bill also abolished the existing cap on trusts' income from non-NHS sources, which in most cases was previously set at a relatively low single-digit percentage.\n\nUnder the Bill's provisions the new commissioning system would be expected to be in place by April 2013, by which time SHAs and PCTs would be abolished.\n\nThe Bill was analysed by Stephen Cragg of Doughty Street Chambers, on behalf of the 38 Degrees campaign, who concluded that \"Effectively, the duty to provide a national health service would be lost if the Bill becomes law, and would be replaced by a duty on an unknown number of commissioning consortia with only a duty to make or arrange provision for that section of the population for which it is responsible.\" It replaces a “duty to provide” with a “Duty to promote”.\n\nAfter an increase in opposition pressure, including from both rank-and-file Liberal Democrats and the British Medical Association, the government announced a \"listening exercise\" with critics. On 4 April 2011 the government announced a \"pause\" in the progress of the Bill to allow the government to 'listen, reflect and improve' the proposals.\n\nThe Prime Minister, David Cameron, said \"the status quo is not an option\" and many within his and Nick Clegg's coalition said that certain aspects of the Bill, such as the formation of Clinical commissioning groups, were not only not open for discussion, but also already too far along the path to completion to be stopped. Cameron insisted that the Act was part of his \"Big Society\" agenda and that it would not alter the fundamental principles of the NHS.\n\nPart of the \"listening exercise\" saw the creation on 6 April 2011 of the \"NHS Future Forum\". The Forum, according to \"Private Eye\", \"brings together 43 hand-picked individuals, many of whom are known as supporters of Lansley's approach\". At the same time, David Cameron set up a separate panel to advise him on the reforms; members of this panel include Lord Crisp (NHS chief executive 2000-2006), Bill Moyes (a former head of Monitor), and the head of global health systems at McKinsey, as well as Mark Britnell, the head of health policy at KPMG. Six months previously Britnell had told a conference of private healthcare executives that \"In future, the NHS will be a state insurance provider not a state deliverer,\" and emphasised the role of Lansley's reforms in making this possible: \"The NHS will be shown no mercy and the best time to take advantage of this will be in the next couple of years.\" KPMG issued a press statement on behalf of Britnell on 16 May 2011 stating \n\"The article in \"The Observer\" attributes quotes to me that do not properly reflect discussions held at a private conference last October. Nor was I given the opportunity to respond ahead of publication. I worked in the NHS for twenty years and now work alongside it. I have always been a passionate advocate of the NHS and believe that it has a great future. Like many other countries throughout the world, the pressure facing healthcare funding and provision are enormous. If the NHS is to change and modernise the public, private and voluntary sectors will all need to play their part.\"\n\nIn June 2011 Cameron announced that the original deadline of 2013 would no longer be part of the reforms. There would also be changes to the Bill to make clear that the main duty of the health regulator, Monitor, will be to promote the interests of patients rather than promoting competition.\n\nThe Future Forum report suggested that any organisation that treats NHS patients, including independent hospitals, should be forced to hold meetings in public and publish minutes. It also wants the establishment of a Citizens’ Panel to report on how easy it is to choose services, while patients would be given a right to challenge poor treatment. The original Bill sought to abolish two tiers of management and hand power to new bodies led by GPs, called commissioning consortia, to buy £60 billion a year in treatment. Professor Steve Field, a GP who chaired the forum, said many of the fears the public and medical profession had about the Health and Social Care Bill had been \"justified\" as it contained \"insufficient safeguards\" against private companies exploiting the NHS.\n\nFollowing the completion of the listening exercise, the Bill was recommitted to a public bill committee on 21 June 2011. On 7 September, the Bill passed the House of Commons and received its third reading by 316-251. On 12 October 2011, the Bill was approved in principle at second reading in the House of Lords by 354-220. An amendment moved by Lord Owen to commit the most controversial clauses of the Bill to a select committee was defeated by 330-262. The Bill was subsequently committed to a committee of the whole House for detailed scrutiny. The committee stage was completed on 21 December 2011, and the Bill was passed by the Lords, with amendments, on 19 March 2012. The Commons agreed to all Lords amendments to the Bill on 20 March 2012. The Bill received Royal Assent and became the Health and Social Care Act 2012 on 27 March 2012.\n\nSection 9 establishes the National Health Service Commissioning Board, which is now known as NHS England. The Secretary of State is to publish, annually, a document known as the mandate which specifies the objectives which the Board should seek to achieve. National Health Service (Mandate Requirements) Regulations are published each year to give legal force to the mandate.\n\nSections 278 to 283 abolished the Alcohol Education and Research Council, the Appointments Commission, the National Information Governance Board for Health and Social Care, the National Patient Safety Agency, the NHS Institute for Innovation and Improvement and the Standing advisory committees.\n\nSections 284 to 309 contained various other provisions.\n\nOn 19 January 2012 two major unions of healthcare professionals that had previously tried to work with the Government on the bill, the Royal College of Nursing and the Royal College of Midwives, decided instead to join with the British Medical Association in \"outright opposition\" to the bill. On 3 February 2012 the Royal College of General Practitioners also called on the Prime Minister to withdraw the bill.\n\nThe Confederation of British Industry supported the bill, declaring that \"Allowing the best provider to deliver healthcare services, whether they are a private company or a charity, will spur innovation and choice.\"\n\nIn May 2011, a number of doctors from GP consortia wrote a letter to the \"Daily Telegraph\" in which they expressed their support for the bill, calling its plans \"a natural conclusion of the GP commissioning role that began with fundholding in the 1990s and, more recently, of the previous government's agenda of GP polysystems and practice-based commissioning\". On 14 May 2011, \"The Guardian\" published an article reporting that the GP appointed to head the NHS \"listening exercise\" has unilaterally condemned the bill. The article said that Steve Field had \"dismissed\" the plans \"as unworkable\" and that these statements were \"provisional conclusions that could fatally undermine the plans\". The Royal College of General Practitioners (RCGP) also denounced the bill.\n\nThe Royal College of Physicians and Royal College of Surgeons welcomed \"in principle\" the idea of medical professionals determining the direction of NHS services, but questioned the Bill's implementation of the principle, particularly in regard to the approach of making GP consortia the primary commissioning deciders, and also in regard to requiring competition. The British Medical Association said similarly. Neither of these organisations supported the bill.\n\nIn February 2011 David Bennett, newly appointed Chair of Monitor, said the NHS could become like other privatised utilities, so that Monitor would potentially be a regulator like Ofcom, Ofgem and Ofwat: \"We, in the UK, have done this in other sectors before. We did it in gas, we did it in power, we did it in telecoms […] We've done it in rail, we've done it in water, so there's actually 20 years of experience in taking monopolistic, monolithic markets and providers and exposing them to economic regulation.\" The House of Commons Select Committee on Health condemned the comparison as not \"accurate or helpful.\"\n\nAny Qualified Provider was called 'Any Willing Provider' under the Labour administration and was a mechanism deployed to improve patient choice. Physicians and other employees of the NHS were worried about the bill's intention to amend one of the founding pillars of the NHS to read \"any willing provider\" rather than the current language guaranteeing a needed service exclusively via the NHS and its direct affiliates and partners. Changing of the language of the NHS tenets to read \"any willing provider\" takes away that requirement and allows private sector providers to have a potentially major say inside the NHS, potentially introducing private-sector operations and pricing within the NHS and even opening up local NHS operations to the possibility of forced closure because the private industry could out-compete them and corral the NHS services into bankruptcy. The British Medical Association has said that \"Forcing commissioners of care to tender contracts to any willing provider, including ... commercial companies, could destabilise local health economies and fragment care for patients. Adding price competition into the mix could also allow large commercial companies to enter the NHS market and chase the most profitable contracts, using their size to undercut on price, which could ultimately damage local services.\"\n\nSee Any Qualified Provider.\n\nThe bill intends to make general practitioners the direct overseers of NHS funds, rather than having those funds channelled through neighbourhood- and region-based Primary Care Trusts, as is currently done.\n\nThere are concerns about fragmentation of the NHS and a loss of coordination and planning. The Royal College of General Practitioners said it was \"concerned that some of the types of choice outlined in the government’s proposals run a risk of destabilising the NHS and causing long-term harm to patient outcomes, particularly in cases of children with disabilities, those with multiple comorbidities and the frail and elderly.\" Similarly, the Royal College of Physicians said that \"Whilst we welcome the broad provision in the bill to seek professional expertise, the RCP is concerned that the bill does not require that specialists are at the heart of the commissioning process.\" The Royal College of Psychiatrists said it \"would be dismayed if psychiatrists were not closely involved with local consortia of GPs in the development of mental health services.\" The Royal College of Surgeons said that \"the legislation leaves the question of regional level commissioning unanswered with no intermediary structure put in place.\" And there are concerns about management expertise, particularly by looking at the US. The \"BMJ\" wrote that \"No matter how many GP consortiums eventually emerge, their number will probably greatly exceed the 152 primary care trusts they are replacing, which brings a set of new challenges. Smaller populations increase the chances that a few very expensive patients will blow a hole in budgets. More consortiums mean that commissioning skills, already in short supply nationally, will be spread even more thinly. Denied economies of scale, smaller consortiums may be tempted to cut corners on high quality infrastructure and management, thereby endangering their survival. These points emerge clearly from an examination of 20 years of US experience of handing the equivalent of commissioning budgets to groups of doctors. Some groups had severely underestimated the importance of high quality professional management support in their early days and gone bankrupt as a result.\"\n\nThe House of Commons health committee has suggested the government let experts other than the consortia GPs and their direct allies get involved in the running of the consortia, including hospital doctors, public health chiefs, social care staff, and councillors. That idea has received some wider support and the government has agreed to give it consideration. Those close to Health Secretary Andrew Lansley have said, however, that Lansley is concerned adding too many people to consortia decision-making risks making the consortia too unwieldy.\" In 2010 the same committee had gone so far as to declare that \"if reliable figures for the costs of commissioning prove that it is uneconomic and if it does not begin to improve soon, \"after 20 years of costly failure, the purchaser/provider split may need to be abolished\".\"\n\nKieran Walshe, professor of health policy and management and Chris Ham, chief executive of the King's Fund, have argued that \"At a national level, it is difficult to see who, if anyone, will be in charge of the NHS. There will be five key national bodies: the Department of Health, the National Institute for Health and Clinical Excellence, the Care Quality Commission, the NHS Commissioning Board, and the economic regulator Monitor. Although the remit of each is set out in legislation, it is not clear how these national bodies will interact or how they will provide coordinated and consistent governance of the NHS.\"\n\nClinical commissioning groups will operate as statutory bodies, though it has been suggested that up to third of CCGs are reluctant to do so.\n\nThe King's Fund said that \"the very real risk that the speed and scale of the reforms could destabilise the NHS and undermine care must be actively managed.\"\n\nThe \"BMJ\" said in January 2011 that \"The bill promises that all general practices will be part of consortiums by April 2012, yet it took six years for 56% of general practices to become fundholders after the introduction of the internal market. Nearly seven years after the first NHS trust was granted foundation status, there are still more than half to go—within two years. And there’s more. The replacement for the 10 strategic health authorities—the NHS Commissioning Board—needs to be fully operational by next April. By then, GP consortiums should have developed relationships with local authorities, which will assume ultimate responsibility for public health via their new health and wellbeing boards, working alongside Public Health England, a completely new entity.\" The BMA believes such targets to be either wholly impossible or, at best, able to be done only in a very roughshod manner, which could in turn have very serious on-the-ground consequences to NHS functioning.\n\nThe British Medical Association opposes the bill, and held its first emergency meeting in 19 years, which asked the government to withdraw the bill and reconsider the reforms, although a motion of no confidence in Andrew Lansley by the BMA failed. A later motion of no confidence in Lansley by attendees at the Royal College of Nursing Conference in 2011, however, succeeded, with 96% voting in favour of the motion, and several speeches thereafter condemning Lansley threefold: the Health and Social Care Bill 2011 as-written; Lansley's decision not to address the entire Conference with a speech, but instead to hold a separate meeting with 40 Conference attendees in a separate space (taken as an insult to nurses, and leading to accusations of 'gutlessness'); and the current separate \"efficiency savings\" measures being undertaken across the NHS and those actions' material impact on frontline medical services, especially as contrasted with several prominent officials, including NHS leaders and Lansley himself, repeatedly assuring that NHS frontline services are 'protected' at all times regardless of these \"savings\" measures. \"People will die\", Richard Horton, editor of \"The Lancet\", warned in March 2012, as he predicted \"unprecedented chaos\" as a result of the reforms, with a leaked draft risk-assessment claiming that emergencies could be less well managed and the increased use of the private sector could drive up costs.\n\nVarious pressure groups opposed the bill, including NHS Direct Action, Keep Our NHS Public, 38 Degrees, the Socialist Health Association, many Trades unions, including the Chartered Society of Physiotherapy, UNISON, and Unite. 38 Degrees' petition against the reforms passed 250,000 signatures by 21 April 2011. In March 2011 a motion at the Liberal Democrat spring conference called for changes to the Bill to ensure greater accountability and prevent cherry-picking by private providers, among other demands aimed at reducing marketisation of the NHS. UNISON sponsored rapper NxtGen to create an unflattering hip hop track about the bill, which has now been viewed over 390,000 times on YouTube.\n\nJeremy Hunt was appointed Health Secretary in a cabinet reshuffle on 4 September 2012, succeeding Lansley. He has previously co-authored a book calling for the NHS to be dismantled and replaced with a system of personal health accounts. The deputy chairman of the British Medical Association, Dr Kailash Chand, said \"Jeremy Hunt is new Health Secretary – disaster in the NHS carries on. I fear a more toxic right winger to follow the privatisation agenda.\"\n\nOn 9 October 2011, a protest organised by UK Uncut took place on Westminster Bridge. an estimated 2,000 health workers and activists attended the protest.\n\nOn 5 March 2012, the campaign group 38 Degrees erected 130 billboards in the centre of London with the aim of persuading David Cameron to abandon the bill.\n\nOn 25 September 2013 Labour's shadow health secretary Andy Burnham promised that the party will repeal the Health and Social Care Act in \"the first Queen's Speech\" if elected.\n\nIn January 2015 Chris Ham and others from the King's Fund produced a review of the government's health reforms. Their conclusions as far as the Act was concerned were that: \n\nIn November 2017 Jeremy Hunt in an interview with the Health Service Journal said \"The idea of lots of competing foundation trusts and payment by results works well when you have in your mind that most of the work the NHS does will be single episode elective care, but when you’re dealing with complex patients who are going in and out of the system a lot those structures prove not to be fit for purpose.\"\n\nNick Timmins, writing in 2018, concluded that the legislation, in its own terms, had failed. Choice and competition were not, as envisaged, the driving principles of the NHS. In fact the development of integrated care systems was unpicking the “purchaser/provider” split that had been the dominant theme of NHS management since 1991. The organisations set up by the Act, Monitor and the NHS Trust Development Authority had effectively been merged. And there was nothing to suggest that “political micro-management” and “excessive bureaucratic and political control” had disappeared. But, he said the Act had given the NHS an independent voice, and that according to Jeremy Hunt “the independence of NHS England is the bit that has worked best”.\n\n\n"}
{"id": "18514732", "url": "https://en.wikipedia.org/wiki?curid=18514732", "title": "Henry Harrower", "text": "Henry Harrower\n\nHenry Robert Harrower, MD (1883–1934) was a controversial early figure in endocrinology, and the author of several books and many papers on the subject. He was the impetus for the foundation of the Association for the Study of Internal Secretions, now called The Endocrine Society, and edited the first two editions of their journal \"Endocrinology\". He was known for his advocacy of organotherapy, which involved consuming various glands and at times other parts of the body. He experienced financial success for this practice. Endocrinologists disdained these practices, believing that only the thyroid gland could have a meaningful effect when consumed orally. Harrower's organotherapy was the subject of repeated criticism. As he was the main proponent of the movement, it faded after his death.\n\nHarrower was born in London, England. When he was 20 years old he traveled to Battle Creek, Michigan to enroll in the American Medical Missionary College after studying for three years in Scandinavia to become a masseuse. At the Seventh-day Adventist college he learned, and was receptive to, the alternative therapy teachings of John Harvey Kellogg. He graduated and spent several years in France and Italy, traveling back and forth between Europe and the United States. It was during this time he became interested in advocating organotherapy. In 1912, he published his book, \"Practical Hormone Therapy\", which dealt with organotherapeutic practices. He eventually settled in an exclusive suburb in Glendale, California and established The Harrower Laboratory and Clinic.\n"}
{"id": "23503226", "url": "https://en.wikipedia.org/wiki?curid=23503226", "title": "Hope (cigarette)", "text": "Hope (cigarette)\n\n\"This article is about the Japanese cigarette brand. For other uses, see Hope (disambiguation).\"\nHope is a Japanese brand of cigarettes, currently owned and manufactured by Japan Tobacco. \n\nHope is a long-selling product familiar with the names of \"Short Hope\" and \"Shoppo\" (it is the official product name to put the number of entries per package in parentheses). There was a Hope brand with a similar name which was introduced in 1931 and existed until September 1940, after Emperor Hirohito forbode any foreign-named brands, Hope was relaunched in 1957, but it is not related to the pre-war Hope. It is the counterpart to Peace cigarettes\n\nThe bow and arrow of the package design are images of the bow and arrow used by the Roman mythical figure Cupid. The color of the bow and arrow and the brand name are navy blue, light uses the colour red, super light uses the colour monotone and menthol uses the colour green. \n\nThe design of Hope has a smaller proportion of letters of \"HOPE\" of the logotype compared to the originally released packs, the proportion such as the serif portion is thick (minor change in mid November 1995, at the same time tar / nicotine value was 15 mg and 1.3 mg and was changed to 14 mg and 1.2 mg). Although other warning texts were inserted, it basically has kept the image since the introduction of the brand in 1957. This package was designed by Shirozu Shiozuka.\n\nHope Light was also released and, at the time of its launch, was adopted with a different design, unified design at the minor change of Hope in November 1995 (at the same time tar / nicotine values went from 11 mg of tar and 1.0 mg of nicotine to 9 mg of tar and 0.8 mg of nicotine), and the Super Lights and Menthol variants released after were basically the same as Hope, except that the color of the bow and arrow were different. Later, in September 2009, the Super Light was changed, instead of featuring the traditional silver arrows, it featured monotone to craft tones, and in October of that year the Light and Menthol variants also complied with the Super Light as it was renewed to a craft style package. At the same time, the Light adopted a charcoal filter and the taste had been changed.\n\nThe pack design was once again changed in February 2014, based on the design of Hope, the bow and arrow would be arranged in three dimensions and a shadow would be placed in the character of \"HOPE\". The design was once again unified with all 4 variants.\n\n\"Hope Dry Gold\" which was released for a limited time from April 2014 (the whole pack was gold) as well as \"Hope Sour Red\" (which had an entirely red pack) which was also released for a limited time from November 2014. \"Hope Hot Black\" (which has an entirely black pack) and \"Hope Passion Yellow\" (the pack is entirely yellow) were also released for a limited time .The basic design is the same for other models, however, \"Hot Black\" and \"Passion Yellow\" were designed on the left side. \n\nIn addition, in the inner pack other than Hope, before the renewal in February 2014, a different illustration was drawn depending on the issue. For example, there was a hidden playful spirit such as a drawing of a drawing that a Samurai draws a bow and arrow, and a hand of a scissors was drawn. Cardboard was embossed in the initial package (different wrapping paper also varied depending on the brand name). \n\nBelow are all the variants of Hope cigarettes, with the levels of tar and nicotine included.\n\nHope (20), which was once sold, was a soft package with a long size (later king size). It is known as \"Long Hope\". The mark of the bow and arrow of the package is red, close to vermillion and is slightly smaller than the current Hope. In addition, the logo type of this package is the difference between the normal one is Roman body \"HOPE\", and the difference is seen that it the \"Century Gothic\" and \"hope\". Despite the fact that all current Hope variants are of the same regular size, it is called \"short hope\" because of the existence of this former Hope (20). Nakajima's writers also love it, and they also appear during the work. \n\nIn the Philippines, Hope is a brand owned by Fortune Tobacco Corporation and is manufactured and distributed by PMFTC, Inc. It is unrelated to Japan Tobacco's Hope brand, although the Philippine brand renders the Hope brand name in a similar typeface. It sold as a mentholated cigarette in 100-mm and 85-mm sticks. It is labelled with the word \"Luxury\" beneath the Hope brand name.\n\nThe brand was advertised on the basis of \"mentholated freshness\". The television commercials showed foreign talents engaged in exhilarating Western leisure activities like sky-diving, wakeboarding and boat racing to drive home the \"freshness\" story. The commercials were made even more popular with its jingle, sang by a 21-year-old Claire de la Fuente, a Karen Carpenter sound-alike. The advertisements lasted from the 1970s until 2006. Since 1 January 2007, the radio and television cigarette advertising was currently banned.\n\n"}
{"id": "2005758", "url": "https://en.wikipedia.org/wiki?curid=2005758", "title": "JDRF", "text": "JDRF\n\nJDRF is an American nonprofit 501(c)(3) organization that funds type 1 diabetes (T1D) research and advocates for regulation favorable to medical research and that makes it easier to market new medical devices. It was formerly called the Juvenile Diabetes Research Foundation.\n\nJDRF was founded to find a cure for juvenile diabetes; in the 2000s it broadened its research efforts to include ways to better manage the disease and ways to prevent it.\n\nIn 2005 the board of JDRF committed to supporting work on medical devices to manage blood glucose, known as artificial pancreas technology. The Board was urged to do so by Jeffrey Brewer, who had founded and sold Citysearch and had become intensely interested in juvenile diabetes and medical devices after his son was diagnosed with the condition. The project brought together academic researchers and medical device companies. The focus was on integrating continuous glucose monitors (CGM's) and insulin pumps via a computerized program that would use blood glucose levels obtained through the CGM to calculate an insulin dosage to be dispensed through the insulin pump. The first such device was approved in 2016.\n\nJDRF has advocated for stem cell research; in a 2004 article in \"The Wall Street Journal\", the authors observed that the JDRF \"... has become adept at unleashing an army of hard-to-resist lobbyists -- made up of determined parents and their afflicted children -- on researchers, politicians and potential donors.\"\n\nIn 2011 the FDA had made it a priority to clarify the requirements for approval for such a closed-loop monitoring and drug delivery device for T1D, and in 2011 announced it was preparing draft guidelines. JDRF launched a campaign to influence those guidelines to be lenient. After the first closed loop device was approved in 2016, JDRF lobbied insurance companies to cover it. It also put resources into educating people with diabetes on how to navigate health insurance in the United States, and into lobbying Congress to continue funding diabetes research through the NIH.\n\nThe FDA lobbying campaign was part of a gradual realignment of the organization to focus on issues other than helping find a cure for JD, to helping treat and manage it. This broadened scope meant that the organization increasingly directed its funds to education and advocacy, along with research funding. This including lobbying insurance companies to pay for continuous glucose monitor devices and educating patients how to advocate for themselves, and lobbying Congress for more NIH funding.\n\n"}
{"id": "9931903", "url": "https://en.wikipedia.org/wiki?curid=9931903", "title": "Jhalaar", "text": "Jhalaar\n\nJhalaar (Punjabi: Shahmukhi جهلار or Gurmukhi ਝਲਾਰ)\n\n\"English Translation\" : An excavation by the side of a pond, river or canal from which water is taken up for irrigation, a waterfall.\n\nA jhalaar is a method of irrigation from an open surface of water by means of the Persian wheel. There are several kinds of jhalaar.\n\n\nJhalaars were commonly found in most parts of Punjab like Jhang and Multan but are rarely seen now as water pumping engines have replaced them.\n"}
{"id": "18962869", "url": "https://en.wikipedia.org/wiki?curid=18962869", "title": "John Dudgeon", "text": "John Dudgeon\n\nJohn Dudgeon (1837 – 1901) was a Scottish physician who spent nearly 40 years in China as a doctor, surgeon, translator, and medical missionary.\n\nDudgeon attended the University of Edinburgh and the University of Glasgow, in the latter of which he graduated M.D. and Master of Surgery in 1862. In 1863, he was appointed to the Medical Mission of the London Missionary Society to serve at the hospital in Peking established by William Lockhart, arriving in China in December 1863. He was also Medical Attendant to the British Legation in Peking (modern-day Beijing) from 1864-1868. Dudgeon was appointed Professor of Anatomy and Physiology at the Imperial College (Tongwen guan) during the 1870s and 1880s. In \"Wanderings in China\", Constance Frederica Gordon Cumming wrote:\n\nHe was an accomplished Chinese scholar, and during his long residence at Pekin he studied the manners and customs of the inhabitants, and the semi-annual reports that he forwarded to the Chinese Maritime Customs Service contain a large amount of valuable information regarding the climatic condition, physical features and drainage, and general habits of the people bearing upon health. He was the author of an \"Historical Sketch of the Ecclesiastical, Political, and Commercial Relation of Russia with China\", of a Chinese work 脱影奇观 \"On the Principles and Practice of Photography\", the first of its kind, and of an article in the \"Pekin Magazine\" (in Chinese) on the virtues of quinine, in which he pointed out the dangers of the imported spurious article. To the \"Chinese Medical Journal\" he contributed papers on \"A Modern Chinese Anatomist\", and \"A Chapter on Chinese Surgery\". He also made several contributions to other medical journals, especially on subjects connected with the medical practice and \"materia medica\" of China. Various editions of his Kung Fu books are still available to purchase : \"Kung Fu or Taoist Medical Gymnastics: The Art of Shaolin Kung Fu, Traditional Chinese Medicine and Qigong Beginning Practice\" and \"Chinese healing arts: Internal Kung-Fu\" co authored with William Berk. Over a period of 10 years he translated both Gray's Anatomy and Holden's Osteology into an 18 volume Chinese edition.\n\nDudgeon said that in China, \"Infanticide does not prevail to the extent so generally believed among us, and in the north it does not exist at all.\"\n\nDudgeon resigned from the London Mission Society in 1884 after conflicts over the prioritisation of evangelical and medical work. Thereafter he continued in private practice in Peking until his death in February 1901.\n\n\"This article incorporates text from an obituary published in \"The British Medical Journal\", March 16, 1901, now in the public domain.\"\n"}
{"id": "9024364", "url": "https://en.wikipedia.org/wiki?curid=9024364", "title": "List of UN numbers 0001 to 0100", "text": "List of UN numbers 0001 to 0100\n\nThe UN numbers from UN 0001 to UN 0100 as assigned by the United Nations Committee of Experts on the Transport of Dangerous Goods.\n"}
{"id": "23910100", "url": "https://en.wikipedia.org/wiki?curid=23910100", "title": "Medical Act 1858", "text": "Medical Act 1858\n\nThe Medical Act (21 & 22 Vict c 90), \"An Act to Regulate the Qualifications of Practitioners in Medicine and Surgery\", also referred to as the Medical Act 1858, was an Act of the Parliament of the United Kingdom which created the General Medical Council to regulate doctors in the UK.\n\nIt is one of the Medical Acts.\n\nDescribing its purpose, the Act notes that \"it is expedient that Persons requiring Medical Aid should be enabled to distinguish qualified from unqualified Practitioners\". \n\nThe Act creates the position of Registrar of the General Medical Council — an office still in existence today — whose duty is to keep up-to-date records of those registered to practise medicine and to make them publicly available.\n\nThe Act has now been almost entirely repealed. The current law governing medical regulation is the Medical Act 1983.\n\nIt stated that under the Poor Law system Boards of Guardians could only employ those qualified in medicine and surgery as Poor Law Doctors.\n\nUnder a clause in the Act that recognized doctors with foreign degrees practising in Britain, Elizabeth Blackwell was able to become the first woman to have her name entered on the Medical Register (1 January 1859).\n"}
{"id": "6053480", "url": "https://en.wikipedia.org/wiki?curid=6053480", "title": "Medical Council of India", "text": "Medical Council of India\n\nThe Medical Council of India (MCI) Indian Medical Council (Amendment) Ordinance, \n2018 (Ordinance 8 of 2018), the Medical Council of India shall stand superseded\nnow is not a statutory body for establishing uniform and high standards of medical education in India. The Council grants recognition of medical qualifications, gives accreditation to medical schools, grants registration to medical practitioners, and monitors medical practice in India. The current President of MCI is Dr. Jayshreeben Mehta.\n\nNow the Supreme Court has allowed the Central Government to replace the medical council and with the help of five specialized doctors monitor the medical education system in India, from July 2017.\n\nThe planning commission has recommended the replacement of Medical Council of India (MCI) with National Medical Commission (NMC). The decision has been approved by most states and after its approval by the Prime Minister it will be proposed as final bill in the upcoming parliamentary sessions. \nThe Medical Council of India was first established in 1934 under the Indian Medical Council Act, 1933. The Council was later reconstituted under the Indian Medical Council Act, 1956 that replaced the earlier Act.\n\nFollowing this, the Council was superseded by the President of India and its functions entrusted to a Board of Governors. The present Board of Governors was notified on 13 May 2011.\n\nAgain vide Govt. of India notification, the Council re-constituted and functioning currently\n\nThe main functions of the Medical Council of India are as follows:\n\nRegistration of doctors and their qualifications is usually done by state medical councils.\n\nThe MCI was dissolved by the President of India on 15 May 2010 following the arrest of MCI's president Ketan Desai by the CBI on 22 April 2010. Desai, alleged middle-man J. P. Singh and doctors Sukhwinder Singh and Kanwaljit Singh have been booked under the Prevention of Corruption Act. The CBI recovered 1.5 kg of gold and 80 kg of silver from Desai's premises. Further, gold worth ₨ 35 lakhs were recovered from Desai's bank lockers in Ahmedabad.\nKetan Desai, the head of urology at B J Medical College and president of the Gujarat Medical Council was caught by the CBI for accepting a bribe of 2 crores to grant recognition to a private college. He was immediately removed from the Medical council and his registration cancelled.\n\nThe council was revamped in 2013 and the current President of MCI, Dr.Jayshreeben Mehta was elected unanimously. She became the first woman president of MCI in 80 years since the council came into being.\n\n\"MCI Online\" is the portal of the Medical Council of India for online processing of applications for registration (of medical qualifications) and for professional certificates. \"MCI Online\" also provides online search of the Indian Medical Registe.Medical Council of India has been superseded vide Indian Medical Council (Amendment) Ordinance, 2018 (Ordinance 8 of 2018) dated 26.09.2018, - by the Board of Governors. The Board of Governors has taken over functions of the Medical Council of India on 26.09.2018 AN.\nThe site is temporarily out of service due to maintenance work.\n\n\n"}
{"id": "14136100", "url": "https://en.wikipedia.org/wiki?curid=14136100", "title": "National Pollutant Release Inventory", "text": "National Pollutant Release Inventory\n\nThe National Pollutant Release Inventory (NPRI), established in 1992, is the national Pollutant Release and Transfer Register of Canada. This list of pollutants contains releases from a facility to the air, water, and land along with disposals at, or from a facility. Reported information is used in the creation of pollution management plans and to inform Canadians about their environment.\n\nFacilities which meet reporting requirements are required to report to the NPRI under the Canadian Environmental Protection Act, 1999 (CEPA 1999). Over 300 substances are listed on the NPRI, and over 8,000 facilities annually report information on their pollutant releases and transfers to Environment and Climate Change Canada.\n\nNPRI data is available through an on-line Query search, downloadable Microsoft Access (mdb) format datasets, and downloadable map layers for use with Google Earth (which were the first Google Earth map layers to be published by the Government of Canada).\n\nThe NPRI records information about:\nAll orders of government, companies and associations use NPRI data to track national environmental performance. The NPRI is also used to inform Canadians of the pollutants in their communities, identify environmental priorities and track progress in pollution prevention. Other uses include evaluating releases and transfers of any substances of concern, model air quality and implement policy initiatives. An overview of the NPRI is released annually and is known as the NPRI data highlights.\n\nData collected by the NPRI is accessible in a variety of ways including:\nData is provided in the language in which it was submitted, and updated at least once every year.\n\nReporting to the NPRI is mandatory under CEPA, 1999. Facility owners and operators may need to report if one or more of these conditions is met:\nFacility owners and operators report their substances by using the tools found on the on-line reporting software known as the Single Window reporting module. This software guides users through a comprehensive questionnaire in order to organize and set up their annual report.\n\n"}
{"id": "47581493", "url": "https://en.wikipedia.org/wiki?curid=47581493", "title": "Newcastle 85+ Study", "text": "Newcastle 85+ Study\n\nThe Newcastle 85+ Study is a longitudinal study of health and aging of people over 85 years old. It began in 2006, led by Professor Tom Kirkwood at Newcastle University, and included over 1,000 85-year-olds born in 1921 and registered with GPs in Newcastle and North Tyneside.\n\n11% of those studied said their health was excellent when compared with others of the same age. About 37% of the men and about 70% of the women reported they could still manage cooking, bathing and their personal finances. Their average number of diseases was four for men and five for women. Most of the subjects were cared for by their female children who were generally around 60.\n\nThere will be a further study of people born in 1931.\n\n"}
{"id": "41136939", "url": "https://en.wikipedia.org/wiki?curid=41136939", "title": "Obstetric transition", "text": "Obstetric transition\n\nIn reproductive health, obstetric transition is a concept around the secular trend of countries gradually shifting from a pattern of high maternal mortality to low maternal mortality, from direct obstetric causes of maternal mortality to indirect causes, aging of maternal population, and moving from the natural history of pregnancy and childbirth to institutionalization of maternity care, medicalization and over medicalization. This concept was originally proposed in the Latin American Association of Reproductive Health Researchers (ALIRH, 2013) in analogy of the epidemiological, demographic and nutritional transitions.\n\nIn the last two decades, the world has seen a substantial reduction of maternal mortality.(1) Considering that maternal mortality is vastly determined by social, societal and contextual factors, this reduction is important not only because of the number of lives that have been spared in this period (an estimated 2,000,000 between 1990 and 2010), but because it denotes that the world is making progress towards development and gender equality.(1,2) However, this progress is still insufficient, unequal and slow: recent estimates suggest that 287,000 women died of causes related to pregnancy and childbirth in 2010. Maternal mortality remains a global tragedy, but the observed progress inspires the international community to believe and strive for the elimination of maternal mortality in the decades to come.(3)\n\nThe vast majority of maternal deaths is avoidable and takes place in developing countries. In developed countries, the maternal mortality ratio can be as low as 10 maternal deaths per 100,000 live births while among the least developed countries it can be as a high as 1,000 maternal deaths or more per 100,000 live births.(4) This disparity is also observed within countries and when the population is disaggregated in quintiles of income or education.(5-7) Thus, countries, regions within countries and different population groups within country experience a specific momentum in a dynamic process of reduction of maternal mortality, which may benefit from specific approaches.\n\nIn 1929, Thompson described the phenomenon of demographic transition characterized by a gradual shift from a pattern of high mortality and high fertility to a pattern of low mortality and low fertility.(8) Omram (1971) described the epidemiologic transition, with a shift from a pattern of high prevalence of communicable diseases to a pattern of high prevalence of non-communicable diseases.(9) Finally, Poppkin (1993) proposed the nutritional transition model, which helps to understand the transformations in human diets and the global epidemic of obesity.(10) These transitions and other socioeconomic and cultural changes (e.g. globalization, urbanization) led us to develop the concept of “obstetric transition” (11).\n\nAs a result of the Millennium Development Goals Project, improved data related to maternal mortality and severe maternal morbidity became available for the period between 1990 and 2010. Altogether, these data reflect a secular trend where countries are gradually shifting from a pattern of high maternal mortality to low maternal mortality, from direct obstetric causes of maternal mortality to indirect causes, moving from the natural history of pregnancy and childbirth to institutionalization of maternity care, medicalization and over medicalization, and aging of maternal population. This is the “obstetric transition” phenomenon, which has implications for the strategies aimed at reducing maternal mortality.\n\nFigure 1 presents trends of maternal mortality by world region for the period 1990 to 2010 derived from recent estimates (2). Considering that countries and world regions are transitioning in the same pathway towards elimination of maternal deaths, five stages can be devised. It should be noted that countries are experiencing this transition at different paces, and have started this process in different moments of their history (e.g. most developed countries started their transitions more than a century ago, while some developing countries have started their transition much more recently).\n\nIn the Stage I (MMR> 1,000 / 100,000) most women are experiencing a situation close to the natural history of pregnancy and childbirth, with very little being done – if anything at all – to reduce the risk of maternal mortality at the population level. Considering 2010 data, Chad and Somalia are countries that could illustrate this stage. Hopefully, as time passes (and progress occurs), no country will remain in this stage. Stage I is characterized by very high maternal mortality, high fertility and the predominance of direct causes of maternal deaths together with a substantial proportion of deaths attributable to communicable diseases such as malaria. \n\nIn the Stage II (MMR: 999 – 300) mortality and fertility remain very high, with a similar pattern of causes as compared to the Stage I. However, a greater proportion of women in the population are being able to somewhat detach from the natural history of pregnancy and childbirth. Several countries in the Sub-Saharan Africa could illustrate the Stage II. For Stages I and II, the main issue is access to care. In general, these are countries with a substantial lack of basic infrastructure (such as roads, transportation, health facilities), very low education levels (particularly female literacy), weak health systems, severe shortages of skilled birth attendants and low capacity to deliver essential life-saving interventions. In this context, poor quality of care functions as deterrent for generating demand for health services. In countries in these stages, focus should be directed to creating the basic infra-structure and implement maternal-mortality primary prevention measures (e.g. family planning, iron supplementation, insecticide treated nets, intersectorial measures to remove barriers to access the health system). As the minimal infra-structure is created, health services should strive to deliver quality care in order to become a sensible alternative to pregnant women (demand generation). (21)\n\nIn the obstetric transition, the tipping point occurs in the Stage III. In this stage the mortality is still high (MMR 299 – 100 maternal deaths / 100,000 live births), the fertility is variable and direct causes of mortality still predominates. This is a complex stage because access remain an issue for a great deal of the population, but as a large proportion of pregnant women are indeed reaching health facilities, quality of care becomes a major determinant of health outcomes. Not only primary prevention is important, but also secondary and tertiary prevention are critical for improving maternal health outcomes in this stage. In other words, quality of care, with skilled birth attendance and appropriate management of complications and disabilities, is essential to reduce maternal mortality. India, Guatemala and South Africa are countries that could illustrate this stage.\n\nIn the Stage IV (MMR <50 maternal deaths / 100,000 live births), the maternal mortality is moderate or low, there is low fertility and the indirect causes of maternal mortality, particularly the non-communicable diseases, acquire greater importance. In order to further advance the reduction of maternal mortality, the main issue becomes quality of care and elimination of delays within health systems. Another aspect that emerges in this stage is the growing role of over medicalization as a threat to quality and improved health outcomes. Various Asian countries and most Latin American countries have joined developed countries in this stage. \nIn the Stage V, all avoidable maternal deaths are indeed avoided. The maternal mortality rate is very low, the fertility is low or very low, and the non-communicable diseases are the main causes of maternal mortality. As this is an aspirational, largely theoretical stage at the moment, the maternal mortality levels remain uncertain, but could be lower than 5 maternal deaths per 100,000 live births. The main issue in this stage would be the sustainability of excellence in quality of care.\n\nIt is worth noting that the main purpose of this framework is to illustrate different phases of a dynamic process and offer a rational for different focus and solutions for reducing mortality according to the stage in the obstetric transition. The ranges of maternal mortality ratio uses to define the proposed stages of obstetric transition are frequently in country stratification, (2, 16) but the boundaries between these stages are somewhat imprecise and one stage tends to fade into another. Progression is not always linear and, largely due to equity issues, different stages often co-exist in the same country.\n\n"}
{"id": "1957138", "url": "https://en.wikipedia.org/wiki?curid=1957138", "title": "Our Bodies, Ourselves", "text": "Our Bodies, Ourselves\n\nOur Bodies, Ourselves is a book about women's health and sexuality produced by the nonprofit organization Our Bodies Ourselves (originally called the Boston Women's Health Book Collective). First published in the late 1960s, it contains information related to many aspects of women's health and sexuality, including: sexual health, sexual orientation, gender identity, birth control, abortion, pregnancy and childbirth, violence and abuse, and the menopause. The most recent edition of the book was published in 2011. The book was revolutionary in that it encouraged women to celebrate their sexuality, including chapters on reproductive rights, lesbian sexuality, and sexual independence. The move towards women’s active engagement with their actual sexual desires was contradicting the popular gendered myth of “women as docile, and passive,” and “men as active and aggressive” in a sexual relationship.\n\nThe book has been translated and adapted by women's groups around the world and is available in 29 languages. Sales for all the books exceed four million copies. The \"New York Times\" has called the seminal book \"America's best-selling book on all aspects of women's health\" and a \"feminist classic\".\n\nThe health seminar that inspired the booklet was organized in 1969 by Nancy Miriam Hawley at Boston's Emmanuel College. \"We weren't encouraged to ask questions, but to depend on the so-called experts,\" Hawley told \"Women's eNews\". \"Not having a say in our own health care frustrated and angered us. We didn't have the information we needed, so we decided to find it on our own.\" As a result of this goal, the book contained information intended to guide women on \"how to maneuver the American health care system, with subsections called 'The Power and Role of Male Doctors,' 'The Profit Motive in Health Care,'\" 'Women as Health Care Workers,' and 'Hospitals.'\n\nThe original writers of the book stated four main reasons for creating it. First, that personal experiences provide a valuable way to understand one's own body beyond the mere facts that experts can provide, creating an empowering learning experience. Second, this kind of learning meant that they were \"better prepared to evaluate that institutions that are supposed to meet our health needs . . .\". Third, the historical lack of self-knowledge about the female body \"had had one major consequence - pregnancy\" and through greater information, women will have more ability to make proactive choices about when to get pregnant. Fourth, information about one's body is perhaps the most essential kind of education, because \"bodies are the physical bases from which we move out into the world\". Without this basic information, women are alienated from their own body and necessarily on unequal footing with men.\n\nThe women researched and wrote up the information themselves. Wendy Sanford wrote about abortion, Jane Pincus and Ruth Bell about pregnancy, and Paula Doress and Esther Rome about postpartum depression. The 12 feminists then published their research as a 35-cent, 136-page booklet called \"Women and Their Bodies\", published in 1970 by the New England Free Press. The booklet sold 250,000 copies in New England without any formal advertising.\n\nAs a result of their success, the women formed the non-profit Boston Women's Health Book Collective (which now goes by the name Our Bodies Ourselves) and published the first 276-page \"Our Bodies, Ourselves\" in 1973. The collective published it with the major publisher Simon & Schuster only on the condition that they would have complete editorial control and that nonprofit health centers could purchase copies at a significant discount. It featured first-person stories from women, and tackled many topics then regarded as taboo. Since then, over four million copies have been sold.\n\nIn 2018, the group announced that due to financial pressures, it would no longer publish new print editions nor have experts update its web site with new health information.\n\nThe Boston Women's Health Book Collective, also known as the Our Bodies, Ourselves Collective, is a feminist group that created \"Our Bodies, Ourselves\". The collective formed at the peak of the women's movement in Boston.\n\nTwelve women all between the ages of 23 to 39 first attended a workshop entitled \"Women and Their Bodies\" which allowed the women to discuss together the issues they had surrounding their health. The discussion created a consciousness-raising environment, providing each woman with information that they all deal with when handling issues about their bodies. The strong discussion supplied the women with the necessary tools and ideas that lead to the creation of their book that addressed issues surrounding sexuality and abortion. They put their knowledge into an accessible format that served as a model for women who wanted to learn about themselves, communicate with doctors, and challenge the medical establishment to change and improve the health of women everywhere.\n\nReproductive justice was at the forefront during the women's liberation, causing much debate over the biological rights of women. The Equal Rights Amendment had a section specifically targeting the important issues about Reproductive justice that combines multiple reproductive rights and issues surrounding family. The strategy of the reproductive justice plank was to establish the necessary rights and access for women to gain control over their bodies. Through the passing of this legislation woman would be granted the ability to have abortions, obtain access to birth control and gain full control over their bodies. \n\nThe Boston Collective focused on these ideas to allow women the ability to understand their bodies and themselves as women. During the National Women's Conference, women from all over the country deliberated to determine the exact laws that should be put into place for women's reproductive justice. The Boston Collective work together to teach courses and create books that provide knowledge from women not only in Boston, but women across the nation. These women use their skills and knowledge to provide many women with knowledge about their lives through rhetoric that avoids describing the female reproductive system as passive, unproductive, helpless, or powerless.\n\nThe organization has also created two single-topic books. \"Our Bodies, Ourselves: Menopause\" was published in 2006, and \"Our Bodies, Ourselves: Pregnancy and Birth\" in 2008. The Boston Women's Health Book Collective earlier produced \"Changing Bodies, Changing Lives: A Book For Teens on Sex and Relationships\" and \"The New Ourselves, Growing Older: Women Aging with Knowledge and Power\".\n\nThe first book was a product of the feminist movement and could still be said to reflect its values. The personal experiences of women are taken into account and are quoted throughout, while the social and political context of women's health informs the content of the book. The book emphasizes empowerment through information and learning, specifically, information gained through women sharing their personal narratives with each other because \"by sharing our responses we can develop a base on which to be critical of what the experts tell us.\"\n\nTopics such as male-to-female and female-to-male transsexualism/transgenderism are discussed in the most recent edition and considered in a nonjudgmental manner, despite the controversy to which they have been subject within the feminist movement. The writing style of the book tends toward a familiar, inclusive tone, with the authors referring to women and themselves as a collective group.\n\nThe collective of women who initiated \"Our Bodies, Ourselves\" are part of the documentary \"She's Beautiful When She's Angry\", about the founders of the modern women's movement from 1966 to 1971.\n\n\n"}
{"id": "43846467", "url": "https://en.wikipedia.org/wiki?curid=43846467", "title": "Partnership for Maternal, Newborn &amp; Child Health", "text": "Partnership for Maternal, Newborn &amp; Child Health\n\nThe Partnership for Maternal, Newborn & Child Health (PMNCH) is a multi-constituency partnership hosted by the World Health Organization and chaired by Graça Machel. PMNCH seeks to achieve universal access to comprehensive, high-quality reproductive, maternal, newborn and child health care. PMNCH works with more than 650 members in the reproductive, maternal, newborn and child health (RMNCH) communities across seven constituencies:\n\n\nPMNCH describes itself as \"a platform for knowledge, advocacy and accountability to improve women and children’s health\". The Partnership is governed by a Board chaired by Graça Machel.\n\nThe Partnership plays a central role in facilitating joint action on many fronts, mainly progress towards the United Nations Millennium Development Goals (MDGs) 4 and 5, to\nreduce child mortality and improve maternal health, as tracked by the Countdown to 2015\ninitiative, and through support for the Global Strategy for Women’s and Children’s Health (Global Strategy) and Every Woman Every Child. PMNCH enables members to share\nstrategies, align objectives and resources, and collectively agree on policy interventions.\n\nPMNCH’s work and support to partners is focused on three key Strategic Objectives: \n\nThe Partnership issues annual reports on progress of commitments from more than 250 stakeholders and estimates that the Global Strategy has leveraged over US$18 billion in new and additional money for women’s and children’s health.\n\nPMNCH was launched in September 2005 when the world’s three leading maternal, newborn and child health alliances joined forces under the new name of The Partnership for Maternal, Newborn & Child Health. 80 original members joined together from the three organizations, which included: the Partnership for Safe Motherhood and Newborn Health, hosted by the World Health Organization in Geneva; the Healthy Newborn Partnership, based at Save the Children USA; and the Child Survival Partnership, hosted by UNICEF in New York. All three partnerships focused on accelerating action by countries—both donor and\ndeveloping countries—to achieve Millennium Development Goals (MDGs) 4 (reduce child\nmortality) and 5 (improve maternal health).\n\nAs of July 2014, the following bodies are represented on the PMNCH Board. The Board is chaired by Mrs Graça Machel and co-chaired by Mr CK Mishra, Government of India and Dr Flavia Bustreo, the World Health Organization.\n\n\n\n\n\n\n\n\n\n"}
{"id": "39337624", "url": "https://en.wikipedia.org/wiki?curid=39337624", "title": "Pediatric gastroenterology", "text": "Pediatric gastroenterology\n\nPediatric gastroenterology developed as a sub-specialty of pediatrics and gastroenterology. It is concerned with treating the gastrointestinal tract, liver and pancreas of children from infancy until age eighteen. The principal diseases it is concerned with are acute diarrhea, persistent vomiting, gastritis, and problems with the development of the gastric tract.\n\nPediatric gastroenterology has grown greatly in North America and Europe. It began with the speciality of pediatrics, which was developed along with children’s hospitals in the 19th century. The concept of specialists concentrating on organ specific specialties started around the same time. A person who contributed to the development of the specialty was Dr. Samuel Gee in London with his focus on serious clinical conditions in children such as celiac disease and cyclic vomiting syndrome. The first national gastrointestinal society was created in Germany in 1920 by Ismar Isidor Boas. He was also the first physician devoted completely to only gastroenterology. Later the American Gastroenterological Association was founded in 1897 by Dr. D. Stewart. The combination to make a pediatric gastroenterological a specialty emerged in the 1960s, almost a century after the specialties of pediatrics and gastroenterology started out individually. All pediatric specialties started out with the concept that children with special needs were not receiving the adequate medical attention that they needed.\n\nMargot Shiner, who in 1956 invented a biopsy tube that could be used to diagnose intestinal disease in children, particularly celiac disease, has been credited with initiating the emergence of pediatric gastroenterology as a distinct clinical specialty.\n\nCenters for gastrointestinal disorders in children began being established in the 1960s in Great Britain, Australia, and continental Europe. The first centers for pediatric gastroenterology were established by Dolf Weijers and the biochemist Van de Kamer. Pediatricians and biochemists were crucial to the development of such specialty since they created the ability to calculate the fat in the feces of celiac patients with or without gluten. A clinical and research program in pediatric gastroenterology and a gastroenterological research were established in the 1960s at the Royal Children’s Hospital in Melbourne by Charlotte Anderson. Later on an important center focused on nutrition and gut pathophysiology was established by Bertil Linquist in Lund, Sweden. This was the first place in which glucose-galactose malabsorption was reported. Pediatric gastroenterology centers in London contributed greatly to this field and hepatology by helping and recognizing multiple doctors with their investigations. An example is Tom Macdonald, who concentrated his immunological research on gastroenterological diseases in children and the use of a fetal intestinal organ culture model. Important pediatric gastroenterology centers were also established in Helsinki and Tampere, Finland. These centers, led by Jamro Visakorpi, primarily focused on celiac disease, gastroenteritis¸ and food allergies. Other important centers were established in Switzerland, under the leadership of Andrea Prader making Zurich one of the first main centers for pediatric gastroenterology. In that same center, David Shmerling started studying gluten elimination and celiac disease. Salvatore Auricchio along with Giorgio Semenza began comprehending and identifying sugar absorption disorders in children. Ettore Rossi in Berne founded centers in which Beat Hadorn and Michael Kentze, who later went on to establish German centers in Munich and Bonn, which made great contributions in the research of absorption pathophysiology. After working in Zurich, Salvatore Auricchio went on to establish an important center in Naples which focused research on celiac disease, the physiology of absorption, and oral re hydration therapy. In a center located in Brussels, led by E. Eggermont and Helmuth Loeb, Samy Cadranel started developing the concept of endoscopy in children.\n\nNorth America has also been a center for the development of pediatric gastroenterology. A pediatric gastroenterology program focusing on researching inflammatory bowel disease, infectious diarrhea, and motility disorders associated with gastrointestinal complications such as constipation and gastro esophageal reflux was established by Murray Davidson at the Albert Einstein Medical School and the Bronx-Lebanon Hospital Center in New York. Harry Shwachman created the center of excellence for pediatric gastroenterology in Boston in the early 1960s. This center, under the leadership of Richard Grand and Allan Walker, went on to become a major training program for pediatric gastroenterologists. In order to commemorate Dr. Shwaschman and his impact to the field, a Scwaschman Award is given annually since 1984 by the North American Society for Pediatric Gastroenterology and Nutrition to a person with important contributions to the field. In Canada, gastroenterology and hepatology surged independently from nutrition at the Hospital for Sick Children (HSC) in Toronto. Peter Durie combined the nutrition and gastroenterology research at the HSC in 1985.\n\nMany more centers have been developed in multiple places including Sydney, Adelaide, Brisbane, Jerusalem, São Paulo, Santiago, Taipei, and Tokyo.\n\nThe specialty of pediatric gastroenterology requires four years of undergraduate courses at a college or university in order to obtain a BS, BA, or other bachelor's degree. During these four years a student studying pediatric gastroenterology can also take a pre-med course. Afterwards, the student needs four years of medical school in order to obtain an MD or DO degree and become a general doctor. Afterwards the student needs to take a specialty in pediatrics consisting in three more years of education called residency. Afterwards pediatrics sub-specialize in a more specific area such as pediatric gastroenterology. The time to sub-specialize is called post-residency training also known as a fellowship. It can take from one to three or more years consisting in a total of fourteen years or more. In the United States, the committees to certify pediatric gastroenterologist were created in the 1980s. This gave rise to sub-specialty boards in pediatric gastroenterology in 1990 under the leadership of American board of Pediatrics and its Pediatric Gastroenterology and Nutrition subspecialty sub-board, led by Bill Kish. A formal training program was created later in 1997 by the sub-specialty advisory committee for pediatric gastroenterology of the royal college of pediatrics and child health in Great Britain.\nThe correct function of the gastric tract and the internal health is related to the nutrition that the child or its mother receives. From the prenatal period, correct nutrition can affect the developing of the system, short bowel syndrome (the most common one), necrotizing enterocolitis, gastroschisis or omphalocele to the postnatal period with diseases such as diarrhea.\n\nOne of the principal problems of a newborn is an iron deficiency, which will generate anemia. This is caused when the only food that the baby receives is maternal milk which does not fulfill the baby’s nutrition. There is no treatment for this in this period because iron will reach normal levels with the weaning process. The weaning process consists in transitioning from feeding the baby low density food such as maternal milk to start feeding it more complex foods such as meat, fish, or chicken. (uniped) If the weaning process is not carried out correctly or if the child rejects the transition of food the iron deficiency will generate an anemia or even create allergies to certain food. In such cases gastric pediatricians, and not regular pediatricians, should be consulted to treat the anemia because they will now how to recover the correct iron levels without causing any secondary effects in the digestive system.\n\nThe most common nutrition problems during the childhood are being overweight or underweight, both caused by an imbalance in the number of caloried consumed versus the number burned. Both in children should be treated by a gastric pediatrician and a pediatric nutritionist at the same time to help the child recover his normal weight without secondary effects (hypertension, gastritis, etc.). The nutritionist will regulate the eating habits of the child, however, the pediatric gastroenterologist will be the one checking how the change in food habits affects the correct functionality of the digestive system.\n\nA pediatrician can provide treatment to many gastric diseases, but chronic diseases, related with the nutrition of the children, the pancreas or the liver needs to be treated by a specialist. The following are two of the most common ones. Acute diarrhea is one of the most common. Globally, each of the 140 million children born annually experience an average of 7-30 episodes of diarrhea in the first 5 years of life. Some of the causes are infections, lower levels of zinc or problems with some gastric cells.\n\nInfant regurgitation is caused by a central nervous system reflex involving both autonomic and skeletal muscles in which gastric contents are forcefully expelled through the mouth because of coordinated movements of the small bowel, stomach, esophagus, and diaphragm. Diagnosis requires that the child be between 1 and 12, the regurgitation must be two or more times per day for three or more weeks, and there is a strong involuntary effort to vomit, hematemesis, aspiration, apnea, failure to thrive, or abnormal posturing. This is transient problem, possibly cause to the immaturity of gastrointestinal motility.\n"}
{"id": "8030036", "url": "https://en.wikipedia.org/wiki?curid=8030036", "title": "Primitive reflexes", "text": "Primitive reflexes\n\nPrimitive reflexes are reflex actions originating in the central nervous system that are exhibited by normal infants, but not neurologically intact adults, in response to particular stimuli. These reflexes are suppressed by the development of the frontal lobes as a child transitions normally into child development. These primitive reflexes are also called infantile, infant or newborn reflexes.\n\nOlder children and adults with atypical neurology (e.g., people with cerebral palsy) may retain these reflexes and primitive reflexes may reappear in adults. Reappearance may be attributed to certain neurological conditions including dementia (especially in a rare set of diseases called frontotemporal degenerations), traumatic lesions, and strokes. An individual with cerebral palsy and typical intelligence can learn to suppress these reflexes, but the reflex might resurface under certain conditions (i.e., during extreme startle reaction). Reflexes may also be limited to those areas affected by the atypical neurology, (i.e., individuals with cerebral palsy that only affects their legs retaining the Babinski reflex but having normal speech); for those individuals with hemiplegia, the reflex may be seen in the foot on the affected side only.\n\nPrimitive reflexes are primarily tested with suspected brain injury or some dementias such as Parkinson's disease for the purpose of assessing frontal lobe functioning. If they are not being suppressed properly they are called frontal release signs. Atypical primitive reflexes are also being researched as potential early warning signs of autistic spectrum disorders.\n\nPrimitive reflexes are mediated by extrapyramidal functions, many of which are already present at birth. They are lost as the pyramidal tracts gain functionality with progressive myelination. They may reappear in adults or children with loss of function of the pyramidal system due to a variety of reasons. However, with the advent of \"Amiel Tison method of neurological assessment\", the importance of assessment of such reflexes in the pediatric population has come down.\n\nReflexes vary in utility. Some reflexes hold a survival value (e.g., the rooting reflex, which helps a breastfed infant find the mother's nipple). Babies display the rooting reflex only when they are hungry and touched by another person, not when they touch themselves. There are a few reflexes that likely assisted in the survival of babies during human evolutionary past (e.g., the Moro reflex). Other reflexes such as sucking and grabbing help establish gratifying interaction between parents and infants. They can encourage a parent to respond with love and affection, and to feed their child more competently. In addition, it helps parents to comfort their infant while allowing the baby to control distress and the amount of stimulation they receive.\n\nThe sucking reflex is common to all mammals and is present at birth. It is linked with the rooting reflex and breastfeeding. It causes the child to instinctively suck anything that touches the roof of their mouth, and simulates the way a child naturally eats. There are two stages of the action:\n\nThe rooting reflex is present at birth (age of appearance 28 weeks) and disappears around four months of age, as it gradually comes under voluntary control. The rooting reflex assists in the act of breastfeeding. A newborn infant will turn its head toward anything that strokes its cheek or mouth, searching for the object by moving its head in steadily decreasing arcs until the object is found. After becoming familiar to responding in this way (if breastfed, approximately three weeks after birth), the infant will move directly to the object without searching.\n\nThis is sometimes referred to as the startle reaction, startle response, startle reflex or embrace reflex. It is more commonly known as the Moro response or Moro reflex after its discoverer, pediatrician Ernst Moro. The Moro reflex is present at birth, peaks in the first month of life, and begins to integrate around 2 months of age. It is likely to occur if the infant's head suddenly shifts position, the temperature changes abruptly, or they are startled by a sudden noise. The legs and head extend while the arms jerk up and out with the palms up and thumbs flexed. Shortly afterward the arms are brought together and the hands clench into fists, and the infant cries loudly. The reflex normally integrates by three to four months of age, though it may last up to six months. Bilateral absence of the reflex may be linked to damage to the infant's central nervous system, while a unilateral absence could mean an injury due to birth trauma (e.g., a fractured clavicle or injury to the brachial plexus). Erb's palsy or some other form of paralysis is also sometimes present in such cases. In human evolutionary history, the Moro reflex may have helped infants cling to the mother while being carried around. If the infant lost its balance, the reflex caused the infant to embrace its mother and regain its hold on the mother's body.\n\nThe walking or stepping reflex is present at birth, though infants this young cannot support their own weight. When the soles of their feet touch a flat surface they will attempt to walk by placing one foot in front of the other. This reflex integrates around 5–6 months as infants start attempting to walk after this reflex disappears.\n\nThe asymmetrical tonic neck reflex, also known as 'fencing posture', is present at one month of age and integrates at around four months. When the child's head is turned to the side, the arm on that side will straighten and the opposite arm will bend (sometimes the motion will be very subtle or slight). If the infant is unable to move out of this position or the reflex continues to be triggered past six months of age, the child may have a disorder of the upper motor neurons. According to researchers, the tonic neck reflex is a precursor to the hand/eye coordination of the infant. It also prepares the infant for voluntary reaching.\n\nThe symmetric tonic neck reflex normally appears and develops around 6–9 months of age and should integrate by around 12 months. When the child's head flexes forward, extending the back of the neck, the upper extremities will contract and the lower extremities will extend. Conversely, when the child's head is extended backward, contracting the back of the neck, the upper extremities will extend and the lower extremities will contract. This reflex is important to help a child push up onto their hands and knees, but may inhibit actual forward creeping or crawling if it is not properly integrated. If this reflex is retained beyond 2–3 years, it may result, directly or indirectly, in a range of physical and neurological developmental delays.\n\nThe tonic labyrinthine reflex is a primitive reflex found in newborn humans. With this reflex, tilting the head back while lying on the back causes the back to stiffen and even arch backwards, the legs to straighten, stiffen, and push together, the toes to point, the arms to bend at the elbows and wrists, and the hands to become fisted or the fingers to curl. The presence of this reflex beyond the newborn stage is also referred to as abnormal extension pattern or extensor tone.\n\nThe presence of the TLR as well as other primitive reflexes such as the asymmetrical tonic neck reflex (ATNR) beyond the first six months of life may indicate that the child has developmental delays and/or neurological abnormalities. For example, in people with cerebral palsy, the reflexes may persist and even be more pronounced. As abnormal reflexes, both the tonic labyrinthine reflex and the asymmetrical tonic neck reflex can cause problems for the growing child. The TLR and ATNR both hinder functional activities such as rolling, bringing the hands together, or even bringing the hands to the mouth. Over time, both the TLR and ATNR can cause serious damage to the growing child's joints and bones, causing the head of the femur to partially slip out of the acetabulum (subluxation) or completely move out of the acetabulum (dislocation).\n\nThe palmar grasp reflex appears at birth and persists until five or six months of age. When an object is placed in the infant's hand and strokes their palm, the fingers will close and they will grasp it with a palmar grasp. To best observe this reflex, on a bed where the child could safely fall onto a pillow, offer the infant two opposing little fingers (as index fingers are typically too large for the infant to grasp), and gradually lift. The grasp of it may be able to support the child's weight, they may also release their grip suddenly and without warning. The reverse motion can be induced by stroking the back or side of the hand.\n\nA plantar reflex is a normal reflex that involves plantar flexion of the foot, which moves toes away from the shin and curls them down. An abnormal plantar reflex (aka Babinski Sign) occurs when upper motor neuron control over the flexion reflex circuit is interrupted. This results in a dorsiflexion of the foot (foot angles towards the shin, big toe curls up). This also occurs in babies under c. 1 year, because of low myelination of the corticospinal tracts. As these tracts develop to adult form, the flexion-reflex circuit is inhibited by the descending corticospinal inputs, and the normal plantar reflex develops. Also known as the Babinski reflex, this is a sign of neurological abnormality in adults (e.g., upper motor neuron lesion).\n\nThe Galant reflex, also known as \"Galant's infantile reflex\", is present at birth and fades between the ages of four to six months. When the skin along the side of an infant's back is stroked, the infant will swing towards the side that was stroked. If the reflex persists past six months of age, it is a sign of pathology. The reflex is named after the Russian neurologist Johann Susman Galant.\n\nThe swimming reflex involves placing an infant face down in a pool of water. The infant will begin to paddle and kick in a swimming motion. The reflex disappears between 4–6 months. Despite the infant displaying a normal response by paddling and kicking, placing them in water can be a very risky procedure. Infants can swallow a large amount of water while performing this task, therefore caregivers should proceed with caution. It is advisable to postpone swimming lessons for infants until they are at least three months old, because infants submerged in water can die from water intoxication.\n\nThe Babkin reflex occurs in newborn babies, and describes varying responses to the application of pressure to both palms. Infants may display head flexion, head rotation, opening of the mouth, or a combination of these responses. Smaller, premature infants are more susceptible to the reflex, with an observed occurrence in a child of 26 weeks gestation. It is named after the Russian physiologist, Boris Babkin.\n\nThis reflex occurs in slightly older infants when the child is held upright and the baby’s body is rotated quickly to face forward (as in falling). The baby will extend their arms forward as if to break a fall, even though this reflex appears long before the baby walks.\n\nReflexes that aren't suppressed in infancy are referred to as unintegrated or persistent reflexes. When they persist, they are related to academic struggles. For example, children with learning difficulties have been found to exhibit persistent primitive reflexes. In addition, a persistent ATNR has been found to be associated with lower reading and spelling scores, and children with reading problems tend to display the Tonic labyrinthine reflex more than children without reading problems. Lastly, a relationship has been found between ADHD symptoms and ATNR persistence and another between ADHD diagnosis and Moro and Galant reflex persistence. \n\nAs mentioned in the introduction, when primitive reflexes are not being suppressed properly they are generally referred to as frontal release signs (although this may be a misnomer). In addition to the reflexes previously mentioned, they include the palmomental reflex, snout reflex, glabellar reflex or \"tap\" reflex.\n\nThe term \"high-risk newborns\" refers to neonates with a significant chance of mortality or morbidity, especially within the first month of being born. High-risk newborns will often show abnormal responses of primitive reflexes, or lack a response entirely. Performance of primitive reflexes in high-risk newborns will often vary in response depending on the reflex (e.g., normal Moro reflex may be present, while the walking reflex is absent or abnormal). Normal performance of primitive reflexes in newborns can be linked to a greater likelihood of having higher Apgar scores, higher birth weight, shorter hospitalization time after birth, and a better overall mental state.\n\nA recent cross-sectional study assessing primitive reflexes in 67 high-risk newborns, used a sample method to evaluate responses of the sucking, Babinski and Moro reflexes. The results of the study showed that the sucking reflex was performed normally most often (63.5%), followed by the Babinski reflex (58.7%), and the Moro reflex (42.9%). The study concluded that high-risk newborns presented more periodic abnormal and absent responses of primitive reflexes, and that each reflex varied in response.\n\nHowever, with the advent of simple and effective methods like the \"Amiel Tison method of neurological assessment\", as predictor of neurological sequele in high-risk neonates and infants, the importance of assessment of primitive reflexes is decreasing.\n\n"}
{"id": "39185670", "url": "https://en.wikipedia.org/wiki?curid=39185670", "title": "Ramón Rosa Rodríguez", "text": "Ramón Rosa Rodríguez\n\nGeneral Ramón Rosa Rodríguez (? – 10 October 1994) was a Paraguayan military officer. He was the head of Paraguay's national anti-drugs agency, Secretaría Nacional Antidrogas (SENAD), and was delivering a report to President Juan Carlos Wasmosy when he was assassinated. One of the soldiers escorting him, Captain Juan Emiliano Ruiz Díaz, was convicted of his murder in 1997. Rosa Rodríguez' suitcase was stolen in the attack, later re-appearing with most of its contents missing. The missing report is said to have implicated ex-President Andrés Rodríguez, then a Senator, as \"the chief drug kingpin in Paraguay\".\n"}
{"id": "3092610", "url": "https://en.wikipedia.org/wiki?curid=3092610", "title": "Robert Kpoto", "text": "Robert Kpoto\n\nRobert Kpoto is a Liberian orthopedic surgeon, politician, and member of the Union of Liberian Democrats (ULD). \n\nRunning as the ULD presidential candidate in the 11 October 2005 elections, Kpoto placed 19th out of 22 candidates, receiving 0.4% of the vote.\n\nIn 1990 during Liberia's civil war, Kpoto was Liberia's chief medical officer and told a reporter that he was concerned about the threat of typhoid and cholera. He worked 12-hour days operating on people with gunshot wounds or throats that had been cut.\n\nIn 2009, Kpoto was flown to Ghana for treatment after he and some other people were involved in an automobile accident that claimed at least one life.\n"}
{"id": "21615074", "url": "https://en.wikipedia.org/wiki?curid=21615074", "title": "Robert Reynolds Macintosh", "text": "Robert Reynolds Macintosh\n\nSir Robert Reynolds Macintosh (17 October 1897, Timaru, New Zealand – 28 August 1989, Oxford, England) was a New Zealand-born anaesthetist. He was the first professor of anaesthetics outside the United States.\n\nMacintosh was baptised with the Maori name Rewi Rawhiti. He was the youngest son of Charles Nicholson Macintosh, newspaper editor and mayor of Timaru in 1901, and his wife, Lydia Beatrice Thompson. He spent part of his childhood in Argentina, but returned to New Zealand when he was thirteen years old. He was educated at Waitaki Boys' High School, where he was head of school and excelled academically and athletically.\n\nIn December 1915, he travelled to Britain and was commissioned in the Royal Scots Fusiliers, soon transferring to the Royal Flying Corps. He was shot down behind enemy lines on 26 May 1917 and taken prisoner, escaping several times.\n\nAfter the war, Macintosh trained at Guys Hospital Medical School, qualifying MRCS LRCP in 1924 and FRCS Ed in 1927. While studying surgery, he earned a living by giving dental anaesthetics and developed an interest in anaesthetics.\n\nIn 1936, the University of Oxford approached Lord Nuffield to consider endowing three chairs in medicine, surgery, and obstetrics and gynaecology. Nuffield, who had received an anaesthetic from Macintosh, agreed, but against the university's wishes, insisted on the addition of a chair in anaesthetics, to be held by Macintosh. They could not ignore the £2 million on offer and Macintosh took up his appointment in February 1937, the first professor of anaesthetics outside America.\n\nIn the Second World War, Macintosh held the rank of Air Commodore and trained anaesthetists for the armed services. His research included hazardous experiments to test life jackets (immersing E A Pask in a wave tank while anaesthetised), the provision of respirable atmospheres in submarines and survival during parachute descent from high altitudes.\n\nMacintosh designed equipment that now bears his name: a laryngoscope, an anaesthetic vaporiser, spray and endobronchial tube. The laryngoscope he designed in 1941 remains the most-used today. It was developed from a Boyle-Davis mouth gag, used for tonsillectomy. Macintosh noted that this mouth gag indirectly elevated the epiglottis and exposed the laryngeal aperture.\n\nMacintosh studied unexplained deaths that occurred under anaesthesia and established a training programme. He travelled widely, giving demonstrations of \"safe and simple\" anaesthesia.\n\nMacintosh married Dorothy Manning, whose sister Mary, was married to Archie Forbes.\n\nMacintosh was knighted in 1955, and received many honorary doctorates and fellowships.\n\n"}
{"id": "20771351", "url": "https://en.wikipedia.org/wiki?curid=20771351", "title": "Rodolfo Robles", "text": "Rodolfo Robles\n\nRodolfo Robles (1878–1939) was a Guatemalan physician and philanthropist. He was the first to describe onchocerciasis.\n\nRodolfo Robles was born in Quetzaltenango, Guatemala. He studied at the Sorbonne, and Columbia University in New York. He performed research at the Pasteur Institute in Paris, where he obtained the Ordre national de la Légion d'honneur (French: \"National Order of the Legion of Honour\") in the degree of \"Grand Officier\" (Grand Officer).\n\nRobles married Julia Isabel Herrera Dorión, and had one child, Rodolfo Robles Herrera, born in Paris in 1928. \n\nRobles has been honored in Guatemala and México with many schools and hospitals named in his honor. The highest medical honor in Guatemala bears his name.\n"}
{"id": "13914029", "url": "https://en.wikipedia.org/wiki?curid=13914029", "title": "Scores on the doors", "text": "Scores on the doors\n\nA term probably originating in widespread public use with the TV Show The Generation Game in regards to the points scored by contestants, Scores on the doors is also now a term for publication or display of food hygiene or food safety inspection results of food businesses. Regulatory inspection results are published as either an inspection and compliance summary or, elsewhere, a grade or score is all that is published.\n\nOn 1 January 2005 the UK Freedom of Information Act and Environmental Information Regulations came into effect and local councils slowly began to publish the information on the Internet and via certificates. However there was no uniform grading system and many councils chose their own schemes, thus making comparison difficult. On 10 December 2008 the Food Standards Agency (FSA) board decided to approve a 6-tier scheme called the Food Hygiene Rating Scheme (FHRS) for England, Wales and Northern Ireland and a 2-tier (Pass/Improvement required) Food Hygiene Information Scheme (FHIS) for Scotland.\n\nFrom November 2013 it became compulsory for food businesses in Wales to display stickers, with similar legislation coming into force in Northern Ireland from October 2016. FSA is compiling evidence to commence introducing legislation for compulsory display of stickers in England.\n\nThe official UK government ratings website includes ratings for all UK regions and is mobile device friendly, although no app is provided. The FSA data is publicly available for download \n\nOther commercial websites and smartphone apps are also available, together with reporting and analysis software to enable businesses to performance manage their compliance and compare with their competitors.\n\nIn Australia, where national food safety standards are brought into force by state government statutes and enforced at the state or local level, the New South Wales Food Authority commenced a pilot program with local governments in 2010 utilising A, B and C letter grades. This was expanded to a trial in participating local government areas in 2011 utilising an equivalent system of star ratings (5 stars, 4 stars, 3 stars) and an accompanying interpretive grade (Excellent, Very Good or Good) to reflect the degree of compliance with minimum food safety standards. In late 2013 the program was enhanced to encourage further take-up.\n\nParticipation in the program is voluntary.\n"}
{"id": "25673677", "url": "https://en.wikipedia.org/wiki?curid=25673677", "title": "Second Green Revolution", "text": "Second Green Revolution\n\nThe Second Green Revolution is a change in agricultural production widely thought necessary to feed and sustain the growing population on Earth\nThese calls have precipitated in part, as a response to rising food commodity prices, and fears of peak oil among other factors.\n\nIt is named after the Green Revolution, a movement to increase crop selection and agrichemical usage to increase yield in the 1930s through to the 1960s.\n\nIt is thought that genetic engineering of new crops and foods will take the lead in producing increased crop yield and nutrition.\n\nBill Gates has been among the proponents of a second green revolution, saying: \n\nThree quarters of the world's poorest people get their food and income by farming small plots of land...if we can make smallholder farming more productive and more profitable, we can have a massive impact on hunger and nutrition and poverty...the charge is clear—we have to develop crops that can grow in a drought; that can survive in a flood; that can resist pests and disease...we need higher yields on the same land in harsher weather.\"\n\nGates made these remarks during the World Food Prize. He has made over 1.4 billion in contributions towards agricultural developments.\n\nThe then Union Finance Minister of India, Pranab Mukherjee, made a statement to parliament that he would explore the possibility of setting up a committee of CMs of the eastern states for a second green revolution in the region and praised Assam, Bihar, Jharkhand and West Bengal for substantial increase in rice production during the current fiscal. Replying to the debate on 2012-13 Union Budget in Rajya Sabha, Mukherjee said due to substantial increase in rice output in the eastern states to the tune of 7 million tonnes in 2011-12, production of the staple grain has risen to a record 10.2 million tonnes. He said this was possible because of special thrust given on realizing the agricultural potential of eastern states.\n\nAccepting the suggestion of JD(U) member N K Singh, Mukherjee said he would explore the possibility of setting up a committee of chief ministers of eastern states \"to give further impetus to achieving green revolution\" in the region. Singh had suggested setting up of such a panel. He said: \"Given the importance of incentivizing agriculture in the eastern region, a chief ministers' committee comprising the CMs from the eastern states should be constituted for a coherent action plan and adequate support from the central government\". His suggestion came as one of the eight \"tangible actions\" which, he thought, would lend credibility to the budgetary announcements. The government had earlier allocated an additional Rs 400 crore in 2011-12 under Rashtriya Krishi Vikas Yojana for extending green revolution to the eastern region comprising Assam, Bihar, Jharkhand, Eastern UP, Chhattisgarh, Odisha and West Bengal. Rice was a priority crop under the scheme. Seeing the success of the scheme, the Budget 2012-13 has raised the allocation to Rs 1,000 crore.\n\nMukherjee lauded CMs of these states, particularly Bihar CM Nitish Kumar, whose state has doubled rice output to 67.5 lakh tonnes in 2011-12. Handsome increase in rice production has also been witnessed in Jharkhand, West Bengal and other eastern states.\n\nNoting that the achievement has attracted accolades from world over, he said the UN's Food and Agriculture Organization (FAO) and Indonesia-based World Rice Institute have commended the eastern states.\n\nOpponents views include social inequity as a major factor in food insecurity not addressed by increasing food production capacity.\n\nOthers\nhave used the term to refer to a combination of urban agriculture, smaller farm size and organic agriculture with the aim of increasing resource sustainability of crop production.\n\n"}
{"id": "31965764", "url": "https://en.wikipedia.org/wiki?curid=31965764", "title": "Timeline of the Greater Victoria Water System", "text": "Timeline of the Greater Victoria Water System\n\nThe water supply system for Victoria, British Columbia, Canada, now operated by the Capital Regional District (CRD), served in 2010 over 330,000 people with clean drinking water from a catchment area of centered on its main reservoir at Sooke Lake. The CRD’s ownership and complete control of its entire watershed assures its customers of a supply that is secure in both quantity and quality. The main reservoir and its subsidiary reservoirs are estimated to contain 93 billion litres of water, enough to meet the needs of its customers for two years without any rainfall. The history of this remarkable system is sketched below.\n\nIn 1842 Sir James Douglas led an expedition from Fort Vancouver on the Columbia River to find a suitable location for a Hudson’s Bay trading post on southern Vancouver Island. He examined three harbours: Sy-yousung (now Sooke), Is-whoy-malth (now Esquimalt), and Camosack (now Victoria). Of these he picked Camosack as “the most advantageous.” He rejected the first two for various reasons, which for Esquimalt included the scarcity of fresh water. “There are several good Runs in Winter,” he wrote, “but we found them all dried up, and we could not manage to fill a single Beaker in the Harbour.” But for all its other advantages, Camosack, which became Fort Victoria, had the same problem. Lieutenants Warre and Vavason of the Royal Engineers noted on their inspection of the place in 1845: “This fort has lately been established; it is badly situated with regard to water and position, which latter has been chosen for its agricultural advantages only.”\n\nOf course the newly established Fort Victoria could not exist without a water supply. Exploration of the surrounding area located two sources, both about east of the fort at what became known as Spring Hill and Harris Pond (near the present location of Victoria High School). At first, water was transported to the fort in barrels. Eventually the trail became a road over which wagons could be driven. As the town developed around the fort, private operators took over the operation and provided customers with two buckets a day for the equivalent of fifty cents a week.\n\nBy the late 1850s, especially with the Victoria’s growth as a port in response to the gold rushes on the Fraser River in 1858 and in the Cariboo in 1861, transport of water by wagon was becoming impractical. In 1863, entrepreneurs John Coe and Thomas Martin undertook to dig a shaft at the spring that greatly increased the flow of water. They contracted with J. P. Cranford to build a pipeline into town. The pipes were -long logs that were hollowed out and attached end to end to extend from the spring to the San Francisco Bathhouse on Government Street, from where deliveries were made to customers by wagon. The resulting increase in the water supply made it possible to fill four cisterns, ranging in size from 25,000 to 60,000 imperial gallons (114,000 to 276,000 L) to provide a reserve of water for fire protection. Coe and Martin formed the Spring Ridge Water Works Company in 1864, serving the city until 1875.\n\nBy 1869 it was evident that the spring and pond would soon be incapable of supplying Victoria’s growing population. Concerns were also expressed about the business practices of the Spring Ridge Water Company. The city engineer, Mr. Buckley, was asked to investigate the possibilities. He submitted a report in May 1872 recommending the use of Elk and Beaver Lakes that lay about north of the city. One result of his report was passage of the Victoria Waterworks Act of 1873 by the Provincial Legislature giving the City of Victoria disposal over all water sources within a radius of .\n\nDebentures were issued raising the money needed, and work began in 1874. Beaver Lake was the smaller and lower of the two lakes. A dam and filter bed were built at its southwest corner where its water flowed into Colquitz Creek. This raised the water level to that of Elk Lake, forming a single larger lake. A pipeline ranging in diameter from was laid along what is now Pipeline Road to a distribution point known as Fountain Square at the intersection of Government Street, Douglas Street and Hillside Avenue, from which water was supplied to customers in the city.\n\nThe quality of this water was problematic from the start. The filter beds were altered and enlarged four times between 1876 and 1883 with only minimally noticeable effect, while demand was constantly increasing. Connections to users outside the city were cut off in 1885, and use within the city for lawns and gardens was banned. Between 1887 and 1889 a 16-inch main was added, which for the moment solved the availability problem but exacerbated the quality problem, as the increased flow rate carried more sediment through the filters. Additional modifications to the filter beds provided only temporary relief.\n\nIn 1900 the North Dairy pumping station was established on Quadra Street at Reynolds Road. This improved the quantity but not the quality. In August, 1904, a fire in downtown Victoria devastated several city blocks because despite increased quantity there was still insufficient water for such a large fire. A separate high-pressure system was built in the city using saltwater solely for fire protection. Work was also begun on a balancing reservoir on Smith's Hill, which was completed in 1909 and is now the location of Summit Park.\n\nDespite these improvements, the supply and quality of water remained problematic until 1915. Between 1909 and 1915 the Water Department was constantly dealing with complaints about quality and low pressure. Water had to be rationed during this period. At one point the Water Commissioner, Charles Henry Rust, noticed an unusually heavy usage at the Empress Hotel. Investigation revealed that the hotel, which was owned by Canadian Pacific, was washing all the laundry for the CP steamships that came into the harbour. He warned that the hotel would be shut off completely if it did not cease this practice immediately.\n\nIt was understood already in 1905 that the supply from Elk and Beaver Lakes would not be adequate in the long term. The city brought in a consulting engineer from San Francisco, Arthur L. Adams, to study the problem and recommend solutions. He recommended that the city continue to use the then existing source but with extensive improvements, and if possible to acquire the Esquimalt Water Works Company which was then drawing water from Thetis Lake but also held the rights to the Goldstream Lakes. Adams considered Sooke Lake as a possible source, but members of city council thought it too expensive. Over the next three years, several attempts to claim Goldstream water and/or expropriate or purchase the Esquimalt Water Works failed. Adams was called upon for advice again in 1907. This time he put greater emphasis on Sooke Lake. Early in the following year, the council put the question of Sooke Lake to the ratepayers in a referendum. Going to Sooke Lake was supported by a two-thirds majority of those voting. It was, however, not until November 1910 that council finally passed the bylaw authorizing the development of Sooke Lake as a source of water supply. \nThe engineering of the project was contracted to the firm of Sanderson & Porter, with offices in New York and San Francisco. The responsible design engineer was Wynn Meredith of San Francisco, who had overseen several significant recent engineering projects in British Columbia. Initially, the resident engineer was Harry Hartwell, but he was replaced in July 1912 by Boyd Ehle from Sanderson & Porter's New York Office. The firm established an office in Victoria in the Drake Block at 1414 Douglas St.\n\nAside from acquiring ownership of the lake and surrounding watershed, Meredith’s plan involved constructing a flowline of from a dam at Sooke Lake to a holding reservoir to be constructed at the Humpback Road near Goldstream. From there a pipeline would run about through the Helmcken Fields and along Burnside Road to a distribution point in the city at Fountain Square.\nThe initial contract for the construction work was awarded to Solomon Cameron and Parker Clarke of the Westholme Lumber Co. in December, 1911. The work began in January, 1912. Problems with the Westholme company led to two significant moves in 1912. First, Charles Henry Rust, who had been the City Engineer in Toronto and had a reputation for getting things done, was brought in as City of Victoria Engineer and was soon appointed to the additional position of Water Commissioner, replacing J. L. Raymur who had held that position in addition to serving as City Comptroller, a position that he retained. Second, the City cancelled Westholme’s contract in April 1913, and took over the project as a public work.\n\nThe watershed was secured through purchase by the City of the surrounding Sooke Lake. The consulting engineer recommended that the neighboring Leech River watershed also be acquired and connected to Sooke Lake by a conduit, but this was not undertaken at the time. Sufficient land was acquired around the planned reservoir at Humpback, and a right-of-way for the flowline from Sooke Lake to Humpback, as well as the necessary right-of-way for the water main to the city, were added to the package.\n\nThe concrete dam at Sooke Lake raised the water level , expanding the surface area from and creating an available storage capacity of 3.355 billion imperial gallons (15,240,000 m3). The balancing reservoir at Humpback was created by building a concrete dam to a height of , closing off a sloping valley that would fill with the water piped down from Sooke Lake. The resulting reservoir would cover and hold up to 136 million imperial gallons (612,000 m3).\nThe greatest engineering challenge was to build the flow line of concrete pipe from Sooke Lake to Humpback. A grade was established that would drop per (0.0947%) for the . The plan had been for internal diameter pipe, but a contractor, the Pacific Lock Joint Pipe Co., was found, which already had forms for a diameter reinforced concrete pipe, so it was decided to use that size. A pipe factory was established at Cooper's Cove in Sooke Harbor within of the planned flowline grade, from Sooke Lake and from Humpback. Altogether, this factory produced more than 36,000 interlocking sections of concrete pipe.\n\nThe laying of the flowline involved building a small gauge railway on the grade from the pipe factory to Sooke Lake and to Humpback. Sections of pipe were loaded on cars, 22 at a haul, and pulled by a small engine up to the end of the line where they were placed into position. As the pipeline was laid, the railway tracks were taken up. When the rails were first laid, 56 wooden trestles had to be built across gullies. When it came to laying the pipeline, 51 of those trestles were replaced by concrete trestles; in five cases they were replaced by inverted siphons.\n\nThe final task of the project was to lay a diameter rivetted steel pipeline from the Humpback dam to Fountain Square from which a main delivered water into town. These pipes were produced by the Burrard Engineering Co. In addition, a line ran from this point to the reservoir on Smith's Hill.\nThe project was completed in May 1915 with the official opening ceremony held at Sooke Dam on the 28th of that month, Mayor Alexander Stewart presiding. A notice appeared in the city's two newspapers on 1 June that water restrictions would no longer be enforced. There was then more than ample water for the city’s population of 50,000.\n\nBoyd Ehle retired from the project in February 1915, to take up an assignment in Cuba. For the last year, Leonard Frederick Young was acting as resident engineer, with Harry Huston Crawford as his assistant. The on-site engineering team included Ivar Hallen, Frederick Sealy, John Krog, Philip Fox, and Charles Pollock. The records of others have been lost except for one engineer with the surname Bartholomew.\n\nIn 1925 the city expropriated the Esquimalt Waterworks Company, thus acquiring Goldstream Lake and about of additional watershed as well as facilities at Japan Gulch.\nUntil 1943 there had been no need for disinfection. In that year, however, Victoria was a marshaling point for both Canadian and American troops. Under pressure from U.S. military authorities chloramination stations were installed at Japan Gulch and Humpback.\nIn 1948 the Greater Victoria Water District was formed to manage the overall water supply for the municipalities of Victoria, Esquimalt, Oak Bay, and Saanich. The latter two municipalities retained responsibility for distribution in their areas.\nWith district population rising, it became necessary in 1954 to add a main from Humpback to a new balancing reservoir on Mount Tolmie. The reservoir on Smith Hill could no longer handle the added pressure and was taken out of service. By the late 1950s it was becoming evident that the flowline from Sooke Lake to Humpback would soon be outgrown. Aside from limitations of capacity, the old pipeline was leaking significantly, with fully a third of the water that entered it at Sooke Dam being lost through its 36,000 joints before reaching Humpback. Between 1967 and 1970, the level of Sooke Reservoir was raised three times by the addition of flashboards to the spillway.\n\nIn 1960 work began on a tunnel from Sooke Lake Reservoir to Japan Gulch in the Goldstream valley. The possibility of a tunnel had already been broached by the engineering consultant Arthur L. Adams in 1905, and again in 1907, but was discouraged by council's concern about cost as well as threatened legal action by the Esquimalt Water Works Co., which had a prior claim to the Goldstream watershed. \nAs with the flowline, the work was begun on the tunnel by a private company under contract. A full-face boring machine called a mole was used to drill an diameter tunnel into the mountain. The equipment, however, kept breaking down and the contractor went bankrupt. Once again, the project was taken over by the public authority, now the District, and was completed using more conventional methods of drilling, blasting, and mucking. Water was flowing through the tunnel at the rate of 140 million imperial gallons (636,000 m3) per day by 1970. At the same time, the flowline from near the town of Sooke to Humpback was decommissioned. The remaining section coming down from the dam would continue to serve the Sooke area. 1970 also saw the construction of a new dam at Sooke Lake Reservoir downstream from the old one, which was then inundated. The annual amount of water now available for use was 57 billion litres.\n\nIn 1995, 100 people became ill when water from the Humpback reservoir, which was still in service, became contaminated with the parasite \"Toxoplasma gondii\", which causes toxoplasmosis, from the feces of feral cats. As a result of this, Humpback Reservoir was shut down for good and construction was begun on a disinfection plant at Japan Gulch that would use ultraviolet light to neutralize micro-organisms not killed by chlorine. When it came into operation in 2004, it was the largest such plant in North America. In 1996, the now vastly expanded water supply system was transferred from the Greater Victoria Water District to the Capital Regional District.\n\nIn 2002, Sooke Dam was raised once again, creating a total system capacity of . A tunnel had been built in the 1980s from Leech River to Deception Reservoir, a small body of water adjacent to the south end of Sooke Lake Reservoir and separated from it by a saddle dam. The Leech watershed was finally purchased in 2007, adding to the already existing of watershed. Owing, however, to concerns about the quality of water from Leech River, its water has, at least for the time being, not been added to that of Sooke Lake Reservoir, but instead has been dedicated to supplementing fisheries water in Sooke River.\n\n\n"}
{"id": "20768356", "url": "https://en.wikipedia.org/wiki?curid=20768356", "title": "United States Army Medical Research Unit-Kenya", "text": "United States Army Medical Research Unit-Kenya\n\nThe United States Army Medical Research Unit-Kenya (USAMRU-K) — sometimes known informally as the \"Walter Reed Project\" — is a \"Special Foreign Activity\" of the Walter Reed Army Institute of Research headquartered in Nairobi, Kenya. The unit was established in 1969 and operates under a cooperative agreement with the Kenya Medical Research Institute. Much of the research done there has focused on tropical diseases, such as malaria, trypanosomiasis, and leishmaniasis, as well as arboviruses, HIV/AIDS, and other emerging infectious diseases.\n\n\n"}
{"id": "3545035", "url": "https://en.wikipedia.org/wiki?curid=3545035", "title": "University of Veterinary Science, Yezin", "text": "University of Veterinary Science, Yezin\n\nThe University of Veterinary Science, Yezin ( ), located in Yezin in the outskirts of Naypyidaw, is the only university of veterinary science in Myanmar (Burma). The university offers a six-year Bachelor of Veterinary Science (BVSc) program and it advanced the degree to a six-year [Doctor of Veterinary Medicine] and accepts about 100 students a year. It also offers graduate (PhD, MPhil, MVM and MVSc) degree programs. The language of instruction at UVS is English.UVS has been raised qualified veterinarians and keep raising qualified veterinarians with the level of ASEAN and veterinarians are recognized as top professionals around the world.\n\nVeterinary science education in Myanmar began in 1890 during the British colonial rule when the Veterinary Assistant Training School was opened at Shan Road in Kyimyindaing, Yangon. The school offered a two-year program, and senior veterinary officer Bhattiwallah was its first principal. In 1920, the school was upgraded, and the faculty was expanded by 12 veterinary inspectors and five veterinary superintendents, all non-Burmese. In 1923, the first Burmese veterinarian, Pe Than, a graduate of Bengal Veterinary College, was appointed a vet superintendent at the school. In February 1925, Governor Sir Harcourt Butler laid the foundation stone for the construction of the school's new building in Insein that would later bear his name. By 1931, the original two-year program had been extended to three years.\n\nIn 1957, the Veterinary College, a Faculty of Rangoon University was established at the Insein campus. The school's four-year BSc (Veterinary) program accepted university students who passed Intermediate Science Part II with distinctions in zoology, chemistry and physics. In 1964, the college became the Institute of Animal Husbandry and Veterinary Science (IAHVS) ( ), under the Ministry of Education, offering a six-year BVSc program. From 1957 to 1975, the two-year vet assistant program at the Veterinary Assistant Training School and the bachelor's degree program at the IAHVS were concurrently offered by two different government ministries. In 1981, the IAHVS was relocated to Yezin, Pyinmana (now part of Naypyidaw). In October 1999, the institute's name was formally changed to the present name in both English and Burmese.\n\nDuring the 1990s, the UVS like most universities in the country was repeatedly closed by the military government fearing of student unrest. On 31 December 1994, the institute came under the administration of the Ministry of Livestock and Fisheries.\n\nThe university began offering postgraduate courses for MPhil in 1988, MVSc and MSc programs in 1992, and three-year doctoral (PhD) programs in 2007. The government has sent some of the faculty to the Universiti Putra Malaysia for doctoral studies. The total number of graduates at the university between 1957 and 2012 was 4409.\n\nThe Japanese government has sponsored two to three Burmese veterinarians for MSc and PhD courses each year since 2000. A new generation of foreign trained veterinarians has begun to take over the teaching roles at the UVS, with some of them as departmental head and/or professors. Moreover, some of staff from UVS were also supported by German Academic Exchange {Deutscher Akademisher Austauschdienst (DAAD). More outstanding staff got scholarships from DAAD.\n\n\nThe University of Veterinary Science comprises a Rector’s Office and 18 departments namely:\n\n"}
{"id": "3549136", "url": "https://en.wikipedia.org/wiki?curid=3549136", "title": "Village-level operation and maintenance (pumps)", "text": "Village-level operation and maintenance (pumps)\n\nVillage Level Operation and Maintenance (VLOM) is an unofficial classification given to handpumps used in developing countries that require minimal maintenance or that can be done \"at the village level.\" Not all maintenance and repair needs to be done by the villagers for a pump to be classed as a VLOM pump. VLOMM, or Village Level Operation and Management of Maintenance is often used synonymously. This addition emphasizes the role of users as the managers of maintenance able choose to use someone from outside the village to assist with more complicated repairs.\n\nDuring the first UN decade on water boreholes, hand-dug wells and tubewells were constructed and water pumps were provided to developing countries by various NGOs. Unfortunately this top down approach led to the installation of pumps, notable the India Mark II, that were difficult to maintain. VLOM pumps were designed to allow remote villages to maintain pumps themselves as part of a larger strategy to reduce the dependency of villages on government and donor agencies and provide more sustainable access to drinking water.\n\nThe concept of Village Level Operation and Maintenance Management in relation to communal handpumps has gained wide acceptance in the rural water sector. Project and pump designs based on VLOM principles are now commonplace. However, implementation of handpump programs in accordance with VLOM criteria have been only partially successful and the VLOM approach to maintenance has been very difficult to realize in the field, especially in Africa.\n\nIt was assumed that the private sector would take care of the distribution of spare parts, but most parts had to be imported and were difficult to get. Low profit margins on spares did not encourage the private sector to take up the role of importing and distributing spare parts. As a result, VLOM technology is increasingly seen as one amongst many components needed for the sustainable provision of village water supplies.\n\nDifficulties with the introduction of VLOM have called into question a number of inherent assumptions in the concept relating to the user community, the supporting environment and technology choice. Of particular importance is the assumption that introducing and supporting VLOM is an easier task for government than running a centralized maintenance service.\n\nVLOM has undoubtedly brought the answer to sustainability a little closer; however, the goal of easy maintenance remains elusive. Perhaps the greatest lesson is that there are currently no ‘off-the-shelf’ solutions which can bypass the need for effective government institutional community water point support. Wherever this problem is unresolved, and where there are no NGOs or other agencies to fill the gap, sustainability will always be in doubt.\n\nRecently there have been attempts to involve the private sector, not only in selling spares and handpump repairs, but also in local pump sales and installation. This is called the \"BlueZone\" approach where a handpump dealer has its own region to take care of. Due to economics of scale, this would raise a more interesting business case and keep the handpump dealer interested to maintain this service while the communities have a reliable source of water with a local back-up. Unfortunately there are no simple one-fit-all solution on the horizon for sub-Saharan Africa, which experiences these problems most acutely.\n\n"}
{"id": "39642318", "url": "https://en.wikipedia.org/wiki?curid=39642318", "title": "Water scarcity in India", "text": "Water scarcity in India\n\nWater scarcity involves water \"stress, water shortage \"or \"deficits\", and \"water crisis\". This may be due to both nature and humans. Main factors that contribute to this issue include poor management of resources, lack of government attention, and man made waste. 18 percent of the world's population which resides in India only has access to 4 percent of usable water sources. Official data in the past decade depicts how annual per capita availability of water in the country has plummeted significantly with 163 million Indians lacking access to safe drinking water. \n\nThe water sources are contaminated with both bio and chemical pollutants. 21% of the country's diseases are water-related with only 33% of the country having access to traditional sanitation. Excessive use of groundwater for agriculture has also caused a strain in the resource. As India is one of the top agriculture producers in the world, the consumption of water for land and crops is also one the highest. The results of the widespread use of ineffective techniques used for irrigation aligned with mismanagement are few of the reasons for the water deficit. A significant portion of water used for industrial and domestic purposes is waste when returned to the streams. The demand for freshwater is increasing with the growing population, but the decreasing amount of supply fails to meet the needs of the people.\n\nThe increased amount of solid wastes in water systems such as lakes,canals and rivers also heavily pollute the water. To combat this problem, the government issued the Ganga Action Plan issued in 1984 to clean up the Ganges River. However, much of the river remains polluted with a high coli form count at many places. This is largely due to lack of maintenance of the facilities as well inadequate fees for service. Due to this issue, urgent need for safe drinking water is 70.1% of the households in urban areas. 18.7 % in rural received organized pipe water supply and others have to depend on surface and ground water which is untreated.\n\nAlong with the strain on surface water, the country is also facing great stress with freshwater. Lack of strict state regulation on ground water development has caused a strain on the amount of freshwater available. Indifference from bureaucratic powers and constant neglect has caused the problem to intensify. In hand with the lack of government interference and continued industrial waste deposited into major rivers, most freshwater entering the bodies of water is defiled. The approximation of the untreated water entering the water sources such as rivers and lakes is 90 percent and only furthers the problem. \n\nIn 2016, the city of Latur experienced a great water shortage. Much of the farming industry came to a halt and created both food insecurity and massive unemployment. Much of the local economy and farming regions nearly collapsed with the citizens having no choice but to use the polluted water. \n\nThe acute water shortage prevailing in the forest areas of Tamil Nadu's districts of Madurai and Dindigul has led to the deaths of Indian gaurs found in the forest of the region, as they come in search of water are killed falling into the wells.\n\nWith support from government and UNICEF, villagers in Palve Budruk, located in the drought-prone Parner Block in Ahmednagar district of Maharashtra, developed a catchment plan covering 1,435 hectors – over 80% of the land available. The system has three check dams, 20 canal bunds, two small percolation tanks linked to the main tank and 19 village ponds. Water stored in the percolation tank, is strictly meant for domestic use only. Piped water is supplied for an hour a day in the morning, during which time families fill up water for drinking and cooking.\n\nSIS Seoul International School is Fundraising to bring water to India, and can be found in South Korea, or siskorea.They have also started building a strong community for the water crisis in india\n\nThe Canadian start-up Decode Global has developed the mobile game Get Water!, a game for social change focusing on the water scarcity in India and the effect it has on girls' education. The game's primary goal is to raise awareness of the water crisis, by educating children as well as adult gamers. To put more focus on children'd learning, the company has published a 6-part lesson plan for 4-6 grade teachers, available for download as a pdf from the game's website.\n\nThe Central Ground Water Authority (CGWA) has notified 82 areas (Districts, Blocks, Mandals, Talukas, Municipalities) for regulation of ground water development. In these areas, installation of new ground water abstraction structures is not permitted without prior specific approval of the Authority / Authorized officer. Moreover, proposals for setting up/expansion of ground water based industries including bottled water manufacturing units are forwarded by State Pollution Control Boards and Bureau of Indian Standards to CGWA for seeking No Objection Certificate (NOC) for ground water withdrawal. NOC is not accorded to such industries including bottled water manufacturing units p\neas notified by the Authority. In non-notified areas, NOC is issued with mandatory pre-conditions of adoption of rain water harvesting system, monitoring of ground water abstraction as well as monitoring of ground water level and quality etc. by the industry. For enforcement of the regulatory directions issued under Section 5 of Environment (Protection) Act, 1986, concerned Deputy Commissioners/District Collectors have been authorized to take necessary action in case of violations of directives of CGWA in the notified areas.\n\nAccording to Indian government report, warns that 21 cities will run out a groundwater by years of 2020.\n\n\n\n"}
{"id": "841522", "url": "https://en.wikipedia.org/wiki?curid=841522", "title": "Yoshio Nishina", "text": "Yoshio Nishina\n\nNishina was born in Satoshō, Okayama, and graduated from Tokyo Imperial University as an electrical engineer in 1918. After graduation, he became a staff member at the Institute of Physical and Chemical Research (now RIKEN).\n\nIn 1921, he was sent to Europe for research. He visited some European universities and institutions, including Cavendish Laboratory, Georg August University of Göttingen, and University of Copenhagen. In Copenhagen, he did research with Niels Bohr and they became good friends. In 1928, he wrote a paper on incoherent or Compton scattering with Oskar Klein in Copenhagen, from which the Klein–Nishina formula derives.\n\nIn 1929, he returned to Japan, where he endeavored to foster an environment for the study of quantum mechanics. He established Nishina Laboratory at RIKEN in 1931, and invited some Western scholars to Japan including Heisenberg, Dirac and Bohr to stimulate Japanese physicists. His laboratory was severely damaged during World War II and most equipment had to be discarded and rebuilt after the war.\n\nHe died from liver cancer in 1951.\n\nThe crater Nishina on the Moon is named in his honor.\n\nNishina co-authored the Klein–Nishina formula. His research was concerned with cosmic rays and particle accelerator development for which he constructed a few cyclotrons at RIKEN. In particular, he detected what turned out to be the muon in cosmic rays, independently of Anderson \"et al\". He also discovered the uranium-237 isotope and pioneered the studies of symmetric fission phenomena occurring upon fast neutron irradiation of uranium (1939–1940), and narrowly missed out on the discovery of the first transuranic element, neptunium.\n\nHe was a principal investigator of RIKEN and mentored generations of physicists, including two Nobel Laureates: Hideki Yukawa and Sin-Itiro Tomonaga.\n\nDuring World War II, he was the head of the Japanese nuclear weapon program.\n\n"}
