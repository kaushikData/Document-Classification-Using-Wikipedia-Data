{"id": "30241041", "url": "https://en.wikipedia.org/wiki?curid=30241041", "title": "Adults with Incapacity (Scotland) Act 2000", "text": "Adults with Incapacity (Scotland) Act 2000\n\nThe Adults with Incapacity (Scotland) Act 2000 (2000 asp 4) is an Act of the Scottish Parliament. It was passed on 29 March 2000, receiving royal assent on 9 May. It concerns the welfare of adults (the age of legal capacity in Scotland being 16) who are unable to make decisions for themselves because they have a mental disorder or are not able to communicate. It provides the framework for other people (such as carers) to act on the behalf of people with incapacity.\n\nThe Act was one of the first pieces of legislation passed by the Scottish Parliament upon it being reconvened in 1999.\n\nPart 2 of the act concerns power of attorney and provides the framework for an individual (whilst they have capacity) to appoint someone to act as their continuing (financial) or welfare attorney.\n\nPart 3 of the act concerns the accounts and funds of the adult with incapacity. It enables access to the bank or building society account of the adult with incapacity, in order to pay their costs of living.\n\nPart 4 of the act concerns the management of finances of adults with incapacity who are residents of registered establishments including health service or private hospitals, psychiatric hospitals, state hospitals and care home services.\n\nPart 5 of the act concerns medical research and treatment of adults with incapacity. It allows, under certain circumstances, medical research to be carried out on adults unable to give consent.\n\nPart 6 of the act concerns intervention orders and guardianship orders. An intervention order can be applied for by, or on behalf of, an adult with incapacity and granted by the sheriff court. It may cover welfare or financial matters. An application for a guardianship order may be made by individuals or by a local authority regarding an adult with incapacity who may have long-term needs.\n\nPart 7 of the act (\"Miscellaneous\") makes it an offence for an individual to wilfully neglect and adult with incapacity.\n\n\n\n"}
{"id": "51022070", "url": "https://en.wikipedia.org/wiki?curid=51022070", "title": "American Nurses Association Hall of Fame", "text": "American Nurses Association Hall of Fame\n\nThe American Nurses Association Hall of Fame or the ANA Hall of Fame is an award which recognizes the historical contributions to nursing in the United States.\n\nIn 1974, in preparation for the United States Bicentennial, the American Nurses Association (ANA) created a seven-member committee to recognize the dedication and achievements of professional nurses in a Hall of Fame. Fifteen inaugural women were selected as inductees and the committee recommended that the nomination process and inductions become a permanent vehicle for recognition. In 1982, National Nurse's Day was proclaimed by President Ronald Reagan to be celebrated on May 6 and in conjunction with the celebration, the ANA at their annual convention, inducted six more nurses. The ANA board approved periodic addition of members thereafter, inducting new members in 1984, 1986, and 1996. In 1996, the criteria changed so that inductees did not have to be deceased and that inductions occur biennially.\n\nThe criteria for induction include that the nominees must be leaders in health, social or political policy which have had a sustaining impact on nursing in the United States. All candidates, unless they were working prior to 1873, must have completed a formal registered nursing program. Contributions to the field could have occurred locally or internationally, but must demonstrate their enduring value beyond the honoree's lifetime. Since 1996, inductees may be living or deceased.\n"}
{"id": "3146632", "url": "https://en.wikipedia.org/wiki?curid=3146632", "title": "Bland–Altman plot", "text": "Bland–Altman plot\n\ncodice_1\nA Bland–Altman plot (Difference plot) in analytical chemistry or biomedicine is a method of data plotting used in analyzing the agreement between two different assays. It is identical to a Tukey mean-difference plot, the name by which it is known in other fields, but was popularised in medical statistics by J. Martin Bland and Douglas G. Altman.\n\nBland and Altman make the point that any two methods that are designed to measure the same parameter (or property) should have good correlation when a set of samples are chosen such that the property to be determined varies considerably. A high correlation for any two methods designed to measure the same property could thus in itself just be a sign that one has chosen a widespread sample. A high correlation does not necessarily imply that there is good agreement between the two methods.\n\nConsider a set of formula_1 samples (for example, objects of unknown volume). Both assays (for example, different methods of volume measurement) are performed on each sample, resulting in formula_2 data points. Each of the formula_1 samples is then represented on the graph by assigning the mean of the two measurements as the formula_4-value, and the difference between the two values as the formula_5-value.\n\nThe Cartesian coordinates of a given sample formula_6 with values of formula_7 and formula_8 determined by the two assays is\n\nFor comparing the dissimilarities between the two sets of samples independently from their mean values, it is more appropriate to look at the ratio of the pairs of measurements. Log transformation (base 2) of the measurements before the analysis will enable the standard approach to be used; so the plot will be given by the following equation:\n\nThis version of the plot is used in MA plot.\n\nOne primary application of the Bland–Altman plot is to compare two clinical measurements that each produce some error in their measures. It can also be used to compare a new measurement technique or method with a gold standard, as even a gold standard does not - and should not - imply it to be without error. See Analyse-it, MedCalc, NCSS, GraphPad Prism, R, or StatsDirect for software providing Bland–Altman plots.\n\nBland-Altman plots are extensively used to evaluate the agreement among two different instruments or two measurements techniques. Bland-Altman plots allow identification of any systematic difference between the measurements (i.e., fixed bias) or possible outliers. The mean difference is the estimated bias, and the SD of the differences measures the random fluctuations around this mean. If the mean value of the difference differs significantly from 0 on the basis of a 1-sample t-test, this indicates the presence of fixed bias. If there is a consistent bias, it can be adjusted for by subtracting the mean difference from the new method. It is common to compute 95% limits of agreement for each comparison (average difference ± 1.96 standard deviation of the difference), which tells us how far apart measurements by 2 methods were more likely to be for most individuals. If the differences within mean ± 1.96 SD are not clinically important, the two methods may be used interchangeably. The 95% limits of agreement can be unreliable estimates of the population parameters especially for small sample sizes so, when comparing methods or assessing repeatability, it is important to calculate confidence intervals for 95% limits of agreement. This can be done by Bland and Altman's approximate method or by more precise methods.\n\nBland-Altman plots were also used to investigate any possible relationship of the discrepancies between the measurements and the true value (i.e., proportional bias). The existence of proportional bias indicates that the methods do not agree equally through the range of measurements (i.e., the limits of agreement will depend on the actual measurement). To evaluate this relationship formally, the difference between the methods should be regressed on the average of the 2 methods. When a relationship between the differences and the true value was identified (i.e., a significant slope of the regression line), regression-based 95% limits of agreement should be provided.\n\nA similar method was proposed in 1981 by Eksborg. This method was based on Deming regression—a method introduced by Adcock in 1878.\n\nBland and Altman's Lancet paper was number 29 in a list of the top 100 most-cited papers of all time with over 23,000 citations.\n\n"}
{"id": "41297086", "url": "https://en.wikipedia.org/wiki?curid=41297086", "title": "Buda Health Center", "text": "Buda Health Center\n\nThe Buda Health Center is a private health clinic in Budapest. Established in 2000, it offers outpatient health care in two locations in the XIIth District, on Nagy Jenő Street and Királyhágó Street, and in one location in the IIIrd District, at the Graphisoft Park. More than 100 physicians in 45 specialties see their private patients in the facility and more than 230 national and multinational companies have contracted with them for their employees’ health care.\n\nThe National Center for Spinal Disorders is its affiliate hospital. The hospital also offers publicly financed outpatient care in the areas of musculoskeletal disorders (spine care, orthopedics, traumatology) and anesthesiology as well as inpatient spine care and spine surgery for national and international private patients and patients covered by Hungarian Health Insurance.\n\nIn 2006, the Buda Health Center earned 1.7 billion Hungarian Forints mainly from international patients while in 2011, the earnings reached 3 billion. By the middle of 2013, the Buda Health Center had contract agreements with more than 230 national and multinational companies.\n\nThe Buda Health Center was established by Peter Paul Varga, MD in a villa in Budapest originally the residence of one of the directors of the Hungarian Optical Works. The building consequently served for a time as a kindergarten, in the 90’s was occupied by the health clinic of the Postabank then in 2000 by the Buda Health Center. The clinic first opened its doors as a private orthopedic clinic, gradually enlarging its portfolio, adding more and more specialties every year. In 2002, screening examinations and the Occupational Health Program were added.\n\nThe Buda Health Center is committed to promoting the importance of a healthy life style by providing incentives through articles appearing in their blogs, in local publications and on their own website. These articles cover diseases and their possible treatments and also emphasize the importance of daily physical education in the prevention of diseases. The Center takes an active part in the District’s health (Egészséges Hegyvidék) program offering free screening examinations and lectures.\n\nThe quality of the services provided are controlled and guaranteed by the Hungarian MSZ EN 9001: 2001 standards and the Hungarian Health Care Standards (MEES 1.0).\n\n\n"}
{"id": "52540299", "url": "https://en.wikipedia.org/wiki?curid=52540299", "title": "Cannabis in Trinidad and Tobago", "text": "Cannabis in Trinidad and Tobago\n\nThe manufacturing, selling and possession of Cannabis is illegal in Trinidad and Tobago.\n\nIn 1915 Trinidad created the Ganja Ordinance, by which all cannabis sold on the island was gathered into bonded warehouses and distributed only to sellers who paid a license fee, similar to the system found in Bengal. Cannabis was banned in the islands in 1925. In 2018, the head of the Caribbean Collective for Justice has called for the nation to decriminalize cannabis.\n"}
{"id": "13675634", "url": "https://en.wikipedia.org/wiki?curid=13675634", "title": "Capital punishment in Andorra", "text": "Capital punishment in Andorra\n\nPere Areny was the last man to be executed in Andorra. He was shot by a firing squad for the murder of his brother, Antoni Areny, on 18 October 1943. Capital punishment was abolished in Andorra in 1990 and Protocol No. 6 to the ECHR came into force on 1 February 1996.\n\n"}
{"id": "38243422", "url": "https://en.wikipedia.org/wiki?curid=38243422", "title": "Children's Food Trust", "text": "Children's Food Trust\n\nThe Children's Food Trust (formerly the School Food Trust, renamed in 2012) was a charity in the United Kingdom that sought to promote healthy eating for children.\n\nThe Trust - originally named the School Food Trust - was created as a non-departmental public body in 2005 by the Department for Education and Skills (DfES), following celebrity chef Jamie Oliver's critique of the nutritional quality of school meals in his TV documentary \"Jamie's School Dinners\" and the recommendations of the School Meals Review Panel. It had been found that standards of school food were low, with average ingredient spend per meal before 2005 at secondary schools at around 40p. Childhood obesity is a problem in the UK in specific demographic groups (see National Statistics Socio-economic Classification), with some medical professionals predicting that today's youngsters will have a lower life expectancy than their parents with problems with diabetes and heart disease.\n\nSuzi Leather was appointed as Chair of the Trust and Judy Hargadon, an NHS senior manager, was appointed as the Trust's first Chief Executive. Leather resigned in 2006 to become Chair of the Charity Commission and, in November of that year, Prue Leith was named as the Chair. She retired in January 2010. Hargadon retired in 2013 and was succeeded by Linda Cregan. \n\nIn April 2007, the Trust also became a registered charity. In October 2011, the Trust officially ceased to be an NDPB, expanding its work both as a charity and by trading its services through a new community interest company, as the Children's Food Trust.\n\nIn July 2017 the charity's closure was announced due to running out of funding and the charity was officially closed on 30th September 2017.\n\nThe trust was initially funded by a £15 million grant from the Department for Education and Skills, and has been awarded in partnership with organisations including The Prince's Trust, Business in the Community, Magic Outcomes and the Improvement Foundation, £20 million additional funding from the Big Lottery Fund for a network of school children's cookery clubs called Let's Get Cooking.\n\n"}
{"id": "48455308", "url": "https://en.wikipedia.org/wiki?curid=48455308", "title": "Cranial ultrasound", "text": "Cranial ultrasound\n\nCranial ultrasound is a technique for scanning the brain using high-frequency sound waves. It is used almost exclusively in babies because their fontanelle (the soft spot on the skull) provides an \"acoustic window\". \nA different form of ultrasound-based brain scanning, transcranial Doppler, can be used in any age group. This uses Doppler ultrasound to assess blood flow through the major arteries in the brain, and can scan through bone. It is not usual for this technique to be referred to simply as \"cranial ultrasound\". Additionally, cranial ultrasound can be used for intra-operative imaging in adults undergoing neurosurgery once the skull has been opened, for example to help identify the margins of a tumour.\n\nMost neonatal units in the developed world routinely perform serial cranial ultrasound scans on babies who are born significantly premature. A typical regimen might involve performing a scan on the first, third and seventh day of a premature baby's life, and then at regular intervals until the baby reaches term.\n\nPremature babies are especially vulnerable to certain conditions involving the brain. These include intraventricular haemorrhage (IVH), which often occurs during the first few days, and periventricular leukomalacia (PVL), which tends to occur later on. One of the main purposes of routine cranial ultrasound scanning in neonatal units is to identify these problems as they develop. If severe intraventricular haemorrhage is noted then the baby will need to be scanned more frequently in case post-haemorrhagic hydrocephalus (swelling of the ventricles as the natural flow of the cerebrospinal fluid is blocked by blood-clots) develops.\n\nMany other conditions can also be identified by cranial ultrasound. These include:\nTherefore unwell mature babies often undergo cranial ultrasound as well as premature babies.\n\nA water-based gel is applied to the infant's head, over the anterior fontanelle, to aid conduction of ultrasound waves. Ideally scans are performed during sleep or when the infant is calm. The operator then uses an ultrasound probe to examine the baby's brain, viewing the images on a computer screen and recording them as necessary.\n\nA standard cranial ultrasound examination usually involves recording approximately 10 views of the brain from different angles, five in the coronal plane and five in the sagittal or parasaggital planes. This allows all parts of the ventricles and most of the rest of the brain to be visualised.\n\nWho performs the scans varies between different health systems. In many hospitals in the United Kingdom paediatricians or neonatologists usually perform cranial ultrasound; in other systems advanced nurse practitioners, radiologists or sonographers may perform most scans.\n\nWhile the anterior fontanelle is the most commonly used acoustic window for cranial ultrasounds, more advanced operators may gain additional views, especially of posterior fossa structures, by using the mastoid fontanelle, the posterior fontanelle and/or the temporal window.\n\nOther refinements of cranial ultrasound technique include serial measurement of the width of the lateral ventricles (\"ventricular index\") to monitor suspected ventricular dilatation and colour Doppler to assess blood flow.\n\nCranial ultrasound is a very safe technique as it is non-invasive and does not involve any kind of ionising radiation. However, it is subject to certain limitations.\nTherefore many neonatal services prefer to perform an MRI scan when the infant is near term, as well as routine cranial ultrasound, to avoid missing more subtle abnormalities.\n"}
{"id": "55904617", "url": "https://en.wikipedia.org/wiki?curid=55904617", "title": "Danielle Ripich", "text": "Danielle Ripich\n\nDanielle Newberry Ripich (born March 4, 1945) is a retired American academic who served as president of the University of New England, Maine, from 2006 to 2017. She has a background in speech pathology and communication studies.\n\nRipich was born and raised in Portsmouth, Ohio, the daughter of two schoolteachers. She studied speech pathology at Cleveland State University, completing a B.A. and M.A., and later received a Ph.D. from Kent State University. Ripich joined the faculty of Case Western Reserve University in 1982, and was elevated to a full professorship in 1994. She was initially chair of the Department of Communication Studies, and later associate dean of the College of Arts and Sciences. In 1999, she joined the Medical University of South Carolina as dean of the College of Health Professions.\n\nIn July 2006, Ripich took office as president of the University of New England. As president, she oversaw the development of a new campus in Tangier, Morocco, and the openings of new colleges of pharmacy and dental medicine. Enrolment swelled from 4,000 students at the beginning of her tenure to 12,000 at the end. In May 2016, Ripich announced her intention to leave office in June 2017. Senators Susan Collins and Angus King issued a joint statement \"thanking her for all that she has done to advance higher education in Maine\".\n"}
{"id": "24471476", "url": "https://en.wikipedia.org/wiki?curid=24471476", "title": "Denominator data", "text": "Denominator data\n\nIn epidemiology, data or facts about a population is called denominator data. Denominator data are independent of any specific disease or condition. This name is given because in mathematical models of disease, disease-specific data such as the incidence of disease in a population, the susceptibility of the population to a specific condition, the disease resistance, etc. disease-specific variables are expressed as their proportion of some attribute of the general population, and hence appear as the numerator of the fraction or percentage being calculated, general data about the population typically appearing in the denominator; hence the term denominator data.\n\nIn an epidemiological compartment model, for example, variables are often scaled to total population. The susceptible fraction of a population is obtained by taking the ratio of the number of people susceptible to the total population. Susceptibility to a disease may depend on other factors such as age or sex. Data about a population including age distribution, male/female ratios, and other demographic factors may be relevant as denominator data. Denominator data is not only limited to data describing human populations but also includes information about wild and domestic animal populations.\n\n"}
{"id": "6003729", "url": "https://en.wikipedia.org/wiki?curid=6003729", "title": "Direct support professional", "text": "Direct support professional\n\nDirect Support Professionals (DSPs) are people who work directly with people with physical disabilities and/or intellectual disabilities with the aim of assisting the individual to become integrated into his/her community or the least restrictive environment. \n\nA direct support professional is a person who assists an individual with a disability to lead a self-directed life and contribute to the community, assists with activities of daily living if needed, and encourages attitudes and behaviors that enhance community inclusion. A DSP may provide supports to a person with a disability at home, work, school, church, and other community places. A DSP also acts as an advocate for the disabled individual, in communicating their needs, self-expression and goals.\n\nDirect Support Professional training and community placement/living became more prevalent following the Willowbrook State School scandal where it was uncovered following an investigation by then WABC journalist Geraldo Rivera, that residents were being physically mistreated and kept in poor living conditions. Telly Award winning film \"Everyday Heroes\", produced by Pleasantville, New York media production company Creators Media Group, highlights the work of Direct Support Professionals.\n\nAs of May 2006 Michigan and 5 other states were gearing up to implement fingerprinting background checks for Direct Support Professionals that provide care in long term care facilities. Some states, such as California, require criminal background checks, while other states do not.\n\nThe requirement for the community care facility direct care staff training (a.k.a. Direct Support Professional Training) was created by Assembly Bill 2780 enacted in 1998. AB 950, approved by the Governor in August 2001, amends the Welfare and Institutions Code. Effective January 1, 1999, the Department of Developmental Services implemented mandated statewide competency-based training for direct support professionals employed in regional center vendored community care facilities. This legislation followed a series reported by the San Francisco Chronicle on poorly trained staff and a high death rate for the developmentally disabled in the State of California.\n\nIn 1998, the California legislature established the Direct Support Professional (DSP) Training Program.\nThe purpose of the program is to increase quality of care for people with developmental disabilities living in licensed community care facilities by ensuring core competencies or skills for all direct support professionals.\n\nThe statewide training program requires all direct support professionals to successfully complete 70-hours of training over two years, or pass a challenge test for each of two, 35-hour training segments. Upon successfully completing either of these requirements, Direct Support Professional Certification will be provided.\n\nThe DSP requirements are not in place for DDN or DDH facilities under the Department of Health Services of the State of California. These requirements are also not in place for day programs, work activity centers or for at home vendored service providers.\n\nDirect Support Professional Training through the College of Direct Support\n\nLouisiana Direct Support Professionals\n\nIllinois Council on Developmental Disabilities – The Illinois project has been reviewing options for retention and training since 2003 with a projected outcome of having trained Direct Care Professional and retention once trained.\n\nDirect Support Professionals Association of Tennessee\n\nThe Kansas Chapter of the National Alliance for Direct Support Professionals\n\nNational Alliance for Direct Support Professionals –\nOffers Training and National Standards. Some standards may be higher than the National Alliance depending on the state.\n\n\n\n"}
{"id": "708453", "url": "https://en.wikipedia.org/wiki?curid=708453", "title": "Eating your own dog food", "text": "Eating your own dog food\n\nEating your own dog food, also called dogfooding, occurs when an organization uses its own product. This can be a way for an organization to test its products in real-world usage. Hence dogfooding can act as quality control, and eventually a kind of testimonial advertising. Once in the market, dogfooding demonstrates confidence in the developers' own products.\n\n\"InfoWorld\" commented that this needs to be transparent and honest: \"watered-down examples, such as auto dealers' policy of making salespeople drive the brands they sell, or Coca-Cola allowing no Pepsi products in corporate offices ... are irrelevant.\" In this sense, a corporate culture of not supporting the competitor is not the same as a philosophy of \"eating your own dog food\". The latter focuses on the functional aspects of the company's own product.\n\nDogfooding allows employees to test their company's products in real-life situations; a perceived, but still controversial, advantage beyond marketing, which gives management a sense of how the product might be used—all before launch to consumers. In software development, dogfooding can occur in multiple stages: first, a stable version of the software is used with just a single new feature added. Then, multiple new features can be combined into a single version of the software and tested together. This allows several validations before the software is released. The practice enables proactive resolution of potential inconsistency and dependency issues, especially when several developers or teams work on the same product.\n\nThe risks of public dogfooding, specifically that a company may have difficulties using its own products, may reduce the frequency of publicized dogfooding.\n\nIn 2006, the editor of \"IEEE Software\" recounted that in the 1970s, television advertisements for Alpo dog food, Lorne Greene pointed out that he fed Alpo to his own dogs. Another possible origin he remembers is from the president of Kal Kan Pet Food, who was said to eat a can of his dog food at shareholders' meetings.\n\nIn 1988, Microsoft manager Paul Maritz sent Brian Valentine, test manager for Microsoft LAN Manager, an email titled \"Eating our own Dogfood\", challenging him to increase internal usage of the company's product. From there, the usage of the term spread through the company.\n\nDave Cutler's February 1991 insistence on dogfooding in development of Windows NT at Microsoft was documented in Pascal Zachary's 1994 book, \"Showstopper! The Breakneck Race to Create Windows NT and the Next Generation at Microsoft\". Microsoft developed the operating system on computers running NT daily builds, initially text only, then with graphics, and finally with networking.\n\nThe development of Windows NT at Microsoft involved over 200 developers in small teams, and it was held together by Dave Cutler's February 1991 insistence on dogfooding. Microsoft developed the operating system on computers running NT daily builds. It was initially crash prone, but the immediate feedback of code breaking the build, the loss of pride, and the knowledge of impeding the work of others were all powerful motivators. Windows developers would typically dogfood or self-host Windows starting from the early (alpha) builds, while the rest of the employees would start from the more stable beta builds that were also available to MSDN subscribers. In 2005, \"Infoworld\" reported that a tour of Microsoft's network operations center \"showed pretty much beyond a reasonable doubt that Microsoft does run its 20,000-plus node, international network on 99 percent Windows technology, including servers, workstations, and edge security\". \"InfoWorld\" argued that \"Microsoft's use of Windows for its high-traffic operations tipped many doubters over to Windows' side of the fence.\"\n\nIn the mid-1990s, Microsoft's internal email system was initially developed around Unix. When asked why, they publicly moved to using Microsoft Exchange. In 1997, an email storm known as the Bedlam DL3 incident made Microsoft build more robust features into Microsoft Exchange Server to avoid lost and duplicate emails and network and server down-time, although dogfooding is rarely so dramatic. A second email storm in 2006 was handled perfectly by the system.\n\nIn 1999, Hewlett-Packard staff referred to a project using HP's own products as \"Project Alpo\". Around the same time, Mozilla also practised dogfooding under that exact name.\n\nGovernment green public procurement that allows testing of proposed environmental policies has been compared to dogfooding.\n\nOn 1 June 2011, YouTube added a license feature to its video uploading service allowing users to choose between a standard or Creative Commons license. The license label was followed by the message (Shh! - Internal Dogfood) that appeared on all YouTube videos lacking commercial licensing. A YouTube employee confirmed that this referred to products that are tested internally.\n\nForcing those who design products to actually use and rely on them is sometimes thought to improve quality and usability, but software developers may be blind to usability and may have knowledge to make software work that an end user will lack. Microsoft's chief information officer noted in 2008 that, previously, \"We tended not to go through the actual customer experience. We were always upgrading from a beta, not from production disk to production disk.\" Dogfooding may happen too early to be viable, and those forced to use the products may assume that someone else has reported the problem or they may get used to applying workarounds. Dogfooding may be unrealistic, as customers will always have a choice of different companies' products to use together, and the product may not be used as intended. The process can lead to a loss of productivity and demoralisation, or at its extreme to \"Not Invented Here\" syndrome, i.e. only using internal products.\n\nIn 1989, Donald Knuth published a paper recounting lessons from the development of his TeX Typesetting software, in which the benefits of the approach were mentioned:\n\nIn 2007, Jo Hoppe, the CIO of Pegasystems, said that she uses the alternative phrase \"drinking our own champagne\". Novell's head of public relations Bruce Lowry, commenting on his company's use of Linux and OpenOffice.org, said that he also prefers this phrase. In 2009, the new CIO of Microsoft, Tony Scott, argued that the phrase \"dogfooding\" was unappealing and should be replaced by \"icecreaming\", with the aim of developing products as \"ice cream that our customers want to consume\". A less controversial and common alternative term used in some contexts is self-hosting, where developers' workstations would, for instance, get updated automatically overnight to the latest daily build of the software or operating system on which they work. Developers of IBM's mainframe operating systems have long used the term \"eating our own cooking\".\n\n\n"}
{"id": "34313346", "url": "https://en.wikipedia.org/wiki?curid=34313346", "title": "Georgian folk medicine", "text": "Georgian folk medicine\n\nGeorgian folk medicine (or Georgian traditional medicine) originated at the crossroads of the East and West and therefore integrates the principles of both medical traditions. On a scale between tribal level folk medicine and highly institutionalized Chinese and Unani Traditional medicines, Georgian traditional medicine ranks closer to the better institutionalized and formalized end of the scale. Some ancient Georgian folk remedies made it to the modern formulations and are commercially distributed in the form of modern drugs, mostly petrolatum-based ointments.\n\nAnthropological data suggest that Paleolithic Cro-Magnon people that dwelt on the territory of modern western Georgia may have known of some sort of primitive ointment made from animal brains mixed with fat. Classical Greek mythology suggests that ancient Kolkhs (Colchis people) had practiced somewhat highly developed medicine that must have impressed the Mycenaean Greek (Minyan) travelers at the time. Some historians of medicine suggest that the modern medical scientific principle \"Contraria contrariis curantur\" (opposite cures the opposite) dates back to ancient Kolkhs and their healer and sorceress princess Medea, acquiring its final form in the classical Greek and eventually in the modern medicine. Georgian popular tradition even attributes the origins of the term Medicine solely to Medea's name. In fact, the term likely stems from the Indo-European root MA and MAD, “and its more familiar hypothetical form MED, meaning to think or to reflect, to give a consideration or care to”. Still, a possible relation between the name of Medea and the term Medicine cannot be decisively denied.\n\nBeginning of the recorded history of Georgian traditional medicine should be related to the first almanac of medical remedies and medical knowledge written in the 11th century, known as “Ustsoro Karabadini” (Georgian: უსწორო კარაბადინი). After that, different compilations thereof, as well as original fundamental works, all mostly under similar titles (with the exception of the influential 16th-century medical encyclopedia titled \"Iadigar Daudi\" - Georgian: იადიგარ დაუდი, and a few more), were published once or twice every 100 years until the end of the 19th century. These works, along with the unique local remedies, also include knowledge influenced by the ancient Greek, Byzantine, and Central Asian and Middle East medical traditions.\n\nThe highly developed feudal social structure of Medieval Georgia led to the emergence of traditional Georgian medical families (not too unlike the better known Irish medical families), one of which, the Turmanidze family (Georgian: თურმანიძეები) is first mentioned in historical documents somewhere on the turn of the 10th and 11th centuries. So great was the clout of the bearers of Turmanidze family traditions even in the twentieth century that some representatives of the family who lacked any formal education were nevertheless granted medical licenses by the Soviet officials, who were generally very adamant about disallowing traditional medicine methods in the official Soviet medicine.\n\n"}
{"id": "10721076", "url": "https://en.wikipedia.org/wiki?curid=10721076", "title": "Grease trap", "text": "Grease trap\n\nA grease trap (also known as grease interceptor, grease recovery device and grease converter) is a plumbing device (a type of trap) designed to intercept most greases and solids before they enter a wastewater disposal system. Common wastewater contains small amounts of oils which enter into septic tanks and treatment facilities to form a floating scum layer. This scum layer is very slowly digested and broken down by microorganisms in the anaerobic digestion process. Large amounts of oil from food preparation in restaurants can overwhelm a septic tank or treatment facility, causing release of untreated sewage into the environment. High-viscosity fats and cooking grease such as lard solidify when cooled, and can combine with other disposed solids to block drain pipes.\n\nGrease traps have been used since Victorian days: Nathaniel Whiting obtained the first patent in the late 1800's. The traps reduce the amount of fats, oils and greases (FOGs) that enter sewers. They comprise boxes within the drain run that flows between the sinks in a kitchen and the sewer system. They only have kitchen waste water flowing through them, and do not serve any other drainage system, such as toilets. They can be made from many different materials, such as stainless steel, plastics, concrete & cast iron. They range from 35 liter capacity to 45,000 liters and greater. They can be located above ground, below ground, inside the kitchen or outside the building.\n\nThere are three primary types of device. The most common are those specified by ASME (American Society Of Mechanical Engineers), utilizing baffles, or a proprietary inlet diffuser. \nGrease trap sizing is based on the size of the 2- or 3-compartment sink, dishwasher, pot sinks, and mop sinks. The cumulative flow rates of these devices, as well as overall grease retention capacity (in pounds or kilograms) are considered. Currently, ASME Standard (ASME A112.14.3) is being adopted by both of the National Model Plumbing Codes that cover most of the US. This standard requires that grease interceptors remove a minimum of 90% of incoming FOGs. It also requires that grease interceptors are third-party tested and certified to 90 days compliance with the standard pumping. This third-party testing must be conducted by a recognized and approved testing laboratory.\n\nThe most common passive grease traps are smaller, point-of-use units used under three-compartment sinks or adjacent to dishwashers in kitchens.\n\nThe second most common type of interceptor is the large in-ground tank, which is usually . These units are constructed of concrete, fiberglass or steel. They have greater grease and solid storage capacities for high-flow applications such as a restaurant or hospital store. They are commonly called gravity interceptors. Interceptors require a retention time of 30 minutes to allow the fats, oils, grease and food solids to settle in the tank. As more waste water enters the tank, the grease-free water is pushed out of the tank. The rotting brown grease inside a grease trap or grease interceptor must be pumped out on a scheduled basis. The brown grease is not recycled and goes to landfill. On average of brown grease goes to landfill annually from each restaurant.\n\nA third system type, GRDs (grease recovery devices), removes the grease automatically when trapped. The recovered grease or \"yellow grease\" is recycled with the waste vegetable oil from the kitchen's deep-fryers. Restaurants need not effect grease trap pumping as do restaurants with conventional grease traps or grease interceptors. \n\nPassive grease traps and passive grease interceptors must be emptied and cleaned when 25% full. As the passive devices fill with fats, oils, and grease, they become less productive for grease recovery. A full grease trap does not stop any FOG from entering the sanitary sewer system. The emptied contents or \"brown grease\" is considered hazardous waste in many jurisdictions.\n\nRestaurant and foodservice kitchens produce much waste grease which is present in the drain lines from various sinks, dishwashers and cooking equipment such as combi ovens and commercial woks. If not removed, the grease can clump and cause blockage and back-up in the sewer.\n\nIn the US, sewers back up annually “an estimated 400,000 times, and municipal sewer overflows on 40,000 occasions”. The EPA has determined that sewer pipe blockages are the leading cause of sewer overflows, and grease is the primary cause of sewer blockages. Even if accumulated FOG does not escalate into blockages and sanitary sewer overflows, it can disrupt wastewater utility operations and increase operations and maintenance requirements” \n\nFor these reasons, depending on the country, nearly all municipalities require commercial kitchen operations to use some type of interceptor device to collect grease before it enters sewers. Where FOG is a concern in the local wastewater system, communities have established inspection programs to ensure that these grease traps and/or interceptors are being routinely maintained.\n\nIt is estimated 50% of all sewer overflows are caused by grease blockages, with over of raw sewage spills annually.\n\nWhen the outflow from the kitchen sink enters the grease trap, the solid food particles sink to the bottom, while lighter grease and oil floats to the top. The relatively grease-free water is then fed into the normal septic system. The food solids at the bottom and floating oil and grease must be periodically removed in a manner similar to septic tank pumping. A traditional grease trap is not a food disposal unit. Unfinished food must be scraped into the garbage or food recycling bin. Milkshakes, gravy, sauces and food solids must be scraped off dishes before entering the sink or dishwasher.\n\nTo maintain some degree of efficiency, there has been a trend to specify larger traps. Unfortunately, providing a large tank for the effluent to stand also means that food waste has time to settle to the bottom of the tank, reducing available volume and adding to clean-out problems. Also, rotting food contained within an interceptor breaks down, producing toxic waste (such as sulfur gases) - hydrogen sulfide combines with the water present to create sulfuric acid. This attacks mild steel and concrete materials, resulting in \"rot out\", On the other hand, polyethylene has acid-resisting properties. A bigger interceptor is not a better interceptor. In most cases, multiple interceptors in series will separate grease much better.\n\nBecause it has been in the trap for some time, grease thus collected will be contaminated and is unsuitable for further use. This type of grease is called brown grease.\n\nWaste from passive grease traps and gravity interceptors is called brown grease. Brown grease is rotted food solids in combination with fats, oils, and grease (FOG). Brown grease is pumped from the traps and interceptors by grease pumping trucks. Unlike the collected yellow grease, the majority of brown grease goes to landfill sites. New facilities (2012) and new technology are beginning to allow brown grease to be recycled.\n\n"}
{"id": "15789647", "url": "https://en.wikipedia.org/wiki?curid=15789647", "title": "Guided bone and tissue regeneration", "text": "Guided bone and tissue regeneration\n\nGuided bone regeneration or GBR, and guided tissue regeneration or GTR are dental surgical procedures that use barrier membranes to direct the growth of new bone and gingival tissue at sites with insufficient volumes or dimensions of bone or gingiva for proper function, esthetics or prosthetic restoration.\n\nGBR is similar to guided tissue regeneration (GTR) but is focused on development of hard tissues in addition to the soft tissues of the periodontal attachment. At present, guided bone regeneration is predominantly applied in the oral cavity to support new hard tissue growth on an alveolar ridge to allow stable placement of dental implants. Bone grafting used in conjunction with sound surgical technique, GBR is a reliable and validated procedure.Guided bone regeneration typically refers to ridge augmentation or bone regenerative procedures; guided tissue regeneration typically refers to regeneration of periodontal attachment. \nUse of barrier membranes to direct bone regeneration was first described in the context of orthopaedic research 1959. The theoretical principles basic to guided tissue regeneration were developed by Melcher in 1976, who outlined the necessity of excluding unwanted cell lines from healing sites to allow growth of desired tissues. Based on positive clinical results of regeneration in periodontology research in the 1980s, research began to focus on the potential for re-building alveolar bone defects using guided bone regeneration. The theory of Guided tissue regeneration has been challenged in dentistry. \nThe GBR principle was first examined by Dahlin et al. in 1988 on rats.\nThe selective ingrowth of bone-forming cells into a bone defect region could be improved if the adjacent tissue is kept away with a membrane; this was confirmed in a study by Kosopoulos and Karring in 1994.\nGBR can be used for bone regeneration on exposed implant coils . Recent studies have shown greater attachment gain for guided tissue regeneration (GTR) over open flap debridement. However, this systematic review has shown that the outcomes following GTR are highly variable, both between and within studies. Therefore, patients and health professionals need to consider the predictability of the technique compared with other methods of treatment before making final decisions on use.\n\nFour stages are used to successfully regenerate bone and other tissues, abbreviated with the acronym PASS:\n\nThe first application of barrier membranes in the mouth occurred in 1982 in the context of regeneration of periodontal tissues via GTR, as an alternative to resective surgical procedures to reduce pocket depths.\nBarrier membrane is utilized in GBR technique to cover the bone defect and create a secluded space, which prevents the connective tissue from growing into the space and facilitates the growth priority of bone tissue.\n\nBarrier membrane criteria should be as follows: \n\nSeveral surgical techniques via GBR have been proposed regarding the tri-dimensional bone reconstruction of the severely resorbed maxilla, using different types of bone substitutes that have regenerative, osseoinductive or osseoconductive properties which is then packed into the bony defect and covered by resorbable membranes. In cases where augmentation materials used are autografts or allografts the bone density is quite low and resorption of the grafted site in these cases can reach up to 30% of original volume. For higher predictability, nonresorbable titanium-reinforced d-polytetrafluoroethylene (d-PTFE) membranes—as a barrier against the migration of epithelial cells within the grafted site—are recommended. In patients with systemic problems interdisciplinary collaboration is indicated to adjust therapy background so that it does not adversely affect implanto-prosthetic treatment. Current treatments for destructive periodontal\n\ndisease are not able to restore damaged bone and connective tissue support for teeth (infra-bony defects). There are limitations in treating patients with advanced disease but GTR may be able to achieve regeneration and therefore improve upon conventional surgical results.\n\nTwo types of membranes based on the characteristics and resorbability.\n\nResorbable:\n\nThere are many different types of resorbable membranes out there but the main ones are synthetic polymers and natural biomaterials. Synthetic polymers are such that it is a polylactic acid bilayer, or the collagen-derived membranes. These membranes can be obtained from bovine or porcine or dermis. E.g. Emdogain which has been shown to significantly improve probing attachment levels (1.1mm) and periodontal pocket depth reduction (0.9mm) when compared to a placebo or control materials. Resorption rates ranging from six to 24 weeks depending on its different chemical structures. With the resorbable membrane used, the membrane will bio-degrade. There is no need for a second surgery to remove the membrane, this will prevent any disruption to the healing process of the regenerated tissues. A synthetic resorbable membrane indicated an amount of stable augmented bone similar to that of a collagen resorbable membrane. These are the results obtained based on a randomised clinical trial done to compare the stability of augmented bone between a synthetic resorbable membrane and a collagen membrane with guide bone regeneration simultaneous with dental implant placement in the aesthetic zone in terms of facial bone thickness.\n\nThere are several uses of bone regeneration:\n\n\n\n"}
{"id": "20911779", "url": "https://en.wikipedia.org/wiki?curid=20911779", "title": "Gynaecologic cytology", "text": "Gynaecologic cytology\n\nGynecologic cytology, also Gynecologic cytology, is a field of pathology concerned with the investigation of disorders of the female genital tract. \n\nThe most common investigation in this field is the Pap test, which is used to screen for potentially precancerous lesions of the cervix. Cytology can also be used to investigate disorders of the ovaries, uterus, vagina and vulva.\n"}
{"id": "26091647", "url": "https://en.wikipedia.org/wiki?curid=26091647", "title": "Helmuth Orthner", "text": "Helmuth Orthner\n\nDr. Helmuth F. \"Helly\" Orthner (March 27, 1941 – March 16, 2009) was a pioneering American scientist in the field of medical informatics. He was one of the founders of the Symposium on Computer Applications in Medical Care (SCAMC), which later grew into the American Medical Informatics Association. He was a Fellow of the American College of Medical Informatics.\n\n"}
{"id": "25524868", "url": "https://en.wikipedia.org/wiki?curid=25524868", "title": "Indonesian Red Cross Society", "text": "Indonesian Red Cross Society\n\nThe Indonesian Red Cross Society () is a humanitarian organization in Indonesia. It is a member of International Federation of Red Cross and Red Crescent Societies.\n\nIndonesia is the one of the very few Muslim-majority countries to use the Red Cross as its symbol. Because Indonesia is neither a strictly faith-based nor secular nation, it has chosen to use the Red Cross as its symbol.\n\nIn mid-2013, the Indonesian Red Cross Society had 32,568 people in its Volunteer Corps, 19,294 Individual Volunteers and 893,381 Blood Donor Volunteers, for a total of 945,243 persons, which is recorded as the highest number of volunteers in the world.\n\nThe IRCS was created on 17 September 1945, exactly one month after Indonesia's independence. President Sukarno ordered its inception when a battle between Indonesian soldiers and allied troops broke out, leaving many wounded, on 3 September 1945. Based on the performance, IRCS received an international recognition in 1950 that it was accepted as a member of the International Red Cross and achieved its legal status through Presidential Decree Number 25 Year 1959, which was later reinforced by Presidential Decree Number 245 Year 1963.\n\nThe IRCS central headquarters is located at Jl. Jenderal Gatot Soebroto Kav. 96, Jakarta 12790.\n\n\n"}
{"id": "26394003", "url": "https://en.wikipedia.org/wiki?curid=26394003", "title": "Interklinik Bratislava", "text": "Interklinik Bratislava\n\nInterklinik Bratislava is a clinic based in the capital of the Slovak Republic, Bratislava. Established in 1995, it consists of over 1,000 square meters of operating rooms, ambulances, inpatient rooms and spa.\n\nInterklinik constist of a number of interconnected companies, several ones of which are in default- their net equity is negative. \nThe Interklinik companies in default as of June 2018 are:\nINTERKLINIK SPA s.r.o. and \nINTERKLINIK VITAL s.r.o. . \n\nAs of June 2018, there are creditors publicly seeking other creditors for the purposes of joint action/acquisition of debt.\n\nInterklinik was established in 1994 as a clinic specialising in several areas of surgery. Under the auspices of its new director Tomas Stern, M.D. it later moved to the city-center of Bratislava and increased its scope of specialisations, including stomatology and medical spa treatments. The company offering spa treatments- Interklinik SPA s.r.o., is currently in default.\n\nMr. Tomas Stern is currently the sole director of INTERKLINIK VITAL s.r.o. and one o the directors of INTERKLINIK SPA s.r.o. \n\nToday the clinic is situated at Einsteinova street in the Petržalka district.\n\n"}
{"id": "18054690", "url": "https://en.wikipedia.org/wiki?curid=18054690", "title": "Intravenous marijuana syndrome", "text": "Intravenous marijuana syndrome\n\nIntravenous marijuana syndrome is a distinct short-term clinical syndrome related to the intravenous injection of boiled cannabis broth, which had been filtered through a cotton cloth. The syndrome has at least 25 known cases in the English language literature, but all of them prior to 1983.\n\nIt is postulated that contamination, perhaps from the cotton used to strain the liquid of the broth or from particulate plant matter getting through the straining method, could be cause for the cases of illnesses.\n\nThe common side effects of intravenous marijuana syndrome include fever, myalgia, nausea, and vomiting.\n\n"}
{"id": "250029", "url": "https://en.wikipedia.org/wiki?curid=250029", "title": "Iron poisoning", "text": "Iron poisoning\n\nIron poisoning is an iron overload caused by a large excess of iron intake and usually refers to an acute overload rather than a gradual one. The term has been primarily associated with young children who consumed large quantities of iron supplement pills, which resemble sweets and are widely used, including by pregnant women; approximately 3 grams is lethal for a two-year-old. Targeted packaging restrictions in the US for supplement containers with over 250 mg elemental iron have existed since 1978, and recommendations for unit packaging have reduced the several iron poisoning fatalities per year to almost zero since 1998. No known cases of iron poisoning have been identified that are associated with iron mining.\n\nThe first indication of iron poisoning by ingestion is stomach pain, as iron is corrosive to the lining of the gastrointestinal tract, including the stomach. Nausea and vomiting are also common symptoms and bloody vomiting may occur. The pain then abates for 24 hours as the iron passes deeper into the body, resulting in metabolic acidosis, which in turn damages internal organs, particularly the brain and the liver. Iron poisoning can cause hypovolemic shock due to iron's potent ability to dilate the blood vessels. Death may occur from liver failure.\n\nIf intake of iron is for a prolonged period of time, symptoms are likely to be similar to other causes of iron overload.\n\nIn nature, iron is usually found in its oxidized form, iron (III) oxide, which is insoluble. Ferrous iron, iron (II), is soluble and its toxicity varies, largely with the integrity of the gastrointestinal lining. Iron supplements are typically used to treat anemia. Modalities include: diet, parasite control, vitamin A, riboflavin (B), vitamin C (for absorption), folate(B), vitamin B and multivitamin-multimineral supplements, with or without iron; potentially avoiding the use of iron only supplements.\n\nThe amount of iron ingested may give a clue to potential toxicity. The therapeutic dose for iron deficiency anemia is 3–6 mg/kg/day. Toxic effects begin to occur at doses above 10–20 mg/kg of elemental iron. Ingestions of more than 50 mg/kg of elemental iron are associated with severe toxicity.\n\n\nIn terms of blood values, iron levels above 350–500 µg/dL are considered toxic, and levels over 1000 µg/dL indicate severe iron poisoning.\n\nA detail history of the ingestion especially the number of pills taken can be vital. Diagnosis of iron poisoning can be made in the absence of a specific history by clinical judgment, imagining investigation and lab assessment. Iron tablets may be imaged by radiography. Serum iron levels can be tested and are useful regarding the administration of iron-binding ligands such as deferoxamine. Clinic presentation in the absence of treatment follows in stages and is dose dependent (how much iron was taken):,\nLater stage treatment consists of cleaning the iron from the blood, using a chelating agent such as deferoxamine. If this fails then dialysis is the next step.\n\n\n"}
{"id": "5918527", "url": "https://en.wikipedia.org/wiki?curid=5918527", "title": "José Pampuro", "text": "José Pampuro\n\nJosé Juan Bautista Pampuro (born December 28, 1949) is an Argentine politician. He is a member of the Justicialist Party, was formerly a Defense Minister and is currently a senator for Buenos Aires Province. He serves as the Senate provisional President and is second in line for the presidential succession.\n\nPampuro was born in Buenos Aires in 1949. He enrolled at the University of Buenos Aires and earned a Medical Degree. He entered public service in 1983, when he was named Public Health Secretary to the Mayor of Lanús, Manuel Quindimil. He was elected to the Lower House of Congress on the populist Justicialist Party ticket in 1987, and was named Minister of Health and Social Policy for Buenos Aires Province by newly elected Governor Eduardo Duhalde in 1991.\n\nHe was named director of the Buenos Aires Provincial Office (each Argentine province maintains one in the nation's capital) in 1993, and remained in the post until being returned by voters to Congress in 1999. Eduardo Duhalde, appointed President of Argentina by Congress during a crisis in 2002, named Pampuro Chief of Staff, and on May 25, 2003, he was retained in government by President Néstor Kirchner, who named Pampuro his first Defense Minister.\n\nPampuro was elected to the Senate on the Front for Victory slate alongside Cristina Fernández de Kirchner in the 2005 mid-term elections, in which the center-left Front for Victory did well. He was elected Provisional President of the Senate on February 22, 2006, putting him second in line to the presidency, and twice as President of the Mercosur Parliament (during the first half of 2008 and the first half of 2010).\n\nPampuro retired from the Senate in 2011 with the distinction of being the first man in Argentina to twice be succeeded by women who were first to hold their respective posts: as Defense Minister by Nilda Garré, and as Provisional President of the Senate by Beatriz Rojkés de Alperovich.\n"}
{"id": "56039834", "url": "https://en.wikipedia.org/wiki?curid=56039834", "title": "Kafbikh", "text": "Kafbikh\n\nKafBikh or KafBeex in Persian(کفبیخ)is a kind of traditional sweet in Khorasan in Iran specially in the city of Gonabad. In part of Iran there are some special classical traditions specially for the night of yalda. during this longest night in south Khorasan family are gathering to provide a kind of sweet called Kaf.\n\nThe sweet Kaf is based on the root of Acanthophyllum squarrosum the root should be cleaned and boiled at least three times and the boiled water be discarded until the water has a good smell and good taste.\n\nDuring this ceremony, the root of the plant called \"Chubak\", or Bikh which is known as Acanthophyllum , is soaked in water and after several boils, they are shed in a large pot called \"Tegar\". Families and men, with a handful of thin pods of pomegranate trees, called the \"batches\" shake of the liquid, for hours, to become rigid, and this should be done in a cool environment so that the liquid is foamed and then hardened to dry. Like Isfahan Gaz\nThe prepared Kaf is prepared at the end by mixing the juice or sugar, and after being decorated, the walnut and pistachio are taken to the guests. In the meantime, a group of young are allowed to sweeten the kaf by throwing it to each other and rubbing the kaf to face of each other adding happiness to the guests.\n\nAnother custom performed in certain parts of Iran and khorasan on the night of yalda (Chelleh) involves young engaged couples. The men send an edible arrangement containing seven kinds of fruits and a variety of gifts to their fiancees on this night. In some areas, the girl and her family return the favor by sending gifts back for the young man.\n\n\n"}
{"id": "4344101", "url": "https://en.wikipedia.org/wiki?curid=4344101", "title": "Lalonde report", "text": "Lalonde report\n\nThe Lalonde Report is a 1974 report produced in Canada formally titled \"A new perspective on the health of Canadians\". It proposed the concept of the \"health field\", identifying two main health-related objectives: the health care system; and prevention of health problems and promotion of good health. The report is considered the \"first modern government document in the Western world to acknowledge that our emphasis upon a biomedical health care system is wrong, and that we need to look beyond the traditional health care (sick care) system if we wish to improve the health of the public.\"\n\nMarc Lalonde, who was the Canadian Minister of National Health and Welfare in 1974, proposed a new \"health field\" concept, as distinct from medical care. Lalonde noted that the \"traditional or generally-accepted view of the health field is that the art or science of medicine has been the fount from which all improvements in health have flowed, and popular belief equates the level of health with the quality of medicine.\" The new concept \"envisage[d] that the health field can be broken up into four broad elements: Human biology, Environment, Lifestyle, and Health care organization;\" that is, determinants of health existed outside of the health care systems.\n\nThe report was written by a group of civil servants led by Hubert (Bert) Laframboise.\n\nThe report is considered to have led to the development and evolution of health promotion, recognizing both the need for people to take more responsibility in changing their behaviors to improve their own health, and also the contribution of healthy communities and environments to health.\n\nAnother innovation of the report was that it proposed that public health interventions should focus attention on that segment of the population with the highest level of risk exposure. It this sense, the report was fundamental in identifying health risk behaviours as a determinant of health inequalities.\n\nThe proposals advocated by the report seem to have had mixed outcomes; while its nutritional and exercise recommendations are believed to have been widely accepted, there remains disagreement about its overall impact on population health. It has been argued such debates highlight the need for a fuller exploration of the health policies in place.\n\nThe concept of the \"health field\", as identified in the Lalonde report, is considered to be composed of four interdependent fields determined to influence individual's health. These include:\n\n\n\n"}
{"id": "16993993", "url": "https://en.wikipedia.org/wiki?curid=16993993", "title": "Life Extension Institute", "text": "Life Extension Institute\n\nThe Life Extension Institute was an organization formed in the United States in 1913 with the philanthropic goal of prolonging human life through hygiene and disease prevention. Its organizational officers included many celebrity-philanthropists such as William Howard Taft, Alexander Graham Bell, and Mabel Thorp Boardman but also genuine medical experts including William James Mayo, Russell Henry Chittenden, and J. H. Kellogg and a \"Hygiene Reference Board\" of dozens of nationally recognized physicians of that era such as Mazÿck Porcher Ravenel and Major General William Crawford Gorgas.\n\nA major project of the institute which fulfilled its mission to disseminate knowledge was publication of the book \"How to Live, Rules for Healthful Living Based on Modern Science\", now in the public domain.\n\nThe institute was a proponent of eugenics including sterilization of grossly \"unfit\" individuals:\n"}
{"id": "7238159", "url": "https://en.wikipedia.org/wiki?curid=7238159", "title": "List of United Nations Security Council resolutions concerning Cyprus", "text": "List of United Nations Security Council resolutions concerning Cyprus\n\nThe United Nations Security Council (UNSC) is the organ of the United Nations charged with maintaining peace and security among nations. While other organs of the United Nations only make recommendations to member governments, the Security Council has the power to make decisions; which member governments must carry out if they fall under Chapter VII of the under the United Nations Charter. The decisions of the Council are known as United Nations Security Council Resolutions.\n\nA UN member State, is obligated to respect the United Nations Charter and UN members are bound by its articles. Cyprus claims that Turkey violates the charter against Republic of Cyprus. Turkey does not recognize the continued existence of the Republic of Cyprus, as established by the London and Zurich Agreements Turkey refers to the Republic of Cyprus as the \"Greek Cypriot administration\" or \"South Cyprus\". \n\nIn 1974 Turkey invaded Cyprus, after a military coup staged by the Greek Junta against the lawfully elected Government of Cyprus under President Makarios. The Turkish army subsequently occupied ~38% of the territory of the island which to this day remains de facto divided with \"Turkish Republic of Northern Cyprus\" (TRNC) proclaimed in 1983 following a UDI by the Turkish Cypriots. The \"TRNC\" is an illegal entity as per UN Security Council Resolutions UN Security Council Resolution 541 and UN Security Council Resolution 550 and is recognized only by Turkey. The latter has, subsequently, been condemned by the \"European Court of Human Rights\" (ECHR) for human rights violations in Cyprus.\n\n\n\n\n\n"}
{"id": "40401585", "url": "https://en.wikipedia.org/wiki?curid=40401585", "title": "Mahamaya Chhara Irrigation Extension Project", "text": "Mahamaya Chhara Irrigation Extension Project\n\nMahamaya irrigation project () is an irrigation project in Bangladesh situated at Durgapur Union, Mirsharai Upazila, Chittagong. Initiated in the 2007-2008 financial year, the project provides irrigation water to a 3360 hectare area. It cost about 230 million taka and construction was completed in 2009. This project was inaugurated by Prime Minister Sheikh Hasina on 29 December 2010. It is the second largest man made lake in Bangladesh after Kaptai Lake.\n\nThe project also provided recreational areas.\n\nGovernment is also planning to install a 50 kW mini hydro electric powerplant here.\n\n"}
{"id": "27766311", "url": "https://en.wikipedia.org/wiki?curid=27766311", "title": "McKenzie method", "text": "McKenzie method\n\nThe McKenzie method (also MDT = Mechanical Diagnosis and Therapy) is a comprehensive method of care primarily used in physical therapy.\n\nNew Zealand physical therapist Robin McKenzie, OBE (1931–2013) developed the method in the late 1950s. In 1981 he launched the concept which he called \"Mechanical Diagnosis and Therapy (MDT)\" – a system encompassing assessment (evaluation), diagnosis and treatment for the spine and extremities. MDT categorises patients' complaints not on an anatomical basis, but subgroups them by the clinical presentation of patients.\n\nThe McKenzie method consists of two components used to treat musculoskeletal conditions: assessment and intervention. The assessment component of the McKenzie method uses repeated movements and/or sustained postures in a single direction to elicit centralisation. In spinal patients centralisation refers to a pattern of pain level response which is characterised by decreased or abolished pain symptoms, experienced sequentially, first to the left and right of the spine (distal symptoms), and ultimately abolished pain symptoms in the spine altogether.\n\nThe assessment portion attempts to discover “directional preference”, which identifies the pattern of lumbosacral movement in a single direction that effectively results in centralisation and subsequent abolishment of pain symptoms in the spine and the return of proper range of motion.\n\nThe intervention component of the McKenzie method is the corresponding repeated and/or sustained flexion and extension movements as prescribed by the assessment component.\n\n‘‘Everything I know I learnt from my patients. I did not set out to develop a McKenzie method. It evolved spontaneously over time as a result of clinical observation’’ - Doctor Robin McKenzie.\n\nThe McKenzie method has its roots in a single event in 1956 that led to increased experimentation of certain movement in order to elicit what is now known as the centralisation phenomenon. A patient who was experiencing pain on the right side of his lower back buttock, laid down on doctor McKenzie's treatment table. The patient ended up lying in significant lumbar extension for around five minutes, meaning his back was bending backwards because the head of the table had been raised for a previous patient. After ceasing this sustained position in lumbar extension the patient noted the pain on the right side of his body had experienced surprising and significant improvement.\n\nThis led McKenzie to continuously experiment with specific movement and movement patterns to treat chronic lower back pain and bring about centralisation of pain symptoms. Over the years of experimentation in Robin McKenzie’s career, he noted patterns of symptom relief in response to prescribed spinal movements and positions and developed a classification system to categorise spinal pain problems. McKenzie went on to write and publish books so people could manage and treat their own back pain, such as “Treat Your Own Back” first published in 1980, with the latest edition being published in 2011.\n\nThe McKenzie Method also referred to as Mechanical Diagnosis and Therapy is a method of assessing and treating spinal back pain and related extremity pain most commonly through the use of specific repeated movements and appropriate prevention measures. The method puts an emphasis on self-care after initial clinical visits. There are four major steps when it comes to proper McKenzie method therapy: assessment, classification, treatment, and prevention.\n\nThe assessment or evaluation procedure determines the type of movements that result in centralisation and reduction in pain.\n\nMDT uses primarily self treatment strategies, and minimises manual therapy procedures, with the McKenzie trained therapist supporting the patient with passive procedures only if an individual self treatment program is not fully effective.\n\nMcKenzie states that self treatment is the best way to achieve a lasting improvement of back pain and neck pain.\n\nCentralisation plays an enormous role to treating patients with lower back pain with the McKenzie method.\n\nCentralisation occurs when Pain symptoms off-centred from the mid-line of the spine, often diagnosed as sciatica, migrate towards the centre of the mid-line of the spine. This migration of pain symptoms to the centre of the lower back is a sign of progress in the McKenzie method. A patient has found their directional preference once they discover which repeated end-range exercise movements elicit centralisation of pain symptoms. The most common directional preference that result in centralisation is extension of the back. In many cases extension exercises are commonly referred to as McKenzie exercises for this very reason.\n\nAccording to the McKenzie method, movements and exercises that produce centralisation are very beneficial whereas movements that create pain that wander from the spinal mid-line are extremely detrimental to a patients specific condition. A 2012 systematic review found that lumbar centralisation was associated with a better recovery prognosis in terms of pain, short- and long-term disability, and the likelihood of undergoing surgery in the following year\n\nThe first step is understanding a patients symptoms and how they behave. Such as where patient feels pain and when, how often in a day, to what degree, and in what specific movements or positions does pain intensify or express itself. The patient will be tested and asked by a clinician to perform specific single direction movement, both sustained and repeated. A large differentiator from other physical therapy methods of assessment is the use of repeated movements. A range of single direction movements are used in this phase of the McKenzie method, depending on how pain symptoms behave and change will allow the clinician to categorise the problem to effectively prescribe the proper movements to achieve centralisation and elimination of spinal and sciatic pain.\n\nThere are three primary classifications that result from the assessment portion of the McKenzie method's comprehensive approach; Postural syndrome, dysfunction syndrome, and derangements syndrome with a minority of patients falling into an 'other category. Each classification represents the likely underlying reason of experienced pain symptoms and symptom behaviour. The classification process is very important because it determines if the McKenzie method is an appropriate approach for specific patients and also determines which movement and protocols will most likely lead to centralisation and a cessation or reduction of pain symptoms. Each syndrome corresponds to specific mechanical procedures.\n\nDepending on the classification and the nature of the underlying cause of disablement, certain treatment protocols are used. Depending on classification type and directional preference, patients perform specific exercises to end-range. There will be limited mobility and the position will likely cause discomfort, but the patient repeats the exercises one after the other until centralisation occurs, pain symptoms subside, and mobility to end-range increases.\n\nThe most common treatment classification. Defined by pain that is experienced due to a disturbance in the joint area resulting in diminished movement in certain directions. Depending on a patients specific directional preference as discovered in the assessment stage of the McKenzie method, patients are prescribed to use repeated movements in a single direction that cause a gradual reduction in pain and centralisation of pain symptoms. That is, symptoms of pain from the left and right of the middle-lower back become centralised to the centre of the lower back and over time result in lasting reduction of pain symptom intensity.\n\nThis type of pain is categorised by mechanical impairments and deformities of impaired tissue within the body such as scar tissue or shortened tissues. To treat this treatment classification the goal is to remodel the impaired tissue by mobilisation exercise\n\nThis type of pain is the result of postural deformation. Static holds of improper end-range positions, such as slouching are the cause of postural syndrome. Treatment is more geared towards education and proper posture training rather than repeated exercises as the other syndrome classifications prescribe.\n\nThe last portion of treatment is designed to educate patients to ensure proper continuation of appropriate exercises and correct structural positionings day-to-day. Self-care and proper exercise is stressed and encouraged as prevention methods.\n\nAccording to a meta-analysis of clinical trials in 2006, treatment using the McKenzie method is somewhat effective for acute low back pain, but the evidence suggests that it is not effective for chronic low-back pain. A 2012 systematic review agreed with this, finding that centralisation occurred more frequently in acute patients (74%) compared to subacute (50%) and chronic (40%). Also, centralisation was found to be more common in younger patients. Cervical centralisation was observed in only 37% of patients.\n\nThere have also been other reviews of the literature.\n\nA 2006 systematic review into the clinical evidence of the McKenzie method's ability to treat spinal pain concluded that the McKenzie method decreased short-term (<3 months) to a higher degree than other standard treatments including: \"nonsteroidal anti-inflammatory drugs, educational booklet, back massage with back care advice, strength training with therapist supervision, and spinal mobilization\". At the intermediate term follow-up there was no statistical differences among therapies.\n\nA report published in 2008 noted only marginal benefits over an assessment and advice-only group at the short-term follow up mark, 6 month, and 1 year.\n\nA 2010 study concluded that the McKenzie method \"does not produce appreciable additional short-term improvements in pain, disability, function or global perceived effect\".\n\nA 2006 systematic review of the literature assessed whether or not the McKenzie method treated Lower back pain more effectively than passive therapy, advice to stay active, flexion exercises, and others. The assessment concluded that there were no clinically significant benefits compared with the passive therapy and advice to stay active in those with acute lower back pain\n\nThe McKenzie method is commonly used worldwide in diagnosis and treatment of low back pain, and peripheral joint complaints.\n\n\n"}
{"id": "41337387", "url": "https://en.wikipedia.org/wiki?curid=41337387", "title": "National Lung Screening Trial", "text": "National Lung Screening Trial\n\nThe National Lung Screening Trial was a United States-based clinical trial which recruited research participants between 2002-2004. It was sponsored by the National Cancer Institute and conducted by the American College of Radiology Imaging Network and the Lung Screening Study Group. The major objective of the trial was to compare the efficacy of low-dose helical computed tomography (CT screening) and standard chest X-ray as methods of lung cancer screening. The primary study ended in 2010, and the initial findings were published in November 2010, with the main results published in 2011 in the \"New England Journal of Medicine\".\n\nThe trial led to a recommendation in the United States in 2013 that CT screening be used on people at high risk for developing lung cancer in an effort to detect the cancer earlier and reduce mortality. In December 2013 the U.S. Preventative Services Task Force (USPSTF) changed its long-standing recommendation that there is insufficient evidence to recommend for or against screening for lung cancer to the following: \"The USPSTF recommends annual screening for lung cancer with low-dose computed tomography in adults ages 55 to 80 years who have a 30 pack-year smoking history and currently smoke or have quit within the past 15 years. Screening should be discontinued once a person has not smoked for 15 years or develops a health problem that substantially limits life expectancy or the ability or willingness to have curative lung surgery\".\n\nThe study looked at 53,454 current or former heavy smokers from 33 medical centers in the US. The ages of the patients in the trial varied from 55 to 74. When their initial findings were published in the \"New England Journal of Medicine\", the researchers reported that low-dose CT scanning was associated with a 20% decrease in deaths from lung cancer, and that this effect was visible in both current smokers and former smokers. More recent research based on this trial, published in \"JAMA Internal Medicine\", has found that low-dose computed tomography detects many false positives—in the study, 18% of total detections were considered to be an overdiagnosis, i.e. the cancer would never have threatened the life of the patient.\n\nThe National Cancer Institute funded a $300m study, the National Lung Screening Trial (NLST), which began in 2002, to compare the effectiveness of CT scan screening versus X-ray screening. This study, too, raised concern in the media over potential conflicts of interest related to the tobacco company, although this time on the contra-CT scan side: on October 8, 2007, the \"Wall Street Journal\" reported that at least two lead investigators of the study had conflicts of interest arising from their serving as paid, expert defense witnesses for the tobacco industry – one of them had given testimony asserting that promoting CT screening was \"reckless or irresponsible\", and another had provided an expert report warning that CT screening \"may do more harm than good.\"\n\nDeaths in either group were then logged for up to five years. As of October 2010, 354 people in the CT scan group had died from lung cancer, versus 442 people in the X-ray group; in other words, deaths in the CT scan group of patients were 20.3% lower than in the X-ray group. The study's review board concluded that this difference was statistically significant and recommended terminating the study. The director of the National Cancer Institute's director, Harold Varmus, said that early analysis results appeared to indicate that CT scans detected more lung cancers, at an earlier and more treatable stage, and that CT scans could therefore reduce the number of deaths in patients at high risk of lung cancer.\n\nThe trial's main result is here:\n\n"}
{"id": "34123709", "url": "https://en.wikipedia.org/wiki?curid=34123709", "title": "Occupational health nursing", "text": "Occupational health nursing\n\nOccupational health nursing is a specialty nursing practice that provides for and delivers health and safety programs and services to workers, worker populations, and community groups. The practice focuses on promotion, maintenance and restoration of health, prevention of illness and injury, and protection from work‐related and environmental hazards. Occupational health nurses (OHNs) aim to combine knowledge of health and business to balance safe and healthful work environments and a \"healthy\" bottom line.\n\nAs of 2012, there were approximately 19,000 occupational health nurses in the US. Occupational health nurse training in the U.S. is supported by the National Institute for Occupational Safety and Health through the NIOSH Education and Research Centers.\n\n\nCanadian Occupational Health Nursing Association-Association Canadienne des Infirmieres et Infiriers en Sante du Travail Inc\n(AOHNA) Alberta Occupational Health Nurses Association\n"}
{"id": "33103070", "url": "https://en.wikipedia.org/wiki?curid=33103070", "title": "Paraveterinary workers in Norway", "text": "Paraveterinary workers in Norway\n\nParaveterinary workers in Norway, known as \", include veterinary nurses, veterinary technicians and veterinary assistants.\n\nThese workers are represented by the Norwegian Veterinary Nurse and Assistant Association (NDAF—\"Norsk Dyrepleier og Assistent Forening\"). The Norwegian veterinary nurse/technician education is a two-year university-level program taught exclusively at the Norwegian School of Veterinary Science. Prior to 2003 it was a one-year program followed by one year of practical experience. \n\nNurse/technician graduates of the school must apply for an official authorisation issued from the Norwegian Food Safety Authority (\"Mattilsynet\") in order to use the title \"\"Dyrepleier\".\n\n"}
{"id": "24579", "url": "https://en.wikipedia.org/wiki?curid=24579", "title": "Pelvic inflammatory disease", "text": "Pelvic inflammatory disease\n\nPelvic inflammatory disease, also known as pelvic inflammatory disorder (PID), is an infection of the upper part of the female reproductive system namely the uterus, fallopian tubes, and ovaries, and inside of the pelvis. Often there may be no symptoms. Signs and symptoms, when present may include lower abdominal pain, vaginal discharge, fever, burning with urination, pain with sex, or irregular menstruation. Untreated PID can result in long term complications including infertility, ectopic pregnancy, chronic pelvic pain, and cancer.\nThe disease is caused by bacteria that spread from the vagina and cervix. Infections by \"Neisseria gonorrhoeae\" or \"Chlamydia trachomatis\" are present in 75 to 90 percent of cases. Often multiple different bacteria are involved. Without treatment about 10 percent of those with a chlamydial infection and 40 percent of those with a gonorrhea infection will develop PID. Risk factors are similar to those of sexually transmitted infections generally and include a high number of sexual partners and drug use. Vaginal douching may also increase the risk. The diagnosis is typically based on the presenting signs and symptoms. It is recommended that the disease be considered in all women of childbearing age who have lower abdominal pain. A definitive diagnosis of PID is made by finding pus involving the fallopian tubes during surgery. Ultrasound may also be useful in diagnosis.\nEfforts to prevent the disease include not having sex or having few sexual partners and using condoms. Screening women at risk for chlamydial infection followed by treatment decreases the risk of PID. If the diagnosis is suspected, treatment is typically advised. Treating a woman's sexual partners should also occur. In those with mild or moderate symptoms a single injection of the antibiotic ceftriaxone along with two weeks of doxycycline and possibly metronidazole by mouth is recommended. For those who do not improve after three days or who have severe disease intravenous antibiotics should be used.\nGlobally about 106 million cases of chlamydia and 106 million cases of gonorrhea occurred in 2008. The number of cases of PID however, is not clear. It is estimated to affect about 1.5 percent of young women yearly. In the United States PID is estimated to affect about one million people yearly. A type of intrauterine device (IUD) known as the Dalkon shield led to increased rates of PID in the 1970s. Current IUDs are not associated with this problem after the first month.\n\nSymptoms in PID range from none to severe. If there are symptoms, then fever, cervical motion tenderness, lower abdominal pain, new or different discharge, painful intercourse, uterine tenderness, adnexal tenderness, or irregular menstruation may be noted.\n\nOther complications include endometritis, salpingitis, tubo-ovarian abscess, pelvic peritonitis, periappendicitis, and perihepatitis.\n\n\"Chlamydia trachomatis\" and \"Neisseria gonorrhoeae\" are usually the main cause of PID. Data suggest that PID is often polymicrobial. Isolated anaerobes and facultative microorganisms have been obtained from the upper genital tract. \"N. gonorrhoeae\" has been isolated from fallopian tubes, facultative and anaerobic organisms were recovered from endometrial tissues.\n\nThe anatomical structure of the internal organs and tissues of the female reproductive tract provides a pathway for pathogens to ascend from the vagina to the pelvic cavity thorough the infundibulum. The disturbance of the naturally occurring vaginal microbiota associated with bacterial vaginosis increases the risk of PID.\n\n\"N. gonorrhoea\" and \"C. trachomati\"s are the most common organisms. The least common were infections caused exclusively by anaerobes and facultative organisms. Anaerobes and facultative bacteria were also isolated from 50 percent of the patients from whom \"Chlamydia\" and \"Neisseria\" were recovered; thus, anaerobes and facultative bacteria were present in the upper genital tract of nearly two-thirds of the PID patients. PCR and serological tests have associated extremely fastidious organism with endometritis, PID, and tubal factor infertility. Microorganisms associated with PID are listed below.\n\nRarely cases of PID have developed in people who have stated they have never had sex.\n\n\nUpon a pelvic examination, cervical motion, uterine, or adnexal tenderness will be experienced. Mucopurulent cervicitis and or urethritis may be observed. In severe cases more testing may be required such as laparoscopy, intra-abdominal bacteria sampling and culturing, or tissue biopsy.\n\nLaparoscopy can visualize \"violin-string\" adhesions, characteristic of Fitz-Hugh–Curtis perihepatitis and other abscesses that may be present.\n\nOther imaging methods, such as ultrasonography, computed tomography (CT), and magnetic imaging (MRI), can aid in diagnosis. Blood tests can also help identify the presence of infection: the erythrocyte sedimentation rate (ESR), the C-reactive protein (CRP) level, and chlamydial and gonococcal DNA probes.\n\nNucleic acid amplification tests (NAATs), direct fluorescein tests (DFA), and enzyme-linked immunosorbent assays (ELISA) are highly sensitive tests that can identify specific pathogens present. Serology testing for antibodies is not as useful since the presence of the microorganisms in healthy people can confound interpreting the antibody titer levels, although antibody levels can indicate whether an infection is recent or long-term.\n\nDefinitive criteria include histopathologic evidence of endometritis, thickened filled Fallopian tubes, or laparoscopic findings. Gram stain/smear becomes definitive in the identification of rare, atypical and possibly more serious organisms. Two thirds of patients with laparoscopic evidence of previous PID were not aware they had PID, but even asymptomatic PID can cause serious harm.\n\nLaparoscopic identification is helpful in diagnosing tubal disease; a 65 percent to 90 percent positive predictive value exists in patients with presumed PID.\n\nUpon gynecologic ultrasound, a potential finding is \"tubo-ovarian complex\", which is edematous and dilated pelvic structures as evidenced by vague margins, but without abscess formation.\n\nA number of other causes may produce similar symptoms including appendicitis, ectopic pregnancy, hemorrhagic or ruptured ovarian cysts, ovarian torsion, and endometriosis and gastroenteritis, peritonitis, and bacterial vaginosis among others.\n\nPelvic inflammatory disease is more likely to reoccur when there is a prior history of the infection, recent sexual contact, recent onset of menses, or an IUD (intrauterine device) in place or if the partner has a sexually transmitted infection.\n\nAcute pelvic inflammatory disease is highly unlikely when recent intercourse has not taken place or an IUD is not being used. A sensitive serum pregnancy test is typically obtained to rule out ectopic pregnancy. Culdocentesis will differentiate hemoperitoneum (ruptured ectopic pregnancy or hemorrhagic cyst) from pelvic sepsis (salpingitis, ruptured pelvic abscess, or ruptured appendix).\n\nPelvic and vaginal ultrasounds are helpful in the diagnosis of PID. In the early stages of infection, the ultrasound may appear normal. As the disease progresses, nonspecific findings can include free pelvic fluid, endometrial thickening, uterine cavity distension by fluid or gas. In some instances the borders of the uterus and ovaries appear indistinct. Enlarged ovaries accompanied by increased numbers of small cysts correlates with PID.\n\nLaparoscopy is infrequently used to diagnose pelvic inflammatory disease since it is not readily available. Moreover, it might not detect subtle inflammation of the fallopian tubes, and it fails to detect endometritis. Nevertheless, laparoscopy is conducted if the diagnosis is not certain or if the person has not responded to antibiotic therapy after 48 hours.\n\nNo single test has adequate sensitivity and specificity to diagnose pelvic inflammatory disease. A large multisite U.S. study found that cervical motion tenderness as a minimum clinical criterion increases the sensitivity of the CDC diagnostic criteria from 83 percent to 95 percent. However, even the modified 2002 CDC criteria do not identify women with subclinical disease.\n\nRegular testing for sexually transmitted infections is encouraged for prevention. The risk of contracting pelvic inflammatory disease can be reduced by the following:\n\n\nTreatment is often started without confirmation of infection because of the serious complications that may result from delayed treatment. Treatment depends on the infectious agent and generally involves the use of antibiotic therapy although there is no clear evidence of which antibiotic regimen is more effective and safe in the management of PID. If there is no improvement within two to three days, the patient is typically advised to seek further medical attention. Hospitalization sometimes becomes necessary if there are other complications. Treating sexual partners for possible STIs can help in treatment and prevention.\n\nFor women with PID of mild to moderate severity, parenteral and oral therapies appear to be effective. It does not matter to their short- or long-term outcome whether antibiotics are administered to them as inpatients or outpatients. Typical regimens include cefoxitin or cefotetan plus doxycycline, and clindamycin plus gentamicin. An alternative parenteral regimen is ampicillin/sulbactam plus doxycycline. Erythromycin-based medications can also be used. A single study suggests superiority of azithromycin over doxycycline. Another alternative is to use a parenteral regimen with ceftriaxone or cefoxitin plus doxycycline. Clinical experience guides decisions regarding transition from parenteral to oral therapy, which usually can be initiated within 24–48 hours of clinical improvement.\n\nEven when the PID infection is cured, effects of the infection may be permanent. This makes early identification essential. Treatment resulting in cure is very important in the prevention of damage to the reproductive system. Formation of scar tissue due to one or more episodes of PID can lead to tubal blockage, increasing the risk of the inability to get pregnant and long-term pelvic/abdominal pain. Certain occurrences such as a post pelvic operation, the period of time immediately after childbirth (postpartum), miscarriage or abortion increase the risk of acquiring another infection leading to PID.\n\nPID can cause scarring inside the reproductive system, which can later cause serious complications, including chronic pelvic pain, infertility, ectopic pregnancy (the leading cause of pregnancy-related deaths in adult females), and other complications of pregnancy. Occasionally, the infection can spread to the peritoneum causing inflammation and the formation of scar tissue on the external surface of the liver (Fitz-Hugh–Curtis syndrome).\n\nGlobally about 106 million cases of chlamydia and 106 million cases of gonorrhea occurred in 2008. The number of cases of PID; however, is not clear. It is estimated to affect about 1.5 percent of young women yearly. In the United States PID is estimated to affect about one million people yearly. Rates are highest with teenagers and first time mothers. PID causes over 100,000 women to become infertile in the US each year.\n\n"}
{"id": "6823306", "url": "https://en.wikipedia.org/wiki?curid=6823306", "title": "Primary nursing", "text": "Primary nursing\n\nOriginated in 1969 by staff nurses at the University of Minnesota, Primary Nursing is a system of nursing care delivery which emphasizes continuity of care and responsibility acceptance by having one registered nurse (RN), often teamed with a licensed practical nurse (LPN) and/or nursing assistant (NA), who together provide complete care for a group of patients throughout their stay in a hospital unit or department. For the duration of a patient’s episode of care, the primary nurse accepts responsibility for administering some and coordinating all aspects of the patient’s nursing care. When RNs supervise LPNs and NAs in the care of patients, costs associated with labor and other resources typically decrease while more attentive, well-coordinated care is provided for patients, increasing patient satisfaction and safety.\n\nThis is distinguished from the practice of team nursing, functional nursing, or total patient care, in that primary nursing focuses on the therapeutic relationship between a patient and a named nurse who assumes responsibility for a patient’s plan of care for their length of stay in a particular area.\n\nMarie Manthey, one of the originators of this care delivery system and the author of \"The Practice of Primary Nursing\" (2002), asserts that a nursing system can enhance and facilitate either professional or bureaucratic values as it either focuses on caring for people or tending to the needs of an organization. From \"The Practice of Primary Nursing\", “Primary Nursing is a delivery system for nursing at the station level that facilitates professional nursing practice despite the bureaucratic nature of hospitals. The practice of any profession is based on an independent assessment of a client’s needs which determines the kind and amount of service to be rendered: services in bureaucracies are usually delivered according to routine pre-established procedures without sensitivity to variations in needs.”\n\nA delivery system is a set of organizing principles that is used to deliver a product or service and generally consist of four elements: decision-making, work allocation, communication, and management.The following table illustrates the similarities and differences between the four most common nursing care delivery systems:<br>\n<br>\nFrom the book \"Relationship-Based Care: A Model for Transforming Practice\" (2004), Mary Koloroutis, editor. Used by permission.<br>\n\nFrom the book \"Relationship-Based Care: A Model for Transforming Practice\" (2004), Mary Koloroutis, editor. Used by permission.\n\nMarie Manthey tells this story about the origins of primary nursing in the book \"Relationship-Based Care: A Model for Transforming Practice\":\n\n“Primary Nursing was implemented in 1969 on Unit 32 at the University of Minnesota Hospital. This radical change in care delivery came about when a colleague, Pat Robertson (nursing supervisor) and I (assistant director of nursing) held an evening meeting with nursing staff and leaders at [my] home. This was an unprecedented and radical action—to invite staff nurses and leaders to come together to figure out how to improve patient care and the work environment itself. The nurses told stories about attempts to implement [care delivery systems like] Primary Nursing elsewhere in the United States, and we discussed how it could happen in our organization. Our message to the staff that night was that they have the ability to influence their own practice and how it will look—and step one was that it was okay for them to make patient assignments.” (p. 170)\n\nThe first seminar presenting primary nursing to the nursing community took place in 1970, and the first article, \"Primary nursing: a return to the concept of 'my nurse' and 'my patient',” co-authored by Marie Manthey, Karen Ciske, Patricia Robertson, and Isabel Harris was published in January 1970 in the journal \"Nursing Forum\". A second article, \"A Dialogue on Primary Nursing,\" written by Marie Manthey and Marlene Kramer, was published in the journal \"Nursing Forum\" in October 1970. Throughout the 1970s, interest and development were steady, but never well-organized; however, several hospitals quickly realized the benefits of a primary nursing care delivery system to patients and nurses. The nursing staffs at Boston Beth Israel led by Joyce Clifford and Evanston Hospital led by June Werner were early adopters of primary nursing and were recognized for their outstanding work in fully implementing this professional nursing model.\n\n"}
{"id": "23388437", "url": "https://en.wikipedia.org/wiki?curid=23388437", "title": "Project C.U.R.E.", "text": "Project C.U.R.E.\n\nPROJECT C.U.R.E. (Commission on Urgent Relief and Equipment) is the registered trademark of the Benevolent Healthcare Foundation, a 501(c)(3) non-profit, humanitarian relief organization based in Denver, CO. It is one of the largest nonprofit organizations in the world that delivers medical supplies and equipment to developing countries. Its main purpose is to collect and sort donated medical supplies and equipment from manufacturers, hospitals, and surpluses and then distribute the supplies and equipment to developing countries based on a needs assessment of the local hospitals and clinics in those countries.\n\nThe idea of PROJECT C.U.R.E. was created in 1987 by the founder, James W. Jackson while working as an international economic consultant with heads of governments in developing nations. During a trip to Brazil, Jackson observed how many of the clinics in rural areas were unable to accommodate many of the patients due to the lack of medical supplies and equipment and the large number of people seeking medical attention.\nWhen Jackson returned home to Colorado, he collected about $250,000 worth of donated, surplus medical supplies in under a month. He then personally paid for the shipping costs of the medical supplies to Brazil. Since that first shipment in 1987, PROJECT C.U.R.E. has expanded and now works in over 130 countries around the world.\n\nPROJECT C.U.R.E.'s headquarters is located in Centennial, CO, outside of Denver. Distribution centers are located in Centennial, CO, Phoenix, AZ, Nashville, TN, Houston, TX, and Chicago, IL. Project C.U.R.E. maintains collection centers in Albuquerque, NM, Austin, TX, Basalt, CO, Brooklyn, NY, Grand Junction, CO, Harrisburg, PA, Ithaca, NY, Lexington, KY, Sarasota, FL, and Tampa, FL.\n\nPROJECT C.U.R.E. uses the majority of its funding into the completion of its projects. 98.6% of PROJECT C.U.R.E.'s total annual spending is made up of program expenses. Administrative expenses total 0.7% of the organization's budget and fundraising expenses constitute 0.6% of total annual spending.\n\nProCURE is the name of the project in which PROJECT C.U.R.E. collects new and overstock medical supplies and working equipment from manufacturers, wholesale suppliers, hospitals, clinics and individuals. The goods obtained from ProCURE are then sorted and inventoried at PROJECT C.U.R.E. distribution centers before being sent to hospitals and clinics in developing counties.\n\nThe C.U.R.E. Corps is the volunteer member group for PROJECT C.U.R.E. made up of individuals, families, civic and church groups. Volunteer tasks include contacting hospitals and doctors for donations, collecting donations, sorting supplies, packing boxes, and loading supplies onto cargo containers to be shipped.\n\nCargo containers for PROJECT C.U.R.E. are the size of a semi-truck trailer. Each container holds an average of $400,000 in medical supplies and equipment. On average, PROJECT C.U.R.E. delivers two cargo containers a week to developing nations.\n\nC.U.R.E. Kits are boxes which contain essential medical supplies and equipment to be carried as luggage on an international flight. C.U.R.E. Kits are designed to meet the needs for short-term medical missions abroad and can be shipped directly to the traveler's home.\n\nC.U.R.E. Clinics prove an avenue for volunteer medical professionals to travel to developing countries where they are able to offer medical services. Location in which PROJECT C.U.R.E. Clinics have operated include: Guatemala, Kenya, Rwanda, Ghana, Bolivia, China, and Togo.\n\nC.U.R.E. Kits for Kids is a program where drawstring backpacks are filled with personal hygiene and basic \"medicine cabinet\" items that are scarce in the third world. Kits for Kids gives parents the supplies they need to care for their children at home. Each bag has a tag, which allows for tracking as it makes its way across the world and into the hands of a family in need.\n\nPROJECT C.U.R.E. has delivered medical relief in over 120 countries:\nAfghanistan, Albania, Angola, Argentina, Armenia, Azerbaijan, Bali, Bangladesh, Belarus, Belize, Benin, Bhutan, Bolivia, Bosnia, Brazil, Bulgaria, Burkina Faso, Burundi, Cambodia, Cameroon, Chile, China, Christmas Island, Colombia, Costa Rica, Côte d'Ivoire, Croatia, Cuba, Czech Republic, DR Congo, Dominican Republic, Djibouti, Ecuador, El Salvador, Equatorial Guinea, Estonia, Eritrea, Ethiopia, Fiji, Gabon, Gambia, Georgia, Ghana, Greece, Grenada, Guatemala, Guinea, Guinea Bissau, Guyana, Haiti, Honduras, Hungary, India, Indonesia, Iraq, Israel, Jamaica, Jordan, Kazakhstan, Kenya, Kiribati, Kyrgyzstan, Laos, Lebanon, Lesotho, Liberia, Macedonia, Madagascar, Malawi, Mali, Mauritania, Mexico, Mongolia, Montenegro, Morocco, Mozambique, Union of Myanmar, Nagorno Karabakh Republic, Namibia, Nepal, Nicaragua, Nigeria, North Korea, Panama, Papua New Guinea, Pakistan, Palestine/West Bank, Paraguay, Peru, Philippines, Poland, Romania, Russia, Rwanda, Saba, Netherlands Antilles, Samoa, Senegal, Serbia, Sierra Leone, Somalia/Somaliland, South Africa, St. Lucia, St. Vincent, Sudan, Swaziland, Tajikistan, Tanzania, Thailand, Tokelau Islands, Togo, Tonga, Trinidad, Tunisia, Turkey, Uganda, Ukraine, Uruguay, Uzbekistan, Venezuela, Vietnam, Zambia, and Zimbabwe \n\nJames W. Jackson is the founder and chairman emeritus of PROJECT C.U.R.E.'s board of directors. He received a Bachelor of Arts in 1963 and completed his Master of Arts in 1964. He completed postgraduate studies in economics and the University of Colorado and received a Doctor of Humanities degree from Colorado Christian University in 1997. Jackson has been awarded the Colorado \"Ethics in Business Award,\" the American Red Cross \"Healthcare Lifetime Achievement Award,\" and Regis University's Civis Princeps Award for his efforts in changing lives around the world.\n\nDr. Douglas Jackson, son of the Founder James W. Jackson, became the Chief Executive Officer and President of PROJECT C.U.R.E. in 1997. Before coming PROJECT C.U.R.E., Dr. Jackson was Provost for Colorado Christian University in Lakewood, Colorado. And prior to this position, Douglas was the Director of the Fermanian Business Center at Point Loma University in San Diego, California.\nDouglas Jackson graduated magna cum laude from Northwest Nazarene College in 1982, with a Bachelor of Arts in Business Administration. In 1985, he earned a Juris Doctor from the University of Colorado at Boulder, and received the American Jurisprudence Award for Excellence in the study of law. After becoming an attorney, Douglas directed the legal affairs for the international agricultural firm, Chore-Time/Brock (CTB), Inc. in Milford, Indiana. In 1992, he was awarded a Ph.D. in Business Administration with an emphasis in finance and econometrics from the University of Colorado at Boulder. Douglas is a member of the Alpha Delta Sigma and the Beta Gamma Sigma national honor societies.\nFor nearly 15 years, Dr. Jackson taught at the university level in the disciplines of finance, investments and legal issues. Dr. Jackson is a Rotary International Paul Harris Fellow, and a director of the Denver Rotary Club #31. He is a Director of the Institute for International Education which administers the Fulbright Scholarships. He is a member of the National Who's Who, Registry #57689, and is a graduate of the community leadership program, LEAD San Diego. He has also served as a director for such organizations as: HOPE International, Christian Executive Officers, YMCA, and the Leadership Denver Association.\n\n"}
{"id": "33537087", "url": "https://en.wikipedia.org/wiki?curid=33537087", "title": "Remote patient monitoring", "text": "Remote patient monitoring\n\nRemote patient monitoring (RPM) is a technology to enable monitoring of patients outside of conventional clinical settings (e.g. in the home), which may increase access to care and decrease healthcare delivery costs.\n\nIncorporating RPM in chronic disease management can significantly improve an individual's quality of life. It allows patients to maintain independence, prevent complications, and minimize personal costs. RPM facilitates these goals by delivering care right to the home. In addition, patients and their family members feel comfort knowing that they are being monitored and will be supported if a problem arises. This is particularly important when patients are managing complex self-care processes such as home hemodialysis.\nKey features of RPM, like remote monitoring and trend analysis of physiological parameters, enable early detection of deterioration; thereby, reducing number of emergency department visits, hospitalizations, and duration of hospital stays.\nThe need for wireless mobility in healthcare facilitates the adoption of RPM both in community and institutional settings. The time saved as a result of RPM implementation increases efficiency, and allows healthcare providers to allocate more time to remotely educate and communicate with patients.\n\nThe diverse applications of RPM lead to numerous variations of RPM technology architecture. However, most RPM technologies follow a general architecture that consists of four components.:\nDepending on the disease and the parameters that are monitored, different combinations of sensors, storage, and applications may be deployed.\n\nPhysiological data such as blood pressure and subjective patient data are collected by sensors on peripheral devices. Examples of peripheral devices are: blood pressure cuff, pulse oximeter, and glucometer. The data are transmitted to healthcare providers or third parties via wireless telecommunication devices. The data are evaluated for potential problems by a healthcare professional or via a clinical decision support algorithm, and patient, caregivers, and health providers are immediately alerted if a problem is detected. As a result, timely intervention ensures positive patient outcomes. The newer applications also provide education, test and medication reminder alerts, and a means of communication between the patient and the provider. The following section illustrates examples of RPM applications, but RPM is not limited to those disease states.\n\nFor patients with dementia that are at risk for falls, RPM technology promotes safety and prevents harm through continuous surveillance. RPM sensors can be affixed to the individual or their assistive mobility devices such as canes and walkers. The sensors monitor an individual’s location, gait, linear acceleration and angular velocity, and utilize a mathematical algorithm to predict the likelihood for falls, detect movement changes, and alert caregivers if the individual has fallen. Furthermore, tracking capabilities via Wi-Fi, global positioning system (GPS) or radio frequency enables caregivers to locate wandering elders.\n\nDiabetes management requires control of multiple parameters: blood pressure, weight, and blood glucose. The real-time delivery of blood glucose and blood pressure readings enables immediate alerts for patient and healthcare providers to intervene when needed. There is evidence to show that daily diabetes management involving RPM is just as effective as usual clinic visit every 3 months.\n\nA systematic review of the literature on home monitoring for heart failure patients indicates that RPM improves quality of life, improves patient-provider relationships, shortens duration of stay in hospitals, decreases mortality rate, and reduces costs to the healthcare system.\n\nA recent study of a remote patient monitoring solution for infertility demonstrated that for appropriately screened patients who had been seeking In-Vitro Fertilization (IVF) treatment, a six-month remote monitoring program had the same pregnancy rate as a cycle of IVF. The remote patient monitoring product and service used had a cost-per-patient of $800, compared to the average cost of a cycle of IVF of $15,000, suggesting a 95% reduction in the cost of care for the same outcome.\n\nThe Veterans Health Administration (VHA), United States’ largest integrated healthcare system, is highly involved in the implementation and evaluation of RPM technologies. It has expanded use of RPM beyond common chronic disease applications, to post-traumatic stress disorder, cancer and palliative care. VHA’s findings indicate improvements in a wide range of metrics, including decrease in emergency department visits, hospitalizations, and nursing home admissions. Findings from the VHA Care Coordination/Home Telehealth program show that RPM deployment resulted in significant savings to the organization.\n\nThe UK’s Department of Health’s Whole System Demonstrator (WSD) launched in May 2008. It is the largest randomised control trial of telehealth and telecare in the world, involving 6191 patients and 238 GP practices across three sites, Newham, Kent and Cornwall. The trials were evaluated by: City University London, University of Oxford, University of Manchester, Nuffield Trust, Imperial College London and London School of Economics.\n\n\nIn the UK, the Government's Care Services minister, Paul Burstow, has stated that telehealth and telecare would be extended over the next five years (2012-2017) to reach three million people.\n\nRPM is highly dependent on the individual’s motivation to manage their health. Without the patient’s willingness to be an active participant in their care, RPM implementation will likely fail. Cost is also a barrier to its widespread use. \nThere is a lack of reimbursement guidelines for RPM services, which may deter its incorporation into clinical practice.\nThe shift of accountability associated with RPM brings up liability issues. There are no clear guidelines in respect to whether clinicians have to intervene every time they receive an alert regardless of the urgency.\nThe continuous flow of patient data requires a dedicated team of health care providers to handle the information, which may, in fact, increase the workload. Although technology is introduced with the intent to increase efficiency, it can become a barrier to some healthcare providers that are not technological.\nThere are common obstacles that health informatics technologies encounter that applies to RPM. Depending on the comorbidities monitored, RPM involves a diverse selection of devices in its implementation. Standardization is required for data exchange and interoperability among multiple components. Furthermore, RPM deployment is highly dependent on an extensive wireless telecommunications infrastructure, which may not be available or feasible in rural areas. Since RPM involves transmission of sensitive patient data across telecommunication networks, information security is a concern.\n\nPublished by the New England Journal of Medicine, a randomized controlled trial involving congestive heart failure patients concluded that the use of telemonitoring failed to provide a benefit over usual care. The telemonitoring patient group was instructed to call a designated number daily, and answer a series of questions about their symptoms using a keypad. Clearly, the process described by Chaudhry et al. (2010) differs from the RPM methodology illustrated in the overview, which involves actual collection and transmission of physiological data through point-of-care devices. With articles from Forbes associating RPM with the negative findings by Chaudhry et al. (2010), it may be difficult to clear the misconception that telemonitoring is synonymous with remote patient monitoring. The lack of standardization of RPM nomenclature and definition makes it difficult to differentiate between different forms of patient monitoring involving technology.\n\n"}
{"id": "58582242", "url": "https://en.wikipedia.org/wiki?curid=58582242", "title": "Repeated implantation failure", "text": "Repeated implantation failure\n\nRepeated Implantation failure (RIF) is the failure of the embryo to implant onto the side of the uterus wall following IVF treatment. Regularly, this happens at 6-7 days after conception and involves the embedding of the growing embryo into the mothers uterus and a connection being formed . A successful implantation can be determined by using an ultrasound to view the sac which the baby grows in, inside the uterus.\n\nHowever, the exact definition of RIF is debated. Recently the most commonly accepted definition is when a women under 40 has gone through 3 unsuccessful cycles of IVF, when in each cycle 4 good quality eggs have been transferred .\n\nRepeated implantation failure should not be confused with recurrent IVF failure. Recurrent IVF failure is a much more broad term and includes all repeated failures to get pregnant from IVF. Repeated implantation failure specifically refers to those failures due to unsuccessful implanting to the uterus wall. \n\nAn unsuccessful implantation can be down to either problems with the mother or with the embryo. It is essential that the mother and embryo are able to communicate with each other during all stages of pregnancy, and an absence of this communication can lead to an unsuccessful implantation and a further unsuccessful pregnancy . \n\nDuring implantation, the embryo must cross the epithelial layer of the maternal endometrium before invading and implanting in the stroma layer. Maternal factors, including congenital uterine abnormalities, fibroids, endometrial polyps, intrauterine adhesions, adenomyosis, thrombophilia and endometriosis, can reduce the chances of implantation and result in RIF.\n\nCongenital uterine abnormalities are irregularities in the uterus which occur during the mothers foetal development.\n\nTwo genes have been identified to assist in the development and receptivity of the uterus and endometrium, Hoxa10 and Hoxa11. Hoxa10 has been shown to change the upper uterine segment into oviduct-like structures, creating a smaller uterus that appears normal. Embryo transfer into the lower uterine segment does not allow for implantation, so the Hoxa10 gene has multiple effects throughout the uterus. Hoxa11 mutations alter the endometrial gland development and reduce the secretion of Leukaemia-Inhibitory factor (LIF) which is required for implantation.\nFibroids are benign tumours found in the smooth muscle of the uterus, they are often asymptomatic but can cause pelvic pain. They effect implantation rates by altering the shape and cytokine composition of the uterus. Removal of submucosal fibroids has shown to increase implantation rates.\n\nEndometrial polyps are benign tumours found in the endometrium which factor into female infertility. There has been limited research into if their removal increases the chances of implantation and pregnancy.\n\nIntrauterine adhesions (Asherman's Syndrome) occur from scar tissue within the uterus which cause the closure of part or all of the uterus. The adhesions prevent embryos from implanting by reducing the surface area and decreasing the receptivity. Intrauterine adhesions normally occur after damage has been caused to the endometrium, either through removal of unwanted pregnancies, miscarriage, infection, and surgical damage.\n\nThrombophilia is a condition which makes the blood more likely to clot and this increases cardiovascular risk, meaning the individual is at higher risk of heart attacks, strokes or DVTs . In pregnancy it can lead to a disruption in the flow of blood to the placenta and the uterus wall. This can lead to a decreased receptivity of the uterus wall for a pregnancy and can lead to a miscarriage further on. However, how significantly this contributes to RIF is not fully known but each case should be assessed on a personal basis by a clinician \n\nThe successful implantation of an embryo not only relies on a receptive uterine environment in the mother but also on the quality of the embryo itself. Embryo quality and probability of implantation can be affected by maternal and paternal genetic abnormalities as well as zona pellucida dysfunction and poor embryo transfer technique.\n\nThe quality of the sperm that fertilizes an egg is a key contributor to the overall quality of the embryo. Abnormalities in DNA fragmentation and chromosomal arrangements are the main source of genetic deviation in males that can affect embryo quality. DNA fragmentation occurs when the strands of DNA are separated to form two separate strands, this disrupts the genetic information that is coded in genes. Depending on the severity of the fragmentation, this can lead to the dysfunction of specific genes which may or may not be essential for embryo survival and in this case the initiation of implantation. DNA fragmentation can happen spontaneously in cells that undergo programmed cell death (apoptosis) where DNA is broken apart by enzymes called endonucleases. However, since the male DNA isn't activated until around day 3 after fertilisation, it is often difficult to diagnose sperm genetic abnormalities because morphological studies could identify a good quality oocyte when initial transfer occurs, but due to DNA fragmentation in the sperm, the embryo will die after day 3 of growth.\n\nOocyte quality is also a main contributor to overall embryo quality since it is the DNA of the oocyte that is mainly involved in the first 3 days of embryo growth following fertilization. A major source of genetic abnormalities are balanced translocations (Figure 1).\n\nA translocation involves the exchange of segments of chromosomes that are not a homologous pair. In most cases, this leads to balanced translocations, in which no DNA is lost therefore is usually asymptomatic. However, as female gametes are formed, it is probable that 2/3 of embryos produced will have unbalanced translocations within their DNA if fertilised by sperm with a balanced translocation too. Translocation mutations can occur at any point during fertilization or even the first meiotic division that the oocyte undergoes during foetal life.\n\nThe female egg (oocyte) is surrounded by a layer of glycoproteins called the zona pellucida. Once fertilisation has occurred, this layer will harden to prevent further sperm entering and maintain the shape of the fertilized egg (zygote) as it divides to form a blastocyst (Figure 2). Once the inner cell mass - the group of cells within the blastocyst that go on to form the embryo - starts to expand, lysin enzymes secreted by the inner cell mass will act on the zona pellucida and weaken the hardened structure. Eventually, this will cause the rupture of the zona pellucida, allowing the blastocyst to hatch and begin to implant into the uterine wall.\n\nIf the zona pellucida fails to thin in preparation for rupture, this will prevent the blastocyst from hatching and therefore be unable to implant, therefore this is a probable cause of repeated implantation failure (RIF). This is supported by a study which showed that implantation rates in women who received assisted zona pellucida hatching - use of synthetic chemical to artificially weaken the zona pellucida - increased.\n\nWomen with RIF should undergo ovarian function testing to explore their levels of FSH, AMH and any other hormones or follicle counts which may indicate the overall behaviour of the ovarian reserve. Male partners may also be offered laboratory testing of sperm DNA integrity. \n\nIn the instance of genetic testing, karyotyping may be made available to couples with RIF to exclude the possibility of balanced chromosomal translocations. Ultrasounds may be used to oversee the morphological growth and development of follicles throughout IVF treatment, in addition to assessing endometrial thickness. \n\nHysteroscopy is an essential part of investigating a couple’s RIF pathology and is used as a diagnostic tool to examine the cervical canal and uterine cavity. \n\nIn depth reviews of the underlying causes of a couple's infertility should be undertaken with a qualified fertility specialist in order to make decisions regarding further management.\n\nModifiable risk factors include smoking, alcohol consumption and BMI. Women with RIF should be advised to abstain from both alcohol and smoking, and male partners may also consider cessation of smoking due to effects associated with weaker sperm counts and damage to sperm DNA and motility. An ideal BMI target for women with RIF is between 19 and 29; obese women may consider structured weight-loss programmes and regular exercise over bariatric surgery due to potential folate, iron, vitamin B12 and other nutritional deficiencies. \n\nTable below showing the main first-line treatments for couples undergoing RIF. \n"}
{"id": "4103290", "url": "https://en.wikipedia.org/wiki?curid=4103290", "title": "Revised Trauma Score", "text": "Revised Trauma Score\n\nThe Revised Trauma Score (RTS) is a physiologic scoring system, designed for use in based on the initial vital signs of a patient. A lower score indicates a higher severity of injury.\n\nThe Revised Trauma Score is made up of a three categories: Glasgow Coma Scale, systolic blood pressure, and respiratory rate. The score range is 0–12. In START triage, a patient with an RTS score of 12 is labeled delayed, 11 is urgent, and 3–10 is immediate. Those who have an RTS below 3 are declared dead and should not receive certain care because they are highly unlikely to survive without a significant amount of resources.\n\nThe score is as follows:\n\nThese three scores (Glasgow Coma Scale, Systolic Blood Pressure, Respiratory Rate) are then used to take the weighted sum by RTS = 0.9368 GCS + 0.7326 SBP + 0.2908 RR. Values for the RTS are in the range 0 to 7.8408. The RTS is heavily weighted towards the Glasgow Coma Scale to compensate for major head injury without multisystem injury or major physiological changes. A threshold of RTS < 4 has been proposed to identify those patients who should be treated in a trauma centre, although this value may be somewhat low.\n\n"}
{"id": "1364413", "url": "https://en.wikipedia.org/wiki?curid=1364413", "title": "Scope of practice", "text": "Scope of practice\n\nThe scope of practice describes the procedures, actions, and processes that a healthcare practitioner is permitted to undertake in keeping with the terms of their professional license. The scope of practice is limited to that which the law allows for specific education and experience, and specific demonstrated competency. Each jurisdiction has laws, licensing bodies, and regulations that describe requirements for education and training, and define scope of practice.\n\nIn most jurisdictions, health care professions with scope of practice laws and regulations include any profession within health care that requires a license to practice such as physicians, surgeon's assistant, nurses, dietitians, respiratory therapists, physical therapists, occupational therapists and dentists among many others.\n\nGoverning, licensing, and law enforcement bodies are often at the sub-national (e.g. state or province) level, but federal guidelines / regulations also often exist. For example, in the United States, the National Highway Traffic Safety Administration in the Department of Transportation has a national scope of practice for emergency medical services.\n\n\n\n"}
{"id": "5599330", "url": "https://en.wikipedia.org/wiki?curid=5599330", "title": "Sensitivity and specificity", "text": "Sensitivity and specificity\n\nSensitivity and specificity are statistical measures of the performance of a binary classification test, also known in statistics as a classification function:\n\nEquivalently, in medical tests sensitivity is the extent to which actual positives are not overlooked (so false negatives are few), and specificity is the extent to which actual negatives are classified as such (so false positives are few). Thus a highly sensitive test rarely overlooks an actual positive (for example, showing \"nothing bad\" despite something bad existing); a highly specific test rarely registers a positive classification for anything that is not the target of testing (for example, finding one bacterial species and mistaking it for another closely related one that is the true target); and a test that is highly sensitive \"and\" highly specific does both, so it \"rarely overlooks a thing that it is looking for\" \"and\" it \"rarely mistakes anything else for that thing.\" Because most medical tests do not have sensitivity and specificity values above 99%, \"rarely\" does \"not\" equate to certainty. But for practical reasons, tests with sensitivity and specificity values above 90% have high credibility, albeit usually no certainty, in differential diagnosis.\n\nSensitivity therefore quantifies the avoiding of false negatives and specificity does the same for false positives. For any test, there is usually a trade-off between the measures – for instance, in airport security, since testing of passengers is for potential threats to safety, scanners may be set to trigger alarms on low-risk items like belt buckles and keys (low specificity) in order to increase the probability of identifying dangerous objects and minimize the risk of missing objects that do pose a threat (high sensitivity). This trade-off can be represented graphically using a receiver operating characteristic curve. A perfect predictor would be described as 100% sensitive, meaning all sick individuals are correctly identified as sick, and 100% specific, meaning no healthy individuals are incorrectly identified as sick. In reality, however, any non-deterministic predictor will possess a minimum error bound known as the Bayes error rate.\n\nIn the terminology \"true/false positive/negative\", \"true\" or \"false\" refers to the assigned classification being correct or incorrect, while \"positive\" or \"negative\" refers to assignment to the positive or the negative category.\n\nImagine a study evaluating a new test that screens people for a disease. Each person taking the test either has or does not have the disease. The test outcome can be positive (classifying the person as having the disease) or negative (classifying the person as not having the disease). The test results for each subject may or may not match the subject's actual status. In that setting:\n\nIn general, Positive = identified and negative = rejected.\nTherefore:\n\nLet us consider a group with P positive instances and N negative instances of some condition. The four outcomes can be formulated in a 2×2 \"contingency table\" or \"confusion matrix\", as follows:\n\nSensitivity refers to the test's ability to correctly detect ill patients who do have the condition. In the example of a medical test used to identify a disease, the sensitivity (sometimes also named as detection rate in a clinical setting) of the test is the proportion of people who test positive for the disease among those who have the disease. Mathematically, this can be expressed as:\n\nA negative result in a test with high sensitivity is useful for ruling out disease. A high sensitivity test is reliable when its result is negative, since it rarely misdiagnoses those who have the disease. A test with 100% sensitivity will recognize all patients with the disease by testing positive. A negative test result would definitively \"rule out\" presence of the disease in a patient.\n\nA positive result in a test with high sensitivity is not useful for ruling in disease. Suppose a 'bogus' test kit is designed to show only one reading, positive. When used on diseased patients, all patients test positive, giving the test 100% sensitivity. However, sensitivity by definition does not take into account false positives. The bogus test also returns positive on all healthy patients, giving it a false positive rate of 100%, rendering it useless for detecting or \"ruling in\" the disease.\n\nSensitivity is not the same as the precision or positive predictive value (ratio of true positives to combined true and false positives), which is as much a statement about the proportion of actual positives in the population being tested as it is about the test.\n\nThe calculation of sensitivity does not take into account indeterminate test results.\nIf a test cannot be repeated, indeterminate samples either should be excluded from the analysis (the number of exclusions should be stated when quoting sensitivity) or can be treated as false negatives (which gives the worst-case value for sensitivity and may therefore underestimate it).\n\nSpecificity relates to the test's ability to correctly reject healthy patients without a condition. Consider the example of a medical test for diagnosing a disease.\nSpecificity of a test is the proportion of healthy patients known not to have the disease, who will test negative for it. Mathematically, this can also be written as:\n\nA positive result in a test with high specificity is useful for ruling in disease. The test rarely gives positive results in healthy patients. A test with 100% specificity will read negative, and accurately exclude disease from all healthy patients. A positive result signifies a high probability of the presence of disease.\n\nA test with a higher specificity has a lower type I error rate.\n\nIn medical diagnosis, test sensitivity is the ability of a test to correctly identify those with the disease (true positive rate), whereas test specificity is the ability of the test to correctly identify those without the disease (true negative rate).\nIf 100 patients known to have a disease were tested, and 43 test positive, then the test has 43% sensitivity. If 100 with no disease are tested and 96 return a negative result, then the test has 96% specificity. Sensitivity and specificity are prevalence-independent test characteristics, as their values are intrinsic to the test and do not depend on the disease prevalence in the population of interest. Positive and negative predictive values, but not sensitivity or specificity, are values influenced by the prevalence of disease in the population that is being tested. These concepts are illustrated graphically in this applet Bayesian clinical diagnostic model which show the positive and negative predictive values as a function of the prevalence, the sensitivity and specificity.\n\nIt is often claimed that a highly specific test is effective at ruling in a disease when positive, while a highly sensitive test is deemed effective at ruling out a disease when negative. This has led to the widely used mnemonics SPIN and SNOUT, according to which a highly SPecific test, when Positive, rules IN disease (SP-P-IN), and a highly 'SeNsitive' test, when Negative rules OUT disease (SN-N-OUT). Both rules of thumb are, however, inferentially misleading, as the diagnostic power of any test is determined by both its sensitivity \"and\" its specificity.\n\nThe tradeoff between specificity and sensitivity is explored in ROC analysis as a trade off between TPR and FPR (that is, recall and fallout). Giving them equal weight optimizes Informedness = Specificity+Sensitivity-1 = TPR-FPR, the magnitude of which gives the probability of an informed decision between the two classes (>0 represents appropriate use of information, 0 represents chance-level performance, <0 represents perverse use of information).\n\nThe sensitivity index or \"d' \" (pronounced 'dee-prime') is a statistic used in signal detection theory. It provides the separation between the means of the signal and the noise distributions, compared against the standard deviation of the noise distribution. For normally distributed signal and noise with mean and standard deviations formula_3 and formula_4, and formula_5 and formula_6, respectively, d' is defined as:\n\nAn estimate of d' can be also found from measurements of the hit rate and false-alarm rate. It is calculated as:\n\nwhere function \"Z\"(\"p\"), \"p\" ∈ [0,1], is the inverse of the cumulative Gaussian distribution.\n\n\"d' \" is a dimensionless statistic. A higher \"d\"' indicates that the signal can be more readily detected.\n\nSensitivity and specificity values alone may be highly misleading. The 'worst-case' sensitivity or specificity must be calculated in order to avoid reliance on experiments with few results. For example, a particular test may easily show 100% sensitivity if tested against the gold standard four times, but a single additional test against the gold standard that gave a poor result would imply a sensitivity of only 80%. A common way to do this is to state the binomial proportion confidence interval, often calculated using a Wilson score interval.\n\nConfidence intervals for sensitivity and specificity can be calculated, giving the range of values within which the correct value lies at a given confidence level (e.g., 95%).\n\nIn information retrieval, the positive predictive value is called precision, and sensitivity is called recall. Unlike the Specificity vs Sensitivity tradeoff, these measures are both independent of the number of true negatives, which is generally unknown and much larger than the actual numbers of relevant and retrieved documents. This assumption of very large numbers of true negatives versus positives is rare in other applications.\n\nThe F-score can be used as a single measure of performance of the test for the positive class. The F-score is the harmonic mean of precision and recall:\n\nIn the traditional language of statistical hypothesis testing, the sensitivity of a test is called the statistical power of the test, although the word \"power\" in that context has a more general usage that is not applicable in the present context. A sensitive test will have fewer Type II errors.\n\n"}
{"id": "57631881", "url": "https://en.wikipedia.org/wiki?curid=57631881", "title": "Share of throat", "text": "Share of throat\n\nShare of throat is a beverage industry term that refers to the proportion of the world's beverage consumption produced by a single company. The term was originally coined by Coca-Cola as \"throat share\", in order to measure how much of the world's beverages were theirs, but is now more commonly referred to as \"share of throat\".\n"}
{"id": "2645309", "url": "https://en.wikipedia.org/wiki?curid=2645309", "title": "Sharefarming", "text": "Sharefarming\n\nSharefarming is a system of farming in which sharefarmers make use of agricultural assets they do not own in return for some percentage of the profits. Sometimes the sharefarmer will receive a wage from the owner instead, although such a person is normally considered a tenant farmer or farm labourer. Two common implementations of the sharefarming concept are sharecropping and sharemilking, although it is applied to other sorts of agricultural assets.\n\nSharefarming was common in colonial Africa, in Scotland, and in Ireland; it came into wide use in the United States during the Reconstruction era (late 19th-century). In Europe, especially France and Italy, a sharefarming system called metayage once commonly occurred.\n\nWhile sharefarming can be seen as a form of oppression similar to feudal serfdom and is in practice in many poor areas today, such as India, it is also common in highly developed countries. The latter case occurs where individual farmers prefer not to have complete responsibility for agricultural assets such as the land or livestock, and in such applications it is not considered exploitative.\n\nSharecropping is the most common application of the sharefarming principle. In practice, sharefarmers work land which they don't own in return for varying portions of the total profit. In many cases where it is practiced in very poor farming communities it is considered an exploitative model. Sharecropping began after the Civil War and ended between the 1930s and the 1940s because when machines came that could to farming more easily, landowners didn't need actual people working the fields.\n\nSharemilking is the application of the sharefarming concept to the dairy industry. Sharemilkers tend to own their own cows but use facilities they do not own to actually milk the cows. This is often a convenient arrangement as milking facilities would otherwise lie empty and unused for several hours of the day.\n\n"}
{"id": "31650838", "url": "https://en.wikipedia.org/wiki?curid=31650838", "title": "Standard of living in Pakistan", "text": "Standard of living in Pakistan\n\nThe standard of living in Pakistan differentiates and varies between different classes of society. Pakistan is a largely developing country and according to the Human Development Index, is ranked 147th out of 170 countries, upper side of \"low human development.\" \nDespite having a growing middle class numbering over 70 million, a large portion of the country's population remains poor. Poverty, unemployment and a population boom contribute to Pakistan's current social problems. As of 2008, over 17% of the total population was found abjectly living below the poverty line while the unemployment rate, as of 2010, lumbered up to an unprecedented 15%. Poor governance and political insecurity have further added to the issues faced by the average\n\n\n"}
{"id": "2196348", "url": "https://en.wikipedia.org/wiki?curid=2196348", "title": "Stanton Samenow", "text": "Stanton Samenow\n\nStanton E. Samenow (born October 16, 1941) is an American psychologist and writer.\n\nSamenow was born to Charles and Sylvia Samenow. He is married, has two children, and resides in Falls Church, Virginia.\n\nFrom 1970 through 1978, Dr. Samenow worked as a clinical research psychologist for the Program for the Investigation of Criminal Behavior at St. Elizabeth's Hospital in Washington, D.C.. With Dr. Samuel Yochelson, the findings of their clinical research-treatment study of offenders were published in the three-volume set entitled \"The Criminal Personality\". Since 1978, Dr. Samenow has been in private practice as a clinical psychologist in Alexandria, Virginia.\n\nDr. Stanton Samenow received his B.A. (cum laude) from Yale University in 1963 and his PhD in psychology from the University of Michigan in 1968...In 1978, Dr. Samenow entered the private practice of clinical psychology in Alexandria, Virginia. His specialty has continued to be the evaluation and treatment of juvenile and adult offenders. Dr. Samenow has delivered lectures, training seminars, and workshops in 48 states, Canada, and England, to professional groups including mental health, law enforcement, corrections, education, social services, and the judiciary.\n\nDr. Samenow frequently carries out psychological reports for use in family court cases in the USA. Dr. Samenow wrote a book based on his experience as an independent custody evaluator published in 2002. It is titled \"In the Best Interest of the Child: How to Protect Your Child from the Pain of Your Divorce\".\n\n\n\n\n"}
{"id": "11035731", "url": "https://en.wikipedia.org/wiki?curid=11035731", "title": "Swedish Polytechnic", "text": "Swedish Polytechnic\n\nThe Swedish Polytechnic () was an institution of higher professional education (vocational university) in Vaasa, Finland. It offered bachelor's and master's degree programmes in Swedish in the fields of technology, health care, social welfare in Vaasa and within culture in Nykarleby and Jakobstad.\n\nOn August 1, 2008, the University merged with the Sydväst Polytechnic to form the Novia University of Applied Sciences.\n\n"}
{"id": "20055575", "url": "https://en.wikipedia.org/wiki?curid=20055575", "title": "São Tomé and Príncipe Red Cross", "text": "São Tomé and Príncipe Red Cross\n\nSão Tomé and Príncipe Red Cross was founded in 1976. It has its headquarters in São Tomé.\n\n"}
{"id": "31287978", "url": "https://en.wikipedia.org/wiki?curid=31287978", "title": "The Cyprus Institute of Neurology and Genetics", "text": "The Cyprus Institute of Neurology and Genetics\n\nThe Cyprus Institute of Neurology and Genetics is a non-profit institution that was established in 1990. Its parent organisation is The Cyprus Foundation for Muscular Dystrophy Research.\n\nIt specialises in neurology, molecular biology and all aspects of human genetics. It also collaborates with the University of Cyprus on a Medical Genetics graduate programme.\n\nThe study was performed from July 2007 until December 2010, according to the global standards of clinical research for the disease and with the participation of 80 patients with relapsing multiple sclerosis. The study design and the medical protocol included many innovations leading to the preparation of the formulation. Unlike anything else available, this formulation (with the code PLP10) is a nutraceutical (with natural biomolecules), administered orally, can be co-administered with all other available treatments, showed great therapeutic effect in reducing the frequency of relapses (flares) of the disease but mainly on the progression of the disability of patients. Finally, it is also potentially able to trigger remyelination, neuroprotection and mainly free of side effects. It thus has the ability to influence a holistic treatment of the disease, since it can affect the total known biological and biochemical network of pathogenic / pathogenetic events and mechanisms that cause the disease, including the biochemical mechanisms responsible for remyelination and restoration of neurons (healing).\n\nUpon completion of our clinical study and research, we are pleased to be able to announce the of-international interest intriguing research results for the treatment of the disease in relation to the PLP10 preparation. The study was accepted and published in the British Medical Journal, in the open edition, after an independent assessment by world-class scientists with knowledge, long-term experience and international recognition in research and treatment of MS. The product is registered for a USA and a worldwide patent.\n\n\n"}
{"id": "44901291", "url": "https://en.wikipedia.org/wiki?curid=44901291", "title": "United in Anger: A History of ACT UP", "text": "United in Anger: A History of ACT UP\n\nUnited in Anger: A History of ACT UP is a 2012 documentary film about the beginning and progress of the AIDS activist movement from the perspective of the people fighting the epidemic. Archival footage with oral histories of members of ACT UP depicts the history of civil disobedience against corporate greed, social indifference, and government negligence in the face of AIDS. Producers Jim Hubbard and Sarah Schulman created a documentary film that captures the efforts of ACT UP to remove the stigma associated with AIDS, fast track experimental drug research and testing, and provide a context for the devastating effects of the epidemic. Film includes several actions by ACT UP: Seize Control of the FDA, Stop the Church, and Day of Desperation.\n\nHIV arrives in the United States. People, mostly gay men, start dying. The US government ignores it. The Church condemns homosexuals. The Pharmaceutical industry produced expensive drugs. People keep dying. Love, grief and outrage lead to the formation of ACT UP in March 1987. \"United in Anger: A History of ACT UP\" documents ACT UP's use of direct activism, civil disobedience, inroads and outroads to raise awareness and affect change on a national level.\n\n\n\n"}
{"id": "3972534", "url": "https://en.wikipedia.org/wiki?curid=3972534", "title": "Vaccination and religion", "text": "Vaccination and religion\n\nVaccination and religion have interrelations of varying kinds. Almost no religions object to vaccination, and some parents either fake religious adherence or invent fake religions to provide exemption.\n\nThe influential Massachusetts preacher Cotton Mather was the first known person to attempt smallpox inoculation on a large scale, inoculating himself and over 200 members of his congregation with the help of a local doctor. While his view became standard, he also caused the first reaction against the practice.\n\nRowland Hill (1744–1833) was a popular English preacher acquainted with Edward Jenner, the pioneer of smallpox vaccination, and he encouraged the vaccination of the congregations he visited or preached to. He published a tract on the subject in 1806, at a time when many medical men refused to sanction it. Later he became a member of the Royal Jennererian Society, which was established when vaccination was accepted in Britain, India, the US, and elsewhere. John C. Lettsom, an eminent Quaker physician of the day wrote to Rowland Hill commenting:\n\nSeveral Boston clergymen and devout physicians formed a society that opposed vaccination in 1798. Others complained that the practice was dangerous, going so far as to demand that doctors who carried out these procedures be tried for attempted murder.\n\nIn 1816 Iceland made the clergy responsible for smallpox vaccination and gave them the responsibility of keeping vaccination records for their parishes; Sweden also had similar practices.\n\nWhen vaccination was introduced into UK public policy, and adoption followed overseas, there was opposition from trade unionists and others, including sectarian ministers and those interested in self-help and alternative medicines like homeopathy.\n\nAnti-vaccinationists were most common in Protestant countries. Those who were religious often came from minority religious movements outside of mainstream Protestantism, including Quakers in England and Baptists in Sweden.\n\nCatholic and Anglican missionaries vaccinated Northwest Coast Native Americans during an 1862 smallpox epidemic.\n\nIn the UK, a number of Vaccination Acts were introduced to control vaccination and inoculation, starting in 1840, when smallpox inoculation was banned. The 1853 Act introduced compulsory free infant vaccination enforced by local authorities. By 1871, infant vaccination was compulsory and parents refusing to have their child vaccinated were fined and imprisoned if the fines were not paid. Resistance to compulsion grew, and in 1889, after riots in Leicester, a Royal Commission was appointed and issued six reports between 1892 and 1896. It recommended the abolition of cumulative penalties. This was done in an 1898 Act, which also introduced a conscience clause that exempted parents who did not believe vaccination was efficacious or safe. This extended the concept of the \"conscientious objector\" in English law. A further Act in 1907 made it easier to obtain exemption.\n\nJehovah's Witnesses banned their members from receiving vaccinations from 1931 to 1952. They have since reversed their position. The decision of whether to vaccinate themselves or their family is left to the individual Witness. Some more recent Jehovah's Witness publications have mentioned the success of vaccination programs.\n\nChristian Science selectively rejects various forms of medical care including vaccination. The Congregation of Universal Wisdom, a religion based on belief in chiropractic spinal adjustments and Universal Intelligence, forbids vaccinations. The \"New York Times\" covered the Congregation of Universal Wisdom and noted that many families have used these religious memberships to avoid vaccination requirements. In a court case citing the Congregation of Universal Wisdom, \"Turner v. Liverpool Cent. School\", the United States District Court in New York affirmed the permissibility of claiming religious exemption from vaccination on the basis of such membership.\n\nSome conservative Christian groups in the United States oppose mandatory vaccination for diseases typically spread via sexual contact, arguing that the possibility of disease deters risky sexual contact. For example, the Family Research Council opposes mandatory vaccination against HPV, a virus that causes various cancers, writing, \"Our primary concern is with the message that would be delivered to nine- to 12-year-olds with the administration of the vaccines. Care must be taken not to communicate that such an intervention makes all sex 'safe'.\" Studies have shown that HPV vaccination does not result in increased sexual activity.\n\nThe Church of Jesus Christ of Latter-day Saints has made vaccination an official initiative in its humanitarian relief program. The Church has also called on its members to see that their own children are properly vaccinated.\n\nIslam and Judaism, religions with dietary prohibitions that regard particular animals as unclean, make exceptions for medical treatments derived from those animals.\n\nIn Aceh Province, an autonomous province of Indonesia with its own Islamic Sharia Law, 80 percent of people refuse all vaccinations due to concerns about pig, or its derivatives, being used to make some vaccines (eating pig is considered haram).\n\nThe use of fetal tissue in the development of vaccines has also provoked some controversy among religions opposed to abortion. The cell culture media of some viral vaccines, and the virus of the rubella vaccine, are derived from tissues taken from therapeutic abortions performed in the 1960s, leading to moral questions. For example, the principle of double effect, originated by Thomas Aquinas, holds that actions with both good and bad consequences are morally acceptable in specific circumstances, and the question is how this principle applies to vaccination. The Vatican Curia has expressed concern about the rubella vaccine's embryonic cell origin, saying Catholics have \"...a grave responsibility to use alternative vaccines and to make a conscientious objection with regard to those which have moral problems.\" The Vatican concluded that until an alternative becomes available it is acceptable for Catholics to use the existing vaccine, writing, \"This is an unjust alternative choice, which must be eliminated as soon as possible.\"\n\nThe majority of Orthodox Rabbis view vaccination as a religious obligation. A magazine called P.E.A.C.H. that presented an anti-immunization message to Orthodox Jews was distributed in Brooklyn, New York in early 2014. This is not a widespread phenomenon though. 96% of students at Yeshivas (who are essentially all Orthodox Jewish) in New York City were immunized according to information obtained in 2014, although this is a lower than average rate.\n\nIn 2003 imams in northern Nigeria advised their followers not to have their children vaccinated with oral polio vaccine, perceived to be a plot by Westerners to decrease Muslim fertility. The boycott caused the number of polio cases to rise not only in Nigeria but also in neighboring countries. The followers were also wary of other vaccinations, and Nigeria reported over 20,000 measles cases and nearly 600 deaths from measles from January through March 2005. In 2006 Nigeria accounted for over half of all new polio cases worldwide. Outbreaks continued thereafter; for example, at least 200 children died in a late-2007 measles outbreak in Borno State. In 2013, nine health workers administering polio vaccine were targeted and killed by gunmen on motorcycles in Kano, but this was an isolated incident. Local traditional and religious leaders and polio survivors worked to support the vaccination campaign, and Nigeria has not had a polio case since July 24, 2014; in 2017, if no new cases appear, Nigeria will be declared polio-free.\n\nIn the 2000s, in Pakistan and Afghanistan, some Taliban issued \"fatwas\" opposing vaccination as an American plot to sterilize Muslims, and kidnapped, beat, and assassinated vaccination officials; the head of Pakistan's vaccination campaign in Bajaur Agency was assassinated in 2007, on his way back from a meeting with a religious leader. In 2011, a CIA spy ran a fake hepatitis vaccination campaign to search for Osama bin Laden; such actions were strongly condemned by US and international health NGOs, the doctor involved was jailed and the CIA promised not to use vaccination as a cover again. A genuine polio vaccinator had previously vaccinated Osama bin Laden's children and grandchildren in his compound in Abbottabad. Both major sides of the Afghani civil war now support polio vaccination, and polio rates are declining rapidly in Afghanistan, with only five cases in Jan–July 2015. In Pakistan there were 28 cases in the same period.\n\nIn 2015, leaders of the Nation of Islam spoke out against a California Bill that removed philosophical exemptions to school vaccination requirements. Saying that data suggests \"that African American males who received the MMR vaccine before age 36 months were at increased risk for autism.\" They also said that that government mandated vaccines were another Tuskegee Syphilis Study.\n\nIn the U.S., all states except Mississippi, California and West Virginia allow parents to opt out of their children's otherwise-mandatory vaccinations for religious reasons. The number of religious exemptions rose greatly in the late 1990s and early 2000s; for example, in Massachusetts, the rate of those seeking exemptions rose from 0.24% in 1996 to 0.60% in 2006. Some parents falsely claim religious beliefs to get exemptions. The American Medical Association opposes such exemptions, saying that they endanger health not only for the unvaccinated individual but also for neighbors and the community at large.\n\nOn January 1, 2016 Australia introduced legislation that removed eligibility for childcare and welfare benefits if parents refuse to vaccinate their children, removing religious exemptions at the same time as the only religion to apply for an exemption (Church of Christ Science) deemed their exemption to no longer be relevant.\n"}
{"id": "38248414", "url": "https://en.wikipedia.org/wiki?curid=38248414", "title": "Variable electro-precipitator", "text": "Variable electro-precipitator\n\nA variable electro-precipitator (VEP) is a waste water remediation unit using electrocoagulation. The differences between a standard electrocoagulation (EC) unit and a variable Electro-precipitation unit are in the enhanced flow path and the unit electrode connections. The variable electro-precipitator's flow path has been designed to maximize retention time and to increase the turbulence of the water within the unit. This design aids in increasing the amount of effective treatment per gallon of water.\n\nA major design weakness of the electrocoagulation units is the method used in connecting the electrode to the power source. These designs cause overheating, resulting in premature failure of the electrocoagulation reaction chamber. VEP reaction chambers are designed to resolve these performance issues by changing all electrode connections from the standard wet connection (inside the chamber) to an external dry connection. The VEP is cooler-operating, and has a longer chamber life than an electrocoagulation unit.\n"}
{"id": "18266531", "url": "https://en.wikipedia.org/wiki?curid=18266531", "title": "Water resources management in Pakistan", "text": "Water resources management in Pakistan\n\nWater resources management in Pakistan.\n\nAccording to the United Nations' \"UN World Water Development Report\", the total actual renewable water resources increased from 2,961 m³ per capita in 2000 to 3,420 m³ per capita in 2005. A more recent study indicates an available supply of water of little more than 1,000 m³ per person, which puts Pakistan in the category of a high stress country. Using data from the Pakistani federal government's Planning and Development Division, the overall water availability has decreased from 1,299 m³ per capita in 1996-97 to 1,101 m³ per capita in 2004-05. In view of growing population, urbanization and increased industrialization, the situation is likely to get worse. Nevertheless, excessive mining of groundwater goes on. Despite a lowering water table, the annual growth rate of electric tubewells has been indicated to 6.7% and for diesel tubewells to about 7.4%. In addition, increasing pollution and saltwater intrusion threaten the country's water resources. About 36% of the groundwater is classified as highly saline.\n\nIn urban areas, most water is supplied from groundwater except for the cities of Karachi, and a part of Islamabad, where mainly surface water is used. In most rural areas, groundwater is used. In rural areas with saline groundwater, irrigation canals serve as the main source of domestic water.\n\nOut of the 169,384 billion m³ of water which were withdrawn in 2000, 96% were used for agricultural purposes, leaving 2% for domestic and another 2% for industrial use. By far most water is used for irrigated agriculture, emphasizing the particular significance of agriculture in the country. The sector contributes about 25% of the Pakistan's GNP (2000-2001). The country still has the world's largest contiguous irrigation system. In 1999-2000, the total irrigated area in Pakistan was 181,000 km².\n\nWater is also essential for power generation in Pakistan, since about 29% is generated through hydropower.\n\n"}
