{"id": "24328360", "url": "https://en.wikipedia.org/wiki?curid=24328360", "title": "2009 Chinese lead poisoning scandal", "text": "2009 Chinese lead poisoning scandal\n\nThe 2009 Chinese lead poisoning scandal occurred in the Shaanxi province of China when pollution from a lead plant poisoned children in the surrounding area. Over 850 were affected. Villagers have accused the local and central governments of covering up the scandal.\n\nIn 2003 the Dongling Lead and Zinc Smelting Company set up a factory in the Changqing township near the city of Baoji, describing it in brochures as \"a garden-like factory\". Soon \"100,000 tons of lead and zinc a year and 700,000 tons of coke\" were being produced. In 2008 it paid more than £10m in taxes to the local government, 17% of the administration's total income, and provided jobs for 2,000 households. Local parents however noticed that children were showing signs of illness - such as nose bleeds and memory problems. 851 children from seven villages surrounding the plant displayed up to 10 times the level of lead in their blood deemed safe by Chinese authorities. Over 170 of the children had to be hospitalised.\n\nLocal villagers protested to authorities but claim they were ignored. On 17 August 2009 they attacked the plant causing the managers to flee. The plant has now been closed down, but according to Western reports all coverage in the Chinese media of events has now been banned.\n\nChinese lead supplies the country's battery industry, the world's largest. Lead poisoning can lead to anaemia, muscle weakness and brain damage and damages the nervous and reproductive systems.\n\nThe Times reported in September 2009 that \"similar protests broke out in three other provinces, where horrified parents living near smelters of lead, copper and aluminium also learnt that their children had been poisoned—1,300 of them in one city alone\". Villages that suffer from such pollution are often dubbed 'cancer villages\". Child health is an important issue in China, where many families are restricted to just one child. Nearly 2,000 children were poisoned in the Shaanxi and Hunan provinces. Parents and villagers rioted in the Hunan province after the mass poisonings became known. The government promised to move villagers to a new, safer living location, but plans for the move were postponed when the new location was found also to be contaminated.\n\n"}
{"id": "22584367", "url": "https://en.wikipedia.org/wiki?curid=22584367", "title": "2009 flu pandemic timeline", "text": "2009 flu pandemic timeline\n\nThis article covers the chronology of the 2009 novel influenza A (H1N1) pandemic. Flag icons denote the first announcements of confirmed cases by the respective nation-states, their first deaths (and other major events such as their first intergenerational cases, cases of zoonosis, and the start of national vaccination campaigns), and relevant sessions and announcements of the World Health Organization (WHO), the European Union (and its agency the European Centre for Disease Prevention and Control),\nand the U.S. Centers for Disease Control (CDC).\n\nUnless otherwise noted, references to terms like S-OIV, H1N1 and such, all refer to this new A(H1N1) strain and not to sundry other strains of H1N1 which are endemic in humans, birds and pigs.\n\nTake note that the date of the first confirmations of the disease or any event in a country may be before or after the date of the events in local time because of the International Dateline.\n\n Mexico\nIn La Gloria, Veracruz 60% of the town's population is sickened by a respiratory illness of unknown provenance. The government of Mexico believes it to be caused by H3N2 influenza, though at least one patient in La Gloria tested positive for A/H1N1. Two babies died in the outbreak but both were buried without testing.\n\n United States In the ninth week of its routine influenza surveillance, the CDC reports on FluView that thirty-five states have reported widespread influenza activity, and 14 states have reported regional activity, but that although the rate of activity was high, that the proportion of deaths attributed to pneumonia and influenza (P&I) was below the epidemic threshold.\n\n United States The CDC reports on the 10th week of FluView that thirty states reported widespread influenza activity and 18 states reported regional activity.\n\n Mexico\nEarliest known onset of a case that is later to be confirmed as Swine-Origin Influenza A (H1N1) Virus Infection.\n\n United States CDC FluView, Week 11: Widespread influenza activity in twenty-four states; regional activity in 19. Influenza activity continues to decrease.\n\n United States\nEarliest known onset of a USA case later confirmed as swine flu, that of a nine-year-old girl residing in Imperial County, California. Thirteen states reported widespread influenza activity and 19 reported regional activity on the CDC's FluView, Week 12.\n\n United States\nA sample is collected from a nine-year-old female patient which is later confirmed to contain the novel virus strain (genetically sequenced as A/California/05/2009(H1N1)).\n\nOnset of illness for a ten-year-old boy residing in San Diego County, California; his case is eventually the first to be confirmed as swine flu in the US.\n\n United States\nA nasopharyngeal swab is collected from a ten-year-old male patient in San Diego County, later confirmed as containing the novel virus and the first organism of that strain to be completely sequenced (A/California/04/2009(H1N1)).\n\n Mexico\nIn La Gloria, Veracruz, a four-year-old boy falls ill at the end of the outbreak. Only his sample, which was eventually sent abroad, tested positive for A(H1N1). Veracruz officials state that there were no plans to exhume the bodies of two infants who died in the outbreak.\n\n United States CDC FluView, Week 13: Widespread influenza activity in four states, regional activity in 18.\n\n European Union\nThe media monitoring website MedISys reports on a Mexican article about the epidemiological alert.\n\n Mexico\nPublic health authorities begin investigating unusual cases of pneumonia. 400 people had reportedly sought treatment for pneumonia/influenza-like illness (ILI) in La Gloria the preceding week.\n\nBiosurveillance firm Veratect reports the unusual respiratory illness in Mexico. Veratect publishes the alert \"La Gloria: 'Strange' Respiratory Affects 60% of Local Population; Three Pediatric Deaths May be Associated with the Outbreak.\"\n\n United States CDC FluView, Week 14: Widespread influenza activity in one state; regional activity in 14.\n\n Mexico\nThe General Directorate of Epidemiology (DGE) reports the outbreak of an ILI in a small community in Veracruz to the Pan American Health Organization (PAHO), which is the Regional Office of the World Health Organization (WHO). Furthermore, a 39-year-old woman dies of severe viral pneumonia in the city of San Luis Potosí; this is later believed to be the earliest known fatality related to the outbreak.\n\n Mexico\nFirst death in Oaxaca due to what would later be identified as swine flu.\n\nThe U.S. Centers for Disease Control (CDC) is advised of a ten-year-old boy with a respiratory illness in San Diego County, California. Test results revealed an Influenza A virus but were negative for standard human strains. The San Diego County Health Department is notified.\n\n United States\nThe CDC receives its first sample from California (from the ten-year-old boy in San Diego County), and identifies the virus as a strain of swine influenza A(H1N1).\n\n Mexico\nAuthorities notify the PAHO of the atypical pneumonia.\n\nVeratect publishes the alert \"Atypical Pneumonia Cases Reported at Hospital\" regarding the Oaxaca cases.\n\n Mexico\nA case of atypical pneumonia in Oaxaca prompts enhanced national surveillance. A field investigation is started.\nMexico contacts Canada to request more specialized testing.\n\nThe CDC receives a second sample from Southern California (taken from the nine-year-old girl in Imperial County), and again identifies the virus as a strain of swine influenza A(H1N1). The California Department of Public Health is notified.\n\n Mexico\nMexico sends 14 mucus samples to the CDC and dispatches health teams hospitals to look for patients showing severe influenza- or pneumonia-like symptoms.\n\n United States\nVeratect advises the CDC of the Mexican events.\nThe CDC is already investigating the California and Texas cases.\n\n United States\nThe CDC alerts physicians to a similar novel strain of swine influenza A(H1N1) in two cases from Southern California in an Morbidity and Mortality Weekly Report Early Release on its website. Local investigations, including investigations in Texas, are already underway, and overall surveillance is enhanced. The Associated Press covers the alert, the first mention of the A(H1N1) outbreak in English-language news media.\n\n Canada\nCanada receives the samples from Mexico for testing.\n\n Mexico\nThe Public Health Agency of Canada confirms Mexico cases of swine-origin influenza A (H1N1) virus (S-OIV) infection.\nGenetic sequence analysis reveals that the Mexican patients were infected with the same S-OIV strain detected in two California children.\nThe PAHO is informed that a cluster in Mexico of severe respiratory illnesses has been laboratory-confirmed as S-OIV infection.\n\nThe WHO issues its first Disease Outbreak Notice on the matter, confirming the infection of a number of people in Mexico and the United States by \"Swine Influenza A/H1N1 viruses... not... previously detected in pigs or humans\".\n\nThe Minister of Health confirms the Mexican cases of human infection by swine influenza and states that it believes that some of these cases had resulted in death.\nHealth authorities implement public health measures for all airport passengers and the vaccination of health care workers with seasonal influenza vaccine.\nThe CDC tells a press conference that seven of the 14 Mexican samples contained the same virus strain as the known in California and Texas, and that indications suggested that containment in the USA was \"not very likely\".\nThe novel strain had already been reported on the CDC's Morbidity and Mortality Weekly Report website.\n\n WHO Under the International Health Regulations (IHR), the Emergency Committee convenes for the first time since its establishment in 2007, resulting in the WHO Director-General declaring a formal \"public health emergency of international concern,\" (PHEIC), the first ever.\n\nThe PAHO Vaccination Week In The Americas starts.\nThe 2009 Week was planned to emphasize the vaccination of entire families, and health worker immunization.\n\n WHO The Emergency Committee meets for the second time. The WHO Director-General issues a statement that containment of the outbreak is not feasible, and elevates the pandemic alert from Phase 3 to Phase 4.\n\nFirst six cases confirmed, four in Nova Scotia and two in British Columbia.\n\nFirst confirmed case of swine flu, in Almansa, and thus the first case in Europe; A(H1N1) has spread from the WHO Region of the Americas to the WHO European Region.\n\nFirst two confirmed cases, in Scotland.\n\n WHO Confirmed cases are now extant in four of six WHO regions (see map). As of 19:15 GMT seven countries have officially reported cases of swine influenza A(H1N1) infection.\n\nConfirmed: two cases and another four in Alberta and Ontario, respectively.\n\nFirst confirmed case in Israel and thus the WHO Eastern Mediterranean Region (color-coded yellow), the third region to be affected.\n\nFirst three confirmed cases in New Zealand and thus the WHO Western Pacific Region (color-coded red), the fourth region to be affected.\n\nThe second confirmed case in Spain, in Valencia.\n\n WHO\nThe Emergency Committee meets for the third time,\nand the WHO raises its pandemic alert level from Phase 4 to Phase 5, its second highest. As of 1800 GMT, nine countries have officially reported 148 cases of swine influenza A(H1N1) infection.\n\nASEAN ASEAN officials are looking at coordinating measures to address the potential pandemic.\n\nFirst confirmed case.\n\nFirst three confirmed cases, two in Bavaria and one in Hamburg.\n\nEight more cases raises the total in Spain to 10, including the first human-to-human intergenerational transmission (in which the patient had not recently been to Mexico but was infected by another patient who had just visited Mexico, namely his girlfriend). This is the first intergenerational transmission to be documented in Europe.\n\nFirst death outside Mexico, a 23-month-old Mexican child hospitalized in Texas. Ninety-one confirmed cases in the USA to date.\n\nFirst two cases reported within South Africa, by two women that travelled in Mexico weeks earlier. The cases were confirmed on 18 June 2009.\n\n Canada\nConfirmed: One more case in Toronto, and eight more cases in Nova Scotia, and Alberta bringing total to 28.\n\nFirst confirmed case.\n\nFirst confirmed case, a three-year-old child. The child returned from Mexico to the Netherlands on April 27, 2009. The parents test negative for A(H1N1).\n\nFirst confirmed case.\n\nFour cases are confirmed in an outbreak at the University of Delaware; another 12 cases are deemed \"probable\". One of the confirmed cases is a baseball player, which results in the university cancelling sporting events, a concert by rapper Young Jeezy, and other school activities.\n\nThree further confirmed cases of swine flu, giving a total of eight confirmed cases.\n\n WHO As of 0600 GMT, 11 countries have officially reported 331 cases of influenza A(H1N1) infection.\n\n51 confirmed cases.\n\n\nFirst confirmed case (in Hvidovre).\n\nFirst two confirmed cases.\n\nFirst and second case of human to human (or intergenerational) transmission within the UK confirmed.\n\n155 confirmed cases, including two at George Washington University's Thurston Hall.\n\n WHO As of 0600 GMT 15 countries have officially reported 615 cases of influenza A(H1N1) infection.\n\nThe Canadian Food Inspection Agency confirms the first human-to-animal transmission of the virus after an Albertan returns from Mexico and infects a pig farm, the first known case of (reverse) zoonosis.\n\nFirst confirmed case.\n\nThere are more than 430 school closures in 18 states. CDC FluView Week 17: Widespread activity in seven states, regional activity in 12.\n\n WHO As of 0600 GMT, 17 countries have officially reported 787 cases of (A)H1N1.\n\n101 confirmed cases after seven cases in British Columbia, three in Alberta, two in Nova Scotia and Ontario, and one in Quebec were confirmed.\n\nFirst confirmed case in South America.\n\n WHO As of 06:00 GMT, 20 countries have officially reported 985 cases of influenza A (H1N1) infection.\n\n WHO\nAs of 06:00 GMT, 21 countries have officially reported 1,124 cases of influenza A (H1N1) infection.\n\n\n WHO\nAs of 06:00 GMT, 22 countries have officially reported 1,516 cases of influenza A (H1N1) infection.\n\nASEAN A special regional summit to fight possible swine flu pandemic was held in Bangkok and was attended by senior ASEAN health officials along with those from China, Japan and South Korea.\n\n WHO\nAs of 18:00 GMT, 24 countries have officially reported 2,371 cases of influenza A (H1N1) infection.\n\nFirst confirmed case.\n\nReports suggest that an elderly woman who had swine flu has died in northern Alberta, marking the first death in Canada related to swine flu. Furthermore, an unusual case of zoonosis occurred when a swine flu inspector in improper gear caught the virus from an infected pig.\n\nSecond case confirmed, a 53-year-old woman who had recently travelled to Mexico.\n\nThe New England Journal of Medicine establishes its H1N1 Influenza Center on its website.\n\n WHO\nAs of 16:00 GMT, 25 countries have officially reported 2,500 cases of influenza A (H1N1) infection.\n\n WHO\nAs of 06:00 GMT, 29 countries have officially reported 3,440 cases of influenza A(H1N1) infection.\n\n WHO\nAs of 07:30 GMT, 29 countries have officially reported 4,379 cases of influenza A(H1N1) infection.\n\n WHO\nAs of 06:00 GMT, 30 countries have officially reported 4,694 cases of influenza A(H1N1) infection.\n\n WHO As of 06:00 GMT, 30 countries have officially reported 5,251 cases of influenza A(H1N1) infection.\n\n WHO As of 06:00 GMT, 13 May 2009, 33 countries have officially reported 5,728 cases of influenza A(H1N1) infection.\n\n WHO As of 06:00 GMT, 33 countries have officially reported 6,497 cases of influenza A(H1N1) infection.\n\n WHO As of 06:00 GMT, 34 countries have officially reported 7,520 cases of influenza A(H1N1) infection.\n\n WHO As of 06:00 GMT 36 countries have officially reported 8,451 cases of influenza A(H1N1) infection.\n\n WHO As of 06:00 GMT 37 countries have officially reported 8,480 cases of influenza A(H1N1) infection.\n\n WHO\nAs of 06:00 GMT, 40 countries have officially reported 8,829 cases of influenza A(H1N1) infection, including 74 deaths.\n\n WHO As of 06:00 GMT, 40 countries have officially reported 9,830 cases of influenza A(H1N1) infection, including 79 deaths.\n\n WHO As of 06:00 GMT, 40 countries have officially reported 10,243 cases of influenza A(H1N1) infection, including 80 deaths.\n\nUnited States A patient dies in Arizona, and a 22-year-old man dies in Utah, the nation's eighth and ninth H1N1 fatalities. Roughly half of the influenza viruses detected by the CDC's routine influenza surveillance systems are now that of novel A(H1N1). An unusual number of outbreaks in schools is reported.\n\nand the cities of Hachiōji and Kawasaki in the Greater Tokyo Area. Two female high school students from Tokyo who had recently attended a Model United Nations conference in New York are presumed to have become infected abroad.\n\n WHO As of 06:00 GMT, 41 countries have officially reported 11,034 cases of influenza A(H1N1) infection, including 85 deaths.\n\n WHO As of 06:00 GMT, 42 countries have officially reported 11,168 cases of influenza A(H1N1) infection, including 86 deaths.\n\nThird confirmed in Tokyo, a 25-year-old man who visited Osaka from May 14-20th. Philippines First case confirmed.\n\n WHO As of 06:00 GMT, 43 countries have officially reported 12,022 cases of influenza A(H1N1) infection, including 86 deaths.\n\n Australia Two more confirmed cases, which now brings the national toll to 16.\n\n WHO As of 06:00 GMT, 46 countries have officially reported 12,515 cases of influenza A(H1N1) infection, including 91 deaths.\n\n WHO As of 06:00 GMT, 46 countries have officially reported 12,954 cases of influenza A(H1N1) infection, including 92 deaths.\n\n WHO As of 06:00 GMT, 48 countries have officially reported 13,398 cases of influenza A(H1N1) infection, including 95 deaths\n\n Australia 147 confirmed Cases.\n\n WHO As of 06:00 GMT, 53 countries have officially reported 15,510 cases of influenza A(H1N1) infection, including 99 deaths\n\n Estonia First confirmed case.\n\n Dominican Republic Nine more cases confirmed, for a total of 11 cases nationwide.\n\n WHO As of 06:00 GMT, 62 countries have officially reported 17,410 cases of influenza A(H1N1) infection, including 115 deaths.\n\n Bermuda First case confirmed.\n\n WHO As of 06:00 GMT, 3 June 2009, 66 countries have officially reported 19,273 cases of influenza A(H1N1) infection, including 117 deaths.\n\n Barbados First confirmed case.\n\n WHO As of 06:00 GMT, 69 countries have officially reported 21,940 cases of influenza A(H1N1) infection, including 125 deaths.\n\n Malaysia One more case confirmed. Total: 7\n\n Chile Second death confirmed.\n\n WHO As of 06:00 GMT, 73 countries have officially reported 25,288 cases of influenza A(H1N1) infection, including 139 deaths.\n\n WHO As of 06:00 GMT, 74 countries have officially reported 27,737 cases of influenza A(H1N1) infection, including 141 deaths.\n\n The WHO raises its Pandemic Alert Level to Phase 6, citing significant transmission of the virus.\n\n WHO As of 07:00 GMT, 12 June 2009, 74 countries have officially reported 29,669 cases of Influenza A (H1N1) infections, including 145 deaths.\n\n Bolivia First two domestic infections. Total: 7\n\n Malaysia Five more cases of H1N1 confirmed. Total: 17\n\n Sri Lanka First confirmed case.\n\n Monaco First confirmed case.\n\n Antigua and Barbuda First confirmed case.\n\n Philippines First death in Asia confirmed. H1N1 deaths now confirmed in 3 of 6 WHO regions.\n\n Iraq First seven cases confirmed.\n\n United States CDC FluView Week 25: Widespread influenza activity in ten states, regional in 11 states.\n\n Bosnia and Herzegovina First case confirmed.\n\n Guam First case confirmed.\n\n Australia First confirmed death in NSW. National total: 10\n\n United States CDC FluView Week 26: Widespread influenza activity in nine states, regional influenza activity in 12. \"Over 97% of all subtyped influenza A viruses being reported to CDC were novel influenza A (H1N1) viruses.\"\n\n Peru First two deaths confirmed.\n\n WHO 429 deaths worldwide are reported.\n\n Belize First five cases confirmed.\n\n Tanzania First case confirmed.\n\n United States CDC FluView Week 27: Widespread influenza activity in nine states, regional activity in 12. \"Over 99% of all subtyped influenza A viruses being reported to CDC were novel influenza A (H1N1) viruses.\"\n\n Colombia 6th death case confirmed out of 165 infected\n\n Brazil One more death confirmed. Total Deaths: 3.\n\n Brazil Fourth death confirmed.\n\n Singapore First flu-related death confirmed, that of a 49-year-old man with heart problems.\n\n Hawaii First death, that of a sexagenarian with underlying health problems.\n\n United States CDC FluView Week 28: Widespread influenza activity in seven states, regional activity in 13. \"Over 99% of all subtyped influenza A viruses being reported to CDC were novel influenza A (H1N1) viruses.\"\n\nmale who also suffered from diabetes, hypertension and high cholesterol, from a heart attack caused by severe pneumonia.\n\n Egypt First death confirmed.\n\n Albania First case confirmed.\n\n Canada The fourth case of mutation in the world from Tamiflu has been found in a 60-year-old man from Quebec, Canada.\n\n Hungary First death confirmed, that of a man with underlying heart and lung\ndisease.\n\n The WHO ceases the tracking of cumulative individual cases.\n\n Canada Nova Scotia reports its first H1N1 death.\n\n Indonesia First H1N1 death confirmed, that of a 6-year-old girl suffering from severe pneumonia.\n\n Norway An international 4H youth camp with 1,700 participants from fifteen nations is\nshut down after fifty Norwegian participants catch H1N1.\n\n WHO 816 deaths worldwide are reported.\n\n Japan Third case of Oseltamivir (Tamiflu) resistance.\n\n Swaziland First case confirmed.\n\n Azerbaijan First two cases of A(H1N1) confirmed, those of people who had been on holiday in France and the U.K., respectively.\n\n WHO 1,154 deaths worldwide are reported.\n\n Australia First case of reverse zoonosis confirmed in a piggery in Dunedoo.\n\n South Africa\nFirst confirmed death in South Africa. Total number of deaths at end of epidemic 93.\n\n India First death confirmed.\n\n WHO 1,462 deaths worldwide are reported.\n\n United States CDC FluView Week 31: Widespread influenza activity in four states, regional activity in 10.\n\n Costa Rica President Óscar Arias is confirmed to have swine flu, the first head of state known to have been infected.\n\n WHO 1,799 deaths worldwide are reported.\n\n Madagascar First case confirmed.\n\n Democratic Republic of the Congo First H1N1 case confirmed.\n\n Malaysia Two more deaths confirmed. Total: 64 deaths.\n\n Malaysia Three more deaths confirmed. Total: 67 deaths.\n\n Belarus First H1N1 case confirmed.\n\n Kuwait First death confirmed.\n\n Chile H1N1 is found in turkeys on farms in Chile near the port city of Valparaiso in a unique zoonosis cluster.\n\n New Caledonia First death confirmed.\n\n WHO At least 2,185 deaths worldwide are reported.\n\n Germany 14,325 H1N1 cases confirmed.\n\n Malaysia One more death confirmed. Total: 70 deaths.\n\n Angola First case confirmed.\n\n UN;Chile The United Nations issues a warning regarding the discovery of H1N1-infected turkeys on farms in Chile, an unusual case of zoonosis which raises concerns about possible increased genetic reassortment of the virus.\n\n WHO Most countries in the Southern Hemisphere (represented by Chile, Argentina, New Zealand, and Australia) appear to have passed their peak of influenza activity and returned to baseline activity.\n\nfirst wave of infections in autumn and winter which stresses hospitals in particular; it is noted, however, that\n\"the overall interruption of essential services in (well-prepared) countries has been manageable\".\n\n Bangladesh First death confirmed.\n\n WHO At least 2,837 deaths worldwide are reported.\n\n Argentina The most H1N1 deaths \"per capita\".\n\nunderyling medical conditions.\n\n Macau First death confirmed.\n\n Malaysia One more death confirmed. Total: 73 deaths.\n\n Italy First death confirmed.\n\n United States CDC FluView Week 35: Influenza increases in the U.S. with widespread influenza activity in 11 states and regional activity in 13; the proportion of outpatient visits for influenza-like illness (ILI) is above the national baseline, with four out of ten HHS Surveillance Regions reporting ILI above region-specific baselines. \"97% of all subtyped influenza A viruses being reported to CDC were 2009 influenza A (H1N1) viruses.\"\n\n WHO At least 3,205 deaths worldwide are reported.\n\n Ecuador Ecuador's chief of presidential security, Col. John Merino,\ndies of H1N1 flu\nafter twenty-eight days at Quito Military Hospital.\n\n Suriname First death confirmed.\n\n Madagascar First death confirmed.\n\nAn outbreak is confirmed at the gaming convention PAX in Seattle, Washington.\n\n Malawi First case confirmed.\n\n Australia First case of Oseltamivir (Tamiflu) resistance found.\n\n United States CDC FluView Week 36: Influenza activity continues to increase with widespread influenza activity in twenty-one states, regional influenza activity in nine. Seven of ten HHS Surveillance Regions report ILI activity above region-specific baselines. \"99% of all subtyped influenza A viruses being reported to CDC were 2009 influenza A (H1N1) viruses.\"\n\n WHO At least 3,486 deaths worldwide are reported.\n\n Mozambique First death confirmed, that of a 29-year-old female with an unspecified chronic illness.\n\n Malta Third death confirmed.\n\n Martinique First death confirmed, that of an 18-month-old girl.\n\n Malaysia One more death confirmed. Total: 77 deaths. United States CDC FluView Week 37: Widespread influenza activity in twenty-six states, regional activity in 11. All of the HHS ILI regions report elevated levels of influenza activity above their region-specific baselines except for Region I (New England).\n\n WHO Over 3,917 deaths worldwide are reported.\n\n China A national vaccination campaign begins in China, making it the first country to issue the H1N1 vaccine.\n\n Portugal The first death confirmed, that of a Portuguese man living in France.\n\n Germany First death confirmed, that of a 36-year-old woman who died of a so-called\nsuperinfection which included H1N1.\n\nbegins in early autumn.\n\n United States CDC FluView Week 38: Widespread influenza activity in twenty-seven states, regional activity in 18.\n\n WHO At least 4,108 deaths worldwide are reported.\n\n Cambodia First death confirmed, in Phnom Penh.\n\n Ireland First case of reverse zoonosis in pigs.\n\n Australia Mass vaccination drive begins, the second in the world.\n\n United States CDC FluView Week 39: The proportion of deaths attributed to pneumonia and influenza (P&I) reaches the epidemic threshold with eight out of ten HHS ILI regions reporting region-specific ILI activity above region-specific baseline levels. Widespread influenza activity in thirty-seven states, regional activity in 11.\n\n WHO At least 4,525 deaths worldwide are reported.\n\n United Nations Rich countries should make more vaccines available to poorer nations where the H1N1 virus is starting to hit, United Nations health officials said. They said increased readiness for swine flu was needed in developing countries with weaker medical systems and with large, young populations, who are most vulnerable to the disease. Some countries, such as the United States, Brazil and France, have agreed to make 10 percent of their national vaccine stockpile available to developing countries. Manufacturers have also donated about 150 million doses of vaccine.\n\n China First death confirmed, in Lhasa, Tibet.\n\n Yemen Tamiflu resistance found.\n\n Cuba First deaths confirmed, that of three pregnant women.\n\n WHO At least 4,735 deaths worldwide are reported.\n\n Norway first case of reverse zoonosis detected in Nord-Trøndelag.\n\n Mongolia First cases confirmed.\n\n India Six more deaths confirmed. Total: 405 deaths.\n\n United States An initial shortfall of swine flu vaccine is predicted shortly after the proportion of deaths attributed to pneumonia and influenza goes above the epidemic threshold<ref name=\"https://www.cdc.gov/flu/weekly\">CDC - Seasonal Influenza (Flu) - Weekly Report: Influenza Summary Update. Cdc.gov</ref> in some states, with flu activity widespread in 41 states.<ref name=\"https://www.cdc.gov/H1N1FLU\">CDC 2009 H1N1 Flu. Cdc.gov (2010-07-15)</ref> It is also announced that the number cases, hospitalizations and deaths are unprecedented for this time of year, with flu-like illnesses accounting for 6.1% of all doctor visits, itself an unusually high number.\n\n WHO At least 4,999 deaths worldwide are reported.\n\n United States H1N1 is confirmed in a nasal mucus sample taken from a show hog at the Minnesota State Fair in the first case of zoonosis in the country.\n\n Canada\nH1N1-infected turkeys are confirmed in Ontario, the second such case of zoonosis reported in the world. Iceland\nFirst death confirmed.\n\nIn a unique case of zoonosis, a pet ferret in Oregon is confirmed to be infected with H1N1.\n\n Canada A turkey farm in Ontario province has been confirmed infected with A/H1N1 flu, making Canada the second country to report such infection after Chile, health officials confirmed\n\n Czech Republic First death confirmed.\n\nFears over the H1N1 virus prompts nearly 2,500 school closures.\n\n Germany Third H1N1 death confirmed.\n\nTwo new deaths reported, that of a 14-year-old girl and 40-year-old man. Total deaths: 6\n\n US Various public health departments across the country run out of the H1N1 vaccine due to the shortfall of 10 million doses as the national vaccination campaign gets underway in earnest; 40 million doses had initially been projected. According to the CDC's FluView Week 42, influenza activity is widespread in 48 states, with regional activity in just two: Hawaii and South Carolina.\n\n WHO At least 5,712 deaths worldwide are reported.\n\n China Another death confirmed, in the northwestern province of Xinjiang.\n\n Canada Canada's H1N1 vaccination campaign begins. Russia First two deaths confirmed, in the far eastern city of Chita.\n\n Portugal A ten-year-old dies 48 hours after contracting the flu.\n\n Afghanistan First death confirmed.\n\n ECDC The European Centre for Disease Control reports a total of 302 fatal cases in Europe to date; all of the 27 EU and the four EFTA countries are reporting cases of pandemic (H1N1) 2009 influenza.\n\n Croatia First death confirmed.\n\n Afghanistan Schools are closed for three weeks after the first H1N1 death is recorded.\n\n Turkey Mass vaccinations begin.\n\n WHO At least 6,071 deaths worldwide are reported.\n\n Netherlands First case of Oseltamivir (Tamiflu) resistance found.\n\n San Marino First case confirmed.\n\n Bulgaria A nationwide epidemic is declared.\n\n Bahrain Mass vaccinations begin.\n\n Pakistan First death confirmed.\n\n Latvia First death confirmed.\n\n Greenland First case confirmed.\n\n Armenia First two cases confirmed.\n\n WHO In its 74th update, the WHO reports early signs that the early flu season has peaked in North America, even as the pandemic intensifies across much of Europe and Central and Eastern Asia.\n\n Kosovo First death confirmed.\n\n\"The proportion of outpatient visits for influenza-like illness (ILI) was 5.5% which is above the national baseline of 2.3%. All 10 regions reported ILI above region-specific baseline levels.\"\n\n Tunisia First confirmed deaths.\n\n Hungary National epidemic declared.\n\n Maldives First death confirmed.\n\n Denmark First death confirmed.\n\n US CDC FluView Week 46: Widespread influenza activity in thirty-two states, regional activity in 17. \"The proportion of outpatient visits for influenza-like illness (ILI) was 4.3% which is above the national baseline of 2.3%. All 10 regions reported ILI above region-specific baseline levels.\n\n Romania First death confirmed, that of a 43-year-old man with obesity, high blood pressure, and diabetes.\n\n United States First double infection case confirmed, in a pediatrician in West Virginia.\n\n WHO H1N1 mutations have led to roughly 75 people worldwide developing Tamiflu resistance. Furthermore, the separate D222G or D225G mutation which helps the virus to reach deep into the lungs has been reported in cases both severe and mild in Norway, Ukraine, Brazil, China, Japan, Mexico and the United States.\n\n China Two cases in dogs are confirmed, the first instance of canine zoonosis in the world.\n\n\"The proportion of outpatient visits for influenza-like illness (ILI) was 3.7% which is above the national baseline of 2.3%. Eight of the 10 regions reported ILI at or above region-specific baseline levels. Regions 6 and 10 reported ILI below their region specific baselines.\"\n\n United States The CDC states that H1N1 may have peaked as the number of states reporting widespread influenza dropped from 43 the previous week to 32 this week. Furthermore, influenza-like illness now account for 4.3% of doctor visits, down from 8% four weeks ago (on average, influenza accounts for 2.5% of doctor visits). The proportion of deaths attributed to pneumonia and influenza continues to be higher than expected for this time of year, however. This proportion has remained elevated for eight weeks now.\n\n Saudi Arabia Only five deaths and 73 cases are reported from the haj.\n\n United Kingdom First case of reverse zoonosis in pigs is discovered, in Norfolk.\n\n US CDC FluView Week 48: Widespread flu activity in 14 states, regional activity in 25. \"The proportion of deaths attributed to pneumonia and influenza (P&I) was above the epidemic threshold for the tenth consecutive week. The proportion of outpatient visits for influenza-like illness (ILI) was 2.7% which is above the national baseline of 2.3%.\"\n\n Gaza Strip First five cases are confirmed in the blockaded Gaza Strip.\n\nWith one in six Americans infected, or 15% of the country, nearly 10,000 have died to date, including 1,100 children and 7,500 younger adults. More than 200,000 Americans had been hospitalized to date — roughly the same number who are so affected by the regular seasonal flu variant in an entire year. Furthermore, with 12 million additional doses of H1N1 vaccine being released this week, several states begin to distribute the vaccine to the general public.\n\n North Korea First deaths are confirmed, according to newsletters released by the Seoul-based aid group Good Friends.\n\n Macao First mutation confirmed, in the country's first H1N1 fatality.\n\n Afghanistan The 17th H1N1 fatality is reported.\n\n Georgia First fatality confirmed, that of a 27-year-old man.\n\n US Roughly 100 million H1N1 vaccines become widely available to the general public in pharmacies in several American states as the supply increases and restrictions to high-risk groups are lifted.\n\n Thailand First confirmed case of H1N1 in a pig, in a case of reverse zoonosis in Saraburi Province. The pig recovered.\n\n US CDC FluView Week 50: The CDC reports that levels of influenza are declining steadily, with only seven states reporting widespread influenza activity and 18 reporting regional activity; furthermore, the proportion of deaths attributed to pneumonia and influenza (P&I) is below the epidemic threshold. The CDC also notes that almost all isolates of H1N1 remain sensitive to oseltamivir. \"The proportion of outpatient visits for influenza-like illness (ILI) was 2.3% which is at the national baseline of 2.3%.\"\n\n US First case of canine zoonosis confirmed. The 13-year-old dog from New York state was believed to have contracted the virus from his owner.\n\n US H1N1 is discovered at two North Carolina pig farms, making it the 10th state to identify the virus in animals. The swine caught the disease from infected workers and recovered after becoming moderately ill.\n\n US CDC FluView Week 51: Influenza activity decreases slightly, although the proportion of deaths attributed to P&I remained above the epidemic threshold. \"Four states reported geographically widespread influenza activity, 13 states reported regional influenza activity, the District of Columbia, Puerto Rico, and 19 states reported local influenza activity, Guam and 13 states reported sporadic influenza activity, and one state reported no influenza activity, the U.S. Virgin Islands did not report.\"\n\n WHO At least 12,220 deaths globally are formally confirmed. (By contrast, the WHO estimates that the seasonal flu kills from 250,000 to 300,000 people around the world each year.) Overall, the activity of the H1N1 pandemic has peaked.\n\n WHO In Geneva Dr. Margaret Chan, Director-General of the WHO, remarks in the context of the H5N1 bird flu virus that \"The fact that the long overdue influenza pandemic is so moderate in its impact is probably the best health news of the decade\" but that \"No, the world is not ready for a pandemic to be caused by H5N1.\" Given that H1N1 could still mutate, however, the WHO shall continue to monitor the pandemic for six months to a year. She also said that it would take at least two years before a true death total is established. (Approximately 11,500 people are believed to have died in more than 200 countries.)\n\n A study published in the NEJM finds that \"household contacts less than 18 years of age were twice as susceptible to an acute respiratory illness as were those 19 to 50 years of age, whereas contacts older than 50 years were less susceptible\".\n\n A joint US-UK study shows that children are twice as likely as adults to catch H1N1.\n\n United States CDC FluView Week 52: The proportion of deaths attributed to P&I falls below the epidemic threshold. No influenza activity is reported in Nebraska. \"One state reported geographically widespread influenza activity, 12 states reported regional influenza activity, Puerto Rico, the District of Columbia, and 17 states reported local influenza activity, the U.S. Virgin Islands, Guam, 19 states reported sporadic influenza activity, and one state reported no influenza activity.\"\n\n United States The CDC reports that only one state —Alabama— reports widespread influenza activity.\n\n Mali First case confirmed.\n\n United States According to the CDC no states have reported widespread influenza activity.\n\n Bermuda First death confirmed.\n\n Chad First case confirmed.\n\n Mauritania First case confirmed.\n\n United States The weekly report released by the CDC states that H1N1 activity has either remained stable or decreased over the past week in nine out of the ten regions of the United States. Furthermore, the proportion of deaths attributed to pneumonia and influenza, which technically remains above the epidemic threshold, has declined over the past week.\n\n Senegal First case confirmed\n\n United States According to the CDC, only three states have reported regional influenza activity: Alabama, Georgia, and South Carolina.\n\n Niger First case confirmed\n\n United States According to the CDC, only four states have reported regional influenza activity: Mississippi, Alabama, Georgia, and South Carolina.\n\n United States According to the CDC, five states have reported regional influenza activity: Mississippi, Alabama, Georgia, South Carolina, and Maine.\n\n United States According to the CDC, only three states have reported regional influenza activity: Mississippi, Alabama, and Georgia.\n\n United States According to the CDC, only three states have reported regional influenza activity: Alabama, Georgia, and South Carolina.\n\n Cuba Mass vaccination begins.\n\n United States The CDC Morbidity and Mortality Weekly Report states that inoculation rates varied, with the highest rates in New England and the lowest in the South. (E.g., roughly 39% of the population of Rhode Island is immunized vis-à-vis 13% that of Mississippi.) Among children Georgia had the lowest vaccination rate, with 21%; the state currently has the highest level of H1N1 flu activity.\n\n US According to the CDC, only three states have reported regional influenza activity: Alabama, Georgia, and South Carolina.\n\n US According to the CDC, only three states have reported regional influenza activity: Alabama, Georgia, and South Carolina.\n\n Guinea First case confirmed.\n\n WHO An external panel advises against winding down the pandemic alert level until experts have tracked the southern hemisphere's traditional autumn and winter flu season. Accusations of undue influence from the pharmaceutical industry were also addressed.\n\n US According to the CDC, no states have reported either widespread or regional influenza activity, and four have reported local activity: Hawaii, Alabama, Georgia, and South Carolina.\n\n WHO Director-General Dr. Margaret Chan states that \"It is still premature and too early for us to say we have come to an end of the pandemic influenza worldwide. It would be prudent and appropriate... to continue to monitor the evolution of this pandemic for the next six to 12 months,\" i.e. possibly into 2011. She also remarked that although the United States, Britain and Canada have passed through a second wave of H1N1, outbreaks in India, Egypt and elsewhere are intensifying, and reiterates that countries remain ill-prepared for a bird flu (H5N1) pandemic. More than 200 countries have now been affected by H1N1 with almost 12,000 confirmed deaths worldwide, although the vast majority of those infected recovered without special treatment.\n\n Philippines Mass vaccinations begin.\n\n US Only one state -Hawaii- reports local flu activity, and 28 states report no flu activity.\n\n WHO Director-General Dr. Margaret Chan states at the U.N.'s World Health Assembly that \"We are just plain lucky ... This has been the case with the A/ H1N1 influenza pandemic... The virus did not mutate to a more lethal form. Cases of resistance to oseltamivir remained few and isolated. The vaccine closely matched circulating viruses and showed an excellent safety record,\" Chan said. \"Emergency wards and intensive care units were often strained, few health systems were overwhelmed ... Schools closed, but borders remained open, and disruptions to travel and trade were far less severe than feared,\" she told delegates from the agency's 193 member states. \"Had things gone wrong in any of these areas, we would have a very different agenda before us today,\" she added.\"\n\n US Researchers discover the mutation which had enabled the pandemic.\n\n WHO Director-General Margaret Chan officially declares the H1N1 pandemic over as countries are now seeing a mix of H1N1, H3N2, and B viruses, with some populaces displaying community-level immunity to H1N1 of 20% to 40%. Nevertheless, Angus Nicoll of the European Centre for Disease Prevention and Control urged health officials worldwide to \"prepare for a new type of seasonal flu to appear in the near future that will combine elements of the pandemic A(H1N1) strain, and older A(H3N2) strain and several lesser strains\". \"Pandemics are unpredictable and prone to deliver surprises,\" Director-General Chan noted.\n\n"}
{"id": "47993806", "url": "https://en.wikipedia.org/wiki?curid=47993806", "title": "A. V. Rama Rao", "text": "A. V. Rama Rao\n\nAlla Venkata Rama Rao is an Indian inventor and chemist, known for his pioneering researches in the field of drug technology. He is the founder of the \"A. V. Rama Rao Research Foundation\", a non governmental organization promoting research and doctoral studies in chemistry and \"Avra Laboratories\", an organization dealing in intermediates and \"active pharmaceutical ingredients\", used in therapeutics. An elected fellow of the Indian National Science Academy, Indian Academy of Sciences, National Academy of Sciences, India, and Third World Academy of Sciences (TWAS), Rama Rao is a recipient of several awards such as TWAS Technology Award, VASVIK Industrial Research Award and Om Prakash Bhasin Award. The Government of India awarded him Padma Shri in 1991 and Padma Bhushan in 2016.\n\nRama Rao was born on 2 April 1935 in Guntur, a coastal city in the south Indian state of Andhra Pradesh, to a government employee as one of his nine children. As his father had to work at various places due to frequent transfers, he stayed with his grand parents at Guntur during his school days. He graduated in chemistry (BSc) from A. C. College of Andhra University in 1956 and worked for one year at his alma mater as a demonstrator, before moving to Mumbai to secure his post graduate degree in Pharmaceuticals and Fine Chemicals from the University Department of Chemical Technology (UDCT) of Mumbai University in 1960. This was followed by doctoral studies under the guidance of K. Venkataraman, the first Indian director of the National Chemical Laboratory (NCL), to obtain a PhD in 1965. He continued his research at NCL, working there as a B Grade Scientist, till 1975 when he joined Elias James Corey, 1991 Nobel laureate in Chemistry, at Harvard University for a two-year stint at research along with the American organic chemist. He returned to India in 1977 and continued his researches at NCL for another eight years. In 1985, he was appointed as the director of the Indian Institute of Chemical Technology (IICT) (then known as Regional Research Laboratory) where he worked till 1995. After his superannuation from IICT, he founded Avra Laboratories, at Hyderabad, then capital of Andhra Pradesh, for \"high end contract research\" and manufacture of intermediates and active pharmaceutical ingredients for the medical industry. The company operates out of three centres in Hyderabad and one in Visakhapatanam.\n\nRao married Hymavathy during his early years at NCL and the couple has two sons, Chandra and Ramakrishna, both doctorate holders in chemistry, assisting their father at Avra Laboratories. The family lives in Hyderabad, attending to the businesses of Avra Laboratories and Avra Synthesis, a sister concern. He serves as the Managing Director of both the companies, while holding the directorship of Andhra Sugars Limited, manufacturers of industrial chemicals and supplies.\n\nRao's researchers, in the beginning, was focused on synthetic dyes and advanced studies on plant and insect pigments. His elucidation of the structure of the lac dye as a composition of four different constituents, A, B, C and D variants of the Laccaic acid was one of his early achievements. Working further on the biogenetic origin of the product, he explored other insect pigments such as Kermesic acid, Erythrolaccin, Ceroalbolinic acid which led to the revision of the established concepts of their origin. His researches led to the isolation of 100 new compounds from plants and insects. Association with Corey at Harvard University shifted his focus to studies related to the synthesis of biologically active natural products and he turned his attention to antitumor antibiotics, macrolide, immunosuppressants and cyclic peptides. After his return to India and resuming his career at NCL, he set up a school for synthesis of biofunctional molecules. Later, he guided the Indian Institute of Chemical Technology to become one of the top schools in India and introduced private and public sector industry participation in the research projects of the institution. The laboratory he established at IICT was fully funded by the members of the industry. He has mentored 109 research scholars in their doctoral studies as well as several post doctoral fellows.\n\nThe contributions of Rama Rao are reported to be noteworthy in the area of organic synthesis, especially asymmetric synthesis. He is known to have developed cheaper methodology for the synthesis of anti-tumour antibiotics such as Anthracyclines, Fredericamycin-A, Cervinomycins A1 and A2, Aronorosin, and Lavendamycin. He evolved a new method for the construction of the spiro[2,2]-nonane system, a constituent of Fredericamycin A, a first time achievement in the world, and succeeded in its total synthesis. He proposed alternative methodologies for the synthesis of MeBmt, a variety of amino acid present in cyclosporin-A and of FK-506k, a 23-membered macrolide with 14-asymmetric carbons, which are reported to be noteworthy achievements in the field of asymmetric synthesis. His work also covered the synthesis of depsipeptides such as Jaspamide and Geodiamolides and macrolides, namely Zearalenone, Rifamycin-S, Rhizoxin and Rapamycin.\n\nRao is the pioneer of Chiral synthesis and technology in India and is known to have synthesized compounds of high structural diversity like Coriolic acid, Dimorphicolic acid, β-Lactam antibiotics, Azamacrolides, Camptothecin, Andrimid and Chrysanthemic acid. His work on K-13 has been adopted for the synthesis of Vancomycin and has helped in the synthesis of vancomycinic acid and the biphenyl segment of Vancomycin. Cipla, an Indian drug manufacturer, utilised the cost effective methodology Rao introduced in the manufacture of Azidothymidine (AZT), the first curative drug in the disease management of AIDS. His researches have also helped in the synthesis of the HIV inhibitors namely Betzalladines, Calanolides, Mischellamines and Abbot's protease inhibitor. Cipla have acknowledged Rao's contributions in the formulations of several drugs such as Salbutamol, Vinblastine, Vincristine and Etoposide, apart from AZT.\n\nIn 1995, when Rao set out to establish his own research centre, Avra Laboratories, several agencies such as Dai-ichi Karkaria, G.D. Searle, LLC and Council for Scientific and Industrial Research provided him financial and infrastructural assistance. He undertook several research assignments under the aegis of the centre for drug manufacturers like G. D. Searle, Pfizer and Bristol-Myers Squibb; his successful assignment of stabilizing a molecule with anti-asthmatic properties for Cytomed, a US drug manufacturer, was one of them. His early researches on plant and insects have been documented in over 70 scientific papers and the latter day work by way of over 190 scientific papers, totalling 260 papers, published in peer reviewed journals. Chemical Reviews, a known journal, invited him to contribute to their special issue on the synthesis of bio-functional molecules in 1995. He holds 30 patents, for chemical synthesis and isolation processes, many of which are in use with drug manufacturers in the US and India. Besides being a member of many government policy making bodies, he has been associated with the World Health Organization and the Ozone Cell of United Nations Environmental Programme. He has also delivered many keynote addresses and Endowment lectures at various conferences. A. V. Rama Rao Research Foundation, the science forum he founded, promotes research, conducts doctoral courses in association with Osmania University and has instituted awards, together with Indian Institute of Chemical Engineers (IICHe), for recognising excellence in chemical research.\n\nThe Indian Academy of Sciences, Bengaluru, elected Rao as their Fellow in 1985. The Indian National Science Academy and the National Academy of Sciences, India, the two other major science academies in India, followed suit, by electing him as a Fellow in 1986 and 1989, respectively. Subsequently, the Third World Academy of Sciences also elected him as a Fellow in 1995. He received the K. G. Naik Medal in 1982 and, two years later, he was awarded the 1984 VASVIK Industrial Research Award. The Government of India included him in the 1991 Republic Day honours list for the civilian award of the Padma Shri. He was awarded the Durga Prasad Khaitan Memorial Medal of the Asiatic Society in 1992 and the Council for Scientific and Industrial Research (CSIR) Technology Award reached him in 1993.\n\nThe Academy of Sciences for the Developing World (TWAS) honoured him with their Technology Award in 1994, making him the first Indian chemist to receive the award. He received three more awards the same year, the first, UDCT Distinguished Alumni and UDCT Diamond Award, from his alma mater, University Department of Chemical Technology, followed by CSIR Business Prize from the Council for Scientific and Industrial Research and Om Prakash Bhasin Award from Shri Om Prakash Bhasin Foundation. The first decade of the 21st century saw him receiving three awards, Chemical Research Society Gold Medal in 2006, Indian Science Congress Presidential Gold Medal in 2007 and Institute of Chemical Technology Platinum Award in 2009. In 2012, he was awarded the Dr. Yellapragada Subba Rao Award, by the Nellore based foundation, in the name of the late Indian biochemist. He is also a recipient of P. C. Ray Medal, Dr. Y. Nayudamma Gold Medal, INSA Viswakarma Medal, Ranbaxy Research Foundation Award and FICCI Award. Jawaharlal Nehru Centre for Advanced Scientific Research instituted a lecture series, \"A. V. Rama Rao Lecture Series\", composed of Foundation lectures and Prize lectures, to commemorate his 70th birthday. Indian Space Research Organization (ISRO), in association with Avra Laboratories, has also instituted an award lecture in his honour. Archive for Organic Chemistry issued a commemorative issue in 2005, to mark the 70th birth year of Rama Rao.\n\n\n\n"}
{"id": "710243", "url": "https://en.wikipedia.org/wiki?curid=710243", "title": "Abortion in the Netherlands", "text": "Abortion in the Netherlands\n\nAbortion in the Netherlands was fully legalized on November 1, 1984, allowing abortions to be done on-demand until the twenty-first week. Abortion for medical reasons can be performed until 24 weeks. There is a five-day waiting period for abortions.\n\nAbortion was deemed illegal under the Penal Code of 1886. Convictions were all but precluded, however, by a requirement that the prosecution prove that the fetus had been alive until the abortion. The Morality Acts of 1911 closed this loophole, and strictly barred all abortions, except those performed to save the life of the pregnant woman. \n\nLegalization reached the forefront of public debate in the Netherlands during the 1970s as many other Western European countries liberalized their laws. The Staten-Generaal, however, was unable to reach a consensus between those opposing legalization, those in favor of allowing abortion, and those favoring a compromise measure. A controversial abortion law was passed in 1981 with single swing votes: 76 pro and 74 against in the House of Representatives, and 38 pro and 37 against in the Senate. The law left abortion a crime, unless performed at a clinic or hospital that is issued an official abortion certificate by the Dutch government, and the woman who is asking for the abortion declares she considers it to be an emergency. The law came into effect on November 1, 1984.\n\nCurrently, there are a little over 100 Dutch general hospitals certified to perform abortions, and 17 specialized abortion clinics. More than 90% of abortions take place in the specialized clinics.\n\nIn the Netherlands, abortion performed by a certified clinic or hospital is effectually allowed at any point between conception and viability, subject to a five-day waiting period. After the first trimester, the procedure becomes stricter, as two doctors must consent to treatment. In practice, abortions are performed until approximately 24 weeks into pregnancy, although this limit is the topic of ongoing discussion among physicians in the Netherlands, since, due to recent medical advancements, a fetus can sometimes be considered viable prior to 24 weeks. As a result of this debate, abortions are only rarely performed after 22 weeks of pregnancy. Abortions must be performed in a hospital.\n\nThe number of abortions has been relatively stable in the 21st century, around 28,000 per year. , the abortion rate was 9.7 abortions per 1000 women aged 15–44 years.\n\n\n"}
{"id": "40148358", "url": "https://en.wikipedia.org/wiki?curid=40148358", "title": "Adipsia", "text": "Adipsia\n\nAdipsia, also known as hypodipsia, is a symptom of inappropriately decreased or absent feelings of thirst. It involves an increased osmolality or concentration of solute in the urine, which stimulates secretion of antidiuretic hormone (ADH) from the hypothalamus to the kidneys. This causes the person to retain water and ultimately become unable to feel thirst. Due to its rarity, the disorder has not been the subject of many research studies.\n\nAdipsia may be seen in conditions such as diabetes insipidus and may result in hypernatremia. It can occur as the result of abnormalities in the hypothalamus, pituitary and corpus callosum, as well as following pituitary/hypothalamic surgery.\n\nIt is possible for hypothalamic dysfunction, which may result in adipsia, to be present without physical lesions in the hypothalamus, although there are only four reported cases of this. There are also some cases of patients experiencing adipsia due to a psychiatric disease. In these rare psychogenic cases, the patients have normal levels of urine osmolality as well as typical ADH activity.\n\nDopamine, a neurotransmitter, has been linked with feeding behaviors. In an experiment, scientists measured how much food and water mice consumed when they were born without dopamine in their systems. They found that without dopamine, the mice would starve and be dehydrated to the point of death. The scientists then injected the mice without dopamine with its precursor, L-DOPA, and the mice started eating again. But, even though the mice were born without dopamine in their systems, they still had the capacity to control their feeding and drinking behaviors, suggesting that dopamine does not play a role in developing those neural circuits. Instead, dopamine is more closely related to the drive for hunger and thirst. Although the lack of dopamine resulted in adipsia in these rats, low levels of dopamine do not necessarily cause adipsia.\n\nOther findings in support of the role of dopamine in thirst regulation involved the nigrostriatal pathway. After completely degenerating the pathway, the animal becomes adipsic, aphagic, and loses its interest in exploring. Although dopamine plays a role in adipsia, there is no research involving exclusively the relationship between adipsia and dopamine, as changes in dopamine simultaneously mediate changes in eating and curiosity, in addition to thirst.\n\nThe area of the brain that regulates thirst is located in the anterior part of the hypothalamus. The anterior hypothalamus is in close proximity to osmoreceptors which regulate the secretion of antidiuretic hormone (ADH). ADH secretion is one of the primary mechanisms by which sodium and osmolar homeostasis are regulated, ADH is also secreted when there are small increases in serum osmolality. Thirst is triggered by increases in serum osmolality and along with increases ADH secretion. Both serum osmolality and ADH maintain normal ranges of serum osmolality.\n\nAdipsia can tend to result from lesions to hypothalamic regions involved in thirst regulation. These lesions can be congenital, acquired, trauma, or even surgery. Lesions or injuries to those hypothalamic regions cause adipsia because the lesions cause defects in the thirst regulating center which can lead to adipsia. Lesions in that region can also cause adipsia because of the extremely close anatomical proximity of the hypothalamus to ADH-related osmoreceptors.\n\nDiagnosing adipsia can be difficult as there is no set of concrete physical signs that are adipsia specific. Changes in the brain that are indicative of adipsia include those of hyperpnea, muscle weakness, insomnia, lethargy, and convulsions (although uncommon except in extreme cases of incredibly rapid rehydration). Patients with a history of brain tumors, or congenital malformations, may have hypothalamic lesions, which could be indicative of adipsia. Some adults with Type A adipsia are anorexic in addition to the other symptoms.\n\nInitial testing for adipsia involves electrolyte, blood urea nitrogen and creatinine levels, serum and urine osmolality, blood hormone levels, like vasopressin. In patients who have defects in thirst regulation and vasopresin secretion, serum vassopresin levels are low or absent. Measurements of urine electrolytes and osmolality are critical in determining the central, rather than renal, nature of the defect in water homeostasis. In adipsia, the fractional excretion of sodium is less than 1%, unless a coexisting defect in AVP secretion is present. In salt intoxication, the urine sodium concentrations are very high and fractional excretion of sodium is greater than 1%. Initial test results may be suggestive of diabetes insipidus. The circulating AVP levels tend to be high, which indicate an appropriate response of the pituitary to hyperosmolality. Patients may have mild stable elevations of serum sodium concentrations, along with elevations in both BUN and creatinine levels and in the BUN/creatinine ratio.\nType A (essential hypernatremia syndrome) involves an increase of the level in which solvent molecules can pass through cell membranes (osmotic threshold) for vasopressin release and the activation of the feeling of thirst. This is the most characterized sub-type of adipsia, however there is no known cause for Type A adipsia. There is debate over whether osmoreceptor resetting could lead to the increase in threshold. Other studies have shown that it is the loss of osmoreceptors, not resetting, that cause the change in threshold. Patients with Type A adipsia can be at risk of seizures if they rapidly re-hydrate or quickly add a significant amount of sodium into their bodies. If not treated, Type A adipsia could result in both a decrease in the size of the brain and bleeding in the brain.\n\nType B adipsia occurs when vasopressin responses are at decreased levels in the presence of osmotic stimuli. Although minimal, there is still some secretion of AVP. This type may be due to some elimination of osmoreceptors.\n\nType C adipsia (type C osmoreceptor dysfunction) involves complete elimination of osmoreceptors, and as a result have no vasopressin release when there normally would be. Type C is generally the adipsia type found in patients with adipsic diabetes insipidus.\n\nType D is the least commonly diagnosed and researched type of adipsia. The AVP release in this subtype occurs with normally functioning levels of osmoregulation.\n\nPeople affected by adipsia lack the ability to feel thirst, thus they often must be directed to drink. Adipsic persons may undergo training to learn when it is necessary that they drink water. Currently, there is no medicine available to treat adipsia. For people with adipsia because of hypothalamic damage, there is no surgical or medicinal option to fix the damage. In some cases where adipsia was caused by growths on thirst centers in the brain, surgical removal of the growths was successful in treating adipsia. Although adipsic persons must maintain a strict water intake schedule, their diets and participation in physical activities are not limited.\nPeople affected by diabetes insipidus have the option of using the intranasal or oral hormone desmopressin acetate (DDAVP), which is molecularly similar enough to vasopressin to perform its function. In this case, desmopressin helps the kidneys to promote reabsorption of water. Some doctors have reported success in treating psychogenic adipsic patients with electroconvulsive therapy, although the results are mixed and the reason for its success is still unknown. Additionally, some patients who do not successfully complete behavioral therapy may require a nasogastric tube in order to maintain healthy levels of fluids.\n\n"}
{"id": "35807581", "url": "https://en.wikipedia.org/wiki?curid=35807581", "title": "African Nutrition Leadership Programme", "text": "African Nutrition Leadership Programme\n\nThe African Nutrition Leadership Programme (ANLP) is a 10 days training course that started in 2002 to assist the development of future leaders in the field of human nutrition in Africa. The emphasis of the programme is on understanding and developing the qualities and skills of leaders, team building, communication and understanding nutrition information in a broader context. The long-term aim of the ANLP is to meet the demands for leadership in Africa to solve its nutritional challenges.\n\nThe programme is designed for individuals who have experience in various fields of nutrition. Preference will be given to candidates with a postgraduate qualification, postdoctoral fellows and candidates with comparable working experience in the broader human nutrition sciences, studying or working in Africa.\n\nThe ANLP is a leadership development and networking seminar aimed at assisting the development of future leaders in the field of human nutrition in Africa. Emphasis is placed on understanding the qualities and skills of leaders, team building, communication and nutrition information in a broader context, and to understanding the role of nutrition science in the world around us.\n\n\nThe course is held each year at Elgro River Lodge, Free State, South Africa.\n\nEach year, an average of 30 candidates from all around Africa participate to the ANLP.\n\n"}
{"id": "35685115", "url": "https://en.wikipedia.org/wiki?curid=35685115", "title": "António Mendes Correia", "text": "António Mendes Correia\n\nAntónio Mendes Correia (1888 - 1960) was a Portuguese anthropologist, physician and scientist.\n"}
{"id": "1840155", "url": "https://en.wikipedia.org/wiki?curid=1840155", "title": "Biodistribution", "text": "Biodistribution\n\nBiodistribution is a method of tracking where compounds of interest travel in an experimental animal or human subject. For example, in the development of new compounds for PET (positron emission tomography) scanning, a radioactive isotope is chemically joined with a peptide (subunit of a protein). This particular class of isotopes emits positrons (which are antimatter particles, equal in mass to the electron, but with a positive charge). When ejected from the nucleus, positrons encounter an electron, and undergo annihilation which produces two gamma rays travelling in opposite directions. These gamma rays can be measured, and when compared to a standard, quantified.\n\nFor example, a new compound would be injected intravenously into a group of 16-20 rodents (typically mice or rats). At intervals of 1, 2, 4, and 24 hours, smaller groups (4-5) of the animals are euthanized, then dissected. The organs of interest (usually: blood, liver, spleen, kidney, muscle, fat, adrenals, pancreas, brain, bone, stomach, small intestine, and upper and lower large intestine, etc.) are placed in pre-weighed containers, then into a device that measures gamma radiation. The results give a dynamic view of how the compound moves through the animal.\nA useful compound is one that is used either for the medical imaging of certain body parts or tumors (at low doses of radioactivity) or treating tumors (at high doses of radioactivity).\n\nIn gene therapy, gene delivery vectors, such as viruses, can be imaged according either to their particle biodistribution or their transduction pattern. The former means labeling the viruses with a contrast agent, being visible in some imaging modality, such as MRI or SPECT/PET and latter means visualising the marker gene of gene delivery vector to be visible by the means of immunohistochemical methods, optical imaging or even by PCR. Non-invasive imaging has gained popularity as the imaging equipment has become available for research use from clinics.\n\nFor example, avidin-displaying baculoviruses could be imaged in rat brain by coating them with biotinylated iron particles, rendering them visible in MR imaging. The biodistribution of the iron-virus particles was seen to concentrate on the choroid plexus cells of lateral ventricles.\n"}
{"id": "33745761", "url": "https://en.wikipedia.org/wiki?curid=33745761", "title": "Cannibalism in poultry", "text": "Cannibalism in poultry\n\nCannibalism in poultry is the act of one individual of a poultry species consuming all or part of another individual of the same species as food. It commonly occurs in flocks of domestic hens reared for egg production, although it can also occur in domestic turkeys, pheasants and other poultry species. Cannibalism can occur as a consequence of feather pecking which has caused denuded areas and bleeding on a bird's skin. Cannibalism can cause large mortality rates within the flock and large decreases in production due to the stress it causes. Vent pecking, sometimes called 'cloacal cannibalism', is considered to be a separate form of cannibalistic pecking as this occurs in well-feathered birds and only the cloaca is targeted.\n\nPoultry species which exhibit cannibalism are omnivores. For example, hens in the wild often scratch at the soil to search for seeds, insects and even larger animals such as lizards or young mice, although they are mainly herbivorous in adulthood. Feather pecking is often the initial cause of an injury which then attracts the cannibalistic pecking of other birds – perhaps as re-directed foraging or feeding behaviour. In the close confines of modern farming systems, the increased pecking attention is easily observed by multiple birds which join in the attack, and often the escape attempts of the cannibalised bird attract more pecking attention.\n\nChicks brooded with a hen had lower mortality levels due to feather pecking and cannibalism compared to non-brooded chicks. This may indicate the hen guides the chicks to peck at more rewarding substrates, such as food or litter.\n\nCannibalism among layer hen flocks is highly variable; when it is not problematic, mortalities among production systems are generally similar. Published data on the prevalence of cannibalism could be misleading due to the inclusion of vent-pecking by some researchers but not others. Mortalities, due mainly to cannibalism, can be up to 15% in egg-laying flocks housed in aviaries, straw yards, and free-range systems. Because egg-laying strains of chickens can be kept in smaller group sizes in cage systems, cannibalism is reduced, leading to a lowered trend in mortality as compared to non-cage systems. In a study which examined 'skin damage' (most of which would have been cause by pecking) on hens at the end of their productive lives, damage was lowest in hens from free range systems, followed by barns, then furnished cages, and highest in conventional or battery cages.\n\nBeak-trimming is the most common method of preventing or reducing injuries by cannibalism. In a three-year study of floor-housed laying hens, death by cannibalism was reported as 7% in beak-trimmed birds but was increased to 18% in non-trimmed birds.\n\nIncreased group sizes in larger cages or floor systems can elevate the risk of cannibalism and feather pecking, probably due to the spread of the behaviour through social learning.\n\nLights are sometimes provided in nest-boxes to attract hens to use the nests, but this practice has been correlated with an increased risk of cannibalism.\n\nRearing chicks with access to perches by four weeks of age has been associated with increased use of perches, and reduced cannibalism, in adulthood.\n\nA sibling-selection programme has genetically selected a low mortality line which shows decreased mortality from cannibalism compared to a control line.\n\nCannibalism may be reduced by fitting hens with a range of eyewear. Rose-tinted spectacles or contact lenses have been used. Opaque spectacles, or blinders, have also been used. For both spectacles and blinders, there are versions that are held in place by circlips into the nares of the bird, or others in which a pin pierces through the nasal septum: this latter method is illegal in the UK. It is theorized that — as with placing red filters over windows, or keeping the birds in red light — the coloured lenses prevent the birds from recognising the blood or raw flesh of other hens, thereby diminishing cannibalistic behaviour.\n\n"}
{"id": "5260658", "url": "https://en.wikipedia.org/wiki?curid=5260658", "title": "Compassion fatigue", "text": "Compassion fatigue\n\nCompassion fatigue, also known as secondary traumatic stress (STS), is a condition characterized by a gradual lessening of compassion over time. Scholars who study compassion fatigue note that the condition is common among workers who work directly with victims of disasters, trauma, or illness, especially in the health care industry. Professionals in other occupations are also at risk for experiencing compassion fatigue, e.g. attorneys, child protection workers and veterinarians. Other occupations include: therapists, child welfare workers, nurses, radiology technologists, teachers, psychologists, police officers, paramedics, emergency medical technicians (EMTs), firefighters, animal welfare workers and health unit coordinators. Non-workers, such as family members and other informal caregivers of people who are suffering from a chronic illness, may also experience compassion fatigue. It was first diagnosed in nurses in the 1950s.\n\nPeople who experience compassion fatigue can exhibit several symptoms including hopelessness, a decrease in experiences of pleasure, constant stress and anxiety, sleeplessness or nightmares, and a pervasive negative attitude. This can have detrimental effects on individuals, both professionally and personally, including a decrease in productivity, the inability to focus, and the development of new feelings of incompetency and self-doubt.\n\nJournalism analysts argue that news media have caused widespread compassion fatigue in society by saturating newspapers and news shows with decontextualized images and stories of tragedy and suffering. This has caused the public to become desensitized or resistant to helping people who are suffering.\n\nCompassion fatigue has been studied by the field of traumatology, where it has been called the \"cost of caring\" for people facing emotional pain. \nCompassion fatigue has also been called secondary victimization, secondary traumatic stress, vicarious traumatization, and secondary survivor. Other related conditions are rape-related family crisis and \"proximity\" effects on female partners of war veterans. Compassion fatigue has been called a form of burnout in some literature. However, unlike compassion fatigue, “burnout” is related to chronic tedium in careers and the workplace, rather than exposure to specific kinds of client problems such as trauma. fMRI-rt research suggests the idea of compassion without engaging in real-life trauma is not exhausting itself. According to these, when empathy was analyzed with compassion through neuroimaging, empathy showed brain region activations where previously identified to be related to pain whereas compassion showed warped neural activations.\n\nIn academic literature, the more technical term \"secondary traumatic stress disorder\" may be used. The term \"compassion fatigue\" is considered somewhat euphemistic. Compassion fatigue also carries sociological connotations, especially when used to analyse the behavior of mass donations in response to the media response to disasters. One measure of compassion fatigue is in the ProQOL, or Professional Quality of Life Scale. Another is the Secondary Traumatic Stress Scale.\n\nSeveral personal attributes place a person at risk for developing compassion fatigue. Persons who are overly conscientious, perfectionists, and self-giving are more likely to suffer from secondary traumatic stress. Those who have low levels of social support or high levels of stress in personal life are also more likely to develop STS. In addition, previous histories of trauma that led to negative coping skills, such as bottling up or avoiding emotions, having small support systems, increase the risk for developing STS.\n\nMany organizational attributes in the fields where STS is most common, such as the healthcare field, contribute to compassion fatigue among the workers. For example, a “culture of silence” where stressful events such as deaths in an intensive-care unit are not discussed after the event is linked to compassion fatigue. Lack of awareness of symptoms and poor training in the risks associated with high-stress jobs can also contribute to high rates of STS.\n\nBetween 16% and 85% of health care workers in various fields develop compassion fatigue. In one study, approximately 85% of emergency room nurses met the criteria for compassion fatigue. In another study, more than 25% of ambulance paramedics were identified as having severe ranges of post-traumatic symptoms. In addition, 34% of hospice nurses in another study met the criteria for secondary traumatic stress/compassion fatigue.\n\nHealthcare professionals experiencing compassion fatigue may find it difficult to continue doing their jobs. They can be exposed to trauma while trying to deal with compassion fatigue, potentially pushing them out of their career field. If they decide to stay, it can negatively affect the therapeutic relationship they have with patients because it depends on forming an empathetic, trusting relationship that could be difficult to make in the midst of compassion fatigue. Because of this, healthcare institutions are placing increased importance on supporting their employees emotional needs so they can better care for patients.\n\nCaregivers for dependent people can also experience compassion fatigue; this can become a cause of abusive behavior in caring professions. It results from the taxing nature of showing compassion for someone whose suffering is continuous and unresolvable. One may still care for the person as required by policy, however, the natural human desire to help them is significantly diminished. This phenomenon also occurs for professionals involved with long-term health care. It can also occur for loved ones who have institutionalized family members. These people may develop symptoms of depression, stress, and trauma. Those who are primary care providers for patients with terminal illnesses are at a higher risk of developing these symptoms. In the medical profession, this is often described as \"burnout\": the more specific terms secondary traumatic stress and vicarious trauma are also used. Some professionals may be predisposed to compassion fatigue due to personal trauma.\n\nMental health professionals are another group that often suffer from compassion fatigue, particularly when they treat those who have suffered extensive trauma. A study on mental health professionals that were providing clinical services to Katrina victims found that rates of negative psychological symptoms increased in the group. Of those interviewed, 72% reported experiencing anxiety, 62% experienced increased suspiciousness about the world around them, and 42% reported feeling increasingly vulnerable after treating the Katrina victims.\n\nCompassion fatigue, or vicarious trauma, refers to the secondary exposure to trauma seen in fields where workers are directly in contact with the sufferer(s). Symptoms manifest as visualizing the event, insomnia, fear, and avoiding anything that can remind someone of what happened. Those caring for people who have experienced trauma can experience a change in how they view the world; they see it more negatively. It can negatively affect the worker's sense of self, of safety, and of control. Those with a better ability to empathize and be compassionate are at a higher risk of developing compassion fatigue.\n\nThose who experience compassion fatigue, or STS, can begin to exhibit patterns where they feel disengaged, inadequate, overwhelmed, parental, undervalued, over-involved, sexualized, or positive.\n\nAnother name and concept directly tied to compassion fatigue is moral injury. Moral injury in the context of healthcare was directly named in the \"Stat News\" article by Drs. Wendy Dean and Simon Talbot, entitled \"Physicians aren’t ‘burning out.’ They’re suffering from moral injury.\" The article and concept goes on to explain that physicians (in the United States) are caught in double and triple and quadruple binds between their obligations of electronic health records, their own student loans, the requirements for patient load through the hospital and number of procedures performed – all while working towards the goal of trying to provide the best care and healing to patients possible. However, the systemic issues facing physicians often cause deep distress because the patients are suffering, despite a physician's best efforts. This concept of Moral Injury in healthcare is the expansion of the discussion around compassion fatigue and 'burnout.'\n\nRecent research shows that a growing number of attorneys who work with victims of trauma are exhibiting a high rate of compassion fatigue symptoms. In fact, lawyers are four times more likely to suffer from depression than the general public. They also have a higher rate of suicide and substance abuse. Most attorneys, when asked, stated that their formal education lacked adequate training in dealing with trauma. Besides working directly with trauma victims, one of the main reasons attorneys can develop compassion fatigue is because of the demanding case loads, and long hours that are typical to this profession.\n\nThere is an effort to prepare those in the healthcare professions to combat compassion fatigue through resiliency training. Teaching workers how to relax in stressful situations, be intentional in their duties and work with integrity, find people and resources who are supportive and understand the risks of compassion fatigue, and focus on self-care are all components of this training.\n\nStress reduction and anxiety management practices have been shown to be effective in preventing and treating STS. Taking a break from work, participating in breathing exercises, exercising, and other recreational activities all help reduce the stress associated with STS. Conceptualizing one's own ability with self-integration from a theoretical and practice perspective helps to combat criticized or devalued phase of STS. In addition, establishing clear professional boundaries and accepting the fact that successful outcomes are not always achievable can limit the effects of STS.\n\nSocial support and emotional support can help practitioners maintain a balance in their worldview. Maintaining a diverse network of social support, from colleagues to pets, promotes a positive psychological state and can protect against STS.\n\n\n"}
{"id": "613318", "url": "https://en.wikipedia.org/wiki?curid=613318", "title": "Congenital insensitivity to pain", "text": "Congenital insensitivity to pain\n\nCongenital insensitivity to pain (CIP), also known as congenital analgesia, is one or more rare conditions in which a person cannot feel (and has never felt) physical pain. The conditions described here are separate from the HSAN group of disorders, which have more specific signs and cause. Because feeling physical pain is vital for survival, CIP is an extremely dangerous condition. It is common for people with the condition to die in childhood due to injuries or illnesses going unnoticed. Burn injuries are among the more common injuries.\n\nFor people with this disorder, cognition and sensation are otherwise normal; for instance, patients can still feel discriminative touch (though not always temperature), and there are generally no detectable physical abnormalities.\n\nBecause children with the disorder cannot feel pain, they may not respond to problems, thus being at a higher risk of more severe diseases. Children with this condition often sustain oral cavity damage both in and around the oral cavity (such as having bitten off the tip of their tongue) or fractures to bones. Unnoticed infections and corneal damage due to foreign objects in the eye are also seen.\n\nThere are generally two types of non-response exhibited:\n\nIt may be that the condition is caused by increased production of endorphins in the brain. In this case, naloxone may be a treatment, but it does not always work.\nIn all cases, this disorder can be in the voltage-gated sodium channel SCN9A (Na1.7). Patients with such mutations are congenitally insensitive to pain and lack other neuropathies. There are three mutations in SCN9A: W897X, located in the P-loop of domain 2; I767X, located in the S2 segment of domain 2; and S459X, located in the linker region between domains 1 and 2. This results in a truncated non-functional protein. Na1.7 channels are expressed at high levels in nociceptive neurons of the dorsal root ganglia. As these channels are likely involved in the formation and propagation of action potentials in such neurons, it is expected that a loss of function mutation in SCN9A leads to abolished nociceptive pain propagation.\n\nPRDM12 gene is normally switched on during the development of pain-sensing nerve cells. People with homozygous mutations of the PRDM12 gene experience congenital insensitivity to pain (CIP).\n\nDevelopmental disabilities such as autism can include varying degrees of pain insensitivity as a sign. However, since these disorders are characterized by dysfunction of the sensory system in general, this specific condition is not in itself an indicator of any of these conditions.\n\nThe opioid antagonist naloxone allowed a woman with congenital insensitivity to pain to experience it for the first time. Similar effects were observed in Na1.7 null mice treated with naloxone. As such, opioid antagonists like naloxone and naltrexone may be effective in treating the condition.\n\nCongenital insensitivity to pain is found in Vittangi, a village in Kiruna Municipality in northern Sweden, where nearly 40 cases have been reported. Some Americans also have it.\n\n\n"}
{"id": "53631891", "url": "https://en.wikipedia.org/wiki?curid=53631891", "title": "Cuisine of Menorca", "text": "Cuisine of Menorca\n\nMinorcan cuisine refers to the typical food and drink of Minorca.\n\nMinorca is a rocky island in the Balearic archipelago in Spain, consisting of eight municipalities. Featuring a Mediterranean climate, the weather is milder in the south while in the north there are strong winds all year round. Marine salt, carried by the wind to the pastures where cows graze, is what gives the cheese its typical flavour. Fish is a certain source of food, but additionally there are horses, pigs (used for cold cuts) and cows (the skin of which is used to produce leather, and the milk to produce cheese). Agriculture is small-scale and varied, consisting of typical Mediterranean products. Within this typical Mediterranean cuisine there are also the influences of various invading people, particularly the English, who brought \"plum cake\", puddings, and punch. The rural and marine cuisine is mostly based on greens and vegetables from one's own garden, locally produced meat, and fish and seafood caught in the same day. Cold cuts are used as seasoning. Olive oil, although not produced on the island, is also a fundamental ingredient in local dishes.\n\nMinorcan cuisine is at times a survival cuisine, which preserves the original flavour of its high-quality products to the maximum. It is simple, with few complications, and above all seasonal. It is based on fishing, particularly longline fishing, and on seafood, especially crustaceans, clams and squid. Fruits and vegetables are cultivated in as much variety as possible, and on a small scale, only for local consumption.\n\nUntil the second half of the twentieth century, goats were in such abundance that they were only eaten when there was a famine, caused by spoiled crops or insufficient fishing. Today, they are a luxury. The legs of Minorcan kids are particularly appreciated.\n\nThere were so many rabbits on the island that Roman emperor Augustus had to send ferrets to help with hunting them; for this reason, rabbit is a common element of the cuisine. In later times, there were periods when hunting them was forbidden. In the seventeenth century, The English unsuccessfully attempted to introduce deer and hares. Few are left nowadays, but rabbits and various fowl are still hunted or bred.\n\nThe recipes and ways of Minorcan cuisine have been mostly transmitted through oral tradition, as opposed to Catalonia, for example, where recipe books can be found even from the Middle Ages. In Minorca, the first written mentions of its cuisine are only found in 1891, in some notes belonging to Archduke Ludwig Salvator of Austria, who references some typical cooking but without any recipes. There is nothing else until 1923, when \"De re cibaria,\" by Pedro Ballester, is published, a \"major work\" that collects a substantial part of popular wisdom and offers detailed anonymous recipes, which nevertheless require prior knowledge of local cuisine in order to be interpreted.\n\nMinorcan cuisine is based on local products, from land or sea. Classic Mediterranean crops had a strong influence, encouraging the use of olive oil, wine, legumes and foods pickled in salt. The substratum of Arab culture is also important, as well as additions from French and English cuisine in particular, owing to their respective periods of domination in the eighteenth century.\n\nBeing a small island meant that the region passed through periods of scarcity, for various reaons, yet very flavourful dishes were still created despite also being very modest. Simpler versions of dishes that once belonged only to a minority were created, that were now accessible to everyone, under any circumstances. This is known as 'survival cuisine', and it is not absolutely exclusive to the island. Even during times of abundance, it is believed that a dish containing superfluous ingredients is not necessarily better, but actually the opposite, and the simplicity of a cuisine that would normally be considered 'poor and rural' is more appreciated.\n\nEven today, when most products can be obtained all year round, Minorca has a seasonal cuisine, with seasonal ingredients and recipes, which follows the cycles of nature and marked holidays, according to its traditions.\n\n\nMayonnaise supposedly originates in the city of Mahón. According to this theory, this sauce - an emulsion of eggs and olive oil - became known as a consequence of the brief French occupation of the island, which would take it to France. According to a different theory, it was invented in a French town called Maiona, or perhaps Baiona. A third is based on the dislike of the French towards garlic. As they tasted the Minorcan aioli, the French asked for the garlic to be removed, which left them with a white sauce made of olive and eggs: mayonnaise. In any case, mayonnaise, with or without garlic, is a product of frequent use in the traditional cuisine of the island since ancient times, on its own or as an ingredient in dishes.\n\nA local cheese is produced in Minorca: Mahón cheese. It features Denominación de Origen Protegida (Protected Demonination of Origin). It is pressed instead of boiled, and has a characteristic orange colourm, a parallelepiped shape, and rounded corners. It is made and matured only in Minorca, according to tradition and to the norms of the DO. In 1985, the definitve form of the Denomination of Origin was given as \"queso Mahón,\" and later, in 1998, the word \"Menorca \"was added, making the full name \"Mahón-Menorca\". There are four main varieties, according to maturation time: mild, semi-mature, mature and aged. Ricotta or fresh, high-quality cottage cheese is also made in the same dairy shops in Minorca, but it does not have a specific name and is not widely known, since it is consumed only locally.\n\nWith the exception of the sobrassada, the cold cuts made in Minorca are an evolution of the Roman legacy. Everything is made of pork. The slaughter of the pigs, usually undertaken in winter, is called \"porquejades\" or \"porquetjades\". Blood is added as an ingredient to some of these products, which gives them a black colour.\n\nSimilarly to the cuisine of the Catalan cuisine, the spices used are few and not very varied, but they are the ones that give each product a distinct personality, and makes them different and flavourul. The spices normally used are black pepper, white pepper, paprika (in sobrassada), anise, cinnamon and salt. Some also add other typical Mediterranean spices such as thyme, rosemary and oregano.\n\n• White Botifarra, of grayish clear brown color, since it does not contain blood, it has the form of the ball that is used for the escudella. It is made up of meat and other parts of the pig and it is surrounded by a fine membrane. It is generally eaten cooked, usually fried. \n\nMinorcan cuisine is very Mediterranean, rich in vegetables of all types. The island has been very self-sufficient providing these type of fresh products, thus they have never gone missing, thanks to the farming activity as part of the economy even to this day, time in which the crops represent approximately half of the Minorcan territory. The salad, hanging, bouquet tomatoes, etc. ,and other green vegetables to prepare salads and stir fry stand out—onions, Italian green peppers, red pepper, garlic—, Roman lettuce to prepare salads, Mediterranean green vegetables that are fried, stuffed or oven baked, like eggplant, that in Minorca is small and very white in its interior, a variety of the summer season that cannot be cultivated in a greenhouse, zucchini, that is prepared in a similar way, or the artichoke, that is also from a local variety, small, long, and purple colored, that is eaten mainly as a side dish, battered and fried, oven baked or in stews.\n\nFruits are also abundant, specially figs, that are also eaten in savoury dishes, like for example the \"oliaigua\".\n\nLocal green vegetables are prepared a \"thousand ways\", some of the most common are the \"guixons\"\", the habas, the lentils, and the chickpeas.\"\n\nMushrooms are very much appreciated, oven baked, fried, with or without sauce to accompany meats, and the wild asparagus, very appreciated in the oliaigua (local soup) or simply with a tortilla.\n\nOlive oil is the grease that is used to cook these dishes and is also common in pastry, while olives themselves are appreciated in this cooking, just like local capers. Until a few decades ago there were hundreds of olive trees in Minorca but nowadays these are not cultivated.\n\nSome Minorcan dishes that contain these ingredients are:\n\nA lot of salty products are made with wheat flour, many of which the bread dough often encircles the land's produce, like for example, the \"rubiols\", the M\"inorcan flaons\"- salty pasta filled with cheese-, to the agujas or croissants- made with bread dough and shaped like a half moon- filled with sobrassada. The \"formatjades \"stand out, common in Easter time. The salty \"cocas\" are usually rectangular, open or closed, and can be traditionally filled with a stir-fry, vegetables or pepper, even though some have meat or fish. On Christmas eve it is common to eat, before the Midnight Mass, bread rolls filled with diced meat and soaked in milk and oven-cooked.\nSea products, for their insular condition, are widely consumed. Traditionally, Whitefish is used just the same- like for example, Goosefish or the Hake- like the Oily fish- like the Atlantic mackerel or the sardine, for example-, very fresh, bought the same day it is fished. This type of cooking with fish is traditional because many Minorcans have a boat, in which they go fishing on weekends and in summer it was a customary, and it still happens, to go around the island on a boat, an excursion that forced you to eat the captured and cooked fish on board. The Scorpaena or scrofa, among them, is a highly appreciated and abundant fish. Another appreciated fish is the Rajiformes that can be oven-baked, grilled or in a paella.\n\nA number of seafood, shells and mollusks are also used. These products, just like the earth products, change according to the season. They are cooked in pots or boilers, rice, and sometimes also in salty pies or puddings, oven-baked, grilled or in the oven. In Minorca there is a great tradition of eating varied fish, and even octopus or squid, in the form of meatballs. The cod\" ab burrida\", that is prepared mixing cod sauce with garlic and oil dressing, is a dish that has the resemblance with others cooked in Catalonia, Provence, and other nearby areas.\n\nSome Minorcan dishes with fish and seafood are: \n\nPig farming is common locally, because pigs are easy to raise and traditional sausages are very popular. There is also cattle farming, which is the traditional source of milk -to make cheese among other things, meat and hides; the latter being used as a raw material for the local traditional leather craftsmen. A very old recipe is, for example, the \"Feixets\" or \"Chaplain’s Partridges\", thinly sliced veal rolls filled with boiled egg, bacon and \"sobrasada\".\n\nLamb, chicken and rabbit are also consumed. There are local varieties of chicken and lamb.\n\nGame meats, which are currently very limited, are mainly rabbits and birds. Rabbits are hunted with the help of dogs, including an indigenous breed, the \"Rabbit’s Dog\", and shotguns, while for the haunting of birds, typical techniques are the use of decoy and the \"fencing in the neck\".\n\nSnails are also part of this gastronomy, both in simple preparations, with alioli, for example, and in many more sophisticated ones, such as snails with sea crab.\n\nSome Minorcan dishes with meats or sausages are:\n\n\nThe Minorcan bakery, pastry, and dessert making incorporates ideas, techniques and products from cultures as diverse as Jewish, Arabic and English. The brief stay of the French in the island served to create the \"Gató\", according to the technique of the French housewives of the moment, but incorporating almonds in the recipe. From the British the islanders took a taste for puddings, they use Catalan cream abundantly; and they also use meringue in the Italian way, to take advantage of the egg whites to decorate desserts and cakes. This taste for very sweet recipes is shared in common with other neighbours in the southern Mediterranean.\n\n\n\nCuinaArt Menorca is a gastronomic fair that is celebrated every April since 2007 as a showcase for Minorcan products. It consists of exhibitors, debates, tastings, conferences, etc. It is aimed at all types of public.\n"}
{"id": "53151225", "url": "https://en.wikipedia.org/wiki?curid=53151225", "title": "Deborah L. Best", "text": "Deborah L. Best\n\nDeborah L. Best is the William L. Poteat Professor of Psychology at Wake Forest University in Winston-Salem, North Carolina. Best is an expert in human development and early childhood. Her interests include: development of gender concepts and stereotypes in the United States and cross-nationally, memory development (mnemonic strategies and metamemory) in young children and older adults, health psychology with adolescents and older adults, and attitudes toward gender, age, race, color, and disability.\n\nBest earned a bachelor's degree in psychology and an MA in General Experimental Psychology at Wake Forest University, and a PhD in developmental psychology at the University of North Carolina at Chapel Hill.\n\nBest is a professor of psychology at Wake Forest University and served as the first female Dean of the College at Wake Forest University.. Best is the Editor-in-Chief of The Journal of Cross-Cultural Psychology. Best is also a former president of the International Association for Cross-Cultural Psychology. Best is the recipient of the 2017 American Psychology Association's - Division 52 - Florence L. Denmark and Mary E. Reuder Award. This APA Division 52 award recognizes and encourages outstanding psychologists who have made international contributions to further the understanding of women and/or gender. \n\nBest's research has ranged from cognitive development during the preschool and primary school years – including age-related changes in memory and the effects of memory training – to cross-cultural comparisons of public social behaviors of men and women.\n\nMeasuring sex stereotypes: A thirty nation study. J. E. Williams and D.L. Best, (1982, Berkeley, CA: Sage Publications).\n\nSex and psyche: Gender and self viewed cross-culturally. J. E. Williams and D.L. Best, (1990, Newbury Park, CA: Sage Publications)\n"}
{"id": "17907733", "url": "https://en.wikipedia.org/wiki?curid=17907733", "title": "Dhivehi beys", "text": "Dhivehi beys\n\nDhivehi beys is the local Dhivehi name given to the Traditional Medicine of the Maldives and Minicoy, Lakshadweep or the Dweep Unani / \"Dheebu Yoonaanee\", the islanders' system of herbal medicine. The term \"Dhivehi\" means Islanders' and \"beys\" means medicine. \"Dweep\" is another word used for islands and \"Unani\" is the term for Hippocratic humoral system of herbal medicine practiced in South Asia.\n\nThe Maldive Islanders still rely on traditional medicine men and women. At the crossroads of the Indian Ocean, healing secrets from Indians, Arabs, Persians, Malaysians, Sri Lankans and Chinese were acquired and synthesized, then used to develop local herbal remedies.\n\nLegends abound about the feats of such special healers as \"Buraki Ranin\", the sixteenth-century queen of Sultan Muhamed, who was said to cure sword wounds overnight with her own dressings. The treatise written by El-Sheikh El-Hakeem Ahmed Didi of Meedhoo (Seenu Atoll) who died in 1937 forms the foundation of today's traditional medicine. Known as hakeems, practitioners of this medicine are well respected by the village communities.\n\nA basic tenet of their philosophy is that good health is a result of a proper balance between the hot, cold and dry \"humours\" in the body, so \"cold food\" is recommended for someone with fever, and dry fish for flu. Some hakeems are schooled in \"Unani\" medicine, which treats the whole person, combining ancient remedies with new drugs. In recent years there has been an attempt to integrate traditional and modern medicine.\n\nAdvice and training, for instance, is offered to local midwives who learned their skill from older practitioners. Arabic system of Graeco-Islamic medicine in Maldives was introduced by Arabs. Unani medicine soon got acceptance by the masses due to its efficacy and non toxicity of the drugs.\n\nAisaabeegedharu Ahmed Didi ( son of El-Allama El_Shaikh El-Hafiz Ibrahim Thakurufaanu, Aisaabeegedharu Dhonbeyya) died in 1938 was most dedicated scholar of Arabic system of medicine in Maldives. He was known for his book Tibbl Fuqara fee hikmathil Umarai based on his lifelong clinical experience. He referred to more than 20 books and encyclopedias of Arabic in his book. He was the first person who opened the research in old Dhivehi system of medicine. He examined Dhivehi medicine in the light of unani medicine.\n\n"}
{"id": "55824030", "url": "https://en.wikipedia.org/wiki?curid=55824030", "title": "Digeponics", "text": "Digeponics\n\nDigeponics (pronounced die-jeh-ponics, as in digestion) is a method of agriculture which integrates the products of anaerobic digestion, including CO and digestate, with greenhouse cultivation of vegetables.\n\nDigeponics was developed in Norway by the \"Food to Waste to Food\" (F2W2F) program, a part of the EU Eco-innovation Initiative, in partnership with the waste management company Lindum AS.\n\nThe method involves the use of various products of anaerobic digestion in the cultivation of vegetables in a greenhouse environment. The more widely used aspects include the use of biogas for electricity production, which is used for lighting and heating the greenhouse in the winter months, as well as the introduction of carbon dioxide into the greenhouse, which is a byproduct of biogas combustion, for increased plant growth. The more novel aspect of this method is the use of a \"mix of vermicompost and garden waste compost fertilized by (non-separated) digestate in a circulating system including earth worms in the substrate and aeration in a biofilter buffer tank.\" \n\nResearch conducted on digeponics found that this method, and others like it, could meet or exceed the production rates of mineral fertilizers. For tomato production, digeponics yielded 5430 g, compared to 4920 g for mineral fertilizers. For cucumber production, digeponics yielded 19560g, compared to 8502g for mineral fertilizers.\n\nIn addition to increased yields, this method can provide decreased energy costs and very low carbon emissions, by producing energy on site from renewable carbon neutral sources that are readily available to the farmer, and could even provide an additional source of income by charging tipping fees for organic waste collection and selling excess electricity or gas back into the grid. Methane emissions were shown to be reduced by 98%, compared to landfilling of organic waste, and carbon emissions were reduced 95%, compared with conventional tomato greenhouse production.\n"}
{"id": "30068770", "url": "https://en.wikipedia.org/wiki?curid=30068770", "title": "Emergency medical services in Spain", "text": "Emergency medical services in Spain\n\nEmergency Medical Services in Spain (\"Servicios de Emergencias Médicas, SEM\") (EMS) are public services usually provided by regional Governments.\n\nSpanish organization for medical emergencies is a Public Health Integrated EMS (IEMS) that has a network of SAMU/IEMS Medical Emergency Regulation Centers (MERC = SAMU in international appellation). Emergency Primary Care and GP are fully integrated in Spanish IEMS.\n\nSpain has 17 autonomous communities with 17 regional Health Departments. The National Health System is the agglomeration of these 17 Health Departments. So each autonomous community has its own regional IEMS that depend on Regional Health Department. Some EMS have their own staff and vehicles, others outsource the vehicles and staff to private companies. Public EMS departments usually outsource the vehicles and BLS staff. ALS staff are usually government employees.\nIn addition, some cities have local EMS too (e.g. SAMUR-Madrid).\n\nThere are also Emergency Medical Services in some fire departments: cities of Barcelona, Sevilla, Valencia, Zaragoza, Malaga, Bilbao, and Catalonia community. In these EMS, doctors and nurses work with firefighters in advanced life support (ALS) ambulances or helicopters.\n\nFurthermore, non-profit organizations (Spanish Red Cross, DYA) and Civil Defense Groups provide ambulances (usually BLS) with volunteers for some situations (disasters, mass incidents, special events: sports, concerts...)\n\nNew legislation was published in June 2012.\n\nSpanish EMS is a physician led system with physicians, emergency nurses and technicians in the field. It's a two-tiered response system (Advanced Life Support with physicians and nurses, and Basic Life Support with technicians).\n\nIn addition there are fast vehicles (non-ambulance) for emergency interventions:\n\n<gallery caption=\"Non-profit organizations/volunteers\" widths=\"150px\" heights=\"120px\" perrow=\"4\">\nFile:Ambulancias (MAG).JPG|Spanish Red Cross Ambulances (volunteers)\nFile:Ambulancia Cruz Roja Española en Orihuela.jpg|Red Cross Ambulance(volunteers)\nFile:Ambulancias DYA Las Arenas.jpg|DYA Ambulances (volunteers)\nFile:DYAako Donostiako anbulantzia.jpg|DYA Ambulance(volunteers)\n</gallery>\n\nBefore 2007 there was not a national standard for EMT (\"TES/Técnico en Emergencias Sanitarias\") education, so each region had their own rules (courses from 60 to 600 hours or sometimes only a first aid course; no reciprocity between regions; different terms: \"TTS-Técnico de Transporte Sanitario, ATTS-Auxiliar de Transporte Sanitario, ATA-Auxiliar de Transporte en Ambulancia, TEM-Técnico en Emergencias Médicas...\"). Since 2007 there is a 2 years training occupational course (vocational-Community College)\n\nThe emergency dial is 112 (European Emergency Number). in all regions. However, the emergency number for medical services, 061, is available in several regions.\n\nIn Spain, the emergency dispatch is a physician regulated system. Each region has its own emergency call center with phone operators (\"telefonistas\"), emergency medical dispatchers (\"gestores de recursos/coordinadores/locutores\"), medical-regulators (physician) and sometimes nurses.\n\nIn Spain, until August, 1st 2018, the law (motor vehicle code) only allowed the police vehicles to use blue lights. Ambulances and fire engines had to use amber lights. However some ambulances used red/amber, white/amber, blue/amber, blue/red lights although this was illegal. Since that date, all emergency vehicles (police cars, ambulances, RRU, fire trucks...) have to use blue lights. Vehicles that had amber lights have to change them within a maximum time period of two years. .\n\n\n"}
{"id": "7149912", "url": "https://en.wikipedia.org/wiki?curid=7149912", "title": "Epidemiology of chikungunya", "text": "Epidemiology of chikungunya\n\nChikungunya is a mosquito-borne alpha virus that was first isolated after a 1952 outbreak in modern-day Tanzania. The virus has circulated in forested regions of sub-Saharan African in cycles involving nonhuman primate hosts and arboreal mosquito vectors. Phylogenetic studies indicate that the urban transmission cycle—the transmission of a pathogen between humans and mosquitoes that exist in urban environments—was established on multiple occasions from strains occurring on the eastern half of Africa in non-human primate hosts. This emergence and spread beyond Africa may have started as early as the 18th century. Currently, available data does not indicate whether the introduction of chikungunya into Asia occurred in the 19th century or more recently, but this epidemic Asian strain causes outbreaks in India and continues to circulate in Southeast Asia.\n\nA number of chikungunya outbreaks have occurred since 2005. An analysis of the chikungunya virus's genetic code suggests that the increased severity of the 2005–present outbreak may be due to a change in the genetic sequence, altering the virus' viral coat protein, which potentially allows it to multiply more easily in mosquito cells. The change allows the virus to use the Asian tiger mosquito (an invasive species) as a vector in addition to the more strictly tropical main vector, \"Aedes aegypti\". In July 2006, a team analyzed the virus' RNA and determined the genetic changes that have occurred in various strains of the virus and identified those genetic sequences which led to the increased virulence of recent strains.\n\nThe largest outbreak of chikungunya ever recorded at the time occurred on the island of Réunion in the western rim of the Indian Ocean from late March 2005 to February 2006. At its height, the incidence peaked at about 25,000 cases per week or 3500 daily in early 2006. After an initial peak in May 2005, the incidence decreased and remained stable through the summer hemisphere winter, rising again at the beginning of October 2005. By mid-December, when southern hemisphere summer temperatures are favorable for the mosquito vector, the incidence began to rise dramatically into the first two months of 2006. The number of reported cases was thought to be underestimated. The French government sent several hundred troops to help eradicate mosquitoes. Although confirmed cases were much lower, some estimates based on extrapolations from the number detected by sentinel physicians suggested that as many as 110,000 of Réunion's population of 800,000 people may have been infected. Twelve cases of meningoencephalitis cases were confirmed to be associated with chikungunya infection. Other countries in the southwest Indian Ocean reported cases as well, including Mauritius and the Seychelles, and in Madagascar, the Comoros, and Mayotte.\n\nIn 2006, there was a large outbreak in India. States affected by the outbreak were Andhra Pradesh, Andaman & Nicobar Islands, Tamil Nadu, Karnataka, Maharashtra, Gujarat, Madhya Pradesh, Kerala and Delhi. The initial cases were reported from Hyderabad and Secunderabad as well as from Anantpur district as early as November and December 2005 and is continue unabated. In Hyderabad alone an average practitioner saw anywhere between 10 and 20 cases every day. Some deaths have been reported but it was thought to be due mainly to the inappropriate use of antibiotics and anti-inflammatory tablets. The major cause of mortality is due to severe dehydration, electrolyte imbalance and loss of glycemic control. Recovery is the rule except for about 3 to 5% incidence of prolonged arthritis. As this virus can cause thrombocytopenia, injudicious use of these drugs can cause erosions in the gastric epithelium leading to exsanguinating upper GI bleed (due to thrombocytopenia). Also the use of steroids for the control of joint pains and inflammation is dangerous and completely unwarranted. On average there are around 5,300 cases being treated every day. This figure is only from public sector. The figures from the private sector combined would be much higher.\n\nThere have been reports of large scale outbreak of this virus in Southern India. At least 80,000 people in Gulbarga, Tumkur, Bidar, Raichur, Bellary, Chitradurga, Davanagere, Kolar and Bijapur districts in Karnataka state are known to have been affected since December 2005.\n\nA separate outbreak of chikungunya fever was reported from Malegaon town in Nasik district, Maharashtra state, in the first two weeks of March 2006, resulting in over 2000 cases. In Orissa state, at most 5000 cases of fever with muscle aches and headache were reported between February 27 and March 5, 2006.\n\nIn Bangalore, the state capital of Karnataka (India), there seemed to be an outbreak of chikungunya in May 2006 with arthralgia/arthritis and rashes. As well as in the neighbouring state of Andhra Pradesh. In the 3rd week of May 2006 the outbreak of chikungunya in North Karnataka was severe. All the North Karnataka districts specially Gulbarga, Koppal, Bellary, Gadag, Dharwad were affected. The people of this region are hence requested to be alert. Stagnation of water which provides fertile breeding grounds for the vector (\"Aedes aegypti\") should be avoided. The latest outbreak is in Tamil Nadu, India - 20,000 cases have been reported in June 2006. Earlier it was found spreading mostly in the outskirts of Bangalore, but now it has started spreading in the city also (Updated 30/06/2006). More than 300,000 people are affected in Karnataka as of July 2006.\n\nReported on 29/06/2006, Chennai—fresh cases of this disease has been reported in local hospitals. A heavy effect has been reflected in south TN districts like Kanyakumari and Tirunelveli. Residents of Chennai are warned against the painful disease.\n\nJune 2006—Andaman Islands (India) chikungunya cases had been registered virtually for the first time in the month of June 2006. In the beginning of the September cases have gone as much as in thousands.As reported in a local news magazine it has taken the state of epidemic in Andamans. Health authorities are doing their best to handle the situation. Relapsed cases have been noticed with severe pain and swelling in the lower limbs, vomiting and general weakness.\n\nAs of July 2006, nearly 50,000 people were affected in Salem, Tamil Nadu.\n\nAs of August 2006, nearly 100,000 people were infected in Tamil Nadu. Chennai, capital of Tamil Nadu is one of the worst affected.\n\nOn 24 August 2006, \"The Hindu\" newspaper reported that the Indian states of Tamil Nadu, Karnataka, Andhra Pradesh, Maharashtra, Madhya Pradesh, Gujarat and Kerala had reported 1.1 million (11 lakh) cases. The government's claim of no deaths is questioned.\n\nIn September 2007, 130 cases were confirmed in the province of Ravenna, Northern Italy, in the contiguous towns of Castiglione di Cervia and Castiglione di Ravenna. One person died. The source of the outbreak was an Indian from Kerala, India.\n\nBy the end of September 2009, the Thai Ministry of Health reported more than 42,000 cases during the previous year in 50 provinces in the south of Thailand, including the popular tourist destination of Phuket. About 14 years had lapsed since the last appearance of the disease. In May 2009 the provincial hospital in Trang Province prematurely delivered a 6-year-old male baby from his chikungunya-infected mother in the hopes of preventing mother-foetus virus transmission. After a cesarean delivery, the physicians discovered that he had also been infected with the chikungunya virus, and put him under intensive care. The child died from respiratory complications, possibly the only death from the outbreak, but the cause of death may not have been chikungunya since the child was delivered prematurely . The Thai physicians gave a preliminary presumption that chikungunya virus might be transmitted from a mother to her foetus.\n\nOutbreaks in the Pacific Islands began in New Caledonia in 2011 and have since occurred in a number of Pacific countries. Fully 1/2 of the entire population of French Polynesia has come down with chikungunya Asian genotype (130,000 cases with 14 dead), exploding from a month earlier with 35,000 cases in December 2014; the first ever case was in 2013.\n\nAn outbreak occurred in Cambodia with at least 1500 confirmed cases. Provinces for which affection was confirmed were: Preah Vihear, Battambang, Kampong Thom, Kampong Chhnang, Kandal, Kampong Speu and Takeo.\n\nIn December 2013, it was confirmed that chikungunya was being locally transmitted in the Americas for the first time in the French Caribbean dependency of St. Martin, with 66 confirmed cases and suspected cases of around 181. It is the first time in the Americas that the disease has spread to humans from a population of infected mosquitoes.\n\nBy mid-January 2014, a number of cases had been confirmed in five countries: St. Martin, St. Barthelemy, Martinique, Guadeloupe, and the British Virgin Islands. At the start of April, at least ten nations had reported cases. By the start of May, there were more than 4,100 probable cases, and 31,000 suspected cases spanning 14 countries, including French Guiana, the only non-island nation with at least one reported case. On May 1, the Caribbean Public Health Agency (CARPHA) declared a Caribbean-wide epidemic of the virus.\n\nAs of 21 January 2014, no cases had been reported in Puerto Rico. But by 15 July 2014, over 400 cases had been reported and health authorities believed the number of actual cases (i.e., including unreported cases) was much higher.\nBy November 2014 the Pan American Health Organization reported about 800,000 suspected chikungunya cases in the Caribbean alone.\n\nOn July 17, 2014, the first chikungunya case acquired in the United States was reported in Florida by the Centers for Disease Control and Prevention in a man who had not recently traveled outside the United States. Shortly after another case was reported of a person in Florida being infected by the virus, not having traveled outside the U.S.\n\nThese were the first two cases where the virus was passed directly by mosquitoes to persons on the U.S. mainland. Aside from the locally acquired infections, there were 484 other cases reported in the United States as of 5 August 2014.\n\nAs of 11 September 2014, the number of reported cases in Puerto Rico for the year was 1,636. By 28 October, that number had increased to 2,974 confirmed cases with over 10,000 cases suspected.\n\nIn September 2014, the Central University of Venezuela stated that there could be between 65,000 and 117,000 Venezuelans infected with chikungunya. Health Minister Nancy Pérez stated that only 400 Venezuelans were infected with chikungunya\n\nOn October 20, 2014, 11 locally acquired cases of chikungunya were reported in Montpellier, Languedoc-Roussillon, in the South of France. 449 imported cases of chikungunya were also reported throughout France during the period May–November 2014.\n\nAs of December 2014, Costa Rica had 47 reported cases of chikungunya, 40 of which originated abroad, while 7 were locally acquired.\n\nOn June 2014 six cases of the virus were confirmed in Brazil, two in the city of Campinas in the state of São Paulo. The six cases are Brazilian army soldiers who had recently returned from Haiti, where they were participating in the reconstruction efforts as members of the United Nations Stabilisation Mission in Haiti. The information was officially released by Campinas municipality, which considers that it has taken the appropriate actions.\n\nOn 25 September 2014, official authorities in El Salvador report over 30,000 confirmed cases of this new epidemic.\n\nOn 7 November 2014 Mexico reported an outbreak of chikungunya, acquired by local transmission, in southern state of Chiapas. The outbreak extends across the coastline from the Guatemala border to the neighbouring state of Oaxaca. Health authorities have reported a cumulative load of 39 laboratory-confirmed cases (by the end of week 48). No suspect cases have been reported.\n\nThe first cases were officially confirmed in July 2014. Between that month and the end of 2014, as reported by the Colombian Health Institute (Instituto Nacional de Salud - INS ), there were 82,977 clinically confirmed cases and 611 cases confirmed through laboratory tests, bringing the total of confirmed cases during 2014 in Colombia to 83,588, 7 of which led to deaths. These cases were reported in the following regions: Amazonas, Atlántico, Arauca, Antioquia, Barranquilla, Bolívar, Boyacá, Caldas, Cartagena, Casanare, Cauca, Cesar, Córdoba, Cundinamarca, Huila, La Guajira, Magdalena, Meta, Putumayo, Nariño, Norte de Santander, Sucre, Santander, Santa Marta, Risaralda, Tolima, San Andrés and Valle del Cauca. According to news outlets, as of January 2015 at least one major city (Medellín) has issued sanitary alerts due to the expanding epidemic. By January 2015 the epidemic is considered to be in the initial expansion phase and it is expected by the Colombian National Health Institute (Instituto Nacional de Salud - INS) that the total number of cases will reach around 700,000 by the end of 2015 due to the in-country massive travel of tourists to and from regions where cases of the disease have been confirmed and the vector \"A. aegypti\" is indigenous. It is expected that the disease will become endemic and sustain itself, with a pattern of outbreaks similar to dengue fever, due to the fact that both vector and natural reservoirs are indigenous in large areas of the country.\n\nOn 24 September 2015, the Ministry of Health and Social Protection of Colombia officially declared the country free of Chikungunya. There were 441,000 reported cases but the government estimated the infected to reach the 873,000.\n"}
{"id": "17032622", "url": "https://en.wikipedia.org/wiki?curid=17032622", "title": "Expanded Program on Immunization", "text": "Expanded Program on Immunization\n\nThe Expanded Program on Immunization is a World Health Organization program with the goal to make vaccines available to all children.\n\nThe World Health Organization (WHO) initiated the Expanded Program on Immunization (EPI) in May 1974 with the objective to vaccinate children throughout the world. \n\nTen years later, in 1984, the WHO established a standardized vaccination schedule for the original EPI vaccines: Bacillus Calmette-Guérin (BCG), diphtheria-tetanus-pertussis (DTP), oral polio, and measles. Increased knowledge of the immunologic factors of disease led to new vaccines being developed and added to the EPI’s list of recommended vaccines: Hepatitis B (HepB), yellow fever in countries endemic for the disease, and Haemophilus influenzae meningitis (Hib) conjugate vaccine in countries with high burden of disease.\n\nIn 1999, the Global Alliance for Vaccines and Immunization (GAVI) was created with the sole purpose of improving child health in the poorest countries by extending the reach of the EPI. The GAVI brought together a grand coalition, including the UN agencies and institutions (WHO, UNICEF, the World Bank), public health institutes, donor and implementing countries, the Bill and Melinda Gates Foundation and The Rockefeller Foundation, the vaccine industry, non-governmental organizations (NGOs) and many more. The creation of the GAVI has helped to renew interest and maintain the importance of immunizations in battling the world’s large burden of infectious diseases.\n\nThe current goals of the EPI are \n\nIn addition, the GAVI has set up specific milestones to achieve the EPI goals: that by 2010 all countries have routine immunization coverage of 90% of their child population, that HepB be introduced in 80% of all countries by 2007, and that 50% of the poorest countries have Hib vaccine by 2005.\n\nIn each of the United Nations’ member states, the national governments create and implement their policies for vaccination programs following the guidelines set by the EPI. Setting up an immunization program is multifaceted and contains many complex components including a reliable cold chain system, transport for the delivery of the vaccines, maintenance of vaccine stocks, training and monitoring of health workers, outreach educational programs to inform the public, and a means of documenting and recording which child receives which vaccines. \n\nEach region has slightly varying ways of setting up and implementing their immunization programs based on their level of health infrastructure. \n\nSome areas will have fixed sites for vaccination: health care facilities such as hospitals or health posts that include vaccination with many other health care activities. But in areas where the number of structured health facilities is small, mobile vaccination teams consisting of staff members from a health facility can deliver vaccines straight to individual towns and villages. These ‘outreach’ services are often scheduled throughout the year. However, in especially under-developed countries where proper communication and infrastructure is absent, cancellation of the planned immunization visits leads to deterioration of the program. A better strategy in such countries is the ‘pulse immunization’ technique, where ‘pulses’ of vaccines are given to children in annual vaccination campaigns.\n\nAdditional strategies are needed if the area of the program consists of poor urban communities because such areas tend to have low uptake of vaccination programs. Door-to-door canvassing, also referred to as channeling, is used to increase uptake in such hard to reach groups. Finally, periodic national-level mass vaccination campaigns are being increasingly included in the programs.\n\nIn each country, immunization programs are monitored using two methods: an administrative method and through community-based surveys. The administrative method uses immunization data from public, private, and NGO clinics. Thus, the accuracy of the administrative method is limited by the availability and accuracy of reports from these facilities. This method is easily performed in areas where government services deliver the immunizations directly or where the government supplies the vaccines to the clinics. In countries without the infrastructure to do this, community-based surveys are used to estimate immunization coverage.\n\nCommunity-based surveys are applied using a modified cluster sampling survey method developed by the World Health Organization. Vaccine coverage is evaluated using a two-stage sampling approach in which 30 clusters and seven children in each cluster are selected. Health care workers with no or limited background in statistics and sampling are able to carry out data collection with minimal training. Such a survey implementation provides a way to get information from areas where there is no reliable data source. It is also used to validate reported vaccine coverage (for example, from administrative reports) and is expected to estimate vaccine coverage within 10 percent.\n\nSurveys or questionnaires, though frequently considered inaccurate due to self-reporting, can provide more detailed information than administrative reports alone. If home-based records are available, vaccination status be determined and dates of vaccination can be reviewed to determine if they were given at an ideal age and in appropriate intervals. Missed immunizations can be identified and further qualified. Importantly, systems of vaccine delivery besides clinics used for administrative evaluation can be identified and included in the analysis.\n\nBefore the initiation of the EPI, child vaccination coverage for tuberculosis, diphtheria, pertussis, tetanus, polio and measles was estimated to be fewer than 5 percent. Now, not only has coverage increased to 79 percent, it has been expanded to include vaccinations for hepatitis B, Haemophilus influenzae type B, rubella, tetanus, and yellow fever. The impact of increased vaccination is clear from the decreasing incidence of many diseases. For example, measles deaths decreased by 60% worldwide between 1999 and 2005, and polio, although missing the goal of eradication by 2005, has decreased significantly as there were fewer than 2,000 cases in 2006.\n\n"}
{"id": "6336280", "url": "https://en.wikipedia.org/wiki?curid=6336280", "title": "HIV/AIDS in South Africa", "text": "HIV/AIDS in South Africa\n\nHIV/AIDS is the most serious health concern in South Africa. The country has the fourth-highest adult HIV prevalence rate in the world, according to the 2016 United Nations statistics.\n\nAccording to a UNAids dataset sourced from the World Bank, in 2016 the HIV prevalence rate for adults aged 15 to 49 was 27% in Swaziland, 25% in Lesotho, 25% in Botswana and 19% in South Africa.\n\nHIV prevalence does not indicate that a country has an AIDS crisis, as HIV and AIDS are separate conditions. HIV prevalence, instead, indicates that people remain alive, despite the infection. South Africa has the largest HIV treatment programme in the world. With the correct medication, HIV is a manageable chronic condition, like diabetes or hypertension. A population with a larger proportion of diabetics, means more people are receiving treatment for the condition. Hence, a population with a larger proportion of HIV-positive people, means more people are receiving anti-retroviral treatment.\n\nWorld Bank Open Data explains the data it publishes on HIV prevalence as follows:\n\nSouth Africa's HIV treatment programme was launched in earnest in 2005. The trend in South Africa's HIV and AIDS statistics has changed significantly in the years since then.\n\nThe World Bank and United Nations source their data on HIV prevalence from Statistics South Africa.\n\nAccording to Statistics South Africa's mid-year population estimates for 2017, the total HIV prevalence rate for the country is 12.6%. The HIV prevalence rate for all adults aged 15 to 49 is 17.9%, for women aged 15 to 49 is 21.2%, and for youth aged 15 to 24 is 4.6%.\n\nStatistics South Africa estimates the number of deaths attributable to AIDS in 2017 as 126,755 or 25.03% of all South African deaths.\n\nA 2008 study revealed that HIV/AIDS infection in South Africa was distinctly divided along racial lines: 13.6% of Black Africans in South Africa are HIV-positive, whereas only 0.3% of Whites living in South Africa have the disease. False traditional beliefs about HIV/AIDS, which contribute to the spread of the disease, persist in townships due to the lack of education and awareness programmes in these regions. Sexual violence and local attitudes toward HIV/AIDS have also amplified the epidemic.\n\nHIV/AIDS is more prevalent among females, especially those under the age of 40. Women made up roughly 4 in every 5 people with HIV/AIDS aged 20–24, and 2 out of 3 of those aged 25–29. Although prevalence is higher among women in general, only 1 in every 6 HIV/AIDS infected people with multiple sex partners are women.\n\nYoung boys and girls in South Africa are both highly affected by intimate partner violence and HIV/AIDS. Research has found links between the two, as well as a relationship with drug use. It was found that problem drinking and marijuana use are mediating variables in the relationship between men who experienced childhood sexual abuse and who engage in HIV sexual risk behaviors.\n\nIn adult and adolescent women, low relationship power and victimization by intimate partner violence were found to be linked to HIV risk. This lower relationship power affects interpersonal dynamics that increase sexual risk due to condom nonuse and the likelihood of a girl with low relationship power having more sexual partners. However, both boys and girls with lower relationship power were found to be more likely to have multiple partners. Regardless of gender, youths with lower power are more vulnerable to be pressured or coerced into transactional sex.\n\nHIV prevalence among pregnant women is highest in the populous KwaZulu-Natal province (37%), and lowest in the Western Cape (13%), Northern Cape (16%) and Limpopo (18%) provinces. In the five other provinces (Eastern Cape, Free State, Gauteng, Mpumalanga and North West) at least 26% of women attending antenatal clinics in 2006 tested HIV-positive.\n\nThe latest HIV data collected at antenatal clinics suggest that HIV infection levels might be levelling off, with HIV prevalence in pregnant women at 30% in 2007, 29% in 2006, and 28% in 2005. The decrease in the percentage of young pregnant women (15–24 years) found to be infected with HIV can be extrapolated to suggest a possible decline in the annual number of new infections.\n\nBetween 2005 and 2008, the number of older teenagers with HIV/AIDS has nearly halved. Between 2002 and 2008, prevalence among South Africans over 20 years old have increased whereas the figure for those under 20 years old have dropped somewhat over the same period.\n\nCondom use is highest among the youth and lowest among older people. More than 80% of men and more than 70% of women under 25 years old use condoms, and slightly more than half of men and women aged 25–49 claim to use condoms.\n\nMore than 30% of young adults and more than 80% of older adults are aware of the dangers posed by HIV/AIDS. Knowledge about HIV/AIDS is lowest among people older than 50 years—less than two thirds know exactly what HIV/AIDS is.\n\nIn 2008, more than half (55%) of all South Africans infected with HIV resided in the KwaZulu-Natal and Gauteng provinces.\n\nBetween 2005 and 2008, the total number of people infected with HIV/AIDS has increased in all of South Africa's provinces except KwaZulu-Natal and Gauteng. Nevertheless, KwaZulu-Natal still has the highest infection rate at 15.5% In the province with the lowest infection rate, the Western Cape, the total number of people with HIV/AIDS doubled between 2005 and 2008.\n\nCondom use has increased twofold in all provinces between 2002 and 2008. The two provinces where condoms were least used in 2002 were also the provinces where condoms are least used in 2008, namely the Northern Cape and the Western Cape.\n\nHIV/AIDS prevalence among sexually active South Africans by province are:\n\n\nThe four main HIV/AIDS awareness campaigns in South Africa are Khomanani (funded by the government), LoveLife (primarily privately funded), Soul City (a television drama for adults) and Soul Buddyz (a television series for teenagers). Soul City and Soul Buddyz are the most successful campaigns although both campaigns experienced a slight loss of effectiveness between 2005 and 2008. Khomanani is the least successful campaign, although its effectiveness has increased by more than 50% between 2005 and 2008.\n\nThe dubious quality of condoms which are distributed is a setback to these efforts. In 2007, the government recalled more than 20 million locally manufactured condoms which were defective. Some of the contraceptive devices given away at the ANC's centenary celebrations in 2012 failed a water test conducted by the Treatment Action Campaign.\n\nIn 2007, it was estimated that one third of HIV infected people will develop TB (tuberculosis) in their lifetimes. In 2006, 40% of TB patients were tested for HIV. It has been the government policy since 2002 to cross-check all new cases of TB for HIV infection.\n\nAlthough STI prevention is part of the government's HIV/AIDS programmes, as is that of most countries, in South Africa HIV/AIDS prevention is done in conjunction with TB prevention. Most patients who die from HIV-related causes die from TB or similar illnesses. In fact the Health Department's programme of prevention is called the \"National HIV and AIDS and TB Programme\". In line with United Nations requirements, South Africa has also drawn up an \"HIV & AIDS and STI Strategic Plan\".\n\nIn 1983, AIDS was diagnosed for the first time in two patients in South Africa. The first recorded AIDS-related death occurred in the same year.\n\nIn 1990, the first national antenatal survey to test for HIV found that 0.8% of pregnant women were HIV-positive. It was estimated that there were between 74,000 and 6,500,135 people in South Africa living with HIV.\n\nIn 1993, the HIV prevalence rate among pregnant women was 4.3%. By 1993, the National Health Department reported that the number of recorded HIV infections had increased by 60% in the previous two years and the number was expected to double in 1993.\n\nIn August 1995, the Department of Health awarded a R14.27-million contract to produce a sequel to the musical, \"Sarafina!\", about AIDS, in order to reach young people. The project was dogged by controversy, and was finally shelved in 1996.\n\nFrom 6 to 10 March 1995, the 7th International Conference for People Living with HIV and AIDS was held in Cape Town, South Africa. The conference was opened by then-Deputy President Thabo Mbeki.\n\nIn January 1996, it was decided that South Africa's national soccer team, Bafana Bafana, would contribute to the AIDS Awareness Campaign by wearing red ribbons to all their public appearances during the Africa Nations Cup.\n\nOn 5 July 1996, South Africa's Health Minister, Nkosazana Dlamini-Zuma, spoke at the 11th International Conference on AIDS in Vancouver. She said:\n\nIn February 1997, South African government's Health Department defended its support for the controversial AIDS drug Virodene by stating that \"the 'cocktails' that are available [for the treatment of HIV/AIDS] are way beyond the means of most patients [even from developed countries]\". Parliament had previously launched an investigation into the procedural soundness of the clinical trials for the drug.\n\nIn 1999, the South African HIV prevention campaign LoveLife was founded.\n\nIn 2000, the Department of Health outlined a five-year plan to combat AIDS, HIV and STIs. A National AIDS Council (SANAC) was set up to oversee these developments.\n\nThe South African government successfully defended against a legal action brought by transnational pharmaceutical companies in April 2001 of a law that would allow cheaper locally produced medicines, including anti-retrovirals, although the government's roll-out of anti-retrovirals remained generally slow.\n\nIn 2001, Right to Care, an NGO dedicated to the prevention and treatment of HIV and associated diseases, was founded. Using USAID's PEPFAR funding, the organisation expanded rapidly and after ten years (2011) had over 125,000 HIV-positive patients in clinical care.\n\nIn 2002, South Africa's Constitutional Court ordered the government to remove restrictions on the drug nevirapine and make it available to pregnant women in all state hospitals and clinics to help prevent mother-to-child transmission of HIV, following a court challenge by Treatment Action Campaign and others.\n\nAccording to the National HIV and Syphilis Antenatal Sero-prevalence Survey of 2005 and 2007, the percentage of pregnant women with HIV per year was as follows:\n\nAccording to a 2006 study by the South African Department of Health, 13.3% of 9,950 Africans that were included in the poll had HIV. Out of 1,173 whites, 0.6% had HIV. These numbers are confirmed in a 2008 study by the Human Sciences Research Council that found a 13.6% infection rate among Africans, 1.7% among Coloreds, 0.3% among Indians, and 0.3% among Whites.\n\nIn 2007, it was estimated that between 4.9 and 6.6 million of South Africa's 48 million people of all ages were infected with HIV, which is the virus that causes AIDS.\n\nOn 9 July 2000, then President Thabo Mbeki opened the International AIDS Conference in Durban with a speech not about HIV or AIDS but about extreme poverty in Africa. In the speech, he confirmed his belief that immune deficiency is a big problem in Africa but that one can't possibly attribute all immune deficiency-related diseases to a single virus.\n\nOn 4 September 2000, Thabo Mbeki acknowledged during an interview with Time Magazine (South African edition) that HIV can cause AIDS but confirmed his opinion that HIV should not be regarded as the sole cause of immune deficiency. He said:\n\nOn 20 September 2000, then President Thabo Mbeki responded to a question in Parliament about his views. He said:\n\nIn 2001 the government appointed a panel of scientists, including a number of AIDS denialists, to report back on the issue. The report suggested alternative treatments for HIV/AIDS, but the South African government responded that unless alternative scientific proof is obtained, it will continue to base its policy on the idea that the cause of AIDS is HIV.\n\nDespite international drug companies offering free or cheap anti-retroviral drugs, the Health Ministry remained hesitant about providing treatment for people living with HIV. Only in November 2003 did the government approve a plan to make anti-retroviral treatment publicly available. Prior to 2003, South Africans with HIV who used the public sector health system could get treatment for opportunistic infections but could not get anti-retrovirals.\n\nThe effort to improve treatment of HIV/AIDS was damaged by the attitude of many figures in the government, including President Mbeki. The then health minister, Manto Tshabalala-Msimang, advocated a diet of garlic, olive oil and lemon to cure the disease. Although many scientists and political figures called for her removal, she was not removed from office until Mbeki himself was removed from office. These policies led to the deaths of over 300,000 South Africans.\n\nIn August 2007, President Mbeki and Health Minister Tshabalala-Msimang dismissed Deputy Health Minister Nozizwe Madlala-Routledge. Madlala-Routledge has been widely credited by medical professionals and AIDS activists. Although she was officially dismissed for corruption, it was widely held that she was dismissed for her more mainstream beliefs about AIDS and its relation with HIV.\n\nThe South African press took a strong advocacy position during the denialism era under Thabo Mbeki. There are numerous examples of journalists taking the government to task for policy positions and public statements that were seen as irresponsible. Some of these examples include: attacks on Health Minister Manto Tshabalala-Msimang’s “garlic and potato” approach to treatment, outrage at Mbeki’s statement that he never knew anyone who had died of AIDS, and coverage of the humiliating 2006 International AIDS Conference.\n\nIt could be claimed that the news media have taken a less aggressive stance since the end of Mbeki’s presidency and the death of Tshabalala Msimang. The emergence of Jacob Zuma as party and state leader heralded what the press saw as a new era of AIDS treatment. However, this also means that HIV is afforded less news coverage. A recent study by the HIV/AIDS and the Media Project has shown that the quantity of HIV-related news coverage has declined dramatically from 2002/3 (what could be considered the pinnacle of government denialism) to the more recent “conflict resolution” phase under Zuma. Perhaps HIV has fallen into the traditional categories of being impersonal, undramatic, \"old\" news. The number of health journalists has also declined considerably.\n\n\nGeneral:\n\n\n"}
{"id": "46575859", "url": "https://en.wikipedia.org/wiki?curid=46575859", "title": "Health Equity Impact Analysis", "text": "Health Equity Impact Analysis\n\nA Health Equity Impact Analysis is a decision support tool which walks users through the steps of identifying how a program, policy or similar initiative will impact population groups in different ways. HEIAs are meant to show, \"inter alia\", unintended potential impacts. The goal is to maximize positive impacts and reduce negative impacts that could potentially widen health disparities between population groups.\n"}
{"id": "16465535", "url": "https://en.wikipedia.org/wiki?curid=16465535", "title": "Health in Afghanistan", "text": "Health in Afghanistan\n\nHealth in Afghanistan is unsatisfactory but slowly improving. The Ministry of Public Health oversees all matters concerning the health of Afghanistan's population. According to the Human Development Index, Afghanistan is the 15th least developed country in the world. Its average life expectancy at birth is reported at around 60 years. The country's maternal mortality rate is 396 deaths/100,000 live births and its infant mortality rate is 66 to 112.8 deaths in every 1,000 live births.\n\nThere are over 100 government-run and private or internationally-administered hospitals in Afghanistan. The most advanced medical treatments are available in Kabul. The French Medical Institute for Children and Indira Gandhi Children's Hospital in Kabul are the leading children's hospitals in the country. The Kabul Military Hospital and the Jamhuriat Hospital are two of the popular hospitals in the country. In spite of all this, many Afghans still travel to Pakistan and India for advanced treatment.\n\nThe decades of war have destroyed Afghanistan's already-poor health care system. Most medical professionals left the country by 1992, and all medical training programs ceased. In 2003, there were 11 physicians and 18 nurses per 100,000 population, and the per capita health expenditure was $28 US dollars. The nation had one medical facility for every 27,000 people in 2004, and some centers were responsible for as many as 300,000 people. An estimated one-quarter of the population had no access to health care. The international organizations provided a large share of medical care. The drought of 1999–2002 exacerbated these conditions. \nIt was reported in 2006 that an estimated 800,000 Afghans are disabled. Infant, child, and maternal mortality rates in Afghanistan reached the highest in the world, by some estimates as high as 275 per 1,000. In rural areas, one in six children die before reaching age five. This is because of poor sanitation and insufficient potable water supply, infectious and parasitic diseases such as malaria and diarrhea are very common. Malnutrition and poor nutrition also are pervasive.\n\nUser fees have been a major deterrent to accessing health care. Various interventions have been devised to improve uptake of health care services, including the distribution of waiver cards to very poor and female-headed households and the introduction of community-based health insurance.\n\nFollowing the national user fee ban in 2008, a pilot study conducted by the Future Health Systems consortium found a 400% increase in utilization of services that had previously charged fees for services and medicine. The government's strategy to collaborate with non-governmental organisations has led to higher primary health outcomes among the poor, with relatively high levels of perceived health care quality reported by clients in a recent study of primary care services.\n\nThe physical and psychological effects of war have substantially increased the need for medical care. In the last decade a number of new hospitals were established, with the most advanced treatments being available in Kabul. The French Medical Institute for Children and Indira Gandhi Childrens Hospital in Kabul are the leading children's hospitals in the country. Some of the other main hospitals in Kabul include the 350-bed Jamhuriat Hospital, the Sardar Mohammad Daud Khan Hospital, and the Jinnah Hospital, which is under construction. There are also a number of military-controlled hospitals in different regions of the country. A new 350-bed hospital is under construction in the southern Afghan city of Kandahar.\n\n2011 surveys show that 57 percent of Afghans say they have good or very good access to clinics or hospitals, and Afghans themselves pay approximately 75% of health care costs directly.\n\nTuberculosis is endemic in Afghanistan, with over 76,000 cases reported per year. The United States Agency for International Development is engaged in promulgating DOTS (directly observed therapy, short course) treatments, as well as TB awareness and prevention.\n\nBRAC is a development organisation that focuses on the alleviation of poverty through the empowerment of the poor to improve their lives. BRAC Afghanistan is involved in assisting Afghan Ministry of Public Health in the implementation of the Basic Package of Health Services (BPHS) in Kabul, Badghis, Balkh and Nimroz. This implementation is mainly funded by the World Bank and the USAID-REACH (United States Agency for International Development - Rural Expansion of Afghanistan Community-based Healthcare).\n\nTuberculosis is a serious public health problem in Afghanistan. In 2007, 8,200 people in the country died from tuberculosis and, in the WHO's Global Tuberculosis Control Report 2009, an annual estimated figure of 46,000 new cases of tuberculosis were in Afghanistan. As such, Afghanistan is ranked 22nd in amongst highly affected Tuberculosis countries.\n\nTo help control tuberculosis, BRAC Afghanistan started the community-based TB DOTS under the \"Fund for Innovative DOTS Expansion through Local Initiatives to Stop TB (FIDELIS)\" project in 2006. In the first phase of this programme, diagnostic facilities for tuberculosis were expanded through the setting up of 50 TB microscopy centres. This phase lasted from January 2006 and up to March 2007. Over the next two years, facilities were further expanded and 92 more Tuberculosis Microscopy Centres were set up under the FIDELIS programme.\n\nThe Tuberculosis Control Assistance Programme (TB CAP) is another project taken up between BRAC Afghanistan, World Health Organization (WHO) and Management Sciences for Health (MSH) in a bid to fight TB in Afghanistan. In this project, BRAC Afghanistan supports the BPHS (Basic Package of Health Services) project by replicating the CB-DOTS model into health systems of four provinces: Baghlan, Jawzjan, Badakshan and Herat. BRAC Afghanistan was selected as Principal Recipient (PR) for malaria and TB components of the Global Fund 8.\n\nIn 2009, 2,143,354 patients received treatment under the health programs mentioned. As of August 2010, BRAC Afghanistan had covered 388 districts and 25 million of the total population are under the BRAC Afghanistan Health Program. Health facilities also include six District Hospitals, 26 Comprehensive Health Centres, 53 Basic Health Centres, 18 Sub Health Centres as well as 533 Mobile Clinics every month.\n\nThe prevalence of HIV in Afghanistan is 0.04%. According to Afghanistan's National Aids Control Program (NACP), 504 cases of HIV/AIDS were documented in late 2008. By the end of 2012, the numbers reached 1,327. Afghanistan's healthy ministry stated that most of the HIV patients were among intravenous drug users and that 70% of them were men, 25% women, and the remaining 5% children. They belonged to Kabul, Kandahar and Herat, the provinces from where people make the most trips to neighboring or other foreign countries. Regarding Kandahar, 22 cases were reported in 2012. \"AIDS Prevention department head Dr Hamayoun Rehman said 1,320 blood samples were examined and 21 were positive. Among the 21 patients, 18 were males and three were females who contracted the deadly virus from their husbands. He said four people had reached a critical stage while three had died. The main source of the disease was the use of syringes used by drug addicts.\" There are approximately 23,000 addicts in the country who inject drugs into their bodies using syringes. As of 2015, as much as 6,900 people are living in Afghanistan with HIV and about 300 have died in from the disease.\n\nPoliomyelitis\n\nThe Afghan Ministry of Public Health along with World Health Organization and UNICEF are engaged in a campaign to eliminate polio in the country. Wild poliovirus is present in Afghanistan, though in limited areas. Reported cases were on the decline, from 63 in 1999 to 17 in 2007, until increased violence in 2008 impeded vaccination efforts, causing cases to climb to 20 for the first nine months of 2009. Afghanistan, the remaining country where polio is endemic. Most of Afghanistan is polio-free. The country has not yet interrupted transmission of wild poliovirus. While most cases in 2014, 2015 and 2016 were due to poliovirus imported from neighbouring Pakistan, there is also ongoing transmission of virus within Afghanistan. In 2015 and from January/2016 to September/ 2016. Afghanistan had a major reduction in WPV cases. The majority of cases were reported from Nangarhar province in eastern Afghanistan, which borders Pakistan, and were genetically linked to cases in Pakistan. Afghanistan reported 20 cases in 16 districts in 2015, compared with 28 cases in 19 districts in 2014, and 8 cases in 2016, The most recent case had onset of paralysis on 8 August/2016, from Kabul.\n\nMalnutrition\n\nMore than half of Afghan girls and boys suffer damage to their minds and bodies that cannot be undone because they are poorly nourished in the crucial first two years of life. High levels of Malnutrition in Children is rate of stunting 60.5%, One third of children (33.7%) underweight, Anaemia 50% in children 6–24 months, High iodine deficiency: 72%(school age) and also the high levels of Malnutrition in Women is Iron deficiency: 48.4%, non-pregnant and Iodine deficiency 75%.and high levels of chronic energy deficiency are 20.9% low BMI.\nSupporting the Implementation of Nutrition (and Health)-Specific Interventions through BPHS and EPHS. The Ministry of Public Health, World Bank and WFP are working together for ensuring that mothers are healthy before they become pregnant and throughout pregnancy, promoting appropriate Infant and Young Child Feeding Practices, ensuring that children receive adequate health care to prevent growth faltering resulting from illness and early treatment of acute malnutrition and Promote appropriate hygiene practices.\n\nDespite anti-leprosy initiatives by Leprosy Control (LEPCO) dating to 1984, leprosy is present in Afghanistan, with 231 cases reported in the 2001-2007 period. Just over three-quarters of the cases were the MB-type, with the rest PB-type. Leprosy has been reported in the central Hindu Kush mountain area of the country. Mainly in the provinces of Bamyan, Ghazni, Balkh.\n\nBeing the 15th least developed country in the world, Afghanistan faces difficulties in sanitation. In urban areas 40% of the population have unimproved access to sanitation facilities. Because of this many Afghanistan natives are forced to combat typhoid fever. Typhoid fever is one of Afghanistan's major infectious diseases in terms of food/waterborne diseases. This infectious disease occurs when fecal material comes into contact with food or water. Symptoms vary from case to case but often mild fever is present and if left untreated death may occur.\n\nSanitation issues place the Afghanistan population at risk of contracting hepatitis A through the consumption of food and water that has been contaminated by fecal material. Hepatitis A works by inhibiting the liver from functioning properly. Symptoms generally include jaundice, fatigue, loss of appetite, while some victims may experience diarrhea. Furthermore, symptoms will appear 2–6 weeks after an individual has come into contact with the hepatitis A virus. Efforts have been made to fight hepatitis through efforts by the Pashtun community. Tribal leader Davud Suleimankhel is credited with establishing an organization that teaches people about Hepatitis, Tuberculosis, and other diseases. In a speech to the Jalalabad Pashtun League, he said that \"the red-blooded vigor of the Pashtuns and the iron soul of Afghanistan shall not falter in the face of disease\". Various aid organizations have also started to work in Afghanistan to combat Hepatitis.\n\nVisceral leishmaniasis infections are often recognised by fever, swelling of the liver and spleen, and anemia. They are known by many local names, of which the most common is probably \"Kala azar\". A total of 21 cases of VL acquired in Afghanistan, all in the 1980s according to CDC reporting.\n\nAfghanistan made significant improvement in the last decade to its maternal and child health care. According to United States Agency for International Development (USAID), Afghanistan's mortality rate has decreased by about 25% since 2003. It was reported in 2006 that nearly 60% of the population lives within two hours walking distance of the nearest health facility.\n\nThe maternal mortality rate is currently 396 deaths/100,000 live births and its infant mortality rate is 66 to 112.8 deaths in every 1,000 live births. The Ministry of Public Health wants to further improve these higher rates by making them normal. \n\nThe country has more than 3,000 midwives, with an additional 300 to 400 being trained each year. According to Sima Ayubi, a maternity doctor in Kabul who advocates hospital births, explains: \"Now pregnant women have more information about health. This mortality rate is still a problem. There's just a decrease. The problem is not completely eliminated or under control.\"\n\nAccording to a 2012 report by Save the Children, improved healthcare and the rise of females attending school have made Afghanistan climb up from its position as the worst place on earth to be a mother. \"More mothers are surviving and fewer children are dying and this is something we need to be celebrating,\" said Rachel Maranto, Advocacy and Mobilisation senior Manager at Save the Children in Kabul.\n\n\n"}
{"id": "10919408", "url": "https://en.wikipedia.org/wiki?curid=10919408", "title": "Johns Hopkins School of Nursing", "text": "Johns Hopkins School of Nursing\n\nThe Johns Hopkins University School of Nursing (JHUSON) is part of the Johns Hopkins University located in Baltimore, Maryland, United States. Established in 1889, it is one of the nation’s oldest and schools for nursing education, ranking 2nd in the nation. It is also among the top recipients of nursing research funding from the National Institutes of Health. The school's mission is to provide leadership to improve health care and advance the nursing profession through education, research, practice, and service.\n\nThe founder Johns Hopkins' desire for a training school for female nurses was formally stated in a posthumous 1873 instruction letter to the board of trustees of the Johns Hopkins institutions. The School of Nursing in conjunction with the Johns Hopkins Hospital was eventually founded in 1889 after in depth consultation with Florence Nightingale on its planning, organization, structure and curriculum.\n\nThe Johns Hopkins University School of Nursing is located on the Johns Hopkins University East Baltimore campus along with the Bloomberg School of Public Health, School of Medicine, and the Johns Hopkins Hospital.\n\nThe School of Nursing offers a variety of programs from pre-licensure programs to Master's, DNP and PhD programs, online options, post-degree opportunities, and nursing prerequisites.\n\n\n\nThe school has four research centers (Center for Innovative Care in Aging, Center for Nursing Research and Sponsored Projects, Center for Collaborative Intervention Research and the Center on Health Disparities Research) and also offers Interdisciplinary Fellowship research on violence, pain, and health disparities in underserved populations, as well as research focused on cardiovascular health prevention and risk reduction, care at end of life, community-based health promotion, health disparities, interpersonal violence, maternal-child health, psychoneuroimmunology, and symptom management areas. The school is also home to the country’s first and only Peace Corps Fellows Program in nursing. The school offers a special program for Arts and Science College students to transfer after two years.\n\nThe Johns Hopkins School of Nursing ranks #1 nationally among graduate schools of nursing and #3 for online programs, according to \"U.S. News & World Report,\" and was named the Most Innovative Nursing Graduate Program in the U.S. by Best Master of Science in Nursing Degrees. The school ranks #1 among nursing schools for Federal Research Grants and National Institutes of Health (NIH) funding. Nearly 95 percent of graduates pass the NCLEX on their first try. Among the faculty, more than 40 percent are ranked as Fellows of the American Academy of Nursing. The school has clinics across Baltimore that reach out to abused women, struggling mothers and other underrepresented communities, giving over 12,000 volunteer hours annually and conducting 40 different community-based service programs. The School of Nursing is associated with nursing practice at Johns Hopkins Hospital, ranked #1 in the United States an unprecedented 22 times by \"U.S. News & World Report\".\n\n\n\n\n"}
{"id": "25864701", "url": "https://en.wikipedia.org/wiki?curid=25864701", "title": "Kazuo Imanishi", "text": "Kazuo Imanishi\n\nImanishi was born in Hiroshima on January 12, 1941. After graduating from Tokyo University of Education, he joined his local club Toyo Industries (later \"Mazda\") in 1963. In 1965, Toyo Industries joined new league Japan Soccer League. The club won the champions for 4 years in a row (1965-1968). The club also won 1965, 1967 and 1969 Emperor's Cup. He retired in 1969. He played 42 games in the league. He was elected Best Eleven in 1966.\n\nIn December 1966, Imanishi was elected Japan national team for 1966 Asian Games. At this competition, on December 10, he debuted against India. He played 3 games for Japan in 1966.\n\nAfter retirement, Imanishi became a manager for Mazda as Teruo Nimura successor in 1984. This season was the first season the club was relegated to Division 2. He promoted the club to Division 1 in 1986. In 1987, he resigned a manager and Hans Ooft became a manager. However, the club was relegated to Division 2 again in 1988. Imanishi became a manager as successor Ooft again in 1988. Imanishi promoted the club to Division 1 in 1991 and he resigned in 1992. From 1994, he worked for Japan Football Association until 2002. He also served as president at FC Gifu from 2008 to 2012.\n\n\n"}
{"id": "36986491", "url": "https://en.wikipedia.org/wiki?curid=36986491", "title": "Kiss up kick down", "text": "Kiss up kick down\n\nKiss up kick down (or suck up kick down) is a neologism used to describe the situation where middle level employees in an organization are polite and flattering to superiors but abusive to subordinates. It is believed to have originated in the US, with the first documented use having occurred in 1993. The concept can be applied to any social interaction where one person believes they have power over another person and believes that another person has power over them.\n\nThe \"Bulletin of the Atomic Scientists\" described Robert McNamara, an American business executive and the eighth United States Secretary of Defense, as a classic case of the \"kiss up, kick down\" personality in August 1993.\n\nOn day 2 of the Senate confirmation hearings, April 12, 2005, for John R. Bolton, a Bush nomination for the US representative to the UN, the Senate panel focused on allegations that Bolton pressured intelligence analysts. Former State Department intelligence chief Carl W. Ford Jr. characterized Bolton as a \"\"kiss-up, kick-down\" sort of guy\", implying that he was always ready to please whoever had authority over him, while having very little regard for people working under him.\n\nCalum Paton, Professor of Health Policy at Keele University, describes \"kiss up kick down\" as a prevalent feature of the UK National Health Service culture. He raised this point when giving evidence at the Stafford Hospital scandal public inquiry. Credit is centralised and blame devolved. \"\"Kiss up kick down\" means that your middle level people will \"kiss-up\", they will please their masters, political or otherwise, and they will \"kick down\" to blame somebody else when things go wrong.\"\nFor example, NHS Trust bosses are nervous of reporting deficits and seek to under-report until it's too late. They seek to please their political superiors in the short term and shift blame down the line.\n\nSome systems theorists and management consultants, such as Gerald Weinberg, see the flow of blame in an organization as one of the most important indicators of that organization's robustness and integrity. Blame flowing downwards, from management to staff, or laterally between professionals, indicates organizational failure. In a blame culture, problem-solving is replaced by blame-avoidance. Weinberg emphasizes that blame coming from the top generates \"fear, malaise, errors, accidents, and passive-aggressive responses from the bottom\", with those at the bottom feeling powerless and lacking emotional safety.\n\n\"Kick up kiss-down\" has been suggested as a viable more healthy dynamic. Blame flowing upwards in a hierarchy, Weinberg argues, proves that superiors can take responsibility for their orders to their inferiors, and supply them with the resources required to do their jobs.\n\nThe workplace bully is often expert at knowing how to work the system. They can spout all the current management buzzwords about supportive management but basically use it as a cover. By keeping their abusive behavior hidden, any charges made by individuals about his or her bullying will always come down to your word against the bully's. They may have a \"kiss up kick down\" personality, wherein they are always highly cooperative, respectful, and caring when talking to upper management but the opposite when it comes to their relationship with those whom they supervise. Bullies tend to ingratiate themselves to their bosses while intimidating subordinates. The bully may be socially popular with others in management, including those who will determine\nthe bully's fate. Often, a workplace bully will have mastered \"kiss up kick down\" tactics that hide their abusive side from superiors who review their performance.\n\nAs a consequence of this \"kiss up kick down\" strategy: \n\n"}
{"id": "58508562", "url": "https://en.wikipedia.org/wiki?curid=58508562", "title": "Levonorgestrel cyclobutylcarboxylate", "text": "Levonorgestrel cyclobutylcarboxylate\n\nLevonorgestrel cyclobutylcarboxylate (or levonorgestrel 17β-cyclobutylcarboxylate; developmental code name HRP-001) is a progestin and a progestogen ester which was studied for potential use as an injectable hormonal contraceptive but was never marketed. It was developed by the World Health Organization's Special Programme on Human Reproduction in the 1980s. Analogues of levonorgestrel cyclobutylcarboxylate include levonorgestrel butanoate (HRP-002) and levonorgestrel cyclopropylcarboxylate (HRP-003).\n\n"}
{"id": "47267690", "url": "https://en.wikipedia.org/wiki?curid=47267690", "title": "List of cities in China by life expectancy", "text": "List of cities in China by life expectancy\n\nThis is a list of the cities of the People's Republic of China, including all direct-controlled municipalities, sub-provincial cities, prefecture-level cities, but excluding special administrative regions, in order of their life expectancy.\n\nMost cities with high life expectancy are located in the Yangtze River Delta, Pearl River Delta and Beijing-Tianjin region.\n\n"}
{"id": "431121", "url": "https://en.wikipedia.org/wiki?curid=431121", "title": "List of deaths through alcohol", "text": "List of deaths through alcohol\n\nThis is a list of notable people who died either from the effects of excessive alcohol consumption or alcohol poisoning. The Journal of the American Medical Association defines alcoholism as \"a primary, chronic disease characterized by impaired control over drinking, preoccupation with the drug alcohol, use of alcohol despite adverse consequences, and distortions in thinking, most notably denial.\" The majority of people in this list died from causes brought on by alcoholism. In some cases, they died of multiple causes, with alcoholism being a major factor. Exceptions to this are those who died from accidental death, such as alcohol poisoning caused by binge drinking. In these cases, misuse of drugs sometimes contributed to the person dying. Deaths caused indirectly by alcohol, such as in a car accident are not listed here. The table below lists people who died as a direct result of alcohol misuse. Dates of death are listed instead of dates of birth.\n\n"}
{"id": "61793", "url": "https://en.wikipedia.org/wiki?curid=61793", "title": "List of diseases (W)", "text": "List of diseases (W)\n\nThis is a list of diseases starting with the letter \"W\".\n\n\n\n\n\n\n\n\n\n"}
{"id": "20843699", "url": "https://en.wikipedia.org/wiki?curid=20843699", "title": "List of healthcare reform advocacy groups in the United States", "text": "List of healthcare reform advocacy groups in the United States\n\nHealthcare reform advocacy groups in the United States are non-profit organizations in the US who have as one of their primary goals healthcare reform in the United States.\n\nThese notable organizations address issues such as universal healthcare, national health insurance, and single-payer healthcare.\n\n\n\n\n\n"}
{"id": "45376731", "url": "https://en.wikipedia.org/wiki?curid=45376731", "title": "List of medically significant spider bites", "text": "List of medically significant spider bites\n\nA number of spiders can cause spider bites that are medically important. Almost all spiders produce venom but only a few are classified as \"venomous\" and able to cause significant harm to humans. Two medically important spider genera have a worldwide distribution—\"Latrodectus\" and \"Loxosceles\". Others have a limited distribution.\n\nMedical reports have been criticized for poor evidence. In the last century, both white tailed and wolf spiders were considered medically significant, only to be recanted. Only four genera (\"Phoneutria\", \"Atrax\", \"Latrodectus\", and \"Loxosceles\") are considered medically significant. Bites of these spiders have a range of severity, with only a minority having severe symptoms. Deaths by verified spider bites are exceedingly rare (e.g. one in Australia for 40 years).\n\nThe Brazilian wandering spider (a ctenid spider) is a large brown spider similar to North American wolf spiders in appearance, although somewhat larger. It has a highly toxic venom and is regarded (along with the Australian funnel-web spiders) as among the most dangerous spiders in the world.\nBased on one of the few pharmacological studies performed in the 1970s, \"Phoneutria\"'s venom toxicity was more virulent than both \"Atrax\" and \"Latrodectus\".\n\nAs their name suggests, Brazilian wandering spiders are active ground hunters. If the spider has a reason to be alarmed, it will bite in order to protect itself, but unless startled or provoked, most bites will be without venom. Venom bites will occur if the spider is pressed against something and hurt. In this case, the high levels of serotonin contained in the venom, plus at minimum strong chelicera, will contribute to deliver a very painful bite.\n\nChildren are more sensitive to the venom of wandering spiders. The spiders often make threat gestures, such as raising up their legs, or hopping sideways on the ground, which might amuse a child to the point of reaching towards the spider. In male humans, bites of this spider may also result in prolonged painful penile erections (priapism). Scientists are attempting to create an erectile dysfunction treatment that can be combined with other medicines out of the peptide that causes this reaction.\n\nThe Australian funnel-web spiders, such as the Sydney funnel-web spider \"Atrax robustus\" (a mygalomorph spider not to be confused with the araneomorph funnel-weaver or grass spiders) are regarded as among the most venomous in the world. They react vigorously to threats and, reputedly, will more often attempt to bite than run away. \"A. robustus\", a large black spider, is found within a radius of about 100 km from Sydney. Its venom contains a compound known as atracotoxin which is highly toxic to primates. Approximately 10% of bites lead to serious symptoms for a total of 3-4 severe envenomations annually.\n\n\"A. robustus\" is one of three designated species of the genus \"Atrax\". The related genus \"Hadronyche\" is represented by about 40 other dangerous species in eastern Australia, including Queensland and Tasmania. The males in this case have somewhat more potent venom than females and they also wander, making them more likely to be encountered in summer. Bites by males of two large species, the Sydney funnel-web and northern tree funnel-web, have resulted in death. One specific case denoted an individual being bitten on the heel through his leather footwear after provoking the spider, indicating the great strength of the spider's chelicerae.\n\nOne other genus in the Hexathelidae family has been reported to cause severe symptoms in humans. Severe bites have been attributed to members of the genus \"Macrothele\" in Taiwan, but no fatalities. In other mammals, such as rodents, for example, the effects of funnel web spider venom are much less severe.\n\nFunnel web spiders are related to other mygalomorphs such as tarantulas and trapdoor spiders. These spiders are similar to funnel-webs in size and general appearance and also have huge chitinous fangs that can deliver painful bites, but their venom is usually extremely mild or harmless to humans.\n\nTwo genera of the tangle web spiders have venom which is known to be medically significant. One genus, the widow spiders of genus \"Latrodectus\", has caused human fatalities. The other genus, the false widow spiders of \"Steatoda\", has a far less serious bite.\n\nThe widow spiders (genus \"Latrodectus\"), such as the black widow, redback spider, and katipo are spiders that carry a neurotoxic venom which can cause a set of symptoms known as Latrodectism.\n\nWidow spiders are large, shiny house spiders with relatively spindly legs and deep, globular abdomens. Mature females have dark and shiny abdomens with one or several red spots, either above and/or below. The spots may take the form of an hourglass, or two triangles, point-to-point. They seldom leave their webs, but if they have to, they can run fast enough over short distances. Male widows and immature females may have a variety of streaks and spots on a browner, less globular abdomen. The males are generally too small to be dangerous. Widows tend to be non-aggressive. Some species, especially those in North America, have no spot on their backs, with the hourglass becoming visible only when the spider hangs upside-down, and can thus be mistaken for their less dangerous cousins, which is especially true in males.\n\nThe Australian red-back and North American widow species live near humans and bites are frequent, numbering thousands yearly. The venom produces very painful effects including muscle spasms, 'tetanus-like' contractions, nausea and vomiting, and severe generalized pain. A serious bite will often require a short hospital stay to control pain. Children may be less sensitive to severe effects of redback venom. Still, children as well as elderly and ill individuals are advised to seek medical attention. Fatalities were reported as high as 10% of cases in the early-20th century but deaths have been not reported in the United States for decades and only 0.5% of those bitten have had major medical complications. In 2016 a young Australian man died ten days after he was bitten; the follow-up care may have been erroneous as he was released from the hospital only to die several days later. The previous record of a red-back fatality in Australia was 1955.\n\nThe false black widow spiders (also known as false katipo, false button spider, cupboard spider, and in Australia, brown house spider) are spiders of the genus \"Steatoda.\" They resemble widow spiders in size and physical form, due to being members of the same family. While the bite of \"Steatoda\" spiders are never as serious as can be for true widow spiders, several have been often reported to give general symptoms away from the bite site, indicating the action of venom. The bite of \"Steatoda grossa\" may cause nausea, widespread but short lived pain, muscle spasms, and malaise; the medical community now refers to the symptoms of \"Steatoda\" bites as steatodism. Other spiders in this genus with potentially symptomic venom include two chiefly European varieties, \"S. paykulliana\" and \"S. nobilis\", and a species found mainly in New Zealand and South Africa, \"S. capensis\"\n\nUse of widow spider antivenom has been shown effective in treating steatodism. The genera \"Steatoda\" and \"Latrodectus\" are biologically close relatives; both belonging to the same family Theridiidae. There are over 100 species in this genus \"Steatoda\", but only several species have been associated with symptomatic bites, and many alleged reports have not been confirmed as actual bites (actual bite event not seen, etc.) nor can be directly attributed to certain species (no specimen collected and examined by an arachnologist, etc.).\n\nMembers of this genus are characterized by the \"D\" shape of the cephalothorax, and the way the relatively straight line thus formed is mirrored by the blunt forward surface of the abdomen. Other genera in this family generally have cephalothoraxes that are more oval in shape or even rather round, and that give the appearance of two body parts that are joined by a small connector.\n\nThe family Sicariidae includes three genera which can potentially inflict cytotoxic bites. One genus, \"Loxosceles\", comprises the recluse spiders (below). The other genera, \"Sicarius\" and \"Hexophthalma\", are found only in the southern hemisphere, an example being \"Hexophthalma hahni\".\n\nRecluse spiders (\"Loxosceles\" spp.), such as the brown recluse spider, also known as \"violin spiders\", \"fiddlers\", or \"fiddlebacks\", from the dark violin-shaped marking on the cephalothorax, are retiring spiders which wander about in dim areas and under things. Large populations can infest a house without any bites reported. Due to small fangs, bites happen when trapped against one's skin by clothing, bed sheets, etc. Most encounters with this spider occur from moving boxes or rooting about in closets or under beds. The range of the brown recluse, \"L. reclusa\" in the U.S. is limited to the central and southern states. A number of related recluse spiders (some non-native introductions) are found in the western deserts. Reports of recluse bites far outnumber the number of spiders found in much of the U.S.\n\nMost recluse spider bites are minor with a small area of redness. However, a small number of bites produce severe dermonecrotic lesions, and, sometimes, severe systemic reaction known as hemolytic anemia. Brown recluse bites have been suspected in several fatalities.\n\nA minority of bites form a necrotizing ulcer that destroys soft tissue and may take months and, on very rare occasions, years to heal, leaving deep scars. The damaged tissue will become black and eventually slough away. Bites occur commonly during dressing as spiders are trapped in the sleeve or pant leg. Bites usually become painful and itchy within 2 to 8 hours, pain and other local effects worsen 12 to 36 hours after the bite with the necrosis developing over the next few days. Around the face, swelling is common.\n\nSerious systemic effects known as visceral loxoscelism may occur before this time, as the venom spreads throughout the body. Moderate symptoms include nausea, vomiting, fever, rashes, and muscle and joint pain. Rarely more severe symptoms occur including hemolysis, thrombocytopenia, and disseminated intravascular coagulation. Debilitated patients, the elderly, and children may be more susceptible to systemic loxoscelism. Hemolysis may require transfusion and could lead to kidney failure. Deaths have been reported from suspected brown recluse envenomation. and the related South American species bites \"L. laeta\" and \"L. intermedia.\"\n\nThe Chilean recluse, a species native to South America have been known to cause systemic visceral loxoscxelism in 15% of reported cases, and fatalities in 3‒4% of cases. A few spiders have been found in Pasadena, California, but no bites have been reported.\n\nThe six-eyed sand spiders of southern Africa in the genus \"Hexophthalma\" inject a cytotoxic venom, believed to contain sphingomyelinase D, for which there is currently no antivenom. Fortunately, this specimen rarely interacts with humans, and is seldom known to bite. This spider buries itself in sand in order to ambush prey that wanders nearby. Sand particles adhere to cuticles on its abdomen, thus acting as a natural camouflage if uncovered.\n\nThe mouse spiders of the genus \"Missulena\" are a type of primitive burrowing spider found primarily in Australia. Several species of this genus are known to possess a venom which contains compounds similar to atracotoxin, the substance in funnel-web venom which can be fatal. However, most bites suffer only local pain and bleeding, a few more have limited neurotoxic symptoms (tingling, racing heart, more widespread pain) and there have been several recorded bites by this spider producing severe symptoms requiring medical treatment. There are no recorded human fatalities due to mouse spider bites. When severe envenomation does occur, funnel-web antivenom has been shown to be effective.\n\nThe tarantulas of the family Theraphosidae are fearsome-looking spiders and a favorite of movies and television. The fangs deliver a weak venom and simultaneously crush the insect. The Sydney Funnel web is a relative with a much more potent neurotoxic venom. Trapdoor spiders, many of which resemble tarantulas but are shinier and less hairy, also have large fangs that deliver painful bites, but have very mild venom.\n\nNew-world tarantulas—those indigenous to the Americas—have bites that generally pose little threat to humans (other than causing localized pain). The primary defense deployed by these spiders is by means of urticating hairs, which can cause irritant symptoms in humans.\n\nOld-world tarantulas, especially those indigenous to Asia, lack urticating hairs and may bite as a defensive mechanism. They are far less docile than new-world tarantulas, and are more likely to bite when provoked.\n\nHobbyists report bites by \"Poecilotheria\" species, occasionally resulting in hospitalization. Symptoms include localized pain and swelling, exhaustion, moderate to severe muscle cramping, labored breathing and fever, sometimes delayed days after the initial bite. Medical documentation is lacking.\n\nThere are several species of spider (and related arachnids), which have had false historical reputations for being harmful to humans.\n\nThe Centers for Disease Control blamed hobo spider for the necrotic bite reports. Many brown recluse bites have been reported in the U.S. west coast states (Washington, Oregon, and northern California) where populations of brown recluse spiders have not been found. The hobo spider, \"Tegenaria agrestis\", may wander away from its web, especially in the fall, and thus come into contact with people. Studies performed by arachnologist Darwin Vest reported that this spider's venom caused significant necrotic effects in laboratory animals. The CDC published six reports of hobo spiders being found in and around the home of patients with a \"spider bite\" story. Many agricultural authorities have published the advice that this species is potentially harmful, and medical personnel in the western United States and Canada have been advised to consider hobo spider bites when patients present with necrotic wounds.\n\nHowever, in Europe, where the spider originates, the species is considered a harmless outdoor relative of the common house spider (\"Tegenaria domestica\"), and no other spider in the genus \"Tegenaria\" is considered to be harmful to people. Attempts to replicate Vest's study that reported necrotic effects of the venom have failed, thus casting the \"dangerous\" status of this spider into doubt. In addition, Vest's methodologies have been questioned; he has been accused of incorrectly attributing symptoms to hobo spider bites when no positive identification of the spider was made. The one fatality attributed to the spider by medical authorities has also been questioned, and there are no documented cases where an otherwise-healthy person has developed a necrotic lesion from a positively identified hobo spider bite. Many scientists now question whether or not the spider is harmful at all.\n\n\"Lycosa tarantula\", a species of wolf spider which is found near Taranto, Italy, Serbia, Montenegro (and the origin of the name tarantula, which today refers to a completely different kind of spider), was once blamed for a condition known as tarantism. A bitten young woman would be forced to dance wildly in the central plaza—the tarantella. Cultural interpretations report sexuality as an important aspect of the \"spider bite\". Originally thought to be mass hysteria, some scholars point to a culturally accepted means of exhibitionism. History of medicine believe the confusion came from workers in the fields would suffer bites, and observe large, conspicuous, hairy spiders in the area. That spider, \"L. tarantula\", was blamed for the pain and suffering (and occasional death) associated with tarantism. It is known that the bite of \"L. tarantula\", while sometimes painful, has no serious medical consequences for humans. It is also suspected that the real culprit was another spider, \"Latrodectus tredecimguttatus\", the European widow spider, which causes latrodectism. A similar mass hysteria surrounds purported brown recluse bites.\n\"Lycosa raptoria\" of South America has been reported to have caused a painful bite followed by intense tissue swelling and in some cases either mild systemic effects or a necrotic lesion. Subsequent investigation removed the species from suspicion.\n\nWhite-tailed spiders (\"Lampona\" spp.), indigenous to Australia and present as an invasive pest in New Zealand, have been blamed for a necrotic bite, producing symptoms similar to a brown recluse. The white-tailed spider (Lampona) was implicated for decades in necrotic lesions but has been exonerated. A study of 130 white-tailed spider bites found no necrotic ulcers or confirmed infections only a red mark, local swelling and itchiness. Very occasionally nausea, vomiting, malaise or headache may occur.\n\nThe Yellow Sac spiders, \"Cheiracanthium sp.\", were reported to produce a necrotic skin lesions. The few reports were cited many times. New analyses of numerous verified bites demonstrate no skin lesions but some local pain and redness. They are also very common in households and like to wander, which suggests a higher probability of the bites.\n\nThe spider-like arachnids known as Opiliones (also known as \"harvestmen\" or \"daddy-long-legs\"), are a species often handled by humans. They are the subject of an urban legend which not only claims that harvestmen are venomous, but are in fact more venomous than any of the spiders but are incapable of biting humans due to their lack of penetration. This is untrue on several counts. None of the known species have venom glands or chelicerae bearing fangs, instead having smaller, pincer-like chelicerae that cannot usually penetrate human skin. In addition, incidents of opiliones biting people are rare, and no reported bites by these species have had any lasting effects.\n\nThe term \"daddy-long-legs\" also can refer to the similar-looking cellar spider. This species (a true spider) can bite humans, but its venom is not known to have any effects beyond mild discomfort at the site of the bite.\n\nThe arachnids of the order Solifugae, also known as wind scorpions, camel or sun spiders, are neither spiders nor scorpions. In the Middle East, it is common belief among some American soldiers stationed there that Solifugae will feed on living human flesh. The urban myth claims that the creature will inject some anesthetizing venom into the exposed skin of its sleeping victim, then feed voraciously, leaving the victim to awaken with a gaping wound. Solifugae, however, do not produce such an anesthetic, and do not attack prey larger than themselves unless threatened.\n\nFurther, Solifugae are known to not possess any venom (other than one species in India, which may possess venom according to one study). However, due to the large size of their jaws, bites by Solifugae can cause significant wounds, which should be treated accordingly to avoid infection.\n"}
{"id": "22184505", "url": "https://en.wikipedia.org/wiki?curid=22184505", "title": "Marilyn T. Miller", "text": "Marilyn T. Miller\n\nMarilyn Miller is an American pediatric ophthalmologist specializing in the diagnosis and treatment of congenital eye diseases and strabismus. She has held leadership positions in her field, often as the first female in those positions.\n\nMiller graduated from the University of Illinois School of Medicine in 1959, and subsequently completed her internship, ophthalmology residency and fellowship in pediatric ophthalmology at University of Illinois Hospital. She was a student of strabismus expert Eugene R. Folk. Miller received her B.A. in microbiology from Purdue University in 1954 and M.S. in the same subject from the University of Illinois in 1966.\n\nMiller's contributions include descriptions of ocular findings in Möbius syndrome, Parry–Romberg syndrome, and fetal alcohol syndrome. She described associations of Duane syndrome with craniofacial abnormalities, as well as dyslexia, thalidomide toxicity, and other first-trimester anomalies. In the 1990s, her study of eye motility problems in people affected by thalidomide contributed to research into the causes of autism.\n\nDuring her long career, Miller became known particularly for her interest in international ophthalmology. Along with administrative and educational work in this area, she has cared for thousands of patients around the world, and particularly in Nigeria.\n\nDr. Miller has been recognized for decades of care provided to children. She was the first female to serve as president of the American Association for Pediatric Ophthalmology and Strabismus, and also the first female board member of the American Academy of Ophthalmology.\n\n\n"}
{"id": "23735746", "url": "https://en.wikipedia.org/wiki?curid=23735746", "title": "Medical education agency", "text": "Medical education agency\n\nMedical education agencies are a specialty subset of advertising agencies that develop educational content for the Healthcare, Life Science and Biotechnology industries. Medical education agencies are divided into two categories:\n\nMedical education agencies that develop Continuing medical education (most commonly referred to as CME) programs in the United States, do so within the strict guidelines set forth by the Accreditation Council for Continuing Medical Education (ACCME) and the Society for Academic Continuing Medical Education (SACME). Those who wish to offer CME courses, and thus employ the services of a medical education agency, must receive accreditation from the ACCME. Accreditation allows organizations, such as the American Nursing Certification Center (ANCC) to develop educational course content that physicians and other professional medical staff may use to satisfy annual CME requirements.\n\nTo avoid the risk of undue bias from commercial sponsorship, all accredited organizations must follow the commercial disclosure rules set out by the ACCME. Medical education agencies must familiarize themselves with these regulations in order to receive CME accreditation from one or more ACCME accredited organizations.\n\nMedical education agencies that develop Non-CME, also referred to as Promotional education, programs specialize in developing content whose commercial sponsorship is clearly outlined, and course content focuses on specific products or therapies in which the sponsoring organization has a financial interest.\n\nThe majority of content developed by medical education agencies supports one of two types of delivery mechanism: Instructor Led Training (ILT) and Self Directed Training (SDT).\n\nInstructor led training, ILT, is the practice of face-to-face delivery of information and learning material between an instructor and learners. Instructor lead training can take the form of didactic training, laboratory demonstration and/or clinical application.\n\nHospitals, Universities, Pharmaceutical and Medical device manufacturers may employ medical education agencies to develop specific content, or to apply Instructional Design principles to existing content to make it more readily understood by an instructor led audience. This will include developing informational structures to follow learning theories, targeting content toward a specific audience or set of audiences and\n\nSelf Directed Training, is the practice of gaining information from learning materials without an instructor present. Self-directed training takes many forms, including deployed eLearning content, textbooks, searchable databases of information and viewing of training presentations at one's own pace. Self-directed training often takes place through a web portal, a SCORM compliant Learning Management System (LMS) or a webcast engine.\n\nHospitals, Universities, Pharmaceutical and Medical device manufacturers may employ medical education agencies to develop specific content, or to apply Instructional Design principles to existing content, to make a product, technology or concept more readily understood by a self-directed audience. Medical education agencies also help learners to better understand complex content through interactivity, animation and virtual simulations of training content.\n\n"}
{"id": "21162922", "url": "https://en.wikipedia.org/wiki?curid=21162922", "title": "Ministry of Health (Ghana)", "text": "Ministry of Health (Ghana)\n\nThe Ministry of Health (MoH) is the government ministry of Ghana that is responsible for the health of Ghana. It is involved in providing public health services, managing Ghana's healthcare industry, and building Ghana's hospitals and medical education system.\n\nMinistry main offices are located in Accra.\n\nThe ministry is responsible for all health related issues in Ghana. It was responsible for direct public health service delivery or provision in the country. However, with the enactment of an ACT 525 of parliament, the functions of promotion, preventive, curative and rehabilitative care has been delegated to the Ghana Health Service and Teaching hospitals. Hence, the ministry is now responsible for only policy formulation, monitoring and evaluation, resource mobilization and regulation of the health service delivery in the country.\n\nMinistry agencies include:\n\n\n"}
{"id": "13278008", "url": "https://en.wikipedia.org/wiki?curid=13278008", "title": "Mirko Tomassoni", "text": "Mirko Tomassoni\n\nMirko Tomassoni (born 24 April 1969) was Captain Regent of San Marino for the six-month term from October 2007 to March 2008 and the second term from October 2018. He served together with Alberto Selva the first term and currently serving with Luca Santolini his second term. He is a Member of the Parliament of San Marino, Member of the ICD Advisory Board, Minister of Culture of San Marino.\n\nMirko Tomassoni was born in Borgo Maggiore on 24 April 1969. He entered the political life of the country beginning from 1992. In 1999 he was in a car accident that changed his life and deprived him from active lifestyle. He was elected to the Local Town Council for three times before his being elected to the Grand and General Council.\n\nTomassoni was elected in June 2006 to the Grand and General Council as an independent on the list of the Party of Socialists and Democrats. On October 1, 2007 Mirko Tomassoni was elected as one of the heads of state, making him the first disabled person to ever have been elected as captain regent. According to the laws of San-Marino after his stay at the post of Head of State of San Marino he returned to the civil life.He seeks to improve awareness of disability among all people and does all the best to help such people in their everyday life. He wrote the book \"Bolivia 2013\" which was published on 19 March 2014. \n\n"}
{"id": "15423983", "url": "https://en.wikipedia.org/wiki?curid=15423983", "title": "Monogram Biosciences", "text": "Monogram Biosciences\n\nMonogram Biosciences Inc. (formerly ViroLogic Inc.), a wholly owned subsidiary of LabCorp, is an international biotechnology laboratory located in South San Francisco, California, USA. Monogram develops and markets assays to help guide and improve the treatment of infectious diseases (including HIV and Hepatitis) and cancer.\n\nVirologic was founded in 1996 by Daniel Capon, Ph.D., Martin Goldstein and Robert S. Capon. The company went public (NASDAQ: VLGC) in 2000.\n\nMonogram was acquired by Laboratory Corporation of America in June 2009.\n\n\n "}
{"id": "7176424", "url": "https://en.wikipedia.org/wiki?curid=7176424", "title": "Norwegian Electronic Health Library", "text": "Norwegian Electronic Health Library\n\nThe Norwegian Electronic Health Library (Helsebiblioteket.no), established 2006, is a publicly funded web based knowledge service that provides Norwegian health workers with access to updated professional information and clinical decision tools.\n\nThis is done by\n\n\nThe library is unique globally in giving general access to the entire population of a country to international point-of-care tools and the largest international medical journals. The Norwegian Electronic Health Library provides access to new research, patient leaflets and guidelines from national authorities, as well as guidelines, and procedures developed by renowned professional institutions. The library includes topic libraries for drugs, mental health, poisoning, quality assurance and public health.\n\nThe Norwegian Electronic Health Library is funded by Norway's National Budget. It is run by the Norwegian Institute of Public Health.\n\nHelsebiblioteket.no was awarded «Library of the year 2011» by the Norwegian Library Association.\n\nThe Norwegian Electronic Health Library is widely used by health personnel, students, as well as lay people.\n\nNHS Evidence is a similar public website for health professionals and students in the UK.\n\n"}
{"id": "22969987", "url": "https://en.wikipedia.org/wiki?curid=22969987", "title": "Novia University of Applied Sciences", "text": "Novia University of Applied Sciences\n\nThe Novia University of Applied Sciences () is an institution of higher professional education (vocational university) in Finland. It offers Bachelor's and Master's degree programmes in Swedish in Vaasa, Turku, Raseborg and Jakobstad.\n\nThe university was formed on August 1, 2008, by the merging of the Sydväst Polytechnic and the Swedish Polytechnic.\n\nThese programmes are conducted in English\n\n\n\nThese programmes are available at Novia University of Applied Sciences as of 2015, with a range of sub-categories.\n\nThe university has a proud tradition of student unions, and student union events are regularly held throughout the academic year.\n\n\n"}
{"id": "325663", "url": "https://en.wikipedia.org/wiki?curid=325663", "title": "Pollination management", "text": "Pollination management\n\nPollination management is the label for horticultural practices that accomplish or enhance pollination of a crop, to improve yield or quality, by understanding of the particular crop's pollination needs, and by knowledgeable management of pollenizers, pollinators, and pollination conditions.\n\nWhile people think first of the European honey bee when pollination comes up, in fact there are many different means of pollination management that are used, both other insects and other mechanisms. There are other insects commercially available that are more efficient, like the blue orchard bee for fruit and nut trees, local bumblebees better specialized for some other crops, hand pollination that is essential for production of hybrid seeds and some greenhouse situations, and even pollination machines.\n\nWith the decline of both wild and domestic pollinator populations, pollination management is becoming an increasingly important part of horticulture. Factors that cause the loss of pollinators include pesticide misuse, unprofitability of beekeeping for honey, rapid transfer of pests and diseases to new areas of the globe, urban/suburban development, changing crop patterns, clearcut logging (particularly when mixed forests are replaced by monoculture pine), clearing of hedgerows and other wild areas, bad diet because of loss of floral biodiversity, and a loss of nectar corridors for migratory pollinators.\n\nThe increasing size of fields and orchards (monoculture) increase the importance of pollination management. Monoculture can cause a brief period when pollinators have more food resources than they can use (but monofloral diet can reduce their immune system) while other periods of the year can bring starvation or pesticide contamination of food sources. Most nectar source and pollen source throughout the growing season to build up their numbers.\n\nCrops that traditionally have had managed pollination include apple, almonds, pears, some plum and cherry varieties, blueberries, cranberries, cucumbers, cantaloupe, watermelon, alfalfa seeds, onion seeds, and many others. Some crops that have traditionally depended entirely on chance pollination by wild pollinators need pollination management nowadays to make a profitable crop. Many of these were at one time universally turning to honeybees, but as science has shown that honeybees are actually inefficient pollinators, demand for other managed pollinators has risen. While honeybees may visit dozens of different kinds of flowers, diluting the orchard pollen they carry, the Blue orchard bee will visit only the intended tree, producing a much higher fertilization rate. The focus on the specific tree also makes the orchard bee 100 times more efficient at pollinating, per bee.\n\nSome crops, especially when planted in a monoculture situation, require a very high level of pollinators to produce economically viable crops, especially if depending on the more generalized honeybee. This may be because of lack of attractiveness of the blossoms, or from trying to pollinate with an alternative when the native pollinator is extinct or rare. These include crops such as alfalfa, cranberries, and kiwifruit. This technique is known as saturation pollination. In many such cases, various native bees are vastly more efficient at pollination (e.g., with blueberries), but the inefficiency of the honey bees is compensated for by using large numbers of hives, the total number of foragers thereby far exceeding the local abundance of native pollinators. In a very few cases, it has been possible to develop commercially viable pollination techniques that use the more efficient pollinators, rather than continued reliance on honey bees, as in the management of the alfalfa leafcutter bee. \n\nIn the case of the kiwifruit, its flowers do not even produce nectar, so that honeybees are reluctant to even visit them, unless present in such overwhelming numbers that they do so incidentally. This has led bumblebee pollination companies to begin offering their services for kiwifruit, as they appear to be far more efficient at the job than honeybees, even more efficient than hand pollination.\n\nIt is estimated that about one hive per acre will sufficiently pollinate watermelons. In the 1950s when the woods were full of wild bee trees, and beehives were normally kept on most South Carolina farms, a farmer who grew ten acres (4 ha) of watermelons would be a large grower and probably had all the pollination needed. But today's grower may grow 200 acres (80 ha), and, if lucky, there might be one bee tree left within range. The only option in the current economy is to bring beehives to the field during blossom time.\n\nOrganisms that are currently being used as pollinators in managed pollination are honey bees, bumblebees, alfalfa leafcutter bees, and orchard mason bees. Other species are expected to be added to this list as this field develops. Humans also can be pollinators, as the gardener who hand pollinates her squash blossoms, or the Middle Eastern farmer, who climbs his date palms to pollinate them.\n\nThe Cooperative extension service recommends one honey bee hive per acre (2.5 hives per hectare) for standard watermelon varieties to meet this crop's pollination needs. In the past, when fields were small, pollination was accomplished by a mix of bees kept on farms, bumblebees, carpenter bees, feral honey bees in hollow trees and other insects. Today, with melons planted in large tracts, the grower may no longer have hives on the farm; he may have poisoned many of the pollinators by spraying blooming cotton; he may have logged off the woods, removing hollow trees that provided homes for bees, and pushed out the hedgerows that were home for solitary native bees and other pollinating insects.\n\nBefore pollination needs were understood, orchardists often planted entire blocks of apples of a single variety. Because apples are self-sterile, and different members of a single variety are genetic clones (equivalent to a single plant), this is not a good idea. Growers now supply pollenizers, by planting crab apples interspersed in the rows, or by grafting crab apple limbs on some trees. Pollenizers can also be supplied by putting drum bouquets of crab apples or a compatible apple variety in the orchard blocks.\n\nThe field of pollination management cannot be placed wholly within any other field, because it bridges several fields. It draws from horticulture, apiculture, zoology (especially entomology), ecology, and botany.\n\nGrowers’ demand for beehives far exceeds the available supply. The number of managed beehives in the US has steadily declined from close to 6 million after WWII, to less than 2.5 million today. In contrast, the area dedicated to growing bee-pollinated crops has grown over 300% in the same time period. To make matters worse, in the past five years we have seen a decline in winter managed beehives, which has reached an unprecedented rate near 30%. At present, there is an enormous demand for beehive rentals that cannot always be met. There is a clear need across the agricultural industry for a management tool to draw pollinators into cultivations and encourage them to preferentially visit and pollinate the flowering crop. By attracting pollinators like honeybees and increasing their foraging behavior, particularly in the center of large plots, we can increase grower returns and optimize yield from their plantings.\n\n"}
{"id": "29728894", "url": "https://en.wikipedia.org/wiki?curid=29728894", "title": "Psychosocial treatment of needle phobia in children", "text": "Psychosocial treatment of needle phobia in children\n\nWhile needle phobia is not age-specific, it is more common in children than in adults. The latest research from all fields indicates that needle-fear is predominant among children fears with some research claiming that up to 93% of children experience [needle-related] stress.\" Many studies have been performed investigating psychosocial methods of helping children cope with their fear. Current research in this area has investigated several types of non-invasive treatments to aid children in their needle phobia. These can be categorized into distraction techniques and other methods. These techniques offer safer, cheaper alternatives to drug or anesthetic treatments (see Treatment).\n\nDistraction treatments take advantage of the brain's inability to pay full attention to two things at once. Distraction works by passively or actively redirecting the child's attention away from the needle in the medical procedure at hand, leaving \"less attention available to perceive pain.\" Taking the child's attention from the needle also lessens his or her ability to feel anxiety; this is important because a large part of needle phobia is the anticipatory stress caused by the needle. This phenomenon is referred to as an \"analgesic effect,\" meaning \"pain-relieving effect.\" Distraction treatments can be divided into passive and active distraction.\n\nPassive distraction is defined for the following studies as a form of distraction that commands the child's attention but does not require any participation on the child's part. The following studies used television to display movies or cartoons as a form of passive distraction. Several studies have investigated the analgesic effect that these can provide during venipuncture.\n\nActive distraction is defined as a form of distraction that requires the patient's participation. Most of the studies investigating active distraction and its effect on children's fear of needles had the children play with a toy. Several also used nurses and the child's caregiver(s) to actively distract the child.\n\n\"Paediatric Nursing Magazine\" reviewed several studies that investigated distraction techniques for children during venipuncture. In one of the covered studies, Cohen concluded in a study that watching a children's movie decreased the child's stress, more so than having the child play with an \"interactive toy.\" \nBellieni \"et al\" performed a comprehensive study on active and passive distraction at the University of Siena, Italy. They studied 69 children aged 7–12 that were scheduled to undergo venipuncture. To be included in the study, children had to fit all of the following criteria: \nChildren were randomly assigned to one of three experimental groups: the control group, where venipuncture was performed without distraction (Group C); the active distraction experimental group, where venipuncture was performed while the mother distracted the child (Group M); and the passive distraction experimental group, where venipuncture was performed while the child watched a TV cartoon (Group TV). There were 23 children in each group; the average age and gender ratios of each group are shown in Table 1. The mothers in Group M were instructed to \"actively distract their children during the venipuncture by speaking, caressing, and soothing them.\" The children in Group TV were placed in a room in front of a television; the cartoon started at least two minutes before the venipuncture took place, and the only distraction offered was an invitation for the child to watch the cartoon when it started playing.\n\nThis study used the Oucher scale to assess pain in the children. The Oucher scale, a \"validated visual pain scale scoring from 0 (no pain) to 100 (maximum pain),\" has two separate scales to help children identify their pain level. The scale from 0 to 100 is placed alongside six photographs of children in various levels of discomfort; children in the report were asked to use the pictures as an aid for choosing a numerical value to represent their pain level. Parents of the children were also asked to assess their child's pain levels on the same scale, basing their assessment on the child's external indication of pain and not the child's reported score.\n\nThe results of Bellieni's study suggest that passive distraction is more effective than active distraction in lessening perceived pain from venipuncture, although active distraction does have some effect in lessening perceived pain. The average scores on the Oucher scale for Group C, Group M, and Group TV were 23.04, 17.39, and 8.91, respectively; with standard deviation 24.57, 21.36, and 8.65, also respectively. Even taking these fluctuations in data into account, it is apparent that the passive distraction technique significantly lowered the perceived pain when compared to the control group and the active distraction group, according to both parents and children.\n\nThese results show that distraction by television had a greater analgesic effect than active distraction performed by the mothers. This is shown by both the children's self-reported scores and the mothers' scores. Mason \"et al\", who published a study in \"The Journal of Clinical Psychology in Medical Settings\", suggested that while both mothers and television are effective distraction techniques, the mothers may have been less effective because the children's fear and distress could have affected their ability to interact with their mothers.\n\nIn the \"Journal of Holistic Nursing\", Cavendar \"et al\" performed a study investigating the effect of parents as active distraction to the child. Children in the experimental group received standard care, but the parents were given instruction in how to distract the child. Also, they were given a choice between three distraction items. The control group received standard care, and mothers were present in the room but were not coached on distraction techniques nor given distraction items. The researchers concluded that \"fear was rated as significantly lower\" in the experimental group, though there was \"no statistical difference between the two groups with regard to pain and distress.\"\n\nThe way parents act and react in situations where their child is undergoing venipuncture can have an effect on children and their fear of needles. In \"The Journal of Family Practice\", James G. Hamilton hypothesized that \"needle phobia is learned as well as inherited.\" He observed that \"negative experiences associated with immunization, laboratory work, dental visits, and other medical procedures can condition children … toward becoming fearful of needles.\" Other factors, such as physical and verbal restraint during children's medical procedures, can influence children to fear needles and associated medical situations.\n\nAn article published in \"Nursing Forum\" by Ives \"et al\" outlined several helpful and unhelpful caregiver behaviors during venipuncture. Unhelpful behaviors included overly reassuring children, overly empathizing with children, apologizing, and criticizing children. It was also noted that giving the child control of the procedure from the beginning or asking the child to \"indicate readiness to receive the needle\" increased distress in the children. Other unhelpful responses included \"inadequate or overly forceful restraint by the parent; shaming, threatening, yelling, slapping, lying; or, alternately, pitying, placating, bribing, and helpless parent behaviors.\" The researchers identified a need to provide instruction to parents on what not to say to their child.\n\nNurses identified lack of explanation to the child as a major problem in many immunization procedures. One nurse reported \"getting kicked and hit by a struggling child\" whose parents had not explained the purpose of the visit to the child. Despite the fear that the prospect of venipuncture may invoke, nurses agree that it is better to tell the child exactly what is going to happen beforehand. Nurses also reported that children's fear seemed to correlate with parents' anxiety, and cited parental anxiety as an obstacle in performing venipuncture.\n\nKlieber found several helpful parent behaviors as a part of active distraction in his study published in the \"Journal of Pain and Symptom Management\". These included using a calm voice, giving children permission to cry, remaining firm but not threatening, and using stickers to celebrate effort. The \"Nursing Forum\" article also found active and passive distraction by way of toys and television cartoons to be helpful. The researchers agreed that effective coaching and successful clinical visits involving venipuncture could provide children with an opportunity to practice and master \"adaptive coping skills.\"\n\nKettwich \"et al\" of the Department of International Medicine of the University of New Mexico conducted an experiment published in the \"Journal of Family Practice\" comparing decorated and plain syringes (see picture). The research hypothesis was that \"adding decorative designs or stickers to medical devices before a procedure [would] significantly reduce aversion, fear, and anxiety…[in] needle-phobic patients.\" The experimental syringes were made with conventional 10-milliliter syringes, decorated so that the \"markings of the barrel could still be seen\".\n\nIn the experiment, \"the presentation of individual devices to each subject was randomized to eliminate the possibility of a consistent bias.\" To determine emotional responses to the medical devices, the researchers used the validated Visual analogue scale where 0 denotes lowest response and 10 shows the strongest response. The Visual Analogue Scale for Aversion, Fear, and Anxiety were used. The study defined \"significant needle phobia\" as an \"aversion, fear, or anxiety score of greater than or equal to 5.\" \nThe results of this study showed that the stress-reducing medical devices are effective in reducing aversion, fear, and anxiety towards the medical needles. The results are shown in the table, in the form (Visual Analogue Score) ± (standard deviation).\n\nFor all three Visual Analogue tests, the mean score was much lower for the stress-reducing syringes; on average, the scores for the aversion, fear, and anxiety tests were 79%, 53%, and 51% lower, respectively.\n\nGemma Murphy, a staff nurse at the neonatal unit of University College London Hospital, suggested that future research should investigate types of passive distraction other than cartoons and movies. Murphy suggested studies comparing the effect of books, guided imagery, music, and virtual reality video glasses as other forms of passive distraction.\n\n"}
{"id": "55289698", "url": "https://en.wikipedia.org/wiki?curid=55289698", "title": "Scottish Food and Drink Fortnight", "text": "Scottish Food and Drink Fortnight\n\nThe Scottish Food and Drink Fortnight is a nationwide festival in Scotland, designed to celebrate all aspects of Scottish food and drink, including its variety, producers and history. The event takes place at the start of September and is organised by Scotland Food & Drink and VisitScotland.\n\nThe event involves over 200 miniature events across Scotland, each designed to showcase a different aspect of Scotland's cuisine. These include food festivals, farmers' markets, street parties, celebrity cookery shows, cooking demonstrations and tasting events. Tourists and people across Scotland are encouraged to try new foods made in Scotland, find out about local Scottish producers, learn about the history of Scottish cuisine, showcase new dishes and host traditional Scottish dinners and parties to celebrate the wide variety of Scottish food available.\n\nExamples of events held include, Jocktoberfest - an Oktoberfest style beer festival showcasing Scottish beers; the Wee G & T Festival in Perth - a festival celebrating the wide variety of Scottish gins and mixers; the Edinburgh Harvest Festival - a Harvest Festival held in the Royal Botanic Gardens in Edinburgh, to demonstrate the large selection of Scottish vegetables available.\n"}
{"id": "11691968", "url": "https://en.wikipedia.org/wiki?curid=11691968", "title": "Sex and Love Addicts Anonymous", "text": "Sex and Love Addicts Anonymous\n\nSex and Love Addicts Anonymous (SLAA) is a twelve-step program for people recovering from sex addiction and love addiction. SLAA was founded in Boston, Massachusetts in 1976, by a member of Alcoholics Anonymous (AA). Though he had been a member of AA for many years, he repeatedly acted out and was serially unfaithful to his wife. He founded SLAA as an attempt to stop his compulsive sexual and romantic behavior. SLAA is also sometimes known as the Augustine Fellowship, because early members saw many of their shared symptoms described by St. Augustine of Hippo in his work \"Confessions\". COSLAA is another twelve-step fellowship created to support the family members and friends of sex and love addicts.\n\nSLAA encourages members to identify their own \"bottom-line behaviors.\" The organization identifies these behaviors as \"any sexual or emotional act, no matter what its initial impulse may be, which leads to loss of control over rate, frequency, or duration of its occurrence or recurrence, resulting in spiritual, mental, physical, emotional, and moral destruction of oneself and others.\" Maintaining \"sobriety\" in the SLAA program requires abstaining from one's bottom-line behaviors. However, these behaviors are never set in stone and may change as SLAA members continue in the program. Examples of bottom line behaviors might include sexual or romantic activity outside the scope of monogamous relationships, anonymous or casual sex, compulsive avoidance of intimacy or emotional attachment, one-night stands, compulsive masturbation, obsessive fantasy, compulsive attraction to unavailable or abusive partners, and a wide variety of addictive sexual, romantic, or avoidant behaviors.\n\nMany of those practicing the SLAA recovery program develop the ability to engage in a healthy committed relationship. SLAA encourages recovery from sexual anorexia, emotional anorexia and social anorexia, three related areas of self-deprivation that lead to isolation and often accompany patterns of addictive behavior.\n\nSLAA publishes the book \"Sex and Love Addicts Anonymous.\" It is approved by the organization for use in their fellowship. \n\n\n"}
{"id": "35975551", "url": "https://en.wikipedia.org/wiki?curid=35975551", "title": "Shapsug Reservoir", "text": "Shapsug Reservoir\n\nThe Shapsug Reservoir, also known as the Shapsugskoye Reservoir () is a deactivated reservoir in Takhtamukaysky District of the Republic of Adygea, Russia, located southwest of Krasnodar.\n\nIt was built between 1940 and 1952 on the left bank of the Kuban River valley, at the mouth of the Afips River as a part of rice irrigation system and was important to the economy of Krasnodar Krai of Russia. It was named after the Shapsugs—a tribe which has inhabited the area for thousands of years—and is considered a part of historical Shapsugia, which was a part of historical Circassia. With the area of , the reservoir has a rounded shape, with the length of , the width of , and an average depth of . In the southeast there is a small bay. Together with Tshchik Reservoir, they have a combined capacity of , which made it one of the largest irrigation schemes in the northern part of the Caucasus. The flood water from the reservoir is actively used for crop irrigation. The bottom is subject to severe siltation, and due to pesticides and fertilizers discharged from rice farming, fish kills have occurred in the reservoir, and also in the Krasnodar and Kryukov Reservoirs.\n\nIn 2007, reconstruction of the reservoir was started. The cost of the project on reconstruction was estimated at about 1.8 billion rubles, but later rose to 2.4 billion. The reconstruction was scheduled to be completed in 2015, two years later than initially scheduled.\n"}
{"id": "155823", "url": "https://en.wikipedia.org/wiki?curid=155823", "title": "Sievert", "text": "Sievert\n\nThe sievert (symbol: Sv) is a derived unit of ionizing radiation dose in the International System of Units (SI) and is a measure of the health effect of low levels of ionizing radiation on the human body. The sievert is of importance in dosimetry and radiation protection, and is named after Rolf Maximilian Sievert, a Swedish medical physicist renowned for work on radiation dose measurement and research into the biological effects of radiation.\n\nThe sievert is used for radiation dose quantities such as equivalent dose and effective dose, which represent the risk of external radiation from sources outside the body, and committed dose which represents the risk of internal irradiation due to inhaled or ingested radioactive substances. The sievert is intended to represent the stochastic health risk, which for radiation dose assessment is defined as the probability of radiation-induced cancer and genetic damage. One sievert carries with it a 5.5% chance of eventually developing cancer based on the linear no-threshold model.\n\nTo enable consideration of stochastic health risk, calculations are performed to convert the physical quantity absorbed dose into equivalent dose and effective dose, the details of which depend on the radiation type and biological context. For applications in radiation protection and dosimetry assessment the International Commission on Radiological Protection (ICRP) and International Commission on Radiation Units and Measurements (ICRU) have published recommendations and data which are used to calculate these. These are under continual review, and changes are advised in the formal \"Reports\" of those bodies.\n\nConventionally, the sievert is not used for high dose rates of radiation that produce deterministic effects, which is the severity of acute tissue damage that is certain to happen, such as acute radiation syndrome; these effects are compared to the physical quantity absorbed dose measured by the unit gray (Gy).\n\nOne sievert equals 100 rem. The rem is an older, non-SI unit of measurement.\n\nThe SI definition given by the International Committee for Weights and Measures (CIPM) says:\n\n\"The quantity dose equivalent \"H\" is the product of the absorbed dose \"D\" of ionizing radiation and the dimensionless factor \"Q\" (quality factor) defined as a function of linear energy transfer by the ICRU\"\n\nThe value of \"Q\" is not defined further by CIPM, but it requires the use of the relevant ICRU recommendations to provide this value.\n\nThe CIPM also says that \"in order to avoid any risk of confusion between the absorbed dose \"D\" and the dose equivalent \"H\", the special names for the respective units should be used, that is, the name gray should be used instead of joules per kilogram for the unit of absorbed dose \"D\" and the name sievert instead of joules per kilogram for the unit of dose equivalent \"H\"\".\n\nIn summary:\n\nThe gray – quantity \"D\"\n\nThe sievert – quantity \"H\"\n\nThe ICRP definition of the sievert is:\n\nThe sievert is used for a number of dose quantities which are described in this article and are part of the international radiological protection system devised and defined by the ICRP and ICRU.\n\nThe ICRU/ICRP dose quantities have specific purposes and meanings, but some use common words in a different order. There can be confusion between, for instance, \"equivalent dose\" and \"dose equivalent\".\n\nAlthough the CIPM definition states that the linear energy transfer function (Q) of the ICRU is used in calculating the biological effect, the ICRP in 1990 developed the \"protection\" dose quantities \"effective\" and \"equivalent\" dose which are calculated from more complex computational models and are distinguished by not having the phrase \"dose equivalent\" in their name. Only the operational dose quantities which still use Q for calculation retain the phrase \"dose equivalent\". However, there are joint ICRU/ICRP proposals to simplify this system by changes to the operational dose definitions to harmonise with those of protection quantities. These were outlined at the 3rd International Symposium on Radiological Protection in October 2015, and if implemented would make the naming of operational quantities more logical by introducing \"dose to lens of eye\" and \"dose to local skin\" as \"equivalent doses\".\n\nIn the USA there are differently named dose quantities which are not part of the ICRP nomenclature.\n\nThe sievert is used to represent the biological effects of different forms of external ionizing radiation on various types of human tissue. Some quantities cannot be practically measured, but they must be related to actual instrumentation and dosimetry measurements. The resultant complexity has required the creation of a number of different dose quantities within a coherent system developed by the ICRU working with the ICRP.\n\nThe external dose quantities and their relationships are shown in the accompanying diagram. The ICRU is primarily responsible for the operational dose quantities, based upon the application of ionising radiation metrology, and the ICRP is primarily responsible for the protection quantities, based upon modelling of dose uptake and biological sensitivity of the human body.\n\nThese are directly measurable physical quantities in which no allowance has been made for biological effects. Radiation fluence is the number of radiation particles impinging per unit area per unit time, kerma is the ionising effect of the radiation field, and absorbed dose is the amount of radiation energy deposited per unit mass.\n\nProtection quantities are calculated models, and are used as \"limiting quantities\" to specify exposure limits to ensure, in the words of ICRP, \"that the occurrence of stochastic health effects is kept below unacceptable levels and that tissue reactions are avoided\". These quantities cannot be measured in practice but their values are derived using models of external dose to internal organs of the human body, using anthropomorphic phantoms. These are 3D computational models of the body which take into account a number of complex effects such as body self-shielding and internal scattering of radiation. The calculation starts with organ absorbed dose, and then applies radiation and tissue weighting factors.\n\nAs protection quantities cannot practically be measured, operational quantities must be used to relate them to practical radiation instrument and dosimeter responses.\n\nOperational quantities can be measured in practice, and are the means of measuring dose uptake due to exposure or predicting dose uptake in a measured environment, in relation to protection dose values. In this way they are used for practical dose control, by providing an estimate or upper limit for the value of the protection quantities related to an exposure. They are used in practical regulations and guidance.\n\nThe calibration of individual and area dosemeters in photon fields is performed by measuring the collision \"air kerma free in air\" under conditions of secondary electron equilibrium. Then the appropriate operational quantity is derived applying a conversion coefficient that relates the air kerma to the appropriate operational quantity. The conversion coefficients for photon radiation are published by the ICRU.\n\nSimple (non-anthropomorphic) \"phantoms\" are used to relate operational quantities to measured free-air irradiation. The ICRU sphere phantom is based on the definition of an ICRU 4-element tissue-equivalent material which does not really exist and cannot be fabricated. The ICRU sphere is a theoretical 30 cm diameter \"tissue equivalent\" sphere consisting of a material with a density of 1 g·cm and a mass composition of 76.2% oxygen, 11.1% carbon, 10.1% hydrogen and 2.6% nitrogen. This material is specified to most closely approximate human tissue in its absorption properties. According to the ICRP, the ICRU \"sphere phantom\" in most cases adequately approximates the human body as regards the scattering and attenuation of penetrating radiation fields under consideration. Thus radiation of a particular energy fluence will have roughly the same energy deposition within the sphere as it would in the equivalent mass of human tissue.\n\nTo allow for back-scattering and absorption of the human body, the \"slab phantom\" is used to represent the human torso for practical calibration of whole body dosimeters. The slab phantom is depth to represent the human torso.\n\nThe joint ICRU/ICRP proposals outlined at the 3rd International Symposium on Radiological Protection in October 2015 to change the definition of operational quantities would not change the present use of calibration phantoms or reference radiation fields.\n\nThis is an actual reading obtained from such as an ambient dose gamma monitor, or a personal dosimeter. Such instruments are calibrated using radiation metrology techniques which will trace them to a national radiation standard, and thereby relate them to an operational quantity. The readings of instruments and dosimeters are used to prevent the uptake of excessive dose and to provide records of dose uptake to satisfy radiation safety legislation; such as in the UK, the Ionising Radiations Regulations 1999.\n\nThe sievert is used in external radiation protection for equivalent dose (the external-source, whole-body exposure effects, in a uniform field), and effective dose (which depends on the body parts irradiated).\n\nThese dose quantities are weighted averages of absorbed dose designed to be representative of the stochastic health effects of radiation, and use of the sievert implies that appropriate weighting factors have been applied to the absorbed dose measurement or calculation (expressed in grays).\n\nThe ICRP calculation provides two weighting factors to enable the calculation of protection quantities.\n\nWhen a whole body is irradiated uniformly only the radiation weighting factor \"W\" is used, and the effective dose equals the whole body equivalent dose. But if the irradiation of a body is partial or non-uniform the tissue factor \"W\" is used to calculate dose to each organ or tissue. These are then summed to obtain the effective dose. In the case of uniform irradiation of the human body, these summate to 1, but in the case of partial or non-uniform irradiation, they will summate to a lower value depending on the organs concerned; reflecting the lower overall health effect. The calculation process is shown on the accompanying diagram. This approach calculates the biological risk contribution to the whole body, taking into account complete or partial irradiation, and the radiation type or types.\nThe values of these weighting factors are conservatively chosen to be greater than the bulk of experimental values observed for the most sensitive cell types, based on averages of those obtained for the human population.\n\nSince different radiation types have different biological effects for the same deposited energy, a corrective radiation weighting factor \"W\", which is dependent on the radiation type and on the target tissue, is applied to convert the absorbed dose measured in the unit gray to determine the equivalent dose. The result is given the unit sievert.\n\nThe equivalent dose is calculated by multiplying the absorbed energy, averaged by mass over an organ or tissue of interest, by a radiation weighting factor appropriate to the type and energy of radiation. To obtain the equivalent dose for a mix of radiation types and energies, a sum is taken over all types of radiation energy dose.\n\nwhere\nThus for example, an absorbed dose of 1 Gy by alpha particles will lead to an equivalent dose of 20 Sv.\n\nThis may seem to be a paradox. It implies that the energy of the incident radiation field in joules has increased by a factor of 20, thereby violating the laws of Conservation of energy. However, this is not the case. The sievert is used only to convey the fact that a gray of absorbed alpha particles would cause twenty times the biological effect of a gray of absorbed x-rays. It is this biological component that is being expressed when using sieverts rather than the actual energy delivered by the incident absorbed radiation.\n\nThe second weighting factor is the tissue factor \"W\", but it is used only if there has been non-uniform irradiation of a body. If the body has been subject to uniform irradiation, the effective dose equals the whole body equivalent dose, and only the radiation weighting factor \"W\" is used. But if there is partial or non-uniform body irradiation the calculation must take account of the individual organ doses received, because the sensitivity of each organ to irradiation depends on their tissue type. This summed dose from only those organs concerned gives the effective dose for the whole body. The tissue weighting factor is used to calculate those individual organ dose contributions.\n\nThe ICRP values for \"W\" are given in the table shown here.\nThe article on effective dose gives the method of calculation. The absorbed dose is first corrected for the radiation type to give the equivalent dose, and then corrected for the tissue receiving the radiation. Some tissues like bone marrow are particularly sensitive to radiation, so they are given a weighting factor that is disproportionally large relative to the fraction of body mass they represent. Other tissues like the hard bone surface are particularly insensitive to radiation and are assigned a disproportionally low weighting factor.\n\nIn summary, the sum of tissue-weighted doses to each irradiated organ or tissue of the body adds up to the effective dose for the body. The use of effective dose enables comparisons of overall dose received regardless of the extent of body irradiation.\n\nThe operational quantities are used in practical applications for monitoring and investigating external exposure situations. They are defined for practical operational measurements and assessment of doses in the body. Three external operational dose quantities were devised to relate operational dosimeter and instrument measurements to the calculated protection quantities. Also devised were two phantoms, The ICRU \"slab\" and \"sphere\" phantoms which relate these quantities to incident radiation quantities using the Q(L) calculation.\n\nThis is used for area monitoring of penetrating radiation and is usually expressed as the quantity \"H\"*(10). This means the radiation is equivalent to that found 10 mm within the ICRU sphere phantom in the direction of origin of the field. An example of penetrating radiation is gamma rays.\n\nThis is used for monitoring of low penetrating radiation and is usually expressed as the quantity \"H\"'(0.07). This means the radiation is equivalent to that found at a depth of 0.07 mm in the ICRU sphere phantom. Examples of low penetrating radiation are alpha particles, beta particles and low-energy photons. This dose quantity is used for the determination of equivalent dose to such as the skin, lens of the eye. In radiological protection practice value of omega is usually not specified as the dose is usually at a maximum at the point of interest.\n\nThis is used for individual dose monitoring, such as with a personal dosimeter worn on the body. The recommended depth for assessment is 10 mm which gives the quantity \"H\"(10).\n\nIn order to simplify the means of calculating operational quantities, and assist in the comprehension of radiation dose protection quantities, ICRP Committee 2 & ICRU Report Committee 26 started in 2010 an examination of different means of achieving this by dose coefficients related to Effective Dose or Absorbed Dose.\n\nSpecifically;\n\n1. For area monitoring of effective dose of whole body it would be:\n\n\"H\" = Φ × conversion coefficient\n\nThe driver for this is that \"H\"(10) is not a reasonable estimate of effective dose due to high energy photons, as a result of the extension of particle types and energy ranges to be considered in ICRP report 116. This change would remove the need for the ICRU sphere and introduce a new quantity called \"E\"\n\n2. For individual monitoring, to measure deterministic effects on eye lens and skin, it would be:\n\n\"D\" = Φ × conversion coefficient for absorbed dose.\n\nThe driver for this is the need to measure the deterministic effect, which it is suggested, is more appropriate than stochastic effect. This would calculate equivalent dose quantities \"H\" and \"H\".\n\nThis would remove the need for the ICRU Sphere and the Q-L function. Any changes would replace ICRU report 51, and part of report 57.\n\nA final draft report was issued in July 2017 by ICRU/ICRP for consultation. \n\nThe sievert is used for human internal dose quantities in calculating committed dose. This is dose from radionuclides which have been ingested or inhaled into the human body, and thereby \"committed\" to irradiate the body for a period of time. The concepts of calculating protection quantities as described for external radiation applies, but as the source of radiation is within the tissue of the body, the calculation of absorbed organ dose uses different coefficients and irradiation mechanisms.\n\nThe ICRP defines Committed effective dose, E(\"t\") as the sum of the products of the committed organ or tissue equivalent doses and the appropriate tissue weighting factors \"W\", where \"t\" is the integration time in years following the intake. The commitment period is taken to be 50 years for adults, and to age 70 years for children.\n\nThe ICRP further states \"For internal exposure, committed effective doses are generally determined from an assessment of the intakes of radionuclides from bioassay measurements or other quantities (e.g., activity retained in the body or in daily excreta). The radiation dose is determined from the intake using recommended dose coefficients\".\n\nA committed dose from an internal source is intended to carry the same effective risk as the same amount of equivalent dose applied uniformly to the whole body from an external source, or the same amount of effective dose applied to part of the body.\n\nIonizing radiation has deterministic and stochastic effects on human health. Deterministic (acute tissue effect) events happen with certainty, with the resulting health conditions occurring in every individual who received the same high dose. Stochastic (cancer induction and genetic) events are inherently random, with most individuals in a group failing to ever exhibit any causal negative health effects after exposure, while an indeterministic random minority do, often with the resulting subtle negative health effects being observable only after large detailed epidemiology studies.\n\nThe use of the sievert implies that only stochastic effects are being considered, and to avoid confusion deterministic effects are conventionally compared to values of absorbed dose expressed by the SI unit gray (Gy).\n\nStochastic effects are those that occur randomly, such as radiation-induced cancer. The consensus of nuclear regulators, governments and the UNSCEAR is that the incidence of cancers due to ionizing radiation can be modeled as increasing linearly with effective dose at a rate of 5.5% per sievert. This is known as the Linear no-threshold model (LNT model). Some commentators such as the French Academy of Sciences (2005, \"Dose-effect relationships and...\"Tubiana, M. and Aurengo, A. Académie des Sciences & Académie Nationale de Médecine. (2005) www.researchgate.net/publication/277289357) and Oxford University (Wade Allison, 2015, Nuclear is for Life, pp79–80, ) argue that this LNT model is now outdated and should be replaced with a threshold below which the body's natural cell processes repair damage and/or replace damaged cells. There is general agreement that the risk is much higher for infants and fetuses than adults, higher for the middle-aged than for seniors, and higher for women than for men, though there is no quantitative consensus about this.\n\nThe deterministic (acute tissue damage) effects that can lead to acute radiation syndrome only occur in the case of acute high doses (> ~0.1 Gy) and high dose rates (> ~0.1 Gy/h) and are conventionally not measured using the unit sievert, but use the unit gray (Gy).\nA model of deterministic risk would require different weighting factors (not yet established) than are used in the calculation of equivalent and effective dose.\n\nThe ICRP recommends a number of limits for dose uptake in table 8 of report 103. These limits are \"situational\", for planned, emergency and existing situations. Within these situations, limits are given for the following groups;\n\n\nFor occupational exposure, the limit is 50 mSv in a single year with a maximum of 100 mSv in a consecutive five-year period, and for the public to an average of 1 mSv (0.001 Sv) of effective dose per year, not including medical and occupational exposures.\n\nFor comparison, natural radiation levels inside the US capitol building are such that a human body would receive an additional dose rate of 0.85 mSv/a, close to the regulatory limit, because of the uranium content of the granite structure. According to the conservative ICRP model, someone who spent 20 years inside the capitol building would have an extra one in a thousand chance of getting cancer, over and above any other existing risk (calculated as: 20 a·0.85 mSv/a·0.001 Sv/mSv·5.5%/Sv = ~0.1%). However, that \"existing risk\" is much higher; an average American would have a 10% chance of getting cancer during this same 20-year period, even without any exposure to artificial radiation (see natural Epidemiology of cancer and cancer rates). These estimates are, however, unmindful of every living cell's natural repair mechanisms, evolved over a few billion years of exposure to environmental chemical and radiation threats that were higher in the past, and exaggerated by the evolution of oxygen metabolism.\n\nSignificant radiation doses are not frequently encountered in everyday life. The following examples can help illustrate relative magnitudes; these are meant to be examples only, not a comprehensive list of possible radiation doses. An \"acute dose\" is one that occurs over a short and finite period of time, while a \"chronic dose\" is a dose that continues for an extended period of time so that it is better described by a dose rate.\n\nAll conversions between hours and years have assumed continuous presence in a steady field, disregarding known fluctuations, intermittent exposure and radioactive decay. Converted values are shown in parentheses.\nNotes on examples:\nThe sievert has its origin in the röntgen equivalent man (rem) which was derived from CGS units. The International Commission on Radiation Units and Measurements (ICRU) promoted a switch to coherent SI units in the 1970s, and announced in 1976 that it planned to formulate a suitable unit for equivalent dose. The ICRP pre-empted the ICRU by introducing the sievert in 1977.\n\nThe sievert was adopted by the International Committee for Weights and Measures (CIPM) in 1980, five years after adopting the gray. The CIPM then issued an explanation in 1984, recommending when the sievert should be used as opposed to the gray. That explanation was updated in 2002 to bring it closer to the ICRP's definition of equivalent dose, which had changed in 1990. Specifically, the ICRP had introduced equivalent dose, renamed the quality factor (Q) to radiation weighting factor (W), and dropped another weighting factor 'N' in 1990. In 2002, the CIPM similarly dropped the weighting factor 'N' from their explanation but otherwise kept other old terminology and symbols. This explanation only appears in the appendix to the SI brochure and is not part of the definition of the sievert.\n\nFrequently used SI prefixes are the millisievert (1 mSv = 0.001 Sv) and microsievert (1 μSv = 0.000001 Sv) and commonly used units for time derivative or \"dose rate\" indications on instruments and warnings for radiological protection are μSv/h and mSv/h. Regulatory limits and chronic doses are often given in units of mSv/a or Sv/a, where they are understood to represent an average over the entire year. In many occupational scenarios, the hourly dose rate might fluctuate to levels thousands of times higher for a brief period of time, without infringing on the annual limits. The conversion from hours to years varies because of leap years and exposure schedules, but approximate conversions are:\n\nConversion from hourly rates to annual rates is further complicated by seasonal fluctuations in natural radiation, decay of artificial sources, and intermittent proximity between humans and sources. The ICRP once adopted fixed conversion for occupational exposure, although these have not appeared in recent documents:\n\nTherefore, for occupation exposures of that time period,\n\nThe following table shows radiation quantities in SI and non-SI units:\nAlthough the United States Nuclear Regulatory Commission permits the use of the units curie, rad, and rem alongside SI units, the European Union European units of measurement directives required that their use for \"public health ... purposes\" be phased out by 31 December 1985.\n\nAn older unit for the dose equivalent is the rem, still often used in the United States. One sievert is equal to 100 rem:\n\n\n"}
{"id": "23566604", "url": "https://en.wikipedia.org/wiki?curid=23566604", "title": "Squamous intraepithelial lesion", "text": "Squamous intraepithelial lesion\n\nA squamous intraepithelial lesion (SIL) is an abnormal growth of epithelial cells on the surface of the cervix, commonly called squamous cells. This condition can lead to cervical cancer, but can be diagnosed using a Pap smear or a colposcopy. It can be treated by using methods that remove the abnormal cells, allowing normal cells to grow in their place. In the Bethesda system, the cytology can be graded as LSIL (low-grade squamous intraepithelial lesion) or HSIL (high-grade squamous intraepithelial lesion).\n"}
{"id": "21282070", "url": "https://en.wikipedia.org/wiki?curid=21282070", "title": "Taste", "text": "Taste\n\nTaste, gustatory perception, or gustation is one of the five traditional senses that belongs to the gustatory system.\n\nTaste is the sensation produced when a substance in the mouth reacts chemically with taste receptor cells located on taste buds in the oral cavity, mostly on the tongue. Taste, along with smell (olfaction) and trigeminal nerve stimulation (registering texture, pain, and temperature), determines flavors of food and/or other substances. Humans have taste receptors on taste buds (gustatory calyculi) and other areas including the upper surface of the tongue and the epiglottis. The gustatory cortex is responsible for the perception of taste.\n\nThe tongue is covered with thousands of small bumps called papillae, which are visible to the naked eye. Within each papilla are hundreds of taste buds. The exception to this is the filiform papillae that do not contain taste buds. There are between 2000 and 5000 taste buds that are located on the back and front of the tongue. Others are located on the roof, sides and back of the mouth, and in the throat. Each taste bud contains 50 to 100 taste receptor cells.\n\nThe sensation of taste includes five established basic tastes: sweetness, sourness, saltiness, bitterness, and umami. Scientific experiments have demonstrated that these five tastes exist and are distinct from one another. Taste buds are able to distinguish between different tastes through detecting interaction with different molecules or ions. Sweet, savory, and bitter tastes are triggered by the binding of molecules to G protein-coupled receptors on the cell membranes of taste buds. Saltiness and sourness are perceived when alkali metal or hydrogen ions enter taste buds, respectively.\n\nThe basic tastes contribute only partially to the sensation and flavor of food in the mouth—other factors include smell, detected by the olfactory epithelium of the nose; texture, detected through a variety of mechanoreceptors, muscle nerves, etc.; temperature, detected by thermoreceptors; and \"coolness\" (such as of menthol) and \"hotness\" (pungency), through chemesthesis.\n\nAs taste senses both harmful and beneficial things, all basic tastes are classified as either aversive or appetitive, depending upon the effect the things they sense have on our bodies. Sweetness helps to identify energy-rich foods, while bitterness serves as a warning sign of poisons.\n\nAmong humans, taste perception begins to fade around 50 years of age because of loss of tongue papillae and a general decrease in saliva production. Humans can also have distortion of tastes through dysgeusia. Not all mammals share the same taste senses: some rodents can taste starch (which humans cannot), cats cannot taste sweetness, and several other carnivores including hyenas, dolphins, and sea lions, have lost the ability to sense up to four of their ancestral five taste senses.\n\nTaste in the gustatory system allows humans to distinguish between safe and harmful food, and to gauge foods’ nutritional value. Digestive enzymes in saliva begin to dissolve food into base chemicals that are washed over the papillae and detected as tastes by the taste buds. The tongue is covered with thousands of small bumps called papillae, which are visible to the naked eye. Within each papilla are hundreds of taste buds. The exception to this are the filiform papillae that do not contain taste buds. There are between 2000 and 5000 taste buds that are located on the back and front of the tongue. Others are located on the roof, sides and back of the mouth, and in the throat. Each taste bud contains 50 to 100 taste receptor cells.\n\nBitter foods are generally found unpleasant, while sour, salty, sweet, and umami tasting foods generally provide a pleasurable sensation. The five specific tastes received by taste receptors are saltiness, sweetness, bitterness, sourness, and \"savoriness\", often known by its Japanese term \"umami\" which translates to ‘delicious’. As of the early twentieth century, Western physiologists and psychologists believed there were four basic tastes: sweetness, sourness, saltiness, and bitterness. At that time, savoriness was not identified, but now a large number of authorities recognize it as the fifth taste.\n\nOne study found that both salt and sour taste mechanisms detect, in different ways, the presence of sodium chloride (salt) in the mouth, however, acids are also detected and perceived as sour. The detection of salt is important to many organisms, but specifically mammals, as it serves a critical role in ion and water homeostasis in the body. It is specifically needed in the mammalian kidney as an osmotically active compound which facilitates passive re-uptake of water into the blood. Because of this, salt elicits a pleasant taste in most humans.\n\nSour and salt tastes can be pleasant in small quantities, but in larger quantities become more and more unpleasant to taste. For sour taste this is presumably because the sour taste can signal under-ripe fruit, rotten meat, and other spoiled foods, which can be dangerous to the body because of bacteria which grow in such media. Additionally, sour taste signals acids, which can cause serious tissue damage.\n\nThe bitter taste is almost universally unpleasant to humans. This is because many nitrogenous organic molecules which have a pharmacological effect on humans taste bitter. These include caffeine, nicotine, and strychnine, which respectively compose the stimulant in coffee, addictive agent in cigarettes, and active compound in many pesticides. It appears that some psychological process allows humans to overcome their innate aversion to bitter taste, as caffeinated drinks are widely consumed and enjoyed around the world. Many common medicines have a bitter taste if chewed; the gustatory system apparently interprets these compounds as poisons. In this manner, the unpleasant reaction to the bitter taste is a last-line warning system before the compound is ingested and can do damage.\n\nSweet taste signals the presence of carbohydrates in solution. Since carbohydrates have a very high calorie count (saccharides have many bonds, therefore much energy), they are desirable to the human body, which evolved to seek out the highest calorie intake foods. They are used as direct energy (sugars) and storage of energy (glycogen). However, there are many non-carbohydrate molecules that trigger a sweet response, leading to the development of many artificial sweeteners, including saccharin, sucralose, and aspartame. It is still unclear how these substances activate the sweet receptors and what adaptational significance this has had.\n\nThe savory taste (known in Japanese as \"umami\") was identified by Japanese chemist Kikunae Ikeda of Tokyo Imperial University, which signals the presence of the amino acid L-glutamate, triggers a pleasurable response and thus encourages the intake of peptides and proteins. The amino acids in proteins are used in the body to build muscles and organs, transport molecules (hemoglobin), antibodies, and the organic catalysts known as enzymes. These are all critical molecules, and as such it is important to have a steady supply of amino acids, hence the pleasurable response to their presence in the mouth.\n\nIn Asian countries within the sphere of mainly Chinese and Indian cultural influence, pungency (piquancy or hotness) had traditionally been considered a sixth basic taste. In 2015, researchers suggested a new basic taste of fatty acids called fat taste, although oleogustus and pinguis have both been proposed as alternate terms.\n\nSweetness, usually regarded as a pleasurable sensation, is produced by the presence of sugars and a few other substances. Sweetness is often connected to aldehydes and ketones, which contain a carbonyl group. Sweetness is detected by a variety of G protein coupled receptors coupled to the G protein gustducin found on the taste buds. At least two different variants of the \"sweetness receptors\" must be activated for the brain to register sweetness. Compounds the brain senses as sweet are thus compounds that can bind with varying bond strength to two different sweetness receptors. These receptors are T1R2+3 (heterodimer) and T1R3 (homodimer), which account for all sweet sensing in humans and animals. Taste detection thresholds for sweet substances are rated relative to sucrose, which has an index of 1. The average human detection threshold for sucrose is 10 millimoles per liter. For lactose it is 30 millimoles per liter, with a sweetness index of 0.3, and 5-Nitro-2-propoxyaniline 0.002 millimoles per liter. “Natural” sweeteners such as saccharides activate the GPCR, which releases gustducin. The gustducin then activates the molecule adenylate cyclase, which catalyzes the production of the molecule cAMP, or adenosine 3', 5'-cyclic monophosphate. This molecule closes potassium ion channels, leading to depolarization and neurotransmitter release. Synthetic sweeteners such as saccharin activate different GPCRs and induce taste receptor cell depolarization by an alternate pathway.\n\nSourness is the taste that detects acidity. The sourness of substances is rated relative to dilute hydrochloric acid, which has a sourness index of 1. By comparison, tartaric acid has a sourness index of 0.7, citric acid an index of 0.46, and carbonic acid an index of 0.06.\n\nSour taste is detected by a small subset of cells that are distributed across all taste buds in the tongue. Sour taste cells can be identified by expression of the protein PKD2L1, although this gene is not required for sour responses. There is evidence that the protons that are abundant in sour substances can directly enter the sour taste cells through apically located ion channels. This transfer of positive charge into the cell can itself trigger an electrical response. It has also been proposed that weak acids such as acetic acid, which is not fully dissociated at physiological pH values, can penetrate taste cells and thereby elicit an electrical response. According to this mechanism, intracellular hydrogen ions inhibit potassium channels, which normally function to hyperpolarize the cell.\nBy a combination of direct intake of hydrogen ions (which itself depolarizes the cell) and the inhibition of the hyperpolarizing channel, sourness causes the taste cell to fire action potentials and release neurotransmitter.\n\nThe most common food group that contains naturally sour foods is fruit, such as lemon, grape, orange, tamarind, and sometimes melon. Wine also usually has a sour tinge to its flavor, and if not kept correctly, milk can spoil and develop a sour taste. Children in the US and UK show a greater enjoyment of sour flavors than adults, and sour candy is popular in North America including Cry Babies, Warheads, Lemon drops, Shock Tarts and sour versions of Skittles and Starburst. Many of these candies contain citric acid or malic acid.\n\nThe simplest receptor found in the mouth is the sodium chloride (salt) receptor. Saltiness is a taste produced primarily by the presence of sodium ions. Other ions of the alkali metals group also taste salty, but the further from sodium, the less salty the sensation is. A sodium channel in the taste cell wall allows sodium cations to enter the cell. This on its own depolarizes the cell, and opens voltage-dependent calcium channels, flooding the cell with positive calcium ions and leading to neurotransmitter release. This sodium channel is known as an epithelial sodium channel (ENaC) and is composed of three subunits. An ENaC can be blocked by the drug amiloride in many mammals, especially rats. The sensitivity of the salt taste to amiloride in humans, however, is much less pronounced, leading to conjecture that there may be additional receptor proteins besides ENaC to be discovered.\n\nThe size of lithium and potassium ions most closely resemble those of sodium, and thus the saltiness is most similar. In contrast, rubidium and caesium ions are far larger, so their salty taste differs accordingly. The saltiness of substances is rated relative to sodium chloride (NaCl), which has an index of 1. Potassium, as potassium chloride (KCl), is the principal ingredient in salt substitutes and has a saltiness index of 0.6.\n\nOther monovalent cations, e.g. ammonium (NH), and divalent cations of the alkali earth metal group of the periodic table, e.g. calcium (Ca), ions generally elicit a bitter rather than a salty taste even though they, too, can pass directly through ion channels in the tongue, generating an action potential. But the chloride of calcium is saltier and less bitter than potassium chloride, and is commonly used in pickle brine instead of KCl.\n\nBitterness is the most sensitive of the tastes, and many perceive it as unpleasant, sharp, or disagreeable, but it is sometimes desirable and intentionally added via various bittering agents. Common bitter foods and beverages include coffee, unsweetened cocoa, South American mate, bitter gourd, olives, citrus peel, many plants in the family Brassicaceae, dandelion greens, wild chicory, and escarole. The ethanol in alcoholic beverages tastes bitter, as do the additional bitter ingredients found in some alcoholic beverages including hops in beer and orange in bitters. Quinine is also known for its bitter taste and is found in tonic water.\n\nBitterness is of interest to those who study evolution, as well as various health researchers since a large number of natural bitter compounds are known to be toxic. The ability to detect bitter-tasting, toxic compounds at low thresholds is considered to provide an important protective function. Plant leaves often contain toxic compounds, yet even amongst leaf-eating primates, there is a tendency to prefer immature leaves, which tend to be higher in protein and lower in fiber and poisons than mature leaves. Amongst humans, various food processing techniques are used worldwide to detoxify otherwise inedible foods and make them palatable. Furthermore, the use of fire, changes in diet, and avoidance of toxins has led to neutral evolution in human bitter sensitivity. This has allowed several loss of function mutations that has led to a reduced sensory capacity towards bitterness in humans when compared to other species.\n\nThe threshold for stimulation of bitter taste by quinine averages a concentration of 8 μM (8 micromolar). The taste thresholds of other bitter substances are rated relative to quinine, which is thus given a reference index of 1. For example, brucine has an index of 11, is thus perceived as intensely more bitter than quinine, and is detected at a much lower solution threshold. The most bitter substance known is the synthetic chemical denatonium, which has an index of 1,000. It is used as an aversive agent (a bitterant) that is added to toxic substances to prevent accidental ingestion. It was discovered in 1958 during research on lignocaine, a local anesthetic, by MacFarlan Smith of Gorgie, Edinburgh, Scotland.\n\nResearch has shown that TAS2Rs (taste receptors, type 2, also known as T2Rs) such as TAS2R38 coupled to the G protein gustducin are responsible for the human ability to taste bitter substances. They are identified not only by their ability to taste for certain \"bitter\" ligands, but also by the morphology of the receptor itself (surface bound, monomeric). The TAS2R family in humans is thought to comprise about 25 different taste receptors, some of which can recognize a wide variety of bitter-tasting compounds. Over 670 bitter-tasting compounds have been identified, on a bitter database, of which over 200 have been assigned to one or more specific receptors. Recently it is speculated that the selective constraints on the TAS2R family have been weakened due to the relatively high rate of mutation and pseudogenization. Researchers use two synthetic substances, phenylthiocarbamide (PTC) and 6-n-propylthiouracil (PROP) to study the genetics of bitter perception. These two substances taste bitter to some people, but are virtually tasteless to others. Among the tasters, some are so-called \"supertasters\" to whom PTC and PROP are extremely bitter. The variation in sensitivity is determined by two common alleles at the TAS2R38 locus. This genetic variation in the ability to taste a substance has been a source of great interest to those who study genetics.\n\nGustducin is made of three subunits. When it is activated by the GPCR, its subunits break apart and activate phosphodiesterase, a nearby enzyme, which in turn converts a precursor within the cell into a secondary messenger, which closes potassium ion channels. Also, this secondary messenger can stimulate the endoplasmic reticulum to release Ca2+ which contributes to depolarization. This leads to a build-up of potassium ions in the cell, depolarization, and neurotransmitter release. It is also possible for some bitter tastants to interact directly with the G protein, because of a structural similarity to the relevant GPCR.\n\nSavory, or savoriness is an appetitive taste and is occasionally described by its Japanese name, umami or meaty. It can be tasted in cheese and soy sauce,\nand is also found in many other fermented and aged foods. This taste is also present in tomatoes, grains, and beans.\n\nA loanword from Japanese meaning \"good flavor\" or \"good taste\", is considered fundamental to many Eastern cuisines; and other cuisines have long operated under principles that sought to combine foods to produce savory flavors, such as in the emphasis on veal stock by Auguste Escoffier, the pre-eminent chef of 19th century French cuisine, and in the Romans' deliberate use of fermented fish sauce. However, it was only recently recognized in modern science as a basic taste; well after the other basic tastes have been recognized by scientists, in part due to their correspondence with the four tastes of ancient Greek philosophy. Umami, or “scrumptiousness”, was first studied with the scientific method and identified by Kikunae Ikeda, who began to analyze kombu in 1907, attempting to isolate its dashi taste. He isolated a substance he called \"ajinomoto\", Japanese for “at the origin of flavor”. His Ajinomoto Co., Inc. currently employs over 32,000 people. \"Ajinomoto\" was later identified as the chemical monosodium glutamate (MSG), and increasingly used independently as a food additive, it is a sodium salt that produces a strong savory taste, especially combined with foods rich in nucleotides such as meats, fish, nuts, and mushrooms.\n\nSome savory taste buds respond specifically to glutamate in the same way that \"sweet\" ones respond to sugar. Glutamate binds to a variant of G protein coupled glutamate receptors. It is thought that the amino acid L-glutamate bonds to a type of GPCR known as a metabotropic glutamate receptor (mGluR4). This causes the G-protein complex to activate a secondary receptor, which ultimately leads to neurotransmitter release. The intermediate steps are not known.\n(See TAS1R1 and TAS1R3 pages for a further explanation of the amino-acid taste receptor).\n\nMeasuring the degree to which a substance presents one basic taste can be achieved in a subjective way by comparing its taste to a reference substance.\n\nSweetness is subjectively measured by comparing the threshold values, or level at which the presence of a dilute substance can be detected by a human taster, of different sweet substances. Substances are usually measured relative to sucrose, which is usually given an arbitrary index of 1 or 100. Fructose is about 1.4 times sweeter than sucrose; glucose, a sugar found in honey and vegetables, is about three-quarters as sweet; and lactose, a milk sugar, is one-half as sweet.\n\nThe sourness of a substance can be rated by comparing it to very dilute hydrochloric acid (HCl).\n\nRelative saltiness can be rated by comparison to a dilute salt solution.\n\nQuinine, a bitter medicinal found in tonic water, can be used to subjectively rate the bitterness of a substance. Units of dilute quinine hydrochloride (1 g in 2000 mL of water) can be used to measure the threshold bitterness concentration, the level at which the presence of a dilute bitter substance can be detected by a human taster, of other compounds. More formal chemical analysis, while possible, is difficult.\n\nIn the human body a stimulus refers to a form of energy which elicits a physiological or psychological action or response. Sensory receptors are the structures in the body which change the stimulus from one form of energy to another. This can mean changing the presence of a chemical, sound wave, source of heat, or touch to the skin into an electrical action potential which can be understood by the brain, the body’s control center. Sensory receptors are modified ends of sensory neurons; modified to deal with specific types of stimulus, thus there are many different types of sensory receptors in the body. The neuron is the primary component of the nervous system, which transmits messages from sensory receptors all over the body.\n\nTaste is a form of chemoreception which occurs in the specialised taste receptors in the mouth. To date, there are five different types of taste receptors known: salt, sweet, sour, bitter, and umami. Each receptor has a different manner of sensory transduction: that is, of detecting the presence of a certain compound and starting an action potential which alerts the brain. It is a matter of debate whether each taste cell is tuned to one specific tastant or to several; Smith and Margolskee claim that \"gustatory neurons typically respond to more than one kind of stimulus, [a]lthough each neuron responds most strongly to one tastant\". Researchers believe that the brain interprets complex tastes by examining patterns from a large set of neuron responses. This enables the body to make \"keep or spit out\" decisions when there is more than one tastant present. \"No single neuron type alone is capable of discriminating among stimuli or different qualities, because a given cell can respond the same way to disparate stimuli.\" As well, serotonin is thought to act as an intermediary hormone which communicates with taste cells within a taste bud, mediating the signals being sent to the brain. Receptor molecules are found on the top of microvilli of the taste cells.\n\nSweetness is produced by the presence of sugars, some proteins, and a few other substances. It is often connected to aldehydes and ketones, which contain a carbonyl group. Sweetness is detected by a variety of G protein-coupled receptors coupled to a G protein that acts as an intermediary in the communication between taste bud and brain, gustducin. These receptors are T1R2+3 (heterodimer) and T1R3 (homodimer), which account for sweet sensing in humans and other animals.\n\nSaltiness is a taste produced best by the presence of cations (such as , or ) and is directly detected by cation influx into glial like cells via leak channels causing depolarisation of the cell.\n\nOther monovalent cations, e.g., ammonium, , and divalent cations of the alkali earth metal group of the periodic table, e.g., calcium, , ions, in general, elicit a bitter rather than a salty taste even though they, too, can pass directly through ion channels in the tongue.\n\nSourness is acidity, and, like salt, it is a taste sensed using ion channels. Undissociated acid diffuses across the plasma membrane of a presynaptic cell, where it dissociates in accordance with Le Chatelier's principle. The protons that are released then block potassium channels, which depolarise the cell and cause calcium influx. In addition, the taste receptor PKD2L1 has been found to be involved in tasting sour.\n\nResearch has shown that TAS2Rs (taste receptors, type 2, also known as T2Rs) such as TAS2R38 are responsible for the human ability to taste bitter substances. They are identified not only by their ability to taste certain bitter ligands, but also by the morphology of the receptor itself (surface bound, monomeric).\n\nThe amino acid glutamic acid is responsible for savoriness, but some nucleotides (inosinic acid and guanylic acid) can act as complements, enhancing the taste.\n\nGlutamic acid binds to a variant of the G protein-coupled receptor, producing a savory taste.\n\nThe tongue can also feel other sensations not generally included in the basic tastes. These are largely detected by the somatosensory system. In humans, the sense of taste is conveyed via three of the twelve cranial nerves. The facial nerve (VII) carries taste sensations from the anterior two thirds of the tongue, the glossopharyngeal nerve (IX) carries taste sensations from the posterior one third of the tongue while a branch of the vagus nerve (X) carries some taste sensations from the back of the oral cavity.\n\nThe trigeminal nerve (cranial nerve V) provides information concerning the general texture of food as well as the taste-related sensations of peppery or hot (from spices).\n\nSubstances such as ethanol and capsaicin cause a burning sensation by inducing a trigeminal nerve reaction together with normal taste reception. The sensation of heat is caused by the food's activating nerves that express TRPV1 and TRPA1 receptors. Some such plant-derived compounds that provide this sensation are capsaicin from chili peppers, piperine from black pepper, gingerol from ginger root and allyl isothiocyanate from horseradish. The piquant (\"hot\" or \"spicy\") sensation provided by such foods and spices plays an important role in a diverse range of cuisines across the world—especially in equatorial and sub-tropical climates, such as Ethiopian, Peruvian, Hungarian, Indian, Korean, Indonesian, Lao, Malaysian, Mexican, New Mexican, Singaporean, Southwest Chinese (including Szechuan cuisine), Vietnamese, and Thai cuisines.\n\nThis particular sensation, called chemesthesis, is not a taste in the technical sense, because the sensation does not arise from taste buds, and a different set of nerve fibers carry it to the brain. Foods like chili peppers activate nerve fibers directly; the sensation interpreted as \"hot\" results from the stimulation of somatosensory (pain/temperature) fibers on the tongue. Many parts of the body with exposed membranes but no taste sensors (such as the nasal cavity, under the fingernails, surface of the eye or a wound) produce a similar sensation of heat when exposed to hotness agents. Asian countries within the sphere of, mainly, Chinese, Indian, and Japanese cultural influence, often wrote of pungency as a fifth or sixth taste.\n\nSome substances activate cold trigeminal receptors even when not at low temperatures. This \"fresh\" or \"minty\" sensation can be tasted in peppermint, spearmint, menthol, ethanol, and camphor. Caused by activation of the same mechanism that signals cold, TRPM8 ion channels on nerve cells, unlike the actual change in temperature described for sugar substitutes, this coolness is only a perceived phenomenon.\n\nBoth Chinese and Batak Toba cooking include the idea of 麻 (\"má\" or \"mati rasa\"), a tingling numbness caused by spices such as Sichuan pepper. The cuisines of Sichuan province in China and of the Indonesian province of North Sumatra often combine this with chili pepper to produce a 麻辣 \"málà\", \"numbing-and-hot\", or \"mati rasa\" flavor. These sensations although not taste fall into a category of Chemesthesis.\n\nSome foods, such as unripe fruits, contain tannins or calcium oxalate that cause an astringent or puckering sensation of the mucous membrane of the mouth. Examples include tea, red wine, rhubarb, some fruits of the genus \"Syzygium\", and unripe persimmons and bananas.\n\nLess exact terms for the astringent sensation are \"dry\", \"rough\", \"harsh\" (especially for wine), \"tart\" (normally referring to sourness), \"rubbery\", \"hard\" or \"styptic\".\n\nWhen referring to wine, \"dry\" is the opposite of \"sweet,\" and does not refer to astringency. Wines that contain tannins and so cause an astringent sensation are not necessarily classified as \"dry\", and \"dry\" wines are not necessarily astringent.\n\nIn the Indian Ayurvedic tradition, one of the six tastes is astringency (\"kasaaya\"). In Sinhala and Sri Lankan English it is referred to as \"kahata\". in Tamil it is referred to as thuvarppu.\n\nA metallic taste may be caused by food and drink, certain medicines or amalgam dental fillings. It is generally considered an off flavor when present in food and drink. A metallic taste may be caused by galvanic reactions in the mouth. In the case where it is caused by dental work, the dissimilar metals used may produce a measurable current. Some artificial sweeteners are perceived to have a metallic taste, which is detected by the TRPV1 receptors. Many people consider blood to have a metallic taste. A metallic taste in the mouth is also a symptom of various medical conditions, in which case it may be classified under the symptoms dysgeusia or parageusia, referring to distortions of the sense of taste, and can be caused by various kinds of medication, including saquinavir and zonisamide, and occupational hazards, such as working with pesticides.\n\nThe distinctive taste of chalk has been identified as the calcium component of that substance. In 2008, geneticists discovered a CaSR calcium receptor on the tongues of mice. The CaSR receptor is commonly found in the gastrointestinal tract, kidneys, and brain. Along with the \"sweet\" T1R3 receptor, the CaSR receptor can detect calcium as a taste. Whether closely related genes in mice and humans means the phenomenon exists in humans as well is unknown.\n\nRecent research reveals a potential taste receptor called the CD36 receptor. CD36 was targeted as a possible lipid taste receptor because it binds to fat molecules (more specifically, long-chain fatty acids), and it has been localized to taste bud cells (specifically, the circumvallate and foliate papillae). There is a debate over whether we can truly taste fats, and supporters of our ability to taste free fatty acids (FFAs) have based the argument on a few main points: there is an evolutionary advantage to oral fat detection; a potential fat receptor has been located on taste bud cells; fatty acids evoke specific responses that activate gustatory neurons, similar to other currently accepted tastes; and, there is a physiological response to the presence of oral fat. Although CD36 has been studied primarily in mice, research examining human subjects' ability to taste fats found that those with high levels of CD36 expression were more sensitive to tasting fat than were those with low levels of CD36 expression; this study points to a clear association between CD36 receptor quantity and the ability to taste fat.\n\nOther possible fat taste receptors have been identified. G protein-coupled receptors GPR120 and GPR40 have been linked to fat taste, because their absence resulted in reduced preference to two types of fatty acid (linoleic acid and oleic acid), as well as decreased neuronal response to oral fatty acids.\n\nMonovalent cation channel TRPM5 has been implicated in fat taste as well, but it is thought to be involved primarily in downstream processing of the taste rather than primary reception, as it is with other tastes such as bitter, sweet, and savory.\n\nProposed alternate names to fat taste include oleogustus and pinguis, although these terms are not widely accepted. The main form of fat that is commonly ingested is triglycerides, which are composed of three fatty acids bound together. In this state, triglycerides are able to give fatty foods unique textures that are often described as creaminess. But this texture is not an actual taste. It is only during ingestion that the fatty acids that make up triglycerides are hydrolysed into fatty acids via lipases. The taste is commonly related to other, more negative, tastes such as bitter and sour due to how unpleasant the taste is for humans. Richard Mattes, a co-author of the study, explained that low concentrations of these fatty acids can create an overall better flavor in a food, much like how small uses of bitterness can make certain foods more rounded. However, a high concentration of fatty acids in certain foods is generally considered inedible. To demonstrate that individuals can distinguish fat taste from other tastes, the researchers separated volunteers into groups and had them try samples that also contained the other basic tastes. Volunteers were able to separate the taste of fatty acids into their own category, with some overlap with savory samples, which the researchers hypothesized was due to poor familiarity with both. The researchers note that the usual \"creaminess and viscosity we associate with fatty foods is largely due to triglycerides\", unrelated to the taste; while the actual taste of fatty acids is not pleasant. Mattes described the taste as \"more of a warning system\" that a certain food should not be eaten.\n\nThere are few regularly consumed foods rich in fat taste, due to the negative flavor that is evoked in large quantities. Foods whose flavor to which fat taste makes a small contribution include olive oil and fresh butter, along with various kinds of vegetable and nut oils.\n\nSome Japanese researchers refer to the \"kokumi\" of foods. This sensation has also been described as mouthfulness, and appears to be related to a number of , which activate a calcium-sensing receptor which is also sensitive to glutathione.\n\nTemperature can be an essential element of the taste experience. Food and drink that—in a given culture—is traditionally served hot is often considered distasteful if cold, and vice versa. For example, alcoholic beverages, with a few exceptions, are usually thought best when served at room temperature or chilled to varying degrees, but soups—again, with exceptions—are usually only eaten hot. A cultural example are soft drinks. In North America it is almost always preferred cold, regardless of season.\n\nA 2016 study suggested that humans can taste starch (specifically, a glucose oligomer) independently of other tastes such as sweetness. However, no specific chemical receptor has yet been found for this taste.\n\nThe glossopharyngeal nerve innervates a third of the tongue including the circumvallate papillae. The facial nerve innervates the other two thirds of the tongue and the cheek via the chorda tympani.\n\nThe pterygopalatine ganglia are ganglia (one on each side) of the soft palate. The greater petrosal, lesser palatine and zygomatic nerves all synapse here. The greater petrosal, carries soft palate taste signals to the facial nerve. The lesser palatine sends signals to the nasal cavity; which is why spicy foods cause nasal drip. The zygomatic sends signals to the lacrimal nerve that activate the lacrimal gland; which is the reason that spicy foods can cause tears. Both the lesser palatine and the zygomatic are maxillary nerves (from the trigeminal nerve).\n\nThe special visceral afferents of the vagus nerve carry taste from the epiglottal region of the tongue.\n\nThe lingual nerve (trigeminal, not shown in diagram) is deeply interconnected with chorda tympani in that it provides all other sensory info from the ⅔ of the tongue. This info is processed separately (nearby) in rostal lateral subdivision of nucleus of the solitary tract (NST).\n\nNST receives input from the amygdala (regulates oculomotor nuclei output), bed nuclei of stria terminalis, hypothalamus, and prefrontal cortex. NST is the topographical map that processes gustatory and sensory (temp, texture, etc.) info.\n\nReticular formation (includes Raphe nuclei responsible for serotonin production) is signaled to release serotonin during and after a meal to suppress appetite. Similarly, salivary nuclei are signaled to decrease saliva secretion.\n\nHypoglossal and thalamic connections aid in oral-related movements.\n\nHypothalamus connections hormonally regulate hunger and the digestive system.\n\nSubstantia innominata connects the thalamus, temporal lobe, and insula.\n\nEdinger-Westphal nucleus reacts to taste stimuli by dilating and constricting the pupils.\n\nSpinal ganglion are involved in movement.\n\nThe frontal operculum is speculated to be the memory and association hub for taste.\n\nThe insula cortex aids in swallowing and gastric motility.\n\nTaste can be objective in terms of the five tastes (sweet, salt, sour, bitter, and savory) but it can also be subjective in terms of what we deem \"good\" and \"bad.\" Taste is \"subjective, objective, and qualitative\". In terms of it being a philosophical concept, taste is hard to define because it is essentially subjective when pertaining to the personal preferences of individuals i.e. \"'de gustibus non est disputandum' (there is no disputing taste)\". We cannot tell someone they do not \"think\" something tastes good because we do not agree, and vice versa. In order to evaluate taste in this context, we must explore all the ways in which taste can be defined. According to Alan Weiss, taste fulfills the purpose of six functions: taste is the tool in which we use to define flavor; it is also flavor and how we categorize flavor (sweet or salty); it is the preference, we as the tastemakers, place on specific flavors and our demand for those flavors; it is whether we choose to like or dislike a certain taste and therefore allow it into our general society of acceptable tastes or exile it; it is the value in which we place on certain taste (one might believe one's taste in Bach or Rothko earns one capital); and lastly, with good judgement comes good taste and therefore, one with expressively good taste are expected to have good judgement, just as those in bad taste are expected to be in bad judgement \n\nA supertaster is a person whose sense of taste is significantly more sensitive than average. The cause of this heightened response is likely, at least in part, due to an increased number of fungiform papillae. Studies have shown that supertasters require less fat and sugar in their food to get the same satisfying effects. However, contrary to what one might think, these people actually tend to consume more salt than the average person. This is due to their heightened sense of the taste of bitterness, and the presence of salt drowns out the taste of bitterness. (This also explains why supertasters prefer salted cheddar cheese over non-salted.)\n\nAftertastes arise after food has been swallowed. An aftertaste can differ from the food it follows. Medicines and tablets may also have a lingering aftertaste, as they can contain certain artificial flavor compounds, such as aspartame (artificial sweetener).\n\nAn acquired taste often refers to an appreciation for a food or beverage that is unlikely to be enjoyed by a person who has not had substantial exposure to it, usually because of some unfamiliar aspect of the food or beverage, including bitterness, a strong or strange odor, taste, or appearance.\n\nPatients with Addison's disease, pituitary insufficiency, or cystic fibrosis sometimes have a hyper-sensitivity to the five primary tastes.\n\n\nIn the West, Aristotle postulated in c. 350 BCE that the two most basic tastes were sweet and bitter. He was one of the first to develop a list of basic tastes.\n\nAyurveda, an ancient Indian healing science, has its own tradition of basic tastes, comprising sweet, salty, sour, pungent, bitter & astringent.\n\nThe Ancient Chinese regarded spiciness as a basic taste.\n\nThe receptors for the basic tastes of bitter, sweet and savory have been identified. They are G protein-coupled receptors. The cells that detect sourness have been identified as a subpopulation that express the protein PKD2L1. The responses are mediated by an influx of protons into the cells but the receptor for sour is still unknown. The receptor for amiloride-sensitive attractive salty taste in mice has been shown to be a sodium channel.\nThere is some evidence for a sixth taste that senses fatty substances.\n\nIn 2010, researchers found bitter taste receptors in lung tissue, which cause airways to relax when a bitter substance is encountered. They believe this mechanism is evolutionarily adaptive because it helps clear lung infections, but could also be exploited to treat asthma and chronic obstructive pulmonary disease.\n\n<div col||20em|small=yes>\n<div col end>\n\na. It has been known for some time that these categories may not be comprehensive. In Guyton's 1976 edition of \"Textbook of Medical Physiology\", he wrote:On the basis of physiologic studies, there are generally believed to be at least four \"primary\" sensations of taste: \"sour\", \"salty\", \"sweet,\" and \"bitter\". Yet we know that a person can perceive literally hundreds of different tastes. These are all supposed to be combinations of the four primary sensations...However, there might be other less conspicuous classes or subclasses of primary sensations\",\n\nb. Some variation in values is not uncommon between various studies. Such variations may arise from a range of methodological variables, from sampling to analysis and interpretation. In fact there is a \"plethora of methods\" Indeed, the taste index of 1, assigned to reference substances such as sucrose (for sweetness), hydrochloric acid (for sourness), quinine (for bitterness), and sodium chloride (for saltiness), is itself arbitrary for practical purposes.\n\nSome values, such as those for maltose and glucose, vary little. Others, such as aspartame and sodium saccharin, have much larger variation. Regardless of variation, the perceived intensity of substances relative to each reference substance remains consistent for taste ranking purposes. The indices table for McLaughlin & Margolskee (1994) for example, is essentially the same as that of Svrivastava & Rastogi (2003), Guyton & Hall (2006), and Joesten \"et al.\" (2007). The rankings are all the same, with any differences, where they exist, being in the values assigned from the studies from which they derive.\n\nAs for the assignment of 1 or 100 to the index substances, this makes no difference to the rankings themselves, only to whether the values are displayed as whole numbers or decimal points. Glucose remains about three-quarters as sweet as sucrose whether displayed as 75 or 0.75.\n\n\n"}
{"id": "17475776", "url": "https://en.wikipedia.org/wiki?curid=17475776", "title": "The Heart Truth", "text": "The Heart Truth\n\nThe Heart Truth is a campaign meant to raise awareness of the risk of heart disease in women. The campaign is sponsored in the United States by the National Heart, Lung, and Blood Institute, an organization of the United States Department of Health and Human Services; a similar campaign is promoted in Canada by the Heart and Stroke Foundation of Canada. It focuses mainly on educating women aged forty to sixty, as that is the time when the risk of heart disease begins to increase.\n\nThe campaign began in March 2001 on recommendation from over seventy experts on the health of women. The research stressed the need to communicate to women about the risk of heart disease, and endorsed The Heart Truth as a means of doing so.\n\nThe logo of the campaign is a red dress. It came into being as a way to attract attention to the Heart Truth, and eliminate perceptions that heart disease is an issue only for men. The dress reminds women to focus on their \"outerselves\", as well as their \"innerselves\", especially heart health.\n\nThe campaign has also conjured a National Wear Red Day, meant to take place on the first Friday of February annually.\n\nThe Heart Truth has joined with the United States Federal Government and fashion industries, in an attempt to appeal to female audiences. Red dresses have been displayed across the country, primarily at New York's Fashion Week. The first Red Dress Collection Fashion Week took place in 2003 when nineteen designers, including Vera Wang, Oscar de la Renta, and Carmen Marc Valvo contributed dresses that were displayed in the Byrant Park Tents. Many fashion shows have been put on in recent years during the Fashion Week festivities; many famous celebrities have participated in walking the aisle, including Jenna Fischer, Sheryl Crow, Natalie Morales, Kelly Ripa, Deborah Harry, Venus Williams, Angela Bassett, Rachael Ray, Valerie Bertinelli, Christie Brinkley, Thalía, Vanessa L. Williams, Raven-Symoné, Allison Janney, Sara Ramirez, Billie Jean King, Katie Couric, Sarah, Duchess of York, Lindsay Lohan, LeAnn Rimes, Christina Milian, Fergie, Jordin Sparks, Ashanti, Hilary Duff, Mary Lynn Rajskub, Rose McGowan and Eartha Kitt.\n\nLaureen Harper, the Wife of Canadian Prime Minister Stephen Harper has been a great supporter and has served as guest of honour at the event at Nathan Phillips Square in Toronto, Ontario for many consecutive years.\n\nFormer First Lady Laura Bush has been the ambassador for the Heart Truth since 2003. She has led the federal government in giving women more information relating to heart disease. Bush has coordinated many events relating to the Heart Truth, including a White House ceremony in 2004, the Kennedy Center exhibit, the Reagan Library exhibit, and has participated in all Fashion Week events dating to 2003.\n\nA signature component of Mrs. Bush's involvement is her communication with women at hospital events featuring those living with heart disease. She promotes the campaign through various media interviews as well.\n\nIn May 2005, the Heart Truth constructed a special exhibition at the John F. Kennedy Center for the Performing Arts in Washington, D.C., known as the First Ladies Red Dress Collection. The collection featured seven red dresses worn by America's first ladies Lady Bird Johnson, Betty Ford, Rosalynn Carter, Nancy Reagan, Barbara Bush, Hillary Clinton and Laura Bush. The exhibit was unveiled by Laura Bush, in the presence of many Congressional spouses and Cabinet secretaries.\n\nIn February 2007, the Heart Truth moved that exhibit to the Ronald Reagan Presidential Library and Museum in Simi Valley, California. There, the exhibit was opened by former First Lady Nancy Reagan along with television personality Larry King and Laura Bush. A conference was held at the library with leaders of the heart disease awareness movement as well as Bush and Reagan.\n\nIn February 2013, the Heart Truth presented a fashion show at Manhattan's Hammerstein Ballroom. Celebrities who walked the runway included Minka Kelly, Soledad O'Brien, Wendy Williams, Brenda Strong, Kris Jenner, Jamie Chung, Toni Braxton, Kelly Osbourne and others.\n\n"}
{"id": "22145250", "url": "https://en.wikipedia.org/wiki?curid=22145250", "title": "Tobacco control", "text": "Tobacco control\n\nTobacco control is a field of international public health science, policy and practice dedicated to addressing tobacco use and thereby reducing the morbidity and mortality it causes. Tobacco control is a priority area for the World Health Organization (WHO), through the Framework Convention on Tobacco Control. References to a tobacco control movement may have either positive or negative connotations, both briefly covered here.\n\nThe tobacco control field comprises the activity of disparate health, policy and legal research and reform advocacy bodies across the world. These took time to coalesce into a sufficiently organised coalition to advance such measures as the World Health Organization Framework Convention on Tobacco Control, and the first article of the first edition of the \"Tobacco Control\" journal suggested that developing as a diffusely organised movement was indeed necessary in order to bring about effective action to address the health effects of tobacco use.\n\nThe tobacco control movement has also been referred to as an \"anti-smoking movement\" by some who disagree with the movement, as documented in internal tobacco industry memoranda.\n\nThe first attempts to respond to the health consequences to tobacco use followed soon after the introduction of tobacco to Europe. Pope Urban VII's thirteen-day papal reign included the world's first known tobacco use restrictions in 1590 when he threatened to excommunicate anyone who \"took tobacco in the porchway of or inside a church, whether it be by chewing it, smoking it with a pipe or sniffing it in powdered form through the nose\". The earliest citywide European smoking restrictions were enacted in Bavaria, Kursachsen, and certain parts of Austria in the late 17th century.\n\nIn Britain, the still-new habit of smoking met royal opposition in 1604, when King James I wrote \"A Counterblaste to Tobacco\", describing smoking as: \"A custome loathsome to the eye, hateful to the nose, harmeful to the brain, dangerous to the lungs, and in the black stinking fume thereof, nearest resembling the horrible Stigian smoke of the pit that is bottomeless.\" His commentary was accompanied by a doctor of the same period, writing under the pseudonym \"Philaretes\", who as well as explaining tobacco's harmful effects under the system of the four humours ascribed an infernal motive to its introduction, explaining his dislike of tobacco as grounded upon eight 'principal reasons and arguments' (in their original spelling):\n\nLater in the seventeenth century, Sir Francis Bacon identified the addictive consequences of tobacco use, observing that it \"is growing greatly and conquers men with a certain secret pleasure, so that those who have once become accustomed thereto can later hardly be restrained therefrom\".\n\nSmoking was forbidden in Berlin in 1723, in Königsberg in 1742, and in Stettin in 1744. These restrictions were repealed in the revolutions of 1848. In 1930s Germany, scientific research for the first time revealed a connection between lung cancer and smoking, so the use of cigarettes and smoking was strongly discouraged by a heavy government sponsored anti-smoking campaign.\n\nAfter the Second World War, the German research was effectively silenced due to perceived associations with Nazism. However, the work of Richard Doll in the UK, who again identified the causal link between smoking and lung cancer in 1952, brought this topic back to attention. Partial controls and regulatory measures eventually followed in much of the developed world, including partial advertising bans, minimum age of sale requirements, and basic health warnings on tobacco packaging. However, smoking prevalence and associated ill health continued to rise in the developed world in the first three decades following Richard Doll's discovery, with governments sometimes reluctant to curtail a habit seen as popular as a result - and increasingly organised disinformation efforts by the tobacco industry and their proxies (covered in more detail below). Realisation dawned gradually that the health effects of smoking and tobacco use were susceptible only to a multi-pronged policy response which combined positive health messages with medical assistance to cease tobacco use and effective marketing restrictions, as initially indicated in a 1962 overview by the British Royal College of Physicians and the .\n\nThe 1964 report of the Advisory Committee to the Surgeon General represented a landmark document that included an objective synthesis of the evidence of the health consequences of smoking according to causal criteria. The report concluded that cigarette smoking was a cause of lung cancer in men and sufficient in scope that “remedial action” was warranted at the societal level. The Surgeon General report process is an enduring example of evidence-based public health in practice.\n\nThe concept of multi-pronged and therefore 'comprehensive' tobacco control arose through academic advances (e.g. the dedicated Tobacco Control journal), not-for-profit advocacy groups such as Action on Smoking and Health and government policy initiatives. Progress was initially notable at a state or national level, particularly the pioneering smoke-free public places legislation introduced in New York City in 2002 and the Republic of Ireland in 2004, and the UK efforts to encapsulate the crucial elements of tobacco control activity in the 2004 'six-strand approach' (to deliver upon the joined-up approach set out in the white paper 'Smoking Kills' ) and its local equivalent, the 'seven hexagons of tobacco control'. This broadly organised set of health research and policy development bodies then formed the Framework Convention Alliance to negotiate and support the first international public health treaty, the World Health Organization Framework Convention on Tobacco Control, or FCTC for short.\n\nThe FCTC compels signatories to advance activity on the full range of tobacco control fronts, including limiting interactions between legislators and the tobacco industry, imposing taxes upon tobacco products and carrying out demand reduction, protecting people from exposure to second-hand smoke in indoor workplaces and public places through smoking bans, regulating and disclosing the contents and emissions of tobacco products, posting highly visible health warnings upon tobacco packaging, removing deceptive labelling (e.g. 'light' or 'mild'), improving public awareness of the consequences of smoking, prohibiting all tobacco advertising, provision of cessation programmes, effective counter-measures to smuggling of tobacco products, restriction of sales to minors and relevant research and information-sharing among the signatories.\n\nWHO subsequently produced an internationally-applicable and now widely recognised summary of the essential elements of tobacco control strategy, publicised as the mnemonic MPOWER tobacco control strategy. The six components are:\n\nIn 2003, India passed the Cigarettes and Other Tobacco Products (Prohibition of Advertisement and Regulation of Trade and Commerce, Production, Supply and Distribution) Act, 2003 restricted advertisement of tobacco products, banning smoking in public places and other regulation on trade of tobacco products. In 2010, Bhutan, passed the Tobacco Control Act of Bhutan 2010 to regulate tobacco and tobacco products, banning the cultivation, harvesting, production, and sale of tobacco and tobacco products in Bhutan.\n\nTobacco policies that limit the sale of cigarettes to minors and restrict smoking in public places are important strategies to deter youth from accessing and consuming cigarettes. Amongst youth in the United States, for example, when compared with students living in states with strict regulations, young adolescents living in states with no or minimal restrictions, particularly high school students, were more likely to be daily smokers. These effects were reduced when logistic regressions were adjusted for sociodemographic characteristics and cigarette price, suggesting that higher cigarette prices may discourage youth to access and consume cigarettes independent of other tobacco control measures.\n\nSmokers are not fully informed about the risks of smoking. Warnings that are graphic, larger, and more comprehensive in content are more effective in communicating the health risks of smoking. Smokers who noticed the warnings were significantly more likely to endorse health risks, including lung cancer and heart disease. In each instance where labelling policies differed between countries, smokers living in countries with government mandated warnings reported greater health knowledge.\n\nGraphic warning labels on cigarette packs are noticed by the majority of adolescents, increase adolescents’ cognitive processing of these messages and have the potential to lower smoking intentions. Based on extensive research of adolescents in the United States, the introduction of graphic warning labels has greatly reduced smoking among adolescents.\n\nThe tobacco control community is internationally organized - as is its main opponent, the tobacco industry (sometimes referred to as 'Big Tobacco'). This allows for sharing of effective practice (both in advocacy and policy) between developed and developing states, for instance through the World Conference on Tobacco or Health held every three years. However, some significant gaps remain, particularly the failure of the US and Switzerland (both bases for international tobacco companies and, in the former case, a tobacco producer) to ratify the FCTC.\n\nNow an accepted element of the public health arena, tobacco control policies and activity are seen to have been effective in those administrations which have implemented them in a co-ordinated fashion. England, for instance, met its target to reduce its adult smoking prevalence to 21% or lower by 2010 through such an approach. Direct and indirect opposition from the tobacco industry continue, for instance through the tobacco industry's efforts at misinformation via suborned scientists and 'astroturf' counter-advocacy operations such as FOREST.\n\n\"Tobacco Control\" is also the name of a journal published by BMJ Group (the publisher of the British Medical Journal) which studies the nature and implications of tobacco use and the effect of tobacco use upon health, the economy, the environment and society. Edited by Ruth Malone, Professor and Chair, Department of Social & Behavioral Sciences, University of California, San Francisco, it was first published in 1992.\n\n\n"}
{"id": "11863132", "url": "https://en.wikipedia.org/wiki?curid=11863132", "title": "Transvaginal oocyte retrieval", "text": "Transvaginal oocyte retrieval\n\nTransvaginal oocyte retrieval (TVOR), also referred to as oocyte retrieval (OCR), is a technique used in in vitro fertilization (IVF) in order to remove oocytes from the ovary of a woman, enabling fertilization outside the body. Transvaginal oocyte retrieval is more properly referred to as transvaginal ovum retrieval when the oocytes have matured into ova, as is normally the case in IVF.\n\nUnder ultrasound guidance, the operator inserts a needle through the vaginal wall and into an ovarian follicle, taking care not to injure organs located between the vaginal wall and the ovary. The other end of the needle is attached to a suction device. Once the follicle is entered, suction is gently applied to aspirate follicular fluid and with it, hopefully, cellular material including the oocyte. The follicular fluid is delivered to a technician in the IVF laboratory to identify and quantify the ova. Next, other follicles are aspirated. Once the ovarian follicles have been aspirated on one ovary, the needle is withdrawn, and the procedure repeated on the other ovary. It is not unusual to remove 20 oocytes as women are generally hyperstimulated in advance of this procedure. After completion, the needle is withdrawn, and hemostasis is achieved. The procedure usually lasts 2060 minutes.\n\nInitially performed using transabdominal ultrasonography, TVOR is currently performed with a transvaginal ultrasound transducer with an attached needle. TVOR is performed in an operating room or a physician's office, with the (female) subject in the lithotomy position. TVOR is usually performed under procedural sedation, general anesthesia, paracervical block, or sometimes spinal anesthesia. Local anesthesia is not typically used because local anesthetic agents interfere with follicular cleavage and the technique requires multiple needle punctures.\n\nFollicular flushing has not been found to increase pregnancy rates, nor result in an increase in oocyte yield. On the other hand, it requires a significantly longer operative time and more analgesia.\n\nSeminal fluid contains several proteins that interact with epithelial cells of the cervix and uterus, inducing active gestational immune tolerance. There are significantly improved outcomes when women are exposed to seminal plasma around the time of oocyte retrieval, with statistical significance for clinical pregnancy, but not for ongoing pregnancy or live birth rates with the limited data available.\n\nTVOR is typically performed after ovarian hyperstimulation, where oocytes are pharmacologically stimulated to mature. When the ovarian follicles have reached a certain degree of development, induction of final oocyte maturation is performed, generally by an intramuscular or subcutaneous injection of human chorionic gonadotropin (hCG). TVOR is typically performed 3436 hours after hCG injection, when the eggs are fully mature but just prior to rupture of the follicles.\n\nInjection of hCG as a trigger for ovulation confers a risk of ovarian hyperstimulation syndrome, especially in women with polycystic ovary syndrome who have been hyperstimulated during previous assisted reproduction cycles.\n\nComplications of TVOR include injury to pelvic organs, hemorrhage, and infection. Occurring more often in lean patients with polycystic ovary syndrome, ovarian hemorrhage after TVOR is a potentially catastrophic and not so rare complication. Additional complications may result from the administration of intravenous sedation or general anesthesia. These include asphyxia caused by airway obstruction, apnea, hypotension, and pulmonary aspiration of stomach contents.\n\nPropofol-based anesthetic techniques result in significant concentrations of propofol in follicular fluid. As propofol has been shown to have deleterious effects on oocyte fertilization (in a mouse model), some authors have suggested that the dose of propofol administered during anesthesia should be limited, and also that the retrieved oocytes should be washed free of propofol. Anecdotal evidence suggests that certain airborne chemical contaminants and particles, especially volatile organic compounds (VOC), may be toxic to and impair the growth and development of embryos if present in sufficient concentrations in the ambient atmosphere of an IVF incubator.\n\nThis technique was first developed by Pierre Dellenbach and colleagues in Strasbourg, France, and reported in 1984. Steptoe and Edwards used laparoscopy to recover oocytes when IVF was introduced, and laparoscopy was the major method of oocyte recovery until TVOR was introduced.\n\n"}
{"id": "24397074", "url": "https://en.wikipedia.org/wiki?curid=24397074", "title": "Vision Aid Overseas", "text": "Vision Aid Overseas\n\nVision Aid Overseas (VAO) is a registered charity in the United Kingdom, which provides optical aid and services to developing countries in Africa.\n\nIn 1985, a group of British optometrists and dispensing opticians each took two weeks out of their businesses to establish clinics in Tanzania, where they tested the eyes of local people and dispensed second-hand spectacles collected in UK. After the project gained publicity via the media and resultant public support, they formalised their efforts by registering the charity Vision Aid Overseas in 1987.\n\nFounded on the delivery of direct service to patient, since registering as a charity, VAO has operated direct service clinics in 23 countries and tested the eyes of over 600,000 patients, helping over 350,000 people to see with a pair of spectacles.\n\nIn the 1997 New Years Honours list, founder Brian Ellis was awarded the MBE.\n\nVAO today focuses it operations around three core services:\n\nVAO presently runs sustainable projects in five target countries: Ethiopia, Malawi, Sierra Leone, Uganda, and Zambia.\n\nVAO Honorary Vice Presidents include competing newsreaders Fiona Bruce of the BBC, and Sir Trevor MacDonald of ITV News. In February 2005 Bruce did the voice over for VAO's Lifeline Appeal, and in 2007 launched VAO's Annual Review.\n\nThe charity has formalised its relationship with the UK eye care industry, and is often the chosen charity supported by many dispensing opticians, and professionals via the Worshipful Company of Spectacle Makers, who collect old spectacles from customers for recycling via VAO.\n\nThe charity gained publicity in 2005 after the death of \"Countdown\" game show host Richard Whiteley. After his death, his longtime partner Kathryn Apanowicz donated three pairs of Whiteley's spectacles to VAO, who sent them with a team of optical professionals to Ethiopia, where they were fitted to three locals with the same prescription. The BBC followed this story on their \"Inside Out\" programme, which was broadcast on 19 September 2007.\n\n"}
{"id": "20047326", "url": "https://en.wikipedia.org/wiki?curid=20047326", "title": "Water supply and sanitation in England and Wales", "text": "Water supply and sanitation in England and Wales\n\nPublic water supply and sanitation in England and Wales has been characterised by universal access and generally good service quality. Salient features of the sector in the United Kingdom compared to other developed countries is the full privatisation of service provision and the pioneering of independent economic regulation in the sector in Europe. There has been a substantial increase in real tariffs between 1989 and 2005, whilst independent assessments place the cost of water provision in the UK as higher than most other major countries in the EU. The government body responsible for water regulation, together with the water companies, have claimed improvements in service quality during the same period.\n\nOn average, only about 10 percent of freshwater resources in England and Wales are abstracted. Water companies abstract almost half of this amount. The remainder is used for cooling power plants, other industries, fish farming and other uses. Water companies use mainly surface water (two thirds), but also groundwater (one third).\n\nThe amount of water available in England and Wales to meet the needs of people and to sustain the water environment varies greatly between different places and seasons, and from one year to another. Parts of Wales and the English Lake District are well endowed with water, while water is scarce in parts of Eastern and Southeastern England. Parts of England were affected by severe drought in 1976, 1995 and 2005-2007.\n\nHousehold water use in England and Wales stood at about 145 litres/capita/day in 2008/09. Total water supply for domestic and commercial customers in England and Wales was 14.5 million cubic metres per day in 2009.\n\nThe quality of water and sanitation services in England and Wales is regularly and comprehensively monitored by the economic regulator, OFWAT. OFWAT statistics show that service quality has improved since the early 1990s, i.e. shortly after services were privatised. For example, the number of unplanned interruptions, properties at risk of low pressure, the share of complaints that were not answered within five days and combined sewer overflows have all declined, while sewage treatment works compliance has increased and river water quality has improved. A comparison with service quality in other areas of the European Union is difficult, since in few other countries such comprehensive water and sanitation service quality data are being published as it is being done by OFWAT.\n\nDrinking water quality is also universally high, although isolated incidents where quality falls have occurred. For example, in June 2008 about 250,000 people in Northamptonshire were being told to boil tap water for drinking after routine tests by Anglian Water found cryptosporidium\n\nPhysical assets of private water and sanitation companies in England and Wales include 1,000 reservoirs, over 2,500 water treatment works and 9,000 sewage treatment works. More than 700,000 kilometres of mains and sewers are buried beneath the ground – that’s enough to stretch to the moon and back, or a distance 200 times greater than the UK’s entire motorway network.\n\nWithin the government the Department of Environment, Food and Rural Affairs (Defra) has the responsibility for policy in the water and sanitation sector. The economic regulator of water companies in England and Wales is the Water Services Regulation Authority, OFWAT. The Environment Agency is responsible for environmental regulation, and the Drinking Water Inspectorate for regulating drinking water quality. Drinking water standards and wastewater discharge standards in the U.K., as in other countries of the European Union, are determined by the EU (see EU water policy).\n\nIn England and Wales water and sewerage services are provided by 10 private regional water and sewerage companies and 16 mostly smaller private \"water only\" companies.\n\nBefore 1973 water and sanitation services were provided by water undertakings and sewerage and sewage disposal authorities respectively. Until the 1950s there existed over a thousand water undertakings, with administrative boundaries similar to those of local government boundaries. By the early 1970s their number had been reduced to 198 by a gradual consolidation process aimed at achieving economies of scale. Out of the 198 water undertakings 64 were run by individual local government authorities, 101 by joint boards comprising several local government authorities, and 33 were statutory privately owned water companies, some of which date back to the Victorian era. At the same time there were over 1,300 sewerage and sewage disposal authorities, most of them run by individual local government authorities. The sector thus was highly fragmented.\n\nWater resources management was entrusted to 29 river authorities created in 1965. Their responsibilities included water conservation, land drainage, fisheries, control of river pollution and, in some cases, navigation.\n\nThrough the Water Act 1973 the government established 10 Regional Water Authorities in order to achieve even greater economies of scale, especially in sanitation, compared to the prior gradual consolidation of water undertakings. The reform was also aimed at putting in practice the principle of integrated river basin management, especially concerning the planning of investments in wastewater treatment. Given the small size of many river basins in England and Wales, in practice the area covered by each of the Regional Water Authorities typically contained more than one river basin.\n\nThe Regional Water Authorities were not only in charge of water supply and sanitation, but also of water resources management, thus opening the possibility of conflicts of interest since the same institution was in charge of abstracting water and discharging wastewater on the one hand, and controlling these same abstractions and discharges on the other hand. The Water Act left open the possibility to contract out water supply and sanitation services to local authorities. However, in practice this did not happen, and substantial assets were transferred from local governments to the new water authorities. Since the transfer was internal to the public sector, no compensation was paid to local authorities. Local authorities also initially held a majority of the Board seats of the new organisations. The private statutory water companies, which provided water to 25% of the population, escaped reorganisation and were left to operate as before.\n\nWith the election of Margaret Thatcher in 1979 the water and sanitation sector initially remained public, but the government attempted to make the enterprises operate more along commercial lines. As a result, the number of employees in the sector declined from 61,000 in 1976 to 52,000 in 1985, real operating costs declined, tariffs were increased above the inflation rate and the share of self-financing of investments increased. However, government regulators also cut back on investments. While the industry became profitable, the rate of return on assets based on replacement cost values remained low at less than 2%. As part of the attempt to commercialise the service providers, the Water Act 1983 reduced the number of Board members of the water authorities. However, it also eliminated the local government representation on the Boards and made all Board members appointed by Ministers, thus further centralising the sector.\n\nIn 1989 the government privatised the ten public regional water authorities through divestiture (sale of assets). The authorities' functions related to water resources management were separated and retained by the public sector. At the same time the regulatory agency OFWAT was created, following the model of infrastructure regulatory agency set up in other sectors such as telecommunications and energy.\n\nThe Water Industry Act 1999 banned the disconnection of water and sewerage services for non-payment by domestic customers. It also allows the continuation of water charges based on rateable property value, as opposed to volumetric rates based on metering.\n\nFrom 1 April 2017, most businesses and organisations in England will be able to choose which company will supply their retail water services.\n\nTariff level. Water and sanitation tariffs in England and Wales have increased by 44% in real terms between 1989 and 2008–09 and are among the highest in the world. The average household water and sewage bill in England and Wales was £330 in 2008-09. According to a 2006 survey by NUS Consulting Group the average water tariff (price) without sewerage in the U.K. for large consumers was the equivalent of US$1.90 per cubic metre. This was the third-highest tariff among the 14 mostly OECD countries covered by the report. A study commissioned by the German industry association BGW in 2006, compared the average household water and sanitation bill (as opposed to the tariff per cubic metre that the NUS study used as a comparator) in four EU countries. This study showed that water bills in England and Wales were the highest among the four countries. Average water bills (excluding sanitation) were 295 euro per year in England and Wales, higher than in Germany, France (85 euro) or Italy (59 euro).\n\nComparison of annual water and sanitation bills in four EU countries:\n\nSource: Metropolitan Consulting Group: VEWA - Vergleich europaeischer Wasser- und Abwasserpreise, 2006, p. 7 of the executive summary\n\nTaking into account differences in subsidies and service quality, the cost of supplying water at an equalised service level would be 84 euros in Germany, 106 euro in both France and England/Wales, and 74 euro in Italy. Concerning sanitation, unequalised tariffs are the highest in Germany at 111 euro per year, 93 euro in England and Wales, €90 in France and only €40 in Italy. Equalised costs net of subsidies are, however, highest in England and Wales with €138, followed by France (€122), Germany (119 euro) and Italy (85 euro).\n\nTariff structure and cross subsidies. Metered connections are charged at a volumetric rate, while unmetered connections are charged at a flat rate based on the rateable value of the property. The rateable value system was intended as a cross subsidy from wealthier to poorer households. However, since rateable values are often outdated, the subsidy is poorly targeted. Since more and more highly rated households opt for metering, flat rates for the remaining unmetered customers are being increased to compensate for the lost revenue. As a result, the already imperfect cross-subsidy system is unwinding. An Independent Report on Charging for Household Water and Sewerage Services published in 2009 by Anna Walker recommended a package of help to ensure that \"the transition to metering is not to cause real problems of affordability to those on low incomes\".\n\nTariff review procedures Water and sanitation tariffs are regulated by OFWAT, which sets caps for tariff changes over five-year asset management plan periods. In the 2000–2005 review period OFWAT mandated an average annual reduction of tariffs of 1.6%. However, in the 2006–2010 review period it has allowed an average annual increase of 4.2%.\n\nAffordability As a proportion of income, in England and Wales the cost of water and sewerage together works out at less than 1.5% of weekly earnings. More details on tariffs in England and Wales are provided in OFWAT's annual reports on water and sewerage charges.\n\nAverage annual investments in water and sewerage in England and Wales were £3.3 billion in 2000–2005 and £3.6bn in 2005–2010, according to OFWAT, which corresponds to £61 per capita per year. According to the industry association Water UK, between 1980 and 2010 the water and wastewater industry in England and Wales will have invested over £88bn.\n\nInvestments are financed primarily through self-financing and borrowing in the capital market. In March 2006 overall borrowing stood at £23.5bn for England and Wales. Net returns on this borrowing in 2006 were 6.6%.\n\nEfficiency of service provision has many dimensions, of which only one (water losses) is treated here.\n\nAccording to OFWAT leakage in England and Wales has declined significantly from 228 litres/property/day in 1994-95 to 141 l/p/d in 2006–07, enough to supply the needs of 10 million people. According to the Environment Agency, many companies in the UK have reduced their water loss to the economic level of leakage. This is the level at which, in the long-term, the marginal cost of leakage control is equal to the marginal benefit of the water saved. The rate of reduction in leakage has slowed for many companies because the most obvious causes of leakage have been detected and addressed, leaving only less apparent leakage problems. Models have been developed and fine-tuned to assess the economic level of leakage. A summary of the debate on these models can be found in a recent report by OFWAT. \nAccording to a comparative study commissioned by the German water industry association BGW average water losses in the distribution network in England and Wales have been estimated at 19 percent. They are lower than in France (26 percent) or Italy (29 percent), but higher than in Germany, where they are apparently only 7 percent. The study states that its methodology allows for an accurate comparison, including water used to flush pipes and for firefighting. This is consistent with the International Water Association's definition of non-revenue water, which includes authorised non-metered consumption such as for flushing and firefighting.\n\nOFWAT does not use percentage figures when it assesses leakage levels. Also it assesses only leakage and not broader losses. It is thus difficult to compare figures from the comparative study cited above with OFWAT figures for England and Wales.\n\nA particularity of water tariffs in England and Wales is the low share of metering. Most users are not billed on a volumetric basis and have no financial incentive for water conservation. Since the 1990s efforts have been made to increase the share of household metering, which reached 33% in 2008 for the UK. The Environment Agency would like to see 75% of households metered by 2025. Studies show that water meters lead to a 5-15% reduction in household water use. Meters are typically only installed at the request of customers.\n\nIn 2006 the Environment Agency announced it favours compulsory metering in water-scarce southern England. The measure is controversial. Consumer groups fear it will penalise poorer families with lots of children, and the disabled, who use more water. The announcement also represents a U-turn for Labour, which fiercely opposed compulsory water meters when in opposition, describing them as a 'tax on family life'. In March 2006 the company Folkestone & Dover Water Services was granted the power to install compulsory water meters in a landmark ministerial ruling under which it was given 'water scarcity status' by Environment Minister Elliot Morley. In a written ministerial statement, Mr Morley said: 'In many parts of the country, water is a precious resource which we can no longer simply take for granted.' The company says that Folkestone and Dover are in one of the driest areas in the UK. Many parts of the Middle East had more rain than this area, and it is getting even drier and warmer due to climate change.\n\nIn July 2011, the think tank Policy Exchange reported a significant decline in river quality due to abstraction carried out by water companies. The report calls for water companies to be charged more for using the most environmentally vulnerable rivers and aquifers in drier parts of the country, with cheaper rates where water is more abundant. It also called for higher water charges during droughts.\n\nIn 2009, an investigation conducted by the BBC's Panorama concluded that the operation of more than 20,000 Combined Sewer Overflow pipes (CSO) was leading to the routine spillage of untreated wastes around Britain's coastline, potentially leading to very dirty water around some of the most popular beaches in the UK. The CSOs, intended for use in very rare occasions, were not covered by the existing legislation for waste emissions.\n\nA 2001 study by the Public Services International Research Unit, which is affiliated with trade unions and opposes privatisation, stated that \n\n\n"}
