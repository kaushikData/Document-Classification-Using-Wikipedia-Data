{"id": "254190", "url": "https://en.wikipedia.org/wiki?curid=254190", "title": "Ambulatory Patient Group", "text": "Ambulatory Patient Group\n\nAmbulatory Patient Group (APG) is a classification system for outpatient services reimbursement developed for the American Medicare service by the Health Care Financing Administration. It classifies patients into nearly 300 pathology groups rather than the 14,000 of the International Classification of Diseases.\n\nThe APG system is similar to the diagnosis-related groups (DRG), which apply to inpatient care rendered by a hospital.\n"}
{"id": "22983063", "url": "https://en.wikipedia.org/wiki?curid=22983063", "title": "AmeriHealth", "text": "AmeriHealth\n\nAmeriHealth New Jersey is a provider of health insurance to nearly 260,000 employers and individuals throughout New Jersey. The company's contracted hospital and physician network includes thousands of physicians at 76 hospitals throughout its service area. Its HMO and POS plans are New Jersey's top-rated health plans based on the highest ratings for customer service and quality-of-care in the 2008 New Jersey Department of Banking and Insurance HMO Performance Report. AmeriHealth New Jersey is headquartered in Cranbury.\n\nAmeriHealth New Jersey offers nationwide coverage through PHCS, a Preferred Provider Organization (PPO). The company offers insurance solutions through AmeriHealth’s wellness benefits and incentive programs.\n\nAmeriHealth, originally known as Delaware Valley HMO, was established in 1995 to provide health coverage to Pennsylvania employers and their staff residing in Burlington, Camden, Gloucester, and Salem counties of New Jersey. It expanded its coverage area to include southern New Jersey and Delaware, and, by 1997, AmeriHealth offered coverage to the entire state of New Jersey. In 2013 AmeriHealth announced it would be offering plans in New Jersey on the federally run health insurance exchange.\n\nAmeriHealth New Jersey is a provider of employer on-site health coaching with a nurse wellness specialist to small- and mid-sized New Jersey-based organizations. Workplace wellness services include sending registered nurses to provide a broad spectrum of on-site health education, seminars, screenings, and support. AmeriHealth New Jersey offers an incentive-based wellness program, called Commit2Wellness Rewards, which provides individuals and groups with tools to support wellness and rewards for living a healthy lifestyle.\n\nAmeriHealth New Jersey is the name sponsor of the New Jersey Devils’ practice facility, the AmeriHealth Pavilion. At the time this sponsorship was announced, news reports cited AmeriHealth’s desire to contribute to the “revitalization of Newark.”\n\nAmeriHealth New Jersey is also a sponsor and participant in Special Olympics New Jersey’s annual “Lincoln Tunnel Challenge.” In 2009 the event drew a record crowd of 3,500 runners and walkers to the tunnel. Additionally, AmeriHealth New Jersey sponsors and participates in the “Ben Franklin Bridge Challenge,” which benefits the Larc School for the disabled; and sponsors Rutgers University and several local the minor league baseball teams.\n\nNJBIZ magazine has recognized AmeriHealth New Jersey in multiple awards programs over the past several years. The company is one of New Jersey's Best Places to Work for five consecutive years, one of the Top Privately Held Companies, and one of the 50 Fastest Growing Companies in New Jersey.\n\nAmeriHealth earned top ratings for customer service and quality of care in the 2008 New Jersey Department of Banking and Insurance’s HMO Performance Report.\n\nThe company’s managed care plan, AmeriHealth HMO Inc. of New Jersey, has received the highest possible accreditation by the National Committee for Quality Assurance (NCQA) by meeting NCQA's rigorous evaluation standards.\n\n"}
{"id": "32889386", "url": "https://en.wikipedia.org/wiki?curid=32889386", "title": "Andrew Duncan, the elder", "text": "Andrew Duncan, the elder\n\nAndrew Duncan, the elder (17 October 1744 – 5 July 1828)\nFRSE FRCPE FSA(Scot) was a British physician and professor at Edinburgh University. He was joint founder of the Royal Society of Edinburgh.\n\nDuncan was the second son of Andrew Duncan, merchant and shipmaster, of Crail, afterwards of St. Andrews, his mother being a daughter of Professor \"William Vilant\", and related to the Drummonds of Hawthornden. He was born at Pinkerton, near St. Andrews, Fife, on 17 October 1744, and was educated first by Sandy Don of Crail, celebrated in the convivial song of \"Crail Town,\" and afterwards by \"Richard Dick\" of St. Andrews.\n\nDuncan proceeded next to University of St Andrews, where he obtained the M.A. degree in 1762. As a youth he was known as \"the smiling boy\", and his character for good nature was retained through life. Lord Erskine and his brother Henry Erskine were among his school fellows and fast friends through life. In 1762, he entered Edinburgh University as a medical student, being the pupil of Cullen, John Gregory, Alexander Monro secundus, Hope, and Black.\n\nDuncan was president of the Royal Medical Society in 1764, and five times afterwards.\nHis attachment to the society continued through life; he was its treasurer for many years; and in 1786 a gold medal was voted to him for his services. On the completion of his course of studies in 1768, he went a voyage to China as surgeon of the East India Company's ship \"Asia\". Refusing an offer of five hundred guineas to undertake a second voyage, Duncan graduated M.D. at St. Andrews in October 1769, and in May 1770 became a licentiate of the Edinburgh College of Physicians. In the same year he was an unsuccessful candidate for the professorship of medicine in St. Andrews University.\n\nDuring the absence of Dr. Drummond, professor-elect of medicine at Edinburgh, Duncan was appointed to lecture in 1774–6. Drummond failing to return, Dr. James Gregory was elected professor, and Duncan started an extra-academical course, as well as a public dispensary, (the first free hospital in Scotland), which afterwards became the Royal Public Dispensary, incorporated by royal charter in 1818.\n\nIn 1773 he lived on Bristo Street in the south of Edinburgh.\n\nIn 1773, he commenced the publication of \"Medical and Philosophical Commentaries\", a quarterly journal of medicine, at first issued in the name of \"a society in Edinburgh\", Duncan being named as secretary. It was the first medical review journal published regularly in Great Britain. The seventh volume was entitled \"Medical Commentaries for the year 1780, collected and published by Andrew Duncan\", and reached a third edition. The series extended ultimately to twenty volumes, the last issue being in 1795, after which the publication was entitled \"Annals of Medicine\", of which eight volumes were issued. In 1804 it was discontinued in favour of the \"Edinburgh Medical and Surgical Journal\", edited by his son.\n\nDuncan's extra-academical lectures were continued with considerable success till 1790, when he became the president of the Edinburgh College of Physicians. On Cullen's resignation in that year he was succeeded in the professorship of medicine by Dr. James Gregory, and Duncan followed the latter in the chair of the theory or institutes of medicine (physiology).\n\nIn 1792, he proposed the erection of a public lunatic asylum in Edinburgh, having first conceived the idea after hearing of the miserable death of Robert Fergusson in 1774 in the common workhouse. It was not until many difficulties had been surmounted that the project was at last accomplished, and a royal charter was granted in 1807 under which a lunatic asylum was built at Morningside.\n\nInspired by a miscarriage of justice, he also delivered the first lectures on forensic medicine in Britain, at the University of Edinburgh and campaigned to establish a chair of medical jurisprudence there, which was filled by his son, Andrew Duncan, the younger, who followed him into the profession.\n\nIn 1808, the freedom of Edinburgh was conferred upon Duncan for his services in the foundation of the dispensary and the asylum. In 1809, he founded the Caledonian Horticultural Society, which, being afterwards incorporated, became of great scientific and practical value. \n\nIn his later years, Duncan was actively occupied in promoting the establishment of a public experimental garden, the scheme for which was actively progressing at his death. In 1819, his son became joint professor with him, and in 1821, Dr. W. P. Alison succeeded to that post, but Duncan continued to do much of the duty to the last. In 1821, on the death of Dr. James Gregory, Duncan became first Physician to the King in Scotland, having held the same office to the Prince of Wales for more than thirty years.\n\nIn 1821, Duncan was elected president of the Edinburgh Medico-Chirurgical Society at its foundation. In 1824, he was again elected president of the Edinburgh College of Physicians.\nAlthough in his later years, he failed to keep up with the progress of physiology, his zeal was unabated, and he discharged many useful offices with extreme punctuality. He used to say that the business of no institution should be hindered by his absence, whether it was forwarded by his presence or not.\n\nFor more than half a century he walked to the top of Arthur's Seat on May-day morning, accomplishing this for the last time on 1 May 1827. He died at his home, Adam Square in Edinburgh on 5 July 1828, in his eighty-fourth year.\n\nHe bequeathed to the Edinburgh College of Physicians seventy volumes of manuscript notes from the lectures of the founders of the Edinburgh School of Medicine, and a hundred volumes of practical observations on medicine in his own handwriting. A portrait of him by Raeburn is in the Edinburgh Royal Dispensary, as well as a bust; a full-length portrait was painted in 1825 for the Royal Medical Society by Watson Gordon.\n\nDuncan was industrious, and a perspicuous rather than a brilliant lecturer. He was generous and hospitable to his pupils and, being naturally gregarious, he founded several clubs, among which the Harveian Society, founded in 1782, was the most notable.\nHe was its secretary until his death, and never failed to provide its annual meeting with an appropriate address, usually commemorating some deceased ornament of the medical profession. The Esculapian and gymnastic clubs were also of his foundation, and many of his poetical compositions were read or sung at their meetings. He was much loved for his geniality and benevolence.\n\nDuncan's larger works, besides those already mentioned, are:\n\nIn connection with the Harveian Society, Duncan published an oration in praise of Harvey, 1778; and memoirs of Alexander Monro (primus), 1780; Dr. \"John Parsens\", 1786; Professor Hope, 1789; Alexander Monro (secundus), 1818; Sir Joseph Banks, 1821; and Sir Henry Raeburn, 1824.\n\nDuncan published his \"Opinion\", 1808, and a \"Letter to Dr. James Gregory\", 1811, on the subject of Dr. James Gregory's many controversies. Some of his poetry is included in \"Carminum Rariorum Macaronicorum Delectus\" (Esculapian Society), 1801, second edition enlarged; and \"Miscellaneous Poems, extracted from the Records of the Circulation Club, Edinburgh\", 1818. He also selected and caused to be published \"Monumental Inscriptions selected from Burial Grounds at Edinburgh\", 1815.\n\nIn February 1771, he married Miss Elizabeth Knox, who bore him twelve children. His eldest son, Andrew, also became a professor at Edinburgh. His third son, Alexander Duncan (1780–1859), became a general in the army and distinguished himself in India.\n\nHe is buried together with many of his family in a family mausoleum in Buccleuch Churchyard. The Church was built as a Chapel of Ease to resolve overcrowding of the graveyard at its mother church: the parish church of St. Cuthbert's, Edinburgh.\n\nAs a favour, one of his prodigy students is buried in the tomb, having died during his studies: Charles Darwin (1758-1778) by blood the uncle of his namesake Charles Darwin the naturalist, but dying before his birth.\n\n\n"}
{"id": "5312695", "url": "https://en.wikipedia.org/wiki?curid=5312695", "title": "Batu Dam", "text": "Batu Dam\n\nBatu Dam () is one of the major dams of Klang Valley located in Selangor, Malaysia. The dam is a water supply dam. The dam holding capacity is 30,199 million litres. The Sungai Batu water treatment plant produces 114 million litres per day of treated water.\n\n\nThe Star newspaper, 8 February 2007\n"}
{"id": "20013272", "url": "https://en.wikipedia.org/wiki?curid=20013272", "title": "Boškov Most Hydro Power Plant", "text": "Boškov Most Hydro Power Plant\n\nBoškov Most Hydro Power Plant, hereinafter referred to as Boškov Most HPP, is planned to be built in Mala Reka valley in the southernmost part of the Mavrovo National Park. It will have a total capacity of 70 MW. The project threatens the survival of the Balkan lynx. The European Bank for Reconstruction and Development (EBRD) agreed in November 2011 to lend EUR 65 million to Macedonia for the construction of the dam.\n\nBoškov Most HPP will be built near the town of Debar in the western part of the country and will have a generating capacity of 70 MW. It is intended to utilise the hydro power potential of the tributaries of the river Mala Reka and will include a dam and a reservoir near the village of Tresonce. It is estimated that it will produce 117 GW of power per year. Plans to build the Boskov Most HPP date back to 1983 but it was postponed several times due to financial problems.\n\nIn November 2011 European Bank for Reconstruction and Development (EBRD) signed on loaning a country EUR 65 million for the construction of the project. The rest is to be provided by the AD Elektrani na Makedonija (ELEM).\n\nELEM is a 100% state owned electric power utility of Macedonia responsible for mining and power generation. It was formed in 2005 and currently carries out mining operations in four coal mines and operates 1,329 MW of power generating capacity, of which 60% is lignite-fired and 40% hydropower.\n\nIn 2011 it was estimated that the total cost of the project was to be EUR 84 million however, in 2014 that figure rose to EUR 107 million.\n\nUnfavourable energy mix, strong dependence on energy import, obsolete energy system and inefficiency in energy production and use are the main problems of the Macedonian energy sector. Macedonia imports roughly a quarter of its annual electricity needs. Domestic energy production is based mainly on the low-quality domestic lignite, biomass and hydro. The purpose of the Boškov most HPP is to support Macedonia's drive to improve the security and quality of its energy supplies, as well as promoting renewable sources of energy generation. Once operating, the plant will enable the nation to reduce electricity imports and in addition decrease the carbon intensity of the Macedonian generation sector.\n\nThe Mavrovo National Park is one of the oldest national parks in Europe, famous for its pristine nature. The park hosts more than 1,000 different plant species. Trout species, wolves, bears and otters are an important part of the ecosystem. The park is also a centre of the remaining population of the Balkan Lynx, an endangered subspecies of the Eurasian Lynx. The territory where it moves is thus a critical habitat and represents an area where measures for protection and preservation of this species should be undertaken. Putting any additional stress on this source population may lead to the extinction of the species.\n\nBoškov HPP is designed to produce peak energy which means that the water from Mala Reka river and its tributaries will be diverted into a reservoir and on demand released once a day. Aside from the fact that the entire valley will suffer from the diversion of the majority of its natural water supplies, it will also result in daily flushes, which have enormous negative impacts on biodiversity and species populations in the river sections below the HPP.\n\nThe Environmental impact assessment prepared for the project is lacking significant information vital for the precise and objective evaluation of the impact of the project on the environment, specifically data on the mammals in the project area and complete absence of the Balkan lynx from the study.\n\nThe project is also not in accordance with Law on Nature protection specifically with Article 74, which does not envisage the use of natural resources for energy as a part of national park management and Article 75 which lists the prohibited activities in the national park. Furthermore, the project is not in accordance with the following international conventions signed and ratified by the government of Macedonia: Bern Convention, Bonn Convention and Convention on Biodiversity.\n\nAfter over five years of campaigns against the Boskov Most project, CEE Bankwatch along with its member groups, Macedonian center for environmental research and information, Eko-svest, and Macedonian environmental lawyer association, Front 21/42, finally welcomed the cancellation of the project. \nIn 2015, just few days after the Berne Convention decision on Mavrovo, the World Bank withdrew its funds from the Lukovo Pole project, thus preventing the project from being realised. \nIt took the EBRD another year to cancel its EUR 65 million loan for Boškov Most as well, stating that it fully respects Bern Convention’s recommendation and believes that the project should be suspended.\n\n"}
{"id": "1040488", "url": "https://en.wikipedia.org/wiki?curid=1040488", "title": "Chain smoking", "text": "Chain smoking\n\nChain smoking is the practice of smoking several cigarettes in succession, sometimes using the ember of a finished cigarette to light the next. The term chain smoker often also refers to a person who smokes relatively constantly, though not necessarily \"chaining\" each cigarette. The term applies primarily to cigarettes, although it can be used to describe incessant cigar and pipe smoking as well. It is a common form of addiction.\n\nThe use of cocaine or an amphetamine with cigarettes can result in chain smoking. Many people chain-smoke when drinking alcoholic beverages, because alcohol potentiates nicotinic acetylcholine receptors, leading to re-sensitization and hence inducing a craving.\n\nThe extent to which chain smoking is driven by nicotine dependence has been studied. It does not seem that the amount of nicotine delivered is a significant factor, as the puff volume correlates poorly with the frequency of cigarette consumption.\n\nChain-smoking is given as an example of excessive addictive behaviour in the Diagnostic and Statistical Manual of Mental Disorders. It may be used as a form of aversion therapy for smokers who are unused to such heavy smoking, inducing them to give up altogether.\n\nHeating, ventilating, and air conditioning (HVAC) professionals claim that an airflow of about 1000 cubic feet (28.32 cubic meters) per minute per smoker is required to maintain satisfactory air quality when the smokers are chain smoking. However, research confirms that current HVAC systems, while important for general air quality, cannot control exposure to secondhand smoke.\n\nA number of public figures were noted for being chain smokers.\n\n"}
{"id": "24145110", "url": "https://en.wikipedia.org/wiki?curid=24145110", "title": "Clitoral erection", "text": "Clitoral erection\n\nClitoral erection is a physiological phenomenon where the clitoris becomes enlarged and firm. \n\nClitoral erection is the result of a complex interaction of psychological, neural, vascular and endocrine factors, and is usually, though not exclusively, associated with sexual arousal.\n\nThe clitoris is the homologue of the penis in the female. \n\nThe part visible on the outside varies in size from a few millimeters to one centimeter and is located hidden in the upper labial fold. \n\nAny type of motion can increase blood flow to this organ and this results in increased secretions which lubricate the vagina. There are many ways to stimulate the clitoris.\n\nClitoral erection occurs when the corpora cavernosa, two expandable erectile structures, become engorged with blood. This may result from any of various physiological stimuli, including sexual arousal. During sexual arousal, arterial blood flow to the clitoris is increased, and trabecular smooth muscle within the clitoris relaxes allowing blood to engorge the erectile tissues. The ischiocavernosus and bulbocavernosus muscles contract to compress the dorsal vein of the clitoris to stop drainage of the clitoris, trapping the blood. More specifically, the clitoris has two adjoining erectile tissues corpus cavernosa (corpus cavernosa clitoridis) that form a main body that connects to the glans clitoridis. There is also a strip of erectile tissue (similar to the placement of the corpus spongiosum in males) running along the ventral surface of the corpus cavernosa main body that connects the glans clitoridis to the commissure of the vestibular bulbs. The main body of the corpus cavernosa with a ventral erectile tissue strip make up the shaft, which is connected to the glans clitoridis. The tunica albuginea is a fibrous-elastic sheath, surrounds the shaft and glans clitoridis. The tunica albuginea does not surround the bulbs of vestibule. The erectile tissues are composed of endothelium-lined vascular spaces in a trabecular matrix, with the endothelium-lined vascular spaces surrounded by smooth muscle capable of contraction and relaxation.\n\nDuring sexual arousal, arterial blood flow to the clitoris is increased, and within the clitoris, the arteries further branch to supply the erectile tissues. The trabecular smooth muscles of the erectile tissue relax increasing blood flow to fill the vascular spaces, expanding the erectile tissues until they are fully engorged with blood. The ischiocavernosus and bulbocavernosus muscles contract, compressing the dorsal vein of the clitoris. This compression of the vein restricts drainage of the erectile structures, trapping the blood. This process stretches the tunica albuginea. As a result, the clitoris becomes tumescent to accommodate the increased intracavernosus pressure. The tunica albuginea of the clitoris is made up of one layer making it more elastic than the tunica albuginea of the penis, which is composed of two layers. Erick Janssen (2007) elaborates on this reporting that \"the corpora cavernosa of the clitoris are essentially similar to that of the penis except that there is no subalbugineal layer interposed between the tunica albuginea and the erectile tissue. In the penis, this tissue engorges with blood during sexual arousal and becomes compressed against the unyielding tunica, creating penile rigidity --a true erection. The lack of this plexus in the clitoris indicates that while the organ can become tumescent or engorged, it cannot, like the penis become stiffly erect. The clitoris thus does not really become erect with sexual excitement, but engorged.\" In addition, the tunica albuginea around the glans is thinner than around the shaft in both the clitoris and penis. This gives the glans less firmness relative to the shaft. The extrusion of the glans clitoridis and thinning of the skin enhances sensitivity to physical contact. After a female has orgasmed, the erection usually ends, but this may take time.\n\n\n"}
{"id": "54525932", "url": "https://en.wikipedia.org/wiki?curid=54525932", "title": "Constipation in children", "text": "Constipation in children\n\nConstipation in children refers to the medical condition of constipation in children. It is a functional gastrointestinal disorder.\n\nChildren have different bowel movement patterns than adults. In addition, there is a wide spectrum of normalcy when considering children’s bowel habits. On average, infants have 3-4 bowel movements/day, and toddlers have 2-3 bowel movements per day. At around age 4, children develop an adult-like pattern of bowel movements (1-2 stools/day). Children benefit from scheduled toilet breaks, once early in the morning and 30 minutes after meals. The Rome III Criteria for constipation in children helps to define constipation for various age groups.\n\nWhile it is difficult to assess an exact age at which constipation most commonly arises, children frequently suffer from constipation in conjunction with life-changes. Examples include: toilet training, starting or transferring to a new school, and changes in diet. Especially in infants, changes in formula or transitioning from breast milk to formula can cause constipation. Fortunately, the majority of constipation cases are not tied to a medical disease, and treatment can be focused on simply relieving the symptoms.\n\nA number of diseases present at birth can result in constipation. They are as a group uncommon with Hirschsprung’s disease (HD) being the most common. HD is more common in males than females, affecting 1 out of 5000 babies. In people with HD, specific types of cells called ‘neural crest cells’ fail to migrate to parts of the colon. This causes the affected portion of the colon to be unable to contract and relax to help push out a bowel movement. The affected portion of the colon remains contracted, making it difficult for stool to pass through. Concern for HD should be raised in a child who has not passed stool during the first 48 hours of life. Milder forms of HD, in which only a small portion of the colon is affected, can present later in childhood as constipation, abdominal pain, and bloating. Similar disorders to HD include anal achalasia and hypoganglionosis. In hypoganglionosis, there is a low number of neural crest cells, so the colon remains contracted. In anal achalasia, the internal anal sphincter remains contracted, making it difficult for stool to pass. However, there is a normal number of neural crest cells present.\n\nThere are also congenital structural anomalies that can lead to constipation, including anterior displacement of the anus, imperforate anus, strictures, and small left colon syndrome. Anterior displacement of the anus can be diagnosed on physical exam. The disease causes constipation because the inappropriate positioning of the anus which make it difficult to pass a bowel movement. Imperforate anus is an anus that ends in a blind pouch and does not connect to the rest of the person's intestines. Small left colon syndrome is a rare disease in which the left side of the babies colon has a small diameter, which makes it difficult for stool to pass. A risk factor for small left colon syndrome is having a mother with diabetes.\n\nSome symptoms that may indicate an underlying disease include:\n\nThe Rome process suggests a diagnosis of constipation in children fewer than 4 years old when the child has 2 or more of the following complaints for at least 1 month. For children older than 4 years, there must be 2 of these complaints for at least 2 months.\n\nFor children, the degree of constipation may be scored by the \"Leech\" or the \"Barr\" systems:\n\n\nLactulose and milk of magnesia have been compared with polyethylene glycol (PEG) in children. All had similar side effects, but PEG was more effective at treating constipation. Osmotic laxatives are recommended over stimulant laxatives.\n\nThere is wide variation in the rates of constipation as reported by research in various countries. The variation in research data makes it challenging to describe the true global situation.\n\nApproximately 3% of children have constipation, with girls and boys being equally affected. With constipation accounting for approximately 5% of general pediatrician visits and 25% of pediatric gastroenterologist visits, the symptom carries a significant financial impact upon our healthcare system.\n\nConstipation is often emotionally stressful for children and their caregivers. It is common for parents to bring their children to doctors for this condition. The experience of going to a doctor for this can be stressful.\n\nToo often, children at doctors receive unnecessary health care when they get medical imaging for constipation. Children should only get tests when there is an indication.\n\n"}
{"id": "16238003", "url": "https://en.wikipedia.org/wiki?curid=16238003", "title": "Cream skimming", "text": "Cream skimming\n\nCream skimming is a pejorative conceptual metaphor used to refer to the perceived business practice of a company providing a product or a service to only the high-value or low-cost customers of that product or service, while disregarding clients that are less profitable for the company.\nThe term derives from the practice of extracting cream from fresh milk at a dairy, in which a separator draws off the cream (which is lighter, and floats) from fresh or raw milk. The cream has now been \"skimmed\" or captured separately from the fresh milk. \n\nThe idea behind the concept of cream skimming in business is that the \"cream\" – high value or low-cost customers, who are more profitable to serve – would be captured by some suppliers (typically by charging less than the previous higher prices, but still making a profit), leaving the more expensive or harder to service customers without the desired product or service at all or \"dumping\" them on some default provider, who is left with less of the higher value customers who, in some cases, would have provided extra revenue to subsidize or reduce the cost to service the higher-cost customers, and the loss of the higher value customers might actually require the default provider to have to \"raise\" prices to cover the lost revenue, thus making things worse.\n\nWhether or not the perceived negative effects of cream skimming actually do occur – or only occur in limited circumstances – is a matter of judgment and debate.\n\nThe term has been used in relation to the concept of school vouchers in which it is claimed that the vouchers could be used by parents of \"better\" students (i.e., students with above average grades who are not disciplinary risks) to move them out of lower performing or substandard state schools and into less-crowded private ones, leaving the \"worse\" students (i.e., students with learning disabilities or who are troublemakers) behind in the state schools, making the situation worse.\n\nFor example, it was believed that MCI and Sprint long distance telephone companies would end up taking away very high value business and some residential accounts from AT&T, leaving AT&T primarily with higher-cost to service accounts or ones producing less revenue (such as customers in less-densely populated or rural areas), meaning all customers of AT&T would end up paying more. This could conceivably lead to a vicious circle as more customers leave the high-price carrier for the lower priced carrier, thus forcing still more price increases to cover the upward spiraling costs of providing service to a shrinking revenue base. This scenario did not occur, as various technological changes (spurred in part by the availability of competition) eventually lowered the net cost for most long-distance telephone calls.\n\nThe United States Postal Service has a monopoly on the delivery of \"non-urgent\" first-class mail, where delivery is not time-sensitive. It also has the exclusive right to use customer-owned mail boxes for placing the customer's mail for delivery. This means that, even though mail boxes, such as those in the door of a house, or on the curb, or in the front lobby of the customer's building, are owned by the customer, and not owned by the Postal Service, by law only the Postal Service may use them to deliver mail. This law is in effect because it is believed that were the Postal Service to not have this monopoly, other competing mail carriers would take over the most lucrative parts of the business (e.g. local delivery of bills in dense urban areas), leaving the Postal Service with more expensive urban deliveries and rural service.\n\n"}
{"id": "1117969", "url": "https://en.wikipedia.org/wiki?curid=1117969", "title": "Dental technician", "text": "Dental technician\n\nA dental technologist (dental laboratory technician) is a member of the dental team who, upon prescription from a dental clinician, constructs custom-made restorative and dental appliances.\n\nThere are four major disciplines within dental technology. These are \"fixed prosthesis\" including crowns, bridges and implants; \"removable prosthesis\", including dentures and removable partial dentures; \"maxillofacial prosthesis\", including ocular prosthesis and craniofacial prosthesis; and \"orthodontics and auxiliaries\", including orthodontic appliances and mouthguards.\n\nThe dentist communicates with the dental technologist with prescriptions, drawings and measurements taken from the patient. The most important aspect of this is a dental impression into which the technologist flows a gypsum dental stone to create a replica of the patient's anatomy known as a dental cast. A technologist can then use this cast for the construction of custom appliances.\n\nA fixed dental restoration is an appliance designed to replace a tooth or teeth that may have been lost or damaged by injury, caries or other oral diseases. These restorations are distinguished from other restorations by the fact that once they have been placed by a dentist the patient can not remove them.\nSuch Restorations include; crowns, bridges, veneers, fixed implant restorations, inlays and onlays.\n\nRemovable restorations are dental appliances to replace one or more teeth that have been completely lost. These restorations ideally remain stable in normal function but can be removed by the patient for cleaning and at night. Removable restorations are either retained by the patients soft tissue as in full dentures, supported by other teeth as with partial dentures and overdentures or on implant attachments as with implant retained overdentures and partial dentures.\n\nOrthodontic technologists make removable orthodontic appliances with wires, springs and screws on prescription from an orthodontist to either move teeth to form a more harmonious occlusion and aesthetic appearance of teeth or to maintain the position of previously moved teeth.\n\n\n"}
{"id": "48913115", "url": "https://en.wikipedia.org/wiki?curid=48913115", "title": "Diplophonia", "text": "Diplophonia\n\nDiplophonia, also known as diphthongia, is a phenomenon in which a voice is perceived as being produced with two concurrent pitches. Diplophonia is a result of vocal fold vibrations that are quasi-periodic in nature. It has been reported from old days, but there are no uniform interpretation of established mechanisms. It has been established that diplophonia can be caused by various vocal fold pathologies, such as vocal folds polyp, vocal fold nodule, recurrent laryngeal nerve paralysis or vestibular fold hypertrophy.\n"}
{"id": "58563702", "url": "https://en.wikipedia.org/wiki?curid=58563702", "title": "Endoscopic sleeve gastroplasty", "text": "Endoscopic sleeve gastroplasty\n\nEndoscopic sleeve gastroplasty is a form of minimally invasive endoscopic gastroplasty, in which sutures are made within the stomach using an endoscope inserted through the mouth into the stomach.\n\nIt is regarded as an alternative to more invasive forms of bariatric surgery. It is believed to work through inducing changes in gastric physiology.\n\n"}
{"id": "47917565", "url": "https://en.wikipedia.org/wiki?curid=47917565", "title": "Federation of European Nutrition Societies", "text": "Federation of European Nutrition Societies\n\nThe Federation of European Nutrition Societies (FENS) is a non-profit association, established in 1979 as a roof organization for the national nutrition societies in Europe, with each country represented by its representative Nutrition Society or Association within FENS.\n\nThe aims of FENS are the combination of efforts for the development of research and education in Nutrition Sciences and the promotion of the importance of Nutrition for public health in Europe. It seeks to do this by coordinating the European nutrition societies at a European level, promoting and disseminating research and knowledge on nutrition sciences and facilitating nutrition learning and training, as well as scientific exchange across Europe.\n\nFENS conducts every 4 years its main event, the FENS European Nutrition Conference, which is organized by one of the FENS member societies, elected by the FENS General Assembly. All FENS Member Societies and Associations can take part in the bidding process for the organization of a FENS ENC.\n\nThe Federation of European Nutrition Societies is a member of the International Union of Nutritional Sciences (IUNS) and the official FENS Journal is the “Annals of Nutrition and Metabolism” (IF 2014/2015: 2.618)\n\n"}
{"id": "1570026", "url": "https://en.wikipedia.org/wiki?curid=1570026", "title": "Gynecologic ultrasonography", "text": "Gynecologic ultrasonography\n\nGynecologic ultrasonography or gynecologic sonography refers to the application of medical ultrasonography to the female pelvic organs (specifically the uterus, the ovaries, and the Fallopian tubes) as well as the bladder, the adnexa, and the Pouch of Douglas. The procedure may lead to other medically relevant findings in the pelvis.\n\nThe examination can be performed by transabdominal ultrasonography, generally with a full bladder which acts as an acoustic window to achieve better visualization of pelvis organs, or by transvaginal ultrasonography with a specifically designed vaginal transducer. Transvaginal imaging utilizes a higher frequency imaging, which gives better resolution of the ovaries, uterus and endometrium (the fallopian tubes are generally not seen unless distended), but is limited to depth of image penetration, whereas larger lesions reaching into the abdomen are better seen transabdominally. Having a full bladder for the transabdominal portion of the exam is helpful because sound travels through fluid with less attenuation to better visualize the uterus and ovaries which lies posteriorly to the bladder. The procedure is by definition invasive when performed transvaginally. Scans are performed by health care professionals called sonographers, or gynecologists trained in ultrasound.\n\nGynecologic sonography is used extensively:\n\nThrough transvaginal sonography ovarian cysts can be aspirated. This technique is also used in transvaginal oocyte retrieval to obtain human eggs (oocytes) through sonographic directed transvaginal puncture of ovarian follicles in IVF.\n\nGynecologic ultrasonography is sometimes overused when it is used to screen for ovarian cancer in women who are not at risk for this cancer. There is consensus that women with only average risk for ovarian cancer should not be screened with this procedure for cancer.\n\nSonohysterography is a specialized procedure by which fluid, usually sterile saline (then called saline infusion sonography or SIS), is instilled into the uterine cavity, and gynecologic sonography performed at the same time. A review in 2015 came to the conclusion that SIS is highly sensitive in the detection of intrauterine abnormalities in subfertile women, comparable to hysteroscopy. SIS is highly sensitive and specific test in the diagnosis of uterine polyps, submucous uterine fibroids, uterine anomalies and intrauterine adhesions (as part of Asherman's syndrome), and can be used as a screening tool for subfertile women prior to IVF treatment.\n\n\n"}
{"id": "19023511", "url": "https://en.wikipedia.org/wiki?curid=19023511", "title": "HIV/AIDS in Malawi", "text": "HIV/AIDS in Malawi\n\n, approximately 1,100,000 people in Malawi are HIV-positive, which represents 10.8% of the country's population. Because the Malawian government was initially slow to respond to the epidemic under the leadership of Hastings Banda (1966–1994), the prevalence of HIV/AIDS increased drastically between 1985, when the disease was first identified in Malawi, and 1993, when HIV prevalence rates were estimated to be as high as 30% among pregnant women. The Malawian food crisis in 2002 resulted, at least in part, from a loss of agricultural productivity due to the prevalence of HIV/AIDS. Various degrees of government involvement under the leadership of Bakili Muluzi (1994–2004) and Bingu wa Mutharika (2004–2012) resulted in a gradual decline in HIV prevalence, and, in 2003, many people living in Malawi gained access to antiretroviral therapy. Condoms have become more widely available to the public through non-governmental organizations, and more Malawians are taking advantage of HIV testing services.\n\nDue to several successful television and radio campaigns by the Malawian government and non-governmental organizations in Malawi, levels of awareness regarding HIV/AIDS are high among the general population. However, many men have adopted fatalistic attitudes in response to the epidemic, convincing themselves that death from AIDS is inevitable; on the other hand, some have implemented preventative techniques such as partner selection to try to reduce their risk of infection. Although many women have developed strategies to protect themselves from HIV, women are more likely to be HIV-positive than men in Malawi. The epidemic has affected sexual relationships between partners, who must cooperate to protect themselves from the disease. In addition, many teachers exclude HIV/AIDS from their curricula because they are uncomfortable discussing the topic or because they do not feel knowledgeable about the issue, and, therefore, many children are not exposed to information about HIV/AIDS at school. Finally, the epidemic has produced significant numbers of orphans in Malawi, leaving children vulnerable to abuse and exploitation.\n\nThe first case of HIV/AIDS in Malawi was reported at Lilongwe's Kamuzu Central Hospital in 1985. President Hastings Banda, who was in power at the time, responded with several small-scale prevention initiatives and created the National AIDS Control Programme, a division of the Ministry of Health, to manage the growing epidemic. Banda believed that issues relating to sex, including HIV transmission, should not be addressed in the public sphere; during this time, it was illegal for Malawian citizens to discuss the epidemic openly. In 1989, Banda introduced a five-year World Bank Medium Term Plan to combat the epidemic, but HIV prevalence had already increased drastically at this point.\n\nIn 1994, when Bakili Muluzi became president, he addressed the nation's need for a coordinated response to the HIV/AIDS epidemic. In 2000, Muluzi introduced another five-year policy known as the National Strategic Framework, but, like Banda's five-year World Bank Medium Term Plan, this plan was largely ineffective. In 2001, in response to problems within the National AIDS Control Programme established by Banda, Muluzi created the National AIDS Commission. Unlike Banda, who prevented the public from accessing information about the epidemic, Muluzi ensured that information about HIV/AIDS was available on the radio and television, in newspapers, and on billboards. However, despite Muluzi's efforts, HIV prevalence was already significantly influencing national agricultural productivity during this period, and Malawi experienced an AIDS-related nationwide famine in 2002.\n\nMalawians gained access to antiretroviral drugs in 2003, and, with a donation from the Global Fund to Fight AIDS, Tuberculosis, and Malaria and the election of new President Bingu wa Mutharika in 2004, government interventions increased substantially. However, soon after his election, Mutharika experienced tensions with Muluzi after implementing an anti-corruption program, which distracted the government from addressing the nation's food and HIV/AIDS-related crises. Despite these obstacles, Mutharika successfully developed a National AIDS Policy and appointed a Principal Secretary for HIV/AIDS during his presidency.\n\nDespite Malawi's limited health and educational infrastructure, knowledge regarding HIV/AIDS is high among many people living in both urban and rural Malawi. According to a 2004 study by Barden-O'Fallon et al. involving 100 households, women in Malawi are most likely to learn about HIV/AIDS through radio and television, health workers at local clinics, and female members of their social networks. Men are also likely to access information about HIV/AIDS through radio and television; however, unlike women, they are not likely to gain information about HIV/AIDS from their male friends. When 57 Malawian men were interviewed in 2003, 100% of them said they had heard about the HIV/AIDS epidemic on the radio, and 84.2% of them said they had learned about HIV/AIDS during their visits to local health facilities; this supports the fact that many people in Malawi have access to information about the epidemic, both through the radio and other sources.\n\nPersonal traits such as age, gender, location, and education correlate, either positively or negatively, with HIV/AIDS awareness levels. For example, older women have demonstrated higher levels of knowledge regarding HIV/AIDS than younger women in Malawi. Because men typically have greater access to education and other social resources, they are often more knowledgeable about HIV prevention and transmission than women. While men are, on average, able to list 2.2 ways to prevent HIV transmission, women are only able to list 1.5 ways. Only 38% of women surveyed in 2003-2004 understood that their husbands would be less likely to contract HIV if they used condoms during intercourse with prostitutes and other women from high-risk groups. In addition, men who are raised in urban environments are, on average, more informed about HIV/AIDS than men who are raised in rural environments, presumably because urban children typically have greater access to educational resources than rural children. Among both men and women, higher levels of education correspond to increased knowledge about HIV/AIDS: men and women who have received secondary school educations are significantly more likely to understand complex aspects of the disease, such as the fact that people who appear healthy can still be HIV-positive, than those who have not. Finally, people who have lost friends or family members to the disease are likely to have greater knowledge about HIV/AIDS due to their personal, firsthand exposure to the problem.\n\nThe aforementioned study by Barden-O'Fallon et al., which surveyed 940 women and 661 men, indicated that, despite their knowledge and awareness, many people in Malawi do not feel personally susceptible to HIV infection. On average, only 23% of the adults who were surveyed during this study, both male and female, believed that they were likely to contract HIV and die of AIDS. Greater HIV/AIDS awareness among men does not seem to correspond with increased perceived risk; on the other hand, increased levels of knowledge about HIV/AIDS do correlate positively to perceived risk among women. Another study conducted in rural Malawi between 1998 and 2001 by Kirsten P. Smith et al. indicated that concerns about personal vulnerability to HIV/AIDS declined during this four-year time frame, probably because the increased use of preventative strategies gave people a sense of control. In fact, many participants in this study claimed that they were \"not at all worried\" about HIV/AIDS; unless they had simply adopted a fatalistic standpoint towards the epidemic, these respondents probably felt that they had successfully reduced their risk of exposure through personal behavioral changes.\n\nStudents in Malawi have expressed high levels of dissatisfaction regarding the HIV/AIDS-related education and support they receive at school. According to a survey of students in Malawi, most secondary students do not believe that the HIV/AIDS curricula at their schools provide them with an adequate understanding of the disease. Although the Malawian government and non-governmental organizations have conducted many campaigns to improve awareness about HIV/AIDS in schools, there is still a significant shortage of age-appropriate audio and visual educational materials relating to HIV/AIDS available to instructors, particularly in rural areas. In addition, most teachers cannot identify the students in their classes who have been personally affected by the epidemic, either through friends or relatives, which suggests that school-based support for HIV/AIDS is minimal. However, despite this lack of support, surveys indicate that children who have been affected by the epidemic do not usually experience HIV/AIDS-based discrimination at school.\n\nMost teachers are required to address HIV/AIDS in their curricula; although instructors are, for the most part, committed to helping their students understand and avoid the disease, they face many obstacles that prevent them from informing their students about HIV/AIDS in productive ways. For example, some teachers cannot advise their students to remain faithful to their sexual partners without seeming hypocritical because they engage in extramarital sexual relations themselves. Others feel uncomfortable discussing sexual matters with their students, and some believe that, due to their limited training, they are not knowledgeable enough about HIV/AIDS to direct classroom discussions about the disease. In addition, many teachers feel unsupported by community members, who often either deny the extent of the epidemic or believe that HIV/AIDS should not be addressed in the classroom.\n\nAlthough the HIV/AIDS epidemic has affected men, women, and children in Malawi, certain factors such as sexual orientation, gender, and age influence infection patterns. In Malawi, HIV/AIDS is usually transmitted through heterosexual sex, but the epidemic has also significantly impacted the homosexual male population in Malawi. In addition, women in Malawi are more likely to be HIV-positive than men, suggesting that women are particularly vulnerable to HIV/AIDS. Finally, the disease has affected children and young adults both directly and indirectly; 170,000 Malawian children were HIV-positive in 2011, and the number of orphans in Malawi has increased dramatically since the epidemic began in 1985.\n\nDue to the vast scope of the HIV/AIDS epidemic, many Malawian men believe that HIV contraction and death from AIDS are inevitable. Older men in particular often claim that the HIV/AIDS epidemic is a punishment issued by God or other supernatural forces. Other men refer to their own irresponsible sexual behaviors when explaining why they believe that death from AIDS is inevitable. These men sometimes claim that unprotected sex is natural (and therefore necessary and good) when justifying their lack of condom use during sex with extramarital partners. Finally, some men identify as HIV-positive without having undergone testing for HIV, preferring to believe that they have already been infected so they can avoid adopting undesirable preventative measures such as condom use or strict fidelity. Because of these fatalistic beliefs, many men continue engaging in extramarital sexual relations despite the prevalence of HIV/AIDS in Malawi.\n\nHowever, despite these widespread feelings of fatalism, some men believe that they can avoid HIV contraction by modifying their personal behaviors. Men who decide to change their behaviors to reduce their risk of infection are unlikely to use condoms consistently, particularly during marital intercourse; instead, they usually continue engaging in extramarital sexual relations, but alter the ways in which they choose their sexual partners. For example, before selecting extramarital sexual partners, men sometimes survey their peers to determine whether their potential partners are likely to have exposed themselves to the virus. Men who choose their sexual partners based on external appearances and peer recommendations often believe that women who violate traditional gender norms by, for example, wearing modern clothing are more likely to carry HIV, while young girls, who are perceived as sexually inexperienced, are considered \"pure.\" Because of this perception, many people are concerned that schoolchildren in Malawi, particularly girls, are becoming exposed to the virus through sexual harassment or abuse by their instructors.\n\nAccording to traditional gender roles in Malawi, men operate primarily in the formal work sector and are responsible for supporting their families through paid labor, whereas women, who are valued for their domestic skills, are responsible for agricultural labor and care work; this gender-based division of labor decreases women's autonomy, thereby increasing their vulnerability to HIV/AIDS. Even within the home, women often lack bargaining power because they have limited access to education, formal employment, and other resources that could give them a sense of financial and personal independence. Women who are able to work in the formal sector typically earn significantly less money than men, even when they are completing the same tasks, making it difficult for them to elevate their status.\n\nMany women are convinced that their husbands are putting their lives at risk by engaging in extramarital sexual relations without using protection; however, because of their secondary status, they are often unwilling to initiate discussions about HIV/AIDS in the home. Most women in Malawi do not view divorce as a viable option, even when their husbands are HIV-positive and refuse to protect them from the virus by wearing condoms during marital intercourse. Because they lack the education and training needed to seek gainful employment, women are not usually able to support themselves and their children outside of marriage without resorting to commercial sex work for money.\n\nHowever, despite their vulnerability, some women in rural Malawi believe that they do, to a certain extent, have control over their own health and well-being. They tell their husbands that the HIV/AIDS epidemic has made sexual infidelity extremely dangerous and encourage them to refrain from engaging in extramarital sexual contact. In addition, many women are convinced that, by appealing to the vulnerability of their children (who will probably be orphaned if their parents contract HIV), they can convince their husbands to use condoms consistently during extramarital sexual encounters. Other women seek support from their friends and family members when they believe that their husbands' unsafe behaviors are putting their lives at risk. Finally, as a last resort, women might warn their husbands that they will visit the \"ankhoswe\", or traditional marriage counselor, and demand divorce if their husbands refuse to remain faithful and actively prevent the transmission of the disease.\n\nThe number of orphaned children in Malawi has increased dramatically since the HIV/AIDS epidemic began in 1985, with certain surveys indicating that more than 35% of schoolchildren have experienced the death of at least one parent due to HIV/AIDS. Because HIV is transmitted sexually, married couples who engage in unprotected sexual relations put their children at increased risk of becoming double orphans, or children who have lost both parents to HIV/AIDS. Older children who have lost both parents to HIV/AIDS often become responsible for the care of their younger siblings, and many double orphans drop out of school or migrate to urban areas to try to support themselves and their siblings. Girls who have been orphaned by HIV/AIDS have unusually high rates of school absenteeism in Malawi.\n\nWhen parents die of HIV/AIDS, extended family members usually become the children's primary caregivers: in Malawi, 44% of double orphans are adopted by grandparents or other close relatives. Extended family members often provide crucial support to HIV/AIDS orphans; however, some sources indicate that extended family members mistreat orphans whose parents have died from HIV/AIDS. For example, family members who are unable to support adopted children often arrange early marriages for female orphans, who may then become victims of domestic violence and sexual abuse.\n\nEvidence suggests that schoolchildren in Malawi are at risk of being exposed to HIV by their teachers, who sometimes value them as sexual partners because they believe that children have not yet been exposed to the virus. Children are particularly vulnerable to exploitation by adults who offer them money in exchange for sex; because they are often unable to afford basic necessities, they might feel compelled to accept gifts in exchange for sex out of desperation. Interviews indicate that teachers and school administrators in Malawi often misinterpret the definition of sexual assault, as some believe that sexual relations between teachers and students are appropriate as long as the children have consented. Although most schools have strict policies against sexual abuse, children are often hesitant to accuse adults of wrongdoing, and many administrators are unwilling or unable to investigate the truth behind the accusations.\n\nAlthough couples are starting to use condoms during extramarital intercourse more frequently, condom use during marital sex is still viewed as inappropriate by many Malawians; in 2000, only 2.3% of people reported using condoms regularly during sexual intercourse with their spouses. Some people believe that condoms are only necessary during sex with high-risk partners such as sex workers, and that condom use during marital sex implies infidelity. Others believe that marital condom use violates the religious purposes of marriage: sexual pleasure and reproduction. In a study published in 2007 by Agnes M. Chimbiri, men claimed that they use condoms with their wives for the sake of avoiding unwanted pregnancies; on the other hand, they were more concerned about sexually transmitted infections when discussing condom use with extramarital sexual partners.\n\nMany different sources of information can motivate discussion about HIV/AIDS among married couples. After hearing information about HIV/AIDS at local health facilities or during conversations with friends or family members, people are more likely to address the risk of HIV contraction with their spouses. In addition, women are more likely than men to mention the dangers of HIV/AIDS when they suspect that their spouses are engaging in extramarital sexual relations. According to a 2003 study by Eliya Msiyaphazi Zulu and Gloria Chepngeno, although higher levels of education do correspond to greater knowledge about HIV/AIDS, education levels do not significantly impact the likelihood that couples will discuss HIV-related prevention strategies.\n\nA 2002 study conducted by CARE International across three districts in the Central Region of Malawi considers how HIV/AIDS has affected economic well-being in rural Malawi. When skilled laborers are infected with HIV, they are usually unable to work; therefore, they often shift agricultural production on their land to less labor-intensive crops, sacrificing the opportunity to grow more profitable, labor-intensive crops such as tobacco. When family members fall ill with HIV/AIDS, their relatives invest time in their treatment and care, further reducing household productivity. In addition, when family members are infected with HIV, households often use the money they would normally invest in agriculture to cover medical expenses, further decreasing economic stability at the household level. Finally, when adults contract HIV, their children often remain home from school to work in the fields, threatening long-term productivity and economic advancement in Malawi.\n\nCARE International proposes several strategies that might reduce the destructive economic impact of HIV/AIDS on rural households. They recommend introducing new technologies that improve productivity to allow households affected by HIV/AIDS to continue supporting themselves through agriculture. Women in patrilineal/patrilocal villages are often unable to support themselves and their children when their husbands die of HIV/AIDS; therefore, helping women acquire traditionally masculine agricultural skills might decrease their vulnerability while improving agricultural productivity at the household and community levels. CARE International recommends increasing cooperation at the community level by establishing labor and food banks in areas that have been devastated by the HIV/AIDS epidemic. Finally, CARE International highlights the importance of increasing access to information about HIV/AIDS in Malawi to help families prepare for and cope with the economic burdens associated with the epidemic.\n\nThe HIV/AIDS epidemic in Malawi has been characterized by drastic declines in the number of health workers available to provide treatment and care and increasing strain on health services: more than half of all hospital admissions in Malawi are related to HIV/AIDS. However, Malawi currently faces a significant deficit in human resources: only 159 doctors were practicing in Malawi in 2007. The World Health Organization's Essential Health Package recommends placing at least three health workers at every health facility in the country, but the vast majority of Malawi's health facilities fail to meet this standard.\n\nWhile migration to more developed countries in search of better opportunities, also known as \"brain drain,\" is partially responsible for the shortage of health care workers in Malawi, many health care workers have been personally affected by the HIV/AIDS epidemic; in fact, an average of 48 nurses die of HIV/AIDS in Malawi every year. The HIV/AIDS epidemic has resulted in high levels of absenteeism among health workers in Malawi, who often leave work to spend time with HIV-positive friends or relatives, and the Malawian government has failed to respond to the declining number of full-time employees working in the health sector. Health workers who are not chronically absent frequently abandon their jobs because they are unable to cope with the heavy patient loads or because they are afraid that working in a medical environment will increase their risk of becoming infected with HIV.\n\nMalawi has adopted task shifting strategies to overcome the shortage of workers available for HIV/AIDS treatment and care. Task shifting, which has been successful in many other regions, involves training less specialized health workers to perform health-related tasks that do not require professional training, such as the initiation of antiretroviral therapy. For example, at Thyolo District Hospital, health workers spend one week learning how to initiate antiretroviral therapy in a classroom setting and an additional two weeks practicing their knowledge in a supervised clinical setting; after completing this course, they are legally (under Ministry of Health guidelines) allowed to initiate antiretroviral therapy. Another form of task shifting involves training health-oriented counselors in HIV testing and counseling, which relieves nurses of this additional task.\n\nMalawi has taken many steps towards slowing the spread of HIV/AIDS, such as increasing access to condoms and improving testing services and treatment options. Many of these efforts have been funded by international donors including the World Bank, the Global Fund, the World Health Organization, the President's Emergency Plan for AIDS Relief (PEPFAR), and the Joint United Nations Programme on HIV and AIDS (UNAIDS). The World Bank has lent $407.9 million to Malawi, the Global Fund has agreed to give $390 million, and PEPFAR has donated $25 million for prevention and treatment campaigns.\n\nThe number of people using antiretroviral therapy in Malawi has increased dramatically in the past decade: between 2004 and 2011, an estimated 300,000 people gained access to antiretroviral treatment. In addition to improving access to antiretroviral therapy, in 2008, Malawi introduced the World Health Organization's treatment guidelines for antiretroviral therapy, which improved the quality of treatment available to Malawians. However, Malawi's proposal for a new antiretroviral treatment plan in 2011, which would have cost $105 million per year, was rejected by the Global Fund, threatening Malawi's ability to continue expanding access to antiretroviral treatment.\n\nIn 2000, Malawi's Ministry of Health and Population began developing a plan to distribute antiretroviral drugs to the population, and, as of 2003, there were several sites providing antiretroviral drugs in Malawi. The Lighthouse, a trust in Lilongwe that fights HIV/AIDS, provides antiretroviral drugs at a cost of 2,500 kwacha per month. Queen Elizabeth Central Hospital in Blantyre provides antiretroviral therapy through its outpatient department, and Médecins Sans Frontières distributes antiretroviral drugs to patients for free in the Chiradzulu and Thyolo Districts. Many different private providers sell antiretroviral drugs, particularly in cities; however, very few patients can afford to receive drugs from the private sector in Malawi. In addition, private providers are not currently required to obtain certification before selling antiretroviral drugs, and, therefore, this practice is not closely monitored. Finally, some employees receive access to antiretroviral drugs through the health insurance policies provided by their employers, but this practice is not widespread.\n\nDue to the advent of antiretroviral drugs, HIV/AIDS has become a manageable disease for people who can access and afford treatment; however, antiretroviral therapy remains largely unaffordable and inaccessible to most people in Malawi. For example, the South East region of Malawi has disproportionately low access to antiretroviral drugs. In many rural areas, poor health infrastructure combined with widespread famine have made sustained, high-quality antiretroviral therapy difficult or impossible. In addition, donations from the Global Fund to Fight AIDS, Tuberculosis, and Malaria were used to fund antiretroviral therapy programs that distributed medication on a \"first-come, first-served\" basis, making the drugs more accessible to the male, urban, educated population. Because there are no explicit policies regarding the fair distribution of antiretroviral drugs in Malawi, individual health care workers often become responsible for deciding who will receive treatment, which inevitably leads to inequitable distribution.\n\nAlthough condoms effectively prevent the sexual transmission of HIV, several factors have limited widespread condom distribution and uptake in Malawi. People living in non-urban areas often have difficulty accessing condoms, and condoms are not typically available at bars and other social locations where they could have a significant impact on HIV prevention. Many people oppose condoms because they believe that condoms make sex less enjoyable or because they question their ability to prevent the transmission of HIV. However, despite these factors, many unmarried couples have started using condoms more consistently as concern and fear about the HIV/AIDS epidemic have increased.\n\nNon-governmental organizations such as Population Services International (Malawi), an organization that strives to improve the health of Malawians, and Banja La Mtsogolo, an organization that distributes information and resources related to family planning, have conducted campaigns advertising condom use as an effective form of protection against HIV/AIDS. Banja La Mtsogolo provides condoms to both men and women, and has significantly improved the availability of condoms for women in particular. Because of efforts by Population Services International, Banja La Mtsogolo, and many other organizations, condoms have become more widely available to many people in Malawi.\n\nPeople living in areas with high rates of HIV/AIDS face several psychological barriers when deciding whether to undergo testing for HIV. For example, people may prefer not to know if they are HIV-positive because, due to the obstacles they often face in gaining access to antiretroviral drugs, many view HIV/AIDS diagnoses as death sentences. Others may simply believe that they are HIV-negative, either because they practice strict monogamy and consistently use condoms during sexual intercourse or because they are in denial about the prevalence of the disease. However, despite these barriers, both mobile and static testing services have become more widely available in Malawi recently: 1,392 testing and counseling sites existed in 2011. Certain non-governmental organization such as the Malawi AIDS Counseling and Resource Organisation (MACRO) provide door-to-door counseling and testing services, which have drastically improved the accessibility of HIV testing.\n\n"}
{"id": "1346128", "url": "https://en.wikipedia.org/wiki?curid=1346128", "title": "Health risks from dead bodies", "text": "Health risks from dead bodies\n\nThe health risks of dead bodies are dangers related to the improper preparation and disposal of cadavers. While normal circumstances allow cadavers to be quickly embalmed, cremated, or buried, natural and man-made disasters can quickly overwhelm and/or interrupt the established protocols for dealing with the dead. Under such circumstances, the decomposition and putrefaction of cadavers goes unchecked, and raises a series of health, logistical, and psychological issues. After disasters with extensive loss of life due to trauma rather than disease—earthquakes, storms, human conflict, etc.—many resources are often expended on burying the dead quickly, and applying disinfectant to bodies for the specific purpose of preventing disease. Specialists say that spraying is a waste of disinfectant and manpower, that \"resources that should be going into establishment of water supply, sanitation, shelter, warmth and hygienic food for the survivors are being applied to digging mass graves\", and that \"Time and time again, eminent and authoritative experts have pointed out that dead bodies do not constitute a health hazard\".\n\nAccording to health professionals, the fear of spread of disease by bodies killed by trauma rather than disease is not justified. Among others, Steven Rottman, director of the UCLA Center for Public Health and Disasters, said that no scientific evidence exists that bodies of disaster victims increase the risk of epidemics, adding that cadavers posed less risk of contagion than living people. In disasters involving trauma where there is competition for resources, they should be going into establishment of water supply, sanitation, shelter, warmth and hygienic food for the survivors, not digging mass graves. Spraying is a waste of disinfectant and manpower. Indiscriminate burial of corpses demoralises survivors and the lack of death certificates can cause practical problems to survivors.\nOther considerations which are very important, but not directly relevant to the topic of health risks, include religious and cultural practices, the stench, and the effect on morale.\n\nThe incorrect notion that \"all\" dead bodies inherently cause diseases is consistent with:\n\nAccording to the Pan American Health Organization (PAHO) \"concern that dead bodies are infectious can be considered a 'natural' reaction by persons wanting to protect themselves from disease\" although \"the risk that bodies [of those killed in a natural disaster] pose for the public is extremely small\".\n\nContamination of water supplies by unburied bodies, burial sites, or temporary storage sites may result in the spread of gastroenteritis from normal intestinal contents.\nAccording to a PAHO article on the Infectious Disease Risks From Dead Bodies Following Natural Disasters: \n\nTo those in close contact with the dead, such as rescue workers, there is a health risk from chronic infectious diseases which those killed may have been suffering from and which spread by direct contact, including hepatitis B and hepatitis C, HIV, enteric intestinal pathogens, tuberculosis, cholera and others.\n\nThe substances cadaverine and putrescine are produced during the decomposition of animal (including human) bodies, and both give off a foul odor. They are toxic if massive doses are ingested (acute oral toxicity of 2 g per kg of body weight of pure putrescine in rats, a larger dose for cadaverine); there are no effects at all for a tenth of that dose. While figures for humans are not available, allometric scaling, which takes into account body surface area, is often used to compare doses in different animals, with useful results. Scaling 2g/kg from rats suggests that a 60 kg (132 lb) person would be significantly affected by of pure putrescine. For comparison the similar substance spermine, found in semen, is over 3 times as toxic.\n\n\n"}
{"id": "58839767", "url": "https://en.wikipedia.org/wiki?curid=58839767", "title": "List of rampage killers (China)", "text": "List of rampage killers (China)\n\nThis section of the list of rampage killers contains those cases that occurred in China.\n\nThis section does not include school massacres; workplace killings; religious, political, or racial crimes; or mass murders that took place primarily in a domestic environment, like familicides, which are covered in their own categories. Cases where the primary motive for the murders was to facilitate or cover up another felony, like robbery, are also excluded.\n\nA rampage killer has been defined as follows:\n\nThis list should contain every case with at least one of the following features:\n\nAll abbreviations used in the table are explained below.\n\nW – A basic description of the weapons used in the murders\n"}
{"id": "497424", "url": "https://en.wikipedia.org/wiki?curid=497424", "title": "List of types of malnutrition", "text": "List of types of malnutrition\n\nList of types of malnutrition or list of nutritional disorders include diseases that results from excessive or inadequate intake of food and nutrients. They come in two broad categories: undernutrition and overnutrition.\n\nObesity is caused by eating too many calories compared to the amount of exercise the individual is performing, causing a distorted energy balance. It can lead to diseases such as cardiovascular disease and diabetes. Obesity is a condition in which the natural energy reserve, stored in the fatty tissue of humans and other mammals, is increased to a point where it is associated with certain health conditions or increased mortality.\n\nThe low-cost food that is generally affordable to the poor in affluent nations is low in nutritional value and high in fats, sugars and additives. In rich countries, therefore, obesity is often a sign of poverty and malnutrition while in poorer countries obesity is more associated with wealth and good nutrition. Other non-nutritional causes for obesity included: sleep deprivation, stress, lack of exercise, and heredity.\n\nAcute overeating can also be a symptom of an eating disorder.\n\nGoitrogenic foods can cause goitres by interfering with iodine uptake.\n\nVitamin poisoning is the condition of overly high storage levels of vitamins, which can lead to toxic symptoms. The medical names of the different conditions are derived from the vitamin involved: an excess of vitamin A, for example, is called \"hypervitaminosis A\".\n\nIron overload disorders are diseases caused by the overaccumulation of iron in the body. Organs commonly affected are the liver, heart and endocrine glands in the mouth.\n\n\n"}
{"id": "2245783", "url": "https://en.wikipedia.org/wiki?curid=2245783", "title": "Medical research", "text": "Medical research\n\nBiomedical research (or experimental medicine) encompasses a wide array of research, extending from \"basic research\" (also called \"bench science\" or \"bench research\"), – involving fundamental scientific principles that may apply to a \"preclinical\" understanding – to clinical research, which involves studies of people who may be subjects in clinical trials. Within this spectrum is applied research, or translational research, conducted to expand knowledge in the field of medicine.\n\nBoth clinical and preclinical research phases exist in the pharmaceutical industry's drug development pipelines, where the clinical phase is denoted by the term \"clinical trial\". However, only part of the clinical or preclinical research is oriented towards a specific pharmaceutical purpose. The need for fundamental and mechanism-based understanding, diagnostics, medical devices, and non-pharmaceutical therapies means that pharmaceutical research is only a small part of medical research.\n\nThe increased longevity of humans over the past century can be significantly attributed to advances resulting from medical research. Among the major benefits of medical research have been vaccines for measles and polio, insulin treatment for diabetes, classes of antibiotics for treating a host of maladies, medication for high blood pressure, improved treatments for AIDS, statins and other treatments for atherosclerosis, new surgical techniques such as microsurgery, and increasingly successful treatments for cancer. New, beneficial tests and treatments are expected as a result of the Human Genome Project. Many challenges remain, however, including the appearance of antibiotic resistance and the obesity epidemic.\n\nMost of the research in the field is pursued by biomedical scientists, but significant contributions are made by other type of biologists. Medical research on humans, has to strictly follow the medical ethics sanctioned in the Declaration of Helsinki and hospital review board where the research is conducted. In all cases, research ethics are expected.\n\nExample areas in basic medical research include cellular and molecular biology, medical genetics, immunology, neuroscience, and psychology. Researchers, mainly in universities or government-funded research institutes, aim to establish an understanding of the cellular, molecular and physiological mechanisms of human health and disease.\n\nPreclinical research covers understanding of mechanisms that may lead to clinical research with people. Typically, the work requires no ethical approval, is supervised by scientists rather than physicians, and is carried out in a university or company, rather than a hospital.\n\nClinical research is carried out with people as the experimental subjects. It is generally supervised by physicians and conducted by nurses in a medical setting, such as a hospital or research clinic, and requires ethical approval.\n\nResearch funding in many countries derives from research bodies and private organizations which distribute money for equipment, salaries, and research expenses. In the United Kingdom, funding bodies such as the Medical Research Council derive their assets from UK tax payers, and distribute revenues to institutions by competitive research grants. The Wellcome Trust is the UK's largest non-governmental source of funds for biomedical research and provides over £600 million per year in grants to scientists and funds for research centres.\n\nIn the United States, data from ongoing surveys by the National Science Foundation (NSF) show that federal agencies provided only 44% of the $86 billion spent on basic research in 2015. The National Institutes of Health and pharmaceutical companies collectively contribute $26.4 billion and $27 billion, which constitute 28% and 29% of the total, respectively. Other significant contributors include biotechnology companies ($17.9 billion, 19% of total), medical device companies ($9.2 billion, 10% of total), other federal sources, and state and local governments. Foundations and charities, led by the Bill and Melinda Gates Foundation, contributed about 3% of the funding. These funders are attempting to maximize their return on investment in public health. One method proposed to maximize the return on investment in medicine is to fund the development of open source hardware for medical research and treatment. \n\nThe enactment of orphan drug legislation in some countries has increased funding available to develop drugs meant to treat rare conditions, resulting in breakthroughs that previously were uneconomical to pursue.\n\nSince the establishment of the National Institutes of Health (NIH) in the mid-1940s, the main source of U.S. federal support of biomedical research, investment priorities and levels of funding have fluctuated. From 1995 to 2010, NIH support of biomedical research increased from 11 billion to 27 billion Despite the jump in federal spending, advancements measured by citations to publications and the number of drugs passed by the FDA remained stagnant over the same time span. Financial projections indicate federal spending will remain constant in the near future.\n\nThe National Institutes of Health (NIH) is the agency that is responsible for management of the lion's share of federal funding of biomedical research. It funds over 280 areas directly related to health. Over the past century there were two notable periods of NIH support.\nFrom 1995 to 1996 funding increased from $8.877 billion to $9.366 billion, years which represented the start of what is considered the \"doubling period\" of rapid NIH support. The second notable period started in 1997 and ended in 2010, a period where the NIH moved to organize research spending for engagement with the scientific community.\n\nSince 1980 the share of biomedical research funding from industry sources has grown from 32% to 62%, which has resulted in the development of numerous life-saving medical advances. The relationship between industry and government-funded research in the US has seen great movement over the years. The 1980 Bayh Dole Act was passed by Congress to foster a more constructive relationship between the collaboration of government and industry funded biomedical research. The Bayh Doyle Act gave private corporations the option of applying for government funded grants for biomedical research which in turn allowed the private corporations to license the technology. Both government and industry research funding increased rapidly from between the years of 1994–2003; industry saw a compound average annual growth rate of 8.1% a year and slowed only slightly to a compound average annual growth rate of 5.8% from 2003 to 2008.\n\n\"Conflict of interest\" in the field of medical research has been defined as \"a set of conditions in which professional judgment concerning a primary interest (such as a person's welfare or the validity of research) tends to be unduly influenced by a secondary interest (such as financial gain).\"\n\nRegulation on industry funded biomedical research has seen great changes since Samuel Hopkins Adams declaration. In 1906 congress passed the Pure Food and Drugs Act of 1906. In 1912 Congress passed the Shirley Amendment to prohibit the wide dissemination of false information on pharmaceuticals. The Food and Drug Administration was formally created in 1930 under the McNarey Mapes Amendment to oversee the regulation of Food and Drugs in the United States. In 1962 the Kefauver-Harris Amendments to the Food, Drug and Cosmetics Act made it so that before a drug was marketed in the United States the FDA must first approve that the drug was safe. The Kefauver-Harris amendments also mandated that more stringent clinical trials must be performed before a drug is brought to the market. The Kefauver-Harris amendments were met with opposition from industry due to the requirement of lengthier clinical trial periods that would lessen the period of time in which the investor is able to see return on their money. In the pharmaceutical industry patents are typically granted for a 20-year period of time, and most patent applications are submitted during the early stages of the product development. According to Ariel Katz on average after a patent application is submitted it takes an additional 8 years before the FDA approves a drug for marketing. As such this would leave a company with only 12 years to market the drug to see a return on their investments. After a sharp decline of new drugs entering the US market following the 1962 Kefauver-Harris amendments economist Sam Petlzman concluded that cost of loss of innovation was greater than the savings recognized by consumers no longer purchasing ineffective drugs. In 1984 the Hatch-Waxman Act or the Drug Price Competition and Patent Term Restoration Act of 1984 was passed by congress. The Hatch-Waxman Act was passed with the idea that giving brand manufacturers the ability to extend their patent by an additional 5 years would create greater incentives for innovation and private sector funding for investment.\n\nThe relationship that exists with industry funded biomedical research is that of which industry is the financier for academic institutions which in turn employ scientific investigators to conduct research. A fear that exists wherein a project is funded by industry is that firms might negate informing the public of negative effects to better promote their product.\nA list of studies show that public fear of the conflicts of interest that exist when biomedical research is funded by industry can be considered valid after a 2003 publication of \"Scope and Impact of Financial Conflicts of Interest in Biomedical Research\" in The Journal of American Association of Medicine. This publication included 37 different studies that met specific criteria to determine whether or not an academic institution or scientific investigator funded by industry had engaged in behavior that could be deduced to be a conflict of interest in the field of biomedical research. Survey results from one study concluded that 43% of scientific investigators employed by a participating academic institution had received research related gifts and discretionary funds from industry sponsors. Another participating institution surveyed showed that 7.6% of investigators were financially tied to research sponsors, including paid speaking engagements (34%), consulting arrangements (33%), advisory board positions (32%) and equity (14%). A 1994 study concluded that 58% out of 210 life science companies indicated that investigators were required to withhold information pertaining to their research as to extend the life of the interested companies' patents. Rules and regulations regarding conflict of interest disclosures are being studied by experts in the biomedical research field to eliminate conflicts of interest that could possibly affect the outcomes of biomedical research.\n\nThe earliest narrative describing a medical trial is found in the Book of Daniel, which says that Babylonian king Nebuchadnezzar ordered youths of royal blood to eat only red meat and wine for three years, while another group of youths ate only beans and water. The experiment was intended to determine if a diet of vegetables and water was healthier than a diet of wine and red meat. At the experiment endpoint, the trial accomplished its prerogative: the youths who ate only beans and water were noticeably healthier. Scientific curiosity to understand health outcomes from varying treatments has been present for centuries, but it was not until the mid-19th century when an organizational platform was created to support and regulate this curiosity. In 1945, Vannevar Bush said that biomedical scientific research was \"the pacemaker of technological progress\", an idea which contributed to the initiative to found the National Institutes of Health (NIH) in 1948, a historical benchmark that marked the beginning of a near century substantial investment in biomedical research. The NIH provides more financial support for medical research that any other agency in the world to date and claims responsibility for numerous innovations that have improved global health. The historical funding of biomedical research has undergone many changes over the past century. Innovations such as the polio vaccine, antibiotics and antipsychotic agents, developed in the early years of the NIH lead to social and political support of the agency. Political initiatives in the early 1990s lead to a doubling of NIH funding, spurring an era of great scientific progress. There have been dramatic changes in the era since the turn of the 21st century to date; roughly around the start of the century, the cost of trials dramatically increased while the rate scientific discoveries did not keep pace.\n\nBiomedical research spending increased substantially faster than GDP growth over the past decade in the US, between the years of 2003 and 2007 spending increased 14% per year, while GDP growth increased 1% over the same period (both measures adjusted for inflation). Industry, not-for-profit entities, state and federal funding spending combined accounted for an increase in funding from $75.5 billion in 2003 to $101.1 billion in 2007. Due to the immediacy of federal financing priorities and stagnant corporate spending during the recession, biomedical research spending decreased 2% in real terms in 2008. Despite an overall increase of investment in biomedical research, there has been stagnation, and in some areas a marked decline in the number of drug and device approvals over the same time period.\n\nToday, industry sponsored research accounts for 58% of expenditures, NIH for 27% of expenditures, state governments for 5% of expenditures, non NIH-federal sources for 5% of expenditures and not-for-profit entities accounted for 4% of support. Federally funded biomedical research expenditures increased nominally, 0.7% (adjusted for inflation), from 2003 to 2007. Previous reports showed a stark contrast in federal investment, from 1994 to 2003, federal funding increased 100% (adjusted for inflation).\n\nThe NIH manages the lions-share, over 85%, of federal biomedical research expenditures. NIH support for biomedical research decreased from $31.8 billion in 2003, to $29.0 billion in 2007, a 25% decline (in real terms adjusted for inflation), while non-NIH federal funding allowed for the maintenance of government financial support levels through the era (the 0.7% four-year increase). Spending from industry-initiated research increased 25% (adjusted for inflation) over the same time period of time, from 2003 to 2007, an increase from $40 billion in 2003, to $58.6 billion in 2007. Industry sourced expenditures from 1994 to 2003 showed industry sponsored research funding increased 8.1%, a stark contrast to 25% increase in recent years.\n\nOf industry sponsored research, pharmaceutical firm spending was the greatest contributor from all industry sponsored biomedical research spending, but only increased 15% (adjusted for inflation) from 2003 to 2007, while device and biotechnology firms accounted for the majority of the spending. The stock performance, a measure that can be an indication of future firm growth or technological direction, has substantially increased for both predominantly medical device and biotechnology producers. Contributing factors to this growth are thought to be less rigorous FDA approval requirements for devices as opposed to drugs, lower cost of trials, lower pricing and profitability of products and predictable influence of new technology due to a limited number of competitors. Another visible shift during the era was a shift in focus to late stage research trials; formerly dispersed, since 1994 an increasingly large portion of industry-sponsored research was late phase trials rather than early-experimental phases now accounting for the majority of industry sponsored research. This shift is attributable to a lower risk investment and a shorter development to market schedule. The low risk preference is also reflected in the trend of large pharmaceutical firms acquiring smaller companies that hold patents to newly developed drug or device discoveries which have not yet passed federal regulation (large companies are mitigating their risk by purchasing technology created by smaller companies in early-phase high-risk studies). \nMedical research support from Universities increased from $22 billion in 2003 to $27.7 billion in 2007, a 7.8% increase (adjusted for inflation). In 2007 the most heavily funded institutions received 20% of HIN medical research funding, and the top 50 institutions received 58% of NIH medical research funding, the percent of funding allocated to the largest institutions is a trend which has increased only slightly over data from 1994. Relative to federal and private funding, health policy and service research accounted for a nominal amount of sponsored research; health policy and service research was funded $1.8 billion in 2003, which increased to $2.2 billion in 2008.\n\nStagnant rates of investment from the US government over the past decade, may be in part attributable to challenges that plague the field. To date only two-thirds of published drug trial findings have results that can be re-produced, which raises concerns from a US regulatory standpoint where great investment has been made in research ethics and standards, yet trial results remain inconsistent. Federal agencies have called upon greater regulation to address these problems; a spokesman from the National Institute of Neurological Disorders and Stroke, an agency of the NIH, stated that there is \"widespread poor reporting of experimental design in articles and grant applications, that animal research should follow a core set of research parameters, and that a concerted effort by all stakeholders is needed to disseminate best reporting practices and put them into practice\".\n\nTwo laws which are both still in effect, one passed in 2006 and the other in 2010, were instrumental in defining funding reporting standards for biomedical research, and defining for the first time reporting regulations that were previously not required. The 2006 Federal Funding Accountability and Transparency Act mandates that all entities receiving over $25,000 in federal funds must report annual spending reports, including disclosure of executive salaries. The 2010 amendment to the act mandates that progress reports be submitted along with financial reporting. Data from the federal mandate is managed and made publicly available on usaspending.gov. Aside from the main source, usaspending.gov, other reporting mechanisms exist: Data specifically on biomedical research funding from federal sources is made publicly available by the National Health Expenditure Accounts (NHEA), data on health services research, approximately 0.1% of federal funding on biomedical research, is available through the Coalition of Health Services Research, the Agency for Healthcare Research and Quality, the Centers for Disease Control and Prevention, the Centers for Medicare & Medicaid Services, and the Veterans Health Administration.\n\nCurrently there are not any funding reporting requirements for industry sponsored research, but there has been voluntary movement toward this goal. In 2014, major pharmaceutical stakeholders such as Roche and Johnson and Johnson have made financial information publicly available and Pharmaceutical Research and Manufacturers of America (PhRMA), the most prominent professional association for biomedical research companies, has recently begun to provide limited public funding reports.\n\nMedical research is very highly regulated. National regulatory authorities are appointed in almost every country worldwide to oversee and monitor medical research, such as for the development and distribution of new drugs. In the US the Food and Drug Administration oversees new drug development, in Europe the European Medicines Agency (see also EudraLex), and in Japan the Ministry of Health, Labour and Welfare (Japan). The World Medical Association develops the ethical standards for the medical profession, involved in medical research. The most fundamental of them is the Declaration of Helsinki. The International Conference on Harmonisation of Technical Requirements for Registration of Pharmaceuticals for Human Use (ICH) works on the creation of rules and guidelines for the development of new medication, such as the guidelines for Good Clinical Practice (GCP). All ideas of regulation are based on a country's ethical standards code. This is why treatment of a particular disease in one country may not be allowed, but is in another.\n\nA major flaw and vulnerability in biomedical research appears to be the hypercompetition for the resources and positions that are required to conduct science. The competition seems to suppress the creativity, cooperation, risk-taking, and original thinking required to make fundamental discoveries. Other consequences of today's highly pressured environment for research appear to be a substantial number of research publications whose results cannot be replicated, and perverse incentives in research funding that encourage grantee institutions to grow without making sufficient investments in their own faculty and facilities. Other risky trends include a decline in the share of key research grants going to younger scientists, as well as a steady rise in the age at which investigators receive their first funding.\n\nFields of biomedical research include:\n"}
{"id": "11644470", "url": "https://en.wikipedia.org/wiki?curid=11644470", "title": "Microinsurance", "text": "Microinsurance\n\nMicroinsurance is the protection of low-income people (those living on between approximately $1 and $4 per day( below $4)) against specific perils in exchange for regular premium payment proportionate to the likelihood and cost of the risks involved. This definition is exactly the same as one might use for regular insurance except for the clearly prescribed target market: low-income people. The target population typically consists of persons ignored by mainstream commercial and social insurance schemes, as well as persons who have not previously had access to appropriate insurance products.\n\nThe institutions or set of institutions implementing microinsurance are commonly referred to as a microinsurance scheme.\n\n\nInsurance functions on the concept of risk pooling, and likewise, regardless of its small unit size and its activities at the level of single communities, so does microinsurance. Microinsurance links multiple small units into larger structures, creating networks that enhance both insurance functions (through broader risk pools) and support structures for improved governance (i.e. training, data banks, research facilities, access to reinsurance etc.). This mechanism is conceived as an autonomous enterprise, independent of permanent external financial lifelines, and its main objective is to pool both risks and resources of whole groups for the purpose of providing financial protection to all members against the financial consequences of mutually determined risks.\n\nThe last definition therefore, includes the critical features of the previous three:\n\nMicroinsurance, like regular insurance, may be offered for a wide variety of risks. These include both health risks (illness, injury, or death) and property risks (damage or loss). A wide variety of microinsurance products exist to address these risks, including crop insurance, livestock/cattle insurance, insurance for theft or fire, health insurance, term life insurance, death insurance, disability insurance, insurance for natural disasters, etc.\n\nMicroinsurance has made a significant difference in countries like Mali, as Maxime Prud'Homme and Bakary Traoré describe in Innovations in Sikasso. Still, many countries face continuing challenges. Specifically in Bangladesh, micro health insurance schemes are having trouble with financial and institutional sustainability, Syed Abdul Hamid and Jinnat Ara describe, but things are improving. Progress in Bangladesh\n\nOne of the greatest challenge for microinsurance is the actual delivery to clients. Methods and models for doing so vary depending on the organization, institution, and provider involved. As Dubby Mahalanobis states, one must be thorough and careful when making policies, otherwise microinsurance could do more harm than good. Tricky challenges In general, there are four main methods for offering microinsurance the partner-agent model, the provider-driven model, the full-service model, and the community-based model. Each of these models has their own advantages and disadvantages.\n\n\nA microinsurance scheme is a scheme that uses, among others, an insurance mechanism whose beneficiaries are (at least in part) people excluded from formal social protection schemes, particularly, informal economy workers and their families. The scheme differs from others created to provide legal social protection to formal economy workers. Membership is not compulsory (but can be automatic), and members pay, at least in part, the necessary contributions in order to cover benefits.\n\nThe expression \"microinsurance scheme\" designates either the institution that provides insurance (e.g., a health mutual benefit association) or the set of institutions (in the case of linkages) that provide insurance or the insurance service itself provided by an institution that also handles other activities (e.g., a micro-finance institution).\n\nThe use of the mechanism of insurance implies:\n\nMicroinsurance schemes may cover various risks (health, life, etc.); the most frequent microinsurance products are: \n\nDirk Reinhard provides a good list summarising reading pertinent to microinsurance. Small means, massive impact\n\nMicroinsurance is recognized as a useful tool in economic development. As many low-income people do not have access to adequate risk-management tools, they are vulnerable to fall back into poverty in times of hardship, for example when the breadwinner of the family dies, or when high hospital bills force families to take out loans with high interest rates. Furthermore, microinsurance makes it possible for people to take more risks. When farmers are insured against a bad harvest (resulting from drought), they are in a better position to grow crops which give high yields in good years, and bad yields in year of drought. Without the insurance, however, they will be inclined to do the opposite; since they have to safeguard a minimal level of income for themselves and their families, crops will be grown which are more drought resistant, but which have a much lower yield in good weather conditions.\n\n\n"}
{"id": "37992999", "url": "https://en.wikipedia.org/wiki?curid=37992999", "title": "Ministry of Health (Czech Republic)", "text": "Ministry of Health (Czech Republic)\n\nThe Ministry of Health of the Czech Republic () is a government ministry of the Czech Republic.\n"}
{"id": "150389", "url": "https://en.wikipedia.org/wiki?curid=150389", "title": "Nipple", "text": "Nipple\n\nThe nipple is a raised region of tissue on the surface of the breast from which, in females, milk leaves the breast through the lactiferous ducts to feed an infant. The milk can flow through the nipple passively or it can be ejected by smooth muscle contractions that occur along the ductal system. The nipple is surrounded by the areola which is often a darker color than the surrounding skin. It is often called a teat when referring to non-humans. Teat can also be used to describe the flexible mouthpiece of a baby bottle. In humans, nipples of both males and females can be stimulated as part of sexual arousal. In many cultures, human female nipples are sexualized, or \"...regarded as sex objects and evaluated in terms of their physical characteristics and sexiness.\"\n\nIn mammals, a nipple (also called mammary papilla or teat) is a small projection of skin containing the outlets for 15–20 lactiferous ducts arranged cylindrically around the tip. Marsupials and eutherian mammals typically have an even number of nipples arranged bilaterally, from as few as two to as many as 19.\n\nThe skin of the nipple is rich in a supply of special nerves that are sensitive to certain stimuli: these are slowly-adapting and rapidly-adapting cutaneous mechanoreceptors. Mechanoreceptors are identified respectively by Type I slowly-adapting with multiple Merkel corpuscle end-organs and Type II slowly-adapting with single Ruffini corpuscle end-organs, as well as Type I rapidly-adapting with multiple Meissner corpuscle end-organs and Type II rapidly-adapting with single Pacinian corpuscle end-organs. The dominant nerve supply to the nipple comes from the lateral cutaneous branches of fourth intercostal nerve. The nipple is also used as an anatomical landmark. It marks the T4 (fourth thoracic vertebra) dermatome and rests over the approximate level of the diaphram.\n\nThe arterial supply to the nipple and breast originates from the anterior intercostal branches of the internal thoracic (mammary) arteries; lateral thoracic artery; and thoracodorsal arteries. The venous vessels parallel the arteries. The lymphatic ducts that drain the nipple are the same for the breast. The axillary nodes are the apical axillary nodes, the lateral group and the anterior group. 75% of the lymph is drained through the axillary lymph nodes located near the armpit. The rest of the drainage leaves the nipple and breast through infroclavicular, pectoral, or parasternal nodes.\n\nSince nipples change throughout the life span in men and women, the anatomy of the nipple can change and this change may be expected and considered normal.\n\nAlmost all mammals have nipples. Why males have nipples has been the subject of scientific research. Differences among the sexes (called sexual dimorphism) within a given species are considered by evolutionary biologists to be mostly the result of sexual selection, directly or indirectly. For traits where there is no difference among the sexes, evolutionary biologists assume that there has been no advantage to one of the sexes losing the trait.\n\nThe physiological purpose of nipples is to deliver milk to the infant, produced in the female mammary glands during lactation. During breastfeeding, nipple stimulation by an infant will simulate the release of oxytocin from the hypothalamus. Oxytocin is a hormone that increases during pregnancy and acts on the breast to help produce the milk-ejection reflex. Oxytocin release from the nipple stimulation of the infant causes the uterus to contract even after childbirth. The strong uterine contractions that are caused by the stimulation of the mother's nipples help the uterus contract to clamp down the uterine arteries. These contractions are necessary to prevent post-partum hemorrhage.\n\nWhen the baby suckles or stimulates the nipple, oxytocin levels rise and small muscles in the breast contract and move the milk through the milk ducts. The result of nipple stimulation by the newborn helps to move breast milk out through the ducts and to the nipple. This contraction of milk is called the “let-down reflex.” Latching on refers to the baby fastening onto the nipple to breastfeeding. A good attachment is when the bottom of the areola (the area around the nipple) is in the baby's mouth and the nipple is drawn back inside his or her mouth. A poor latch results in insufficient nipple stimulation to create the let down reflex. The nipple is poorly stimulated when the baby latches on too close to the tip of the nipple. This poor attachment can cause sore and cracked nipples and a reluctance of the mother to continue to breastfeed. After the birth of the infant, the milk supply increases based upon the continuous and increasing stimulation of the nipple by the infant. If the baby increases nursing time at the nipple, the mammary glands respond to this stimulation by increasing milk production.\n\nNipple pain can be a disincentive for breastfeeding. Sore nipples that progress to cracked nipples is of concern since many woman cease breastfeeding due to the pain. In some instances an ulcer will form on the nipple. One reason for the development of cracked and sore nipples is the incorrect latching-on of the infant to the nipple. If a nipple appears to be wedge-shaped, white and flattened, this may indicates that the attachment of the infant is not good and there is a potential of developing cracked nipples. Herpes infection of the nipple is painful. Nipple pain can also be caused by excessive friction of clothing against the nipple that causes a fissure.\n\nNipple discharge refers to any fluid that seeps out of the nipple of the breast. Discharge from the nipple does not occur in lactating women. And discharge in non-pregnant women or women who are not breasfeeding may not cause concern. Men that have discharge from their nipples are not typical. Discharge from the nipples of men or boys may indicate a problem. Discharge from the nipples can appear without squeezing or may only be noticeable if the nipples are squeezed. One nipple can have discharge while the other does not. The discharge can be clear, green, bloody, brown or straw-colored. The consistency ct can be thick, thin, sticky or watery.\n\nSome cases of nipple discharge will clear on their own without treatment. Nipple discharge is most often not cancer (benign), but rarely, it can be a sign of breast cancer. It is important to find out what is causing it and to get treatment. Here are some reasons for nipple discharge:\n\n\nSometimes, babies can have nipple discharge. This is caused by hormones from the mother before birth. It usually goes away in 2 weeks. Cancers such as Paget disease (a rare type of cancer involving the skin of the nipple) can also cause nipple discharge.\n\nNipple discharge that is not normal is bloody, comes from only one nipple, or comes out on its own without squeezing or touching the nipple. Nipple discharge is more likely to be normal if it comes out of both nipples or happens when the nipple is squeezed your nipples. Squeezing the nipple to check for discharge can make it worse. Leaving the nipple alone may make the discharge stop.\n\nAny nipple discharge in a male usually is of more concern. Most of the time a mammogram and an examination of the fluid is done. Oftentimes a biopsy is performed A fine needle aspiration (FNA) biopsy can be fast and least painful. A very thin, hollow needle and slight suction will be used to remove a small sample from under the nipple. Using a local anesthetic to numb the skin may not be necessary since a thin needle is used for the biopsy. Receiving an injection to prevent pain from the biopsy may be more painful than the biopsy itself.\n\nSome genetically-males develop a condition known as gynecomastia, in which the breast tissue under the nipple develops and grows. Discharge from the nipple can occur. The nipple may swell in some genetically-males possibly due to increased levels of estrogen.\n\nChanges in appearance may be normal or related to disease.\nThe average projection and size of human female nipples is slightly more than .\n\nSymptoms of breast cancer can often be seen first by changes of the nipple and areola, although not all women have the same symptoms, and some people do not have any signs or symptoms at all. A person may find out they have breast cancer after a routine mammogram.\nWarning signs can be:\n\n\nChanges in the nipple are not necessarily symptoms or signs of breast cancer. Other conditions of the nipple can mimic the signs and symptoms of breast cancer.\n\nSome infections are transmitted through the nipple, especially if irritation or injury to the nipple has occurred. In these circumstances, the nipple itself can become infected with Candida that is present in the mouth of the breastfeeding infant. The infant will transmit the infection to the mother. Most of the time, this infection is localized to the area of the nipple. In some cases the infection can can progress to become a full-blown case of mastitis or breast infection. In some cases, if the mother has an infection with no nipple cracks or ulcerations, it is still safe to breastfeed the infant.\n\nHerpes infection of the nipple can go unnoticed because the lesions are small but usually are quite painful. Herpes in the newborn is a serious and sometimes fatal infection. Transmission of Hepatitis C and B to the infant can occur if the nipples are cracked.\n\nOther infections can be transmitted through a break of the skin of the nipple and can infect the infant.\n\nA nipple-sparing/subcutaneous mastectomy is a surgical procedure where breast tissue is removed, but the nipple and areola is preserved. This procedure was historically done only prophylactically or with mastectomy for benign disease over fear of increased cancer development in retained areolar ductal tissue. Recent series suggest that it may be an oncologically sound procedure for tumors not in the subareolar position.\n\nThe culture tendency to hide the female nipple under clothing has existed in Western culture since the 1800s. As female nipples are often perceived an intimate part, covering them might originate as a Victorian taboo just as was riding side saddle. Exposing the entire breast and nipple is a form of protest for some and a crime for others. The exposure of nipples is usually considered immodest and in some instances is viewed as lewd or indecent behavior.\n\nA case in Erie, Pennsylvania concerning the exposure of breasts and nipple proceeded to the Supreme Court in the US. The Erie ordinance was regulating the nipple in public as an act that is committed when a person \"'... knowingly or intentionally, ... appears in a state of nudity commits Public Indecency.'\" Later in the statute, nudity is further described as an uncovered female nipple. But nipple exposure of a man was not regulated. A commentator expressed this opinion on the statute by noting: \"Ponder the significance of that. A man walks around bare-chested and the worst that happens is he won't get served in restaurants. But a woman who goes topless is legally in the same boat as if she'd had sex in public. That may seem crazy, but in the U.S. it's a permissible law. — Cecil Adams\"\nThe legality around the exposure of nipples are inconsistently regulated throughout the US. Some states do not allow the visualization of any part of the breast. Other jurisdictions prohibit any female chest anatomy by banning anatomical structures that lie below the top of the areola or nipple. Such is the case in West Virginia and Massachusetts. West Virginia's regulation is very specific and is not likely to be misinterpreted and states: \"[The] display of 'any portion of the cleavage of the human female breast exhibited by a dress, blouse, skirt, leotard, bathing suit, or other wearing apparel provided the areola is not exposed, in whole or in part.'\"\n\nInstagram has a 'no nipples' policy with exceptions: material that is not allowed includes \"...some photos of female nipples, but photos of post-mastectomy scarring and women actively breastfeeding are allowed. Nudity in photos of paintings and sculptures is OK, too\". Previously, Instagram had removed images of nursing mothers. Instagram removed images of Rihanna and had her account cancelled when she posted selfies with nipples. This was incentive for the Twitter campaign #FreeTheNipple. Another recent development is the Instagram page that invites users to post images of nipples from both sexes. The account called @genderless_nipples displays close ups of both the nipples of men and women for the purpose of spotlighting what may be inconsistency. Some contributors have found 'a way around' this policy. Facebook has also been struggling to define its nipple policy.\n\nFilmmaker Lina Esco made a film entitled \"Free The Nipple\", which is about \"...laws against female toplessness or restrictions on images of female, but not male, nipples\", which Esco states is an example of sexism in society.\n\nNipples can be sensitive to touch, and nipple stimulation can incite sexual arousal. Few women report experiencing orgasm from nipple stimulation. Before Komisaruk et al.'s functional magnetic resonance (fMRI) research on nipple stimulation in 2011, reports of women achieving orgasm from nipple stimulation relied solely on anecdotal evidence. Komisaruk's study was the first to map the female genitals onto the sensory portion of the brain; it indicates that sensation from the nipples travels to the same part of the brain as sensations from the vagina, clitoris and cervix, and that these reported orgasms are genital orgasms caused by nipple stimulation, and may be directly linked to the genital sensory cortex (\"the genital area of the brain\").\n\nSome companies and non-profit organisations have used the word \"nipple\" or images of nipples to draw attention to their product or cause.\n\nThe word \"nipple\" most likely originates as a diminutive of \"neb\", an Old English word meaning \"beak\", \"nose\", or \"face\", and which is of Germanic origin. The words \"teat\" and \"tit\" share a Germanic ancestor. The second of the two, tit, was inherited directly from Proto-Germanic, while the first entered English via Old French.\n\n"}
{"id": "56660677", "url": "https://en.wikipedia.org/wiki?curid=56660677", "title": "Pamela Enderby", "text": "Pamela Enderby\n\nPamela Enderby FRCSLT, MBE (born 1949) is a British Speech Therapist and Professor of Community Rehabilitation at the University of Sheffield.\n\nIn 1975 Enderby became Head of the Speech Therapy Department at Frenchay Hospital. In 1983 she gained her PhD from Bristol University Medical School. In 1986 she became Head of the Frenchay District Speech Therapy Services.\n\nEnderby was Chair and Vice President of the Royal College of Speech and Language Therapists, of which she is a Fellow, in 1993–1994 and President of the Society for Research and Rehabilitation from 1994 to 1996. She has led research programmes into various aspects of therapy, particularly related to models of delivery, and effectiveness and outcomes. She is currently non-executive Director of South Yorkshire Health Authority and chairperson of the Regional Older Peoples´ Task Force. She is on the editorial advisory board for the International Journal of Language & Communication Disorders.\n\nEnderby was awarded an Honorary Doctorate from the University of West England in December 2000 in recognition of her outstanding contribution to speech and language therapy and to rehabilitation research. In 1986 Enderby was awarded the Jacques Parisot Foundation Fellowship Award presented by the World Health Organization.\n\nEnderby was the lead claimant in a landmark legal case for equal pay in the NHS (see Enderby v Frenchay Health Authority). In 1986 she argued that her work and that of her colleagues, mostly women, was of equal value to clinical psychologists, who were predominantly men. Her employers said the difference in pay could be justified because the two groups bargain separately. This claim launched the second longest group action for equal pay for equal work since a 1985 claim by female canteen workers against British Coal. The case involved twenty-six court appearances (including at the European Court of Justice), 2,000 applicants and sixteen test cases.\n\nThe resulting compensation cost the government approximately £30 million in back-pay. The Enderby case led the then Labour government to institute a review of pay and grading scales throughout the health service in the form of the Agenda for Change.\n\n\n"}
{"id": "24754204", "url": "https://en.wikipedia.org/wiki?curid=24754204", "title": "Perineal tear", "text": "Perineal tear\n\nA perineal tear is a laceration of the skin and other soft tissue structures which, in women, separate the vagina from the anus. Perineal tears mainly occur in women as a result of vaginal childbirth, which strains the perineum. Tears vary widely in severity. The majority are superficial and require no treatment, but severe tears can cause significant bleeding, long-term pain or dysfunction. A perineal tear is distinct from an episiotomy, in which the perineum is intentionally incised to facilitate delivery.\n\nIn a woman, an anatomical area known as the perineum separates the opening of the vagina from that of the anus. Each opening is surrounded by a wall, and the anal wall is separated from the vaginal wall by a mass of soft tissue including:\n\n\nA perineal tear may involve some or all of these structures, which normally aid in supporting the pelvic organs and maintaining faecal continence.\n\nTears are classified into four categories:\n\n\nIn humans and some other primates, the head of the term fetus is so large in comparison to the size of the birth canal that delivery may result in some degree of trauma.\nAs the head passes through the pelvis, the soft tissues are stretched and compressed. The risk of severe tear is greatly increased if the fetal head is oriented occiput posterior (face forward), if the mother has not given birth before or if the fetus is large.\n\nSeveral techniques are used to reduce the risk of tearing, but with little evidence for efficacy. Antenatal digital perineal massage is often advocated, and may reduce the risk of trauma only in nulliparous women. ‘Hands on’ techniques employed by midwives, in which the foetal head is guided through the vagina at a controlled rate have been widely advocated, but their efficacy is unclear. Waterbirth and labouring in water are popular for several reasons, and it has been suggested that by softening the perineum they might reduce the rate of tearing. However, this effect has never been clearly demonstrated.\n\nA 2008 study found that over 85% of women having a vaginal birth sustain some form of perineal trauma, and 60-70% receive stitches. A retrospective study of 8,603 vaginal deliveries in 1994 found a third degree tear had been clinically diagnosed in only 50 women (0.6%). However, when the same authors used anal endosonography in a consecutive group of 202 deliveries, there was evidence of third degree tears in 35% of first-time mothers and 44% of mothers with previous children. These numbers are confirmed by other researchers in 1999.\n\nA study by the Agency for Healthcare Research and Quality (AHRQ) found that in 2011, first- and second-degree perineal tear was the most common complicating condition for vaginal deliveries in the U.S. among women covered by either private insurance or Medicaid. \nSecond-degree perineal laceration rates were higher for women covered by private insurance than for women covered by Medicaid.\n\nFirst and second degree tears rarely cause long-term problems. Among women who experience a third or fourth degree tear, 60-80% are asymptomatic after 12 months. Faecal incontinence, faecal urgency, chronic perineal pain and dyspareunia occur in a minority of patients, but may be permanent. The symptoms associated with perineal tear are not always due to the tear itself, since there are often other injuries, such as avulsion of pelvic floor muscles, that are not evident on examination.\n\nThere are claims that sometimes the perineum is excessively repaired after childbirth, using a so-called \"husband stitch\" and that this can increase vaginal tightness or result in pain during intercourse.\n"}
{"id": "25382638", "url": "https://en.wikipedia.org/wiki?curid=25382638", "title": "Pes anserine bursitis", "text": "Pes anserine bursitis\n\nPes anserine bursitis is an inflammatory condition of the medial (inner) knee at the anserine bursa, a sub muscular bursa, just below the pes anserinus. \n\nThe pes anserinus is the insertion of the conjoined tendons sartorius, gracilis, and semitendinosus into the anteromedial proximal tibia. Theoretically, bursitis results from stress to this area (e.g. stress may result when an obese individual with anatomic deformity from arthritis ascends or descends stairs). An occurrence of pes anserine bursitis commonly is characterized by pain, especially when climbing stairs, tenderness, and local swelling.\n\nThe etymology of the name relates to the insertion of the conjoined tendons into the anteromedial proximal tibia. From anterior to posterior, the pes anserinus is made up of the tendons of the sartorius, gracilis, and semitendinosus muscles. The tendon's name, which literally means \"goose's foot,\" was inspired by the pes anserinus's webbed, footlike structure. The conjoined tendon lies superficial to the tibial insertion of the medial collateral ligament (MCL) of the knee.\n\n\nPes anserine bursitis can be treated with a variety of physical therapy treatments, steroids to reduce inflammation, or surgery if necessary. Physical therapy treatments include therapeutic ultrasound, electrical stimulation (E-stim), rehabilitative exercises, and ice. Therapeutic ultrasound and E-stim deliver medication deep to the bursa to reduce inflammation. The rehabilitative exercises are done with the intention of stretching and strengthening the hip abductors, quadriceps, and hamstrings. These stretches have the potential to significantly reduce the tension over the pes anserine bursa.\n\n"}
{"id": "58470726", "url": "https://en.wikipedia.org/wiki?curid=58470726", "title": "Pharmacy management system", "text": "Pharmacy management system\n\nComputerized pharmacy management systems put patient profiles, medication, inventory, pricing, and other essential information within easy access for pharmacists and pharmacy technicians. The programs automate elements such as label printing, inventory management, stock reordering and billing. As a result, pharmacies are more time-efficient, and dispense more prescriptions and information while ensuring the safe and effective use of pharmaceutical drugs. Pharmacy computer software is usually purchased ready made or provided by a drug wholesaler as part of their service. Various pharmacy software operating systems are used throughout the many practice settings of pharmacy across the world.\n\n"}
{"id": "27702479", "url": "https://en.wikipedia.org/wiki?curid=27702479", "title": "Pizza effect", "text": "Pizza effect\n\nThe pizza effect is a term used especially in religious studies and sociology for the phenomenon of elements of a nation or people's culture being transformed or at least more fully embraced elsewhere, then re-imported back to their culture of origin, or the way in which a community's self-understanding is influenced by (or imposed by, or imported from) foreign sources. It is named after the idea that modern pizza toppings were developed among Italian immigrants in the United States (rather than in native Italy, where in its simpler form it was originally looked down upon), and was later exported back to Italy to be interpreted as a delicacy in Italian cuisine.\n\nRelated phrases include \"hermeneutical feedback loop\", \"re-enculturation\", and \"self-orientalization\". The term \"pizza effect\" was coined by the Austrian-born Hindu monk and professor of Anthropology at Syracuse University, Agehananda Bharati in 1970.\n\nThe original examples given by Agehananda Bharati mostly had to do with popularity and status:\n\nAnalyst Mark Sedgwick wrote that Islamist terrorism, and specifically suicide bombing, can be seen as examples, beginning as isolated interpretations of the concept of shahid, or martyrdom, then being re-exported to the greater Muslim world.\n\nThe Day of the Dead parade in Mexico City was inspired by an event in the James Bond film \"Spectre\", which was fictional at the time of the film's production. \n\nThe founders of the Theosophical Society, Helena Blavatsky and Henry Steel Olcott, were influenced by Eastern religions, then placed their headquarters in Adyar, Chennai, from where they spread their views within India.\n\nSimilarly, Buddhist modernism or \"Protestant Buddhism\" was developed by Westerners, who according to scholar Stephen Jenkins, \"mistook it for an indigenous Sri Lankan product\", and they in turn influenced Sri Lankan Buddhist Anagarika Dharmapala, who, along with the Theosophical Society, was instrumental in spreading Buddhism in both India and the West.\n\nAccording to scholar Kim Knott, Mahatma Gandhi \"was not very interested in religion until he went to London to study law, where he studied the Bhagavad Gita in English in Sir Edwin Arnold's translation, and this deeply influenced his spiritual outlook.\"\n\nThe influence of translations by the British-based Pali Text Society on South Asian Buddhism.\n\nThe religious thought of Ibn Rushd (Averroes), which was taken up by 19th-century Europeans such as Ernest Renan, and thereby regained popularity during the Nahda, the Islamic renaissance.\n\nChicken tikka masala, a dish created in Britain, based on Indian cooking, which then became popular in India.\n\nTeppanyaki, a Western-influenced style created in Japan, popular in the U.S.\n\nSalsa music: the first salsa bands were mainly Puerto Ricans who moved to New York in the 1930s.\n\nHaoqiu zhuan, a Chinese novel. James St. André, author of \"Modern Translation Theory and Past Translation Practice: European Translations of the \"Haoqiu zhuan\"\", wrote that in China the novel was originally \"considered second-rate fiction and stood in danger of being completely forgotten with changes in literary taste in the early twentieth century.\" He stated that the fact there had been interest in translating the novel into English \"gave life and fame\" to \"Haoqiu zhuan\" and therefore affected its standing in China.\n\nScholar David Miller wrote that Westerners were responsible for \"…the renewed interest in the four Vedas and the Upanishads, as texts in themselves apart from the endless number of commentaries that have been written by Indians to interpret and to systematize the texts,\" and that due to this interest, \"Indian scholars have also served up that menu, often in a less appetizing way than their Western counterparts. In so doing they have missed the very life force or essence of Indian ethical traditions.\"\n\nScholar Jørn Borup wrote about an \"inverted pizza-effect\", when a society's modification of another culture gets further re-modified by that same society, such as European philosophers including Martin Heidegger \"appear to have been significantly inspired by Eastern thought - an Eastern thought itself presented through \"Protestant\" or \"Western\" eyes. This transformation is naturally not a unique phenomenon in religious studies, where interpretations, re-interpretations and inventions are seen as common characteristics of religion.\"\n\nStephen Jenkins noted that the feedback phenomenon could continue; in the case of pizza, he wrote that the return of pizza to Italy again influenced American cuisine: \"...pizza-loving American tourists, going to Italy in the millions, sought out authentic Italian pizza. Italians, responding to this demand, developed pizzerias to meet American expectations. Delighted with their discovery of \"authentic\" Italian pizza, Americans subsequently developed chains of \"authentic\" Italian brick-oven pizzerias. Hence, Americans met their own reflection in the other and were delighted.\"\n\nJim Douglas, familiar with Bharati's thesis, applied it to black blues originating in the United States before 1960. The music of Robert Johnson, Muddy Waters, etc. went over to England, where it was embraced by other musicians (especially white men playing electric guitar). Then, this re-packaged blues came back to the US presented by the Rolling Stones, Cream, Led Zeppelin, etc. in the late 1960s where it was embraced by baby boomers (who had never heard of Robert Johnson, etc.). Later, some of these American baby boomers discovered the roots of the British blues-rock in the recordings of the original American blues artists.\n\n"}
{"id": "7761770", "url": "https://en.wikipedia.org/wiki?curid=7761770", "title": "Prawle Point", "text": "Prawle Point\n\nPrawle Point (, \"lookout hill\") is a coastal headland in south Devon, England\n\nIt is the southernmost point of Devon.\n\nAccess is from the village of East Prawle along a single-track road, at the end of which a National Trust car park is present.\n\nAt the point itself, there are high cliffs.\n\nThe National Coastwatch Institution has a station at the point\n\nThe area around the point is a noted area for cirl bunting, a localised bird in Britain, while the area has also attracted many rare vagrant birds including Britain's second chestnut-sided warbler.\n\nThe point is included within the Prawle Point and Start Point Site of Special Scientific Interest.\n\nMany ships have been wrecked at Prawle Point, the most recent being in December, 1992, when the ship \"Demetrios\", formerly the \"Long Lin\" from China was being towed by a tug from Dunkirk to a Mediterranean scrapyard. During terrible gales in the English Channel, the tow broke and the \"Demetrios\" drifted helplessly. The ship struck the rocks at Prawle Point on 18 December, breaking her back in a few hours. The wreck attracted huge crowds for many weeks, and eventually a local salvage company cut up the ship and towed away the remains to Plymouth. However, the cost of scrapping the ship sent them into liquidation. Some remains were, however left over and are still visible today. \n\n"}
{"id": "1602257", "url": "https://en.wikipedia.org/wiki?curid=1602257", "title": "Presbycusis", "text": "Presbycusis\n\nPresbycusis (also spelled presbyacusis, from Greek \"presbys\" \"old\" + \"akousis\" \"hearing\"), or age-related hearing loss, is the cumulative effect of aging on hearing. It is a progressive and irreversible bilateral symmetrical age-related sensorineural hearing loss resulting from degeneration of the cochlea or associated structures of the inner ear or auditory nerves. The hearing loss is most marked at higher frequencies. Hearing loss that accumulates with age but is caused by factors other than normal aging (nosocusis and sociocusis) is not presbycusis, although differentiating the individual effects of distinct causes of hearing loss can be difficult.\n\nThe cause of presbycusis is a combination of genetics, cumulative environmental exposures and pathophysiological changes related to aging. At present there are no preventative measures known; treatment is by hearing aid or surgical implant.\n\nPresbycusis is the most common cause of hearing loss, afflicting one out of three persons by age 65, and one out of two by age 75. Presbycusis is the second most common illness next to arthritis in aged people.\n\nMany vertebrates such as fish, birds and amphibians do not suffer presbycusis in old age as they are able to regenerate their cochlear sensory cells, whereas mammals including humans have genetically lost this regenerative ability.\n\nPrimary symptoms:\nSecondary symptoms:\nUsually occurs after age 50, but deterioration in hearing has been found to start very early, from about the age of 18 years. The ISO standard 7029 shows expected threshold changes due purely to age for carefully screened populations (i.e. excluding those with ear disease, noise exposure etc.), based on a meta-analysis of published data. Age affects high frequencies more than low, and men more than women. One early consequence is that even young adults may lose the ability to hear very high frequency tones above 15 or 16 kHz. Despite this, age-related hearing loss may only become noticeable later in life. The effects of age can be exacerbated by exposure to environmental noise, whether at work or in leisure time (shooting, music, etc.). This is noise-induced hearing loss (NIHL) and is distinct from presbycusis. A second exacerbating factor is exposure to ototoxic drugs and chemicals.\n\nOver time, the detection of high-pitched sounds becomes more difficult, and speech perception is affected, particularly of sibilants and fricatives. Patients typically express a decreased ability to understand speech. Once the loss has progressed to the 2–4 kHz range, there is increased difficulty understanding consonants. Both ears tend to be affected. The impact of presbycusis on communication depends on both the severity of the condition and the communication partner.\n\nThe aging process has three distinct components: physiologic degeneration, extrinsic damage (nosocusis), and intrinsic damage (sociocusis). These factors are superimposed on a genetic substrate, and may be overshadowed by general age-related susceptibility to diseases and disorders.\n\nHearing loss is only weakly correlated with age. In preindustrial and non-industrial societies, persons retain their hearing into old age. In the Framingham cohort study, only 10% of the variability of hearing with age could be explained by age-related physiologic deterioration. Within family groups, heredity factors were dominant; across family groups, other, presumably sociocusis and nosocusis factors were dominant.\n\n\n\nNosocusis factors are those that can cause hearing loss, which are not noise-based and separate from pure presbycusis. They may include:\n\nHowever, a recent study found that diabetes, atherosclerosis and hypertension had no correlation to presbycusis, suggesting that these are nosocusis (acquired hearing loss) factors, not intrinsic factors.\nExamples of microscopic changes seen in this condition are hair cell degeneration of the cochlea and giant stereociliary degeneration.\n\nThere are four pathological phenotypes of presbycusis:\n\nIn addition there are two other types:\n\nThe shape of the audiogram categorizes abrupt high-frequency loss (sensory phenotype) or flat loss (strial phenotype).\n\nThe mainstay of SNHL is strial, with only about 5% of cases being sensory. This type of presbycusis is manifested by a low-frequency hearing loss, with unimpaired speech recognition.\n\nClassically, audiograms in neural presbycusis show a moderate downward slope into higher frequencies with a gradual worsening over time. A severe loss in speech discrimination is often described, out of proportion to the threshold loss, making amplification difficult due to poor comprehension.\n\nThe audiogram associated with sensory presbycusis is thought to show a sharply sloping high-frequency loss extending beyond the speech frequency range, and clinical evaluation reveals a slow, symmetric, and bilateral progression of hearing loss.\n\nHearing loss is classified as mild, moderate, severe or profound. Pure-tone audiometry for air conduction thresholds at 500, 1000 and 2000 Hz is traditionally used to classify the degree of hearing loss in each ear. Normal hearing thresholds are considered to be 25 dB sensitivity, though it has been proposed that this threshold is too high, and that 15 dB (about half as loud) is more typical. Mild hearing loss is thresholds of 25–45 dB; moderate hearing loss is thresholds of 45–65 dB; severe hearing loss is thresholds of 65–85 dB; and profound hearing loss thresholds are greater than 85 dB.\n\nTinnitus occurring in only one ear should prompt the clinician to initiate further evaluation for other etiologies. In addition, the presence of a pulse-synchronous rushing sound may require additional imaging to exclude vascular disorders.\n\nAn examination of the external ear canal and tympanic membrane performed by a medical doctor, otolaryngologist, or audiologist using an otoscope, a visual instrument inserted into the ear. This also allows some inspection of the middle ear through the translucent tympanic membrane.\n\nA test administered by a medical doctor, otolaryngologist or audiologist of the tympanic membrane and middle ear function using a tympanometer, an air-pressure/sound wave instrument inserted into the ear canal. The result is a tympanogram showing ear canal volume, middle ear pressure and eardrum compliance. Normal middle ear function (Type A tympanogram) with a hearing loss may suggest presbycusis. Type B and Type C tympanograms indicate an abnormality inside the ear and therefore may have an additional affect on the hearing.\n\nThis may include a blood or other sera test for inflammatory markers such as those for autoinflammatory diseases.\n\nA hearing test administered by a medical doctor, otolaryngologist (ENT) or audiologist including pure tone audiometry and speech recognition may be used to determine the extent and nature of hearing loss, and distinguish presbycusis from other kinds of hearing loss. Otoacoustic emissions and evoked response testing may be used to test for audio neuropathy. The diagnosis of a sensorineural pattern hearing loss is made through audiometry, which shows a significant hearing loss without the \"air-bone gap\" that is characteristic of conductive hearing disturbances. In other words, air conduction is equal to bone conduction. Persons with cochlear deficits fail otoacoustic emissions testing, while persons with 8th cranial nerve (vestibulocochlear nerve) deficits fail auditory brainstem response testing.\n\nAs part of differential diagnosis, an MRI scan may be done to check for vascular anomalies, tumors, and structural problems like enlarged mastoids. MRI and other types of scan cannot directly detect or measure age-related hearing loss.\n\nAt present, presbycusis, being primarily sensorineural in nature, cannot be prevented, ameliorated or cured. Treatment options fall into three categories: pharmacological, surgical and management.\n\n\nIn cases of severe or profound hearing loss, a surgical cochlear implant is possible. This is an electronic device that replaces the cochlea of the inner ear. Electrodes are typically inserted through the round window of the cochlea, into the fluid-filled scala tympani. They stimulate the peripheral axons of the primary auditory neurons, which then send information to the brain via the auditory nerve. The cochlea is tonotopically mapped in a spiral fashion, with lower frequencies localizing at the apex of the cochlea, and high frequencies at the base of the cochlea, near the oval and round windows. With age, comes a loss in distinction of frequencies, especially higher ones. The electrodes of the implant are designed to stimulate the array of nerve fibers that previously responded to different frequencies accurately. It is important to note that due to spatial constraints, the cochlear implant may not be inserted all the way into the cochlear apex. It provides a different kind of sound spectrum than natural hearing, but may enable the recipient to recognize speech and environmental sounds.\n\nThese are surgically implanted hearing aids inserted onto the middle ear. These aids work by directly vibrating the ossicles, and are cosmetically favorable due to their hidden nature.\n\n\nPharmacological treatment options are limited, and remain clinically unproven. Among these are the water-soluble coenzyme Q10 formulation, the prescription drug Tanakan, and combination antioxidant therapy.\n\n\n\nAbilities of young people to hear high frequency tones inaudible to those over 25 or so has led to the development of technologies to disperse groups of young people around shops (The Mosquito), and development of a cell phone ringtone, Teen Buzz, for students to use in school, that older people cannot hear. In September 2006 this technique was used to make a dance track called 'Buzzin'. The track had two melodies, one that everyone could hear and one that only younger people could hear.\nMany vertebrates such as fish, birds and amphibians do not suffer presbycusis in old age as they are able to regenerate their cochlear sensory cells, whereas mammals including humans have genetically lost this ability. A number of laboratories worldwide are conducting comparative studies of birds and mammals that aim to find the differences in regenerative capacity, with a view to developing new treatments for human hearing problems.\n\n"}
{"id": "25185070", "url": "https://en.wikipedia.org/wiki?curid=25185070", "title": "Pyrrolizidine alkaloidosis", "text": "Pyrrolizidine alkaloidosis\n\nPyrrolizidine alkaloidosis is a disease caused by chronic poisoning found in humans and other animals caused by ingesting poisonous plants which contain the natural chemical compounds known as pyrrolizidine alkaloids. Pyrrolizidine alkaloidosis can result in damage to the liver, kidneys, heart, brain, smooth muscles, lungs, DNA, lesions all over the body, and could be a potential cause of cancer. Pyrrolizidine alkaloidosis is known by many other names such as \"Pictow Disease\" in Canada and \"Winton Disease\" in New Zealand. Cereal crops and forage crops can sometimes become polluted with pyrrolizidine-containing seeds, resulting in the alkaloids contaminating flour and other foods, including milk from cows feeding on these plants.\n\nPyrrolizidine alkaloidosis is caused by the consumption of one or more of the 200 known plant species containing the toxic pyrrolizine alkaloids found all over the world today. Established as the most common source of this illness are plants such as ragwort (\"Senecio jacobaea\"), woolly groundsels (\"Senecio redellii\", \"Senecio longilobus\"), rattleweed (\"Crotalaria retusa\"), and seeds of yellow tarweed (\"Amsinckia intermedia\"). There are 30 known pyrrolizidine alkaloids that are hepatotoxic, meaning they cause injury to the liver. Although animals innately know to give these toxic plants a wide berth while grazing, in extreme drought conditions animals have been known to ingest them as a source of minimal protein. Animals can also be poisoned if the toxic plant material is in pellets, or harvested with grain.\n\nPyrrolizidine alkaloidosis poisoning in the United States has remained moderately rare among humans. The most common reports are the outcome of the misuse of medicinal home remedies, or the alkaloids are present in food and drink substances such as milk and honey when the animal carriers were exposed to the toxins. In other countries, mass human poisonings have occurred when cereal crops used were infected with seeds containing pyrrolizidine alkaloids.\n\nInfants and young children are most likely to acquire pyrrolizidine alkaloidosis because of their intrinsic nature to put everything they find into their mouths. However, anyone who consumes one of the mentioned toxic plants is susceptible to the disease.\n\nThe typical case of pyrrolizidine alkaloidosis toxicity ends in liver damage that ranges from severe to moderate, as well as damage to other organs. The longevity of the disease is wide ranging from 2 weeks to 2 years subsequent to when the poison was ingested. The patient's recovery results may be as diverse as the permanence. Some have recovered as if they were never affected by pyrrolizidine alkaloidosis poisoning if the damage to the liver was not too severe, and others have died from it.\n\nThe severity of pyrrolizidine alkaloidosis depends on how much of the poisonous plant was consumed in a height, age, and weight to the amount of substance ingested ratio. The only difference in the symptoms will be how prominent they are depending on the above ratio. Symptoms include:\n\nTo stop the spread and severity of pyrrolizidine alkaloidosis the first step is to remove the poisonous plant from the source. Once the plant has been removed, the alkaloids can be extracted with chloroform. However, ethyl acetate is a handy and less toxic substitute. Depending on the severity of the toxicity and how long the person has been exposed to the disease, there may be no means of treatment and fatality may occur.\n\nThe only known technique of prevention is to avoid ingesting the poisonous alkaloids. Some methods of control have been defoliation in areas in both Oregon and California. Also mass relocation efforts of moths, flea beetles and seed flies have been made in hopes that they will eat the toxic plants and help control the population of the plants. This manner of alkaloid control has been met with variable success. Because sheep and goats have such a high immunity to the toxicity of the alkaloids they are commonly used to graze on the plants to control them. However, this method has its risks unless sheep meant for early slaughter are used. Before hay cutting in the spring is the optimal time frame for annual herbicide applications which have also enhanced the destruction of the alkaloids.\n\n"}
{"id": "47006222", "url": "https://en.wikipedia.org/wiki?curid=47006222", "title": "Radhe Mohan", "text": "Radhe Mohan\n\nRadhe Mohan is a medical physicist who significantly advanced radiation treatment safety for oncology patients. He is a recipient of the ASTRO Gold Medal for outstanding contributions in the field of radiation oncology.\n\nDuring the 1970s, Dr. Mohan developed computer-aided systems for automated dosimetry and record-and-verify systems. Subsequently, in the 1980s and 1990s, he was a leader in researching newer methods of radiation treatments such as 3-D conformal radiation therapy, intensity modulation radiation therapy, and in the 2000s, proton therapy. His research activities include intensity-modulated radiotherapy, Monte Carlo techniques and image-guided radiotherapy. Dr. Mohan is the author or co-author of nearly 200 papers, book chapters and publications in proceedings of conferences. He has been the principal investigator, co-PI or co-investigator on numerous grants from the National Cancer Institute and research projects sponsored by industry.\n\nDr. Mohan was the Chairman of the Department of Radiation Physics at The University of Texas MD Anderson Cancer Center and is currently a principal investigator at MD Anderson researching the optimization of proton therapy.\n\nIn 1983, Dr. Mohan was part of the team at the computer services department of Memorial Sloan Kettering Cancer Center which helped the F.B.I. track down one of the earliest groups of computer hackers, The 414s.\nIn 1969, Dr. Mohan received his PhD in physics from Duke University. Prior to that he received BS and MS degrees in physics from Punjab University. Dr. Mohan was a 1965 recipient of a Fulbright Fellowship.\n\nIn addition to the ASTRO award, Dr. Mohan has received the AAPM Award for Lifetime Achievement in Medical Physics (2003), the Cormack Gold Medal from the Association of Medical Physicists in India (2004), and the Failla Award from the Radiological and Medical Physics Society of New York (2009).\n"}
{"id": "26242624", "url": "https://en.wikipedia.org/wiki?curid=26242624", "title": "Ronald Krauss", "text": "Ronald Krauss\n\nRonald M. Krauss is Director of Atherosclerosis Research at Children's Hospital Oakland Research Institute, Adjunct Professor of Medicine, UCSF, Adjunct Professor of Nutritional Sciences, University of California at Berkeley, and Guest Senior Scientist in the Genome Sciences Division of Lawrence Berkeley National Laboratory. He received his medical degree at Harvard Medical School.\n\nHe researches genetic, dietary, and hormonal effects on plasma lipoproteins and coronary disease risk.\n\n"}
{"id": "23244650", "url": "https://en.wikipedia.org/wiki?curid=23244650", "title": "Routine health outcomes measurement", "text": "Routine health outcomes measurement\n\nRoutine health outcomes measurement is the process of examining whether or not interventions are associated with change (for better or worse) in the patient's health status. This change can be directly measured (e.g. by rating scales used by the clinician or patient) or assumed by the use of proxy measurement (e.g. a blood test result). Interventions can be direct (e.g. medication) or indirect (e.g. change in the process of health care like integration care by different specialists).\nSome definitions of health outcomes measurement stipulate that the population or group has to be defined (different outcomes are expected for different people & conditions). A strong example is that of Australia’s New South Wales Health Department: health outcome is \n\n\"change in the health of an individual, group of people or population which is attributable to an intervention or series of interventions\"\n\nIn its purest form, measurement of health outcomes implies identifying the context (diagnosis, demographics etc.), measuring health status before an intervention is carried out, measuring the intervention, measuring health status again and then plausibly relating the change to the intervention.\n\nEvidence-based practice describes a healthcare system in which evidence from published studies, often mediated by systematic reviews or processed into medical guidelines is incorporated into clinical practice. The flow of information is one way; from research to practice. However many interventions by health systems and treatments by their staff have never been, or cannot easily be, subject to research study. Of the rest, quite a lot is from research that is graded as low quality. All health staff intervene in their patients on the basis of both information from research evidence and from their own experience. The latter is personal, subjective and strongly influenced by stark instances which may not be representative. However, when information on these interventions and their outcomes are collected systematically it becomes \"practice-based evidence\" and can complement that from academic research. To date, such initiatives have been largely confined to primary care and rheumatology. An example of practice-based evidence is found in the evaluation of a simple intervention like a medication. Efficacy is the degree with which it can improve patients in randomised controlled trials– the epitome of evidence-based practice. Effectiveness is the degree with which the same drug improves patients in the uncontrolled hurly-burly of everyday practice; data which are much more difficult to come by. Routine health outcomes measurement has the potential to provide such evidence.\n\nThe information required for practice-based evidence is of three sorts: context (e.g. case mix), intervention (treatment) and outcomes (change). Some mental health services are developing a practice-based evidence culture with the routine measurement of clinical outcomes and creating behavioral health outcomes management programs.\n\nAn early example of a routine clinical outcomes system was set up by Florence Nightingale in the Crimean War. The outcome under study was death. The context was the season and the cause of death– wounds, infections and any other cause. The interventions were nursing and administrative. She arrived just before the barracks in Scutari were accepting the first soldiers wounded at the battle of Inkerman in November 1854, and mortality was already high. She was appalled at the disorganisation and standards of hygiene and set about cleaning and reorganisation. However, mortality continued to rise. It was only after the sewers were cleared and ventilation improved in March 1856 that mortality fell. On return to the UK she reflected on these data and produced new sorts of chart (she had trained in mathematics rather than \"worsted work and practising quadrilles\") to show that it was most likely that these excess deaths were caused by living conditions rather than, as she initially believed, poor nutrition. She also showed that soldiers in peacetime also had an excess mortality over other young men, presumably from the same causes. Her reputation was damaged, however, when she and William Farr, Registrar General, collaborated in producing a table which appeared to show a mortality in London hospitals of over 90% compared with less than 13% in Margate. They had made an elementary error in the denominator; the true rate for London hospitals was actually 9% for admitted patients. She was never too keen on hospital mortality figures as outcome measures anyway:\n\n\"If the function of a hospital were to kill the sick, statistical comparisons of this nature would be admissible. As, however, its proper function is to restore the sick to health as speedily as possible, the elements which really give information as to whether this is done or not, are those which show the proportion of sick restored to health, and the average time which has been required for this object…\"\n\nHere she presaged the next key figure in the development of routine outcomes measurement\n\nCodman was a Boston orthopaedic surgeon who developed the \"end result idea\". At its core was \n\n\"The common sense notion that every hospital should follow every patient it treats, long enough to determine whether or not the treatment has been successful, and then to inquire 'if not, why not?' with a view of preventing similar failures in the future.\"\n\nHe is said to have first articulated this idea to his gynaecologist colleague and Chicagoan Franklin H Martin, who later founded the American College of Surgeons, in a Hansom Cab journey from Frimley Park, Surrey, UK in the summer of 1910. He put this idea into practice in Massachusetts General Hospital.\n\n\"Each patient who entered the operating room was provided with a 5-inch by 8-inch card on which the operating surgeon filled out the details of the case before and after surgery. This card was brought up 1 year later, the patient was examined, and the previous years' treatment was then evaluated based on the patient's condition. This system enabled the hospital and the public to evaluate the results of treatments and to provide comparisons among individual surgeons and different hospitals\"\n\nHe was able to demonstrate his own patients’ outcomes and those of some of his colleagues but unaccountably this system was not embraced by his colleagues. Frustrated by their resistance, he provoked an uproar at a public meeting and thus fell dramatically from favour in the hospital and at Harvard, where he held a teaching post, and he was only able to fully realize the idea in his own, struggling small private hospital although some colleagues continued with it at the larger hospitals. He died in 1940 disappointed that his dream of publicly available outcomes data was not even on the horizon, but hoped that posterity would vindicate him.\n\nIn a classic 1966 paper, Avedis Donabedian, the renowned public health pioneer, described three distinct aspects of quality in health care: outcome, process and structure (in that order in the original paper). He had misgivings about solely using outcomes as a measure of quality, but concluded that:\n\"Outcomes, by and large, remain the ultimate validation of the effectiveness and quality of medical care.\"\nHe may have muddied the waters a bit when discussing patient satisfaction with treatment (usually regarded as a measure of process) as an outcome, but more importantly it has become apparent that his three-aspect model has been subverted into what is called the \"structure-process-outcomes\" model, a directional, putatively causal chain that he never originally described. This subversion has been the justification for repeated attempts to improve process and thus outcomes by reorganizing the structure of health care, wittily described by Oxman et al. Donabedian himself cautioned that outcomes measurement cannot distinguish efficacy from effectiveness: (outcomes may be poor because the right treatment is badly applied or the wrong treatment is carried out well), that outcomes measurement must always take into account context (factors other than the intervention may be very important in determining outcomes), and also that the most important outcomes may be the least easy to measure, so easily measured but irrelevant outcomes are chosen (e.g. mortality instead of disability).\n\nPerhaps because of instances of scandalously poor care (for example at the Bristol Royal Infirmary 1984-1995) mortality data have become more and more openly available as a proxy for other health outcomes in hospitals, and even for individual surgeons. However Florence Nightingale’s astringent judgement and Donabedian’s reservations retain their full force for most health services, where routine non-mortal health outcomes measurement remains the most appropriate method.\n\n\nWhy is routine health outcomes measurement so rare? One can find reports of routine health outcomes measurement in many medical specialties and in many countries. However, the vast majority of these reports are by or about enthusiasts who have set up essentially local systems, with little connection with other similar systems elsewhere, even down the street. In order to realise the full benefits of an outcomes measurement system we need large-scale implementation using standardised methods with data from high proportions of suitable healthcare episodes being trapped. In order to analyse change in health status (health outcomes) we also need data on context, as recommended by Donabedian and others, and data on the interventions being used, all in a standardised manner. Such large-scale systems are only at present evident in the field of mental health services, and only well developed in two locations: Ohio and Australia, even though in both of these data on context and interventions are much less prominent than data on outcomes. The major challenge for health outcomes measurement is now the development of usable and discriminatory categories of interventions and treatments, especially in the field of mental health.\n\nAspirations include the following benefits\n\n\n\nExperience suggests that the following factors are necessary for routine health outcomes measurement\n\n"}
{"id": "11768884", "url": "https://en.wikipedia.org/wiki?curid=11768884", "title": "Safe to Sleep", "text": "Safe to Sleep\n\nThe Safe to Sleep campaign, formerly known as the Back to Sleep campaign, is an initiative backed by the US National Institute of Child Health and Human Development (NICHD) at the US National Institutes of Health to encourage parents to have their infants sleep on their backs (supine position) to reduce the risk of sudden infant death syndrome, or SIDS. Since \"Safe to Sleep\" was launched in 1994, the incidence of SIDS has declined by more than 50%.\n\nIn 1992, the American Academy of Pediatrics (AAP) issued the recommendation that babies sleep on their backs or sides to reduce the risk of SIDS (a statement that was later revised in 1996 to say that only the back was safest). NICHD launched the \"Back to Sleep\" campaign in 1994 to spread the message.\n\nThe campaign was successful in that it significantly reduced the percentage of babies sleeping on their stomachs (prone position). It was found, however, that a significant portion of African-American babies were still sleeping on their stomachs; in 1999, an African-American baby was 2.2 times more likely to die of SIDS than a white baby. Thus, then Secretary of Health and Human Services Donna Shalala and Tipper Gore refocused the \"Back to Sleep\" campaign on minority babies.\n\nIn 1985 Davies reported that in Hong Kong, where the common Chinese habit was for supine infant sleep position (face up), SIDS was a rare problem. In 1987 the Netherlands started a campaign advising parents to place their newborn infants to sleep on their backs (supine position) instead of their stomachs (prone position). This was followed by infant supine sleep position campaigns in the United Kingdom (as \"Back to Sleep\"), New Zealand, and Australia in 1991, the U.S. and Sweden in 1992, and Canada in 1993.\n\nThis advice was based on the epidemiology of SIDS and physiological evidence which shows that infants who sleep on their back have lower arousal thresholds and less slow-wave sleep (SWS) compared to infants who sleep on their stomachs. In human infants sleep develops rapidly during early development. This development includes an increase in non-rapid eye movement sleep (NREM sleep) which is also called quiet sleep (QS) during the first 12 months of life in association with a decrease in rapid eye movement sleep (REM sleep) which is also known as active sleep (AS). In addition, slow wave sleep (SWS) which consists of stage 3 and stage 4 NREM sleep appears at 2 months of age and it is theorized that some infants have a brain-stem defect which increases their risk of being unable to arouse from SWS (also called deep sleep) and therefore have an increased risk of SIDS due to their decreased ability to arouse from SWS.\n\nStudies have shown that preterm infants, full-term infants, and older infants have greater time periods of quiet sleep and also decreased time awake when they are positioned to sleep on their stomachs. In both human infants and rats, arousal thresholds have been shown to be at higher levels in the electroencephalography (EEG) during slow-wave sleep.\n\nIn 1992 a SIDS risk reduction strategy based upon lowering arousal thresholds during SWS was implemented by the American Academy of Pediatrics (AAP) which began recommending that healthy infants be positioned to sleep on their back (supine position) or side (lateral position), instead of their stomach (prone position), when being placed down for sleep. In 1994, a number of organizations in the United States combined to further communicate these non-prone sleep position recommendations and this became formally known as the \"Back To Sleep\" campaign. In 1996 the AAP further refined its sleep position recommendation by stating that infants should only be placed to sleep in the supine position and not in the prone or lateral positions.\n\nIn 1992, the first National Infant Sleep Position (NISP) Household Survey was conducted to determine the usual position in which U.S. mothers placed their babies to sleep: lateral (side), prone (stomach), supine (back), other, or no usual position. According to the 1992 NISP survey, 13.0% of U.S. infants were positioned in the supine position for sleep. According to the 2006 NISP survey 75.7% of infants were positioned in the supine position to sleep.\n\n\n"}
{"id": "53498890", "url": "https://en.wikipedia.org/wiki?curid=53498890", "title": "Salome Karwah", "text": "Salome Karwah\n\nSalomé Karwah ( – February 21, 2017) was a Liberian nurse who was named co-Person of the Year by \"Time magazine\" in 2014 for her efforts to combat the West African Ebola virus epidemic in Liberia. She appeared on the cover of \"Time\" in December 2014 with other health care workers and colleagues working to end the epidemic. Karwah survived ebola herself before returning to work to help other patients afflicted with the disease. The actions of Karwah, who worked with Médecins Sans Frontières (Doctors Without Borders) (MSF) and other health care professionals, are believed to have saved lives of thousands.\n\nHowever, two years later, Karwah died from complications of child birth, possibly due to the widespread, mistaken belief that ebola survivors can still transmit the virus, according to accounts by her husband. Even before the ebola outbreak, Liberia had one of the highest rates of maternal mortality in the world.\n\nKarwah's father was a doctor. She met her future husband, James Harris, at a mutual friend's in 2013 after both had recently ended previous relationships. They began dating shortly afterwards.\n\nOne year after Karwah and Harris began dating, the West African Ebola virus epidemic struck Liberia, as well as neighboring Guinea and Sierra Leone, in 2014. Her family was among the first to become ill with ebola during the summer of 2014. Her father was the first to die from ebola, which ultimately killed both her parents and seven other relatives. Karwah, her sister, Josephine, her mother, and Harris were all soon stricken with ebola as well. Salome, Harris and Josephine Karwah were all placed in a Doctors Without Borders medical unit in Monrovia with other ebola patients to be treated. Salome Karwah's priority was to care for her sister, Josephine Manly, who was pregnant at the time she contracted ebola. Salome cared for Josephine, who nearly died, by changing her clothes and cleaning fluids that contained ebola. She withheld the news of their mother's death from Josephine, fearing that it would have a detrimental effect on her health.\n\nBy September 2014, both the Karwah sisters had recovered, determined free of the disease, and discharged from the hospital. Salome Karwah was released from the ebola unit on August 28, 2014. Karwah's boyfriend, James Harris, also recovered and was released from the medical unit a few days later. The staff at Doctors Without Borders (MSF) had noticed that Karwah and Harris had both shown an ability to care for other ebola victims, regardless of the risk to their own health, while they had been patients. Shortly after their discharge from the hospital, MSF hired them to serve as mental health counselors in their ebola units. Salome Karwah returned to the unit, this time as a counselor and nurse, one month after her release. As survivors, she and Harris had developed a natural immunity to that particular strain of ebola.\n\nKarwah, who was interviewed on her work by \"NPR\" in 2014, recalled that \"It was not hard to come back [to the Ebola treatment center]. Of course I lost my two parents here...but if I can help someone survive, I will be very happy.\" She remained at the unit until the end of the ebola epidemic.\n\nIn October 2014, Karwah wrote a guest piece in \"The Guardian\" noting that helping others with ebola brought meaning to her life. In the same essay, Karwah reiterated that \"if someone has Ebola, it isn’t good to stigmatize them, because you don’t know who is next in line to contract the virus.\"\n\n\"Time magazine\" named Salome Karwah as its co-Person of the Year, alongside several other \"ebola fighters\". She appeared on the worldwide cover of \"Time\" in December 2014 just months after being released from the hospital.\n\nHarris and Karwah became engaged. They were married to January 2016 while Karwah was pregnant with their third child, who was born a few months later. In the summer of 2016, Karwah became pregnant with their fourth child, which they agreed would be their last. The couple, who were religious but already had three small children, thought of having an abortion, but chose to keep the baby.\n\nSalome Karwah went through a difficult pregnancy. In February 2017, Karwah underwent a caesarean section though she was suffering from high blood pressure at the time. Although she had high blood pressure, Karwah was discharged from Eternal Love Winning Africa Hospital (ELWA) on the outskirts of Monrovia several days after undergoing the cesarean. She and Harris returned to their home to care for their new infant son, Jeremiah Solomon Karwah, and their other children. Karwah continued to feel unwell, exhibit spikes in blood pressure, and confided to family members that staff at ELWA hospital had neglected her complications. Just hours after arriving home, Karwah collapsed and began foaming from her mouth.\n\nHer husband rushed her back to ELWA hospital on the night of February 19, 2017. However, the hospital's doctor who specialized in treating ebola survivors was not on duty at the time. Another doctor refused to treat Karwah, who remained in the car for \"three hours\" while suffering from convulsions and seizures. Harris eventually went to the emergency room himself and brought out a wheelchair to bring his wife into the hospital. According to Harris, the doctor and nurses on duty still refused to see or touch Karwah, telling him that he would have to take her to another hospital. Harris gave his account to NPR in an interview, saying \"\"[The doctor] was checking Facebook...I had to rush into the emergency room myself to get a wheelchair, but I was struggling to take her from the car to put her in it. Other nurses came to help me, but the doctor told me that she would not touch her, and that if [Salome] stayed [at the hospital] she would die.\"\n\nHe managed to contact an epidemiologist named Dr. Mosoka Fallah, who arrived at ELWA three hours later and finally admitted Karwah to the hospital. Despite his efforts, Salome Karwah, who had survived ebola, died from complications of child birth on February 21, 2017, at the age of 28, just four days after giving birth. She was survived by her husband and their four children, including the youngest, Jeremiah Solomon Karwah.\n\nHarris and Karwah's sister, Josephine, accused the ELWA staff of malpractice due to her status as a former ebola patient. They accuse the medical staff of providing inadequate care because they were afraid to touch her. Josephine Manly, Karwah's sister who also survived ebola, reiterated Harris's claims of poor treatment by hospital staff, saying \"They said she was an Ebola survivor. They didn't want contact with her fluids. They all gave her distance. No one would give her an injection.\" Manly believes that Karwah would have survived the child birth complications if she had received proper, timely emergency medical treatment.\n\nThe mistaken belief that ebola survivors can still transmit ebola remains widespread across the country, including among medical staff, which may have contributed to Karwah's death. According to the \"Associated Press\", the country's chief medical officer, Dr. Francis Kateh, echoed this falsehood when he told reporters that \"the hospital knew she had Ebola and they operated on her, which put them at more risk.\"\n\nTributes came in from around the world, including her former employer, Médecins Sans Frontières, who wrote in a statement, \"Salome's own experience of Ebola gave her incredible empathy for the patients that she worked so hard to care for...Our many staff who remember working with her speak of her strength and compassion, but also of her smile...She made a huge contribution to MSF's work at the height of the outbreak in Monrovia.\" Ella Watson-Stryker, a MDF health promoter and colleague of Karwah, told \"Time\" magazine of the shock of her death, \"To survive Ebola and then die in the larger yet silent epidemic of health system failure … I have no words.\"\n\nKarwah's life was remembered on BBC Radio 4's obituary programme \"Last Word\" by \"Time\" magazine’s Africa correspondent, Aryn Baker.\n"}
{"id": "24420947", "url": "https://en.wikipedia.org/wiki?curid=24420947", "title": "School social work in Hungary", "text": "School social work in Hungary\n\nSchool social work in Hungary aims to provide services to children and their families to ensure that they have the opportunity to complete their education. Aid is particularly focused on impoverished areas with higher proportions of at-risk children and youth.\n\nThe first steps toward school social work in Hungary were taken after World War I, when school nurses (referred to as green cross nurses by Emőke Bányai) started working at schools in the late 1930s. Similar to that of a present-day social worker, they pursued individual case work and aided families in the field and at school. The nurses had a college or university degree in education and belonged to the staff of the school, with the scope of their duties shaped according to its needs. The nurses offered family care services mainly for families residing in the slums of Budapest in order to prevent academic failure and school dropout.\nFollowing World War II, the Hungarian political elite declared that education was the primary requirement for child protection. The first significant change in child protection took place in 1964, when teachers were appointed child protection workers in the kindergartens and schools of Budapest. Elements similar to those in the work of school social workers appeared in the scope of activities of family care workers employed by educational advisory services, which were launched in 1967. In 1975, child protection supervisors were appointed to advise child protection workers at schools. Such child protection supervision functioned until 1985. \nEmployees of family-care centres established in the mid-1980s developed a committed social worker identity. They made regular contacts with local schools, kindergartens, and offered various services to the children, parents and teachers. As a form of youth protection, a so-called afternoon-care system was functioning in the 1970s and 1980s with elements resembling present-day social work. \nSocial and economic changes taking place in the late 1980s and the consequent increase in the rate of unemployment, declassing and dramatic impoverishment of certain social groups, changes in social norms and values, and the related emergence and extension of deviant behaviour challenged schools. It became apparent that these sudden and intensely rising problems were preventing schools from fulfilling their basic tasks, and could not be addressed by traditional educational tools. Child protection workers, whose positions were filled by teachers, did not have the qualifications or the time necessary for the management of complicated cases. Finally, schools stated their claim to employ professionals who provide personal social services for pupils, parents and staff members.\n\nTo resolve the problems which had arisen, three basic concepts were developed by the early 1990s: the appointment of dedicated full- and part-time child protection workers, specialized schools for underprivileged areas with large numbers of at-risk children, and teams of social workers based in local child care centres.\n\nThe management of some schools sought to enhanced child protection service by partially or wholly freeing the workdays of teachers willing and suited to the task of assisting troubled children and their families. Teachers so appointed usually did not have proper qualifications nor were they sufficiently equipped (with an interview room, telephone and supervision). As they were expected to act according to the interests of the school which employed them, it was difficult for them to advocate for the children and their families against the school administration. Colleagues often overwhelmed them with feelings of frustration and unreasonable demands, and they were frequently called to serve as substitute teachers on their days off.\n\nTo improve upon the above model, child protection workers were separated from schools in the early 1990s and employed by the Educational Service Cabinet, in districts XV and XVI of Budapest. Their assignment and supervision was made by the educational department of the local government. This ended the conflict of loyalties but it continued to use educational means and an educational approach. The model was criticized as it continued to employ people who were teachers by training, rather than social workers; and as a government employee the school social worker could not stand against the state schools administration. \nDespite these problems, the employment of child protection workers remained standard practice at schools.\n\nAlternative schools established in the early 1990s sought to provide education satisfying the individual needs of children coming from underprivileged social backgrounds and being unable to manage in a traditional school. In these schools, educational and social work overlap; the educational concept requires the staff to utilize social expertise in educational work. Success of the model is presumably due to the staff's awareness in handling problems that pupils face outside school and a supporting attitude toward pupils. Despite facing some of the same issues of conflict of interest, such schools continue to employ school social workers even when traditional schools ceased to offer services. Both the need among the pupils and the academic mission of the alternative schools legitimized the role of the school social worker.\n\nRecognizing the important role that schools played in child and youth protection work, the first school social work teams in Hungary were formed in the early 1990s (Gedeon 1996). Social services provided by external experts were introduced in several schools at the same time. On the basis of such work launched in autumn 1991 from a local child care centre to a school in District VII of Budapest, a team was set up with the help of the local government in 1992. In District VIII, it was also a child care centre that posted a school social worker to a local school. In 1993, the Child Protection Group initiated services in District XI. At the outset, the group belonged to the Educational Service Centre, and later was converted into a child welfare centre (Bányai 2009, Molnár 2009, Mihály 1991). These were distinguished from the independent child protection workers under the educational department of the local government. \nPerhaps the best-known experimental project carrying out \"external\" school social work was the \"Ferencváros\" Network of School Social Workers. The network was started in summer 1992. Later it was renamed \"Ferencváros\" White Raven Child Welfare Service. In District IX of Budapest, the local government promoted the establishment of the child welfare service in 1992. The concept was developed by Dr Mihaly and her colleagues. The main principle on which they stood was: \"Child protection must be removed from schools, but it must not be handed over to the system of authorities. A child protection system independent form authorities has to be created\" (Dr Mihaly, 2008). It is a characteristic of the model that it considers the community surrounding the school, including the network of supporting organizations. They aspired to create and run a region-based child protection system. The social worker did not want to take up the child protection worker's duties, but focused on the role of a mediator, co-ordinator, and \"catalyst\". Working with pupils was reduced, since social workers were on duty at schools only once a week. The range of activities covered group work, organizing club sessions, summer camping and playrooms, and offering homework help – instead of doing case management for individuals. Furthermore, they worked with families and were entitled to offer them financial and in-kind assistance. A structure of services different from that of the traditional school social work evolved due to the lack of modern child protection services and institutions providing customized care for clients in Hungary. In particular, services were offered to families to prevent children from being removed from their birth parents, as there was no basic child welfare services separate from the operation of authorities. \"Ferencváros\" Child Welfare Service attempted to fill this gap.\n\nThis work led to the Child Welfare Act that came into effect in November 1997. After the law came into effect, the \"Ferencváros\" Child Welfare Service underwent a transformation: child welfare activities began to outweigh school social work, which had previously been of primary importance. The Child Welfare Act created new conditions for the operation of the other networks of school social workers and child welfare services as well, easing the burden on local governments. As a consequence, classical school social work became overshadowed by the corrective tasks of child welfare. As since 1996, Annex 1 of Act LXII of 1996 have been obliging schools to employ a part-time child protection worker, schools should have increased capability of support for students. However, in practice schools continued to give this work to teachers without adequate qualifications.\n\nSince 2004, school social work has been expanding, with increasing employment. Child welfare services also focus more on school social work. Since the national register of school social workers is currently being prepared, exact data is unavailable.\n\nAt present, there are three main approaches to school social work in Hungary:\nEmploying teachers as child protection workers is no longer a viable option following the introduction of university degree programmes in social work and social education, which provided qualified professionals.\n\nIn the internal or traditional model, the school social worker's employer is the administrator of the school. The school social worker offers various social services while present at the school, and is familiar with its functioning. The social worker may form a team with a school doctor or nurse, but generally does not have supervision or team case management available. This model is applied mainly by schools maintained by (e.g.: Burattino Általános - és Szakképző Iskola, Forrás Szakiskola, Gandhi Gimnázium, Világ Világossága Alapítvány), but a few such state schools also exist (e.g.: Radnóti Szakközépiskola in the city of Pécs, Éltes Mátyás Iskola, Magyarmecskei Általános Iskola). The first school social work programmes in Hungary followed this model.\n\nIn the external or Ferencváros model, school social work is delivered to the by external suppliers through networks. Each colleague assists 4–5 schools (or kindergartens), with weekly service available for a relatively short time to each school. Group and community work overshadows individual case management. Qualified professionals are aided by supervision and team case management. External school social work is implemented mainly by state-run child welfare services (e.g.: II. kerületi Gyermekjóléti Központ, Újbudai Humán Szolgáltató Központ Gyermekjóléti Szolgálata, Sopron, Szombathely, Nyíregyháza), but there are some NGO-run services as well (e.g. Periféria Egyesület).\n\nProgrammes based on the external model were set back by the Child Protection Act, since the act promoted the corrective child protection activities of the services. However, new emphasis was placed on school social work after the 2003 consensus conference of child welfare services, which found only 14 percent of services carried out school social work in 2005. Strengths of the model are the employment of professionals with adequate qualifications and the support of networks. Critics of the model blame the departure from the conceptional framework of the traditional model (Bányai 2006), and the so-called \"schedule of attendance\", which means that a school social worker spends only a few hours a week at a particular school.\n\nThe Pécs model, which was formed in 2006, combines the advantages of the previous two models. The school social worker assists one school per day with social services and attends weekly team case management meetings. A network of professionals offers support in supervision and individual counselling, case management, standardized paperwork and registration of clients, etc. The school social worker is employed by an NGO independent from both the school and the child welfare system, and is thus less biased by organizational hierarchy.\n\nConceptually, the framework uses modern ecological models applied to child-oriented school social work. The school social worker applies a preventive approach to find solutions to pupils' problems, using individual casework, social group work and community work, considering both the environment and the complexity of the personality, and seeks solutions with the help of a multidisciplinary team (Máté 2008). This model is applied by the Network of School Social Workers of INDIT Közalapítvány at six schools. The model co-operates closely with youth supporting programs outside schools. Moreover, INDIT Közalapítván itself runs youth-supporting programmes such as Youth Office \"Alternative\" (the first youth-supporting programme in Hungary located in a shopping mall), Street Social Work Service and the Party Service (a harm reduction programme for party-goers). Integration of the above programmes into one organization makes it possible for INDIT to reach school-dropouts and truants.\n\nStandardized training and active associations are of crucial importance to forming a cohesive profession. It is standard practice for school social workers in Hungary to have a university or college degree in social work or social education. These two professions, rooted in different cultures [social work from the United States and social education from Germany], have developed quite similarly and are nearly identical in scope.\n\nThere are some regional variances depending on the type of degree programmes available in the area. At Bárczi Gusztáv Gyógypedagógiai Főiskola, psychoeducators for specialized child protection work have been trained since 1973. From 1985 several degree programmes for general child protection have been accredited. ELTE (Eötvös Loránd University of Budapest) launched a postgraduate degree programme in social policy in 1985. Hungarian colleges and universities started undergraduate programmes in general social work in 1989 and in social education in 1990. Requirements of qualification of undergraduate programmes in social studies (social policy, social work, social education) were issued in 1996 (Government Decree on Requirements of Qualification of Undergraduate University Degree Programmes in Social Studies 6/1996 [January 18], Annex 2) (Bucsy 2005). Courses on school social work were introduced to the above programmes. Dr. István Budai at Vitéz János Tanítóképző Főiskola (Vitéz János Teacher Training College) in 1991 and Emőke Bányai at ELTE in 1993 were the first to teach this subject. According to the results of a study carried out in 2009, school social work is currently taught at eleven university departments of social work and at six departments of social education. School social work is part of undergraduate degree programmes at most faculties training social professionals, which demonstrates the importance of the subject. However, there have yet to be any graduate-level programs in Hungary, though Kodolányi János University of Applied Sciences plans to launch a one-year master programme in school social work. The first Hungarian school social work textbook was published in 1993 by the Vitéz János Tanítóképző Főiskola (Vitéz János Teacher Training College of Esztergom) and the Óvóképző Főiskola (Preschool Teacher Training College of Hajdúböszörmény) and was edited by István Budai. The book was published under the title \"Papers on child welfare I. – School social work\".\n\nThe Hungarian School Social Worker Association was founded at a conference organized by Kodolányi János University of Applied Sciences on November 30, 2007, in Székesfehérvár. Objectives of the association are:\nThe association intends to participate in the codification of regulations controlling school social work. As part of the above policy formulation and law making process, the association is ready to contribute to defining the conditions and protocol for school social work and to the improvement of finances.\n\n"}
{"id": "31273385", "url": "https://en.wikipedia.org/wiki?curid=31273385", "title": "Service Excellence – Health Care", "text": "Service Excellence – Health Care\n\nIn United States healthcare, service excellence is the ability of the provider to consistently meet and manage patient expectations. Clinical excellence must be the priority for any health care system. However, the best healthcare systems combine professional (clinical) service excellence with outstanding personal service. Although health care in the United States is touted as the “world’s largest service industry,” the quality of the service is infrequently discussed in medical literature. Thus, many questions regarding service excellence in healthcare largely remain unanswered.\n\nService excellence in healthcare is difficult to define and better described as a “I know when I receive it, or perhaps more frequently, I know when I have not.” According to Robert Johnson (Institute of Customer Service), service excellence has four key elements: delivering the promise of quality healthcare, providing a personal touch, doing a more than adequate job and resolving problems well.\n\nIn order to achieve these elements, healthcare institutions, in particular, must be concerned with reducing the drivers of dissatisfaction, and providing exceptional healthcare. According to the federal Agency for Healthcare Research and Quality (AHRQ), exceptional healthcare is defined as “doing the right thing, at the right time, for the right person, and having the best quality result [outcome].”\n\nDuring the past decade, healthcare has been receiving increased attention not only because of unsustainable costs, but also because of an emphasis on quality of care improvement. Institutions are now attempting to measure and compare quality outcomes, as well as report them in both the consumer press and peer reviews literature to the delight of some and the consternation of others. Managers of healthcare delivery systems endeavor to provide the highest possible care achievable. Inherent to this goal is the need for evaluation of the quality of the health services provided. Measuring patient satisfaction is an indirect measure of quality, and can pose some difficult challenges to individuals attempting to assess quality. One difficulty is that in healthcare it is difficult to assess a patient’s outcome after receiving care compared to the outcome they would have had with a different provider. The most important problem is establishing a definition of “satisfaction.” Because the definition of satisfaction can vary from patient to patient, many institutions have created surveys asking patients to rate the quality of the services they have received. This method of evaluation is extremely subjective, and many factors unrelated to the quality of care (the topic of interest) can affect the results. For example, a review of 37 studies addressing different methods of satisfaction evaluation found that phone interview increased the response rate by 30%. Additionally, mailing surveys resulted in more criticism and less satisfaction. Some speculate that this is due to the anonymity and a lack of pressure for socially acceptable responses. Mailing surveys also results in more variability in response than a phone survey with patients either feeling really satisfied or dissatisfied. Even the timing of administration of the survey can have a major effect on the results. The literature of the studies in this area suggests further research needs to be conducted on this topic. Crow et al. also point out that if patients are not constrained by outside factors, the selection of which healthcare facility to receive care in is an objective measurement of a their satisfaction. When satisfaction is low, a service failure has occurred.\n\nEvery patient has a basic assumption that the healthcare services they seek, and pay for, will meet their expectations. If these expectations are met then they are satisfied. Moreover, if these expectations are exceeded the patient is delighted, and much more likely to recommend the healthcare institution to friends and family members. However, when these expectations are not met the patient is much more likely to share this disappointment with more than just their immediate circle.\nService failures are inevitable, but anticipating service failures can significantly affect patient satisfaction. A measure of a well-managed organization is whether they work hard to plan for, prevent, identify, and correct any and all service failures. These steps are key because if a patient experiences a service failure early in their encounters with a healthcare institutions, it’s likely to weigh more heavily on their decisions to return to the healthcare institution. More important, however, is whether the service failure is corrected because patients are not very tolerant of poor service recovery. Meaning, if a patient experiences the same service failure twice it is likely this patient will be lost to the institution forever. A study conducted by Bowen and Johnson suggests that this is true because patients are more angered by the belief that the system in which the service failure occurred remains unchanged than their dissatisfaction with the service itself. In other words, patients are put off by a healthcare organization that makes no efforts to correct its mistakes.\nLearning the sources of service failures is not only important to the customer, but it is also important to the bottom line.\n\nEvery point in the healthcare experience has a potential to result in a service failure. For example, if a health service takes longer than a patient expects, or if a service does have the outcome the patient was anticipating, a service failure has occurred. Even the setting or environment in which the care is being provided can affect a service failure. Perhaps surprisingly, patients themselves can contribute to service failures by failing to read signage or correctly completing required forms. Finally, rude, untrained, or poorly trained staff members can bring about a service failure. Thus, the service product, setting, delivery system, and staff must be carefully managed to minimize the likelihood of a service failure. If a healthcare institution does not make changes in response to a service failure, it fails twice:\n\nDecreasing service failures and focusing on service excellence can decrease patient defection (leaving one healthcare institution for another). Having a solid service recovery plan when service failures do occur is key to ensuing an excellent healthcare experience for every patient. Service failures resulting in patient defection do not only derail the goal of service excellence, but they affect the bottom line. A Study performed by Reichheld and Sasser found that reducing patient defection by 5% can raise profits between 25%-85%.\n\nOften there is a gap between what an organization wants to do and what the employees actually do, so many times many institutions set up infrastructure to focus on service excellence.\nIn an effort to provide patients with the highest possible quality of clinical care, the National institute of clinical excellence (NICE) was created. This program attempts to provide health professionals in the United Kingdom National Health Service (NHS) with the skills they need to provide high-quality cost-effective clinical care by focusing on Service Excellence. These efforts are not unique to the United Kingdom. In Prescription for Excellence, Joseph Michelli gives a detailed review of the steps Ronald Reagan UCLA Medical Center has taken to provide service excellence in healthcare.\n\nService excellence in healthcare has been found to have unintended adverse effects: \n"}
{"id": "52229324", "url": "https://en.wikipedia.org/wiki?curid=52229324", "title": "Severe achondroplasia with developmental delay and acanthosis nigricans", "text": "Severe achondroplasia with developmental delay and acanthosis nigricans\n\nSevere achondroplasia with developmental delay and acanthosis nigricans (SADDAN), is a very rare genetic disorder. This disorder is one that affects bone growth and is characterized by skeletal, brain, and skin abnormalities. Those affected by the disorder are severely short in height and commonly possess shorter arms and legs. In addition, the bones of the legs are often bowed and the affected have smaller chests with shorter rib bones, along with curved collarbones. Other symptoms of the disorder include broad fingers and extra folds of skin on the arms and legs. Developmentally, many individuals who suffer from the disorder show a higher level in delays and disability. Seizures are also common due to structural abnormalities of the brain. Those affected may also suffer with apnea, the slowing or loss of breath for short periods of time.\n\nMany of the features of SADDAN are similar to those seen in other skeletal disorders, specifically achondroplasia and thanatophoric dysplasia.\nAchondroplasia is a form of short-limbed dwarfism. This type of dwarfism is caused by the inability of the cartilage of the skeleton to ossify and turn to bone. Acanthosis nigricans is a skin condition in which areas of the skin is of a dark and velvety discoloration, often seen in the body folds and creases such as the armpits, groin, and neck. Within those affected by SADDAN, acanthosis nigricans develops early on, usually in infancy or early childhood.\n\nThe mutated gene responsible for the disorder is the FGFR3 gene, more specifically; a Lys650Met missense mutation of the FGFR3 gene is what causes SADDAN. This gene codes for the instructions of a protein that is integral in the development and maintenance of bone and brain tissue. Mutations of this gene cause the protein to be overly active, causing many characteristics of this disorder.\n\nSADDAN is an autosomal dominant genetic disorder. Autosomal means that the gene responsible for the mutation and disorder is found on a non-sex chromosome and that either the mother or father can pass on the gene, while dominant means that only one copy of the gene is required for the individual to have the disorder.\n\nFortunately the disorder is very rare and has only been described in a few number of cases worldwide. While the disorder can be genetically inherited, no instances of inheritance have been recorded as of yet. Rather, of the few cases documented, the individual affected by the disorder is affected as a product of a random mutation, also called a de novo mutation, of the FGFR3 gene only, not by inheritance of the mutated gene.\n\nMedical diagnosis is required. Clinical tests can be performed, as well as molecular genetic testing. The available tests include:\n\nSequence analysis of the entire coding region\n\nMutation scanning of select exons\n\nSequence analysis of select exons\n\nDeletion/duplication analysis\n\nLife with SADDAN is manageable, although therapy, surgery, and lifelong doctor surveillance may be required.\n\n"}
{"id": "27638", "url": "https://en.wikipedia.org/wiki?curid=27638", "title": "Spermatozoon", "text": "Spermatozoon\n\nA spermatozoon (pronounced , alternate spelling spermatozoön; plural spermatozoa; from \"seed\" and \"living being\") is a motile sperm cell, or moving form of the haploid cell that is the male gamete. A spermatozoon joins an ovum to form a zygote. (A zygote is a single cell, with a complete set of chromosomes, that normally develops into an embryo.)\nSperm cells contribute approximately half of the nuclear genetic information to the diploid offspring (excluding, in most cases, mitochondrial DNA). In mammals, the sex of the offspring is determined by the sperm cell: a spermatozoon bearing a X chromosome will lead to a female (XX) offspring, while one bearing a Y chromosome will lead to a male (XY) offspring. Sperm cells were first observed in Anton van Leeuwenhoek's laboratory in 1677.\n\nThe human sperm cell is the reproductive cell in males and will only survive in warm environments; once it leaves the male body the sperm's survival likelihood is reduced and it may die, thereby decreasing the total sperm quality. Sperm cells come in two types, \"female\" and \"male\". Sperm cells that give rise to female (XX) offspring after fertilization differ in that they carry an X-chromosome, while sperm cells that give rise to male (XY) offspring carry a Y-chromosome.\n\nA human sperm cell consists of a flat, disc shaped head 5.1 µm by 3.1 µm and a tail 50 µm long. The tail flagellates, which propels the sperm cell (at about 1–3 mm/minute in humans) by whipping in an elliptical cone. Sperm have an olfactory guidance mechanism, and after reaching the Fallopian tubes, must undergo a period of capacitation before penetration of the ovum.\n\nHead: It has a compact nucleus with only chromatic substance and is surrounded by only a thin rim of cytoplasm. Above the nucleus lies a cap-like structure called the \"acrosome\", formed by modification of the Golgi body, which secretes the enzyme spermlysin \"(hyaluronidase, corona-penetrating enzyme, zona eyesin, or aerosin.)\" On the surface of the head lies a decapacitating substance which is removed before fertilisation.\n\nNeck: It is the smallest part (0.03 ×10 m), and has a proximal and distal centriole. The proximal centriole enters into the egg during fertilisation and starts the first cleavage division of the egg, which has no centriole. The distal centriole gives rise to the axial filament which forms the tail and has a (9+2) arrangement. A transitory membrane called the \"Manchette\" lies in the middle piece.\n\nMiddle piece: It has 10–14 spirals of mitochondria surrounding the axial filament in the cytoplasm. It provides motility, and hence is called the powerhouse of the sperm. It also has a ring centriole (annulus) with unknown function.\n\nTail: It is the longest part (50×10 m), having an axial filament surrounded by cytoplasm and plasma membrane, but at the posterior end the axial filament is naked.\n\nSemen has an alkaline nature and the spermatozoa do not reach full motility (hypermotility) until they reach the vagina, where the alkaline pH is neutralized by acidic vaginal fluids. This gradual process takes 20–30 minutes. During this period, fibrinogen from the seminal vesicles forms a clot, securing and protecting the sperm. Just as they become hypermotile, fibrinolysin from the prostate gland dissolves the clot, allowing the sperm to progress optimally.\n\nThe spermatozoon is characterized by a minimum of cytoplasm and the most densely packed DNA known in eukaryotes. Compared to mitotic chromosomes in somatic cells, sperm DNA is at least sixfold more highly condensed.\n\nThe specimen contributes with DNA/chromatin, a centriole, and perhaps also an oocyte-activating factor (OAF). It may also contribute with paternal messenger RNA (mRNA), also contributing to embryonic development.\n\nDNA damages present in spermatozoa in the period after meiosis but before fertilization may be repaired in the fertilized egg, but if not repaired, can have serious deleterious effects on fertility and the developing embryo. Human spermatozoa are particularly vulnerable to free radical attack and the generation of oxidative DNA damage. (see e.g. 8-Oxo-2'-deoxyguanosine)\n\nExposure of males to certain lifestyle, environmental or occupational hazards may increase the risk of aneuploid spermatozoa. In particular, risk of aneuploidy is increased by tobacco smoking, and occupational exposure to benzene, insecticides, and perfluorinated compounds. Increased aneuploidy of spermatozoa often occurs in association with increased DNA damage. DNA fragmentation and increased in situ DNA susceptibility to denaturation, the features similar to these seen during apoptosis of somatic cells, characterize abnormal spermatozoa in cases of male infertility.\n\nGlycoprotein molecules on the surface of ejaculated sperm cells are recognized by all human female immune systems, and interpreted as a signal that the cell should not be rejected. The female immune system might otherwise attack sperm in the reproductive tract. The specific glycoproteins coating sperm cells are also utilized by some cancerous and bacterial cells, some parasitic worms, and HIV-infected white blood cells, thereby avoiding an immune response from the host organism.\n\nThe blood-testis barrier, maintained by the tight junctions between the Sertoli cells of the seminiferous tubules, prevents communication between the forming spermatozoa in the testis and the blood vessels (and immune cells circulating within them) within the interstitial space. This prevents them from eliciting an immune response. The blood-testis barrier is also important in preventing toxic substances from disrupting spermatogenesis.\n\nFertilization relies on spermatozoa for most sexually reproductive animals.\n\nSome species of fruit fly produce the largest known spermatozoon found in nature. \"Drosophila melanogaster\" produces sperm that can be up to 1.8 mm, while its relative \"Drosophila bifurca\" produces the largest known spermatozoon, measuring over 58 mm in length. In Drosophila melanogaster, the entire sperm, tail included, gets incorporated into the oocyte cytoplasm, however, for Drosophila bifurca only a small portion of the tail enters the oocyte.\n\nThe wood mouse \"Apodemus sylvaticus\" possesses spermatozoa with falciform morphology. Another characteristic which makes these gametocytes unique is the presence of an apical hook on the sperm head. This hook is used to attach to the hooks or to the flagella of other spermatozoa. Aggregation is caused by these attachments and mobile trains result. These trains provide improved motility in the female reproductive tract and are a means by which fertilization is promoted.\n\nThe postmeiotic phase of mouse spermatogenesis is very sensitive to environmental genotoxic agents, because as male germ cells form mature spermatozoa they progressively lose the ability to repair DNA damage. Irradiation of male mice during late spermatogenesis can induce damage that persists for at least 7 days in the fertilizing spermatozoa, and disruption of maternal DNA double-strand break repair pathways increases spermatozoa-derived chromosomal aberrations. Treatment of male mice with melphalan, a bifunctional alkylating agent frequently employed in chemotherapy, induces DNA lesions during meiosis that may persist in an unrepaired state as germ cells progress though DNA repair-competent phases of spermatogenic development. Such unrepaired DNA damages in spermatozoa, after fertilization, can lead to offspring with various abnormalities.\n\nSea urchins such as \"Arbacia punctulata\" are ideal organisms to use in sperm research, they spawn large numbers of sperm into the sea, making them well-suited as model organisms for experiments.\n\nThe gametophytes of bryophytes, ferns and some gymnosperms produce motile sperm cells, contrary to pollen grains employed in most gymnosperms and all angiosperms. This renders sexual reproduction in the absence of water impossible, since water is a necessary medium for sperm and egg to meet. Algae and lower plant sperm cells are often multi-flagellated (see image) and thus morphologically different from animal spermatozoa.\n\nSome algae and fungi produce non-motile sperm cells, called spermatia. In higher plants and some algae and fungi, fertilization involves the migration of the sperm nucleus through a fertilization tube (e.g. pollen tube in higher plants) to reach the egg cell.\n\nSpermatozoa are produced in the seminiferous tubules of the testes in a process called spermatogenesis. Round cells called spermatogonia divide and differentiate eventually to become spermatozoa. During copulation the cloaca or vagina gets inseminated, and then the spermatozoa move through chemotaxis to the ovum inside a Fallopian tube or the uterus.\n\nApproaching the egg cell is a rather complex, multistep process of chemotaxis guided by different chemical substances/stimuli on individual levels of phylogeny. One of the most significant, common signaling characters of the event is that a prototype of professional chemotaxis receptors, formyl peptide receptor (60,000 receptor/cell) as well as the activator ability of its ligand formyl Met-Leu-Phe have been demonstrated in the surface membrane even in the case of human sperms. \nMammalian sperm cells become even more active when they approach an egg cell in a process called sperm activation. Sperm activation has been shown to be caused by calcium ionophores \"in vitro\", progesterone released by nearby cumulus cells and binding to ZP3 of the zona pellucida. The cumulus cells are embedded in a gel-like substance made primarily of hyaluronic acid, and developed in the ovary with the egg and support it as it grows.\n\nThe initial change is called \"hyperactivation\", which causes a change in spermatozoa motility. They swim faster and their tail movements become more forceful and erratic.\n\nA recent discovery links hyperactivation to a sudden influx of calcium ion into the tails. The whip-like tail (flagellum) of the sperm is studded with ion channels formed by proteins called CatSper. These channels are selective, allowing only calcium ions to pass. The opening of CatSper channels is responsible for the influx of calcium. The sudden rise in calcium levels causes the flagellum to form deeper bends, propelling the sperm more forcefully through the viscous environment. Sperm hyperactivity is necessary for breaking through two physical barriers that protect the egg from fertilization.\n\nThe second process in sperm activation is the acrosome reaction. This involves releasing the contents of the acrosome, which disperse, and the exposure of enzymes attached to the inner acrosomal membrane of the sperm. This occurs after the sperm first meets the egg. This lock-and-key type mechanism is species-specific and prevents the sperm and egg of different species from fusing. There is some evidence that this binding is what triggers the acrosome to release the enzymes that allow the sperm to fuse with the egg.\n\nZP3, one of the proteins that make up the zona pellucida, then binds to a partner molecule on the sperm. Enzymes on the inner acrosomal membrane digest the zona pellucida. After the sperm penetrates the zona pellucida, part of the sperm's cell membrane then fuses with the egg cell's membrane, and the contents of the head diffuse into the egg.\n\nUpon penetration, the oocyte is said to have become activated. It undergoes its secondary meiotic division, and the two haploid nuclei (paternal and maternal) fuse to form a zygote. In order to prevent polyspermy and minimise the possibility of producing a triploid zygote, several changes to the egg's zona pellucida renders them impenetrable shortly after the first sperm enters the egg.\n\nSpermatozoa can be stored in diluents such as the \"Illini Variable Temperature\" (IVT) diluent, which have been reported to be able to preserve high fertility of spermatozoa for over seven days. The IVT diluent is composed of several salts, sugars and antibacterial agents and gassed with CO.\n\nSemen cryopreservation can be used for far longer storage durations. For human spermatozoa, the longest reported successful storage with this method is 21 years.\n\n\n\n"}
{"id": "41371128", "url": "https://en.wikipedia.org/wiki?curid=41371128", "title": "St. Anthony's Hospital, North Cheam", "text": "St. Anthony's Hospital, North Cheam\n\nSpire St Anthony's Hospital is a private hospital in North Cheam, formerly in the county of Surrey, now in the London Borough of Sutton. The hospital is part of the Spire Healthcare group, the second largest provider of private healthcare in the United Kingdom. It was formerly owned and operated by the Daughters of the Cross of Liege, a Roman Catholic religious order. It is located on the junction between the A24 and Gander Green Lane.\n\nSt Anthony's was founded in 1904. Its location, once the site of North Cheam House, was purchased by the Daughters of the Cross for £4,625. By 1914 the Daughters of the Cross had replaced North Cheam House, erecting a building of three storeys and 163-foot frontage.\n\nThe hospital operated a 'pay-by-your-means' policy until 1948, when the National Health Service was formed, causing St Anthony's to begin accepting public patients with funding from the NHS. In the early 1970s, St. Anthony's NHS contract was withdrawn and the hospital reverted to private status. Responding to this change in status, it developed a speciality for cardiac surgery and moved to a smaller purpose-built facility opened by Miles Fitzalan-Howard, 17th Duke of Norfolk in October 1975.\n\nIn 1987, the Daughters of the Cross formed St. Raphael's Hospice, a registered charity providing specialist medical and nursing care for those with cancer and other serious illnesses and support for the families of the afflicted.\n\nBy 2012, a decline in the membership of the Daughters of the Cross, coupled with the advanced age of many of its members, led the order to seek to divest itself of responsibility for the hospital and hospice. After obtaining a management consultancy's advice, they decided to try to sell the hospital but retain ownership of the hospice. They expected to make a decision on a buyer in December 2013. Staff and consultants of the hospital and the chairman of the hospice board raised concerns about how a sale to a private firm might affect the charity work of the hospice, which is subsidised by hospital revenues, and the ability of the hospital to operate within moral directives of the Catholic Church. In June 2013 they appealed to Vatican officials to prevent the sale, and Paul Burstow, the member of parliament for Sutton and Cheam, said he would seek to have the Foreign Office direct an embassy official to bring the issue to the Vatican's attention. In November 2013, Burstow presented a petition to Parliament, signed by over 7,000 people, requesting government help in blocking the sale. Opponents of the sale hoped for formation of a new Catholic charity to take over the hospital and hospice. In March 2014, it was announced that they were to be sold to Spire Healthcare.\n\nSpire St Anthony's is a 92-bed private hospital. It provides routine and complex surgery and has an 8-bed intensive care unit.\n\nSpire St Anthony’s offers a wide range of treatments from diagnostic imaging to major surgery covering a range of specialities including orthopaedics, neurosurgery, paediatric day cases, cardiology and cardiac surgery. They have continually invested in development projects to ensure a high standard of accommodation and facilities including six state of the art integrated theatres suites, incorporating three laminar flow and one hybrid theatre. They have also invested in a dedicated physiotherapy suite.\n\nThe associated St. Raphael's Hospice is operated as a charity; it employs 53 nurses.\n\nIn 2015/6 it made a loss of £1.5 million, attributed to delays in the redevelopment programme by Spire.\n\n\n\n"}
{"id": "24634013", "url": "https://en.wikipedia.org/wiki?curid=24634013", "title": "St. Joseph Hospital (Nashua, New Hampshire)", "text": "St. Joseph Hospital (Nashua, New Hampshire)\n\nSt. Joseph Healthcare is a network of hospitals and health care facilities serving the greater Nashua area, southern New Hampshire and northern Massachusetts. \n\nThe main facility is the 208-bed St. Joseph Hospital, with satellite centers in Milford and Merrimack. The service is now part of Covenant Health Systems.\n\nThe service was founded in 1906 on Kinsley Street in Nashua, by the parish of St. Louis de Gonzague. From 1907 it was run by the Sisters of Charity of Montreal.\n\nIt is a Roman Catholic foundation, in the tradition of St. Marguerite d'Youville.\n\n"}
{"id": "15104088", "url": "https://en.wikipedia.org/wiki?curid=15104088", "title": "Streff syndrome", "text": "Streff syndrome\n\nStreff syndrome is a vision condition primarily exhibited by children under periods of visual or emotional stress. \nFrequently patients will have reduced stereopsis, large accommodative lag on dynamic retinoscopy, and a reduced visual field (tubular or spiral field). Streff Syndrome was first described in 1962 by an optometrist, Dr. John Streff as Non-malingering syndrome. In 1962, Dr. Streff and Dr. Richard Apell expanded the concept to add early adaptive syndrome as a precursor to Streff syndrome. Dr. Streff believed the visual changes were induced by stress from reading. There is dispute on the taxonomy of functional vision defects. Some research indicates that Streff syndrome may be caused by a dysfunction in the magnocellular pathway of the retinal ganglion cells. These cells are only 10% of the retinal nerve cells and register motion detection. \nEarly Adaptive Syndrome\n\nMost optometrists agree that Streff syndrome is a generalized reduction in visual performance that is not caused by structural damage. It is a disease involving vision distress primarily of the accommodation system. Hans Selye described stress, distress and eustress. It is most common in girls ages 8 to 14. Hand held reading material is often positioned excessively close. Reading aloud shows signs of elevated pitch and stumbling over common words. History of homework avoidance and falling class performance are often present. If the patient is directed to read aloud and +.50 lenses are then used, there is usually a dramatic improvement as observed by patient and parent. Abnormal results on color vision or visual field testing is not uncommon. Visual field often presents as constricted 'tubular' at multiple test distances. The poor visual performance is understood as distress, and treatments are usually to provide the patient with low powered reading glasses. The \"relaxing\" nature of reading glasses is believed to reduce the near vision stress and allow normal function. The emotional effects of chronic near vision stress are also reduced.\nThe \"non-Malingering\" name is a refutation that the patient is malingering.\n"}
{"id": "38851547", "url": "https://en.wikipedia.org/wiki?curid=38851547", "title": "Symptom targeted intervention", "text": "Symptom targeted intervention\n\nSymptom targeted intervention (STI) is a clinical program being used in medical settings to help patients who struggle with symptoms of depression or anxiety or adherence to treatment plans but who are not interested in receiving outpatient mental health treatment. STI is an individualized therapeutic model and clinical program that teaches patients brief, effective ways to cope with difficult thoughts, feelings, and behaviors using evidence-based interventions. Its individualized engagement process employs techniques from solution-focused therapy, using a Rogerian, patient-centered philosophy. This engagement process ensures that even challenging, at-risk, and non-adherent patients are able to participate.\n\nSocial workers and other mental health practitioners and medical professionals use STI to assist patients with a number of specific concerns, from sleep and stress to pain management, relationships and mood management. STI’s coping tools are cognitive behavioral therapy and mindfulness interventions that have been condensed and modified to make them user friendly and effective in brief sessions. After meeting with the clinician, the patient takes charge, performing interventions at home through assignments that extend and reinforce learning.\n\nUsing STI, the clinician helps the patient identify the most problematic symptom of the depression (such as depressed mood, insomnia, anxiety, rumination, irritability, negative thinking, social isolation), then together the clinician and patient address that symptom using STI’s evidence-based selection of brief cognitive, behavioral, and mindfulness techniques. The emphasis is on keeping interactions brief since mental health treatment in the primary care setting is typically time limited—although the Collaborative Care and Integrated Care models provides hope for improved and expanded mental health services in the primary care setting.\n\nAs patients learn better coping skills, they become more engaged with their treatment and more adherent to doctors’ recommendations.\n\nSTI also gives social workers ways to uncover their clinical strengths and tools to continue to work with resistant patients. With STI training, clinicians learn a nuanced approach to all patients, even those who resist help, since often those are the individuals who need help most. After learning STI, clinicians report that they are more likely to approach rather than avoid difficult patient situations.\n\nSTI was created in 2009 by licensed clinical social worker (LCSW) Melissa McCool to give clinicians a toolkit for helping depressed patients who cannot or will not seek outpatient psychotherapy. McCool originally developed STI for patients with end-stage renal disease (ESRD). Patients with ESRD and other chronic diseases often suffer from depression and it often goes undiagnosed. Studies suggest that at least 25% of dialysis patients have clinical depression and at least 35% have symptoms that put them at risk for depression. Additionally, for a variety of reasons, patients who are suffering mentally and physically from depression often go untreated. Social workers using STI with ESRD patients have reported promising outcomes.\n\nThe intellectual premise for STI is based on systems theory, which considers a system as a set of interacting and independent parts. If depression is a system consisting of various symptoms, when one of the symptoms improves, the entire trajectory of the depressive episode is transformed. In this sense, STI is related to Bowen’s systemic theory and its interactional dynamics. Using STI, the patient and clinician focus on one element, or symptom, helping the patient avoid feeling overwhelmed by multiple problems. The parallel process is also in effect: Clinicians may be similarly overwhelmed by attempting to tackle multiple symptoms in their depressed patients.\n\nAlso central to STI is the cognitive triangle, which illustrates how one’s thoughts, feelings, and behaviors are all interconnected and dependent upon one another. If a behavior changes, thoughts and feelings change; if a thought changes, behaviors and feelings change.\n\nSTI has been expanded beyond ESRD to support the many patients who are suffering from depression who receive treatment for chronic disease in outpatient clinics, hospitals, nursing homes or rehabilitation centers. Kaiser Permanente is now using STI as the main treatment modality in its Collaborative Care study.\n\nA review of treatments for anxiety and depression in dialysis patients cited STI as an economical way to alleviate depression using brief, in-clinic sessions. A review that considered measures of quality of life in patients with ESRD noted that STI’s techniques are promising and productive. STI was included in a 2013 review of best practices for effective screening and managing depression in dialysis patients.\n\nIn a 2014 article about ways that social workers can ease chronically ill patients’ burdens and effectively address their emotional challenges, Joseph R. Merighi, PhD, MSW, an associate professor at the University of Minnesota School of Social Work, describes STI as “an innovative, brief, and patient-centered approach that modifies cognitive, behavioral, and mindfulness techniques to make them user-friendly for patients and brief in their delivery.” The article’s author adds that STI is “used by the leading dialysis providers and has become the standard of care.”\n\nSTI is now being used by medical social workers in a range of settings across the United States, who have reported positive results. To teach social workers STI’s techniques, trainings are held across the country, led by Ms. McCool and her colleagues, in person as well as through online webinars. Nephrology social workers who participated in a 2014 study of the effectiveness of STI webinar trainings found the trainings to be very useful and wanted them to continue.\n\nSTI is used by medical practices and Accountable Care Organizations (ACOs) for population health management and in integrated care and chronic care. STI provides curriculum, training, clinical assessment tools, and treatment plans for these organizations through 20 min win, a system that allows patient issues, identified in required biopsychosocial care plans, to be addressed in 20-minute sessions.\n\nIn 2011, STI was assessed by nephrology social workers in 17 states. Results suggested that STI further enhances existing social work skills in identifying, treating, and tracking outcomes of patient issues requiring clinical intervention. Most of the social workers spent 1.5 hours over a six-week period using STI to address symptoms of depression with a patient. This short period of intervention led to a reported improvement in physical component summary and mental component summary scores (part of the Short Form Health Survey (SF-36) patient evaluation) in 51% and 64% of patients, respectively, and improvement in CES-D scores in 72.1% of patients. In 2013, a pilot program showed that using STI's techniques helped increase patients' adherence to treatment recommendations.\n\nA 2013 study with DaVita Clinical Research, published at the National Kidney Foundation meeting in April 2014, showed statistically significant improvements in quality of life and depression scores for patients receiving STI. There were 91 participants in the study. Statistically significant improvement occurred in KDQOL-36 mental component scores (p < 0.001), physical component scores (p = 0.042), as well as burden (p < 0.001) and effects (p = 0.001) domain scores. Statistically significant improvement also occurred in patients' CES-D 10 scores (p < 0.001).\n\nIn an ongoing study conducted by Fresenius Medical Care, the use of STI, along with other clinical interventions, was shown to decrease missed treatments, decrease hospitalizations and improve quality of life indicators and depression scores. The baseline number of missed treatment rate (per month) was 1.7 (±1.3) vs. 0.9 (±1.0) post-intervention (p < 0.0001). The number of hospitalization was 0.4 (±0.8) vs. 0.2 (±0.8) per month for pre- and post-intervention, respectively, (p = 0.07). Significant improvement was found in CES-D 10 and KDQOL-36 domain scores except for physical component scores. Sleep-quality barriers and stressors also indicated significant improvement (except for restless legs and stressors related to health symptoms or loss/grief). Preliminary results indicated that an intensive social worker-initiated intervention program was able to reduce unexcused missed treatments in the short term (three months). Indicators of quality of life and well-being that potentially contributed to the non-adherent behavior also improved, which may help sustain the favorable results over the long term.\n\nResults of a 2015 study by Ms. McCool and colleagues at DaVita HealthCare Partners suggested that implementation of a social worker-based STI clinical program targeting improved quality of life for in-center hemodialysis patients led to health improvements due to increased adherence to the prescribed dialysis treatment regimen in the least-compliant patients. A poster presenting the results received best poster award at the National Kidney Foundation spring 2015 meeting. A pilot study using STI with transplant patients at the Royal Infirmary of Edinburgh was completed in 2014, and a poster presenting the results was included in the British Renal Society's annual meeting in July 2015.\n\nFurther studies are under way on the effectiveness of STI in patients with a variety of chronic diseases, including an ongoing multi-center IRB-approved research study involving the University of Maryland, University of Utah, and University of Minnesota, on the use of STI with solid organ transplant recipients.\n\n"}
{"id": "4332663", "url": "https://en.wikipedia.org/wiki?curid=4332663", "title": "Syngnathia", "text": "Syngnathia\n\nSyngnathia is a congenital adhesion of the maxilla and mandible by fibrous bands.\n"}
{"id": "702484", "url": "https://en.wikipedia.org/wiki?curid=702484", "title": "Tumescence", "text": "Tumescence\n\nTumescence is the quality or state of being tumescent or swollen. Tumescence usually refers to the normal engorgement with blood (vascular congestion) of the erectile tissues, marking sexual excitation, and possible readiness for sexual activity. The tumescent sexual organ in men is the penis and in women is the clitoris.\n\nDetumescence is the reversal of this process, by which blood leaves the erectile tissue, returning to the flaccid state. Something that causes an erection is sometimes referred to as a tumefier (tumefyer) or tumescer.\n\nRegularly, men who experience erectile dysfunction are given a nocturnal penile tumescence (NPT) test, usually over a three-day period. Such a test detects the presence of an erection occurring during sleep using either:\n\nThe goal of nocturnal penile tumescence testing is to determine whether a man can experience an erection while sleeping after reporting he is unable to experience an erection while awake. If a man does obtain an erection while sleeping, but cannot obtain one while awake, a psychological cause or a medication side effect is usually suspected. Otherwise, if a man does not obtain an erection in either state, a physiological cause is usually suspected. \n\n\n"}
{"id": "18207552", "url": "https://en.wikipedia.org/wiki?curid=18207552", "title": "Vaginal contraction", "text": "Vaginal contraction\n\nVaginal contractions are contractions of the pelvic muscles surrounding the vagina, especially the pubococcygeus muscle. Vaginal contractions are generally an involuntary muscular response to sexual stimulation, including sexual arousal, and are commonly most intense during sexual stimulation and culminating in orgasm. Though usually an involuntary response, some women can control the muscles of the vagina to perform vaginal contractions at will. Vaginal contractions enhance the sexual experience and pleasure for both parties during sexual intercourse.\n\nIn a 1982 study, pelvic contractions of 11 women who manually self-stimulated to orgasm were monitored using an anal probe and a vaginal probe simultaneously. Near the perceived start of orgasm, a series of regular contractions began in 9 of the women, with anal and vaginal contractions synchronizing with each other. Three of the women's orgasms consistently included only a series of regular contractions; for six other women, orgasms consistently continued beyond the regular series with additional irregular contractions. Two women had no regular contractions during reported orgasms. The women showed marked differences in orgasm duration and the number of contractions. A 1994 study confirmed these results, but concluded that some women experience their orgasm regularly without contractions and some report having contractions during orgasm only occasionally.\n\nVaginal contractions are caused by both the activity of certain brain regions and the release of the hormone oxytocin. It has been suggested that vaginal contractions during orgasm can increase the chances of pregnancy as they transport sperm up the reproductive tract from the vagina to the oviducts, which decreases the distance it has to travel. Additionally, when the woman is fertile sperm is only transported to the side of the dominant ovary.\n\nInvoluntary vaginal contractions may arise from non-sexual causes. Involuntary spasm of the muscles around the vagina, usually caused by anxiety, can result in vaginismus.\n\nVaginal contractions should not be confused with uterine contractions.\n\n\n"}
{"id": "28626102", "url": "https://en.wikipedia.org/wiki?curid=28626102", "title": "Western Cape Department of Health", "text": "Western Cape Department of Health\n\nThe Western Cape Department of Health is a department of the Government of the Western Cape, responsible for providing public healthcare to the population of the Western Cape province of South Africa.\n\nThe political head of the department is the Provincial Minister of Health; this is Nomafrench Mbombo of the Democratic Alliance. The administrative head is the Superintendent-General of Health; this was Professor Craig Househam. \nIn the 2010/11 financial year, the department had 27,993 employees and a budget of R11,962,863,000.\n\nIn the Western Cape there are 428 public primary care facilities (clinics and community health centres), some operated by the Department of Health, while others are operated by the City of Cape Town and funded by transfer payments from the department.\n\nPublic secondary care services are provided by 32 district hospitals, six regional hospitals, and three central hospitals (which also provide tertiary care; see below).\n\nThree central hospitals in Cape Town provide tertiary care; these are Groote Schuur Hospital, Tygerberg Hospital, and Red Cross War Memorial Children's Hospital. They take specialist referrals from other hospitals across the province, and in many cases from other provinces or even other African countries.\n\nThe department also runs various specialised facilities, including six tuberculosis hospitals, four psychiatric hospitals, and a rehabilitation centre.\n\n\n"}
{"id": "41561791", "url": "https://en.wikipedia.org/wiki?curid=41561791", "title": "Wisconsin WIC Association", "text": "Wisconsin WIC Association\n\nThe Wisconsin WIC Association, founded in 1998, is an American professional association with a mission to support and promote Wisconsin's WIC (Special Supplemental Nutrition Program for Women, Infants and Children) program as well as assist the National WIC Association in ensuring continual program existence.\n\nIn 1973, Wisconsin became a pilot state for the WIC Program. By 1974, with a budget of $350,000 and total participation of 1,300: WIC operated in Green Bay Area Free clinic, Menominee Tribe, and Great Lakes Intertribal Council. By 1980, WIC had expanded to over 55 projects, including the State’s two major urban locations Milwaukee and Madison. By 1990, the majority of the current WIC Program was in place. Divided into 5 regions and WIC services were being provided in nearly every county of Wisconsin. As WIC expanded, it became increasingly more difficult to maintain contact and communication with the numerous WIC projects throughout the state. Recognizing that, on June 30, 1998 a group of like-minded individuals met together resulting in the formation of Wisconsin WIC Association (WWA).\n\nThe WWA organizes meetings and projects by WIC employees, politicians, and community members to encourage funding, grant dispersal, and educational programs related to the WIC.\n\n"}
{"id": "36552209", "url": "https://en.wikipedia.org/wiki?curid=36552209", "title": "Yaoundé Gynaecology, Obstetrics and Pediatrics Hospital", "text": "Yaoundé Gynaecology, Obstetrics and Pediatrics Hospital\n\nThe Yaoundé Gynaecology, Obstetrics and Pediatrics Hospital (French Hôpital gynéco-obstétrique et pédiatrique de Yaoundé - HGOPY) is a hospital in Yaoundé, Cameroon that specializes in caring for women and children. The hospital was built with the assistance of the Government of China.\nIt was officially opened on 28 March 2002 by President Paul Biya in a ceremony attended by the Chinese Vice-Minister of Health.\nOutpatient care began on 1 April 2002.\n"}
{"id": "307132", "url": "https://en.wikipedia.org/wiki?curid=307132", "title": "Yovkovtsi", "text": "Yovkovtsi\n\nThe Yovkovtsi Reservoir (язовир „Йовковци“) is situated in northeastern Bulgaria, away of the town of Elena. It was built 20 years ago on the Veselina River. The reservoir is located in the territory of Elena municipality, and supplies water to Veliko Tarnovo, Gorna Oryahovitsa, Lyaskovets, Strazhitsa, Zlataritsa, Elena, Gabrovo and Dryanovo. of the reservoir are hygienic protected zone. The dam is rich in carp, pikeperch and many other kinds of fish.\n\nIt is named after the prominent writer Yordan Yovkov.\n"}
