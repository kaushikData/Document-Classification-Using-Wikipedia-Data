{"id": "23161242", "url": "https://en.wikipedia.org/wiki?curid=23161242", "title": "1962 Mexico City radiation accident", "text": "1962 Mexico City radiation accident\n\nIn March–August 1962, a radiation incident in Mexico City occurred when a ten-year-old boy took home an unprotected industrial radiography source. Four people died from overexposure to radiation from a 5-Ci cobalt-60 capsule, an industrial radiography orphaned source that was not contained in its proper shielding. For several days, the boy kept the capsule in his pocket, then placed it in the kitchen cabinet of his home in Mexico City. Having obtained the source on March 21, the boy died 38 days later on April 29. Subsequently, his mother died on July 10; his 2-year-old sister died on August 18, and his grandmother died on October 15 of that year. The boy's father also received a significant dose of radiation, however he survived. Five other individuals also received significant overdoses of radiation.\n\n"}
{"id": "1930919", "url": "https://en.wikipedia.org/wiki?curid=1930919", "title": "Abortion clinic", "text": "Abortion clinic\n\nAn abortion clinic is a medical facility that provides abortions. Such clinics may be public medical centers, private medical practices or nonprofit organizations such as Planned Parenthood.\n\n\nAbortion clinics have frequently been the site of protests by anti-abortion activists. Protesters often engage in what is known as \"sidewalk counseling\", in which they warn people entering the clinic about alleged risks of abortion, attempt to offer alternatives to abortion or show pictures of fetuses. In 1985, 85% of abortion providers were experiencing either picketing, clinic blockades or invasion of the facility, with 19% or providers receiving bomb threats and 16% were picketed at their homes . In 2000 82% of facilities received protests with 61% receiving 20 or more pickets. \n\nThe 2007 film \"Juno\" contains an example of such protest. The protagonist enters a clinic with the purpose of procuring an abortion, but sees a fellow student protesting outside the clinic who tells her that the fetus \"has fingernails\". This causes Juno to change her mind about having an abortion, and she leaves the clinic, with her friend calling out to her, \"God appreciates your miracle.\"\n\nAnother tactic in which protestors film or photograph patients entering the clinic utilizes the societal stigma surrounding abortion and attempts to expose or shame women who are seeking the procedure. Anti-abortion activists have also attempted to access abortion clinic medical records by breaking into dumpsters, proposing state legislation that would require clinics to provide information regarding their patients to the government and hacking online databases containing confidential patient information.\n\nIn some countries, a buffer zone is enforced to prevent protesters from standing within a certain distance of the clinic entrance. In the United States these buffer zones have been the subject of many lawsuits and legislative actions on both statewide and national levels. In 2014 the Supreme Court struck down a Massachusetts bill that had legalized a 35-foot buffer zone around abortion clinics in the state in 2007.\n\nOne way that anti-abortion activists have restricted access to abortion is through systematically forcing the closure of abortion clinics across the country. Between 2011 and 2016 162 abortion clinics in the United States closed or stopped offering abortions due largely to legislative regulations enacted by pro-life politicians. These bills, referred to as TRAP (Targeted Regulation of Abortion Provider) laws implement medically unnecessary restrictions for clinics that will be difficult or impossible for providers to meet, therefore forcing clinics to close under the guise of increasing the safety of the procedure.\n\nAccess to abortions is extremely limited, particularly in rural and conservative areas. According to the Guttmacher Institute, 31% of women in rural areas traveled over 100 miles in order to receive an abortion while another 43% traveled between 50–100 miles. These numbers are only increasing as more clinics are forced to close. Between 2011 and 2016 the number of abortion clinics in Texas dropped from 40 to 19 as a result of the state's House Bill 2, a TRAP law designed to force clinics into closure, which was struck down by the Supreme Court in June, 2016.\n\nAbortion clinics have frequently been subject to anti-abortion violence. \"The New York Times\" cites over one hundred clinic bombings and incidents of arson, over three hundred invasions, and over four hundred incidents of vandalism between 1978 and 1993, and the National Abortion Federation, an organization of abortion providers, cites over 300 attempted or completed instances of bombing or arson, thousands of invasions and vandalism incidents, as well as other attacks, between 1977 and 2009. According to the NAF, the first instance of arson at an abortion clinic took place in March 1976 in Oregon, and the first bombing was in Ohio in February 1978. Some notable incidents are:\n\nIn the United States, the Freedom of Access to Clinic Entrances Act was passed in 1994 in response to acts of violence at clinics, which prohibits the use of force or obstruction to interfere with a person's attempt to obtain or provide reproductive health services, and the intentional damage of a reproductive health care facility such as an abortion clinic.\n\n\n"}
{"id": "44905", "url": "https://en.wikipedia.org/wiki?curid=44905", "title": "Asthma", "text": "Asthma\n\nAsthma is a common long-term inflammatory disease of the airways of the lungs. It is characterized by variable and recurring symptoms, reversible airflow obstruction, and bronchospasm. Symptoms include episodes of wheezing, coughing, chest tightness, and shortness of breath. These episodes may occur a few times a day or a few times per week. Depending on the person, they may become worse at night or with exercise.\nAsthma is thought to be caused by a combination of genetic and environmental factors. Environmental factors include exposure to air pollution and allergens. Other potential triggers include medications such as aspirin and beta blockers. Diagnosis is usually based on the pattern of symptoms, response to therapy over time, and spirometry. Asthma is classified according to the frequency of symptoms, forced expiratory volume in one second (FEV1), and peak expiratory flow rate. It may also be classified as atopic or non-atopic, where atopy refers to a predisposition toward developing a type 1 hypersensitivity reaction.\nThere is no cure for asthma. Symptoms can be prevented by avoiding triggers, such as allergens and irritants, and by the use of inhaled corticosteroids. Long-acting beta agonists (LABA) or antileukotriene agents may be used in addition to inhaled corticosteroids if asthma symptoms remain uncontrolled. Treatment of rapidly worsening symptoms is usually with an inhaled short-acting beta-2 agonist such as salbutamol and corticosteroids taken by mouth. In very severe cases, intravenous corticosteroids, magnesium sulfate, and hospitalization may be required.\nIn 2015, 358 million people globally had asthma, up from 183 million in 1990. It caused about 397,100 deaths in 2015, most of which occurred in the developing world. It often begins in childhood. The rates of asthma have increased significantly since the 1960s. Asthma was recognized as early as Ancient Egypt. The word \"asthma\" is from the Greek , \"ásthma\", which means \"panting\".\n\nAsthma is characterized by recurrent episodes of wheezing, shortness of breath, chest tightness, and coughing. Sputum may be produced from the lung by coughing but is often hard to bring up. During recovery from an attack, it may appear pus-like due to high levels of white blood cells called eosinophils. Symptoms are usually worse at night and in the early morning or in response to exercise or cold air. Some people with asthma rarely experience symptoms, usually in response to triggers, whereas others may have marked and persistent symptoms.\n\nA number of other health conditions occur more frequently in those with asthma, including gastro-esophageal reflux disease (GERD), rhinosinusitis, and obstructive sleep apnea. Psychological disorders are also more common, with anxiety disorders occurring in between 16–52% and mood disorders in 14–41%. However, it is not known whether asthma causes psychological problems or psychological problems lead to asthma. Those with asthma, especially if it is poorly controlled, are at high risk for radiocontrast reactions.\n\nAsthma is caused by a combination of complex and incompletely understood environmental and genetic interactions. These factors influence both its severity and its responsiveness to treatment. It is believed that the recent increased rates of asthma are due to changing epigenetics (heritable factors other than those related to the DNA sequence) and a changing living environment. Onset before age 12 is more likely due to genetic influence, while onset after 12 is more likely due to environmental influence.\n\nMany environmental factors have been associated with asthma's development and exacerbation including allergens, air pollution, and other environmental chemicals. Smoking during pregnancy and after delivery is associated with a greater risk of asthma-like symptoms. Low air quality from factors such as traffic pollution or high ozone levels has been associated with both asthma development and increased asthma severity. Over half of cases in children in the United States occur in areas with air quality below EPA standards. Low air quality is more common in low-income and minority communities.\n\nExposure to indoor volatile organic compounds may be a trigger for asthma; formaldehyde exposure, for example, has a positive association. Also, phthalates in certain types of PVC are associated with asthma in children and adults. While exposure to pesticides is linked to the development of asthma it is unclear if this is a cause and effect relationship.\nThere is an association between acetaminophen (paracetamol) use and asthma. The majority of the evidence does not, however, support a causal role. A 2014 review found that the association disappeared when respiratory infections were taken into account. Use by a mother during pregnancy is also associated with an increased risk as is psychological stress during pregnancy.\nAsthma is associated with exposure to indoor allergens. Common indoor allergens include dust mites, cockroaches, animal dander (fragments of fur or feathers), and mold. Efforts to decrease dust mites have been found to be ineffective on symptoms in sensitized subjects. Certain viral respiratory infections, such as respiratory syncytial virus and rhinovirus, may increase the risk of developing asthma when acquired as young children. Certain other infections, however, may decrease the risk.\n\nThe hygiene hypothesis attempts to explain the increased rates of asthma worldwide as a direct and unintended result of reduced exposure, during childhood, to non-pathogenic bacteria and viruses. It has been proposed that the reduced exposure to bacteria and viruses is due, in part, to increased cleanliness and decreased family size in modern societies. Exposure to bacterial endotoxin in early childhood may prevent the development of asthma, but exposure at an older age may provoke bronchoconstriction. Evidence supporting the hygiene hypothesis includes lower rates of asthma on farms and in households with pets.\n\nUse of antibiotics in early life has been linked to the development of asthma. Also, delivery via caesarean section is associated with an increased risk (estimated at 20–80%) of asthma—this increased risk is attributed to the lack of healthy bacterial colonization that the newborn would have acquired from passage through the birth canal. There is a link between asthma and the degree of affluence which may be related to the hygiene hypothesis as less affluent individuals often have more exposure to bacteria and viruses.\n\nFamily history is a risk factor for asthma, with many different genes being implicated. If one identical twin is affected, the probability of the other having the disease is approximately 25%. By the end of 2005, 25 genes had been associated with asthma in six or more separate populations, including GSTM1, IL10, CTLA-4, SPINK5, LTC4S, IL4R and ADAM33, among others. Many of these genes are related to the immune system or modulating inflammation. Even among this list of genes supported by highly replicated studies, results have not been consistent among all populations tested. In 2006 over 100 genes were associated with asthma in one genetic association study alone; more continue to be found.\n\nSome genetic variants may only cause asthma when they are combined with specific environmental exposures. An example is a specific single nucleotide polymorphism in the CD14 region and exposure to endotoxin (a bacterial product). Endotoxin exposure can come from several environmental sources including tobacco smoke, dogs, and farms. Risk for asthma, then, is determined by both a person's genetics and the level of endotoxin exposure.\n\nA triad of atopic eczema, allergic rhinitis and asthma is called atopy. The strongest risk factor for developing asthma is a history of atopic disease; with asthma occurring at a much greater rate in those who have either eczema or hay fever. Asthma has been associated with eosinophilic granulomatosis with polyangiitis (formerly known as Churg–Strauss syndrome), an autoimmune disease and vasculitis. Individuals with certain types of urticaria may also experience symptoms of asthma.\n\nThere is a correlation between obesity and the risk of asthma with both having increased in recent years. Several factors may be at play including decreased respiratory function due to a buildup of fat and the fact that adipose tissue leads to a pro-inflammatory state.\n\nBeta blocker medications such as propranolol can trigger asthma in those who are susceptible. Cardioselective beta-blockers, however, appear safe in those with mild or moderate disease. Other medications that can cause problems in asthmatics are angiotensin-converting enzyme inhibitors, aspirin, and NSAIDs. Use of acid suppressing medication (proton pump inhibitors and H2 blockers) during pregnancy is associated with an increased risk of asthma in the child.\n\nSome individuals will have stable asthma for weeks or months and then suddenly develop an episode of acute asthma. Different individuals react to various factors in different ways. Most individuals can develop severe exacerbation from a number of triggering agents.\n\nHome factors that can lead to exacerbation of asthma include dust, animal dander (especially cat and dog hair), cockroach allergens and mold. Perfumes are a common cause of acute attacks in women and children. Both viral and bacterial infections of the upper respiratory tract can worsen the disease. Psychological stress may worsen symptoms—it is thought that stress alters the immune system and thus increases the airway inflammatory response to allergens and irritants.\n\nAsthma is the result of chronic inflammation of the conducting zone of the airways (most especially the bronchi and bronchioles), which subsequently results in increased contractability of the surrounding smooth muscles. This among other factors leads to bouts of narrowing of the airway and the classic symptoms of wheezing. The narrowing is typically reversible with or without treatment. Occasionally the airways themselves change. Typical changes in the airways include an increase in eosinophils and thickening of the lamina reticularis. Chronically the airways' smooth muscle may increase in size along with an increase in the numbers of mucous glands. Other cell types involved include: T lymphocytes, macrophages, and neutrophils. There may also be involvement of other components of the immune system including: cytokines, chemokines, histamine, and leukotrienes among others.\n\nWhile asthma is a well-recognized condition, there is not one universal agreed upon definition. It is defined by the Global Initiative for Asthma as \"a chronic inflammatory disorder of the airways in which many cells and cellular elements play a role. The chronic inflammation is associated with airway hyper-responsiveness that leads to recurrent episodes of wheezing, breathlessness, chest tightness and coughing particularly at night or in the early morning. These episodes are usually associated with widespread but variable airflow obstruction within the lung that is often reversible either spontaneously or with treatment\".\n\nThere is currently no precise test for the diagnosis, which is typically based on the pattern of symptoms and response to therapy over time. A diagnosis of asthma should be suspected if there is a history of recurrent wheezing, coughing or difficulty breathing and these symptoms occur or worsen due to exercise, viral infections, allergens or air pollution. Spirometry is then used to confirm the diagnosis. In children under the age of six the diagnosis is more difficult as they are too young for spirometry.\n\nSpirometry is recommended to aid in diagnosis and management. It is the single best test for asthma. If the FEV1 measured by this technique improves more than 12% and increases by at least 200 milliliters following administration of a bronchodilator such as salbutamol, this is supportive of the diagnosis. It however may be normal in those with a history of mild asthma, not currently acting up. As caffeine is a bronchodilator in people with asthma, the use of caffeine before a lung function test may interfere with the results. Single-breath diffusing capacity can help differentiate asthma from COPD. It is reasonable to perform spirometry every one or two years to follow how well a person's asthma is controlled.\n\nThe methacholine challenge involves the inhalation of increasing concentrations of a substance that causes airway narrowing in those predisposed. If negative it means that a person does not have asthma; if positive, however, it is not specific for the disease.\n\nOther supportive evidence includes: a ≥20% difference in peak expiratory flow rate on at least three days in a week for at least two weeks, a ≥20% improvement of peak flow following treatment with either salbutamol, inhaled corticosteroids or prednisone, or a ≥20% decrease in peak flow following exposure to a trigger. Testing peak expiratory flow is more variable than spirometry, however, and thus not recommended for routine diagnosis. It may be useful for daily self-monitoring in those with moderate to severe disease and for checking the effectiveness of new medications. It may also be helpful in guiding treatment in those with acute exacerbations.\n\nAsthma is clinically classified according to the frequency of symptoms, forced expiratory volume in one second (FEV), and peak expiratory flow rate. Asthma may also be classified as atopic (extrinsic) or non-atopic (intrinsic), based on whether symptoms are precipitated by allergens (atopic) or not (non-atopic). While asthma is classified based on severity, at the moment there is no clear method for classifying different subgroups of asthma beyond this system. Finding ways to identify subgroups that respond well to different types of treatments is a current critical goal of asthma research.\n\nAlthough asthma is a chronic obstructive condition, it is not considered as a part of chronic obstructive pulmonary disease, as this term refers specifically to combinations of disease that are irreversible such as bronchiectasis, chronic bronchitis, and emphysema. Unlike these diseases, the airway obstruction in asthma is usually reversible; however, if left untreated, the chronic inflammation from asthma can lead the lungs to become irreversibly obstructed due to airway remodeling. In contrast to emphysema, asthma affects the bronchi, not the alveoli.\n\nAn acute asthma exacerbation is commonly referred to as an \"asthma attack\". The classic symptoms are shortness of breath, wheezing, and chest tightness. The wheezing is most often when breathing out. While these are the primary symptoms of asthma, some people present primarily with coughing, and in severe cases, air motion may be significantly impaired such that no wheezing is heard. In children, chest pain is often present.\n\nSigns occurring during an asthma attack include the use of accessory muscles of respiration (sternocleidomastoid and scalene muscles of the neck), there may be a paradoxical pulse (a pulse that is weaker during inhalation and stronger during exhalation), and over-inflation of the chest. A blue color of the skin and nails may occur from lack of oxygen.\n\nIn a mild exacerbation the peak expiratory flow rate (PEFR) is ≥200 L/min, or ≥50% of the predicted best. Moderate is defined as between 80 and 200 L/min, or 25% and 50% of the predicted best, while severe is defined as ≤ 80 L/min, or ≤25% of the predicted best.\n\nAcute severe asthma, previously known as status asthmaticus, is an acute exacerbation of asthma that does not respond to standard treatments of bronchodilators and corticosteroids. Half of cases are due to infections with others caused by allergen, air pollution, or insufficient or inappropriate medication use.\n\nBrittle asthma is a kind of asthma distinguishable by recurrent, severe attacks. Type 1 brittle asthma is a disease with wide peak flow variability, despite intense medication. Type 2 brittle asthma is background well-controlled asthma with sudden severe exacerbations.\n\nExercise can trigger bronchoconstriction both in people with or without asthma. It occurs in most people with asthma and up to 20% of people without asthma. Exercise-induced bronchoconstriction is common in professional athletes. The highest rates are among cyclists (up to 45%), swimmers, and cross-country skiers. While it may occur with any weather conditions, it is more common when it is dry and cold. Inhaled beta2-agonists do not appear to improve athletic performance among those without asthma, however, oral doses may improve endurance and strength.\n\nAsthma as a result of (or worsened by) workplace exposures is a commonly reported occupational disease. Many cases, however, are not reported or recognized as such. It is estimated that 5–25% of asthma cases in adults are work-related. A few hundred different agents have been implicated, with the most common being: isocyanates, grain and wood dust, colophony, soldering flux, latex, animals, and aldehydes. The employment associated with the highest risk of problems include: those who spray paint, bakers and those who process food, nurses, chemical workers, those who work with animals, welders, hairdressers and timber workers.\n\nAspirin-exacerbated respiratory disease (AERD), also known as aspirin-induced asthma, affects up to 9% of asthmatics. AERD consists of asthma, nasal polyps, sinus disease, and respiratory reactions to aspirin and other NSAID medications (such as ibuprofen and naproxen). People often also develop loss of smell and most experience respiratory reactions to alcohol.\n\nAlcohol may worsen asthmatic symptoms in up to a third of people. This may be even more common in some ethnic groups such as the Japanese and those with aspirin-induced asthma. Other studies have found improvement in asthmatic symptoms from alcohol.\n\nNonallergic asthma, also known as intrinsic or nonatopic asthma, makes up between 10 and 33% of cases. There is negative skin test to common inhalant allergens and normal serum concentrations of IgE. Often it starts later in life, and women are more commonly affected than men. Usual treatments may not work as well.\n\nMany other conditions can cause symptoms similar to those of asthma. In children, other upper airway diseases such as allergic rhinitis and sinusitis should be considered as well as other causes of airway obstruction including foreign body aspiration, tracheal stenosis, laryngotracheomalacia, vascular rings, enlarged lymph nodes or neck masses. Bronchiolitis and other viral infections may also produce wheezing. In adults, COPD, congestive heart failure, airway masses, as well as drug-induced coughing due to ACE inhibitors should be considered. In both populations vocal cord dysfunction may present similarly.\n\nChronic obstructive pulmonary disease can coexist with asthma and can occur as a complication of chronic asthma. After the age of 65, most people with obstructive airway disease will have asthma and COPD. In this setting, COPD can be differentiated by increased airway neutrophils, abnormally increased wall thickness, and increased smooth muscle in the bronchi. However, this level of investigation is not performed due to COPD and asthma sharing similar principles of management: corticosteroids, long-acting beta-agonists, and smoking cessation. It closely resembles asthma in symptoms, is correlated with more exposure to cigarette smoke, an older age, less symptom reversibility after bronchodilator administration, and decreased likelihood of family history of atopy.\n\nThe evidence for the effectiveness of measures to prevent the development of asthma is weak. The World Health Organization recommends decreasing risk factors such as tobacco smoke, air pollution, chemical irritants including perfume, and the number of lower respiratory infections. Other efforts that show promise include: limiting smoke exposure in utero, breastfeeding, and increased exposure to daycare or large families, but none are well supported enough to be recommended for this indication.\n\nEarly pet exposure may be useful. Results from exposure to pets at other times are inconclusive and it is only recommended that pets be removed from the home if a person has allergic symptoms to said pet.\n\nDietary restrictions during pregnancy or when breast feeding have not been found to be effective and thus are not recommended. Reducing or eliminating compounds known to sensitive people from the work place may be effective. It is not clear if annual influenza vaccinations affects the risk of exacerbations. Immunization; however, is recommended by the World Health Organization. Smoking bans are effective in decreasing exacerbations of asthma.\n\nWhile there is no cure for asthma, symptoms can typically be improved. A specific, customized plan for proactively monitoring and managing symptoms should be created. This plan should include the reduction of exposure to allergens, testing to assess the severity of symptoms, and the usage of medications. The treatment plan should be written down and advise adjustments to treatment according to changes in symptoms.\n\nThe most effective treatment for asthma is identifying triggers, such as cigarette smoke, pets, or aspirin, and eliminating exposure to them. If trigger avoidance is insufficient, the use of medication is recommended. Pharmaceutical drugs are selected based on, among other things, the severity of illness and the frequency of symptoms. Specific medications for asthma are broadly classified into fast-acting and long-acting categories.\n\nBronchodilators are recommended for short-term relief of symptoms. In those with occasional attacks, no other medication is needed. If mild persistent disease is present (more than two attacks a week), low-dose inhaled corticosteroids or alternatively, an leukotriene antagonist or a mast cell stabilizer by mouth is recommended. For those who have daily attacks, a higher dose of inhaled corticosteroids is used. In a moderate or severe exacerbation, corticosteroids by mouth are added to these treatments.\n\nPeople with asthma have higher rates of anxiety and depression. This is associated with poorer asthma control. Cognitive behavioral therapy may improve quality of life, asthma control, and anxiety levels in people with asthma.\n\nAvoidance of triggers is a key component of improving control and preventing attacks. The most common triggers include allergens, smoke (tobacco and other), air pollution, non selective beta-blockers, and sulfite-containing foods. Cigarette smoking and second-hand smoke (passive smoke) may reduce the effectiveness of medications such as corticosteroids. Laws that limit smoking decrease the number of people hospitalized for asthma. Dust mite control measures, including air filtration, chemicals to kill mites, vacuuming, mattress covers and others methods had no effect on asthma symptoms. Overall, exercise is beneficial in people with stable asthma. Yoga could provide small improvements in quality of life and symptoms in people with asthma.\n\nMedications used to treat asthma are divided into two general classes: quick-relief medications used to treat acute symptoms; and long-term control medications used to prevent further exacerbation. Antibiotics are generally not needed for sudden worsening of symptoms.\n\n\n\nMedications are typically provided as metered-dose inhalers (MDIs) in combination with an asthma spacer or as a dry powder inhaler. The spacer is a plastic cylinder that mixes the medication with air, making it easier to receive a full dose of the drug. A nebulizer may also be used. Nebulizers and spacers are equally effective in those with mild to moderate symptoms. However, insufficient evidence is available to determine whether a difference exists in those with severe disease. There is no strong evidence for the use of intravenous LABA for adults or children who have acute asthma.\n\nLong-term use of inhaled corticosteroids at conventional doses carries a minor risk of adverse effects. Risks include thrush, the development of cataracts, and a slightly slowed rate of growth. Higher doses of inhaled steroids may result in lower bone mineral density.\n\nWhen asthma is unresponsive to usual medications, other options are available for both emergency management and prevention of flareups. For emergency management other options include:\n\n\nMany people with asthma, like those with other chronic disorders, use alternative treatments; surveys show that roughly 50% use some form of unconventional therapy. There is little data to support the effectiveness of most of these therapies. Evidence is insufficient to support the usage of vitamin C. There is tentative support for its use in exercise induced bronchospasm. In people with mild to moderate asthma, treatment with vitamin D supplementation is likely to reduce the risk of asthma exacerbations.\n\nAcupuncture is not recommended for the treatment as there is insufficient evidence to support its use. Air ionisers show no evidence that they improve asthma symptoms or benefit lung function; this applied equally to positive and negative ion generators.\n\nManual therapies, including osteopathic, chiropractic, physiotherapeutic and respiratory therapeutic maneuvers, have insufficient evidence to support their use in treating asthma. The Buteyko breathing technique for controlling hyperventilation may result in a reduction in medication use; however, the technique does not have any effect on lung function. Thus an expert panel felt that evidence was insufficient to support its use.\n\nThe prognosis for asthma is generally good, especially for children with mild disease. Mortality has decreased over the last few decades due to better recognition and improvement in care. In 2010 the death rate was 170 per million for males and 90 per million for females. Rates vary between countries by 100 fold.\n\nGlobally it causes moderate or severe disability in 19.4 million people as of 2004 (16 million of which are in low and middle income countries). Of asthma diagnosed during childhood, half of cases will no longer carry the diagnosis after a decade. Airway remodeling is observed, but it is unknown whether these represent harmful or beneficial changes. Early treatment with corticosteroids seems to prevent or ameliorates a decline in lung function. Asthma in children also has negative effects on quality of life of their parents.\n\nAs of 2011, 235–330 million people worldwide are affected by asthma, and approximately 250,000–345,000 people die per year from the disease. Rates vary between countries with prevalences between 1 and 18%. It is more common in developed than developing countries. One thus sees lower rates in Asia, Eastern Europe and Africa. Within developed countries it is more common in those who are economically disadvantaged while in contrast in developing countries it is more common in the affluent. The reason for these differences is not well known. Low and middle income countries make up more than 80% of the mortality.\n\nWhile asthma is twice as common in boys as girls, severe asthma occurs at equal rates. In contrast adult women have a higher rate of asthma than men and it is more common in the young than the old. In children, asthma was the most common reason for admission to the hospital following an emergency department visit in the US in 2011.\n\nGlobal rates of asthma have increased significantly between the 1960s and 2008 with it being recognized as a major public health problem since the 1970s. Rates of asthma have plateaued in the developed world since the mid-1990s with recent increases primarily in the developing world. Asthma affects approximately 7% of the population of the United States and 5% of people in the United Kingdom. Canada, Australia and New Zealand have rates of about 14–15%.\n\nThe average death rate from 2011 to 2015 from asthma in the UK was about 50% higher than the average for the European Union and had increased by about 5% in that time.\n\nFrom 2000 to 2010, the average cost per asthma-related hospital stay in the United States for children remained relatively stable at about $3,600, whereas the average cost per asthma-related hospital stay for adults increased from $5,200 to $6,600. In 2010, Medicaid was the most frequent primary payer among children and adults aged 18–44 years in the United States; private insurance was the second most frequent payer. Among both children and adults in the lowest income communities in the United States there is a higher rate of hospital stays for asthma in 2010 than those in the highest income communities.\n\nAsthma was recognized in ancient Egypt and was treated by drinking an incense mixture known as kyphi. It was officially named as a specific respiratory problem by Hippocrates circa 450 BC, with the Greek word for \"panting\" forming the basis of our modern name. In 200 BC it was believed to be at least partly related to the emotions. In the 12th century the Jewish physician-philosopher Maimonides wrote a treatise on asthma in Arabic, based partly on Arabic sources, in which he discussed the symptoms, proposed various dietary and other means of treatment, and emphasized the importance of climate and clean air.\nIn 1873, one of the first papers in modern medicine on the subject tried to explain the pathophysiology of the disease while one in 1872, concluded that asthma can be cured by rubbing the chest with chloroform liniment. Medical treatment in 1880 included the use of intravenous doses of a drug called pilocarpine. In 1886, F.H. Bosworth theorized a connection between asthma and hay fever. Epinephrine was first referred to in the treatment of asthma in 1905. Oral corticosteroids began to be used for this condition in the 1950s while inhaled corticosteroids and selective short acting beta agonist came into wide use in the 1960s.\n\nA notable and well-documented case in the 19th century was that of young Theodore Roosevelt (1858–1919). At that time there was no effective treatment. Roosevelt's youth was in large part shaped by his poor health partly related to his asthma. He experienced recurring nighttime asthma attacks that caused the experience of being smothered to death, terrifying the boy and his parents.\n\nDuring the 1930s to 1950s, asthma was known as one of the \"holy seven\" psychosomatic illnesses. Its cause was considered to be psychological, with treatment often based on psychoanalysis and other talking cures. As these psychoanalysts interpreted the asthmatic wheeze as the suppressed cry of the child for its mother, they considered the treatment of depression to be especially important for individuals with asthma.\n"}
{"id": "48511978", "url": "https://en.wikipedia.org/wiki?curid=48511978", "title": "Australian Institute of Personal Trainers", "text": "Australian Institute of Personal Trainers\n\nThe Australian Institute of Personal Trainers (AIPT – RTO 32363) is a privately owned registered training organisation, specialising in a range of health, wellness and fitness qualifications which are delivered both online and face-to-face.\n\nEstablished in 2000 the Australian Institute of Personal Trainers expanded from a handful of education training centres in Queensland to an Australia-wide fitness education network.\n\nAIPT was founded by Paul Timms.\n\nAdam Jacobs joined AIPT as National Campus Manager in 2011. In 2014, he was promoted to CEO of AIPT.\n\nKylie Fahey became Foundation Education Group CEO in March 2014.\n\nKevin Kalinko has a bachelor's degree in Commerce and a Post Graduate Diploma in Applied Finance. He is Foundation Education Director and a board member for Fitness Australia.\n\nThe Australian Institute of Personal Trainers offers nationally recognised Certificate and Diploma level qualifications (with VET FEE-HELP approved for eligible courses), with a primary focus on health and fitness, extending through to subjects including business, management, finance, marketing, events, education and travel.\n\nThe AIPT delivers the majority of their courses online, with a number of fitness qualifications offered in a face-to-face environment.\n\nThe Australian Institute of Personal Trainers partners with several health and fitness clubs in Australia, including:\nThese partners also act as a placement outlet for fitness students undertaking practical elements of their course.\n\nThe Australian Institute of Personal Trainers partners with several Australian universities, offering both articulation agreements and credit transfer agreements to minimise the cost and time spent undertaking a tertiary qualification.\n\n"}
{"id": "8853649", "url": "https://en.wikipedia.org/wiki?curid=8853649", "title": "Bakulev Scientific Center of Cardiovascular Surgery", "text": "Bakulev Scientific Center of Cardiovascular Surgery\n\nBakulev Scientific Center for Cardiovascular Surgery () is attached to the Russian Academy of Medical Sciences and is one of the leading cardiovascular surgery-related facilities of the Russian Federation. The center consists of Burakovskiy Institute of Cardiac Surgery and the Institute of Coronary and Vascular Surgery, both located in Moscow, as wells as it has a filial branch in Perm - Perm Heart Institute. In 2005 the Center started the first phase of research into the transplant of marrow cells in patients with acute myocardial infarction.\n\nThe Center was founded in 1956 by Soviet surgeon Aleksandr Bakulev, being officially named the Thoracal Surgery Institute of the Academy of Medical Sciences of the USSR (Институт грудной хирургии Академии медицинских наук СССР) at the time. In 1961 the facility was renamed to the Institute of Cardiovascular Surgery and in 1967, following Bakulev's death, gained his name.\n\nBourakovsky Institute of Cardiac Surgery of Bakoulev CCVS RAMS\n\nInstitute of Coronary and Vascular Surgery of BCCVS RAMS\n\nPerm Heart Institute – The Filial Branch of BCCVS RAMS\n\nThe network community Dissernet has pointed out that the Center has repeatedly (>45 cases) awarded the Ph.D level degrees based on heavily plagiarised and sometimes falsified theses.\n\n"}
{"id": "23931236", "url": "https://en.wikipedia.org/wiki?curid=23931236", "title": "Caribbean Accreditation Authority for Education in Medicine and other Health Professions", "text": "Caribbean Accreditation Authority for Education in Medicine and other Health Professions\n\nThe Caribbean Accreditation Authority for Education in Medicine and other Health Professions (CAAM-HP) is an accrediting body for medical, veterinary, and dental schools in the 15 member nations of the Caribbean Community (CARICOM). CAAM-HP was established in 2003.\n\nThe US Department of Education's National Committee on Foreign Medical Education and Accreditation (NCFMEA) recognizes CAAM-HP as a standard comparable to the standards used in medical schools in the United States.\n\nThe departments of education from both United States and Canada contacted the Educational Commission for Foreign Medical Graduates (ECFMG) and has required that all Caribbean Medical Schools be at the standard of United States and Canadian medical schools, this led the CARICOM to create the Caribbean Accreditation Authority for Education in Medicine and other Health Professions (CAAM-HP) organization who will be assessing Caribbean medical schools. Students of those schools that do not receive accreditation from CAAM-HP or another regional accrediting body recognized by the World Federation for Medical Education (WFME) will not be able to complete neither USMLE examinations nor MCCQE, and therefore will not be able to become United States or Canadian doctors, if their school is not certified by the year 2023. \n\nSchools in CARICOM member countries not appearing above have either not been assessed by CAAM-HP or are pending accreditation.\n\n\n"}
{"id": "44396100", "url": "https://en.wikipedia.org/wiki?curid=44396100", "title": "Carlos Baca", "text": "Carlos Baca\n\nCarlos Baca (born July 24, 1951) is a Mexican intellectual, cartoonist, visual artist, ecologist, yogi, writer and rock music critic. He is most recognized for being a key figure of the counterculture movement known as La Onda and the creator of the comic strip character \"Avandarito\".\n\nBorn as Carlos Eduardo Baca Delgado in Mexico City, he was attracted to nature from early childhood, spending long hours in the famous Chapultepec Woods. From 1969 to 1979 he studied Yoga and vegetarianism at the Universal Great Brotherhood becoming an international teacher and lecturer afterwards.\n\nIn 1968 he was invited to collaborate with the magazine \"México Canta\" and by 1969 he was appointed its director. At the same time he was also hired as collaborator in the \"POP\" magazine, writing about philosophy and ecology and making memorable interviews to artists such as Juan Gabriel, Ravi Shankar, Love Army, Jim Morrison, Joan Manuel Serrat, Janis Joplin among others.\n\nIn 1971, together with other La Onda stars such as Mayita Campos, José Roberto Hill and Margarita Bauche, he funded the commune \"La Nueva Familia\" (The new family) in San Lorenzo Acopilco, outside Mexico City. The hippie commune was notable for its production of bread and cereals.\n\nIn September of the same year he went to the Avandaro Festival to make a reportage on site, but since he was highly revered by the \"jipitecas\" and his La Onda peers, he was persuaded by Armando Molina, the festival's appointed music coordinator, to inaugurate the festival with a yoga session and an ecology lecture.\n\nIn the aftermath of the festival he created the comic strip \"Aliviane a la Madre Tierra\" (Aid to Mother Earth) including its famous character \"Avandarito\" which was included as part of the POP magazine and was printed from 1971 to 1973.\n\nBy 1974 as the hippie movement waned world wide and the commune members dispersed each pursuing their own goals in their careers, Baca focused his attention to further his knowledge of nature studying in Taos, New Mexico and attending several seminars. He published his book \"Nutrición Natural al Alcance de Todos\" (Natural nutrition for all) in 1976, starting a notable career which expands 4 decades as a lecturer and writer of ecology, nutrition and environmental issues. He founded \"ALECOS\", a club destined to promote healthy lifestyles and alternative medicine.\n\nHis authoritative texts about the counterculture are still being re-published in new books on the subject.\n\nOn the special occasion of the 40th anniversary of the Avandaro Festival, he was invited by his peers to an event named \"Estrellas de Avandaro\" (Avandaro stars) and received coverage by publications like the \"Rolling Stone\" and \"El Universal\".\n\n\n\n\n"}
{"id": "18041561", "url": "https://en.wikipedia.org/wiki?curid=18041561", "title": "Centre for Applied Genomics", "text": "Centre for Applied Genomics\n\nThe Centre for Applied Genomics is a genome centre in the Research Institute of The Hospital for Sick Children, and is affiliated with the University of Toronto. TCAG also operates as a Science and Technology Innovation Centre of Genome Canada, with an emphasis on next-generation sequencing (NGS) and bioinformatics support. Research at TCAG focuses on the genetic and genomic basis of human variability, health and disease, including research on the genetics of autism spectrum disorder and structural variation of the human genome. The Centre is located in the Peter Gilgan Centre for Research and Learning in downtown Toronto, Canada.\n\nThe need for a centralized core facility for human genome research at SickKids Hospital prompted the establishment of The Centre for Applied Genomics (TCAG) in 1998. The Founding Director and Associate Director were Drs. Lap-Chee Tsui and Stephen W. Scherer, respectively. Dr. Scherer is now the Scientific Director.\n\nFunding from the Canada Foundation for Innovation (CFI) enabled TCAG to form by consolidating existing core facilities including the Medical Research Council of Canada Genome Resource Facility, the Canadian Genetic Diseases Network (CGDN) large insert clone core, the CGDN DNA Sequencing Core and the SickKids Biotechnology Service DNA Sequencing and Synthesis labs. A genome-wide microsatellite genotyping laboratory at the Ottawa Health Research Institute led by Dr. Dennis Bulman was added. Subsequently, operational funding from the CIHR Genomics Special Projects panel provided for additional staff.\n\nIn 2001, a proposal entitled \"Genome Resource Core Platform\" was submitted to the then newly formed Genome Canada. This provided operational support, enhancing existing facilities and adding a mouse genotyping core at the University of Toronto led by Dr. Lucy Osborne. In 2002, SickKids built a new Affymetrix microarray facility. This core has quickly grown to become the largest such service centre in Canada and is in the top ten in North America.\n\nIn 2004, TCAG entered a second phase of development driven by a $12 million CFI/Ontario Innovation Trust funded project entitled \"Integrative Genomics for Health Research\", allowing for consolidation of the mouse genotyping core with the SickKids facilities. This award also supported the establishment of an \"Ontario Population Genomics Repository\" (OPGP) to be used as controls in studies of common diseases. To efficiently complete this project, TCAG partnered with Dr. John McLaughlin's group at Mount Sinai Hospital (Toronto).\n\nIn May, 2004, an application to the newly announced CFI Research Hospital Fund resulted in a $10.9 million award to build out lab space and consolidate all operations on the 14th and 15th floors of the Toronto Medical Discovery Tower (TMDT) in the MaRS Discovery District. TCAG was the first occupant of TMDT (in August, 2005), quickly followed by other SickKids scientists. Investments in computer infrastructure from the 2003 CFI/Ontario Innovation Trust competition resulted in the establishment of new phases of the high-performance computing cluster (HPF) that is currently used by TCAG and many other users, to allow analysis of large genomic datasets arising from new microarray and sequencing technologies. Further enhancements to the TCAG infrastructure were supported by a $10.7 million renewal grant from CFI's Leading Edge Fund competition, entitled \"Integrative Genomics for Health Research – Phase II\", awarded in June 2009. More recently, a CFI grant entitled \"The Centre for Applied Genomics: Paediatric Genomes to Outcomes\" provided further infrastructure support. In October 2013, TCAG moved to the Peter Gilgan Centre for Research and Learning, a new building housing the SickKids Research Institute.\n\nTCAG operates in large part on Science and Technology Innovation Centre (STIC) funds from Genome Canada, administered by the Ontario Genomics Institute.\n\nCurrent research at TCAG centres around large-scale projects performed by facility personnel, including support of Genome Canada projects, and a significant focus on the genetics of autism spectrum disorders and structural variation of the human genome. Service work is also performed for over 600 other academic, private sector and government labs each year, drawn from 30 different countries and spanning a wide variety of research disciplines.\n\nPast research at TCAG is reflected by numerous peer-reviewed scientific publications. In 2008, TCAG Scientific Directors, Associate Scientists and staff co-authored 58 peer-reviewed manuscripts dependent in some way (either entirely, or in part) on the platform infrastructure, as documented in PubMed. Since 2002, over 270 such papers have been published. Support of other researchers worldwide is found in many similar publications, with at least 145 papers in scholarly journals, book chapters, or graduate thesis dissertations acknowledging support or use of database resources during 2008 alone.\n\nHistorical papers include:\n\nTCAG was also integral to publications describing the decoding of human chromosome 7, the discovery of large-scale copy number variation in the human genome, and the analysis of the first diploid human genome sequence (with the J. Craig Venter Institute).\n\nAs a Science and Technology Innovation Centre of Genome Canada, TCAG currently supports numerous large-scale projects, including research on autism spectrum disorders, structural variation of the human genome, integrative biology, conditional mouse mutagenesis, interactions of signaling molecules, type I diabetes, cancer stem cells, Cystic Fibrosis, biodiversity, structural biology, and stem cells, from Genome Canada's Competition III, New Technology Development and Applied Genomics Research in Bioproducts or Crops (ABC) competitions. The Centre is now working with applicants in the Large-Scale Applied Research Project and Advancing Technology Innovation Through Discovery competitions.\n\nTCAG also hosts and curates websites and databases developed from supported projects, namely \"The Chromosome 7 Database\", \"The Database of Genomic Variants\", the \"Segmental Duplication Database\", the \"Autism Chromosome Rearrangement Database\", and others. These databases contain publicly available information.\n\nTCAG employs a variety of genomic technologies to support different types of experimentation. These are organized into separate Core Facilities, with dedicated managers.\n\nThe Bioinformatics team assists with data handling and analysis, and develops new algorithms and analytical methods, with a focus on the analysis of high-throughput (\"next-generation\") sequencing data. The Statistical Analysis group provides project consultation and power analysis, statistical analysis (genetic, microarray, and pathway data, epidemiology, population genetics), and copy number variation analysis, as well as developing new statistical methods.\n\nThe facility uses conventional capillary Sanger sequencing on Applied Biosystems 3730xl instruments, governed by a Laboratory Information Management System (LIMS). Additionally, next-generation sequencing (NGS) using Illumina HiSeq 2500 and HiScan SQ instruments, Life Technologies Ion Proton and Applied Biosystems SOLiD instruments, and a 454/Roche GS-FLX Titanium instrument is performed. A key component of this facility is the use of high-performance computing and bioinformatics support for NGS analysis.\n\nThe Oligonucleotide Synthesis component of this facility makes conventional, long (up to 120 bases) and modified oligonucleotides, and purifies these by desalting, cartridge or high-performance liquid chromatography (HPLC).\n\nThe Microarray and Gene Expression Core Facility has a dedicated manager, and operates technologies from Affymetrix, Agilent and Illumina. Additionally, there is a wide variety of analytical software packages available for on-site data analysis.\n\nThe Cytogenomics and Genome Resources Core Facility has a single manager between these two functions. Cytogenomics includes karyotyping and spectral (SKY) karyotyping (for mouse, human, and other species), fluorescent \"in situ\" hybridization (FISH) mapping, transgenic insertion site mapping (G-to-FISH mapping) and clone labeling for FISH experiments. The Genome Resources components includes a clone repository (Mammalian Gene Collection (MGC) cDNA (mouse and human), genomic clones including human bacterial artificial chromosomes (BACs)) and provides project consultation and design assistance (annotation, database queries, probe selection). It also provides cDNA library screening and quantitative PCR.\n\nThe Genetic Analysis area includes capillary-based genotyping (Applied Biosystems TaqMan and SNaPshot, microsatellites), custom genotyping (e.g. heteroduplex analysis), mouse genotyping (for cross progeny and genetic linkage analysis), and methylation analysis (for epigenetics research).\n\nThe Biobanking Core Facility has its own dedicated manager. It performs white cell immortalization (from blood) and banking, fibroblast culture and banking, culture and banking of other cell types including non-human cells, genomic DNA preparation from blood, saliva, tissues or cells, and whole-genome amplification (WGA).\n\nTCAG is funded by several agencies, including the Canada Foundation for Innovation (CFI), Genome Canada through the Ontario Genomics Institute, the Ontario Ministry of Research and Innovation. Additionally, philanthropic donations are administered by The Hospital for Sick Children Foundation, and specific research projects are funded by a wide variety of agencies and charitable foundations.\n\nThe Scientific Director of TCAG is Dr. Stephen W. Scherer, Senior Staff Scientist in The Hospital for Sick Children's Research Institute, Director of the McLaughlin Centre, and a professor at the University of Toronto.\n\nTCAG is governed by a Scientific Management Committee, who meet regularly to discuss high-level strategic planning. The Scientific Management Committee consists of:\n\n\nDrs. Bader and Brudno are located at the University of Toronto, and the others at The Hospital for Sick Children (Brudno is also appointed at SickKids). The committee also includes three \"ex officio\" members: the Assistant Director, Facility Manager, and a representative from the Ontario Genomics Institute.\n\nSince 2006, TCAG has appointed Associate Investigators. These associates consult on their specific areas of expertise, and assist in identification and implementation of new technologies. At present, there are seven Associate Investigators: Drs. Ann George (SickKids), Esteban Parra (UTM), Mary Shago (SickKids), Mark Silverberg (MSH), James Stavropoulos (SickKids), Michael Taylor (SickKids), and John Vincent (CAMH).\n\nHigh-level scientific oversight of TCAG's scientific mandate and operations is provided through an external Scientific Advisory Board (SAB). The SAB members are:\n\n\nThe Ontario Genomics Institute (OGI) and Genome Canada also provide \"ex officio\" members.\n\n"}
{"id": "18908012", "url": "https://en.wikipedia.org/wiki?curid=18908012", "title": "Community hospital", "text": "Community hospital\n\nA community hospital can be purely a nominal designation or have a more specific meaning. When specific, it refers to a hospital that is accessible to the general public, and provides a general or specific medical care which is usually short-term, in a cost-effective setting, and also focuses on preventing illnesses and not only treating them. The following countries have specified definitions for a community hospital:\n\nIn Thailand, \"community hospital\" is a specific classification of public hospitals with a capacity of 150 beds or fewer. They serve local populations in provincial districts, providing primary care.\n\nAn older term \"cottage hospital\" is now no longer applicable, having falling from use because it inadequately describes the wide range of services being offered by their more modern equivalents. For many years the development of community hospitals was ad hoc, reflecting history rather than any rational planning.\n\nThe (non-statutory) phrase is used in England in a similar manner to Scotland. Actual arrangements will be under legislation applicable to the English NHS.\n\nIn Northern Ireland the phrase has similar use to Scotland but official publications give the appearance of \"community hospitals\" being more recent as a concept rather than a mere description.\n\n\"Community Hospital\" is not a statutory phrase but it is often used where there is \"a unit or centre providing an appropriate range and format of accessible health care facilities and resources\". Medical care is normally led by GPs, in liaison with consultant, nursing and allied health professional colleagues as necessary. These hospitals are typically small, using either purpose-built new premises or smaller general hospitals which have been retained to provide non-emergency services after general hospital services have been transferred to more centralised facilities; in some cases the services include in-patient care. Community hospitals can assist multidisciplinary working and can be used as an extended primary care resource. Community hospitals provide over 2,900 inpatient beds and over 750,000 outpatient, allied health professional and nurse led appointments. In many rural and remote communities this allows access to more specialised services and inpatient facilities closer to home.\n\nThe (non-statutory) phrase is used in Wales in a similar (but possibly less restricted) manner to Scotland. Some are named as community hospitals and many more are also listed as having this function. Some community hospitals have been chosen to act as a hub for services. Actual arrangements will be under legislation applicable to NHS Wales/Gig Cymru.\n\nThe American Hospital Association (AHA) defines community hospitals as “all nonfederal, short-term general, and other special hospitals.” Health associations and hospital rating organizations, however, typically also say that teaching hospitals are not community hospitals. Some further restrict the community hospital definition to only include independently-run facilities serving a local demographic. A basic definition, therefore, is a hospital serving a local community, run by local leaders, providing financial opportunities for the local economy. A community hospital can be either rural or urban.\n\nhttps://yourcommunityhospital.com/ - Grand Junction, Colorado\n"}
{"id": "34827520", "url": "https://en.wikipedia.org/wiki?curid=34827520", "title": "Declaration of Sexual Rights", "text": "Declaration of Sexual Rights\n\nThe Declaration of Sexual Rights is a statement on sexual rights that was first proclaimed at the 13th World Congress of Sexology, run by the World Association for Sexual Health, in Valencia 1997. It was revised and expanded in 2014.\n\nThe 2014 version names 16 positions:\n\n\n"}
{"id": "19375994", "url": "https://en.wikipedia.org/wiki?curid=19375994", "title": "Dos Amigos Pumping Plant", "text": "Dos Amigos Pumping Plant\n\nDos Amigos Pumping Plant is a water pumping plant of the California State Water Project, located 10 miles (16 km) south of Los Banos, on Interstate 5, within central Merced County, in the San Joaquin Valley, central California. \n\nThe plant is the second pumping plant for the California Aqueduct and the South Bay Aqueduct. It provides the necessary fluid head (potential energy) for the California Aqueduct to flow for approximately 95 miles (153 km) to where the Coastal Branch splits from the \"main line\" approximately 10 miles (16 km) south-southeast of Kettleman City. \n\nAfter the Coastal Branch junction, the line continues south by gravity another 66 miles (106 km) to the Buena Vista Pumping Plant. \n\n"}
{"id": "24847830", "url": "https://en.wikipedia.org/wiki?curid=24847830", "title": "Eastman Dental Dispensary", "text": "Eastman Dental Dispensary\n\nThe Eastman Dental Dispensary was constructed between 1915 and 1917 in the Italian Renaissance architectural style by architects Gordon, Madden, and Kaelber. In October 1915, George Eastman provided the funds to build a free dispensary in Rochester, New York that provided oral health benefits to the entire community. This dispensary would serve as the central location for dental services in the Rochester community, supplementing many other smaller offsite locations that had been constructed by other area philanthropists such as Henry Lomb and William Bausch. On May 9, 1917 the dispensary was dedicated and on October 15, 1917 the dispensary officially opened to the public. 1917 also saw the graduation of the first class of the Dental Hygiene School. Over the next few years the dispensary continued to grow, prompting George Eastman to make an endowment of 1,000 additional Kodak stock shares in 1919. This endowment provided necessary funds for the dispensary to aid in the treatment of nose and throat disorders, as well as provide orthodontics services. This endowment also provided the necessary means for the dispensary to open a tonsil-adenoid clinic. Mr. Eastman continued to be a major benefactor of the dispensary even into his death in 1932, leaving a bequest of an additional $1 million. In 1941 the dispensary officially gained its name as the Eastman Dental Dispensary. By 1978, Eastman Dental, as the organization came to be known, moved to a new larger building, the Eastman Dental Center at the University of Rochester Medical Center campus. Following the move, the Eastman Dental Dispensary building sat vacant for close to four decades, and fell into a state of disrepair. It was listed on the National Register of Historic Places in 1983.\n\nIn 2013, Home Leasing LLC, a for profit developer of affordable housing based in Rochester, NY, announced plans to redevelop the Eastman Dental Dispensary into 57 rental apartments. On April 16, 2014, New York State Homes & Community Renewal (HCR) announced awards of $2,200,000 in Housing Trust Fund (HTF) program funds, $946,000 in federal Low-Income Housing Tax Credits (LIHTC) and $449,356 in New York State Low-Income Housing Credits (SLIHC) to the project.\n\nOn Wednesday September 26, 2018 a ribbon cutting ceremony was held at the former dispensary to celebrate the opening of the new senior apartment community, named Eastman Gardens in honor of the building's original founder, George Eastman. The total cost of renovations and restorations totaled $20.7 million.\n\n"}
{"id": "8407203", "url": "https://en.wikipedia.org/wiki?curid=8407203", "title": "Equating", "text": "Equating\n\nTest equating traditionally refers to the statistical process of determining comparable scores on different forms of an exam. It can be accomplished using either classical test theory or item response theory.\n\nIn item response theory, \"equating\" is the process of placing scores from two or more parallel test forms onto a common score scale. The result is that scores from two different test forms can be compared directly, or treated as though they came from the same test form. When the tests are not parallel, the general process is called linking. It is the process of equating the units and origins of two scales on which the abilities of students have been estimated from results on different tests. The process is analogous to equating degrees Fahrenheit with degrees Celsius by converting measurements from one scale to the other. The determination of comparable scores is a by-product of equating that results from equating the scales obtained from test results.\n\nSuppose that Dick and Jane both take a test to become licensed in a certain profession. Because the high stakes (you get to practice the profession if you pass the test) may create a temptation to cheat, the organization that oversees the test creates two forms. If we know that Dick scored 60% on form A and Jane scored 70% on form B, do we know for sure which one has a better grasp of the material? What if form A is composed of very difficult items, while form B is relatively easy? Equating analyses are performed to address this very issue, so that scores are as fair as possible.\n\nIn item response theory, person \"locations\" (measures of some quality being assessed by a test) are estimated on an interval scale; i.e., locations are estimated in relation to a unit and origin. It is common in educational assessment to employ tests in order to assess different groups of students with the intention of establishing a common scale by equating the origins, and when appropriate also the units, of the scales obtained from response data from the different tests. The process is referred to as equating or test equating.\n\nIn item response theory, two different kinds of equating are horizontal and vertical equating. Vertical equating refers to the process of equating tests administered to groups of students with different abilities, such as students in different grades (years of schooling). Horizontal equating refers the equating of tests administered to groups with similar abilities; for example, two tests administered to students in the same grade in two consecutive calendar years. Different tests are used to avoid practice effects.\n\nIn terms of item response theory, equating is just a special case of the more general process of \"scaling\", applicable when more than one test is used. In practice, though, scaling is often implemented separately for different tests and then the scales subsequently equated.\n\nA distinction is often made between two methods of equating; \"common person\" and \"common item\" equating. Common person equating involves the administration of two tests to a common group of persons. The mean and standard deviation of the scale locations of the groups on the two tests are equated using a linear transformation. Common item equating involves the use of a set of common items referred to as the anchor test embedded in two different tests. The mean item location of the common items is equated.\n\nIn classical test theory, mean equating simply adjusts the distribution of scores so that the mean of one form is comparable to the mean of the other form. While mean equating is attractive because of its simplicity, it lacks flexibility, namely accounting for the possibility that the standard deviations of the forms differ.\n\nLinear equating adjusts so that the two forms have a comparable mean and standard deviation. There are several types of linear equating that differ in the assumptions and mathematics used to estimate parameters. The Tucker and Levine Observed Score methods estimate the relationship between observed scores on the two forms, while the Levine True Score method estimates the relationship between true scores on the two forms.\n\nEquipercentile equating determines the equating relationship as one where a score could have an equivalent percentile on either form. This relationship can be nonlinear.\n\nUnlike with item response theory, equating based on classical test theory is somewhat distinct from scaling. Equating is a raw-to-raw transformation in that it estimates a raw score on Form B that is equivalent to each raw score on the base Form A. Any scaling transformation used is then applied on top of, or with, the equating.\n\n\n"}
{"id": "33900406", "url": "https://en.wikipedia.org/wiki?curid=33900406", "title": "Frances Payne Bolton School of Nursing", "text": "Frances Payne Bolton School of Nursing\n\nThe Frances Payne Bolton School of Nursing is a nursing school at Case Western Reserve University in Cleveland, OH. The school is named in honor of Frances Payne Bolton, a former congresswoman from Cleveland's 22nd District.\n\nThe Frances Payne Bolton School of Nursing educates health care professionals. It offers undergraduate and graduate nursing programs, including: \nKate Benedict Hanna Harvey (1871-1936), an heiress to the M. A. Hanna Company fortune and philanthropist, spearheaded its establishment.\n"}
{"id": "19627485", "url": "https://en.wikipedia.org/wiki?curid=19627485", "title": "Glossary of clinical research", "text": "Glossary of clinical research\n\nA glossary of terms used in clinical research.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "49504891", "url": "https://en.wikipedia.org/wiki?curid=49504891", "title": "Groaning food", "text": "Groaning food\n\nIn English folklore, groaning food was food, which was occasionally kept uneaten for superstitious reasons, customarily made and served after childbirth.\n\nThe word groaning referred to the noises made during childbirth by the woman. The groaning food was served on a groaning board, with the various foods served prefaced by the term 'groaning'.\n"}
{"id": "58052972", "url": "https://en.wikipedia.org/wiki?curid=58052972", "title": "Hamish Watson (paediatrician)", "text": "Hamish Watson (paediatrician)\n\nHamish Watson FRCP (26 June 1923 - 23 May 2001), pioneer in paediatric cardiac catheterisation. Watson was most notable for being an authority on the congenital heart defect, Ebstein's anomaly.\n\nHamish Watson was born in Edinburgh to dairy owner John T R Watson and his wife, Annie Ewing Spence. He was educated at George Watson's School before studying medicine at the University of Edinburgh, from where he graduated with an MB ChB and an MD in 1945.\n\nIn 1951, he married Lesley Wood and had two daughters and a son.\n\nFollowing his graduation, Watson spent his national service in Africa as RMO, Nigeria Regiment. Watson returned to Edinburgh with a small collection of animals bound for the zoo. His medical career continued at the Royal Infirmary of Edinburgh where he was strongly influenced by cardiologist Andrew Rae Gilchrist, who established the cardiology department at the Infirmary. Two years later, moved to St Andrews University Department of Medicine under Sir Ian Hill, working in Dundee hospitals. Watson's early research was in the field of anticoagulant therapy but the tragic death of his young son from severe congenital heart disease, provided the impetus for him to undertake pioneering research work in congenital heart disease in children. From this, Watson developed a diagnostic and treatment technique which involved insertion of narrow tubes into the heart - cardiac catheterisation. Watson went on to establish the first coronary care unit in Tayside, and was appointed both Post-graduate Dean at the University of Dundee and head of the Cardiology Department at Dundee Royal Infirmary. Watson was editor of the 1968 multi-authored book, \"Paediatric Cardiology\" which became a standard text for students. Watson was influential in the establishment of the European Association of Paediatric Cardiologists, becoming its first president. Watson was also a Fellow of the American College of Cardiology, and in 1987, joint chairman of the British Cardiac Society and a trustee of the Royal College of Physicians of Edinburgh.\n\nFollowing his retirement, Watson pursued his love of the great outdoors, hunting and fishing regularly. He was a joint Master of Fox Hounds and, like his wife, an expert fly fisher. The Watsons were also keen gardeners. A car accident brought this outdoors lifestyle to an abrupt halt however, leaving Watson paralysed and in great pain. He was nursed by his wife and died in 2001, at the age of 77, from pneumonia in the coronary care unit he had helped establish.\n\n"}
{"id": "4169183", "url": "https://en.wikipedia.org/wiki?curid=4169183", "title": "Hong Kong Baptist University School of Chinese Medicine", "text": "Hong Kong Baptist University School of Chinese Medicine\n\nThe School of Chinese Medicine at Hong Kong Baptist University is a school in Hong Kong that offers full-time degree programmes in Chinese medicine, Biomedical science, and pharmacy in Chinese medicine, also offers part-time programmes in Chinese medicine, pharmacy in Chinese medicine, acupuncture, \"tui na\", orthopaedics and beauty care.\n\n\n"}
{"id": "6423951", "url": "https://en.wikipedia.org/wiki?curid=6423951", "title": "Hospital-acquired pneumonia", "text": "Hospital-acquired pneumonia\n\nHospital-acquired pneumonia (HAP) or nosocomial pneumonia refers to any pneumonia contracted by a patient in a hospital at least 48–72 hours after being admitted. It is thus distinguished from community-acquired pneumonia. It is usually caused by a bacterial infection, rather than a virus.\n\nHAP is the second most common nosocomial infection (after urinary tract infections) and accounts for 15–20% of the total. It is the most common cause of death among nosocomial infections and is the primary cause of death in intensive care units.\n\nHAP typically lengthens a hospital stay by 1–2 weeks.\n\nNew or progressive infiltrate on the chest X-ray with one of the following:\nIn an elderly person, the first sign of hospital-acquired pneumonia may be mental changes or confusion.\nOther symptoms may include:\n\n\nVentilator-associated pneumonia (VAP) is a sub-type of hospital-acquired pneumonia (HAP) which occurs in people who are receiving mechanical ventilation. VAP is not characterized by the causative agents; rather, as its name implies, definition of VAP is restricted to patients undergoing mechanical ventilation while in a hospital. A positive culture after intubation is indicative of ventilator-associated pneumonia and is diagnosed as such. In order to appropriately categorize the causative agent or mechanism it is usually recommended to obtain a culture prior to initiating mechanical ventilation as a reference.\n\nHCAP is a condition in patients who can come from the community, but have frequent contact with the healthcare environment. Historically, the etiology and prognosis of nursing home pneumonia appeared to differ from other types of community acquired pneumonia, with studies reporting a worse prognosis and higher incidence of multi drug resistant organisms as etiology agents. The definition criteria which has been used is the same as the one which has been previously used to identify bloodstream healthcare associated infections.\n\nHCAP is no longer recognized as a clinically independent entity. This is due to increasing evidence from a growing number of studies that many patients defined as having HCAP are not at high risk for MDR pathogens. As a result, 2016 IDSA guidelines removed consideration of HCAP as a separate clinical entity.\n\nHealthcare-associated pneumonia can be defined as pneumonia in a patient with at least one of the following risk factors:\n\nIn some studies, the bacteria found in patients with HCAP were more similar to HAP than to CAP; compared to CAP, they could have higher rates of \"Staphylococcus aureus\" (\"S. aureus\") and \"Pseudomonas aeruginosa\", and less \"Streptococcus pneumoniae\" and \"Haemophilus influenzae\". In European and Asian studies, the etiology of HCAP was similar to that of CAP, and rates of multi drug resistant pathogens such as \"Staphylococcus aureus\" and \"Pseudomonas aeruginosa\" were not as high as seen in North American studies. It is well known that nursing home residents have high rates of colonization with MRSA. However, not all studies have found high rates of S. aureus and gram-negative bacteria. One factor responsible for these differences is the reliance on sputum samples and the strictness of the criteria to discriminate \nbetween colonising or disease-causing bacteria. Moreover, sputum samples might be less frequently obtained in the elderly.Aspiration (both of microscopic drops and macroscopic amounts of nose and throat secretions) is thought to be the most important cause of HCAP. Dental plaque might also be a reservoir for bacteria in HCAP. \nBacteria have been the most commonly isolated pathogens, although viral and fungal pathogens are potentially found in immunocompromised hosts (patients on chronic immunosuppressed medications, solid organ and bone marrow transplant recipients). In general, the distribution of microbial pathogens varies among institutions, partly because of differences in patient population and local patterns of anti microbial resistance in hospitals and critical care units' Common bacterial pathogens include aerobic GNB, such as \"Pseudomonas aeruginosa\", \"Acinetobacter baumanii\", \"Klebsiella pneumoniae\", \"Escherichia coli\" as well as gram-positive organisms such as \"Staphylococcus aureus\". In patients with an early onset pneumonia (within 5 days of hospitalization), they are usually due to anti microbial-sensitive bacteria such as \"Enterobacter\" spp, \"E. coli\", \"Klebsiella\" spp, \"Proteus\" spp, \"Serratia mare scans\", community pathogens such as \"Streptococcus pneumoniae, Haemophilus influenzae\", and methicillin-sensitive \"S. aureus\" should also be considered. \nPneumonia that starts in the hospital tends to be more serious than other lung infections because: people in the hospital are often very sick and cannot fight off germs. The types of germs present in a hospital are often more dangerous and more resistant to treatment than those outside in the community. Pneumonia occurs more often in people who are using a respirator. This machine helps them breathe. Hospital-acquired pneumonia can also be spread by health care workers, who can pass germs from their hands or clothes from one person to another. This is why hand-washing, wearing grows, and using other safety measures is so important in the hospital.\n\nPatients with HCAP are more likely than those with community-acquired pneumonia to receive inappropriate antibiotics that do not target the bacteria causing their disease.\n\nIn 2002, an expert panel made recommendations about the evaluation and treatment of probable nursing home-acquired pneumonia. They defined probably pneumonia, emphasized expedite antibiotic treatment (which is known to improve survival) and drafted criteria for the hospitalization of willing patients.\n\nFor initial treatment in the nursing home, a fluoroquinolone antibiotic suitable for respiratory infections (moxifloxacin, for example), or amoxicillin with clavulanic acid plus a macrolide has been suggested. In a hospital setting, injected (parenteral) fluoroquinolones or a second- or third-generation cephalosporin plus a macrolide could be used. Other factors that need to be taken into account are recent antibiotic therapy (because of possible resistance caused by recent exposure), known carrier state or risk factors for resistant organisms (for example, known carrier of MRSA or presence of bronchiectasis predisposing to Pseudomonas aeruginosa), or suspicion of possible Legionella pneumophila infection (legionnaires disease).\n\nIn 2005, the American Thoracic Society and Infectious Diseases Society of America have published guidelines suggesting antibiotics specifically for HCAP. The guidelines recommend combination therapy with an agent from each of the following groups to cover for both \"Pseudomonas aeruginosa\" and MRSA. This is based on studies using sputum samples and intensive care patients, in whom these bacteria were commonly found.\n\nIn one observational study, empirical antibiotic treatment that was not according to international treatment guidelines was an independent predictor of worse outcome among HCAP patients.\n\nGuidelines from Canada suggest that HCAP can be treated like community-acquired pneumonia with antibiotics targeting Streptococcus pneumoniae, based on studies using blood cultures in different settings which have not found high rates of MRSA or Pseudomonas.\n\nBesides prompt antibiotic treatment, supportive measure for organ failure (such as cardiac decompensation) are also important. Another consideration goes to hospital referral; although more severe pneumonia requires admission to an acute care facility, this also predisposes to hazards of hospitalization such as delirium, urinary incontinence, depression, falls, restraint use, functional decline, adverse drug effects and hospital infections. Therefore, mild pneumonia might be better dealt with inside the long term care facility. In patients with a limited life expectancy (for example, those with advanced dementia), end-of-life pneumonia also requires recognition and appropriate, palliative care.\n\nHealthcare-associated pneumonia seems to have fatality rates similar to hospital-acquired pneumonia, worse than community-acquired pneumonia but less severe than pneumonia in ventilated patients. Besides clinical markers like tachypnea (fast breathing) or a high white cell count (leukocytosis), the prognosis seems to be influenced by the underlying associated diseases (comorbidities) and functional capacities (for example, the ADL score). Many patients have a decreased health condition after the episode.\n\nSeveral studies found that healthcare-associated pneumonia is the second most common type of pneumonia, occurring less commonly than community-acquired pneumonia but more frequently than hospital-acquired pneumonia and ventilator-associated pneumonia. In a recent observational study, the rates for CAP, HCAP and HAP were 60%, 25% and 15% respectively. Patients with HCAP are older and more commonly have simultaneous health problems (such as previous stroke, heart failure and diabetes).\n\nThe number of residents in long term care facilities is expected to rise dramatically over the next 30 years. These older adults are known to develop pneumonia 10 times more than their community-dwelling peers, and hospital admittance rates are 30 times higher.\n\nNursing home-acquired pneumonia is an important subgroup of HCAP. Residents of long term care facilities may become infected through their contacts with the healthcare system; as such, the microbes responsible for their pneumonias may be different from those traditionally seen in community-dwelling patients, requiring therapy with different antibiotics. Other groups include patients who are admitted as a day case for regular hemodialysis or intravenous infusion (for example, chemotherapy). Especially in the very old and in demented patients, HCAP is likely to present with atypical symptoms.\n\nAmong the factors contributing to contracting HAP are mechanical ventilation (ventilator-associated pneumonia), old age, decreased filtration of inspired air, intrinsic respiratory, neurologic, or other disease states that result in respiratory tract obstruction, trauma, (abdominal) surgery, medications, diminished lung volumes, or decreased clearance of secretions may diminish the defenses of the lung. Also, poor hand-washing and inadequate disinfection of respiratory devices cause cross-infection and are important factors.\n\nMost nosocomial respiratory infections are caused by so-called skorvatch microaspiration of upper airway secretions, through inapparent aspiration, into the lower respiratory tract. Also, \"macroaspirations\" of esophageal or gastric material is known to result in HAP. Since it results from aspiration either type is called aspiration pneumonia.\n\nAlthough gram-negative bacilli are a common cause they are rarely found in the respiratory tract of people without pneumonia, which has led to speculation of the mouth and throat as origin of the infection.\n\nIn hospitalised patients who develop respiratory symptoms and fever, one should consider the diagnosis. The likelihood increases when upon investigation symptoms are found of respiratory insufficiency, purulent secretions, newly developed infiltrate on the chest X-Ray, and increasing leucocyte count. If pneumonia is suspected material from sputum or tracheal aspirates are sent to the microbiology department for cultures. In case of pleural effusion thoracentesis is performed for examination of pleural fluid. In suspected ventilator-associated pneumonia it has been suggested that bronchoscopy(BAL) is necessary because of the known risks surrounding clinical diagnoses.\n\n\nUsually initial therapy is empirical. If sufficient reason to suspect influenza, one might consider oseltamivir. In case of legionellosis, erythromycin or fluoroquinolone.\n\nA third generation cephalosporin (ceftazidime) + carbapenems (imipenem) + beta lactam & beta lactamase inhibitors (piperacillin/tazobactam)\n\n\n"}
{"id": "1070221", "url": "https://en.wikipedia.org/wiki?curid=1070221", "title": "Human eye", "text": "Human eye\n\nThe human eye is an organ which reacts to light and pressure. As a sense organ, the mammalian eye allows vision. Human eyes help to provide a three dimensional, moving image, normally coloured in daylight. Rod and cone cells in the retina allow conscious light perception and vision including color differentiation and the perception of depth. The human eye can differentiate between about 10 million colors and is possibly capable of detecting a single photon.\n\nSimilar to the eyes of other mammals, the human eye's non-image-forming photosensitive ganglion cells in the retina receive light signals which affect adjustment of the size of the pupil, regulation and suppression of the hormone melatonin and entrainment of the body clock.\n\nThe eye is not shaped like a perfect sphere, rather it is a fused two-piece unit, composed of the anterior segment and the posterior segment. The anterior segment is made up of the cornea, iris and lens. The cornea is transparent and more curved, and is linked to the larger posterior segment, composed of the vitreous, retina, choroid and the outer white shell called the sclera. The cornea is typically about 11.5 mm (0.3 in) in diameter, and 1/2 mm (500 μm) in thickness near its center. The posterior chamber constitutes the remaining five-sixths; its diameter is typically about 24 mm. The cornea and sclera are connected by an area termed the limbus. The iris is the pigmented circular structure concentrically surrounding the center of the eye, the pupil, which appears to be black. The size of the pupil, which controls the amount of light entering the eye, is adjusted by the iris' dilator and sphincter muscles.\n\nLight energy enters the eye through the cornea, through the pupil and then through the lens. The lens shape is changed for near focus (accommodation) and is controlled by the ciliary muscle. Photons of light falling on the light-sensitive cells of the retina (photoreceptor cones and rods) are converted into electrical signals that are transmitted to the brain by the optic nerve and interpreted as sight and vision.\n\nDimensions typically differ among adults by only one or two millimetres, remarkably consistent across different ethnicities. The vertical measure, generally less than the horizontal, is about 24 mm. The transverse size of a human adult eye is approximately 24.2 mm and the sagittal size is  23.7 mm with no significant difference between sexes and age groups. Strong correlation has been found between the transverse diameter and the width of the orbit (r = 0.88). The typical adult eye has an anterior to posterior diameter of 24 millimetres, a volume of six cubic centimetres (0.4 cu. in.), and a mass of 7.5 grams (weight of 0.25 oz.)..\n\nThe eyeball grows rapidly, increasing from about 16–17 millimetres (about 0.65 inch) at birth to 22.5–23 mm (approx. 0.89 in) by three years of age. By age 13, the eye attains its full size.\n\nThe eye is made up of three coats, or layers, enclosing various anatomical structures. The outermost layer, known as the fibrous tunic, is composed of the cornea and sclera. The middle layer, known as the vascular tunic or uvea, consists of the choroid, ciliary body, pigmented epithelium and iris. The innermost is the retina, which gets its oxygenation from the blood vessels of the choroid (posteriorly) as well as the retinal vessels (anteriorly).\n\nThe spaces of the eye are filled with the aqueous humour anteriorly, between the cornea and lens, and the vitreous body, a jelly-like substance, behind the lens, filling the entire posterior cavity. The aqueous humour is a clear watery fluid that is contained in two areas: the anterior chamber between the cornea and the iris, and the posterior chamber between the iris and the lens. The lens is suspended to the ciliary body by the suspensory ligament (Zonule of Zinn), made up of hundreds of fine transparent fibers which transmit muscular forces to change the shape of the lens for accommodation (focusing). The vitreous body is a clear substance composed of water and proteins, which give it a jelly-like and sticky composition.\n\nThe approximate field of view of an individual human eye (measured from the fixation point, i.e., the point at which one's gaze is directed) varies by facial anatomy, but is typically 30° superior (up, limited by the brow), 45° nasal (limited by the nose), 70° inferior (down), and 100° temporal (towards the temple). For both eyes combined (binocular) visual field is 135° vertical and 200° horizontal. When viewed at large angles from the side, the iris and pupil may still be visible by the viewer, indicating the person has peripheral vision possible at that angle.\n\nAbout 15° temporal and 1.5° below the horizontal is the blind spot created by the optic nerve nasally, which is roughly 7.5° high and 5.5° wide.\n\nThe retina has a static contrast ratio of around 100:1 (about 6.5 f-stops). As soon as the eye moves rapidly to acquire a target (saccades), it re-adjusts its exposure by adjusting the iris, which adjusts the size of the pupil. Initial dark adaptation takes place in approximately four seconds of profound, uninterrupted darkness; full adaptation through adjustments in retinal rod photoreceptors is 80% complete in thirty minutes. The process is nonlinear and multifaceted, so an interruption by light exposure requires restarting the dark adaptation process over again. Full adaptation is dependent on good blood flow; thus dark adaptation may be hampered by retinal disease, poor vascular circulation and high altitude exposure. \n\nThe human eye can detect a luminance range of 10, or one hundred trillion (100,000,000,000,000) (about 46.5 f-stops), from 10 cd/m, or one millionth (0.000001) of a candela per square meter to 10 cd/m or one hundred million (100,000,000) candelas per square meter. This range does not include looking at the midday sun (10 cd/m) or lightning discharge.\n\nAt the low end of the range is the absolute threshold of vision for a steady light across a wide field of view, about 10 cd/m2 (0.000001 candela per square meter). The upper end of the range is given in terms of normal visual performance as 10 cd/m (100,000,000 or one hundred million candelas per square meter).\n\nThe eye includes a lens similar to lenses found in optical instruments such as cameras and the same physics principles can be applied. The pupil of the human eye is its aperture; the iris is the diaphragm that serves as the aperture stop. Refraction in the cornea causes the effective aperture (the entrance pupil) to differ slightly from the physical pupil diameter. The entrance pupil is typically about 4 mm in diameter, although it can range from 2 mm () in a brightly lit place to 8 mm () in the dark. The latter value decreases slowly with age; older people's eyes sometimes dilate to not more than 5-6mm in the dark, and may be as small as 1mm in the light.\n\nThe visual system in the human brain is too slow to process information if images are slipping across the retina at more than a few degrees per second. Thus, to be able to see while moving, the brain must compensate for the motion of the head by turning the eyes. Frontal-eyed animals have a small area of the retina with very high visual acuity, the fovea centralis. It covers about 2 degrees of visual angle in people. To get a clear view of the world, the brain must turn the eyes so that the image of the object of regard falls on the fovea. Any failure to make eye movements correctly can lead to serious visual degradation.\n\nHaving two eyes allows the brain to determine the depth and distance of an object, called stereovision, and gives the sense of three-dimensionality to the vision. Both eyes must point accurately enough that the object of regard falls on corresponding points of the two retinas to stimulate stereovision; otherwise, double vision might occur. Some persons with congenitally crossed eyes tend to ignore one eye's vision, thus do not suffer double vision, and do not have stereovision. The movements of the eye are controlled by six muscles attached to each eye, and allow the eye to elevate, depress, converge, diverge and roll. These muscles are both controlled voluntarily and involuntarily to track objects and correct for simultaneous head movements.\n\nEach eye has six muscles that control its movements: the lateral rectus, the medial rectus, the inferior rectus, the superior rectus, the inferior oblique, and the superior oblique. When the muscles exert different tensions, a torque is exerted on the globe that causes it to turn, in almost pure rotation, with only about one millimeter of translation. Thus, the eye can be considered as undergoing rotations about a single point in the center of the eye.\n\nRapid eye movement, REM, typically refers to the sleep stage during which the most vivid dreams occur. During this stage, the eyes move rapidly. It is not in itself a unique form of eye movement.\n\nSaccades are quick, simultaneous movements of both eyes in the same direction controlled by the frontal lobe of the brain. Some irregular drifts, movements, smaller than a saccade and larger than a microsaccade, subtend up to one tenth of a degree.\n\nEven when looking intently at a single spot, the eyes drift around. This ensures that individual photosensitive cells are continually stimulated in different degrees. Without changing input, these cells would otherwise stop generating output. Microsaccades move the eye no more than a total of 0.2° in adult humans.\n\nThe vestibulo-ocular reflex is a reflex eye movement that stabilizes images on the retina during head movement by producing an eye movement in the direction opposite to head movement in response to neural input from the vestibular system of the inner ear, thus maintaining the image in the center of the visual field. For example, when the head moves to the right, the eyes move to the left. This applies for head movements up and down, left and right, and tilt to the right and left, all of which give input to the ocular muscles to maintain visual stability.\n\nEyes can also follow a moving object around. This tracking is less accurate than the vestibulo-ocular reflex, as it requires the brain to process incoming visual information and supply feedback. Following an object moving at constant speed is relatively easy, though the eyes will often make saccadic jerks to keep up. The smooth pursuit movement can move the eye at up to 100°/s in adult humans.\n\nIt is more difficult to visually estimate speed in low light conditions or while moving, unless there is another point of reference for determining speed.\n\nThe Optokinetic reflex (or optokinetic nystagmus) stabilizes the image on the retina through visual feedback. It is induced when the entire visual scene drifts across the retina, eliciting eye rotation in the same direction and at a velocity that minimizes the motion of the image on the retina. When the gaze direction deviates too far from the forward heading, a compensatory saccade is induced to reset the gaze to the centre of the visual field.\n\nFor example, when looking out of the window at a moving train, the eyes can focus on a moving train for a short moment (by stabilizing it on the retina), until the train moves out of the field of vision. At this point, the eye is moved back to the point where it first saw the train (through a saccade).\n\nThe adjustment to close-range vision involves three processes to focus an image on the retina.\n\nWhen a creature with binocular vision looks at an object, the eyes must rotate around a vertical axis so that the projection of the image is in the centre of the retina in both eyes. To look at a nearby object, the eyes rotate 'towards each other' (convergence), while for an object farther away they rotate 'away from each other' (divergence).\n\nLenses cannot refract light rays at their edges as well as they can closer to the center. The image produced by any lens is therefore somewhat blurry around the edges (spherical aberration). It can be minimized by screening out peripheral light rays and looking only at the better-focused center. In the eye, the pupil serves this purpose by constricting while the eye is focused on nearby objects. Small apertures also give an increase in depth of field, allowing a broader range of \"in focus\" vision. In this way the pupil has a dual purpose for near vision: to reduce spherical aberration and increase depth of field.\n\nChanging the curvature of the lens is carried out by the ciliary muscles surrounding the lens; this process is called \"accommodation\". Accommodation narrows the inner diameter of the ciliary body, which actually relaxes the fibers of the suspensory ligament attached to the periphery of the lens, and allows the lens to relax into a more convex, or globular, shape. A more convex lens refracts light more strongly and focuses divergent light rays from near objects onto the retina, allowing closer objects to be brought into better focus.\n\nThe human eye contains enough complexity to warrant specialized attention and care beyond the duties of a general practitioner. These specialists, or eye care professionals, serve different functions in different countries. Eye care professionals can have overlap in their patient care privileges. For example, both an ophthalmologist (M.D.) and optometrist (O.D.) are professionals who diagnoses eye disease and can prescribe lenses to correct vision. However, typically only ophthalmologists are licensed to perform surgical procedures. Ophthalmologists may also specialize within a surgical area, such as cornea, cataracts, laser, retina, or oculoplastics. Other eye care professionals include:\n\nEye irritation has been defined as \"the magnitude of any stinging, scratching, burning, or other irritating sensation from the eye\". It is a common problem experienced by people of all ages. Related eye symptoms and signs of irritation are discomfort, dryness, excess tearing, itching, grating, foreign body sensation, ocular fatigue, pain, scratchiness, soreness, redness, swollen eyelids, and tiredness, etc. These eye symptoms are reported with intensities from mild to severe. It has been suggested that these eye symptoms are related to different causal mechanisms, and symptoms are related to the particular ocular anatomy involved.\n\nSeveral suspected causal factors in our environment have been studied so far. One hypothesis is that indoor air pollution may cause eye and airway irritation. Eye irritation depends somewhat on destabilization of the outer-eye tear film, in which the formation of dry spots on the cornea, resulting in ocular discomfort. Occupational factors are also likely to influence the perception of eye irritation. Some of these are lighting (glare and poor contrast), gaze position, reduced blink rate, limited number of breaks from visual tasking, and a constant combination of accommodation, musculoskeletal burden, and impairment of the visual nervous system. Another factor that may be related is work stress. In addition, psychological factors have been found in multivariate analyses to be associated with an increase in eye irritation among VDU users. Other risk factors, such as chemical toxins/irritants (e.g. amines, formaldehyde, acetaldehyde, acrolein, N-decane, VOCs, ozone, pesticides and preservatives, allergens, etc.) might cause eye irritation as well.\n\nCertain volatile organic compounds that are both chemically reactive and airway irritants may cause eye irritation. Personal factors (e.g. use of contact lenses, eye make-up, and certain medications) may also affect destabilization of the tear film and possibly result in more eye symptoms. Nevertheless, if airborne particles alone should destabilize the tear film and cause eye irritation, their content of surface-active compounds must be high. An integrated physiological risk model with blink frequency, destabilization, and break-up of the eye tear film as inseparable phenomena may explain eye irritation among office workers in terms of occupational, climate, and eye-related physiological risk factors.\n\nThere are two major measures of eye irritation. One is blink frequency which can be observed by human behavior. The other measures are break up time, tear flow, hyperemia (redness, swelling), tear fluid cytology, and epithelial damage (vital stains) etc., which are human beings' physiological reactions. Blink frequency is defined as the number of blinks per minute and it is associated with eye irritation. Blink frequencies are individual with mean frequencies of < 2-3 to 20-30 blinks/minute, and they depend on environmental factors including the use of contact lenses. Dehydration, mental activities, work conditions, room temperature, relative humidity, and illumination all influence blink frequency. Break-up time (BUT) is another major measure of eye irritation and tear film stability. It is defined as the time interval (in seconds) between blinking and rupture. BUT is considered to reflect the stability of the tear film as well. In normal persons, the break-up time exceeds the interval between blinks, and, therefore, the tear film is maintained. Studies have shown that blink frequency is correlated negatively with break-up time. This phenomenon indicates that perceived eye irritation is associated with an increase in blink frequency since the cornea and conjunctiva both have sensitive nerve endings that belong to the first trigeminal branch. Other evaluating methods, such as hyperemia, cytology etc. have increasingly been used to assess eye irritation.\n\nThere are other factors that are related to eye irritation as well. Three major factors that influence the most are indoor air pollution, contact lenses and gender differences. Field studies have found that the prevalence of objective eye signs is often significantly altered among office workers in comparisons with random samples of the general population. These research results might indicate that indoor air pollution has played an important role in causing eye irritation. There are more and more people wearing contact lens now and dry eyes appear to be the most common complaint among contact lens wearers. Although both contact lens wearers and spectacle wearers experience similar eye irritation symptoms, dryness, redness, and grittiness have been reported far more frequently among contact lens wearers and with greater severity than among spectacle wearers. Studies have shown that incidence of dry eyes increases with age, especially among women. Tear film stability (e.g. break-up time) is significantly lower among women than among men. In addition, women have a higher blink frequency while reading. Several factors may contribute to gender differences. One is the use of eye make-up. Another reason could be that the women in the reported studies have done more VDU work than the men, including lower grade work. A third often-quoted explanation is related to the age-dependent decrease of tear secretion, particularly among women after 40 years of age.\n\nIn a study conducted by UCLA, the frequency of reported symptoms in industrial buildings was investigated. The study's results were that eye irritation was the most frequent symptom in industrial building spaces, at 81%. Modern office work with use of office equipment has raised concerns about possible adverse health effects. Since the 1970s, reports have linked mucosal, skin, and general symptoms to work with self-copying paper. Emission of various particulate and volatile substances has been suggested as specific causes. These symptoms have been related to sick building syndrome (SBS), which involves symptoms such as irritation to the eyes, skin, and upper airways, headache and fatigue.\n\nMany of the symptoms described in SBS and multiple chemical sensitivity (MCS) resemble the symptoms known to be elicited by airborne irritant chemicals. A repeated measurement design was employed in the study of acute symptoms of eye and respiratory tract irritation resulting from occupational exposure to sodium borate dusts. The symptom assessment of the 79 exposed and 27 unexposed subjects comprised interviews before the shift began and then at regular hourly intervals for the next six hours of the shift, four days in a row. Exposures were monitored concurrently with a personal real time aerosol monitor. Two different exposure profiles, a daily average and short term (15 minute) average, were used in the analysis. Exposure-response relations were evaluated by linking incidence rates for each symptom with categories of exposure.\n\nAcute incidence rates for nasal, eye, and throat irritation, and coughing and breathlessness were found to be associated with increased exposure levels of both exposure indices. Steeper exposure-response slopes were seen when short term exposure concentrations were used. Results from multivariate logistic regression analysis suggest that current smokers tended to be less sensitive to the exposure to airborne sodium borate dust.\n\nSeveral actions can be taken to prevent eye irritation—\n\nIn addition, other measures are proper lid hygiene, avoidance of eye rubbing, and proper use of personal products and medication. Eye make-up should be used with care.\n\nThe paraphilic practice of oculolinctus, or eyeball-licking, may also cause irritations, infections, or damage to the eye.\n\nThere are many diseases, disorders, and age-related changes that may affect the eyes and surrounding structures.\n\nAs the eye ages, certain changes occur that can be attributed solely to the aging process. Most of these anatomic and physiologic processes follow a gradual decline. With aging, the quality of vision worsens due to reasons independent of diseases of the aging eye. While there are many changes of significance in the non-diseased eye, the most functionally important changes seem to be a reduction in pupil size and the loss of accommodation or focusing capability (presbyopia). The area of the pupil governs the amount of light that can reach the retina. The extent to which the pupil dilates decreases with age, leading to a substantial decrease in light received at the retina. In comparison to younger people, it is as though older persons are constantly wearing medium-density sunglasses. Therefore, for any detailed visually guided tasks on which performance varies with illumination, older persons require extra lighting. Certain ocular diseases can come from sexually transmitted diseases such as herpes and genital warts. If contact between the eye and area of infection occurs, the STD can be transmitted to the eye.\n\nWith aging, a prominent white ring develops in the periphery of the cornea called arcus senilis. Aging causes laxity, downward shift of eyelid tissues and atrophy of the orbital fat. These changes contribute to the etiology of several eyelid disorders such as ectropion, entropion, dermatochalasis, and ptosis. The vitreous gel undergoes liquefaction (posterior vitreous detachment or PVD) and its opacities — visible as floaters — gradually increase in number.\n\nVarious eye care professionals, including ophthalmologists (eye doctors/surgeons), optometrists, and opticians, are involved in the treatment and management of ocular and vision disorders. A Snellen chart is one type of eye chart used to measure visual acuity. At the conclusion of a complete eye examination, the eye doctor might provide the patient with an eyeglass prescription for corrective lenses. Some disorders of the eyes for which corrective lenses are prescribed include myopia (near-sightedness) which affects about one-third of the human population, hyperopia (far-sightedness) which affects about one quarter of the population, astigmatism, and presbyopia (the loss of focusing range during aging).\n\nMacular degeneration is especially prevalent in the U.S. and affects roughly 1.75 million Americans each year. Having lower levels of lutein and zeaxanthin within the macula may be associated with an increase in the risk of age-related macular degeneration. Lutein and zeaxanthin act as antioxidants that protect the retina and macula from oxidative damage from high-energy light waves. As the light waves enter the eye they excite electrons that can cause harm to the cells in the eye, but before they can cause oxidative damage that may lead to macular degeneration or cataracts. Lutein and zeaxanthin bind to the electron free radical and are reduced rendering the electron safe. There are many ways to ensure a diet rich in lutein and zeaxanthin, the best of which is to eat dark green vegetables including kale, spinach, broccoli and turnip greens. Nutrition is an important aspect of the ability to achieve and maintain proper eye health. Lutein and zeaxanthin are two major carotenoids, found in the macula of the eye, that are being researched to identify their role in the pathogenesis of eye disorders such as age-related macular degeneration and cataracts.\n\n"}
{"id": "53214717", "url": "https://en.wikipedia.org/wiki?curid=53214717", "title": "Intratracheal instillation", "text": "Intratracheal instillation\n\nIntratracheal instillation is the introduction of a substance directly into the trachea. It is widely used to test the respiratory toxicity of a substance as an alternative to inhalation in animal testing. Intratracheal instillation was reported as early as 1923 in studies of the carcinogenicity of coal tar. Modern methodology was developed by several research groups in the 1970s. By contrast, tracheal administration of pharmaceutical drugs in humans is called endotracheal administration.\n\nAs compared to inhalation, intratracheal instillation allows greater control over the dose and location of the substance, is cheaper and less technically demanding, allows lower amounts of scarce or expensive substances to be used, allows substances to be tested that can be inhaled by humans but not small mammals, and minimizes exposure to laboratory workers and to the skin of laboratory animals. Disadvantages include its nonphysiological and invasive nature, the confounding effects of the delivery vehicle and anesthesia, and the fact that it bypasses the upper respiratory tract. Instillation results in a less uniform distribution of the substance than inhalation, and the substance is cleared from the respiratory tract more slowly. Their results provide a quick screen of potential toxicity and can be used to test its mechanism, but may not be directly applicable to occupational exposure that occurs over an extended period. Some of these difficulties are overcome by another method, pharyngeal aspiration, which is less technically difficult and causes less trauma to the animal, and has a pulmonary deposition pattern more similar to inhalation.\n\nIntratracheal instillation is often performed with mice, rats, or hamsters, with hamsters often preferred because their mouth can be opened widely to aid viewing the procedure, and because they are more resistant to lung diseases than rats. Instillation is performed either through inserting a needle or catheter down the mouth and throat, or through surgically exposing the trachea and penetrating it with a needle. Generally, short-acting inhaled anesthetic drugs such as halothane, metaphane, or enflurane are used during the instillation procedure. Saline solution is usually used as a delivery vehicle in a typical volume of 1–2 mL/kg body weight. A wide range of substances can be tested, including both soluble materials and insoluble particles or fibers, including nanomaterials.\n\n"}
{"id": "36477140", "url": "https://en.wikipedia.org/wiki?curid=36477140", "title": "Kermack–McKendrick theory", "text": "Kermack–McKendrick theory\n\nKermack–McKendrick theory is a hypothesis that predicts the number and distribution \nof cases of an infectious disease as it is transmitted through a population over time.\nBuilding principle on the research of Ronald Ross and Hilda Hudson,\nA. G. McKendrick and W. O. Kermack published their theory in a set of three articles from 1927, 1932, and 1933. While Kermack—McKendrick theory was indeed the source of SIR models and their relatives, Kermack and McKendrick were thinking of a more subtle and empirically useful problem than the simple compartmental models discussed here. The text is somewhat difficult to read, compared to modern papers, but the important feature is it was a model where the age-of-infection affected the transmission and removal rates.\n\nBecause of their seminal importance to the field of theoretical epidemiology, these articles were republished in the \"Bulletin of Mathematical Biology\" in 1991.\n\nIn its initial form, Kermack—McKendrick theory is a compartmental differential-equation model that structures the infectioned population in terms of age-of-infection, while\nusing simple compartments for people who are susceptible (S) and recovered/removed (R).\nSpecified initial conditions would change over time according to\n\nwhere formula_4 is a Dirac delta-function and the infection pressure\n\nOnly in the special case when the removal rate formula_6 and the transmission rate formula_7 are constant for all ages does the substitution formula_8 transform\ntheir theory into the simple SIR model. This basic model only accounts for infection and removal events, which are sufficient to describe a simple epidemic, including the threshold condition necessary for an epidemic to start, but can not explain endemic disease transmission or recurring epidemics.\n\nIn their subsequent articles, Kermack and McKendrick extended their theory to allow for birth, migration, and death, as well as imperfect immunity. In modern notation, their model can be represented as\n\nwhere formula_13 is the immigration rate of susceptibles, \"b\" is the per-capita birth rate for state \"j\", \"m\" is the per-capita mortality rate of individuals in state \"j\", formula_14 is the relative-risk of infection to recovered individuals who are partially immune, and the infection pressure\n\nKermack and McKendrick were able to show that it admits a stationary solution where disease is endemic, as long as the supply of susceptible individuals is sufficiently large. This model is difficult to analyze in its full generality, and a number of open questions remain regarding its dynamics.\n"}
{"id": "10607718", "url": "https://en.wikipedia.org/wiki?curid=10607718", "title": "Kwame Addo-Kufuor", "text": "Kwame Addo-Kufuor\n\nKwame Addo-Kufuor (born 14 July 1940) is a Ghanaian politician and physician. Addo-Kufuor was a member of parliament from Manhyia, and from 2001 to 2007 he was the Minister for Defense under President John Kufuor, his brother. Between June 2008 and 2009, he was Minister for Interior.\n\nBorn in Kumasi, Addo-Kufuor is a distinguished Ghanaian consultant physician and statesman, former president of the Ghana Medical Association and later, Ghana’s Minister of Defence and Interior. He concurrently served as Member of Parliament for the Manhyia Constituency in Kumasi from 1997 to 2008.\n\nHe was educated at Osei Tutu Boarding School (Osei Tutu Senior High School), before he proceeded to the famous Achimota School in Accra, Ghana after which he gained admission to study at Jesus College, University of Cambridge, England, where he initially enrolled in the arts earning a master's degree before switching to the sciences to do a Bachelor of Medicine, and Bachelor of Surgery degree. He became the first black student to be secretary of the Medical Students Association at Jesus College before continuing with other advance courses in medicine at the University College Medical School, London. \nHis postgraduate studies were at The Middlesex Medical School Hospital, London.\nIn 1975, Addo Kufuor passed the MRCP (UK) examination.\n\nAddo-Kufuor started his medical practice as a member of the teaching staff of the Middlesex Medical School Hospital and other hospitals in London before returning home to Ghana. He first worked at two of the country’s leading hospitals, the Korle Bu Teaching Hospital in Accra and later the Komfo Anokye Teaching Hospital in Kumasi. It was in Kumasi in 1978 that he later set up what became one of the city’s leadings clinics, Kufuor Clinic, of which he remains to date as the consultant-physician in charge.\n\nIn Kumasi during that period, he became a lecturer at the Department of Medicine at the Kwame Nkrumah University of Science and Technology, which university instituted in his honour in 1990, the Addo-Kufuor Prize for the best student in the final Bachelor of Medicine examination.\n\nCurrently a Fellow of the Royal College of Physicians (London), of the Royal Society of Tropical Medicine, the Ghana Medical Association, and of the West African College of Physicians, Addo-Kufuor was in 1993 appointed inspector of examinations for the final medical examinations at the University of Ghana Medical School. He also served as member of the executive council of the medical school and was appointed member of Court of Examiners responsible for assessing foreign trained doctors wishing to practice in Ghana by the Ghana Medical and Dental Council.\n\nDuring his presidency of the Ghana Medical Association from 1992 to 1995, a critical period in Ghana’s transition to democratic rule, Addo-Kufuor successful steered the GMA off potential political conflicts and set on course infrastructural development for this professional association and was representative for West Africa on the Confederation of African Medical Associations.\n\nWhen the ban on party politics was lifted by the military government of Jerry John Rawlings in 1992, Addo-Kufuor decided to go into public service and was unanimously elected as the Member of Parliament for the Manhyia Constituency of the New Patriotic Party from 1997 to 2008 when he resigned.\nHe was former chairman, Control Board of Command and Staff College of the Ghana Armed Forces, chairman of Cabinet Committee on Governance, and chairman of the board of Kofi Annan International Peace Keeping Centre.\n\nIn 2001, when the NPP won the Presidential elections and claimed majority in Parliament, Addo-Kufuor was appointed defence minister, a position he held until 2007.\n\nBefore his appointment as Minister for Defence, he was ranking member for\nhealth in Parliament and played a leading role during the pilot stage of the\nestablishment of the National Health Insurance Scheme.\n\nThe new Ministry of Defence Complex, the Kofi Annan International\nPeacekeeping Centre, Burma Hall, Burma Camp Computer Centre were among some of the major initiatives undertaken during his tenure as Minister for Defence.\n\nAddo-Kufuor was instrumental in the construction of the new 37 Military\nHospital in Accra and with the support of Ghanaian and Indian colleagues, the elevation of the hospital to a post - graduate medical college currently training medical specialists.\n\nThe Beijing Barracks and the “Open Day” of the Ghana Armed Forces were\namong the projects undertaken during this time.\n\nAs M.P. for Manhyia, he was responsible for many educational, health, and\ninfrastructural development initiatives. The Abbey Park Community Centre was\nthe most significant of these projects.\n\nHe was a member of the ECOWAS negotiation team that arranged the first\nMeeting between the Ivorian government and the rebel movement, Forces\nNouvelles. He also led the Ministry of Defence delegations to China, UK, US, Russia,\nBurundi, Rwanda, Senegal, Tanzania, Sierra Leone, India, Lebanon, Togo, and\nSouth Africa. These contacts helped to enhance the human and equipment\ncapabilities of the Ghana Armed Forces.\n\nDuring the Dagbon chieftaincy crisis in northern Ghana, from 2002 to 2003, Addo–Kufuor served concurrently as defence minister and interior minister. In 2008, he was again appointed interior minister. It was during this time he assisted in developing close collaboration between the police and military in the fight against armed robbery in Ghana. He was also instrumental in safeguarding the peace during the 2008 general elections.\n\nIn 2017, Addo-Kufuor was appointed by the government of Nana Addo Danquah Akufuo Addo as chairman of the board of directors of the SSNIT, the state pension fund.\n\nAddo-Kufuor is an active member of the Anglican Church for many years. His\nhobbies are gardening, reading, music, foreign travel, and listening to the radio.\nHe also enjoys boxing and football in a spectator capacity.\n\nHe married his wife Rosemary in London in 1966 and they have three children: Kwame, who is currently president of the Ghana Chamber of Mines; Kojo, an investment banker and the chief operating officer of Ghana Home Loans; and Nana Ama, also a banker and currently deputy managing director of the Eximbank, Ghana.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "306040", "url": "https://en.wikipedia.org/wiki?curid=306040", "title": "La Borde clinic", "text": "La Borde clinic\n\nLa Borde is a psychiatric clinic that opened in 1951, near the town of Cour-Cheverny in the Loire Valley of France. Still in operation today, La Borde has been a model in the field of institutional psychotherapy where patients actively participate in running the facility.\n\nThe clinic was founded by Jean Oury, a psychiatrist who previously worked in experimental therapy at Saint-Alban Psychiatric Hospital. The psychiatric practice borrowed the idea of Hermann Simon that it is necessary to look after the establishment and to look after each patient, while returning initiative and responsibility to them by developing situations in which they can work and express their creativity.\n\nFrom the mid-50s Félix Guattari worked at La Borde, developing its practice and organization and producing alongside Oury a body of theoretical work on the practice and theory of schizoanalysis, set in practice at La Borde, and included in his 1972 collaboration with the philosopher Gilles Deleuze, \"Anti-Œdipus\".\n\nAmong the many aspects of La Borde is the annual summer tradition in which the \"boarders\" and staff work together to perform a play. Nicolas Philibert, the documentary film-maker, made a documentary set at La Borde entitled \"Every Little Thing\" (French \"\"). The film was released in 1997 and follows the patients and staff staging their production of \"Operette\" by Witold Gombrowicz.\n\n\n \n"}
{"id": "12995624", "url": "https://en.wikipedia.org/wiki?curid=12995624", "title": "Land &amp; Water Australia", "text": "Land &amp; Water Australia\n\nLand & Water Australia was an Australian statutory corporation established under the Primary Industries and Energy Research and Development Act of 1989. Its primary focus was to organize and fund research and development activities which improved the long term productive capacity, sustainable use, management and conservation of Australia's land, water and vegetation resources.\n\nIt also acted as a research broker, organising collaborative programs like Managing Climate Variability and the National Program for Sustainable Irrigation.\n\nThe research programs of Land & Water Australia were managed to facilitate the purposeful co-investment of government and other funds to achieve natural resource management outcomes in 'productive lands' (a phrase used to differentiate it from land used predominantly for conservation, Indigenous or Defence purposes). The focus of most programs was on co-investment with research, policy and practitioners to get existing and new knowledge into the minds and hands of people who could use it. After the agency was closed responsibility for some programs and project was transferred.\n\nLand & Water Australia was closed in 2009.\n\nOver the twenty years people at Land & Water Australia learned and contributed a great deal in terms of science and policy understanding about managing Australian landscapes. They also learned a great deal about the business of investing in collaborative applied research, development and extension. These insights are reflected in the following publications:\n\n\"The Getting of Knowledge: a guide to funding and managing applied research\"\n\n\"The Australian NRM Knowledge System\": an analysis of how well current arrangements generate and organise the knowledge needed for Australia to manage its natural resource more wisely\n\n\"Knowledge for Managing Australian Landscapes\" (PDF): a comprehensive analysis of the knowledge needed for sustainable natural resource management in Australia and areas for improvement.\n\nThe legacy of Land & Water Australia was the subject of a conference and a promised publication held at the Australian Academy of Science's Shine Dome in May 18–19, 2010, Canberra. Presentations and audio from the conference are available to download .\n\nA list of achievements selected by the agency include:\n\nHyperlinks (see below) to programs, projects and documents started to fail in 2015, reducing accessibility. There is concern that this substantial investment in knowledge to inform Australia's long-term social, environmental and economic well-being could be lost. However, knowledge resides in many people and agencies. An important Director of LWA, Peter Cullen, used to say, the challenge was to \"make new mistakes\". Land & Water Australia has a legacy of innovative, high impact and important research.\n\nLand & Water Australia's Board and Innovation Manager commissioned an excellent triple bottom line research evaluation that sought to report on the return on investment of projects and programs. The TBL-ROI method was described by Chudleigh et al. (2006) and further developed (Schofield et al., 2007) before being rapidly adopted in a rolling evaluation of Australia’s agricultural research and development investment of about A$441m per year.\n\nFull list of Land & Water Australia's Research programs\nArchive of Land & Water's publications and research programs managed by Pandora - The National Library of Australia\nOther Research and Development Corporations in the Agriculture Fisheries and Forestry Portfolio\n"}
{"id": "29605965", "url": "https://en.wikipedia.org/wiki?curid=29605965", "title": "Life satisfaction", "text": "Life satisfaction\n\nLife satisfaction (LS) is the way in which people show their emotions, feelings (moods) and how they feel about their directions and options for the future. It is a measure of well-being assessed in terms of mood, satisfaction with relationships, achieved goals, self-concepts, and self-perceived ability to cope with one's daily life. Life satisfaction involves a favorable attitude towards one's life rather than an assessment of current feelings. Life satisfaction has been measured in relation to economic standing, degree of education, experiences, residence, among many other topics.\n\nLife satisfaction is a key part of subjective wellbeing.\n\nOne of the primary concepts of personality is the Big Five factor model. This model illustrates what some researchers believe to be the building blocks of every individual's personality. This model considers the dimensions of openness to experience, conscientiousness, extraversion, agreeableness, and neuroticism. In a study carried out by Deneve and Cooper in 1998, multiple studies were analyzed with certain personality questionnaires that linked subjective well-being and personality measures. They found that neuroticism was the strongest predictor of life satisfaction. Neuroticism is also linked to people who have difficulty making up their mind, and is common in people who suffer from mental illness. The personality factor \"openness to experience\" is positively correlated with life satisfaction. Apart from the personality dimensions studied in the Big Five model, the trait chronotype has been related to life satisfaction; morning-oriented people (\"larks\") showed higher life satisfaction than evening-oriented individuals (\"owls\").\n\nMore frequent socialization can also contribute to overall well-being. Social support via others has been shown to affect the well-being of adults and the overall health of those individuals. Therefore, people who tend to communicate, and who are considered to be more open to others would have a higher-level of life satisfaction.\n\nHeritability has been shown to have an effect on how one is ranked in terms of life satisfaction. Heritability plays a role in both personality and individual experiences. Research suggests that heritability can influence life satisfaction to some degree. This study found that there were no individual differences between males and females in terms of the heritability of life-satisfaction, however the personality elements that were affected by heritability did seem to have an effect on their overall life-satisfaction.\n\nIt has been further suggested that being able to independently deal with negative emotions can influence long-term life-satisfaction. Having a personality capable of properly dealing with emotions like anger, angst, or hate can be beneficial when dealing with similar things later in life. People who are more easy-going tend to deal with their negative emotions differently than someone who is up-tight. These individual differences can influence the way people deal with problems in the present and how they deal with similar situations in the future.\n\nThe Satisfaction with Life Scale (SWLS) is a single scale that is used by UNESCO, the CIA, the New Economics Foundation, the WHO, the Veenhoven Database, the Latinbarometer, the Afrobarometer, and the UNHDR to measure how one views his or her self-esteem, well-being and overall happiness with life. Previous modeling showed that positive views and life satisfaction were completely mediated by the concept of self-esteem, together with the different ways in which ideas and events are perceived by people. Several studies found that self-esteem plays a definite role in influencing life satisfaction. By knowing yourself and your worth, you are driven to think in a positive way. There is also a homeostatic model that supports these findings.\n\nA person's mood and outlook on life can also influence his or her perception of his or her own life satisfaction. There are two kinds of emotions that may influence how people perceive their lives. Hope and optimism both consist of cognitive processes that are usually oriented towards the reaching of goals and the perception of those goals. Additionally, optimism is linked to higher life satisfaction, whereas pessimism is related to symptoms in depression.\n\nAccording to Seligman, the happier people are, the less they focus on the negative aspects of their lives. Happier people also have a greater tendency to like other people, which promotes a happier environment. This correlates to a higher level of the person's satisfaction with his or her life, due to the notion that constructiveness with others can positively influence life satisfaction. However, others have found that life satisfaction is compatible with profoundly negative emotional states like depression.\n\nLife-review therapy using Autobiographical Retrieval Practice for older adults with depressive symptoms, in a study carried out by Serrano JP, Latorre JM, Gatz M, and Montanes J, Department of Psychology at Universidad de Castilla-La Mancha, demonstrated that, with increased specificity of memories, individuals show decreased depression and hopelessness and increased life satisfaction. The test was designed to measure participants' ability to recall a specific memory in response to a cue word, while being timed.\nThirty cue words; including five words classified as 'positive' (e.g., \"funny, lucky, passionate, happy, hopeful),\" five as 'negative' \"(unsuccessful, unhappy, sad, abandoned, gloomy),\" and five as 'neutral' \"(work, city, home, shoes, family);\" were presented orally in a fixed, alternating order to each member of a focus group. To ensure that the participants understood the instructions, examples were provided of both 'general' memories (e.g., summers in the city) and 'specific' memories (e.g., the day I got married). For each cue word, participants were asked to share a memory evoked by that word. The memory had to be of an event that should have occurred only once, at a particular time and place, and lasted no longer than a day. \nIf the person could not recall a memory within 30 seconds, then that cue instance was not counted. Two psychologists served as raters and independently scored the responses of each participant. Each memory was tagged either as 'specific' – if the recalled event lasted no more than one day – or, otherwise, as 'general'. The raters were not informed regarding the hypotheses of the study, the experimental (control) group's membership, nor the content of the pretest or post-test.\n\nThe psychologists Yuval Palgi and Dov Shmotkin (2009) studied people who were primarily in their nineties. This subject group was found to have thought highly of their past and present. But generally, the group thought lower of their future. These people were very satisfied with their life up until the point they were surveyed but knew that the end was near and so were not quite as hopeful for the future. Intelligence is also a factor because life satisfaction grows as people become older; as they grow older, they become wiser and more knowledgeable, so they begin to see that life will be better and understand the important things in life more.\n\nIt has been recorded that adolescents seem to have a lower level of life satisfaction than their older counterparts. This could be because many decisions are imminent, and an adolescent could be facing them for the first time in his or her life. Although many adolescents have insecurities about many aspects of their lives, satisfaction with friends stayed at a consistent level. This is hypothesized to be due to the amount one can identify with those in one's age group over other age groups. In this same study, researchers found that satisfaction with family decreased. This could be because more rules and regulations are typically implemented by parental figures, and adolescents tend to demonize those in control of them. Also, it was found that life satisfaction in terms of sexuality increased. This is because at this age many adolescents reach sexual maturation, which can encourage them to find verification and satisfaction in the idea of a sexual partnership.\n\nIt has been suggested that there are several factors that contribute towards our level of life satisfaction. Experiences that are both acute events (e.g., death of\na loved one) and chronic, daily experiences (e.g., ongoing family discord) influence self-reports of life satisfaction. The book “Happier” by Harvard lecturer Tal Ben-Shahar argues that happiness should be one's ultimate goal, the primary factor in evaluating alternative choices. As the subtitle implies, Happier recommends for us to pursue immediate joyful experience in ways that contributes to more long-term, meaningful satisfaction. Furthermore, Ben-Shahar argues that pursuing genuine self-motivated goals, rather than just instant pleasure or selflessness in service of long-delayed enjoyment, results in an optimal combination of short- and long-term happiness.\n\nDifferences in experience can greatly shape the way that we observe and engage with the world around us. It can influence the way we speak to people, the way we act in public, and our general outlook. These experiences which shape the way we think about our surroundings affect our life-satisfaction. Someone who has the tendency to see the world in a more negative light, may have a completely different level of satisfaction than someone who is constantly admiring the beauty of his or her surroundings. People who engage with more stress on average tend to have higher levels of stress can contribute to higher levels of self-report life satisfaction, as long as those who understand how to deal with their stress in a positive way.\n\nA recent study analyzes time-dependent rhythms in happiness comparing life satisfaction by weekdays (weekend neurosis), days of the month (negative effects towards the end of the month) and year with gender and education and outlining the differences observed. Primarily within the winter months of the year, an onset of depression can affect us, which is called seasonal affective disorder (SAD). It is recurrent, beginning in the fall or winter months, and remitting in the spring or summer. It is said that those who experience this disorder usually have a history of major depressive or bipolar disorder, which may be hereditary, having a family member affected as well.\n\nSeasonal affective disorder is hypothesized to be caused by the diminishing of the exposure to environmental light which can lead to changes in levels of the neurotransmitter chemical seratonin. Diminishing active seratonin levels increases depressive symptoms. There are currently a few treatment therapies in order to help with seasonal affective disorder. The first line of therapy is light therapy. Light therapy involves exposure to bright, white light that mimics outdoor light, counteracting the presumed cause of SAD. Due to the shifts in one's neurochemical levels, antidepressants are another form of therapy. Other than light therapy and antidepressants, there are several alternatives which involve agomelatine, melatonin, psychological interventions, as well as diet and lifestyle changes.\n\nResearch has found that the onset of SAD typically occurs between the ages of 20–30 years, but most affected people do not seek medical help. This could be due to the stigma of mental health issues. Many are afraid to state they are suffering and would rather hide it. As a society we should push forward towards greater acceptance and gain knowledge in order to solve these issues.\n\nIt is proposed that overall life satisfaction comes from within an individual based on the individual's personal values and what he or she holds important. For some it is family, for others it is love, and for others it is money or other material items; either way, it varies from one person to another. Economic materialism can be considered a value. Previous research found that materialistic individuals were predominantly male, and that materialistic people also reported a lower life satisfaction level than their non-materialistic counterparts. The same is true of people who value money over helping other people; this is because the money they have can buy them the assets they deem valuable. Materialistic people are less satisfied with life because they constantly want more and more belongings, and once those belongings are obtained they lose value, which in turn causes these people to want more belongings and the cycle continues. If these materialistic individuals do not have enough money to satisfy their craving for more items, they become more dissatisfied. This has been referred to as a hedonic treadmill. Individuals reporting a high value on traditions and religion reported a higher level of life satisfaction. This is also true for reported routine churchgoers and people who pray frequently. Other individuals that reported higher levels of life satisfaction were people who valued creativity, and people who valued respect for and from others – two more qualities seemingly not related to material goods. Because hard times come around and often people count on their peers and family to help them through, it is no surprise that a higher life satisfaction level was reported of people who had social support, whether it be friends, family, or church. The people who personally valued material items were found to be less satisfied overall in life as opposed to people who attached a higher amount of value with interpersonal relationships. accordance with the findings above, it is also fair to say that the notion of how one values themselves plays a part in how someone considers their own life. People who take pride in themselves by staying mentally and physically fit have higher levels of life satisfaction purely due to the content of their day. These values come together in determining how somebody sees themselves in light of others.\n\nDefining culture by reference to deeply engrained societal values and beliefs. Culture affects the subjective well-being. Well-being includes both general life satisfaction, and the relative balance of positive affect verses negative affect in daily life. Culture directs the attention to different sources of information for making the life satisfaction judgments, thus affecting subjective well-being appraisal.\n\nIndividualistic cultures direct attention to inner states and feelings (such as positive or negative affects), while in collectivistic cultures the attention is directed to outer sources (i.e. adhering to social norms or fulfilling one's duties). Indeed, Suh et al. (1998) found that the correlation between life satisfaction and the prevalence of positive affect is higher in individualistic cultures, whereas in collectivistic cultures affect and adhering to norms are equally important for life satisfaction. Most of modern western societies, such as the United States and European countries are directed towards individualism, while the eastern societies like China and Japan, are directed towards collectivism. Those of a collectivistic culture emphasize deeply on the unity one has with their families. They put others' needs before their individual desires. An individualistic culture is geared towards one's own personal achievements and it signals a strong sense of competition. They are expected to carry their own weight and rely on themselves. The United States is said to be one of the most individualistic countries, and on the other hand Korea and Japan are some of the most collectivistic countries. However both groups have their flaws. With an individualistic approach, one is inclined in possibly experiencing loneliness. Meanwhile, those in a collectivist culture, may be prone to having a dismay of rejection.\n\nLife satisfaction can also be looked at in a new one as influenced by a family. Family life satisfaction is a pertinent topic as everyone's family influences them in some way and most strive to have high levels of satisfaction in life as well as within their own family. As discussed by Gary L. Bowen in his article, \"Family Life Satisfaction: A Value Based Approach\" he examines how family life satisfaction is enhanced by the ability of family members to jointly realize their family-related values in behavior (459). It is important to examine family life satisfaction from all members of the family from a \"perceived\" perspective and an \"ideal\" perspective. Greater life satisfaction within a family increases through communication and understanding each member's attitudes and perceptions. A family can make all the difference for someone's life satisfaction.\n\nIn the article \"Family System Characteristics, Parental Behaviors, and Adolescent Life Satisfaction\" by Carolyn S. Henry, adolescent life satisfaction has much different origins than the life satisfaction of adults. An adolescent's life satisfaction is heavily influenced by his or her family's dynamic and characteristics. Family bonding, family flexibility, parental support are all huge factors into the adolescent's life satisfaction. The more bonding, flexibility, and support there is within a family the higher the adolescent's life satisfaction. Results of this study also revealed that adolescents living in a single-parent family home had significantly lower life satisfaction that adolescents in a two-parent home. An adolescent's age is extremely important in terms of life satisfaction coming from their family (Henry).\n\nFamily also relates to life satisfaction in a very different way: a woman's decision to have children or not. In the \"Relationship between Information Search in the Childbearing Decision and Life Satisfaction for Parents and Nonparents\" article by Carole K. Holahan, reveals that childless women have much higher life satisfaction than women with children. Women who consciously decided not to have children overall had very high life satisfaction. It was found that most of the life satisfaction came from careers instead of children. On the other hand, women who did have children had high life satisfaction which depended on the reasons and decision making for having children. These are just generalizations and life satisfaction comes from many different sources which are unique and different for every person. Life satisfaction can shift all the time from events, situations, family and friend implications and many different things that all must be taken into consideration.\n\nOn the other hand, life satisfaction is also affected by parenthood and couples introducing children into their relationship. Research has shown that adults with children are less happy (McLanahan & Adams 1987) due to less life satisfaction, less marital satisfaction, more anxiety and more depression.\n\nA satisfying career is an important component of life satisfaction. Doing something meaningful in a productive capacity contributes to one's feeling of life satisfaction. This notion of accomplishment is related to a person’s drive. Need for accomplishment is an essential part of becoming a fully functional person, and if someone feels accomplished they would be more able to see bright sides in their life; thus improving their life satisfaction\n\nInternationally, the salary one earns is important – income levels show a moderate correlation with individual evaluations of life satisfaction. However, in developed nations, the connection is weak and disappears for the most part when individuals earn enough money to meet basic needs (Kahneman & Deaton 2010; Diener et al., 2010; Myers and Diener, 1995).\n\nLife satisfaction is one component of subjective well-being, along with affective balance..\n\n\n\n"}
{"id": "2841639", "url": "https://en.wikipedia.org/wiki?curid=2841639", "title": "Manfred Curry", "text": "Manfred Curry\n\nManfred Curry (11 December 1899 – 13 February 1953) was a German born American scientist, physician, inventor, sailor and author. Born in Munich, Germany to American parents.\n\nAn accomplished Olympic yachtsman, he sailed more than 1400 regattas many of which he won. In later life he worked as a doctor specialising in bioclimatics and became the self-proclaimed discoverer of the pseudoscientific phenomenon of \"geomagnetic lines\" called the \"Curry Grid\".\n\nManfred Curry wrote a pioneering book on yacht aerodynamics and racing tactics, published in several editions and several languages, describing how he studied sailing-boat design scientifically, testing numerous rig configurations in the wind-tunnel at Göttingen. The importance of his book within yachting has been described as having brought scientific sailboat design into the public eye. In the book, he describes several of his inventions or developments that are in widespread use today, including the fully battened mainsail, the Genoa jib (so called because first used competitively in a regatta at Genoa) and the cam cleat (Called the \"Curryklemme\" in German). He described two successful racing dinghies as well innovations used on an America's Cup defending yacht. He was the most successful German yachtsman in history sailing in around 1400 races and winning more than 1000.\n\nOne of his dinghies, \"Aero\", has recently been found and restored.\n\nAs a doctor specialising in bioclimatics and allergies, he founded the American Bioclimatics Research Institute, which was renamed the Manfred Curry Clinic after his death. Curry also investigated the supposed allergenic properties of \"earth radiation\", a concept invented by him and his colleague Ernst Hartmann. \"Earth Radiation\" has never been accepted as a scientific field of study and is considered to be pseudoscience.\n\nAs a youth he was friends with the activist Roger Casement during the latter's stay in Germany. \n"}
{"id": "9052709", "url": "https://en.wikipedia.org/wiki?curid=9052709", "title": "Markus Kronthaler", "text": "Markus Kronthaler\n\nMarkus Kronthaler (April 5, 1967 – July 8, 2006) was an Austrian gendarme and mountaineer.\n\nKronthaler was born in Kufstein, Tyrol. He was an officer in the alpine section of Austria's Gendarmerie, which he left in 2003 to become a professional climber. Surviving a free fall of 150 meters (450 ft) into snow in January 2006, Kronthaler led a new expedition to Chogolisa and Broad Peak, Pakistan, in May 2006. He died of exhaustion on Broad Peak after reaching the summit on July 8. His body was left on the mountain.\n\nIn the summer of 2007, an Austrian mountaineering team climbed Broad Peak to retrieve Kronthaler's corpse, which was brought to Austria and cremated. This was the highest ever body recovery from a mountain. His urn was buried in Kufstein.\n\n\n"}
{"id": "40945859", "url": "https://en.wikipedia.org/wiki?curid=40945859", "title": "Median follow-up", "text": "Median follow-up\n\nIn statistics, median follow-up is the median time between a specified event and the time when data on outcomes are gathered. The concept is used in cancer survival analyses.\n\nMany cancer studies aim to assess the time between two events of interest, such as from treatment to remission, treatment to relapse, or diagnosis to death. This duration is generically called survival time, even if the end point is not death.\n\nTime-to-event studies must have sufficiently long follow-up durations to capture enough events to reveal meaningful patterns in the data. A short follow-up duration is appropriate for studying very severe cancers with poor prognoses, whereas a long follow-up duration is better suited to studying less-severe disease, or participants with good prognoses.\n\nMedian follow-up time is included in about half the survival analyses published in cancer journals, but of those, only 31% specify the method used to compute it.\n"}
{"id": "34588130", "url": "https://en.wikipedia.org/wiki?curid=34588130", "title": "National Department of Health of Papua New Guinea", "text": "National Department of Health of Papua New Guinea\n\nPapua New Guinea (PNG)’s National Department of Health is a statutory organisation focused on the delivery of better health services for the people of Papua New Guinea.\n\nThe department’s stated key goals for the period from 2009 to 2013 are:\n\n\nThe current Minister for Health is Hon. Dr Puka Temu. \n\nPNG’s National Department of Health has been accused of corruption, including taking bribes from pharmaceutical companies and misappropriation of government funds.\n\nIn October 2011, Investigation Task Force Sweep Chairman Sam Koim expanded Task Force Sweep’s scope to include an investigation into corruption at the National Department of Health. His team began the process of collecting and collating information on:\nA report on these findings is due to be provided to the National Executive Council (NEC) in the coming months. The investigation was initiated after Maxtone-Graham handed over a file to the police fraud squad which contained allegations of corrupt activities in his department.\nIn May 2011, Dr Clement Malau (Dr Malua), former Secretary for Health and Head of the National Department of Health until August 2011, under the previous PNG administration, was under fire for depositing a sum of PGK1.767 million from government money into the Bank of South Pacific (BSP) in 1998, instead using it for healthcare purposes and, ten years later, in August 2008, authorising the re-payment of this amount, plus interest, to an unregistered company named PACPNG Pharmaceuticals, instead of back to the government.\n\nIn March 2011, it was reported that senior officials in the National Department of Health received massive kickbacks from pharmaceutical companies for a period of up to ten years. At the time, Dr Malau said payments by medical suppliers to government officials for favours had run into “the equivalent of hundreds of thousands of dollars”.\n\nPNG's former Health Minister Sasa Zibe also stated that the Health Department's drug supply division “is riddled with corruption and is ineffective”.\nThe government blamed a lack of transparency within the tender process as a reason why the corruption went unnoticed for such a long period of time. However, pharmaceutical companies that have significant contracts with the PNG government, including Borneo Pacific Pharmaceutical Ltd, remained silent when questioned by the media.\n\nDoctors in national hospitals reported that they were “starved” of drugs in order to create an emergency system that would allow the National Department of Health to bypass the tender process and give preferential treatment to certain pharmaceutical companies.\nIn order to combat these allegations, Dr Malau hired a drug procurement and distribution specialist, charged with establishing an efficient drug ordering and distribution system. However, officials in the department attempted to terminate the expert’s contract prematurely.\n\nA paper prepared by the Australian government’s aid division, AUSAID in 2005, stated that although the country has a sound national health policy, a number of factors are hindering its implementation.\nThese factors include:\n\n"}
{"id": "20258767", "url": "https://en.wikipedia.org/wiki?curid=20258767", "title": "Norwegian Child Welfare Services", "text": "Norwegian Child Welfare Services\n\nThe Norwegian Child Welfare Services (, literally \"child protection\") are the public agencies responsible for child welfare in Norway. They consist of services in each municipality, which are aided and supervised by different governmental bodies at the state as well as the county level.\n\nThe Child Welfare Services’ statutory obligation is \"to ensure that children and youth who live in conditions that may be detrimental to their health and development receive the necessary assistance and care at the right time.\" Roughly 3% of all children in Norway receive some sort of measure from the Child Welfare Services, most of them in the form of relief measures to the child and its parents (such as counselling, advice, external support contacts, access to day care etc.). In about one quarter of the cases, the children are placed outside their homes (mainly in foster families or institutions) after care orders.\n\nThe Norwegian Child Welfare Services were established, and their activities are regulated, by the Child Welfare Act of 1992, which has the purpose \"to ensure that children and youth who live in conditions that may be detrimental to their health and development receive the necessary assistance and care at the right time,\" and \"to help ensure children and youth grow up in a secure environment\"\n\nThe superior authority in the field of child welfare in Norway is the Ministry of Children and Equality (Norwegian \"Barne- og likestillingsdepartementet\", abbreviated \"BLD\"). The Ministry is responsible for developing regulations and guidelines, but is not involved in individual cases.\n\nEach Norwegian municipality is obliged to have Child Welfare Services. These are responsible for the local and day-to-day implementation of the Child Welfare Act (such as preventive work, investigation, support service, approval of foster families, follow-up of children placed in foster families or institutions). This \"municipal child welfare\" is aided by two agencies that constitute the \"governmental child welfare\":\n\nIn addition, the following bodies at the county level are involved in child welfare:\n\nThe Child Welfare Services are responsible for implementing measures for children and their families in situations where there are special needs in relation to the home environment. Assistance may be provided as counselling, advisory services, and aid measures, including external support contacts, relief measures in the home, and access to day care.\nUnder the guidelines of the Norwegian Child Welfare Services, children are entitled to participate in decisions involving their personal welfare, and have the right to state their views in accordance with their age and level of maturity. This applies especially in cases where there are administrative and legal proceedings that will strongly affect the children's day-to-day lives.\n\nThe Child Welfare Services are required to take action if measures implemented in the home environment are not sufficient to safeguard the child's needs. In such cases, the Child Welfare Service in consultation with the parents may place children under foster care, in a child welfare institution, or introduce specific parent–child measures.\n\nRemoving a child from the home without parental consent is a measure of last resort in cases of (justifiable suspicion of) serious neglect, maltreatment, violence, abuse, trafficking etc. This requires a decision from the County Social Welfare Board on the basis of a recommendation submitted by the municipal authorities. In urgent cases (i.e. imminent danger for the physical or mental health of the child), the municipal welfare services are entitled (and obliged) to issue a provisional care order. Provisional care orders expire after six weeks unless they are confirmed by the County Social Welfare Board. Decisions taken by the County Social Welfare Board may only be overturned by the courts.\n\nThe municipal Child Welfare Services are charged with monitoring the development of children who have been placed in care outside their homes as well as their parents.\n\nChild Welfare Service employees are privy to a large amount of personal client information, and must comply with strict rules of confidentiality. However, information may be provided to other administrative agencies when this is necessary for carrying out child welfare service tasks.\n\nAccording to figures provided by Statistics Norway, 36,800 children received measures from the Norwegian Child Welfare Services at the end of 2015. This means that 2.9% of all children in Norway received some sort of measure. Of these, 12% were aged 0–2 years, 23% 3–5 years, 30% 6–12 years, and 35% 13–17 years. In addition, 6,800 young people aged 18–22 years (1.1% of their age class) received follow-up care.\n\n60% of the 36,800 children received support measures within their families. 16% received support measures while placed outside their homes with the consent of their parents. In the remainder 24% of the cases, children were placed outside their homes after care orders. Of the 14,850 children living outside their homes by the end of 2015, 72% lived in foster families, 14% were old enough to live by themselves with follow-up from the Child Welfare Services, and 8% were taken care of in institutions, while 5% where temporarily placed in private homes awaiting other solutions.\n\nThe main reasons for measures (both support measures and care measures) were lacking parenting skills (29%), parents’ mental problems (17%), high domestic conflict level (11%) and parents’ drug misuse (8%).\n\nStatistics Norway has also published some figures according to immigration status: while 2.2% of all children with Norwegian parents received measures, the corresponding figures were 3.2% for children born in Norway by immigrant parents, and 4.9% for immigrant children. The latter group includes minor asylum seekers arriving without parents.\n\nThe Norwegian Child Welfare Services are periodically the subject of public criticism, generally on two main issues. On the one hand, they are criticised for detecting too few cases of parental neglect and helping children too late (i.e., for having a too high threshold for taking action). On the other hand, they are criticised for taking over custody too easily (i.e., for having a too low threshold for taking action). Due to their duty of confidentiality, the Norwegian Child Welfare Services themselves cannot participate in public debates of single cases.\n\nThe Norwegian Child Welfare Services are obliged to ensure the well-being of all children residing in Norway, irrespective of their (or their parents’) nationality. While Norwegian legislation, following the United Nations Convention on the Rights of the Child, treats children as legal subjects in their own rights, some cultures regard children as the sole responsibility of the family. In several cases, therefore, culture clashes seem to exacerbate conflicts between the Child Welfare Services and immigrant parents. Children with a foreign mother are four times more likely than other children in Norway to be forcibly taken from their families and the number of children taken into emergency care rose by 50% in just 5 years (from 2008 to 2013) with the commonest reason for a care order now being simply \"lack of parenting skills\".\n\nThe European Court of Human Rights have by 2017 accepted eight separate hearings against Norway for the activity of its Child Welfare agency since December 2015. The ECHR rendered a judgement in one of these cases on the 7th of September, 2017 with a judgement of \"No violation of Article 8\".\n\n\n\n"}
{"id": "5007230", "url": "https://en.wikipedia.org/wiki?curid=5007230", "title": "Nutrient density", "text": "Nutrient density\n\nNutrient density identifies the proportion of nutrients in foods, with terms such as nutrient rich and micronutrient dense referring to similar properties. Several different national and international standards have been developed and are in use (see Nutritional rating systems).\n\nAccording to the World Health Organization, nutrient profiling classifies and/or ranks foods by their nutritional composition in order to promote human (and/or animal) health and to prevent disease. Ranking by nutrient density is one such nutrient profiling strategy. Ordering foods by nutrient density is a statistical method of comparing foods by the proportion of nutrients in foods. Some such comparisons can be the glycemic index and the Overall Nutritional Quality Index.\n\nNutrient-dense foods such as fruits and vegetables are the opposite of energy-dense food (also called \"empty calorie\" food), such as alcohol and foods high in added sugar or processed cereals.\n\nThe Academy of Nutrition and Dietetics reported in 2013 that:\n\nSeveral indicators of nutrient quality have been summarized by the Academy.\nThe Nutrient Rich Food Index has been developed by a research coalition involving food and nutrition practitioners. This index uses nutrient profiles that have been validated against accepted measures of a healthy diet, such as the Healthy Eating Index created by the USDA.\n\nThe Nutrient Profiling Scoring Calculator (NPSC) in Australia and New Zealand is a calculator for determining whether health claims can be made for a food by its reference to the Nutrient Profiling Scoring Criterion (NPSC). It is defined by the FSANZ Board, which operates under the FSANZ Act.\n\nThe United Kingdom Ofcom nutrient profiling model provides \"a single score for any given food product, based on calculating the number of points for ‘negative’ nutrients which can be offset by points for ‘positive’ nutrients.\" A 2007 UK-commissioned review of nutrient profiling models commissioned by the UK Food Standards Agency identified over 40 different schemes.\n\nThe World Health Organization reviews scientific and operational issues related to human nutrition, specifically when developing world populations are impacted.\n\n"}
{"id": "16856479", "url": "https://en.wikipedia.org/wiki?curid=16856479", "title": "Plague of Cyprian", "text": "Plague of Cyprian\n\nThe Plague of Cyprian is the name given to a pandemic that afflicted the Roman Empire from about AD 249 to 262. The plague is thought to have caused widespread manpower shortages for food production and the Roman army, severely weakening the empire during the Crisis of the Third Century. Its modern name commemorates St. Cyprian, bishop of Carthage, an early Christian writer who witnessed and described the plague. The agent of the plague is highly speculative due to sparse sourcing, but suspects include smallpox, pandemic influenza and viral hemorrhagic fever (filoviruses) like the Ebola virus. \nIn 250 to 262, at the height of the outbreak, 5,000 people a day were said to be dying in Rome. Cyprian's biographer, Pontius of Carthage, wrote of the plague at Carthage:\n\nIn Carthage, the \"Decian persecution\", unleashed at the onset of the plague, sought out Christian scapegoats. Fifty years later, North African convert to Christianity Arnobius defended his new religion from pagan allegations:\n\nCyprian drew moralizing analogies in his sermons to the Christian community and drew a word picture of the plague's symptoms in his essay \"De mortalitate\" (\"On the Plague\"):\n\nAccounts of the plague date from about AD 249 to 262. There was a latter incident from 270 involving the death of Claudius II Gothicus, though it's unknown if this was the same plague or a different outbreak. The \"Historia Augusta\" says that \"in the consulship of Antiochianus and Orfitus the favour of heaven furthered Claudius' success. For a great multitude, the survivors of the barbarian tribes, who had gathered in Haemimontum were so stricken with famine and pestilence that Claudius now scorned to conquer them further... during this same period the Scythians attempted to plunder in Crete and Cyprus as well, but everywhere their armies were likewise stricken with pestilence and so were defeated.\"\n\nThe severe devastation to the European population from the two plagues may indicate that the people had no previous exposure or immunity to the plague's cause. Historian William Hardy McNeill asserts that both the earlier Antonine Plague (166–180) and the Plague of Cyprian (251–270) were the first transfers from animal hosts to humanity of two different diseases, one of smallpox and one of measles although not necessarily in that order. D. Ch. Stathakopoulos asserts that both outbreaks were of smallpox. \n\nAccording to historian Kyle Harper, the symptoms attributed by ancient sources to the Plague of Cyprian better match a viral disease causing a hemorrhagic fever, such as ebola, rather than smallpox. (Conversely, Harper believes that the Antonine Plague was caused by smallpox.)\n\nAccording to historian Kyle Harper, the period of the plague nearly saw the end of the Roman Empire. He states that between AD 248 and 268, \".. the history of Roman is a confusing tangle of violent failures. The structural integrity of the imperial machine burst apart. The frontier system crumbled. The collapse of legitimacy invited one usurper after another to try for the throne. The empire fragmented and only the dramatic success of later emperors in putting the pieces back together prevented this moment from being the final act of Roman imperial history.\"\n\nMany Roman authorities blamed the plague itself on Christianity. Despite this, the threat of imminent death from the plague and the unwavering conviction among many of the Christian clergy in the face of it won more converts to the faith.\n\n\n"}
{"id": "11613197", "url": "https://en.wikipedia.org/wiki?curid=11613197", "title": "Predictive informatics", "text": "Predictive informatics\n\nPredictive informatics (PI) is the combination of predictive modeling and informatics applied to healthcare, pharmaceutical, life sciences and business industries.\n\nPredictive informatics enables researchers, analysts, physicians and decision-makers to aggregate and analyze disparate types of data, recognize patterns and trends within that data, and make more informed decisions in an effort to preemptively alter future outcomes.\n\nOver the past decade the increased usage of electronic health records has produced vast amounts of clinical data that is now computable. Predictive informatics integrates this data with other datasets (e.g., genotypic, phenotypic) in centralized and standardized data repositories upon which predictive analytics may be conducted.\n\nThe biopharmaceutical industry uses predictive informatics (a superset of chemoinformatics) to integrate information resources to transform data into knowledge in order to make better decisions faster in the area of drug lead identification and optimization.\n\nScientists involved in systems biology employ predictive informatics to integrate complex data about the interactions in biological systems from diverse experimental sources.\n\nPredictive informatics and analytics are also used in financial services, insurance, telecommunications, retail, and travel industries. \n\n\n"}
{"id": "288215", "url": "https://en.wikipedia.org/wiki?curid=288215", "title": "Respect for the Aged Day", "text": "Respect for the Aged Day\n\nThis national holiday traces its origins to 1947, when Nomadani-mura (later Yachiyo-cho, currently Taka-cho), Hyōgo Prefecture, proclaimed September 15 Old Folks' Day (Toshiyori no Hi). Its popularity spread nationwide, and in 1966 it took its present name and status. Annually, Japanese media take the opportunity to feature the elderly, reporting on the population and highlighting the oldest people in the country.\n\nSince 1963, the Japanese government has given a commemorative silver sake cup to Japanese who reach the age of 100. In 1963 the number was 153, but with numbers increasing, the government decided to reduce the size of the cup to cut costs in 2009. In 2014 29,357 received a cup. The cost increase from this led to the government considering making the cups from a different material or simply sending a letter.\n"}
{"id": "32452436", "url": "https://en.wikipedia.org/wiki?curid=32452436", "title": "Richard Sprenger", "text": "Richard Sprenger\n\nRichard Sprenger is a food safety expert and author of a number of books and many interactive training presentations on the topic of food safety and hygiene. His commentary on food safety has featured in media in the Middle East such as \"The National\" and the \"Khaleej Times\". He contributes regularly at such events as the Dubai International Food Safety Conferences, which are held annually across that Middle East and also speaks at events such as the annual Food Chain Conferences in Doha.\n\nSprenger started his career in food safety in 1973 when he qualified as an Environmental Health Officer. At the age of 38 he became a Director of Doncaster Metropolitan Borough Council’s (one of the UK’s largest local authorities) multidisciplinary Directorate of Environmental Services.\n\nIn 1990 Sprenger became the first environmental health officer appointed as a member of the UK Government Advisory Committee on the Microbiological Safety of Food and a member of the Salmonella in Eggs sub-committee. He was also a Local Authorities Coordinator of Regulatory Services (LACORS) advisor and Chair of the LACORS Food Poisoning Working Group.\n\nSprenger is a fellow of the Society of Food Hygiene Technology (SOFHT), the Royal Environmental Health Institute of Scotland and the Chartered Institute of Environmental Health (CIEH). He has worked closely with large organisations to develop food safety management systems and training programmes, including CWS Retail Services, Marks & Spencer Plc, McDonald's, The De Vere Group, WRVS, Shell Retail International, HM Prison Catering Services and Gala Retail Services (Ireland). He has provided advice and consultancy services to Governments including the UK Food Standards Agency (The training of Environmental Health Officers regarding the enforcement of the food safety management system for small businesses), such as Safer Food Better Business and the Ministry of Health in Bahrain.\n\nHe was the founder member of the Institute of Environmental Health Officer's Food Hygiene Education Working group. In 1982 the CIEH used Sprenger’s Basic and Advanced Food Safety courses he had developed in King's Lynn and with a few minor amendments these became the most popular food safety courses in the UK.He started Highfield.\n\nSprenger regularly speaks at international conferences. He has been involved in assisting in the training of environmental health officers in the UK, Ireland, Malta, Dubai, Cyprus, Mauritius and the Seychelles. In 2011 he held a workshop in Dubai. His specialist subjects include food safety management, food poisoning investigations, the training of food handlers and enforcement officers, auditing and inspection and HACCP/Food Safety management programmes.\n\nSprenger has been based in Dubai since 2010 where he was, at the request of the Dubai Municipality and working closely with Bobby Krishna (the Senior Food Studies and Surveys Officer with the Food Control Department of the Dubai Municipality. responsible for the development and implementation of the very successful Person in Charge Programme. He has also helped run several workshops in Dubai for all stakeholders involved with the PIC programme. In January 2011 this certification programme became compulsory for all food businesses who must have at least one Certified person in charge (PIC) who has been trained in food safety. Sprenger has been responsible for delivering \"train the trainer\" sessions to over 130 food safety trainers and Dubai Food Inspectors who are responsible for delivering PIC training. In 2011 Sprenger and Bobby Krishna developed the original PIC Handbook and Sprenger designed all of the original PIC training materials including interactive PowerPoint presentations for both Level 2 and Level 3.\n\nAround 12,000 supervisors and managers are trained as PICs each year and, according to Sprenger, highlights the importance of protecting consumers. and according to Sprenger, this is one of the world's leading initiatives concerned with improving food safety and protecting consumers.\n"}
{"id": "43309212", "url": "https://en.wikipedia.org/wiki?curid=43309212", "title": "Rivers State Dental and Maxillofacial Hospital", "text": "Rivers State Dental and Maxillofacial Hospital\n\nRivers State Dental and Maxillofacial Hospital (RSDMH) situated in Garrison, Port Harcourt, is a Nigerian specialist hospital opened in 2013 to provide dental, oral and maxillofacial services to the general public. The hospital is owned by the Rivers State government and is considered the first of its kind in Sub-Saharan Africa. \n\nThe hospital is one of the major health facilities in the state that is managed by the International Trauma and Care Centre (ITCC). Its building is four stories high.\n\n"}
{"id": "44506528", "url": "https://en.wikipedia.org/wiki?curid=44506528", "title": "Robert Lumsden", "text": "Robert Lumsden\n\nRobert Benny Lumsden TD, FRCSED (1903 – 8 October 1973) was a Scottish consultant ear, nose and throat (E.N.T.) surgeon.\n\nLumsden was educated at Strathallan School, the University of Edinburgh and for a short period at the University of Vienna. He graduated in medicine (MB, ChB) from Edinburgh in 1926 and became a Fellow of the Royal College of Surgeons of Edinburgh (FRCSED) in 1932.\n\nAfter his house appointments Lumsden joined the E.N.T. department of the Royal Infirmary, Edinburgh, where he eventually became honorary consultant. In 1928, he was appointed consultant to the E.N.T. department at Stirling Royal Infirmary and the Deaconess Hospital, Edinburgh.\n\nAt the outbreak of the Second World War, Lumsden, already serving with the Officers' Training Corps, was appointed E.N.T. specialist to a field general hospital. Shortly afterward, he was appointed as consultant adviser in E.N.T. to the Middle East Force. Lumsden was promoted to captain on 11 April 1945. He retired from the Territorial Army Reserve of Officers on 17 April 1955 with the rank of lieutenant colonel. On 29 April 1955, he was awarded the Territorial Decoration (TD). Lumsden published several papers during his military career detailing some of his medical cases.\n\nFollowing the end of the war, Lumsden spent time in Rome studying the treatment of Ménière's disease by destruction of the labyrinth of the inner ear by ultrasound and in Britain introduced the treatment at the experimental stage. While based at the Wilkie Surgical Research Institution at the University of Edinburgh he conducted extensive research on the effects of ultrasound on the inner ear. Lumsden retired from the Royal Infirmary, Edinburgh, in 1967.\n\nIn 1961 Lumsden was assistant editor on the sixth edition of Arthur Logan Turner's 1924 textbook \"Logan Turner's Diseases of the Nose, Throat, and Ear\". In 2014, the book was on its 11th edition. A review of the sixth edition appeared in the \"Proceedings of the Royal Society of Medicine\" in March 1962.)\n"}
{"id": "20513780", "url": "https://en.wikipedia.org/wiki?curid=20513780", "title": "Ross Creek Reservoir", "text": "Ross Creek Reservoir\n\nThe Ross Creek Reservoir is an artificial lake in Dunedin, New Zealand. One of the oldest artificial lakes in the country, and the oldest water supply reservoir still in use in the country, it was created in the 1860s to provide water for the city of Dunedin, at that time in the middle of rapid expansion due to the Otago goldrush. Designed by engineer Ralph Donkin and supervising builder David Proudfoot, the reservoir was opened in 1867 as the Royal Albert Reservoir, but the name was unpopular and it has been known as the Ross Creek Reservoir for over a century.\n\nThe reservoir, dams, and picturesque valve tower have a New Zealand Historic Places Trust Level I classification.\n\nThe reservoir is located in a heavily wooded valley in the suburb of Glenleith, four kilometres north of the city centre. Fed by a small stream, the Ross Creek — a tributary of the Water of Leith — it is held behind two small dams, 23 metres and 10 metres in height. The base of the larger dam is 95 metres above sea level, with the water surface at approximately 115 metres ASL.\n\nThe reservoir is surrounded by a public reserve which has been allowed to regenerate with native bush. Though not technically covered by the New Zealand Reserves Act, the area is referred to as a reserve and managed and maintained as such by the Dunedin City Council, by virtue of its high scenic and recreational value. This lies between Tanner and Rockside Roads in Glenleith and Cannington Road in Maori Hill. The winding Burma Road runs through the reserve to the north and west of the reservoir. One of Dunedin's most popular golf courses, Balmacewen Golf Course, abuts the reserve's southwest corner. The highest point in the reserve, in its northeastern corner close to Tanner Road, is some above sea level.\n\nNumerous popular walking tracks lead to and circle the reservoir, and follow the course of the Ross Creek and its tributary, School Creek. Track counters have recorded as many as 4,000 walkers on the tracks per month, making them some of Dunedin's most well-used bush walks. The tracks are marked with stone markers, and a permanent orienteering course is also marked numbered posts. The walks can be entered from various points along Burma and Tanner Roads, but the main entry is from lower down Ross Creek at Glenleith. A further track links the reserve with a walkway which follows the course of the Water of Leith past a former quarry to link with tracks which run through Woodhaugh Gardens at the mouth of the Leith Valley to the southeast.\nNotable features of the reserve — other than the reservoir — include a waterfall which cascades some into School Creek. Though these falls appear completely natural, they were created by the diversion of Ross Creek to form the reservoir, and now carry waters from the creek's flood channel. The lower parts of the reserve's tracks close to Glenleith are also notable, as they pass through the narrowest part of the Ross Creek's valley, which rises as canyon walls on both sides of the track and creek.\n\n"}
{"id": "16759570", "url": "https://en.wikipedia.org/wiki?curid=16759570", "title": "Russian twist", "text": "Russian twist\n\nThe Russian twist is a type of exercise that is used to work the abdominal muscles by performing a twisting motion on the abdomen. The exercise is believed by those who practice it to build explosiveness in the upper torso, which may help in sports such as tennis, swimming, baseball, track & field, hockey, golf, lacrosse, or boxing.\n\nTo perform the Russian twist, first, one should sit on the floor with knees bent as in a \"sit-up\" position. The feet should be kept together and slightly above the ground or put under a stable surface. The torso should be kept straight with the back kept off the ground at a 45 degree angle. Arms should be held together away from the body in a straight fashion and hands kept locked together like a ball or one can hold a weight to increase the difficulty. Next, the arms should be swung from one side to another in a twisting motion, with each swing to a side counting as one repetition. The slower one moves the arms from side to side, the harder the exercise becomes, working the abdomen that much better. When moving one's arms during the exercise, it is crucial to not stop between repetitions or else one will lose the effect of working the abdomen. Constant breathing in and out during the exercise is important as one should not hold one's breath.\n\nThere are also other variants of this exercise such as using a stability ball or with a barbell standing up.\n\nThe Mason twist is a more advanced (difficult) version of the Russian twist. It is performed in the same manner, except the legs are straight and the feet are held off the ground (in the V-sit position) for the duration of the exercise. \n"}
{"id": "22874833", "url": "https://en.wikipedia.org/wiki?curid=22874833", "title": "Stroke Alliance for Europe", "text": "Stroke Alliance for Europe\n\nThe Stroke Alliance for Europe (SAFE) is a non-profit coalition of European charities all connected with improving healthcare provided to stroke survivors. \nIt represents a range of patient groups from across Europe whose mutual goal is to drive stroke prevention and awareness and promote prevention of stroke through education.\n\nThe Stroke Alliance for Europe was formed by the European Parliament in 2004.\n\n"}
{"id": "5325318", "url": "https://en.wikipedia.org/wiki?curid=5325318", "title": "Systemic disease", "text": "Systemic disease\n\nA systemic disease is one that affects a number of organs and tissues, or affects the body as a whole.\n\n\nGetting a regular eye exam may play a role in identifying the signs of some systemic diseases. \"The eye is composed of many different types of tissue. This unique feature makes the eye susceptible to a wide variety of diseases as well as provides insights into many body systems. Almost any part of the eye can give important clues to the diagnosis of systemic diseases. Signs of a systemic disease may be evident on the outer surface of the eye (eyelids, conjunctiva and cornea), middle of the eye and at the back of the eye (retina).\"\n\nSince 500 B.C., some researchers have believed that the physical condition of the fingernails and toenails can indicate various systemic diseases. Careful examination of the fingernails and toenails may provide clues to underlying systemic diseases , since some diseases have been found to cause disruptions in the nail growth process. The nail plate is the hard keratin cover of the nail. The nail plate is generated by the nail matrix located just under the cuticle. As the nail grows, the area closest to becoming exposed to the outside world (distal) produces the deeper layers of the nail plate, while the part of the nail matrix deeper inside the finger (proximal) makes the superficial layers. Any disruption in this growth process can lead to an alteration in the shape and texture.\n\nFor example, pitting looks like depressions in the hard part of the nail. Pitting is to be associated with psoriasis, affecting 10% - 50% of patients with that disorder. Pitting also may be caused by a variety of systemic diseases, including reactive arthritis and other connective tissue disorders, sarcoidosis, pemphigus, alopecia areata, and incontinentia pigmenti. Because pitting is caused by defective layering of the superficial nail plate by the proximal nail matrix, any localized dermatitis (e.g., atopic dermatitis or chemical dermatitis) that disrupts orderly growth in that area also can cause pitting.\n"}
{"id": "39319232", "url": "https://en.wikipedia.org/wiki?curid=39319232", "title": "Tabagie (room)", "text": "Tabagie (room)\n\nA tabagie is a room designated for smoking tobacco and socializing.\n\nIn modern Quebec French, \"tabagie\" refers to a tobacco shop, which in Parisian French is called a \"bureau de tabac\".\n\n"}
{"id": "12348916", "url": "https://en.wikipedia.org/wiki?curid=12348916", "title": "The Institute of Optometry", "text": "The Institute of Optometry\n\nThe Institute of Optometry is a centre for optometry, based in south London, England. It was established in 1922 as the London Refraction Hospital.\n\nThe London Refraction Hospital (LRH) was formed in October 1922, the first institute of its kind in the world. The first committee of management consisted of Owen Aves (Chairman), F.W. Bateman, J.H. Cuff, F.W. Dadd, G.E. Houghton and W. H. Nichols. The first secretary was F.T. Gregg. James Forrest, who was a surgeon oculist, was also involved in the founding.\n\nThe LRH was enlarged and re-modelled in October 1928 and re-opened in February 1929 by the Rt. Hon. the Countess of Mayo. In November 1938 the LRH was reconstituted by order of the Charity Commission.\n\nThe second Lord Charnwood was active in the management of the London Refraction Hospital after the second world war.\n\nIn 1985 it was suggested by Rishi Agarwal in Optometry Today that 'in addition to making efforts for a Royal College of Optometrists, efforts should also be made for a Royal status for the LRH.\n\nIn 1988 the LRH changed its name to the Institute of Optometry.\n\nIn 2008 the Institute of Optometry, in partnership with London South Bank University, established a post-graduate Doctor of Optometry programme. This was the first professional doctorate in optometry by that description offered in the UK, distinct from a traditional PhD.\n\n"}
{"id": "50347617", "url": "https://en.wikipedia.org/wiki?curid=50347617", "title": "Timeline of malaria", "text": "Timeline of malaria\n\nMalaria is an infectious disease caused by a parasite; it is spread by the bite of an infected mosquito. Every year, 300 to 700 million people get infected. Malaria kills 1 million to 2 million people every year. 90% of the deaths occur in Africa.\n\n"}
{"id": "35872466", "url": "https://en.wikipedia.org/wiki?curid=35872466", "title": "Tobacco use in Afghanistan", "text": "Tobacco use in Afghanistan\n\nTwo types of tobacco are used in Afghanistan. Cigarette smoking and \"naswar\" or moist snuff which is used through mouth and nose. Global Youth Tobacco Survey (GYTS) held in schools of five provinces of Afghanistan showed high exposure to second hand smoke.\n\nAnother unpublished study by Welayatee et all in general population of Kabul, the capital of Afghanistan, showed high prevalence of cigarette smoking among males aged 18 years and older. Naswar was another common form of tobacco used by adult males.\n"}
{"id": "20927937", "url": "https://en.wikipedia.org/wiki?curid=20927937", "title": "Translational research", "text": "Translational research\n\nTranslational research – often used interchangeably with translational medicine or translational science or bench to bedside – is an effort to build on basic scientific research to create new therapies, medical procedures, or diagnostics. Basic biomedical research is based on studies of disease processes using for example cell cultures or animal models. The term translational refers to the \"translation\" of basic scientific findings in a laboratory setting into potential treatments for disease.\n\nTranslational medicine is defined by the European Society for Translational Medicine (EUSTM) as \"an interdisciplinary branch of the biomedical field supported by three main pillars: benchside, bedside and community.\"\n\nIt is defined for school-based education by the Education Futures Collaboration (www.meshguides.org) as research which translates concepts to classroom practice. Examples of translational research are commonly found in education subject association journals and in the MESHGuides which have been designed for this purpose.\n\nTranslational research applies findings from basic science to enhance human health and well-being. In a medical research context, it aims to \"translate\" findings in fundamental research into medical practice and meaningful health outcomes. Translational research implements a \"bench-to-bedside\", from laboratory experiments through clinical trials to point-of-care patient applications, model, harnessing knowledge from basic sciences to produce new drugs, devices, and treatment options for patients. The end point of translational research is the production of a promising new treatment that can be used with practical applications, that can then be used clinically or are able to be commercialized.\n\nAs a relatively new research discipline, translational research incorporates aspects of both basic science and clinical research, requiring skills and resources that are not readily available in a basic laboratory or clinical setting. It is for these reasons that translational research is more effective in dedicated university science departments or isolated, dedicated research centers. Since 2009, the field has had specialized journals, the \"American Journal of Translational Research\" and \"Translational Research\" dedicated to translational research and its findings.\n\nTranslational research is broken down into different stages, including two-stage (T1 and T2), four-stage (T1, T2, T3, and T4), and five-stage (T1, T2, T3, T4, and T5) schemes. In a two-stage model, \"T1 research\", refers to the \"bench-to-bedside\" enterprise of translating knowledge from the basic sciences into the development of new treatments and \"T2 research\" refers to translating the findings from clinical trials into everyday practice. In a five-stage scheme, T1 involves basic research, T2 involves pre-clinical research, T3 involves clinical research, T4 involves clinical implementation, and T5 involves implementation in the public health sphere. Waldman et al. propose a scheme going from T0 to T5. T0 is laboratory (before human) research. In T1-translation, new laboratory discoveries are first translated to human application, which includes phase I & II clinical trials. In T2-translation, candidate health applications progress through clinical development to engender the evidence base for integration into clinical practice guidelines. This includes phase III clinical trials. In T3-translation, dissemination into community practices happens. T4-translation seeks to (1) advance scientific knowledge to paradigms of disease prevention, and (2) move health practices established in T3 into population health impact. Finally, T5-translation focuses on improving the wellness of populations by reforming suboptimal social structures. \n\nIn a two-stage scheme, translational research includes two areas of translation. One is the process of applying discoveries generated during research in the laboratory, and in preclinical studies, to the development of trials and studies in humans. The second area of translation concerns research aimed at enhancing the adoption of best practices in the community. Cost-effectiveness of prevention and treatment strategies is also an important part of translational science.\n\nBasic research is the systematic study directed toward greater knowledge or understanding of the fundamental aspects of phenomena and is performed without thought of practical ends. It results in general knowledge and understanding of nature and its laws.\n\nApplied research is a form of systematic inquiry involving the practical application of science. It accesses and uses the research communities' accumulated theories, knowledge, methods, and techniques, for a specific, often state, business, or client-driven purpose.\n\nIn medicine, translational research is increasingly a separate research field. A citation pattern between the applied and basic sides in cancer research appeared around 2000.\n\nCritics of translational research point to examples of important drugs that arose from fortuitous discoveries in the course of basic research such as penicillin and benzodiazepines, and the importance of basic research in improving our understanding of basic biological facts (e.g. the function and structure of DNA) that go on to transform applied medical research.\n\nExamples of failed translational research in the pharmaceutical industry include the failure of anti-aβ therapeutics in Alzheimer's disease. Other problems have stemmed from the widespread irreproducibility thought to exist in translational research literature.\n\nIn U.S., the National Institutes of Health has implemented a major national initiative to leverage existing academic health center infrastructure through the Clinical and Translational Science Awards. \nThe National Center for Advancing Translational Sciences (NCATS) was established on December 23, 2011.\n\nAlthough translational research is relatively new, it is being recognized and embraced globally. Some major centers for translational research include:\nAdditionally, translational research is now acknowledged by some universities as a dedicated field to study a PhD or graduate certificate in, in a medical context. These institutes currently include Monash University in Victoria, Australia, the University of Queensland, Diamantina Institute in Brisbane, Australia, at Duke University in Durham, North Carolina, America, at Creighton University in Omaha, Nebraska. and at Emory University in Atlanta, Georgia,\nThe industry and academic interactions to promote translational science initiatives has been carried out by various global centers such as European Commission, GlaxoSmithKline and Novartis Institute for Biomedical Research.\n\n\n"}
{"id": "8370276", "url": "https://en.wikipedia.org/wiki?curid=8370276", "title": "Trindade (water)", "text": "Trindade (water)\n\nTrindade (Portuguese meaning Trinity) is a brand of still bottled water in Cape Verde. It is produced by the company Tecnicil Indústria (\"Águas de Cabo Verde\" before 2008).\n"}
{"id": "14853653", "url": "https://en.wikipedia.org/wiki?curid=14853653", "title": "Wheelchair lift", "text": "Wheelchair lift\n\nA wheelchair lift, also known as a platform lift, or vertical platform lift is a fully powered device designed to raise a wheelchair and its occupant in order to overcome a step or similar vertical barrier.\n\nWheelchair lifts can be installed in homes or businesses and are often added to both private and public vehicles in order to meet accessibility requirements laid out by disability acts. These mobility devices are often installed in homes as an alternative to a stair lift, which only transport a passenger and not his/her wheelchair or mobility scooter.\n\nIn the United States, the Americans with Disabilities Act of 1990 (ADA) required that all new mass transit vehicles placed into service after July 1, 1993, be accessible to persons in wheelchairs, and until the 2000s, this requirement was most commonly met by the inclusion of a wheelchair lift. In 1993, 29,033 transit buses in the U.S. were equipped with a wheelchair lift or ramps, 52 percent of all U.S. transit buses. By 2001, this figure had grown to 58,785 buses (but the percentage that were equipped with lifts, as opposed to ramps, is not known).\n\nLow-floor transit vehicles (buses, streetcars, light rail cars) – fitted with ramps or bridge plates rather than lifts – later began to become more common than lifts for heavy-duty transit vehicles, while lifts continued to be used in paratransit vehicles.\n\nA number of legal regimes in various countries regulate the use of wheelchair lifts, setting forth standards for the devices and requiring certain kinds of businesses to make parking lots accessible to vehicles bearing the devices. In some instances, accessibility standards have been achieved in legal settlements. For example, in the 2005 case of \"Dilworth, et al. v. City of Detroit\", NO. 2:04- cv-73152 (E.D. Mich. 2005), the defendant city conceded that the Americans With Disabilities Act and its supporting legislation required the city \"to maintain the wheelchair lifts on its buses in operative condition; promptly repair wheelchair lifts if they are damaged or out of order; establish a system of regular and frequent maintenance checks of wheelchair lifts; remove a vehicle from service if the lift is inoperative (with limited exceptions); provide alternative transportation when the lift doesn't work and the next accessible bus is more than 30 minutes away.\"\n\nWhile some wheelchair-accessible vans use a powered lift to assist the occupant in boarding, a wheelchair ramp is usually less expensive for this purpose and is often installed on minivans. Full-size vans require the use of a platform lift. There are two types of platform lifts installed on wheelchair-accessible vans: single-arm and dual-arm. Single-arm wheelchair lifts are only used in side-entry applications. They take up less interior space and leave the passenger entry open; however, they have less lifting capacity than dual-arm lifts. Most dual-arm wheelchair lifts have a lift capacity up to 800 pounds. These lifts consume more interior space and block the side entry and, for these reasons, are often mounted in the back of the vehicle for rear-entry applications.\n\nAs mandated by the National Highway Traffic Safety Administration (NHTSA), wheelchair-accessible vans with wheelchair lifts are equipped with a safety lift interlock. Designed to prevent operation of the wheelchair van or wheelchair lift in unsafe situations, the safety interlock will sound an alarm if an unsafe condition exists (e.g., the vehicle attempts to move while the lift is deployed) or prevent the vehicle from shifting into drive while the wheelchair lift is in operation.\n\nRecent innovations have allowed for the development of wheelchair lifts which assist people in entering truck cabs, so that they may drive or operate heavy equipment. Wheelchair lifts can also be used to move an unoccupied scooter into a vehicle.\n\nAn indoor vertical platform lift operates much like an elevator which is installed within a hoist-way or shaft-way. Although the installation of a vertical platform lift is similar to that of an elevator, it's much less expensive. Some models, such as the Savaria V-1504 hydraulic lift, offer options to finish a vertical platform lift to make it operate more like a home elevator.\n\nAn outdoor vertical platform may include factory-built enclosures that protect the user from the weather and keep them dry. The enclosure acts as a shaft-way inside the unit with gates or doors that are added to the entrance or exit.\n\n\n"}
{"id": "47606777", "url": "https://en.wikipedia.org/wiki?curid=47606777", "title": "Éric A. Cohen", "text": "Éric A. Cohen\n\nÉric A. Cohen (born March 19, 1958) is a Canadian molecular virologist whose research is focused on human immunodeficiency virus (HIV)-host interactions that govern viral replication and persistence.\n\nCohen graduated from Collège Jean-de-Brébeuf of Montréal in 1977 with a college diploma in Health Sciences. He received a B.Sc. in Biochemistry from McGill University in 1981 and a Ph.D. in Molecular Biology from Université de Montréal in 1987.\n\nAs a Ph.D. student, he worked on fundamental aspects of herpes simplex virus replication and transformation under the direction of Yves Langelier. In 1986, he joined the laboratory of William A. Haseltine at the Dana-Farber Cancer Institute and Harvard Medical School as a postdoctoral fellow, working on fundamental aspects of HIV structure and function to uncover new targets for antiviral therapy. His postdoctoral work led to the identification of two HIV-1 non-structural proteins, named Viral Protein U (Vpu) and Viral Protein R (Vpr), part of a new class of retroviral proteins - designated accessory proteins - that are required for optimal virus multiplication and dissemination.\n\nIn 1990, Cohen became a Faculty member of the Department of Microbiology, Infectiology and Immunology at Université de Montréal and was appointed Professor of Virology in 1999. In 2004, he joined the Institut de recherches cliniques de Montréal, where he is currently pursuing research aimed at understanding HIV persistence and identifying intervention strategies for an HIV cure.\n\nCohen's laboratory has contributed to describing the structure and function of Vpr during HIV-1 infection. His work was also involved in defining Vpr as a viral factor with immune-modulatory functions.\n\nCohen has investigated the role and function of Vpu in HIV pathogenesis. His laboratory demonstrated that Vpu enables the optimal production and dissemination of the virus and helped shed light on the molecular and cellular mechanisms through which Vpu counteracts BST2 (also designated Tetherin), an interferon-regulated host factor that strongly inhibits the release and transmission of HIV-1 and other enveloped viruses. Cohen's work also showed that Vpu plays a key part in the negative regulation of the CD4 receptor observed during HIV infection and that the antagonistic actions of Vpu on CD4 and BST2 are among the strategies employed by HIV to circumvent several types of anti-HIV immune responses.\n\nCohen has received a senior-level Canada Research Chair in Human Retrovirology and most recently the IRCM-Université de Montréal Chair of Excellence in HIV Research. He has authored more than 140 manuscripts and books published in scientific and medical journals, and holds several international patents. He is the team leader of CanCURE, a multidisciplinary research consortium studying HIV-host interactions governing HIV persistence and developing intervention strategies towards an HIV cure. Cohen is a founding member of the AIDS and Infectious Disease Network (SIDA-MI) of the Fonds de recherche du Québec – Santé (FRQS), and currently serves on its scientific committee. \nHe was also a member of the Canadian Institutes of Health Research HIV/AIDS Research Advisory Committee (CHARAC). He was part of the International AIDS Society (IAS) 2016 International Scientific Working Group of more than 50 experts responsible for updating and revising the 2012 Global Scientific Strategy: Towards an HIV Cure.\n\nIn 2012, Cohen received the Marcel-Piché prize awarded to an IRCM researcher. In 2014, he received the Pierre-Bois prize bestowed to an IRCM researcher for his philanthropic and institutional activities as well as his scientific outreach. He was elected as Fellow of the Royal Society of Canada and of the Canadian Academy of Health Sciences in 2016.\n\nCohen was the Director of the Small Genome Division at Human Genome Sciences, a genomics company that was acquired by GlaxoSmithKline. He was a scientific advisor and collaborator for Theratechnologies, a Canadian biotechnology company that developed Egrifta, the only treatment indicated to reduce excess abdominal fat in HIV-infected patients with lipodystrophy. He was also the co-founder and chairman of the Canadian genomics company Ecopia BioSciences.\n"}
