{"id": "17327417", "url": "https://en.wikipedia.org/wiki?curid=17327417", "title": "Abraham S. Luchins", "text": "Abraham S. Luchins\n\nAbraham S. Luchins (March 8, 1914 – December 27, 2005) was one of the most important American Gestalt Psychologists and a pioneer of group psychotherapy. He was born in Brooklyn, New York and died in Albany.\n\nLuchins was a student and staff member of Max Wertheimer, the main originator of Gestalt Psychology. After Max Wertheimer fled to the USA and started lecturing at the New School for Social Research, Luchins worked as his assistant and became one of his closest collaborators from 1936 till 1942. \n\nHe is well known for his research on the role of a \"mental set\" (Einstellung effect) in the use of the various water jar refill problems.\nThe idea was to find out, to what extent the successful use of a problem solving strategy has a negative effect when the task cannot be solved by the previous strategy.\n\nOther fields of research were group psychotherapy and research methods and strategies.\n\nLuchins lectured at Yeshiva University (New York), McGill University (Montreal), the University of Oregon, the University of Miami.\nFrom 1962 on he was professor of psychology at the University at Albany, State University of New York and professor emeritus from 1984.\n\nIn 1993 he became an honorary member of the international \"Society for Gestalt Theory and its Applications (GTA)\" - \"Gesellschaft für Gestalttheorie und ihre Anwendungen (GTA)\".\n\n\n"}
{"id": "22181335", "url": "https://en.wikipedia.org/wiki?curid=22181335", "title": "Al-Khidmat Foundation", "text": "Al-Khidmat Foundation\n\nAlKhidmat (اﻟﺧدﻣﺖ) Foundation is network that provides humanitarian services across Pakistan. It is registered with the Government of Pakistan as a non-governmental organisation (NGO) under the Societies Act XXI of 1860. , its president was Muhammad Abdul Shakoor. Its sole aim is service to humanity without discrimination of religion, race, cast, sect, language, or political affiliation. Mainly, Alkhidmat Foundation works in seven (7) key areas such as: Disaster Management, Education, Health Services, Clean Water, Orphan Care, Mawakhat and Community Services which altogether cover all fields of the life. Alkhidmat Foundation has expanded its operations to other countries as well and the organization is engaged in welfare activities in Bangladesh, Syria, Indonesia, Malaysia Nepal and Myanmar.\n\nAlkhidmat Foundation Pakistan is one of the advancing, non-for-profit and autonomous organization, wholly devoted to humanitarian cause. In spite of the fact that AlKhidmat Foundation authoritatively enrolled in 1990 as an NGO, its relief and humanitarian records goes back to the times of Independence of Pakistan with initially focusing on furnishing safe house, nourishing and treating outcasts and protecting the deserves which has later become the trade mark of Alkhidmat Foundation Pakistan.\n\nThe Foundation has presence all over Pakistan including all the provinces and federally administered areas. It has one of the quick and vast grass-root structure which is vigilant to sudden emergency situation all time.\n\nOne of the latest initiative of Alkhidmat Foundation is its Orphan Care Program where the Foundation is having two fold activities i.e. 'Aghosh Homes' and 'Orphan Family Support'. These two programs are for those orphans who are below the age of 14 where the Foundation provides complete support to the child and his family. The Orphan homes of the Foundation are one of the best where state of the art facilities are provided to the children. This program is sponsored by many individuals and international donors. \n\nAlongside other NGOs, the Al-Khidmat Foundation participated in relief operations for the victims of the 2005 earthquake. Al-Khidmat is reported to have provided over 10,000 shelters and makeshift homes for those affected.\nIn the wake of 2010 floods in Pakistan, the Japanese Government provided financial support to the Al-Khidmat Foundation to support the people of Charsadda who were affected by the flood.\n\n[[Category:Emergency medical services in Pakistanhello jrgri0i340wknni"}
{"id": "53020225", "url": "https://en.wikipedia.org/wiki?curid=53020225", "title": "Ambulance Américain", "text": "Ambulance Américain\n\nIn 1915 before the United States' formal entry into World War I, teams of surgeons and their support staff had already been deployed to France. The surgeons' service at the Ambulance Américaine in Paris and at other smaller hospital facilities in the French countryside often close to the front lines brought about the efficient integration of civilian American medicine into World War I's military structure. Under the leadership of George Washington Crile and Harvey Cushing, this early American surgical presence in France during the war pioneered the organizational structure and procedural advances of modern military medicine.\n"}
{"id": "1497221", "url": "https://en.wikipedia.org/wiki?curid=1497221", "title": "Andhra Pradesh Anganwadi Workers and Helpers Union", "text": "Andhra Pradesh Anganwadi Workers and Helpers Union\n\nAndhra Pradesh Anganwadi Workers and Helpers Union, a trade union of Anganwadi workers and helpers in Andhra Pradesh, India. Anganwadi workers and helpers are workers engaged by the Government to work in the State operated Integrated Child Development Services which cater to the health and pre school education needs of 0-6 year old children as also the health and nutrition needs of pregnant women, nursing mothers and adolescent girls. All 0-6 year old children, all pregnant women, nursing mothers and adolescent girls in India are entitled to access to this Service. APAW&HU is affiliated to the Centre of Indian Trade Unions. The president of the union is B. Lalitamma and the secretary P. Roja.\n"}
{"id": "55394684", "url": "https://en.wikipedia.org/wiki?curid=55394684", "title": "Base hospital", "text": "Base hospital\n\nA base hospital is an Australian hospital serving a large rural area. It is often supported by smaller hospitals in local communities.\n"}
{"id": "40823900", "url": "https://en.wikipedia.org/wiki?curid=40823900", "title": "Capital punishment in Moldova", "text": "Capital punishment in Moldova\n\nCapital punishment in Moldova has been abolished in 2005.\n\nMoldova has not executed anyone since its independence. The death penalty was first abolished in 1995, but, until 2006, the Constitution retained it for crimes committed during war or during an inevitable threat of war. \n\nMoldova is a member of the Council of Europe. It has also signed and ratified Protocol no.13.\n\nThe partially recognized state of Transnistria, which declared its independence in 1990, retains the capital punishment, but has placed it under moratorium.\n\n"}
{"id": "310853", "url": "https://en.wikipedia.org/wiki?curid=310853", "title": "Cementum", "text": "Cementum\n\nCementum is a specialized calcified substance covering the root of a tooth. The cementum is the part of the periodontium that attaches the teeth to the alveolar bone by anchoring the periodontal ligament.\n\nThe cells of cementum are the entrapped cementoblasts, the cementocytes. Each cementocyte lies in its , similar to the pattern noted in bone. These lacunae also have canaliculi or canals. Unlike those in bone, however, these canals in cementum do not contain nerves, nor do they radiate outward. Instead, the canals are oriented toward the periodontal ligament and contain cementocytic processes that exist to diffuse nutrients from the ligament because it is vascularized.\n\nAfter the apposition of cementum in layers, the cementoblasts that do not become entrapped in cementum line up along the cemental surface along the length of the outer covering of the periodontal ligament. These cementoblasts can form subsequent layers of cementum if the tooth is injured.\n\nSharpey fibers are part of the principal collagenous fibers of the periodontal ligament embedded in the cementum and alveolar bone to attach the tooth to the alveolus.\n\nThe cementum joins the enamel to form the cementoenamel junction (CEJ), which is referred to as the \"cervical line\".\n\nThree possible types of transitional interfaces may be present at the CEJ. The traditional view was that certain interfaces dominated in certain oral cavities. The CEJ may exhibit all of these interfaces in an individual's oral cavity, and there is even considerable variation when one tooth is traced circumferentially.\n\nWhen the cementoid reaches the full thickness needed, the cementoid surrounding the cementocytes becomes mineralized, or matured, and is then considered cementum. Because of the apposition of cementum over the dentin, the dentinocemental junction (DCJ) is formed. This interface is not as defined, either clinically or histologically, as that of the dentinoenamel junction (DEJ), given that cementum and dentin are of common embryological background, unlike that of enamel and dentin.\n\nThe dentinocemental junction (DCJ) is a relatively smooth area in the permanent tooth, and attachment of cementum to the dentin is firm but not understood completely.\n\nTwo kinds of cementum are formed: acellular and cellular, and fibers can be intrinsic or extrinsic, resulting in four possible permutations; the first cementum to be formed during tooth development is acellular extrinsic fiber cementum. The acellular layer of cementum is living tissue that does not incorporate cells into its structure and usually predominates on the coronal half of the root; cellular cementum occurs more frequently on the apical half.\n\nCementum is slightly softer than dentin and consists of about 45% to 50% inorganic material (hydroxylapatite) by weight and 50% to 55% organic matter and water by weight. The organic portion is composed primarily of collagen and proteoglycans. Cementum is avascular, receiving its nutrition through its own imbedded cells from the surrounding vascular periodontal ligament.\n\nThe cementum is light yellow and slightly lighter in color than dentin. It has the highest fluoride content of all mineralized tissue. Cementum also is permeable to a variety of materials. It is formed continuously throughout life because a new layer of cementum is deposited to keep the attachment intact as the superficial layer of cementum ages. Cementum on the root ends surrounds the apical foramen and may extend slightly onto the inner wall of the pulp canal.\n\nCementum is secreted by cells called cementoblasts within the root of the tooth and is thickest at the root apex. These cementoblasts develop from undifferentiated mesenchymal cells in the connective tissue of the dental follicle or sac.\n\nUnlike ameloblasts and odontoblasts, which leave no cellular bodies in their secreted products, during the later steps within the stage of apposition, many of the cementoblasts become entrapped by the cementum they produce, becoming cementocytes. Thus again, cementum is more similar to alveolar bone, with its osteoblasts becoming entrapped osteocytes.\n\nCementum is capable of repairing itself to a limited degree, but not regenerate. and is not resorbed under normal conditions.\n\n\nA 2010 archeological study has found that cementum has five times the amount of mitochondrial DNA compared to dentin, which is commonly sampled. Teeth are increasingly utilized as a source of nuclear DNA to aid identification of human remains. DNA extraction and the results of genetic analysis from the tissue are extremely variable and to some extent unpredictable. However, the quantity of DNA available in dentin is affected by age and dental disease, whereas that in cementum is not.\n\n\n"}
{"id": "31754666", "url": "https://en.wikipedia.org/wiki?curid=31754666", "title": "Computer Aided Surgery (journal)", "text": "Computer Aided Surgery (journal)\n\nThe Computer Aided Surgery is a scientific journal covering all aspects of Computer-assisted surgery (CAS), a surgical concept and set of methods, that use computer technology for presurgical planning, and for guiding or performing surgical interventions.\n\nThe International Society for Computer Aided Surgery (ISCAS) is involved in the publication of the Journal.\n\n"}
{"id": "100204", "url": "https://en.wikipedia.org/wiki?curid=100204", "title": "Dhatri", "text": "Dhatri\n\nIn Hinduism, Dhatri (Sanskrit - \"earth\") mother earth, a name for Parvati in Lalita sahasranaama. It is also one of the names of the solar deity, one of the Adityas. He is also a god of health and domestic tranquility. He can be called (at least in spirit) in tantra or magic by drawing tantras and chanting Vedic hymns. Often invoked during major yagnas such as Ashwamedha yagna.\n"}
{"id": "307114", "url": "https://en.wikipedia.org/wiki?curid=307114", "title": "Dushantsi Reservoir", "text": "Dushantsi Reservoir\n\nThe Dushantsi reservoir (Bulgarian: Душанци язовир) is settled in the Balkan Mountains, Bulgaria.\n\nThe dam wall can be easily reached by car, driving along the old road to Burgas. The area around the reservoir is used for outgoings, picnics, water sports and fishing.\n\nThe Topolnitsa River feeds the reservoir, and is another suitable place for fishing.\n"}
{"id": "6396743", "url": "https://en.wikipedia.org/wiki?curid=6396743", "title": "Dysbiosis", "text": "Dysbiosis\n\nDysbiosis (also called dysbacteriosis) is a term for a microbial imbalance or maladaptation on or inside the body, such as an impaired microbiota. For example, a part of the human microbiota, such as the skin flora, gut flora, or vaginal flora, can become deranged, with normally dominating species underrepresented and normally outcompeted or contained species increasing to fill the void. Dysbiosis is most commonly reported as a condition in the gastrointestinal tract, particularly during small intestinal bacterial overgrowth (SIBO) or small intestinal fungal overgrowth (SIFO).\n\nTypical microbial colonies found on or in the body are normally benign or beneficial. These beneficial and appropriately sized microbial colonies carry out a series of helpful and necessary functions, such as aiding in digestion. They also help protect the body from the penetration of pathogenic microbes. These beneficial microbial colonies compete with each other for space and resources.\n\nDysbiosis may be caused by such diverse things as repeated and inappropriate antibiotic exposure, alcohol misuse, or inappropriate diet.\n\nWhen this balance is disturbed, these colonies exhibit a decreased ability to check each other's growth, which can then lead to overgrowth of one or more of the disturbed colonies which may further damage some of the other smaller beneficial ones in a vicious cycle. As more beneficial colonies are damaged, making the imbalance more pronounced, more overgrowth issues occur because the damaged colonies are less able to check the growth of the overgrowing ones. If this goes unchecked long enough, a pervasive and chronic imbalance between colonies will set in, which ultimately minimizes the beneficial nature of these colonies as a whole.\n\nMicrobial colonies also excrete many different types of waste byproducts. Using different waste removal mechanisms, under normal circumstances the body effectively manages these byproducts with little or no trouble. Unfortunately, oversized and inappropriately large colonies, due to their increased numbers, excrete increased amounts of these byproducts. As the amount of microbial byproducts increases, the higher waste byproducts levels can overburden the body's waste removal mechanisms.\n\nIt is the combination of these two negative outcomes that causes many of the negative health symptoms observed when dysbiosis is present.\n\nDisruptions in the microbiome can allow outside factors or even pathogenic members of the microbiome to take hold in the gut environment. Dysbiosis has been reported to be associated with illnesses, such as periodontal disease, inflammatory bowel disease, chronic fatigue syndrome, obesity, cancer, bacterial vaginosis, and colitis.\n\nSustained periods of dysbiosis lead to extended amounts of stress and inflammation in the gut microbiome, which can in turn promote the production of carcinogenic metabolites.\n\n\"C. difficile\" is an opportunistic bacteria that commonly infects patients following a disruption in the microbiome, such as treatment with antibiotics. Infection can lead to several different symptoms including watery diarrhea, fever, loss of appetite, nausea, and abdominal pain. Severe or chronic infections of \"C. difficile\" can lead to inflammation of the colon, a condition known as colitis.\n\nPeriodontitis is an oral infection that can damage the bones supporting teeth and lead to tooth loss. One of the major risk factors for periodontitis is the disruption of the oral microbiome such that there is an accumulation of pathogenic bacteria.\n\nBecause of the complex interactions in the microbiome, not much data exists on the efficacy of using antibiotics to treat dysbiosis. However, a broad-spectrum antibiotic that has low impact on the intestinal gut microbiome called rifixin, has been shown to be effective in improving several of the ailments associated with dysbiosis, including Irritable Bowel Syndrome, Ulcerative Coilitis and Crohn's Disease.\n\nFMTs use the same line of reasoning as probiotics; to recreate a healthy balance of microbiota in the microbiome by inserting beneficial microbes into the environment. FMT accomplishes this by taking a donation of fecal matter from a healthy individual, diluted, strained and introduced to a diseased patient. FMTs are currently used to treat patients with Clostridium Difficile infections, who have proved resistant to other therapies. Because the process is not sterile and contaminations can pass from donor to patient, there is a push to isolate key microbiota and culture them independently.\n\nThe World Health Organization defines probiotics as \"live microorganisms, which when administered in adequate amounts, confer a health benefit on the host.\" The benefit of using probiotics to treat dysbiosis related diseases lies in its ability to treat the underlying cause of said diseases. Some benefits include their ability to suppress inflammation in the microbiome and disrupt colonization by pathogens.\n\n\n"}
{"id": "15641117", "url": "https://en.wikipedia.org/wiki?curid=15641117", "title": "Ferguson reflex", "text": "Ferguson reflex\n\nThe Ferguson reflex (also called the foetal ejection reflex) is the neuroendocrine reflex comprising the self-sustaining cycle of uterine contractions initiated by pressure at the cervix or vaginal walls. It is an example of positive feedback in biology. The Ferguson reflex occurs in mammals.\n\nUpon application of pressure to the internal end of the cervix, oxytocin is released(therefore increase in contractile proteins), which stimulates uterine contractions, which in turn increases pressure on the cervix (thereby increasing oxytocin release, etc.), until the baby is delivered.\n\nSensory information regarding mechanical stretch of the cervix is carried in a sensory neuron, which synapses in the dorsal horn before ascending to the brain in the anterolateral columns (ipsilateral and contralateral routes). Via the median forebrain bundle, the efferent reaches the PVN and SON of the hypothalamus. The posterior pituitary releases oxytocin due to increased firing in the hypothalamo-hypophyseal tract. Oxytocin acts on the myometrium, on receptors which have been upregulated by a functional increase of the estrogen-progesterone ratio. This functional ratio change is mediated by a decrease in myometrial sensitivity to progesterone, due to an increase in progesterone receptor A, and a concurrent increase in myometrial sensitivity to estrogen, due to an increase in estrogen receptor α. This causes myometrial contraction and further positive feedback on the reflex.\n\nIt was originally studied among anesthetized rabbits. Studies among ewes demonstrated that it is blocked by epidural anesthesia. In their studies among mice, Niles Newton and colleagues demonstrated the importance of cortical influences. They enlarged to topic by introducing the term \"fetus ejection reflex\".\n\nThe concept of cortical influences provided reasons to raise questions about the process of parturition among humans, characterized by a high encephalization quotient. Odent had observed that, in situations that are exceptionally rare, women can occasionally experience such a reflex, characterized by a birth after a short series of irresistible and powerful contractions without any room for voluntary movements. For such a hormonal cascade to occur, requires sufficient psychological safety, as occurs in normal or undisturbed birth. The higher the intervention rate, such as induction or caesarian section, the lower the likelihood of the Ferguson Reflex occurring. In contrast, the lower the incidence of intervention, such as is found in those countries with high rate of home births,and birth centres worldwide, the higher the likelihood of the Ferguson Reflex occurring. This may explain the lack of research, considering the public health benefits of such education to both hospitals and the general public. \n"}
{"id": "42219881", "url": "https://en.wikipedia.org/wiki?curid=42219881", "title": "Funeral directors to the Royal Household", "text": "Funeral directors to the Royal Household\n\nThe Funeral directors to the Royal Household of the Sovereign of the United Kingdom are selected and appointed by the Lord Chamberlain's Office. \n\nUsually privately owned and commercially operated businesses, the funeral directors to the Royal Household do not have more than an occasional role, although they will be called upon if a death occurs in the Royal Family to assist in arranging the funeral arrangements. \n\nThe same companies are normally used to assist during state or ceremonial funerals of eminent people outside the Royal Family, for example Sir Winston Churchill or Margaret Thatcher.\n\nAlthough comparable in their role and function to Royal Warrant holders, the funeral directors serving the Royal Household do traditionally not advertise the fact that they work for the Royal Family.\n\nIt is not known when the Royal Household of the Sovereign of the United Kingdom began to employ privately owned and commercially operated funeral directors' companies. In the early 19th century, the royal undertakers were the family business of William Banting of St. James’s Street, London. The Banting family conducted the funerals of King George III in 1820, King George IV in 1830, the Duke of Gloucester in 1834, the Duke of Wellington in 1852, Prince Albert in 1861, Prince Leopold in 1884, Queen Victoria in 1901, and King Edward VII in 1910. The royal undertaking warrant for the Banting family ended in 1928 with the retirement of William Westport Banting. \n\nAfter the Banting family had ceased to operate as royal funeral directors in 1928, several society undertaking firms lobbied for the warrant. It was finally awarded to the socially and politically well-connected Sir Harold Vaughan Kenyon, who also served six terms as Mayor of Paddington. His company had been established in 1880 by his father, James Harold Kenyon (1841-91) and was incorporated under the name of \"J. H. Kenyon Ltd\" in 1899. It was this company which oversaw the funerals of King George VI in 1952, Queen Mary in 1953, and Sir Winston Churchill in 1965. The company's chief embalmer during this period was Desmond Henley. Another London firm, William Garstin not J H Kenyon, assisted with the funeral arrangements for King George V.\n\nIn 1991, the royal undertaking warrant passed to \"Leverton & Sons\", a 200-year-old family firm of funeral directors. Leverton & Sons was established in St Pancras in 1763 by Devonshire carpenter John Leverton. In 1888, the business moved to Eversholt Street in Camden, north London, where its headquarters remain. In 2007 company director Clive Leverton explained the mode of appointment to \"The Telegraph\". \"'There is no written contract,' he said. 'It is just a handshake really.'\" In 1997 Leverton & Sons repatriated the body of Diana, Princess of Wales. The company also organised the funerals of Queen Elizabeth The Queen Mother in 2002, Princess Margaret in 2002 and Baroness Thatcher in 2013.\n\n"}
{"id": "3829976", "url": "https://en.wikipedia.org/wiki?curid=3829976", "title": "Genstat", "text": "Genstat\n\nGenstat (General Statistics) is a statistical software package with data analysis capabilities, particularly in the field of agriculture.\n\nSince 1968, it has been developed by many scientific experts in Rothamsted Research, and has a user-friendly interface, professional modular design, excellent linear mixed models and graphic functions. Leading Genstat’s continued development and distribution is VSN International (VSNi), which is owned by The Numerical Algorithms Group and Rothamsted Research.\n\nGenstat is used in a number of research areas, including plant science, forestry, animal science, and medicine, and is recognized by several world-class universities and enterprises.\n\nGenstat’s statistical software can be applied to the following user areas:\n\n\n\n"}
{"id": "45032293", "url": "https://en.wikipedia.org/wiki?curid=45032293", "title": "Health Care Complaints Commission", "text": "Health Care Complaints Commission\n\nThe New South Wales Health Care Complaints Commission (commonly referred to as the HCCC), is an independent statutory body created by the Parliament of New South Wales, Australia to receive, assess, resolve or prosecute complaints relating to health service providers in New South Wales.\n\nThe Health Care Complaints Commission's purpose is stated in the \"Health Care Complaints Act 1993 \"(NSW) which establishes it as \"protection of the health and safety of the public must be the paramount consideration\".\n\nThe Commission receives consistent media attention for its actions. Recent attention includes criticism of its performance with a major Sydney newspaper, the \"Sydney Morning Herald, \"reporting that new \"statistics expos[ed] a dramatic decline in investigations despite complaints from the public being at an all-time high.\"\n\nThe Health Care Complaints Commission was formed in 1994 after the Chelmsford Royal Commission which investigated the 'deep sleep therapy' performed at the Chelmsford Hospital in Sydney.\n\n"}
{"id": "13952556", "url": "https://en.wikipedia.org/wiki?curid=13952556", "title": "Health record trust", "text": "Health record trust\n\nA health record trust (also independent health record trust or health record data bank) provides a secure and protected place for individuals to create, use, and maintain their lifetime electronic health record (EHR). The health record trust takes personal health records one step further by combining an individual's electronic health record with the personal health record. A health record trust protects patient privacy by establishing that the patient is the owner of his or her health care records. It gives patients authority to access and review the entire record at any time as well as the authority to allow health care professionals, facilities, and organizations to view all of the records or a limited portion of the records. Currently a record is left at each facility a patient seeks care. The health record trust allows for all of the information to be in one central document. Patients cannot alter their health records but instead add notes and request corrections. They can also view every provider who downloads their EHR.\n\nLegislation was introduced in the 110th Congress to establish a regulatory framework for the establishment of health record trusts. The Independent Health Record Trust Act of 2007 (H.R. 2991) was introduced by Rep. Dennis Moore (D-KS) and Rep. Paul Ryan (R-WI) on July 11, 2007. The legislation seeks to give people control over their lifetime health records, with the broader goal of reducing health care costs that result from inefficiency, medical errors, inappropriate care, and incomplete information. This legislation provides standards for the use of health record trusts, including certifications and interoperability of independent health record trusts. HR 2991 was referred to the House Committee on Energy and Commerce and the House Committee on Ways and Means. The bill died in committee and has not been reintroduced. With the availability of a longitudinal health record protected by a health record trust, patients receive better quality of care and are able to pass along their medical records to future generations. Health record trusts promote wellness and improve patient care through quick and easy access to critical health information.\n\nArizona's eHealthTrust health record bank launched in 2010 with a freemium pricing strategy. In 2012, Harvard University's Data Privacy Lab launched MyDataCan, offering free data storage and distribution with optional integration for third-party app, both free and paid.\n\n"}
{"id": "43145021", "url": "https://en.wikipedia.org/wiki?curid=43145021", "title": "Healthcare in Sierra Leone", "text": "Healthcare in Sierra Leone\n\nHealthcare in Sierra is generally charged for. and is provided by a mixture of government, private and non-governmental organizations (NGOs). There are over 100 NGOs operating in the health care sector in Sierra Leone. The Ministry of Health and Sanitation is responsible for organizing health care and after the end of the civil war the ministry changed to a decentralized structure of health provision to try to increase its coverage.\n\nSierra Leone is divided into 13 health districts that correspond to the districts of Sierra Leone except for the Western Area Rural and Western Area Urban districts which are combined into the Western Area Health district. Each district has a health management team and an average of 50 peripheral health units (PHU) and over 100 technical staff. The management team is responsible for planning, organizing and monitoring health provision, training personnel, working with communities and supplying equipment and drugs.\n\nThe PHUs are designed to be the delivery point for primary health care in the country and there are three main types.\n\n\nIn April 2010 Sierra Leone launched \"Free Health Care Medical Insurance\", a system of free healthcare for pregnant and breast-feeding women and children under five. A UN population Fund representative said that medical equipment had been ordered and some drugs distributed as part of the new healthcare scheme but the coverage was not yet 100%. The initial set up cost of the scheme was $19 million and it is expected to save the lives of more than a million mothers and children.\n\nHealthcare workers had gone on strike over the plans in March 2010 arguing that free healthcare would increase their workload and working hours, the government settled the dispute with pay rises of 200-500%. Observers argue that many of the women concerned do not even know they have a right for free medical care and that the law would remain a paper tiger if more earnings from the extractive sector was not invested in the countries healthcare system.\n\nThe scheme is funded mainly by the United Kingdom and United Nations who have paid to refurbish hospitals, supply drugs and pay healthcare professionals' wages. The UK alone has agreed to pay for a years worth of drugs for the program and the World Health Organization has provided blood banks in each major town. The British government's funding came from the Department for International Development (DFID) and amounted to $22.6 million to fund the scheme for the next three years from a total allocation of $70.5 million for the 10-year-long \"Reproduction and Child Health Care\" plan. UNICEF also received $7 million from DFID to provide medicines for pregnant women.\n\n\nTraditional medicine forms part of the primary health care system in Sierra Leone. The traditional medicine programme, run by the Ministry of Health and Sanitation, has constructed a training school at Makeni, a healing centre at Kono and conducted workshops to promote co-operation between traditional medicine practitioners and orthodox medical workers. Members of the programme have also located and collected plants from throughout Sierra Leone used for medicine.\n\nHealth in Sierra Leone\n"}
{"id": "31359711", "url": "https://en.wikipedia.org/wiki?curid=31359711", "title": "Indian Genetic Disease Database", "text": "Indian Genetic Disease Database\n\nIndian Genetic Disease Database (IGDD) is the first patient based \"genetic disease\" database of India. It is being developed and maintained at Indian Institute of Chemical Biology (IICB) a unit of the Council of Scientific and Industrial Research.\n\nThe first version of the database has been published online. It has been divided into 19 disease categories in the 1st version of the database. It includes: Blood Related Disorders, Bone and Joints Related Growth Disorders, Eye Disorders, Gastro-Intestinal Disorders, Hearing Disorders, Lysosomal Disorders, Multi-system Disorders, Muscle Related Disorders, Neurological Disorders, Pigmentary Disorders, and Skin Related Disorders.\n\nIndia is a country with many communities where there is high load of genetic disorders. It is due to consanguineous marriage or marriages between close relatives practiced in the community. This database keeps track of mutations in the causal genes for that genetic diseases common in India. The database will be helpful to the Physicians, Geneticists and other professionals in India and abroad related to genetic disorders to retrieve and use the information for the benefit of mankind.\n\nThe database had been launched and updated in August 2010. From this database, one can obtain patient-based data with respect to the patient's Geographical location, Age, Sex, and Ethnic Group. One can also compare the occurrence of that disease with other parts of the world through this database. The mode of inheritance of a particular disease is also known from this database. One can also get an overall picture of a particular disease occurrence in India and all its details from this database.\n\nEach disease is represented with Gene name, Chromosome location, Mutations, Geospatial distribution for the disease.\n\nIn the 1st version of the database, there had been 52 diseases with information on 5,760 individuals in the database. Now there are information about 109 genetic diseases.\n\nThe Publication has been selected as featured Article in Nucleic Acid research peer reviewed international journal( NAR ) in 2011.\n\nPatient specific mutation information can be updated by simply filling up a form from this link.\n\n"}
{"id": "25714496", "url": "https://en.wikipedia.org/wiki?curid=25714496", "title": "Institutional abuse", "text": "Institutional abuse\n\nInstitutional abuse is the maltreatment of a person (often children or older adults) from a system of power. This can range from acts similar to home-based child abuse, such as neglect, physical and sexual abuse, and hunger, to the effects of assistance programs working below acceptable service standards, or relying on harsh or unfair ways to modify behavior. Institutional abuse occurs within emergency care facilities such as foster homes, group homes, kinship care homes, and pre-adoptive homes. Children, who are placed in this type of out of home care, are typically in the custody of the state. The maltreatment is usually caused by an employee of the facility. Out of home placement care is meant to be temporary; however, it can be permanent (Colorado Department of Human Services). Many solutions are underway in preventing and protecting institutionally abused children (Denvergov.org).\n\nInstitutional abuse can typically occur in a care home, nursing home, acute hospital or in-patient setting and can be any of the following:\nTypical of the institutionalized bigotry that coincides with abuse, it is said that it can be considered to mainly apply to four categories of people:\nThis perspective often written into educational material seeks to excuse perpetrators with the \"explanation\" that the abused adults are all somehow mentally inept. This encourages the trend.\n\nInstitutional abuse can be divided into three categories: \n\nThese issues range from personal abuses to situational maltreatment, and differ greatly in their causes. Most institutional abuses are the result of difficult and stressful working environments, where those with the least training often have the most contact with the participants, and have the hardest schedules, least payment, and most undesirable working conditions. The high-stress working environments of care workers combined with low-quality hiring and screening practices of workers can create abusive situations through lack of experience or knowledge on the worker's part. Lack of proper training for workers can conflict or hurt institutional goals for patients through improper implementation of treatments, compounded by organizational structure that only has doctors and psychologists on site for short hours. In overstressed situations, power over the patients can bring feelings of control and significance, leading to stress being a predictor of abuse in institutional and familial settings. isolation from the community can have similar effects.\n\nOften complicating worker issues is lack of organizational goals or policy. In childcare situations, lack of curricular recreation for children can lead to more acting out behavior, causing more stress for workers, and more inclination toward mistreatment. Patients can often be difficult to manage through inability or behavioral issues, and those who are more difficult for staff to work with are often the victims of abusive situations. It is proposed that most abuse rises of out frustration and lack of ability to properly control the patient, not intentional maltreatment.\n\nThere is a lack of state legislation defining or prosecuting institutional abuse, leading to difficulty in investigation or dealing with abusive situations.\n\nInstitutional abuse is also present in situations outside those of child and elder care. The Nuremberg Code was developed during the Nuremberg Trials to create a universal ethical code for the treatment of humans from an institutional standpoint. Though this Code is not formally adopted by any organization, its standard for human rights has been used as a guide for more specific ethical codes. However, history has still shown the abuse of the vulnerable members of society through medical and psychiatric institutions. Under the Nazi regime of the early 1940s, this abuse took the form of sterilization of those purported to be \"mentally ill\", and general medical experimentation without consent or will to leave, and eugenics. The political nature of these policies lead to them being enforced by law under an ideology of purifying race of genetic deficiencies. Eugenics and sterilization campaigns have also been run outside of political dictatorship, including a number of states in the United States, Denmark, Finland, and Sweden. But it is the shift from sterilization to euthanasia of the mentally ill or other politically undesirable groups in Nazi Germany that lead to the actions of the Holocaust. Japanese soldiers of the time also would use these groups as research subjects for infectious diseases and poisons, while Stalin's regime in Russia used the guise of mental illness to torture and punish political dissidents.\n\nThe Army and CIA of the United States also have histories of testing psychiatric drugs on unwilling patients or soldiers. LSD was tested by using prostitutes to trick men into taking the drug, and various combinations of depressants, hallucinogens, and stimulants would be given to unconsenting soldiers for observation of the effects. In response to many of these unethical experiments, specific ethical codes were developed to protect the rights of the participant, and require informed consent.\n\nAbuse in childcare institutions falls most commonly into the categories of overt abuse, program abuse, and system abuse, which arise from the staff, program, or childcare system. As children are still in development as institutional abuse occurs, the definition of institutional abuse for children is often widened to include harming a child's development, altering a child's identity, or devaluing them as a person. Child maltreatment is also often defined as foreseeable or probable harm or injury to a child's physical, social, emotional, or developmental well-being. Researchers found incidents ranging from 39 to 85 abuse cases per 100 children living in full-time housing, with only 85 in 1000 cases being reported to authorities. Children in mental disorder clinics were more likely to report abuse than those in mental disability clinics.\n\nA number of researchers have tried to model the factors that cause abuse and maltreatment in childcare facilities. The acting factors in this model are the caregivers, children, the caregiving environment, and any other exogenic factors. Risk factors towards abuse are associated with each of these, such as the stress of the working environment can be to caregivers. These factors have all be organized into a model of concentric circles, with maltreatment at the center, and each circle further out influencing those within. There are ordered from inside out: maltreatment, child factors, caretaker factors, organization and environment factors, and exogenous factors.\n\nA number of high-risk factors for the institutional abuse of children include lack of caretaker competence or training and adherence to only one treatment methodology, lack of supervision of caretakers, and lots of time for unstructured activities. The probability of a caretaker to be abusive is positively correlated with their job stress, age, lack of job satisfaction and facility status.\n\nChildren who are more likely to be abused often display characteristics of being difficult for workers to deal with and needing more one-on-one supervision, isolation from their family, and previous victims of abuse. Male children are more likely to be abused, and are more often abused physically and neglectfully, while females are more likely to be sexually abused.\n\nIncidents of abuse are most often reported at the beginning and end of the school year, and there are conflicting reports as to unemployment rates' influence on abuse.\n\nThere is not a definitive definition of institutional abuse of older adults, with psychologists differing with legal definitions, and differing depending on the measures used. Definitions often include institutionally caused physical, psychological, financial, or sexual abuse or neglect.\nAmong the abuse that happens among elders, most is concentrated on those who are more frail and need more assistance. In a review of Canadian assistance homes, over 70% of workers reported acting in an abusive way towards patients, frequently in the form of psychological abuse or neglect. In a study of American assistance homes, there was a rate of 20% for employees stealing from residents, with employees acknowledging that it was the residents that were more difficult or abusive that were more likely to be robbed. Further, in Sweden, assistance home employees reported witnessing abuse at 11%, while participating in elder abuse at 2% rates. This abuse was most commonly physical abuse, followed by psychological abuse and neglect. Rates of abuse differ across surveys, countries, and homes, but certain facts are consistent across studies. Victims of abuse are also susceptible to threefold greater mortality rates than their peers.\n\nSeveral frameworks have been developed to model the risk factors for institutional elder abuse. In one model, risk factors are divided into three categories:validated factors, possible factors, and contested factors. Factors that have been shown to be risks for abuse include lack of consistent organizational policies, low-quality enforcement of standards, lack of trained staff, vulnerability due to dementia. Possible factors include gender, personality of the victim, and race.\n\nSexual abuse is one of the lower occurring and under-reported forms of institutional abuse. Women are disproportionately represented among victims, and most often abused by other residents of the home. The majority of victims also suffered from a form of dementia or cognitive impairment. However, institution-based sexual abuse crossed all gender, race, and cultural barriers.\n\nRisk factors of institutional abuse of older adults has been found to be related to the size of the housing, with larger organizations more susceptible to abuse. Staff factors such as unionization, short staffing, and work stress are also predictors of abuse. Patients with severe dementia are also more susceptible to maltreatment such as being constrained.\n\nResearchers do not have a definitive answer for the cause of elder abuse. Workers in assistance homes have suggested that program factors such as understaffing, focus on making money over human welfare, and agism contributing to institutional abuse, aggravated by patients who may be difficult or struggling with mental health issues. Most studies have focused on the interaction of stressed workers with difficult patients.\n\n\nYouth Facilities\n\nCare Homes\n\nHospitals\n\nOther\n\n\n"}
{"id": "2523077", "url": "https://en.wikipedia.org/wiki?curid=2523077", "title": "International AIDS Vaccine Initiative", "text": "International AIDS Vaccine Initiative\n\nThe International AIDS Vaccine Initiative (known as IAVI) is a global not-for-profit, public-private partnership working to accelerate the development of vaccines to prevent HIV infection and AIDS. IAVI researches and develops vaccine candidates, conducts policy analyses, serves as an advocate for the HIV prevention field and engages communities in the trial process and AIDS vaccine education. The organization takes a comprehensive approach to HIV and AIDS that supports existing HIV prevention and treatment programs while emphasizing the need for new AIDS prevention tools. It also works to ensure that future vaccines will be accessible to all who need them.\n\nIn 1994, the Rockefeller Foundation convened an international meeting of AIDS researchers, vaccinologists, public health officials, and representatives from philanthropic organizations in Bellagio, Italy, to evaluate the challenges facing HIV/AIDS vaccine development and identify ways to jump-start research.\n\nIAVI’s scientific team, drawn largely from private industry, researches and develops AIDS vaccine candidates and engages in clinical trials and research through partnerships with more than 50 academic, biotechnology, pharmaceutical and governmental institutions.\n\nIn September 2009, a global group of researchers led by IAVI published a study in the journal \"Science\" identifying PG9 and PG16, two highly powerful broadly neutralizing antibodies against a wide variety of HIV variants. The site on the virus to which PG9 and PG16 attach revealed a vulnerability on HIV. PG9 and PG16 were the first new broadly neutralizing antibodies against HIV discovered in more than a decade and are the result of a global effort launched in 2006.\n\nTo address major obstacles in AIDS vaccine development, IAVI partners with HIV researchers from around the world. Its Neutralizing Antibody Consortium is a network dedicated to discovering and understanding broadly neutralizing antibodies against HIV and using that knowledge in the design of vaccines.\n\nIAVI is a founding member of the Global HIV Vaccine Enterprise, an alliance of independent organizations working towards an AIDS vaccine. It also partners with civil society organizations and other entities to advocate jointly for the development of AIDS vaccines, and is a member of the Global Health Technologies Coalition, an alliance of more than 30 non-profit groups that aims to increase awareness of the urgent need for technologies that save lives in developing countries.\n\n\n"}
{"id": "55194158", "url": "https://en.wikipedia.org/wiki?curid=55194158", "title": "John Edward Church", "text": "John Edward Church\n\nJohn Edward Church (10 August 1899 - 29 September 1989), commonly referred to as Joe Church was a British missionary who served with Church Mission Society (CMS). Dr. Joe Church served primarily in Rwanda and Uganda. He left England in 1927 and served as a missionary for 44 years, alternating between medical and evangelistic missions. He is widely known for playing a key role in the East African Revival. Additionally he served as a doctor in Rwanda for over a decade and constructed hospitals and a church. He has been recognized for his work by governments in East Africa and Europe.\n\nJohn Edward Church was born to Edward Joseph Church and Florence Edith Church in 1899. He grew up in a Cambridgeshire village named Burrough Green where his father served as a clergyman. He was the oldest of ten children and enjoyed a happy childhood in his small village where he often hunted and played cricket.\n\nAt age 11, John Edward Church began attending the junior school at St Lawrence College, Ramsgate and later moved on to its senior school. He was able to attend this school at no cost because he was the son of a clergy. He did well academically and was well known for his shooting and hockey skills. In his senior year, he was enrolled into the officer cadet training camp of the Tank Corp as a result of World War I. At 19 years old, he was ranked as Second Lieutenant and served with the Twentieth Battalion at Bovington in Dorset. The war ended soon after this and through the British Army, he obtained a grant to attend Emmanuel College at the University of Cambridge to study medicine. At Emmanuel College, John Edwards was heavily involved with Cambridge Inter-Collegiate Christian Union (CICCU) where he began a Bible class and was the club’s college representative. His interest in mission work stemmed from this club. Joe Church did his medical training at St Bartholomew’s Hospital in London. In preparation for practicing medicine abroad, Joe Church pursued further training as a house surgeon and casualty officer at Addenbrooke’s Hospital, Cambridge. He received his Doctor of Medicine (MD) in 1926.\n\nJohn Church married Decima Tracey, who was also a trained doctor, on May 19, 1930 in Uganda. The couple had five children: John, David, Robin, Michael, and Janine, all birthed in Rwanda or Uganda. Dr. Decima Tracey Church was an important part of Dr. Joe’s mission work and she often assisted with his medical work.\n\nOn October 28, 1927, Dr. Joe Church set sail for his mission in Rwanda. He first arrived in Kabale, Uganda where he received missions training from Church Mission Society (CMS) for five months. Once his training was completed, Dr Joe Church was sent to Gahini, Rwanda, a village in northeastern Rwanda. He immediately began planning to build a new hospital building since there was an overwhelming demand for medical care. Gahini, Rwanda was experiencing a famine when Dr. Joe first began his work so he dealt with many cases of skin sores and diarrhea. Dr. Joe Church wrote many appeals to the Belgian and British government for food supplies to Rwanda and Uganda, his pleas were heard and he was recognized by the local Gahini government for helping with the famine crisis. Once Gahini Hospital was built, Dr. Joe worked there for eight years. He established a dispensary and often did life-saving surgeries and amputations. Dr. Joe was later given permission by the Rwandan government to establish more hospitals and dispensaries which he did in alliance with CMS. After eight years, Dr. Joe felt called to full time ministerial missions in Rwanda and Uganda and his younger brother, Dr. Bill Church, took over for him at Gahini Hospital.\n\nDr. Joe Church and his family moved to Kabale, Uganda where he would focus on his evangelical missions for eight years. In his first year of full time evangelical missions, Dr. Joe wrote a book of Bible studies titled \"Every Man a Bible Student\" with over 40 studies. Dr. Joe used this book as a tool to train young men interested in ministry around Uganda and Rwanda. Aside from training future ministry workers, Dr. Joe also led many mission trips and held many conferences for the Anglican Church in Rwanda and Uganda. He organized and attended multiple revivals in other locations such as Tanzania, Angola, South Africa, India, and multiple South American countries. He was a pioneer in establishing the Anglican Church in Rwanda and Uganda. In 1943, Dr. Joe Church was called back to medical missions because there was need for a doctor at Gahini Hospital. For about two years, he worked one out of every three months at Gahini Hospital. In 1947, Dr. Joe Church and his family officially moved back to Gahini, Rwanda where he served as a doctor and helped pastor the 300 village churches. He continued leading the revival in Rwanda and rebuilt the Gahini hospital during his time there.\n\nDr. Joe Church was affiliated with Church Mission Society (CMS) for the entirety of his mission work and they described him as a, “pioneer of missionary of the Rwanda Mission.” During his time in East Africa, Dr. Church established Gahini Hospital, Kabarole Hospital, and constructed Toro Hospital with his son Robin Church. In Uganda, he and other missionaries established Kabale Preparatory School as a school for missionary children in Rwanda. Dr. Joe was appointed as the Rwandan King’s physician and later on his son, John Church, was also the King’s physician. Dr. Joe and Dr. Decie were recognized for their work by King Baudouin of the Belgians and were awarded the ‘medaille d’ or de l’ordre royal du Lion’. Dr. Joe Church published his autobiography, \"Quest for the Highest - an autobiographical account of the East African revival\" in 1981. Dr. Joe Church officially retired in 1972 in Little Shelford, England. Dr. Joe Church passed away, aged ninety, on September 29, 1989 in a Royston nursing home.\n"}
{"id": "47250940", "url": "https://en.wikipedia.org/wiki?curid=47250940", "title": "John of Alexandria", "text": "John of Alexandria\n\nJohn of Alexandria () was a Byzantine medical writer who lived in Alexandria, in present-day Egypt.\n\nHe is thought to be the author of a commentary on Galen's \"De sectis\", a Latin version of which survives in several manuscripts. He wrote a commentary on Hippocrates' book about the foetus (\"In Hippocratis De natura pueri commentarium\"), which survives in one Greek manuscript and in a 13th-century Latin version made for King Manfred of Sicily. He also wrote a commentary on the sixth book of Hippocrates' \"Epidemics\" (\"In Hippocratis Epidemiarum librum VI commentarii fragmenta\"), known from an anonymous Latin translation and from extracts from the Greek original, entered in the margins of a Greek translation of an Arabic medical text.\n"}
{"id": "11036044", "url": "https://en.wikipedia.org/wiki?curid=11036044", "title": "Kutaisi Institute of Medicine", "text": "Kutaisi Institute of Medicine\n\nKutaisi Institute of Medicine is a medical school, located in Kutaisi, Georgia. It was founded in 1992.\n\nIn 1992 the initiative group consisting of Ioseb Kachakhidze, Giorgi Arveladze, Nugzar Maglakelidze and Malkhaz Dvalishvili, by the consent of the Ministry of Health Care and on the basis of the license issued by the Ministry of Education (#01-17-08/1197.12.08.92), founded Kutaisi Institute of Medicine - “Kutaisi”.\n\nKutaisi has three specialties: Medicine, Dentistry and Pharmacy. The duration of education at the Medical Specialty is 6 years; and there are 5 years at the Dental and Pharmaceutical specialties. Study process is divided in Basic and clinical parts. Basic sciences are taught during the first three years that includes laboratory and scientific studies needed for clinical subject learning. Clinical subjects are taught at the hospitals during the last three years. Medical instruction is given in Georgian.\n\nThe institution has implemented The European Credit Transfer and Accumulation System(ECTS) since 2005–2006 years.\n\nThe library fund consists of 15,000 textbooks, including about 5000 samples of contemporary foreign editions, video and audio resources. Georgian and foreign periodicals are received systematically.\n\nIn Georgia, all students in higher educational institutions are admitted via United National Examinations.\n\n"}
{"id": "39587099", "url": "https://en.wikipedia.org/wiki?curid=39587099", "title": "List of aircraft accidents and incidents resulting in at least 50 fatalities", "text": "List of aircraft accidents and incidents resulting in at least 50 fatalities\n\nThis article lists aircraft accidents and incidents which resulted in at least 50 fatalities in a single occurrence involving commercial passenger and cargo flights, military passenger and cargo flights, or general aviation flights that have been involved in a ground or mid-air collision with either a commercial or military passenger or cargo flight.\n\nThere have been 548 such incidents, including terrorist or other attacks. Of these, 202 have involved at least 100 fatalities, 34 have had at least 200 fatalities, 8 have had at least 300 fatalities, and 4 have had at least 500 fatalities. Between 1923 (the first year an aircraft accident or incident exceeded 50 fatalities) and the present, these incidents have accounted for precisely 57,654 fatalities across all seven continents and the three largest oceans.\n\nFive years after the pioneering flight of the Wright brothers on 17 December 1903, Thomas Selfridge became the first fatality of powered flight while flying as a passenger with Orville Wright during a demonstration of the Wright Model A at Fort Myer, Virginia, on 17 September 1908. Eugène Lefebvre was the first pilot killed in a powered airplane in 1909, while the first fatal mid-air collision occurred on 19 June 1912, near Douai, France, killing the pilot of each aircraft. Since the deaths of these early aviation pioneers, the scale of fatal aircraft accidents has increased in proportion to the size and capacity of airplanes.\n\nThe first aviation incident to result in more than 50 fatalities did not involve an airplane. On 21 December 1923, the \"Dixmude\", a rigid airship of the French Navy, was reportedly struck by lightning and crashed into the Mediterranean Sea, off Sicily, Italy. All 52 crew and passengers were killed. Nearly 10 years later, the , also a rigid airship, encountered severe weather and crashed into the Atlantic Ocean, off Barnegat Light, New Jersey, killing 73 of those on board. It was another 5 years before a fixed-wing aircraft incident claimed more than 50 fatalities. On 24 July 1938, A Curtiss Hawk II crashed into spectator stands in the Santa Ana air show disaster. 52 spectators were killed on the ground in addition to the pilot of the airplane. One month later on 24 August 1938, the Japan mid-air collision in Tokyo claimed 53 lives on the ground in addition to the 5 crew members aboard both planes. The first rotorcraft incident to result in more than 50 fatalities was the 1977 crash of a Sikorsky CH-53 Sea Stallion in Israel, which killed 54 people.\n\nThe greatest number of fatalities involving one aircraft occurred in 1985 when 520 people died in the crash of Japan Airlines Flight 123. The most fatalities in any aviation accident in history occurred during 1977 in the Tenerife airport disaster when 583 people were killed when two Boeing 747s collided on a runway. The greatest number of fatalities from a midair collision occurred at the Charkhi Dadri mid-air collision, to the west of New Delhi, India on 12 November 1996 when a Saudi Arabian Airlines Boeing 747-100B en route from Delhi to Dhahran, Saudi Arabia, collided with Kazakhstan Airlines Ilyushin Il-76 en route from Chimkent, Kazakhstan to Delhi, killing all 349 people aboard both the airplanes. The 11 September 2001 (9/11) coordinated attack of the World Trade Center claimed not only 157 passengers and crew, but an estimated additional 2,500 victims. In 2012, Boeing released a study of worldwide commercial jet airplane accidents between 1959 and 2011 reporting 1,798 accidents, 603 categorized as fatal, which accounted for 29,025 on-board fatalities and an additional 1,173 ground or non-commercial aircraft collision deaths. The Boeing analysis suggests a decrease of commercial aviation accident fatality rates toward the end of the study period.\n\nCriteria for inclusion require at least 50 fatalities in a single occurrence involving commercial passenger and cargo flights, military passenger and cargo flights, or general aviation flights that have been involved in a ground or mid-air collision with either a commercial or military passenger or cargo flight.\n\nThe US Code of Federal Regulations defines an accident as \"an occurrence associated with the operation of an aircraft which takes place between the time any person boards the aircraft with the intention of flight and all such persons have disembarked, and in which any person suffers death or serious injury, or in which the aircraft receives substantial damage;\" an incident as \"an occurrence other than an accident, associated with the operation of an aircraft, which affects or could affect the safety of operations;\" and a fatal injury as one which results in death within 30 days of the accident. The definitions of accident, incident, and fatality in the Code of Federal Regulations, and used by the FAA and NTSB are generally consistent with those found in the ICAO Chicago Convention on International Civil Aviation Annex 13.\n\n\nOccurrences have been coded to allow for identification and sorting by group membership (accidents and related incidents versus attacks).\n\nAny collision between a commercial and military aircraft is coded COM.\n\nTo provide some indication of distance between the site and the nearest location, the following three descriptors are applied:\nThe names of occurrence locations are based on their present-day names.\n\nThe phases of flight are those defined by the joint Commercial Aviation Safety\nTeam/ICAO Common Taxonomy Team.\n\nAirports associated with occurrences at all phases of flight (except ENR) are represented by their three-letter IATA airport code. In some cases, no IATA code is reported/assigned in which case the four-letter ICAO code is used. In rare instances (e.g., active or decommissioned military bases or closed airports whose civil codes have been reassigned), no codes exist. These airports are represented with three asterisks \"***\" in place of letters. Distance from the point of impact to the airport runway is provided for occurrences during the initial climb (ICL) and approach (APR) phases. On occasion, distance is provided for occurrences during takeoff (TOF) and landing (LDG) if the aircraft impacted within the aerodrome, but not on the runway.\n\nSince 1923, spanning all seven continents and the three largest oceans, there have been 548 high fatality aircraft accidents, incidents, and attacks (as defined above) involving 580 aircraft resulting in 57,654 fatalities. By type, accidents/incidents (COM/MIL) account for 507 occurrences, 536 aircraft, and 50,365 fatalities. Attacks (INB/INH/EXG/EXS) account for 41 incidents, 44 aircraft, and 7,289 fatalities.\nA brief review of the descriptive statistics of fixed-wing, rotary-wing, and lighter-than-air aircraft accidents and incidents between 1923 and 2018 suggests the following:\n\n\nAll accident and incident references to the Aviation Safety Network database are sub-pages of their main website, http://aviation-safety.net.\n\n"}
{"id": "1103692", "url": "https://en.wikipedia.org/wiki?curid=1103692", "title": "List of childhood diseases and disorders", "text": "List of childhood diseases and disorders\n\nThe term childhood disease refers to disease that is contracted or becomes symptomatic before the age of 18 years old. Many of these diseases can also be contracted by adults.\n\nSome childhood diseases include:\n\n\n"}
{"id": "32419003", "url": "https://en.wikipedia.org/wiki?curid=32419003", "title": "List of dams and reservoirs in Afghanistan", "text": "List of dams and reservoirs in Afghanistan\n\nDams and reservoirs in Afghanistan are used for irrigation, water supply, hydro-electric power generation or combination of these. The list of dams and reservoirs in Afghanistan are listed below.\n\n\n\n"}
{"id": "713644", "url": "https://en.wikipedia.org/wiki?curid=713644", "title": "List of hospitals in New Zealand", "text": "List of hospitals in New Zealand\n\nThis is a list of hospitals in New Zealand.\n\n\n\n\n\n\n\n\n"}
{"id": "9407155", "url": "https://en.wikipedia.org/wiki?curid=9407155", "title": "Minimisation (clinical trials)", "text": "Minimisation (clinical trials)\n\nMinimisation is a method of adaptive stratified sampling that is used in clinical trials, as described by Pocock and Simon.\n\nThe aim of minimisation is to minimise the imbalance between the number of patients in each treatment group over a number of factors. Normally patients would be allocated to a treatment group randomly and while this maintains a good overall balance, it can lead to imbalances within sub-groups. For example, if a majority of the patients who were receiving the active drug happened to be male, or smokers, the statistical usefulness of the study would be reduced.\n\nThe traditional method to avoid this problem, known as blocked randomisation, is to stratify patients according to a number of factors (e.g. male and female, or smokers and non-smokers) and to use a separate randomisation list for each group. Each randomisation list would be created such that after every block of x patients, there would be an equal number in each treatment group. The problem with this method is that the number of lists increases exponentially with the number of stratification factors.\n\nMinimisation addresses this problem by calculating the imbalance within each factor should the patient be allocated to a particular treatment group. The various imbalances are added together to give the overall imbalance in the study. The treatment group that would minimise the imbalance can be chosen directly, or a random element may be added (perhaps allocating a higher chance to the groups that will minimise the imbalance, or perhaps only allocating a chance to groups that will minimise the imbalance).\n\nThe imbalances can be weighted if necessary to give some factors more importance than others. Similarly a ratio can be applied to the number of patients in each treatment group.\n\nIn use, minimisation often maintains a better balance than traditional blocked randomisation, and its advantage rapidly increases with the number of stratification factors.\n"}
{"id": "10457228", "url": "https://en.wikipedia.org/wiki?curid=10457228", "title": "Mirror syndrome", "text": "Mirror syndrome\n\nMirror syndrome or triple edema or Ballantyne syndrome is a rare disorder affecting pregnant women. It describes the unusual association of fetal\nand placental hydrops with maternal preeclampsia.\n\nThe name \"mirror syndrome\" refers to the similarity between maternal edema and fetal hydrops. It was first described in 1892 by John William Ballantyne.\n\nThe etiology may be any of the variety of obstetric problems that range from immunological disorders, including Rh-isoimmunization, to fetal infections, metabolic disorders, and fetal malformations. Ballantyne syndrome can result from the maternal reaction to a fetus that has hemoglobin Barts disease due to inherited double alpha thalassemia trait (alpha thalassemia major) from both parents.\n\nThe etiopathogenetic mechanism of Ballantyne syndrome remains unknown.\n\nBallantyne syndrome has several characteristics: \n\nThe fetal symptoms are related to fluid retention, including ascites and polyhydramnios.\nFetal hydrops suggests the presence of an important and probably fatal fetal pathology.\n\nIt can be associated with twin-to-twin transfusion syndrome.\n\nAlthough the exact etiopathogenetic mechanism of Ballantyne syndrome remains unknown, several authors have reported raised uric acid levels, anemia, and low hematocrit without hemolysis.\n\nThe problem of distinguishing (or not) between Ballantyne syndrome and preeclampsia is reflected in the diversity of terminology used and in the debate that surrounds the subject. It seems much more likely that an etiology of severe fetal hydrops may cause Ballantyne syndrome when the fetal status greatly worsens and that the syndrome is only a manifestation of the extreme severity of the fetus-placental pathology. Platelet count, aspartate transaminase, alanine transaminase, and haptoglobin are usually unaffected and may be used to distinguish mirror syndrome from HELLP syndrome.\n\nIn most cases Ballantyne syndrome causes fetal or neonatal death and, in contrast, maternal involvement is limited at the most to preeclampsia.\n"}
{"id": "10751694", "url": "https://en.wikipedia.org/wiki?curid=10751694", "title": "Moltable", "text": "Moltable\n\nMoltable is a drug research initiative based in India, aimed at discovering new drugs to target cancer, AIDS, malaria and other potentially devastating infectious diseases, through chemoinformatics research. It is run by the National Chemical Library (NCL) in Pune, India.\n\n"}
{"id": "32088983", "url": "https://en.wikipedia.org/wiki?curid=32088983", "title": "National Center for Genome Resources", "text": "National Center for Genome Resources\n\nThe National Center for Genome Resources (NCGR) is a nonprofit research organization in Santa Fe, New Mexico founded in 1994 focusing on life sciences research, bioinformatics technologies, and leading-edge molecular data production including sequencing and gene expression. \n"}
{"id": "44632045", "url": "https://en.wikipedia.org/wiki?curid=44632045", "title": "Neven Ljubičić", "text": "Neven Ljubičić\n\nNeven Ljubičić (born 1 May 1963) is a Croatian physician and politician, best known for serving as Croatia's Minister of Health and Social Welfare from 2005 to 2008 in the first caabinet of Ivo Sanader.\n\nLjubičić graduated from Zagreb University School of Medicine in 1987, where he also received his doctorate in 1993 before passing his specialty exam in internal medicine in 1996. He practiced medicine at the Holy Ghost Hospital and the Sisters of Charity Hospital in Zagreb.\n\nA member of the Croatian Democratic Union (HDZ), in 2004 he was appointed assistant to health minister Andrija Hebrang, and after Hebrang's resignation he was made minister in February 2005 under Prime Minister Ivo Sanader. He served in that post until the end of the Sanader cabinet in January 2008.\n\n"}
{"id": "42108562", "url": "https://en.wikipedia.org/wiki?curid=42108562", "title": "PATH Biobank", "text": "PATH Biobank\n\nPATH Biobank (Patients’ Tumor Bank of Hope) is a German biobank for breast cancer, established in 2002 from patients for patients. PATH is an independent non-profit foundation with the purpose of supporting breast cancer research with high quality tumor tissue. In order to achieve this goal, PATH operates sample storage tanks with liquid nitrogen at seven German breast centers. Tumor tissue and blood serum from breast cancer patients are stored in these tanks. More than 7200 women have consented to the storage of their tissue since 2004 (as of January 2014). A centralized database complements the biobank with important patient information.\nPATH is a joint venture of clinicians, scientists and patients. Via sample collection for cancer research, these partners aim to close the gap between basic science and fast implementation in the clinical practice.\n\nEstablishing the infrastructure for sampling high quality tissue for basic and clinical research is time consuming and hence often impossible. The property situation of the tumor tissue is often not clearly regulated, which further complicates the establishment of a tissue collection. This situation was pointed our by Prof. Dr. Axel Ullrich one of the inventors of Trastuzumab and member of the scientific advisory board of PATH. Gathering follow-up data from patients is often impossible for a scientist. PATH solves these problems via a centralized storage of the samples, transparent allocation criteria and routine follow-up surveys.\n\nIn one of the cooperating clinical centers, the breast cancer patient is informed about the option to store her tissue a blood serum at PATH. In the case of her informed consent, the tumor will be split into equal parts (aliquots) immediately after the surgery and routine diagnostic. One part is stored exclusively for the patient, the other samples are donated to PATH Biobank for research purposes. The samples are processed according to strict quality standards (cGCP) in all cooperating clinics and stored in the gas phase of liquid nitrogen (about -160 °C).\n\nThe processing, labelling and storage of the tumor and normal tissue and the blood serum aliquots is performed according to standard operation procedures (SOPs), which have been developed specially for PATH. The size of the tissue samples and maximal ischemia times, as well as clotting times for the blood samples, are regulated by the SOPs and documented.\n\nThe honorary board of the PATH Biobank consists of three individuals, according to the statute two of which need to have had breast cancer. In addition to the representation, e.g. at conferences and towards scientific partners, the board guides the activities and direction. The day-to-day business is organized by the PATH-office in Munich. The staff encompasses two permanent employees, which are supported by working students.\n\nThe PATH database encompasses a large amount of important information, which is crucial for using the samples for research. The database solution is located on a stand-alone-computer without internet access, in order to protect the data from unauthorized access. In addition to this, personal data are stored physically separated from further data. Under no circumstances are these personal data given to third parties. The database includes information about e.g. the number of samples, ischemia/clotting times of the samples before freezing, age and gender of the patient, potential pre-existing medical conditions, type and date of diagnosis, menopausal state, staging/grading, histopathology, receptor state (HER2/neu, ER- and PR-state), recommended therapies and already performed (neoadjuvant) therapies, survival state, events (locoregional relapse, distant metastases, therapy course).\n\nBonn: Evangelische Kliniken Bonn gGmbH, Johanniter-Krankenhaus; Universitäts-Frauenklinik Bonn\n\nDortmund: St. Johannes-Hospital Dortmund, Brustzentrum\n\nBochum/Herne: Universitäts-Frauenklinik Marienhospital Herne, Kooperatives Brustzentrum Bochum/Herne; St. Annahospital, Kooperatives Brustzentrum Bochum/Herne\n\nKassel: Klinikum Kassel GmbH, IBZ- Interdisziplinäres Brustzentrum\n\nMarburg: Klinik für Gynäkologie, gynäkologische Endokrinologie und Onkologie, Universitätsklinikum Gießen und Marburg GmbH, Standort Marburg, Brustzentrum Regio\n\nOffenbach: Klinik für Gynäkologie und Geburtshilfe, Klinikum Offenbach GmbH\n\nRegensburg: Klinik für Frauenheilkunde und Geburtshilfe der Universität Regensburg am Caritas-Krankenhaus St. Josef\n\nScientists from academic groups and from industry can apply for sample allocation.\n\n\n\nIn order to make biobanks more visible in Germany, the German biobank register was established, which is operated by the TMF – Technologie- und Methodenplattform für die vernetzte medizinische Forschung and supported by the German Ministry for Education and Research, the Bundesministerium für Bildung und Forschung. PATH Biobank is registered in the biobank register. \nThe importance of biobanks such as PATH Biobank is also stressed by the initiative \"Nationale Biobanken Initiative\", which is supported with 18 Mio. Euro by the German Ministry for Education and Research.\n\n"}
{"id": "1146344", "url": "https://en.wikipedia.org/wiki?curid=1146344", "title": "Perfusionist", "text": "Perfusionist\n\nA perfusionist, also known as a Clinical Perfusionist, Cardiovascular Perfusionist, Perfusiologist, Clinical Perfusion Scientist, or Medical Perfusionist, is a healthcare professional who uses the cardiopulmonary bypass machine (heart–lung machine) during cardiac surgery and other surgeries that require cardiopulmonary bypass to manage the patient's physiological status. \n\nPerfusionists form part of the wider cardiothoracic surgical team which includes cardiac surgeons, anesthesiologists and physician assistants. The perfusionist shares responsibility with the cardiac surgeon and anesthesiologist for the management of the physiological and metabolic needs of the cardiac surgical patient, so that the surgeon may operate on a still,or unbeating heart during certain procedures. The cardiac surgeon is in overall command of the operation. This is accomplished through the utilization of the heart–lung machine, as well as its associated components of an oxygenator, filters, reservoirs and tubing. The perfusionist is responsible for the management of circulatory and respiratory functions of the patient which has a great effect on the patient systemic condition and allows the cardiac surgeon to focus on the actual surgical procedure and less on the immediate needs of the patient. Other responsibilities include autologous blood collection and processing, implementation and management of the intra-aortic balloon pump, and management of extracorporeal membrane oxygenation, as well as monitoring of anticoagulation, electrolyte, acid-base balance and blood-gas composition. In many tertiary hospitals, perfusionists are also key personnel in placing and managing patients on ventricular assist devices as a bridge to recovery or heart transplantation and supporting patients receiving lung or liver transplants. In some hospitals, perfusionists can be involved in procurement of cardiothoracic donor organs for transplantation.\n\nIn the United States,There are only Certified Clinical Perfusionists who perform all perfusion, for cardiac Surgery. A bachelor's degree with concentrations in biology, chemistry, anatomy and physiology is the prerequisite to be admitted to a perfusion program. As of 2005, there are 18 perfusion training programs in the United States, most offering a master's degree in perfusion sciences or circulatory sciences. Training typically consists of two years of academic and clinical education. Although the structure and training philosophies of perfusion programs differ, typically a perfusion student will begin his or her training in a didactic fashion in which the student will closely follow instructions from a \"certified clinical perfusionist\" in the confines of a cardiac surgery procedure. Academic coursework may be concurrent or precede this clinical instruction and is equally vital for their training. Early in their clinical training, the perfusion student may have little involvement outside of an observational role. However, as time progresses, more tasks may be incrementally delegated to them with the ultimate goal of producing a capable and competent perfusionist. Once a student graduates from a perfusion program, he or she must begin the certification process. In the interim, the perfusion graduate is typically referred to as board-eligible, which is sufficient for employment in cardiac surgery with the understanding that achieving certified status is required for long-term employment. Most employers have stipulations on the duration of board-eligible status.\n\nA two-part exam is required to become certified and use the designation \"C.C.P\". In the United States, this exam is administered and evaluated by the American Board of Cardiovascular Perfusion. Similar governing bodies exist in other countries with comparable examination processes. The first portion of the two-part process is the Perfusion Basic Science Exam, and the latter portion is the Clinical Applications in Perfusion Exam. In order to qualify for this examination process, a perfusion student must have either graduated from or be enrolled in an accredited perfusion program, as well as have participated in a minimum of 75 clinical procedures during the course of their training. A perfusion student may qualify for the Perfusion Basic Science Exam before they actually matriculate from their respective training program. Once employment is provided, and the perfusionist has participated independently in a minimum of 50 clinical procedures, he or she can qualify for the Clinical Applications in Perfusion Exam. Once the Clinical Applications in Perfusion Exam has been successfully passed, a perfusionist can use the designation \"C.C.P\". In addition, there are recertification requirements for perfusionists in which proof of a minimum number of clinical procedures and attendance to scientific or educational meetings must be provided to a certifying body (\"i.e.\" American Board of Cardiovascular Perfusion). These recertification requirements and subsequent verification process occur every three years and are mandatory to maintain certified status to use the designation \"certified clinical perfusionist\".\n\nAs of February 2010, there were 3,766 certified perfusionists in the United States and 6583 in Canada.\n\nIn Canada,There are only Certified Clinical Perfusionits who perform all perfusion, for cardiac Surgery. There are three training programs: Burnaby in Western Canada, and[Toronto]] and Montreal in Eastern Canada. British Columbia Institute of Technology in Burnaby offers an advanced specialty certificate in cardiovascular perfusion to graduates of its two-year program. Applicants must be certified respiratory therapists, critical care nurses, or cardiac professionals with two years or more of current experience in cardiac critical care. Applicants to the Michener Institute program in Toronto must have a bachelor's degree. The training program is 16 months to two years. The perfusion program of the Université de Montréal is a three-year bachelor's degree of 90 credits in biomedical science of which 27 credits are specific to clinical perfusion and in addition a diplôme d’études supérieurs spécialisées (DESS) of 30 credits in clinical perfusion of one-year at the master level.\n\nThere are only Clinical Perfusion Scientists who perform all perfusion, for cardiac Surgery.\nIn the United Kingdom and Ireland, a bachelor's degree in a science subject (usually life or clinical sciences) is a pre-requisite to enrolment on the two-year perfusion training course. Employment as a trainee perfusionist is also required. Trainees must complete a two-year academic and practical course. They complete academic assessments (essays and exams), while in the workplace moving from a purely observational role to one in which they are capable of managing the patient while they are on cardiopulmonary system with minimal supervision. Once a trainee has been the primary perfusionist in 150 clinical procedures, they must undertake a practical exam. For this exam, the candidate is observed by two external examiners whilst building and priming a cardiopulmonary circuit, then using it during a surgical operation. After the practical exam, trainees must complete a 40-minute \"viva voce\" exam, which tests their academic knowledge. After this is successfully completed, they are awarded a postgraduate diploma and the status of qualified clinical perfusion scientist. They must maintain this by performing a minimum of 40 clinical procedures per year.\n\nIn Australia there are both Clinical and medical perfusionists.There are significantly more Clinical Perfusionists in Australia, who may be trained overseas, as well as Australia.. Clinical Perfusionists have the most experience in performing the majority of actual perfusion in cardiac surgery in Australia. Although Masters and PhD graduates have trained and become Clinical Perfusionist, the minimum qualification, is a science degree(usually Clinical/Health Sciences) as an entry requirement, before training. Clinical Perfusion training was at the Masters of Science level via an eLearning course at a university. Further didactic training is in a practical/clinical format. This is performed at a hospital, whilst doing a three-year multi-examined, multi-modular course via correspondence, with the Australian and New Zealand College of Perfusionists (ANZCP). A further final examination for Clinical Perfusionists, is administered by the ANZCP over two days. This involves a three hour written, two hour multiple choice and four half hour viva voce questions.\n\nSignificantly, up to this time, medical perfusionists are unqualified in perfusion. A medical perfusionist is a medical doctor (usually an anaesthetist) Who may become university trained, in a new course, through part time eLearning and simulation to perform perfusion. \n\nIn New Zealand there are only Clinical Perfusionists who perform perfusion in heart surgery. A Clinical Perfusionist must have at least a science degree(usually Clinical/Health Sciences) as an entry requirement, before training. Further didactic training is in a practical/clinical format, at a hospital, whilst doing a three-year course via correspondence with the Australian and New Zealand College of Perfusionists. Final examination for a Clinical Perfusionists, is administered by the ANZCP over two days. This involves a three hour written, two hour multiple choice and four half hour viva voce questions. \n\nThe majority of perfusion in cardiac surgery, in the developed world, is performed by Clinical Perfusionists.In China, Egypt, and some South American countries a clinical perfusionist is a medical doctor who has completed subspecialty training.\nIn Argentina, a perfusionist is a medical doctor, usually a cardiologist, who has undertaken additional sub-specialty training. They are often referred to as \"hemodinamistas\" (i. e. hemodynamics specialists).\n\nIn India there are only Clinical Perfusionists who perform perfusion in heart surgery.There are different education programs for the education of Clinical Perfusionists. A three Year Bachelors degree program. Additionally, there is a two years post graduate diploma that is available to practice as a Clinical Perfusionist. A three and half year bachelor's degree program is also available, which includes six months internship. A two years post graduate diploma in some institutions (i. e. AIIMS Delhi, SMSMC Jaipur) Recently The Board of Clinical Perfusionist of India introduced certification.\nPerfusionists can be involved in a number of cardiac surgical procedures, select vascular procedures and a few other surgical procedures in an ancillary role. In the realm of cardiac surgery, perfusionists perform cardiopulmonary bypass in adult and pediatric surgical procedures, which constitute the majority of procedures that perfusionists perform.\n\nPerfusionists may participate in curative or staged palliative procedures to treat the following pediatric pathologies:\nAdult surgical procedures may include:\nSelect ancillary procedures in which perfusion techniques and/or perfusionists may be involved include isolated limb perfusion, intraperitoneal hyperthermic chemoperfusion and tracheal resection/repair.\n\n\n"}
{"id": "5828206", "url": "https://en.wikipedia.org/wiki?curid=5828206", "title": "Picamilon", "text": "Picamilon\n\nPicamilon (also known as N-nicotinoyl-GABA, pycamilon, and pikamilon) is a drug formed by a synthetic combination of niacin and GABA. It was developed in the Soviet Union in 1969 and further studied in both Russia and Japan as a prodrug of GABA.\n\nIn Russia, picamilon is sold as a prescription drug. The rights to the drug belong to the Russian pharmaceutical company NPK ECHO (\"НПК ЭХО\"). It is not approved for sale in the United States and has been deemed as an adulterating agent in dietary supplements, with five American companies required to remove their picamilon products from the market in November, 2015.\n\nOne study in animals showed that picamilon permeated the blood–brain barrier and then is hydrolyzed into GABA and niacin. The released GABA in theory would activate GABA receptors potentially producing an anxiolytic response. The second released component, niacin, is a vasodilator.\n\nPlasma picamilon concentrations are generally in the 500–3000 \"μ\"g/L range during the first few hours after single oral doses of 50–200 mg with a half-life of 1–2 hours. The drug undergoes hydrolysis to GABA and nicotinic acid. Urinary excretion of parent drug and the two metabolites accounts for up to 79% of a single dose.\n\nIn the United States, the Food and Drug Administration ruled in 2015 that picamilon does not fit any of the dietary ingredient categories in the Dietary Supplement Health and Education Act of 1994, namely that it is not a vitamin; a dietary mineral; an herb or other botanical; an amino acid; a dietary substance for use by humans to supplement the diet by increasing the total dietary intake; or a concentrate, metabolite, constituent, extract, or combination of any ingredient described above. This led to the removal of picamilon as a pure substance or from various supplements manufactured in the US.\n"}
{"id": "67166", "url": "https://en.wikipedia.org/wiki?curid=67166", "title": "Placenta", "text": "Placenta\n\nThe placenta is a temporary organ that connects the developing fetus via the umbilical cord to the uterine wall to allow nutrient uptake, thermo-regulation, waste elimination, and gas exchange via the mother's blood supply; to fight against internal infection; and to produce hormones which support pregnancy. Placentas are a defining characteristic of placental mammals, but are also found in marsupials and some non-mammals with varying levels of development. \n\nThe placenta functions as a fetomaternal organ with two components: the fetal placenta (Chorion frondosum), which develops from the same blastocyst that forms the fetus, and the maternal placenta (Decidua basalis), which develops from the maternal uterine tissue. It metabolizes a number of substances and can release metabolic products into maternal or fetal circulations. The placenta is expelled from the body upon birth of the fetus.\n\nThe word \"placenta\" comes from the Latin word for a type of cake, from Greek πλακόεντα/πλακοῦντα \"plakóenta/plakoúnta\", accusative of πλακόεις/πλακούς \"plakóeis/plakoús\", \"flat, slab-like\", in reference to its round, flat appearance in humans. The classical plural is \"placentae\", but the form \"placentas\" is common in modern English and probably has the wider currency at present.\n\nPlacental mammals, such as humans, have a chorioallantoic placenta that forms from the chorion and allantois. In humans, the placenta averages 22 cm (9 inch) in length and 2–2.5 cm (0.8–1 inch) in thickness, with the center being the thickest, and the edges being the thinnest. It typically weighs approximately 500 grams (just over 1 lb). It has a dark reddish-blue or crimson color. It connects to the fetus by an umbilical cord of approximately 55–60 cm (22–24 inch) in length, which contains two umbilical arteries and one umbilical vein. The umbilical cord inserts into the chorionic plate (has an eccentric attachment). Vessels branch out over the surface of the placenta and further divide to form a network covered by a thin layer of cells. This results in the formation of villous tree structures. On the maternal side, these villous tree structures are grouped into lobules called cotyledons. In humans, the placenta usually has a disc shape, but size varies vastly between different mammalian species.\n\nThe placenta occasionally takes a form in which it comprises several distinct parts connected by blood vessels. The parts, called lobes, may number two, three, four, or more. Such placentas are described as bilobed/bilobular/bipartite, trilobed/trilobular/tripartite, and so on. If there is a clearly discernible main lobe and auxiliary lobe, the latter is called a succenturiate placenta. Sometimes the blood vessels connecting the lobes get in the way of fetal presentation during labor, which is called vasa previa.\n\nAbout 20,000 protein coding genes are expressed in human cells and 70% of these genes are expressed in the normal mature placenta. Some 350 of these genes are more specifically expressed in the placenta and fewer than 100 genes are highly placenta specific. The corresponding specific proteins are mainly expressed in trophoblasts and have functions related to female pregnancy. Examples of proteins with elevated expression in placenta compared to other organs and tissues are PEG10 and the cancer testis antigen PAGE4 expressed in cytotrophoblasts, CSH1and KISS1 expressed in syncytiotrophoblasts, and PAPPA2 and PRG2 expressed in extravillous trophoblasts.\n\nThe placenta begins to develop upon implantation of the blastocyst into the maternal endometrium. The outer layer of the blastocyst becomes the trophoblast, which forms the outer layer of the placenta. This outer layer is divided into two further layers: the underlying cytotrophoblast layer and the overlying syncytiotrophoblast layer. The syncytiotrophoblast is a multinucleated continuous cell layer that covers the surface of the placenta. It forms as a result of differentiation and fusion of the underlying cytotrophoblast cells, a process that continues throughout placental development. The syncytiotrophoblast (otherwise known as syncytium), thereby contributes to the barrier function of the placenta.\n\nThe placenta grows throughout pregnancy. Development of the maternal blood supply to the placenta is complete by the end of the first trimester of pregnancy week 14 (DM).\n\nIn preparation for implantation of the blastocyst, the uterine endometrium undergoes \"decidualisation\". Spiral arteries in decidua are remodeled so that they become less convoluted and their diameter is increased. The increased diameter and straighter flow path both act to increase maternal blood flow to the placenta. There is relatively high pressure as the maternal blood fills intervillous space through these spiral arteries bathes the fetal villi in blood, allowing an exchange of gases to take place. In humans and other hemochorial placentals, the maternal blood comes into direct contact with the fetal chorion, though no fluid is exchanged. As the pressure decreases between pulses, the deoxygenated blood flows back through the endometrial veins.\n\nMaternal blood flow is approximately 600–700 ml/min at term.\n\nThis begins at day 5 - day 12 \n\nDeoxygenated fetal blood passes through umbilical arteries to the placenta. At the junction of umbilical cord and placenta, the umbilical arteries branch radially to form chorionic arteries. Chorionic arteries, in turn, branch into cotyledon arteries. In the villi, these vessels eventually branch to form an extensive arterio-capillary-venous system, bringing the fetal blood extremely close to the maternal blood; but no intermingling of fetal and maternal blood occurs (\"placental barrier\").\n\nEndothelin and prostanoids cause vasoconstriction in placental arteries, while nitric oxide causes vasodilation. On the other hand, there is no neural vascular regulation, and catecholamines have only little effect.\n\nThe fetoplacental circulation is vulnerable to persistent hypoxia or intermittent hypoxia and reoxygenation, which can lead to generation of excessive free radicals. This may contribute to pre-eclampsia and other pregnancy complications. It is proposed that melatonin plays a role as an antioxidant in the placenta. \n\nThis begins at day 17 - day 22 \n\nPlacental expulsion begins as a physiological separation from the wall of the uterus. The period from just after the child is born until just after the placenta is expelled is called the \"third stage of labor\". The placenta is usually expelled within 15–30 minutes of birth.\n\nPlacental expulsion can be managed actively, for example by giving oxytocin via intramuscular injection followed by cord traction to assist in delivering the placenta. Alternatively, it can be managed expectantly, allowing the placenta to be expelled without medical assistance. Blood loss and the risk of postpartum bleeding may be reduced in women offered active management of the third stage of labour, however there may be adverse effects and more research is necessary.\n\nThe habit is to cut the cord immediately after birth, but it is theorised that there is no medical reason to do this; on the contrary, it is theorized that not cutting the cord helps the baby in its adaptation to extrauterine life, especially in preterm infants.\n\nThe placenta is traditionally thought to be sterile, but recent research suggests that a resident, non-pathogenic, and diverse population of microorganisms may be present in healthy tissue. However, whether these microbes exist or are clinically important is highly controversial and is the subject of active research.\n\nThe placenta intermediates the transfer of nutrients between mother and fetus. The perfusion of the intervillous spaces of the placenta with maternal blood allows the transfer of nutrients and oxygen from the mother to the fetus and the transfer of waste products and carbon dioxide back from the fetus to the maternal blood. Nutrient transfer to the fetus can occur via both active and passive transport. Placental nutrient metabolism was found to play a key role in limiting the transfer of some nutrients. Adverse pregnancy situations, such as those involving maternal diabetes or obesity, can increase or decrease levels of nutrient transporters in the placenta potentially resulting in overgrowth or restricted growth of the fetus.\n\nWaste products excreted from the fetus such as urea, uric acid, and creatinine are transferred to the maternal blood by diffusion across the placenta.\n\nIgG antibodies can pass through the human placenta, thereby providing protection to the fetus \"in utero\". This transfer of antibodies begins as early as the 20th week of gestational age, and certainly by the 24th week. This passive immunity lingers for several months after birth, thus providing the newborn with a carbon copy of the mother's long-term humoral immunity to see the infant through the crucial first months of extrauterine life. IgM, however, cannot cross the placenta, which is why some infections acquired \"during\" pregnancy can be hazardous for the fetus.\n\nFurthermore, the placenta functions as a selective maternal-fetal barrier against transmission of microbes. However, insufficiency in this function may still cause mother-to-child transmission of infectious diseases.\n\n\nThe placenta and fetus may be regarded as a foreign allograft inside the mother, and thus must evade from attack by the mother's immune system.\n\nFor this purpose, the placenta uses several mechanisms:\n\nHowever, the Placental barrier is not the sole means to evade the immune system, as foreign fetal cells also persist in the maternal circulation, on the other side of the placental barrier.\n\nThe placenta also provides a reservoir of blood for the fetus, delivering blood to it in case of hypotension and vice versa, comparable to a capacitor.\nNumerous pathologies can affect the placenta.\n\n\nInfections involving the placenta:\n\nThe placenta often plays an important role in various cultures, with many societies conducting rituals regarding its disposal. In the Western world, the placenta is most often incinerated.\n\nSome cultures bury the placenta for various reasons. The Māori of New Zealand traditionally bury the placenta from a newborn child to emphasize the relationship between humans and the earth. Likewise, the Navajo bury the placenta and umbilical cord at a specially chosen site, particularly if the baby dies during birth. In Cambodia and Costa Rica, burial of the placenta is believed to protect and ensure the health of the baby and the mother. If a mother dies in childbirth, the Aymara of Bolivia bury the placenta in a secret place so that the mother's spirit will not return to claim her baby's life.\n\nThe placenta is believed by some communities to have power over the lives of the baby or its parents. The Kwakiutl of British Columbia bury girls' placentas to give the girl skill in digging clams, and expose boys' placentas to ravens to encourage future prophetic visions. In Turkey, the proper disposal of the placenta and umbilical cord is believed to promote devoutness in the child later in life. In Ukraine, Transylvania, and Japan, interaction with a disposed placenta is thought to influence the parents' future fertility.\n\nSeveral cultures believe the placenta to be or have been alive, often a relative of the baby. Nepalese think of the placenta as a friend of the baby; Malaysian Orang Asli regard it as the baby's older sibling. Native Hawaiians believe that the placenta is a part of the baby, and traditionally plant it with a tree that can then grow alongside the child. Various cultures in Indonesia, such as Javanese, believe that the placenta has a spirit and needs to be buried outside the family house.\n\nIn some cultures, the placenta is eaten, a practice known as placentophagy. In some eastern cultures, such as China, the dried placenta (\"ziheche\" , literally \"purple river cart\") is thought to be a healthful restorative and is sometimes used in preparations of traditional Chinese medicine and various health products. The practice of human placentophagy has become a more recent trend in western cultures and is not without controversy; its practice being considered cannibalism is debated.\n\nSome cultures have alternative uses for placenta that include the manufacturing of cosmetics, pharmaceuticals and food.\n\n\n"}
{"id": "9372096", "url": "https://en.wikipedia.org/wiki?curid=9372096", "title": "Recreational therapy", "text": "Recreational therapy\n\nAccording to the American Therapeutic Recreation Association (ATRA), recreational therapy or therapeutic recreation (TR) is a systematic process that utilizes recreation (leisure) and other interest activities as interventions to address the assessed needs of individuals with illnesses and/or disabling conditions, as a means to psychological and physical health, recovery and well-being. Recreational therapy may also be simply referred to as \"recreation therapy\", in short it is the utilization and enhancement of leisure.\n\nThe work of recreational therapists differ from other professionals on the basis of using leisure activities alone to meet well-being goals, they work with clients to enhance motor, social and cognitive functioning, build confidence, develop coping skills, and integrate skills learned in treatment settings into community settings. Intervention areas vary widely and are based upon enjoyable and rewarding interests of the client. Examples of intervention modalities include creative arts (e.g., crafts, music, dance, drama, among others), games, sports like adventure programming, exercises like dance/movement, and skill enhancement activities (Motor, locomotion, sensory, cognition, communication, and behavior).\n\nThere are four approaches in therapeutic recreation:\n\nEight domains of leisure are: leisure awareness, leisure attitudes, leisure skills, community integration skills, community participation, cultural and social behaviors, interpersonal skills.\n\nA bachelor's degree in recreational therapy is required for most entry-level positions. These programs typically cover areas such as treatment and program planning, human body, physiology, kinesiology, and professional ethics. Some programs offer the opportunity to specialize in occupational therapy, and in the intervention of those that are mentally or physically challenged. Most employers prefer to hire candidates who are Certified Therapeutic Recreation Specialists (CTRS). Therapists become certified through the National Council for Therapeutic Recreation Certification (NCTRC) or through a provincial regulatory body such as, Therapeutic Recreation Ontario (TRO). To qualify for certification under the Academic Path, applicants must have a bachelor's degree in TR, complete an internship under the supervision of a CTRS, and pass a written exam. There is also an Equivalency Path A and B for certification. The requirements are slightly different and include a bachelor's degree outside of TR, paid work experience, and successful completion of the written exam.\n\nRecreation Therapists with the Certified Therapeutic Recreation Specialist (CTRS) credential are required to complete 50 clock hours (5.0 CEUs) of continuing education within a 5 year span as part of the overall requirements to renew national certification through NCTRC. \n\nNCTRC has outlined several ways a CTRS can earn continuing education Continuing Education. \n\nThese include: \n\na.) Academic Courses\n\nb.) Teleconferences/Audio Seminars like ATRA's webinar series. \n\nc.) Internet Course Programs: Some online programs identified are on the Therapeutic Recreation Directory website: Therapeutic Recreation Directory: CEU Opportunities. These include websites like SMART CEUs Hub: Success Makers Are Rec Therapists and DannyPettry.com\n\nd.) Conferences: American Therapeutic Recreation Association (ATRA) and state branches of ATRA. Recreation therapists can attend conferences provided by related professional organizations and earn CEUs (pending the session meets Therapeutic Recreation (TR) knowledge areas required by NCTRC. \n\ne.) Internships & Externships: Supervised guidance to practice.\n\nThe American Therapeutic Recreation Association (ATRA) and the Canadian Therapeutic Recreation Association (CTRA) are the largest national membership organizations representing the interests and needs of recreational therapists in the U. S. and Canada. \n\nCertification:\nThe National Council for Therapeutic Recreation Certification, a charter member of the National Organization for Competency Assurance (NOCA), also provides a certification that expires after 5 years. Those who are certified must apply for re-certification at the end of the expiration period. Specialty certification is now available in 5 areas. Health and human service professionals who acquire a higher level of knowledge and more advanced skills provide the consumer with a greater depth of service compared to individuals who practice at less advanced levels. Specialization is well recognized within professional practice and has become the norm within the health and human service delivery system today. The median salary for recreational therapists in the United States was estimated $44,839 a year in 2011. This number may vary slightly based on specific geographic region, years of experience, and type of employing agency.\n\nLicensure:\nThere are currently four states with Recreational Therapy licensure (Utah, North Carolina, New Hampshire, and Oklahoma). To practice Recreational Therapy in these states, professionals must possess a current, valid state license. In addition to the four currently licensed states, numerous other states are currently moving toward developing licensure. Through the Joint Task Force on Recreational Therapy Licensure sponsored by the American Therapeutic Recreation Association and the National Council for Therapeutic Recreation Certification, significant progress is being made in the licensure arena. Licensure is being pursued by the profession as a further means of protecting the public from potential harm.\n\n\n"}
{"id": "51648836", "url": "https://en.wikipedia.org/wiki?curid=51648836", "title": "Salmonellosis in the United States", "text": "Salmonellosis in the United States\n\nSalmonellosis annually causes, per CDC estimation, about 1.2 million illnesses, 23,000 hospitalizations, and 450 deaths in the United States every year.\n\nThe shell of the egg may be contaminated with \"Salmonella\" by feces or environment, or its interior (yolk) may be contaminated by penetration of the bacteria through the porous shell or from a hen whose infected ovaries contaminate the egg during egg formation.\n\nThe United States has struggled to control salmonella infections, with the rate of infection rising from 2001 to 2011. The FDA and the USDA have separate jurisdiction over products which may be contaminated with salmonella, but the rules defining which agency inspects what is complex and difficult to summarize; for example, the FDA inspects shelled eggs while the USDA oversees egg products.\n\nIn 1998, the USDA moved to close plants if salmonella was found in excess of 20 percent, which was the industry’s average at the time, for three consecutive tests. Texas-based Supreme Beef Processors, Inc. sued on the argument that Salmonella is naturally occurring and ultimately prevailed when a federal appeals court affirmed a lower court. These issues were highlighted in a proposed Kevin's Law (formally proposed as the Meat and Poultry Pathogen Reduction and Enforcement Act of 2003), of which components were included the Food Safety Modernization Act passed in 2011, but that law applies only to the FDA and not the USDA. The USDA proposed a regulatory initiative in 2011 to Office of Management and Budget.\n\nIn 2012, the USDA proposed to increase the line speed and reduce the number of inspectors of chickens.\n\nIn 1996, the USDA Food Safety and Inspection Service finalized rules which required slaughter and processing plants to adopt Hazard Analysis and Critical Control Point rules, which included performance standards for acceptable percentage testing positive of salmonella. These included 20% for broilers (chickens), 8.7% for swine, and 7.5% for ground beef. In 2011, updated performance standards went into effect, reducing the salmonella prevalence to 7.5%; however, meeting these standards was not strictly required for operation. Plants not meeting the requirement were publicized online. The agency originally began publishing the names of problem plants in 2008.\n\nIn a 2013 fact sheet, the National Chicken Council observed that although salmonella on raw chicken has signfiicantly declined, salmonellosis has not significantly declined, suggesting that salmonellosis infections have another cause.\n\nAbout 142,000 people in the United States are infected each year with \"Salmonella\" Enteritidis from chicken eggs, and about 30 die.\n\nIn 2010, an analysis of death certificates in the United States identified a total of 1,316 \"Salmonella\"-related deaths from 1990 to 2006. These were predominantly among older adults and those who were immunocompromised.\n\nThe U.S. government reported as many as 20% of all chickens were contaminated with \"Salmonella\" in the late 1990s, and 16.3% were contaminated in 2005. In the mid- to late 20th century, \"Salmonella enterica\" serovar Enteritidis was a common contaminant of eggs. This is much less common now with the advent of hygiene measures in egg production, and the vaccination of laying hens to prevent \"Salmonella\" colonization. Various \"Salmonella\" serovars (strains) also cause severe diseases in animals.\n\nIn February 2007, the U.S. Food and Drug Administration issued a warning to consumers not to eat certain jars of Peter Pan or Great Value peanut butter, due to risk of contamination with \"Salmonella\" Tennessee.[http://www.fda.gov/bbs/topics/NEWS/2007/NEW01563.html <nowiki>[1]</nowiki>]\n\nIn March 2007, around 150 people were diagnosed with salmonellosis after eating tainted food at a governor's reception in Krasnoyarsk, Russia. Over 1,500 people attended the ball on March 1, and fell ill as a consequence of ingesting \"Salmonella\"-tainted sandwiches.\n\nAbout 150 people were sickened by \"Salmonella\"-tainted chocolate cake produced by a major bakery chain in Singapore, in December 2007.[http://www.channelnewsasia.com/stories/singaporelocalnews/view/316110/1/.html <nowiki>[2]</nowiki>]\n\nFrom April 10, 2008 to July 8, 2008, the rare Saintpaul serotype of \"S. enteritidis\" caused at least 1017 cases of salmonellosis in 41 states throughout the United States, the District of Columbia, and Canada. As of July 2008, the U.S. FDA suspected the contaminated food product was a common ingredient in fresh salsa, such as raw tomato, fresh jalapeño pepper, fresh serrano pepper, and fresh cilantro. It is the largest reported salmonellosis outbreak in the United States since 1985. New Mexico and Texas have been proportionally the hardest hit by far, with 49.7 and 16.1 reported cases per million, respectively. The greatest number of reported cases have occurred in Texas (384), New Mexico (98), Illinois (100), and Arizona (49). At least 203 reported hospitalizations have been linked to the outbreak, it has caused at least one death, and it may have been a contributing factor in at least one additional death. The CDC maintains \"it is likely many more illnesses have occurred than those reported.\" If applying a previous CDC-estimated ratio of unreported salmonellosis cases to reported cases (38.6:1), an estimated 40,273 illnesses occurred from this outbreak.\n\nAs of 18 July 2008, the FDA removed raw tomatoes and cilantro as potential carriers; however, fresh jalapeño and serrano peppers still remain.\n\nIn December 2008 and January 2009, several Midwestern states, including Ohio (officially confirmed by state authorities), reported an outbreak of salmonellosis from \"Salmonella typhimurium\" that had sickened at least 50 people, due to contaminated dairy products such as cheeses.\n\nOn January 17, 2009, the FDA announced they had traced the source of an outbreak of \"Salmonella typhimurium\" to a plant in Blakely, Georgia, owned by Peanut Corporation of America (PCA), and urged people to postpone eating commercially prepared or manufactured peanut butter-containing products and institutionally served peanut butter. \"Salmonella\" was reported to be found in 46 states in the United States in at least 3,862 peanut butter-based products, such as crackers, energy bars, and peanut butter cookies from at least 343 food companies. Dog treats were affected, as well. At least 691 people in more than 46 states became sick, and the \"Salmonella\" claimed at least 9 lives as of March 25.\n\nPeanut butter and peanut paste manufactured by PCA were distributed to hundreds of firms for use as an ingredient in thousands of different products, such as cookies, crackers, cereal, candy, and ice cream, all of which were recalled. Some products were also sold directly to consumers in retail outlets, such as dollar stores.\n\nOn March 14, 2009, expressing his own personal concern for the safety of his children who enjoy peanut butter, President Obama announced the establishment of the Food Safety Working Group, \"an inter-agency effort to help overhaul the oversight system.\" The announcement came days after the FDA, also responding, released its first \"guidance\" on dealing with \"Salmonella\" contamination.\n\nAn outbreak of salmonellosis caused by a rarer subspecies, \"Salmonella bareilly\", was reported in multiple US states primarily on the East Coast. No deaths were reported, but many episodes of sickness and some hospitalizations were linked to the consumption of raw scraped ground tuna product.\n"}
{"id": "4803241", "url": "https://en.wikipedia.org/wiki?curid=4803241", "title": "San Roque Lake", "text": "San Roque Lake\n\nThe San Roque Lake is a reservoir (artificial lake) in the province of Córdoba, Argentina. It was created by the damming of several rivers, especially the Suquía and the Cosquín. It is located next to the city of Villa Carlos Paz, about 600 m above mean sea level. It has a surface area of 16 km², an average depth of 16 m, and a maximum volume of 180 million m³.\n\nThe dam was initially built to provide fresh water for the capital and its surroundings. It was designed in 1884 by the engineering firm of Cassaffousth, Bialet Massé and Dumesnil, finished in 1886, and inaugurated officially in 1890. Two years later the dam was suffering from a complete lack of maintenance, however, and a political scandal erupted.\n\nThe original dam was finally replaced by a newer one, located 150 m away, by an initiative of Governor Amadeo Sabattini, and completed in 1944. The newer dam was built to contain and control larger rises in water levels. When the engineers tried to demolish the original dam, the dynamite only blew the metal railing. The new dam was therefore built several meters in front of the old one. When the level of the lake is low, the upper part of the old construction can be seen.\n\n"}
{"id": "274110", "url": "https://en.wikipedia.org/wiki?curid=274110", "title": "Savage Love", "text": "Savage Love\n\nSavage Love is a syndicated sex-advice column by Dan Savage. The column appears weekly in several dozen newspapers, mainly free newspapers in the US and Canada, but also newspapers in Europe and Asia. It started in 1991 with the first issue of the Seattle weekly newspaper \"The Stranger\".\n\nSince October 2006, Savage has also recorded the \"Savage Lovecast\", a weekly podcast version of the column, featuring telephone advice sessions. Podcasts are released every Tuesday.\n\nSince 2002, he has written the column at Eppie Lederer's desk, which he, a \"lifelong fan\" of her Ann Landers column, bought at auction after the noted advice columnist died.\n\nIn 1991, Savage was living in Madison, Wisconsin, and working as a manager at a local video store that specialized in independent film titles. There, he befriended Tim Keck, co-founder of \"The Onion\", who announced that he was moving to Seattle to help start an alternative weekly newspaper titled \"The Stranger\". Savage \"made the offhand comment that forever altered [his] life: 'Make sure your paper has an advice column – everybody claims to hate 'em, but everybody seems to read 'em'.\" He typed up a sample column, and to his surprise Keck offered him the job.\n\nSavage stated in a February 2006 interview in \"The Onion\"s \"A.V. Club\" (which publishes his column) that he began the column with the express purpose of providing mocking advice to heterosexuals, since most straight advice columnists were \"clueless\" when responding to letters from gay people.\n\nFor the first six years of the column, Savage had his readers address him with \"Hey, faggot\", as a comment on previous efforts to recapture offensive words. He was criticized for this by some gay activists.\n\nDuring the run of Savage Love, Savage has popularized several neologisms. He has also debunked several sexual neologisms for violent sex acts, including the \"donkey punch\", the \"pirate\" and the \"hot Karl\", concluding \"They're all fictions.\"\n\nIn any relationship, but particularly those with a large difference of age or experience between the partners, the older or more experienced partner has the responsibility to leave the younger or less experienced partner in at least as good a state (emotionally and physically) as before the relationship. The \"campsite rule\" includes things like leaving the younger or less experienced partner with no STDs, no unwanted pregnancies, and not overburdening them with emotional and sexual baggage.\n\nShortly after a 2009 scandal in Portland, Oregon, involving openly gay mayor Sam Adams and Beau Breedlove, who had allegedly turned 18 almost immediately before the two began a sexual relationship, Savage created a companion rule to the \"campsite rule\", now known as the \"Tea and Sympathy rule\". The rule is a reference to a line in the play of the same name, in which a much older woman asks of a high-school-age boy, right before having sex with him: \"Years from now, when you talk about this – and you will – be kind.\" Savage claimed in an article in \"The Portland Mercury\" that, while Adams followed the \"campsite rule\" – Breedlove did not claim that Adams had given him any diseases or caused him emotional trauma, and in fact still refers to Adams as a friend – Breedlove violated the \"Tea and Sympathy\" rule by making public statements that he knew could ruin Adams's career.\n\nIn a July 20, 2011 column, Savage coined the term \"monogamish\". The term describes couples who are perceived to be monogamous, who are \"mostly\" monogamous, but who are not 100% monogamous. Such couples have an understanding that allows for some amount of sexual contact outside the relationship. Savage believes that of all the couples people think are 100% monogamous, a lot of them are more \"monogamish\" than people realize. The term has since seen mainstream use.\n\nIn 2001, Savage challenged readers of his column to coin a name for the sex act in which a woman uses a strap-on dildo to perform anal sex on her male partner. After multiple nominations and a reader vote, the verb \"peg\" was chosen, with a 43% plurality over runners-up \"bob\" and \"punt\".\n\nSavage reacted strongly to statements made about homosexuality by former United States Senator Rick Santorum in an April 2003 interview with the Associated Press. Santorum included gay sex as a form of deviant sexual behavior, along with incest, polygamy, and bestiality, that he said threatens society and the family; he said he believed consenting adults do not have a constitutional right to privacy with respect to sexual acts. Savage invited his readers to create a sex-related definition for \"santorum\" to \"memorialize the Santorum scandal [...] by attaching his name to a sex act that would make his big, white teeth fall out of his big, empty head.\" The winning definition was \"the frothy mixture of lube and fecal matter that is sometimes the byproduct of anal sex.\" Savage set up a website to spread the term, inviting bloggers and others to link to it, which caused it to rise to the top of a Google search for Santorum's name.\n\nFollowing the \"rent boy\" allegations regarding George Rekers, who has widely promoted aversion therapy, Dan Savage, along with others including Stephen Colbert, promoted the use of the idiom \"to lift [some]one's luggage\", meaning to supply sexual pleasure to, or derive it from, one's partner. This originated from Rekers who, when outed, insisted he had hired the escort only to assist him with lifting his luggage. Rekers also claimed he \"spent a great deal of time sharing scientific information on the desirability of abandoning homosexual intercourse\" and \"shared the gospel of Jesus Christ with him in great detail\".\n\nOriginally Savage suggested that \"lifting my luggage\" refer to listening to the speaker expound on the \"desirability\" of converting oneself from homosexual to heterosexual. Later, after several political humorists started employing \"lifting your luggage\" as an implicit or explicit reference to various sexual acts, Savage suggested that \"whatever lifts your luggage\" supplant \"whatever floats your boat\" in common parlance.\n\nIn 2009, after a controversy involving the Saddleback Church, the column defined \"saddlebacking\" as \"the phenomenon of Christian teens engaging in unprotected anal sex in order to preserve their virginities\".\n\nAfter receiving criticism for use of the word \"retarded\"—considered by many to be an offensive slur against those with intellectual disabilities—Savage suggested \"leotarded\" as an alternative, because \"leotard\" rhymes with \"retard\".\n\nDan Savage coined the abbreviation \"GGG\". It stands for \"good, giving, and game\", and it means one should strive to be \"good\" in bed, \"giving\" \"equal time and equal pleasure\" to one's partner, and \"game\" \"for anything – within reason\". The term has inspired the \"How GGG Are You? Test\" on the popular Internet dating site OkCupid, and the invention of a cocktail.\n\n\"Dump the mother-fucker already\", used at a closing of a response to indicate that acting immediately to end the writer's abusive or worthless relationship is advised.\n\nA reader of Savage Love suggested the initialisation ITMFA, a take on DTMFA, meaning \"Impeach the Motherfucker Already!\" The initialisation was coined in reference to the presidency of George W. Bush in 2006, but was reintroduced in 2017 in reaction to the presidency of Donald Trump.\n\n\"Cheating piece of shit\", said of a cheater, but usually reserved for one who is chronic or abusive/passive-aggressive about it.\n\n\"How'd that happen?\", a mock-incredulous reply to those to who write in and say they had certain (often sexual) things \"happen to\" them, as if they had no part or say in the incident, when they clearly did.\n\nSavage objected to use of the term \"pussy\" as an insult, saying that vaginas were wonderful, popping out babies, and proposed \"scrotum\", plural \"scrota\", as an insult.\n\n"}
{"id": "11724224", "url": "https://en.wikipedia.org/wiki?curid=11724224", "title": "School Health Education Study", "text": "School Health Education Study\n\nThe School Health Education Study (SHES) was a crucial event in transforming health education as practiced in American public schools. It has been called, \"the most significant school health education initiative of the 1960s\" and was largely responsible for establishing the value of comprehensive health education rather than separate disease-specific units and in introducing the concept-based approach to education in general. Most health curricula developed since have followed the model set by the SHES in its School Health Curriculum Project.\n\nIn 1960 millionaire distiller and philanthropist Samuel Bronfman asked Dr. Granville Larimore, then Deputy Commissioner of the New York State Department of Health and a member of the Joint Committee on Health Problems in Education of the American Medical Association (AMA) and the National Education Association (NEA), to suggest several projects in health or education that should receive funding but were being neglected by governmental and private funders. Dr. Larimore suggested three priorities: (I) graduate medical education, (2) effectiveness of the mass media for health education, and (3) school health education. After hearing presentations on each of these three priorities, the Samuel Bronfman Foundation’s board decided to provide $200,000 for a study of the status of health education in the nation’s schools.\n\nThe Study was envisioned as an independent, two-year-long investigation, affiliated with the American Association for Health, Physical Education and Recreation (AAHPER) and the National Education Association. Bronfman sought the advice of Delbert Oberteuffer, professor at the Ohio State University and widely regarded as the leading figure in health education at that time, regarding who could best lead the study. Oberteuffer recommended one of his young OSU colleagues, Elena Sliepcevich. Dr. Sliepcevich accepted the appointment and moved to Washington, DC where the SHES leased office space on Dupont Circle in the building next door to the NEA.\n\nDuring its first year, the Study assessed the state of health education offerings in a total of 135 school systems covering 38 states and involving some 1101 individual elementary schools and 359 secondary schools. This survey remains the broadest of its type ever completed in the United States. In the second year test instruments were administered to students in grades 6, 9, and 12 of the participating schools. Of 17,634 usable answer sheets re¬turned to the researchers, a weighted sample of 2000 scores for each of the three grade levels representative of the makeup of the school sample was selected for analysis. Analysis of the results required a third year of Bronfman Foundation support and led to the conclusion that the state of health education in the nation’s public schools was \"appalling\".\n\nThe [3M] Corporation funded SHES for a further six years (1963–1969) to develop a model curriculum—the School Health Curriculum Project or SHCP. Ann E. Nolte, of Ohio State University, joined SHES as associate director of the study and a curriculum writing team was assembled, consisting of: William H. Creswell, Jr., professor of health education at the University of Illinois; Gus T. Dalis, of the Los Angeles County Schools; Edward B. Johns, professor of school health education at the University of California, Los Angeles; Marion B. Pollock, assistant professor of health education at California State College, Long Beach; Richard K. Means, professor of health education at Auburn University; and Robert D. Russell, associate professor of health education at Southern Illinois University.\n\nProf. Russell proposed as the initial point of view for the SHCP that health was a unified concept of well-being. This was expressed in the curriculum as follows, \"Health is a quality of life involving dynamic interaction and interdependence among the individual's physical well-being, his (or her) mental and emotional reactions, and the social complex in which he (or she) exists\". From this starting point, the SHCP writers identified ten key concepts. Sub concepts were then developed in the physical, mental, and social dimen¬sions for each of the ten concepts. The 31 sub concepts were each linked to behavioral objectives written at four progressive levels—grades K-3, 4-6, 7-9, and 10-12—in the cognitive, affective, and behavioral domains.\n\nThe ten concepts developed by the SHES as the basis for the SHCP were:\n\n"}
{"id": "146717", "url": "https://en.wikipedia.org/wiki?curid=146717", "title": "Social work", "text": "Social work\n\nSocial work is an academic discipline and profession that concerns itself with individuals, families, groups and communities in an effort to enhance health and social functioning and overall well-being. Social functioning refers to the way in which people perform their social roles, and the structural institutions that are provided to sustain them. Social work applies social sciences, such as sociology, psychology, political science, public health, community development, law, and economics, to engage with client systems, conduct assessments, and develop interventions to solve social and personal problems; and create social change. Social work practice is often divided into micro-work, which involves working directly with individuals or small groups; and macro-work, which involves working communities, and within social policy, to create change on a larger scale.\n\nSocial work developed in the 19th century, with roots in voluntary philanthropy and grassroots organizing. However, the act of responding to social needs have existed long before then, primarily from private charities, and religious organizations. The effects of the Industrial Revolution and the Great Depression placed pressure on social work to be a more defined discipline.\n\nSocial work is a broad profession that intersects with several disciplines. Social work organizations offer the following definitions: “Social work is a practice-based profession and an academic discipline that promotes social change and development, social cohesion, and the empowerment and liberation of people. Principles of social justice, human rights, collective responsibility and respect for diversities are central to social work. Underpinned by theories of social work, social sciences, humanities and indigenous knowledge, social work\" \"engages people and structures to address life challenges and enhance wellbeing.\" International Federation of Social Workers \"Social work is a profession concerned with helping individuals, families, groups and communities to enhance their individual and collective well-being. It aims to help people develop their skills and their ability to use their own resources and those of the community to resolve problems. Social work is concerned with individual and personal problems but also with broader social issues such as poverty, unemployment, and domestic violence.\" - Canadian Association of Social Workers Social work practice consists of the professional application of social work values, principles, and techniques to one or more of the following ends: helping people obtain tangible services; counseling and psychotherapy with individuals, families, and groups; helping communities or groups provide or improve social and health services; and participating in legislative processes. The practice of social work requires knowledge of human development and behavior; of social and economic, and cultural institutions; and of the interaction of all these factors.\"- National Association of Social Workers\"Social workers work with individuals and families to help improve outcomes in their lives. This may be helping to protect vulnerable people from harm or abuse or supporting people to live independently. Social workers support people, act as advocates and direct people to the services they may require. Social workers often work in multi-disciplinary teams alongside health and education professionals.\" - British Association of Social Workers \n\nThe practice and profession of social work has a relatively modern and scientific origin, and is generally considered to have developed out of three strands. The first was individual casework, a strategy pioneered by the Charity Organization Society in the mid-19th century, which was founded by Helen Bosanquet and Octavia Hill in London, England. Most historians identify COS as the pioneering organization of the social theory that led to the emergence of social work as a professional occupation. COS had its main focus on individual casework. The second was social administration, which included various forms of poverty relief – 'relief of paupers'. Statewide poverty relief could be said to have its roots in the English Poor Laws of the 17th century, but was first systematized through the efforts of the Charity Organization Society. The third consisted of social action – rather than engaging in the resolution of immediate individual requirements, the emphasis was placed on political action working through the community and the group to improve their social conditions and thereby alleviate poverty. This approach was developed originally by the Settlement House Movement.\n\nThis was accompanied by a less easily defined movement; the development of institutions to deal with the entire range of social problems. All had their most rapid growth during the nineteenth century, and laid the foundation basis for modern social work, both in theory and in practice.\n\nProfessional social work originated in 19th century England, and had its roots in the social and economic upheaval wrought by the Industrial Revolution, in particular the societal struggle to deal with the resultant mass urban-based poverty and its related problems. Because poverty was the main focus of early social work, it was intricately linked with the idea of charity work.\n\nOther important historical figures that shaped the growth of the social work profession are Jane Addams, who founded the Hull House in Chicago and won the Nobel Peace Prize in 1931; Mary Ellen Richmond, who wrote Social Diagnosis, one of the first social work books to incorporate law, medicine, psychiatry, psychology, and history; and William Beveridge, who created the social welfare state, framing the debate on social work within the context of social welfare prevision.\n\nSocial work is an interdisciplinary profession, meaning it draws from a number of areas, such as (but not limited to) psychology, sociology, politics, criminology, economics, ecology, education, health, law, philosophy, anthropology, and counseling, including psychotherapy. Field work is a distinctive attribution to social work pedagogy. This equips the trainee in understanding the theories and models within the field of work. Professional practitioners from multicultural aspects have their roots in this social work immersion engagements from the early 19th century in the western countries. As an example, here are some of the models and theories used within social work practice:\nAbraham Flexner in a 1915 lecture, \"Is Social Work a Profession?\", delivered at the National Conference on Charities and Corrections, examined the characteristics of a profession with reference to social work. It is not a 'single model', such as that of health, followed by medical professions such as nurses and doctors, but an integrated profession, and the likeness with medical profession is that social work requires a continued study for professional development to retain knowledge and skills that are evidence-based by practice standards. A social work professional's services lead toward the aim of providing beneficial services to individuals, dyads, families, groups, organizations and communities to achieve optimum psychosocial functioning.\n\nIts seven core functions are described by Popple and Leighninger as:\n\nSix other core values identified by the National Association of Social Workers' (NASW) Code of Ethics are:\n\n\nA historic and defining feature of social work is the profession's focus on individual well-being in a social context and the well-being of society. Social workers promote social justice and social change with and on behalf of clients. A \"client\" can be an individual, family, group, organization, or community. In the broadening scope of the modern social worker's role, some practitioners have in recent years traveled to war-torn countries to provide psychosocial assistance to families and survivors.\n\nNewer areas of social work practice involve management science. The growth of \"social work administration\" for transforming social policies into services and directing activities of an organization toward achievement of goals is a related field. Helping clients with accessing benefits such as unemployment insurance and disability benefits, to assist individuals and families in building savings and acquiring assets to improve their financial security over the long-term, to manage large operations, etc requires social workers to know financial management skills to help clients and organisation's to be financially self-sufficient.Financial social work also helps clients with low-income or low to middle-income, people who are either unbanked (do not have a banking account) or underbanked (individuals who have a bank account but tend to rely on high cost non-bank providers for their financial transactions), with better mediation with financial institutions and induction of money management skills. Another area that social workers are focusing is risk management, risk in social work is taken as Knight in 1921 defined \"If you don't even know for sure what will happen, but you know the odds, that is risk and If you don't even know the odds, that is uncertainty.\" Risk management in social work means minimising the risks while increasing potential benefits for clients by analysing the risks and benefits in duty of care or in decisions.\n\nIn the United States, according to the Substance Abuse and Mental Health Services Administration (SAMHSA), a branch of the U.S. Department of Health and Human Services, professional social workers are the largest group of mental health services providers. There are more clinically trained social workers—over 200,000—than psychiatrists, psychologists, and psychiatric nurses combined. Federal law and the National Institutes of Health recognize social work as one of five core mental health professions.\n\nExamples of fields a social worker may be employed in are poverty relief, life skills education, community development, rural development, forensics and corrections, legislation, industrial relations, project management, child protection, elder protection, women's rights, human rights, systems optimization, finance, addictions rehabilitation, child development, cross-cultural mediation, occupational safety and health, disaster management, mental health, psychosocial therapy, disabilities, etc.\n\nThe education of social workers begins with a bachelor's degree (BA, BSc, BSSW, BSW, etc.) or diploma in social work or a Bachelor of Social Services. Some countries offer postgraduate degrees in social work, such as a master's degree (MSW, MSSW, MSS, MSSA, MA, MSc, MRes, MPhil.) or doctoral studies (PhD and DSW (Doctor of Social Work)). Increasingly, graduates of social work programs pursue post-masters and post-doctoral study, including training in psychotherapy.\n\nIn the United States, social work undergraduate and master's programs are accredited by the Council on Social Work Education. A CSWE-accredited degree is required for one to become a state-licensed social worker. The CSWE even accredits online master's in social work programs in traditional and advanced standing options. In 1898, the New York Charity Organization Society, which was the Columbia University School of Social Work's earliest entity, began offering formal \"social philanthropy\" courses, marking both the beginning date for social work education in the United States, as well as the launching of professional social work.\n\nA number of countries and jurisdictions require registration or licensure of people working as social workers, and there are mandated qualifications. In other places, a professional association sets academic requirements for admission to the profession. The success of these professional bodies' efforts is demonstrated in that these same requirements are recognized by employers as necessary for employment.\n\nSocial workers have a number of professional associations that provide ethical guidance and other forms of support for their members and for social work in general. These associations may be international, continental, semi-continental, national, or regional. The main international associations are the International Federation of Social Workers (IFSW) and the International Association of Schools of Social Work (IASSW).\n\nThe largest professional social work association in the United States is the National Association of Social Workers. There also exist organizations that represent clinical social workers such as The American Association of Psychoanalysis in Clinical Social Work. AAPCSW is a national organization representing social workers who practice psychoanalytic social work and psychonalysis. There are also a number of states with Clinical Social Work Societies which represent all social workers who conduct psychotherapy from a variety of theoretical frameworks with families, groups and individuals. The Association for Community Organization and Social Administration (ACOSA) is a professional organization for social workers who practice within the community organizing, policy, and political spheres.\n\nIn the UK, the professional association is the British Association of Social Workers (BASW) with just over 18,000 members (as of August 2015).\n\nThe Code of Ethics of the US-based National Association of Social Workers provides a code for daily conduct and a set of principles rooted in 6 core values: service, social justice, dignity and worth of the person, importance of human relationships, integrity, and competence.\n\nIn the United Kingdom, just over half of social workers are employed by local authorities, and many of these are represented by UNISON, the public sector employee union. Smaller numbers are members of the Unite the Union and the GMB (trade union). The British Union of Social Work Employees (BUSWE) has been a section of the Community (trade union) since 2008.\n\nWhile at that stage not a union, the British Association of Social Workers operated a professional advice and representation service from the early 1990s. Social Work qualified staff who are also experienced in employment law and industrial relations provide the kind of representation you would expect from a trade union in the event of grievance, discipline or conduct matters specifically in respect of professional conduct or practice. However, this service depended on the good will of employers to allow the representatives to be present at these meetings, as only trade unions have the legal right and entitlement of representation in the workplace.\n\nBy 2011 several councils had realized that they did not have to permit BASW access, and those that were challenged by skilled professional representation of their staff were withdrawing permission. For this reason BASW once again took up trade union status by forming its arms length trade union section, SWU (Social Workers Union). This gives legal right to represent its members whether the employer or Trades Union Congress (TUC) recognizes SWU or not. At 2015 the TUC was still resisting SWU application for admission to congress membership and while most employers are not making formal statements of recognition until such a time as the TUC may change its policy, they are all legally required to permit SWU (BASW) representation at internal discipline hearings etc.\n\nIn 2011, a critic stated that \"novels about social work are rare,\" and as recently as 2004, another critic claimed to have difficulty finding novels featuring a main character holding a Master of Social Work degree.\n\nHowever, social workers have been the subject of many novels, including:\n\n\n"}
{"id": "34699026", "url": "https://en.wikipedia.org/wiki?curid=34699026", "title": "Stadtmuseum Gütersloh", "text": "Stadtmuseum Gütersloh\n\nThe Stadtmuseum Gütersloh (Gütersloh Town Museum) is a museum in Gütersloh, Germany, dealing with the city's history. Under the auspices of Gütersloh's association for local history it accommodates – beside exhibits to Gütersloh's local history – two exhibitions referring to the history of medicine and the industrial history. Every year about five to seven special exhibitions about local topics respectively travelling exhibitions take place in addition to these three permanent exhibitions. The medical-historic collection – the flagship of the museum – was granted a special prize of the European Museum of the Year Award in 1990. A desk of the Nobel Prize winner Robert Koch and an iron lung are some of the most important exhibits.\n\nOn 24 June 1982 Dr. Wilhelm Angenete (1890-1984) – a family doctor in Gütersloh – and his sister Else donated two real estates with buildings in the city of Gütersloh to the association for local history on condition of establishing a museum there. In 1988 the town museum Gütersloh was opened in a brick building under the responsibility of Gütersloh's association for local history. Till today the town Gütersloh participates in the cost sharing. In 1997 a neighbouring half-timbered house could be renovated in a second construction phase. In the year 2000 the museum's café was opened.\n\nThe museum area comprises five historical buildings. The exhibition about the local history can be visited in a half-timbered house, built about 1750. From 1819 and 1868 it accommodated Prussia's first state-supported primary school in Gütersloh, before the corn-dealer Angenete & Wulfhorst opened its business there. In the year 1874 this enterprise built the brick building which was used as granary. Today the exhibitions about the history of medicine and industry are shown there. Since 1984 both buildings have been put under cultural heritage management.\n\nThe museum's management and -administration as well as the museum's café are accommodated in further half-timbered houses. The museum's store-room/depot is located outside of the actual museum's estate.\n\nIn principle everything in connection with the town of Gütersloh is collected in the Stadtmuseum Gütersloh. The collections focus particularly on medicine, hygiene and health, economy and industry, media and media technology (due to the media trust Bertelsmann being domiciled in Gütersloh), toys and recreational activities. Its comprehensive inventory of collections, of which only a minor part can be exhibited due to the small available exhibition space, turns the museum into one of the largest regional museums.\n\nThe exhibition about Gütersloh's local history features artefacts from the bronze-age to modern testimonials of the digital revolution. Beside original prehistoric finds a replication of the approximately 3.500 years old, 40 cm high \"Pavenstädter Riesenbecher\" (\"Giant Beaker of Pavenstädt\" – Pavenstädt is an urban district of Gütersloh) is exhibited, one of the oldest testimonials of human settlements in Gütersloh's urban area. The former purpose of the half-timbered house is illustrated in a teacher's residence of about 1840 (Vormärz era). The exhibition about the local history mainly deals with the everyday life of families living in Gütersloh in 1868. The furnishing and basic commodities of one Protestant and one Catholic family are shown. Historical meteorological data commemorate Gütersloh's first weather station installed by the town's honorary citizen Dr. Friedrich Wilhelm Stohlmann.\n\nThe entire workshop of Gütersloh's coppersmith Thiro of the year 1900 is exhibited in the former horse stable of the half-timbered house. Three generations of the Thiro family worked with the exhibited equipment till 1977, producing – among others – pots, pans and distillation apparatus for the local distilleries.\n\nA part of the exhibition deals with the topic \"Gütersloh – Town of Patrons and Donors\". Personalities, who campaigned for the town's public welfare by donation activities, are introduced – not only because of the fact that the museum's existence is due to a donation. A prominent example is Reinhard Mohn who set up the oldest community foundation of Germany in 1996. Therefore, a bronze sculpture of Reinhard Mohn – created in 1986 by the sculptor Hubert Hartmann (1915–2006) coming from Wiedenbrück – is exhibited in this area.\n\nThe exhibition dealing with the history of medicine is of supraregional importance and was granted a special prize of the European Museum of the Year Award in 1990. In this exhibition general developments of the history of medicine (\"Medicine in ancient times, Middle Ages and modern times\") are combined with local references (practice furnishing of Dr. Angenete, well-known doctors in Gütersloh). As Germany features only rather few medical-historic museums, this permanent exhibition is a flagship and the museum's unique selling proposition – at least in the regional museum landscape.\n\nThe collection was initiated by Dr. Wilhelm Angenete, a family doctor in Gütersloh. He bequeathed not only the buildings of the museum to the association for local history, but also the equipment of his practice, as for example medical instruments, furniture, a skeleton as well as educational material which partly dated from the 1920s and 1930s. Furthermore, the association managed to achieve substantial components of a store for cosmetics and healthcare of the year 1890 which was originally furnished as pharmacy.\n\nThese exhibits formed the basis for a collection which has meanwhile be completed among others by Robert Koch’s desk, which Koch – winner of the Nobel Prize in Physiology or Medicine for his tuberculosis findings in 1905 – used during his employment as director at the Institute for Hygiene of the University in Berlin (1885–1891). Further appreciable exhibits are the furnishing of two dental practices of the years 1925 and 1955, an X-ray machine, a cystoscope from the 1920s and an iron lung. Nowadays less than a dozen of these breathing machines are presented to the public in Germany.\n\nIn 1998 the town museum also took over the practice equipment of Dr. Kurt Heinrich (1908-1998), an oculist in Gütersloh. In addition to the permanent exhibition special- and travelling exhibitions about medical-historic topics take place in the town museum.\n\nExhibits of the medical-historic collection are often made available by the museum for special exhibitions of other museums. Following the idea of \"History Marketing\" also companies, associations, practices, health insurance companies or hospitals use the collection for exhibitions on the occasion of - for example - anniversaries. The Stadtmuseum Gütersloh grants the loan of its exhibits including expert device as \"historical service\" to make additional income.\n\nThe second permanent exhibition deals with the industrial development in Germany. As companies of Gütersloh are taken as examples, it mainly focuses on the textile- and metal working industry. Apart from work benches and machines a fully functional mechanic weaving loom is exhibited. This permanent exhibition also refers to the topic \"Washing and Washing Machine\" with reference to Miele, a local manufacturer of household appliances.\n\nSpecial exhibitions either deal with local issues or feature travelling exhibitions. In case of local matters, the exhibitions concentrate on the town history including the development of industry, trade, traffic, culture, leisure time and formation. Corresponding to the focus of its collection regarding the history of medicine, exhibitions – either of the Stadtmuseum Gütersloh itself or of third parties - regularly take place in the town museum about this topic.\n\nFollowing a tradition, a toy exhibition is organized in the winter months, which attracts - according to gathered experiences – a tremendous number of visitors. The most successful exhibitions were: an exhibition showing duplications of Gyro Gearloose’s inventions, “Busy Girl – Barbie works her way up“, “Everybody’s constructing by using Lego“ and a “Käthe Kruse”-exhibition.\n\nPupils of primary schools are given the opportunity by the Stadtmuseum to become acquainted with the exhibitions in a playful and child-oriented way. Furthermore, they have the chance to get some background information of a museum. Therefore, museum rallies, guessing games, disguising actions and courses of textile manufacturing and wood working are offered. Furthermore, museum tours – particularly for children – and offers for children's birthday parties are available. A \"museum’s doctor\" and his \"medical secretary\" will explain to them the medical-historic collection. Furthermore, the Stadtmuseum Gütersloh disposes of portable wooden exhibition boxes. They contain material (for example referring to the paper manufacturing or the teaching of historical writing- and printing techniques) and are borrowed to schools for project work.\n\n"}
{"id": "3627004", "url": "https://en.wikipedia.org/wiki?curid=3627004", "title": "Sustenance", "text": "Sustenance\n\nSustenance can refer to any means of subsistence or livelihood.\n"}
{"id": "55702376", "url": "https://en.wikipedia.org/wiki?curid=55702376", "title": "Thomas Paterson Noble", "text": "Thomas Paterson Noble\n\nProf Thomas Paterson Noble FRCSE FRSE OWE (1887–1959) was a Scottish surgeon who served Prajadhipok, the King of Siam\n\nHe was born in Galashiels on 3 March 1887 in son of Alexander Noble, a chemist, and his wife Margaret Paterson. He studied Medicine at Edinburgh University graduating MB ChB in 1911 and gaining his MD in 1913. He also studied at University College London and held resident posts at Leith, Greenwich, and Queen Charlotte's Hospital.\n\nIn the First World War he served as a Lieutenant in the Royal Army Medical Corps. After the war he took a post at the Orthopaedic Hospital in Oswestry then in 1924 gained a Rockefeller Scholarship to the Mayo Clinic in America. From here (around 1925) he received a unique opportunity to work in what was then Siam (now Thailand) as Professor of Surgery at Chulalongkorn University in Bangkok. He also then became official Physician to Prajadhipok, the King of Siam.\n\nHe was awarded the Orders of the Crown and the White Elephant.\n\nIn 1927 he was elected a Fellow of the Royal Society of Edinburgh. His proposers were Sir Frederick Hobday, Spencer Mort, Francis Albert Eley Crew and Sir David Wilkie.\n\nHe left Siam during the Second World War and returned to Britain to fill necessary roles vacated by the war, becoming Surgeon in Charge of Ebbw Vale General Hospital in Wales in 1940.\n\nHe retired to Southampton soon after the end of the war once a suitable person was found to fill his role. He continued as a consultant to the Ministry of Pensions.\n\nHe died in Bournemouth on 16 December 1959.\n\nIn 1914 he married Cecilia Farmer. They had one daughter.\n\n"}
{"id": "935411", "url": "https://en.wikipedia.org/wiki?curid=935411", "title": "Transmission risks and rates", "text": "Transmission risks and rates\n\nTransmission of an infection requires three conditions:\n\nAn effective contact is defined as any kind of contact between two individuals such that, if one individual is infectious and the other susceptible, then the first individual infects the second. Whether or not a particular kind of contact will be effective depends on the infectious agent and its route of transmission.\n\nThe effective contact rate (denoted \"β\") in a given population for a given infectious disease is measured in effective contacts per unit time. This may be expressed as the total contact rate (the total number of contacts, effective or not, per unit time, denoted γ), multiplied by the risk of infection, given contact between an infectious and a susceptible individual. This risk is called the transmission risk and is denoted \"p\". Thus:\n\nThe total contact rate, γ, will generally be greater than the effective contact rate, β, since not all contacts result in infection. That is to say, \"p\" is almost always less than 1 and it can never be greater than 1, since it is effectively the probability of transmission occurring.\n\nThis relation formalises the fact that the effective contact rate depends not only on the social patterns of contact in a particular society (γ) but also on the specific types of contact and the pathology of the infectious organism (\"p\"). For example, it has been shown that a concurrent sexually transmitted infection can substantially increase the probability (\"p\") of infecting a susceptible with HIV. Therefore, one way to reduce the value of \"p\" (and hence lower HIV transmission rates) might be to treat other sexually transmitted infections.\n\nThere are a number of difficulties in using this relation. The first is that it is very difficult to measure contact rates because they vary widely between individuals and groups, and within the same group at different times. For sexually transmitted infections, large scale studies of sexual behaviour have been set up to estimate the contact rate. In developed countries for serious diseases such as AIDS or tuberculosis, contact tracing is often carried out when a patient is diagnosed (the patient and medical authorities try to inform every possible contact the patient may have made since infection). This, however, is not so much a research tool and more to alert the contacts to the possibility that they may be infected and so can seek medical treatment and avoiding passing on the disease if they have contracted it. \n\nA second consideration is that it is generally thought unethical to carry out direct experiments to establish per-contact infection risks as this would require the deliberate exposure of individuals to infectious agents. The Common Cold Unit that researched cold transmission in the UK between 1946 and 1989 was a notable exception. It is also possible to estimate the transmission risk in certain circumstances where exposures to infection have been documented, for example the rate of infection among nurses who have accidentally pricked their fingers with a needle that had previously been used with contaminated blood.\n\nA more direct assessment of transmission risks can be provided by a contact study, which is often carried out because of an outbreak (such a study was carried out during the SARS outbreak of 2002–3). The first (or primary) case within a defined group (such as a school or family) is identified and people infected by this individual (called secondary cases) are documented. If the number of susceptibles in the group is \"n\" and the number of secondary cases is \"x\", then an estimation of the transmission risk is\n\nHere, \"p\" is the same parameter as before but it has been calculated in a different way. To reflect this, it is called the secondary attack rate (it is really a risk, of course, and not a rate, but the term is still commonly used).\n\nEven if the whole group in question is susceptible, \"x\" is generally smaller than the basic reproduction number for the disease. That is defined as the number of individuals each infected individual will go on to infect themselves, in a population with no resistance to the disease. The basic reproduction number includes all secondary cases infected by a primary case, while \"x\" is only the number of secondary cases within the group in question.\n\nSecondary attack rates are useful for comparisons between vaccinated and unvaccinated groups and hence assessing the efficacy of vaccinations against the disease under inspection. However, there are inevitably complications with such contact studies. It is not always obvious which members of the group are susceptible and distinguishing between secondary and subsequent cases (for example, those infected by the secondary cases are tertiary cases and so on) can be difficult. Also, the possibility of infection from an outsider must be ignored.\n\nDespite these problems, the parameters \"p\" and β are powerful tools in the mathematical modelling of epidemics. But it should always be remembered that a model is only as good as the assumptions on which it is based and the data from which its parameters are calculated.\n\n"}
{"id": "2685377", "url": "https://en.wikipedia.org/wiki?curid=2685377", "title": "Trenton Psychiatric Hospital", "text": "Trenton Psychiatric Hospital\n\nThe Trenton Psychiatric Hospital is a state run mental hospital located in Trenton and Ewing, New Jersey. It previously operated under the name New Jersey State Hospital at Trenton and originally as the New Jersey State Lunatic Asylum.\n\nFounded by Dorothea Lynde Dix on May 15, 1848, it was the first public mental hospital in the state of New Jersey, and the first mental hospital designed on the principle of the Kirkbride Plan. The architect was the Scottish-American John Notman. \n\nUnder the Hospital's first superintendent, Dr. Horace A. Buttolph, the hospital admitted and treated 86 patients. In 1907, Dr. Henry Cotton became the medical director. Believing that infections were the key to mental illness, he had his staff remove teeth and various other body parts that might become infected from the hospital patients. Cotton's legacy of hundreds of fatalities and thousands of maimed and mutilated patients did not end with his leaving Trenton in 1930 or his death in 1933; in fact, removal of patients' teeth at the Trenton asylum was still the norm until 1960.\n\n\n"}
{"id": "47677023", "url": "https://en.wikipedia.org/wiki?curid=47677023", "title": "Underage smoking in Australia", "text": "Underage smoking in Australia\n\nUnderage smoking in Australia is still a major concern (National Tobacco Campaign). As a result, statistics have been recorded and compared from surveys completed throughout Australia, showing how the numbers of underage smokers have drastically decreased in the years between 1991 and 2013. However, adolescents are still being pressured to try smoking (whether intentionally or not) by various influences including family, peers, and advertising campaigns. The amount of advertising that is being publicized is still striking attention in adolescent’s minds. This is why tobacco smoking is still relatively popular among youth in Australia. The broadcasts promoting smoking are found to be highly influential to the whole of the targeted audience, regardless of age. However, it is youth who are being most affected. Almost all smokers start while they are young, and studies have found that nearly all first time smoking experiences take place during high school years. Generally, the younger a person is when they start smoking tobacco, the more likely the person is to use it as an adult. This is due to the addictive effects of nicotine, which have been shown to create deeper addictions with those who have smoked for longer periods of time. Substances that are commonly smoked by adolescents in Australia include cigarettes, marijuana, hookahs and electronic cigarettes.\n\nUnderage\nsmoking in Australia has taken a big turn throughout the years and has dropped\nthe percentage of adolescents smoking drastically. The Australian Institute of Health and Welfare (AIHW) conducted surveys detailing daily\nsmokers, they conducted these surveys in the years between 1991-2013. The\nsurvey in 2013 collected information from almost 24,000 and the results showed\nthat \"there has been a significant decrease in daily smokers aged 14 years\nor older in Australia, falling from 16.6% in 2007, 15.1% in 2010, to 12.8% in\n2013.\"\n\nBarola and White from the\nDrug Strategy Branch in the Australian Government Department of Health and Ageing reported that in 2011, the overall rate of current\nsmoking among Australian students aged 12 to 15 years was 6.7%. Within that\namount 4.1% were current smokers between the ages of 12 and 15, the ratio included\nmales taking up 4.4% and females 3.8%. Whereas 12.9% of 16- and 17-year-olds were\ncurrent smokers, and that worked out to be males 13.4% and females 12.3%. These\nfigures are calculated from 25,000 Australian students who took part in this\nsurvey.\n\nThe\nAIHW reported that high levels of tobacco control activities in the community\nhave contributed to the drop in smoking rates among students. These control\nactivities that the community helped instigate included anti-smoking media campaigns,\nthe increase of tobacco tax, restrictions of advertising and the sales of\ntobacco products, smoking bans in public places, and graphic health warnings on cigarette\npacks, alongside multiple more. It was noted that education and tobacco control\nmeasures are also important, so that adolescents are aware and understand the\nharms of smoking and secondhand smoke, and are therefore less likely to start\nsmoking underage.\n\nWinstanley et al. stated, \"Australian\nresearch has shown that young people living in households where English is\nspoken are more likely to smoke, than those living in households where a\nlanguage other than English is the first language.\" This puts forward the\nmatter of concern in regards to what influence this has on the children being\nimpacted. While a child is young, they are at risk of being influenced by bad\nhabits of the people who surround them. In particular family, because\nadolescents look up to their elders as role models, and if the parents,\nsiblings, and extended family are smoking around the child, the child is twice\nas likely to become a smoker. This is not in the best interest of the child, because it promotes that it is suitable for the child to start smoking,\nas family influence has the greatest impact on a child’s behaviour and choices.\n\nA bad issue as a result of this is second hand\nsmoke, British Columbia (2012), stated that people who do not smoke, and who are exposed regularly to the toxic\nchemicals being inhaled from the second-hand smoke can suffer serious, and\nlife-threatening health risks. The fact that these risks can already bring upon\nmany health issues while not physically smoking will only enhance, and become\nmore dangerous to the adolescent if found to take up smoking for themselves.\n\nAdvertising plays a substantial role in the original\nestablishment of underage smoking. The media influences general curiosity about\nthe effects of smoking, which can sway the decisions of underage smokers. This\nis because adolescents are easy targets for the tobacco industry, as they\nare influenced effortlessly to ‘try new things’. Television shows, movies, the\nInternet, and general advertising of tobacco products, all play\nhuge roles in getting young adolescents minds to wonder what smoking is like as they all\npromote that smoking is fun, healthy, and attractive. Tobacco\nadvertisements aim to display one main concept, which is the\nenjoyment that you could get out of the effects of cigarettes, but however\nignore the health risks that come from smoking cigarettes.\n\nFriends\nand social groups have a huge impact on youth smoking. What someone’s friends\ndo and say, play a huge reflection in others minds, so the desire of knowing\nwhat smoking is like for one person, can impact countless others. It is a mixture between peer pressure that encourages\nor discourages smoking, as well as a bonding mechanism among peers. Adolescents\nmay smoke because they want to belong to a particular group and have a sense of\nfitting in, whereas other adolescents may lack the skills to refuse a cigarette\noffered by a friend (peer pressure), or someone they want to get to know. Peer smoking is by far a major influential factor in adolescent\nsmoking, as there are strong desires to look cool in others eyes, and to appear\nolder and more mature to those watching. Smoking is known to be a fun hobby where a\ngroup of friends can get together and bond, a great example of this is hookah smoking. The enjoyment of\nsmoking, the sensations, and feelings which one gets from smoking is being\ntaken out of this ‘social hobby’. However, there is one major problem with this, and\nthat is, adolescents who start smoking in early teenage years don’t think much,\nor at all, about the health risks they can obtain in the near future, due to\nlong-term extended smoking.\n\nThere are two types of cigarettes, one being shredded or\nground tobacco that is wrapped in paper, or another substance that does not\ninclude tobacco and the other is manufactured\ncigarettes, which differ by having filters on one end, which are intended to ‘trap’ some of\nthe toxic chemicals contained in cigarette smoke.\nThe main ingredient in cigarettes is tobacco;\ntobacco is a green, leafy plant named nicotiana tabacum. Artificial\nflavorings and other chemicals are also added into the compound mixed in cigarettes (as seen below in \"Figure 1\").\n\nThere are over 4,000 chemicals in cigarette\nsmoke, and 43 of them are known to be carcinogenic, which is a cancer-causing\ncompound. Ingredients found in cigarettes that are carcinogenics include nicotine,\ntar, carbon monoxide, formaldehyde, ammonia, hydrogen cyanide, arsenic, and\nDDT.\n\nNicotine is a highly addictive drug, and smoke that\ncontains nicotine is inhaled into the lungs and can travel to the brain\nin just six seconds. Nicotine in small doses acts as a stimulant to the brain (when it\nreaches the bloodstream, it makes the smoker feel calm), as opposed to large\ndoses, whereas it acts as a depressant (inhibiting the flow of signals between\nnerve cells). In even larger doses, nicotine is a lethal poison, affecting the\nheart, blood vessels, and hormones.\n\nCarbon monoxide and Tar are also chemicals found in cigarettes that effect health severely. Carbon monoxide makes it harder for red blood cells to\ncarry oxygen throughout the body, and tar is a mixture of substances that together\nform a sticky mass in the lungs. Therefore, when a cigarette is smoked, the amount of tar inhaled\ninto the lungs increases. Most of the chemicals inhaled in cigarette\nsmoke stay in the lungs, so although the more smoke being inhaled is creating a better feeling, its also creating greater damage to the lungs. \n\nCannabis,\nin particular marijuana, is a common street and recreational illegal drug.\nMarijuana is made from dried leaves, flowers,\nstems, and seeds from the hemp plant, cannabis sativa. The hemp plant contains\nthe active ingredient tetra-hydro-cannabinol (THC), which is a mind-altering\nchemical that creates a high when smoked.\n\nMarijuana is\ncommonly smoked in hand-rolled cigarettes, pipes, or water pipes (bongs),\nhowever it can be used in vaporisers, turned\ninto a tea, or used as an ingredient in foods as an edible. The THC in marijuana is responsible for\nchanging how the brain works, by distorting how the mind perceives the world\nand making the heart beat faster. \nIn particular marijuana is used to heighten perception, affect mood, and feel\nrelaxed: it alters senses, sense of time, changes in mood, impaired body\nmovement (coordination), difficultly in thinking (judgment), and impaired\nmemory.\n\nWhen marijuana is being used\nas an adolescent, the chances of getting addicted\nincrease almost instantly. This is because adolescents who smoke marijuana are\ntwice as likely as adults to become addicted. Young\npeople believe that marijuana is a safe drug and it cannot be harmful because\nit is \"natural,\" however this is untrue.\nMarijuana can cause changes in the brain that impair learning, this especially\neffects adolescents as their brains have not finished developing. The drug impacts their brains heavily because it reduces\nthinking, memory, and learning functions.\nHence, why adolescents are addicted easily. Marijuana is dangerous while being\na teenager as the effects to the brain impact their overall achievements and\noutcomes during high school, which determine their future, and health.\n\n\"Young Australians (aged 14–24)\nfirst try cannabis at 16.7 years on average. 14.8% of 12–17 year olds have\ntried cannabis – it is the most commonly used illicit drug among this age group.\"\n\nLong-term health effects of marijuana include damages to the brain, heart, lungs, and reproductive\nsystem, it also increases the development of anxiety, depression, schizophrenia,\nand it can trigger acute psychotic episodes. The major long-term effects of this include cancer of the head and neck.\n\nA hookah is s a single, or\nmulti-stemmed water pipe used for vaporising, and smoking flavored tobacco,\nwhich is called shisha. The tobacco in shisha can be mixed with all sorts of flavours including mint, apple, peach, and or\nfruit heads. The shisha is heated using charcoal that releases the flavours\nwhen burnt in the water pipe, while inhaling. The smoke as result of the inhalation is passed through a\nwater basin first (often glass-based) before being inhaled and exhaled.\n\nHookah smoking is often a social event, which\nallows the smokers to spend time together and talk as they pass the pipe\naround. This form of smoking creates the higher risk of contracting a health\nrelated smoking issue, as many hours can pass by while socialising and smoking,\nit is the lengthy hours on end of smoking shisha which puts adolescents health\nin danger.\n\nHookah smoking is known to be the socially\nacceptable way to smoke tobacco, however this claim is false. Hookah smoke can\ncontain concentrations of toxins, such as carbon monoxide, nicotine, tar, and\nheavy metals. All of these toxins are as high, or higher than those that are\nassociated with cigarette smoke. This is due to the result when physically inhaling the shisha, as water in the basin does not get rid of the toxins in the shisha, it only enhances them. Several types of cancer and infectious\ndiseases are linked with smoking shisha. Health risks including: lung cancer,\ntuberculosis, aspergillus, helicobacter and Epstein-Barr virus, can be\ncontracted from the way the shisha is prepared, the smoking of the shisha, and\nthe sharing around of the mouthpiece connected to the pipe.\nElectronic cigarettes, also known as e-cigarettes,\nare small refillable devices that deliver nicotine and/or other chemicals through\na battery-powered system. The devices are\ndesigned to stimulate the act of smoking tobacco cigarettes, but do not involve\nthe physical burning of tobacco. E-cigarettes use the\nbattery power to help inhale the vapor, which can be flavoured resembling things\nsuch as fruit and candy. It is through these flavours, which makes e-cigarettes\nappealing to adolescents, although it is not warned how e-cigarettes can hook adolescents\non nicotine; which creates a lifelong nicotine addiction that could lead to the\nuse of more harmful tobacco products.\n\nElectronic cigarettes are being marketed as cheap and healthier alternatives to cigarettes, as\nwell as an option for smokers when smoking is not permitted, since they do not\nproduce tobacco smoke. They are also seen as less harmful than cigarettes, but the short and long-term health\nimpacts of using electronic cigarettes remain unknown. However, there is a lot of debate regarding their safety as the Therapeutic Goods\nAdministration stated that, \"The Australian Government is concerned about the\nuse of electronic cigarettes in Australia. The impact of wide scale use of\nthese devices on tobacco use is not known, and the outcome in the community\ncould be harmful.\" One major concern is the impact that e-cigarettes may have on the wider community,\nincluding how they can be a gateway to smoking, or to nicotine addiction to new smokers,\nparticularly amongst adolescents.\n\nSmoking harms nearly every organ in\nthe body, and adolescents who smoke have higher risks of developing health\nissues sooner in life, rather than later. Smoking regardless of age causes health\nissues including lung cancer, throat cancer, mouth cancer, heart disease, heart attacks,\nstrokes, lung diseases, diseases affecting the eyes, gums, blood vessels, bones\nand gut, and countless others.\n\nThe younger someone starts to smoke,\nthe more likely they are to be heavy users of tobacco, and therefore, the\ngreater risk they have of obtaining poor health. Smoking during adolescence\ncauses serious health problems, in regards to the respiratory and asthma-related\nsymptoms, including shortness of breath, coughing spells, phlegm, increased frequent\nheadaches, and wheezing. Smoking\nas an adolescent also impairs lung growth, and causes the early onset of lung\nfunction deterioration during late adolescence and early adulthood; this only\nbrings upon early addition to nicotine, and worse overall health.\n\nImmediate effects of smoking include\na rise in heart rate and blood pressure, shaky hands, and a drop in skin\ntemperature as blood vessels compact in the fingertips and toes. An example of\nthis is the carbon monoxide in cigarettes, it reduces the ability of blood to\ncarry oxygen, and the ability of muscle cells to take up oxygen. Adolescents\nwho smoke have higher increased stress levels than non-smokers, this is due to\nre-occurring nicotine withdrawal symptoms, as nicotine makes the heart work\nharder.\n\nThere are many\nlong-term health issues that come from the initiation of underage smoking.\nAdolescents who continue to smoke can develop complications such as: Gum\ndisease, tooth loss, infertility, impotence, chronic lung diseases, hearing\nloss, vision impairment (which can lead to blindness) and blood vessel diseases\n(which can lead to heart attacks or strokes). These are only some major health\nissues that can be caught, hence why it is important for young people to not\nfall into the trap of smoking at a young age, as it could ruin the rest of\ntheir adult life.\n\nStudents who smoke are more likely to\nfeel more negatively towards school, to miss school more often, to perform less\nwell academically, to engage in early school misbehaviour, and to drop out of\nschool at an earlier age than non-smokers. Mark Wheeler (2011), found a relationship with smoking and the brain,\nthe greater an underage child’s addiction to nicotine is, the less active the\nprefrontal cortex was, which suggests that smoking affects brain function.\n\"As the prefrontal cortex continues to develop during the critical period of adolescence, smoking may influence the trajectory of brain development and affect the function of the prefrontal cortex,\" (London, 2011).\n\nResearch shows that there is a definite link between teen substance\nabuse and how well you do in school. Ultimately this affects the way your\nbrain processes and retains information—and how you think, learn, remember,\nfocus, and concentrate. Teens who abuse\ndrugs have lower grades, a higher rate of absence from school and other\nactivities, and an increased potential for dropping out of school. Youth smoking can biologically reduce\nlearning productivity, while also reducing adolescent’s motivation to go to\nschool, where smoking is forbidden.\n\nMarijuana, for example, affects your attention,\nmemory, and ability to learn. Its effects can last for days or weeks after the\ndrug wears off. So, if a student were smoking marijuana daily, they would not\nbe functioning at their best capable ability. Therefore, students who smoke marijuana tend to\nget lower grades and are more likely to drop out of high school. With saying that, students in their last years\nof high school who drop out before graduation are more likely than their peers\nto be smokers. This\nmakes students’ chances of graduating high school with good grades and\nfurthermore attend college, or obtain a college degree less likely than\nnon-smokers in high school.\n\n"}
{"id": "7580648", "url": "https://en.wikipedia.org/wiki?curid=7580648", "title": "WHOART", "text": "WHOART\n\nThe WHO Adverse Reactions Terminology (WHOART) is a dictionary meant to serve as a basis for rational coding of adverse reaction terms. The system is maintained by the Uppsala Monitoring Centre (UMC), the World Health Organization Collaborating Centre for International Drug Monitoring. The system is no longer actively maintained.\n\n\n\n"}
{"id": "2404627", "url": "https://en.wikipedia.org/wiki?curid=2404627", "title": "Water supply and sanitation in Hong Kong", "text": "Water supply and sanitation in Hong Kong\n\nProviding an adequate water supply for Hong Kong has always been difficult because the region has few natural lakes and rivers, inadequate groundwater sources (inaccessible in most cases due to the hard granite bedrock found in most areas in the territory), a high population density, and extreme seasonable variations in rainfall. Thus about 70 percent of water demand is met by importing water from the Dongjiang River in neighbouring Guangdong province. In addition, freshwater demand is curtailed by the use of seawater for toilet flushing, using a separate distribution system.\n\nWater supply in Hong Kong initially came only from local sources, including numerous small dams built in the valleys of the territory.\n\nUntil 1964 water rationing was a constant reality for Hong Kong residents, occurring more than 300 days per year. The worst crisis occurred in 1963–64 when water was delivered only every 4 days for 4 hours each time. The territory, which was under British colonial administration, then embarked on a three-pronged approach to supply water to an increasing population. (Hong Kong's population increased from 1.7 million in 1945 to about 6 million in 1992.) The strategy involved seawater flushing, the construction of larger freshwater reservoirs in bays that used to be covered by the sea, and water imports from mainland China.\n\nIn 1955 seawater was first used to flush toilets in a pilot scheme. This was followed by installation of seawater flushing systems in all new houses and in selected districts beginning in 1957. In 1960 legislation was introduced to promote seawater flushing on a larger scale, followed by substantial investments in a separate network. However, the system was unpopular due to the need to build a separate plumbing network in each house. Seawater initially was sold, but from 1972 on it was provided for free and the costs of the system were recovered through the drinking water tariff. In 1991, about 65 percent of Hong Kong's households used seawater for flushing. By 1999, the number of conforming households had increased to 79 percent.\n\nIn 1957 construction began on the first dam that would close off a natural sea bay and create the Shek Pik Reservoir. The reservoir was built to store freshwater that previously had been \"lost to the sea\" during the rainy season. The reservoir was completed in 1963. The completion of Shek Pik reservoir was followed by the construction of two larger reservoirs of the same type. After the Plover Cove Reservoir was completed in 1968, water rationing was discontinued until 1977. With the completion of the High Island Reservoir in 1978, continuous water supply was re-established. Water rationing was renewed for the last time in 1980–81. Between 1965 and 1982 water had to be rationed seven times, often for many months with interruptions of up to 16 hours per day. To maintain Hong Kong's competitiveness, rationing was imposed only on residential users. Industry, the city's main water user, was exempted from rationing. The need for rationing was finally overcome in 1982 thanks to water imports.\n\nIn 1960 Hong Kong began importing water from outside its borders through the Dongjiang – Shenzhen (Dongshen) Water Supply Scheme. After many extensions and upgrades the current system consists of a pipeline from Qiaotou Town of Dongguan to a reservoir in Shenzhen next to Hong Kong. Water imports from the Pearl River have increased gradually from 23 million cubic meters per year (under a 1960 agreement) to 1100 million cubic meters per year (under a fifth agreement signed in 1989). Water imports thus played a crucial role in alleviating Hong Kong's water crisis, accounting for 70 percent of the territory's water supply in 1991. The People's Republic of China has never exercised the \"water weapon\" in its relationship with Hong Kong. China needed foreign exchange and between 1979 and 1991 alone Hong Kong paid China almost 4 billion Hong Kong Dollars (about US$500 million applying the 1991 exchange rate) for water imports.\n\nDesalination was a source of water in Hong Kong between 1975 and 1981. A large desalination plant was commissioned in Lok on Pai in 1975, but was decommissioned again in 1981 because its operation was more expensive than importing water from Dongjiang.\n\nThe pollution of raw water supplied to Hong Kong became an increasing concern that triggered a variety of activities designed to protect the quality of raw water. In 1998 the intake of the water pipeline was moved further upstream on the Dongjiang River where water quality was better. In 2003 an 83 km dedicated aqueduct was completed, thus reducing the vulnerability of the supply to pollution. Additionally, wastewater treatment plants were constructed in settlements in the Dongjiang basin and polluting industries were removed, thus protecting the water at the source. In 2006 a Water Supply Agreement was signed with Guangdong Province for a \"flexible\" supply of Dongjiang water. The agreement allows for less water to be withdrawn when reservoirs in Hong Kong are full, and more water to be withdrawn in times of drought, while the annual payment remains the same. Under the new agreement, Hong Kong paid fixed lump sums of HK$2,959 million, HK$3,146 million and HK$3,344 million for 2009, 2010 and 2011 respectively.\n\nIn 2003 the government of Hong Kong announced what it called a \"total water management programme\". In 2005 a study was commissioned and the results were broadly discussed. Based on the study the government reaffirmed its approach to water management, but also started new initiatives concerning leakage reduction, water conservation, greywater reuse, rainwater harvesting, as well as pilots for the reuse of reclaimed water and desalination. For example, the government plans to provide reclaimed water from Shek Wu Hui Sewage Treatment Works for consumers in Sheung Shui and Fanling for toilet flushing and other non-potable uses, as well as pilot desalination plants in Tuen Mun and Ap Lei Chau.\n\nBecause the price of imported water increased from $1 to $3 per cubic meter, the Hong Kong authorities announced in 2011 that the government would build a 50,000 cubic meter per day seawater desalination plant. The plant will allow greater resiliency against droughts that may become more severe due to climate change.\n\nHong Kong's three main sources of water are supplied from Guangdong Province; internal freshwater sources stored in reservoirs; and seawater used for flushing toilets. Dongjiang is Hong Kong's major source of water. The designed maximum capacity of the supply system is 1.1 billion cubic metres per annum. The supply contract, costing HK$2 billion a year, has helped the city's economy grow without the interruption caused by water shortages, although the payment constitutes only 0.15 percent of Hong Kong's HK$1.3 trillion gross domestic product. About one-third of Hong Kong's 1,098 square kilometres has been developed as water catchments including reservoirs behind dams on land and three 'reservoirs in the sea', the Shek Pik Reservoir, the Plover Cove Reservoir and the High Island Reservoir.\n\nAn interesting facet of the waterworks is the seawater supply system with its separate networks of distribution mains, treatment facilities for screening and disinfection, pumping stations and service reservoirs. Eighty (80) percent of the population, including nearly all housing estates in Hong Kong Island and other densely populated districts, receive sea water for flushing. Some remote districts in the New Territories and some outlying islands do not use the system. In 2010, an average of about 740,000 cubic metres of seawater was supplied each day, up from 330,000 cubic meters each day in 1990/91. Seawater is used to flush toilets and accounts for about 22 percent of total water use in 2008–09.\n\nMore than 70 percent of Hong Kong's water is used by industry and services, particularly the textile, metal-working and electronics sectors in manufacturing, hotels and restaurants in services.\n\nAll figures are in million cubic metres\n\nHong Kong's water infrastructure consists of the following water treatment plants, pumping stations and reservoirs.\n\nThe supply is fully treated by chemical coagulation, sedimentation (at most treatment works), filtration, pH value correction, chlorination and fluoridation. The water is soft in character and conforms in all respects – both chemically and bacteriologically – to standards for drinking water set by the World Health Organization. Residents often prefer to boil the water before drinking, but this is generally not necessary.\n\nThe main water treatment plants are:\n\n\nThe total storage capacity of Hong Kong's reservoirs is 586 million cubic metres. The reservoirs and their storage capacities are tabulated below:\n\nThere are a total of 67 sewage treatment facilities in Hong Kong, including 40 in Hong Kong Island, Kowloon and Outlying Islands and 27 in the New Territories. One of the largest facilities is the Sha Tin Sewage Treatment Works covering an area of 28 hectares. It was commissioned in three stages in 1982, 1986 and 2004. In 2012 a study was announced to relocate the facility to mountain caverns using compact advanced treatment systems to free up the land for housing and other uses.\n\nThe Water Supplies Department collects, stores, purifies and distributes potable water to consumers, and provides adequate new resources and installations to maintain a satisfactory standard of water supply. The department also supplies seawater for flushing toilets. The Drainage Services Department is responsible for sanitation.\n\n\n"}
