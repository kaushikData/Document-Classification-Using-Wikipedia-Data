{"id": "42952126", "url": "https://en.wikipedia.org/wiki?curid=42952126", "title": "Advanced Airborne Sensor", "text": "Advanced Airborne Sensor\n\nThe Advanced Airborne Sensor (AAS) is a multifunction radar installed on the P-8 Poseidon maritime patrol aircraft. The radar is built by Raytheon as a follow-on to their AN/APS-149 Littoral Surveillance Radar System (LSRS).\n\nThe AAS has its roots in the highly classified AN/APS-149 LSRS, which was designed to provide multi-function moving target detection and tracking and high resolution ground mapping at standoff ranges covering land, littoral, and water areas. The radar was deployed on a small number of P-3C Orions, with \"game changing\" results. Containing a double-sided AESA radar with near 360-degree coverage, it could scan, map, track, and classify targets, and do all of these tasks near simultaneously; it was reportedly sensitive enough to pick up a formation of people moving over open terrain.\n\nBuilding upon the LSRS, the AAS also has a double-sided AESA radar, which contains a moving target indicator (MTI) that can detect, classify, and track targets on land and at sea at the same time, with synthetic aperture radar (SAR) and inverse synthetic aperture radar (ISAR) for picture-like radar imagery of both inland and ocean areas at the same time; these can profile vessels from a long distance and generate fine resolution without relying on optical sensors, especially in day or night and in adverse weather conditions. Once it detects and classifies a hostile vessel, the P-8 can send targeting information to another armed platform and guide a networked weapon (e.g. Tomahawk cruise missiles, SLAM-ER, JASSM, LRASM, SDB II) to it through a data link. The AAS is in ways superior to the AN/APY-7 used on the U.S. Air Force's E-8 Joint STARS, looking both port and starboard rather than just being side-looking. Other potential missions could include detecting and tracking low flying and stealthy cruise missiles, communications relaying, and electronic warfare as a standoff platform to penetrate contested airspace, since AESA radars are capable of radar jamming, producing fake targets, frying electronic components, and even cyberwarfare.\n\n"}
{"id": "32743838", "url": "https://en.wikipedia.org/wiki?curid=32743838", "title": "Atomic-terrace low-angle shadowing", "text": "Atomic-terrace low-angle shadowing\n\nAtomic Terrace Low Angle Shadowing (\"ATLAS\") is a surface science technique which enables the growth of planar nanowire or nanodot arrays using molecular beam epitaxy on a vicinal surface. ATLAS utilises the inherent step-and-terrace structure of the surface as a template for such nanostructures. The technique involves the low angle incidence of flux material on vicinal substrates. Vicinal substrates are composed of atomic terraces separated by atomic steps. The ATLAS technique allows for the fabrication of well defined planar arrays of plasmonic nanostructures, of dimensions unachievable by lithography.\n\nA collimated beam of atoms or molecules is evaporated at an oblique angle to the substrate. This causes the steps to \"shadow\" the beam, and the molecules to be adsorbed only on the exposed parts of the steps in direct line of sight of the evaporator.\n\nThe principal attraction of the technique is its relative simplicity, as it does not involve multiple lithography steps and can be applied to metal, semiconductor or oxide surfaces alike.\n\nThe technique is a \"bottom-up\" approach and allows great control over the separation of nanostructures within the array, as well as their individual widths. The separation is controlled by the size of the atomic terraces of the substrate, which is determined by its miscut from the principal index; and the width of the nanostructures is controlled by the oblique angle of the deposition.\n\nATLAS has been shown to be a very versatile technique, with the growth of metallic, semi-conducting and magnetic nanowires and nanodots demonstrated using a variety of source materials and substrates.\n\nFigure 1(a) shows a schematic of the deposition in the \"downhill\" direction, that is, from an outer step edge to a lower terrace. The deposition angle \"β\" between the beam and surface is small (1°-3°) so that some areas of the terraces are exposed to the beam, and others are geometrically shadowed.\n\nThe deposition angle \"β\" determines the width of the nanostructures, according to the following relation:\n\nwhere \"w\" is the nanostructure width, \"a\" is the height of one step, \"α\" is the miscut angle and \"β\" is the deposition angle between the incident beam and the surface (\"α\" and \"β\" are assumed to be small and are measured in radians).\n\nFigure 1(b) shows a similar situation, but this time with the substrate rotated by 180° so that the incident beam is now in the \"uphill\" direction, and nearly parallel to the surface. In this case, the step faces provide the bonding sites and the deposited material grows along the steps, similar to the step-flow growth mechanism.\n\nIn order to grow nanowires with a width of fifteen nanometers or less, the deposition temperature for both orientations should be chosen such that the mean free path of the adatoms on the surface is limited to a few nanometers.\n\nThe ATLAS system was developed within the Applied Physics Group at the School of Physics, Trinity College, Dublin. The experimental procedure is relatively straightforward, when compared to lithography or other approaches, meaning that only standard equipment is needed.\n\nThe set-up consists of an ultrahigh vacuum chamber (base pressure in the low 10 Torr range), with the sample mounted at a large working distance (40-100 cm) from the evaporation source. This large distance provides the high collimation required for the ATLAS technique. The sample itself is mounted on a rotation stage and can be tilted through 200° with a precision of ±0.5°.\n\nThe substrate can be heated during deposition by either passing direct current through the sample for semiconductors or by driving current through a separate heating foil underneath the substrate for insulating oxides.\n\nThe capabilities of the system were first tested by growing arrays of 10-30 nm wide metallic nanowires on two types of vicinal substrates, step-bunched Si(111) and α-AlO(0001). Deposition of Au and Ag onto these substrates yields arrays of wires with a width and height of 15 nm and 2 nm, and separated by approximately 30 nm.\n\nSince its introduction in 2008, ATLAS has been demonstrated as a simple technique to produce nanowires of a variety of materials down to a width of 15 nm and thickness of 2 nm, on several stepped substrates.\nAlthough ATLAS is a versatile technique, some limitations do exist. The initial growth of the nanowires is nucleated on certain preferential adsorption sites. This can form epitaxial seeds, which grow independently of each other, until they meet, which forms an overall polycrystalline wire. This polycrystallinity can affect the stability of the wire when exposed to air, and can increase the resistance due to its defective nature. It is an ongoing topic of research to increase the epitaxiality of nanowires by lattice matching, or increasing initial mobility through heating of the substrate.\n\nDespite these limitations, ATLAS's results of a 15 nm width is approximately a five-fold reduction in size compared to other shallow-angle techniques.\n"}
{"id": "34164585", "url": "https://en.wikipedia.org/wiki?curid=34164585", "title": "Construction communication", "text": "Construction communication\n\nConstruction communication, within an organizational context, is to convey an instruction to influence the actions/behaviors of others, or may involve an exchange of, or request for information during a construction project.\n\nCommunication usually involves the transfer of information, a generic term that embraces meaning such as knowledge, processed data, skills and technology.\n\nCommunication within project-based environments presents special challenges. This is especially true within the construction industry, where interaction tends to be characterised by unfamiliar groups of people coming together for short periods before disbanding to work on other endeavours.\n\nPer M.E.L. Hoezen, the author of \"The problem of communication in construction.\"\nThe efficiency and effectiveness of the construction process strongly depend on the quality of\ncommunication. In literature four reasons are mentioned why improvements in communication are\nneeded. The first reason is that an improvement in the communication within the building team, in project teams and between project manager and contractors, could reduce failure. Second, more open communication at all levels could lead to innovations and better technical solutions. Third, communication improvements in early phases of projects would positively influence the quality as perceived by all stakeholders involved. Finally, improved communication during the briefing might lead to better decision making, for example less haste in moving to solutions and better ways of looking at the requirements first.\n\nCommunication is essential to all business activities; it enables an organization, and is an integral part of the construction process. Beyond the argument, any improvement in communication can improve an organization's operating effectiveness. Good communication within an organization and between organizations contributing to the construction project can improve motivation levels and improve the processes. Conversely, inadequate communication can result in a demotivated workforce and lead to problems in construction.\n\nConstruction projects are complex and risky, requiring the active participation of all contributors. Co-operation and co-ordination of activities through interpersonal and group communication are essential in ensuring the project is completed successfully. Poor communication, lack of consultation and inadequate feedback are to be found as the root cause of defects in many constructed works. Poor co-ordination and communication of design information lead to design problems that cause design errors. Communication is the one aspect of the management of projects that pervades all others.\n\nGiven that construction is such a fragmented, dynamic and disparate sector, the challenges of communicating effectively are greater than in most other production environments. Contractually driven relationships, conflict and a lack of mutual respect and trust, all combine to hinder open communication and render the role of the project manager extremely demanding and problematic. Nevertheless, addressing communication in the industry can be seen as a principal enabler for improving the industry in the future.\n\nSince the early 1940s, literature on communication in construction has appeared, mainly based on the situation in the UK.\n\nMany problems concerning communication have been reported, with a focus on intra-supplier communication within the construction sector; demand-supply communication during the design phase; and communication between and within single demand and supply side parties, during whole the construction process.\n\nWith the globalization of the construction industry, emerging issues in construction communication in international contexts, such as problem-solving in international projects, have started to receive more attention.\n\n"}
{"id": "22739594", "url": "https://en.wikipedia.org/wiki?curid=22739594", "title": "Cryogenic rocket engine", "text": "Cryogenic rocket engine\n\nA cryogenic rocket engine is a rocket engine that uses a cryogenic fuel or oxidizer, that is, its fuel or oxidizer (or both) are gases liquefied and stored at very low temperatures. Notably, these engines were one of the main factors of NASA's success in reaching the Moon by the Saturn V rocket.\n\nDuring World War II, when powerful rocket engines were first considered by the German, American and Soviet engineers independently, all discovered that rocket engines need high mass flow rate of both oxidizer and fuel to generate a sufficient thrust. At that time oxygen and low molecular weight hydrocarbons were used as oxidizer and fuel pair. At room temperature and pressure, both are in gaseous state. Hypothetically, if propellants had been stored as pressurized gases, the size and mass of fuel tanks themselves would severely decrease rocket efficiency. Therefore, to get the required mass flow rate, the only option was to cool the propellants down to cryogenic temperatures (below −183 °C [90 K], −253 °C [20 K]), converting them to liquid form. Hence, all cryogenic rocket engines are also, by definition, either liquid-propellant rocket engines or hybrid rocket engines.\n\nVarious cryogenic fuel-oxidizer combinations have been tried, but the combination of liquid hydrogen (LH2) fuel and the liquid oxygen (LOX) oxidizer is one of the most widely used. Both components are easily and cheaply available, and when burned have one of the highest enthalpy releases by combustion, producing specific impulse up to 450 s (effective exhaust velocity 4.4 km/s).\n\nThe major components of a cryogenic rocket engine are the combustion chamber (thrust chamber), pyrotechnic initiator, fuel injector, fuel cryopumps, oxidizer cryopumps, gas turbine, cryo valves, regulators, the fuel tanks, and rocket engine nozzle. In terms of feeding propellants to the combustion chamber, cryogenic rocket engines (or, generally, all liquid-propellant engines) are either pressure-fed or pump-fed, and pump-fed engines work in either a gas-generator cycle, a staged-combustion cycle, or an expander cycle.\n\nThe cryopumps are always turbopumps powered by a flow of fuel through gas turbines. Looking through this aspect, engines can be differentiated into a main flow or a bypass flow configuration. In the main flow design, all the pumped fuel is fed through the gas turbines, and in the end injected to the combustion chamber. In the bypass configuration, the fuel flow is split; the main part goes directly to the combustion chamber to generate thrust, while only a small amount of the fuel goes to the turbine.\n\nCurrently, six countries have successfully developed and deployed cryogenic rocket engines:\n\n"}
{"id": "181431", "url": "https://en.wikipedia.org/wiki?curid=181431", "title": "Delia Derbyshire", "text": "Delia Derbyshire\n\nDelia Ann Derbyshire (5 May 1937 – 3 July 2001) was an English musician and composer of electronic music. She is best known for her pioneering work with the BBC Radiophonic Workshop during the 1960s, particularly her popular electronic arrangement of the theme music to the British science-fiction television series \"Doctor Who\". She has been referred to as \"the unsung heroine of British electronic music.\"\n\nDerbyshire was born in Coventry, daughter of Emma (née Dawson) and Edward Derbyshire. of Cedars Avenue, Coundon, Coventry. Her father was a sheet-metal worker. She had one sibling, a sister, who died young. Her father died in 1965 and her mother in 1994.\n\nDuring the Second World War, immediately after the Coventry Blitz in 1940, she was moved to Preston, Lancashire for safety. Her parents had moved from there originally and most of her surviving relatives still live in the area. She was very bright and, by the age of four, was teaching others in her class to read and write in primary school, but said \"The radio was my education\". Her parents bought her a piano when she was eight years old. Educated at Barr's Hill Grammar School from 1948 to 1956, she was accepted at both Oxford and Cambridge, \"quite something for a working class girl in the 'fifties, where only one in 10 [students] were female\", winning a scholarship to study mathematics at Girton College, Cambridge but, apart from some success in the mathematical theory of electricity, she claims she did badly. After one year at Cambridge she switched to music, graduating in 1959 with a BA in mathematics and music, having specialised in medieval and modern music history. Her other principal qualification was LRAM in pianoforte.\n\nShe approached the careers office at the university and told them she was interested in \"sound, music and acoustics, to which they recommended a career in either deaf aids or depth sounding\". Then she applied for a position at Decca Records, only to be told that the company did not employ women in their recording studios. Instead, she took positions at the UN in Geneva, from June to September, teaching piano to the children of the British Consul-General and mathematics to the children of Canadian and South American diplomats. Then from September to December, she worked as an assistant to Gerald G. Gross, Head of Plenipotentiary and General Administrative Radio Conferences at the International Telecommunications Union. She returned to Coventry and from January to April 1960 taught general subjects in a primary school there. Then she went to London where from May to October she was an assistant in the promotion department of music publishers Boosey & Hawkes.\n\nIn November 1960, she joined the BBC as a trainee assistant studio manager and worked on \"Record Review\", a magazine programme where critics reviewed classical music recordings. She said: \"Some people thought I had a kind of second sight. One of the music critics would say, \"I don't know where it is, but it's where the trombones come in\" and I'd hold it up to the light and see the trombones and put the needle down exactly where it was. And they thought it was magic.\" She then heard about the Radiophonic Workshop and decided that was where she wanted to work. This was received with some puzzlement by the heads in Central Programme Operation because people were usually \"assigned\" to the Radiophonic Workshop. But in April 1962 she was indeed assigned there in Maida Vale, where for eleven years she would create music and sound for almost 200 radio and television programmes.\n\nIn August 1962 she assisted composer Luciano Berio at a two-week summer school at Dartington Hall, for which she borrowed several dozen items of equipment from the BBC. One of her first works, and the most widely known, was her 1963 electronic realization of a score by Ron Grainer for the theme tune of the \"Doctor Who\" series, one of the first television themes to be created and produced by entirely electronic means.\nWhen Grainer first heard it, he was so amazed by her rendering of his theme that he asked \"Did I really write this?\" to which Derbyshire replied \"Most of it\". Grainer attempted to get her a co-composer credit, but the attempt was prevented by the BBC bureaucracy, which then preferred to keep the members of the workshop anonymous. She would not be credited on-screen for her work until \"Doctor Who\"'s 50th anniversary special, \"The Day of the Doctor\". Derbyshire's original arrangement served as Doctor Who's main theme for its first seventeen seasons, from 1963-80. The theme was reworked over the years, to her horror, and the version that had her \"stamp of approval\" is her original one. Delia also composed some of the incidental music used in the show, including \"Blue Veils and Golden Sands\" and \"The Delian Mode\".\n\nIn 1964–65 she collaborated with the British artist and playwright Barry Bermange for the BBC's Third Programme to produce four \"Inventions for Radio\", a collage of people describing their dreams, set to a background of electronic sound.\n\nIn 1966, while still working at the BBC, Derbyshire with fellow Radiophonic Workshop member Brian Hodgson and EMS founder Peter Zinovieff set up Unit Delta Plus, an organisation which they intended to use to create and promote electronic music. Based in a studio in Zinovieff's townhouse at 49 Deodar Road in Putney, they exhibited their music at a few experimental and electronic music festivals, including the 1966 \"The Million Volt Light and Sound Rave\" at which The Beatles' \"Carnival of Light\" had its only public playing.\n\nIn 1966, she recorded a demo with Anthony Newley entitled \"Moogies Bloogies\", although as Newley moved to the United States, the song was never released. After a troubled performance at the Royal College of Art, in 1967, the unit disbanded.\n\nIn the late sixties, she again worked with Hodgson in setting up the Kaleidophon studio at 281–283 Camden High Street in Camden Town with fellow electronic musician David Vorhaus. The studio produced electronic music for various London theatres and in 1968 the three used it to produce their first album as the band White Noise. Their debut, \"An Electric Storm\", is now considered an important and influential album in the development of electronic music. Derbyshire and Hodgson left the group subsequently, and future White Noise albums were solo Vorhaus projects.\n\nThe trio, using pseudonyms, also contributed to the Standard Music Library. Many of these recordings, including compositions by Derbyshire using the name \"Li De la Russe\" (from an anagram-esque use of the letters in \"Delia\" and a reference to her auburn hair) were later used on the seventies ITV science fiction rivals to \"Doctor Who\": \"The Tomorrow People\" and \"Timeslip\".\n\nIn 1967, she assisted Guy Woolfenden with his electronic score for Peter Hall's production of \"Macbeth\" with the Royal Shakespeare Company. The two composers also contributed the music to Hall's film \"Work Is a Four-Letter Word\" (1968). Her other work during this period included taking part in a performance of electronic music at The Roundhouse, which also featured work by Paul McCartney, the score for an ICI-sponsored student fashion show and the sounds for Anthony Roland's award-winning film of Pamela Bone's photography, entitled \"Circle of Light\". She composed a score for Yoko Ono's short film \"Wrapping Event\", but no known copy of the film with the soundtrack is known to exist.\n\nIn 1973, she left the BBC and worked a brief stint at Hodgson's Electrophon studio during which time she contributed to the soundtrack to the film \"The Legend of Hell House\".\n\nThe studios Electrophon and Kaleidophon were named after early electrical musical instruments made by Jörg Mager in pre-war Germany.\n\nIn 1975 she stopped producing music. Her final works were two soundtracks for video pioneers Madelon Hooykaas and Elsa Stansfield on their short films \"Een Van Die Dagen (\"One Of These Days\")\" in 1973 and \"Overbruggen (\"About Bridges\")\" in 1975.\n\nAfter her music career, Derbyshire worked as a radio operator for the laying of a British Gas pipeline, in an art gallery and in a bookshop. In late 1974 she married David Hunter from Haltwhistle in Northumberland, the labourer son of a miner in an attempt to gain local acceptance; the relationship was brief and disastrous although she never divorced. She also frequented the gallery space of Chinese artist Li Yuan-chia at his stone farmhouse in Cumbria. In 1978 she returned to London and met Clive Blackburn. In January 1980 she bought a house in Northampton where, four months later, Blackburn joined her. He remained her partner for the rest of her life, though at one point they lived separately. According to Blackburn, \"in private, she never stopped writing music either. She simply refused to compromise her integrity in any way. And ultimately, she couldn't cope. She just burnt herself out. An obsessive need for perfection destroyed her.\"\n\nIn 2001 she returned to music, providing sounds used as source material by Pete Kember on \"Sychrondipity Machine (Taken from an Unfinished Dream)\", a 55-second track for the compilation \"Grain: A Compilation of 99 Short Tracks\", released by Dot Dot Dot Music in 2001. In the liner notes, she is credited with \"liquid paper sounds generated using fourier synthesis of sound based on photo/pixel info (B2wav - bitmap to sound programme).\" The track was released posthumously and dedicated to her. \n\nDerbyshire's later life was chaotic due to chronic alcoholism; she died of renal failure, aged 64, in July 2001.\n\nAfter Derbyshire's death, 267 reel-to-reel tapes and a box of a thousand papers were found in her attic. These were entrusted to Mark Ayres of the BBC and in 2007 were given on permanent loan to the University of Manchester. Almost all the tapes were digitised in 2007 by Louis Niebur and David Butler, but none of the music has been published due to copyright complications. In 2010, the University acquired Derbyshire's childhood collection of papers and artefacts from Andi Wolf. This collection is accessible at the John Rylands Library in Manchester.\n\nIn 2002, BBC Radio 4 broadcast a radio play entitled as part of its \"Afternoon Play\" strand, telling the story of Derbyshire and her pioneering musical work. The play starred actress Sophie Thompson as Derbyshire and was written by Martyn Wade.\n\nIn October 2004 the Tron Theatre, Glasgow hosted Standing Wave, a play written by Nicola McCartney, score by Pippa Murphy. This was produced by Reeling and Writhing, directed by Katherine Morley.\n\nIn 2009, Canadian filmmaker Kara Blake released \"The Delian Mode\", a short documentary film about Derbyshire. The film won the Genie Award for Best Short Documentary Film in 2010. \n\nIn 2013 the BBC showed a television docudrama depicting the creation and early days of \"Doctor Who\" in 1963, called \"An Adventure in Space and Time\", as part of the celebrations for the programme's fiftieth anniversary. Derbyshire appeared as a character in it, portrayed by actress Sarah Winter.\n\nEpisode 5 \"Derbyshire\" of the BBC children's science TV programme \"Absolute Genius with Dick & Dom\" is an exploration of Derbyshire's creation of the \"Doctor Who\" theme recording using her techniques on equipment archived from the Radiophonic Workshop.\n\nCoventry-based theatre company Noctium Theatre produced a play named Hymns for Robots about Derbyshire's working life, which played at the 2018 Edinburgh Fringe festival.\n\nHer hometown Coventry named a street after her in November 2016, the 'Derbyshire Way'.\n\nA blue plaque was unveiled at Derbyshire's former home of 104 Cedars Avenue, Coventry, on 15 June 2017 as part of a BBC initiative celebrating important musicians and venues. The ceremony was performed by former \"Doctor Who\" actors Colin Baker and Nicola Bryant along with BBC Coventry & Warwickshire presenter Vic Minett.\n\nOn 20 November 2017 Derbyshire was awarded a posthumous honorary doctorate for her pioneering contributions to electronic music.\n\n\n\n"}
{"id": "46255716", "url": "https://en.wikipedia.org/wiki?curid=46255716", "title": "Fossil fuel divestment", "text": "Fossil fuel divestment\n\nFossil fuel divestment or fossil fuel divestment and investment in climate solutions is the removal of investment assets including stocks, bonds, and investment funds from companies involved in extracting fossil fuels, in an attempt to reduce climate change by tackling its ultimate causes.\n\nNumerous groups advocate fossil fuel divestment, which in 2015 was reportedly the fastest growing divestment movement in history. Beginning on campuses in The United States in 2010 with students urging their administrations to turn investments in the fossil fuel industry into investments in clean energy and communities most impacted by climate change, the movement soon spread across the globe. By December 2016, a total of 688 institutions and over 58,000 individuals representing $5.5 trillion in assets worldwide had been divested from fossil fuels.\n\nFossil fuel divestment aims to reduce carbon emissions by accelerating the adoption of renewable energy through the stigmatisation of fossil fuel companies. This includes putting public pressure on companies that are currently involved in fossil fuel extraction to invest in renewable energy.\n\nThe Intergovernmental Panel on Climate Change found that all future carbon dioxide emissions must be less than 1,000 gigatonnes to provide a 66% chance of avoiding dangerous climate change; this figure includes all sources of carbon emissions. To avoid dangerous climate change, only 33% of known extractable fossil fuel of known reserves can be used; this carbon budget can also be depleted by an increase in other carbon emission sources such as deforestation and cement production. It is claimed that, if other carbon emissions increase significantly, then only 10% of the fossil fuel reserves can be used to stay within projected safe limits.\n\nFurthermore, according to the US Environmental Protection Agency, Earth's average temperature has risen by 1.4°F over the past century, and is predicted to rise another 2° to 11.5° over the next hundred years with continued carbon emission rates. This rise in temperature would far pass the level of warming that scientists have deemed safe to support life on earth.\n\nThe \"Toronto Principle\" is a fossil fuel divestment strategy, which puts into action the aims set forth at the Paris Agreement in 2015. It was first coined by Benjamin A. Franta, in an article in the Harvard Crimson, as a reference to the University of Toronto’s fossil fuel divestment process.\n\nAfter 350.org submitted a petition for divestment on 6 March 2014, President Gertler established an \"ad hoc\" Advisory Committee on Divestment from Fossil Fuels. In December 2015, the Committee released a report with several recommendations. Foremost, they argued that \"targeted and principled divestment from companies in the fossil fuels industry that meet certain criteria...should be an important part of the University of Toronto’s response to the challenges of climate change.\" However, the report went further, and allied itself with the Paris Agreement. It recommended that the university divest from companies that “blatantly disregard the international effort to limit the rise in average global temperatures to not more than one and a half degrees Celsius above pre-industrial averages by 2050...These are fossil fuels companies whose actions are irreconcilable with achieving internationally agreed goals.\"\n\nFranta identified this response as the Toronto Principle, which, as he argues, \"aligns rhetoric and action. It suggests that it is all institutions’ responsibility to give life to the Paris agreement. Harvard could adopt this Toronto principle, too, and the world would be better for it.\" Franta also identified how the Toronto Principle would be put into practice, which includes \"moving investments away from coal companies and coal-fired power plants, companies seeking non-conventional or aggressive fossil fuel development (such as oil from the Arctic or tar sands), and possibly also companies that distort public policies or deceive the public on climate. At present, these activities are incompatible with the agreement in Paris.\" In adhering to the Toronto Principle, Franta argues that leading institutions can use their status and power to meaningfully respond to the challenge of climate change, and act based on the goals at the Paris Agreement.\n\nStranded assets, which are known in relation to fossil fuel companies as the carbon bubble, occur when the reserves of fossil fuel companies are deemed environmentally unsustainable and so unusable and so must be written off. Currently the price of fossil fuels companies' shares is calculated under the assumption that all of the companies' fossil fuel reserves will be consumed, and so the true costs of carbon dioxide in intensifying global warming is not taken into account in a company's stock market valuation.\n\nIn 2013 a study by HSBC found that between 40% and 60% of the market value of BP, Royal Dutch Shell and other European fossil fuel companies could be wiped out because of stranded assets caused by carbon emission regulation. Bank of England governor Mark Carney, speaking at the 2015 World Bank seminar, has stated: \"The vast majority of reserves are unburnable\" if global temperature rises are to be limited to below 2°C.\n\nIn June 2014, the International Energy Agency released an independent analysis on the effect of carbon emissions controls. This estimated that $300 billion in fossil-fuel investments would be stranded by 2035 if cuts in carbon emissions are adopted so that the global mean surface temperature increases by no more than 2°C.\n\nA report by the Carbon Tracker Initiative found that between 2010 and 2015 the US coal sector had lost 76% of its value including the closure of 200 mines. It found that Peabody Energy, the world's largest private coal mining company, had lost 80% of its share price over this time. This was attributed to Environmental Protection Agency regulations and competition from shale gas.\n\nIn 2013, fossil fuel companies invested $670billion in exploration of new oil and gas resources.\n\nA 2015 report studied 20 fossil fuel companies and found that, while highly profitable, the hidden economic cost to society was also large. The report spans the period 2008–2012 and notes that: \"for all companies and all years, the economic cost to society of their emissions was greater than their after‐tax profit, with the single exception of ExxonMobil in 2008.\" Pure coal companies fare even worse: \"the economic cost to society exceeds total revenue (employment, taxes, supply purchases, and indirect employment) in all years, with this cost varying between nearly $2 and nearly $9 per $1 of revenue.\" The paper suggests:\nThis hidden or externalised cost is an implicit subsidy and accordingly represents a risk to those companies. There is a reasonable chance that society will act to either reduce this societal cost by regulating against fossil fuel use or recover it by imposing carbon prices. Investors are increasingly focused on this risk and seeking to understand and manage it.\"\nSimilarly, in 2014, financial analyst firm Kepler Cheuvreux projected $28 trillion in lost value for fossil fuel companies under a regulatory scenario that targets 450 parts per million of atmospheric .\n\nCompetition from renewable energy sources may lead to the loss of value of fossil fuel companies due to their inability to compete commercially with the renewable energy sources. In some cases this has already happened. Deutsche Bank predicts that 80% of the global electricity market will have reached grid parity for solar electricity generation by the end of 2017. In 2012, 67% of the world's electricity generation was produced from fossil fuels.\n\nStanwell Corporation, an electricity generator owned by the Government of Queensland made a loss in 2013 from its 4,000MW of coal and gas fired generation capacity. The company attributed this loss to the expansion of rooftop solar generation which reduced the price of electricity during the day; on some days the price (usually AUD$40–50/MWh) was almost zero. The Australian Government and Bloomberg New Energy Finance forecast the production of energy by rooftop solar to rise sixfold between 2014 and 2024.\n\nUnstable fossil fuel prices has made investment in fossil fuel extraction a more risky investment opportunity. West Texas Intermediate crude oil fell in value from $107 per barrel in June 2014 to $50 per barrel in January 2015. Goldman Sachs stated in January 2015 that, if oil were to stabilize at $70 per barrel, $1 trillion of planned oilfield investments would not be profitable.\n\nA study by the Smith School of Enterprise and the Environment at the University of Oxford found that the stigmatisation of fossil fuel companies caused by divestment can \"materially increase the uncertainty surrounding the future cash flows of fossil-fuel companies.\" That, in turn, \"can lead to a permanent compression in the trading multiples – e.g., the share price to earnings (P/E) ratio of a target company.\"\n\nThe study also says that:\nAccording to a 2013 study by the Aperio Group, the economic risks of disinvestment from fossil fuel companies in the Russell 3000 Index are \"statistically irrelevant\".\n\nIn November 2014, a group of seven undergraduate, graduate, and law students filed a lawsuit at the Suffolk County Superior Court against the president and fellows of Harvard College and others for \"mismanagement of charitable funds\" and \"intentional investment in abnormally dangerous activities\" in relation to Harvard's investments in fossil-fuel companies. In March 2015, the superior court granted Harvard's motion to dismiss. The superior judge wrote: \"Plaintiffs have brought their advocacy, fervent and articulate and admirable as it is, to a forum that cannot grant the relief they seek.\"\n\nIn October 2014, Exxon Mobil stated that the fossil-fuel divestment was \"out of step with reality\" and that \"to not use fossil fuels is tantamount to not using energy at all, and that's not feasible.\"\n\nIn March 2014, John Felmy, the chief economist of the American Petroleum Institute, stated that the movement to divest from fossil-fuel companies \"truly disgusts me\" and stated that academics and campaigners who support divestment are misinformed, uninformed or liars. Felmy particularly criticized the environmentalist and author Bill McKibben.\n\nThe World Coal Association has pointed out that divesting from the fossil fuel industry does not necessarily result in a reduction of demand for fossil fuels, rather it would result in environmentally conscious investors losing influence over the operation of those companies. In fact, coal has been the fastest growing energy source over the last decade and is an important raw material for steel and cement in developing countries.\n\nFrom half a dozen college campuses in 2011, calling on their administrations to divest endowments from coal and other fossil fuels and invest in clean energy and \"just transition\" strategies to empower those most impacted by environmental degradation and climate change, the campaign had spread to an estimated 50 campuses in spring 2012. By September 2014, 181 institutions and 656 individuals had committed to divest over $50 billion. One year later, by September 2015, the numbers had grown to 436 institutions and 2,040 individuals across 43 countries, representing $2.6 trillion in assets, of which 56% were based on the commitment of pension funds and 37% of private companies. By April 2016, already 515 institutions had joined the pledge, of which 27% faith-based groups, 24% foundations, 13% governmental organisations, 13% pension funds and 12% colleges, universities and schools, representing, together with the individual investors, a total of $3.4 trillion in assets.\n\nThe divestment campaign at the Australian National University is one of the longest running in the world and, while it has not yet achieved full fossil fuel divestment, it has had substantial wins, most notably in 2011 and 2014.\n\nFossil Free ANU formed out of the ANU Environment Collective (EC), a consensus-based and non-hierarchical group of students affiliated with the Australian Student Environment Network, when students were notified in 2011 by campaigners at the Northern Rivers, NSW that ANU was the 12th largest shareholders in the coal seam gas company Metgasco. Following student protests, including an event called 'ANU Gets Fracked' that saw students erect a mock gas rig in Union Court, the ANU Council announced in October 2013 that it would divest from Metgasco, citing student concerns and the fact that the Australian Ethical Investment did not approve of them. Tom Stayner, an activist from the EC, stated in the ANU student paper Woroni that: \"He took some convincing, but the Vice Chancellor is showing leadership on this urgent issue.\"\n\nHowever, student concerns were again raised in 2012 when it was revealed that the ANU had only reduced its holding in Metgasco from over 4 million shares in 2011 to 2.5 million in 2012. In 2013, Tom Swann filed a FOI request to the ANU requesting all \"documents created during 2012, which refer to the University's purchase, sale or ownership of shares in any company which generates revenue from oil, coal, gas, or uranium.\" These documents revealed that ANU had substantial holdings in major fossil fuel companies and had been buying shares in Santos while selling shares in Metgasco. Students lobbying and public pressure led the ANU Council to implement a Socially Responsible Investment Policy (SRI) in late 2013 modelled on Stanford University, which aims to \"avoid investment opportunities considered to be likely to cause substantial social injury.\"\n\nIn 2014, students from Fossil Free ANU organised the first student-initiated referendum at the ANU and in elections in September more than 82 per cent of students voted in favour of the ANU divesting from fossil fuels in what was the highest turnout in a student election at the university in more than a decade. In October 2014, the ANU Council announced that it would divest from seven companies, two of which, Santos and Oil Search, performed poorly in an independent review undertaken by the Centre for Australian Ethical Research. This decision provoked a month-long controversy with the \"Australian Financial Review\" publishing over 53 stories criticising the decision including 12 front pages attacking the ANU, with its editor-in-chief, Michael Stutchbury, prouncing the decision to be as \"disingenuous\" as banning the burqa. These attacks, which \"The Canberra Times\" editorial described as \"verging on hysterical\" was joined by members of the cabinet of the Abbott Government, with the Treasurer Joe Hockey stating that the ANU Council is \"removed from the reality of what is helping to drive the Australian economy and create more employment,\" Education Minister Christopher Pyne calling it \"bizarre\" and Prime Minister Tony Abbott calling it \"stupid.\" In response, Louis Klee, an activist from Fossil Free ANU, wrote in \"The Age\" that the reaction demonstrated not just \"the complicity of state power with the mining industry,\" but also that the citizens of this country are powerful voices in the debate over climate justice. It demonstrates that they are, ultimately, voices speaking with growing eloquence, urgency and authority for one thing: action to address global climate change.\n\nVice-Chancellor of ANU Ian Young stood by the decision, stating: On divestment, it is clear we were in the right and played a truly national and international leadership role... [W]e seem to have played a major role in a movement which now seems unstoppable.Meeting with students in the wake of the furore of the decision, Ian Young told activists from Fossil Free ANU that while he initially thought divestment was \"a sideshow,\" the reaction of the mining companies revealed that students \"were right all along.\"\n\nANU still has holdings in fossil fuel companies and Fossil Free ANU continues to campaign for ANU to 'Divest the Rest'.\n\n350.org is an international environmental organization encouraging citizens to action with the belief that publicizing the increasing levels of carbon dioxide will pressure world leaders to address climate change and to reduce levels from 400 parts per million to 350 parts per million. As part of its global policy, 350.org launched their Go Fossil Free: Divest from Fossil Fuels! campaign in 2012, which campaign calls for colleges and universities, as well as cities, religious institutions, and pension funds to withdraw their investments from fossil fuel companies.\n\nDivest-Invest Philanthropy is an international platform for institutions committed to fossil fuel divestment.\n\nIn March 2015, \"The Guardian\" launched the 'Keep it in the ground' campaign encouraging the Wellcome Trust and the Bill & Melinda Gates Foundation to divest from fossil fuel companies in which the foundation has a minimum of $1.4 billion invested. The Wellcome Trust has £450m of investments in Shell, BHP Billiton, Rio Tinto and BP. The petition had received over 140,000 signatures by the end of March 2015.\n\nDivest Harvard is an organization at Harvard University that seeks to compel the university to divest from fossil fuel companies. The group was founded in 2012 by students at Harvard College. In November 2012, a referendum on divestment passed at Harvard College with 72% support, followed by a similar referendum at the Harvard Law School in May 2013, which passed with 67% support. During this time, representatives from Divest Harvard began meeting with members of Harvard University's governing body, the Harvard Corporation, but the meetings were described as unproductive.\n\nIn October 2013, the Harvard Corporation formally announced that the university would not consider a policy of divestment. Following this, Divest Harvard began organizing rallies, teach-ins, and debates on divestment. In March 2014, students from Divest Harvard recorded an impromptu exchange on divestment with Harvard President Drew Gilpin Faust, during which Faust appeared to claim that fossil fuel companies do not block efforts to counteract climate change. The video has since become a source of controversy.\n\nIn April 2014, a group of nearly 100 Harvard faculty released an open letter to the Harvard Corporation arguing for divestment. This was followed by a 30-hour blockade of the Harvard president's office by students protesting the president's refusal to engage in a public discussion of divestment; the Harvard administration terminated the blockade by arresting one of the student protesters. Following the protest, Faust said she would not hold the open forum that students and faculty had requested and would not engage with students from Divest Harvard. In May 2014, a group of Harvard alumni interrupted an alumni reunion event with Faust present by standing and holding a pro-divestment banner; the alumni were removed from the event and banned from Harvard's campus.\n\nIn September 2014, Harvard faculty renewed their calls for an open forum on divestment and continued to argue for divestment publicly. In October 2014, Divest Harvard organized a three-day fast and public outreach event to call attention to the harms of climate change. In November 2014, a group of students calling themselves the Harvard Climate Justice Coalition filed a lawsuit against the Harvard Corporation to compel divestment on the grounds of Harvard's status as a non-profit organization. The lawsuit was dismissed by a Massachusetts Superior Court judge, who wrote that \"Plaintiffs have brought their advocacy, fervent and articulate and admirable as it is, to a forum that cannot grant the relief they seek.\" The plaintiffs have stated that they plan to appeal the decision.\n\nIn January 2015, it was revealed that Harvard had increased its direct investments in fossil fuel companies considerably, and the number of faculty and alumni supporting divestment grew. By April 2015, the faculty group calling for divestment grew to 250, the Harvard alumni club of Vermont officially voted to endorse divestment, and Divest Harvard announced the creation of a fossil-free alumni donation fund that Harvard would receive conditional on divestment. In February 2015, Divest Harvard occupied the president's office for 24 hours in protest of the Harvard Corporation's continued unwillingness to engage students on the topic of divestment. This was followed by an open letter from a group of prominent Harvard alumni urging the university to divest. In April 2015, Divest Harvard and Harvard alumni carried out an announced week-long protest called Harvard Heat Week, which included rallies, marches, public outreach, and a continuous civil disobedience blockade of administrative buildings on campus. The Harvard administration avoided engaging with the protest. Following Heat Week, Divest Harvard carried out an unannounced one-day civil disobedience blockade of the Harvard president's office in protest of continued lack of action by the Harvard administration.\n\nFossil Free MIT (FFMIT) is a student organization at the Massachusetts Institute of Technology made up of MIT undergrads, graduate students, post-docs, faculty, staff and alumni. The group was formed in Fall 2012 by six MIT students following a visit to Boston by Bill McKibben of 350.org on his \"Do the Math\" tour. The group has collected over 3,500 signatures in a petition calling for MIT to (1) immediately freeze new investments in fossil fuel companies, and (2) divest within five years from current holdings in these companies.\n\nFollowing discussions with FFMIT, the university administration initiated a \"campus-wide conversation\" on climate change to take place from November 2014 to May 2015, which included the formation of the MIT Climate Change Conversation Committee. The committee, composed of 13 faculty, staff, and students, was charged with engaging the MIT community to determine how the university could address climate change and with offering recommendations. The conversation included solicitation of ideas and opinions of MIT community members, as well as a number of public events. The largest event was a fossil fuel divestment debate among six prominent voices on climate change that was attended by approximately 500 people.\n\nThe committee released a report in June 2015, recommending a number of initiatives to be undertaken by the university. In regards to fossil fuel divestment, the committee \"rejected the idea of blanket divestment from all fossil fuel companies\"; although there was \"support by (three-quarter) majority of the committee for targeted divestment from companies whose operations are heavily focused on the exploration for and/or extraction of the fossil fuels that are least compatible with mitigating climate change, for example coal and tar sands.\"\n\nFollowing the campus-wide conversation, on 21 October 2015, President L. Rafael Reif announced the MIT Plan for Action on Climate Change. While the plan enacted many of the committee’s recommendations, the university administration chose not to divest its holdings in fossil fuel companies, stating that \"divestment...is incompatible with the strategy of engagement with industry to solve problems that is at the heart of today’s plan.\"\n\nThe following day, Fossil Free MIT began a sit-in outside the office of the President to protest the shortcomings of the plan, including the rejection of divestment. Over 100 people overall participated in the sit-in, which received coverage by multiple news outlets, including the Boston Globe, Boston Magazine, and the Daily Caller. The sit-in, which lasted 116 days, ended officially with an agreement with Vice President for Research Maria Zuber following negotiations about how to improve the Plan. The agreement did not include divestment, but succeeded in establishing a climate advisory committee and a climate ethics forum. In addition, the administration agreed to strengthen the university’s carbon mitigation commitments, striving for carbon neutrality \"as soon as possible.\"\n\nA number of individuals and organisations have voiced support for fossil fuel divestment including:\n\n\nIn March 2015 Mary Robinson, Ban Ki-moon’s special envoy on climate change and former Irish President stated, \"it is almost a due diligence requirement to consider ending investment in dirty energy companies\".\n\nDesmond Tutu has voiced support for fossil fuel divestment and compared it to divestment from South Africa in protest of apartheid.\n\nIn 2015, the London Assembly passed a motion calling on the Mayor of London to urgently divest pension funds from fossil fuel companies\n\nA prominent speaker at the 5th annual World Pensions & Investments Forum held in December 2015, Earth Institute Director Jeffrey Sachs voiced for institutional investors to take their fiduciary responsibility in reducing the risk of losses via fossil fuel divestment.\n\nIn February 2015 alumni of Harvard University including Natalie Portman, Robert F. Kennedy, Jr, Darren Aronofsky and Susan Faludi wrote an open letter to Harvard University demanding that it divest its $35.9 billion endowment from coal, gas, and oil companies.\n\nHarvard's decision not to divest was explained in an open letter from the University President, Drew Faust:\n\nThe University of Glasgow became the first university in Europe to agree to divest from fossil fuels. The NSA whistle-blower Edward Snowden commented:\nFor list of fossil fuel companies that divestment campaigns target, see List of oil exploration and production companies.\n\nGovernments and pension funds in the United States that have partially or completely divested, or that have taken steps toward divestment, include (listed alphabetically):\n\nColleges and universities which have partially or completely divested, or which have taken steps toward divestment, include (listed alphabetically):\n\n\nIn September 2014, the Rockefeller Brothers Fund announced it would be divesting its fossil fuel investments totalling $60 million. \"We are quite convinced that if he were alive today, as an astute businessman looking out to the future, he would be moving out of fossil fuels and investing in clean, renewable energy.\"\nThe 2013 general synod of the United Church of Christ (UCC) passed a resolution (sponsored by the Massachusetts Conference and ten other conferences of the UCC) outlining a path to divestment of church funds from fossil-fuel holdings. Under the resolution, a plan for divestment will be developed by June 2018. The original proposal considered by the general synod called for a five-year plan to divestment; this was changed following negotiations between divestment proponents and the UCC's investment arm, United Church Funds. United Church Funds also established a denominational fossil-free fund (believed to be the first of its kind), which raised almost $16 million from UCC congregations, conferences, and other groups by late September 2014.\n\nIn June 2014, the trustees of Union Theological Seminary in New York City unanimously voted to begin divesting fossil fuels from the seminary's $108.4 million endowment.\n\nOn 30 April 2015, the Church of England agreed to divest £12million from its tar sands oil and thermal coal holdings. The church has a £9billion investment fund.\n\n\nIreland is to be the world’s first country to divest public money from fossil fuels. Other sources.\n\n\n\n\n\n"}
{"id": "56737309", "url": "https://en.wikipedia.org/wiki?curid=56737309", "title": "French Restoration style", "text": "French Restoration style\n\nThe French Restoration style was predominantly Neoclassicism, though it also showed the beginnings of romanticism in music and literature. The term describes the arts, architecture, and decorative arts of the Bourbon Restoration period (1814–1830), during the reign of Louis XVIII and Charles X from the fall of Napoleon to the July Revolution of 1830 and the beginning of the reign of Louis-Philippe.\n\nTo commemorate the memory of Louis XVI and Marie Antoinette and to expiate the crime of their execution, King Louis XVIII built the Chapelle expiatoire by Pierre-François-Léonard Fontaine on the site of the small cemetery of the Madeleine, where their remains (now in the Basilica of Saint-Denis) had been hastily buried following their execution. It was completed and dedicated in 1826.\n\nThe royal government restored the symbols of the old regime, but continued the construction of most of the monuments and urban projects begun by Napoleon. The church of La Madeleine, begun under Louis XVI, had been turned by Napoleon into the Temple of Glory (1807). It was now turned back to its original purpose, as the Royal church of La Madeleine. All of the public buildings and churches of the Restoration were built in a relentlessly neoclassical style. Work resumed, slowly, on the unfinished Arc de Triomphe, begun by Napoleon. At the end of the reign of Louis XVIII, the government decided to transform it from a monument to the victories of Napoleon into a monument celebrating the victory of the Duke of Angôuleme over the Spanish revolutionaries who had overthrown their Bourbon king. A new inscription was planned: \"To the Army of the Pyrenees\" but the inscription had not been carved and the work was still not finished when the regime was toppled in 1830. \n\nThe Canal Saint-Martin was finished in 1822, and the building of the Bourse de Paris, or stock market, designed and begun by Alexandre-Théodore Brongniart from 1808 to 1813, was modified and completed by Éloi Labarre in 1826. New storehouses for grain near the Arsenal, new slaughterhouses, and new markets were finished. Three new suspension bridges were built over the Seine; the Pont d'Archeveché, the Pont des Invalides and footbridge of the Grève. All three were rebuilt later in the century.\n\nSeveral new churches were begun during the Restoration to replace those destroyed during the Revolution. A battle took place between architects who wanted a neogothic style, modeled after Notre-Dame, or the neoclassical style, modeled after the basilicas of ancient Rome. The battle was won by a majority of neoclassicists on the Commission of Public Buildings, who dominated until 1850. Jean Chalgrin had designed Saint-Philippe de Role before the Revolution in a neoclassical style; it was completed (1823–30) by Étienne-Hippolyte Godde. Godde also completed Chalgrin's project for Saint-Pierre-du-Gros-Caillou {1822–29), and built the neoclassic basilicas of Notre-Dame-du-Bonne Nouvelle ((1823–30) and Saint-Denys-du-Saint-Sacrament (1826–35). Other notable neoclassical architects of the Restoration included Louis-Hippolyte Lebas, who built Notre-Dame-de-Lorette (1823–36); (1823–30); and Jacques Ignace Hittorff, who built the church of Church of Saint-Vincent-de-Paul (1824–44). Hittorff went on to along a brilliant career in the reigns of Louis Philippe and Napoleon III, designing the new plan of the Place de la Concorde and constructing the Gare du Nord railway station (1861–66). \n\nA new form of commercial architecture had appeared at the end of the 18th century; the passage, or shopping gallery, a row of shops along a narrow street covered by a glass roof. They were made possible by improved technologies of glass and cast iron, and were popular since few Paris streets had sidewalks and pedestrians had to compete with wagons, carts, animals and crowds of people. The first indoor shopping gallery in Paris had opened at the Palais-Royal in 1786; rows of shops, along with cafes and the first restaurants, were located under the arcade around the garden. It was followed by the passage Feydau in 1790–91, the passage du Caire in 1799, and the Passage des Panoramas in 1800. In 1834 the architect Pierre-François-Léonard Fontaine carried the idea a step further, covering an entire courtyard of the Palais-Royal, the Galerie d'Orleans, with a glass skylight. The gallery remained covered until 1935. It was the ancestor of the glass skylights of the Paris department stores of the later 19th century. \n\nDuring the Restoration, and particularly after the coronation of King Charles X in 1824. New residential neighborhoods were built on the Right Bank in Paris, as the city grew to the north and west. Between 1824 and 1826, a time of economic prosperity, the quarters of Saint-Vincent-de-Paul, Europe, Beaugrenelle and Passy were all laid out and construction began. The width of lots grew larger; from six to eight meters wide for a single house to between twelve and twenty meters for a residential building. The typical new residential building was four to five stories high, with an attic roof sloping forty-five degrees, broken by five to seven windows. The decoration was largely adapted from that of the Rue de Rivoli; horizontal rather than vertical orders, and simpler decoration. The windows were larger and occupied a larger portion of the façades. Decoration was provided by ornamental iron shutters and then wrought-iron balconies. Variations of this model were the standard on Paris boulevards until the Second Empire.\n\nThe hôtel particular, or large private house of the Restoration, usually was built in a neoclassical style, based on Greek architecture or the style of Palladio, particularly in the new residential quarters of Nouvelle Athenes and the Square d'Orleans on Rue Taibout (9th arrondissement), a private residential square (1829–35) in the English neoclassical style designed by Edward Cresy. Residents of the square included George Sand and Frédéric Chopin. Some of the houses in the new quarters in the 8th arrondissement, particularly the quarter of François I, begun in 1822, were made in a more picturesque style, a combination of the Renaissance and classical style, called the \"Troubadour\" style. This marked the beginning of the movement away from uniform neoclassicism toward eclectic residential architecture.\n\nThe decorative style of the French Restoration borrowed from both the geometry of the neoclassical style era, and the overload of decoration of the Louis XIV style, along with the color of Renaissance. One of the best examples is the Charles X museum within the Louvre, a suite of rooms that was created for, among other purposes, the Salon of artists that was held there annually. The ceilings were divided into compartments filled with paintings and lavishly decorated with corniches, columns and pilasters. The neo-Gothic also began to appear in interior decoration during the 1820, particularly in the design of galleries and salons with arches and arched windows and rose windows modeled after those in gothic cathedrals. Another feature of the French restoration was polychromy, the use of bright colors in the decorations, either with colored stone, glass, or paintings. Ceilings were particularly lavish, with hemicycles, cupolas, pendants, and vaults, often filled with decorative paintings. \n\nAnother good example of the French Restoration style of design is the interior of the Chapelle expiatoire. While the layout of the building and architecture is sober and perfectly Greco-Roman neoclassicism, the inside of the dome is decorated with rosettes, and there is an abundance of high-relief sculpted decoration in bands below the cornices and between the columns supporting the dome, including stylized Maltese crosses, fleur-de-lis and roses. The floor also has elaborate polychrome decoration in stone with the same motifs. \n\nWith the downfall of Napoleon, those aristocrats who had fled France during the Revolution began to return; they found their furniture had largely been confiscated and sold during the Revolution, and they had little money to buy lavish new furniture. The new King, Louis XVIII, liked the Empire style, so that style remained in place, with slightly rounded lines, and the removal of the Napoleonic symbols and ornaments, After the death of Louis XVIII in 1824, the new King, his brother Charles X, allotted an indemnity to aristocrats whose belongings had been confiscated during the Revolution, and the luxury furniture industry began to revive. Interest began to develop in older styles, particularly Gothic and Renaissance, especially after the creation of a museum of French monuments during the Revolution, but the gothic revival movement did not become really strong until after the publication in 1831 of \"The Hunchback of Notre-Dame\" by Victor Hugo (1831).\n\nOrnament of gilded bronze became rarer; most ornament was marquetry inlay, either light wood into dark, or dark wood into light; often in form of very elaborate floral designs, under the influence of the Duchesse de Berry. Under Charles X, the \"á la Cathédral\" or Cathedral chair became popular, with a back resembling the form of a Gothic stained glass window. The Gothic rose also became a popular decoration on furniture, along with stylized palmettes and other floral designs. Comfort was another consideration in the design of new chairs. The Voltaire armchair, with sabre-curved front legs, a high curving padded back and padded armrests, became popular. It took its name from a popular illustration of portrait of Voltaire, made about 1820, which showed him seated in s similar armchair.\n\nThe Restoration saw the beginning of the long battle between neoclassicism and romanticism in painting and other domains of art. Jacques-Louis David, the dominant neoclassical painter during the reign of Napoleon, went into exile in Belgium; however, other prominent students of David remained in Paris, and continued the style, simply changing the subject matter. They included François Gérard, who painted the coronation of King Charles X in 1827, following almost exactly the composition used by David in his coronation painting of the Emperor Napoleon. Other former pupils of David included Antoine-Jean Gros (1771-1835), and the most prominent of all, Jean-Auguste-Dominique Ingres, (1780-1867), who painted his famous \"Grand Odalisque\" in the year that Napoleon first went into exile.\n\nThe new generation of neoclassicists, led by Ingres and Gérard, largely ignored the idea of a classicism based on Ancient Roman and Greek values, and concentrated instead on the perfection of the depiction of human body, by its lines, composition and color. During the Restoration, Ingres was commissioned to paint a mural for the ceiling of the Salle Clarac of the Louvre, called \"Apothéose de Homer\". Completed in 1827, it brought together all of the famous artists of history, attending the crowning of Homer by an angel. Ingres also surpassed all of his contemporaries of the period as a portrait painter. In 1819 Ingres painted \"Roger rescuing Angelique\", inspired by St. George slaying a dragon, in an almost surrealistic setting. Here Ingres' style foreshadowed the drama of Gustave Moreau Other painters who often followed the more delicate and sensual version of neoclassicism included Pierre-Paul Prud'hon (1758–1821), and the portraitist Élisabeth Vigée Le Brun.\n\nAn entirely different approach to painting was taken by Jean Louis Théodore Géricault with his painting \"The Raft of the Meduse\" (1818–1819), depicting the true story of the survivors of a shipwreck, gathered on a raft, appealing for help to a far distant ship. Géricault had meticulously studied anatomy to make the dead bodies on the raft more realistic. The painting was bitterly attacked by many critics and defended by many others, including the poet Baudelaire and the painter Horace Vernet. Géricault returned to the theme in 1821-24, with \"The Tempest\" or \"The shipwreck\" a painting of a corpse washed ashore on beach during storm. (1821–24), illustrating graphically again how humans were powerless against nature. In 1822–23, Gericault painted \"La Folle\", a portrait of a madwoman in a Paris asylum with a distant, hopeless stare. His school of painting became known a \"theatrical romanticism\".\n\nEugène Delacroix was another major painter of \"theatrical romanticism\" who emerged during the Restoration. As a young painter, he was particularly impressed by the works of Rubens in the Louvre, by the drawings of Goya, and the paintings of Constable. After traveling to England, where he met Constable, he returned to Paris and became friends with Stendhal, Balzac and Victor Hugo. At the Paris Salon of 1827, he showed nine paintings. The following year, he presented \"The Death of Sardanapale\". In the fall of 1830, shortly after the July Revolution, which toppled King Charles X, he painted \"Liberty Leading the People\", which was presented at the 1831 Salon, and became one of the icons of French art.\n\nThe most prominent French sculptor of the Restoration was François Joseph Bosio (1768-1845). Born in Monaco, he received a scholarship from the Prince of Monaco to study in Paris, under Augustin Pajou. During the Empire of Napoleon, he sculpted some of the plaques on the column in Place Vendôme, and made numerous portrait busts of the Emperor's family. During the restoration, he became the royal sculptor to the King, and made both portrait busts and sculptors in the classical-romantic style. He made the central statue Louis XVI for the Expiatory Chapel, called \"Apotheosis of Louis XVI\" or \"Louis XVI called to immortality, supported by an angel\". In 1828 he completed a new work of sculpture for the top of the Arc de Triomphe du Carrousel at the Louvre. A chariot and horse sculpture, taken by Napoleon from St Mark's Basilica in Venice, had originally been placed atop the arch, but it had been returned to Venice after Napoleon's downfall. The Bourbons commissioned Bosio to make a new work, Peace guiding a Chariot, to commemorate the Bourbon Restoration. Bosio was also commissioned to replace the equestrian statue of Louis XIV which had been the centerpiece of Place des Victoires, which had been destroyed during the Revolution. His new version, twelve meters high, was installed in 1828.\n\nAnother notable French sculptor of the period was Pierre Jean David 1788–1856), who called himself David d'Angers, to distinguish himself from his teacher, Jacques Louis David. He worked in the studio of Jacques Louis David beginning in 1809. Then, between 1811 and 1816 he studied at the French Academy in Rome, where he became familiar with the works of Canova, the great Italian master of romanticism. However, he turned his own work toward classicism, illustrating the patriotic and moral virtues. He made busts or statues of many notable statesmen, including the Marquis de Lafayette, Thomas Jefferson and Goethe. In 1830, he began working on his best-known work, the frieze over the entrance of the Pantheon, titled \"The Country recognizes its great men\", which he completed in 1837. \n\nAnother notable sculptor who began his career during the Restoration was François Rude, (1784–1847), He moved to Paris from Dijon in 1805 to study with Pierre Cartellier. In 1811 he won the Prix de Rome, but he was a confirmed Bonapartist, and after the downfall of Napoleon, he went into exile in Beligium, where he had success as a portrait sculptor. He did not return until 1827. Between 1833 and 1836, he made the celebrated sculptures, called \"Les Marseillaise\", which decorate the Arc de Triomphe.\n\nThe Bourbon restoration saw the rise of romanticism to the position of the dominant movement in French literature. The earliest prominent romantic was François-René de Chateaubriand, an essayist and diplomat. He began the Restoration as a committed defender of the Catholic faith and royalist, but gradually moved into the liberal opposition and became a fervent supporter of freedom of speech. Other prominent romantic writers of the period included the poet and politician Alphonse de Lamartine, Gérard de Nerval, Alfred de Musset, Théophile Gautier, and Prosper Mérimée.\n\nDespite limitations on press freedom, Paris editors published the first works of some of France's most famous writers. Honoré de Balzac moved to Paris in 1814, studied at the University of Paris, wrote his first play in 1820, and published his first novel, \"Les Chouans\", in 1829. Alexandre Dumas moved to Paris in 1822, and found a position working for the future King, Louis-Philippe, at the Palais-Royal. In 1829, At the age of 27, he published his first play, \"Henri III and his Courts\". Stendhal, a pioneer of literary realism, published his first novel, \"The Red and the Black\", in 1830.\n\nThe young Victor Hugo declared that he wanted to be \"Chateaubriand or nothing\". His first book of poems, published in 1822 when he was twenty years old, earned him a royal prize from Louis XVIII. His second book of poems in 1826 established him as one of France's leading poets. He wrote his first plays, \"Cromwell\" and \"Hernani\" in 1827 and 1830, and his first short novel, \"The Last Days of a Condemned Man\", in 1829. The premiere of the ultra-romantic play \"Hernani\" caused a riot in the audience, on the eve of the fall of the Bourbon Monarchy,\n\nThe restoration of the monarchy with the coronation of Louis XVIII brought an end to the era of gigantic outdoor celebrations with patriotic music of the Revolution and the Empire of Napoleon. Instead, music returned to the salons of the old aristocracy, who returned from exile, and the new aristocracy created under Napoleon Bonaparte. The Music Conservatory in Paris was renamed the Royal School of Music, and the King commissioned the Italian-born Luigi Cherubini, newly named music director of the chapel of the Tuileries Palace, to write a requiem mass for Louis XVI, as well as a coronation mass for himself. The composer Gaspare Spontini was named director of royal music. A royal institution of religious music was also established in 1825, to perform early masterpieces of French religious music by Clément Janequin and Giovanni Pierluigi da Palestrina, which had been banned during the Revolution and ignored under Napoleon I. \n\nThe composers most performed in the part of the period were the work of composers of the pre-revolutionary period, Gluck, Sacchini and Spontini, but new composers soon appeared, including Carl Maria von Weber, who arrived from Germany, and staged a highly-successful French version of the first romantic German opera, \"Der Freischütz\", or \"The Marksman\", in 1824.\n\nThe most successful musical theater of the period was the Théâtre-Italien, which performed in the Salle Favert in Paris; it produced the a series of operas by the most famous composer of the period, Gioachino Rossini, including \"The Barber of Seville\" in 1819. Rossini moved to Paris in 1824, and was named Director of Music and Staging at the Théâtre-Italien. Only Italian works were presented, always in Italian. Rossini became the most prominent figure of the Paris musical world, writing the music for the coronation of Charles X in 1824.\n\nIn 1820 a Bonapartist assassinated the Duke du Berry at the Paris opera house on rue de Richelieu. King Louis XVIII ordered the immediate closing, and then the demolition, of the Opera House. The Opera moved to the Salle Le Peletier, where it remained for fifty years. This theater was the scene of the birth of the first French grand opera, and the first romantic opera, with the premier of \"La Muette de Portici\" by Auber in July 1829. The theme of this opera, the rebellion of the people of Naples against Spanish rule, was particularly romantic and revolutionary. A performance of the opera in Brussels in 1830 led to riots, followed by a real revolution. Wagner attended a performance and wrote, \"it was something entirely new; no one had seen a subject of an opera so current; it was the first true musical drama in five acts entirely provided with all the elements of tragedy, and notable also for its tragic ending.\"\n\nThe Paris opera continued to astonish its audiences with new musical and visual effects. For the opera \"The Last Days of Pompeii\" by Giovanni Pacini, the opera employed the scientist and inventor Louis Daguerre to create optical illusions on a screen simulating dancing flames and the waves of the sea.\n\nTo satisfy the demands of Paris opera-goers for truly grand opera, Rossini was commissioned to write the Le siège de Corinthe and then \"William Tell\". This last work, which premiered at the Pelletier opera house on August 3, 1829, despite its famed overture, disappointed the critics, who criticized its excessive length, weak story, and lack of action. The criticism stung Rossini, and, at the age of thirty-seven, he retired from writing operas.\n\nThe musical salons of the aristocracy had a working-class counterpart in Paris during the Restoration; the \"goguette\", musical clubs formed by Paris workers, craftsmen, and employees. There were \"goguettes\" of both men and women. They usually met once a week, often in the back room of a cabaret, where they would enthusiastically sing popular, comic, and sentimental songs. During the Restoration, songs were also an important form of political expression. The poet and songwriter Pierre-Jean de Béranger became famous for his songs ridiculing the aristocracy, the established church and the ultra-conservative parliament. He was imprisoned twice for his songs, in 1821 and 1828, which only added to his fame. His supporters around France sent \"foie gras\", fine cheeses and wines to him in prison. The celebrated Paris police chief Eugène François Vidocq sent his men to infiltrate the \"goguettes\" and arrest those who sang songs ridiculing the monarch.\n\n"}
{"id": "57717208", "url": "https://en.wikipedia.org/wiki?curid=57717208", "title": "Gannet oil and gas field", "text": "Gannet oil and gas field\n\nGannet is an oil and gas field located in the United Kingdom’s Central North Sea. It is 180 km east of Aberdeen Scotland, and the water depth at the Gannet offshore installation is 95 metres (312 ft). The field is located in Blocks 22/21, 22/25, 22/26 and 21/30. It is half-owned by Royal Dutch Shell (50%) and partly by ExxonMobil (50%) and has been operated by Shell UK Ltd since ‘first oil’ in November 1993. The Gannet A installation is the host platform for subsea tiebacks designated Gannet B to G. Like most Shell fields in the central and northern North Sea the field is named after a sea bird the gannet.\n\nThe Gannet reservoirs are located at a depth of between 1768 m and 2728 m and extend over several blocks. They comprises good quality turbiditic sands of a Tertiary age (Tay, Rogaland, Forties, Lista and Andrew Formations) and were discovered in 1973. The formation comprises a mixture of hydrocarbon reservoirs.\nThe topsides for Gannet were designed by Matthew Hall Engineering which was also responsible for procurement and construction and commissioning assistance. They were awarded the contract in July 1989. Initially there were facilities for 15 oil production wells, two gas production wells and seven spare slots; there was also provision for 39 subsea risers. The production capacity was 56,000 barrels of oil per day and 4.0 million standard cubic metres of gas per day. There are four production trains for both oil and gas processing. Electricity generation is powered by two 21 MW Rolls Royce RB-211 gas turbines. The topside accommodation was for 40 people. The integrated deck topsides (9600 tonnes) are supported by a four leg steel jacket (lift weight 8400 tonnes). The topsides were fabricated by Redpath Offshore North; and the jacket by RGC Offshore at Methil.\n\nOil from the platform wellheads and subsea wells is routed to one of the three horizontal first stage 3-phase separators. Oil from the separators is combined and fed to common second, third and fourth stage 3-phase separators. Processed oil is exported by pipeline to the Fulmar A installation and thence via Norpipe to Teesside. Gas from the second, third and fourth stage separators is compressed to the operating pressure of the first stage separators with which it is combined and further compressed. Gas from the Gannet A gas wellheads and from the Gannet B &C subsea wells flows to one of the two vertical separators. Gas is co-mingled with the off-gas from the oil separators is dehydrated through counter-current contact with Triethylene glycol. Gas is compressed for export to St Fergus via the Fulmar gas pipeline. There are also facilities for gas injection into Gannet A, B & C reservoirs and for gas lift to oil production wells on reservoirs, A, C, D, E, F and G. Produced water is treated prior to overboard disposal.\n\nOil export capacity is 88,000 barrels per day. Gas compression and dehydration capacity is 246 million standard cubic feet per day. Gannet A has a gas lift capacity of 130 million standard cubic feet per day and a produced water handling capability of 60,000 barrels per day. Shell have indicated that there is greater than 25% ullage of the total system capability available in the plant for additional third party processing and transportation.\n\n"}
{"id": "25567857", "url": "https://en.wikipedia.org/wiki?curid=25567857", "title": "Gap Analysis Program", "text": "Gap Analysis Program\n\nThe Gap Analysis Program is a nationwide program in the United States to assess and support the overall conservation status of wildlife. The program is directed and coordinated under the United States Geological Survey, but is implemented in coordination with state and regional programs. \n\nGAP works to ensure that common species – those that are not officially endangered – remain common by identifying those species and plant communities that are not adequately represented in existing conservation lands. \n\nThe GAP program began in the 1980s, based on analysis of Hawaiian bird species by J. Michael Scott.\n\nGAP has produced national land cover and protected areas datasets, which it uses to assess the conservation status of mammal, bird, reptile, and amphibian species in the U.S.\n\nA GAP program normally has three principal components:\n1. Landcover analysis\n2. Vertebrate species distribution prediction\n3. Land stewardship database\n\nEach component is normally performed as a GIS layer.\n\n"}
{"id": "36842", "url": "https://en.wikipedia.org/wiki?curid=36842", "title": "Gossypium", "text": "Gossypium\n\nGossypium is a genus of flowering plants in the tribe Gossypieae of the mallow family, Malvaceae from which cotton is harvested. It is native to tropical and subtropical regions of the Old and New Worlds. There are about 50 \"Gossypium\" species, making it the largest genus in the tribe Gossypieae and new species continue to be discovered. The name of the genus is derived from the Arabic word \"goz\", which refers to a soft substance.\n\nCotton is the primary natural fibre used by modern humans. Where cotton is cultivated it is a major oilseed crop and a main protein source for animal feed. Cotton is thus of great importance for agriculture, industry and trade, especially for tropical and subtropical countries in Africa, South America and Asia. Consequently, the genus \"Gossypium\" has long attracted the attention of scientists.\n\nThe origin of the genus \"Gossypium\" is dated to around 5–10 million years ago. \"Gossypium\" species are distributed in arid to semiarid regions of the tropics and subtropics. Generally shrubs or shrub-like plants, the species of this genus are extraordinarily diverse in morphology and adaptation, ranging from fire-adapted, herbaceous perennials in Australia to trees in Mexico.\n\nCultivated cottons are perennial shrubs most often grown as annuals. Plants are 1–2 m high in modern cropping systems, sometimes higher in traditional, multiannual cropping systems, now largely disappearing. The leaves are broad and lobed, with three to five (or rarely seven) lobes. The seeds are contained in a capsule called a \"boll\", each seed surrounded by fibres of two types. These fibres are the more commercially interesting part of the plant and they are separated from the seed by a process called ginning. At the first ginning, the longer fibres, called staples, are removed and these are twisted together to form yarn for making thread and weaving into high quality textiles. At the second ginning, the shorter fibres, called \"linters\", are removed, and these are woven into lower quality textiles (which include the eponymous Lint). Commercial species of cotton plant are \"G. hirsutum\" (>90% of world production), \"G. barbadense\" (3–4%), \"G. arboreum\" and \"G. herbaceum\" (together, 2%). Many varieties of cotton have been developed by selective breeding and hybridization of these species. Experiments are ongoing to cross-breed various desirable traits of wild cotton species into the principal commercial species, such as resistance to insects and diseases, and drought tolerance. Cotton fibres occur naturally in colours of white, brown, green, and some mixing of these.\n\nMost wild cottons are diploid, but a group of five species from America and Pacific islands are tetraploid, apparently due to a single hybridization event around 1.5 to 2 million years ago. The tetraploid species are \"G. hirsutum\", \"G. tomentosum\", \"G. mustelinum\", \"G. barbadense\", and \"G. darwinii\".\n\n\n\n\n\n\nA public genome sequencing effort of cotton was initiated in 2007 by a consortium of public researchers. They agreed on a strategy to sequence the genome of cultivated, allotetraploid cotton. \"Allotetraploid\" means that the genomes of these cotton species comprise two distinct subgenomes, referred to as the At and Dt (the 't' for tetraploid, to distinguish them from the A and D genomes of the related diploid species). The strategy is to sequence first the D-genome relative of allotetraploid cottons, \"G. raimondii\", a wild South American (Peru, Ecuador) cotton species, because of its smaller size due essentially to less repetitive DNA (retrotransposons mainly). It has nearly one-third the number of bases of tetraploid cotton (AD), and each chromosome is only present once. The A genome of \"G. arboreum\", the 'Old-World' cotton species (grown in India in particular), would be sequenced next. Its genome is roughly twice the size of \"G. raimondii\"'s. Once both A and D genome sequences are assembled, then research could begin to sequence the actual genomes of tetraploid cultivated cotton varieties. This strategy is out of necessity; if one were to sequence the tetraploid genome without model diploid genomes, the euchromatic DNA sequences of the AD genomes would co-assemble and the repetitive elements of AD genomes would assembly independently into A and D sequences, respectively. Then there would be no way to untangle the mess of AD sequences without comparing them to their diploid counterparts.\n\nThe public sector effort continues with the goal to create a high-quality, draft genome sequence from reads generated by all sources. The public-sector effort has generated Sanger reads of BACs, fosmids, and plasmids, as well as 454 reads. These later types of reads will be instrumental in assembling an initial draft of the D genome. In 2010, two companies (Monsanto and Illumina), completed enough Illumina sequencing to cover the D genome of \"G. raimondii\" about 50x. They announced they would donate their raw reads to the public. This public relations effort gave them some recognition for sequencing the cotton genome. Once the D genome is assembled from all of this raw material, it will undoubtedly assist in the assembly of the AD genomes of cultivated varieties of cotton, but a lot of hard work remains.\n\n\n\n\n"}
{"id": "51618720", "url": "https://en.wikipedia.org/wiki?curid=51618720", "title": "Hot link (sausage)", "text": "Hot link (sausage)\n\nA hot link also referred to as a \"red link\" is a type of sausage often associated with the cuisine of the Southern United States, featured commonly as a part of American barbecue, soul food, and Cajun and Louisiana Creole cuisines. It is sometimes referred to as a \"Louisiana hot link\". It is also a part of Texan cuisine and the cuisine of Chicago, Illinois. The hot link is usually prepared using pork, beef, or a combination of both. It is sometimes used as an ingredient in other dishes, such as jambalaya and gumbo. Hot link sausages are mass-produced by some companies in the United States.\n\nPork or beef, or a blend of both, is typically used as the primary meat ingredient. The hot link can be spiced using red pepper flakes and cayenne pepper. Additional spices may be used, such as thyme, paprika, crushed bay leaves and onion flakes. Hot link sausages are sometimes smoked.\n\nIn Southern Louisiana, where Cajun cuisine is abundant, a hot link sausage on a bun is consumed more frequently than hot dogs.\n\nIn Texas, the hot link is typically prepared with beef, and is usually cooked over indirect heat. Common sides to accompany the Texas hot link includes sliced white bread, crackers, orange cheese, onion slices and pickles. In Pittsburg, Texas, the hot link is a popular food and has been produced there since 1897. In Pittsburg, hot links are typically broiled or baked to the point of having a \"half-burned look\". In 1983, Pittsburg Hot Link Packers, Inc. in Pittsburg, Texas was producing 12,000 pounds of hot links per week. Almost all of the hot links produced by Pittsburg Hot Link Packers were consumed within 100 miles of Pittsburg during this time.\n\nIn Chicago, Illinois, hot links are typically prepared using pork, may be spiced with pepper, fennel and sage, and are typically covered with a barbecue sauce. They are commonly available at soul food barbecue restaurants in the city's south side, often served with french fries and white bread. They may be slow cooked in a barbecue pit.\n\n\n"}
{"id": "2901898", "url": "https://en.wikipedia.org/wiki?curid=2901898", "title": "How It's Made", "text": "How It's Made\n\nHow It's Made (Comment c'est fait in Quebec) is a documentary television series that premiered on January 6, 2001, on the Discovery Channel in Canada, and Science in the United States. The program is produced in the Canadian province of Quebec by Productions MAJ, Inc. and Productions MAJ 2.\n\nThe show is a documentary showing how common, everyday items (including clothing and accessories like alligator handbags, foodstuffs like bubble gum, industrial products such as engines, musical instruments such as guitars, and sporting goods such as snowboards) are manufactured.\n\n\"How It's Made\" is filmed without explanatory text to simplify overdubbing in different languages. For example, the show currently avoids showing a narrator or onscreen host, does not often have employees of featured companies speak on camera, and keeps human interaction with the manufacturing process to a bare minimum.\n\nAn off-screen narrator explains each process, often with humorous puns. Each half-hour show usually has three or four main segments, with each product getting a demonstration of approximately five minutes; exceptions are allowed in the allotted time for more complex products. Usually, every show has at least one product with a historic background note preceding it, showing how and where the product originated, and what people used before it.\n\nIn April 2007, all episodes run in the United States (on the Discovery Channel and Science) had the individual season openings replaced with a new opening used for every episode. Similar to most other Discovery Channel shows, the credits now run during the last segment, with only a blue screen and the request for feedback (and the website) at the end.\n\nIn September 2007, the ninth season began airing on Science, along with new openings, graphics, and soundtracks, and Zac Fine replaced Brooks T. Moore as the narrator. However, the eleventh season, which started airing in September 2008, reinstated Moore as the narrator and reverted to a previous title sequence and soundtrack.\n\nIn June 2008, the Science Channel added \"How It's Made: Remix,\" which consists of previous segments arranged into theme installments like \"Food\", \"Sporting Goods\", and such. In 2013, the Science Channel added \"How It's Made: Dream Cars\", which focused exclusively on high-performance and exotic cars. These were later shown on the Velocity channel.\n\nCanadian hosts have included Mark Tewksbury (season 1, 2001), Lynn Herzeg (seasons 2–4, 2002–2004), June Wallack (season 5, 2005) and Lynne Adams (season 6 onwards, 2006–present).\n\nA different voice-over track is recorded for US audiences by Brooks Moore (seasons 1–8, 2001–2007, 2008–present) and Zac Fine (2007–2008). The scripts are almost identical but the main difference in the US versions are that the units of measurement are given in United States customary units instead of metric units. At one point in the US run, a subtitled conversion was shown on-screen over the original narration.\n\nIn the United Kingdom, the rest of Europe, and in some cases in Southeast Asia, the series is narrated by Tony Hirst.\n\nCommon Sense Media gave the TV show a rating of 4/5 stars, writing \"Curious kids and adults will learn from the show, and some segments can really broaden your perspective\". On the show's success despite its formulaic nature, Rita Mullin, the general manager of the Science Channel, said \"I think what is one of the great appeals of the show as a viewer myself is how little has changed over the years\". \"The Wall Street Journal\" deemed it \"TV's quietest hit\".\n\nThe series was spoofed in an episode of \"Rick and Morty\" in a segment where a \"Plumbus\" was being made, and again in a Captain Disillusion video showing how hoax UFO videos are made.\n\n\n"}
{"id": "46687675", "url": "https://en.wikipedia.org/wiki?curid=46687675", "title": "Independent Production Fund", "text": "Independent Production Fund\n\nThe Independent Production Fund (IPF) is a Canadian private independent foundation that supports the production of Canadian dramatic digital media entertainment content and television series. It also provides professional development services and training to digital media producers and creators, in English and in French. See also entry (in French).\n\nIn 1990 Maclean Hunter Limited, a former Canadian communications company, created the Maclean Hunter Television Fund with a capital endowment of $29.2 M restricted in perpetuity, as a result of a Decision by the Canadian Radio-Television and Telecommunications Commission (CRTC). The Fund was incorporated federally as a corporation without share capital and was granted charitable status. Its mandate was to fund television drama series and undertake industry training with the interest generated by the endowment and return on investments.\n\nThe Fund mandate was extended to undertake the administration of other independent private funds supporting the Canadian film, television and digital media industry: the Cogeco Program Development Fund launched in 1993, the Bell Fund (1997) and a series of other short-term industry Funds.\n\nIn 1994 Maclean Hunter was acquired by Rogers Communications, and the Fund was renamed the Independent Production Fund. A five-member board of directors representing different sectors of the production industry governed the Fund’s activities.\n\nIn 1999 the CRTC approved the IPF as a \"Canadian Independent Production Fund\" eligible to receive contributions from Broadcast Distribution Undertakings (BDU's). In 2017, Cogeco Communications directed its annual Broadcast Distribution Undertaking (BDU) contributions to the IPF to establish the Cogeco TV Production Program. \n\nFrom 1991 to 2010 the IPF invested over $47M in 251 Canadian television drama series. In 2010, the IPF’s mandate was revised to focus funding on drama series created for new digital platforms. It allocates nearly $2M per year from the interest generated by the endowment and recoupment of its funding investments, to original digital drama series. From 2010-2017 the IPF invested $12.8M in 114 short form scripted digital series.\n\n\nAs of 2017, the IPF has supported 251 television projects, 422 professional development activities and 114 original online series which represents nearly $65M in funding.\n"}
{"id": "27721700", "url": "https://en.wikipedia.org/wiki?curid=27721700", "title": "Industrial computed tomography", "text": "Industrial computed tomography\n\nIndustrial computed tomography (CT) scanning is any computer-aided tomographic process, usually X-ray computed tomography, that uses irradiation to produce three-dimensional internal and external representations of a scanned object. Industrial CT scanning has been used in many areas of industry for internal inspection of components. Some of the key uses for industrial CT scanning have been flaw detection, failure analysis, metrology, assembly analysis and reverse engineering applications. Just as in medical imaging, industrial imaging includes both nontomographic radiography (industrial radiography) and computed tomographic radiography (computed tomography).\n\n\"Line beam scanning\" is the traditional process of industrial CT scanning. X-rays are produced and the beam is collimated to create a line. The X-ray line beam is then translated across the part and data is collected by the detector. The data is then reconstructed to create a 3-D volume rendering of the part.\n\nIn \"cone beam scanning\", the part to be scanned is placed on a rotary table. As the part rotates, the cone of X-rays produce a large number of 2D images that are collected by the detector. The 2D images are then processed to create a 3D volume rendering of the external and internal geometries of the part.\n\nIndustrial CT scanning technology was introduced in 1972 with the invention of the CT scanner for medical imaging by Godfrey Hounsfield. The invention earned him a Nobel Prize in medicine, which he shared with Allan McLeod Cormack. Many advances in CT scanning have allowed for its use in the industrial field for metrology in addition to the visual inspection primarily used in the medical field (medical CT scan).\n\nVarious inspection uses and techniques include part-to-CAD comparisons, part-to-part comparisons, assembly and defect analysis, void analysis, wall thickness analysis, and generation of CAD data. The CAD data can be used for reverse engineering, geometric dimensioning and tolerance analysis, and production part approval.\n\nOne of the most recognized forms of analysis using CT is for assembly, or visual analysis. CT scanning provides views inside components in their functioning position, without disassembly. Some software programs for industrial CT scanning allow for measurements to be taken from the CT dataset volume rendering. These measurements are useful for determining the clearances between assembled parts or the dimension of an individual feature.\n\nTraditionally, determining defects, voids and cracks within an object would require destructive testing. CT scanning can detect internal features and flaws displaying this information in 3D without destroying the part. Industrial CT scanning (3D X-ray) is used to detect flaws inside a part such as porosity, an inclusion, or a crack.\n\nMetal casting and moulded plastic components are typically prone to porosity because of cooling processes, transitions between thick and thin walls, and material properties. Void analysis can be used to locate, measure, and analyze voids inside plastic or metal components.\n\nTraditionally, without destructive testing, full metrology has only been performed on the exterior dimensions of components, such as with a coordinate-measuring machine or with a vision system to map exterior surfaces. Internal inspection methods would require using a 2D X-ray of the component or the use of destructive testing. Industrial CT scanning allows for full non-destructive metrology.\n\nImage-based finite element method converts the 3D image data from X-ray computed tomography directly into meshes for finite element analysis. Benefits of this method include modelling complex geometries (e.g. composite materials) or accurately modelling \"as manufactured\" components at the micro-scale.\n\n"}
{"id": "27160355", "url": "https://en.wikipedia.org/wiki?curid=27160355", "title": "Korea Financial Telecommunications &amp; Clearings Institute", "text": "Korea Financial Telecommunications &amp; Clearings Institute\n\nKorea Financial Telecommunications and Clearings Institute(KFTC, in Korean 금융결제원) is a non-profit organization which manages several inter-bank payment systems in South Korea.\n\n\nCashier's Check Truncation<br>\nLocal L/C Clearing<br>\nCorporate Purchasing Fund Bill Truncation<br>\nElectronic Bonds<br>\nManagement of Dishnored Bills<br>\n\n\nPaper based Giro(Bill)<br>\nElectronic Giro(Direct Debit / Direct Credit)(Similar to Automatic Clearing House)<br>\nInternet Giro(Electronic Bill Payment)\n\n\nCD/ATM Network<br>\nIFT Network(Inter-bank Fund Transfer Network)<br>\nHOFINET(Inter-bank Home/Firm Banking Network)<br>\nK-Cash Network(Electronic Money Network)<br>\nCLS Network(and SWIFT Representative Office in Korea)\n\n\nAccredited Certification for Internet/mobile banking(PKI based)<br>\nKF-ISAC(Information Sharing and Analysis Center)<br>\nRetirement Pension Record Keeping\n"}
{"id": "40776935", "url": "https://en.wikipedia.org/wiki?curid=40776935", "title": "List of Azerbaijani inventions and discoveries", "text": "List of Azerbaijani inventions and discoveries\n\nAzerbaijani inventions and discoveries are inventions and discoveries by Azerbaijani scientists and researchers, both locally and while working at overseas research institutes.\n\n\n\n\n\n\n"}
{"id": "41046749", "url": "https://en.wikipedia.org/wiki?curid=41046749", "title": "Long steel products", "text": "Long steel products\n\nIn steel industry terminology long steel products or long products refers to steel products including wire, rod, rail, and bars as well as types of steel structural sections and girders.\n\nThe term long products may include hot rolled bar, cold rolled or drawn bar, rebar, railway rails, wire, rope (stranded wire), woven cloth of steel wire, shapes (sections) such as U, I, or H sections, and may also include ingots from continuous casting, including blooms and billets. Fabricated structural units, such bridge sections are also classed as long products. The definition excludes \"Flat Products\" - slab, plate, strip and coil, tinplate, and electrical steel; and also excludes certain tubular products including seamless and welded tube.\n\nLong products find general use in construction industries, and in capital goods sectors.\n"}
{"id": "27423857", "url": "https://en.wikipedia.org/wiki?curid=27423857", "title": "Melbourne Centre for Nanofabrication", "text": "Melbourne Centre for Nanofabrication\n\nMelbourne Centre for Nanofabrication (MCN) is located in Clayton, Victoria, next to the Australian Synchrotron.\nMCN is the Victorian node of the Australian National Fabrication Facility (ANFF) and is a collaborative initiative between federal and state governments, CSIRO, Monash University, The University of Melbourne, Swinburne University of Technology, La Trobe University, Deakin University and RMIT University. It is also the headquarters to the ANFF.\n\nMCN’s ultimate purpose is to fill the gap in Australia for open access, multi-scale, multi-disciplinary nanofabrication infrastructure. \nThe mission of MCN is to facilitate the integration of nanotechnology techniques into the Research and Development activities that support Australia’s innovation and manufacturing economies.\n\nMCN is based at a purpose-built facility, adjacent to the Australian Synchrotron. Approximately half of the central facility’s research space consists of clean rooms (class 100 and 10,000) and the other half is occupied by biochemical laboratories.\n\n\n\n"}
{"id": "1520931", "url": "https://en.wikipedia.org/wiki?curid=1520931", "title": "Micronet 800", "text": "Micronet 800\n\nMicronet 800 was an information provider (IP) on Prestel, aimed at the 1980s personal computer market. It was an online magazine that gave subscribers computer related news, reviews, general subject articles and downloadable telesoftware.\n\nUsers would log onto the Prestel network (which was usually a local call) and then access the Micronet 800 home page by entering *800# (hence the name) on their modem or computer. Most Micronet 800 members would have their default main index page set to page 800 automatically.\n\nThe name Micronet 800 derives from its home page, 800, on the BT Prestel videotext service.\n\nMicronet 800 derived from the earlier development in 1980 and 1981 of 'Electronic Insight' by Bob Denton. Electronic Insight was a Prestel-based feature-and-price-comparison site listing computers, calculators and other electronic and IT products, whose main page was on page 800 of Prestel. Electronic Insight was acquired by Telemap Group, a part of EMAP, East Midland (note, not Midlands) Allied Press, in 1982 on the recommendation of Richard Hease, a number of whose computer magazines EMAP had just bought. Telemap had been formed in 1981 to explore the opportunities of British Telecom's Prestel videotext service. It had been looking at the horticultural market that EMAP served with a number of magazine titles, notably providing a 'Closed User Group' purchasing network for garden centre businesses, complementing EMAP's printed 'Garden Trade News' magazine. But horticulturalists and IT proved not to be a natural marriage, and the service had insufficient users to make it viable.\n\nRichard Hease, in 1982 Chairman of EMAP's Computer & Business Press which had acquired Electronic Insight, organised a pitch to the Telemap Group by David Babsky of a projected interactive online computer magazine to replace the existing content of Electronic Insight. Babsky showed a 'dummy issue' of the intended online magazine, programmed in Integer BASIC on an Apple II computer. Hease suggested that there be several different 'areas' of the magazine, with titles such as MicroNews, MicroNet (for those interested in networking), etc., and Babsky proposed that the entire project be called 'Micronet 800' to ensure that it could be easily found by anyone using Prestel, as its page number would be part of its name. Hease and Denton negotiated with BT Prestel for a special relationship that would rank it alongside the Nottingham Building Society's plans for its Homelink as the two key thrusts for Prestel.\n\nHease negotiated with then telecoms minister John Butcher a £25 subsidy for Micronet subscribers to have their homes equipped free with a telephone jack-socket for the relevant modem.\n\nThe Telemap editorial staff was first based at 8 Herbal Hill, Clerkenwell, London (after the preliminary discussions and presentation at EMAP's offices in Hatton Garden), and the technical staff in an EMAP building in Peterborough. In 1986 the technical staff moved down to the London building.\n\nTelemap was to be the base for Micronet 800 and the editorial development of the site. Hease's and Denton's Prism Micro Products, the exclusive distributor of Sinclair Computers in the UK, was charged with developing the required modems for the enterprise, to ensure that Micronet 800's pages could be accessed by such 'microcomputers' as Apple II, Sinclair ZX81, BBC Microcomputer, Dragon, IBM PCs, Commodore PETs, and subsequently the Sinclair Spectrum and QL, Lynx, Commodore VIC 20 and 64 and others of the first wave of 1980s home computers.\n\nAlthough fast by contemporary standards, Prestel modems were quite slow from today's point of view (1200 baud download, 75 upload) and the display was just 24 lines of 40 characters, with seven colours and very simple block graphics. Yet Micronet 800 had versions of many of the Internet's subsequent features, especially an interactive 'ChatLine' (similar to Internet Relay Chat) developed by Mike Brown, who joined Micronet 800 from the Council for Educational Technology, where he'd devised a standard UK format for downloadable programs which became known as 'telesoftware'.\n\nMicronet 800 was quite similar in scope to, and compatible with, the German Bildschirmtext and French Minitel services, but Minitel achieved volume sales for its terminals by the simple expedient of replacing paper telephone books with their terminals. Based on its success, Minitel proved resilient against the Internet adoption in France.\n\nFor Micronet, Denton negotiated that the interested parties would all agree to adopt the CET, Council for Educational Technology, format for telesoftware - one of two then competing formats. Telesoftware allowed users to download software directly from the Prestel site. Micronet then negotiated with hobbyist computer groups to provide applications and utilities that would be listed on, and be downloadable from, the Micronet 800 site. Approximately 50% of software - for Sinclair, Apple, BBC Micro, IBM, etc. - was available at no cost, and the other 50% was paid for by the automatic addition of the cost of the software to the subscriber's telephone bill.\n\nPrism developed a broad range of modems from a simple acoustic coupler to integrated 'network interfaces' for each of the early home and personal computers. Prism models included the VTX5000, the only modem custom designed for the popular Sinclair ZX Spectrum, and the more general purpose Modem 1000 and Modem 2000. These were ready-to-use out of a box, so that the buyer would get the modem with all relevant leads, cards (if necessary) and software to connect with Micronet.\n\nSome 25,000 subscribers were eventually signed up to Micronet 800 to make it the largest CUG, Closed User Group, on Prestel; its total user base peaked at 90,000. Micronet achieved over 1.1 million page views a week. Its first subscriber, who joined on its opening day, 1 March 1983, was Jeremy Dredge, an estate agent from Thames Ditton in Surrey. Its 10,000th subscriber was Tom Corcoran, a director of BBC television's Top Of The Pops.\n\nIn 1985 Telemap saw that Prism was preoccupied with its Sinclair computer distribution agency and in developing Prism's own 'luggable' Wren microcomputer, so prospective Micronet subscribers were then sent a list of several other modem suppliers.\n\nFollowing Prism's collapse in 1985 and the subsequent purchase of their stock by Telemap, and in a bid to increase take-up, Micronet 800 encouraged users by giving away a free modem to new users subscribing for a year.\n\nHowever, in a move that saw the demise of Micronet, Prestel priced the home user out of the service with a new pricing structure, adding time charges on top of the phone charges for evening access which effectively killed off home usage even though the network was under-utilized during the 6pm to 8am time-slot. Today this remains the peak usage time of the Internet.\n\nMany of the lessons learned with respect to online publishing and interactive services were pioneered by Micronet 800 and became every bit as important with the growth of the Internet.\n\nBT became the majority shareholder in 1987 (after a previous 19% Telemap stake had been sold to Bell Canada) initially managing the company as part of BT Spectrum, its Value Added Services Group, before passing the group to BT Prestel. In 1988 the company passed a milestone by becoming the only Value Added Data service to become profitable. In 1989 BT finally acquired the entire company, moved it into a BT building (Dialcom House) in Apsley, just outside Hemel Hempstead in Hertfordshire, and folded the business into first the Dialcom Group along with the rest of the BT Prestel companies and Telecom Gold and subsequently BT Managed Network Services.\n\nIn 1991 along with all its online services, BT closed the service deciding to focus on providing network services and transferred the subscriber base to Compuserve which subsequently became AOL in the UK.\n\nThe Micronet service closed 31 October 1991. It had 10,000 members at closure and was \"easily the largest online service in the UK specialising in microcomputing\". Despite this apparent success, this was less than 10% of the number of users they were predicting having shortly after launch.\n\nMicronet/Telemap Management:\n\n\nMicronet editors:\n\n\nOther editorial staff\n\nProduction team:\n\nRichard Tyner- Software sales and acquisition,\n\nMarketing Team:\n\nOther contributors:\n\n\nQuotes:\n\n\"There is no future for online services aimed at domestic computer users\" - Michael Collins, the department head of Prestel/Telecom Gold Business Services, stated in a meeting with Paul Needs. [February 1990 - Paul Needs]\n\n\"Micronet is to communication in the 80s what the [Gutenberg] Bible was to the Middle Ages\" - David Babsky, Micronet Editor, 1984.\n\nMicronet 800 pioneered many public online services, such as Multi User Games, long before the Internet was in widespread use.\n\n"}
{"id": "58005323", "url": "https://en.wikipedia.org/wiki?curid=58005323", "title": "Mika McKinnon", "text": "Mika McKinnon\n\nMika McKinnon is a Canadian field geophysicist, disaster researcher, and science communicator. She is currently a co-investigator of the SETI Institute's Project ESPRESSO and science adviser to the science fiction television series Stargate Atlantis and Stargate Universe.\n\nMcKinnon received her Bachelor of Science in Physics from the University of California, Santa Barbara in 2005, attending the College of Creative Studies. There, she re-launched the Society of Physics Students chapter and led a student colloquia on science in fiction. She received her Master of Science in Geophysics from the University of British Columbia in 2010. Her graduate work centered on assessing and managing risk of landslides using statistical models to map their physical characteristics to better predict landslide runout and reduce the number of casualties and the extent of the damage.\n\nMcKinnon's research interests center on disaster management, preparedness, and communication, working at the intersection of scientific research, advocacy and policy. In the policy arena, she resolved to apply her expertise in both science and communication to teach science to disaster managers, revising Federal Emergency Management Agency's (FEMA) science curriculum for emergency managers as a contractor and working on several projects with Natural Resources Canada. \n\nMcKinnon is currently a co-investigator of Project ESPRESSO, lending her expertise in terrestrial landslides and hazard mapping towards the project's goal of characterizing extraterrestrial target surfaces—asteroids, comets, and moons—and reducing other operational risks for robots and humans in space exploration. The project, which represents a consortium of seven partner institutions, was proposed in response to NASA's 2016 call for Solar System Exploration Research Virtual Institute nodes, and is one of thirteen selected projects resulting from that call. She holds a joint appointment at the SETI Institute, one of ESPRESSO's partner institutions. \n\nMcKinnon's science communication efforts range from popular science writing to consulting on the hit television show Stargate. More recently, McKinnon has consulted on Doomsday: 10 Ways the World Will End, No Tomorrow, Madam Secretary, and . In a profile with her alma mater, UCSB, she notes that her interest in communication stemmed from the media's misrepresentation of a major landslide in the Pacific Northwest. She was a contributing editor for Gawker Media, providing coverage on popular science topics for io9 and later became a science writer for Gizmodo. Her bylines cover a range of topics including space exploration, dinosaur discovery, the convergence of science and art, and disaster preparedness. Her writing appearing outlets like in Wired UK, Smithsonian Magazine, Ars Technica, and Astronomy. She currently volunteers for the National Academy of Sciences Science & Entertainment Exchange, providing subject matter expertise to the entertainment industry for more accurate depictions of science in the media. \n"}
{"id": "49804321", "url": "https://en.wikipedia.org/wiki?curid=49804321", "title": "Moley Robotics", "text": "Moley Robotics\n\nMoley Robotics is a robotics company headquartered in London, United Kingdom. It was founded by Mark Oleynik in 2015 to create service robots for kitchen use. It is best known for creating the first robot kitchen called The Moley Robotic Kitchen (MK1).\n\nMark Oleynik, a computer scientist, founded the Moley Robotics in 2014 as a way to have good food at home without the skills to make it. In 2015, Moley Robotics partnered started working on a robotic kitchen. Subsequently, the company introduced its Robotic Kitchen. It made its debut at the Hannover Messe industrial robotics trade fair in Hannover, Germany in April 2015.\n\nThe Robotic Kitchen has been distinguished in several international science and engineering events. In May 2015, the Robotic Kitchen won the \"Best of the Best\" CES Shanghai award in China. In January 2016, the prototype was finalist at the first edition of the UAE AI & Robotics Award in the international category, health sector. The consumer version of the Robotic Kitchen is slated to launch in 2018.\n\nThe current prototype of the Moley Robotic Kitchen includes two robotic arms with hands equipped with tactile sensors, an oven, an electric stove, a dishwasher and a touchscreen unit. These artificial hands can pick up and interact with most kitchen equipment, such as blenders, whisks, knives and the hob.\n\nIt captures, with an integrated 3D camera and wired glove, the entire work of a human chef and upload it into a database. The chef's actions are translated into digital movements using gesture recognition algorithms created in collaboration with Stanford University and Carnegie Mellon University professors. Later, The Robotic Kitchen reproduces the whole sequence of actions to cook an identical meal from scratch.\n\nIn the current prototype, the user operates the installation via a built-in touchscreen or smartphone application with cooking ingredients prepared in advance and put in preset locations. Moley Robotic's objective in the future is to enable the user to select from a library of over 2,000 recorded recipes.\n\n"}
{"id": "1424363", "url": "https://en.wikipedia.org/wiki?curid=1424363", "title": "NASSCOM", "text": "NASSCOM\n\nThe National Association of Software and Services Companies (NASSCOM) is a trade association of Indian Information Technology (IT) and Business Process Outsourcing (BPO) industry. Established in 1988, NASSCOM is a non-profit organisation.\n\nNASSCOM organises the Indian Leadership Forum. It gives a platform to the developing companies to network and present their product. Notable events include:\n\nNASSCOM Emerge 50 is an annual Indian awards ceremony honoring the most promising and innovative startups in software and technology domains. The awards, first presented in 2009, are overseen by NASSCOM.\n\nThe winners are chosen after a yearlong scrutiny process by a panel of eminent jury. Every year the top 10 startups are given the collective title of The League of 10.\n\nMembers of NASSCOM are Indian Co software development, software services, IT-enabled/BPO services. NASSCOM role has primarily been to make sure that service quality and enforcement of Intellectual Property Rights have been properly implemented in the Indian software and BPO industry. As of June 2007, more than 1,110 information technology companies in India were members of NASSCOM, which included domestic software/ITES companies along with multinationals operating within India. NASSCOM has a Mentorship Programme for the mid-sized companies. This is a six-month engagement, which will help the organisation to develop a better assessment of their strengths and weaknesses.\n\nEmployees and members of executive council of NASSCOM include:\n"}
{"id": "31334548", "url": "https://en.wikipedia.org/wiki?curid=31334548", "title": "Nannochloropsis and biofuels", "text": "Nannochloropsis and biofuels\n\n\"Nannochloropsis\" is a genus of alga within the heterokont line of eukaryotes, that is being investigated for biofuel production. One marine \"Nannochloropsis\" species has been shown to be suitable for algal biofuel production due to its ease of growth and high oil content (28.7% of dry weight), mainly unsaturated fatty acids and a significant percentage of palmitic acid. It also contains enough unsaturated fatty acid linolenic acid and polyunsaturated acid (>4 double bonds) for a quality biodiesel.\n\nOil productivity is defined as the oil produced by the algae per day per liter of culture, which is dependent on both growth rate and lipid content. Growth rate indicates how rapid the algae grow and lipid content indicates the percentage of dry weight that is lipid. In most of the studies, these two factors are investigated independently. Under normal growth conditions, \"Nannochloropsis\" does not reach its optimal oil production. Several conditions, including stress conditions, have been reported to increase oil content in \"Nannochloropsis\".\n\nNitrogen is essential for algal growth. Within a cell, nitrogen is involved in synthesizing amino acids, nucleic acids, chlorophyll, and other nitrogen-containing organic compounds. In a study in which 30 different microalgal strains were screened, one \"Nannochloropsis\" strain was shown to obtain 60% lipid content after nitrogen deprivation, up from 30% under normal growth conditions. This strain was selected for further scale-up experiments in a photobioreactor under natural sunlight. Lipid productivity increased to 204 milligram per liter per day(mg/L/day) under nitrogen starvation conditions, almost twice as much as the 117 mg/L/day under sufficient nutrition conditions. Based on these results, a two-phase cultivation process, with a nutrient sufficient phase to rapidly increase number of cells prior to a nitrogen deprived phase to boost lipid content, was found to produce more than 90 kg of lipid per hectare per day in outdoor cultures. I, depending on sun light conditions.\n\nAlgae play an important role in earth's carbon cycle. Algae generate large deposits of carbonate minerals and organic compounds that are resistant to microbial breakdown, thereby contributing to the reduction of CO level in the atmosphere, making the earth more habitable for other organisms. The CO concentration also has an effect on algae growth and lipid content. In \"Nannochloropsis oculata\", the effect of CO concentration on biomass production and lipid accumulation was investigated. The results showed that the lipid content of \"N. oculata\" increased from 30.8% to 50.4% upon 2% CO aeration. Thus, this algal strain is recommended to be grown with 2% CO to maximize lipid production.\n\nA light-acquisition problem exists for aquatic algae since submergence can reduce light intensity and dampen photosynthesis. For land plants, full-spectrum of sunlight, from blue to red light, is available for chlorophyll absorption. However, red light is absorbed in the few meters of water closest to the surface of an aquatic environment and the light environment beneath these few meters is mainly blue-green in quality. Algal cells are likely to be transported to such depth of water, and many have evolved a mechanism to better absorb blue-green light. A \"Nannochloropsis\" species isolated from Singapore's coastal water was investigated under different light wavelengths (red, green, blue, and white) and intensities to determine the optimal condition for biomass productivity and lipid production. The maximum fatty acid yield was achieved for both phototrophic (sunlight is the only energy source) and mixotrophic (utilize both sunlight and energy from carbon source) cultures at 55.15 and 111.96 mg/L, respectively, under cell exposure to blue light (470 nm). The biomass productivity of the algae also peaked under blue light for both cultures.\n\nIn another study, UV-A (320 - 400 nm) was added to the photosynthetically active light spectrum (400 - 700 nm) to culture \"Nannochloropsis\" in order to study the effect of UV-A on growth and lipid accumulation. The results showed that modulated UV-A usage can lead to an increase in growth rate.\n\nAlginate, or alginic acid, is a natural acidic linear polysaccharide derived from seaweed. It is composed of α-L-guluronate and β-D-mannuronate. Bulk alginate is widely used in the food industry and for medical purposes due to its unique characteristics such as high viscosity in aqueous solution and gel-forming property in the presence of calcium ions. Previous studies have also shown that alginate oligosaccharides may act as growth promoting agents on some plant cells. The effect of an alginate oligosaccharide mixture (AOM) on \"N. oculata\" was studied. The growth rate of this alga was significantly increased by AOM. Moreover, AOM appeared to alleviate the algicidal effect of Cu significantly. These results suggests that AOM can be used a growth promoting supplement for \"N. oculata\" culture.\n\nTemp has significant impact on algal growth rate, cell size, and biochemical composition. Either in natural habitats of algae or in controlled growth systems, temperature will vary. In a study on the effect of temperature on growth rate and lipid content, temperature showed no significant relation with \"Nannochloropsis sp.\" growth rate between 15 °C and 30 °C. However, another algal species in the same study, \"Isochrysis galbana\", showed increased growth rate as the temperature increased from 15 °C to 30 °C. In many algal species, increased lipid content is also observed under increased temperature.\n\nDifferent culture technologies are being tested with \"Nannochloropsis\" to determine most cost-effective culture methods.\n\nTubular systems are the most widely used commercial culture systems. They are usually made of polypropylene acrylic or polyvinylchloride pipes which have small internal diameters and an air pump that generates bubbles to mix and agitate the culture. They usually use artificial light but some models use natural light. The major disadvantages of this type of system, varying among individual systems, are high space requirements, cleaning, low efficiency, low gas transfer, and hydrodynamic stress. Several other problems also occur, including growth of the algae on the tube wall leading to blockage of light, high oxygen concentration inhibition of growth, and limits on the length of the tube in single run. Coiled systems were developed mainly to improve space utilization. The main advantages are: 1) large ratio of culture volume to surface area and optimized light penetration depth; 2) easy control over temperature and contaminants; 3) easy spatial distribution of fresh air and CO; 4) better CO transfer through the culture; and 5) automated sensor providing cell concentration reads.\n\nRaceway ponds are shallow ponds between 10 and 50 cm deep. They are less expensive to build compared to photobioreactors, and have low-energy-consuming paddlewheels to mix the circulate the culture. The culture is open to the atmosphere, thus allowing liquid evaporation to stabilize the temperature. They are widely used to culture several algae and cynobacteria. However, only limited types of microalgae can be grown in open ponds. Other disadvantages include large area required, low efficiency of light utilization, poor gas/liquid transfer, no temperature control, high risk of contamination, and low final density of culture.\n\nFlat-plates are a closed system such as helical-tubular photobioreactor. They have a flat surface screen made of glass or optical light film for the even reception of light. A study compared the cultures of \"Nannochloropsis sp.\" in open ponds and photobioreactors, tubular and flat-plate. Horizontal tubular photobioreactor was not shown to be economically viable. Both open pond and flat-plate photoreactors were proven to be feasible, given that the lipid content of biomass could be increased to 60%. However, neither system is competitive due to the low cost of petroleum.\n\nSome algae can grow faster under mixotrophic conditions rather than under photoautotrophic conditions. Under mixotrophic conditions, both light and a carbon substrate such as sugars can provide energy for cell growth. Although adding glucose increased the growth rate of the algal culture, it also adds extra cost to algal lipid production. This needs to be further studied to determine economical feasibility.\n\nA unique bio-technology-based environmental system can utilize flue gas from coal burning power plants. This method is reported to decrease the cost of algae production significantly. It also absorbs excessive CO, thus alleviating greenhouse effect.\n\nSeveral different technologies were reported to convert algal culture into biofuel or biodiesel.\n\nA direct transesterification of \"Nannochloropsis\" biomass to biodiesel production can be achieved using either microwave or ultrasound radiation. The microwave method was shown to be the simplest and most efficient method for one-stage direct transesterification.\n\nIn a recent study, \"Nannochloropsis sp.\" cells was pyrolyzed. The results showed that bio-oils obtained from catalytic pyrolysis had lower oxygen content and higher heating value than those from direct pyrolysis. The catalytic pyrolysis product mainly contained aromatic hydrocarbons. These properties make \"Nannochloropsis\" residue a very promising candidate for algal fuel production.\n"}
{"id": "20073227", "url": "https://en.wikipedia.org/wiki?curid=20073227", "title": "Operational Land Imager", "text": "Operational Land Imager\n\nThe Operational Land Imager (OLI) is a remote sensing instrument aboard Landsat 8, built by Ball Aerospace & Technologies. Landsat 8 is the successor to Landsat 7 and was launched in 2013.\n\nOLI is a push broom scanner that uses a four-mirror telescope with fixed mirrors.\n\nOLI operates alongside TIRS (Thermal Infrared Sensor) onboard the LDCM. The build and design of OLI differs from previous generations of instruments, while still maintaining data continuity with archived Landsat data from the last 40 years by keeping the same spectral and spatial resolutions of previous instruments.\n\nOLI aids the Landsat-8 mission in the imaging of Earth's surface and the collection of moderate resolution data that is used to monitor changing trends on the surface and evaluate how land usage changes over time. The images and data that OLI has helped collect have practical applications today in agriculture, mapping, and monitoring changes in snow, ice, and water.\n\nOLI is a pushbroom sensor that operates in the visible (VIS) and short wave infrared (SWIR) spectral regions. It has a swath width of , which means it can image the entire Earth over a repeating cycle of 16 days. OLI uses nine channels, which range from wavelengths of 443 nm to 2,200 nm. Of these nine channels, eight are multispectral and one is panchromatic. The eight multispectral channels have a spatial resolution, and the panchromatic channel has a spatial resolution of .\n\nWhile the spectral and spatial resolution of OLI's channels were kept the same as prior instruments in order to maintain data continuity with the entire Landsat archive, two spectral bands (the first a blue visible channel and the second an infrared channel) were added. These bands were designated as band 1 and band 9, and serve as an enhancement from previous instruments, which lacked these channels. Band 1 was created to locate and determine water resources and investigate coastal areas, and band 9 serves a unique purpose of detecting cirrus clouds.\n\nOLI has several different applications due to the many different bands. Band 1 is helpful in imaging shallow water resources and tracking aerosols. Bands 2, 3, and 4 are in the visible spectrum and are helpful in creating true color composite images. Band 5 is helpful for ecology purposes and can help determine vegetation index or NDVI. Bands 6 and 7 are useful in geology and can help in distinguishing different saturated and unsaturated rocks and soils. Band 8 is helpful in creating images with very high resolution and precision. Band 9 is used for detecting different types of clouds.\n\n"}
{"id": "18243283", "url": "https://en.wikipedia.org/wiki?curid=18243283", "title": "Philip Baxter", "text": "Philip Baxter\n\nSir John Philip Baxter (7 May 1905 – 5 September 1989), better known as Philip Baxter, was a British chemical engineer. He was the second director of the University of New South Wales from 1953, continuing as vice-chancellor when the position's title was changed in 1955. Under his administration, the university grew from its technical college roots into the \"fastest growing and most rapidly diversifying tertiary institution in Australia\". Philip Baxter College is named in his honour.\n\nBaxter was born in Wales, but grew up in England, entering the University of Birmingham at age 16. He joined Imperial Chemical Industries as a chemical engineer, and became head of the Central Laboratory of its General Chemicals Division in Widnes, investigating the chemistry of chlorine and fluorine. He was elected to the Widnes Municipal Council in 1939, a seat he held until 1949. During the Second World War he provided James Chadwick with samples of uranium hexafluoride for Tube Alloys, the British wartime nuclear weapons program, and later established a pilot plant to produce it in Widnes. In 1944, in response to a request from the Americans for someone with expertise in both uranium chemistry and industrial operations, he went to Oak Ridge, Tennessee, to assist the Manhattan Project.\n\nBaxter was recruited by the then-New South Wales University of Technology as a professor of chemical engineering in 1949. He became one of the most prolific public advocates of nuclear power for Australia. He served as chairman of the Australian Atomic Energy Commission from 1957 to 1972 and the International Atomic Energy Agency from 1969 to 1970. He oversaw the construction of the High Flux Australian Reactor (HIFAR) at Lucas Heights. He also founded the National Institute of Dramatic Art (NIDA), and, as the chairman of the Sydney Opera House Trust, brought the Sydney Opera House to completion and opening on 20 October 1973.\n\nJohn Philip Baxter was born in Machynlleth in Wales on 7 May 1905, the younger child of John Baxter and his wife Mary Netta Morton. He had an older sister, Muriel. His father was a telegraphist with the British Post Office, as was his mother before her marriage. The family moved to Hereford in England, where he attended Hereford High School for Boys. At school, he enjoyed playing tennis.\n\nBaxter passed the Northern Universities Matriculation examination when he was 14, but found that this was too young to be admitted to a university. He passed it again the following year, and then passed the University of London Matriculation examination the year after, when he was 16, after which he was permitted to enter the University of Birmingham. He was interested in metallurgy and enrolled in a science course. He earned his Bachelor of Science degree with first class honours in 1925, and his Master of Science the following year. His main form of recreation remained tennis. With the help of a £250 per annum James Watt research scholarship, he wrote his 1928 Doctor of Philosophy (PhD) thesis on \"The combustion of carbonic oxide\", under the supervision of F. H. Burstall.\n\nA recommendation from Burstall helped Baxter secure a research engineer position with Imperial Chemical Industries (ICI) in Billingham, where a new chemical factory had been established to make sodium hydroxide. Here he met Lilian May Thatcher, who worked as a stenographer in nearby Stockton-on-Tees. The two became engaged, but before they could marry, Alexander Fleck had Baxter transferred to ICI's new General Chemicals Division in Widnes as head of the Central Laboratory. Baxter and Lilian were married in the register office in Stockton-on-Tees on 17 August 1931. Three years later they designed and built their own home in Farnworth, where they lived until 1949. They had four children: a daughter, Valerie; an adopted son, Peter; and sons Dennis and Roderick.\n\nThe Central Laboratory's focus at this time was on the chemistry of chlorine and fluorine. Electrolysis of salt water produced chlorine and sodium hydroxide (caustic soda), but there was not as much demand for the chlorine, so ICI was eager to create new products using chlorine that it could sell. New products that were created included various solvents, chlorinated rubber, and Lindane, an insecticide developed in collaboration with ICI's Agricultural Research Station at Jealott's Hill. Baxter personally received a number of patents for his work. He became Research Manager of the General Chemicals Division in 1935. He reorganised the Central Laboratory into seven sections, each with its own Assistant Research Manager, an organisational structure known as \"Baxter and the seven dwarves\", which was not generally considered a success at the time.\n\nIn addition to his scientific work, Baxter was involved in local politics. He was elected to the Widnes Municipal Council in 1939, a seat he held until 1949. He was leader of the Conservative Party in the Council, and chairman of the local party organisation in the Widnes UK Parliament constituency.\n\nIn 1940, with Britain at war during the Second World War, Baxter was approached by physicist James Chadwick, who asked if he could supply a sample of uranium hexafluoride. Baxter did so on a personal basis, using research money. Chadwick then came back and asked Baxter if he could supply a much larger amount, about . This time, Baxter demurred. The production of such a large quantity would require the purchase of additional equipment. ICI's hydrofluoric acid plant was out of commission and would require repairs. The bill for that amount of uranium hexafluoride would therefore come to around £3,000, a sum that he could not spend from research funds. He would require permission from senior ICI management, who would want to know if it would assist the war effort and whether 3 kg was all that would be required, or if further orders could be expected. Chadwick then revealed that this was part of a secret project, codenamed Tube Alloys, the object of which was to build an atomic bomb. Permission from ICI management was secured by Frederick Lindemann making a direct approach to Lord Melchett, one of ICI's directors.\n\nICI pilot plants for producing of pure uranium metal and of uranium hexafluoride per diem commenced operation in Widnes in mid-1943. The following year, in response to a request from the Americans for someone with expertise in both uranium chemistry and industrial operations, Baxter was sent to Oak Ridge, Tennessee, for three months to assist the Manhattan Project. The electromagnetic separation process had problems with the efficiency of its chemical processes for uranium recovery. At the request of the director of the Manhattan Project, Brigadier General Leslie R. Groves, Jr., Baxter subsequently returned to Oak Ridge for an indefinite period, this time with his family. He became the personal assistant to the general manager, with responsibility for coordinating research, development and production activities. For his wartime nuclear weapons work, Baxter was made an Officer of the Order of the British Empire on 1 January 1946.\n\nBaxter returned to Widnes as Research Director of the General Chemicals Division after the war ended in 1945. He became a director of\nThorium Ltd, a company half owned by ICI that was involved in the production of radioactive substances, and was a consultant to the British nuclear energy program. His General Chemicals Division at Widnes was involved in chemical separation of uranium products, which he considered a patriotic duty. Baxter was personally responsible for the research and development that was the basis for the design of the Springfields uranium hexafluoride plant, and was a member of the committee that oversaw the construction of the chemical separation plant to extract plutonium. Much to Baxter's disappointment, ICI management did not see nuclear energy as being part of its core mission, and disengaged from it. He also became dismayed at political and economic developments in the United Kingdom after the Conservatives lost office in 1945.\n\nIn 1949, Baxter heard that the New South Wales University of Technology was looking for a professor of chemical engineering. He applied, and was offered the job. Baxter and his family packed their belongings and sailed to Australia on the ocean liner \"Orcades\", arriving in Sydney on 16 January 1950. They bought a house in Enfield, where Baxter would reside for the rest of his life. At the time the university was located in temporary accommodation on the grounds of the Sydney Technical College campus in Ultimo. Baxter became the head of a new School of Chemical Engineering that was created on his arrival, but he initially had only one full-time staff member as most of the instruction was carried out by part-time staff. Although he had no previous teaching experience, he turned out to be a good, well-organised lecturer, and he worked closely with his first postgraduate students, whose research was into fields that Baxter had been involved with in England.\n\nA number of other professors disliked the name and organisational structure of the university, and wanted it to shake off the association with \"technology\" and become a \"real university\". While Baxter did not side with them, contending that the university's association with the government provided funding and facilities, most of what he did moved in that direction. He hired full-time staff, and broadened the scope of the subjects taught and the research carried out. A Department of Food Technology was the first, and for many years the only, one of its kind in Australia. He replaced the diploma-level with a new bachelor of science in chemical engineering degree, offering conversion courses to allow students to upgrade their diplomas to degrees. The first chemical engineering students had enrolled in 1949, and nine graduated with the bachelor of science degree in 1952. The School of Chemical Engineering became the first school to relocate to the new campus in Kensington in 1953.\n\nIn February 1952, Baxter became deputy-director of the university. He defeated Arthur Denning in an election for director in December, assuming the position on 1 January 1953. As Denning had argued for the retention of the university's links with the Public Service Board, it was widely seen as a victory for the proponents of autonomy, but with his industrial background Baxter had little in common with the professors who came from academia, and did not share their views on the role and organisation of a university. The university did receive autonomy on 1 July 1954, and when traditional university titles were adopted in 1955, Baxter became vice-chancellor.\nA committee appointed by the Prime Minister, Robert Menzies, and chaired by Keith Murray, recommended in 1957 that a medical school be established at Kensington. Its creation, followed by that of a Faculty of Arts, prompted the university to change its name to the University of New South Wales (UNSW) in 1958. Baxter established a number of unusual schools. He created a School of Nuclear Engineering in anticipation that a nuclear power industry would be established in Australia. He also created schools of Textile Technology, Wool Technology, Food Technology and Highway Engineering and Traffic Engineering. The School of Business Administration and an Institute of Administration was established in 1960, and ultimately the Australian Graduate School of Management in 1969. When the Faculty of Arts was created, he insisted that all Arts students take at least one science subject.\n\nIn Baxter's eyes, the main role of the university was to provide trained engineers and technologists for industry, which he believed was suffering from a critical skill shortage. With this constantly in mind, he pursued a rapid expansion of the university. Student numbers grew from 3,751 when he became vice-chancellor in 1955, to over 15,988 when he retired in 1969. This was far short of the university of 25,000 students that he had hoped to create, but in the 1950s the idea of a university that large horrified some academics. Baxter considered it wasteful when good students returned to academia after only a brief time working in industry, but even more so when they dropped out or failed their courses. While his critics saw high failure rates as the inevitable result of lowering admission standards in order to boost student numbers, Baxter viewed it as result of poor teaching and inefficient administration. He walked out of a heated Staff Association meeting on the matter. To help industry, he established Unisearch Limited, a company that provided expert assistance in 1959.\n\nBaxter's biggest clashes with academic staff were over governance issues. He had a preference for industry-style organisation, with clear lines of authority. In 1957, he created a committee of deans, chaired by himself, that met every Wednesday. This became the vice-chancellor's advisory committee in 1960. Through this he created an administrative mechanism which set the university free from the traditional constraints. He did away with the election of deans by the faculty, replacing it with one in which deans were appointed by the University Council on his recommendation. This provided for more efficient administration, but violated the academic tradition of a dean being \"primus inter pares\" among academic colleagues. This aroused the ire of academic staff, and in the end a compromise was reached whereby each faculty elected a chairman who was responsible for academic matters, while the council appointed a dean who was in charge of administrative matters. This proved to be quite successful, and was retained by Baxter's successors. Ronald Hartwell characterised Baxter's administration as \"unusual, undemocratic and unacademic\". His successor, Rupert Myers, declared that: \"History will show Sir Philip Baxter to have been a great educational administrator who built a fine university and made many beneficial changes in the ways universities handled their business and interacted with governments and the community.\"\n\nOn 19 August 1949, the Australian government created the Industrial Atomic Energy Policy Committee, chaired by Mark Oliphant and with Baxter as a member, to advise government on the development of nuclear power in Australia. On the committee's own recommendation, it was superseded by the Atomic Energy Policy Committee in April 1952. This in turn was replaced by the Australian Atomic Energy Commission (AAEC) in November. The AAEC was run by a three commissioners, with Jack Stevens as chairman, Baxter as vice-chairman and Hugh Murray from the Mount Lyell Mining and Railway Company as the third member.\n\nBaxter succeeded Stevens as chairman in 1957. He worked part-time, spending Fridays at the AAEC until he retired from the UNSW in 1969. Thereafter he was full-time, until he retired from the AAEC on 15 April 1972. He was also the Australian member on the Board of Governors of the International Atomic Energy Agency when it was created in 1957 and again from 1964 to 1972, serving as its chairman from 1969 to 1970.\n\nThe AAEC established its offices in Coogee. Baxter and Frederick White from the Commonwealth Scientific and Industrial Research Organisation (CSIRO) visited nuclear facilities in Britain, the United States and Canada in 1953. As there were few people in Australia with nuclear technology experience, he arranged with Sir John Cockcroft for Australians to be seconded to the British Atomic Energy Research Establishment in Harwell. Some 60 Australian scientists were working there by 1956. During a symposium on \"Atomic Power in Australia\" held at the New South Wales University of Technology on 31 August and 1 September 1954, Baxter clashed with Harry Messel, the head of the School of Physics at the University of Sydney, over the latter's plans to build a low-power experimental nuclear reactor.\nBaxter would have none of it; he wanted a \"real reactor, not a low-power toy\". He prevailed; the government authorised a High Flux Australian Reactor (HIFAR). Based on the DIDO reactor at Harwell, HIFAR was cooled and moderated by heavy water, and fuelled with enriched uranium. Construction began at Lucas Heights in October 1955, and HIFAR went critical on 26 January 1958. By the time he became full-time chairman in 1969, the AAEC had grown to an organisation with a staff of over 1,000 and a budget of $8.5 million. The AAEC explored the country looking for uranium deposits, developed technology for uranium enrichment, and produced designs for nuclear reactors.\n\nMore controversially, Baxter pressed the case for Australia to have the capacity to produce nuclear weapons. In 1958, he proposed creating a facility at Mount Isa to breed weapons-grade plutonium. His proposals found a sympathetic ear in Prime Minister John Gorton, who approved plans to build a CANDU reactor at Jervis Bay in 1969. An access road was built and ground was cleared, but Gorton lost office on 10 March 1971, and the project was suspended, and later cancelled by his successors. Nailing his colours to the mast, Baxter continued his advocacy. In 1975 he declared:\n\nFor his work as chairman of the Atomic Energy Commission, Baxter was made a Companion Order of St Michael and St George in the Queen's Birthday Honours on 13 June 1959, and was created a Knight Commander of the Order of the British Empire in the Civil Division in the 1965 Queen's Birthday Honours on 12 June 1965.\n\nBaxter had been a member of the drama group in Stockton-on-Tees, and had performed on stage with University Drama Club at UNSW, sometimes with his daughter Valerie. In response to a request from the Australian Broadcasting Commission and the Australian Elizabethan Theatre Trust in 1958 for improved training of actors, he founded the National Institute of Dramatic Art (NIDA). By 2013, NIDA was regarded as one of the world's finest drama schools, with alumni that included Cate Blanchett, Judy Davis, Mel Gibson, Baz Luhrmann and Hugo Weaving.\n\nFrom 1969 to 1975, Baxter was part-time and unpaid chairman of the Sydney Opera House Trust. He had recently retired from the UNSW, but the job was no sinecure. The architect, Jørn Utzon, had left, construction was behind schedule and over budget, and specialist staff needed to be recruited. Baxter put the project under his unpopular but decisive grip, and brought the Sydney Opera House to completion and opening on 20 October 1973.\n\nBaxter was awarded honorary doctorates by Montreal University in 1958, the University of Newcastle in 1966, the University of Queensland in 1967, Loughborough University in 1970 and the UNSW in 1971. Philip Baxter College at the UNSW was named after him in 1966. He died in Haberfield on 5 September 1989, and his remains were cremated. He was survived by three of his children; his wife Lilian had died on 27 July 1989, and his son Peter had died in a motor vehicle accident in the 1960s. His papers are in the archives at the University of New South Wales.\n\n"}
{"id": "11598208", "url": "https://en.wikipedia.org/wiki?curid=11598208", "title": "Portable CD player", "text": "Portable CD player\n\nA portable CD player is a portable audio player used to play compact discs. The first audio player released was the Discman D-50 by Sony.\n\nThe basic features of a portable CD player are:\n\n\nThe play and pause feature allows the user to pause in the middle of the track (song) and resume it at the same place the listener left off at once the play button is hit again. The stop feature stops the track allowing the user to then switch tracks easily. The fast forward and rewind feature will either fast forward or rewind the track the amount of time you hold the button down. The liquid crystal display provides a visual of how much battery is left, what track (number) is currently playing, and the amount of time elapsed on the track. Some portable CD players can play CD-R/CD-RW discs and some can play other formats such as MP3-encoded audio.\n\nThe 8 cm CD provides a smaller alternative to the normal 12 cm CD (although with a lower capacity). Miniature players exist that only play this format.\n\nLike a full-size CD player, a portable CD player reads the bumps and grooves using a laser. With its photocell (a device that detects any sort of light reflection given off of certain area), it determines whether there is a reflection of light given off from the CD when the laser hits. Depending on the light reflection, the photocell will return a 1 (if there is no reflection) or a 0 (if there is any light reflection). When its laser hits a groove on a CD, it will not reflect any light, making it a 1. When its laser hits a bump or any other surface on the CD, a light reflection will appear making it a 0. The series of data from 0–1 on the CD is then transformed by a digital to analog converter, to recreate the shape of a sound wave. The headphones then amplify the sounds and then the audio is now able to be heard.\n\nSome portable CD players do not play recordable CDs (CD-R, CD-RW) because of the way these CDs are recorded. A consumer-recorded CD is recorded by making marks in a thin layer of organic dye, which leads to incompatibility with some CD players. For some users of CD-Rs, the solution to this is to burn the CD at a slower speed or use a different brand of recordable CDs.\n\nPortable CD players are declining in popularity since the rise in popularity of Portable media players that play digital audio files including the iPod and smartphones. Before digital audio players became popular, many switched over to MiniDisc as an alternative to CDs, due to the compact size of the MiniDisc format.\n\n"}
{"id": "10255700", "url": "https://en.wikipedia.org/wiki?curid=10255700", "title": "Poultry CRC", "text": "Poultry CRC\n\nThe Poultry Cooperative Research Centre, or Poultry CRC, is a joint venture established and supported under the Australian Government's Cooperative Research Centres Program.\n\nThe Poultry CRC's major challenge is to help Australia achieve sustainable, ethical poultry production in the face of population growth and climate change.\n\nIn July 2008, the Poultry CRC won the World's Poultry Science Association (WPSA) Industry/Organisation Award at the World’s Poultry Congress in Brisbane in recognition of an outstanding contribution to the development of the poultry industry. In August 2012 the Poultry CRC was awarded WPSA's Education Award at the World's Poultry Congress in Brazil for their exceptional contribution to poultry education. In addition, the Poultry CRC received an Australian Collaborative Innovation Award in May 2012.\n\nThe Poultry CRC is an unincorporated joint venture between seven Essential Participants and is governed by a skills-based board. It manages its research and development programs through a public company, Poultry CRC Ltd. The Poultry CRC is headquartered at the University of New England in Armidale, New South Wales, and has an extensive collaborative network comprising researchers, educators and support staff from its participating organisations. The original Poultry CRC was established on 1 July 2003, with the current CRC an extension to 2017.\n\n\n\nThree integrated Programs address the major challenge of meeting increasing demand for ‘clean and green’ poultry products and maintaining food security in the face of climate change and population growth.\n\nThis requires innovative approaches to:\n\n\nProgram 1 - Health and Welfare - aims to maintain a sustainable, healthy and welfare conscious supply of poultry products despite newly emerging pathogens, increasing environmental concerns about production and changing consumer demands. For many diseases, current vaccines fail to offer complete protection. Changes in production, including reduced reliance on antibiotics and increased use of free-range systems, require a complete reconsideration of protection strategies. The CRC brings together the world’s best research and capability providers in diagnostics, animal health products and welfare to develop a holistic solution. This program of highly integrated projects builds on the success of the first CRC while adding key capabilities, such as vaccine delivery methods, mass sequencing of antigens, and therapeutics.\n\nProgram 2 – Nutrition and Environment - addresses resource utilisation and reduction of environmental impacts, including the emission of odours and greenhouse gases (GHG).\n\nProgram 3 – Safe and Quality Food Production - focuses on controlling food-borne illnesses related to poultry products (\"i.e.\", \"Campylobacter\" for chicken meat and \"Salmonella\" for eggs) and addresses major consumer dissatisfaction associated with inconsistency in egg quality.\n\nThirty-five postgraduates are being integrated within the three Programs' research projects, involving immediate and direct interaction with end-users. The CRC expects several to find direct employment with industry, some through its internships program.\n\n\n\n"}
{"id": "521079", "url": "https://en.wikipedia.org/wiki?curid=521079", "title": "Retaining wall", "text": "Retaining wall\n\nRetaining walls are relatively rigid walls used for supporting the soil mass laterally so that the soil can be retained at different levels on the two sides.\nRetaining walls are structures designed to restrain soil to a slope that it would not naturally keep to (typically a steep, near-vertical or vertical slope). They are used to bound soils between two different elevations often in areas of terrain possessing undesirable slopes or in areas where the landscape needs to be shaped severely and engineered for more specific purposes like hillside farming or roadway overpasses.\n\nA retaining wall is a structure designed and constructed to resist the lateral pressure of soil, when there is a desired change in ground elevation that exceeds the angle of repose of the soil.\n\nA basement wall is thus one kind of retaining wall. But the term usually refers to a cantilever retaining wall, which is a freestanding structure without lateral support at its top. These are cantilevered from a footing and rise above the grade on one side to retain a higher level grade on the opposite side. The walls must resist the lateral pressures generated by loose soils or, in some cases, water pressures.\n\nEvery retaining wall supports a \"wedge\" of soil. The wedge is defined as the soil which extends beyond the failure plane of the soil type present at the wall site, and can be calculated once the soil friction angle is known. As the setback of the wall increases, the size of the sliding wedge is reduced. This reduction lowers the pressure on the retaining wall.\n\nThe most important consideration in proper design and installation of retaining walls is to recognize and counteract the tendency of the retained material to move downslope due to gravity. This creates lateral earth pressure behind the wall which depends on the angle of internal friction (phi) and the cohesive strength (c) of the retained material, as well as the direction and magnitude of movement the retaining structure undergoes.\n\nLateral earth pressures are zero at the top of the wall and – in homogenous ground – increase proportionally to a maximum value at the lowest depth. Earth pressures will push the wall forward or overturn it if not properly addressed. Also, any groundwater behind the wall that is not dissipated by a drainage system causes hydrostatic pressure on the wall. The total pressure or thrust may be assumed to act at one-third from the lowest depth for lengthwise stretches of uniform height.\n\nUnless the wall is designed to retain water, It is important to have proper drainage behind the wall in order to limit the pressure to the wall's design value. Drainage materials will reduce or eliminate the hydrostatic pressure and improve the stability of the material behind the wall. Drystone retaining walls are normally self-draining.\n\nAs an example, the International Building Code requires retaining walls to be designed to ensure stability against overturning, sliding, excessive foundation pressure and water uplift; and that they be designed for a safety factor of 1.5 against lateral sliding and overturning.\n\nGravity walls depend on their mass (stone, concrete or other heavy material) to resist pressure from behind and may have a 'batter' setback to improve stability by leaning back toward the retained soil. For short landscaping walls, they are often made from mortarless stone or segmental concrete units (masonry units). Dry-stacked gravity walls are somewhat flexible and do not require a rigid footing.\n\nEarlier in the 20th century, taller retaining walls were often gravity walls made from large masses of concrete or stone. Today, taller retaining walls are increasingly built as composite gravity walls such as: geosynthetics such as geocell cellular confinement earth retention or with precast facing; gabions (stacked steel wire baskets filled with rocks); crib walls (cells built up log cabin style from precast concrete or timber and filled with granular material); or soil-nailed walls (soil reinforced in place with steel and concrete rods).\n\nCantilevered retaining walls are made from an internal stem of steel-reinforced, cast-in-place concrete or mortared masonry (often in the shape of an inverted T). These walls cantilever loads (like a beam) to a large, structural footing, converting horizontal pressures from behind the wall to vertical pressures on the ground below. Sometimes cantilevered walls are buttressed on the front, or include a counterfort on the back, to improve their strength resisting high loads. Buttresses are short wing walls at right angles to the main trend of the wall. These walls require rigid concrete footings below seasonal frost depth. This type of wall uses much less material than a traditional gravity wall.\n\nSheet pile retaining walls are usually used in soft soil and tight spaces. Sheet pile walls are made out of steel, vinyl or wood planks which are driven into the ground. For a quick estimate the material is usually driven 1/3 above ground, 2/3 below ground, but this may be altered depending on the environment. Taller sheet pile walls will need a tie-back anchor, or \"dead-man\" placed in the soil a distance behind the face of the wall, that is tied to the wall, usually by a cable or a rod. Anchors are then placed behind the potential failure plane in the soil.\n\nBored pile retaining walls are built by assembling a sequence of bored piles, proceeded by excavating away the excess soil. \nDepending on the project, the bored pile retaining wall may include a series of earth anchors, reinforcing beams, soil improvement operations and shotcrete reinforcement layer.\nThis construction technique tends to be employed in scenarios where sheet piling is a valid construction solution, but where the vibration or noise levels generated by a pile driver are not acceptable.\n\nAn anchored retaining wall can be constructed in any of the aforementioned styles but also includes additional strength using cables or other stays anchored in the rock or soil behind it. Usually driven into the material with boring, anchors are then expanded at the end of the cable, either by mechanical means or often by injecting pressurized concrete, which expands to form a bulb in the soil. Technically complex, this method is very useful where high loads are expected, or where the wall itself has to be slender and would otherwise be too weak.\n\nSoil nailing is a technique in which soil slopes, excavations or retaining walls are reinforced by the insertion of relatively slender elements – normally steel reinforcing bars. The bars are usually installed into a pre-drilled hole and then grouted into place or drilled and grouted simultaneously. They are usually installed untensioned at a slight downward inclination. A rigid or flexible facing (often sprayed concrete) or isolated soil nail heads may be used at the surface.\n\nA number of systems exist that do not consist of just the wall, but reduce the earth pressure acting directly on the wall. These are usually used in combination with one of the other wall types, though some may only use it as facing, \"i.e.\", for visual purposes.\n\nThis type of soil strengthening, often also used without an outside wall, consists of wire mesh \"boxes\", which are filled with roughly cut stone or other material. The mesh cages reduce some internal movement and forces, and also reduce erosive forces. \nGabion walls are free-draining retaining structures and as such are often built in locations where ground water is present. However, management and control of the ground water in and around all retaining walls is important.\n\nMechanically stabilized earth, also called MSE, is soil constructed with artificial reinforcing via layered horizontal mats (geosynthetics) fixed at their ends. These mats provide added internal shear resistance beyond that of simple gravity wall structures. Other options include steel straps, also layered. This type of soil strengthening usually needs outer facing walls (S.R.W.'s – Segmental Retaining Walls) to affix the layers to and vice versa.\n\nThe wall face is often of precast concrete units that can tolerate some differential movement. The reinforced soil's mass, along with the facing, then acts as an improved gravity wall. The reinforced mass must be built large enough to retain the pressures from the soil behind it. Gravity walls usually must be a minimum of 50 to 60 percent as deep or thick as the height of the wall, and may have to be larger if there is a slope or surcharge on the wall.\n\nCellular confinement systems (geocells) are also used for steep earth stabilization in gravity and reinforced retaining walls with geogrids. Geocell retaining walls are structurally stable under self- weight and externally imposed loads, while the flexibility of the structure offers very high seismic resistance. The outer fascia cells of the wall can be planted with vegetation to create a green wall.\n\n"}
{"id": "2255444", "url": "https://en.wikipedia.org/wiki?curid=2255444", "title": "Retention basin", "text": "Retention basin\n\nA retention basin, sometimes called a wet pond, wet detention basin or stormwater management pond, is an artificial lake with vegetation around the perimeter, and includes a permanent pool of water in its design. It is used to manage stormwater runoff to prevent flooding and downstream erosion, and improve water quality in an adjacent river, stream, lake or bay. \n\nIt is distinguished from a detention basin, sometimes called a \"dry pond\", which temporarily stores water after a storm, but eventually empties out at a controlled rate to a downstream water body. It also differs from an infiltration basin which is designed to direct stormwater to groundwater through permeable soils.\n\nWet ponds are frequently used for water quality improvement, groundwater recharge, flood protection, aesthetic improvement or any combination of these. Sometimes they act as a replacement for the natural absorption of a forest or other natural process that was lost when an area is developed. As such, these structures are designed to blend into neighborhoods and viewed as an amenity.\n\nIn urban areas, impervious surfaces (roofs, roads) reduce the time spent by rainfall before entering into the stormwater drainage system. If left unchecked, this will cause widespread flooding downstream. The function of a stormwater pond is to contain this surge and release it slowly. This slow release mitigates the size and intensity of storm-induced flooding on downstream receiving waters. Stormwater ponds also collect suspended sediments, which are often found in high concentrations in stormwater water due to upstream construction and sand applications to roadways.\n\nStorm water is typically channeled to a retention basin through a system of street and/or parking lot storm drains, and a network of drain channels or underground pipes. The basins are designed to allow relatively large flows of water to enter, but discharges to receiving waters are limited by outlet structures that function only during very large storm events.\n\nRetention ponds are often landscaped with a variety of grasses, shrubs and/or wetland plants to provide bank stability and aesthetic benefits. Vegetation also provides water quality benefits by removing soluble nutrients through uptake. In some areas the ponds can attract nuisance types of wildlife like ducks or Canada geese, particularly where there is minimal landscaping and grasses are mowed. This reduces the ability of foxes, coyotes and other predators to approach their prey unseen. Such predators tend to hide in the cattails and other tall, thick grass surrounding natural water features.\n\nDepth of retention ponds is of critical importance, for removal of pollutants and the volume of fish that could be inhabiting the pond. Urban fishing continues to be one of the fastest growing fishing segments as new suburban neighbourhoods are built around these aquatic areas\n\nA retention basin can also be a part of a nuclear reactor used to contain a core meltdown.\n\n"}
{"id": "48337586", "url": "https://en.wikipedia.org/wiki?curid=48337586", "title": "Reverse-contrast typefaces", "text": "Reverse-contrast typefaces\n\nA reverse-contrast letterform is a typeface or custom lettering in which the stress is reversed from the norm: instead of the vertical lines being the same width or thicker than horizontals, which is normal in Latin-alphabet writing and especially printing, the horizontal lines are the thickest. The result is a dramatic effect, in which the letters seem to have been printed the wrong way round. Originally invented in the early nineteenth century as attention-grabbing novelty display designs, modern font designer Peter Biľak, who has created a design in the genre, has described them as \"a dirty trick to create freakish letterforms that stood out.\"\n\nReverse-contrast letters are rarely used for body text, being more used in display applications such as headings and posters, in which the unusual structure may be particularly eye-catching. They were particularly common in the nineteenth century, and have been revived occasionally since then. They could be considered as slab serif designs because of the thickened serifs, and are often characterised as part of that genre.\n\nThe reverse-contrast effect has been extended to other kinds of typeface, such as sans-serif designs and designs more suitable for extended text passages. The design style, also known as \"reverse-stroke\" or \"horizontal-stress\", has no connection to reverse-contrast \"printing\", where light text is printed on a black background.\n\nThroughout the development of the modern Latin alphabet with an upper-case based on Roman square capitals and lower-case based on handwriting, it has been the norm for the vertical lines to generally be slightly thicker than the horizontals. Early 'roman' or 'antiqua' type followed this model, often placing the thinnest point of letters at an angle and downstrokes heavier than upstrokes, mimicking the writing of a right-handed writer holding a quill pen. (The Hebrew alphabet, in contrast, is normally \"reverse-contrast\" from a Latin-alphabet perspective, as the verticals are lighter.)\n\nFrom the arrival of roman type around 1475 to the late eighteenth century, relatively little development in letter design took place, as most fonts of the period were intended for body text, and they stayed relatively similar in design and rooted in traditions of Italian humanistic handwriting.\n\nStarting in the eighteenth century, typefounders developed what are now called transitional and then Didone types. These typefaces had a far greater amount of stroke contrast than before, with the difference in stroke width much greater than in earlier types. These had more constructed letterforms, matching the steely calligraphy of the period, and daringly slender horizontals and serif details that could show off the increasingly high quality of paper and printing technology of the period. In addition, these typefaces had a strictly vertical stress: without exception, the vertical lines were thicker than the horizontals, creating a much more geometric and modular design.\n\nA second major development of the period was the arrival of the printed poster and increasing use of signpainting and printing for publicity and advertising material, for example in newspaper adverts. This caused a desire to develop eye-catching new types of letters. As a result, new styles of lettering and \"display type\" began to appear, such as \"fat face\" bold faces, sans serif letters, apparently inspired by classical antiquity, and then slab-serifs. These letterforms were a new departure and not simply larger versions of traditional serif letters. Presumably to be more eye-catching, these new styles of letter were often extremely bold.\n\nThe earliest known reverse contrast typeface dates to about 1821. It was created by the H.W. Caslon company in London, presumably as a parody of the crisp, high-contrast \"Didone\" typefaces and lettering of the period. A caps-only design, the foundry's steel master punches survive in the collection of the St Bride Library, London. Nicolete Gray, quoting French historian Francis Thibaudeau, wrote in \"Nineteenth Century Ornamented Typefaces\" that the style appeared (presumably as lettering) in France slightly earlier during the First French Empire (1804-1815). \n\nThe Caslon company called the type \"Italian\". Gray proposes that the style was \"probably\" Italian in origin, although it was certainly very common for display types to be given unusual, exotic names as a brand; for example, \"Egyptian\" was often applied to sans- (and then slab-) serif types of the period and \"Antique\" to slab-serifs. Reverse-contrast designs do slightly resemble \"capitalis rustica\" writing from Ancient Rome, which also has emphatic horizontal serifs at top and bottom, although this may be a coincidence. Other names such as \"Egyptian\" were also used.\n\nRegarding design, the Caslon Italian typeface is very clearly \"conceptual\" in design, deliberately taking aspects of the fat face and one by one inverting them. It has very thick serifs, so the gap between the serifs and the main strokes making up the letters is very small, as can be seen on letters such as 'E' and 'S'. To make the effect even more shocking, the triangular serifs were inverted (becoming thinner as they met the letter, not thicker), and the thicker line on the 'A' was moved from its normal position on the right (the natural position matching the handwriting of a right-handed writer) to the left, making a letter that seems to have been drawn the wrong way round. Writing for \"Print\" magazine, Paul Shaw described it as \"one of the most bizarre slab serif types of the 19th century.\" Barnes and Schwartz describe it as \"perverse [but] done with sureness and confidence.\"\n\nWithin a few years of their introduction the printer and social reformer Thomas Curson Hansard had described them as \"typographic monstrosities\":\nFashion and Fancy commonly frolic from one extreme to another. To the razor-edged fine lines and serifs of [Didone] type...a reverse [of sans and slab serifs] has succeeded...the property of which is, that the strokes which form the letters are all of one uniform thickness! After this, who would have thought that further extravagance could have been conceived? It remains, however, to be stated, that the ingenuity of one founder has contrived a type in which the natural shape is reversed, by turning all the serifs and fine strokes into fats, and the fats into leans. Oh! sacred shades of \"[eminent typefounders of the past]\" Moxon and , of Baskerville and Bodoni! What would ye have said of the typographic monstrosities here exhibited , which Fashion in our age has produced?\n\nIn contrast, Walter Tracy described the design in 1986 as \"a jeu d’esprit, not meant to be judged in conventional aesthetic terms.\"\n\nThe design was apparently successful, since it rapidly spread to the United States and elsewhere. For example, the George Bruce company of New York displays Caslon's Italian (or a close copy) in its 1828 specimen book. Many versions of similar design were released, both as metal and as wood type. Expansions of the concept included italic faces, confusingly called \"Italian Italic\", backslanted and sans-serif versions.\n\nPeter Biľak's Karloff is a sophisticated revival of the original reverse-contrast faces designed partly through mathematical interpolation. Biľak's group digitally inverted the contrast of a conventional Didone font: this allowed Biľak to create a family of normal and matching reverse-contrast fonts with upper- and lower-case, together with a low-contrast slab serif design, all with the same basic structure. These have been released as Karloff Positive, Negative and Neutral, the name referring to Boris Karloff. Village Type's Arbor like Karloff adds a lower-case, while Match & Kerosene's Slab Sheriff is caps-only, with a 'A' featuring the conventional stress on the right. A revival with extremely high contrast is Kris Sowersby's Maelstrom. Other unreleased revivals have reportedly been made for private use by Paul Barnes and Justin Howes.\n\nThe reverse-contrast idea fused with a separate genre of slab-serif face, known as Clarendons. In the mid to late nineteenth century, it became popular for type foundries to offer reverse-contrast variants of Clarendon, a popular slab serif type genre, especially in the United States, creating large block serifs at the top and bottom of the letter. This was known as \"French Clarendon\" type. The advantage of French Clarendon type was that it allowed very large, eye-catching serifs while the letters remained narrow, suiting the desire of poster-makers for condensed but very bold type. French Clarendon designs were often created in wood type, used for large-print letters on posters. They are often associated with \"wild-west\" printing and seen on circus posters and wanted notices in western movies, although the style was really used in many parts of the world during this period. The style is sometimes called 'circus letter'. The practice was less popular with more artisanal printers: DeVinne commented in 1902 that \"To be hated, it needs but to be seen.\" In Europe the style was sometimes called Italienne, matching the Caslon name. In contrast to the original Caslon type, which features horizontals in the middle of the letter (like the cross-bar in the H) that are often but not always thick, French Clarendon types have the only thick lines at the top and botton, and all inner horizontals thin, and are generally less \"conceptually\" reverse-contrast, with serifs in a more conventional alignment apart from the thick strokes at top and bottom.\n\nDavid Shields reports that the first type of the genre is the \"French Antique\" face of Robert Besley & Co. (which had released and copyrighted the first Clarendon face) in an 1854 specimen. The University of Texas at Austin, which maintains a large archive of American wood type, reports that the first known wood French Clarendon type was issued by William Hamilton Page in 1865. Their collection shows the many other names used for wood type which display reverse-contrast characteristics, including 'Celtic', 'Belgian', 'Aldine' and 'Teutonic', as well as Italian again and sometimes 'Tuscan' or 'Etruscan' also. (At the time a separation did not fully exist between genre names and typeface names, so these may be the names of individual types, or if they proved popular the name of the subgenre they created.) At least one sans-serif typeface with reverse contrast was developed in this period.\n\nA variety of more modern adaptations have been made of the style, including Robert Harling's Playbill (1938) and more recently Adrian Frutiger's Westside, URW++'s Zirkus and Bitstream's P. T. Barnum.\n\nWriting on why he created a design in the genre, Frutiger, a designer better-known for his work in the sans-serif genre, commented:\nAs a type designer I wanted to draw something in every style. It's a matter of professional pride...I found the existing Italiennes with their big feet too harsh and strict...the fine curves in the serifs give \"Westside\" its own expression. A text set in this typeface looks like a weaving pattern...I really enjoyed drawing it. For one thing it was great fun.\n\nFrutiger decided to return to the Caslon type's pattern of all horizontals being thick apart from those on 'a' and 'e', which he felt could not be fitted into this system.\n\nBecause of their quirky, hand-made design, lighter versions of the French Clarendon style were popular for uses such as film posters in the 1950s and '60s.\n\nA well-reviewed modernisation of the style has been Trilby by David Jonathan Ross, who has written and lectured on the history of the genre. Released by Font Bureau, it is reminiscent of Clarendon revivals from the 1950s. It attempts to adapt the style to use in a much wider range of settings, going so far as to be usable for text. Bigfish is another modernisation inspired by lettering, in which the thickest stress is at the top. Some other adaptations have preserved the concept but changed genre, presenting sans-serif or script typefaces in the same style. Antique Olive of 1966 by Roger Excoffon is a well-known sans-serif design with subtle reverse-contrast aspects, particularly visible in its ultra-bold 'Nord' style, while Signo is an award-winning sans-serif reverse-contrast design from 2015.\n\n"}
{"id": "48853442", "url": "https://en.wikipedia.org/wiki?curid=48853442", "title": "Roadometer (odometer)", "text": "Roadometer (odometer)\n\nThe roadometer was a 19th-century device like an odometer for measuring mileage, towed by a wagon, invented in 1847 by William Clayton and Orson Pratt, Mormon pioneers. \n\nThe roadometer invented by William Clayton and Orson Pratt had cogs and gears made of wood. It recorded wheel revolutions by the mile and quarter-mile. They used their invention to provide an estimate of the distance their party traveled each day between Omaha, Nebraska, and Salt Lake City, Utah. Subsequently in 1849, it was attached to the wagon of Addison Pratt, to be used to record the daily mileage of the Jefferson Hunt wagon train that pioneered the Mormon Road from Salt Lake City to Los Angeles.\n"}
{"id": "29565483", "url": "https://en.wikipedia.org/wiki?curid=29565483", "title": "SUMCO", "text": "SUMCO\n\nSUMCO is listed on the first section of the Tokyo Stock Exchange and is a constituent of the Nikkei 225 stock index.\n\nThe company manufactures the following products:\n"}
{"id": "350717", "url": "https://en.wikipedia.org/wiki?curid=350717", "title": "Secretary desk", "text": "Secretary desk\n\nA secretary desk or escritoire is made of a base of wide drawers topped by a desk with a hinged desktop surface, which is in turn topped by a bookcase usually closed with a pair of doors, often made of glass. The whole is usually a single, tall and heavy piece of furniture.\n\nLike the slant top desk, the main work surface is a hinged piece of wood which is flat when open and oblique when raised to enclose secondary work surfaces such as small shelves, small drawers and nooks stacked in front of the user. Thus, like the Wooton desk, the fall front desk and others with a hinged desktop, and unlike closable desks with an unmovable desktop like the rolltop desk or the cylinder desk all documents and various items must be removed from the work surface before closing up.\n\nWhen closed, the secretary desk looks like a cross between a commode-dresser, a slant top desk and a book case. The secretary is one of the most common antique desk forms and has been endlessly reproduced and copied for home use in the last hundred years. Among home desk forms, it is the tallest, biggest and heaviest, excluding wall units and modular desks which typically can be disassembled for moving, or some of the biggest of the armoire desks, which are usually delivered unassembled.\n\nThe desk described here is most correctly termed a \"secretary and bookcase\". There is no unanimity on this term, even among specialists. In Europe the same piece of furniture has been called \"bureau and bookcase\" and then desk and bookcase. Also, the general public usually calls this kind of desk a \"secretary\", or \"secrétaire\". In a taxonomic sense one could sometimes say that all desks which have the capacity to close off the working surface are secretaries, while all others are simply desks, but such a division would be too broad to be useful. To add to the confusion, certain forms of the secretary desk are called \"escritoire\", usually when the bookcase section is covered with glazed panels instead of wooden doors, but the term \"escritoire\" is also sometimes used to define a very portable writing slope, which is it at the other extreme in terms of bulk and weight.\nWhen a secretary desk is cut in half vertically, so to speak, to provide a secretary desk half as wide as usual on one side and a glassed door cabinet on the other, this big piece of furniture is called a \"side-by-side secretary\". The term is also applied sometimes to very big pieces of furniture made up of three elements, one of them being a half-wide secretary desk. Until recently there was a good example of a side-by-side secretary in the second floor office of the historic home of John Muir in Martinez, California. The attic of this home also had a good example of a portable desk.\n\nOn most antique secretaries and also on most reproductions the user has to pull out two small wooden planks called sliders (sometimes \"lopers\") in order to support the desktop, before actually turning the desktop from its closed, angled, position to its normal horizontal working position. However, in quite a few of the antique versions a system of internal gears or levers connected both to the sliders and the hinged desktop automatically pushed the sliders out at the same time as the user pulled on the closed desktop to put it in its horizontal position. When the user closed it afterwards, the sliders would then retract automatically. In such a case, the secretary is also known as a mechanical desk like many other desk forms which have some sort of mechanism pushing out elements of the desk and then pulling them back in automatically.\n\nA secretary desk is, despite its name, generally not used by a person with the title of secretary, since this kind of desk is an antique form which is now extremely rare in the modern office, where a secretary (frequently called an administrative assistant) normally works.\n\n\n"}
{"id": "33213126", "url": "https://en.wikipedia.org/wiki?curid=33213126", "title": "Semex", "text": "Semex\n\nSemex full name Sharp Electrónica Mexico S.A. de C.V. is the semi-independent Mexican division of Japanese Sharp electronics corporation. It is responsible for the manufacture of all Sharp printed circuitboards, LED, LCD, and plasma panels, modules and televisions in North and South America and is the sole representative and distributor of Sharp products in Mexico.\n\nThe venture was formed in 1997 when a group of Mexican investors, the Mexican federal government and Sharp Electronics Japan signed a mutual agreement to open a factory in Baja California for the manufacture of Sharp CRT televisions and Sharp electronics components which would also begin to manufacture LCD televisions in 2001. By 1998 the factory had begun manufacturing home appliances and printed circuit boards with Kyoshas Mexican branch as well. In 2006 Sharp and Semex introduced a second plant in Baja California for the production of LCD panels, modules and televisions to address an increasing demand for flatscreen televisions in the US and Mexican markets. Currently Sharp builds its full range of 19, 26, 32, 40, 42, 46, 52, 60, 70 and 80 inch LCD and LED televisions including 3D models, printed circuitboards, white goods, LCD & LED panels and LCD modules at Semex's facilities. The average weekly salary for a worker is US$150, which is 20% above average industrial salary in Mexico.\n"}
{"id": "650912", "url": "https://en.wikipedia.org/wiki?curid=650912", "title": "Semi-submersible platform", "text": "Semi-submersible platform\n\nA semi-submersible platform is a specialised marine vessel used in a number of specific offshore roles including as offshore drilling rigs, safety vessels, oil production platforms, and heavy lift cranes. They are designed with good stability and seakeeping characteristics. Other terms for these platforms include \"semi-submersible\", \"semi-sub\", \nor simply \"semi\".\n\nWhile drillships are another type of drilling rig that can drill in ultra-deepwater—drillships are capable of holding more equipment—semisubmersibles are sometime chosen for their comparative stability.\n\nOffshore drilling in water depth greater than around 520 meters requires that operations be carried out from a floating vessel, since fixed structures are not practical. Initially in the early 1950s monohull ships such as CUSS I were used, but these were found to have significant heave, pitch and yaw motions in large waves, and the industry needed more stable drilling platforms.\n\nA semi-submersible obtains most of its buoyancy from ballasted, watertight pontoons located below the ocean surface and wave action. Structural columns connect the pontoons and operating deck. The operating deck can be located high above the sea level owing to the good stability of the design, and therefore is kept well away from the waves.\n\nWith its hull structure submerged at a deep draft, the semi-submersible is less affected by wave loadings than a normal ship. With a small water-plane area, however, the semi-submersible is sensitive to load changes, and therefore must be carefully trimmed to maintain stability. Unlike a submersible, a semi-submersible vessel is not supported by resting on the seabed.\n\nSemi-submersible vessels are able to transform from a deep to a shallow draft by deballasting (removing ballast water from the hull), thereby becoming surface vessels. Usually they are moved from location to location in this configuration. The heavy lift vessels use this capability to submerge the majority of their structure, locate beneath another floating vessel, and then deballast to pick up the other vessel as a cargo.\n\nThe semi-submersible design was first developed for offshore drilling activities. Bruce Collipp of Shell is regarded as the inventor.\nHowever, Edward Robert Armstrong may have paved the way with his idea of \"seadrome\" landing strips for airplanes in the late 1920s, since his idea involved the same use of columns on ballast tanks below the surface and anchored to the ocean floor by steel cables.\n\nWhen oil drilling moved into offshore waters, fixed platform rigs and submersible rigs were built, but were limited to shallow waters. The first jackup rigs were built when drilling equipment was needed in water depths greater than in the Gulf of Mexico.\n\nThe first semisubmersible arrived by accident in 1961. Blue Water Drilling Company owned and operated the four column submersible drilling rig \"Blue Water Rig No.1\" in the Gulf of Mexico for Shell Oil Company. As the pontoons were not sufficiently buoyant to support the weight of the rig and its consumables, it was towed between locations at a draught midway between the top of the pontoons and the underside of the deck. It was observed that the motions at this draught were very small, and Blue Water Drilling and Shell jointly decided that the rig could be operated in the floating mode.\n\nThe first purpose built drilling semi-submersible \"Ocean Driller\" was launched in 1963. Since then, many semi-submersibles have been purpose-designed for the drilling industry mobile offshore fleet.\n\nThe industry quickly accepted the semi-submersible concept and the fleet increased rapidly to 30 units by 1972.\n\nDrilling rig construction has historically occurred in boom periods and therefore \"batches\" of drilling rigs have been built. Offshore drilling rigs have been loosely classified in nominal \"generations\" depending upon the year built and water depth capability as follows:\n\nSemi-submersible rigs make stable platforms for drilling for offshore oil and gas. They can be towed into position by a tugboat and anchored, or moved by and kept in position by their own azimuth thrusters with dynamic positioning.\n\nThe IMO MODU Code is an accredited design and operational guideline for mobile offshore drilling units of the semi-submersible type.\n\nThe advantages of the semi-submersible vessel stability were soon recognized for offshore construction when in 1978 Heerema Marine Contractors constructed the two sister crane vessels called \"Balder\" and \"Hermod\". These semi-submersible crane vessels (SSCV) consist of two lower hulls (pontoons), three columns on each pontoon and an upper hull. Shortly after J. Ray McDermott and Saipem also introduced SSCVs, resulting in two new enormous vessels \"DB-102\" (now \"Thialf\") and \"Saipem 7000\", capable of lifting respectively 14,200 and 14,000 tons.\n\nDuring transit an SSCV is de-ballasted to a draught where only part of the lower hull is submerged. During lifting operations, the vessel is ballasted down. This way, the lower hull is well submerged. This reduces the effect of waves and swell. High stability is obtained by placing the columns far apart. The high stability allows them to lift extremely high loads safely.\n\nSemi-submersibles are particularly suited to a number of offshore support vessel roles because of their good stability, large deck areas, and variable deck load (VDL). Some of the most prominent vessels are;\n\nWhen oil fields were first developed in offshore locations, drilling semi-submersibles were converted for use as combined drilling and production platforms. These vessels offered very stable and cost effective platforms. The first semi-submersible floating production platform was the \"Argyll FPF\" converted from the \"Transworld 58\" drilling semi-submersible in 1975 for the Hamilton Brothers North Sea Argyll oil field.\n\nAs the oil industry progressed into deeper water and harsh environments, purpose-built production semi-submersible platforms were designed. The first purpose-built semi-submersible production platform was for the Balmoral field, UK North Sea in 1986.\n\nA summary of offshore semi-submersible oil production platforms is given in the following table derived from industry data.\n\n\n"}
{"id": "52455537", "url": "https://en.wikipedia.org/wiki?curid=52455537", "title": "Smart doorbell", "text": "Smart doorbell\n\nA smart doorbell is an internet-connected doorbell that notifies the smartphone of the home owner when a guest arrives to the entrance of the door. It activates when the guest presses the button of the doorbell, or alternatively, when the doorbell senses a guest with its built-in motion sensors. The smart door bell allows the home owner using the smartphone app to watch and talk with the guest by using the doorbell's built-in high-definition infrared camera and microphone. Some smart doorbells also allow the user to open to door to the guest remotely using a smart lock.\n\nOne of the earliest smart doorbells that entered to the market is the Ring Video Doorbell which was created by entrepreneur James Siminoff in 2012. Since then, several smart doorbells have been introduced to the market, some of them with additional, unique features.\n\nAlarming concerns regarding the security of the smart doorbells have been raised. Researchers at Pen Test Partners in the UK have analyzed the Ring smart doorbell and concluded that it's possible for an attacker to gain access to the homeowner’s wireless network by unscrewing the Ring, pressing the setup button and accessing the configuration URL. In another security issue that have been observed, a mix-up of two databases allowed some users of the Ring smart doorbell to view live footage from complete strangers' front porches.\n\n"}
{"id": "248932", "url": "https://en.wikipedia.org/wiki?curid=248932", "title": "Software development", "text": "Software development\n\nSoftware development is the process of conceiving, specifying, designing, programming, documenting, testing, and bug fixing involved in creating and maintaining applications, frameworks, or other software components. Software development is a process of writing and maintaining the source code, but in a broader sense, it includes all that is involved between the conception of the desired software through to the final manifestation of the software, sometimes in a planned and structured process. Therefore, software development may include research, new development, prototyping, modification, reuse, re-engineering, maintenance, or any other activities that result in software products.\n\nSoftware can be developed for a variety of purposes, the three most common being to meet specific needs of a specific client/business (the case with custom software), to meet a perceived need of some set of potential users (the case with commercial and open source software), or for personal use (e.g. a scientist may write software to automate a mundane task). Embedded software development, that is, the development of embedded software, such as used for controlling consumer products, requires the development process to be integrated with the development of the controlled physical product. System software underlies applications and the programming process itself, and is often developed separately.\n\nThe need for better quality control of the software development process has given rise to the discipline of software engineering, which aims to apply the systematic approach exemplified in the engineering paradigm to the process of software development.\n\nThere are many approaches to software project management, known as software development life cycle models, methodologies, processes, or models. The waterfall model is a traditional version, contrasted with the more recent innovation of agile software development.\n\nA software development process (also known as a software development methodology, model, or life cycle) is a framework that is used to structure, plan, and control the process of developing information systems. A wide variety of such frameworks has evolved over the years, each with its own recognized strengths and weaknesses. There are several different approaches to software development: some take a more structured, engineering-based approach to developing business solutions, whereas others may take a more incremental approach, where software evolves as it is developed piece-by-piece. One system development methodology is not necessarily suitable for use by all projects. Each of the available methodologies is best suited to specific kinds of projects, based on various technical, organizational, project and team considerations.\n\nMost methodologies share some combination of the following stages of software development:\n\nThese stages are often referred to collectively as the software development life-cycle, or SDLC. Different approaches to software development may carry out these stages in different orders, or devote more or less time to different stages. The level of detail of the documentation produced at each stage of software development may also vary. These stages may also be carried out in turn (a “waterfall” based approach), or they may be repeated over various cycles or iterations (a more \"extreme\" approach). The more extreme approach usually involves less time spent on planning and documentation, and more time spent on coding and development of automated tests. More “extreme” approaches also promote continuous testing throughout the development life-cycle, as well as having a working (or bug-free) product at all times. More structured or “waterfall” based approaches attempt to assess the majority of risks and develop a detailed plan for the software before implementation (coding) begins, and avoid significant design changes and re-coding in later stages of the software development life-cycle planning.\n\nThere are significant advantages and disadvantages to the various methodologies, and the best approach to solving a problem using software will often depend on the type of problem. If the problem is well understood and a solution can be effectively planned out ahead of time, the more \"waterfall\" based approach may work the best. If, on the other hand, the problem is unique (at least to the development team) and the structure of the software solution cannot be easily envisioned, then a more \"extreme\" incremental approach may work best.\n\nThe sources of ideas for software products are plentiful. These ideas can come from market research including the demographics of potential new customers, existing customers, sales prospects who rejected the product, other internal software development staff, or a creative third party. Ideas for software products are usually first evaluated by marketing personnel for economic feasibility, for fit with existing channels distribution, for possible effects on existing product lines, required features, and for fit with the company's marketing objectives. In a marketing evaluation phase, the cost and time assumptions become evaluated. A decision is reached early in the first phase as to whether, based on the more detailed information generated by the marketing and development staff, the project should be pursued further.\n\nIn the book \"Great Software Debates\", Alan M. Davis states in the chapter \"Requirements\", sub-chapter \"The Missing Piece of Software Development\"\nStudents of engineering learn engineering and are rarely exposed to finance or marketing. Students of marketing learn marketing and are rarely exposed to finance or engineering. Most of us become specialists in just one area. To complicate matters, few of us meet interdisciplinary people in the workforce, so there are few roles to mimic. Yet, software product planning is critical to the development success and absolutely requires knowledge of multiple disciplines.\n\nBecause software development may involve compromising or going beyond what is required by the client, a software development project may stray into less technical concerns such as human resources, risk management, intellectual property, budgeting, crisis management, etc. These processes may also cause the role of business development to overlap with software development.\n\nPlanning is an objective of each and every activity, where we want to discover things that belong to the project.\nAn important task in creating a software program is extracting the requirements or requirements analysis. Customers typically have an abstract idea of what they want as an end result but do not know what \"software\" should do. Skilled and experienced software engineers recognize incomplete, ambiguous, or even contradictory requirements at this point. Frequently demonstrating live code may help reduce the risk that the requirements are incorrect.\n\n\"Although much effort is put in the requirements phase to ensure that requirements are complete and consistent, rarely that is the case; leaving the software design phase as the most influential one when it comes to minimizing the effects of new or changing requirements. Requirements volatility is challenging because they impact future or already going development efforts.\"\n\nOnce the general requirements are gathered from the client, an analysis of the scope of the development should be determined and clearly stated. This is often called a scope document.\n\nOnce the requirements are established, the design of the software can be established in a software design document. This involves a preliminary or high-level design of the main modules with an overall picture (such as a block diagram) of how the parts fit together. The language, operating system, and hardware components should all be known at this time. Then a detailed or low-level design is created, perhaps with prototyping as proof-of-concept or to firm up requirements.\n\nImplementation is the part of the process where software engineers actually program the code for the project.\n\nSoftware testing is an integral and important phase of the software development process. This part of the process ensures that defects are recognized as soon as possible. In some processes, generally known as test-driven development, tests may be developed just before implementation and serve as a guide for the implementation's correctness.\n\nDocumenting the internal design of software for the purpose of future maintenance and enhancement is done throughout development. This may also include the writing of an API, be it external or internal. The software engineering process chosen by the developing team will determine how much internal documentation (if any) is necessary. Plan-driven models (e.g., Waterfall) generally produce more documentation than Agile models.\n\nDeployment starts directly after the code is appropriately tested, approved for release, and sold or otherwise distributed into a production environment. This may involve installation, customization (such as by setting parameters to the customer's values), testing, and possibly an extended period of evaluation. \n\nSoftware training and support is important, as software is only effective if it is used correctly.\n\nMaintaining and enhancing software to cope with newly discovered faults or requirements can take substantial time and effort, as missed requirements may force redesign of the software. \n\nA view model is a framework that provides the viewpoints on the system and its environment, to be used in the software development process. It is a graphical representation of the underlying semantics of a view.\n\nThe purpose of viewpoints and views is to enable human engineers to comprehend very complex systems and to organize the elements of the problem and the solution around domains of expertise. In the engineering of physically intensive systems, viewpoints often correspond to capabilities and responsibilities within the engineering organization.\n\nMost complex system specifications are so extensive that no one individual can fully comprehend all aspects of the specifications. Furthermore, we all have different interests in a given system and different reasons for examining the system's specifications. A business executive will ask different questions of a system make-up than would a system implementer. The concept of viewpoints framework, therefore, is to provide separate viewpoints into the specification of a given complex system. These viewpoints each satisfy an audience with interest in some set of aspects of the system. Associated with each viewpoint is a viewpoint language\nthat optimizes the vocabulary and presentation for the audience of that viewpoint.\n\nGraphical representation of the current state of information provides a very effective means for presenting information to both users and system developers.\n\n\nUsually, a model is created after conducting an interview, referred to as business analysis. The interview consists of a facilitator asking a series of questions designed to extract required information that describes a process. The interviewer is called a facilitator to emphasize that it is the participants who provide the information. The facilitator should have some knowledge of the process of interest, but this is not as important as having a structured methodology by which the questions are asked of the process expert. The methodology is\nimportant because usually a team of facilitators is collecting information across the facility and the results of the information from all the interviewers must fit together once completed.\n\nThe models are developed as defining either the current state of the process, in which case the final product is called the \"as-is\" snapshot model, or a collection of ideas of what the process should contain, resulting in a \"what-can-be\" model. Generation of process and data models can be used to determine if the existing processes and information systems are sound and only need minor modifications or enhancements, or if re-engineering is required as a corrective action. The creation of business models is more than a way to view or automate your information process. Analysis can be used to fundamentally reshape the way your business or organization conducts its operations.\n\nComputer-aided software engineering (CASE), in the field software engineering, is the scientific application of a set of software tools and methods to the development of software which results in high-quality, defect-free, and maintainable software products. It also refers to methods for the development of information systems together with automated tools that can be used in the software development process. The term \"computer-aided software engineering\" (CASE) can refer to the software used for the automated development of systems software, i.e., computer code. The CASE functions include analysis, design, and programming. CASE tools automate methods for designing, documenting, and producing structured computer code in the desired programming language.\n\nTwo key ideas of Computer-aided Software System Engineering (CASE) are:\n\nTypical CASE tools exist for configuration management, data modeling, model transformation, refactoring, source code generation.\n\nAn integrated development environment (IDE) also known as \"integrated design environment\" or \"integrated debugging environment\" is a software application that provides comprehensive facilities to computer programmers for software development. An IDE normally consists of a:\nIDEs are designed to maximize programmer productivity by providing tight-knit components with similar user interfaces. Typically an IDE is dedicated to a specific programming language, so as to provide a feature set which most closely matches the programming paradigms of the language.\n\nA modeling language is any artificial language that can be used to express information or knowledge or systems in a structure that is defined by a consistent set of rules. The rules are used for interpretation of the meaning of components in the structure. A modeling language can be graphical or textual. Graphical modeling languages use a diagram techniques with named symbols that represent concepts and lines that connect the symbols and that represent relationships and various other graphical annotation to represent constraints. Textual modeling languages typically use standardised keywords accompanied by parameters to make computer-interpretable expressions.\n\nExamples of graphical modelling languages in the field of software engineering are:\n\nNot all modeling languages are executable, and for those that are, using them doesn't necessarily mean that programmers are no longer needed. On the contrary, executable modeling languages are intended to amplify the productivity of skilled programmers, so that they can address more difficult problems, such as parallel computing and distributed systems.\n\nA programming paradigm is a fundamental style of computer programming, which is not generally dictated by the project management methodology (such as waterfall or agile). Paradigms differ in the concepts and abstractions used to represent the elements of a program (such as objects, functions, variables, constraints) and the steps that comprise a computation (such as assignations, evaluation, continuations, data flows). Sometimes the concepts asserted by the paradigm are utilized cooperatively in high-level system architecture design; in other cases, the programming paradigm's scope is limited to the internal structure of a particular program or module.\n\nA programming language can support multiple paradigms. For example, programs written in C++ or Object Pascal can be purely procedural, or purely object-oriented, or contain elements of both paradigms. Software designers and programmers decide how to use those paradigm elements. In object-oriented programming, programmers can think of a program as a collection of interacting objects, while in functional programming a program can be thought of as a sequence of stateless function evaluations. When programming computers or systems with many processors, process-oriented programming allows programmers to think about applications as sets of concurrent processes acting upon logically shared data structures.\n\nJust as different groups in software engineering advocate different \"methodologies\", different programming languages advocate different \"programming paradigms\". Some languages are designed to support one paradigm (Smalltalk supports object-oriented programming, Haskell supports functional programming), while other programming languages support multiple paradigms (such as Object Pascal, C++, C#, Visual Basic, Common Lisp, Scheme, Python, Ruby, and Oz).\n\nMany programming paradigms are as well known for what methods they \"forbid\" as for what they enable. For instance, pure functional programming forbids using side-effects; structured programming forbids using goto statements. Partly for this reason, new paradigms are often regarded as doctrinaire or overly rigid by those accustomed to earlier styles. Avoiding certain methods can make it easier to prove theorems about a program's correctness, or simply to understand its behavior.\n\nExamples of high-level paradigms include:\n\n\n\n\n\n"}
{"id": "30990996", "url": "https://en.wikipedia.org/wiki?curid=30990996", "title": "Suspension array technology", "text": "Suspension array technology\n\nSuspension array technology (or SAT) is a high throughput, large-scale, and multiplexed screening platform used in molecular biology. SAT has been widely applied to genomic and proteomic research, such as single nucleotide polymorphism (SNP) genotyping, genetic disease screening, gene expression profiling, screening drug discovery and clinical diagnosis. SAT uses microsphere beads (5.6 um in diameter) to prepare arrays. SAT allows for the simultaneous testing of multiple gene variants through the use of these microsphere beads as each type of microsphere bead has a unique identification based on variations in optical properties, most common is fluorescent colour. As each colour and intensity of colour has a unique wavelength, beads can easily be differentiated based on their wavelength intensity. Microspheres are readily suspendable in solution and exhibit favorable kinetics during an assay. Similar to flat microarrays (e.g. DNA microarray), an appropriate receptor molecule, such as DNA oligonucleotide probes, antibodies, or other proteins, attach themselves to the differently labeled microspheres. This produces thousands of microsphere array elements. Probe-target hybridization is usually detected by optically labeled targets, which determines the relative abundance of each target in the sample.\n\nDNA is extracted from cells used to create test fragments. These test fragments are added to a solution containing a variety of microsphere beads. Each type of microsphere bead contains a known DNA probe with a unique fluorescent identity. Test fragments and probes on the microsphere beads are allowed to hybridize to each other. Once hybridized, the microsphere beads are sorted, usually using flow cytometry. This allows for the detection of each of the gene variants from the original sample. The resulting data collected will indicate the relative abundance of each hybridized sample to the microsphere.\n\nSince microsphere beads are easily suspended in solution and each microsphere retains its identity when hybridized to the test sample, a typical suspension array experiment can analyze a wide range of biological analysis in a single reaction, called \"multiplexing\". In general, each type of microsphere used in an array is individually prepared in bulk. For example, the commercially available microsphere arrays from Luminex xMAP technology uses a 10X10 element array. This array involves beads with red and infrared dyes, each with ten different intensities, to give a 100-element array. Thus, the array size would increase exponentially if multiple dyes are used. For example, five different dyes with 10 different intensities per dye will give rise to 100,000 different array elements.\n\nWhen using different types of microspheres, SAT is capable of simultaneously testing multiple variables, such as DNA and proteins, in a given sample. This allows SAT to analyze variety of molecular targets during a single reaction. The common nucleic acid detection method includes direct DNA hybridization. The direct DNA hybridization approach is the simplest suspension array assay whereby 15 to 20 bp DNA oligonucleotides attached to microspheres are amplified using PCR. This is the optimized probe length as it minimizes the melting temperature variation among different probes during probe-target hybridization. After amplifying one DNA oligoprobe of interest, it can be used to create 100 different probes on 100 different sets of microspheres, each with the capability of capturing 100 potential targets (if using a 100-plex array). Similarly, target DNA samples are usually PCR amplified and labeled. Hybridization between the capture probe and the target DNA is achieved by melting and annealing complementary target DNA sequences to their capture probes located on the microspheres. After washing to remove non-specific binding between sequences, only strongly paired probe-targets will remain hybridized.\n\n\"For more details on this topic, see flow cytometry\"\n\nSince the optical identity of each microsphere is known, the quantification of target samples hybridized to the microspheres can be achieved by comparing the relative intensity of target markers in one set of microspheres to target markers in another set of microspheres using flow cytometry. Microspheres can be sorted based using both their unique optical properties and level of hybridization to the target sequence.\n\n\n\n"}
{"id": "28284", "url": "https://en.wikipedia.org/wiki?curid=28284", "title": "Switch", "text": "Switch\n\nIn electrical engineering, a switch is an electrical component that can \"make\" or \"break\" an electrical circuit, interrupting the current or diverting it from one conductor to another.\nThe mechanism of a switch removes or restores the conducting path in a circuit when it is operated. It may be operated manually, for example, a light switch or a keyboard button, may be operated by a moving object such as a door, or may be operated by some sensing element for pressure, temperature or flow. A switch will have one or more sets of contacts, which may operate simultaneously, sequentially, or alternately. Switches in high-powered circuits must operate rapidly to prevent destructive arcing, and may include special features to assist in rapidly interrupting a heavy current. Multiple forms of actuators are used for operation by hand or to sense position, level, temperature or flow. Special types are used, for example, for control of machinery, to reverse electric motors, or to sense liquid level. Many specialized forms exist. A common use is control of lighting, where multiple switches may be wired into one circuit to allow convenient control of light fixtures.\n\nBy analogy with the devices that select one or more possible paths for electric currents, devices that route information in a computer network are also called \"switches\" - these are usually more complicated than simple electromechanical toggles or pushbutton devices, and operate without direct human interaction.\n\nThe most familiar form of switch is a manually operated electromechanical device with one or more sets of electrical contacts, which are connected to external circuits. Each set of contacts can be in one of two states: either \"closed\" meaning the contacts are touching and electricity can flow between them, or \"open\", meaning the contacts are separated and the switch is nonconducting. The mechanism actuating the transition between these two states (open or closed) are usually (there are other types of actions) either an \"alternate action\" (flip the switch for continuous \"on\" or \"off\") or \"momentary\" (push for \"on\" and release for \"off\") type.\n\nA switch may be directly manipulated by a human as a control signal to a system, such as a computer keyboard button, or to control power flow in a circuit, such as a light switch. Automatically operated switches can be used to control the motions of machines, for example, to indicate that a garage door has reached its full open position or that a machine tool is in a position to accept another workpiece. Switches may be operated by process variables such as pressure, temperature, flow, current, voltage, and force, acting as sensors in a process and used to automatically control a system. For example, a thermostat is a temperature-operated switch used to control a heating process. A switch that is operated by another electrical circuit is called a relay. Large switches may be remotely operated by a motor drive mechanism. Some switches are used to isolate electric power from a system, providing a visible point of isolation that can be padlocked if necessary to prevent accidental operation of a machine during maintenance, or to prevent electric shock.\n\nAn ideal switch would have no voltage drop when closed, and would have no limits on voltage or current rating. It would have zero rise time and fall time during state changes, and would change state without \"bouncing\" between on and off positions.\n\nPractical switches fall short of this ideal; they have resistance, limits on the current and voltage they can handle, finite switching time, etc. The ideal switch is often used in circuit analysis as it greatly simplifies the system of equations to be solved, but this can lead to a less accurate solution. Theoretical treatment of the effects of non-ideal properties is required in the design of large networks of switches, as for example used in telephone exchanges.\n\nIn the simplest case, a switch has two conductive pieces, often metal, called \"contacts\", connected to an external circuit, that touch to complete (make) the circuit, and separate to open (break) the circuit. The contact material is chosen for its resistance to corrosion, because most metals form insulating oxides that would prevent the switch from working. Contact materials are also chosen on the basis of electrical conductivity, hardness (resistance to abrasive wear), mechanical strength, low cost and low toxicity.\n\nSometimes the contacts are plated with noble metals. They may be designed to wipe against each other to clean off any contamination. Nonmetallic conductors, such as conductive plastic, are sometimes used. To prevent the formation of insulating oxides, a minimum wetting current may be specified for a given switch design.\n\nIn electronics, switches are classified according to the arrangement of their contacts. A pair of contacts is said to be \"\"closed\" when current can flow from one to the other. When the contacts are separated by an insulating air gap, they are said to be \"open\", and no current can flow between them at normal voltages. The terms \"make\" for closure of contacts and \"break\" for opening of contacts are also widely used.\n\nThe terms pole and throw are also used to describe switch contact variations. The number of \"poles\" is the number of electrically separate switches which are controlled by a single physical actuator. For example, a \"2-pole\" switch has two separate, parallel sets of contacts that open and close in unison via the same mechanism. The number of \"throws\"\" is the number of separate wiring path choices other than \"open\" that the switch can adopt for each pole. A single-throw switch has one pair of contacts that can either be closed or open. A double-throw switch has a contact that can be connected to either of two other contacts, a triple-throw has a contact which can be connected to one of three other contacts, etc.\nIn a switch where the contacts remain in one state unless actuated, such as a push-button switch, the contacts can either be normally open (abbreviated \"n.o.\" or \"no\") until closed by operation of the switch, or normally closed (\"n.c.\" or \"nc\") and opened by the switch action. A switch with both types of contact is called a \"changeover switch\" or \"double-throw switch\". These may be \"make-before-break\" (\"MBB\" or shorting) which momentarily connects both circuits, or may be \"break-before-make\" (\"BBM\" or non-shorting) which interrupts one circuit before closing the other.\n\nThese terms have given rise to abbreviations for the types of switch which are used in the electronics industry such as \"single-pole, single-throw\" (SPST) (the simplest type, \"on or off\") or \"single-pole, double-throw\" (SPDT), connecting either of two terminals to the common terminal. In electrical power wiring (i.e., house and building wiring by electricians), names generally involve the suffix \"-way\"; however, these terms differ between British English and American English (i.e., the terms \"two way\" and \"three  way\" are used with different meanings).\n\nSwitches with larger numbers of poles or throws can be described by replacing the \"S\" or \"D\" with a number (e.g. 3PST, SP4T, etc.) or in some cases the letter \"T\" (for \"triple\") or \"Q\" (for \"quadruple\"). In the rest of this article the terms \"SPST\", \"SPDT\" and \"intermediate\" will be used to avoid the ambiguity.\n\nContact bounce (also called \"chatter\") is a common problem with mechanical switches and relays. Switch and relay contacts are usually made of springy metals. When the contacts strike together, their momentum and elasticity act together to cause them to bounce apart one or more times before making steady contact. The result is a rapidly pulsed electric current instead of a clean transition from zero to full current. The effect is usually unimportant in power circuits, but causes problems in some analogue and logic circuits that respond fast enough to misinterpret the on‑off pulses as a data stream.\n\nThe effects of contact bounce can be eliminated by use of mercury-wetted contacts, but these are now infrequently used because of the hazard of mercury release. Alternatively, contact circuit voltages can be low-pass filtered to reduce or eliminate multiple pulses from appearing. In digital systems, multiple samples of the contact state can be taken at a low rate and examined for a steady sequence, so that contacts can settle before the contact level is considered reliable and acted upon. Bounce in SPDT switch contacts signals can be filtered out using a SR flip-flop (latch) or Schmitt trigger. All of these methods are referred to as 'debouncing'.\n\nBy analogy, the term \"debounce\" has arisen in the software development industry to describe rate-limiting or throttling the frequency of a method's execution.\n\nContact bouncing is used in the Hammond organ and together with the multiple non-synchron closing contacts under a piano key known as the \"Hammond Click\". \n\nIn the Hammond organ, multiple wires are pressed together under the piano keys of the manuals. Their bouncing and non-synchronous closing of the switches is known as \"Hammond Click\" and compositions exists that use and emphasize this feature. Some electronic organs have a switchable replica of this sound effect.\n\nWhen the power being switched is sufficiently large, the electron flow across opening switch contacts is sufficient to ionize the air molecules across the tiny gap between the contacts as the switch is opened, forming a gas plasma, also known as an electric arc. The plasma is of low resistance and is able to sustain power flow, even with the separation distance between the switch contacts steadily increasing. The plasma is also very hot and is capable of eroding the metal surfaces of the switch contacts. Electric current arcing causes significant degradation of the contacts and also significant electromagnetic interference (EMI), requiring the use of arc suppression methods.\n\nWhere the voltage is sufficiently high, an arc can also form as the switch is closed and the contacts approach. If the voltage potential is sufficient to exceed the breakdown voltage of the air separating the contacts, an arc forms which is sustained until the switch closes completely and the switch surfaces make contact.\n\nIn either case, the standard method for minimizing arc formation and preventing contact damage is to use a fast-moving switch mechanism, typically using a spring-operated tipping-point mechanism to assure quick motion of switch contacts, regardless of the speed at which the switch control is operated by the user. Movement of the switch control lever applies tension to a spring until a tipping point is reached, and the contacts suddenly snap open or closed as the spring tension is released.\n\nAs the power being switched increases, other methods are used to minimize or prevent arc formation. A plasma is hot and will rise due to convection air currents. The arc can be quenched with a series of non-conductive blades spanning the distance between switch contacts, and as the arc rises, its length increases as it forms ridges rising into the spaces between the blades, until the arc is too long to stay sustained and is extinguished. A \"puffer\" may be used to blow a sudden high velocity burst of gas across the switch contacts, which rapidly extends the length of the arc to extinguish it quickly.\n\nExtremely large switches in excess of 100,000‑watt capacity often have switch contacts surrounded by something other than air to more rapidly extinguish the arc. For example, the switch contacts may operate in a vacuum, immersed in mineral oil, or in sulfur hexafluoride.\n\nIn AC power service, the current periodically passes through zero; this effect makes it harder to sustain an arc on opening. Manufacturers may rate switches with lower voltage or current rating when used in DC circuits.\n\nWhen a switch is designed to switch significant power, the transitional state of the switch as well as the ability to withstand continuous operating currents must be considered. When a switch is in the on state, its resistance is near zero and very little power is dropped in the contacts; when a switch is in the off state, its resistance is extremely high and even less power is dropped in the contacts. However, when the switch is flicked, the resistance must pass through a state where a quarter of the load's rated power (or worse if the load is not purely resistive) is briefly dropped in the switch.\n\nFor this reason, power switches intended to interrupt a load current have spring mechanisms to make sure the transition between on and off is as short as possible regardless of the speed at which the user moves the rocker.\n\nPower switches usually come in two types. A momentary on‑off switch (such as on a laser pointer) usually takes the form of a button and only closes the circuit when the button is depressed. A regular on‑off switch (such as on a flashlight) has a constant on-off feature. Dual-action switches incorporate both of these features.\n\nWhen a strongly inductive load such as an electric motor is switched off, the current cannot drop instantaneously to zero; a spark will jump across the opening contacts. Switches for inductive loads must be rated to handle these cases. The spark will cause electromagnetic interference if not suppressed; a snubber network of a resistor and capacitor in series will quell the spark.\n\nWhen turned on, an incandescent lamp draws a large inrush current of about ten times the steady-state current; as the filament heats up, its resistance rises and the current decreases to a steady-state value. A switch designed for an incandescent lamp load can withstand this inrush current.\n\n\"Wetting current\" is the minimum current needing to flow through a mechanical switch while it is operated to break through any film of oxidation that may have been deposited on the switch contacts. The film of oxidation occurs often in areas with high humidity. Providing a sufficient amount of wetting current is a crucial step in designing systems that use delicate switches with small contact pressure as sensor inputs. Failing to do this might result in switches remaining electrically \"open\" due to contact oxidation.\n\nThe moving part that applies the operating force to the contacts is called the \"actuator\", and may be a toggle or \"dolly\", a rocker, a push-button or any type of mechanical linkage \"(see photo).\"\n\nA switch normally maintains its set position once operated. A biased switch contains a mechanism that springs it into another position when released by an operator. The momentary push-button switch is a type of biased switch. The most common type is a \"push-to-make\" (or normally-open or NO) switch, which makes contact when the button is pressed and breaks when the button is released. Each key of a computer keyboard, for example, is a normally-open \"push-to-make\" switch. A \"push-to-break\" (or normally-closed or NC) switch, on the other hand, breaks contact when the button is pressed and makes contact when it is released. An example of a push-to-break switch is a button used to release a door held closed by an electromagnet. The interior lamp of a household refrigerator is controlled by a switch that is held open when the door is closed.\n\nA rotary switch operates with a twisting motion of the operating handle with at least two positions. One or more positions of the switch may be momentary (biased with a spring), requiring the operator to hold the switch in the position. Other positions may have a detent to hold the position when released. A rotary switch may have multiple levels or \"decks\" in order to allow it to control multiple circuits.\n\nOne form of rotary switch consists of a spindle or \"rotor\" that has a contact arm or \"spoke\" which projects from its surface like a cam. It has an array of terminals, arranged in a circle around the rotor, each of which serves as a contact for the \"spoke\" through which any one of a number of different electrical circuits can be connected to the rotor. The switch is layered to allow the use of multiple poles, each layer is equivalent to one pole. Usually such a switch has a detent mechanism so it \"clicks\" from one active position to another rather than stalls in an intermediate position. Thus a rotary switch provides greater pole and throw capabilities than simpler switches do.\n\nOther types use a cam mechanism to operate multiple independent sets of contacts.\n\nRotary switches were used as channel selectors on television receivers until the early 1970s, as range selectors on electrical metering equipment, as band selectors on multi-band radios and other similar purposes. In industry, rotary switches are used for control of measuring instruments, switchgear, or in control circuits. For example, a radio controlled overhead crane may have a large multi-circuit rotary switch to transfer hard-wired control signals from the local manual controls in the cab to the outputs of the remote control receiver.\n\nA toggle switch is a class of electrical switches that are manually actuated by a mechanical lever, handle, or rocking mechanism.\n\nToggle switches are available in many different styles and sizes, and are used in numerous applications. Many are designed to provide the simultaneous actuation of multiple sets of electrical contacts, or the control of large amounts of electric current or mains voltages.\n\nThe word \"toggle\" is a reference to a kind of mechanism or joint consisting of two arms, which are almost in line with each other, connected with an elbow-like pivot. However, the phrase \"toggle switch\" is applied to a switch with a short handle and a positive snap-action, whether it actually contains a toggle mechanism or not. Similarly, a switch where a definitive click is heard, is called a \"positive on-off switch\". A very common use of this type of switch is to switch lights or other electrical equipment on or off. Multiple toggle switches may be mechanically interlocked to prevent forbidden combinations.\n\nIn some contexts, particularly computing, a toggle switch, or the action of toggling, is understood in the different sense of a mechanical or software switch that alternates between two states each time it is activated, regardless of mechanical construction. For example, the caps lock key on a computer causes all letters to be generated in capitals after it is pressed once; pressing it again reverts to lower-case letters.\n\nSwitches can be designed to respond to any type of mechanical stimulus: for example, vibration (the trembler switch), tilt, air pressure, fluid level (a float switch), the turning of a key (key switch), linear or rotary movement (a limit switch or microswitch), or presence of a magnetic field (the reed switch). Many switches are operated automatically by changes in some environmental condition or by motion of machinery. A limit switch is used, for example, in machine tools to interlock operation with the proper position of tools. In heating or cooling systems a sail switch ensures that air flow is adequate in a duct. Pressure switches respond to fluid pressure.\n\nThe mercury switch consists of a drop of mercury inside a glass bulb with two or more contacts. The two contacts pass through the glass, and are connected by the mercury when the bulb is tilted to make the mercury roll on to them.\n\nThis type of switch performs much better than the ball tilt switch, as the liquid metal connection is unaffected by dirt, debris and oxidation, it wets the contacts ensuring a very low resistance bounce-free connection, and movement and vibration do not produce a poor contact. These types can be used for precision works.\n\nIt can also be used where arcing is dangerous (such as in the presence of explosive vapour) as the entire unit is sealed.\n\nKnife switches consist of a flat metal blade, hinged at one end, with an insulating handle for operation, and a fixed contact. When the switch is closed, current flows through the hinged pivot and blade and through the fixed contact. Such switches are usually not enclosed. The knife and contacts are typically formed of copper, steel, or brass, depending on the application. Fixed contacts may be backed up with a spring. Several parallel blades can be operated at the same time by one handle. The parts may be mounted on an insulating base with terminals for wiring, or may be directly bolted to an insulated switch board in a large assembly. Since the electrical contacts are exposed, the switch is used only where people cannot accidentally come in contact with the switch or where the voltage is so low as to not present a hazard.\n\nKnife switches are made in many sizes from miniature switches to large devices used to carry thousands of amperes. In electrical transmission and distribution, gang-operated switches are used in circuits up to the highest voltages.\n\nThe disadvantages of the knife switch are the slow opening speed and the proximity of the operator to exposed live parts. Metal-enclosed safety disconnect switches are used for isolation of circuits in industrial power distribution. Sometimes spring-loaded auxiliary blades are fitted which momentarily carry the full current during opening, then quickly part to rapidly extinguish the arc.\n\nA footswitch is a rugged switch which is operated by foot pressure. An example of use is in the control of a machine tool, allowing the operator to have both hands free to manipulate the workpiece. The foot control of an electric guitar is also a footswitch.\n\nA DPDT switch has six connections, but since polarity reversal is a very common usage of DPDT switches, some variations of the DPDT switch are internally wired specifically for polarity reversal. These crossover switches only have four terminals rather than six. Two of the terminals are inputs and two are outputs. When connected to a battery or other DC source, the 4-way switch selects from either normal or reversed polarity. Such switches can also be used as intermediate switches in a multiway switching system for control of lamps by more than two switches.\n\nIn building wiring, light switches are installed at convenient locations to control lighting and occasionally other circuits. By use of multiple-pole switches, multiway switching control of a lamp can be obtained from two or more places, such as the ends of a corridor or stairwell. A wireless light switch allows remote control of lamps for convenience; some lamps include a touch switch which electronically controls the lamp if touched anywhere. In public buildings several types of vandal resistant switches are used to prevent unauthorized use.\n\nSlide switches are mechanical switches using a slider that moves (slides) from the open (off) position to the closed (on) position.\n\nA relay is an electrically operated switch. Many relays use an electromagnet to operate a switching mechanism mechanically, but other operating principles are also used. Solid-state relays control power circuits with no moving parts, instead using a semiconductor device to perform switching—often a silicon-controlled rectifier or triac.\n\nThe analogue switch uses two MOSFET transistors in a transmission gate arrangement as a switch that works much like a relay, with some advantages and several limitations compared to an electromechanical relay.\n\nThe power transistor(s) in a switching voltage regulator, such as a power supply unit, are used like a switch to alternately let power flow and block power from flowing.\n\nMany people use metonymy to call a variety of devices \"switches\" that conceptually connect or disconnect signals and communication paths between electrical devices, analogous to the way mechanical switches connect and disconnect paths for electrons to flow between two conductors. Early telephone systems used an automatically operated Strowger switch to connect telephone callers; telephone exchanges contain one or more crossbar switches today.\n\nSince the advent of digital logic in the 1950s, the term \"switch\" has spread to a variety of digital active devices such as transistors and logic gates whose function is to change their output state between two logic levels or connect different signal lines, and even computers, network switches, whose function is to provide connections between different ports in a computer network. The term 'switched' is also applied to telecommunications networks, and signifies a network that is circuit switched, providing dedicated circuits for communication between end nodes, such as the public switched telephone network. The common feature of all these usages is they refer to devices that control a binary state: they are either \"on\" or \"off\", \"closed\" or \"open\", \"connected\" or \"not connected\".\n\n\n \n"}
{"id": "34027125", "url": "https://en.wikipedia.org/wiki?curid=34027125", "title": "TOPAS (CRS)", "text": "TOPAS (CRS)\n\nTOPAS is a Computer reservations system based in South Korea which provides its services in the Korean market. It is majority owned by Korean Airlines with Amadeus IT Group holding 35%.\n\n\n"}
{"id": "29816", "url": "https://en.wikipedia.org/wiki?curid=29816", "title": "Technology", "text": "Technology\n\nTechnology (\"science of craft\", from Greek , \"techne\", \"art, skill, cunning of hand\"; and , \"-logia\") is the collection of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation. Technology can be the knowledge of techniques, processes, and the like, or it can be embedded in machines to allow for operation without detailed knowledge of their workings.\n\nThe simplest form of technology is the development and use of basic tools. The prehistoric discovery of how to control fire and the later Neolithic Revolution increased the available sources of food, and the invention of the wheel helped humans to travel in and control their environment. Developments in historic times, including the printing press, the telephone, and the Internet, have lessened physical barriers to communication and allowed humans to interact freely on a global scale.\n\nTechnology has many effects. It has helped develop more advanced economies (including today's global economy) and has allowed the rise of a leisure class. Many technological processes produce unwanted by-products known as pollution and deplete natural resources to the detriment of Earth's environment. Innovations have always influenced the values of a society and raised new questions of the ethics of technology. Examples include the rise of the notion of efficiency in terms of human productivity, and the challenges of bioethics.\n\nPhilosophical debates have arisen over the use of technology, with disagreements over whether technology improves the human condition or worsens it. Neo-Luddism, anarcho-primitivism, and similar reactionary movements criticize the pervasiveness of technology, arguing that it harms the environment and alienates people; proponents of ideologies such as transhumanism and techno-progressivism view continued technological progress as beneficial to society and the human condition.\n\nThe use of the term \"technology\" has changed significantly over the last 200 years. Before the 20th century, the term was uncommon in English, and it was used either to refer to the description or study of the useful arts or to allude to technical education, as in the Massachusetts Institute of Technology (chartered in 1861).\n\nThe term \"technology\" rose to prominence in the 20th century in connection with the Second Industrial Revolution. The term's meanings changed in the early 20th century when American social scientists, beginning with Thorstein Veblen, translated ideas from the German concept of \"\" into \"technology.\" In German and other European languages, a distinction exists between \"technik\" and \"technologie\" that is absent in English, which usually translates both terms as \"technology.\" By the 1930s, \"technology\" referred not only to the study of the industrial arts but to the industrial arts themselves.\n\nIn 1937, the American sociologist Read Bain wrote that \"technology includes all tools, machines, utensils, weapons, instruments, housing, clothing, communicating and transporting devices and the skills by which we produce and use them.\" Bain's definition remains common among scholars today, especially social scientists. Scientists and engineers usually prefer to define technology as applied science, rather than as the things that people make and use. More recently, scholars have borrowed from European philosophers of \"technique\" to extend the meaning of technology to various forms of instrumental reason, as in Foucault's work on technologies of the self (\"techniques de soi\").\n\nDictionaries and scholars have offered a variety of definitions. The \"Merriam-Webster Learner's Dictionary\" offers a definition of the term: \"the use of science in industry, engineering, etc., to invent useful things or to solve problems\" and \"a machine, piece of equipment, method, etc., that is created by technology.\" Ursula Franklin, in her 1989 \"Real World of Technology\" lecture, gave another definition of the concept; it is \"practice, the way we do things around here.\" The term is often used to imply a specific field of technology, or to refer to high technology or just consumer electronics, rather than technology as a whole. Bernard Stiegler, in \"Technics and Time, 1\", defines technology in two ways: as \"the pursuit of life by means other than life,\" and as \"organized inorganic matter.\"\n\nTechnology can be most broadly defined as the entities, both material and immaterial, created by the application of mental and physical effort in order to achieve some value. In this usage, technology refers to tools and machines that may be used to solve real-world problems. It is a far-reaching term that may include simple tools, such as a crowbar or wooden spoon, or more complex machines, such as a space station or particle accelerator. Tools and machines need not be material; virtual technology, such as computer software and business methods, fall under this definition of technology. W. Brian Arthur defines technology in a similarly broad way as \"a means to fulfill a human purpose.\"\n\nThe word \"technology\" can also be used to refer to a collection of techniques. In this context, it is the current state of humanity's knowledge of how to combine resources to produce desired products, to solve problems, fulfill needs, or satisfy wants; it includes technical methods, skills, processes, techniques, tools and raw materials. When combined with another term, such as \"medical technology\" or \"space technology,\" it refers to the state of the respective field's knowledge and tools. \"State-of-the-art technology\" refers to the high technology available to humanity in any field.\nTechnology can be viewed as an activity that forms or changes culture. Additionally, technology is the application of math, science, and the arts for the benefit of life as it is known. A modern example is the rise of communication technology, which has lessened barriers to human interaction and as a result has helped spawn new subcultures; the rise of cyberculture has at its basis the development of the Internet and the computer. Not all technology enhances culture in a creative way; technology can also help facilitate political oppression and war via tools such as guns. As a cultural activity, technology predates both science and engineering, each of which formalize some aspects of technological endeavor.\n\nThe distinction between science, engineering, and technology is not always clear. Science is systematic knowledge of the physical or material world gained through observation and experimentation. Technologies are not usually exclusively products of science, because they have to satisfy requirements such as utility, usability, and safety.\n\nEngineering is the goal-oriented process of designing and making tools and systems to exploit natural phenomena for practical human means, often (but not always) using results and techniques from science. The development of technology may draw upon many fields of knowledge, including scientific, engineering, mathematical, linguistic, and historical knowledge, to achieve some practical result.\n\nTechnology is often a consequence of science and engineering, although technology as a human activity precedes the two fields. For example, science might study the flow of electrons in electrical conductors by using already-existing tools and knowledge. This new-found knowledge may then be used by engineers to create new tools and machines such as semiconductors, computers, and other forms of advanced technology. In this sense, scientists and engineers may both be considered technologists; the three fields are often considered as one for the purposes of research and reference.\n\nThe exact relations between science and technology in particular have been debated by scientists, historians, and policymakers in the late 20th century, in part because the debate can inform the funding of basic and applied science. In the immediate wake of World War II, for example, it was widely considered in the United States that technology was simply \"applied science\" and that to fund basic science was to reap technological results in due time. An articulation of this philosophy could be found explicitly in Vannevar Bush's treatise on postwar science policy, \"Science – The Endless Frontier\": \"New products, new industries, and more jobs require continuous additions to knowledge of the laws of nature ... This essential new knowledge can be obtained only through basic scientific research.\" In the late-1960s, however, this view came under direct attack, leading towards initiatives to fund science for specific tasks (initiatives resisted by the scientific community). The issue remains contentious, though most analysts resist the model that technology simply is a result of scientific research.\n\nThe use of tools by early humans was partly a process of discovery and of evolution. Early humans evolved from a species of foraging hominids which were already bipedal, with a brain mass approximately one third of modern humans. Tool use remained relatively unchanged for most of early human history. Approximately 50,000 years ago, the use of tools and complex set of behaviors emerged, believed by many archaeologists to be connected to the emergence of fully modern language.\n\nHominids started using primitive stone tools millions of years ago. The earliest stone tools were little more than a fractured rock, but approximately 75,000 years ago, pressure flaking provided a way to make much finer work.\n\nThe discovery and utilization of fire, a simple energy source with many profound uses, was a turning point in the technological evolution of humankind. The exact date of its discovery is not known; evidence of burnt animal bones at the Cradle of Humankind suggests that the domestication of fire occurred before 1 Ma; scholarly consensus indicates that \"Homo erectus\" had controlled fire by between 500 and 400 ka. Fire, fueled with wood and charcoal, allowed early humans to cook their food to increase its digestibility, improving its nutrient value and broadening the number of foods that could be eaten.\n\nOther technological advances made during the Paleolithic era were clothing and shelter; the adoption of both technologies cannot be dated exactly, but they were a key to humanity's progress. As the Paleolithic era progressed, dwellings became more sophisticated and more elaborate; as early as 380 ka, humans were constructing temporary wood huts. Clothing, adapted from the fur and hides of hunted animals, helped humanity expand into colder regions; humans began to migrate\nout of Africa by 200 ka and into other continents such as Eurasia.\n\nHuman's technological ascent began in earnest in what is known as the Neolithic Period (\"New Stone Age\"). The invention of polished stone axes was a major advance that allowed forest clearance on a large scale to create farms. This use of polished stone axes increased greatly in the Neolithic, but were originally used in the preceding Mesolithic in some areas such as Ireland. Agriculture fed larger populations, and the transition to sedentism allowed simultaneously raising more children, as infants no longer needed to be carried, as nomadic ones must. Additionally, children could contribute labor to the raising of crops more readily than they could to the hunter-gatherer economy.\n\nWith this increase in population and availability of labor came an increase in labor specialization. What triggered the progression from early Neolithic villages to the first cities, such as Uruk, and the first civilizations, such as Sumer, is not specifically known; however, the emergence of increasingly hierarchical social structures and specialized labor, of trade and war amongst adjacent cultures, and the need for collective action to overcome environmental challenges such as irrigation, are all thought to have played a role.\n\nContinuing improvements led to the furnace and bellows and provided, for the first time, the ability to smelt and forge of gold, copper, silver, and lead native metals found in relatively pure form in nature. The advantages of copper tools over stone, bone, and wooden tools were quickly apparent to early humans, and native copper was probably used from near the beginning of Neolithic times (about 10 ka). Native copper does not naturally occur in large amounts, but copper ores are quite common and some of them produce metal easily when burned in wood or charcoal fires. Eventually, the working of metals led to the discovery of alloys such as bronze and brass (about 4000 BCE). The first uses of iron alloys such as steel dates to around 1800 BCE.\n\nMeanwhile, humans were learning to harness other forms of energy. The earliest known use of wind power is the sailing ship; the earliest record of a ship under sail is that of a Nile boat dating to the 8th millennium BCE. From prehistoric times, Egyptians probably used the power of the annual flooding of the Nile to irrigate their lands, gradually learning to regulate much of it through purposely built irrigation channels and \"catch\" basins. The ancient Sumerians in Mesopotamia used a complex system of canals and levees to divert water from the Tigris and Euphrates rivers for irrigation.\n\nAccording to archaeologists, the wheel was invented around 4000 BCE probably independently and nearly simultaneously in Mesopotamia (in present-day Iraq), the Northern Caucasus (Maykop culture) and Central Europe. Estimates on when this may have occurred range from 5500 to 3000 BCE with most experts putting it closer to 4000 BCE. The oldest artifacts with drawings depicting wheeled carts date from about 3500 BCE; however, the wheel may have been in use for millennia before these drawings were made. More recently, the oldest-known wooden wheel in the world was found in the Ljubljana marshes of Slovenia.\n\nThe invention of the wheel revolutionized trade and war. It did not take long to discover that wheeled wagons could be used to carry heavy loads. The ancient Sumerians used the potter's wheel and may have invented it. A stone pottery wheel found in the city-state of Ur dates to around 3429 BCE, and even older fragments of wheel-thrown pottery have been found in the same area. Fast (rotary) potters' wheels enabled early mass production of pottery, but it was the use of the wheel as a transformer of energy (through water wheels, windmills, and even treadmills) that revolutionized the application of nonhuman power sources. The first two-wheeled carts were derived from travois and were first used in Mesopotamia and Iran in around 3000 BCE.\n\nThe oldest known constructed roadways are the stone-paved streets of the city-state of Ur, dating to circa 4000 BCE and timber roads leading through the swamps of Glastonbury, England, dating to around the same time period. The first long-distance road, which came into use around 3500 BCE, spanned 1,500 miles from the Persian Gulf to the Mediterranean Sea, but was not paved and was only partially maintained. In around 2000 BCE, the Minoans on the Greek island of Crete built a fifty-kilometer (thirty-mile) road leading from the palace of Gortyn on the south side of the island, through the mountains, to the palace of Knossos on the north side of the island. Unlike the earlier road, the Minoan road was completely paved.\n\nAncient Minoan private homes had running water. A bathtub virtually identical to modern ones was unearthed at the Palace of Knossos. Several Minoan private homes also had toilets, which could be flushed by pouring water down the drain. The ancient Romans had many public flush toilets, which emptied into an extensive sewage system. The primary sewer in Rome was the Cloaca Maxima; construction began on it in the sixth century BCE and it is still in use today.\n\nThe ancient Romans also had a complex system of aqueducts, which were used to transport water across long distances. The first Roman aqueduct was built in 312 BCE. The eleventh and final ancient Roman aqueduct was built in 226 CE. Put together, the Roman aqueducts extended over 450 kilometers, but less than seventy kilometers of this was above ground and supported by arches.\n\nInnovations continued through the Middle Ages with innovations such as silk, the horse collar and horseshoes in the first few hundred years after the fall of the Roman Empire. Medieval technology saw the use of simple machines (such as the lever, the screw, and the pulley) being combined to form more complicated tools, such as the wheelbarrow, windmills and clocks. The Renaissance brought forth many of these innovations, including the printing press (which facilitated the greater communication of knowledge), and technology became increasingly associated with science, beginning a cycle of mutual advancement. The advancements in technology in this era allowed a more steady supply of food, followed by the wider availability of consumer goods.\nStarting in the United Kingdom in the 18th century, the Industrial Revolution was a period of great technological discovery, particularly in the areas of agriculture, manufacturing, mining, metallurgy, and transport, driven by the discovery of steam power. Technology took another step in a second industrial revolution with the harnessing of electricity to create such innovations as the electric motor, light bulb, and countless others. Scientific advancement and the discovery of new concepts later allowed for powered flight and advancements in medicine, chemistry, physics, and engineering. The rise in technology has led to skyscrapers and broad urban areas whose inhabitants rely on motors to transport them and their food supply. Communication was also greatly improved with the invention of the telegraph, telephone, radio and television. The late 19th and early 20th centuries saw a revolution in transportation with the invention of the airplane and automobile.\nThe 20th century brought a host of innovations. In physics, the discovery of nuclear fission has led to both nuclear weapons and nuclear power. Computers were also invented and later miniaturized utilizing transistors and integrated circuits. Information technology subsequently led to the creation of the Internet, which ushered in the current Information Age. Humans have also been able to explore space with satellites (later used for telecommunication) and in manned missions going all the way to the moon. In medicine, this era brought innovations such as open-heart surgery and later stem cell therapy along with new medications and treatments.\n\nComplex manufacturing and construction techniques and organizations are needed to make and maintain these new technologies, and entire industries have arisen to support and develop succeeding generations of increasingly more complex tools. Modern technology increasingly relies on training and education – their designers, builders, maintainers, and users often require sophisticated general and specific training. Moreover, these technologies have become so complex that entire fields have been created to support them, including engineering, medicine, and computer science, and other fields have been made more complex, such as construction, transportation, and architecture.\n\nGenerally, technicism is the belief in the utility of technology for improving human societies. Taken to an extreme, technicism \"reflects a fundamental attitude which seeks to control reality, to resolve all problems with the use of scientific–technological methods and tools.\" In other words, human beings will someday be able to master all problems and possibly even control the future using technology. Some, such as Stephen V. Monsma, connect these ideas to the abdication of religion as a higher moral authority.\n\nOptimistic assumptions are made by proponents of ideologies such as transhumanism and singularitarianism, which view technological development as generally having beneficial effects for the society and the human condition. In these ideologies, technological development is morally good.\n\nTranshumanists generally believe that the point of technology is to overcome barriers, and that what we commonly refer to as the human condition is just another barrier to be surpassed.\n\nSingularitarians believe in some sort of \"accelerating change\"; that the rate of technological progress accelerates as we obtain more technology, and that this will culminate in a \"Singularity\" after artificial general intelligence is invented in which progress is nearly infinite; hence the term. Estimates for the date of this Singularity vary, but prominent futurist Ray Kurzweil estimates the Singularity will occur in 2045.\n\nKurzweil is also known for his history of the universe in six epochs: (1) the physical/chemical epoch, (2) the life epoch, (3) the human/brain epoch, (4) the technology epoch, (5) the artificial intelligence epoch, and (6) the universal colonization epoch. Going from one epoch to the next is a Singularity in its own right, and a period of speeding up precedes it. Each epoch takes a shorter time, which means the whole history of the universe is one giant Singularity event.\n\nSome critics see these ideologies as examples of scientism and techno-utopianism and fear the notion of human enhancement and technological singularity which they support. Some have described Karl Marx as a techno-optimist.\n\nOn the somewhat skeptical side are certain philosophers like Herbert Marcuse and John Zerzan, who believe that technological societies are inherently flawed. They suggest that the inevitable result of such a society is to become evermore technological at the cost of freedom and psychological health.\n\nMany, such as the Luddites and prominent philosopher Martin Heidegger, hold serious, although not entirely, deterministic reservations about technology (see \"The Question Concerning Technology\"). According to Heidegger scholars Hubert Dreyfus and Charles Spinosa, \"Heidegger does not oppose technology. He hopes to reveal the essence of technology in a way that 'in no way confines us to a stultified compulsion to push on blindly with technology or, what comes to the same thing, to rebel helplessly against it.' Indeed, he promises that 'when we once open ourselves expressly to the essence of technology, we find ourselves unexpectedly taken into a freeing claim.' What this entails is a more complex relationship to technology than either techno-optimists or techno-pessimists tend to allow.\"\n\nSome of the most poignant criticisms of technology are found in what are now considered to be dystopian literary classics such as Aldous Huxley's \"Brave New World\", Anthony Burgess's \"A Clockwork Orange\", and George Orwell's \"Nineteen Eighty-Four\". In Goethe's \"Faust\", Faust selling his soul to the devil in return for power over the physical world is also often interpreted as a metaphor for the adoption of industrial technology. More recently, modern works of science fiction such as those by Philip K. Dick and William Gibson and films such as \"Blade Runner\" and \"Ghost in the Shell\" project highly ambivalent or cautionary attitudes toward technology's impact on human society and identity.\n\nThe late cultural critic Neil Postman distinguished tool-using societies from technological societies and from what he called \"technopolies,\" societies that are dominated by the ideology of technological and scientific progress to the exclusion or harm of other cultural practices, values, and world-views.\n\nDarin Barney has written about technology's impact on practices of citizenship and democratic culture, suggesting that technology can be construed as (1) an object of political debate, (2) a means or medium of discussion, and (3) a setting for democratic deliberation and citizenship. As a setting for democratic culture, Barney suggests that technology tends to make ethical questions, including the question of what a good life consists in, nearly impossible because they already give an answer to the question: a good life is one that includes the use of more and more technology.\n\nNikolas Kompridis has also written about the dangers of new technology, such as genetic engineering, nanotechnology, synthetic biology, and robotics. He warns that these technologies introduce unprecedented new challenges to human beings, including the possibility of the permanent alteration of our biological nature. These concerns are shared by other philosophers, scientists and public intellectuals who have written about similar issues (e.g. Francis Fukuyama, Jürgen Habermas, William Joy, and Michael Sandel).\n\nAnother prominent critic of technology is Hubert Dreyfus, who has published books such as \"On the Internet\" and \"What Computers Still Can't Do\".\n\nA more infamous anti-technological treatise is \"\", written by the Unabomber Ted Kaczynski and printed in several major newspapers (and later books) as part of an effort to end his bombing campaign of the techno-industrial infrastructure. There are also subcultures that disapprove of some or most technology, such as self-identified off-gridders.\n\nThe notion of appropriate technology was developed in the 20th century by thinkers such as E.F. Schumacher and Jacques Ellul to describe situations where it was not desirable to use very new technologies or those that required access to some centralized infrastructure or parts or skills imported from elsewhere. The ecovillage movement emerged in part due to this concern.\n\n\"This section mainly focuses on American concerns even if it can reasonably be generalized to other Western countries. \"\n\nIn his article, Jared Bernstein, a Senior Fellow at the Center on Budget and Policy Priorities, questions the widespread idea that automation, and more broadly, technological advances, have mainly contributed to this growing labor market problem.\nHis thesis appears to be a third way between optimism and skepticism. Essentially, he stands for a neutral approach of the linkage between technology and American issues concerning unemployment and declining wages.\n\nHe uses two main arguments to defend his point.\nFirst, because of recent technological advances, an increasing number of workers are losing their jobs. Yet, scientific evidence fails to clearly demonstrate that technology has displaced so many workers that it has created more problems than it has solved. Indeed, automation threatens repetitive jobs but higher-end jobs are still necessary because they complement technology and manual jobs that \"requires flexibility judgment and common sense\" remain hard to replace with machines. Second, studies have not shown clear links between recent technology advances and the wage trends of the last decades.\n\nTherefore, according to Bernstein, instead of focusing on technology and its hypothetical influences on current American increasing unemployment and declining wages, one needs to worry more about \"bad policy that fails to offset the imbalances in demand, trade, income, and opportunity.\"\n\nFor people who use both the Internet and mobile devices in excessive quantities it is likely for them to experience fatigue and over exhaustion as a result of disruptions in their sleeping patterns. Continuous studies have shown that increased BMI and weight gain are associated with people who spend long hours online and not exercising frequently. Heavy Internet use is also displayed in the school lower grades of those who use it in excessive amounts. It has also been noted that the use of mobile phones whilst driving has increased the occurrence of road accidents — particularly amongst teen drivers. Statistically, teens reportedly have fourfold the amount of road traffic incidents as those who are 20 years or older, and a very high percentage of adolescents write (81%) and read (92%) texts while driving. In this context, mass media and technology have a negative impact on people, on both their mental and physical health.\n\nThomas P. Hughes stated that because technology has been considered as a key way to solve problems, we need to be aware of its complex and varied characters to use it more efficiently. What is the difference between a wheel or a compass and cooking machines such as an oven or a gas stove? Can we consider all of them, only a part of them, or none of them as technologies?\n\nTechnology is often considered too narrowly; according to Hughes, \"Technology is a creative process involving human ingenuity\". This definitio's emphasis on creativity avoids unbounded definitions that may mistakenly include cooking \"technologies,\" but it also highlights the prominent role of humans and therefore their responsibilities for the use of complex technological systems.\n\nYet, because technology is everywhere and has dramatically changed landscapes and societies, Hughes argues that engineers, scientists, and managers have often believed that they can use technology to shape the world as they want. They have often supposed that technology is easily controllable and this assumption has to be thoroughly questioned. For instance, Evgeny Morozov particularly challenges two concepts: \"Internet-centrism\" and \"solutionism.\" Internet-centrism refers to the idea that our society is convinced that the Internet is one of the most stable and coherent forces. Solutionism is the ideology that every social issue can be solved thanks to technology and especially thanks to the internet. In fact, technology intrinsically contains uncertainties and limitations. According to Alexis Madrigal's review of Morozov's theory, to ignore it will lead to \"unexpected consequences that could eventually cause more damage than the problems they seek to address.\" Benjamin R. Cohen and Gwen Ottinger also discussed the multivalent effects of technology.\n\nTherefore, recognition of the limitations of technology, and more broadly, scientific knowledge, is needed – especially in cases dealing with environmental justice and health issues. Ottinger continues this reasoning and argues that the ongoing recognition of the limitations of scientific knowledge goes hand in hand with scientists and engineers’ new comprehension of their role. Such an approach of technology and science \"[require] technical professionals to conceive of their roles in the process differently. [They have to consider themselves as] collaborators in research and problem solving rather than simply providers of information and technical solutions.\"\n\nTechnology is properly defined as any application of science to accomplish a function. The science can be leading edge or well established and the function can have high visibility or be significantly more mundane, but it is all technology, and its exploitation is the foundation of all competitive advantage.\n\nTechnology-based planning is what was used to build the US industrial giants before WWII (e.g., Dow, DuPont, GM) and it is what was used to transform the US into a superpower. It was not economic-based planning.\n\nThe use of basic technology is also a feature of other animal species apart from humans. These include primates such as chimpanzees, some dolphin communities, and crows. Considering a more generic perspective of technology as ethology of active environmental conditioning and control, we can also refer to animal examples such as beavers and their dams, or bees and their honeycombs.\n\nThe ability to make and use tools was once considered a defining characteristic of the genus Homo. However, the discovery of tool construction among chimpanzees and related primates has discarded the notion of the use of technology as unique to humans. For example, researchers have observed wild chimpanzees utilising tools for foraging: some of the tools used include leaf sponges, termite fishing probes, pestles and levers. West African chimpanzees also use stone hammers and anvils for cracking nuts, as do capuchin monkeys of Boa Vista, Brazil.\n\nTheories of technology often attempt to predict the future of technology based on the high technology and science of the time. As with all predictions of the future, however, technology's is uncertain.\n\nIn 2005, futurist Ray Kurzweil predicted that the future of technology would mainly consist of an overlapping \"GNR Revolution\" of genetics, nanotechnology and robotics, with robotics being the most important of the three.\n\n"}
{"id": "19076796", "url": "https://en.wikipedia.org/wiki?curid=19076796", "title": "Teledermatology", "text": "Teledermatology\n\nTeledermatology is a subspecialty in the medical field of dermatology and probably one of the most common applications of telemedicine and e-health. In teledermatology, telecommunication technologies are used to exchange medical information (concerning skin conditions and tumours of the skin) over a distance using audio, visual and data communication. Applications comprise health care management such as diagnoses, consultation and treatment as well as (continuous) education.\n\nThe dermatologists Perednia and Brown were the first to coin the term \"teledermatology\" in 1995. In a scientific publication, they described the value of a teledermatologic service in a rural area underserved by dermatologists.\n\nTeledermatology (as telemedicine) is practised on the basis of two concepts: Store and forward (SAF) and real time/live interactive teledermatology. Hybrid modes also exist (combining SAF and real time applications).\n\nThe SAF method is most commonly used in teledermatology: It involves sending (forwarding) digital images associated with (anonymous) medical information to the data storage unit of a consulted specialist. It can be as easy as sending an email with a digital image of a lesion to seek advice for a skin condition. Advantages of this method are that it does not demand the presence of both parties at the same time and does not usually require expensive equipment.\n\nIn real-time/ live interactive teledermatology applications, provider and individuals usually interact via live videoconferencing. It may also involve remote surgery and the use of telerobotic microscopes in dermatopathology. This mode generally requires more sophisticated and costly technology than used in the SAF mode. Both participants must be available at the same time.\n\nDirect consultation involves an individual with a skin condition contacting a dermatologist via telecommunication to request diagnosis and treatment. In this field, mobile applications of teledermatology gain importance.\n\nTelediagnosis in the absence of personal contact with health care workers to the individual is complex. It requires active participation of the individual and without appropriate guidance may lead to improper management. However, as a triage tool, leading the individual directly to the appropriate specialist for his/her disease, it could be very valuable in the near future.\n\nSpecialist referral is a major area of application in teledermatology A general practitioner (or other medical professional) that sees the individual consults a specialist/ specialised centre via telecommunication in order to get a second opinion. The specialist then helps the GP in rendering a diagnosis, providing management options et cetera.\n\nHome telehealth/telehomecare involves an individual with a chronic condition being examined and managed remotely at home. An important field of interest of telehomecare in dermatology is the follow-up treatment of individuals with skin conditions requiring regular follow-up such as crural ulcers. Crural ulcers are a common skin condition that needs follow up visits up to twice a week demanding significant time commitments by the individuals in addition to causing a financial burden on the health care system. Teledermatology can help to reduce the time and costs involved in the follow-up of such conditions.\n\nMedical education/continuous education are a major advantage of telemedicine/e-health. Numerous universities offer online courses, computer-based training and Web applications in this field principally aimed at medical students. Specialist training courses via internet are also available, particularly in dermoscopy.\n\nGeneral medical/health information may be accessed by non-professionals, such as individuals affected by a skin condition, and their relatives, through the internet. They are also able to join peer support groups with others affected by the same condition.\n\nIn teledermoscopy, digital dermoscopic lesion images (with or without clinical images) are transmitted electronically to a specialist for examination. This can be done on the web-based telediagnostic network Campus Medicus.\n\nDermoscopy (dermatoscopy, epiluminescence microscopy) is the technical field of using an epiluminescence microscope for viewing skin lesions in magnification in-vivo. It is particularly useful in the early detection of malignant skin lesions (i.e., melanoma). Digital dermoscopic images can be taken with a digital camera attached to a dermatoscope or special video cameras suited for dermoscopy, e.g. the FotoFinder. Since dermoscopy is based on examination of a two-dimensional image it is very well suited for digital imaging and teledermatology.\n\nTeledermatopathology is the transmission of dermatopathologic images either in real-time with the aid of a robotic microscope or using a store-and-forward system (transmission as a single file). In the latter method (SAF) a rather new development is the introduction of virtual slide systems (VSS).\n\nVirtual slides are made by digitally scanning an entire glass slide at a high resolution and then sending the images to a storage system. These can be then assessed on a computer screen similar to conventional microscopy, allowing the pathologist to maneuver around the image and view every part of the slide at any magnification.\n\nThis is the transmission of crucial medical data and dermoscopic as well as clinical images to a pathologist who renders the conventional histopathologic diagnosis.\n\nIn the everyday clinical setting, skin biopsies are taken by the physician directly responsible for the individual and are assessed by a dermatopathologist. This pathologist has most likely never seen the clinical aspect of the lesion and might not have any information about the person. These limitations can be overcome by teledermoscopically aided dermatopathology whereby a patient history and clinical data may increase the sensitivity of diagnosis.\n\nAdditionally it has been shown that provision of such data may improve the level of diagnostic confidence held by the assessing dermatopathologists.\n\nMobile telemedicine is a system in which at least one participant (the person seeking advice or the doctor, for instance) uses wireless or mobile equipment (i.e. mobile phones, handheld devices), in contrast to conventional stationary telemedicine platforms. Travellers who develop skin lesions as well as doctors who are on the move in hospital/non-hospital area can benefit from this new development in teledermatology. In order to facilitate access to medical advice and enable individuals to play a more active role in managing their own health status, mobile teledermatology seems to be especially suited for patient filtering or triage. (i.e. referral based on the severity and character of their skin condition). Another possible practical application is for follow-up of individuals with chronic skin conditions.\n\nNot all cases are suitable for teledermatology. The type of cases suited for teledermatology is a topic, which requires more studies. Some studies have observed that eczema and follicular lesions were diagnosed with relatively more certainty, while in some other studies it was seen that diagnoses were made with more certainty in cases like viral warts, herpes zoster, acne vulgaris, irritant dermatitis, vitiligo, and superficial bacterial and fungal infections. Unlike in western studies where pigmented lesions suspicious of melanomas are one of the most referred cases for teledermatology (with or without teledermatoscopy), Asian studies have fewer cases referred based on the suspicion of melanoma.\n\n24% of the population in England and Wales seek medical advice for a skin condition, and approximately 6% of patients presenting with a skin problem are referred for specialist advice each year.\n\nThe Department of Health encourages the use of digital technology in key areas to support delivery of the quality, innovation, productivity, and prevention (QIPP). This includes the introduction of digital or online services to deliver greater convenience for patients and to free up face-to-face clinical time for individuals who really need it.\n\nTeledermatology and teledermoscopy currently exist in different forms in Australia. They assist with combatting the high skin cancer rates and allows rural patients to access specialist advice without having to travel. However, store-and-forward teledermatology or teledermoscopy are not currently funded under the Australian national health scheme called Medicare. Research has been done into the economic impact of funding teledermoscopy in the Australian setting, finding that it would cost around $2 for every day that diagnosis or treatment was expedited. Australian dermatologists have been reported as reflecting on teledermoscopy by saying \"that it is valuable, [and] advanced dermatology service\" but given the option \"they would prefer face-to-face consultation with patients where possible to allow for a full body examination\".\n\n\n\n\nSystematic review of economic evidence\n"}
{"id": "13960866", "url": "https://en.wikipedia.org/wiki?curid=13960866", "title": "The RAND Journal of Economics", "text": "The RAND Journal of Economics\n\nThe RAND Journal of Economics (usually called Rand Journal or simply Rand ) is a peer-reviewed scholarly journal of economics published quarterly by Wiley-Blackwell on behalf of the RAND Corporation.\n\nThe journal's purpose is \"to support and encourage research in the behavior of regulated industries, the economic analysis of organizations, and more generally, applied microeconomics\". It publishes both theoretical and empirical papers. According to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 1.465, ranking it 98th out of 347 journals in the category \"Economics\".\n\nAT&T's Bell Labs economics group launched the journal in the spring of 1970 with the name The Bell Journal of Economics and Management Science. From 1975–1983 it was titled The Bell Journal of Economics. In 1984, after transfer to the RAND Corporation, it acquired its present name.\n"}
{"id": "1926425", "url": "https://en.wikipedia.org/wiki?curid=1926425", "title": "Thermostatic radiator valve", "text": "Thermostatic radiator valve\n\nA thermostatic radiator valve (TRV) is a self-regulating valve fitted to hot water heating system radiator, to control the temperature of a room by changing the flow of hot water to the radiator.\n\nThe classic thermostatic radiator valve contains a plug, typically made of wax (forming a wax motor), which expands or contracts with the surrounding temperature. This plug is connected to a pin which in turn is connected to a valve. The valve gradually closes as the temperature of the surrounding area increases, limiting the amount of hot water entering the radiator. This allows a maximum temperature to be set for each room.\n\nAs the valve works by sensing the temperature of the air surrounding it, it is important to ensure that it is not covered by material (such as curtains). If the controller is removed from the valve the valve turns on and the radiator will always be hot.\n\nThe replacement of a manual heating control with a TRV has been estimated to save at least of CO per year. They are also considerably cost-efficient, using heat only when needed, and can reduce heating bills by up to 17 percent a year.\n\nAs of 2012, electronic TRVs are becoming available which use electronic temperature sensing, and frequently contain programmers so that individual radiators may be programmed for different temperatures at different times of the day. Such increased control allows even better energy and CO saving.\n\n"}
{"id": "21730525", "url": "https://en.wikipedia.org/wiki?curid=21730525", "title": "Time-dependent neutronics and temperatures", "text": "Time-dependent neutronics and temperatures\n\nTIme-dependent neutronics and temperatures (TINTE) is a two-group diffusion code for the study of nuclear and thermal behavior of high temperature reactors. It was developed by Forschungszentrum Jülich in Germany, formally known as KFA (), to investigate HTGRs in 2D (r-Z) geometry.\n\n"}
{"id": "5981170", "url": "https://en.wikipedia.org/wiki?curid=5981170", "title": "United Cannery, Agricultural, Packing, and Allied Workers of America", "text": "United Cannery, Agricultural, Packing, and Allied Workers of America\n\nThe United Cannery, Agricultural, Packing, and Allied Workers of America (UCAPAWA) was a labor union formed in 1937 and incorporated large numbers of Mexican, black, Asian, and Anglo food processing workers under its banner. The founders envisioned a national decentralized labor organization with power flowing from the bottom up. Although it was a short-lived, the UCAPAWA influenced the lives of many workers and had a major impact for both women and minority workers in the union.\n\nThe United Cannery, Agricultural, Packing Allied Workers of America (or UCAPAWA) was an organization formed after the American Federation of Labor (AFL) ignored several delegate members plea to have better working conditions for farm and food processing workers. At its head stood an intense and energetic organizer named Donald Henderson who was a young economics instructor at Columbia University and a member of the Communist party. Henderson, who was also one of the founders of the People’s Congress, noted the importance this union placed on popularizing the conditions of black and Mexican American workers and organizing them as a way to improve their social and economic situation. Henderson declared that the “International Office was sufficiently concerned with the conditions facing . . . the Negro people and the Mexican and Spanish American peoples.” Henderson observed that both minority groups were deprived of civil rights, exploited to the point of starvation, kept in decayed housing, denied educational opportunities, and in Henderson’s view, “blocked from their own cultural development.” Henderson eventually, as President of the union, established it as the agricultural arm of Congress of Industrial Organizations (CIO) in 1937 after having been abandoned by the AFL.\n\nUnable to persuade the AFL to charter an international union of agricultural workers and increasingly drawn to the Congress of Industrial Organizations (CIO) industrial union structure, Henderson and representatives from locals throughout the country met in Denver in July 1937 to form UCAPAWA, which promptly received a charter from the CIO. Part of the reason behind its founding was to address the concerns of agricultural laborers and their counterparts in packing and canning during the Great Depression.\n\nThe UCAPAWA represented multi-cultural workers from Mexicans in sugar beet to black sharecroppers in Arkansas and Missouri. They were also very involved in Asian-American workers such as Filipino, Chinese and Japanese cannery workers in Washington. UCAPAWA was particularly strong among Mexican and Mexican American workers. In 1940, the \"San Francisco News\" called UCAPAWA the \"fastest growing agricultural union in California\", and attributed its success to its appeal to Mexican and Mexican American workers. The union was also supported by such outside organizations as the John Steinbeck Committee to Aid Agricultural Organization, the J. Lubin Society, the Spanish-speaking Peoples Congress, and on occasion, local clergy.\n\nA commitment to trade union democracy, shared by both national leaders and regular members provided the underlying philosophy for union endeavors. Some leaders of the UCAPAWA saw themselves as participants of a radical culture and political projects. When the UCAPAWA entered an affiliation the Arkansas-based Southern Tenant Farmers Union (STFU) there was controversy regarding political associations. Infighting between Communist party leaders and the local Socialists who served as the organization’s principal administrators, as well as personality and ideological conflicts marred the alliance from the start. According to the both the STFU and UCAPAWA differed over a fundamental issue: Whether agricultural workers could best be served by a protest organization or a trade union. STFU thought that sharecroppers and tenant farmers could not be organized because they were uneducated and too poor.\n\nThe UCAPAWA disagreed and argued that agricultural workers could be taught the rudimentary procedures for running the locals and that union members had to support their own organization. Another difference between the STFU and UCAPAWA was that the STFU wanted a centralized government while the UCAPAWA believed in a more decentralized system. After the STFU departed, the UCAPAWA’s constitution guaranteed local autonomy and provided for local control of at least half of all dues collected. The STFU dispute was a turning point for UCAPAWA. Agricultural unions did not have collective bargaining rights and often faced local hostility. As a result, UCAPAWA shifted its focus from the fields to processing plants.\n\nThe UCAPAWA distanced themselves further from conventional unions and organizations by representing working classes generally ignored by traditional craft affiliates. Union officers deliberately enlisted black, Mexican, Asian and female labor organizers in order to launch campaigns aimed at minorities and women. UCAPAWA was spreading their wings from fields to fisheries, canneries, processing plants and even tobacco manufacturing workers. The UCAPAWA was fast becoming one of the more influential unions in America and when the 1939 Madera Cotton Strike happened the UCAPAWA proved they were a force to be reckoned with. Besides UCAPAWA proving themselves a strong union they were also beginning to acquire a reputation as a Communist Party (CP).\n\nWhile some truly believe the demise of the UCAPAWA was caused by the involvement with the Radical Party, many members of UCAPAWA believed themselves to be more liberal than anything. The argument of whether the union leaders were supporters of Communism set off an argument between many local leaders. Vicki L. Ruiz makes a very important statement in her book She writes that “UCAPAWA certainly had a leftist stance, though the nature and extent of its leftist ideology will continue to be debated.” Despite their roots or political stance, the UCAPAWA had shown that it could organize the nation’s most vulnerable workers. It also showed that women and minority groups were capable of playing an important role in the labor movement.\n\nOne of the most prominent roles that UCAPAWA played was in the workplace for women, especially Mexican women. Forming half of UCAPAWA’s total membership, women were not silent partners. On the contrary, they performed various services ranging from negotiating contracts to calling numbers at bingo. Women organizing women became a union hallmark. Women enthusiastically joined a labor organization that actively encouraged their involvement and offered them genuine opportunities for leadership. UCAPAWA food and tobacco locals proved successful in securing higher wages and benefits that were particularly important to women. In fact, one of the most important positions, Vice President, was filled by Dorothy Ray Healey. Left-wing labor activists like Healey were successful because they embraced the Popular Front viewpoint and represented themselves as links to ethnic communities and as advocates of racial equality. Healey was assisted by a core group of college students and Young Communist League members who worked in the plant during the summer and were actively involved in organizing.\n\nIn the beginning, UCAPAWA had the financial support of the CIO, but there were hard times ahead for the newly-formed organization. UCAPAWA was one of the few labor unions that allowed women to hold positions of authority. There, they pushed for such benefits as maternity leave and equal pay, and they were on the forefront in the struggle for women's equality. By 1937, Henderson could report a membership of over 120,000 workers in more than 300 locals.\n\nBy 1946, nearly nine of ten cannery contracts set the minimum wage at sixty-five cents an hour. Two thirds contained \"equal pay for equal work\" clauses. More importantly, three fourths provided leave of absence for pregnancy or other reasons without losing seniority. Four fifths of the agreements also included benefits as paid vacations as well as bonuses for night or swing shift work. More than half had stipulations concerning paid holidays, union input in setting piece rates, and overtime pay after forty hours per week.\n\nDuring the 1938 pecan-sheller's strike led by Emma Tenayuca in San Antonio, UCAPAWA president Henderson dispatched organizer Luisa Moreno to turn the local, \"El Nogal\", into an efficient bargaining organization. Tenayuca had by then already established the Texas Pecan Shelling Workers Union, UCAPAWA Local 172. Their primary grievances put forth against the Seligmann Company were a 15% pay cut, deploring plant conditions, and unpaid homework. The strike, which also became violent when strikers were teargassed, ended with the recognition of the UCAPAWA local and a minimum wage for workers. Local San Antonio Police responded by attacking Tenyuaca and the UCAPAWA local leadership, arresting them and charging them with \"Communist Agitation.\"\n\nIn 1939, UCAPAWA Vice-President Dorothy Ray Healey played an important role in unionizing workers at California Sanitary Canning Company (Cal San) in Los Angeles, who struck in August of the same year. Union members picketed the cannery, grocery stores that sold Cal San goods, and the houses of the Shapiro brothers, the plant's owners. Faced with children holding signs bearing slogans such as \"I'm underfed because Mama is underpaid,\" the Shapiro brothers met with negotiators and soon reached a settlement. The Cal San local became UCAPAWA's second largest, and the union's ranks grew to include the workers at several California canneries.\n\nOne of the early strikes of UCAPAWA was the 1939 Madera Cotton Strike, which, despite provoking a violent reaction from the Associated Farmers, succeeded in winning a minimum wage for union members. It also served as an example of inter-ethnic solidarity, with African American, Mexican American, and White American workers all participating in the strike.\n\nIn Seattle, Washington, UCAPAWA represented Filipino cannery workers from 1937 to 1947. That was a great example of UCAPAWA supporting a minority group that wad usually overlooked by bigger unions.\n\nIn Texas, UCAPAWA was instrumental in unionizing and uniting workers from feed, flour, and cotton mills. At a 1938 wildcat strike of shrimp-processing plant workers, a UCAPAWA organizer was murdered on the picket line.\n\nAt post-strike meetings, Dorothy Healey outlined election procedures and general union bylaws. The cannery workers who had led the strike were elected to every major post. UCAPAWA organizers Luke Hinman and Ted Rasmussen, who began an organizing drive at the California Walnut Growers' Association plant, replaced Healey.\n\nIn the South, the Southern Tenant Farmers Union (STFU), which Communist UCAPAWA President Donald Henderson regarded as \"a utopian agrarian movement,\" became affiliated with the union. A power struggle between the groups erupted soon after the affiliation and culminated with a 1939 protest against the eviction of sharecroppers in Missouri, which was not supported by the national organization. As a result, the STFU left the union.\nAnticommunism was not the sole thread in the fabric of responses to UCAPAWA's organization although there were Communists in UCAPAWA. However, UCAPAWA was not a \"communist union.\" In 1944, UCAPAWA became the Food, Tobacco, Agricultural, and Allied Workers (FTA). In 1946, the Los Angeles local \"collapsed under the weight of Red Scare witchhunts.\" By 1950, the FTA had only 1,000 workers as members, and it was folded into the Distributive and Processing Workers of America.\n"}
{"id": "14629712", "url": "https://en.wikipedia.org/wiki?curid=14629712", "title": "Vegetable oil refining", "text": "Vegetable oil refining\n\nVegetable oil refining is a process to transform vegetable oil into biofuel by hydrocracking or hydrogenation. Hydrocracking breaks big molecules into smaller ones using hydrogen while hydrogenation adds hydrogen to molecules. These methods can be used for production of gasoline, diesel, propane, and other chemical feedstock. Diesel fuel produced from these sources is known as \"green diesel\" or \"renewable diesel\".\n\nThe majority of plant and animal oils are vegetable oils which are triglycerides—suitable for refining. Refinery feedstock includes canola, algae, jatropha, salicornia, palm oil, and tallow. One type of algae, Botryococcus braunii produces a different type of oil, known as a triterpene, which is transformed into alkanes by a different process.\n\nBased on its feedstock green diesel could be classified as biodiesel; however, based on the processing technology and chemical formula green diesel and biodiesel are different products. The chemical reaction commonly used to produce biodiesel is known as transesterification. Vegetable oil and alcohol are reacted, producing esters, or biodiesel, and the coproduct, glycerol.\n\nWhen refining vegetable oil, no glycerol is produced, only fuels.\n\nVarious stages of converting renewable hydrocarbon fuels produced by hydrotreating is done throughout energy industry. Some commercial examples of vegetable oil refining are NExBTL, H-Bio, the ConocoPhilips process, and the UOP/Eni Ecofining process. Neste Oil is the largest manufacturer, producing 2 million tons annually (2013). Neste Oil completed their first NExBTL plant in the summer 2007 and the second one in 2009. Petrobras planned to use of vegetable oils in the production of H-Bio fuel in 2007. ConocoPhilips is processing of vegetable oil.Other\ncompanies working on the commercialization and industrialization of renewable hydrocarbons and biofuels include Neste, REG Synthetic Fuels, LLC, ENI, UPM Biofuels, Diamond Green Diesel partnered with countries across the globe.In practice, these renewable diesels lower greenhouse gas emissions by 40-90%, have higher energy per content yields than petroleum-based diesels, and better cold-flow properties to work in colder climates. In addition, all of these green diesels can be introduced into any diesel engine or infrastructure without many mechanical modifications at any ratio with petroleum-based diesels.\n\nRenewable diesel from vegetable oil in particular is a growing and profound substitute for petroleum. California fleets used over 200,000,000 gallons of renewable diesel in 2017. CARB predicts over 2 billion gallons of fuel to be consumed in the state under its Low Carbon Fuel Standard requirements in the next ten years. Fleets operating on Renewable Diesel from various refiners and feedstocks are reported to see lower emissions, reduced maintenance costs, and nearly identical experience when driving with this fuel.\n\n\n"}
{"id": "43882820", "url": "https://en.wikipedia.org/wiki?curid=43882820", "title": "Visual Logic", "text": "Visual Logic\n\nVisual Logic is a graphical authoring tool which allows students to write and execute programs using flowcharts. It is typically used in an academic setting to teach introductory programming concepts.\n\nOther educational programming languages include:\n\n"}
{"id": "49817719", "url": "https://en.wikipedia.org/wiki?curid=49817719", "title": "WhistleOut", "text": "WhistleOut\n\nWhistleOut is a comparison website that assists consumers in shopping for cellphone plans. In Australia, the site also covers comparisons of fixed-line broadband plans, wireless broadband plans and subscription TV service offerings. The technology that powers WhistleOut's search engine is used by a number of online publications like: The Sydney Morning Herald, News.com.au and Yahoo, plus technology sites like Android Central and Techradar.\n\nWhistleOut has been featured on USA Today, ABC Good Morning America, TIME, the Sydney Morning Herald, and News Ltd.\n\nWhistleOut was launched in Sydney, Australia in May 2008 with an initial focus of just mobile phone plans. Later the search tool expanded to include comparisons of broadband plans, subscription TV offers and financial services.\n\nEventually credit card and home loan comparisons were removed, and the company returned its focus to comparison shopping of communication services. The Australia site currently compares over 16,000 plan combinations from 30 suppliers.\n\nThe WhistleOut comparison engine is now available in 6 countries. \n\n"}
