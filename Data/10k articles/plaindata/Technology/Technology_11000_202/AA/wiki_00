{"id": "13038870", "url": "https://en.wikipedia.org/wiki?curid=13038870", "title": "80 Plus", "text": "80 Plus\n\n80 Plus (trademarked 80 PLUS) is a voluntary certification program intended to promote efficient energy use in computer power supply units (PSUs). Launched in 2004 by Ecos Consulting, it certifies products that have more than 80% energy efficiency at 20%, 50% and 100% of rated load, and a power factor of 0.9 or greater at 100% load. Such PSUs waste 20% or less electric energy as heat at the specified load levels, reducing electricity use and bills compared to less efficient PSUs.\n\n\nRedundancy is typically used in data centers.\n\nFor the higher certification levels, the requirement of 0.9 or better power factor was extended to apply to 20% and 50% load levels, as well as at 100% load. The Platinum level requires 0.95 or better power factor for servers.\n\nThe Climate Savers Computing Initiative efficiency level targets for workstations for 2007 through 2011, correspond to the 80 Plus certification levels. From July 2007 through June 2008, basic 80 Plus level (Energy Star 4.0). For the next year, the target is 80 Plus Bronze level, the following year 80 Plus Silver, then 80 Plus Gold, and finally Platinum.\n\nThere have been instances where companies claim or imply that their supplies are 80 Plus when they have not been certified, and in some cases do not meet the requirements. When a company resells an OEM power supply under a new name it must be certified under the new name and company, even if the OEM supply is certified. In some instances, a reseller has claimed a higher wattage than the supply can deliver – in which case, the reseller's supply would not meet 80 Plus requirements. The 80 Plus web site has a list of all certified supplies, so it is possible to confirm that a supply really meets the requirements.\n\nAlthough some power supply manufacturers name their products with similar names, such as \"85 Plus\", there is no such official certification or standard.\n\nThe efficiency of a computer power supply is its output power divided by its input power; the remaining input power is converted into heat. For instance, a 600-watt power supply with 60% efficiency running at full load would draw 1000 W from the mains and would therefore waste 400 W as heat. On the other hand, a 600-watt power supply with 80% efficiency running at full load would draw 750 W from the mains and would therefore waste only 150 W as heat.\n\nFor a given power supply, efficiency varies depending on how much power is being delivered. Supplies are typically most efficient at between half and three quarters load, much less efficient at low load, and somewhat less efficient at maximum load. Older ATX power supplies were typically 60% to 75% efficient. To qualify for 80 Plus, a power supply must achieve at least 80% efficiency at three specified loads (20%, 50% and 100% of maximum rated power). However, 80 Plus supplies may still be less than 80% efficient at lower loads. For instance, an 80 Plus, 520 watt supply could still be 70% or less efficient at 60 watts (a typical idle power for a desktop computer). Thus it is still important to select a supply with capacity appropriate to the device being powered.\n\nIt is easier to achieve the higher efficiency levels for higher wattage supplies, so gold and platinum supplies may be less available in consumer level supplies of reasonable capacity for typical desktop machines.\n\nTypical computer power supplies may have power factors as low as 0.5 to 0.6. The higher power factor reduces the peak current draw, reducing load on the circuit or on an uninterruptible power supply.\n\nReducing the heat output of the computer helps reduce noise, since fans do not have to spin as fast to cool the computer. Reduced heat and resulting lower cooling demands may increase computer reliability.\n\nThe testing conditions may give an unrealistic expectation of efficiency for heavily loaded, high power (rated much larger than 300 W) supplies. A heavily loaded power supply and the computer it is powering generate significant amounts of heat, which may raise the power supply temperature, which is likely to decrease its efficiency. Since power supplies are certified at room temperature, this effect is not taken into account.\n\n80 Plus does not set efficiency targets for very low load. For instance, generation of standby power may still be relatively inefficient, and may not meet requirements of the One Watt Initiative. Testing of 80 Plus power supplies shows that they vary considerably in standby efficiency. Some power supplies consume half a watt or less in standby with no load, where others consume several times as much at standby, even though they may meet higher 80 Plus certification requirement levels.\n\n\n"}
{"id": "29304084", "url": "https://en.wikipedia.org/wiki?curid=29304084", "title": "ATLAS-TIM AT 32", "text": "ATLAS-TIM AT 32\n\nThe ATLAS-TIM AT 32 was the process computer developed by Mihajlo Pupin Institute in Belgrade in the 1980s. The designers were Dr Vukasin Masnikosa, Dr Bozidar Levi, Mr Milenko Nikolic and their associates. Professor Bozidar Levi with 2 coauthors got the Nikola Tesla award for his ATLAS design in 1988 (see Fig.1).\nThe SCADA (Supervisory, Control And Data Acquisition) software systems, such as SCADA VIEW 6000 and SCADA VIEW2, were used in many Serbian Hydro- and Termal- Power plants(ref.Lit.#1). The SCADA hardware developed and manufactured in the M. Pupin Institute includes ATLAS AT 32 (with Intel 386 microprocessors and VLSI circuitry), ATLAS MAX PLC (Intel 486), ATLAS MTU, Programmable controllers TIMKO (ref.Lit.#2), Atlas-2000, ATLAS XP, ATLAS-NANO, pico-ATLAS modular RTU devices etc.(for details see: ref.Lit.#3 and #4).\n\n"}
{"id": "50831293", "url": "https://en.wikipedia.org/wiki?curid=50831293", "title": "Active flow control", "text": "Active flow control\n\nAirplane wing performance has a substantial effect on not only the runway length, approach speed, climb rate, cargo capacity, and operation range but also the community noise and emission levels. The wing performance is often degraded by flow separation, which strongly depends on the aerodynamic design of the airfoil profile. Furthermore, non-aerodynamic constraints are often in conflict with aerodynamic restrictions, and flow control is required to overcome such difficulties. Techniques that have been developed to manipulate the boundary layer, either to increase the lift or decrease the drag, and separation delay are classified under the general heading of flow control. Flow control methods are divided into passive, which require no auxiliary power and no control loop, and active, which require energy expenditure. Passive techniques include geometric shaping, the use of vortex generators, and the placement of longitudinal grooves or riblets on airfoil surfaces. Examples of active flow control methods include steady suction or blowing, unsteady suction or blowing, and the use of synthetic jets.\n"}
{"id": "5518314", "url": "https://en.wikipedia.org/wiki?curid=5518314", "title": "Association for Computer Aided Design In Architecture", "text": "Association for Computer Aided Design In Architecture\n\nThe Association for Computer Aided Design In Architecture (ACADIA) is a 501(c)(3) non-profit organization active in the area of computer-aided architectural design (CAAD).\n\nBegun in 1981, the organization's objectives are recorded in its bylaws:\n\n\"ACADIA was formed for the purpose of facilitating communication and information exchange regarding the use of computers in architecture, planning and building science. A particular focus is education and the software, hardware and pedagogy involved in education.\"\n\n\"The organization is also committed to the research and development of computer aides that enhance design creativity, rather than simply production, and that aim at contributing to the construction of humane physical environments.\"\n\nMembership is open to anyone who subscribes to the objectives of the organization, including architects, educators, and software developers, whether resident in North America or not. An online membership registration form and directory is available via the organization.\n\nThe organization is primarily governed by the elected Board of Directors. The organization is led by the elected President, who presides over Board of Directors meetings, but does not vote except in the case of a tie.\n\nACADIA sponsors an annual national conference, held in the autumn of each year at a different site in North America. Papers for the conferences undergo extensive blind review before being accepted for presentation (and publication). Membership is not a prerequisite for submission of a paper.\nEach year the conference papers are gathered into a proceedings publication which is distributed to members, and available to the public via the open access database CumInCAD.\n\nStarted in 1998, \"ACADIA Awards of Excellence\" are \"the highest award that can be achieved in the field of architectural computing\". The awards are given in areas of practice, teaching, research and service, with at most one award in each category per year. Past awards have recognized various significant contributors to the field of architectural computing.\n\nThe current awards given annually or biannually are the Lifetime Achievement Award, the Digital Practice Award of Excellence, the Innovative Academic Program Award of Excellence, the Innovative Research Award of Excellence, the Society Award for Leadership, and the Teaching Award of Excellence.\n\nThere are four sister organizations around the world to provide a more accessible regional forum for discussion of computing and design. The major ones are\n\n\n"}
{"id": "12341428", "url": "https://en.wikipedia.org/wiki?curid=12341428", "title": "Bicing", "text": "Bicing\n\nBicing is a bicycle sharing system in Barcelona inaugurated on March 22, 2007. It is similar to the Vélo'v service in Lyon or Vélib' in Paris, and using the same bicycles and stations as used in Stockholm, Oslo, and Zaragoza. Its purpose is to cover the small and medium daily routes within the city in a climate-friendly way, eliminating the pollution, roadway noise, and traffic congestion that motor vehicles create..\nThe city council and Clear Channel manage and maintain the system. To use it, users must acquire a yearly membership. Currently the network consists of more than 420 stations to lend and return over 6000 bicycles distributed throughout the system. The stations are situated through most of the flat areas of the city with a distance of around 300 to 400 metres between each one, with many situated next to public transport stops to allow for intermodal use. Metro Stations usually have signs pointing to the locations of nearest Bicing stations.\nThe bikes can be lent from, and returned to, any station in the system, making it suitable for one-way travel. Each station has between 15 and 30 parking slots to fix and lock bicycles, but in highly transited areas many stations may be close together.\n\nTo rent a bike one simply swipes the contactless RFID card at a service station to be personally identified by the system, which then unlocks a bike from the support frame. Bicycles can be used for the first 30 minutes with no extra cost, with subsequent half-hour blocks (up to 2 hours) costing 0.70 € each. Use of a bicycle for more than 2 hours at a time is discouraged with a penalty rate of 4.20 € per hour, but also with the possibility of having membership cancelled after a certain number of uses in excess of two hours. To return a bicycle one simply places the bike in a spare slot at a Bicing station; the bike is recognised automatically and is locked into place.\n\nSpecialised vans are used to redistribute Bicing bicycles between the stations to even out usage patterns. However, as of November 2007, the number and frequency of vans is not able to keep up during the peak hours, making it very difficult to find a spot at which to return the bike in some areas.\n\nUse of the system is based on membership, and users can subscribe online or by visiting a service office. The Bicing member cards are only sent to addresses in Catalonia in an attempt to prevent tourists from using the system. This limitation was imposed upon the City Council by pre-existing local bike hire companies (grouped under Bicitours) that feared what they called illicit competition from the Bicing system. Bicitours and City Council agreed as well in enforcing a user block of ten minutes to change bikes (that is, when docking a bike, the user is blocked for ten minutes before being able to leave with another bike). As a result, tourists are barred from using what is officially denominated a \"public transport system\".\n\nThe bike is specially designed to prevent theft of parts, or of the whole bike, as well as to prevent vandalism. It is also designed to be easily recognised. However, common user complaints include missing ringbells, cut brakes, and poor maintenance. Bikes have sometimes been stolen, even by sawing the anchors that fix bikes on the stands, and found repainted.\n\nBike stations have generally replaced on-street car or motorcycle parking spaces, though others were placed on large pedestrian areas. Each station includes a long series of docks for bikes, with a computerized pylon at one end for completing transactions.\n\nThe system is paid for mostly by local car drivers with an on-street parking control system, distributed throughout much of the densely populated inner city. This money, about €2.23 million annually, is paid to the system operator. The yearly user fee is €47.16 with tax included, which makes it the city's cheapest public transport service.\nRecently the city made a sponsorship agreement with mobile operator Vodafone to feature the operator's logo on the system in exchange for €1.2 million a year.\n\nEach individual bike is used between 10 and 15 times a day by different people. More than 95% of rides in the system are shorter than 30 minutes. When a bicycle is returned, a user must wait 10 minutes before taking another one. Although there were over 90,000 registered users in September 2007 only one third of them were using the system on a regular basis. As of November 2007 the system had been used more than 2,750,000 times, representing 8,000,000 km of travel.\n\nThe bike sharing system was received by the inhabitants with great enthusiasm, covering approximately 70% of the city area, including Ciutat Vella, the Eixample and some parts of Sant Martí and Gràcia. However, stations have not been placed in areas where the grade is greater than four percent, such as the hilly areas of Montjuïc and Tibidabo. Several neighboring cities have asked for the service to be extended to their cities as well, and studies are underway on how to implement this for the wider metropolitan area.\n\nThe name is derived from \"bici\", the Catalan and Spanish short-form for bicycle, and \"BCN\", Barcelona's airport code and a popular abbreviation of its name. The English suffix \"-ing\" was also added, like the Spanish words \"footing\" (a pseudo-anglicism used for jogging), \"parking\" (car park), \"camping\" (campsite) and \"Vueling\", which is a Catalan airline.\n\n\n"}
{"id": "2608423", "url": "https://en.wikipedia.org/wiki?curid=2608423", "title": "Boudreaux's Butt Paste", "text": "Boudreaux's Butt Paste\n\nBoudreaux's Butt Paste is an American brand of skin cream that started out as a remedy for diaper rash. It has also been used for the treatment of various skin ailments including psoriasis, jock itch, shingles, chafing, cold sores and acne. \n\nThe product was created in the 1970s by George Boudreaux of Covington, Louisiana, while he was working as an intern pharmacist. He continued to work on the formula after becoming a licensed pharmacist and sold it at his pharmacy, later naming it \"Boudreaux's Butt Paste\" after a physician told him a story about a patient who had referred to the product as such.\n\nBoudreaux began distributing the product more extensively after he sold his pharmacy in 1974. Manufacturing moved from Alabama to New Orleans in 2004. After Oprah Winfrey recommended the product on her show the response was so great that the company's website crashed, and demand for Boudreaux's Butt Paste quadrupled. When Brad Pitt talked of a \"horrible diaper rash\" in two of his children, a \"People\" magazine article asked readers for advice. It reported that in under five hours almost 900 readers responded, recommending Boudreaux's Butt Paste \"overwhelmingly\".\n\nIn August 2005, a tide caused by Hurricane Katrina hit the area where Boudreaux's Butt Paste was manufactured, so emergency production was moved to Blairex Laboratories Inc. Soon after, the brand was sold to Blairex in Columbus, Indiana. After the sale, Boudreaux continued to work in Covington to work on marketing and developing new products based upon Butt Paste. Blairex focused on manufacturing and distribution. \n\nOn December 29, 2011, Blairex sold the brand to C.B. Fleet Company, Inc. \n\nThe brand became a NASCAR sponsor beginning with a Junie Donlavey-owned car driven by Kevin Ray in the Nextel Cup Series and Kim Crosby's #24 Butt Paste Chevrolet, run by GIC-Mixon Motorsports in the Busch Series. A NASCAR spokesman said to \"USA Today\": \"I think it's very fitting that Junie Donlavey, who has brought more drivers into the world of NASCAR than any other owner, is now being sponsored by a baby product.\" \n\nIn 2008, due to Boudreaux's Butt Paste ads on the car, Ray's No. 90 Ford was named the fifth scariest NASCAR paint scheme of all time by \"ESPN The Magazine\" for having \"'BUTT PASTE' slapped on the rear quarter panels in giant red lettering and a cartoon baby riding on the hood.\"\n\nOn December 22, 2016, Prestige Brands announced an agreement to acquire C.B. Fleet Company, Inc., a portfolio company of Gryphon Investors. This was the fifth transaction in which middle-market investment banking firm TM Capital served as a financial advisor to Fleet Laboratories.\n\nThe ingredients are:\n"}
{"id": "495814", "url": "https://en.wikipedia.org/wiki?curid=495814", "title": "Butcher", "text": "Butcher\n\nA butcher is a person who may slaughter animals, dress their flesh, sell their meat, or participate within any combination of these three tasks. They may prepare standard cuts of meat and poultry for sale in retail or wholesale food establishments. A butcher may be employed by supermarkets, grocery stores, butcher shops and fish markets, slaughter houses, or may be self-employed.\n\nAn ancient trade, whose duties may date back to the domestication of livestock, butchers formed guilds in England as far back as 1272. Today, many jurisdictions offer trade certifications for butchers. Some areas expect a three-year apprenticeship followed by the option of becoming a master butcher.\n\nButchery is a traditional line of work. In the industrialized world, slaughterhouses use butchers to slaughter the animals, performing one or a few of the steps repeatedly as specialists on a semiautomated disassembly line. The steps include stunning (rendering the animal incapacitated), exsanguination (severing the carotid or brachial arteries to facilitate blood removal), skinning (removing the hide or pelt) or scalding and dehairing (pork), evisceration (removing the viscera) and splitting (dividing the carcass in half longitudinally).\n\nAfter the carcasses are chilled (unless \"hot-boned\"), primary butchery consists of selecting carcasses, sides, or quarters from which primal cuts can be produced with the minimum of wastage; separating the primal cuts from the carcass; trimming primal cuts and preparing them for secondary butchery or sale; and storing cut meats. Secondary butchery involves boning and trimming primal cuts in preparation for sale. Historically, primary and secondary butchery were performed in the same establishment, but the advent of methods of preservation and low cost transportation has largely separated them.\n\nIn parts of the world, it is common for butchers to perform many or all of the butcher's duties. Where refrigeration is less common, these skills are required to sell the meat of slaughtered animals.\n\nSome butchers sell their goods in specialized stores, commonly termed a butcher shop (American English), butchery (South African English) or butcher's shop (British English). Butchers at a butcher shop may perform primary butchery, but will typically perform secondary butchery to prepare fresh cuts of meat for sale. These shops may also sell related products, such as hot food (using their own meat products), food preparation supplies, baked goods and grocery items. Butcher shops can have a wider variety of animal types, meat cuts and quality of cuts. Additionally, butcher shops may focus on a particular culture, or nationality, of meat production. Some butcher shops, termed \"meat delis\", may also include a delicatessen.\n\nIn the United States and Canada, butcher shops are becoming less common because of the increasing popularity of supermarkets. Supermarkets employ butchers for secondary butchery, but in the United States even that role is diminished with the advent of \"case-ready\" meat, where the product is packaged for retail sale at the packinghouse or specialized central processing plants.\n\nA primal cut is a piece of meat initially separated from the carcass during butchering. Different countries and cultures make these cuts in different ways, and primal cuts also differ between type of carcass. The British, American and French primal cuts all differ in some respects. A notable example is fatback, which in Europe is an important primal cut of pork, but in North America is regarded as trimmings to be used in sausage or rendered into lard. The primal cuts may be sold complete or cut further.\n\nIn various periods and cultures, the term \"butcher\" has been applied to people who act cruelly to other human beings or slaughter them. For example, Pompey, a prominent Roman general and politician of the first century BC, got the Latin nickname \"adulescentulus carnifex\", translated as \"The Teenage Butcher\" or \"The Butcher Boy\", due to brutal treatment of political opponents in the early part of his career.\n\n\n"}
{"id": "37196528", "url": "https://en.wikipedia.org/wiki?curid=37196528", "title": "Cellmax", "text": "Cellmax\n\nCellMax Technologies, also known as Cellmax, is a Swedish developer and manufacturer of efficient antennas used for base station s in mobile networks.\n\nCellMax Technologies was founded in 2001 and is headquartered in the Swedish ICT cluster Kista, outside Stockholm, with subsidiaries in Singapore and the USA. In 2012, CellMax Technologies opened a factory outside Warsaw.\n\nCellmax was named a Deloitte Technology Fast 500 EMEA 2011 company as one of the fastest growing technology companies in Europe, the Middle East and Africa.\n\nIn 2012, Cellmax invested 20 million SEK in a research center and antenna laboratory in Kista. The plant is described as one of the world's most modern and will be used for research and development of the 'next generation' of base station antennas. King Carl XVI Gustaf of Sweden and Sweden’s Prince Daniel opened the plant in summer 2012 along with global industry leaders in telecommunications, and foreign ambassadors.\n\n"}
{"id": "975309", "url": "https://en.wikipedia.org/wiki?curid=975309", "title": "Cementation process", "text": "Cementation process\n\nThe cementation process is an obsolete technology for making steel by carburization of iron. Unlike modern steelmaking, it increased the amount of carbon in the iron. It was apparently developed before the 17th century. Derwentcote Steel Furnace, built in 1720, is the earliest surviving example of a cementation furnace. Another example in the UK is the cementation furnace in Doncaster Street, Sheffield.\n\nThe process was described in a treatise published in Prague in 1574. It was again invented by Johann Nussbaum of Magdeburg, who began operations at Nuremberg (with partners) in 1601. The process was patented in England by William Ellyot and Mathias Meysey in 1614. At that date, the \"invention\" could consist merely of the introduction of a new industry or product, or even a mere monopoly. They evidently soon transferred the patent to Sir Basil Brooke, but he was forced to surrender it in 1619. A clause in the patent prohibiting the import of steel was found to be undesirable because he could not supply as much good steel as was needed. Brooke's furnaces were probably in his manor of Madeley at Coalbrookdale (which certainly existed before the English Civil War) where two cementation furnaces have been excavated. He probably used bar iron from the Forest of Dean, where he was a partner in farming the King's ironworks in two periods. \n\nBy 1631, it was recognised that Swedish iron was the best raw material and then or later particularly certain marks (brands) such as \"double bullet\" (so called from the mark OO) from Österby and \"hoop L\" from Leufsta (now Lövsta), whose mark consisted of an L in a circle, both belonging to Louis De Geer and his descendants. These were among the first ironworks in Sweden to use the Walloon process of fining iron, producing what was known in England as oregrounds iron. It was so called from the Swedish port of Öregrund, north of Stockholm, in whose hinterland most of the ironworks lay. The ore used came ultimately from the Dannemora mine.\n\nThe process begins with wrought iron and charcoal. It uses one or more long stone \"pots\" inside a furnace. Typically, in Sheffield, each was 14 feet by 4 feet and 3.5 feet deep. Iron bars and charcoal are packed in alternating layers, with a top layer of charcoal and then refractory matter to make the pot or \"coffin\" airtight. Some manufacturers used a mixture of powdered charcoal, soot and mineral salts, called \"cement powder\". In larger works, up to 16 tons of iron was treated in each cycle,though it can be done on a small scale, such as in a small furnace or blacksmith's forge.\n\nDepending on the thickness of the iron bars, the pots were then heated from below for a week or more. Bars were regularly examined and when the correct condition was reached the heat was withdrawn and the pots were left until cool—usually around fourteen days. The iron had gained a little over 1% in mass from the carbon in the charcoal, and had become heterogeneous bars of \"blister steel\".\n\nThe bars were then shortened, bound, heated and forge welded together to become \"shear steel\".It would be cut and re welded multiple times, with each new weld producing a more homogeneous, higher quality steel. This would be done at most 3-4 times, as more is unnecessary and could potentially cause carbon loss from the steel. \n\nAlternatively they could be broken up and melted in a crucible using a crucible furnace with a flux to become \"crucible steel\" or \"cast steel\", a process devised by Benjamin Huntsman in Sheffield in the 1740s.\n\nIn the early modern period, brass, an alloy of copper and zinc, was usually produced by a cementation process in which metallic copper was heated with calamine, a zinc ore, to make calamine brass.\n\n"}
{"id": "10390090", "url": "https://en.wikipedia.org/wiki?curid=10390090", "title": "Chip-scale atomic clock", "text": "Chip-scale atomic clock\n\nA Chip Scale Atomic Clock (CSAC) is a compact, low-power atomic clock fabricated using techniques of microelectromechanical systems (MEMS) and incorporating a low-power semiconductor laser as the light source. The first CSAC physics package was demonstrated at NIST in 2003 , based on an invention made in 2001 . The work was funded by the US Department of Defense's Defense Advanced Research Projects Agency (DARPA) with the goal of developing a microchip-sized atomic clock for use in portable equipment. In military equipment it is expected to provide improved location and battlespace situational awareness for dismounted soldiers when the global positioning system is not available, but many civilian applications are also envisioned. Commercial manufacturing of these atomic clocks began in 2011. The world's smallest atomic clock, the clock is 4 x 3.5 x 1 cm (1.5 x 1.4 x 0.4 inches) in size, weighs 35 grams, consumes only 115 mW of power, and can keep time to within 100 microseconds per day after several years of operation. \n\nLike other microwave atomic clocks, the clock keeps time by interrogating electron spin transitions between two hyperfine energy levels in atoms of non-radioactive cesium-133, rubidium-87, or rubidium-85, with microwave signal referenced to a quartz crystal oscillator. This signal is divided down by digital counters to give 10 MHz and 1 Hz clock signals provided to output pins. On the chip, liquid metal cesium (or rubidium) in a tiny 2 mm capsule, fabricated using silicon micromachining techniques, is heated to vaporize the alkali metal. A semiconductor laser shines a beam of infrared light modulated by a microwave oscillator through the capsule onto a photodetector. When the oscillator is at the precise frequency of the transition, the optical absorption of the cesium atoms is reduced, increasing the output of the photodetector. The output of the photodetector is used as feedback in a frequency locked loop circuit to keep the oscillator at the correct frequency.\n\nConventional vapor cell atomic clocks are about the size of a deck of cards, consume about 10 W of electrical power and cost about $3,000. Shrinking these to the size of a semiconductor chip required extensive development and several breakthroughs described in . An important part of development was designing the device so it could be manufactured using standard semiconductor fabrication techniques where possible, to keep its cost low enough that it could become a mass market device. Conventional vapor cell clocks use a glass tube containing rubidium, which are challenging to make smaller than 1 cm. In the CSAC, MEMS techniques were used to create a cesium capsule only 2 cubic millimeters in size. The light source in conventional atomic clocks is a rubidium atomic-vapor discharge lamp, which was bulky and consumed large amounts of power. In the CSAC this was replaced by an infrared vertical cavity surface emitting laser (VCSEL) fabricated on the chip, with its beam radiating upward into the cesium capsule above it.\n\nAt least one company produces a version of the clock.\n"}
{"id": "42270381", "url": "https://en.wikipedia.org/wiki?curid=42270381", "title": "CineExport", "text": "CineExport\n\nCineExport is a plug-in for Apple Compressor used to convert Final Cut Pro sequences and popular media formats to DCI compliant Digital Cinema Packages (DCP) by Doremi Labs. Using the powerful CineAsset encoding engine, CineExport can be used to create JPEG2000 DCP’s in the XYZ color space. MPEG-2 and H.264 encoded DCP’s can also be created for alternative content and compatible players. Standard and Pro versions are available allowing creation of 2D and 3D DCP’s at up to 4K resolution. The Pro version allows the generation of encrypted DCP’s along with KDM generation for encrypted content. DCP’s created by CineExport are compatible with any standard digital cinema server.\n\n\n\n\n\n\n"}
{"id": "1559357", "url": "https://en.wikipedia.org/wiki?curid=1559357", "title": "Cotton pad", "text": "Cotton pad\n\nCotton pads are pads made of cotton which are used for medical or cosmetic purposes. For medical purposes, cotton pads are used to stop or prevent bleeding from minor punctures such as injections or venipuncture. They may be secured in place with tape. Cotton pads are also used in the application and the removal of makeup. Cotton pads are soft enough that they can be used to clean babies. Cotton balls have much of the same applications as cotton pads, and can be used interchangeably.\n\nDespite their name, most modern cotton balls and pads are not made out of cotton at all but are instead made out of cheaper, bleached synthetic fibers such as polyester and nylon. In the United States, these products are frequently prominently labeled as \"cotton balls\" because non-woven products (of which disposable wipes, diapers and tampons are other examples) are excluded from the Federal Trade Commission's stringent labeling requirements for textile products ().\n\nThe specific phobia of cotton balls has been reported, but its prevalence is unknown.\n\nUse of cotton for sanitary purposes likely dates back to its domestication. There is evidence that toilet paper, made in part of cotton and/or other plant fibers such as hemp, was used at least as early as 589 AD in China. Cotton balls have been used for applying gold leaf since at least as far back as 1801. An artists' manual from that year recommends using a \"squirrel's tail, or cotton ball\" to press the gold leaf into place. There is some evidence that they were being mass produced as far back as 1816, namely an advertisement taken out of the \"New York Evening Post\" by Palmer, Nichols & Co. for many different kinds of fabric and products made of cotton which lists \"Cotton Balls\" as an item for sale. In 1891 \"The Laredo Times\" ran a story about women who put cotton balls in their cheeks to make themselves appear less thin. An 1898 patent by Jerome B. Dillon for a new type of umbilical bandage used an \"antiseptic, absorbent cotton pad\" to carry out its function.\n\nIn 1937, Joseph A. Voss invented a machine which unraveled rolls of cotton and cut them at a fixed interval into cotton pads, starting the widespread consumption of cotton balls and pads. Companies producing cotton balls took out ads in newspapers as early as 1948 to promote their uses to the public. In 1965, the \"Opelousas Daily World\" reported that the sanitary cotton industry in the United States was worth US$60 million (US$460.4 million in 2016 CPI-adjusted dollars). Around this time, there was industry concern that sanitary products using nylon, labeled as cotton balls, were going to crowd out cotton balls actually containing cotton, harming cotton-exporting regions. In 1986, Johnson & Johnson, a manufacturer of cotton balls, published advertisements stating that \"doctors advise\" cotton balls over \"synthetic puffs\". By 2013 however, most consumer cotton balls and pads outside of specifically labeled \"100% Cotton\" organic brands contained mostly polyester and only nominal amounts of cotton. \n\nIn 2015, \"Mass Market Retailers\", a supermarket and chain store trade magazine, estimated that combined sales of cotton balls and pads in the United States were US$177.7 million for the year 2014, down from US$343.1 million in 1999. The change could be due to increases of sales of cheaper store brands: in 1999, only 50.1% of sold cotton balls were store branded, versus 88% in 2014. The top three cotton ball brands in the United States in 2015 were \"Swisspers\" (manufactured by U.S. Cotton), \"Swiss Beauty\" (U.S. Cotton), and \"Cotton Cloud\" (Wabbit, Inc.).\n\n"}
{"id": "10927579", "url": "https://en.wikipedia.org/wiki?curid=10927579", "title": "Cowl (chimney)", "text": "Cowl (chimney)\n\nA cowl is a usually hood-shaped covering used to increase the draft of a chimney and prevent backflow. The cowl, usually made of galvanized iron, is fitted to the chimney pot to prevent wind blowing the smoke back down into the room below. Undoubtedly named after the resemblance of many designs to the cowl garment worn by monks, they have been in use for centuries.\n\nWhen using an open fire to heat a room the smoke rises through a flue to a chimney pot on the roof. Under normal conditions the warm air from the fire will rise up the chimney emitting the smoke with it and dispersing it at rooftop level where it is less of a nuisance.\n\nIn strong winds the pressure of the wind may overwhelm the updraft and push the airflow in reverse down the flue. Smoke will then fill the room it is intended to heat posing a health and fire risk, causing discomfort and dirtying furnishings in its path. \n\nWhen raw coal rather than smokeless fuel is burnt, the amount of smoke may be considerable and measures to prevent backflow occurring are a necessity.\n\nA secondary function is to prevent birds and squirrels from nesting in the chimney. They often also act as a rain guard to keep rain from going down the chimney. A metal wire mesh is sometimes added as a spark arrestor. Wooden cowls were used on oasts to prevent the ingress of rain into kilns, and create a flow of air through the kiln.\n\nA H-style cap (cowl) is a chimney top constructed from chimney pipes shaped like the letter H. It is an age-old method to regulate draft in situations where prevailing winds or turbulence cause downdraft and backpuffing. Although the H-cap has a distinctive advantage over most other downdraft caps, it fell out of favor because of its bulky looks. It is found mainly in marine use but has been gaining popularity again for its energy saving functionality. The H-cap stabilizes the draft rather than increasing it. Other downdraft caps are based on the Venturi effect, solving downdraft problems by increasing the updraft constantly resulting in much higher fuel consumption.\n\nCowls are also used where flues are no longer in use and therefore need to be capped off for protection against ingress of precipitation and nesting birds. Such cowls are designed to afford protection to the flue while still allowing a degree of ventilation.\n\n\n"}
{"id": "516115", "url": "https://en.wikipedia.org/wiki?curid=516115", "title": "Digital Light Processing", "text": "Digital Light Processing\n\nDigital Light Processing (DLP) is a display device based on optical micro-electro-mechanical technology that uses a digital micromirror device. It was originally developed in 1987 by Larry Hornbeck of Texas Instruments. While the DLP imaging device was invented by Texas Instruments, the first DLP-based projector was introduced by Digital Projection Ltd in 1997. Digital Projection and Texas Instruments were both awarded Emmy Awards in 1998 for the DLP projector technology. DLP is used in a variety of display applications from traditional static displays to interactive displays and also non-traditional embedded applications including medical, security, and industrial uses.\n\nDLP technology is used in DLP front projectors (standalone projection units for classrooms and business primarily), DLP rear projection television sets, and digital signs. It is also used in about 85% of digital cinema projection, and in additive manufacturing as a light source in some printers to cure resins into solid 3D objects.\n\nSmaller \"pico\" chipsets are used in mobile devices including cell phone accessories and projection display functions embedded directly into phones.\n\nIn DLP projectors, the image is created by microscopically small mirrors laid out in a matrix on a semiconductor chip, known as a Digital Micromirror Device (DMD). These mirrors are so small that DMD pixel pitch may be 5.4 µm or less. Each mirror represents one or more pixels in the projected image. The number of mirrors corresponds to the resolution of the projected image (often half as many mirrors as the advertised resolution due to wobulation). 800×600, 1024×768, 1280×720, and 1920×1080 (HDTV) matrices are some common DMD sizes. These mirrors can be repositioned rapidly to reflect light either through the lens or onto a heat sink (called a \"light dump\" in Barco terminology).\n\nRapidly toggling the mirror between these two orientations (essentially on and off) produces grayscales, controlled by the ratio of on-time to off-time.\n\nThere are two primary methods by which DLP projection systems create a color image: those used by single-chip DLP projectors, and those used by three-chip projectors. A third method, sequential illumination by three colored light emitting diodes, is being developed, and is currently used in televisions manufactured by Samsung.\n\nIn a projector with a single DLP chip, colors are produced either by placing a color wheel between a white lamp and the DLP chip or by using individual light sources to produce the primary colors, LEDs or lasers for example. The color wheel is divided into multiple sectors: the primary additive colors: red, green, and blue, and in many cases white (clear). Newer systems substitute the primary subtractive colors cyan, magenta, and yellow for white. The use of the subtractive colors is part of the newer color performance system called BrilliantColor which processes the additive colors along with the subtractive colors to create a broader spectrum of possible color combinations on the screen.\n\nThe DLP chip is synchronized with the rotating motion of the color wheel so that the green component is displayed on the DMD when the green section of the color wheel is in front of the lamp. The same is true for the red, blue and other sections. The colors are thus displayed sequentially at a sufficiently high rate that the observer sees a composite \"full color\" image. In early models, this was one rotation per frame. Now, most systems operate at up to 10× the frame rate.\n\nThe black level of a single-chip DLP depends on how unused light is being disposed. If the unused light is scattered to reflect and dissipate on the rough interior walls of the DMD / lens chamber, this scattered light will be visible as a dim gray on the projection screen, when the image is fully dark. Deeper blacks and higher contrast ratios are possible by directing unused HID light away from the DMD / lens chamber into a separate area for dissipation, and shielding the light path from unwanted internal secondary reflections.\n\nDLP projectors utilizing a mechanical spinning color wheel may exhibit an anomaly known as the \"rainbow effect\". This is best described as brief flashes of perceived red, blue, and green \"shadows\" observed most often when the projected content features high contrast areas of moving bright or white objects on a mostly dark or black background. Common examples are the scrolling end credits of many movies, and also animations with moving objects surrounded by a thick black outline. Brief visible separation of the colours can also be apparent when the viewer moves their eyes quickly across the projected image. Some people perceive these rainbow artifacts frequently, while others may never see them at all.\n\nThis effect is caused by the way the eye follows a moving object on the projection. When an object on the screen moves, the eye follows the object with a constant motion, but the projector displays each alternating color of the frame at the same location for the duration of the whole frame. So, while the eye is moving, it sees a frame of a specific color (red, for example). Then, when the next color is displayed (green, for example), although it gets displayed at the same location overlapping the previous color, the eye has moved toward the object's next frame target. Thus, the eye sees that specific frame color slightly shifted. Then, the third color gets displayed (blue, for example), and the eye sees that frame's color slightly shifted again. This effect is not perceived only for the moving object, but the whole picture. Multi-color LED-based and laser-based single-chip projectors are able to eliminate the spinning wheel and minimize the rainbow effect, since the pulse rates of LEDs and lasers are not limited by physical motion. \"Three-chip DLP projectors have no color wheels, and thus do not manifest this [rainbow] artifact.\"\n\nA three-chip DLP projector uses a prism to split light from the lamp, and each primary color of light is then routed to its own DLP chip, then recombined and routed out through the lens. Three chip systems are found in higher-end home theater projectors, large venue projectors and DLP Cinema projection systems found in digital movie theaters.\n\nAccording to DLP.com, the three-chip projectors used in movie theaters can produce 35 trillion colors. The human eye is suggested to be able to detect around 16 million colors , which is theoretically possible with the single chip solution. However, this high color precision does not mean that three-chip DLP projectors are capable of displaying the entire gamut of colors we can distinguish (this is fundamentally impossible with any system composing colors by adding three constant base colors). In contrast, it is the one-chip DLP projectors that have the advantage of allowing any number of primary colors in a sufficiently fast color filter wheel, and so the possibility of improved color gamuts is available.\n\nDLP technology is light-source agnostic and as such can be used effectively with a variety of light sources. Historically, the main light source used on DLP display systems has been a replaceable high-pressure xenon arc lamp unit (containing a quartz arc tube, reflector, electrical connections, and sometimes a quartz/glass shield), whereas most pico category (ultra-small) DLP projectors use high-power LEDs or lasers as a source of illumination.\n\nFor xenon arc lamps, during start-up, the lamp is ignited by a 5–20-kilovolt pulse from a current-regulating ballast to initiate an arc between two electrodes in the quartz tube. After warmup, the ballast's output voltage drops to approximately 60 volts while keeping the current high. As the lamp ages, the arc tube's electrodes wear out and light output declines somewhat, while waste heating of the lamp increases. The lamp's end of life is typically indicated by an LED on the unit or an onscreen text warning, necessitating replacement of the lamp unit.\n\nWhen a lamp is operated past its rated lifespan, the efficiency declines significantly, the lightcast may become uneven, and the lamp starts to operate extremely hot, to the point that the power wires can melt off the lamp terminals. Eventually, the required startup voltage will also rise to the point where ignition can no longer occur. Secondary protections such as a temperature monitor may shut down the projector, but a thermally overstressed quartz arc tube can also crack and/or explode. However, practically all lamp housings contain heat-resistant barriers (in addition to those on the lamp unit itself) to prevent the red-hot quartz fragments from leaving the area.\n\nThe first commercially available LED-based DLP HDTV was the Samsung HL-S5679W in 2006, which also eliminated the use of a color wheel. Besides long lifetime eliminating the need for lamp replacement and elimination of the color wheel, other advantages of LED illumination include instant-on operation and improved color, with increased color saturation and improved color gamut to over 140% of the NTSC color gamut. Samsung expanded the LED model line-up in 2007 with products available in 50-, 56- and 61-inch screen sizes. In 2008, the third generation of Samsung LED DLP products were available in 61\" (HL61A750) and 67\" (HL67A750) screen sizes.\n\nOrdinary LED technology does not produce the intensity and high-lumen output characteristics required to replace arc lamps. The special patented LEDs used in all of the Samsung DLP TVs are PhlatLight LEDs, designed and manufactured by US-based Luminus Devices. A single RGB PhlatLight LED chipset illuminates these projection TVs. The PhlatLight LEDs are also used in a new class of ultra-compact DLP front projector commonly referred to as a \"pocket projector\" and have been introduced in new models from LG Electronics (HS101), Samsung electronics (SP-P400) and Casio (XJ-A series). Home Theater projectors will be the next category of DLP projectors that will use PhlatLight LED technology. At InfoComm, June 2008 Luminus and TI announced their collaboration on using their technology on home theater and business projectors and demonstrated a prototype PhlatLight LED-based DLP home theater front projector. They also announced products will be available in the marketplace later in 2008 from Optoma and other companies to be named later in the year.\n\nLuminus Devices PhlatLight LEDs have also been used by Christie Digital in their DLP-based MicroTiles display system. It is a modular system built from small (20 inch diagonal) rear projection cubes, which can be stacked and tiled together to form large display canvasses with very small seams. The scale and shape of the display can have any size, only constrained by practical limits.\n\nThe first commercially available laser-based DLP HDTV was the Mitsubishi L65-A90 LaserVue in 2008, which also eliminated the use of a color wheel. Three separate color lasers illuminate the digital micromirror device (DMD) in these projection TVs, producing a richer, more vibrant color palette than other methods. See the laser video display article for more information.\n\nDLP Cinema systems have been deployed and tested commercially in theatres since 1999. In June 1999, \"\" was the first movie to be entirely scanned and distributed to theaters. Four theaters installed digital projectors for the movie's release. The same was done for the traditional and computer-animated hybrid film \"Tarzan\" that same year. Later that year,\" Toy Story 2\" was the first movie to be entirely created, edited, and distributed digitally, with more theaters installing digital projectors for its release. DLP Cinema was the first commercial digital cinema technology and is the leading digital cinema technology with approximately 85% market share worldwide as of December 2011. Digital cinema has some advantages over film because film can be subject to color fading, jumping, scratching and dirt accumulation. Digital cinema allows the movie content to remain of consistent quality over time. Today, most movie content is also captured digitally. The first all-digital \"live action\" feature shot \"without\" film was the 2002 release, Star Wars Episode II: Attack of the Clones.\n\nDLP Cinema does not manufacture the end projectors, but rather provides the projection technology and works closely with Barco, Christie Digital and NEC who make the end projection units. DLP Cinema is available to theatre owners in multiple resolutions depending on the needs of the exhibitor. These include, 2K – for most theatre screens, 4K - for large theatre screens, and S2K, which was specifically designed for small theatres, particularly in emerging markets worldwide.\n\nOn February 2, 2000, Philippe Binant, technical manager of Digital Cinema Project at Gaumont in France, realized the first digital cinema projection in Europe with the DLP CINEMA technology developed by Texas Instruments. DLP is the current market-share leader in professional digital movie projection, largely because of its high contrast ratio and available resolution as compared to other digital front-projection technologies. As of December 2008, there are over 6,000 DLP-based Digital Cinema Systems installed worldwide.\n\nDLP projectors are also used in RealD Cinema and newer IMAX theatres for 3-D films.\n\nSince being introduced commercially in 1996, DLP technology has quickly gained market share in the front projection market and now holds greater than 50% of the worldwide share in front projection in addition to 85% market share in digital cinema worldwide. Additionally, in the pico category (small, mobile display) DLP technology holds approximately 70% market share. Over 30 manufacturers use the DLP chipset to power their projection display systems.\n\n\n\nThe most similar competing system to DLP is known as LCoS (liquid crystal on silicon), which creates images using a stationary mirror mounted on the surface of a chip, and uses a liquid crystal matrix (similar to a liquid crystal display) to control how much light is reflected. DLP-based television systems are also arguably considered to be smaller in depth than traditional projection television.\n\n\n"}
{"id": "6220531", "url": "https://en.wikipedia.org/wiki?curid=6220531", "title": "Electronic packaging", "text": "Electronic packaging\n\nElectronic packaging is the protective features and enclosures built into electronic devices. Packaging of an electronic system must consider protection from mechanical damage, cooling, radio frequency noise emission and electrostatic discharge. Prototypes and industrial equipment made in small quantities may use standardized commercially available enclosures such as card cages or prefabricated boxes. Mass-market consumer devices may have highly specialized packaging to increase consumer appeal. Electronic packaging is a major discipline within the field of mechanical engineering. \n\nThe same electronic system may be packaged as a portable device or adapted for fixed mounting in an instrument rack or permanent installation. Packaging for aerospace, marine, or military systems imposes different types of design criteria. This discipline requires the use of subjects normally only within the skill set of the mechanical engineer with their formal education in dynamics, stress analysis, heat transfer and fluid mechanics. High-reliability equipment often must survive drop tests, loose cargo vibration, secured cargo vibration, extreme temperatures, humidity, water immersion or spray, rain, sunlight (UV, IR and visible light), salt spray, explosive shock, and many more. These subjects typically are not the concern of the product's electrical design engineer since they have enough to do already to make sure the product functions as intended. Also, mechanical engineers have knowledge of the mechanical behaviors of materials and are better qualified to specify, source and test candidate materials and finishes for parts used to protect the core electronics which often consist of circuit card assemblies (CCAs), connectors, cables and \"buy-and-bolt\" components such as transformers, power supplies, relays, switches, etc. that are not designed to go on a CCA. That's not to say such components cannot be purchased in versions intended for putting on CCAs. Many components come both ways and the choice of which type falls on the mechanical and electrical engineers together who work closely as part of a multi-functional product development team. Lastly, many electrical products require the manufacturing of high-volume, low-cost parts (i.e. enclosures, covers...) which involve injection molding, die casting, investment casting, and so on. The design of these products depend heavily on the production method and require careful consideration of dimensions and tolerances and tooling design, another specialty in the realm of mechanical engineers. Even complex low-volume parts often require knowledge of specialized manufacturing processes e.g. plaster- and sand-casting of metal enclosures. Lastly, the mechanical engineer is normally more versed in the creation and control of engineering drawings which are ideally drawn in the USA under the auspices of the ASME Y14 family of drawing standards.\n\nIn the design of electronic products, electromechanical (E/M) or electronic packaging (mechanical) engineers sometimes perform manual, spreadsheet, computational fluid dynamic (CFD) and/or finite element method (FEM) analyses using handbooks formulas and commercial CFD and FEM programs to estimate such things as maximum CCA component junction temperatures (CFD and FEM), structural resonant frequencies (FEM) and dynamic stresses and deflections (FEM) under worst-case environments. Such knowledge is important to prevent immediate or premature electronic product failures.\n\nSo \"electronic packaging\" is a broad term that usually means a mechanical engineer doing all design work the electrical engineer is not able to do. Of course, a mechanical engineer, with enough education and training, can do the electrical engineer's job. Conversely, the electrical engineer, with enough education and training, can do the mechanical engineer's job. To confuse things, there are \"electronic packaging\" electrical engineers who design high performance CCA components e.g. systems on chips (SOCs), central processing units (CPUs) etc. for use in electrical circuits most often soldered or wire-bonded to CCAs.\n\nPunched and formed sheet metal is one of the oldest types of electronic packaging. It can be mechanically strong, provides electromagnetic shielding when the product requires that feature, and is easily made for prototypes and small production runs with little custom tooling expense.\n\nGasketed metal castings are sometimes used to package electronic equipment for exceptionally severe environments, such as in heavy industry, aboard ship, or deep under water. Aluminum die castings are more common than iron or steel sand castings.\n\nElectronic packages are sometimes made by machining solid blocks of metal, usually aluminum, into complex shapes. They are fairly common in microwave assemblies for aerospace use, where precision transmission lines require complex metal shapes, in combination with hermetically sealed housings. Quantities tend to be small; sometimes only one unit of a custom design is required. Piece part costs are high, but there is little or no cost for custom tooling, and first-piece deliveries can take as little as half a day. The tool of choice is a numerically controlled vertical milling machine, with automatic translation of computer-aided design (CAD) files to toolpath command files.\n\nMolded plastic cases and structural parts can be made by a variety of methods, offering tradeoffs in piece part cost, tooling cost, mechanical and electrical properties, and ease of assembly. Examples are injection molding, transfer molding, vacuum forming, and die cutting. Pl can be post-processed to provide conductive surfaces.\n\nFormally called \"encapsulation\", potting consists of immersing the part or assembly in a liquid resin, then curing it. Potting can be done in a pre-molded potting shell, or directly in a mold. Today it is most widely used to protect semiconductor components from moisture and mechanical damage, and to serve as a mechanical structure holding the lead frame and the chip together. In earlier times it was often used to discourage reverse engineering of proprietary products built as printed circuit modules. It is also commonly used in high voltage products to allow live parts to be placed closer together, so that the product can be smaller. This also excludes dirt and conductive contaminants (such as impure water) from sensitive areas. Another use is to protect deep-submergence items such as sonar transducers from collapsing under extreme pressure, by filling all voids. Potting can be rigid or soft. When void-free potting is required, it is common practice to place the product in a vacuum chamber while the resin is still liquid, hold a vacuum for several minutes to draw the air out of internal cavities and the resin itself, then release the vacuum. Atmospheric pressure collapses the voids and forces the liquid resin into all internal spaces. Vacuum potting works best with resins that cure by polymerization, rather than solvent evaporation.\n\nPorosity Sealing or Resin Impregnation is similar to potting, but doesn't use a shell or a mold. Parts are submerged in a polymerizable monomer or solvent-based low viscosity plastic solution. The pressure above the fluid is lowered to a full vacuum. After the vacuum is released, the fluid flows into the part. When the part is withdrawn from the resin bath, it is drained and/or cleaned and then cured. Curing can consist of polymerizing the internal resin or evaporating the solvent, which leaves an insulating dielectric material between different voltage components. Porosity sealing (Resin Impregnation) fills all interior spaces, and may or may not leave a thin coating on the surface, depending on the wash/rinse performance. The main application of vacuum impregnation porosity sealing is in boosting the dielectric strength of transformers, solenoids, lamination stacks or coils, and some high voltage components. It prevents ionization from forming between closely spaced live surfaces and initiating failure.\n\nLiquid filling is sometimes used as an alternative to potting or impregnation. It's usually a dielectric fluid, chosen for chemical compatibility with the other materials present. This method is used mostly in very large electrical equipment such as utility transformers, to increase breakdown voltage. It can also be used to improve heat transfer, especially if allowed to circulate by natural convection or forced convection through a heat exchanger. Liquid filling can be removed for repair much more easily than potting.\n\nConformal coating is a thin insulating coating applied by various methods. It provides mechanical and chemical protection of delicate components. It's widely used on mass-produced items such as axial-lead resistors, and sometimes on printed circuit boards. It can be very economical, but somewhat difficult to achieve consistent process quality. See Conformal coating, Parylene.\n\nGlop-top is a variant of conformal coating used in chip-on-board assembly (COB). It consists of a drop of specially formulated epoxy\nor resin deposited over a semiconductor chip and its wire bonds, to provide mechanical support and exclude contaminants such as fingerprint residues which could disrupt circuit operation. It is most commonly used in electronic toys and low-end devices.\n\nSurface-mounted LEDs are frequently sold in COB configurations. In these, the individual diodes are mounted in an array that allows the device to produce a greater amount of luminous flux with greater ability to dissipate the resulting heat in an overall smaller package than can be accomplished by mounting LEDs, even surface mount types, individually on a circuit board.\n\nHermetic metal packaging began life in the vacuum tube industry, where a totally leak-proof housing was essential to operation. This industry developed the glass-seal electrical feedthrough, using alloys such as Kovar to match the coefficient of expansion of the sealing glass so as to minimize mechanical stress on the critical metal-glass bond as the tube warmed up. Some later tubes used metal cases and feedthroughs, and only the insulation around the individual feedthroughs used glass. Today, glass-seal packages are used mostly in critical components and assemblies for aerospace use, where leakage must be prevented even under extreme changes in temperature, pressure, and humidity.\n\nPackages consisting of a lead frame embedded in a vitreous paste layer between flat ceramic top and bottom covers are more convenient than metal/glass packages for some products, but give equivalent performance. Examples are integrated circuit chips in ceramic Dual In-line Package form, or complex hybrid assemblies of chip components on a ceramic base plate. This type of packaging can also be divided into two main types: multilayer ceramic packages (like LTCC and HTCC) and pressed ceramic packages.\n\nPrinted circuits are primarily a technology for connecting components together, but they also provide mechanical structure. In some products, such as computer accessory boards, they're all the structure there is. This makes them part of the universe of electronic packaging.\nAn engineer or designer must balance many objectives and practical considerations when selecting packaging methods.\n\nA typical reliability qualification includes the following types of environmental stresses:\n\n"}
{"id": "58302950", "url": "https://en.wikipedia.org/wiki?curid=58302950", "title": "Elizabeth Bragg", "text": "Elizabeth Bragg\n\nElizabeth Bragg (1854 - 1929) was the first woman to receive a civil engineering degree from an American university. \n\nElizabeth Bragg receiving her degree in civil engineering from the University of California at Berkley in 1876. Bragg married George Cumming in 1888, a civil engineer with the Southern Pacific Railroad Company. Elizabeth Bragg Cumming died on the 10 November 1929, and is buried in California. \n"}
{"id": "313460", "url": "https://en.wikipedia.org/wiki?curid=313460", "title": "Endec", "text": "Endec\n\nIn electronic communications, an endec is a device which acts as both an encoder and a decoder on a signal or data stream, either with the same or separate circuitry or algorithm. The combining of these names is a portmanteau.\n\nThe general difference between an endec and a codec (\"compressor\" / \"decompressor\") is that hardware is usually considered to be an endec, while software is considered to be the codec.\n\nA device or program which uses a compression algorithm to create MPEG audio and/or video is often called an encoder, and one which plays back such files is a decoder. However, this is technically a codec, especially if performed in software.\n\n"}
{"id": "18883278", "url": "https://en.wikipedia.org/wiki?curid=18883278", "title": "Federal Laboratory Consortium", "text": "Federal Laboratory Consortium\n\nThe Federal Laboratory Consortium for Technology Transfer (FLC) is a U.S.-based nationwide network of federal laboratories that provides the forum to develop strategies and opportunities to help transfer laboratory mission technologies into commercial products for the global marketplace.\n\nThe FLC was organized in 1974 and formally chartered by the Federal Technology Transfer Act of 1986. Its host agency is the National Institute of Standards and Technology. More than 250 federal laboratories and centers and their parent departments and agencies are currently FLC members. In accordance with the Act and related federal policy, the FLC’s mission is to promote and facilitate the rapid movement of federal laboratory research results and technologies into the mainstream of the U.S. economy.\n\nSpecifically, the FLC develops and tests transfer methods, addresses barriers to the process, provides training, highlights grass-roots transfer efforts, and emphasizes national initiatives in which technology transfer has a role. For the public and private sectors, the FLC brings laboratories together with potential developers and users of government-owned technologies. The FLC seeks to add value to the federal agencies, laboratories, and their partners to accomplish the rapid integration of research and development resources into commercial products. The Consortium’s vision is to actively promote the fullest application and use of federal research and development by providing an environment for successful technology transfer, thereby enhancing the socioeconomic well-being of the United States in the world.\n\n\n"}
{"id": "52001590", "url": "https://en.wikipedia.org/wiki?curid=52001590", "title": "Gen-Z", "text": "Gen-Z\n\nThe Gen-Z consortium is a trade group of technology vendors involved in designing CPUs, random access memory, servers, storage, and accelerators. The goal was an open and royalty-free \"memory-semantic\" protocol, which is not limited by the memory controller of a CPU. The basic operations consist of simple loads and stores with the addition of modular extensions. It is intended to be used in a switched fabric or point-to-point where each device connects using a standard connector.\n\nThe consortium was publicly announced on October 11, 2016. Server vendor members include Cray, Dell Technologies, Hewlett Packard Enterprise, Huawei, IBM, and Lenovo. CPU vendor members include Advanced Micro Devices, ARM Holdings, Broadcom Limited, Cavium and IBM. Memory and storage vendor members include Micron Technology, Samsung, Seagate Technology, SK Hynix, and Western Digital. Other members include IDT Corporation, Mellanox Technologies, Microsemi, Red Hat, and Xilinx.\nAnalysts noted the absence of Intel (which announced an inter-connect technology of its own called Omni-Path a year before), Nvidia (with its own NVLink technology), and Cisco Systems.\nSome of the vendors also joined a group to promote the Cache coherent interconnect for accelerators (CCIX) protocol on the same day.\nAt about the same time, yet another consortium formed to work on an open specification for the Coherent Accelerator Processor Interface (CAPI).\nThe efforts followed years of delays before products were available with version 4.0 of PCI Express.\n\n"}
{"id": "42602780", "url": "https://en.wikipedia.org/wiki?curid=42602780", "title": "Global waste trade", "text": "Global waste trade\n\nThe global waste trade is the international trade of waste between countries for further treatment, disposal, or recycling. Toxic or hazardous wastes are often exported from developed countries to developing countries, also known as countries of the Global South. Therefore, the burden of the toxicity of wastes from Western countries falls predominantly onto developing countries in Africa, Asia, and Latin America.\nThe World Bank Report \"What a Waste: A Global Review of Solid Waste Management\", describes the amount of solid waste produced in a given country. Specifically, countries which produce more solid waste are more economically developed and more industrialized. The report explains that \"[g]enerally, the higher the economic development and rate of urbanization, the greater the amount of solid waste produced.” Therefore, countries in the Global North, which are more economically developed and urbanized, produce more solid waste than Global South countries.\n\nCurrent international trade flows of waste follow a pattern of waste being produced in the Global North and being exported to and disposed of in the Global South. Multiple factors affect which countries produce waste and at what magnitude, including geographic location, degree of industrialization, and level of integration into the global economy.\n\nNumerous scholars and researchers have linked the sharp increase in waste trading and the negative impacts of waste trading to the prevalence of neoliberal economic policy. With the major economic transition towards neoliberal economic policy in the 1980s, the shift towards “free-market” policy has facilitated the sharp increase in the global waste trade. Henry Giroux, Chair of Cultural Studies at McMaster University, gives his definition of neoliberal economic policy: “Neoliberalism ...removes economics and markets from the discourse of social obligations and social costs. ...As a policy and political project, neoliberalism is wedded to the privatization of public services, selling off of state functions, deregulation of finance and labor, elimination of the welfare state and unions, liberalization of trade in goods and capital investment, and the marketization and commodification of society.” Given this economic platform of privatization, neoliberalism is based on expanding free-trade agreements and establishing open-borders to international trade markets. Trade liberalization, a neoliberal economic policy in which trade is completely deregulated, leaving no tariffs, quotas, or other restrictions on international trade, is designed to further developing countries’ economies and integrate them into the global economy. Critics claim that although free-market trade liberalization was designed to allow any country the opportunity to reach economic success, the consequences of these policies have been devastating for Global South countries, essentially crippling their economies in a servitude to the Global North. Even supporters such as the International Monetary Fund, “progress of integration has been uneven in recent decades” \n\nSpecifically, developing countries have been targeted by trade liberalization policies to import waste as a means of economic expansion. The guiding neoliberal economic policy argues that the way to be integrated into the global economy is to participate in trade liberalization and exchange in international trade markets. Their claim is that smaller countries, with less infrastructure, less wealth, and less manufacturing ability, should take in hazardous wastes as a way to increase profits and stimulate their economies.\n\nCurrent supporters of global waste trade argue that importing waste is an economic transaction which can benefit countries with little to offer the global economy. Countries which do not have the production capacity to manufacture high quality products can import waste to stimulate their economy.\n\nLawrence Summers, former President of Harvard University and Chief Economist of the World Bank, issued a confidential memo arguing for global waste trade in 1991. The memo stated:\n\n\"I think the economic logic behind dumping a load of toxic waste in the lowest wage country is impeccable and we should face up to that… I’ve always thought that countries in Africa are vastly under polluted; their air quality is probably vastly inefficiently low compared to Los Angeles… Just between you and me shouldn't the World Bank be encouraging more migration of the dirty industries to the Least Developed Countries?\"\n\nThis position, which is mainly motivated by economics and financial profit in particular, demonstrates the main argument for global waste trade. The Cato Institute published an article supporting global waste trade suggesting that “there is little evidence that hazardous wastes, which are often chronic carcinogens, contribute to death rates in developing countries.” Elaborating on this point, the article argues that “people in developing countries would rationally accept increased exposure to hazardous pollutants in exchange for opportunities to increase their productivity—and, hence, their income.”\n\nOverall, the argument for global waste trade rests largely upon a perception that developing countries need to further their economic development. Supporters suggest that in engaging in global waste trade, developing countries of the Global South will expand their economies and increase profits.\n\nCritics of global waste trade claim that lack of regulation and failed policies have allowed developing nations to become toxic dump yards for hazardous waste. The ever-increasing amounts of hazardous waste being shipped to developing countries increases the disproportionate risk that the people in these nations face. Critics of the effects of the global waste trade emphasize the enormous amount of hazardous wastes that people in poorer countries must deal with. They highlight the fact that most of the world’s hazardous wastes are produced by Western countries (the United States and Europe), yet the people who suffer negative health effects from these wastes are from poorer countries that did not produce the waste.\n\nPeter Newell, Professor of Development Studies, argues that “environmental inequality reinforces and, at the same time reflects, other forms of hierarchy and exploitation along lines of class, race and gender.” Arguing that the detrimental effects of hazardous waste trade affect the disadvantaged more than others, critics of global waste trade suggest that the implications of dumping hazardous waste has significant consequences for People of Color, women, and low-income people in particular.\n\nCritiquing the global waste trade for reproducing inequality on a global scale, many activists, organizers, and environmentalists from regions affected in the Global South have vocalized their disappointment with global waste trade policies. Evo Morales, the first indigenous Amerindian President of Bolivia, argues against the current economic system forcing the exploitation of his country and people. He claims:\"If we want to save the planet earth, to save life and humanity, we have a duty to put an end to the capitalist system. Unless we put an end to the capitalist system, it is impossible to imagine that there will be equality and justice on this planet earth. This is why I believe that it is important to put an end to the exploitation of human beings and to the pillage of natural resources, to put an end to destructive wars for markets and raw materials, to the plundering of energy, particularly fossil fuels, to the excessive consumption of goods and to the accumulation of waste. The capitalist system only allows us to heap up waste. Jean Francois Kouadio, an African native living near a toxic dump site in the Ivory Coast, explains his experience with the effects of toxic substances lingering throughout his community. With major Western corporations dumping their toxic wastes in the Ivory Coast, Kuoadio has lost two children to the effects of toxic wastes. He describes the loss of his second daughter Ama Grace, and how the doctors \"said she suffered from acute glycemia caused by the toxic waste.\"\n\nIn addition to critics from the Global South, researchers and scholars in the West have begun critiquing the uneven distribution of negative effects these hazardous waste dumpings are causing. Dorceta Taylor, Professor at the University of Michigan, argues how Women of Color in the United States are disproportionately affected by these policies: \"Women of color have been at the forefront of the struggle to bring attention to the issues that are devastating minority communities – issues such as hazardous waste disposal; exposure to toxins; ...Their communities, some of the most degraded environments ... are repositories of the waste products of capitalist production and excessive consumption. As a result, they have been in the vanguard of the struggle for environmental justice; they are the founders of environmental groups, grassroots activists, researchers, conference organizers, workshop leaders, lobbyists, and campaign and community organizers.\"\n\nT.V. Reed, Professor of English and American Studies at Washington State University, argues that the correlation between historical colonialism and toxic colonialism is based on perceptions of indigenous land as ‘waste.’ He argues that Western cultures have deemed indigenous land as “underdeveloped” and “empty,” and that the people inhabiting it are therefore less “civilized.” Using the historical premises of colonialism, toxic colonialism reproduces these same arguments by defining Global South land as expendable for Western wastes.\n\nToxic colonialism, defined as the process by which “underdeveloped states are used as inexpensive alternatives for the export or disposal of hazardous waste pollution by developed states,” is the core critique against the global waste trade. Toxic colonialism represents the neocolonial policy which continues to maintain global inequality today through unfair trade systems. Toxic colonialism uses the term colonialism because “the characteristics of colonialism, involving economic dependence, exploitation of labour, and cultural inequality are intimately associated within the new realm of toxic waste colonialism.” \n\nElectronic waste, also known as e-waste, refers to discarded electrical or electronic devices. A rapidly growing surplus of electronic waste around the world has resulted from quickly evolving technological advances, changes in media (tapes, software, MP3), falling prices, and planned obsolescence. An estimated 50 million tons of e-waste are produced each year, the majority of which comes from the United States and Europe. Most of this electronic waste is shipped to developing countries in Asia and Africa to be processed and recycled.\n\nVarious studies have investigated the environmental and health effects of this e-waste upon the people who live and work around electronic waste dumps. Heavy metals, toxins, and chemicals leak from these discarded products into surrounding waterways and groundwater, poisoning the local people. People who work in these dumps, local children searching for items to sell, and people living in the surrounding communities are all exposed to these deadly toxins.\n\nOne city suffering from the negative results of the hazardous waste trade is Guiyu, China, which has been called the electronic waste dump of the world. It may be the world's largest e-waste dump, with workers dismantling over 1.5 million pounds of junked computers, cell phones and other electronic devices per year.\n\nIncinerator Ash is the ash produced when incinerators burn waste in order to dispose of it. Incineration has many polluting effects which include the release of various hazardous gases, heavy metals, and sulfur dioxide.\n\nAn example of incinerator ash being dumped onto the Global South from the Global North in an unjust trade exchange is the Khian Sea waste disposal incident. Carrying 14,000 tons of ash from an incinerator in Philadelphia, the cargo ship, Khian Sea, was to dispose of its waste. However, upon being rejected by The Dominican Republic, Panama, Honduras, Bermuda, Guinea Bissau, and the Dutch Antilles, the crew finally dumped a portion of the ash near Haiti. After changing the name of the ship twice to try and conceal the original identity, Senegal, Morocco, Yemen, Sri Lanka, and Singapore still banned the ship’s entry. Upon consistent rejections, the ash is believed to have been disposed of in the Atlantic and Indian Oceans. Following this disaster of handling hazardous waste, the Haitian government banned all waste imports leading a movement to recognize all of the disastrous consequences of this global waste trade. Based on the Khian Sea waste disposal incident and similar events, the Basel Convention was written to resist what is known to developing countries as ‘toxic colonialism.’ It was open for signature in March 1989 and went into effect in May 1992. The U.S. has signed the treaty, but has yet to ratify it.\n\nChemical waste is the excess and unusable waste from hazardous chemicals, mainly produced by large factories. It is extremely difficult and costly to dispose of. It poses many problems and health risks upon exposure, and must be carefully treated in toxic waste processing facilities.\n\nOne example of chemical waste being exported from the Global North onto the Global South was the event of an Italian business man seeking to avoid European economic regulations. Allegedly exporting 4,000 tons of toxic waste, containing 150 tons of polychlorinated biphenyls, or PCBs, the Italian businessman made $4.3 million in shipping hazardous waste to Nigeria. The Fordham Environmental Law Review published an article explaining the impacts of the toxic waste imposed on Nigeria in further detail:\n\"Mislabelling the garbage as fertilizers, the Italian company deceived a retired/illiterate timber worker into agreeing to store the poison in his backyard at the Nigerian river port of Koko for as little as 100 dollars a month. These toxic chemicals were exposed to the hot sun and to children playing nearby. They leaked into the Koko water system resulting in the death of nineteen villagers who ate contaminated rice from a nearby farm.\" This is just one example of how the traditional trade flow, from developed Western countries has severely, unfairly, and disproportionately impacted developing countries in the Global South.\n\nAnother danger to developing countries is the growing issue of shipbreaking, which is occurring mainly in Asia. Industrialized countries seeking to retire used vessels find it cheaper to send these ships to Asia for dismantling. China and Bangladesh are seen as the two hubs of shipbreaking in Asia. One of the main issues lies in the fact that these ships which are now too aged to continue, were constructed at a time with less environmental regulation. In an environmental fact sheet, researchers demonstrate the immense impact this new toxic trade sector has on workers and the environment. For one, the older ships contain health-damaging substances such as asbestos, lead oxide, zinc chromates, mercury, arsenic, and tributyltin. In addition, shipbreaking workers in China and in other developing countries traditionally lack proper equipment or protective gear when handling these toxic substances.\n\nThe global waste trade has had negative effects for many people, particularly in poorer, developing nations. These countries often do not have safe recycling processes or facilities, and people process the toxic waste with their bare hands. Hazardous wastes are often not properly disposed of or treated, leading to poisoning of the surrounding environment and resulting in illness and death in people and animals. Many people have experienced illnesses or death due to the unsafe way these hazardous wastes are handled.\n\nThe hazardous waste trade has disastrous effects upon the environment and natural ecosystems. Various studies explore how the concentrations of persistent organic pollutants have poisoned the areas surrounding the dump sites, killing numerous birds, fish, and other wildlife. There are heavy metal chemical concentrations in the air, water, soil, and sediment in and around these toxic dump areas, and the concentration levels of heavy metals in these areas are extremely high and toxic.\n\nThe hazardous waste trade has serious damaging effects upon the health of humans. People living in developing countries may be more vulnerable to the dangerous effects of the hazardous waste trade, and are particularly at risk from developing health problems. The methods of disposal of these toxic wastes in developing countries expose the general population (including future generations) to the highly toxic chemicals. These toxic wastes are often disposed of in open landfills, burned in incinerators, or in other dangerous processes. Workers wear little to no protective gear when processing these toxic chemicals, and are exposed to these toxins through direct contact, inhalation, contact with soil and dust, as well as oral intake of contaminated locally produced food and drinking water. Health problems resulting from these hazardous wastes affect humans by causing cancers, diabetes, alterations in neurochemical balances, hormone disruptions from endocrine disruptors, skin alterations, neurotoxicity, kidney damage, liver damage, bone disease, emphysema, ovotoxicity, reproductive damage, and many other fatal diseases. The improper disposal of these hazardous wastes creates fatal health problems, and is a serious public health risk.\n\nThere have been various international responses to the problems associated with the global waste trade and multiple attempts to regulate it for over thirty years. The hazardous waste trade has proven difficult to regulate as there is so much waste being traded, and laws are often difficult to enforce. Furthermore, there are often large loopholes in these international agreements that allow countries and corporations to dump hazardous wastes in dangerous ways. The most notable attempt to regulate the hazardous waste trade has been the Basel Convention.\n\nThe Basel Convention on the Control of Transboundary Movements of Hazardous Wastes and Their Disposal, usually known as the Basel Convention, is an international treaty that plays a crucial role in regulating the transnational movement of hazardous wastes. The Basel Convention was created in 1989 and attempts to regulate the hazardous waste trade, specifically to prevent the dumping of hazardous waste from more developed countries into less developed countries. The Basel Convention was developed following a series of high-profile cases in which large amounts of toxic waste were dumped into less developed countries, poisoning the people and environment. The Convention seeks to reduce the creation of hazardous wastes, and to control and reduce its trade across borders.\n\nThe Convention was opened for signatures on 22 March 1989, and officially entered into force on 5 May 1992. As of May 2014, 180 states and the European Union are parties to the Convention. Haiti and the United States have signed the Convention but not ratified it.\n\nThe Environmental Network for Optimizing Regulatory Compliance on Illegal Traffic (ENFORCE) is an agency staffed by relevant experts to promote compliance with the Basel Convention. It is an international body created to deal with transboundary issues of the international hazardous waste trade. Because the issue of the transnational hazardous waste trade crosses many borders and affects many nations, it has been important to have a multinational, multilateral organization presiding over these affairs. The members of ENFORCE include one representative from each of the five United Nations regions that are parties to the Convention as well as five representatives from the Basel Convention regional and coordinating centers, based on equitable geographical representation. Members of organizations such as the United Nations Environmental Programme (UNEP), International Criminal Police Organization (INTERPOL), NGOs working to prevent and stop illegal traffic such as the Basel Action Network (BAN), and many other organizations are also eligible to become members of ENFORCE.\n\nIn 1999 the Basel Convention passed the Protocol on Liability and Compensation that sought to improve regulatory measures and better protect people from hazardous waste. The Protocol on Liability and Compensation attempts to “assign appropriate liability procedures when the transboundary movements of hazardous wastes result in damages to human health and the environment”. The Protocol “imposes strict liability for damages in situations involving Parties to the Basel Convention, but only while they maintain control of the hazardous waste through their respective notifying, transporting, or disposing entities.” It seeks to regulate and ensure countries’ and corporations’ compliance with the Basel Convention laws. However, this Protocol remains unsigned by most countries, so its applicability is limited.\n\nIn an effort to protect themselves against unfair hazardous waste dumping, the African, Caribbean, and Pacific States (ACP) signed the Lome IV Convention, which is a supplement to the Basel Convention and prohibits the “export of hazardous wastes from the European Community to ACP States.” This Convention is one attempt by developing countries to protect themselves from Western countries exporting their waste to poorer nations through the hazardous waste trade. When the Lomé IV Convention expired in 2000, the ACP countries and the European countries entered into a new agreement known as the Cotonou Agreement, which “recognizes the existence of disproportionate risks in developing countries and desires to protect against inappropriate hazardous waste shipments to these countries.”\n\nIn 1991 multiple developing nations in Africa met to discuss their dissatisfaction with the Basel Convention in regulating the dumping of hazardous waste into their countries, and designed a ban on the import of hazardous wastes into their countries called the Bamako Convention. The Bamako Convention is different from the Basel Convention in that Bamako “essentially bans the import of all hazardous waste generated outside of the OAU [the Organization of African Unity] for disposal or recycling and deems any import from a non-Party to be an illegal act.” However, these countries could not effectively implement the stipulations of the Convention and could not prevent the dump of toxic wastes due to limited resources and a lack of powerful enforcement. Therefore, the application of the Bamako Convention was very limited.\n\nLaura Pratt, expert on the hazardous waste trade, claims that despite local and international attempts to regulate the hazardous waste trade, the “current international agreements, both the widespread, legally binding agreements and the ad hoc agendas among smaller groups of countries, have not been as successful at eliminating toxic waste colonialism as proponents would have hoped.” She explains that there are various loopholes in the current system that allow toxic waste to continue being dumped, and toxic colonialism to go unchecked. Some of the problems with these international agreements include continued illegal shipments and unclear definitions of terms.\n\nPratt explains that despite attempts to regulate illegal dumping, “[o]ftentimes hazardous waste is simply moved under false permits, bribes, improper labels, or even the pretext of 'recycling,' which is a growing trend.” Companies often export their hazardous wastes to poorer countries through illegal smuggling. Attempts to regulate this market have been hindered by a lack of ability to monitor the trade, as many countries do not have any authoritative legislative bodies in place to prevent or punish the illegal trafficking of hazardous wastes. Furthermore, Pratt explains that without coordinated international methods to enforce the regulations, it is extremely difficult for countries to \"control the illegal trade of hazardous waste, due to the disparity between enforcement resources and regulation uniformity.” Developing nations still bear the brunt of this illegal activity the most, and often do not have the resources or capability to protect themselves.\n\nAnother issue with the Basel Convention and other international agreements to regulate the waste trade is the difficulty of establishing clear, uniform definitions regarding wastes. These overly broad and ambiguous definitions cause problems with the international agreements, as different parties interpret the language of the agreements differently and thus act accordingly. For example, the “‘lack of distinction between ‘waste’ and ‘products’ in the convention and its vague criteria for ‘hazardous’ allowed the continued export of 'hazardous waste’ under the label of commodities or raw materials, despite the fact that these wastes still present environmental and health risks to developing countries.”\n\n"}
{"id": "33746051", "url": "https://en.wikipedia.org/wiki?curid=33746051", "title": "Industrial sickness", "text": "Industrial sickness\n\nIndustrial sickness is defined all over the world as \"an industrial company (being a company registered for not less than five years) which has, at the end of any financial year, accumulated losses equal to, or exceeding, its entire net worth and has also suffered cash losses in such financial year and the financial year immediately preceding such financial year\".\n\nIndustrial sickness is an umbrella term applied to various things associated with industry that make people ill and cause them to miss work. The solutions will have to be tailored to the specific industry, and only in that way can any real effect be made on improving the health and productivity of the industrial workforce.\n\nThe key is an aggressive work-up on the health issues for a given segment of the industrial workforce, and usually broken down by type of work (which makes sense). Even as coal miners face overpowering respiratory threats, and foundry and mill workers have to confront major physical threats from large (heavy) quantities of extremely hot materials, each facet of industrial production has its hot-button health issues.\n\nIndustrial health managers need training and experience identifying and remediating conditions that present major health threats to their respective workforces. Then they can train the rest of management and can teach the workers themselves about the best way to carry out their jobs with minimum threats to their health.\n\nAccording to Companies (Second Amendment) Act, 2002\n\n\"'Sick Industrial Company' means an industrial company which has\n\ni) The Accumulated losses in any financial year equal to 50 per cent or more of its average net worth during four years immediately preceding such financial year; or\n\nii) Failed to repay its debts within any three consecutive quarters on demand made in writing for its repayment by a creditor or creditors of such company.\"\n\nIndustrial sickness specially in small-scale Industry has been always a demerit for the Indian economy, because more and more industries like – cotton, Jute, Sugar, Textiles small steel and engineering industries are being affected by this sickness problem.\n\nAs per an estimate 300 units in the medium and large scale sector were either closed or were on the stage of closing in the year 1976. About 10% of 4 lakhs unit were also reported to be ailing. And this position also remain same in the next decades. At the end of year 1986, the member of sick units in the portfolio of scheduled commercial banks stood at 1,47,740 involving an out standing bank credit of Rs. 4874 crores.\n\nThe different types of industrial sickness in Small Scale Industry (SSI) fall under two important categories. They are as follows:\n\nWe can say pertaining to the factors which are within the control of management. This sickness arises due to internal disorder in the areas justified as following:\n\na) Lack of Finance: This including weak equity base, poor utilization of assets, inefficient working capital management, absence of costing & pricing, absence of planning and budgeting and inappropriate utilization or diversion of funds.\n\nb) Bad Production Policies : Another very important reason for sickness is wrong selection of site which is related to production, inappropriate plant & machinery, bad maintenance of Plant & Machinery, lack of quality control, lack of standard research & development and so on.\n\nc) Marketing and Sickness : This is another part which always affects the health of any sector as well as SSI. This including wrong demand forecasting, selection of inappropriate product mix, absence of product planning, wrong market research methods, and bad sales promotions.\n\nd) Inappropriate Personnel Management: Another internal reason for the sickness of SSIs is inappropriate personnel management policies which includes bad wages and salary administration, bad labour relations, lack of behavioural approach causes dissatisfaction among the employees and workers.\n\ne) Ineffective Corporate Management: Another reason for the sickness of SSIs is ineffective or bad corporate management which includes improper corporate planning, lack of integrity in top management, lack of coordination and control etc.\n\na) Personnel Constraint: The first for most important reason for the sickness of small scale industries are non availability of skilled labour or manpower wages disparity in similar industry and general labour invested in the area.\n\nb) Marketing Constraints: The second cause for the sickness is related to marketing. The sickness arrives due to liberal licensing policies, restrain of purchase by bulk purchasers, changes in global marketing scenario, excessive tax policies by govt. and market recession.\n\nc) Production Constraints: This is another reason for the sickness which comes under external cause of sickness. This arises due to shortage of raw material, shortage of power, fuel and high prices, import-export restrictions.\n\nd) Finance Constraints: Another external cause for the sickness of SSIs is lack of finance. This arises due to credit restrains policy, delay in disbursement of loan by govt., unfavorable investments, fear of nationalization.\n\ne)credit squeeze initiated by the government policies.\n\n\n\n"}
{"id": "7174639", "url": "https://en.wikipedia.org/wiki?curid=7174639", "title": "Insertion time", "text": "Insertion time\n\nThe term insertion time is used to describe the length of time which is required to rearrange a subcritical mass of fissile material into a prompt critical mass. This is one of the three main requirements in a nuclear weapon design to create a working fission atomic bomb. The need for a short insertion time with plutonium-239 is the reason the implosion method was chosen for the first plutonium bomb, while with uranium-235 it is possible to use a gun design.\n\nThe basic requirements are:\n"}
{"id": "15854169", "url": "https://en.wikipedia.org/wiki?curid=15854169", "title": "Korea Engineering &amp; Consulting Association", "text": "Korea Engineering &amp; Consulting Association\n\nThe Korea Engineering & Consulting Association (, KENCA) was founded in 1974 as a nonprofit association of engineering firms in accordance with enactment of the Engineering Services Promotion Law.\n\n\nAs KENCA is committed to furthering advancement of engineering profession, it helps the government form engineering-related policy through raising public awareness; educate and train engineers to elevate the quality of engineering services provided by the member firms; and promote international cooperation between its member firms and foreign engineering firms/clients.\n\nFurther details of its activities are as follows: \n- Research on revision of laws and systems to improve fundamentals of the engineering industry as well as submission of recommendations to the government. \n- Performing national projects entrusted by the government organization such as the Ministry of Science and Technology, the Ministry of Construction and Transportation, the Ministry of Commerce, Industry and Energy, the Fair Trade Commission, the Korea National Statistical Office, and the Korea Science and Engineering Foundation, etc. \n- Publication of 'Engineering' magazine; sponsorship of presentations, lectures and symposiums to promote greater leadership in the field of engineering industry. \n- Developing and publishing materials for improvement of technical capabilities of the member firms; education and training programs, including sponsoring seminars for experts in various engineering fields. \n- International activities including expansion of cooperative network centered on the FIDIC; and pioneering of new overseas market.\n"}
{"id": "23526238", "url": "https://en.wikipedia.org/wiki?curid=23526238", "title": "List of Industrial areas in Dubai", "text": "List of Industrial areas in Dubai\n\nThese are the list of Industrial areas in Dubai.\n\n\n"}
{"id": "59024", "url": "https://en.wikipedia.org/wiki?curid=59024", "title": "List of knots", "text": "List of knots\n\nThis list of knots includes many alternate names for common knots and lashings. Knot names have evolved over time and there are many conflicting or confusing naming issues. The overhand knot, for example, is also known as the thumb knot. The figure-eight knot is also known as the savoy knot or the Flemish knot.\n\n\n\n\n\n"}
{"id": "23798608", "url": "https://en.wikipedia.org/wiki?curid=23798608", "title": "MP4 Watch", "text": "MP4 Watch\n\nAn MP4 watch is a small portable video and music flash-based media player which can be worn on the wrist like a wristwatch. (See MP4 Player for the origin of the 'MP4' moniker.) Most devices are actually functional digital watches as well as being media players. Users can watch video on the LED or OLED color screen and listen to the audio played back over small built-in speakers, earphones, or a wireless headset in the case of Bluetooth MP4 watches.\n\nMP4 watches typically require the user to convert video files to smaller resolution or particular file formats before they can be played back. This led to the development of \"MP5\" watches that could play all the popular video file formats natively.\n\nMP4 watches are also known as \"video watches\", \"MP4 player watches\", and \"watch MP4 players\".\n\nThe first commercially available MP4 watch available to consumers in America was one manufactured by the Chinese electronics manufacturer Shenzhen Adragon Digitek in September 2006 and the now discontinued Aigo F209. Gadget blogs have tracked the evolution of MP4 Watches from the large and unwieldy through successive design improvements making them more realistically \"wearable\" gadgets.\n\nLike standard MP4 Players, MP4 watches are most commonly manufactured in Mainland China. While the form factor has yet to be picked up by well-known brands, a number of original equipment manufacturers currently offer MP4 watches with a wide range of styles. There are indications that well-known consumer electronics brands will not sell MP4 watches, instead moving straight to cellphone watches, which incorporate video functions and arguably supersede the MP4 watch concept.\n\nMP4 watches are traditionally square by design and can have metal, plastic or leather straps. Screen size varies between 1 and 2 inches including some in \"widescreen\" dimensions.\n\nWhile MP4 watches are principally marketed as ultra-portable video and timekeeping devices, watches today may also include functions such as:\n"}
{"id": "4981462", "url": "https://en.wikipedia.org/wiki?curid=4981462", "title": "MRUD", "text": "MRUD\n\nThe MRUD is a plastic bodied, convex rectangular directional type anti-personnel mine designed to wound or kill by fragmentation. It is broadly similar to the M18A1 Claymore mine. \n\nThe casing is a light green color with two detonator wells and three crude sight lines on the top and an embossed grid pattern on the front of some early mines. Two detachable metal legs fit in slots on the bottom to secure the mine when it is ground mounted. \n\nThe body of the MRUD is waterproof and the mine can be used in temperatures from -30˚ to + 50˚ C. The mine body contains 900 grams of TNT-based explosive and 650 5.5-millimeter steel balls. When fired the fragmentation has a lethal arc of 60 degrees and a lethal range of 40–50 meters. The MRUD kit comes packed with a manual inductor, circuit test device and an EK-40-69 electric detonator. The mine can be command detonated from up to 30 meters away using a manual inductor or another electrical power source. The fuse cavities also accept any Serbian booby trap fuse with an M10 x 1 mm including the UMP-1 and UMP-2 pull and the UMNOP-1 multi-function fuse. \n\nThe MRUD comes packed in a grey/green colored canvas shoulder bag which also contains the firing cable a circuit tester and a manual inductor. Ten of these sets come packed in a natural wooden crate.\n\nThese mines have been encountered mounted high in trees as well as the more conventional ground mounting. The MRUD can be located visually as well as with metal detectors. Depending on the actuation method the MRUD will have a limited resistance to blast overpressure from explosive breaching methods like the Giant Viper and MICLIC.\n\n\nThe MRUD is usually command actuated by electric detonator, but it can also be set up for tripwire actuation. In Bosnia and Croatia it was combined with a PMA-2 blast type anti-personnel mine by inserting one end of a length of detonating cord in the detonator cavity of the MRUD and taping the other end of the detonating cord to the bottom of the PMA-2. When the blast mine actuated, the MRUD was actuated as well. \n\nIf an insulated wire is encountered, care must be taken to establish control of both ends of the wire before attempting to neutralize the mine. The mine should be approached from a 90˚ angle (never from the front) in order to remain outside of its blast arc. When tracking the route of a tripwire, keep in mind that additional anti-personnel blast mines may have been buried along its length. It is all too easy to concentrate on following the tripwire, forgetting what may lie concealed underneath it.\n"}
{"id": "2606275", "url": "https://en.wikipedia.org/wiki?curid=2606275", "title": "Medical gas supply", "text": "Medical gas supply\n\nMedical gas supply systems in hospitals and other healthcare facilities are utilized to supply specialized gases and gas mixtures to various parts of the facility. Products handled by such systems typically include:\n\n\nSource equipment systems are generally required to be monitored by alarm systems at the point of supply for abnormal (high or low) gas pressure in areas such as general ward, operating theatres, ICU/ITU/CCU/NICU, recovery, major treatment rooms, etc. Equipment is connected to the medical gas pipeline system via Station Outlets (US) or Terminal Units (ISO). \n\nMedical gas systems are commonly color coded to identify their contents, but as coding systems and requirements (such as those for bottled gas) vary by jurisdiction, the text or labeling is the most reliable guide to the contents. Emergency shut-off valves, or zone valves, are often installed in order to stop gas flowing to an area in the event of fire or substantial leak, as well as for service. Valves may be positioned at the entrance to departments, with access provided via emergency pull-out windows. \n\nOxygen may be used for patients requiring supplemental oxygen via mask. Usually accomplished by a large storage system of liquid oxygen at the hospital which is evaporated into a concentrated oxygen supply, pressures are usually around 345-380 kPa (50-55 psi), or in the UK and Europe, 4-5 bar (approximately 58-72 psi). This arrangement is described as a vacuum insulated evaporator (VIE) or \"bulk tank\". In small medical centers with a low patient capacity, oxygen is usually supplied by a manifold of multiple high-pressure cylinders. In areas where a bulk system or high-pressure cylinder manifold is not suitable, oxygen may be supplied by an oxygen concentrator. However, on site production of oxygen is still a relatively new technology.\n\nMedical air is compressed air supplied by a special air compressor, through a dryer (in order to maintain correct dew point levels), and distributed to patient care areas by Half Hard BS:EN 13348 Copper pipe and also use Isolation Ball Valve for Operating the Services of Compressed Air 4bar. its also say as Medical Air 4 bar. In smaller facilities, medical air may also be supplied via high-pressure cylinders. Pressures are maintained around 345-380 kPa (50-55 psi).\n\nNitrous oxide is supplied to various surgical suites for its anaesthetic functions during pre-operative procedures. It is delivered to the hospital in high-pressure cylinders and supplied through the Medical Gas system. Some bulk systems exist, but are no longer installed due to environmental concerns and overall reduced consumption of Nitrous oxide. System pressures are around 345 kPa (50 psi), 4 bar UK.\n\nNitrogen is typically used to power pneumatic surgical equipment during various procedures, and is supplied by high-pressure cylinders. Pressures range around 1.2 MPa (175 psi) to various locations.\n\nLike Nitrogen, Instrument air is used to power surgical equipment. However, it is generated on site by an air compressor (similar to a Medical air compressor) rather than high-pressure cylinders. Early air compressors could not offer the purity required to drive surgical equipment. However, this has changed and instrument air is becoming a popular alternative to Nitrogen. As with Nitrogen, pressures range around 1.2 MPa (175 psi). UK systems are supplied at 11 bar to the local area and regulated down to 7-8 bar at point of use.\n\nTypically used for insufflation during surgery, and also used in laser surgeries. System pressures are maintained at about 345 kPa (50 psi), UK 4 bar. It is also used for certain respiratory disorders.It contains 5 percent.\n\nMedical vacuum in a hospital supports suction equipment and evacuation procedures, supplied by vacuum pump systems exhausting to the atmosphere. Vacuum will fluctuate across the pipeline, but is generally maintained around -75 kPa (-22 inHg), (450mmHg UK).\n\nWaste Anaesthetic Gas Disposal (WAGD), or Anaesthetic Gas Scavenging System (AGSS), is used in hospital anaesthesia evacuation procedures. Although it is similar to a medical vacuum system, some building codes require anaesthetic gases to be scavenged separately. Scavenging systems do not need to be as powerful as medical vacuum systems, and can be maintained around -50 to -65 kPa (-15 to -19 inHg).\n\nThere are many gas mixtures used for clinical and medical applications. They are often used for patient diagnostics such as lung function testing or blood gas analysis. Test gases are also used to calibrate and maintain medical devices used for the delivery of anaesthetic gases. In laboratories, culture growth applications include controlled aerobic or anaerobic incubator atmospheres for biological cell culture or tissue growth. Controlled aerobic conditions are created using mixtures rich in oxygen and anaerobic conditions are created using mixtures rich in hydrogen or carbon dioxide. Supply pressure is 4 bar.\n\nTwo common medical gas mixtures are Entonox and Heliox.\n\nBritish Compressed Gases Association website: Department of Health (United Kingdom) HTM02-01 Medical Gas Pipeline Systems Part A: Design, installation, validation and verification\n\nBritish Compressed Gases Association website: Department of Health (United Kingdom) HTM02-01 Medical Gas Pipeline Systems Part B: Operational Management\n"}
{"id": "26761951", "url": "https://en.wikipedia.org/wiki?curid=26761951", "title": "Medieval letter tile", "text": "Medieval letter tile\n\nMedieval letter tiles are one-letter ceramic tiles that were employed in monasteries and churches of the late Middle Ages for the creation of Christian inscriptions on floors and walls. They were created by pressing stamps bearing a reverse image into soft clay, which was then baked hard, and they were used to form words by assembling single-letter tiles in the desired order.\n\nThe decoration technique is notable for being an early form of movable type printing which essentially is nothing but the stringing together of identically created individual letters for the purpose of producing an image. Compared to the conventional printing technique later established by Johannes Gutenberg, though, medieval tile alphabets were created in an inverse order: In a first step, the (im)printing was done, and only then the process of typesetting occurred, by spreading out the individual letter tiles onto the floor and composing them into words and lines of text.\n\nThe use of such movable letter tiles is documented for the English Chertsey Abbey, from whose ruins specimens dating to the second half of the 13th century were recovered, as well as for the early 14th‑century flooring of the Dutch . In Zinna Abbey south of Berlin, there is an extant \"Ave Maria\" embedded in the floor before the altar. Each letter appears as a relief print on an unglazed, red-brown terracotta tile measuring 14 x 14 cm. The Latin inscription dates to the 13th or 14th century and was composed in Gothic majuscule.\n\nThe Prüfening dedicatory inscription is a Latin church inscription on a single clay tablet using a different principle, apparently made by stamping out the words with individual letter stamps or types.\n\n\n"}
{"id": "1828075", "url": "https://en.wikipedia.org/wiki?curid=1828075", "title": "Medion", "text": "Medion\n\nMedion AG is a German consumer electronics company owned by Lenovo. The company operates in Europe, the United States, and the Asia-Pacific region. The company's main products are computers and notebooks, but also smartphones, tablet computers, digital cameras, TVs, refrigerators, toasters, and fitness equipment.\n\nMedion products in Australia and the United States are available exclusively at Aldi and Super Billing Computers, with some products (such as DVD players) branded as \"Tevion\" (Aldi's own brand). Some of Medion's formal laptops were sold in North America at Best Buy stores and were sold in Canada at Future Shop as Cicero Computers.\n\nIn the United Kingdom, Medion products, including laptop and desktop computers, have been sold by Aldi, Sainsbury's, Somerfield, Woolworths, and Tesco, as well as being sold direct through Medion's own Web site and various other online retailers.\n\nMedion launched MEDIONMobile as ALDIMobile in Australia in an agreement with Aldi Stores. Medion Australia Pty Limited remains as the owner of ALDIMobile.\n\nIn China Medion products are sold under the Lenovo brand, but not all Lenovo branded products are Medion products.\n\nMedion sponsored Sahara Force India through Formula One Team driver Adrian Sutil in Formula One in 2007 to 2011, until Sutil left the team. In 2013 Sutil returned to Sahara Force India, and Medion returned as a sponsor. Sutil and Medion left the sport at the end of 2013.\n\nOther brands used on Medion products:\n\nThese Medion products can be recognized by the serial number starting with \"MD\" or \"LT\".\n\nOn 1 June 2011, the Chinese multinational Lenovo Group (LNVGY) announced plans to acquire Medion AG. Since August 2011, they hold the majority stake in Medion.\n"}
{"id": "49611486", "url": "https://en.wikipedia.org/wiki?curid=49611486", "title": "Mid-market awards", "text": "Mid-market awards\n\nThe CEO Connection Mid-Market Awards are a critical piece of a larger strategy to ensure the mid-market receives the attention it warrants as a job creator, a force for economic growth, and a driver of social impact. The Mid-Market Awards honor three mid-market leaders and one company that have demonstrated leadership, creativity, generosity and other qualities that represent the true spirit of the mid-market.\n\nAwardees are honored during a dedicated dinner held in conjunction with CEO Connection’s Mid-Market Convention, which is held at the Wharton School of the University of Pennsylvania.\n\nThe award categories include Mid-Market Company of the Year, Mid-Market CEO of the Year, Mid-Market Young Leader, and Mid-Market Social Impact Award. The Mid-Market Awards also includes presentation of a list of honorees of the Most Influential Women of the Mid-Market.\n\n\n\n\n\n\n"}
{"id": "17835849", "url": "https://en.wikipedia.org/wiki?curid=17835849", "title": "Mud weight", "text": "Mud weight\n\nIn the oil industry, mud weight is the density of the drilling fluid and is normally measured in pounds per gallon (lb/gal) (ppg) or pound cubic feet (pcf) . In the field it is measured using a mud scale or mud balance.\n\nIn conventional drilling fluids, barite is used to increase the density. Although other additives such as halite (salt) or calcium carbonate can also be used. Mud weight can be decreased by dilution or solids control equipment such as an industrial centrifuge, desilter, desander and shale shaker . Mud weight use to control the trapped fluids or gas in the formations by adding a hydro static pressure on them, increasing the mud weight = increasing the hydro static pressure. If the hydro static pressure increased over the formations pressure that will make a fracture in the formation leading to lose the mud to the formation, so adding loss circulation material like gel-flake or wood chips that can refill the gap and stop the mud loss. If the mud loss continues, then the hydro static pressure will decrease and flammable fluids and gas trapped under pressure will start leaking to the surface. This can lead to a potential blowout.\n"}
{"id": "2329101", "url": "https://en.wikipedia.org/wiki?curid=2329101", "title": "Nodal analysis", "text": "Nodal analysis\n\nIn electric circuits analysis, nodal analysis, node-voltage analysis, or the branch current method is a method of determining the voltage (potential difference) between \"nodes\" (points where elements or branches connect) in an electrical circuit in terms of the branch currents.\n\nIn analyzing a circuit using Kirchhoff's circuit laws, one can either do nodal analysis using Kirchhoff's current law (KCL) or mesh analysis using Kirchhoff's voltage law (KVL). Nodal analysis writes an equation at each electrical node, requiring that the branch currents incident at a node must sum to zero. The branch currents are written in terms of the circuit node voltages. As a consequence, each branch constitutive relation must give current as a function of voltage; an admittance representation. For instance, for a resistor, I = V * G, where G (=1/R) is the admittance (conductance) of the resistor.\n\nNodal analysis is possible when all the circuit elements' branch constitutive relations have an admittance representation. Nodal analysis produces a compact set of equations for the network, which can be solved by hand if small, or can be quickly solved using linear algebra by computer. Because of the compact system of equations, many circuit simulation programs (e.g. SPICE) use nodal analysis as a basis. When elements do not have admittance representations, a more general extension of nodal analysis, modified nodal analysis, can be used.\n\n\nThe only unknown voltage in this circuit is V. There are three connections to this node and consequently three currents to consider. The direction of the currents in calculations is chosen to be away from the node.\nWith Kirchhoff's current law, we get:\n\nformula_1\n\nThis equation can be solved with respect to V:\n\nformula_2\n\nFinally, the unknown voltage can be solved by substituting numerical values for the symbols. Any unknown currents are easy to calculate after all the voltages in the circuit are known.\n\nformula_3\n\n In this circuit, we initially have two unknown voltages, V and V. The voltage at V is already known to be V because the other terminal of the voltage source is at ground potential.\n\nThe current going through voltage source V cannot be directly calculated. Therefore, we cannot write the current equations for either V or V. However, we know that the same current leaving node V must enter node V. Even though the nodes cannot be individually solved, we know that the combined current of these two nodes is zero. This combining of the two nodes is called the supernode technique, and it requires one additional equation: V = V + V.\n\nThe complete set of equations for this circuit is:\n\nformula_4\n\nBy substituting V to the first equation and solving in respect to V, we get:\n\nformula_5\n\nIn general, for a circuit with formula_6 nodes, the node-voltage equations obtained by nodal analysis can be written in a matrix form as derived in the following.\nFor any node formula_7, KCL states formula_8 where formula_9 is the negative of the sum of the conductances between nodes formula_7 and formula_11, and formula_12 is the voltage of node formula_7.\nThis implies formula_14 where formula_15 is the sum of conductances connected to node formula_7. \nWe note that the first term contributes linearly to the node formula_7 via formula_15, while the second term contributes linearly to each node formula_11 connected to the node formula_7 via formula_21 with a minus sign.\nIf an independent current source/input formula_22 is also attached to node formula_7, the above expression is generalized to formula_24.\nIt is readily to show that one can combine the above node-voltage equations for all formula_6 nodes, and write them down in the following matrix form\nor simply\nThe matrix formula_28 on the left hand side of the equation is singular since it satisfies formula_29 where formula_30 is a formula_31 column matrix. This corresponds to the fact of current conservation, namely, formula_32, and the freedom to choose a reference node (ground). In practice, the voltage is the reference node is taken to be 0. Consider it is the last node, formula_33. In this case, it is straightforward to verify that the resulting equations for the other formula_34 nodes remain the same, and therefore one can simply discard the last column as well as the last line of the matrix equation. This procedure results in a formula_35 dimensional non-singular matrix equation with the definitions of all the elements stay unchanged.\n\n\n\n"}
{"id": "3589086", "url": "https://en.wikipedia.org/wiki?curid=3589086", "title": "Ordnance Corps (United States Army)", "text": "Ordnance Corps (United States Army)\n\nThe United States Army Ordnance Corps, formerly the United States Army Ordnance Department, is a Sustainment branch of the United States Army, headquartered at Fort Lee, Virginia. The broad mission of the Ordnance Corps is to supply Army combat units with weapons and ammunition, including at times their procurement and maintenance. Along with the Quartermaster Corps and Transportation Corps, it forms a critical component of the U.S. Army logistics system.\n\nThe U.S. Army Ordnance Corps mission is to support the development, production, acquisition, and sustainment of weapon systems, ammunition, missiles, electronics, and ground mobility materiel during peace and war to provide combat power to the U.S. Army. The officer in charge of the branch for doctrine, training, and professional development purposes is the Chief of Ordnance. The current Chief of Ordnance is Brigadier General Heidi J. Hoyle.\n\nDuring the colonial era in America, each colony was responsible for its own supply of ordnance materiel and its own personnel to supervise it. The first written record of an ordnance officer in British colonial America was Samuel Sharpe in the Massachusetts Bay Colony appointed in 1629 as Master Gunner of Ordnance. By 1645, the Massachusetts Bay Colony had a permanent Surveyor of Ordnance officer. By the time of the American Revolution, every colony had their own ordnance organization responsible for the procurement, distribution, supply, storage, and maintenance of munitions for the colony.\n\nIn July 1775, Ezekiel Cheever was appointed by General George Washington as Commissary of Artillery Stores, soon to be called Commissary of Military Stores with Major General Henry Knox, the Chief of Artillery. He was the civilian in charge of ordnance support for Washington's army in the field. By the end of the American Revolution, every brigade had ordnance personnel, usually civilian, providing munitions support to the soldiers in the field.\n\nIn 1776, the Board of War and Ordnance was established to oversee the conduct of the war. This board selected Benjamin Flower to be the Commissary General of Military Stores. Benjamin Flower was given the rank of Colonel and served in that capacity throughout the American Revolution. The Commissary General of Military Stores was an echelon above the Commissary of Military Stores in the field. His responsibility was to recruit and train artificers, establish ordnance facilities, and to distribute arms and ammunition to the army in the field. In 1777, a powder magazine was established at Carlisle, Pennsylvania and a foundry at Springfield, Massachusetts.\n\nIn the early years of the 19th Century, the Ordnance profession played a key role in the burgeoning Industrial Revolution in America. In 1794, President Washington established the two federal armories; the Springfield Armory in Massachusetts and the Harpers Ferry Armory in Virginia. At these locations, early developments and innovations striving towards interchangeable parts were achieved. Inventors such as Thomas Blanchard, Simeon North, John Hall, and Eli Whitney would perfect the methods and means for mass production. Growing out of the technical innovations of the arms industry, these methods would be widely adopted by American industry by the middle of the 19th Century, establishing what has become known as the American System of Manufacturing.\n\nOn 14 May 1812, as part of the preparation for the War of 1812, Congress established the Ordnance Department. It was responsible for arms and ammunition production, acquisition, distribution, and storage or ordnance materiel for the U.S. Army. The act also created a new position, the Commissary General of Ordnance. Colonel Decius Wadsworth, former Superintendent of the U.S. Military Academy at West Point, was chosen as the Commissary General of Ordnance. The act also directed the new Commissary General of Ordnance, soon renamed to Chief of Ordnance, to \"enlist artisans and laborers to direct the inspection and proof of all cannon and small arms to direct the construction of gun carriages equipments implements and ammunition to make estimates and contracts for and purchases of ordnance supplies and stores and to issue them to the army to exact from armories and arsenals quarterly returns of property and to receive from all responsible officers reports of damages to ordnance materiel to establish ordnance depots to prepare regulations for the government of the Ordnance Department and forms of returns and reports\".\n\nWadsworth also took great care in establishing and supervising the training of officers who would join the Ordnance Department. Coming from West Point, these officers, such as Alfred Mordecai and George Bomford, were highly trained in mechanical and chemical engineering and were among the highest ranking of graduating cadets from West Point. These new Ordnance officers were usually detailed to the Springfield or Harpers Ferry Armory, or to one of the various arsenals across the growing country, to conduct scientific and industrial experiments in metallurgy, chemistry, or one of the allied engineering fields.\n\nIn 1832, the Ordnance Department established the Non-Commissioned Officer rank of Ordnance Sergeant to be in charge of the Ordnance stores at any of the growing number of army forts and establishments across the country. This rank will remain until the reorganization of the Army under the National Defense Act of 1920.\n\nDuring the Mexican War, the Ordnance Department established the Ordnance Rocket and Howitzer Battery to service the then new M1841 12-pound howitzers and Hale war rockets, which had not yet entered Army service and were still being tested. This was the only Ordnance unit established primarily for a combat role. This unit included junior Army officers who would serve as senior leaders in the Civil War; including Jesse Reno and Benjamin Huger.\n\nDuring the war, the Ordnance Department furnished 90 million pounds of lead, 13 million pounds of artillery projectiles, and 26 million pounds of powder for a Union Army of over 1 million soldiers. However, despite the growth of the Army, the Ordnance Department did not grow in a corresponding manner. By the end of the war, it numbered only 64 Officers and approximately 600 Soldiers, officially. Yet, to support the Ordnance needs of the Army, Officers and Soldiers who had civilian experience in Ordnance responsibilities (i.e. blacksmiths, etc...) were assigned additional duty in their units, so that every unit, company-echelon and above, had someone assigned in Ordnance responsibilities.\n\nFor those few Ordnance officers who had been part of the pre-war Army, several of them accepted line positions, such as Major Generals Oliver O. Howard and Jesse Reno. Most, however, remained in the Ordnance Department and rose in rank to serve as Ordnance officers at one of the various arsenals or senior ordnance command for the Union Army, i.e. in the Army of the Potomac. About half of the Ordnance officers left to join the Confederacy, including its sole Chief of Ordnance during the war, Josiah Gorgas.\n\nBy 1872, the Ordnance Department reflected the Army’s return to a small peacetime status with 50 officers, 475 enlisted soldiers, and 1,738 civilian workers. Despite this constriction, the Ordnance Department continued its tradition of technological innovation and increased professionalism. Ordnance officers, including the Chiefs of Ordnance – Stephen Vincent Benet, Daniel Flagler, Adelbert Rinaldo Buffington – refined, improved, and even invented new Ordnance materiel. Steel breech-loading artillery, machine gun development, smokeless powder, improved gun carriages, officer promotion via examination, and training through apprenticeship at government arsenals and shops characterized the Ordnance Department during the latter 19th Century. In 1874, the first dedicated proving ground was established at Sandy Hook, New Jersey. Watervliet Arsenal was chosen as the location for the first federal cannon foundry in 1887 and a seacoast cannon shop was added in 1889.\n\nEven though WWI had been raging in Europe for nearly three years, the Ordnance Department had to play catch-up when the United States entered the war. With only 97 officers and 1,241 enlisted soldiers, the department had a myriad of problems to overcome. However, by the end of the war, it had solved all these problems, matured as an organization, and adapted to modern, mechanized warfare. It established an embryonic process for echelon based maintenance for field units, a tradition of Ordnance education at one of the officer or enlisted Ordnance schools, a new proving ground at Aberdeen, Maryland, and a plan to coordinate production and mobilize industry. By the end of the war, the Ordnance Department numbered 5,954 officers and 62,047 enlisted soldiers, with 22,700 of those officers and soldiers serving in the American Expeditionary Force in France.\n\nDuring WWII, the Ordnance Department was responsible for roughly half of all Army procurement, $34 billion. President Franklin Delano Roosevelt’s ‘Arsenal of Democracy’ depended on the Ordnance Department to become a reality. Ordnance Department strength increased from 334 officers to 24,000 officers, 4,000 enlisted to 325,000 enlisted, and 27,088 civilians to 262,000 civilians. Ordnance soldiers and civilians worked across the globe, in places as diverse as Iceland, Iran, the Pacific Islands, Africa, Europe, and the Middle East. Aberdeen Proving Ground expanded exponentially and headquartered The Ordnance School, the Ordnance Replacement Training Center, the new Bomb Disposal School, and the Ordnance Unit Training Center.\n\nThe Ordnance mission in the field operated on a scale never experienced previously by the Ordnance Department. During WWII, the Ordnance Branch gained its third core competency, Bomb Disposal (renamed Explosive Ordnance Disposal after WWII) added to its previous missions of ammunition handling and maintenance. By war’s end, there were more than 2,200 Ordnance units of approximately 40 types, ranging in size from squads to regiments.\n\nBeginning in 1942, with the authorization of the Chief of Ordnance, a computing branch at the University of Pennsylvania's Moore School of Electrical Engineering was established as a substation of Aberdeen Proving Ground under the code name \"Project PX\". On 15 February 1946, the Electronic Numerical Integrator and Computer (ENIAC), the world's first general-purpose electronic computer, was formally dedicated. ENIAC was designed to calculate artillery firing tables for the United States Army Ballistic Research Laboratory. The ENIAC's first use was in calculations for the hydrogen bomb.\nIn August 1945, Colonel Holger Toftoy, head of the Rocket Branch of the Research and Development Division of the US Army's Ordnance Department, offered initial one-year contracts to German rocket scientists as part of Operation Paperclip, a program used to recruit the scientists from Nazi Germany for employment by the United States; 127 of them accepted. In September 1945, the first group of seven rocket scientists arrived at Fort Strong, New York and then moving to Fort Bliss, Texas in January 1946.\n\nIn 1949, the German scientists were transferred from the White Sands Missile Range Fort Bliss Range Complex to the Redstone Arsenal Ordnance Rocket Center.\n\nPer the Army Reorganization Act of 1950, the Ordnance \"Department\" was renamed the Ordnance \"Corps\". With the outbreak of the Korean War, the Ordnance Corps largely re-established its successful procedures from World War II. It reactivated the various schools and units at Aberdeen Proving Ground, which had been dis-established following the end of WW II, to serve the Korea effort. It continued its tradition of echeloned-based maintenance and increased the rapidity of maintenance and ammunition supply and repair. Explosive Ordnance Disposal, formerly Bomb Disposal Squads, improved their procedures with a focus on Russian and Chinese ordnance.\n\nIn Vietnam, the capabilities of Explosive Ordnance Disposal became increasingly important due to the nature of a war with no front lines. EOD and other ordnance units work under the auspices of the 1st Logistical Command, which divided the country into four support zones. Despite the difficult circumstances, the operational readiness rates increased and by 1969 exceeded those of previous wars.\n\nIn 1962 the Ordnance Corps and the office of the Chief of Ordnance were disestablished. The Ordnance Branch (along with the Transportation and Quartermaster Branches) was placed under the supervision of the Army’s Deputy Chief of Staff for Logistics. Army Materiel Command assumed responsibility for Ordnance's historical tasks of research and development; procurement, production, and storage; and technical intelligence. Combat Development Command assumed responsibility for developing the Army's organization and doctrine. The Ordnance Center and School trained personnel in ammunition handling, maintenance, and Explosive Ordnance Disposal and was under the direction of Continental Army Command (CONARC). \n\nThe Ordnance Corps was reestablished on 28 October 1985.\n\nIn 2008, the Ordnance Corps consolidated the Ordnance Mechanical Maintenance School from Aberdeen Proving Ground and the United States Army Ordnance Munitions and Electronic Maintenance School from Redstone Arsenal into a single training facility based at Fort Lee, Virginia as a part of the 2005 Base Closure and Realignment Commission (BRAC) decision. With an entirely new campus dedicated to the training of all ranks of Ordnance soldiers and civilians, the Ordnance Corps maintains its commitment to the life-cycle sustainment of the Army’s materiel from cradle to grave, providing ammunition, and protecting the Army’s forces through EOD operations.\n\nThe Ordnance Corps branch insignia is represented by the \"Shell and Flame\". It is considered to be the oldest branch insignia in the U.S. Army. This symbol has been used since the 17th Century by various armies of Western Europe, including British and French forces, and was considered a common symbol used by the military. Ordnance Officers began wearing the symbol in 1832 and have been wearing it ever since. There have been a multiplicity of designs throughout the years, but the current design was adopted in 1936.\n\nThe plaque design has the branch insignia, letters, and rim in gold. The background is crimson.\n\nThe regimental insignia for the Ordnance Corps is a gold color metal and enamel device 1 1/8 inches in height overall consisting of two gray antique cannons in saltire on a white disc behind an encircling scroll in the form of a buckle red belt with, between the intersecting cannons and the belt, a black antique bomb, its scarlet flames issuing at the top of the device from behind the belt, which bears the inscription \"ORDNANCE CORPS U.S.A.\" in gold letters. It is worn on the right side of the uniform, above any unit citations.\n\nThe crossed cannons are representative of the Ordnance Corps's early relationship to the Artillery. The flaming bomb, also known as the shell and flame, represents the armament of days gone by, while the energy it connotes is applicable to the weapons of our own day. The cannoneer's belt, which encircles the flaming bomb and crossed cannons, is embossed with the words \"ORDNANCE CORPS U.S.A.\" and represents the traditional association between munitions and armament. The white background symbolizes the Ordnance Corps' motto, \"ARMAMENT FOR PEACE\".\n\nAs an Ordnance Soldier of the United States Army, I will utilize every available talent and means to ensure that superior mobility, firepower, and communications are advantages enjoyed by the United States Army over its enemies. As an Ordnance Soldier, I fully understand my duty to perform under adverse conditions and I will continually strive to perfect my craft. I will remain flexible so that I can meet any emergency. In my conduct, I will abide by the Soldier's code. In my support mission in the field, I will use every available skill to maintain superiority; I will always be tactically and technically proficient As an Ordnance soldier, I have no greater task.\nThe words and music to \"Arms for the Love of America\" were originally composed by Irving Berlin and published by the Army Ordnance Association in 1941. It was dedicated to Major General C.M. Wesson, the Chief of Ordnance from 1938 to 1942.\n\n<poem>\nOn land and on the sea and in the air\nWe've gotta be there, we've gotta be there\nAmerica is sounding her alarm\nWe've gotta have arms, we've gotta have arms\n\nArms for the love of America!\nThey speak in a foreign land, with weapons in every hand\nWhatever they try, we've gotta reply\nIn language that they understand\n\nArms for the love of America!\nAnd for the love of every mother's son\nWho's depending on the work that must be done\nBy the man behind the man behind the gun\n\n–Lyrics to \"Arms for the Love of America\"\n</poem>\n\nOn 26 February 1628 the Court of Assistants in London, England directed that \"five pieces of ordnance and a great quantity of other arms and great shot\" belonging to a settlement near modern-day Salem, Massachusetts be placed under the control of Mr. Samuel Sharpe, making him the first European \"Master Gunner of our Ordnance\" on the American continent.\n\nThe head of the Ordnance Corps Regiment is the Chief of Ordnance. In addition, the Regimental Command Sergeant Major and the Regimental Chief Warrant Officer assist him with the supervising of the health, training, and welfare of the Soldiers, Warrant Officers, and Officers of the Ordnance Branch. In addition, the Chief of Ordnance holds a secondary hat as the Commandant of the Ordnance School at Fort Lee, Virginia. As of 2017, there have been 40 Chiefs of Ordnance in the U.S. Army.\n\n\n\nThe United States Army Ordnance Museum was formed at Aberdeen Proving Ground, Maryland in 1919. In 2010, the museum was closed and reformed at Fort Lee as the U.S. Army Ordnance Training and Heritage Center.\n\n"}
{"id": "4754533", "url": "https://en.wikipedia.org/wiki?curid=4754533", "title": "Particle counter", "text": "Particle counter\n\nA particle counter is an instrument that detects and counts physical particles.\n\nThe nature of particle counting is based upon either light scattering, light obscuration, or direct imaging. A high intensity light source is used to illuminate the particle as it passes through the detection chamber. The particle passes through the light source (typically a laser or halogen light) and if light scattering is used, then the redirected light is detected by a photo detector. If direct imaging is used, a halogen light illuminates particles from the back within a cell while a high definition, high magnification camera records passing particles. Recorded video is then analyzed by computer software to measure particle attributes. If light blocking (obscuration) is used the loss of light is detected. The amplitude of the light scattered or light blocked is measured and the particle is counted and tabulated into standardized counting bins. The image to the right shows a light scattering particle counter diagram. More information about types of particle counters and types of particle detection follow in this article.\n\nDirect imaging particle counting employs the use of a high resolution camera and a light to detect particles. Vision based particle sizing units obtain two dimensional images that are analyzed by computer software to obtain particle size measurement in both the laboratory and online. Along with particle size, color and shape analysis can also be determined.\n\nApplications of particle counters are separated into three primary categories:\n\nAerosol particle counters are used to determine the air quality by counting and sizing the number of particles in the air. This information is useful in determining the amount of particles inside a building or in the ambient air. It also is useful in understanding the cleanliness level in a controlled environment. A common controlled environment aerosol particle counters are used in is a cleanroom. Cleanrooms are used extensively in semiconductor device fabrication, biotechnology, pharmaceutics, disk drives, aerospace and other fields that are very sensitive to environmental contamination. Cleanrooms have defined particle count limits. Aerosol particle counters are used to test and classify a cleanroom to ensure its performance is up to a specific cleanroom classification standard. Several standards exist for cleanroom classification. The most frequently referred to classification is from the United States. Though originating in the United States, the standard Federal Standard 209E was the first and most commonly referred to. This standard was replaced in 1999 by an international standard, but Federal Standard 209E remains today the most widely referenced standard in the world.\n\nThere are several direct-reading instruments for measuring aerosol particle emissions. The condensation particle counter and differential mobility particle sizers, including the scanning mobility particle sizer and fast mobility particle sizer, can measure aerosol concentration; the diffusion charger and electric low pressure impactor can measure surface area; the size selective static sampler and tapered element oscillating microbalance can measure mass.\n\nThe replacement standard is ISO 14644-1 and is meant to completely replace Federal Standard 209E. This ISO Standard can be found through the non-profit organization, Institute of Environmental Sciences and Technology (IEST). Each of these standards represents the maximum allowable number of particles in a unit of air. The typical unit is either cubic feet or cubic meters. The particle counts are always listed as cumulative.\n\nLiquid particle counters are used to determine the quality of the liquid passing through them. The size and number of particles can determine if the liquid is clean enough to be used for the designed application. Liquid particle counters can be used to test the quality of drinking water or cleaning solutions, or the cleanliness of power generation equipment, manufacturing parts, or injectable drugs.\n\nLiquid particle counters are also used to determine the cleanliness level of hydraulic fluids and various other systems including (engines, gears and compressors), the reason being that 75-80% of hydraulic breakdowns can be attributed to contamination. There are various types, installed on the equipment, operated in a laboratory as part of an oil analysis programme .\nor portable units that can be transported to site, \"e.g.\", a construction site, and then used on the machine, \"e.g.\", a bulldozer, to determine fluid cleanliness. By determining and monitoring these levels, and following a proactive or predictive maintenance program, the user can reduce hydraulic failures, increase uptime and machine availability, and to reduce oil consumption. They can also be used to assure that hydraulic fluids have been cleaned using filtration, to acceptable or target cleanliness levels. There are various standards in use in the hydraulic industry, of which ISO 4406:1999, NAS1638 and SAE AS 4059 are probably the most common.\n\nA typical hydraulic oil cleanliness to iso 4406 is 20/18/15. .\n\nSolid particle counters are used to measure dry particles for various industrial applications. One such application could be for the detection of particle size coming from a rock crusher within a mining quarry. Sieves are the standard instruments used to measure dry particle size. Vision based systems are also used to measure dry particle size. With a vision based system quick and efficient particle sizing can be done with ease and tremendous accuracy.\n\nThere are several methods used for detecting and measuring particle size or size distribution — light blocking (obscuration), light scattering, Coulter principle and direct imaging.\n\nThe light blocking optical particle counter method is typically useful for detecting and sizing particles greater than 1 micrometer in size and is based upon the amount of light a particle blocks when passing through the detection area of the particle counter. This type of technique allows high resolution and reliable measurement.\n\nThe light scattering method is capable of detecting smaller-sized particles. This technique is based upon the amount of light that is deflected by a particle passing through the detection area of the particle counter. This deflection is called light scattering. Typical detection sensitivity of the light scattering method is 0.05 micrometre or larger. However, employment of the condensation nuclei counter (CNC) technique would allow a higher detection sensitivity in particle sizes down to nanometre range. A typical application is monitoring of ultrapure water in semiconductor fabrication facilities.\n\nThe light blocking method is specified for particle counters that are used for counting in hydraulic and lubricating fluids. Particle counters are used here to measure contamination of hydraulic oil, and therefore allow the user to maintain their hydraulic system, reduce breakdowns, schedule maintenance during no or slow work periods, monitor filter performance, etc. Particle counters used for this purpose typically use ISO Standard 4406:1999 as their reporting standard, and ISO 11171 as the calibration standard. Others also in use are NAS 1638 and its successor SAE AS4059D.\n\nDirect imaging is a technique that uses the light emitted by a laser as a source to illuminate a cell where particles are passing through. The technique does not measure the light blocked by the particles, but rather measures the area of the particles functioning like an automated microscope. A pulsed laser diode freezes the particle motion. The light transmitted through the fluid is imaged onto an electronic camera with macro focusing optics. The particles in the sample will block the light, and the resulting silhouettes will be imaged onto the digital camera chip.\n\nSmall particle counters that are used to monitor a fixed location typically inside a cleanroom or mini-environment to continuously monitor particle levels. These smaller counters typically do not have a local display and are connected to a network of other particle counters and other types of sensors to monitoring the overall cleanroom performance. This network of sensors is typically connected to a facility monitoring system (FMS), data acquisition system or programmable logic controller.\n\nThis computer based system can integrate into a database, alarming and may have e-mail capability to notify facility or process personnel when conditions inside the cleanroom have exceeded predetermined environmental limits. Remote particle counters are available in several different configurations, from single channel to models that detect up to 8 channels simultaneously. Remote particle counters can have a particle size detection range from 0.1 to 100 micrometres and may feature one of a variety of output options including 4-20 mA, RS-485 Modbus, Ethernet and pulse output.\n\nModified aerosol portable particle counter that has been attached to a sequencing sampling system. The sequencing sampling system allows for one particle counter to sample multiple locations, via a series of tubes drawing air from up to 32 locations inside a cleanroom. Typically less expensive then utilizing remote particle counters, each tube is monitored in sequence.\n\nA hand-held particle counter is a small, self-contained device that is easily transported and used, and designed for use with Indoor Air Quality (IAQ) investigations. Though lower flow rates of 0.1 ft³/min (0.2 m³/h) than larger portables with 1 ft³/m (2 m³/h), hand-helds are useful for most of the same applications. However longer sample times may be required when performing cleanroom certification and testing. (Hand-held counters are not recommended for cleanrooms). Most hand-held particle counters have direct mount isokinetic sampling probes. One may use a barbed probe on a short piece of sample tubing, but it is recommended that the length of the tubing not exceed , due to loss of larger particles in the sample tubing.\n\n\n"}
{"id": "19923620", "url": "https://en.wikipedia.org/wiki?curid=19923620", "title": "R.R. Donnelley and Sons Co. Calumet Plant", "text": "R.R. Donnelley and Sons Co. Calumet Plant\n\nThe R.R Donnelley Printing Plant, sometimes known as the Calumet Plant or the Lakeside Plant and now known as the Lakeside Technology Center, was built between 1912 and 1929 to house the operations of the RR Donnelley printing company. The building supported printing operations for the company and was the Donnelley headquarters until 1991 when they moved the headquarters to 77 West Wacker. In 1993, the plant was closed after the discontinuation by Sears, Roebuck and Co. of its mail-order catalog, which had been the last major account printed there. In 1999 the building was retrofitted and is currently owned by Digital Realty Trust operating as a carrier hotel or data center. The newly outfitted building was the first and largest planned carrier hotel in the United States.\n\nThe building was designed by Howard Van Doren Shaw to be a fireproof design of poured reinforced concrete columns and an open-shell concrete floor. Although considered to be expensive by the standards of that time, T.E. Donnelley agreed that the support would be needed for the many tons of paper they used and large presses they operated. Supported by 4,675 steel-reinforced concrete columns, this type of construction not only served the Donnelly well, it also provided the perfect infrastructure for future tenants. To further the building's support structure, reinforcing bars, normally laid perpendicular, were laid at various angles enabling the floors to bear loads of at least 250 pounds per square foot.\n\nCurrent major tenants of the building include the Chicago Mercantile Exchange, Telx, Equinix, Steadfast Networks and Qwest.\n\nExterior ornaments depict symbols of printing history. Portions of the building, including the interior Memorial Library, were designed by architect Charles Klauder.\n\n"}
{"id": "16017389", "url": "https://en.wikipedia.org/wiki?curid=16017389", "title": "Renewable energy industry", "text": "Renewable energy industry\n\nThe renewable-energy industry is the part of the energy industry focusing on new and appropriate renewable energy technologies. Investors worldwide have paid greater attention to this emerging industry in recent years. In many cases, this has translated into rapid renewable energy commercialization and considerable industry expansion. The wind power and solar photovoltaics (PV) industries provide good examples of this.\n\nRenewable energy industries expanded during most of 2008, and by August 2008, there were at least 160 publicly traded renewable energy companies with a market capitalization greater than $100 million. An estimated $120 billion was invested in renewable energy globally in 2008. \nDuring 2006/2007, several renewable energy companies went through high profile Initial Public Offerings (IPOs), resulting in market capitalization near or above $1 billion. These corporations included the solar PV companies First Solar (USA), Trina Solar (USA), Centrosolar (Germany), and Renesola (U.K.), wind power company Iberdrola (Spain), and U.S. biofuels producers VeraSun Energy, Aventine, and Pacific Ethanol.\n\nRenewable energy industries expanded during most of 2008, with large increases in manufacturing capacity, diversification of manufacturing locations, and shifts in leadership. By August 2008, there were at least 160 publicly traded renewable energy companies with a market capitalization greater than $100 million. The number of companies in this category has expanded from around 60 in 2005. \n\nSome $150 billion was invested in renewable energy globally in 2009, including new capacity (asset finance and projects) and biofuels refineries. This is more than double the 2006 investment figure of $63 billion. Almost all of the increase was due to greater investment in wind power, solar PV, and biofuels.\n\nIn 2000, venture capital (VC) investment in renewable energy was about 1% of total VC investment. In 2007 that figure was closer to 10%, with solar power alone making up about 3% of the entire Venture Capital asset class of ~$33B. More than 60 start-ups have been funded by\nVCs in the last three years. Venture capital and private equity investments in renewable energy companies increased by 167 percent in 2006, according to investment analysts at New Energy Finance Limited.\n\nNew investment into the sector jumped US$148 billion in 2007, up 60 per cent over 2006, noted a report by the Sustainable Energy Finance Initiative (SEFI). Wind energy attracted one-third of the new capital and solar one-fifth. But interest in solar is growing rapidly on the back of major technological advances which saw solar investment increase 254 per cent. The IEA predicts US$20 trillion will be invested into alternative energy projects over the next 22 years.\n\nIn December 2008, worldwide capacity of wind power was 122,000 MW, of which 28,190 MW was capacity added in 2008.\n\nVestas is the largest wind turbine manufacturer in the world with a 20% market share in 2008. The company operates plants in Denmark, Germany, India, Italy, Britain, Spain, Sweden, Norway, Australia and China, and employs more than 20,000 people globally. After a sales slump in 2005, Vestas recovered and was voted \"Top Green Company of 2006\".\n\nGE Energy was the world's second largest wind turbine manufacturer in 2008, with 19% market share. The company has installed over 5,500 wind turbines and 3,600 hydro turbines, and its installed capacity of renewable energy worldwide exceeds 160,000 MW. GE Energy bought out Enron Wind in 2002 and also has nuclear energy operations in its portfolio.\n\nGamesa, founded in 1976 with headquarters in Vitoria, Spain, was the world's third largest wind turbine manufacturer in 2008, and it is also a major builder of wind farms. Gamesa’s main markets are within Europe, the US and China.\n\nOther major wind power companies include Siemens, Suzlon, Sinovel and Goldwind.\n\nAlthough the wind power industry will be impacted by the global financial crisis in 2009 and 2010, a BTM Consult five year forecast up to 2013 projects substantial growth. Over the past five years the average growth in new installations has been 27.6 per cent each year. In the forecast to 2013 the expected average annual growth rate is 15.7 per cent. More than 200 GW of new wind power capacity could come on line before the end of 2013. Wind power market penetration is expected to reach 3.35 per cent by 2013 and 8 per cent by 2018.\n\nOffshore wind power installations are emerging, and recent years have seen several hundred megawatts added annually, mostly in Europe.\n\nFirst Solar became the world's largest solar cell maker in 2009, producing some 1,100 MW of product, with a 13% market share. Suntech was in second place with a production of 595 MW in 2009 and market share of 7%. Sharp Solar was far behind the leader with 580 MW of output. Q-Cells and its 540 MW output was fourth in 2009. Yingli Green Energy, JA Solar Holdings, SunPower, Kyocera, Motech Solar and Gintech rounded out the 2009 Top 10 ranking.\n\nPhotovoltaic production has been increasing by an average of some 20 percent each year since 2002, making it the world’s fastest-growing energy technology. At the end of 2009, the cumulative global PV installations surpassed 21,000 megawatts.\n\nAccording to the China Greentech Report 2009, jointly issued by the PricewaterhouseCoopers and American Chamber of Commerce in Shanghai and released on 10 Sept in Dalian, China, the estimated size of China's green technology market could be between US$500 billion and US$1 trillion annually, or as much as 15 percent of China's forecasted GDP, in 2013. With the positive drivers from the Chinese government’s policies to develop green technology solution, China has already played a more important role in green technology market development. Following the announcements of the Chinese government in 2009 about the new subsidy scheme of “Golden Sun” to support solar industry development in China, some of the worldwide industry players have announced their development plans in this region, such as the agreement signed by LDK Solar regarding a solar project in Jiangsu province with a total capacity of 500MW, manufacturing facilities of polysilicon ingots and wafers, PV cells and PV modules to be built by Yingli Green Energy in Hainan Province, and the new thin film manufacturing plants of Tianwei Baoding and Anwell Technologies.\n\nSince 2004 there has been renewed interest in concentrating solar power (CSP) and three plants were completed during 2006/2007: the 64 MW Nevada Solar One, a 1 MW trough plant in Arizona, and the 11 MW PS10 solar power tower in Spain. Three 50 MW trough plants were under construction in Spain at the end of 2007 with ten additional 50 MW plants planned. In the United States, utilities in California and Florida have announced plans (or contracted for) at least eight new projects totaling more than 2,000 MW. Companies involved in new projects include Abengoa Solar, Acciona, Ausra, BrightSource Energy, Iberdrola, Solar Euromed, Solar Millennium and Stirling Energy Systems.\n\nBrazil continued its ethanol expansion plans which began in the 70's and now has the largest ethanol distribution and the largest fleet of cars run by any mix of ethanol and gasoline.\n\nIn the ethanol fuel industry, the United States dominated, with 130 operating ethanol plants in 2007, and production capacity of 26 billion liters/year (6.87 billion gallons/year), a 60 percent increase over 2005. Another 84 plants were under construction or undergoing expansion, and this will result in a doubled production capacity.\nThe biodiesel industry opened many new production facilities during 2006/2007 and continued expansion plans in several countries. New biodiesel capacity appeared throughout Europe, including in\nBelgium, Czech Republic, France, Germany, Italy, Poland, Portugal, Spain, Sweden, and the United Kingdom.\n\nCommercial investment in second-generation biofuels began in 2006/2007, and much of this investment went beyond pilot-scale plants. The world’s first commercial wood-to-ethanol plant began operation in Japan in 2007, with a capacity of 1.4 million liters/year. The first wood-to-ethanol plant in the United States is planned for 2008 with an initial output of 75 million liters/year.\n\nRenewable energy use tends to be more labor-intensive than fossil fuels, and so a transition toward renewables promises employment gains. Globally, about 2.3 million people work either directly in renewables or indirectly in supplier industries. The wind power industry employs some 300,000 people, the PV sector accounts for an estimated 170,000 jobs, and the solar thermal industry accounts for about 624,000. More than 1 million jobs are located in the biomass and biofuels sector.\n\n\n"}
{"id": "738292", "url": "https://en.wikipedia.org/wiki?curid=738292", "title": "Robot Hall of Fame", "text": "Robot Hall of Fame\n\nThe Robot Hall of Fame is an American hall of fame that recognizes notable robots in various scientific fields and general society, as well as achievements in robotics technology. The organization was established in 2003 by the School of Computer Science at Carnegie Mellon University in Pittsburgh, Pennsylvania, as an acknowledgement of Pittsburgh's achievements in the field of robotics and with the aim of creating a broader awareness of the contributions of robotics in society. The idea for the Robot Hall of Fame was conceived by Carnegie Mellon School of Computer Science dean James H. Morris, who described it as a means of \"honor[ing] robots that have served an actual or potentially useful function and demonstrated real skill, along with robots that entertain and those that have achieved worldwide fame in the context of fiction.\" The first induction ceremony was held at the Carnegie Science Center on November 10, 2003. Thirty robots – both real and fictional – have been inducted into the Robot Hall of Fame since its inception. An exhibit named Roboworld was later established at the Carnegie Science Center in June 2009, featuring a physical embodiment of the hall of fame.\n\nFrom 2003 to 2010, inductees to the Robot Hall of Fame were chosen by a selected panel of jurists. The opportunity to nominate a robot for induction into the hall of fame was also made open to the public; nominators were required to submit a one-paragraph rationale explaining their selection. The voting process was altered significantly in 2012, with nominations instead being gathered from a survey of 107 authorities on robotics and divided into four categories: Education & Consumer, Entertainment, Industrial & Service, and Research. Through an online voting system, members of the public were allowed to vote for one nominee per category; only the top three nominees in each category, based on the results of the aforementioned robotics experts survey, are included on the ballot. Officials subsequently derived the final list of inductees from both the survey and the public vote. Robot Hall of Fame director Shirley Saldamarco said of the changes:\n\nNo robots have been inducted into the Robot Hall of Fame since 2012.\n\n\n"}
{"id": "34432138", "url": "https://en.wikipedia.org/wiki?curid=34432138", "title": "Romain du Roi", "text": "Romain du Roi\n\nThe (French for \"King's roman\") was a typeface developed in France beginning in 1692. The name refers to Louis XIV who commissioned the design of the new typeface for use by the Royal Print Office.\n\nThe ' stands as a landmark of typography in the Age of Enlightenment. The conception of the letterforms reflects a difference in attitude from the prevailing roman typefaces before it. Whereas previous roman typefaces developed naturally over time, evolving in the hands of punch cutters from the typefaces of the fifteenth century, the ' was the result of rational design: the letterforms were mapped on grids before being cut into metal. \n\nThe ' was not the first \"constructed alphabet\". Felice Feliciano was the first to recreate geometrically the alphabet of roman inscriptions, and published it in 1463 as Alphabetum Romanum Codex Vaticanus 6852. The ', however, because of its allegiance to the grid, shows a distinct shift in style, with an increased emphasis on verticality and increased contrast between thick and thin elements, a style that influenced the Transitional typefaces of Pierre Simon Fournier and John Baskerville.\n\nThe letterforms were the work of the Royal Academy's Bignon Commission as part of its investigation of French typography and printing for the compilation of the \"Description of the Arts and Trades\" of France. The capital letters were drawn on 8×8 grids, the lowercase letters on rectangular grids. The committee's designs were engraved by Louis Simonneau. Punches for the metal type were cut by Philippe Grandjean, who took some liberty with his type, to moderate the cold geometry of the designs. The type was first used for \"\".\n\n"}
{"id": "16710409", "url": "https://en.wikipedia.org/wiki?curid=16710409", "title": "Sandcrete", "text": "Sandcrete\n\nSandcrete is a yellow-white building material made from a binder (typically Portland cement), sand in a ratio of circa 1:8, and water. Sometimes other ingredients may be added to reduce the amount of expensive Portland cement such as pozzolanas and rice husk ash. Sandcrete is similar but weaker than mortar, for which the ratio is circa 1:5. \"Soil cement\" and \"landcrete\" are similar materials but use other types of soil and hydraform blocks which are compressed, stabilized, earth blocks.\n\nSandcrete is usually used as hollow rectangular blocks similar to concrete masonry units, often wide, thick, and with hollows that run from top to bottom and occupy around one third of the volume of the block. The blocks are joined together with mortar.\n\nThe final compressive strength of sandcrete can be as high as 4.6 N/mm, which is much less than concrete's 40 N/mm. Sandcrete is unsuitable for load-bearing columns, and is mainly used for walls, or for foundations if no suitable alternative is available. As material for walls, its strength is less than that of fired clay bricks, but sandcrete is considerably cheaper.\n\nSandcrete is the main building material for walls of single-storey buildings (such as houses and schools) in countries such as Ghana and Nigeria.\n\nResearch has shown using organic ash to replace Portland cement, which is better than simply using less Portland cement.\n\nAddition of coarse aggregates has been tried, since this is a cheap way to increase compressive strength, but since the cement content of sandcrete is small, so is the amount of water that is added to the sand/cement mix to cure it. Adding more solid materials makes the mix much less fluid, making it difficult to cast into blocks.\n"}
{"id": "31249615", "url": "https://en.wikipedia.org/wiki?curid=31249615", "title": "Sasha Bezuhanova", "text": "Sasha Bezuhanova\n\nSasha Bezuhanova () is an activist and philanthropist who contributes to Bulgaria's IT industry.\n\nShe is the founder and chairperson of MOVE.BG - civil platform for collaboration in finding sustainable solutions for the state, economy and society via innovation, participation and co-creation.\n\nSasha had a 20-year business career in HP. She was Director of Public Sector for the world Growth Markets at Hewlett-Packard. Previously she had managed the Central Eastern Europe Public sector business of the corporation. Before that Sasha was the General Manager of Hewlett-Packard Bulgaria for more than 10 years, positioning the company as the leader in the local ICT market and driving important investment in the country where HP employs today more than 5000 people.\n\nHer long list of business achievements and social development engagements throughout the years involve positioning Bulgaria as an ICT center of global significance, boosting the entrepreneurial culture and women empowerment in her home country Bulgaria and at European level.\n\nSasha is Chair of the Boards of European Center of Women in Technologies, Bulgarian Center of Women in Technologies, Technical University in Sofia, co-founder and board member of the Initiative for Social Empowerment. She is the initiator of EDIT.BG – open network initiative for digital innovation.\n\nSasha Bezuhanova was named Digital woman of Europe for 2013 and one of the Top 100 Challengers in New Europe 100 for 2015 and holds many other national and European awards for her contribution to social development.\n\nShe founded her own annual Entrepregirl Award for supporting young women to develop their entrepreneurial ideas into business.\n\nSasha is married with one daughter.\n\nSasha Bezuhanova was born in Pernik, Bulgaria. She graduated German language high school in Sofia. Bezuhanova went on to study in Technical University in Sofia graduating with Masters in Electronics (1985). She holds also Executive master's degree in International Negotiations and Policy Making from the Graduate Institute in Geneva (2015) and has Executive qualifications from INSEAD and Stanford.\n\nShe attended special programs for studying the Irish economic model (Dublin, 2001), the structure of ICT sector in California (Palo Alto, 2002) and European Software Institute (Bilbao, 2003).\n\nAside from her native language Sasha Bezuhanova speaks English, German and Russian.\n\nThe professional career of Sasha Bezuhanova started in 1985 in the Central Institute for Computer Technologies where in 1986 she became Research Associate.\n\nShortly after the democratic changes in Bulgaria when the country opened up for direct presence of international businesses she was invited by the German medical concern HELLIGE to head their Bulgarian operation. Under her leadership in the period 1990 to 1994 the company played key role in the modernization of the Bulgarian health infrastructure.\n\nHer international business and operational management experience evolved further as General Manager for S&T Bulgaria, the exclusive distributor of HP – a role she took over in 1995.\n\nWhen HP decided to open up direct operation in Bulgaria in 1997 Bezuhanova was appointed as General Manager. Sasha Bezuhanova has managed Hewlett-Packard's business in Bulgaria for more than 10 years. In that period of time HP's Bulgarian team developed a series of IT infrastructure projects for the country's three biggest telecommunication companies, industrial manufacturers, and state and private finance institutions. Some of these projects have been implemented for the first time in Bulgaria and became reference solutions incorporated in the HP's portfolio. Among them was the implementation of electronic ID for Bulgarian citizens, which ended in August 1999 and was the key to Bulgaria's acceptance in the EU visa-free countries list in 2001. Another flagship project, that enriched the HP's worldwide practice, was the implementation of the Real-time gross settlement system (RTGS) in Macedonia.\n\nHer most important accomplishment at the time was attracting an important investment of HP in Bulgaria where in 2006 started operation HP Global Delivery Centre. Today it employs more than 5000 high-profile engineers and specialists. That strategic project placed the country on the world IT investment map. As a result, Hewlett-Packard has become the largest IT employer in Bulgaria and the Top 5 in the country overall. Hewlett-Packard became also the largest investor and employer in the Bulgarian IT sector.\n\nSasha Bezuhanova continued her career in HP on international level being appointed in 2008 as Public Sector Director for Central Eastern Europe. She manages the corporation’ government business in 27 countries including Russia, New Europe, Western Balkans and Central Asia bringing in an important strategic dimension and a holistic approach to this market segment.\n\nIn 2012 Bezuhanova was appointed as Director Public Sector and Education for HP Growth Markets – a region including 67 countries around the world. As part of her business development responsibilities she coordinated the company's relations with the EU, WB and UN.\n\nIn 2013 when it became very critical in Bulgaria and the country was shaken by protests against the oligarchic establishment figures, Sasha Bezuhanova decided to leave her career and to devote herself to the cause of positive change in Bulgaria. She founded the non-partisan organization MOVE.BG – a platform for collaboration in finding sustainable solutions for the state, economy and society via innovation, participation and co-creation. MOVE.BG is affirming the culture of constructive dialog, participating leadership, democratic principles and European path of Bulgaria. Some of the programs are ‘Electoral reform’, ‘Media pluralism’, ‘Law and order in 5 steps’, \"You move Europe’, ‘Solutions for Bulgaria: Digital’, ‘Solution for Bulgaria: Economics’ and the online platform ‘My Bulgarian History‘. In 2016 upon initiative of Sasha Bezuhanova MOVE.BG together with key organizations, hubs and companies developing digital knowledge and innovative business in Bulgaria, founded EDIT.bg (Economic Development via Innovation and Technologies) – open network for digital development and innovation in Bulgaria. .\n\nAlongside with MOVE.BG over the years Sasha Bezuhanova is actively engaged in the economic and social development of Bulgaria. She is part of many organizations and initiatives which work for positioning Bulgaria as ICT center of global significance, for boosting the entrepreneurial culture and women empowerment in her home country Bulgaria and at European level.\n\nAs a President of Bulgarian International Business Association (BIBA) (2002-2006) she initiates in 2003 the development of the National ICT Competitiveness Strategy - a program that became a basis for series of initiative in the ICT sector in Bulgaria. She works actively for attracting foreign investments in the sector as also on policy recommendation level in her capacity of chairperson of the Bulgarian ICT Cluster (2005 – 2006), founding Chairperson and a member of Consultancy Committee of the Confederation of Industrialists and Employers in Bulgaria (CEIBG) (2007 - 2010) and member of consultative body to Ministry of Economy for 3S strategy of Bulgaria (2011–2013).\n\nAs a chairperson of the board of Junior Achievement Bulgaria (1999 – 2014) Sasha Bezuhanova worked for developing entrepreneurial and leadership skills among young people. She contributes actively to another cause - the increase of women's leadership and professional participation in the ICT sector and science. She is a co-founder and chairperson of the Advisory Council of the European Centre of Women in Technology (ECWT) (2008 – at present). In 2012 upon her initiative was founded the Bulgarian Centre of Women in Technology (BCWT) for fulfilling this mission in Bulgaria. In 2013 she founded her own yearly Entrepregirl Award for supporting young women to develop their entrepreneurial ideas into business.\n\nShe is also a co-founder and board member of the Initiative for Social Empowerment – organization that aims to enable vulnerable groups of women and youth in Europe.\n\n\nFor her achievements and contribution to the public development Sasha Bezuhanova has won many prestigious awards and honours:\n\n\nSasha Bezuhanova is the Honorary Consul of Grand Duchy of Luxembourg for Bulgaria.\n\n"}
{"id": "56203731", "url": "https://en.wikipedia.org/wiki?curid=56203731", "title": "Style Louis XIV", "text": "Style Louis XIV\n\nThe Style Louis XIV, also called French classicism, was the style of architecture and decorative arts intended to glorify King Louis XIV and his reign. It featured majesty, harmony and regularity. It became the official style during the reign of Louis XIV (1643–1715), imposed upon artists by the newly established \"Académie royale de peinture et de sculpture\" (Royal Academy of Painting and Sculpture) and the \"Académie royale d'architecture\" (Royal Academy of Architecture). It had an important influence upon the architecture of other European monarchs, from Frederick the Great of Prussia to Peter the Great of Russia. Major architects of the period included François Mansart, Jules Hardouin Mansart, Robert de Cotte, Pierre Le Muet, Charles Perrault, and Louis Le Vau. Major monuments included the Palace of Versailles, the Grand Trianon at Versailles, and the Church of Les Invalides (1675–91).\n\nThe Louis XIV style had three periods. During the first period, which coincided with the youth of the King (1643-1660) and the regency of Anne of Austria, architecture and art were strongly influenced by the earlier style of Louis XIII and by the Baroque style imported from Italy. The early period saw the beginning of French classicism, particularly in the early works of Francois Mansart, such as the Chateau de Maisons (1630–51). During the second period (1660-1690), under the personal rule of the King, the style of architecture and decoration became more classical, triumphant and ostentatious, expressed in the building of the Chateau of Versailles, first by Louis Le Vau and then Jules Hardouin-Mansart. Until 1680, furniture was massive, decorated with a profusion of sculpture and gilding. In the later period, thanks to the development of the craft of marquetry, the furniture was decorated with different colors and different woods. The most prominent creator of furniture in the later period was André Charles Boulle. The final period of Louis XIV style, from about 1690 to 1715, is called the period of transition; it was influenced by Hardouin-Mansart and by the King's designer of fetes and ceremonies, Jean Bérain the Elder. The new style was lighter in form, and featured greater fantasy and freedom of line, thanks in part to the use of wrought iron decoration, and greater use of arabesque, grotesque and coquille designs, which continued into the style of Louis XV.\n\nThe model of civic architecture in the early part of the reign was Vaux le Vicomte (1658), by Louis Le Vau, built for the King's chief of finance Nicolas Fouquet and completed in 1658. Louis XIV charged Fouquet with theft, put him prison, and took the building for himself. The design was strongly influenced by the classicism of François Mansart. It combined a facade dominated and rhymed by colossal classical columns, beneath a dome, imported from the Italian Baroque architecture, along with a number of original features, such as a semicircular salon which looked out on the vast French formal garden created by André Le Nôtre.\n\nBased on the success of Vaux le Vicomte, Louis XIV selected Le Vau to construct an immense new palace at Versailles, to augment a smaller palace transformed from a hunting lodge by Louis XIII. This gradually became, over the decades, the master work of the Louis XIV style. Following the death of Le Vau in 1680, Jules Hardouin-Mansart took over the Versailles project; he broke away from the picturesque projections and dome and made a more sober and uniform facade of columns, with a flat roof topped by a balustrade and row of columns (1681). He used the same style to harmonize the other new buildings he created at Versailles, including the Orangerie and the Stables. Hardouin-Mansart constructed the Grand Trianon (completed 1687), single-story royal retreat with arched windows alternating with pairs of columns, and a flat roof and balustrade.\n\nAnother major new project undertaken by Louis was the construction of a new facade for the east side of the Louvre. Louis invited the most famous sculptor architect of the Italian Baroque, Gian Lorenzo Bernini, to submit a design, but rejected it in favor of a more sober and classical colonnade by Perrault (1668).\n\nIn the early period of his reign, Louis began building the church of Val-de-Grâce (1645-1710), the chapel of the Val-de-Grace hospital. The design was worked on successively by Mansart, Jacques Lemercier and Pierre Le Muet before being completed by Gabriel Leduc. Its picturesque tripartite facade, peristyle, detached columns, statues, and \"tondi\", make it the most Italianate and Baroque of Paris churches. It served as the prototype for the later domes of Les Invalides and the Pantheon.\n\nThe next major church built under Louis XIV was the church of Les Invalides (1680-1706). The nave of the church, by Libéral Bruant, was comparable to those of other churches of the period, with ionic pilasters and penetratining vaults, and an interior that resembled the high baroque style. The dome, by Hardouin-Mansart, was more revolutionary, sitting upon a structure with the plan of a Greek Cross. The design used superimposed orders of columns, in the classical style, but the dome achieved greater height, by resting on a double \"tambour\"or drum, and the facade and dome itself were richly decorated with sculptures, \"entablements\" in niches, and ornaments of gilded bronze alternating with the \"nervures\", or ribs of the dome.\n\nThe finest church interior of the late Louis XIV period is the chapel of the Chateau of Versailles, created between 1697 and 1710 by Hardouin-Mansart and his successor as court architect, Robert de Cotte. The decor was carefully restrained, with light colors and sculptural detail in slight relief on the columns. The interior of the chapel opened up and lightened by the use of classical columns placed on the tribune, one level above the ground floor, to support the weight of the vaulted ceiling.\nThough Louis XIV was later accused of having ignored Paris, his reign saw several massive architectural projects which opened up space and ornamented the center of the city. The idea of monumental urban squares surrounded by uniform architecture had begun in Italy, like many architectural ideas of Baroque period. The first such square in Paris was the Place Royal (now Place des Vosges) begun by Henry IV of France, completed with an equestrian statue of Louis XIII; then the Place Dauphine on the Ile de la Cité, which featured an equestrian statue of Henry IV. The initial grand Paris projects of Louis XIV were new facades on the Louvre, one facing the Seine, the other facing to the east. These were showcases of the new monumental style of Louis XIV. The old brick and stone of the Henry IV squares was replaced by the Grand Style of monumental columns, which usually were part of the facade itself, rather than standing separately. All the buildings around the square were connected and built to the same height, in the same style. The ground floor featured a covered arcade for pedestrians.\n\nThe first such complex of buildings built under Louis XIV was the Collège des Quatre-Nations (now the Institut de France) (1662–68), facing the Louvre. It was designed by Louis Le Vau and François d'Orbay, and combined the headquarters of the academies founded by the King, a chapel, and the library of Cardinal Mazarin. The Hôtel Royal des Invalides - a complex for war veterans consisting of residences, a hospital, and a chapel - was constructed by Libéral Bruant and Jules Hardouin-Mansart (1671-1679). Louis XIV then commissioned Mansart to construct a separate private royal chapel featuring a striking dome, the Église du Dôme, which was added to complete the complex in 1708.\n\nThe next major project was the Place des Victoires (1684-1697), a real estate development of seven large buildings in three segments around an oval square, with an equestrian statue of Louis XIV planned for the centerpiece. This was built by an enterprising entrepreneur and nobleman of the court, Jean-Baptiste Prédot, combined with the architect Jules Haroudin-Mansart. The final urban project became the best-known, the Place Vendôme, also by Harouin-Mansart, between 1699 and 1702. In another innovation, this project was partially financed by the sale of lots around the square. All of these projects featured monumental facades in the Louis XIV style, giving a particular harmony to the squares.\nIn the early Louis XIV style, the principle characteristics of decor were a richness of materials and an effort to achieve a monumental effect. The materials used included marble, often combined with multicolor stones, bronze, paintings, and mirrors. These were inserted into an extremely framework of columns, pilasters, niches, which extended up the walls and up upon the ceiling. The doors were surrounded with medallions, frontons and bas-reliefs. The chimneys were smaller than those during the Louis XIII era, but more ornate, with a marble shelf supporting vases, below a carved frame with a painting or mirrors, all surrounded by a thick border of carved leaves or flowers. \n\nDecrative elements on the walls of the early Louis XIV style were usually intended to celebrate the military success, majesty and cultural achievements of the King. They often featured military trophies, with helmets, oak leaves symbolizing victory, and masses of weapons, usually made of glided bronze or sculpted wood, in relief surrounded by marble. Other decorative elements celebrated the King personally: the head of the King was often represented as the sun god Apollo, surrounded by palm leaves or gilded rays of light. An eagle usually represented Jupiter. Other ornamental details included gilded numbers, royal batons, and crowns.\n\nThe Hall of Mirrors of the Palace of Versailles (1678-1684) was the summit of the early Louis XIV style. Designed by Charles Le Brun, it combined a richness of materials (marble, gold, and bronze) which reflected in the mirrors.\n\nIn the late Louis XIV period, after 1690, new elements began to appear, that were less militaristic and more fantastic; particularly seashells, surrounded by elaborate sinuous lines and curves; and exotic designs, including arabesques and Chinoiserie.\n\nDuring the first period of the reign of Louis XIV, furniture followed the previous style of Louis XIII, and was massive, and profusely decorated with sculpture and gilding. After 1680, thanks in large part to the furniture designer André Charles Boulle, a more original and delicate style appeared. It was based on the inlay of ebony and other rare woods, a technique first used in Florence in the 15th century, which was refined and developed by Boulle and others working for Louis XIV. Furniture was inlaid with plaques of ebony, copper, and exotic woods of different colors.\n\nNew and often enduring types of furniture appeared; the commode, with two to four drawers, replaced the old \"coffre\", or chest. The \"canapé\", or sofa, appeared, in the form of a combination of two or three armchairs. New kinds of armchairs appeared, including the \"fauteuil en confessionale\" or \"Confessional armchair\", which had padded cushions ions on either side of the back of the chair. The console table also made its first appearance; it was designed to be placed against a wall. Another new type of furniture was the \"table à gibier\", a marble-topped table for holding dishes. Early varieties of the desk appeared; the Mazarin desk had a central section set back, placed between two columns of drawers, with four feet on each column.\n\nIn the first part of the reign, French painters were largely influenced by the Italians, particularly Caravaggio. Notable French painters included Nicolas Poussin, who was living in Rome; Claude Lorrain, who specialized in landscapes and spent most of his career in Rome; Louis Le Nain, who, along with his brothers, did mostly genre works; Eustache Le Sueur, and Charles Le Brun, who studied with Poussin in Rome and were influenced by him. \n\nWith the death in 1661 of Cardinal Mazarin, the King's prime minister, Louis decided to take personal charge of all aspects of government, including the arts. His chief advisor on the arts was Jean Colbert (1619-1683), who was also his finance minister. In 1663 Colbert reorganized the Royal furniture workshops, which made a wide variety of luxury goods, and added to it the Gobelins tapestry workshops. At the same time, with the assistance of Le Brun, Colbert took charge of the Royal Academy of Painting and Sculpture, which had been founded by Cardinal Mazarin. Colbert also took a dominant role in architecture, taking the title of Superintendent of buildings in 1664. In 1666, the French Academy in Rome was founded, to take advantage of Rome's position as the leading art center of Europe, and to assure a stream of well-trained painters. Le Brun became the dean of French painters under Louis XIV, involved in architectural projects and interior design. His notable decorative works included the ceiling of the Hall of Mirrors in the Palace of Versailles.\n\nThe major painters of the later reign of Louis XIV included Hyacinthe Rigaud (1659-1743) who came to Paris in 1681, and attracted the attention of LeBrun. LeBrun oriented him toward portrait painting, and he made a celebrated portrait of Louis XIV in 1701, surrounded by all the attributes of power, from the crown on the table to the red heels of his shoes. Rigaud soon had an elaborate workshop in place for making portraits of the nobility; he employed specialized artists to create the costumes and draperies, and others to paint the backgrounds, ranging from battlefields to gardens to salons, while he concentrated on the composition, colors and especially the faces.\n\nGeorge de la Tour (1593-1652) was another important figure in the Louis XIV style; he was given a title, named court painter of the King, and received high payments for his portraits, though he rarely ever came to Paris, preferring to work in his home town of Lunéville. His paintings, with their unusual light and dark effecs, were unusually somber, the figures barely seen in the darkness, lit by torchlight, evoking meditation and pity. In addition to religious scenes, he did genre paintings, including the famous \"Tricheur\" or card cheat, showing a young noble being cheated at cards while others look on passively. The writer and later French culture minister Andre Malraux wrote in 1951, \"No other painter, not even Rembrandt, ever suggested such a vast and mysterious silence. La Tour is the only interpreter of the serene aspect of shadows.\"\n\nIn his final years, Louis XIV's tastes changed again, under the influence of his morganic wife, Madame de Maintenon, toward more religious and meditative themes. He had all the paintings in his private room removed and replaced by a single canvas, \"Saint Sebastien being tended by Saint Irene\" (c. 1649) by Georges de la Tour.\nThe most influential sculptor of the period was the Italian Gian Lorenzo Bernini, whose work in Rome inspired sculptors all over Europe. He traveled to France; his proposal for a new facade of the Louvre was rejected by the King, who wanted a more specifically French style, but the Bernini did make a bust of Louis XIV in 1665 which was greatly admired and imitated in France.\n\nOne of the most prominent sculptors under Louis XIV was Antoine Coysevox (pronounced \"qualzevo\") (1640-1720) from Lyon. He studied sculpture under Louis Lerambert and copied in marble ancient Roman works, including the Venus de Medici. In 1776, his bust of the King's official painter Charles Le Brun won him admission to the Royal Academy of Painting and Sculpture. He was soon producing monumental sculpture to accompany the new buildings constructed by Louis XIV; he made a Charlemagne for the royal chapel at Les Invalides, and then a large number of statues for the new Park at Versailles and then at the Chateau de Marly. He originally made the outdoor statues in weather-resistant stucco, then replaced them with marble works when they were finished in 1705. His work of Neptune from Marly is now in the Louvre, and his statues of Pan and a Flora and Dryad are now found in the Tuileries Gardens. His statue of \"The King's Fame riding Pegasus\" was originally made for the Chateau of Marly. After the Revolution it was moved to the Tuileries Gardens, and is now inside the Louvre. He also made a series of greatly admired portrait sculptures of the leading statesmen and artists of the time; Louis XIV at Versailles, Colbert (for his tomb at the Church of Saint Eustache; Cardinal Mazarin in the Collège des Quatre-Nations (now the Institut de France) in Paris; the playwright Jean Racine; the architect Vauban and the garden designer Andre Le Notre.\n\nJacques Sarazin was another notable sculptor working on projects for Louis XIV. He made many statues and decorations for the Palace of Versailles, as well as the Caryatids for the eastern facade of the Pavilion du Horloge of the Louvre, facing the Cour Carré, which were based both on a study of the original Greek models, and on the work of Michelangelo.\n\nAnother notable sculptor of the Style Louis XV was Pierre Paul Puget (1620-1694), who was a sculptor, painter, engineer and architect. He was born in Marseille, and first sculpted ornaments for ships under construction. He then travelled to Italy, where he worked as an apprentice on the Baroque ceilings of the Palazzo Barberini and Palazzo Pitti. He travelled back and forth between Italy and France, painting, sculpting and wood-carving. He made his celebrated statue of caryatids for the city hall of Toulon in 1665-67, then was employed by Nicolas Fouquet to make a statue of Hercules for his chateau at Vaux-le-Vicomte. He continued to live in th south of France, making notable statues of Milo of Croton, Perseus and Andromeda (now in the Louvre).\n\nIn 1662 Jean Baptiste Colbert purchased the tapestry workshop of a family of Flemish artisans and transformed it into a royal workshop for the manufacture of furniture and tapestries, under the name of Gobelins tapestry. Colbert placed the workshop under the direction of the royal court painter, Charles Le Brun, who served in that position from 1663 until 1690. The workshop worked closely with the major painters of the court, who produced the designs. After 1697 the enterprise was reorganized, and thereafter was devoted entirely to the production of tapestries for the King.\n\nThe themes and styles of the tapestry were largely similar to the themes in the paintings of the period, celebrating the majesty of the King and triumphal scenes of military victories, mythological and pastoral scenes. While at first they were made only for use of the King and nobility, the factory soon began exporting its products to the other courts of Europe.\n\nThe royal Gobelins manufactory had competition from two private enterprises, the Beauvais Manufactory and the Aubusson tapestry workshop, which produced works in the same style but with a low-warp process, with slightly lesser quality. Jean Bérain the Elder, the royal draftsman and designer of the King, created a series of grotesque carpets for Aubusson. These tapestries sometimes celebrated contemporary themes, such as a work designed by Aubusson An late 17th to early 18th century tapestry done by the Beauvais Manufactory depicting Chinese astronomers at the Beijing Ancient Observatory using new more accurate instruments brought to them by Europeans (Jesuits) which were installed in 1644.\n\nIn the early years of the King's reign, the most important public royal ceremony was the \"carrousel\", a series of exercises and games on horseback. These events were designed to replace the tournament, which had been banned after 1559 when King Henry II was killed in a jousting accident. In the new, less dangerous version, riders usually had to pass their lance through the interior of a ring, or strike mannequins with the heads of Medusa, Moors and Turks. A grand \"carrousel\" was held on June 5–6, 1662 to celebrate the birth of the \"Dauphin\", the son of Louis XIV. It was held on the square separating the Louvre from the Tuileries Palace, which afterwards became known as the Place du Carrousel.\n\nThe ceremonial entry of the King into Paris also became an occasion for festivities. The return of Louis XIV and Queen Marie-Thérèse to Paris after his coronation in 1660 was celebrated by a grand event on a fairground at the gates of the city, where large thrones were constructed for the new monarchs. After the ceremony the site became known as the Place du Trône, or place of the Throne, until it became the Place de la Nation in 1880.\n\nAn office existed in the royal household of Louis XIV called Menus-Plaisirs du Roi, which was responsible the decoration at royal ceremonies and spectacles, including ballets, masques, illuminations, fireworks, theater performances and other entertainments. This office was held from 1674 to 1711 by Jean Bérain the Elder (1640-1711). He was also designer of the King's bedchamber and offices, and had an enormous influence upon what became known as the Style Louis XIV; his studio was located in the Grand Gallery of the Louvre, along with those of the royal furniture designer André Charles Boulle. He was particularly responsible for introducing the a modified version of the grotesque style of ornament, originally created in Italy by Raphael, into French interior design. He used the grotesque stele not only on wall panels, but also on tapestries made by the Aubusson tapestry workshops. His many varied other designs included the highly-ornate design of transom of the warship \"Soleil Royal\" (1670), named for the King.\n\nIn addition to interior decoration, he designed the costumes and scenery for the royal theaters, including for the opera \"Amadis\" by Jean-Baptiste Lully performed at the Theater of the Palais Royal (1684), and for the opera-ballet \"Les Saisons\" by Lully's successor, Pascal Colasse, in 1695.\n\nOne of the most enduring and popular forms of the Style Louis XIV is The \"Jardin à la française\" or French formal garden, a style based on symmetry and the principle of imposing order on nature. The most famous example is the Gardens of Versailles designed by André Le Nôtre, which inspired copies all across Europe. The first important garden à la française was the Chateau of Vaux-le-Vicomte, created by Nicolas Fouquet, the superintendent of Finances to Louis XIV, beginning in 1656. Fouquet commissioned Louis Le Vau to design the chateau, Charles Le Brun to design statues for the garden, and André Le Nôtre to create the gardens. For the first time, that garden and the chateau were perfectly integrated. A grand perspective of 1500 meters extended from the foot of the chateau to the statue of the Hercules of Farnese; and the space was filled with parterres of evergreen shrubs in ornamental patterns, bordered by colored sand, and the alleys were decorated at regular intervals by statues, basins, fountains, and carefully sculpted topiaries. \"The symmetry attained at Vaux achieved a degee of perfection and unity rarely equalled in the art of classic gardens. The chateau is at the center of this strict spatial organization which symbolizes power and success.\"\n\nThe Gardens of Versailles, created by André Le Nôtre between 1662 and 1700, were the greatest achievement of the Garden à la francaise. They were the largest gardens in Europe – with an area of 15,000 hectares, and were laid out on an east–west axis followed the course of the sun: the sun rose over the Court of Honor, lit the Marble Court, crossed the Chateau and lit the bedroom of the King, and set at the end of the Grand Canal, reflected in the mirrors of the Hall of Mirrors. In contrast with the grand perspectives, reaching to the horizon, the garden was full of surprises – fountains, small gardens filled with statuary, which provided a more human scale and intimate spaces. The central symbol of the Garden was the sun; the emblem of Louis XIV, illustrated by the statue of Apollo in the central fountain of the garden. \"The views and perspectives, to and from the palace, continued to infinity. The king ruled over nature, recreating in the garden not only his domination of his territories, but over the court and his subjects.\"\n"}
{"id": "2220846", "url": "https://en.wikipedia.org/wiki?curid=2220846", "title": "Teleogenesis", "text": "Teleogenesis\n\nIn the theory of cybernetics, teleogenesis (from the Greek \"teleos\" = 'purpose' and \"genesis\" = 'creation') is the creation of goal-creating processes.\n\nAccording to Peter Corning:\n\"A cybernetic system is by definition a dynamic purposive system; it is 'designed' to pursue or maintain one or more goals or end-states\".\n\nTeleogenesis refers from an extension of classical cybernetics, as proposed by Norbert Wiener, Ashby and others in late 1950s.\n\n\n"}
{"id": "49321811", "url": "https://en.wikipedia.org/wiki?curid=49321811", "title": "UAV-related events", "text": "UAV-related events\n\nUnmanned aerial vehicles (UAVs) or drones have frequently been involved in military operations. Non-military UAVs have often been reported as causing hazards to aircraft, or to people or property on the ground. Safety concerns have been raised due to the potential for an ingested drone to rapidly disable an aircraft engine, and several near-misses and verified collisions have involved hobbyist drone operators flying in violation of aviation safety regulations.\n\n\n\n\n\n\n\n\n\n\nIn January 2017 a 23 year old UAV operator from Xiaoshan was detained because of footage taken from a drone flying near airliners descending to land at Hangzhou Xiaoshan International Airport. The incident came to light when footage was uploaded to QQ. This was an eight-second clip from a ten-minute recording taken from an altitude of 450m. The operator had flown it to photograph a sunset, but had also recorded several airliners flying past. The model used was a DJI Mavic and the manufacturer strongly condemned the incident.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUAVs have historically had a much higher loss rate than manned military aircraft. In addition to anti-aircraft weapons, UAVs are vulnerable to power and communications link losses.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3020263", "url": "https://en.wikipedia.org/wiki?curid=3020263", "title": "Ultrasonic cleaning", "text": "Ultrasonic cleaning\n\nUltrasonic cleaning is a process that uses ultrasound (usually from 20–400 kHz) to agitate a fluid. The ultrasound can be used with just water, but use of a solvent appropriate for the item to be cleaned and the type of soiling present enhances the effect. Cleaning normally lasts between three and six minutes, but can also exceed 20 minutes, depending on the object to be cleaned.\n\nUltrasonic cleaners are used to clean many different types of objects, including jewelry, lenses and other optical parts, watches, dental and surgical instruments, tools, coins, fountain pens, golf clubs, fishing reels, window blinds, firearms, car fuel injectors, musical instruments, gramophone records, industrial parts and electronic equipment. They are used in many jewelry workshops, watchmakers' establishments, and electronic repair workshops.\n\nThe surface mechanisms of ultrasonic cleaning are well understood, with many works dedicated to this science since the first commercial ultrasonic cleaning equipment appeared in the 1950s, and came into use as relatively inexpensive home appliances in about 1970. Ultrasonic cleaning has been used industrially for decades, particularly to clean small intricate parts, and to accelerate surface treatment processes.\n\nUltrasonic cleaning uses cavitation bubbles induced by high frequency pressure (sound) waves to agitate a liquid. The agitation produces high forces on contaminants adhering to substrates like metals, plastics, glass, rubber, and ceramics. This action also penetrates blind holes, cracks, and recesses. The intention is to thoroughly remove all traces of contamination tightly adhering or embedded onto solid surfaces. Water or solvents can be used, depending on the type of contamination and the workpiece. Contaminants can include dust, dirt, oil, pigments, rust, grease, algae, fungus, bacteria, lime scale, polishing compounds, flux agents, fingerprints, soot wax and mold release agents, biological soil like blood, and so on. Ultrasonic cleaning can be used for a wide range of workpiece shapes, sizes and materials, and may not require the part to be disassembled prior to cleaning.\n\nObjects must not be allowed to rest on the bottom of the device during the cleaning process, because that will prevent cavitation from taking place on the part of the object not in contact with solvent.\n\nIn an ultrasonic cleaner, the object to be cleaned is placed in a chamber containing a suitable solution (in an aqueous or organic solvent, depending on the application). In aqueous cleaners, surfactants (e.g., laundry detergent) are often added to permit dissolution of non-polar compounds such as oils and greases. An ultrasound generating transducer built into the chamber, or lowered into the fluid, produces ultrasonic waves in the fluid by changing size in concert with an electrical signal oscillating at ultrasonic frequency. This creates compression waves in the liquid of the tank which 'tear' the liquid apart, leaving behind many millions of microscopic 'voids'/'partial vacuum bubbles' (cavitation). These bubbles collapse with enormous energy; temperatures and pressures on the order of 5,000 K and 135 MPa are achieved; however, they are so small that they do no more than clean and remove surface dirt and contaminants. The higher the frequency, the smaller the nodes between the cavitation points, which allows for cleaning of more intricate detail.\n\nTransducers are usually piezoelectric (e.g. made with lead zirconate titanate (PZT), barium titanate, etc.), but are sometimes magnetostrictive. The often harsh chemicals used as cleaners in many industries are not needed, or used in much lower concentrations, with ultrasonic agitation. Ultrasonics are used for industrial cleaning, and also used in many medical and dental techniques and industrial processes.\n\nUltrasonic activity (cavitation) helps the solution to do its job; plain water would not normally be effective. The cleaning solution contains ingredients designed to make ultrasonic cleaning more effective. For example, reduction of surface tension increases cavitation levels, so the solution contains a good wetting agent (surfactant). Aqueous cleaning solutions contain detergents, wetting agents and other components, and have a large influence on the cleaning process. Correct composition of the solution is very dependent upon the item cleaned. Solutions are mostly used warm, at about , however, in medical applications it is generally accepted that cleaning should be at temperatures below to prevent protein coagulation.\n\nWater-based solutions are more limited in their ability to remove contaminants by chemical action alone than solvent solutions; e.g. for delicate parts covered with thick grease. The effort required to design an effective aqueous-cleaning system for a particular purpose is much greater than for a solvent system.\n\nSome machines (which are not unduly large) are integrated with vapour degreasing machines using hydrocarbon cleaning fluids: Three tanks are used in a cascade. The lower tank containing dirty fluid is heated causing the fluid to evaporate. At the top of the machine there is a refrigeration coil. Fluid condenses on the coil and falls into the upper tank. The upper tank eventually overflows and clean fluid runs into the work tank where the cleaning takes place. Purchase price is higher than simpler machines, but such machines are economical in the long run. The same fluid can be reused many times, minimising wastage and pollution.\n\nMost hard, non-absorbent materials (metals, plastics, etc.) not chemically attacked by the cleaning fluid are suitable for ultrasonic cleaning. Ideal materials for ultrasonic cleaning include small electronic parts, cables, rods, wires and detailed items, as well as objects made of glass, plastic, aluminium or ceramic.\n\nUltrasonic cleaning does not sterilize the objects being cleaned, because spores and viruses will remain on the objects after cleaning. In medical applications, sterilization normally follows ultrasonic cleaning as a separate step.\n\nIndustrial ultrasonic cleaners are used in the automotive, sporting, printing, marine, medical, pharmaceutical, electroplating, disk drive components, engineering and weapons industries.\n\nUltrasonic cleaning is used to remove contamination from industrial process equipment such as pipes and heat exchangers.\n\nUltrasonic cleaning is used widely to remove flux residue from soldered circuit boards. However, some electronic components, notably MEMS devices such as gyroscopes, accelerometers and microphones can become damaged or destroyed by the high intensity vibrations they are subjected to during cleaning. Piezoelectric buzzers can work in reverse and produce voltage, which may pose a danger to their drive circuits.\n\nIt is recommended to avoid using flammable cleaning solutions because ultrasonic cleaners increase temperature even when not equipped with a heater. When the unit is running, inserting your hand into the solution could cause burning due to the temperature; discomfort and skin irritation can also occur.\n\n"}
{"id": "5791251", "url": "https://en.wikipedia.org/wiki?curid=5791251", "title": "VORTAC", "text": "VORTAC\n\nA VORTAC is a radio-based navigational aid for aircraft pilots consisting of a co-located VHF omnidirectional range (VOR) beacon and a tactical air navigation system (TACAN) beacon. Both types of beacons provide pilots azimuth information, but the VOR system is generally used by civil aircraft and the TACAN system by military aircraft. However, the TACAN distance measuring equipment is also used for civil purposes because civil DME equipment is built to match the military DME specifications. Most VOR installations in the United States are VORTACs. The system was designed and developed by the Cardion Corporation. (The RDT&E contract was awarded 28 December 1981.)\n\n"}
{"id": "1557503", "url": "https://en.wikipedia.org/wiki?curid=1557503", "title": "Wake-on-ring", "text": "Wake-on-ring\n\nWake-on-Ring (WOR), sometimes referred to as Wake-on-Modem (WOM), is a specification that allows supported computers and devices to \"wake up\" or turn on from a sleeping, hibernating or \"soft off\" state (e.g. ACPI state G1 or G2), and begin operation.\n\nThe basic premise is that a special signal is sent over phone lines to the computer through its dial-up modem, telling it to fully power-on and begin operation. Common uses were archive databases and BBSes, although hobbyist use was significant.\n\nFax machines use a similar system, in which they are mostly idle until receiving an incoming fax signal, which spurs operation.\n\nThis style of remote operation has mostly been supplanted by Wake-on-LAN, which is newer but works in much the same way. \n\n\n"}
{"id": "56955933", "url": "https://en.wikipedia.org/wiki?curid=56955933", "title": "WordLift", "text": "WordLift\n\nWordLift is a start-up founded in 2017 and based in Rome, Italy. The company has developed the homonymous WordPressplugin which, through the use of semantic technologies and artificial intelligence, optimises the writing and organisation of content and the findability of websites. Wordlift supports 32 different languages and in 2017 has had over 200 clients, amongst which are SalzburgerLand Tourismus GmbH, Greenpeace, Legambiente and The American University in Cairo.\n\nWordLift was founded in Rome in 2017 by Andrea Volpini, David Riccitelli, and other partners, and its plugin was developed using the results of European Union's research and development projects Interactive Knowledge Stack (IKS) and Media in Context (MICO). Both projects were co-funded by the European Union and aimed at developing open source semantic technologies. WordLift aids content writing on the web by enriching it with structured metadata that increases the PageRank of website pages. In March 2017 WordLift has created a partnership with WooRank, a Belgian a company specialising in digital marketing, thus obtaining a 200.000 euro grant.\n\nIn 2011 WordLift took part and the IKS Semantics UX Contest winning 40.000 euros.\n\n\n"}
{"id": "39458532", "url": "https://en.wikipedia.org/wiki?curid=39458532", "title": "Yoda conditions", "text": "Yoda conditions\n\nIn programming jargon, Yoda conditions (also called \"Yoda notation\") is a programming style where the two parts of an expression are reversed from the typical order in a conditional statement. A Yoda condition places the constant portion of the expression on the left side of the conditional statement. The name for this programming style is derived from the \"Star Wars\" character named Yoda, who speaks English with non-standard grammar.\n\nYoda conditions are part of the Symfony coding standards.\n\nUsually a conditional statement would be written as:\nYoda conditions describe the same expression, but reversed:\nThe constant is written to the left of the comparison operator, and the variable whose value is being checked against the constant is written to the right. This order is comparable to the non-standard speaking style of Yoda, which is roughly object–subject–verb (e.g., “When nine hundred years old you reach, look as good you will not.\").\n\nPlacing the constant value in the expression does not change the behavior of the program (unless the values evaluate to false—see below). In programming languages that use a single equals sign (codice_1) for assignment and not for comparison, a possible mistake is to assign a value unintentionally instead of writing a conditional statement.\nUsing Yoda conditions:\nSince 42 is a constant and can not be changed, this error will be caught by the compiler.\n\nIt can also avoid some types of unsafe null behavior.\n\nWith Yoda conditions:\nCritics of Yoda conditions see the lack of readability as a disadvantage that outweighs the benefits described above. Some programming languages as Python and Swift do not allow variable assignments within conditionals, by defining that assignments do not return a value, in which case this error is impossible to make. Many compilers produce a warning for code such as codice_2 (e.g., the GCC codice_3 option warns \"suggest parentheses around assignment used as truth value\"), which alerts the programmer to the likely mistake. In dynamic languages like JavaScript, linters such as ESLint can warn on assignment inside a conditional.\n\nThe advantage of avoiding null behavior can also be considered a disadvantage, as null pointer errors can be hidden and only appear much later in the program.\n\nAnother disadvantage appears in C++ when comparing non-basic types as the == is an operator and there may not be a suitable overloaded operator function defined. Example: a Microsoft's codice_4 compare against a string literal, written as codice_5, does not map to an overload function.\n\n"}
