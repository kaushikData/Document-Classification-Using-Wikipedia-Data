{"id": "35188921", "url": "https://en.wikipedia.org/wiki?curid=35188921", "title": "Bellman pseudospectral method", "text": "Bellman pseudospectral method\n\nThe Bellman pseudospectral method is a pseudospectral method for optimal control based on Bellman's principle of optimality. It is part of the larger theory of pseudospectral optimal control, a term coined by Ross. The method is named after Richard E. Bellman. It was introduced by Ross et al.\nfirst as a means to solve multiscale optimal control problems, and later expanded to obtain suboptimal solutions for general optimal control problems.\n\nThe multiscale version of the Bellman pseudospectral method is based on the spectral convergence property of the Ross–Fahroo pseudospectral methods. That is, because the Ross–Fahroo pseudospectral method converges at an exponentially fast rate, pointwise convergence to a solution is obtained at very low number of nodes even when the solution has high-frequency components. This aliasing phenomenon in optimal control was first discovered by Ross et al. Rather than use signal processing techniques to anti-alias the solution, Ross et al. proposed that Bellman's principle of optimality can be applied to the converged solution to extract information between the nodes. Because the Gauss–Lobatto nodes cluster at the boundary points, Ross et al. suggested that if the node density around the initial conditions satisfy the Nyquist–Shannon sampling theorem, then the complete solution can be recovered by solving the optimal control problem in a recursive fashion over piecewise segments known as Bellman segments.\n\nIn an expanded version of the method, Ross et al., proposed that method could also be used to generate feasible solutions that were not necessarily optimal. In this version, one can apply the Bellman pseudospectral method at even lower number of nodes even under the knowledge that the solution may not have converged to the optimal one. In this situation, one obtains a feasible solution.\n\nA remarkable feature of the Bellman pseudospectral method is that it automatically determines several measures of suboptimality based on the original pseudospectral cost and the cost generated by the sum of the Bellman segments.\n\nOne of the computational advantages of the Bellman pseudospectral method is that it allows one to escape Gaussian rules in the distribution of node points. That is, in a standard pseudospectral method, the distribution of node points are Gaussian (typically Gauss-Lobatto for finite horizon and Gauss-Radau for infinite horizon). The Gaussian points are sparse in the middle of the interval (middle is defined in a shifted sense for infinite-horizon problems) and dense at the boundaries. The second-order accumulation of points near the boundaries have the effect of wasting nodes. The Bellman pseudospectral method takes advantage of the node accumulation at the initial point to anti-alias the solution and discards the remainder of the nodes. Thus the final distribution of nodes is non-Gaussian and dense while the computational method retains a sparse structure.\n\nThe Bellman pseudospectral method was first applied by Ross et al. to solve the challenging problem of very low thrust trajectory optimization. It has been successfully applied to solve a practical problem of generating very high accuracy solutions to a trans-Earth-injection problem of bringing a space capsule from a lunar orbit to a pin-pointed Earth-interface condition for successful reentry.\n\nThe Bellman pseudospectral method is most commonly used as an additional check on the optimality of a pseudospectral solution generated by the Ross–Fahroo pseudospectral methods. That is, in addition to the use of Pontryagin's minimum principle in conjunction with the solutions obtained by the Ross–Fahroo pseudospectral methods, the Bellman pseudospectral method is used as a primal-only test on the optimality of the computed solution.\n\n"}
{"id": "2447768", "url": "https://en.wikipedia.org/wiki?curid=2447768", "title": "Broad Institute", "text": "Broad Institute\n\nThe Eli and Edythe L. Broad Institute of MIT and Harvard (), often referred to as the Broad Institute, is a biomedical and genomic research center located in Cambridge, Massachusetts, United States. The institute is independently governed and supported as a 501(c)(3) nonprofit research organization under the name Broad Institute Inc., and is partners with Massachusetts Institute of Technology, Harvard University, and the five Harvard teaching hospitals.\n\nThe Broad Institute evolved from a decade of research collaborations among MIT and Harvard scientists. One cornerstone was the Center for Genome Research of Whitehead Institute at MIT. Founded in 1982, the Whitehead became a major center for genomics and the Human Genome Project. As early as 1995, scientists at the Whitehead started pilot projects in genomic medicine, forming an unofficial collaborative network among young scientists interested in genomic approaches to cancer and human genetics. Another cornerstone was the Institute of Chemistry and Cell Biology established by Harvard Medical School in 1998 to pursue chemical genetics as an academic discipline. Its screening facility was one of the first high-throughput resources opened in an academic setting. It facilitated small molecule screening projects for more than 80 research groups worldwide.\n\nTo create a new organization that was open, collaborative, cross-disciplinary and able to organize projects at any scale, planning took place in 2002–2003 among philanthropists Eli and Edythe Broad, MIT, the Whitehead Institute, Harvard and the Harvard-affiliated hospitals (in particular, the Beth Israel Deaconess Medical Center, Brigham and Women's Hospital, Children's Hospital Boston, the Dana-Farber Cancer Institute and the Massachusetts General Hospital).\n\nThe Broads made a founding gift of $100 million and the Broad Institute was formally launched in May 2004. In November 2005, the Broads announced an additional $100 million gift to the Institute. On September 4, 2008, the Broads announced an endowment of $400 million to make the Broad Institute a permanent establishment. In November 2013, they invested an additional $100 million to fund a second decade of research at the institute.\n\nThe Broad Institute has 11 core faculty and 195 associate members from Harvard, MIT, and the Harvard-affiliated hospitals.\n\nThe Broad Institute is made up of three types of organizational units: core member laboratories, research programs, and platforms. The institute's scientific research programs include:\n\nThe Broad Institute's platforms are teams of professional scientists who focus on the discovery, development, and optimization of the technological tools that Broad and other researchers use to conduct research. The platforms include:\n\nThe Broad Institute also supports the Data Visualization Initiative led by the Institute creative director Bang Wong, which is aimed at developing data visualizations to explore and communicate research findings.\n\nThe faculty and staff of the Broad Institute include physicians, geneticists, and molecular, chemical, and computational biologists. The faculty currently includes 11 Core Members, whose labs are primarily located within the Broad Institute, and 195 Associate Members, whose primary labs are located at one of the universities or hospitals.\n\nThe Core Members of the Broad Institute include:\n\n\nThe Broad Institute's facilities at 320 Charles Street in Cambridge, Massachusetts, house one of the largest genome sequencing centers in the world. As WICGR (Whitehead Institute/MIT Center for Genome Research), this facility was the largest contributor of sequence information to the Human Genome Project.\n\nIn February 2006, The Broad Institute expanded to a new building at 415 Main Street, adjacent to the Whitehead Institute for Biomedical Research. This seven-story building contains office, research laboratory, retail and museum space. In 2011, the institute announced plans to construct an additional tower adjacent to the 415 Main Street site at 75 Ames Street. On May 21, 2014, the Broad officially inaugurated a 375,000-square-foot research building at 75 Ames Street in Cambridge’s Kendall Square. The new facility has 15 floors, 11 of which are occupied, and has LEED gold certification. As of July 2014, it has around 800 occupants.\n\nBetween 2009 and 2012, the operating revenue of the institute was approximately $200 million, with 55% of that coming from federal grants. The Broad Foundation (Eli and Edythe Broad) has provided $700 million in funding to the Broad Institute as of February 2014.\n\nThe Klarman Family Foundation provided a $32.5 million grant to Broad to study cellular processes in 2012. In October 2013, Fundación Carlos Slim (the Carlos Slim Foundation) of Mexico announced a $74 million grant to Broad Institute for the SIGMA2 consortium.\n\nIn July 2014, coinciding with the publication of a new study on the genetics of schizophrenia, the Broad Institute received a $650 million gift from the Stanley Family Foundation, one of the largest private gifts ever for scientific research.\n\nOn October 10, 2017, it was reported that Deerfield Management Co. was giving $50 million to the Broad Institute of MIT and Harvard to support biology research.\n\nSince 2010, the Broad Institute has been listed on the \"Boston Globe\"'s Top Places to Work. The 2014 report from Thomson Reuters' ScienceWatch entitled \"The World's Most Influential Scientific Minds\" recognized that 12 out of the 17 \"hottest\" researchers in science belonged to genomics, and 4 out of the top 5 were affiliated with the Broad Institute. Additionally, Stacey B. Gabriel of the Broad Institute topped this entire list. Twenty-eight researchers from Broad Institute have been recognized on ISI's Highly Cited, a database that recognizes the top 250 researchers in multiple areas of science.\n\nEric S. Lander, Stuart L. Schreiber and Edward M. Scolnick are members of the National Academy of Sciences and the Institute of Medicine. David Altshuler is a member of the Institute of Medicine. Feng Zhang received the 2014 Alan T. Waterman Award from the National Science Foundation, its highest honor that annually recognizes an outstanding researcher under the age of 35, for contributions to both optogenetics and CRISPR technology.\n\nIn biochemistry, genetics, and molecular biology areas, the institute was ranked #1 in the \"Mapping Excellence\" report, a survey that assessed high-impact publications.\n\nFor its architecture, Broad's 415 Main Street building architects Elkus Manfredi Architects of Boston and AHSC McLellan Copenhagen of San Francisco received high honors in the 2007 Laboratory of the Year competition of the R&D Magazine.\n\n\n"}
{"id": "37960118", "url": "https://en.wikipedia.org/wiki?curid=37960118", "title": "CCIR System I", "text": "CCIR System I\n\nCCIR System I is an analog broadcast television system. It was first used in the Republic of Ireland starting in 1962 as the 625-line broadcasting standard to be used on VHF Band I and Band III, sharing Band III with 405-line System A signals radiated in the north of the country. The UK started its own 625-line television service in 1964 also using System I, but on UHF only - the UK has never used VHF for 625-line television except for some cable relay distribution systems.\n\nSince then, System I has been adopted for use by Hong Kong, Macau, the Falkland Islands and South Africa. The Republic of Ireland has (slowly) extended its use of System I onto the UHF bands.\n\nAs of late 2012, analog television is no longer transmitted in either the UK or the Republic of Ireland. South Africa expects to discontinue System I in 2013, and Hong Kong by 2020.\n\nSome of the important specs are listed below.\nA frame is the total picture. The frame rate is the number of pictures displayed in one second. But each frame is actually scanned twice interleaving odd and even lines. Each scan is known as a field (odd and even fields.) So field rate is twice the frame rate. In each frame there are 625 lines (or 312.5 lines in a field.) So line rate (line frequency) is 625 times the frame frequency or 625•25=15625 Hz.\n\nThe total RF bandwidth of System I (as originally designed with its single FM audio subcarrier) was about 7.4 MHz, allowing System I signals to be transmitted in 8.0 MHz wide channels with an ample 600 kHz guard zone between channels.\n\nIn specs, sometimes, other parameters such as vestigial sideband characteristics and gamma of display device are also given.\n\nSystem I has only been used with the PAL colour systems, but it would have been technically possible to use SECAM or a 625-line variant of the NTSC color system. However, apart from possible technical tests in the 1960s, this has never been done officially.\n\nWhen used with PAL, the colour subcarrier is 4.43361875 MHz and the sidebands of the PAL signal have to be truncated on the high-frequency side at +1.066 MHz (matching the rolloff of the luminance signal at +5.5 MHz). On the low-frequency side, the full 1.3 MHz sideband width is radiated. ( This behaviour would cause some U/V crosstalk in the NTSC system, but delay-line PAL hides such artefacts. )\n\nAdditionally, in order to minimise beat-patterns between the chrominance subcarrier and the sound subcarrier, when PAL is used with System I, the sound subcarrier is moved slightly off the originally-specified 6.0 MHz to 5.9996 MHz. This is such a slight frequency shift that no alterations needed to be made to existing System I television sets when the change was made.\n\nNo colour encoding system has any effect on the bandwidth of system I as a whole.\n\nEnhancements have been made to the specification of System I's audio capabilities over the years. Starting in the late 1980s and early 1990s it became possible to add a digital signal carrying NICAM sound. This extension to audio capability has completely eaten the guard band between channels, indeed there would be a small amount of analogue-digital crosstalk between the NICAM signal of a transmitter on channel N and the vestigial sideband of a transmission on channel N+1. Good channel planning means that under normal situations no ill effects are seen or heard.\n\nThe NICAM system used with System I adds a 700 kHz wide digital signal, and needs to be placed at least 552 kHz from the audio subcarrier.\n\nVHF Band 1 was already discontinued for TV broadcasting well before Ireland's digital switchover.\n\n♥ No longer used for TV broadcasting.\n\nUHF takeup in Ireland was slower than in the UK. A written answer in the Dáil Éireann (Irish parliament) shows that even by mid 1988 Ireland was only\ntransmitting on UHF from four main transmitters and 11 relays.\n\n† Officially these channels \"don't exist\", being between UHF Band IV and Band V and were supposed to be reserved for radio astronomy. However, from 1997 until the finish of analog TV in the UK in 2012, the UK used channels 35 through 37 for analog broadcasts of Channel 5.\n\n§ Allocated, but never used in the UK.\n\n\n"}
{"id": "37070715", "url": "https://en.wikipedia.org/wiki?curid=37070715", "title": "Cap torque tester", "text": "Cap torque tester\n\nThe cap torque tester is used in the packaging industry to measure the opening or closuring torque of the screwing cap. It is a specific quality control equipment that can be placed on the production line or into the laboratory.\n\nA torque tester is required during the packaging design process. It could be used as a destructive tester to identify if there is any material weakness of the packaging during the screwing process. It also allows to define the torque tolerances of the capping machine. The lower torque limit is considered as the minimum pressure of the cap to avoid any leak of the product. This torque test needs to be combined with a leak test with secure seal analyzer. The higher torque limit is the maximum torque the customer can apply to open or close the product's cap.\n\nOnce torque tolerances have been defined, the cap torque tester is used as a torque control device on the final product. If the measurement are out of the limits, the capping machine needs to be adjusted. Depending on the production process, it could be necessary to control the opening torque, 24hours after the packaging process. Temperature variations can modify product characteristic with a result of different torque measurement.\n\n"}
{"id": "22172572", "url": "https://en.wikipedia.org/wiki?curid=22172572", "title": "Capaware", "text": "Capaware\n\nCapaware is a 3D general purpose virtual worlds viewer. It is a free software project which began in 2007, released for the purpose of promoting the development of free software in the Canary Islands by its Government. Capaware allows interaction with 3D virtual terrain mapping, and is distributed under license GPL. It provides access to information that fits the specifications of the OGC. \n\nIt was developed in C++ programming language. At present it works under Microsoft Windows and Linux. Capaware uses OpenSceneGraph as graphics engine, achieving extremely high frames per second rates. Capaware's architecture has a plugin interface allowing new plugins.\n\nAt present there is only a half-developed plugin as an example of the potential of Capaware: \n\n"}
{"id": "21206136", "url": "https://en.wikipedia.org/wiki?curid=21206136", "title": "Carex nebrascensis", "text": "Carex nebrascensis\n\nCarex nebrascensis is a species of sedge known as Nebraska sedge.\n\nThis sedge is native to the central and Western United States and north into central Canada. It grows in wetlands at various elevations, including the Sierra Nevada and Mojave Desert sky islands. \"Carex nebrascensis\" tolerates alkaline soils and submersion for long periods of time.\n\n\"Carex nebrascensis\" produces upright, angled, spongy stems up to about 90 centimeters tall. The waxy, bluish leaves form tufts around the base of each stem. The root system is a very dense network of rhizomes. The inflorescence includes a few narrow staminate spikes above some wider pistillate spikes on short peduncles. The fruit is covered in a tough, slightly inflated sac called a perigynium which sometimes has a pattern of red spotting.\n\nUses for this sedge, \"Carex nebrascensis\", include: \n\n"}
{"id": "4564673", "url": "https://en.wikipedia.org/wiki?curid=4564673", "title": "Colloid mill", "text": "Colloid mill\n\nA colloid mill is a machine that is used to reduce the particle size of a solid in suspension in a liquid, or to reduce the droplet size of a liquid suspended in another liquid. Colloid mills work on the rotor-stator principle: a rotor turns at high speeds (2000 - 18000 RPM). The resulting high levels of hydraulic shear applied to the process liquid disrupt structures in the fluid. Colloid mills are frequently used to increase the stability of suspensions and emulsions, but can also be used to reduce the particle size of solids in suspensions. Higher shear rates lead to smaller droplets, down to approximately 1 µm which are more resistant to emulsion separation.\n\nColloid mills are used in the following industries:\n\n"}
{"id": "16001928", "url": "https://en.wikipedia.org/wiki?curid=16001928", "title": "Concrete step barrier", "text": "Concrete step barrier\n\nA concrete step barrier is a safety barrier used on the central reservation of motorways and dual carriageways as an alternative to the standard steel crash barrier.\n\nThe barrier has contained all vehicles up to .\n\nWith effect from January 2005 and based primarily on safety grounds, the UK Highways Agency policy is that all new motorway schemes are to use high-containment concrete barriers in the central reserve. All existing motorways will introduce concrete barriers into the central reserve as part of ongoing upgrades and through replacement when these systems have reached the end of their useful life. This change of policy applies only to barriers in the central reserve of high-speed roads and not to verge-side barriers. Other routes will continue to use steel barriers. Government policy ensures that all future crash barriers in the UK will be made of concrete unless there are overriding circumstances.\n\nThe usage of the concrete step barrier has become widespread in Ireland. As of 2017, of motorways use this barrier. Some motorways such as parts of the M8 and M6 have had the crash barrier since their original construction. Other motorways had it installed as part of their upgrade (M50).\n\nSteel guard rails (since 2000s as thrie-beam barrier) and concrete profile barrier are the barrier systems used in expressways in the territory. The designs of their beam barrier are based in American and Australian designs and concrete based in European standards.\n\nVarious types of aggregate may undergo chemical reactions in concrete, leading to damaging expansive phenomena. The most common are those containing reactive silica, that can react with the alkalis in concrete. Amorphous silica is one of the most reactive mineral components in some aggregates containing e.g., opal, chalcedony, flint. Following the alkali-silica reaction (ASR), an expansive gel can form, that creates extensive cracks and damage on structural members.\n\n"}
{"id": "8885941", "url": "https://en.wikipedia.org/wiki?curid=8885941", "title": "Core-and-veneer", "text": "Core-and-veneer\n\nCore-and-veneer, brick and rubble, wall and rubble, ashlar and rubble, and emplekton all refer to a building technique where two parallel walls are constructed and the core between them is filled with rubble or other infill, creating one thick wall. Originally, and in later poorly constructed walls, the rubble was not consolidated. Later, mortar and cement were used to consolidate the core rubble and produce studier construction.\n\nModern masonry still uses core and veneer walls; however, the core is now generally concrete block instead of rubble, and moisture barriers are included. Often such walls end up as cavity walls by the inclusion of space between the external veneer and the core in order to provide for moisture and thermal control.\n\nBoth the early Phoenicians and Greeks used rubble-filled masory walls. The word \"emplekton\" was borrowed from Greek ἔμπλεκτον and originally meant \"rubble\" but came to apply to the construction technique as well.\n\nThe Romans started with basic emplekton masonry walls, but developed the technique one step further using temporary walls (forms), that were removed after the cemented rubble (concrete) had cured. This Roman technique was called \"opus caementicium\", and eventually led to modern ferroconcrete construction.\n\nThe buildings of the Taj Mahal are constructed with walls of brick and rubble inner cores faced with either marble or sandstone locked together with iron dowels and clamps. Some of the walls of the mausoleum are several metres thick.\n\nIn the large complexes at Chaco Canyon, the Ancestral Puebloans used the wall and rubble technique, with walls of carefully shaped sandstone. The Ancestral Puebloans used mud as their mortar, both with the veneer and to consolidate the core. This core and veneer technique was also used at other Ancestral Puebloans sites outside of Chaco Canyon. Later pueblos used mud bricks (adobe) for the veneer.\n\nIn the Puuc region, and as far south as at least Tikal, the Mayans developed core-and-veneer walls to the point where, by the classic period, they were filled with concrete.\n\nTraditional core-and-veneer walls suffered from moisture migration and thermal expansion and contraction. They had a low tensile strength, hence a poor resistance to twisting or stretching. Tensile strength was increased by increasing the width of the walls or by providing masonry \"piers\" (vertical columns or ribs), either inside the wall or as additional exterior support.\n\n\n"}
{"id": "8347218", "url": "https://en.wikipedia.org/wiki?curid=8347218", "title": "Corn gluten meal", "text": "Corn gluten meal\n\nCorn gluten meal (CGM) is the principal protein of corn (maize) endosperm consisting mainly of zein and glutelin. It is a byproduct of corn processing that has historically been used as an animal feed. Despite the name, \"corn gluten\" does not contain true gluten, which is formed by the interaction of gliadin and glutenin proteins.\n\nIn 1985, Dr. Nick Christians of Iowa State University discovered that CGM displayed pre-emergent herbicidal effects during a series of turf grass experiments. The use of corn gluten meal as an herbicide was patented in 1991, but, like many food-related substances used for gardening, is not regulated in the US.\n\nCGM targets a range of plants including small-seeded annual and perennial herbs. It is most frequently used in lawns, but may be applied to gardens and fields as well. Large-seeded weeds seem unaffected.\n\nThe corn gluten meal breaks down over time as an organic nitrogen source (NPK rating of 10-0-0).\n\nProteins in CGM inhibit root formation on newly germinated seeds, killing the plant. Applications must be timed so that the CGM is present and effective as seeds are germinating.\n\nSubsequent research has not been conclusive regarding the effectiveness of corn gluten as a preemergent.\n\nCGM is applied using a spreader or even by hand: the material is essentially harmless if not inhaled, and is, in fact, edible (though not particularly palatable). On lawns, CGM is applied in early spring (usually timed phenologically by the blooming of crocus or forsythia), and again in the autumn. If the lawn is overseeded, CGM should either be applied at least six weeks before sowing, or two weeks afterwards.\n\nThough very safe to use and nontoxic, CGM should not be applied to areas where it is likely to wash directly into watersheds (it is a nitrogen source). Otherwise it is ecologically safe.\n\nCGM is used as an inexpensive protein source for pet foods. CGM is an especially good source of the amino acid cysteine, but must be balanced with other proteins for lysine. \n\nIt is commonly used as livestock feed, including poultry and fish. It is a good source of protein, energy and pigments.\n"}
{"id": "48253117", "url": "https://en.wikipedia.org/wiki?curid=48253117", "title": "Corvida Raven", "text": "Corvida Raven\n\nCorvida Raven is a writer, technological artist, entrepreneur and public speaker who lives and works out of New York City, New York. She has been garnering national attention since the age of 19 for her blog, shegeeks.net, and other projects aimed at making technological skills and information accessible to the public at large, and particularly to youth, people of colour, women and marginalized communities.\n\nRaised in Miami, Florida, Raven began blogging in eighth grade. She majored in Computer Science at Hampton University while working at Blockbuster before taking a sabbatical and moving to Atlanta, Georgia. Her trademark plain-language approach to blogging about tech is informed by her experiences teaching family members how to resolve computer problems. Speaking on the challenges of being a black woman in a largely male dominated field, Raven has said: \n“I do my best to let my passion [for working] with new technology speak for me. I also make a point of highlighting and recommending other women — black, white, Latina and Asian — within my network, because the change starts with me. Sometimes you have to expose others to the things you’re already exposed to. That’s what helps you become successful in an office, boardroom and on the Web.”\n\nRaven’s blog, shegeeks.net, is her main platform for educating others about navigating social media, the internet and technological devices. Since founding the site in 2008, Raven has worked as a social media advisor for Intel and for General Motors' ChevyVolt Unplugged Tour. Once a freelance contributor to Laptop Mag, she has also served as Blog Editor for Mr. Tweet and as a Community Manager at ReadWriteWeb, the Industry Standard, Fast Company, and TED. She is co-founder of everythingtwitter.com and the Social Geeks Roundtable podcast.\n\nshegeeks.net was awarded Best Technology Blog at the 2008 Black Weblog Awards, and named one of the Top 100 Social Media, Internet Marketing and SEO Blogs in 2013. Fast Company named Raven as one of The 50 Most Influential Women in Technology in 2009 and a Social Media Curator to Watch. She was listed as one of Glamour Magazine's 21 Amazing Young Women of 2011, and recognized by Essence Magazine as a Power Player and one of the Top 25 Black Women Entrepreneurs. \nTime Magazine's Techland Blog listed hers among 25 Facebook Profiles You Should Subscribe to Right Now, and she is a recipient of a \n2012 Women Interactive Digital Vanguard Award.\n"}
{"id": "199966", "url": "https://en.wikipedia.org/wiki?curid=199966", "title": "Engine configuration", "text": "Engine configuration\n\nEngine configuration is an engineering term for the layout of the major components of a reciprocating piston internal combustion engine. These components are the cylinders and crankshafts in particular but also, sometimes, the camshaft(s).\n\nMany apparently 'standard' names for configurations are historic, arbitrary, or overlapping. For example, the 180° V engine is so named because the crankshaft is related to a V engine more closely than it is related to other opposed-piston engines such as the boxer. Others would consider it a flat engine because of its shape.\n\nThe names \"W engine\" and \"rotary engine\" have each been used for several unconnected designs. The \"H-4\" and \"H-6\" engines produced by Subaru are not H engines at all, but boxer engines. The Subaru H-4 and H-6 designs are so named because they are horizontally opposed pistons.\n\nEngine types include:\n\nThe standard names for some configurations are historic, arbitrary, or both, with some overlap. For example, the cylinder banks of a 180° V engine do not in any way form a V, but it is regarded as a V engine because of its crankshaft and big end configuration, which result in performance characteristics similar to a V engine. But it is also considered a flat engine because of its shape. On the other hand, some engines which have none of the typical V engine crankshaft design features and consequent performance characteristics are also regarded as V engines, purely because of their shape. Similarly, the Volkswagen Group VR6 engine is a hybrid of the V engine and the straight engine, and can not be definitively labeled as either.\n\nThe majority of four stroke engines have poppet valves, although some aircraft engines have sleeve valves. Valves may be located in the cylinder block (side valves), or in the cylinder head (overhead valves). Modern engines are invariably of the latter design. There may be two, three, four or five valves per cylinder, with the intake valves outnumbering the exhaust valves in case of an odd number.\n\nPoppet valves are opened by means of a camshaft which revolves at half the crankshaft speed. This can be either chain, gear or toothed belt driven from the crankshaft, and can be located in the crankcase (where it may serve one or more banks of cylinders) or in the cylinder head.\n\nIf the camshaft is located in the crankcase, a valve train of pushrods and rocker arms will be required to operate overhead valves. Mechanically simpler are side valves, where the valve stems rested directly on the camshaft However, this gives poor gas flows within the cylinder head as well as heat problems and fell out of favor for automobile use, see \"flathead engine\".\n\nThe majority of modern automobile engines place the camshaft on the cylinder head in an overhead camshaft (OHC) design. There may be one or two camshafts in the cylinder head; a single camshaft design is called single overhead camshaft (SOHC). A design with two camshafts per cylinder head is called double overhead camshaft (DOHC). Note that the camshafts are counted per cylinder head, so a V engine with one camshaft in each of its two-cylinder heads is still an SOHC design, and a V engine with two camshafts per cylinder head is DOHC, or informally a \"quad cam\" engine.\n\nWith overhead camshafts, the valvetrain will be shorter and lighter, as no pushrods are required. Some overhead camshaft designs still have rocker arms; this facilitates adjustment of mechanical clearances.\n\nA four valves per cylinder design usually has two valves for intake and two for exhaust, which requires two camshafts per cylinder bank. If there are two camshafts in the cylinder head, the cams can sometimes bear directly on cam followers on the valve stems (tappets). The cam followers aid in noise reduction, dampened vibration, shock absorption and the carrying of axial load. This latter arrangement is the most inertia free, allows the most unimpeded gas flows in the engine and is the usual arrangement for high performance automobile engines. It also permits the spark plug to be located in the center of the cylinder head, which promotes better combustion characteristics. Beyond a certain number of valves, the effective area covered \"decreases\", so four is the common-most number. Odd numbers of valves necessarily means the intake or exhaust side must have one valve more. In practice this is invariably the intake valves - even in even-numbered head designs, inlet valves are often larger in size than exhaust.\n\nVery large engines (e.g. marine engines) can have either extra camshafts or extra lobes on the camshaft to enable the engine to run in either direction. Furthermore, other manipulations of valves can be used for e.g. engine braking, such as in a Jake brake.\n\nA disadvantage of overhead cams is that a much longer chain (or belt) is needed to drive the cams than with a camshaft located in the cylinder block, usually a tensioner is also needed. A break in the belt may destroy the engine if pistons touch open valves at top dead center.\n"}
{"id": "4043055", "url": "https://en.wikipedia.org/wiki?curid=4043055", "title": "Film holder", "text": "Film holder\n\nA film holder is a device that holds one or more pieces of photographic film, for insertion into a camera or optical scanning device such as a dedicated film scanner or a flatbed scanner with film scanning capabilities. The widest use of the term refers to a device that holds sheet film for use in large format cameras, but it can also refer to various interchangeable devices in medium format or even 135 film camera systems.\n\nThe most common instance of film holder is the sheet film holder. Also referred to as a \"dark slide\" or \"double dark slide\", they are flat devices, slightly larger than the films they hold, which commonly hold one sheet of film on each side. The plate holder, which is a very similar device, holds glass plates instead of sheet film. A dark slide, from which the device derives its alternate name, is simply a dark cover that slides into a recess in the holder to protect the film (or plate) from exposure to light. Many dark slides have differently colored bands or handles on each side, one usually light and the other dark, so the photographer can distinguish between exposed and unexposed film.\n\nTraditionally, sheet film and glass plate holders have been made out of wood. Wooden holders, properly treated, can last a very long time, and apart from possible warpage, many very old specimens are still in service. Some companies continue to make wood models today, particularly for more uncommon film sizes, and as many are mostly handmade, they can be quite expensive. The majority of new sheet film holders are now made out of plastic.\n\nWhen using a sheet film holder, the device is inserted into the camera, often a view camera, and the dark slide is withdrawn, making the film available for exposure. After the exposure has been made, the dark slide is reinserted into the film holder, and the device is removed from the camera for later processing of the exposed film.\n\nSome film holders can hold more than two sheets. One of the most common is the Grafmatic, manufactured by Graflex, which holds six sheets of film in individual septums. They were available in \"23\" and \"45\" models, corresponding to 6×9 cm (2¼×3¼ inches) and 4×5 inch sheets. It takes little effort to quickly cycle through all six sheets, which makes the Grafmatic ideal for press camera usage. Burke & James produced a similar device called the Kinematic, which holds 10 sheets, though was only available in 4×5 inch format.\n\nGraflex also produced the Film Magazine. It is commonly referred to as a \"bag magazine\" (or \"bag mag\"), and uses a leather bag that hangs on the side of the frame to exchange the septums from front to back. It is a much more manual device than the Grafmatic, as exchanging a septum is done manually through the bag, rather than by a simple manipulation of the magazine's dark slide. They were sold in separate versions for film and glass plates, and held 12-18 sheets/plates, depending on the model. They are found in 3×4, 4×5, and 5×7 inch formats.\n\nThough all are superficially similar (a \"bag mag\" film (not plate) septum is the same thickness as a Grafmatic septum, but has slightly different width and length; a Kinematic septum appears almost identical to a Grafmatic septum but is in fact considerably thinner) in fact use of a septum from a different type of holder in any of these multi-sheet holders is very likely to jam the entire magazine and bend internal parts, which can then damage yet another holder if used with it. As replacement parts are no longer available one must be careful not to interchange pieces of different types of multi-sheet holders.\n\nFuji created a 4×5 system in the late 1990s called QuickChange, which is somewhat similar to a Grafmatic in principle. It is made of plastic rather than metal, making it lighter, and less prone to bent septums, but also less durable. It can hold 8 shots, and inserts are purchased already loaded with film. Though not sold as such, these inserts can be reloaded a limited number of times with standard sheet film. Because, like Grafmatic or \"bag mag\" holders, the Fuji holders used sheet film of normal thickness, they offered higher image quality than the older \"film packs\" (see below), but never became widely popular before digital imaging brought much production of traditional large-format materials to a halt.\n\nGraflex and Polaroid produced film pack holders that could be loaded in subdued light. Film packs were available from various film manufacturers in 12 and 16-sheet units. The classic film pack consisted of several \"sheets\" of film (actually much thinner than standard sheet film, as they were cut from large-format roll film, for economy and physical flexibility) taped together and wound in a series of S-bends around a metal frame. To \"advance\" the film, the user pulled a paper tab that protruded from the side of the film pack. The tab was attached—facing the opposite direction—to the junction of each sheet and its intervening section of tape. The thin film and only slight tension this system provided resulted in poor film flatness, and negatives are often sharp enough only for contact printing. They were primarily used by press photographers, and demand fell off dramatically as photojournalists converted to roll film cameras.\n\nAccording to former Kodak employees at the Eastman House photographic museum, Kodak stopped producing film packs when the last employee trained to assemble them (which required working with the very sharp metal frame in total darkness) retired in the 1980s. This rendered all traditional film pack holders in the world obsolete at once. Polaroid film packs, though mechanically similar, are not (and never were) available in standard film sizes. The Fuji QuickChange system was sometimes referred to as a film pack system but, as noted above, was a mechanical multi-sheet holder.\n\nPolaroid produced the widest range of instant sheet and pack film, but discontinued all production in 2008, leaving Fujifilm as the only producer of instant film and backs. The Polaroid 545, the lighter and more modern 545i, and the 545 Pro backs were 4×5 inch instant sheet film holders that many photographers used. New55 Holdings, LLC started producing a black and white P/N film for the 545 and 545i backs. This new instant sheet film produces a black and white negative and a positive image. The older Polaroid 550 packfilm back can take Fuji FP-100C film (3.25x4.25 inches), which was the last product of this type and was discontinued in February 2016. Polaroid also produced 8×10 inch film holders and films. Polaroid produced 10-sheet 4×5 inch instant film packs and holders.\n\nSome 4×5 inch films come in light-tight envelopes that can be loaded into a special holder in daylight. The envelopes are much smaller and lighter than a dark-slide loaded with film, so a photographer can carry a larger quantity of film than the same amount of film in dark-slides. Fuji Quickload TM film and holders, and Kodak Readyload TM film and holders, are of this type. These have not been manufactured for several years, although old stock may sometimes be sold online. New55 Holdings, LLC has started producing a variety of Ready Loads called 1SHOT TM for the preloaded systems, these include Black and white negative, color negative and color slide films.\n\nFilm holders that adapt rollfilm to sheet film cameras are usually called \"film backs\". Film backs for 4×5 inch cameras are particularly common—there is little point in taking 6×9 cm pictures on a camera. Horseman, Linhof, Graflex, and other manufacturers have made roll film holders in 6×7, 6×8, 6×9, 6×12, and 6×17 cm formats. Some models can slip under the ground glass like a normal sheet film holder, while others require that the photographer replace the ground glass with the roll holder.\n\nFilm holders are available as accessories for some medium format cameras. The most usual case is the \"Polaroid back\" taking instant film, often used to check exposure values, color rendition, etc. before taking final photographs on conventional film.\n\nSeveral of the types of holders made for large format film, including darkslide sheet holders, Grafmatic multi-sheet holders, the Graflex bag mag, and film packs were also manufactured in medium format sizes, almost always 2\"×3\" (6×9 cm). Press camera manufacturers often produced smaller versions of their 4×5 cameras in this size, often called \"23\", and while later versions of these cameras could use rollfilm adaptors, these were not widely available until almost 1950, and were expensive in their first years of production.\n\nSheet film or glass plate holders for medium format rollfilm cameras can be found, but are of mainly historical interest. Some rollfilm cameras have interchangeable backs to accommodate different film types. Some 35mm cameras have motorised backs that hold longer than normal film lengths, with a mechanism that automatically advances the film after each exposure.\n\n\n"}
{"id": "18410611", "url": "https://en.wikipedia.org/wiki?curid=18410611", "title": "Flame jet drill", "text": "Flame jet drill\n\nThe Flame Jet Drill is a type of drilling equipment whereby there is no contact with the drilling surface, therefore the drill never wears down.\n\nThe tool expels an ultra hot hydrogen flame (~4000 °C) which causes small inconsistencies in the rock to fracture and fly away and thus \"drill\" surface.\n\nAnother prototype drill called a Hydro Jet Drill is able to work in hot damp conditions by superheating water and spraying the rock with the fluid.\n\nThe devices were featured in a National Geographic documentary \"MegaStructures: Deep Earth Drillers\" about geothermal energy. \n\n"}
{"id": "49226989", "url": "https://en.wikipedia.org/wiki?curid=49226989", "title": "Food and Canning Workers' Union", "text": "Food and Canning Workers' Union\n\nThe South African Food and Canning Workers' Union was established in 1941 by Rachel Simons. It was a founder member of the South African Congress of Trade Unions. \n\nIt spread through the fruit canning industry of the Boland, Western Cape and up the west coast among fishing communities. Many of the members were women.\n\nIn 1945 it obtained a Wage Determination for the fish canning industry which improved wages and working conditions.\n\nOscar Mpetha became the General Secretary in 1951.\n\nIn 1979 it organised a successful consumer boycott. At that time it had about 25000 members.\n\nIt was one of the members of the Federation of South African Trade Unions established in 1979.\n\nIn 1982 Dr Neil Aggett was the leader of the union, though unpaid. He was detained on 27 November 1981 and died in detention.\n\nIt amalgamated with the Sweet, Food and Allied Workers' Union and the Retail and Allied Workers' Union to form the Food and Allied Workers Union\n"}
{"id": "4311837", "url": "https://en.wikipedia.org/wiki?curid=4311837", "title": "Genpact", "text": "Genpact\n\nGenpact (NYSE: G) is a professional services firm with key offices in New Delhi, Palo Alto, Hyderabad, Bengaluru, London, Kolkata, and New York.\n\nGenpact began in 1997 as a unit within General Electric. Its charter was to provide business process services to GE's businesses. During the eight years that followed, Genpact began to manage a wide range of processes across GE's financial services and manufacturing businesses.\n\nIn January 2008, Genpact became an independent company and began to serve clients outside of GE. The company name, Genpact, is designed to convey the business impact it generates for its clients. In August 2007, Genpact was listed on the NYSE under the symbol 'G'. Since then the company has grown from 32,000 employees and revenue of US$823 million, to 77,000+ employees and revenues of US$2.57 billion (2016).\n\nBain Capital became the firm's largest shareholder in October 2012.\n\nIn 2009, Genpact launched a joint venture with Indian company NDTV to offer outsourcing services for the media industry. \n\nIn June 2017, Genpact unveiled Genpact Cora, an artificial intelligence (AI)-based platform for enterprises. The platform has an application program interface (API) design and open architecture that includes Genpact’s own intellectual property as well as other providers, integrating three areas:\nGenpact Cora's claimed benefits include deciphering large chunks of data, seamless customer service, faster financial reporting, and increasing speed to market.\n\nGenpact completed the acquisition of Endeavour Software Technologies, an enterprise mobility software company, based out of Austin TX, in April 2016. \n\nIn August 2017, Genpact acquired TandemSeven, a Boston-headquartered company.\n\nGenpact then acquired OnSource in September 2017. OnSource, headquartered in Braintree, Mass., is a provider of an Inspection-as-a-Service (IaaS) product for property and casualty (P&C) insurance carriers and their customers. OnSource uses technologies such as real-time browser-based communication, self-service applications, and drones to put consumers in control of their insurance claims. \n\nOn July 18 , 2018 Genpact signed an agreement to acquire Barkawi Management Consultants, a leading supply chain management firm with operations in the U.S. and Europe that is part of the Barkawi Group.\n\nOn June 17, 2011, NV “Tiger” Tyagarajan became the president and chief executive officer (CEO) of Genpact and was appointed to the Board of Directors. He had served as chief operating officer of Genpact. He succeeded Pramod Bhasin, who stepped down as CEO and member of the board and became non-executive vice chairman of the company.\n\nTyagarajan had been CEO of Genpact from 1999 to 2002, when he led the business through a critical growth phase as a subsidiary of GE. When Genpact became an independent company, he rejoined Genpact from GE Capital U.S. as executive vice president of sales and business development from 2005 to 2009. Thereafter, he took on the role of Genpact’s chief operating officer.\n\n"}
{"id": "51919012", "url": "https://en.wikipedia.org/wiki?curid=51919012", "title": "Gilmour Space Technologies", "text": "Gilmour Space Technologies\n\nGilmour Space Technologies (also known as Gilmour Space, Gilmour Space Tech or GSpaceTech) is an Australian private space company with a subsidiary in Singapore. Headquartered in Queensland, Australia, the company is developing new hybrid-engine rockets and associated technology to support the development of a low-cost space launch vehicle.\n\nIts stated mission is to provide affordable space launch services to the region’s fast-growing small satellite industry – beginning with a commercial sounding rocket in 2019, and small satellites up to 400 kg to Low Earth Orbit by the end of 2020. Eventually, the company is also looking to provide low-cost space access for human spaceflight and exploration.\n\nGilmour Space was founded in 2012 in Singapore by former banker, Adam Gilmour. In 2013, the Australian CEO & Founder set up similar operations in Queensland, Australia with his brother James Gilmour.\n\nThe company’s first project in 2013 was to design and manufacture high-fidelity spaceflight simulators and replicas for a number of space-related exhibits, and education centers, including Spaceflight Academy Gold Coast, Australia’s first astronaut training center. It began its rocket development program in 2015; and within 18 months, successfully launched Australia and Singapore’s first privately developed hybrid test rocket using proprietary 3D printed fuel. The Gilmour brothers have also met with NASA officials at the Kennedy Space Center to discuss launch opportunities.\n\nGilmour Space employs a proprietary hybrid rocket motor technology. A hybrid-propellant rocket utilises a mixture of solid and liquid fuel. Advantages of hybrid rockets include acceptably high specific impulse values with relatively very low complexity and associated risks. In general, hybrid rocket engines are the safest of the three major rocket engines  – e.g. as compared to a solid-propellant rocket which is typically propelled by an explosive compound; and a liquid-propellant rocket which typically requires cryogenic fuel storage and complex turbine systems to provide sufficient combustion chamber pressure.\n\nGilmour Space was listed as a commercial launch vehicle provider when it successfully launched its first test vehicle, at Westmar, Queensland on June 2016. The RASTA launch vehicle flew to an altitude of 5 km and was reportedly among the first successful demonstrations of 3D printed rocket fuel in the world. \n\nSince then, the Queensland-based company has conducted a series of orbital-class engine test fires, including a 12-second test in May 2018 that recorded 75 kN (16,900 lbs) of thrust.\n\nA second test launch is scheduled in third quarter 2018, and the engine is then expected to propel the ARIEL commercial sounding rocket in 2019. In the next phase, multiple engine will be combined in a multi-stage orbital launch vehicle called ERIS, which is expected to deliver payloads up to 400 kg to LEO by fourth quarter 2020.\n\nGilmour Space has also supported a number of proof-of-concept technology projects related to the development of a long-term space habitat. An example is the M.A.R.S (Mars Aqua Retrieval System) rover project, a collaborative educational project at SUTD which received an award at the 2016 ASME international student competition . and was featured in National Geographic’s Exploring Mars exhibit in Singapore. .\n\nThe company is also working on an in-space cubesat propulsion system, which could potentially be used to send a 1U cubesat from Earth’s orbit to that of other moons or planets in the solar system.\n\nIn Feb 2018, it signed a reimbursable Space Act Agreement with NASA to collaborate on various research, technology development and educational initiatives, including the testing of its MARS rover at Kennedy Space Center.\n\nThe company has earlier developed a number of unique high-fidelity spaceflight simulators and replicas, including a 6 degree-of-freedom space plane simulator, space capsule simulator, fighter cockpit trainers, low gravity climb, mission control simulators, and others.\n\nIn February 2017, the Design Business Chamber of Singapore awarded Gilmour Space with the Singapore Good Design Mark (SG Mark 2017) for excellence in design and quality of its simulators.\n\nIn fourth quarter 2016, its Singapore business was awarded a grant by the country’s National Additive Manufacturing Innovation Cluster (NAMIC) to develop aerospace-related additive manufacturing capabilities with the Singapore University of Technology and Design (SUTD).\n\nIn May 2017, Gilmour Space Tech secured AUD 5 million in Series A round funding to develop and launch a low-cost launch vehicle for the small payload market. The lead investor was Australian venture capital firm Blackbird Ventures, with co-investors including global venture capital firm 500 Startups and other private investors.\n\nThe company has also been awarded other grants by Advance Queensland in Australia, and the Singapore Economic Development Board.\n\nIn June 2018, it received the Australian Trade & Investment Commission Innovation Award by the Australian Chamber of Commerce, Singapore \"for the individual or organisation that has demonstrated innovation through bringing progressive and new ideas to business in priority sectors\". \n"}
{"id": "13319982", "url": "https://en.wikipedia.org/wiki?curid=13319982", "title": "Good Design Award (Japan)", "text": "Good Design Award (Japan)\n\nThe is Japanese comprehensive design evaluation and commendation system, operated by the Japan Institute of Design Promotion (formerly known as the Japan Industrial Design Promotion Organization). The system has its origins in the “Good Design Selection System” (known as the “G-Mark System”) instituted by the Ministry of International Trade and Industry of Japan in 1957.\n\nThe award system was established based on the belief that good design is essential and indispensable to everyday life of people after the Pacific war, and that the good design shall give people prosperous lives through the eminent power of good designs. More than 1,000 companies and designers submit entries for consideration for the Good Design Awards each year. These entries are screened by distinguished design experts who are selected by JIDPO from various industries for assessing those worthy of the Good Design Awards. The main deciding factor for the Award selection is always based on whether or not product can bless and enrich society and people's lives through its design.\n\nApproximately 35,000 awards have been given since the inception.\n\n\n"}
{"id": "57849906", "url": "https://en.wikipedia.org/wiki?curid=57849906", "title": "Grand Musée du Parfum", "text": "Grand Musée du Parfum\n\nThe Grand Musée du Parfum was a Paris perfumery museum that operated from December 22, 2016 to July 6, 2018. It was founded by entrepreneur Guillaume de Maussion and overseen by industry experts including Jean-Claude Ellena, then the in-house perfumer at Hermes; Mathilde Laurent, house perfumer at Cartier; and Sylvaine Delacourte, director of fragrance for Guerlain. The museum, developed over two years for $7 million, was Iocated in the \"hôtel particulier\" (townhouse mansion) at 73, rue du Faubourg Saint-Honoré, once the residence of the Roederer champagne family and later the location of fashion house Christian Lacroix. Entry cost between 5 and 14.50 Euro. Exhibits included a recreation of the laboratory of French perfume house Houbigant (founded in 1775 at 19, rue du Faubourg-Saint-Honoré), using items on loan from the Musée Carnavalet (the museum of the history of Paris). It also had a \"garden of scent\" with white sculptures that each released different scents.\n"}
{"id": "57879722", "url": "https://en.wikipedia.org/wiki?curid=57879722", "title": "IED Countermeasure Equipment", "text": "IED Countermeasure Equipment\n\nThe Improvised Explosive Device Countermeasure Equipment (ICE) is a vehicle-mounted electronics-based jamming system that uses low-power radio frequency energy to thwart enemy improvised explosive devices (IEDs). The radio frequency energy it emits blocks the signals broadcast by radio-controlled detonators, such as cell phones and cordless telephones, that would otherwise trigger the hidden IED to explode. ICE was developed by the Army Research Laboratory (ARL) at White Sands Missile Range and the Physical Science Laboratory (PSL) at New Mexico State University in 2004 to counter the rising IED threat in Iraq. Due to the urgent demand for counter-IED equipment, ICE was designed and built within three weeks and was provided to troops in less than six months after the project started.\n\nICE was designed to be adaptable to future adjustments in order to keep up with changing IED technology. In addition, it was simple enough for soldiers to repair it at the unit level. Researchers later developed a portable version of ICE called Dismounted IED Countermeasures Equipment (DICE), which allowed soldiers to carry the jamming system in a backpack.\n\nICE proved to be largely successful against the IED threat and several thousand ICE systems were deployed to U.S. military personnel. In 2005, it was recognized as one of the U.S. Army’s \"Top Ten Greatest Inventions of 2004,\" and the award was shared between those who spearheaded the project, ARL’s Shane Cunico, PSL’s Sam Mares, and Maj. Raymond Pickering.\n"}
{"id": "51130248", "url": "https://en.wikipedia.org/wiki?curid=51130248", "title": "IET A F Harvey Prize", "text": "IET A F Harvey Prize\n\nThe IET A F Harvey Engineering Research Prize is a global engineering research prize awarded annually to an innovative researcher by the Institution of Engineering and Technology. It was named after an engineer, Arthur Frank Harvey.\nThe award was made for the first time in 2011 and one award is made each year. Between 2011 and 2015 the prize money was £300,000. From 2016, the prize increased to £350,000.\n\nThe prize follows a three-year cycle, as follows:\n\nThe prize money is to be used for the furtherance of scientific research into the fields of medical, microwave, laser or radar engineering.\n\nThe IET A F Harvey Engineering Prize committee searches for potential candidates from around the world for the prize, drawing on wide international networks. The committee draws up a short-list of candidates from whom additional information is requested for further detailed consideration. \nThe selection takes into account outstanding achievement and potential for further substantial advances in engineering and technology to the benefit of society.\n\nBelow is a list of recipients of the prize:\n"}
{"id": "22998410", "url": "https://en.wikipedia.org/wiki?curid=22998410", "title": "Iran Software &amp; Hardware Co. (NOSA)", "text": "Iran Software &amp; Hardware Co. (NOSA)\n\nIran Software & Hardware Co. (NOSA) () is an independently owned development and consulting corporation, which provides software applications and support to businesses of all sizes located in Iran. Since its founding in 1988, NOSA has engaged in the development and distribution of a range of integrated business software, library systems and related products designed to meet the needs of public, private and not-for-profit organizations in the region.\n\nIran Software & Hardware Company's digital information management package for companies and libraries. Simorgh is an n-tier program based on .NET framework. Simorgh uses three databases in order to effectively store information. the first server is an indigenous Database Management System built by NOSA that can efficiently support right to left and left to right text functionality and search options while storing document and book information. Second server is an SQL repository of all digital media files and documents with in document search engine. Simorgh's third server is also based on SQL and stores user and system information.\n\nSimorgh is used in hundreds of libraries and companies around Iran, including Islamic Republic of Iran Broadcasting corporation's 52 countrywide databases which are all now using a single server solution and online client accesses. Simorgh can link libraries and data sources to provide unified access through one portal. Simorgh can be used as a repository of digital documents and provide them to clients. The latest version of Simorgh incorporates radio-frequency identification, and was covered by news agencies including the Iranian News channel, the Iranian Technology news and the Iranian Students News Agency.\n\nWith arising needs of scholars to use digital sources for research and the desire of publishers and libraries to safely share such copyrighted sources online, NOSA created NOSA Books. This Project uses an artificial intelligent cloud computing server called Brain Center to match available metadata and document information across all of Simorgh's network of 100+ libraries and intelligently match them with reference libraries such as Library of Congress, National Library of Medicine and National Library of Iran.\n\n\n"}
{"id": "31384740", "url": "https://en.wikipedia.org/wiki?curid=31384740", "title": "Israel Stoughton", "text": "Israel Stoughton\n\nIsrael Stoughton (1603?-1644) was an early English colonist in Massachusetts and a colonial commander in the Pequot War. Returning to England, he served as Parliamentarian officer in the First English Civil War.\n\nBorn in England, a younger brother of John Stoughton, Stoughton emigrated to the Massachusetts Colony in 1632. He settled at Dorchester near Richard Callicot's trading post. Stoughton was admitted as a freeman at Dorchester on 5 November 1633. Stoughton was chosen as a representative for Dorchester in the Massachusetts General Court in 1634 and 1635. In 1634 Stoughton was allowed to build the first mill on the Neponset River in what is now the Dorchester-Milton Lower Mills Industrial District. Stoughton had several apprentices and servants, including John Whipple.\n\nDuring the height of the Antinomian Controversy in the colony, Stoughton wrote a book that attacked the colony's constitution. The book offended some members of the General Court, which barred Stoughton from holding any colony offices for three years. Stoughton later petitioned that the book be ‘forthwith burnt, as being weak and offensive.’ Despite this reversal, the General Court maintained their ban until 1636. In 1637, the General Court allowed Stoughton to become an assistant.\n\nIn 1636, war broke out between the Pequot tribe and the three New England colonies and their Native American allies. Appointed commander of the Massachusetts Colony militia, Stoughton reportedly employed brutal tactics against the Pequots. In 1637 Stoughton transported Pequot prisoners to Massachusetts to serve as servants, and Stoughton requested \"the fairest and largest\" of the Pequot female prisoners to be his servant. He also had African American slaves, including the well known, Dorcas the Blackmore, who joined the First Parish Church of Dorchester, and evangelized Stoughton's Native American servants and eventually attempted to gained her freedom with the help of the local church.\n\nIn 1639 Stoughton and John Endecott acted as commissioners on behalf of Massachusetts Colony to settle a boundary dispute with Plymouth Colony.\nToward the end of 1643, Stoughton made a brief trip to England, returning home by the beginning of 1644. In late 1644 he went to England again, never to return to Massachusetts.\n\nWith the advent of the First English Civil War, the English Parliament appointed Stoughton as a lieutenant colonel in their army. Stoughton died very soon afterwards in Lincoln.\n\nStoughton's children included William Stoughton, best known as the chief magistrate of the Salem witch trials in Massachusetts.\n\n\n"}
{"id": "40222602", "url": "https://en.wikipedia.org/wiki?curid=40222602", "title": "Jar opener", "text": "Jar opener\n\nA traditional jar opener will have two handles, leading up to two concentric grooved rings which can be used to fit different jars. It also sometimes has a device to open a bottle on it. \n\n"}
{"id": "25829048", "url": "https://en.wikipedia.org/wiki?curid=25829048", "title": "List of Italian inventions", "text": "List of Italian inventions\n\nItaly has been the source of many significant inventions. The following inventions and discoveries were made by people that lived in the geographical region of Italy or were made by Italians.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "677286", "url": "https://en.wikipedia.org/wiki?curid=677286", "title": "Mary Ellen Weber", "text": "Mary Ellen Weber\n\nMary Ellen Weber (born 1962) is an American executive, scientist, aviator, speaker, and a former NASA astronaut.\n\nWeber was born in Cleveland, Ohio and raised in Bedford Heights, Ohio. She graduated from Bedford High School in 1980; received a B.S. in 1984 in chemical engineering (with honors) from Purdue University, where she was a member of Phi Mu sorority; received a Ph.D. in physical chemistry from the University of California, Berkeley in 1988; and received an M.B.A. from Southern Methodist University in 2002.\n\nAs an undergrad, Weber was a chemical engineering intern at Ohio Edison, Delco Electronics, and 3M. In her doctoral research at Berkeley, she explored the physics of chemical reactions involving silicon. At Texas Instruments she researched new processes and revolutionary equipment for making computer chips, with SEMATECH and Applied Materials. She holds one patent and published nine papers in scientific journals.\n\nWeber was selected by NASA in the fourteenth group of astronauts in 1992. During her ten-year career with NASA, she held several positions. She worked extensively in technology commercialization, and as part of a team reporting to NASA's chief executive, she worked directly with a venture capital firm to successfully identify and develop a business venture leveraging a space technology. In addition, Weber was the Legislative Affairs liaison at NASA Headquarters in Washington D.C., interfacing with Congress and traveling with NASA's chief executive. Prior to this appointment, she was Chairman of the procurement board for the Biotechnology Program contractor, and she also served on a team that revamped the $2 billion plan for Space Station research facilities. Weber's principal technical assignments within the Astronaut Office included Shuttle launch preparations at the Kennedy Space Center, payload and science development, and development of standards and methods for crew science training. A veteran of two space flights, STS-70 and STS-101, she was among the youngest to fly in space and she logged over 450 hours. She is the recipient of the NASA Exceptional Service Medal. She resigned from NASA in December 2002.\n\nSTS-70 Discovery (July 13–22, 1995), a mission that successfully delivered to orbit a critical $200 million NASA communications satellite, TDRS-G to its 22-thousand-mile orbit above the equator. Weber deployed the satellite and also performed pioneering biotechnology experiments, growing colon cancer tissues never before possible to later become a leading NASA biotechnology spokesperson in this field. She was the prime spacewalk crewmember in the event a malfunction required a spacewalk, crew medical officer, and flight deck crew member for landing. STS-70 was known for its \"All-Ohio crew\" and for its last-minute launch delay due to woodpeckers, becoming the \"Woodpecker flight.\" The STS-70 mission was completed in 142 orbits of the Earth, after traveling 3.7 million miles in 214 hours and 20 minutes.\n\nSTS-101 Atlantis (May 19–29, 2000), the third Shuttle mission devoted to International Space Station construction—a critical mission, with no mission to the fledgling Station in over a year and batteries failing. The crew repaired and installed electrical and life-support components, both inside and out, and boosted the Station to a safe orbit. Weber was a flight deck crew member for launch, landing and Station rendezvous, drove Atlantis' 60-foot robotic arm to maneuver spacewalk crewmembers along the Station surface, and directed the logistics and transfer of over three thousand pounds of equipment. She also developed new crew checklists for engine failures during ascent and new procedures for robotic arm operations. The STS-101 mission—the subject of an A&E documentary, Mission Possible—was accomplished in 155 orbits of the Earth, after traveling 4.1 million miles in 236 hours and 9 minutes.\n\nWeber is currently (January 2014) with STELLAR Strategies, LLC, providing consulting services in strategies for operations in high-stakes business ventures, technology communications, and legislative strategy. She is also a speaker, with over twenty years of experience with a wide range of audiences and venues.\n\nPrior to STELLAR Strategies, Weber was Vice President for Government Affairs and Policy for nine years at the University of Texas Southwestern Medical Center in Dallas, Texas.\n\nWeber is married to Dr. Jerome Elkind—founder of Stellar Generation, LLC, an alternative energy technology company—who is originally from Bayonne, New Jersey.\n\nHaving logged nearly 5,000 skydives, Weber is an active skydiver, with 13 silver and bronze medals to date at the U.S. National Skydiving Championships and a world record in 2002 for the largest freefall formation with 300 skydivers. In addition, she is an instrument-rated pilot, a skier, and a scuba diver.\n\n"}
{"id": "58301658", "url": "https://en.wikipedia.org/wiki?curid=58301658", "title": "Mathletics (educational software)", "text": "Mathletics (educational software)\n\nMathletics is an online, educational website launched in 2005 by 3P Learning, specialising in the improvement of mathematical literacy and ability for both Primary and High School students. Specifically, Mathletics bases and functions their learning strategies from various international educational curricula, initially beginning solely with the Australian Curriculum.\n\nThe website places an emphasis upon Web 2.0 technologies to foster an interactive learning style which is designed to replicate the use of a personal tutor as to \"address the balance between teacher-led instruction and independent, student-driven learning\". Mathletics operates through a subscription-based system, offering access at an individual level as well as collectively as a school. Online users, acknowledged by the website as 'Mathletes', have access to math quizzes and challenges, and can participate in a real-time networked competition known as 'Live Mathletics'. Mathletics provides a customisable avatar for each individual user, which visually represents the player in the 'Live Mathletics' competitions. Alongside these learning interfaces, Mathletics grants individual users with the capacity to customise their avatar's clothing and general aesthetic, which are fuelled by credits awarded to the user through the completion of quizzes and tasks.\n\nAs of 2018, Mathletics caters to 4.1 million users worldwide and 17,000 schools. \n\nMathletics was established as a Personal Learning Environment (PLE) application in 2005 by 3P Learning, catering for Australian schools. The website is structured to facilitate an engagement with students from K-12 educational level, and offers various visual resources in their interactive and online Web 2.0 appropriation of the Australian Curriculum. Though initially based around this curriculum, by 2012 Mathletics had broadened its offices as well as its student and teacher audiences to various other countries residing in North America, Europe, Asia and the Middle East; adapting to those regions' various school curricula. The US and Canadian version of the website aligns with state-based educational standards including the Common Core and Texas Essential Knowledge and Skills (TEKS) from Kindergarten into High School. The UK version of the website follows the various National Curricula within Britain, comprising Foundation Stage to Key Stage 5. Both the Middle Eastern and Asian versions of the website adopt and reflect International Curricula, and offer an entire translation of the English course.\n\nMathletics is one of numerous projects created by 3P Learning, and is a sister website to Spelladrome, ReadingEggs and IntoScience. \n\nMathletics draws from the Web 2.0 technologies to foster their website as an \"interactive e-learning resource, for schools, parents and children\". Mathletics accredits the interactive aesthetic and function of their website to Web 2.0 format, which is typically characterised by its fluid accessibility to user-content creation and editing without prior knowledge of HTML programming language. With this, Mathletics takes from the features of Web 2.0 and implements them into their interface to assure that the website content can remain dynamic and regularly updated, and provides users with the option to edit and personalise their online profiles within the site without programming skills, as well as facilitate online competitions with other profiles. \n\nMathletics functions via an emphasis upon the bilateral capabilities of Web 2.0, which concerns interface and user interactivity.Mathletics heavily anchors their teaching styles within the \"Primary\" section of their website through the lens of 'visual learning'; employing a vast array of colours combined with cartoon imagery to create a \"captivating\" website aesthetic in an effort to appease the juvenile temperament of students under twelve years old. The site offers animated tutorials and learning support that display animated adolescent characters offering mathematic tips and answers to questions. The website currently offers 1200 unique questions, that have been individually tailored to suit each user's mathematic comprehension. Students are encouraged to participate in Mathematic activities which host up to 20 questions related to a certain topic. Once a student answers a question, the website recognises its completion and then adapts to the \"student's progress in understanding\", leading to questions that may be more complex in difficulty.At the completion of each topic, students are offered the opportunity to take a 'Topic Test' which summates the hardest questions in the past activities. \n\nA certificate award is presented to a student once they have earned 1000 points within a week. 10 points are awarded per correct activity answer in a regular activity. 20 points are awarded per correct answer in a 'Topic Test'. \n\nThe 'Primary Section' of the website is accessible via Tablet device, and is available for offline use if the user doesn't have sufficient Wi-Fi. All points garnered whilst on offline will be synchronised onto online servers once the individuals access the website online. \n\nMathletics believes that \"secondary school is a whole new world and a new school demands an older, more study-focused interface for new students\". As a result, the \"Secondary\" section of the website available to students doesn't reflect the juvenile decor that saturates the \"Primary\" section of the website, replacing it with a \"more study-based\" interface. Further, this \"Secondary\" area of the website exclusively promotes the use of a student progress system through use of a 'Traffic Light System', which categorises a user's understanding of a mathematical topic into three, colour-based, identifiable sections:\n\n\nAlongside this colour-coded progress guide secondary students have access to \"adaptive practice activities with animated support, plus interactive and video content\" as well as a library of various printable eBooks. Secondary Students also are offered the option to personally customise the website's interface from a range of differing backgrounds, in an effort to suit their \"learning needs\". The collection of backgrounds encompass pictures of natural environments, sporting fields, pictures of live animals and vibrant pattens of colours. \n\nAlike to the \"Primary' section, accumulative points are awarded for the completion of questions in activities. Secondary Students also have access to 'Topic Tests' which summate the most difficult questions of the topic. \n\nThe \"Secondary Students\" section of the website is also reachable on a Tablet device, and can be accessed for offline use. The same process of offline synchronisation to the online profile is also applied in the 'Secondary Students\" section of the website.\n\nThe 'Early Learners Numeracy' section of the site offers a series of multimedia resources that are designed to support students aged from four to seven. The section's mascot feature animated 'Numbeanies', drawn and designed to appeal to infants. These 'Numbeanies' present younger users with a series of flash cards that represent numbers as \"collections, numerals and words\". \n\nThe overall purpose of the Early Learners section is to be entertaining, and provide the basic foundations of mathematics through the guise of interactive games and videos. \n\n'Baby Mathletics' caters to users 6-24 months old, and is independent to the Mathletics website. 'Baby Mathletics' is an iOS based application is designed to \"help build confidence for when they start learning Mathematics at school\". The application is a video tour of a fictional story that includes animated animals and shapes, which \"poses questions, stimulate reactions and spark new interests in learning\". The purpose of the application is ultimately to foster a sense of confidence in regards to numerical learning in young toddlers.\n\nUsers that identify as teachers have access to a 'Mathletics Teacher Console' which manages their classroom's collective progress, as well as providing insight into each individual student's progress also. The teacher console delineates live data analysis of each student's progress, represented via colour-coded visuals, in an attempt to provide teachers greater agency in assigning \"targeted and personalised learning pathways\" for the class. The teacher console provides teachers with tools and instruments to manage classes, create custom mathematical learning courses to suit different and various learning groups, and bestow students with multimedia sources that will assist them answer the questions assigned.Teachers have the option to select mandatory assignments and activities to be completed by their students. These assignments must be completed before a student participate in games of Live Mathletics or other activities. \n\nThe teacher console is multi-platformed and available on various media devices including Tablet and Mobile. \n\nEach individual subscriber of Mathletics must create an identifiable Avatar. The customisable Avatar template provided by Mathletics is a portrait-view shot of a head and face in the foreground, combined with an animated environment in the background. This online persona is known as the user's 'Mathlete'. The avatar does not have to represent a user's actual facial features, however the avatar's design will represent the user against others in competitions of 'Live Mathletics'. The Avatar can be updated/altered through the 'Face Maker' interface via purchasing upgrades with credits that have been earned from completing tasks and competitions of 'Live Mathletics'.\n\nMathletics operates via a credits-based incentive system, awarding students who have completed quizzes or competitions of 'Live Mathletics' with in-app online credits that replicate virtual currency, and can be used to purchase aesthetic upgrades to their 'Mathlete'. The Mathletics website will award an obligatory 10 credits to user for participation in a quiz or competition, as an added bonus to their base gained score. \n\nThe option to participate in real-time, live networked mathematic competitions known as 'Live Mathletics' are offered to users on the Mathletics Website. The primary objective to win is for users to complete as many addition, subtraction and multiplication problems as possible before the one-minute timer ends. Users must select which difficulty level they wish to compete in, which vary on a difficulty scale from 1-10 (1 being the easiest, 10 being the hardest) that dictates the complexity of the questions asked by the website. The user who answers the most correctly, wins. It is possible for a user to 'strike-out' and forfeit their position in the game if they incorrectly answer more than two problems. A total of 5 credits are awarded to users for winning a game of Live Mathletics, and a total of 10 credits are awarded to any user who beats their previous score on any difficulty level. \n\n'Live Mathletics' incorporates a \"Who's Online\" panel which allows users to read a live feed of other students in their class that are currently online and engaged with 'Live Mathletics'. Each student listing is accompanied by a high score rating, and an option that directly requests and challenges said student to a game of 'Live Mathletics'. In addition, there is a panel that displays the students that are offline, whom can also be challenged to games of 'Live Mathletics'. Offline students who are challenged are replaced by a computer that emulates the offline individual's average game completion speed. \n\nStudents are also assigned an individual 'ability' ranking that operates on a scale from \"Raging Rookie to Human Calculator\". Mathletics determines this ranking based upon the student's overall high score. \n\nThe overall reception of Mathletics as an educational software has been generally positive. Technology-based reviewer TeachWire appraised Mathletics, calling it an \"intuitive and engaging resource; one that's bound to improve the learners' skills, knowledge and ability in maths, especially in numerical skills and speed\". EducationWorld named Mathletics a \"tremendous resource\" and an educational website that \"injected(ed) a little competitions into lessons\". \n\nCritically, Macquarie University's leading mathematic education expert, Dr Michael Cavanagh described Mathletics to SMH as a \"drill and practise\" learning software. He believes that \"this type of program needs to be complemented - and this is when the teacher comes in, to develop a deeper and broader understanding\". He then substantiates his belief that Mathletics is only \"one piece of the puzzle\" in regards to mathematical informative learning with \"If all students do is stuff on Mathletics then that's a pretty shallow approach\". \n\nBelow are a list of awards Mathletics has received since its inception. \n\n"}
{"id": "9326712", "url": "https://en.wikipedia.org/wiki?curid=9326712", "title": "Maycom Co.", "text": "Maycom Co.\n\nMaycom Co., Ltd. (Hangul: 메이콤) is a S. Korean electronics equipment manufacturer and seller primarily in the field of radio/communications and audio equipment.\n\nEstablished in 1994 by S.W. Bae, Maycom's president and sole owner, its headquarters and manufacturing facilities are based in Anyang, Gyeonggi-do, South Korea. Previously the company had offices in the UK, Poland, Hong Kong, Japan and the Middle East.\n\nAccording to its website, Maycom's current products are:\n\n\nMaycom has also manufactured products as an OEM for other companies.\n\n\nIn March 2006, e.Digital informed its shareholders that Maycom was either unwilling or unable to fulfill a purchase order for 1,250 digEplayers and batteries it had placed to fulfill an order from its customer, digEcor, in November 2005.\n\ndigEcor had fully paid e.Digital and e.Digital had fully paid Maycom. In May 2006, digEcor, filed a lawsuit against e.Digital regarding the non-delivery of the pre-paid order and other matters seeking actual damages of $793,750 and consequential damages of not less than $1,000,000. Maycom eventually delivered the players to e.Digital and e.Digital to digEcor without batteries in October 2006. e.Digital and digEcor entered into a partial settlement agreement reducing the actual damages claim to $98,846 for undelivered batteries, with consequential damages still to be proven at trial (scheduled for January 2009). e.Digital claims it will seek any damages it is required to pay from Maycom.\n"}
{"id": "22203855", "url": "https://en.wikipedia.org/wiki?curid=22203855", "title": "Ministry of Information and Broadcasting", "text": "Ministry of Information and Broadcasting\n\nMinistry of Information and Broadcasting may refer to:\n\n\n"}
{"id": "6241959", "url": "https://en.wikipedia.org/wiki?curid=6241959", "title": "Nanocomputer", "text": "Nanocomputer\n\nNanocomputer refers to a computer smaller than the microcomputer, which is smaller than the minicomputer.\n\nMicroelectronic components that are at the core of all modern electronic devices employ semiconductor transistors. The term nanocomputer is increasingly used to refer to general computing devices of size comparable to a credit card. Products sometimes referred to by this term include:\n\n\nDie shrink has been more or less continuous since around 1970. A few years later, the 6 µm process allowed the making of desktop computers, known as microcomputers. Moore's Law in the next 40 years brought features 1/100th the size, or ten thousand times as many transistors per square millimeter, putting smartphones in every pocket. Eventually computers will be developed with fundamental parts that are no bigger than a few nanometers. \n\nThere are several ways nanocomputers might be built, using mechanical, electronic, biochemical, or quantum technology. Consensus among hardware developers has been that is unlikely that nanocomputers will be made out of semiconductor transistors, as they seem to perform significantly less well when shrunk to sizes under 100 nanometers. Although developers have reduced microprocessors to 22 nm as of April 2012. Moreover, Intel's 5 nanometer technology outlook predicts 5 nm feature size by 2022. The International Technology Roadmap for Semiconductors gives an industrial consensus on feature scaling following Moore's Law.\n\nNote that a Silicon-Silicon bond length is 235.2 pm, which means that a 5 nm-width transistor would be 21 silicon atoms wide.\n\n\n"}
{"id": "24652568", "url": "https://en.wikipedia.org/wiki?curid=24652568", "title": "Olive mill pomace", "text": "Olive mill pomace\n\nOlive mill pomace is a by-product from the olive oil mill extraction process. Usually it is used as fuel in a cogeneration system or as organic fertiliser after a composting operation.\n\nOlive mill pomace compost is made by a controlled biologic process that transforms organic waste into a stable humus. Adding composted olive mill pomace as organic fertiliser in olive orchards allows the soil to get nutrients back after each olive crop.\n\nIn crude olive oil production, the traditional system, i.e. pressing, and the three-phase system produce a press cake and a considerable amount of waste water while the two-phase system, which is mainly used in Spain, produces a paste-like waste called \"alperujo\" or \"two-phase pomace\" that has a higher water content and is more difficult to treat than traditional solid waste. The water content of the press cake, composed of crude olive cake, pomace and husk, is about 30 percent if it is produced by traditional pressing technology and about 45–50 percent using decanter centrifuges. The press cake still has some oil that is normally recovered in a separate installation. The exhausted olive cake is incinerated or used as a soil conditioner in olive groves.\n\n"}
{"id": "320906", "url": "https://en.wikipedia.org/wiki?curid=320906", "title": "Packard Bell", "text": "Packard Bell\n\nPackard Bell is a Dutch-based computer manufacturing subsidiary of Acer. The brand name originally belonged to an American radio set manufacturer, Packard Bell, founded by Herbert \"Herb\" A. Bell and Leon S. Packard in 1933. Some websites use 1926 as the founding date when Herbert Bell was an executive with Jackson Bell Company, Los Angeles, California. In 1986, Israeli investors bought the brand from Teledyne, in order to name their newly formed personal computer manufacturing company producing discount computers in the United States and Canada. In the late 1990s Packard Bell became a subsidiary of NEC. In 2000, Packard Bell stopped its North American operations whilst expanding overseas and becoming a leading brand in the European PC markets. In 2008 it was acquired by the Taiwanese consumer electronic firm Acer in the aftermath of its takeover of Gateway, Inc. Gateway products are now sold in the Americas and Asia, while Packard Bell products are sold in Africa, Europe and the Middle East.\n\nIn 1986, Beny Alagem, Larry Metz and a group of other Israeli investors bought the American former radio and television set brand from Teledyne and resurrected it as a manufacturer of low-cost personal computers. Their computers were among the first IBM PC compatibles sold in retail chains such as Sears.\n\nAccording to \"Fortune\" magazine, Packard Bell sometimes benefited from misplaced name recognition, with consumers (especially first-time computer buyers) and even some salespeople erroneously associating the company with others of a similar name, such as Hewlett-Packard, Pacific Bell, and Bell Laboratories. The confusion was further facilitated by Packard Bell's then-current slogan, \"America grew up listening to us. It still does.\" The company also sold nearly identical systems under different names, making comparison difficult.\nAside from low price and brand confusion, Packard Bell's success in number of units sold may have come from two areas of innovation: 1) branding and industrial design, provided by the San Francisco offices of frog design; and 2) its boot-up shell Packard Bell Navigator, created by The Pixel Company in Seattle. They targeted a huge section of consumers who were inexperienced using computers. Frog design gave the look of quality and utilized innovations such as color-coding cable connectors (first seen on the IBM PS/2), while Navigator provided the ability for users to launch installed programs by clicking on-screen buttons, and then later a house metaphor. During this phase, returns dropped from 19% to 10%, and sales grew exponentially. \n\nIn late 1995 to early 1996 Microsoft forced boot-up shells off OEM computers by updating its Microsoft Windows distribution agreement (OPK 2) and Packard Bell, without a clear on-shelf differentiator, saw sales begin to decrease. Also in 1995, Compaq sued Packard Bell for not disclosing that Packard Bell computers incorporated used parts. This practice was, in fact, widespread in the computer industry, including Compaq itself. However, unlike its rival companies, Packard Bell was judged not to have advertised the practice sufficiently in its warranties (Compaq, for instance, disclosed it in the warranty statement).\n\nIn 1995, Packard Bell acquired Zenith Data Systems from Groupe Bull in a deal which saw Groupe Bull and NEC taking a larger stake in Packard Bell to create a $4.5 billion company. The company then became integrated with NEC Computers. Its 15% market share made it the largest PC manufacturer, in terms of units shipped, in the United States. However, Compaq overtook it in retail sales in mid-1996, and cemented its lead the next year with the release of a $999 PC in March 1997.\n\nPackard Bell posted losses totaling more than $1 billion in 1997 and 1998. In the U.S., price pressure from Compaq and, later, eMachines, along with continued poor showings in consumer satisfaction surveys made it difficult for the company to remain profitable and led to Alagem's departure in 1998. In 1999, NEC began withdrawing the Packard Bell name from the U.S. market, while keeping it in Europe, where the brand was untainted by allegations of sub-standard quality.\nFrom 1996 until 2000, when Strongbow took over the contract, Packard Bell sponsored English football club Leeds United.\n\nFrom 2009 to 2010, the name Packard Bell has been seen on the FIAT Yamaha MotoGP racebike of World Champion Valentino Rossi of Italy. Packard Bell also dropped their sponsorship from the 4Kings professional electronic sports team.\n\nOn October 14, 2016 PBX Holdings acquired the United States Packard Bell trademark. PBX Holdings is led by a group of investors with experience in the technology and retail space. PBX began manufacturing Packard Bell products in 2017. In June 2017 JCPenney revealed that they would begin selling a line of Packard Bell laptops as part of their expansion into the dormitory market. PBX is set to expand the brand into home automation and gaming accessories with product launches set for the Holiday 2018 season.\n\n"}
{"id": "592136", "url": "https://en.wikipedia.org/wiki?curid=592136", "title": "Palladian architecture", "text": "Palladian architecture\n\nPalladian architecture is a European style of architecture derived from and inspired by the designs of the Venetian architect Andrea Palladio (1508–1580). That which is recognised as Palladian architecture today is an evolution of Palladio's original concepts. Palladio's work was strongly based on the symmetry, perspective and values of the formal classical temple architecture of the Ancient Greeks and Romans. From the 17th century Palladio's interpretation of this classical architecture was adapted as the style known as Palladianism. It continued to develop until the end of the 18th century.\n\nPalladianism became popular briefly in Britain during the mid-17th century, but its flowering was cut short by the onset of the English Civil War and the imposition of austerity which followed. In the early 18th century it returned to fashion, not only in England but also, directly influenced from Britain, in Prussia. Count Francesco Algarotti may have written to Burlington from Berlin that he was recommending to Frederick the Great the adoption in Prussia of the architectural style Burlington had introduced in England but Knobelsdorff's opera house on the Unter den Linden, based on Campbell's Wanstead House, had been constructed from 1741. Later in the century, when the style was falling from favour in Europe, it had a surge in popularity throughout the British colonies in North America, highlighted by examples such as Drayton Hall in South Carolina, the Redwood Library in Newport, Rhode Island, the Morris-Jumel Mansion in New York City, the Hammond-Harwood House in Annapolis, Maryland and Thomas Jefferson's Monticello and Poplar Forest in Virginia.\n\nThe style continued to be popular in Europe throughout the 19th and early 20th centuries, where it was frequently employed in the design of public and municipal buildings. From the latter half of the 19th century it was rivalled by the Gothic revival in the English-speaking world, whose champions, such as Augustus Pugin, remembering the origins of Palladianism in ancient temples, deemed it too pagan for Anglican and Anglo-Catholic worship. However, as an architectural style it has continued to be popular and to evolve; its pediments, symmetry and proportions are clearly evident in the design of many modern buildings today.\n\nBuildings entirely designed by Palladio are all in Venice and the Veneto, with an especially rich grouping of palazzi in Vicenza. They include villas, and churches such as Redentore in Venice. In Palladio's architectural treatises he followed the principles defined by the Roman architect Vitruvius and his 15th-century disciple Leon Battista Alberti, who adhered to principles of classical Roman architecture based on mathematical proportions rather than the rich ornamental style also characteristic of the Renaissance.\n\nPalladio always designed his villas with reference to their setting. If on a hill, such as Villa Capra, facades were frequently designed to be of equal value so that occupants could have fine views in all directions. Also, in such cases, porticos were built on all sides so that occupants could fully appreciate the countryside while being protected from the sun, similar to many American-style porches of today. Palladio sometimes used a loggia as an alternative to the portico. This can most simply be described as a recessed portico, or an internal single storey room, with pierced walls that are open to the elements. Occasionally a loggia would be placed at second floor level over the top of a loggia below, creating what was known as a double loggia. Loggias were sometimes given significance in a facade by being surmounted by a pediment. Villa Godi has as its focal point a loggia rather than a portico, plus loggias terminating each end of the main building.\n\nPalladio would often model his villa elevations on Roman temple facades. The temple influence, often in a cruciform design, later became a trademark of his work. Palladian villas are usually built with three floors: a rusticated basement or ground floor, containing the service and minor rooms. Above this, the piano nobile accessed through a portico reached by a flight of external steps, containing the principal reception and bedrooms, and above it is a low mezzanine floor with secondary bedrooms and accommodation. The proportions of each room within the villa were calculated on simple mathematical ratios like 3:4 and 4:5, and the different rooms within the house were interrelated by these ratios. Earlier architects had used these formulas for balancing a single symmetrical facade; however, Palladio's designs related to the whole, usually square, villa.\n\nPalladio deeply considered the dual purpose of his villas as both farmhouses and palatial weekend retreats for wealthy merchant owners. These symmetrical temple-like houses often have equally symmetrical, but low, wings sweeping away from them to accommodate horses, farm animals, and agricultural stores. The wings, sometimes detached and connected to the villa by colonnades, were designed not only to be functional but also to complement and accentuate the villa. They were, however, in no way intended to be part of the main house, and it is the design and use of these wings that Palladio's followers in the 18th century adapted to become an integral part of the building.\n\nPalladio's Four Books of Architecture was first published in 1570, This architectural treaty contains descriptions and illustrations of his own architecture along with the Roman building that inspired him to create the style. Palladio reinterpreted Rome's ancient architecture and applied it to all kinds of buildings from grand villas and public buildings to humble houses and farm sheds.\n\nThe Palladian, Serlian, or Venetian window features largely in Palladio's work and is almost a trademark of his early career. It consists of a central light with semicircular arch over, carried on an impost consisting of a small entablature, under which, and enclosing two other lights, one on each side, are pilasters. In the library at Venice, Sansovino varied the design by substituting columns for the two inner pilasters. To describe its origin as being either Palladian or Venetian is not accurate; the motif was first used by Donato Bramante and later mentioned by Sebastiano Serlio (1475–1554) in his seven-volume architectural book \"Tutte l'opere d'architettura et prospetiva\" expounding the ideals of Vitruvius and Roman architecture, this arched window is flanked by two lower rectangular openings, a motif that first appeared in the triumphal arches of ancient Rome. Palladio used the motif extensively, most notably in the arcades of the Basilica Palladiana in Vicenza. It is also a feature of his entrances to both Villa Godi and Villa Forni Cerato. It is perhaps this extensive use of the motif in the Veneto that has given the window its alternative name of the Venetian window; it is also known as a Serlian window. Whatever the name or the origin, this form of window has probably become one of the most enduring features of Palladio's work seen in the later architectural styles evolved from Palladianism. According to James Lees-Milne, its first appearance in Britain was in the remodelled wings of Burlington House, London, where the immediate source was actually in Inigo Jones's designs for Whitehall Palace rather than drawn from Palladio himself.\n\nA variant, in which the motif is enclosed within a relieving blind arch that unifies the motif, is not Palladian, though Burlington seems to have assumed it was so, in using a drawing in his possession showing three such features in a plain wall (see illustration of Claydon House above right). Modern scholarship attributes the drawing to Scamozzi. Burlington employed the motif in 1721 for an elevation of Tottenham Park in Savernake Forest for his brother-in-law Lord Bruce (since remodelled). Kent picked it up in his designs for the Houses of Parliament, and it appears in Kent's executed designs for the north front of Holkham Hall.\n\nIn 1570 Palladio published his book, \"I Quattro Libri dell'Architettura\", which inspired architects across Europe.\n\nDuring the 17th century, many architects studying in Italy learned of Palladio's work. Foreign architects then returned home and adapted Palladio's style to suit various climates, topographies and personal tastes of their clients. Isolated forms of Palladianism throughout the world were brought about in this way. However, the Palladian style did not reach the zenith of its popularity until the 18th century, primarily in England, Wales, Scotland, Ireland and later North America. In Venice itself there was an early reaction to the excesses of Baroque architecture that manifested itself as a return to Palladian principles. The earliest neo-Palladians there were the exact contemporaries, both trained up as masons, Domenico Rossi (1657–1737) and Andrea Tirali (1657–1737). Tommaso Temanza, their biographer, proved to be the movement's most able and learned proponent; in his hands the visual inheritance of Palladio's example became increasingly codified in correct rules and drifted towards neoclassicism.\n\nThe most influential follower of Palladio anywhere, however, was the Englishman Inigo Jones, who travelled throughout Italy with the 'Collector' Earl of Arundel, annotating his copy of Palladio's treatise, in 1613–14. The \"Palladianism\" of Jones and his contemporaries and later followers was a style largely of facades, and the mathematical formulae dictating layout were not strictly applied. A handful of great country houses in England built between 1640 and c. 1680, such as Wilton House, are in this Palladian style. These follow the great success of Jones' Palladian designs for the Queen's House at Greenwich and the Banqueting House at Whitehall, the uncompleted royal palace in London of King Charles I.\n\nHowever, the Palladian designs advocated by Inigo Jones were too closely associated with the court of Charles I to survive the turmoil of the civil war. Following the Stuart restoration Jones's Palladianism was eclipsed by the baroque designs of such architects as William Talman and Sir John Vanbrugh, Nicholas Hawksmoor, and even Jones' pupil John Webb.\n\nThe baroque style, popular in continental Europe, was never truly to the English taste and was considered excessively flamboyant, catholic and 'florid'. It was quickly superseded when, in the first quarter of the 18th century, four books were published in Britain which highlighted the simplicity and purity of classical architecture. These were:\n\nThe most popular of these among the wealthy patrons of the day was the four-volume \"Vitruvius Britannicus\" by Colen Campbell. Campbell was both an architect and a publisher. The book was basically a book of design containing architectural prints of British buildings, which had been inspired by the great architects from Vitruvius to Palladio; at first mainly those of Inigo Jones, but the later tomes contained drawings and plans by Campbell and other 18th-century architects. These four books greatly contributed to Palladian architecture becoming established in 18th-century Britain. Their three authors became the most fashionable and sought after architects of the era. Due to his book \"Vitruvius Britannicus\", Colen Campbell was chosen as the architect for banker Henry Hoare I's Stourhead house (\"illustration above\"), a masterpiece that became the inspiration for dozens of similar houses across England.\n\nAt the forefront of the new school of design was the aristocratic \"architect earl\", Richard Boyle, 3rd Earl of Burlington; in 1729, he and William Kent, designed Chiswick House. This House was a reinterpretation of Palladio's Villa Capra, but purified of 16th century elements and ornament. This severe lack of ornamentation was to be a feature of the Palladianism.\nIn 1734 William Kent and Lord Burlington designed one of England's finest examples of Palladian architecture with Holkham Hall in Norfolk. The main block of this house followed Palladio's dictates quite closely, but Palladio's low, often detached, wings of farm buildings were elevated in significance. Kent attached them to the design, banished the farm animals, and elevated the wings to almost the same importance as the house itself. These wings were often adorned with porticos and pediments, often resembling, as at the much later Kedleston Hall, small country houses in their own right. It was the development of the flanking wings that was to cause English Palladianism to evolve from being a pastiche of Palladio's original work.\n\nArchitectural styles evolve and change to suit the requirements of each individual client. When in 1746 the Duke of Bedford decided to rebuild Woburn Abbey, he chose the Palladian style for the design, as this was now the most fashionable of the era. He selected architect Henry Flitcroft, a protege of Burlington. Flitcroft's designs, while Palladian in nature, would not be recognised by Palladio himself. The central block is small, only three bays, the temple-like portico is merely suggested, and it is closed. Two great flanking wings containing a vast suite of state rooms replace the walls or colonnades which should have connected to the farm buildings; the farm buildings terminating the structure are elevated in height to match the central block, and given Palladian windows, to ensure they are seen as of Palladian design. This development of the style was to be repeated in countless houses, and town halls in Britain over one hundred years. Falling from favour during the Victorian era, it was revived by Sir Aston Webb for his refacing of Buckingham Palace in 1913. Often the terminating blocks would have blind porticos and pilasters themselves, competing for attention with, or complementing the central block. This was all very far removed from the designs of Palladio two hundred years earlier.\n\nEnglish Palladian houses were now no longer the small but exquisite weekend retreats from which their Italian counterparts were conceived. They were no longer villas but \"power houses\" in Sir John Summerson's term, the symbolic centres of power of the Whig \"squirearchy\" that ruled Britain. As the Palladian style swept Britain, all thoughts of mathematical proportion were swept away. Rather than square houses with supporting wings, these buildings had the length of the façade as their major consideration; long houses often only one room deep were deliberately deceitful in giving a false impression of size.\n\nDuring the Palladian revival period in Ireland, even quite modest mansions were cast in a neo-Palladian mould. Palladian architecture in Ireland subtly differs from that in England. While adhering as in other countries to the basic ideals of Palladio, it is often truer to them – perhaps because it was often designed by architects who had come directly from mainland Europe, and therefore were not influenced by the evolution that Palladianism was undergoing in Britain. Whatever the reason, Palladianism still had to be adapted for the wetter, colder weather.\n\nOne of the most pioneering Irish architects was Sir Edward Lovett Pearce (1699–1733), who became one of the leading advocates of Palladianism in Ireland. A cousin of Sir John Vanbrugh, he was originally one of his pupils, but rejecting the baroque, he spent three years studying architecture in France and Italy, before returning home to Ireland. His most important Palladian work is the former Irish Houses of Parliament in Dublin. He was a prolific architect who also designed the south façade of Drumcondra House in 1725 and Summerhill House in 1731, which was completed after Pearce's death by Richard Cassels.\n\nPearce oversaw the building of Castletown House, near Dublin, designed by the Italian architect Alessandro Galilei (1691–1737). It is perhaps the only Palladian house in Ireland to have been built with Palladio's mathematical ratios, and one of the three Irish mansions which claim to have inspired the design of the White House in Washington.\n\nOther examples include Russborough, designed by Cassels, who also designed the Palladian Rotunda Hospital in Dublin, and Florence Court, County Fermanagh. Irish Palladian Country houses often feature robust Rococo plasterwork, frequently executed by the Lafranchini brothers, an Irish speciality, which is far more flamboyant than the interiors of their contemporaries in England. So much of Dublin was built in the 18th century that it set a Georgian stamp on the city; however arising out of bad planning and poverty, until recently Dublin was one of the few cities where fine 18th-century housing could be seen in ruinous condition. Elsewhere in Ireland after 1922, the lead was removed from the roofs of unoccupied Palladian houses for its value as scrap, with the houses often abandoned owing to excessive roof-rate based taxes. Some roofless Palladian houses can still be found in the depopulated Irish countryside.\n\nPalladio's influence in North America is evident almost from the beginning of architect-designed building there though the Anglo-Irish philosopher, George Berkeley, may have been America's pioneering Palladian. Acquiring a large farmhouse in Middletown, near Newport in the late 1720s, Berkeley dubbed it \"Whitehall\" and improved it with a Palladian doorcase derived from William Kent's \"Designs of Inigo Jones\" (1727), which he may have brought with him from London; Palladio's work was included in the library of a thousand volumes he amassed for the purpose and sent to Yale College. In 1749 Peter Harrison adopted the design of his Redwood Library in Newport, Rhode Island, more directly from Palladio's \"Quattro Libri\", while his Brick Market, also in Newport, of a decade later is also Palladian in conception.\n\nThe Hammond-Harwood House in Annapolis, Maryland (\"illustration\") is an example of Palladian architecture in the United States. It is the only existing work of colonial academic architecture that was principally designed from a plate in Andrea Palladio’s \"Quattro Libri\". The house was designed by the architect William Buckland in 1773–74 for wealthy farmer Matthias Hammond of Anne Arundel County, Maryland. It was modeled on the design of the Villa Pisani in Montagnana, Italy in Book II, Chapter XIV of \"I Quattro Libri dell’Achitettura.\"\n\nThe politician and architect Thomas Jefferson (1743–1826) once referred to Palladio's \" Quattro Libri\" as his bible. Jefferson acquired an intense appreciation of Palladio's architectural concepts, and his designs for his own beloved Monticello, the James Barbour Barboursville estate, Virginia State Capitol, and the University of Virginia were based on drawings from Palladio's book. Realizing the powerful political significance pertaining to ancient Roman buildings, Jefferson designed his civic buildings in the Palladian style. Monticello (remodelled between 1796 and 1808) is quite clearly based on Palladio's Villa Capra, however, with modifications, in a style which is described in America today as Colonial Georgian. Jefferson's Pantheon, or Rotunda, at the University of Virginia is undeniably Palladian in concept and style.\n\nIn Virginia and Carolina, the Palladian manner is epitomised in numerous Tidewater plantation houses, such as Stratford Hall or Westover Plantation, or Drayton Hall near Charleston. These examples are all classic American colonial examples of a Palladian taste that was transmitted through engravings, for the benefit of masons—and patrons, too—who had no first-hand experience of European building practice. A feature of American Palladianism was the re-emergence of the great portico, which again, as in Italy, fulfilled the need of protection from the sun; the portico in various forms and size became a dominant feature of American colonial architecture. In the north European countries the portico had become a mere symbol, often closed, or merely hinted at in the design by pilasters, and sometimes in very late examples of English Palladianism adapted to become a porte-cochere; in America, the Palladian portico regained its full glory.\n\nOne house which clearly shows this Palladian-Gibbs influence is Mount Airy, in Richmond County, Virginia, built in 1758–62.\n\nAt Westover the north and south entrances, made of imported Portland stone, were patterned after a plate in William Salmon's \"Palladio Londinensis\" (1734).\n\nThe distinctive feature of Drayton Hall, its two-storey portico, was derived directly from Palladio.\n\nThe neoclassical presidential mansion, the White House in Washington, was inspired by Irish Palladianism. Both Castle Coole and Richard Cassel's Leinster House in Dublin claim to have inspired the architect James Hoban, who designed the executive mansion, built between 1792 and 1800. Hoban, born in Callan, County Kilkenny, in 1762, studied architecture in Dublin, where Leinster House (built c. 1747) was one of the finest buildings at the time. The White House is more neoclassical than Palladian; particularly the South façade, which closely resembles James Wyatt's 1790 design for Castle Coole, also in Ireland. Castle Coole is, in the words of the architectural commentator Gervase Jackson-Stops, \"A culmination of the Palladian traditions, yet strictly neoclassical in its chaste ornament and noble austerity.\"\n\nOne of the adaptations made to Palladianism in America was that the piano nobile now tended to be placed on the ground floor, rather than above a service floor, as was the tradition in Europe. This service floor, if it existed at all, was now a discreet semi-basement. This negated the need for an ornate external staircase leading to the main entrance as in the more original Palladian designs. This would also be a feature of the neoclassical style that followed Palladianism.\n\nThe only two houses in the United States—from the English colonial period (1607–1776)—that can be definitively attributed to designs from the \"Four Books of Architecture\" are architect William Buckland's Hammond-Harwood House (1774) in Annapolis, Maryland, and Thomas Jefferson's first Monticello. The design source for the Hammond-Harwood House is Villa Pisani at Montagnana (Book II, Chapter XIV), and for the first Monticello (1770) the design source is Villa Cornaro at Piombino Dese (Book II, Chapter XIV). Thomas Jefferson later covered this façade with additions so that the Hammond-Harwood House remains the only pure and pristine example of direct modeling in America today.\n\nBecause of its later development, Palladian architecture in Canada is rare. One notable example is the Nova Scotia Legislature building, completed in 1819. Another example is Government House in St. John's, Newfoundland.\nThe Center for Palladian Studies in America, Inc., a non-profit membership organization, was founded in 1979 to research and promote understanding of Palladio’s influence in the United States.\n\nBy the 1770s, in Britain, such architects as Robert Adam and Sir William Chambers were in huge popular demand, but they were now drawing on a great variety of classical sources, including ancient Greece, so much so that their forms of architecture were eventually defined as neoclassical rather than Palladian. In Europe, the Palladian revival ended by the end of the 18th century. In North America, Palladianism lingered a little longer; Thomas Jefferson's floor plans and elevations owe a great deal to Palladio's \"Quattro Libri.\" The term \"Palladian\" today is often misused, and tends to describe a building with any classical pretensions. There was, however, a revival of Palladian ideas amongst the colonial revivalists of the early 20th century, and the strain has been unbroken, even through the modernist period.\n\nIn the mid-20th century, the originality of the approach of the architectural historian Colin Rowe had the effect of re-situating the assessment of modern architecture within history and acknowledged the Palladian architecture as an active influence. In the later 20th century, when Rowe's influence had spread worldwide, this approach had become a key element in the process of architectural and urban design. If \"the presence of the past\" was evident in the work of many architects in the late 20th century, from James Stirling to Aldo Rossi, Robert Venturi, Oswald Matthias Ungers, Peter Eisenman, Michael Graves and others, this was largely due to the influence of Rowe. Colin Rowe's unorthodox and non-chronological view of history then made it possible for him to develop theoretical formulations such as his famous essay \"The Mathematics of the Ideal Villa\" (1947) in which he theorised that there were compositional \"rules\" in Palladio’s villas that could be demonstrated to correspond to similar \"rules\" in Le Corbusier’s villas at Poissy and Garches. This approach enabled Rowe to elaborate an astonishingly fresh and provocative trans-historical assessment of both Palladio and Le Corbusier, in which the architecture of both was assessed not in chronological time, but side by side in the present moment.\n\n\n\n"}
{"id": "22558189", "url": "https://en.wikipedia.org/wiki?curid=22558189", "title": "Post-combustion capture", "text": "Post-combustion capture\n\nPost-combustion capture refers to the removal of \"CO\" from power station flue gas prior to its compression, transportation and storage in suitable geological formations, as part of carbon capture and storage. A number of different techniques are applicable, almost all of which are adaptations of acid gas removal processes used in the chemical and petrochemical industries. Many of these techniques existed before World War II and, consequently, post combustion capture is the most developed of the various carbon-capture methodologies. \n\n\n"}
{"id": "6910727", "url": "https://en.wikipedia.org/wiki?curid=6910727", "title": "Programmable thermostat", "text": "Programmable thermostat\n\nA programmable thermostat is a thermostat which is designed to adjust the temperature according to a series of programmed settings that take effect at different times of the day. Programmable thermostats may also be called setback thermostats or clock thermostats.\n\nHeating and cooling losses from a building (or any other container) become greater as the difference in temperature increases. A programmable thermostat allows reduction of these losses by allowing the temperature difference to be reduced at times when the reduced amount of heating or cooling would not be objectionable.\n\nFor example, during cooling season, a programmable thermostat used in a home may be set to allow the temperature in the house to rise during the workday when no one will be at home. It may then be set to turn on the air conditioning before the arrival of occupants, allowing the house to be cool upon the arrival of the occupants while still having saved air conditioning energy during the peak outdoor temperatures. The reduced cooling required during the day also decreases the demands placed upon the electrical supply grid.\n\nConversely, during the heating season, the programmable thermostat may be set to allow the temperature in the house to drop when the house is unoccupied during the day and also at night after all occupants have gone to bed, re-heating the house prior to the occupants arriving home in the evening or waking up in the morning. Since most people sleep better when a room is cooler and the temperature differential between the interior and exterior of a building will be greatest on a cold winter night, this reduces energy losses.\n\nSimilar scenarios are available in commercial buildings, with due consideration of the building's occupancy patterns.\n\nAccording to \"Consumer Reports\" magazine, programmable thermostats can reduce energy bills by about $180 a year.\n\nWhile programmable thermostats may be able to save energy when used correctly, little or no average energy savings has been demonstrated in residential field studies. Difficulty with usability in residential environments appears to lead to lack of persistence of energy savings in homes. According to the US EPA regarding residential programmable thermostat, \"Available studies indicate no savings from programmable thermostat (PT) installation. Some studies indicate slight increased consumption.\" This is supported with studies by Nevius and Pigg, Cross and Judd and others and Peffer et al. has a recent review of the topic.\n\nIn addition to potential increased energy consumption, digital programmable thermostats have been criticised for their poor usability. Several studies have found that digital programmable thermostats are difficult for users to programme and older people in particular can struggle to use them (see Combe et al.). \n\nIt has been noted that the use of programmable thermostats is hampered by misconception about the setback feature, reducing the amount of heating or cooling in a building needs for a short time (e.g. at night or when it is unoccupied). The belief is that if the building is allowed to change temperature, its heating or cooling system has to \"work harder\" to bring it back to a comfortable temperature, counteracting or even exceeding the energy saved during reduced heating or cooling. Actually the setback and recovery feature can result in energy savings of five to fifteen percent as the heat transfer between a structure and its environment is proportional to the temperature difference between the inside and outside of the structure.\n\nThe most basic clock thermostats may only implement one program with two periods (a hotter period and a colder period), and the same program is run day after day. More sophisticated clock thermostats may allow four or more hot and cold periods to be set per day. Usually, only two distinct temperatures (a hotter temperature and a colder temperature) can be set, even if multiple periods are permitted. The hotter and colder temperatures are usually established simply by sliding two levers along an analogue temperature scale, much the same as in a conventional (non-clock) thermostat.\n\nThis design, while simple to manufacture and relatively easy to program, sacrifices comfort on weekends since the program is repeated each of the seven days of the week with no variation. To overcome this deficit, a push-button is sometimes provided to allow the user to explicitly switch (once) the current period from hot period to a cold period or vice versa; the usual use of this button is to over-ride a \"set back\" that takes place during the workday when the home is normally unoccupied.\n\nThe clock mechanism is electrical. Two methods have commonly been used to operate it:\n\n[1] A separate, continuous source of 24 volts alternating current (24 VAC) is provided to the thermostat.\n\n[2] A rechargeable battery in the thermostat operates the clock. This battery charges when the thermostat is not calling for heat and 24 VAC is available to it. It discharges to operate the clock when the thermostat is set for heating or cooling.\n\nDigital thermostats may implement the same functions, but most provide more versatility. For example, they commonly allow setting temperatures for two, four, or six periods each day, and rather than being limited to a single \"hotter\" temperature and a single \"colder\" temperature, digital thermostats usually allow each period to be set to a unique temperature. The periods are commonly labeled \"Morning\", \"Day\", \"Evening\", and \"Night\", although nothing constrains the time intervals involved. Digital thermostats usually allow the user to override the programmed temperature for the period, automatically resuming programmed temperatures when the next period begins. A function to \"hold\" (lock-in) the current temperature is usually provided as well; in this case, the override temperature is maintained until the user cancels the hold or a programmed event occurs to resume the normal program. More-sophisticated models will allow for the release of the hold to take place at a set time in the future.\n\nAs with clock thermostats, basic digital thermostats may have just one cycle that is run every day of the week. More-sophisticated thermostats may have a weekday schedule and a separate weekend schedule (so-called \"5-2\" setting) or separate Saturday and Sunday schedules (so-called \"5-1-1\" settings), while other thermostats will offer a separate schedule for each day of the week (\"7 day\" settings). The selection of which days are defined as the \"weekend\" is arbitrary, depending on the user's heating and cooling schedule requirements. Often, a manufacturer will sell three similar thermostats offering each of those levels of functionality, and there is no obvious difference in the thermostats other than the factory programming and the price.\n\nMost digital thermostats have separate programs for heating and cooling, and may feature a digital or manual switch to turn on the furnace blower for air circulation, even when the system isn't heating or cooling. More-sophisticated models may be programmed to run the circulating fan for a brief 5- to 10-minute period in the event a heating or cooling cycle has not taken place during the previous hour. This is particularly useful in buildings subject to stratification where without frequent air circulation, hot air rises and separates from the cooler air that falls.\n\nDigital thermostats may also have a user-programmable air filter change reminder; this counts the accumulated run-time of the heating/cooling system and reminds the user when it is time to change the filter. The feature often displays the accumulated run-time either as an aggregate of both heating and cooling or displaying each time separately.\n\nSome digital thermostats have the capability of being programmed using a touch-tone telephone or over the Internet, such as the Nest Learning Thermostat.\n\nDigital thermostats are usually powered one of three ways:\n\nMore expensive models have a built-in PID controller, so that the thermostat learns how the system will react to its commands. Programming the morning temperature to be 21° C at 7:00 AM, for instance, makes sure that at that time the temperature will be 21 °C. A standard programmable thermostat would simply start working toward 21° at 7:00 AM. The PID controller decides at what time the system should be activated in order to reach the desired temperature at the desired time. It knows this by remembering the past behavior of the room, and the current temperature of the room. This is called optimal start.\n\nProcess control or industrial thermostat also makes sure that the temperature is very stable(for instance, by reducing first overshoot and fluctuation at the end of the heating cycle) so that the comfort level is increased.\n\nIn commercial applications, the thermostat may not contain any clock mechanism. Instead, another means may be used to select between the \"hotter\" and \"colder\" settings. For example, if the thermostat uses pneumatic controls, a change in the air pressure supplied to the thermostat may select between the \"hotter\" and \"colder\" settings, and this air pressure is determined by a central regulator. With electronic controls, a specific signal may indicate whether to operate at the \"hotter\" or \"colder\" setting.\n\n\n"}
{"id": "11274652", "url": "https://en.wikipedia.org/wiki?curid=11274652", "title": "Relationship Management Application", "text": "Relationship Management Application\n\nRelationship Management Application (RMA) is a service provided by SWIFT to manage the business relationships between financial institutions.\n\nRMA operates by managing which message types are permitted to be exchanged between users of a SWIFT service:\n\nRMA uses a SWIFTNet InterAct Store and Forward service to exchange the permission data between financial institutions.\n\nRMA was initially scheduled for roll-out on the SWIFT FIN service as part of the SWIFTNet Phase 2 project in 2008.\n"}
{"id": "55613190", "url": "https://en.wikipedia.org/wiki?curid=55613190", "title": "Scotlandite", "text": "Scotlandite\n\nScotlandite is a sulfite mineral first discovered in a mine at Leadhills in South Lanarkshire, Scotland, an area known to mineralogists and geologists for its wide range of different mineral species found in the veins that lie deep in the mine shafts. This specific mineral is found in the Susanna vein of Leadhills, where the crystals are formed as chisel-shaped or bladed. Scotlandite was actually the first naturally occurring sulfite, which has the ideal chemical formula of PbSO. The mineral has been approved by the Commission on New Minerals and Mineral Names, IMA, to be named scotlandite for Scotland.\n\nScotlandite is found in association with pyromorphite, anglesite, lanarkite, leadhillite, susannite, and barite. It occurs in cavities in massive barite and anglesite, and is closely associated with lanarkite and susannite. Scotlandite represents the latest phase in the crystallization sequence of the associated lead secondary minerals. It can often be found in the vuggy anglesite as yellowish single crystals up to 1 millimeter in length that sometimes arrange in a fan-shaped aggregates. Anglesite can usually be recognized in a very thin coating on scotlandite which is used to protect the sulfite from further oxidation. A second variety of scotlandite can also occur in discontinuously distributed cavities between the anglesite mass containing the first variety and the barite matrix. This variety is characterized by tiny, whitish to water-clear crystals, and crystal clusters less than one millimeter in size, which encrust large portions of the interior of the cavities. Scotlandite is a uniquely rare mineral, as it occurs in small amounts in few locations around the world.\n\nScotlandite is a pale yellow, greyish-white, colorless, transparent mineral with an adamantine or pearly luster. It exhibits a hardness of 2 on the Mohs hardness scale. Scotlandite occurs as chisel-shaped or bladed crystals elongated along the c-axis, with a tendency to form radiating clusters. Its crystals are characterized by the {100}, {010}, {011}, {021}, {031}, and {032}. faces. Scotlandite shows perfect cleavage along the {100} plane and a less good one along the {010} plane. The measured density is 6.37 g/cm.\n\nScotlandite is biaxial positive, which means it will refract light along two axes. The mineral is optically biaxial positive, 2V 35° 24'(Na). The refractive indices are: α ~ 2.035, β ~ 2.040, and γ ~ 2.085 (Na). Dispersion is strong, v » r. The extinction is β//b, and α [001] = 20° (γ [100] = 4° in the obtuse angle β. H(Mohs) < 2. D = 6.37 and calculated D = 6.40 g cm. The infrared spectrum of scotlandite shows conclusively that it is an anhydrous sulfite, with no OH groups or other polyatomic anions being present. It is also proven by electron microprobe analysis and infrared spectroscopy that scotlandite must be a polymorph of lead sulfite.\n\nScotlandite is a sulfite compared with chemically related compounds, it is very close to the value of anglesite (6.38 g cm), but distinctly different from that of lanarkite (6.92 g cm). Orthorhombic lead sulfite is of higher density (D = 6.54, calculated D = 6.56 g cm), and has the same chemical properties as well. The empirical chemical formula for scotlandite calculated on the basis of Pb+S = 2, is PbSO or more ideally PbSO.\n\nA small crystal of scotlandite, showing some cleavage faces, was examined using Weissenberg and precession techniques. Scotlandite is in the monoclinic crystal system. The only systematic extinctions observed from the single crystal patterns were 0k0 where k was odd. Thus the possible space group is either P2 or P2/m. The unit cell parameters obtained from the single crystal study were used to index the X-ray powder pattern and were then refined with the indexed powder data. The results are: a = 4.505 Å, b = 5.333 Å, c = 6.405 Å; β= 106.24°; Z = 2. If the present a and c axes are interchanged, the unit cell of scotlandite is very similar, isotypic, to that of molybdomenite, PbSeO. Lead is coordinated to nine oxygen atoms with Pb-O=2.75 Å, and possibly further to one sulfur atom with Pb−S=3.46 Å. The average S−O distance in the pyramidal SO group is 1.52 Å.\n\nList of Minerals\n"}
{"id": "43346433", "url": "https://en.wikipedia.org/wiki?curid=43346433", "title": "Soleus Running", "text": "Soleus Running\n\nSoleus Running is a watch company that produces timing devices such as watches and cycling computers that use GPS and heart rate monitors. Its headquarters are located in Austin, Texas.\n\nSoleus Running gets its name from the muscle located in the back part of the lower leg called the soleus. It begins right below the knee and runs down to the heel, and is involved in standing, walking and running. If not for the soleus, the body would fall forward.\n\nSoleus Running sells a variety of devices ranging in style, features and price. Some of the watches have the ability to track an activity using GPS or a heart rate monitor. \n\nAs of July 2014, the watches for sale on its website are:\n\nRunning:\nGPS:\nCycling:\n\nOn the website, other items besides watches can be bought such as heart rate monitors, hats and headbands.\n\n"}
{"id": "10831708", "url": "https://en.wikipedia.org/wiki?curid=10831708", "title": "Spinosad", "text": "Spinosad\n\nSpinosad is an insecticide based on chemical compounds found in the bacterial species \"Saccharopolyspora spinosa\". The genus \"Saccharopolyspora\" was discovered in 1985 in isolates from crushed sugarcane which produce yellowish-pink aerial hyphae, with bead-like chains of spores enclosed in a characteristic hairy sheath. This genus is defined as aerobic, Gram-positive, nonacid-fast actinomycetes with fragmenting substrate mycelium. \"S. spinosa\" was isolated from soil collected inside a nonoperational sugar mill rum still in the Virgin Islands. Spinosad is a mixture of chemical compounds in the spinosyn family that has a generalized structure consisting of a unique tetracyclic ring system attached to an amino sugar (-forosamine) and a neutral sugar (tri-\"Ο\"-methyl--rhamnose). Spinosad is relatively nonpolar and not easily dissolved in water.\n\nSpinosad is a novel mode-of-action insecticide derived from a family of natural products obtained by fermentation of \"S. spinosa\". Spinosyns occur in over 20 natural forms, and over 200 synthetic forms (spinosoids) have been produced in the lab. Spinosad contains a mix of two spinosoids, spinosyn A, the major component, and spinosyn D (the minor component), in a roughly 17:3 ratio.\n\nSpinosad is highly active, by both contact and ingestion, in numerous insect species. Its overall protective effect varies with insect species and life stage. It affects certain species only in the adult stage, but can affect other species at more than one life stage. The species subject to very high rates of mortality as larvae, but not as adults, may gradually be controlled through sustained larval mortality. The mode of action of spinosoid insecticides is by a neural mechanism. The spinosyns and spinosoids have a novel mode of action, primarily targeting binding sites on nicotinic acetylcholine receptors (nAChRs) of the insect nervous system that are distinct from those at which other insecticides have their activity. Spinosoid binding leads to disruption of acetylcholine neurotransmission. Spinosad also has secondary effects as a γ-amino-butyric acid (GABA) neurotransmitter agonist. It kills insects by hyperexcitation of the insect nervous system. Spinosad so far has proven not to cause cross-resistance to any other known insecticide.\n\nSpinosad has been used around the world for the control of a variety of insect pests, including Lepidoptera, Diptera, Thysanoptera, Coleoptera, Orthoptera, and Hymenoptera, and many others. It was first registered as a pesticide in the United States for use on crops in 1997. Its labeled use rate is set at 1 ppm (1 mg a.i./kg of grain) and its maximum residue limit (MRL) or tolerance is set at 1.5 ppm. Spinosad’s widespread commercial launch was deferred, awaiting final MRL or tolerance approvals in a few remaining grain-importing countries. It is considered a natural product, thus is approved for use in organic agriculture by numerous nations. Two other uses for spinosad are for pets and humans. Spinosad has recently been used in oral preparations (as Comfortis) to treat \"C. felis\", the cat flea, in canines and felines; the optimal dose set for canines is reported to be 30 mg/kg.\n\nTrade names include Comfortis and Trifexis (which also includes milbemycin oxime) (both brands treat adult fleas on pets; the latter also prevents heartworm disease), and Natroba (for human head lice). It is commonly used to kill thrips.\n\nSpinosyn A does not appear to interact directly with known insecticidal-relevant target sites, but rather acts via a novel mechanism. Spinosyn A resembles a GABA antagonist and is comparable to the effect of avermectin on insect neurons. Spinosyn A is highly active against neonate larvae of the tobacco budworm, \"Heliothis virescens\", and is slightly more biologically active than spinosyn D. In general, spinosyns possessing a methyl group at C6 (spinosyn D-related analogs) tend to be more active and less affected by changes in the rest of the molecule. Spinosyn A is slow to penetrate to the internal fluids of larvae; it is also poorly metabolized once it enters the insect. The apparent lack of spinosyn A metabolism may contribute to its high level of activity, and may compensate for the slow rate of penetration.\n\nSpinosad has high efficacy, a broad insect pest spectrum, low mammalian toxicity, and a good environmental profile, a unique feature of the insecticide compared to others currently used for the protection of grain products. It is regarded as natural product-based, and approved for use in organic agriculture by numerous national and international certifications. Spinosad residues are highly stable on grains stored in bins, with protection ranging from 6 months to 2 years.\nEcotoxicology parameters have been reported for spinosad, and are:\n\nChronic exposure studies failed to induce tumor formation in rats and mice; mice given up to 51 mg/kg/day for 18 months resulted in no tumor formation. Similarly, administration of 25 mg/kg/day to rats for 24 months did not result in tumor formation.\n"}
{"id": "57819", "url": "https://en.wikipedia.org/wiki?curid=57819", "title": "The Open Group", "text": "The Open Group\n\nThe Open Group is an industry consortium that seeks to \"enable the achievement of business objectives\" by developing \"open, vendor-neutral technology standards and certifications\". It has over 625 members and provides a number of services, including strategy, management, innovation and research, standards, certification, and test development. It was established in 1996 when X/Open merged with the Open Software Foundation.\n\nThe Open Group is the certifying body for the UNIX trademark, and publishes the Single UNIX Specification technical standard, which extends the POSIX standards. The Open Group also develops and manages the TOGAF standard, which is an industry standard enterprise architecture framework.\n\nThe over 625 members include a range of IT buyers and vendors as well as government agencies, including, for example, Capgemini, Fujitsu, Oracle, HPE, Orbus Software, IBM, Huawei, Philips, U.S. Department of Defense, NASA.\n\nBy the early 1990s, the major UNIX system vendors had begun to realize that the standards rivalries (often called the \"Unix wars\") were causing all participants more harm than good, leaving the UNIX industry open to emerging competition from Microsoft. The COSE initiative in 1993 can be considered to be the first unification step and the merger of the Open Software Foundation (OSF) and X/Open in 1996 as the ultimate step in the end of those skirmishes. OSF had previously merged with UNIX International in 1994, meaning that the new entity effectively represented all elements of the Unix community of the time.\n\nIn January 1997, the responsibility for the X Window System was transferred to The Open Group from the defunct X Consortium. In 1999, X.Org was formed to manage the X Window System, with management services provided by The Open Group. The X.Org members made a number of releases up to and including X11R6.8 while The Open Group provided management services. In 2004, X.Org and The Open Group worked together to establish the newly formed X.Org Foundation who then took control of the x.org domain name, and the stewardship of the X Window System. (See the history of the X Window System.)\n\nThe Open Group's best-known services are their certification programs, including certification for products and best practices: POSIX, North American State Lotteries Association (NASPL), and UNIX.\n\nThe Open Group offers certifications for IT professionals. In addition to TOGAF certification which covers tools, services and people certification, The Open Group also administers the Open Group Certified Architect (Open CA) program and the Open Group Certified IT Specialist (Open CITS) certification program; the latter are skills and experience based certification programs.\nThe Open Group also offers certification for ArchiMate tools and people, as well as people certification for Open FAIR and IT4IT.\n\nThe Open Group provides a platform for its members to discuss their requirements, and work jointly on development and adoption of industry standards, to facilitate enterprise integration. (Note: Some of The Open Group documents are only available to members, especially when they are under development.) Based on their area of interest, members can join one or more semi-autonomous forums, which include:\nMembers come together at The Open Group's quarterly events and member meetings.\n\nThe Open Group also provides a range of services, from initial setup and ongoing operational support to collaboration, standards and best practices development, and assistance with market impact activities. They assist organizations with setting business objectives, strategy and procurement, and also provide certification and test development. This includes services to the government agencies, suppliers, and companies or organizations set up by governments.\n\n\n"}
{"id": "39351592", "url": "https://en.wikipedia.org/wiki?curid=39351592", "title": "Thermal work limit", "text": "Thermal work limit\n\nThermal Work Limit (TWL) is defined as the limiting (or maximum) sustainable metabolic rate that well-hydrated, acclimatized individuals can maintain in a specific thermal environment, within a safe deep body core temperature (< ) and sweat rate (<  per hour). The index is designed for self-paced workers and does not rely on estimation of actual metabolic rates, a process that is difficult and subject to considerable error. The index has been introduced into the United Arab Emirates and Australia, resulting in a substantial and sustained fall in the incidence of heat illness in the latter.\n\nThe idea of a thermal work limit (TWL) was developed by Dr. Graham Bates and Dr. Derrick Brake in 1997. Over the past 80 years, many heat stress indices have been developed to assist with the management of heat stress problems. Some of these have been developed for particular industries and empirically derived such as ISO 7933 and WBGT. These indices required estimation of metabolic rate but failed to consider the direct measurement of wind speed, reduction of work rate, location and time shift during work and removal of clothing, making these indices not accurate for self-paced and acclimatized workers.\nThe need for a heat stress index designed primarily for self-paced workers has led to the development of the thermal work limit (TWL). TWL and its accompanying management protocols have been introduced into several industrial operations where workers are subject to thermal stress. Approximately 1400 persons work in these locations with over 10 million man-shifts being worked between 1965 and 1995 at wet bulb temperatures in excess of . Since the introduction of TWL-based policies in the Australian mining industry, the amount of man-hours lost due to serious heat illness has fallen from 12 million to 6 million, and the amount lost due to all heat illness incidences has fallen from 31 million to 18 million.\n\nThe basic purpose of the thermal work limit index is to calculate the maximum metabolic rate, in watts of metabolic heat per square meter of body surface area, that can be continuously expended in a particular thermal environment, in order to keep the body within safe physiological limits. The TWL is an integrated measure of the dry bulb, wet bulb, wind speed and radiant heat. From these variables, and taking into consideration the type of clothing worn and acclimatization state of the worker, the TWL predicts the maximum level of work that can be carried out in a given environment, without workers exceeding a safe core body temperature and sweat rate. In excessively hot conditions, the index can also determine the safe work duration, thus providing guidelines for work/rest cycling. Sweat rates are also calculated, so the level of fluid replacement necessary to avoid dehydration can be established.\nThe thermal work limit algorithm builds on work originated by Mitchell and Whillier, who developed an index “specific cooling power,” which subsequently became known as “air cooling power” (ACP). \nTo determine TWL the following must be measured:\nThe thermal environment can be classified on the basis of TWL into the working zones shown in the adjacent image.\n\nThe TWL heat stress index is the heat stress index that has been included in the Abu Dhabi EHSMS code of practice for the management of Heat Stress. TWL gives a measure of the maximum safe work rate for the environmental conditions present at a worksite. If TWL is too low then even low rates of work cannot safely be carried out continuously and extra rest breaks and other precautions are needed to ensure worker safety.\n\n"}
{"id": "1616551", "url": "https://en.wikipedia.org/wiki?curid=1616551", "title": "Thermo Electron", "text": "Thermo Electron\n\nThermo Electron Corporation (NYSE: TMO) (incorporated 1956) was a major provider of analytical instruments and services for a variety of domains. It was co-founded in 1956 by George N. Hatsopoulos, an MIT PhD in mechanical engineering, and Peter M. Nomikos, a Harvard Business School graduate.\n\nAfter graduating from Northeastern University in 1959 John Hatsopoulos (brother of George) joined the company as CFO. Arvin Smith joined the company in 1970, and was President from January 1998.\n\nIn 2011, Thermo Fisher Scientific, its successor, had revenues of over $11 billion, and employed 37,000 people.\n\nOn May 14, 2006, Thermo and Fisher Scientific announced that they would merge in a tax-free, stock-for-stock exchange. The merged company became Thermo Fisher Scientific. On November 9, 2006, the companies announced that the merger had been completed. However, the Federal Trade Commission ruled that this acquisition was anticompetitive with regard to centrifugal evaporators, requiring Fisher to divest Genevac. In April 2007, Genevac was sold to Riverlake Partners LLC and the merger closed with FTC approval.\n\n\n"}
{"id": "4039958", "url": "https://en.wikipedia.org/wiki?curid=4039958", "title": "Thlaspi caerulescens", "text": "Thlaspi caerulescens\n\nThlaspi caerulescens, Alpine Penny-cress and also known as alpine pennygrass, is a flowering plant in the family Brassicaceae. It is found in Scandinavia and Europe.\n\n\"Thlaspi caerulescens\" is a low biennial or perennial plant that has small basal rosettes of stalked elliptic–lanceolate leaves with entire margins. The one or more flowering stems have small stalkless, alternate leaves clasping the stem. The inflorescence is a dense raceme which continues to lengthen after flowering. The individual flowers are regular, with white or pinkish petals and are about wide. Each has four sepals, four petals, six stamens (four long and two short) with violet anthers, and a single carpel. The fruit is many-seeded and narrowly spatulate and has a notched tip. This plant flowers in late spring.\n\nIn Europe it is found in Finland and Sweden, in all but the most northerly regions. It is also found in the Alps, the Massif Central, the Pyrenees, eastern Norway, southern Germany, and northern England. It is a plant of dry hillside meadows, forest margins, banks, gardens, lawns, pastures, field margins, yards and bare places.\n\nAlpine pennycress has been cited in phytoremediation to have special phytoextractional properties and is known to absorb cadmium with very good results and in certain instances is said to have absorbed zinc as well.\n"}
{"id": "29153686", "url": "https://en.wikipedia.org/wiki?curid=29153686", "title": "Three-way hybrid", "text": "Three-way hybrid\n\nA three-way hybrid set-top box is a hybrid device typically used by Pay TV operators and Telecommunications service providers to converge content delivered via three different video transport networks – satellite, terrestrial and IP [managed or public Internet]. Three-way Hybrid [or tribrid] Set-Top Boxes enable consumers to navigate between a wide range of content quickly and intuitively, and view it all on the main household TV set.\n\nOne of the first operators to deploy a tribrid platform is ITI Neovision's n in Poland, which rolled out their Turbo Dekoder HD in December 2009 using Advanced Digital Broadcast's ADB-5720SX. The n deployment won the 2010 IP TV World Forum award for Best Interactive TV service and \"best in show\" awards.\n\n"}
{"id": "19550534", "url": "https://en.wikipedia.org/wiki?curid=19550534", "title": "Toy program", "text": "Toy program\n\nA toy program is a small computer program typically used for educational purposes. Toy programs are generally of little practical use, although the concepts implemented may be useful in a much more sophisticated program.\n\nA toy program typically focuses on a specific problem, such as computing the Nth term in a sequence, finding the roots of a quadratic equation and testing if a number is prime.\n\nToy programs are also used for a developer trying out a new programming language, to test all of the language's syntax and coding methods.\n\nyou can begin learning any new programming language by writing a toy programme."}
{"id": "38100144", "url": "https://en.wikipedia.org/wiki?curid=38100144", "title": "Transit metropolis", "text": "Transit metropolis\n\nA Transit metropolis is an urbanized region with high-quality public transportation services and settlement patterns that are conducive to riding public transit. While Transit villages and Transit-oriented developments (TODs) focus on creating compact, mixed-use neighborhoods around rail stations, transit metropolises represent a regional constellation of TODs that benefit from having both trip origins and destinations oriented to public transport stations. In an effort to reduce mounting traffic congestion problems and improve environmental conditions, a number of Chinese mega-cities, including Beijing and Shenzhen, have embraced the transit metropolis model for guiding urban growth and public-transport investment decisions.\n\nAround the world, mass transit have been struggling to compete with private automobile and in many places its market is eroding. Transit metropolis and TOD are among the planning strategies being introduced to help reserve ridership losses and advance more sustainable patterns of urban development.\n\nTransit metropolises recognize that one or two TODs as islands in a sea of automobile-oriented development (AOD) will do little to get people out of cars and into trains and buses. Only when TODs are organized along linear corridors, as in Stockholm, Copenhagen and Curitiba , or inter-connected by high-capacity transit at a regional scale can they significantly reduce car-dependence and improve environmental conditions. \n\n"}
{"id": "50428178", "url": "https://en.wikipedia.org/wiki?curid=50428178", "title": "Ultraviolet thermal processing", "text": "Ultraviolet thermal processing\n\nUltraviolet thermal processing or UVTP is the name given to the process of using ultraviolet light to stabilize dielectric films used to insulate semiconductors.\n\nSemiconductor films need low dielectric constants (k-values) for optimal thermal conductivity, to ensure semiconductor scaling. Newer dielectric films used to insulate modern chips can be easily damaged, causing them to lose their insulating capacity. Specialized treatments applied with ultraviolet light improve chip performance. Tungsten halogen lamps are the sources used for traditional rapid thermal processing.\n"}
{"id": "56264802", "url": "https://en.wikipedia.org/wiki?curid=56264802", "title": "Unmanned aircraft system traffic management", "text": "Unmanned aircraft system traffic management\n\nUnmanned aircraft system traffic management (UTM) is an air traffic management ecosystem under development for autonomously controlled operations of unmanned aerial systems (UAS) by the FAA, NASA, other federal partner agencies, and industry. They are collaboratively exploring concepts of operation, data exchange requirements, and a supporting framework to enable multiple UAS operations beyond visual line-of-sight at altitudes under 400 ft above ground level in airspace where FAA air traffic services are not provided.\n\nUTM is separate from but complementary to the FAA's Air Traffic Management (ATM) system. UTM development will ultimately identify services, roles/responsibilities, information architecture, data exchange protocols, software functions, infrastructure, and performance requirements for enabling the management of low-altitude uncontrolled UAS operations.\n\nA Research Transition Team (RTT) has been established between the FAA, NASA and industry to coordinate the UTM initiative. Areas of focus include concept and use case development, data exchange and information architecture, communications and navigation, and sense and avoid. Research and testing will identify airspace operations requirements to enable safe visual and beyond visual line-of-sight UAS flights in low-altitude airspace. FAA published a UAS Traffic Management Research Plan in 2017.\n"}
{"id": "12712443", "url": "https://en.wikipedia.org/wiki?curid=12712443", "title": "W64", "text": "W64\n\nThe W64 nuclear warhead was the Los Alamos Laboratory's entry into a brief competition between Lawrence Livermore Laboratory and Los Alamos to design an \"enhanced-radiation\" nuclear warhead (i.e., a \"neutron bomb\") for the United States Army's MGM-52 Lance tactical surface-to-surface missile. In July 1964, both Livermore Labs and Los Alamos started developing competing warheads for the Lance. The Los Alamos design, the W64, was canceled in September 1964 in favor of Livermore's W63. In November 1966, the W63 was canceled in favor of the W70, the model that finally entered production.\n"}
{"id": "36784431", "url": "https://en.wikipedia.org/wiki?curid=36784431", "title": "École nationale supérieure de création industrielle", "text": "École nationale supérieure de création industrielle\n\nENSCI–Les Ateliers, the École nationale supérieure de création industrielle, is a French design school located in the 11th arrondissement of Paris. As a public commercial and industrial establishment under authority of both the Ministry of Culture and the Ministry of Industry, it is the first and only French national institute exclusively devoted to the advanced studies in design. It is a member of the Hautes Études-Sorbonne-Arts et Métiers cluster and of the Conférence des grandes écoles.\n\nThe school was founded in 1982 under the sponsorship of Jean Prouvé and Charlotte Perriand, and have been established in the same building that once housed the \"Ateliers Saint-Sabin\" of the Maison Jansen, hence its name; its premises are open 24 hours a day and seven days a week, enabling students to work according to their own production schedules and patterns. It has been classed number one design school in the Americas & Europe region by the 2011 Red Dot Award: Design Concept ranking, and the best design school in France by the 2012 L'Étudiant ranking. It is also one of the 60 best design schools in the world according to the 2007 Businessweek D-Schools list.\n\nThe school offers five different programmes:\n\n\nENSCI–Les Ateliers is also one of the seven partner schools that deliver the Master of European Design degree.\n\n\n"}
