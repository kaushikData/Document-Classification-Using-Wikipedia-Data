{"id": "58272448", "url": "https://en.wikipedia.org/wiki?curid=58272448", "title": "2N696", "text": "2N696\n\nThe 2N696 and 2N697 were the first silicon transistors manufactured in Silicon Valley, in 1958, by Fairchild Semiconductor. Fairchild introduced itself to the world via its advertisements for these transistors, which were identical except for a post-manufacturing binning on current gain.\n\nThe 2N696/2N697 NPN mesa transistor was developed by a team led by Gordon Moore. The first batch of 100 was sold to IBM for $150 each () in order to build the computer for the B-70 bomber. More transistors were sold to Autonetics to build the guidance system for the Minuteman ballistic missile.\n\nThe 2N696 and 2N697 were popular devices, quickly copied by several other semiconductor companies, including Texas Instruments, Rheem Semiconductor, and others including Hoffman Electronics Corp. and Industro Transistor Corp. In a 1960 advertisement, Fairchild bragged, \"The Fairchild 2N696 and 2N697 are the world's most copied transistors. We have now copied them ourselves in scaled down versions. The 2N717 and 2N718 are exactly the same as these popular types but packaged in the TO-18 case. They occupy 1/3 the volume of the of the standard TO-5, making them ideal for high-density equipment designs.\"\n\n"}
{"id": "48580458", "url": "https://en.wikipedia.org/wiki?curid=48580458", "title": "Alexandra Chong", "text": "Alexandra Chong\n\nAlexandra Chong is a Jamaican businessperson. She was the founder & CEO of Lulu, a mobile app for dating intelligence. Business Insider and AdWeek have recognized her as one of the top entrepreneurs in New York. She launched Luluvise in 2011 and Lulu was released in the US by 2013. It was nominated as TechCrunch's 2013 \"Fastest Rising Startup\". Lulu was acquired in 2016 by Badoo where she is now an employee.\n\nChong was born in Jamaica to a Canadian mother and Chinese-Jamaican father, who won the lottery and started a successful tourism company with the money. She grew up in Ocho Rios. In the 1990s, she played tennis in the women-only Federation Cup. She attended Florida International University on a sports scholarship, and Florida served as one of the main sites for Lulu's launch in US. She's a former member of the Jamaica Fed Cup tennis team and has a law degree from the London School of Economics.\n\nAfter graduation, she worked in the legal department of a music licensing start-up. Before founding Lulu, Chong had a position in Upstream, a London-based mobile marketing firm.\n\nLulu has been covered by the New York Times, which wrote that Chong started a \"take back the internet movement for young women\". Her unique idea to bring the reputation economy into the world of online dating also gained coverage by international media, including People, TechCrunch, Fox News, CNN, The New Yorker, The Next Web, Wired UK, among others. She came up with the idea for the app while having lunch with friends and discussing the potential benefits of being able to rate a male friend using a suitable hashtag.\n\nIn February 2016, it was reported that Lulu was bought by Badoo, which is the biggest dating company in the world. Chong had known Badoo CEO Andrey Andreev since 2011, which is before Lulu had launched. Chong became Badoo's president as part of the deal and moved back to London. She departed Badoo in July 2016.\n\nChong married Jack Brockway, the nephew of British businessman Richard Branson, in June 2015 in Jamaica. Brockway is the brother of Ned Rocknroll.\n"}
{"id": "24446858", "url": "https://en.wikipedia.org/wiki?curid=24446858", "title": "Bioproducts", "text": "Bioproducts\n\nBioproducts or bio-based products are materials, chemicals and energy derived from renewable biological resources.\n\nBiological resources include agriculture, forestry, and biologically-derived waste, and there are many other renewable bioresource examples. One of the scientific terms used to denote renewable bioresources is lignocellulose. Lignocellulosic tissues are biologically-derived natural resources containing some of the main constituents of the natural world. 1) Holocellulose is the carbohydrate fraction of lignocellulose that includes cellulose, a common building block made of sugar (glucose) that is the most abundant biopolymer, as well as hemicellulose. 2) Lignin is the second most abundant biopolymer. Cellulose and lignin are two of the primary natural polymers used by plants to store energy as well as to give strength, as is the case in woody plant tissues. Other energy storage chemicals in plants include oils, waxes, fats, etc., and because these other plant compounds have distinct properties, they offer potential for a host of different bioproducts \n\nConventional bioproducts and emerging bioproducts are two broad categories used to categorize bioproducts.\nExamples of conventional bio-based products include building materials, pulp and paper, and forest products. Examples of emerging bioproducts or biobased products include biofuels, bioenergy, starch-based and cellulose-based ethanol, bio-based adhesives, biochemicals, bioplastics, etc. Emerging bioproducts are active subjects of research and development, and these efforts have developed significantly since the turn of the 20/21st century, in part driven by the price of traditional petroleum-based products, by the environmental impact of petroleum use, and by an interest in many countries to become independent from foreign sources of oil. Bioproducts derived from bioresources can replace much of the fuels, chemicals, plastics etc. that are currently derived from petroleum \n\nBioproducts engineering (also referred to as bioprocess engineering) refers to engineering of bio-products from renewable bioresources. This pertains to the design, development and implementation of processes, technologies for the sustainable manufacture of materials, chemicals and energy from renewable biological resources.\n\nAlso referred to as Bioprocess Engineering: Bioprocess Engineering is a specialization of Biotechnology, Chemical Engineering or Biological Engineering or of Agricultural Engineering. It deals with the design and development of equipment and processes for the manufacturing of products such as food, feed, pharmaceuticals, nutraceuticals, chemicals, and polymers and paper from biological materials. Bioprocees engineering is a conglomerate of mathematics, biology and industrial design, and consists of various spectrums like designing of Fermentors, study of fermentors (mode of operations etc.). It also deals with studying various biotechnological processes used in industries for large scale production of biological product for optimization of yield in the end product and the quality of end product. Bio process engineering may include the work of mechanical, electrical and industrial engineers to apply principles of their disciplines to processes based on using living cells or sub component of such cells \n\nAlso referred to as Bioresource Engineering: Bioresource engineering is related to the applications of biological engineering, chemical engineering and agricultural engineering usually based on biological and/or agricultural feedstocks. Bioresource engineering is more general and encompasses a wider range of technologies and various elements such as biomass, biological waste treatment, bioenergy, biotransformations and bioresource systems analysis, and technologies associated with Thermochemical conversion technologies: combustion, pyrolysis, gasification, catalysis, etc. Biochemical conversion technologies: aerobic methods, anaerobic digestion, microbial growth processes, enzymatic methods, composting Products: fibre, fuels, feedstocks, fertilisers, building materials, polymers and other industrial products Management: modelling, systems analysis, decisions, support systems. The impact of urbanization and increasing demand for land, food, and water presents engineers in a world with serious challenges. Little attention has been given to the interface between the biological world and traditional engineering in the past. It is the job of bioresource engineers to fill that gap. Agricultural and bioresource engineers develop efficient and environmentally-sensitive methods of producing food, fiber, timber, bio-based products and renewable energy sources for an ever-increasing world population.\n\n\n"}
{"id": "2058177", "url": "https://en.wikipedia.org/wiki?curid=2058177", "title": "Biotecnol", "text": "Biotecnol\n\nBiotecnol is an immune-oncology company focusing on the development of multifunctional antibodies for highly heterogeneous oncological situations. Biotecnol is developing oncological treatments for rare diseases such as triple-negative breast cancer, malignant mesothelioma, and other highly-aggressive and mutated cancer subtypes.\n\nStarted in 1996, Biotecnol operated as a consultancy company, providing consultancy services to Portuguese pharmaceutical companies, and also European biotech companies. In 2000, Biotecnol attracted its first investment and was able to begin independent activities. This allowed Biotecnol to develop into the first pharmaceutical biotech research & development-driven company in Portugal. In 2002, Biotecnol accomplished further financing, which allowed Biotecnol to transition to product development. The company's early administrative quarters were located in the TagusPark science park in Oeiras near Lisbon, Portugal, and the research and development facilities were located nearby. The company was funded through a mixture of private funding (72%) and Portuguese venture capital (28%). The company is headquartered in the United Kingdom and has its Research and Development laboratories in Oeiras Portugal.\n\nDuring Q1 2006, Biotecnol consolidated all its activities into the current facility at Lagoas Park in Portugal. Biotecnol has also established a wholly owned subsidiary, Biotecnol Inc, in Durham, North Carolina, USA in 2008. Today Biotecnol is headquartered in the United Kingdom and has its Research and Development Facilities in Portugal.\n\nIn addition to these activities, Biotecnol also co-founded the Portuguese Bio-Industries Association (APBio) in 1998 to promote the development of a biotechnological industry in Portugal. APBio is part of the European Bioindustries Association (EuropaBio), which represents over 600 European companies.\n\nIn 2013, Biotecnol created a spin-off company called Rodon Biologics to focus on therapeutic development for clients, while keeping the US branch of Biotecnol focused on the company's proprietary drug development.\n\nIn 2017, Biotecnol partnered with Cancer Research UK for clinical development of Biotecnol's first drug, Tb535H, which targets the 5T4/WAIF1 tumor antigen, and was developed with Biotecnol's antibody-based Trisoma platform.\n\nBiotecnol was founded by Dr Pedro de Noronha Pissarra and Dr Andrew Kelly. Dr Kelly's training included work as part of the European Community ECLAIR-funded project on commercially significant phytopathogenic fungi. After work on Escherichia coli at King's College, London, he helped create Biotecnol's research programmes. Dr de Noronha Pissarra has worked at numerous institutions, including King's College, London, the Massachusetts Institute of Technology, USA and the Centre for Biotechnology of the Technical University of Denmark, Lyngby.\n\n"}
{"id": "1565305", "url": "https://en.wikipedia.org/wiki?curid=1565305", "title": "Biscuit tin", "text": "Biscuit tin\n\nBiscuit tins are utilitarian or decorative containers used to package and sell biscuits (such as those served during tea) and some confectionery. They are commonly found in households in Great Britain, Ireland, and Commonwealth countries, but also on continental Europe and French Canada. Popularity in the United States and English Canada spread later in the 20th century.\n\nBecause of their attractive appearance, biscuit tins have often been used by charities and by some visitor attractions as fundraising devices since the value of the biscuits in a biscuit tin is substantially less than the price that many customers will happily pay for a tin of biscuits.\n\nBiscuit tins are steel cans made of tin plate. This consists of steel sheets thinly coated with tin. The sheets are then bent to shape. By about 1850, Great Britain had become the dominant world supplier of tin plate, through a combination of technical innovation and political control over most of the suppliers of tin ore. Biscuit tin manufacture was a small but prestigious part of the vast industry of tin plate production, which saw a huge increase in demand in the 19th century was directly related to the growing industrialisation of food production, by increasingly sophisticated methods of preservation and the requirements made by changing methods of distribution.\n\nThe British biscuit tin came about when the Licensed Grocer's Act of 1861 allowed groceries to be individually packaged and sold. Coinciding with the removal of the duty on paper for printed labels, printing directly on to tinplate became common. The new process of offset lithography, patented in 1877, allowed multicoloured designs to be printed on to exotically shaped tins.\nThe earliest decorated biscuit tin was commissioned in 1868 by Huntley & Palmers from the London firm of De La Rue to a design by Owen Jones. Early methods of printing included the transfer process (essentially the method used to decorate porcelain and pottery since about 1750) and the direct lithographic process, which involved laying an inked stone directly on to a sheet of tin. Its disadvantage was that correct colour registration was difficult. The breakthrough in decorative tin plate production was the invention of the offset lithographic process. It consists of bringing a sheet of rubber into contact with the decorated stone, and then setting-off the impression so obtained upon the metal surface. The advantages over previous methods of printing were that any number of colours could be used, correctly positioned, and applied to an uneven surface if necessary. Thus the elaborately embossed, colourful designs that were such a feature of the late Victorian biscuit tin industry became technically possible.\n\nThe most exotic designs were produced in the early years of the 20th century, just prior to the First World War. In the 1920s and 1930s, costs had risen substantially and the design of biscuit tins tended to be more conservative, with the exception of the tins targeted at the Christmas market and intended to appeal primarily to children. The designs generally reflected popular interests and tastes.\n\nThe advent of the Second World War stopped all production of decorative tin ware and after it ended in 1945, the custom did not enjoy the same popularity as before.\n\nVintage biscuit tins can be found in various museums and on the market have become collector items.\n\nBiscuit tins have always been more than just containers. The manufacturers aimed to make products which would be enjoyed beyond the life span of the biscuits themselves.\n\nTins shaped like actual objects began to be made in the late 1890s. The earlier tins were shaped like baskets but gradually a whole range of fine art objects appeared. Biscuit tins were no longer aimed merely at children at the Christmas market. They had become useful and decorative parts of the middle class home.\n\nReplicas of Chinese vases could be used as such when the biscuits had been eaten. Boxes imitating porcelain, Wedgwood china or fine wooden boxes mimicked the wonderful objects found in grand houses or in museums.\n\nThe First World War saw a break in the supply of decorated biscuit tins. Many manufacturers hesitated to resume production of \"fancy\" tins once the restrictions had been lifted. Children however had a strong influence on the market and ensured the survival of well designed, elaborately shaped tins.\n\nBritish biscuit manufacturers supplied grocer's shops with biscuits packed into large tins, typically containing seven pounds (3.2 kilogrammes). These would be displayed in the shop, and the shopkeeper would weigh out the required amount of biscuits into a paper bag for each customer. Some tins had a glass panel in the lid, so that customers could see the biscuits inside.\n\n"}
{"id": "1577335", "url": "https://en.wikipedia.org/wiki?curid=1577335", "title": "Borehole mining", "text": "Borehole mining\n\nBorehole Mining (BHM) is a remote operated method of extracting (mining) mineral resources through boreholes by means of high pressure water jets. This process can be carried-out from land surface, open pit floor, underground mine or floating platform or vessel through pre-drilled boreholes. \n\n\nThe tool consists of at least two concentric pipes which are forming two hydraulic channels - one for pumping down a high-pressure working agent (water) and second for delivering pregnant slurry back to the surface. A BHM tool usually has (down-up): an eductor (waterjet pump) section, a hydromonitor section, an extension section and a hub, connecting it all to a drill pipe string. This string extends the tool up to the surface. Above the surface, the tool has a swivel allowing its suspension and rotation in a hole, and also connections to the working agent supply (pump station) and a slurry collector. A drill rig is normally required to operate a BHM tool.\n\nThe tool is lowered into a well until the hydromonitor reaches the required depth where the actual borehole mining is started. Then the high-pressure water is pumped down and receives back productive slurry. In the collecting pond or tank, slurry is separated and clarified water is pumped down for re-circulating.\n\nWhile extracting of material, different shape underground caverns could be created. Their shapes depend on the BHM tool manipulation while mining, which obviously consist of the tool rotation, sliding it up and down and combination of these two movements. Borehole mining is applied from vertical, horizontal and deviated wells.\n\nThe main advantages of BHM include its low capital cost, mobility, selectivity, ability to work in hazardous and dangerous conditions and low environmental impact. The method has been used in mining of such natural resources and industrial materials as: uranium, iron ore, quartz sand, gravel, coal, poly-metallic ores, phosphate, gold, diamonds, rare earths, amber and several more. Borehole mining is also used in exploration, oil, gas and water stimulation, underground storage construction and drainage.\n\nOr is a remote control mining\n\n"}
{"id": "27305835", "url": "https://en.wikipedia.org/wiki?curid=27305835", "title": "Cameron ram-type blowout preventer", "text": "Cameron ram-type blowout preventer\n\nThe Cameron ram-type blowout preventer was the first successful blowout preventer (BOP) for oil wells. It was developed by James S. Abercrombie and Harry S. Cameron in 1922. The device was issued on January 12, 1926. The blowout preventer was designated as a Mechanical Engineering Landmark in 2003.\n\nWhile drilling an oil or gas well, the top of the wellbore is lined with a casing. The drill string runs through the casing. The annular (ring-shaped) region between the casing and the drill stem is filled with drilling mud which provides hydrostatic pressure to keep the formation fluid from coming up the wellbore. If the pressure of the formation fluid exceeds the hydrostatic pressure of the drilling mud, the oil or gas can blow out of the wellbore. This has caused spills of large quantities of oil and fires on drilling rigs. The blowout of the Lucas well at the Spindletop field in 1901 lasted for over nine days and spilled over of oil.\n\nJames Smither Abercrombie (1891–1975), a Texas oil driller, and Harry S. Cameron (1872–1928), who operated a machine shop, formed the Cameron Iron Works in 1920. \nAbercrombie had an idea for a blowout preventer and took it to Cameron. They designed and built the device at the Cameron Iron works. This resulted in the first ram-type blowout preventer, which they called the MO BOP.\n\nCameron Iron Works successfully marketed their blowout preventer and developed other tools for petroleum exploration. In 1990, Cooper Industries acquired the company. Cooper's petroleum divisions were transferred into the Cooper Cameron Corporation. This company is now called Cameron International Corporation.\n\nThe blowout preventer is a T-shaped coupling that is screwed onto the top of the casing. It has a passage through the coupling for the drill string. There is a ram with a concave, semi-circular face in each arm of the tee. Each ram is moved in or out by turning its valve stem, which extends beyond the coupling. The ends of the stems are squared off.\n\nWhen the rams are retracted, there is a passage for the drilling mud. If a blowout begins, the drill string is stopped. Then wrenches are used to manually close the rams around the drill string to seal the wellbore. The MO BOP was tested to withstand .\n\nThe device had a lateral valve below the rams on its bottom section. In case of a blowout, a mud pump could be used to pump drilling mud into the wellbore to control the blowout.\n"}
{"id": "25412598", "url": "https://en.wikipedia.org/wiki?curid=25412598", "title": "Carey Foster bridge", "text": "Carey Foster bridge\n\nIn electronics, the Carey Foster bridge is a bridge circuit used to measure medium resistances, or to measure small differences between two large resistances. It was invented by Carey Foster as a variant on the Wheatstone bridge. He first described it in his 1872 paper \"On a Modified Form of Wheatstone's Bridge, and Methods of Measuring Small Resistances\" (\"Telegraph Engineer's Journal\", 1872–1873, 1, 196).\n\nIn the adjacent diagram, X and Y are resistances to be compared. P and Q are nearly equal resistances, forming the other half of the bridge. The bridge wire EF has a jockey contact D placed along it and is slid until the galvanometer G measures zero. The thick-bordered areas are thick copper busbars of almost zero resistance.\n\n\nTo measure a low unknown resistance \"X\", replace \"Y\" with a copper busbar that can be assumed to be of zero resistance.\n\nIn practical use, when the bridge is unbalanced, the galvanometer is shunted with a low resistance to avoid burning it out. It is only used at full sensitivity when the anticipated \nmeasurement is close to the null point.\n\nTo measure the unit resistance of the bridge wire EF, put a known resistance (e.g., a standard 1 ohm resistance) that is less than that of the wire as X, and a copper busbar of assumed zero resistance as Y.\n\nTwo resistances to be compared, X and Y, are connected in series with the bridge wire. Thus, considered as a Wheatstone bridge, the two resistances are X plus a length of bridge wire, and Y plus the remaining bridge wire. The two remaining arms are the nearly equal resistances P and Q, connected in the inner gaps of the bridge.\nLet be the null point D on the bridge wire EF in percent. is the unknown left-side extra resistance EX and is the unknown right-side extra resistance FY, and is the resistance per percent length of the bridge wire:\n\nand add 1 to each side:\n\nNow swap X and Y. is the new null point reading in percent:\n\nand add 1 to each side:\n\nEquations 1 and 2 have the same left-hand side and the same numerator on the right-hand side, meaning the denominator on the right-hand side must also be equal:\n\nThus: the difference between X and Y is the resistance of the bridge wire between and .\n\nThe bridge is most sensitive when P, Q, X and Y are all of comparable magnitude.\n\n"}
{"id": "22049784", "url": "https://en.wikipedia.org/wiki?curid=22049784", "title": "Cell Signaling Technology", "text": "Cell Signaling Technology\n\nCell Signaling Technology, Inc. (CST) is a privately held company that develops and produces antibodies, ELISA kits, ChIP kits, proteomic kits, and other related regents used to study the cell signaling pathways that impact human health. CST maintains an in-house research program, particularly in the area of cancer research, and has published scientific papers in many peer-reviewed journals.\n\nCell Signaling Technology, Inc. (CST) was founded in 1999 by scientists in the Cell Signaling group at New England Biolabs (NEB).\n\nOriginally housed in the Cummings Center (Beverly, Massachusetts), CST moved to its current United States headquarters located at the former King’s Grant Inn (Danvers, Massachusetts) in late 2005. Following extensive renovation, the U.S. Green Building Council has certified the current headquarters as a LEED (Leadership in Energy and Environmental Design) certified facility in 2007. In 2008 and 2009, CST expanded its overseas operations, establishing subsidiary offices in the People’s Republic of China, Japan, and the Netherlands.\n\nIn 2013, CST moved its production group into an ISO9001 certified facility in Beverly, Massachusetts.\n\nCell Signaling Technology, Inc. (CST) was named as one of the “Top 100 Places to Work” in a 2009-2013 survey published by the Boston Globe.\n\nIn addition to product development and production, CST is also involved in the development of new technologies for signaling analysis as well as mechanistic cell biology research, particularly in the field of cancer research. CST scientists publish their findings in peer-reviewed journals, including Nature Cell Biology, Cell, Molecular and Cellular Biology, and Journal of Biological Chemistry.\n\nCST curates and maintains PhosphoSitePlus, a web-based bioinformatics resource that details post-translational modifications (PTMs) in human, mouse and rat proteins. The types of PTMs curated include phosphorylation, acetylation, methylation, ubiquitylation, glycosylation, etc. This freely accessible, online resource is funded in part through grant support from the NIH, and most recently through the NIH BD2K initiative.\n\n"}
{"id": "2435490", "url": "https://en.wikipedia.org/wiki?curid=2435490", "title": "Color print film", "text": "Color print film\n\nColor prints have been developed since their beginnings in 1935 with Eastman Kodak’s Company’s Kodachrome film, as well in 1936 with Agfa Company’s Agfacolor film. Color print film is the most common type of photographic film in consumer use. Print film produces a negative image when it is developed, requiring it to be reversed again when it is printed onto photographic paper.\n\nAlmost all color print film made today is designed to be processed according to the C-41 process.\n\nColor negatives are prone to damage through fingerprints and tears, therefore it is a good idea to wear nylon or cotton gloves when handling them and placing them in negative sleeves. Avoid bending, folding or rolling up your negatives sleeves as well.\n\nGenerally, color prints are more sensitive to temperature and light as opposed to black and white film, therefore there are more precautions to take when trying to protect and optimize the lifespan of them.\n\nIt is important to keep the prints protected from physical damage from as little as a fingerprint to as much as scratches that can destroy them completely. Storage for prints that are developed from color print film should be free of any unsafe, harmful chemicals, specifically referring to peroxides, sulfur dioxide, ozone and nitrogen oxides. For the best prolonged storage and protection, placing the prints in polyester uncoated sleeves and then into an envelope seals it from further damage. When it comes to storing them, the optimal temperature would be at 2 °C, as it is found to be the most effective preservation temperature when it comes to a mass collection of colored photographic film prints. It is best to keep the color prints away from strong sunlight exposure for prolonged periods of time because it may result in the decay of the gelatin layer as well as a significant fade in the dye found in the print. Similar to that of watercolors and textiles, dyes in color prints are prone to fade as well when exposed to too much light. However it is to be noted that color photographs are susceptible to build stains if stored in dark fully for prolonged periods of time as well, for example, an area of white in a photograph can change into yellow. Therefore, it is key to not store them in an area where they are exposed to long periods of light and/or long periods of dark, there should be a balance. Prime examples of places to store the color prints are: durable binders, cabinets, trays or rigid boxes.\n\nIf there is a chance that the prints got dirty, there are several effective methods that can be undertaken to clean them carefully without damaging them. First off is using a soft brush that can remove surface dirt on the print. Make sure to lightly brush the dirt off of the print. Damping cotton swabs or using a specialized cleaning pad to dry wipe the surface of the print is also another method to clean it. Remember to never wash photographs until the gelatin layer is dry and stables. Furthermore, never attempt chemical treatments on color photographs because they can get distorted and destroy the image as a whole.\n"}
{"id": "52458933", "url": "https://en.wikipedia.org/wiki?curid=52458933", "title": "Computer Aided Transceiver", "text": "Computer Aided Transceiver\n\nA computer aided transceiver (CAT) is a device used by radio amateurs for controlling a transceiver radio receiver using a computer.\n\nConventional transmitters are manually controlled and used to transmit voice using buttons, dials, etc. However, advances in electronics have come to market devices that can be controlled by a computer and allowing digital modes such as packet radio and also the use of satellite tracking, because it can continuously change the device's frequency according to the Doppler effect.\n\n"}
{"id": "12234994", "url": "https://en.wikipedia.org/wiki?curid=12234994", "title": "Continuous flight augering", "text": "Continuous flight augering\n\nContinuous flight augering (CFA), also known as auger cast piling, is a technique used in construction to create a concrete deep foundation.\n\nContinuous flight auger has been used in the United Kingdom since 1966, but its use is relatively new in the United States. A continuous flight auger drill is used to excavate a hole and concrete is injected through a hollow shaft under pressure as the auger is extracted. Reinforcement is then inserted after the auger is removed. This creates a continuous pile without ever leaving an open hole.\n\nContinuous flight augering can be used to construct a secant piled wall which can be used as a retaining wall or as shoring during excavation. Once initial piles are set with concrete, other shafts are augured between them, slicing into the original piles, with the new ones receiving rebar. The finished result is a continuous wall of reinforced concrete that aids and protects workers during excavation.\n"}
{"id": "1920803", "url": "https://en.wikipedia.org/wiki?curid=1920803", "title": "Contraflexure", "text": "Contraflexure\n\nIn a bending beam, a point is known as a point of contraflexure if it is a location at which no bending occurs (where bending moment changes its sign). In a bending moment diagram, it is the point at which the bending moment curve intersects with the zero line. In other words, where the bending moment changes its sign from negative to positive or vice versa. Knowing the place of the contraflexure is especially useful when designing reinforced concrete or structural steel beams and also for designing bridges.\n\nFlexural reinforcement may be reduced at this point. However, to omit reinforcement at the point of contraflexure entirely is inadvisable as the actual location is unlikely to realistically be defined with confidence. Additionally, an adequate quantity of reinforcement should extend beyond the point of contraflexure to develop bond strength and to facilitate shear force transfer.\n\n\nfluid mechanics\n"}
{"id": "6625288", "url": "https://en.wikipedia.org/wiki?curid=6625288", "title": "Cradle-to-cradle design", "text": "Cradle-to-cradle design\n\nCradle-to-cradle design (also referred to as Cradle to Cradle, C2C, cradle 2 cradle, or regenerative design) is a biomimetic approach to the design of products and systems that models human industry on nature's processes viewing materials as nutrients circulating in healthy, safe metabolisms. The term itself is a play on the popular corporate phrase \"Cradle to Grave,\" implying that the C2C model is sustainable and considerate of life and future generations (i.e. from the birth, or \"cradle,\" of one generation to the next versus from birth to death, or \"grave,\" within the same generation.)\n\nC2C suggests that industry must protect and enrich ecosystems and nature's biological metabolism while also maintaining a safe, productive technical metabolism for the high-quality use and circulation of organic and technical nutrients. It is a holistic economic, industrial and social framework that seeks to create systems that are not only efficient but also essentially waste free. The model in its broadest sense is not limited to industrial design and manufacturing; it can be applied to many aspects of human civilization such as urban environments, buildings, economics and social systems.\n\nThe term Cradle to Cradle is a registered trademark of McDonough Braungart Design Chemistry (MBDC) consultants. Cradle to Cradle product certification began as a proprietary system; however, in 2012 MBDC turned the certification over to an independent non-profit called the Cradle to Cradle Products Innovation Institute. Independence, openness, and transparency are the Institute's first objectives for the certification protocols. The phrase \"cradle to cradle\" itself was coined by Walter R. Stahel in the 1970s. The current model is based on a system of \"lifecycle development\" initiated by Michael Braungart and colleagues at the \"Environmental Protection Encouragement Agency\" (EPEA) in the 1990s and explored through the publication \"A Technical Framework for Life-Cycle Assessment\".\n\nIn 2002, Braungart and William McDonough published a book called \"\", a manifesto for cradle to cradle design that gives specific details of how to achieve the model. The model has been implemented by a number of companies, organizations and governments around the world, predominantly in the European Union, China and the United States. Cradle to cradle has also been the subject of many documentary films, including the critically acclaimed \"Waste=Food\".\nIn the cradle to cradle model, all materials used in industrial or commercial processes—such as metals, fibers, dyes—fall into one of two categories: \"technical\" or \"biological\" nutrients. \"Technical nutrients\" are strictly limited to non-toxic, non-harmful synthetic materials that have no negative effects on the natural environment; they can be used in continuous cycles as the same product without losing their integrity or quality. In this manner these materials can be used over and over again instead of being \"downcycled\" into lesser products, ultimately becoming waste.\n\n\"Biological Nutrients\" are organic materials that, once used, can be disposed of in any natural environment and decompose into the soil, providing food for small life forms without affecting the natural environment. This is dependent on the ecology of the region; for example, organic material from one country or landmass may be harmful to the ecology of another country or landmass.\n\nThe two types of materials each follow their own cycle in the regenerative economy envisioned by Keunen and Huizing.\n\nInitially defined by McDonough and Braungart, the Cradle to Cradle Products Innovation Institute's five certification criteria are:\nThe certification is available at several levels: basic, silver, gold, platinum, with more stringent requirements at each. Prior to 2012, MBDC controlled the certification protocol.\n\nCurrently, many human beings come into contact or consume, directly or indirectly, many harmful materials and chemicals daily. In addition, countless other forms of plant and animal life are also exposed. C2C seeks to remove dangerous \"technical nutrients\" (synthetic materials such as mutagenic materials, heavy metals and other dangerous chemicals) from current life cycles. If the materials we come into contact with and are exposed to on a daily basis are not toxic and do not have long term health effects, then the health of the overall system can be better maintained. For example, a fabric factory can eliminate all harmful \"technical nutrients\" by carefully reconsidering what chemicals they use in their dyes to achieve the colours they need and attempt to do so with fewer base chemicals.\n\nThe use of a C2C model often lowers the financial cost of systems. For example, in the redesign of the Ford River Rouge Complex, the planting of Sedum (stonecrop) vegetation on assembly plant roofs retains and cleanses rain water. It also moderates the internal temperature of the building in order to save energy. The roof is part of an $18 million rainwater treatment system designed to clean of rainwater annually. This saved Ford $50 million that would otherwise have been spent on mechanical treatment facilities. If products are designed according to C2C design principles, they can be manufactured and sold for less than alternative designs. They eliminate the need for waste disposal such as landfills.\n\n\nThe question of how to deal with the countless existing \"technical nutrients\" (synthetic materials) that cannot be recycled or reintroduced to the natural environment is dealt with in C2C design. The materials that can be reused and retain their quality can be used within the technical nutrient cycles while other materials are far more difficult to deal with, such as plastics in the Pacific Ocean.\n\nOne effective example is a shoe that is designed and mass-produced using the C2C model. The sole might be made of \"biological nutrients\" while the upper parts might be made of \"technical nutrients\". The shoe is mass-produced at a manufacturing plant that utilises its waste material by putting it back into the cycle; an example of this is using off-cuts from the rubber soles to make more soles instead of merely disposing of them (this is dependent on the technical materials not losing their quality as they are reused). Once the shoes have been manufactured, they are distributed to retail outlets where the customer buys the shoe at a fraction of the price they would normally pay for a shoe of comparable aspects; the customer is only paying for the use of the materials in the shoe for the period of time that they will be using the shoe. When they outgrow the shoe or it is damaged, they return it to the manufacturer. When the manufacturer separates the sole from the upper parts (separating the technical and biological nutrients), the biological nutrients are returned to the natural environment while the technical nutrients are used to create the sole of another shoe.\n\nAnother example of C2C design is a disposable cup, bottle, or wrapper made entirely out of biological materials. When the user is finished with the item, it can be disposed of and returned to the natural environment; the cost of disposal of waste such as landfill and recycling is eliminated. The user could also potentially return the item for a refund so it can be used again.\n\nFord Model U is a design concept of a car, made completely from cradle-to-cradle materials. It also uses hydrogen propulsion.\n\n\nThe C2C model can be applied to almost any system in modern society: urban environments, buildings, manufacturing, social systems. 5 steps are outlined in \"Cradle to Cradle – Remaking the way we make things\":\n\nProducts that adhere to all steps can generally be granted a certification. Two certifications used for cradle-to-cradle products include Leadership in Energy and Environmental Design (LEED) and BRE Environmental Assessment Method (BREEAM).\n\nC2C principles were first applied to systems in the early 1990s by Braungart's Hamburger Umweltinstitut (HUI) and The Environmental Institute in Brazil for biomass nutrient recycling of effluent to produce agricultural products and clean water as a byproduct.\n\nIn 2005, William McDonough helped found the Center for Eco-Intelligent Management at Instituto de Empresa Business School. The center's research produced the Biosphere Rules, a set of five implementation principles that facilitate the adoption of closed loop production approaches with a minimum of disruption for established companies.\n\nIn 2007, MBDC and the EPEA formed a strategic partnership with global materials consultancy Material ConneXion to help promote and disseminate C2C design principles by providing greater global access to C2C material information, certification and product development.\n\nAs of January 2008, Material ConneXion's Materials Libraries in New York, Milan, Cologne, Bangkok and Daegu, Korea started to feature C2C assessed and certified materials and, in collaboration with MBDC and EPEA, the company now offers C2C Certification, and C2C product development.\n\nWhile the C2C model has influenced the construction or redevelopment of many smaller buildings, several large companies, organisations and governments have also implemented the C2C model and its ideas and concepts:\n\n\nThe Cradle to Cradle model can be viewed as a framework that considers systems as a whole or holistically. It can be applied to many aspects of human society, and is related to Life cycle assessment. See for instance the LCA based model of the Eco-costs, which has been designed to cope with analyses of recycle systems. The Cradle to Cradle model in some implementations is closely linked with the Car-free movement, such as in the case of large-scale building projects or the construction or redevelopment of urban environments. It is closely linked with passive solar design in the building industry and with permaculture in agriculture within or near urban environments. An earthship is a perfect example where different re-use models are used, cradle to cradle and permaculture.\n\nIn 2005, IE Business School in Madrid launched the Center for Eco-Intelligent Innovation in collaboration with William McDonough to study the implementation of Cradle to Cradle design approaches in pioneering businesses. The academic research of companies lead to the elaboration of the Biosphere Rules, a set of five principles derived from nature that guide the implementation of circular models in production. \n\nA major constraint in the optimal recycling of materials is that at civic amenity sites, products are not disassembled by hand and have each individual part sorted into a bin, but instead have the entire product sorted into a certain bin.\n\nThis makes the extraction of rare earth elements and other materials uneconomical (at recycling sites, products typically get crushed after which the materials are extracted by means of magnets, chemicals, special sorting methods, ...) and thus optimal recycling of, for example metals is impossible (an optimal recycling method for metals would require to sort all similar alloys together rather than mixing plain iron with alloys).\n\nObviously, disassembling products is not feasible at currently designed civic amenity sites, and a better method would be to send back the broken products to the manufacturer, so that the manufacturer can disassemble the product. These disassembled product can then be used for making new products or at least to have the components sent separately to recycling sites (for proper recycling, by the exact type of material). At present though, few laws are put in place in any country to oblige manufacturers to take back their products for disassembly, nor are there even such obligations for manufacturers of cradle-to-cradle products. One process where this is happening is in the EU with the Waste Electrical and Electronic Equipment Directive.\n\nCriticism has been advanced on the fact that McDonough and Braungart previously kept C2C consultancy and certification in their inner circle. Critics argued that this lack of competition prevented the model from fulfilling its potential. Many critics pleaded for a public-private partnership overseeing the C2C concept, thus enabling competition and growth of practical applications and services.\n\nMcDonough and Braungart responded to this criticism by giving control of the certification protocol to a non-profit, independent Institute called the Cradle to Cradle Products Innovation Institute. McDonough said the new institute \"will enable our protocol to become a public certification program and global standard.\" The new Institute announced the creation of a Certification Standards Board in June 2012. The new board, under the auspices of the Institute, will oversee the certification moving forward.\n\nExperts in the field of environment protection have questioned the practicability of the concept. Friedrich Schmidt-Bleek, head of the German Wuppertal Institute called his assertion, that the \"old\" environmental movement had hindered innovation with its pessimist approach \"pseudo-psychological humbug\".\n\"I can feel very nice on Michael's seat covers in the airplane. Nevertheless I am still waiting for a detailed proposal for a design of the other 99.99 percent of the Airbus 380 after his principles.\"\nIn 2009 Schmidt-Bleek stated that it is out of the question that the concept can be realized on a bigger scale.\n\nSome claim that C2C certification may not be entirely sufficient in all eco-design approaches. Quantitative methodologies (LCAs) and more adapted tools (regarding the product type which is considered) could be used in tandem. The C2C concept ignores the use phase of a product. According to the Variants of Life Cycle Assessment the entire life cycle of a product or service has to be evaluated, not only the material itself. For many goods e.g. in transport, the use phase has the most influence on the environmental footprint. E.g. the more lightweight a car or a plane the less fuel it consumes and consequently the less impact it has. Braungart fully ignores the use phase.\n\nIt is safe to say that every production step or resource-transformation step needs a certain amount of energy.\n\nThe C2C concept foresees an own certification of its analysis and therefore is in contradiction to international ISO standards 14040 and 14044 for Life Cycle Assessment whereas an independent and critical review is needed in order to obtain comparative and resilient results. Independent external review.\n\n"}
{"id": "2903446", "url": "https://en.wikipedia.org/wiki?curid=2903446", "title": "Dump leaching", "text": "Dump leaching\n\nDump leaching is an industrial process to extract precious metals and copper from ores.\n\nDump leaching is similar to heap leaching, however in the case of dump leaching ore is taken directly from the mine and stacked on the leach pad without crushing where, in the case of gold and silver, the dump is irrigated with a dilute cyanide solution that percolates through the ore to dissolve gold and silver. The solution containing gold and silver exits the base of the dump, is collected and precious metals extracted. The resultant barren solution is recharged with additional cyanide and returned to the dump.\n\nThis method of leaching is usually suitable for low grade ores because it is very low cost. However, it operates with slow kinetics and may take up about 1 to 2 years to extract 50% of the desired mineral.\n"}
{"id": "32909899", "url": "https://en.wikipedia.org/wiki?curid=32909899", "title": "Eddy current separator", "text": "Eddy current separator\n\nAn eddy current separator uses a powerful magnetic field to separate non-ferrous metals from waste after all ferrous metals have been removed previously by some arrangement of magnets. The device makes use of eddy currents to effect the separation. Eddy current separators are not designed to sort ferrous metals which become hot inside the eddy current field. This can lead to damage of the eddy current separator unit belt.\n\nThe eddy current separator is applied to a conveyor belt carrying a thin layer of mixed waste. At the end of the conveyor belt is an eddy current rotor. Non-ferrous metals are thrown forward from the belt into a product bin, while non-metals simply fall off the belt due to gravity.\n\nEddy current separators may use a rotating drum with permanent magnets, or may use an electromagnet depending on the type of separator.\n\nA patent for a device using eddy currents to separate non-ferrous metals from non-metals was granted to William Benson and Thomas Falconer of Eriez Magnetics in 1969.\n"}
{"id": "46804622", "url": "https://en.wikipedia.org/wiki?curid=46804622", "title": "Factum Arte", "text": "Factum Arte\n\nFactum Arte is a company based in Madrid, Milan, and London that seeks to construct a bridge between new technologies and craft skills in the conservation of cultural heritage and in contemporary art. By using various forms of high-definition 3D scanners, Factum Arte has been able to record, in digital form using non-contact equipment, a number of endangered sites/objects of cultural importance. This is done in conjunction with the Factum Foundation for Digital Technology in Conservation, which seeks to promote the use of non-contact 3D scanners to record museum collections and historic monuments, especially in areas where they are at risk.\n\nIn addition to recording objects, Factum Arte is able to use the digital data to create an exact facsimile of the object on a scale of 1:1. In 2014, Factum Arte completed the installation of an exact facsimile of the tomb of Tutankhamun in the Valley of the Kings in Luxor, near Howard Carter’s house. The facsimile, and its proximity to the original tomb, is intended to provoke a debate about preservation; as Factum Arte’s Director, Adam Lowe, was said: \"The tomb of Tutankhamun was built to last for eternity, but it wasn’t built to be visited\".\n\nOver the years, Factum Arte has worked with institutions such as the British Museum in London, the Musée du Louvre in Paris, the Pergamon Museum in Berlin, the Museo del Prado in Madrid, and the Supreme Council of Antiquities in Egypt. In addition to its work in the field of cultural heritage, Factum Arte also assists a wide range of contemporary artist in creating technically difficult and innovative works of art.\n\nFactum Arte was founded in 2001 by the artists Adam Lowe, Manuel Franquelo, with Fernando Garcia-Guereta to facilitate the recording of the Tomb of Seti I and works with a number of artists including Marc Quinn and Anish Kapoor. The Seti project involved the design and construction of 3D laser scanners, software, and photographic equipment to record the walls of the tomb at high-resolution.\n\nFactum Arte was founded in 2001 in order to facilitate the development of technology needed specifically for the recording of the Tomb of Seti I.\n\nSeti’s tomb is regarded by many as the most visually impressive, and historically important tomb in the Valley of the Kings. Discovered by Giovanni Battista Belzoni in October 1817, the tomb of Pharaoh Seti I is the longest and one of the most decorated tombs in the Valley of the Kings. Despite being in excellent condition on its discovery, the tomb is currently closed to visitors to the Valley due to its deteriorating condition over the years. In addition to the removal of wall panels, and the loss of paint due to 19th century plaster casts, the tomb has suffered from collapses and cracks due to expeditions searching for hidden chambers in the 1950s and 60s that caused changes in the moisture levels of the surrounding rock.\n\nFactum Arte was commissioned by United Exhibits Group to make a 1:1 facsimile of the Tomb of Thutmose III in 2002. The facsimile was toured at exhibitions in various museums in the United States between November 2002 and December 2007. In 2005 a second facsimile of the tomb was exhibited in Madrid, Edinburgh, and Basel titled Immortal Pharaoh: The Tomb of Thutmose III (Edinburgh) and The Tomb of Thutmose III: The Dark Hours of the Sun (Madrid and Basel).\n\nThe Tomb of Thutmose III is the oldest complete version of the narrative of the Egyptian Amduat, the journey the Sun God takes through the hours of the night.\n\nThe facsimile of the tomb was installed briefly outside the Conrad Hotel in Cairo for the EU-Egypt Business and Tourism Summit and was unveiled by Catherine Ashton the European High Representative of the Union for Foreign Affairs in November 2012 as a gift to the people of Egypt, coinciding with the 90th anniversary of the tomb’s discovery.\nIn 2014 Factum Arte installed the facsimile in the Valley of the Kings, beside Howard Carter’s house, the consultant of the construction site where the facsimile was installed was \"Tarek Waly center architecture and heritage\". It was unveiled by the Minister of Antiquities Mohamed Ibrahim, the Minister for Tourism Hisham Zazou, the Governor of Luxor Tarek Saad el Din and EU Ambassador James Moran. The aim of the facsimile is to inform visitors to the valley about the importance of preservation and to promote awareness about the degrading state of the tombs since their opening to tourists.\n\nIn August 2015, Egyptologist Nicholas Reeves published a paper in which he hypothesised the presence of the tomb of Nefertiti as being behind one of the walls of Tutankhamun's tomb. Reeves' based his theory on markings he observed on the wall in the data recorded by Factum Arte. In September 2015, Egyptian newspaper \"Ahram\" reported that initial examinations had confirmed the existence of the wall markings observed by Reeves in Factum Arte's data. The same article reported that the results of further examinations would be published on 4 November 2015; the same day that the tomb was discovered in 1922.\n\nIn 2004, during the Second Gulf War, Factum Arte and Danish company United Exhibits Group (UEG) embarked on a project to record, and create a facsimile of the throne room of Ashurnasirpal II in the ancient city of Nimrud. Fragments of the throne room exist in the collections of various museums in Europe and the United States. Factum Arte was given permission to record these fragments in the British Museum, the Pergamon in Berlin, Dresden, Harvard, and Princeton.\n\nUnfortunately, at the time, Iraq was considered too dangerous to send a team out to record the remaining fragments in Nimrud. In 2015 the Islamic State militants in Northern Iraq destroyed much of the remaining artwork in the ruins of the palace of Nimrud. While recording these fragments in 2005 would not have prevented their destruction by ISIS, it would have kept avenues open to further in-depth study through the high-resolution 3D data, and presented the possibility of reuniting the fragments in the form of facsimile.\n\nIn November 2007, Factum Arte’s facsimile of \"The Wedding Feast at Cana\" (1563), by Paolo Veronese, was presented by the Cini Foundation in the original location of the painting, the Andrea Palladio's refectory for the Monastery of San Giorgio Maggiore, Venice. The original painting, commissioned in 1562, was plndered by the French Revolutionary Army of Napoleon in 1797 and sent to the Louvre Museum, where it hangs opposite the Mona Lisa. The facsimile was commissioned in 2006 by the Fondazione Giorgio Cini and, following an agreement with the Louvre, Factum Arte’s technicians were allowed to scan the painting at night. \"Corriere della Sera\" called the facsimile a \"turning point in art\".\n\nIn 2010 the Cini Foundation commissioned the visualisation and manufacture of objects designed by the 18th century artist and antiquarian Giambattista Piranesi. The project was conceived by Adam Lowe, Michele de Lucchi, and John Wilton-Ely and was exhibited in the Cini Foundation on the island of San Giorgio Maggiore for the Venice Biannale. The objects were later toured for exhibitions in Madrid, Barcelona, and San Diego\n\nIn March–May 2014, Factum Arte exhibited the series at the Sir John Soane Museum in London. Diverse Manieri: Piranesi, Fantasy and Excess aimed to explore the relationship between Sir John Soane and Piranesi. The objects were shown in the context of prints, drawings and books in Soane’s library.\n\nThe objects were visualised in digital form from Piranesi’s designs and then rematerialized in three dimensions in the materials specified in the design. The manufacture of the objects involved a variety of methods including stereo-lithography, milling, fused deposition modelling, electro forming and electro plating, in addition to a host of moulding and casting technologies\n\nThe 16 panels of the Polittico Griffoni once formed the altarpiece of the Basilica of San Petronio in Bologna. It was considered one of the greatest altarpieces of the 15th Century Bolognese School. The panels were originally painted by Francesco del Cossa and Ercole De Roberti. The panels, removed in 1725, are now scattered in various museums in Italy, the United Kingdom, the United States, France, the Netherlands, and the Vatican City.\n\nUsing the Lucida 3D scanner, designed by Manuel Franquelo, Factum Arte and the Factum Foundation for Digital Technology in Conservation collaborated with San Petronio Basilica to record, reproduce and reunite the panels as a facsimile in their original location.\n\nOther projects in the realm of cultural conservation include:\n\nFactum Arte has developed a number technologies in order to better facilitate the recording and production of objects.\n\n\nFactum Arte collaborates with a large number of companies and individuals from the tech industry and the art world.\n\nFactum Arte has undertaken projects with, among others, the following artists:\n\n\nIn 2013, when referring to the facsimile of the Tomb of Tutankhamun and the facsimile of the caves at Lascaux, historian Tom Holland voiced criticism of the idea of creating \"fakes\" as a means to protect the originals:\nIn our society, there is a huge premium set on authenticity. Clearly, were there not a difference between the copy and the original, it wouldn’t matter – you could make a replica and trash the original. Tutankhamun and Lascaux were created by people who believed in the world of the spirits, the dead, and the supernatural. You don’t have to believe in a god or gods to feel a place is consecrated and has a particular quality that cannot be reproduced.\n\n"}
{"id": "25051576", "url": "https://en.wikipedia.org/wiki?curid=25051576", "title": "Feature phone", "text": "Feature phone\n\nFeature phone is a term typically used as a retronym to describe a class of mobile phones. Feature phones tend to use a proprietary, custom-designed software and user interface, and lack the capabilities of smartphones. Feature phones typically provide voice calling and text messaging functionality, in addition to basic multimedia and Internet capabilities, and other services offered by the user's wireless service provider. Feature phones have a backlit LCD screen and micro USB port and may have a physical keyboard, a microphone, SD card slot, a rear-facing camera to record video and capture pictures; and GPS. Some feature phones include a rudimentary app store that include basic software such as mobile games, calendar and calculator programs.\n\nPrior to the popularity of smartphones, the term 'feature phone' was often used on high-end phones with assorted functions for retail customers, developed around the advent of 3G networks, which allowed sufficient bandwidth for these capabilities. Feature phones were typically mid-range devices, between basic phones on the low end with few or no features beyond basic dialing and messaging, and business-oriented smartphones on the high end. The best-selling feature phones include those by Nokia, the Razr by Motorola, the multimedia-enabled Sony Ericsson W580i, and the LG Black Label Series that targeted retail customers.\n\nFeature phones run on proprietary firmware with third-party software support through platforms such as Java ME or BREW. The proprietary operating systems were not designed in mind to develop nor handle the intensive applications found on iOS and Android, both of which specifically cater to third-party application development which became increasingly important.\n\nDepending on extent of functionality, feature phones may have many of the capabilities of a smartphone, within certain cases. For example, today's feature phones typically serve as a portable media player, and can have digital cameras, GPS navigation, Wi-Fi and mobile broadband internet access, and mobile gaming through discrete apps. \n\nIn developed economies, feature phones are primarily specific to niche markets, or have become merely a preference—owing to certain feature combinations not available in other devices, such as affordability, durability, simplicity, and extended battery life per one charge (viz standby and talk times). In emerging markets, a feature phone remains the primary means of communication for many.\n\nA well-designed feature phone can be used in industrial environments and the outdoors, at workplaces that proscribe dedicated cameras, and as an emergency telephone. Several models are equipped with hardware functions — such as FM radio and flashlight — that prevent the device from becoming useless in the event of a major disaster, or entirely obsolete, if and when 2G network infrastructure is shut down. Other feature phones are specifically designed for the elderly, and yet others for religious purposes.\n\nFeature phones are often kept in phone manufacturers' lineups for several reasons:\n\n\nFrom the point of view of markets and consumers, there are several situations for which feature phones are beneficial:\n\n\nThe first cellular phone, the Motorola DynaTAC released in 1984, is considered a basic mobile phone due to its inability to do anything more than making voice calls.\n\nDespite the introduction of smartphones in the mid-1990s, ignited with the August 1994 release of the IBM Simon, Nokia Communicator from 1996 on, and the BlackBerry line of handheld personal digital assistants from Research in Motion, feature phones enjoyed unchallenged popularity into the mid 2000s. In North America, smartphones, such as Palm and BlackBerry, were still considered a niche category for enterprise use. Outside North America, Nokia's Symbian devices had captured the smartphone market, in which price was the only barrier to entry, and Nokia offered smartphones across all feasible price segments. In the mid-2000s, phone makers such as Nokia and Motorola enjoyed record sales of feature phones. In developed economies, fashion and brand drove sales, as markets had matured and people moved to their second and third phones. In the U.S., technological innovation with regard to expanded functionality was a secondary consideration, as phone designs there centered on miniaturisation. \n\nHowever, consumer-oriented smartphones such as the iPhone and those running Android fundamentally changed the market, with Steve Jobs proclaiming in 2007 that \"the phone was not just a communication tool but a way of life\". Existing feature-phone operating systems at the time, such as Symbian, were not designed to handle additional tasks beyond communication and basic functions, did not emphasis application developers much, and due to infighting among manufacturers as well as the complex bureaucracy and bloatness of the OS, they never developed a thriving ecosystem like Apple's App Store or Android's Google Play. By contrast, iPhone OS (renamed iOS in 2010) and Android were designed as a robust OS, embracing third-party apps, and having capabilities such as multitasking and graphics in order to meet future consumer demands.\n\nThere has been an industry shift from feature phones (including low-end smartphones), which rely mainly on volume sales, to high-end flagship smartphones which also enjoy higher margins, thus manufacturers find high-end smartphones much more lucrative than feature phones. For instance Apple Inc.'s operating margins from the iPhone remain high since these devices have always been sold to carriers at a high enough cost which compels carriers to get wireless customers to sign multiyear contracts. The shift away from feature phones has forced wireless carriers to increase subsidies of handsets, and the high selling-prices of flagship smartphones have had a negative effect on the wireless carriers (AT&T Mobility, Verizon, and Sprint), who have seen their EBITDA service-margins drop as they sold more smartphones and fewer feature phones. Trends have shown that consumers are willing to pay more for smartphones that deliver more features/applications such as 4G LTE and touchscreens, and smartphones have become a part of North American pop-culture (while feature phones are no longer \"cool\"). Though smartphones cost more to produce, they deliver higher profit-margins than feature phones, thus device makers and wireless carriers have shifted towards smartphones.\n\nDuring the mid-2000s, best-selling feature phones such as the fashionable flip-phone Motorola Razr, multimedia Sony Ericsson W580i, and the LG Black Label Series not only occupied the mid-range pricing in a wireless provider's lineup, they made up the bulk of retail sales as smartphones from BlackBerry and Palm were still considered a niche category for business use. Even as late as 2009, smartphone penetration in North America was low.\n\nIn 2007, Apple introduced the groundbreaking iPhone and by 2009, the iPhone and Google Android shifted the smartphone focus from the enterprise to mass market consumers (at the expense of business-oriented operating systems such as Windows Mobile and BlackBerry). As a result, smartphones have enjoyed the largest selection and advertising among carriers, who are devoting less and less store space and marketing to feature phones.\n\nIn 2011, feature phones accounted for 60 percent of the mobile telephones in the United States and 70 percent of mobile phones sold worldwide. According to Gartner in Q2 2013, 225 million smartphones were sold which represented a 46.5 percent gain over the same period in 2012, while 201 million feature phones were sold which was a decrease of 21 percent year over year, the first time that smartphones have outsold feature phones. Smartphones accounted for 51.8 percent of mobile phone sales in the second quarter of 2013, resulting in smartphone sales surpassing feature phone sales for the first time.\n\nA survey of 4,001 Canadians by Media Technology Monitor in fall 2012 suggested about 83 per cent of the anglophone population owned a cellphone, up from 80 per cent in 2011 and 74 per cent in 2010. About two thirds of the mobile phone owners polled said they had a smartphone and the other third had feature phones or non-smartphones. According to MTM, non-smartphone users are more likely to be female, older, have a lower income, live in a small community and have less education. The survey found that smartphone owners tend to be male, younger, live in a high-income household with children in the home, and residents of a community of one million or more people. Students also ranked high among smartphone owners.\n\nIn Japan, mobile phones developed a wide array of features prior to the development of smart phones. The introduction of smart phones has largely displaced these at the high end, though smart phones for the Japanese market often include features first developed on feature phones. Many of these features were and remain specific to Japan, often requiring network support, and the resulting phones, while dominant in Japan, proved unsuccessful abroad. This led to the term \"Galápagos syndrome\" – specialized development dominant on an island, but not found abroad – and then the term is , blending with , to refer to Japanese feature phones, by contrast with newer smart phones.\n\nWhen Apple Inc., a company then known for its production of the iPod media player and the iMac personal computer, introduced the iPhone, featuring an all-touch user interface closely based on that of the iPod Touch. The first iPhone had a much more powerful hardware and operating system than contemporary feature phones and smartphones; in fact the hardware/software was derived from the Macintosh personal computer, in contrast to the existing phones which had slow processors and limited applications/firmware to conserve battery life. The iPhone's applications were also much more bandwidth-intensive than contemporary phones which would strain existing wireless networks. Featuring access to millions of mobile apps from Apple's iTunes Store (now the App Store), it was considered to be among the first retail/consumer-oriented smartphones. At the event, Steve Jobs proclaimed that \"the phone was not just a communication tool but a way of life\". \n\nAt around the same time, Google was developing its Android operating system as a direct competitor to Nokia's Symbian and Microsoft's Windows Mobile operating systems. The iPhone's success lead to the company, led by Larry Page, turning its methodology around, and Android as an open-source software platform for mobile phones was announced in November 2007 together with the founding of the Open Handset Alliance, and the first Android smartphone, the HTC Dream, was released in October 2008 in the US. Google would go on to launch its Nexus line of smart devices and collaborate with various original equipment manufacturers, including popular feature phone manufacturers Samsung, LG, Sony, and Motorola, to adapt Android for devices of varying form factors and computing platforms. \n\nMotorola had stayed too long with its aging RAZR flip phone and missed consumer trends for touchscreens and enhanced multimedia. Nokia and Research in Motion's attempts to implement some of the new capabilities from iPhone and Android to their existing proprietary firmware platforms was mixed, as these earlier operating systems were designed in mind to handle these intensive applications. Nonetheless as the iPhone was initially too expensive for mass market adoption, Nokia and Research in Motion did enjoy expanded sales as their offerings were considered a lower-priced alternative.\n\nBy the turn of the decade, iOS and Android, together with less-common platforms such as BlackBerry 10 and Windows Phone, had shifted the smartphone focus from being a niche to mass market consumers. Feature phones were primarily designed as communication devices, and manufacturers had, up to that point, been enjoying record sales of cell phones based more on fashion and brand, rather than technological innovation. Though smartphones cost more to produce, they were delivering higher profit margins than feature phones, leading to manufacturers and wireless carriers shifting towards smartphones. As a result, smartphones now have the largest selection and advertising among carriers, which devoted less and less store space and marketing to feature phones. In 2013, smartphones outsold feature phones for the first time, accounting for 51.8% of mobile phone sales in the second quarter of that year.\n\nIn an effort to provide parity with smartphones, modern feature phones have also incorporated support for 3G and even 4G connectivity, multi-touch screens of varying sizes, various sensors ranging from proximity sensors and GPS to Bluetooth and NFC, plus access to popular social networking services. However, their functionality and support for third-party apps purchased or downloaded via an app store or other online distribution platform are still relatively limited in comparison to smartphones.\n\nSeveral distinct operating systems have been developed which can run on a feature phone. These operating systems are designed to be lightweight to increase the feature phone battery life, work well with a small screen which does not have touch features, and also work well with a small hardware keyboard such as T9 keyboard commonly found on feature phones.\n\nNokia has developed the Series 30 and Series 40 software platform and application user interfaces which run the Nokia Asha platform.\n\nMediaTeK has developed an embedded real-time operating system Nucleus RTOS, MAUI Runtime Environment.\n\nNTT Docomo has developed MOAP software platform and (Japanese).\n\nQualcomm has developed a lightweight runtime environment Brew MP, an operating system for ARM phones REX OS, (Japanese), and (Japanese).\n\nTizen Association (formerly LiMo Foundation) has developed a Linux-based LiMo Platform for smartphones.\n\nSmarterphone has developed Smarterphone OS, a full operating system designed for feature phones. The first release was in 2008. \n\nKaiOS Tech has developed KaiOS, a lightweight fork of Firefox OS which was developed by Mozilla.\n\n"}
{"id": "2376296", "url": "https://en.wikipedia.org/wiki?curid=2376296", "title": "Flying Heavy Metal", "text": "Flying Heavy Metal\n\nFlying Heavy Metal was a five-part British television series produced by Ricochet and originally broadcast in the UK and Europe on the Discovery Channel in 2005, and subsequently repeated on Discovery Wings in the UK. It was presented by commercial Boeing 757 pilot and Iron Maiden frontman, Bruce Dickinson.\n\nIn the series, Dickinson looked at, and often flew, a number of aircraft from across the history of commercial aviation. There were some quite surprising aerobatics done in rather large aircraft.\n\n\"Flying Heavy Metal\" is now repeated on the new channel from Discovery Networks UK called Discovery Turbo.\n\nThe development of the de Havilland Comet and the Boeing 707 herald the end of an era for propeller-driven airliners such as the Douglas DC-3.\nJet travel becomes available to the masses with the development of the Hawker Siddeley Trident and the Boeing 727.\nEurope develops Concorde while Boeing develops the 747 jumbo jet.\nJetliner safety enhancements, including the automatic landing capabilities of the Hawker Siddeley Trident, the fly-by-wire capabilities of the Airbus A320 (and lack thereof in the Boeing 737) as well as other safety features currently in development.\n\nNew records in airliner size, fuel economy, and passenger comfort with the Airbus A380 and the Boeing 787 (known as the 7E7 at the time). Also explores the wisdom of space airliner travel.\n\nSeries Producer - James Bates\n\nProducer - Dan Peirson\n\nAssistant Producer - Greg Chivers\n\nProduction Manager - Amanda Rohan\n\nFlying Heavy Metal - Najam Ul Saqib\n\n"}
{"id": "42438345", "url": "https://en.wikipedia.org/wiki?curid=42438345", "title": "Goražde printing house", "text": "Goražde printing house\n\nThe Goražde printing house ( or ) was one of the earliest printing houses among the Serbs, and the first in the territory of present-day Bosnia and Herzegovina (then part of the Ottoman Empire). Established in 1519 in Venice, it was soon relocated to the Serbian Orthodox Church of Saint George in the village of Sopotnica near Goražde, in the Ottoman Sanjak of Herzegovina. It was founded and run by Božidar Ljubavić, also known as Božidar Goraždanin, who was a prominent merchant from Goražde. His son Teodor Ljubavić, a hieromonk of the Mileševa Monastery, managed the work of the printing house. It worked until 1523, producing three books, which are counted among the better accomplishments of early Serb printers.\n\nAfter the printing press was invented around 1450 by Johannes Gutenberg in Mainz, Germany, the art of book printing was soon introduced in other parts of Europe. By the end of the 15th century, Venice had become a major centre of printing. In 1493, Đurađ Crnojević, the ruler of the Principality of Zeta (in present-day Montenegro), sent Hieromonk Makarije to Venice to buy a press and learn the art of printing. At Cetinje, the capital of Zeta, Makarije printed in 1494 the Cetinje Octoechos, the first incunable written in the Serbian recension of Church Slavonic. The Crnojević printing house worked until 1496, when Zeta fell to the Ottomans. In 1518, Božidar Ljubavić resided at the Mileševa Monastery, the see of a Serbian Orthodox diocese which had been part of the Kingdom of Bosnia since 1373. Mileševa and other parts of its diocese, including the town of Goražde, were located in the region of Herzegovina, which was gradually conquered by the Ottomans between 1465 and 1481.\n\nIn the second half of 1518, Božidar Ljubavić sent his sons, Đurađ and hieromonk Teodor, to Venice to buy a printing press and to learn the art of printing. The Ljubavić brothers procured a press and began printing a hieratikon (priest's service book), copies of which had been completed by 1 July 1519 either in Venice or at the Church of Saint George near Goražde. After Đurađ Ljubavić died in Venice on 2 March 1519, it is unclear whether his brother transported the press to Goražde before or after finishing the work on the hieratikon. At the Church of Saint George, Teodor organised the Goražde printing house, which produced, beside the hieratikon, two more books in Church Slavonic of the Serbian recension: a psalter in 1521, and a small euchologion in 1523. The Goražde Psalter, containing 352 leaves, is the biggest of the three books. They were not bound at the printing house, as this job was a responsibility of book vendors. Trade was well developed in Goražde, as the town was built at the junction of three important roads, which connected it with Dubrovnik, Vrhbosna (Sarajevo), and Kosovo.\n\nThe next printing house would not appear in Bosnia and Herzegovina until 1866, when Sopron's Printing House began its work. In 1544, the printing press was transported from Goražde to Târgoviște, the capital of Wallachia, thus becoming the second such facility in the territory of present-day Romania. Its relocation and reactivation was accomplished by Dimitrije Ljubavić, Božidar's grandson. In Târgoviște, Dimitrije printed a euchologion at the beginning of 1545, and an apostolarium in 1547. Božidar Vuković founded his printing house in Venice in 1519 or 1520, contemporaneously with the Ljubavić brothers. It worked, with interruptions, until the end of the 16th century. There were other early Serbian printing works, established in the territory of the Ottoman Empire: at the Rujan Monastery near Užice in 1529, at the Gračanica Monastery near Priština in 1539, at the Mileševa Monastery in 1546, in Belgrade in 1552, again at Mileševa in 1557, at the Mrkšina Crkva Monastery near Valjevo in 1562, and in Skadar in 1563. They were active for one to four years and produced one to three books each.\n\n\n"}
{"id": "32064224", "url": "https://en.wikipedia.org/wiki?curid=32064224", "title": "GreenXC", "text": "GreenXC\n\nGreenXC, established in 2011, is an organization that works to raise awareness for National Parks, National Forests and the National Park Foundation, the official charity of America’s nearly 400 national parks. It focuses on the youth and reaches out to connect them to the parks and forests in order to ensure the parks are supported for the next generation of taxpayers. GreenXC aligns itself with the National Park Foundation's goal of being \"deeply committed to engaging the country's youth into a lifelong experience with the parks.\"\n\nGreenXC also works closely with the USDA United States Forest Service on setting destinations for their cross-country awareness campaign during the summer of 2011. They will be visiting and touring various sites and conducting interviews which they will share with their readers through their site. The purpose of the campaign is to encourage the young generation to have a more active involvement with their environment.\n\nIn 2011 GreenXC is set to travel cross country to raise awareness for the National Parks and National Forests. \"GreenXC, an ensemble of green-minded young professionals, has a mission to travel cross-country solely by ride-shares. A unique twist to a traditional road trip, rideshares make for great adventures as eco-enthusiastic travelers connect, journey together and help reduce carbon footprints. Roadtrippers find one another via blogs, social media, even Craig’s List.\"\n\n\"GreenXC will collect and document the stories of the people who help turn these ambitions into a reality. The experiences will be shared through daily blog posts and video footage on YouTube.\" Those following can interact and donate directly to the parks visited. The route of the trip will be crowd sourced through suggestions on Twitter, Facebook, the GreenXC blog/forum and social sites like Reddit.\n\nGreenXC aligns itself with the Federal Government's goal of promoting the National Parks and Forests to the young generation. In 2011, the President set as one of the top goals of the Federal Government to promote the great outdoors and especially to the youth. \"Special attention should be given to bringing young Americans into the conversation.\"\n\n"}
{"id": "13666834", "url": "https://en.wikipedia.org/wiki?curid=13666834", "title": "Hybrid Insect Micro-Electro-Mechanical Systems", "text": "Hybrid Insect Micro-Electro-Mechanical Systems\n\nHybrid Insect Micro-Electro-Mechanical Systems is a project of DARPA, a unit of the United States Department of Defense, with the goal of developing tightly coupled machine-insect interfaces by placing micro-mechanical systems inside the insects during the early stages of metamorphosis. The primary application is surveillance.\n\n"}
{"id": "18172", "url": "https://en.wikipedia.org/wiki?curid=18172", "title": "Land mine", "text": "Land mine\n\nA land mine is an explosive device concealed under or on the ground and designed to destroy or disable enemy targets, ranging from combatants to vehicles and tanks, as they pass over or near it. Such a device is typically detonated automatically by way of pressure when a target steps on it or drives over it, although other detonation mechanisms are also sometimes used. A land mine may cause damage by direct blast effect, by fragments that are thrown by the blast, or by both.\n\nThe name originates from the ancient practice of military mining, where tunnels were dug under enemy fortifications or troop formations. These killing tunnels (\"mines\") were at first collapsed to destroy targets located above, but they were later filled with explosives and detonated in order to cause even greater devastation.\n\nNowadays, in common parlance, \"land mine\" generally refers to devices specifically manufactured as anti-personnel or anti-vehicle weapons. Though some types of improvised explosive devices (\"IEDs\") are mistakenly classified as land mines, the term \"land mine\" is typically reserved for manufactured devices designed to be used by recognized military services, whereas \"IED\" is used for makeshift \"devices placed or fabricated in an improvised manner incorporating explosive material, destructive, lethal, noxious, incendiary, pyrotechnic materials or chemicals designed to destroy, disfigure, distract or harass. They may incorporate military stores,\nbut are normally devised from non-military components\". \n\nThe use of land mines is controversial because of their potential as indiscriminate weapons. They can remain dangerous many years after a conflict has ended, harming civilians and the economy. 78 countries are contaminated with land mines and 15,000–20,000 people are killed every year while countless more are maimed. Approximately 80% of land mine casualties are civilian, with children as the most affected age group. Most killings occur in times of peace. With pressure from a number of campaign groups organised through the International Campaign to Ban Landmines, a global movement to prohibit their use led to the 1997 Convention on the Prohibition of the Use, Stockpiling, Production and Transfer of Anti-Personnel Mines and on their Destruction, also known as the \"Ottawa Treaty\". To date, 164 nations have signed the treaty.\n\nLand mines were designed for two main uses: \n\nLand mines are currently used in large quantities mostly for this first purpose, thus their widespread use in the demilitarized zones (DMZs) of likely flashpoints such as Cyprus, Afghanistan and Korea. As of 2013, the only governments that still laid land mines were Myanmar in its internal conflict, and Syria in its civil war.\n\nLand mines continue to kill or injure at least 4,300 people every year, even decades after the ends of the conflicts for which they were placed.\n\nJiao Yu in the preface to his \"Huolongjing Quanzhi\", written in 1412 AD, claimed that in the third century, the chancellor Zhuge Liang of the Shu Han state had used not only \"fire weapons\" but land mines in the Battle of Hulugu Valley against the forces of Sima Yi and his son Sima Zhao of the rival Cao Wei state. This claim is dubious, as gunpowder warfare did not develop in China until the advent of the flamethrower (Pen Huo Qi) in the 10th century, while the land mine was not seen in China until the late 13th century.\n\nExplosive land mines were used in 1277 by the Chinese during the Song dynasty against an assault of the Mongols, who were besieging a city in southern China. The invention of this detonated \"enormous bomb\" was credited to one Lou Qianxia of the 13th century. The famous 14th-century Chinese text of the \"Huolongjing\", which was the first to describe hollow cast iron cannonball shells filled with gunpowder, was also the first to describe the invention of the land mine in greater detail than references found in texts written beforehand.\n\nThis mid 14th century work compiled during the late Yuan dynasty and early Ming dynasty (before 1375, when its co-editor Liu Bowen died) stated that mines were made of cast iron and were spherical in shape, filled with either \"magic gunpowder\", \"poison gunpowder\", or \"blinding and burning gunpowder\", any one of these compositions being suitable for use. The wad of the mine was made of hard wood, carrying three different fuses in case of defective connection to the touch hole.\n\nIn those days, the Chinese relied upon command signals and carefully timed calculation of enemy movements into the minefield, since a long fuse had to be ignited by hand from the ambushers in a somewhat far-off location lying in wait. The \"Huolongjing\" also describes land mines that were set off by enemy movement, called the 'ground-thunder explosive camp', one of the 'self-trespassing' (zifan) types, as the text says:\n\nThe \"Huolongjing\" describes the trigger device used for this as a \"steel wheel\", which directed sparks of flame onto the connection of fuses running to the multiple-laid land mines underneath the carefully hidden trap. Further description of how this flint device operated was not made until a Chinese text of 1606 AD revealed that a weight drive (common in medieval clockworks) had been used to work the 'steel wheel'.\n\nThe way in which the Chinese land mine trigger worked was a system of two steel wheels rotated by a falling weight, the cord of which was wound around their axle, and when the enemy stepped onto the disguised boards they released the pins that dropped the weights. In terms of global significance, the first wheellock musket in Europe was sketched by Leonardo da Vinci around 1500 AD, although no use of metal flint for gunpowder weapons were known before that point in Europe.\n\nBesides the use of steel wheels providing sparks for the fuses, there were other methods used as well, such as the 'underground sky-soaring thunder'. The Ming Dynasty (1368–1644) text of the \"Wubei Zhi\" (Treatise on Armament Technology), written by Mao Yuanyi in 1628, outlined the use of land mines that were triggered by the heat of a slow-burning incandescent material in an underground bowl placed directly above the train of fuses leading to the mines buried 3 ft beneath. The booby trap of this mine system had a mound where weapons of halberds, pikes, and lances were dug in, meant to entice the enemy to walk up the small mound and claim their stolen prize of war booty.\n\nWhen the weapons were removed from the mound, this movement disturbed the bowl beneath them where the butt ends of the staffs were, which in turn ignited the fuses. According to the \"Wubei Huolongjing\" volume of the 17th century, the formula for this slow-burning incandescent material allowed it to burn continuously for 20 to 30 days without going out. This formula included of white sandal wood powder, of iron rust (ferric oxide), of 'white' charcoal powder (from quicklime), of willow charcoal powder, of dried, ground, and powdered red dates, and of bran.\n\nThe Chinese also made use of the naval mine at sea and on the rivers of China and elsewhere in maritime battles.\n\nThe first known land mine in Europe was created by Pedro Navarro (d. 1528), a Spanish soldier, who used it in the settles of the Italian castles, in the beginning of the sixteenth century.\n\nAt Augsburg in 1573, a German military engineer by the name of Samuel Zimmermann invented an extremely effective mine known as the \"Fladdermine\". It consisted of a fougasse (or later, sometimes a \"shell fougasse\", that is, a fougasse loaded not with stones but with early black powder mortar shells, similar to large black powder hand grenades) activated by a snaphance or flintlock mechanism connected to a tripwire on the surface. Combining the effects of a tripwire activated bounding fragmentation mine with a cluster bomb, it was devastating to massed attackers but required high maintenance due to the susceptibility of black powder to dampness. Consequently, it was mainly employed in the defenses of major fortifications, in which role it continued to be used until the 1870s.\n\nIn Europe in the early eighteenth century, improvised land mines or booby traps were constructed in the form of bombs buried in shallow wells in the earth and covered with scrap metal and/or gravel to serve as shrapnel. Known in French as \"fougasse\", the term is sometimes still used in the present day to describe such devices. This technique was used in several European wars of the eighteenth century, the American Revolution, and the American Civil War.\n\nThe first modern mechanically fused high explosive anti-personnel land mines were created by Confederate troops of Brigadier General Gabriel J. Rains during the Battle of Yorktown in 1862. As a Captain, Rains had earlier employed explosive booby traps during the Seminole Wars in Florida in 1840. Both mechanically and electrically fused \"land torpedoes\" were employed, although by the end of the war mechanical fuses had been found to be generally more reliable. Many of these designs were improvised in the field, especially from explosive shells, but by the end of the war nearly 2,000 standard pattern \"Rains mines\" had been deployed.\n\nImproved designs of mines were created in Imperial Germany, circa 1912, and were copied and manufactured by all major participants in the First World War. Both sides employed land mines (defensively) and tunnel mines (offensively). Well before the war was over, the British were manufacturing land mines that contained poison gas instead of explosives. Poison gas mines were manufactured at least until the 1980s in the Soviet Union. The United States was known to have at least experimented with the concept in the 1950s.\n\nNuclear mines have also been developed, both land and naval varieties. An example is the British Blue Peacock project, while another was the U.S. Medium Atomic Demolition Munition.\n\nA typical land mine includes the following components:\n\nA land mine can be triggered by a number of things including pressure, movement, sound, magnetism and vibration. Anti-personnel mines commonly use the pressure of a person's foot as a trigger, but tripwires are also frequently employed. Most modern anti-vehicle mines use a magnetic trigger to enable it to detonate even if the tires or tracks did not touch it. Advanced mines are able to sense the difference between friendly and enemy types of vehicles by way of a built-in signature catalog. This will theoretically enable friendly forces to use the mined area while denying the enemy access.\n\nMany mines combine the main trigger with a touch or tilt trigger to prevent enemy engineers from defusing it. Land mine designs tend to use as little metal as possible to make searching with a metal detector more difficult; land mines made mostly of plastic have the added advantage of being very inexpensive.\n\nSome types of modern mines are designed to self-destruct, or chemically render themselves inert after a period of weeks or months to reduce the likelihood of civilian casualties at the conflict's end. These self-destruct mechanisms are not absolutely reliable, and most land mines laid historically are not equipped in this manner.\n\nThere is a common misperception that a landmine is armed by stepping on it and only triggered by stepping off, providing tension in movies. In fact the initial pressure trigger will detonate the mine, as they are designed to kill or maim, not to make someone stand very still until it can be disarmed.\n\nAnti-handling devices detonate the mine if someone attempts to lift, shift or disarm it. The intention is to hinder deminers by discouraging any attempts to clear minefields. There is a degree of overlap between the function of a boobytrap and an anti-handling device insofar as some mines have optional fuze pockets into which standard pull or pressure-release boobytrap firing devices can be screwed. Alternatively, some mines may mimic a standard design, but actually be specifically intended to kill deminers, such as the MC-3 and PMN-3 variants of the PMN mine. Anti-handling devices can be found on both anti-personnel mines and anti-tank mines, either as an integral part of their design or as improvised add-ons. For this reason, the standard render safe procedure for mines is often to destroy them on site without attempting to lift them.\n\nAnti-tank mines were created not long after the invention of the tank in the First World War. At first improvised, purpose-built designs were developed. Set off when a tank passes, they attack the tank at one of its weaker areas — the tracks. They are designed to immobilize or destroy vehicles and their occupants. In U.S. military terminology destroying the vehicles is referred to as a catastrophic kill while only disabling its movement is referred to as a mobility kill.\n\nAnti-tank mines are typically larger than anti-personnel mines and require more pressure to detonate. The high trigger pressure, normally requiring prevents them from being set off by infantry or smaller vehicles of lesser importance. More modern anti-tank mines use shaped charges to focus and increase the armor penetration of the explosives.\n\nAnti-personnel mines are designed primarily to kill or injure people, as opposed to vehicles. They are often designed to injure rather than kill in order to increase the logistical support (evacuation, medical) burden on the opposing force. Some types of anti-personnel mines can also damage the tracks or wheels of armored vehicles.\n\nUnder the Ottawa Treaty, the Parties undertake not to use, produce, stockpile or transfer anti-personnel mines and ensure their destruction.\n\nAs of early 2016, 162 countries have joined the Treaty. Thirty-six countries, including the People's Republic of China, the Russian Federation and the United States, which together may hold tens of millions of stockpiled antipersonnel mines, are not party to the Convention.\n\nIn the asymmetric warfare conflicts and civil wars of the 21st century, improvised explosives, known as IEDs, have partially supplanted conventional landmines as the source of injury to dismounted (pedestrian) soldiers and civilians. IEDs are used mainly by insurgents and terrorists against regular armed forces and civilians. The injuries from the anti-personnel IED were recently reported in BMJ Open to be far worse than with landmines resulting in multiple limb amputations and lower body mutilation.\n\nIn military science, minefields are considered a defensive or harassing weapon, used to slow the enemy down, to help deny certain terrain to the enemy, to focus enemy movement into kill zones, or to reduce morale by randomly attacking material and personnel. In some engagements during World War II, anti-tank mines accounted for half of all vehicles disabled.\n\nSince combat engineers with mine-clearing equipment can clear a path through a minefield relatively quickly, mines are usually considered effective only if covered by fire.\n\nThe extents of minefields are often marked with warning signs and cloth tape, to prevent friendly troops and non-combatants from entering them. Of course, sometimes terrain can be denied using dummy minefields. Most forces carefully record the location and disposition of their own minefields, because warning signs can be destroyed or removed, and minefields should eventually be cleared. Minefields may also have marked or unmarked safe routes to allow friendly movement through them.\n\nPlacing minefields without marking and recording them for later removal is considered a war crime under Protocol II of the Convention on Certain Conventional Weapons, which is itself an annex to the Geneva Conventions.\n\nArtillery and aircraft scatterable mines allow minefields to be placed in front of moving formations of enemy units, including the reinforcement of minefields or other obstacles that have been breached by enemy engineers. They can also be used to cover the retreat of forces disengaging from the enemy, or for interdiction of supporting units to isolate front line units from resupply. In most cases these minefields consist of a combination of anti-tank and anti-personnel mines, with the anti-personnel mines making removal of the anti-tank mines more difficult. Mines of this type used by the United States are designed to self-destruct after a preset period of time, reducing the requirement for mine clearing to only those mines whose self-destruct system did not function. Some designs of these scatterable mines require an electrical charge (capacitor or battery) to detonate. After a certain period of time, either the charge dissipates, leaving them effectively inert or the circuitry is designed such that upon reaching a low level, the device is triggered, thus destroying the mine.\n\nNone of the conventional tactics and norms of mine warfare applies when they are employed in a guerrilla role: \n\nLand mines were commonly deployed by insurgents during the South African Border War, leading directly to the development of the first dedicated mine-protected armoured vehicles in South Africa. Namibian insurgents used anti-tank mines to throw South African military convoys into disarray before attacking them. To discourage detection and removal efforts, they also laid anti-personnel mines directly parallel to the anti-tank mines. This initially resulted in heavy South African military and police casualties, as the vast distances of road network vulnerable to insurgent sappers every day made comprehensive detection and clearance efforts impractical. The only other viable option was the adoption of mine-protected vehicles which could remain mobile on the roads with little risk to their passengers even if a mine was detonated. South Africa is widely credited with inventing the v-hull, a vee-shaped hull for armoured vehicles which deflects mine blasts away from the passenger compartment.\n\nDuring the ongoing Syrian Civil War, Iraqi Civil War (2014–present) and Yemeni Civil War (2015–present) landmines have been used for both defensive and guerrilla purposes.\n\nMinefields may be laid by several means. The preferred, but most labour-intensive, way is to have engineers bury the mines, since this will make the mines practically invisible and reduce the number of mines needed to deny the enemy an area. Mines can be laid by specialized mine-laying vehicles. Mine-scattering shells may be fired by artillery from a distance of several tens of kilometers.\n\nMines may be dropped from helicopters or airplanes, or ejected from cluster bombs or cruise missiles.\n\nAnti-tank minefields can be scattered with anti-personnel mines to make clearing them manually more time-consuming; and anti-personnel minefields are scattered with anti-tank mines to prevent the use of armored vehicles to clear them quickly. Some anti-tank mine types are also able to be triggered by infantry, giving them a dual purpose even though their main and official intention is to work as anti-tank weapons.\n\nSome minefields are specifically booby-trapped to make clearing them more dangerous. Mixed anti-personnel and anti-tank minefields, anti-personnel mines \"under\" anti-tank mines, and fuses separated from mines have all been used for this purpose. Often, single mines are backed by a secondary device, designed to kill or maim personnel tasked with clearing the mine.\n\nMultiple anti-tank mines have been buried in stacks of two or three with the bottom mine fuzed, in order to multiply the penetrating power. Since the mines are buried, the ground directs the energy of the blast in a single direction—through the bottom of the target vehicle or on the track.\n\nAnother specific use is to mine an aircraft runway immediately after it has been bombed in order to delay or discourage repair. Some cluster bombs combine these functions. One example is the British JP233 cluster bomb which includes munitions to damage (crater) the runway as well as anti-personnel mines in the same cluster bomb.\n\nMetal detectors were first used for demining, after their invention by the Polish officer Józef Kosacki. His invention, known as the Polish mine detector, was used by the Allies alongside mechanical methods, to clear the German mine fields during the Second Battle of El Alamein when 500 units were shipped to Field Marshal Montgomery's Eighth Army.\n\nThe Nazis used captured civilians who were chased across minefields to detonate the explosives. According to Laurence Rees \"Curt von Gottberg, the SS-Obergruppenführer who, during 1943, conducted another huge anti-partisan action called Operation Kottbus on the eastern border of Belarus, reported that 'approximately two to three thousand local people were blown up in the clearing of the minefields'.\"\n\nWhereas the placing and arming of mines is relatively inexpensive and simple, the process of detecting and removing them is typically expensive, slow, and dangerous. This is especially true of irregular warfare where mines were used on an ad hoc basis in unmarked areas. Anti-personnel mines are most difficult to find, due to their small size and the fact that many are made almost entirely of non-metallic materials specifically to escape detection.\n\nManual clearing remains the most effective technique for clearing mine fields, although hybrid techniques involving the use of animals and robots are being developed. Animals are desirable due to their strong sense of smell, which is more than capable of detecting a land mine. Animals like rats and dogs can also differentiate between other metal objects and land mines because they can be trained to detect the explosive agent itself.\n\nOther techniques involve the use of geo-location technologies. A joint team of researchers at the University of New South Wales and Ohio State University is working to develop a system based on multi-sensor integration.\n\nThe laying of land mines has inadvertently led to a positive development in the Falkland Islands. Mine fields laid near the sea during the Falklands War have become favorite places for penguins, which do not weigh enough to detonate the mines. Therefore, they can breed safely, free of human intrusion. These odd sanctuaries have proven so popular and lucrative for ecotourism that efforts exist to prevent removal of the mines.\n\nThe use of land mines is controversial because they are indiscriminate weapons, harming soldier and civilian alike. They remain dangerous after the conflict in which they were deployed has ended, killing and injuring civilians and rendering land impassable and unusable for decades. To make matters worse, many factions have not kept accurate records (or any at all) of the exact locations of their minefields, making removal efforts painstakingly slow. These facts pose serious difficulties in many developing nations where the presence of mines hampers resettlement, agriculture, and tourism. The International Campaign to Ban Landmines campaigned successfully to prohibit their use, culminating in the 1997 Convention on the Prohibition of the Use, Stockpiling, Production and Transfer of Anti-Personnel Mines and on their Destruction, known informally as the Ottawa Treaty.\n\nThe Treaty came into force on 1 March 1999. The treaty was the result of the leadership of the Governments of Canada, Norway, South Africa and Mozambique working with the \"International Campaign to Ban Landmines\", launched in 1992. The campaign and its leader, Jody Williams, won the Nobel Peace Prize in 1997 for its efforts.\n\nThe treaty does not include anti-tank mines, cluster bombs or claymore-type mines operated in command mode and focuses specifically on anti-personnel mines, because these pose the greatest long term (post-conflict) risk to humans and animals since they are typically designed to be triggered by any movement or pressure of only a few kilograms, whereas anti-tank mines require much more weight (or a combination of factors that would exclude humans). Existing stocks must be destroyed within four years of signing the treaty.\n\nSignatories of the Ottawa Treaty agree that they will not use, produce, stockpile or trade in anti-personnel land mines. In 1997, there were 122 signatories; the Treaty has now been signed by 162 countries. Another 34 have yet to sign on. The United States is not one of the signatories, based on lacking an exception for the DMZ of Korea.\n\nThere is a clause in the treaty, Article 3, which permits countries to retain land mines for use in training or development of countermeasures. Sixty-four countries have taken this option.\n\nAs an alternative to an outright ban, 10 countries follow regulations that are contained in a 1996 amendment of Protocol II of the Convention on Conventional Weapons (CCW). The countries are China, Finland, India, Israel, Morocco, Pakistan, South Korea and the United States. Sri Lanka, which had adhered to this regulation announced in 2016, that it would join the Ottawa Treaty.\n\nThe ICBL has identified the following countries as manufacturing land mines as of August 2004. None are signatories of the Ottawa Treaty.\n\nOf other states which are thought to have manufactured mines recently:\n\nTackling the issue of land mines is a difficult one, as it involves a number of different approaches and disciplines to consider. It requires attempting to prevent the planting of landmines in the first place, removing those in place and finding viable approaches to deal with the negative implications that have already occurred.\n\nThe purpose of mines are often placed, and succeed in, “decreasing access to fresh water, increasing the rates of water-born diseases and malnutrition, and decreasing the access of livestock to water sources”. \n\nLand mines have been proven to have many different negative affects on the environment, both in the social and natural realms.\n\nThroughout the world (specifically in Europe, North Africa and Asia, etc.), there are millions of hectares that remain contaminated with land mines.\n\nAlthough mines that cost only a few dollars to plant may be viewed as cheap military weapons, they require hundreds or thousands of dollars to remove, and perpetrate huge costs in both humanitarian and environmental damages.\n\nWhen comparing the amount of deaths caused by weapons of mass destruction, in which mines are rarely classified under, nuclear and chemical combined have not killed nearly as many compared to land mines.\n\nWhen these mines do explode, other than causing severe cases of injury and death to humans and wildlife, they destroy soil, plant and water systems which, in turn, accelerate ecosystem disruption.\n\nIn addition, natural disasters can have a significant impact on the process of demining areas of land. For example, the floods that occurred in Mozambique in 1999 and 2000, possibly displaced hundreds of thousands of land mines left from the war, which caused concern about their locations and thereby delayed recovery efforts.\n\nThe effect that landmines on environmental degradation can be observed on a number of different scales.\n\nFrom a recent study done by Asmeret Asefaw Berhe, the environmental aftermath of a land mine explosion depends on: “(i) the objectives and methodological approaches of the investigation; (ii) concentration of mines in a unit area; (iii) chemical composition and toxicity of the mines; (iv) previous uses of the land and (v) alternatives that are available for the affected populations.” \n\nAccording to Berhe, the ways in which land degradation is caused by land mines “can be classified into five groups: access denial, loss of biodiversity, micro-relief disruption, chemical composition, and loss of productivity”.\n\nThe most prominent ecological issue associated with landmines (or fear of) is access denial to vital resources. In this context, ‘access’ refers to the ability to use resources, compared to ‘property’ which refers to the right to use resources.\n\nThe presence and fear of presence of even a single landmines can deny people access to land that they need for agricultural practices, water supplies and possibly conservation measures.\n\nContrastingly, access denial has been observed to have ‘positive’ effects when the mined areas become ‘no-man’s land’.\n\nAs research and experiments have shown in the past, during limited human interference plants and vegetation, get a chance to grow and recover.\n\nFor example, formerly arable lands in Nicaragua were turned into forests and remained undisturbed after the establishment of landmines. However, these benefits can only last as long as animals, tree limbs, etc. do not detonate the mines. In addition, long idle periods could “potentially end up creating or exacerbating loss of productivity”, particularly within land of low quality.\n\nBiodiversity can be threatened by landmines in a certain region by wiping out vegetation and possible wildlife, during explosion or de-mining.\n\nLandmines can also pose an extra burden for threatened and endangered species, possibly pushing species to extinction. They have been known to be used to target endangered species by poachers.\n\nDisplaced people and refugees can “further contribute to the loss of biodiversity when they hunt animals for food or destroy their habitat in order to make shelters for themselves”, after being forced to do so, as they learn and are directly affected by the presence of landmines.\n\nShrapnel or abrasions of their bark or roots caused by detonated mines, can cause the slow death of trees and provide entry sites for wood-rotting fungi.\n\nThose areas where the land is no longer able to be used for farming practices, because of landmines, make residents resort to the forests to meet all of their survival needs. This makes for many forested areas to become exploited by affected populations, furthering the loss of biodiversity.\n\nContaminated soils, particularly with heavy metals, is a very common observance in areas close by to mines after they explode or decay. Products produced from the explosives, both organic and inorganic substances, are most likely to be “long lasting, water-soluble and toxic even in small amounts”. They can be implemented either “directly or indirectly into soil, water bodies, microorganisms and plants with drinking water, food products or during respiration”.\n\nToxic compounds can also find its way into important water areas and cause bioaccumulation within land animals, fish and plants. Their effects could be deadly to some animals and other organisms “by acting as a nerve poison to hamper growth”.\n\n“One study in Central Vietnam found that nearly 7,000 hectares of land-enough to support 12,000 families continued to remain unproductive because of land mines.”\n\nThe presence of land mines in previously inhabited areas may also cause population shifts, resulting in overcrowding in urban areas with a subsequently increased risk of infectious disease transmission.\n\nLand mine presence may also cause populations to shift to urban areas where overcrowding and risk of spreading diseases are likely to occur.\n\nReconstruction and development efforts of important structures, including schools and hospitals, are also likely to be delayed by the presence of land mines.\n\n\n\n\n"}
{"id": "7499462", "url": "https://en.wikipedia.org/wiki?curid=7499462", "title": "Lanthanide trifluoromethanesulfonates", "text": "Lanthanide trifluoromethanesulfonates\n\nLanthanide triflates are triflate salts of the lanthanide family with many uses in organic chemistry as Lewis acid catalysts. The catalysts act similarly to aluminium chloride or ferric chloride, but are stable in water, which makes it possible to use water as a solvent instead of organic solvents.\n\nLanthanide triflates consist of a lanthanide metal ion and three triflate ions. The lanthanides, or rare earth metals, are the elements from lanthanum to lutetium in the periodic table. Triflate is a contraction of trifluoromethanesulfonate; its molecular formula is CFSO, and is commonly designated ‘OTf’. Triflic acid is a ‘superacid’ so its conjugate base ions are very stable. Lanthanide triflates are normally nonahydrates, mostly commonly depicted as Ln(OTf)·(HO); however, in the solid state and in aqueous solution, the waters are bound to the lanthanide and the triflates are counteranions, so more accurately lanthanide triflate nonahydrate is written as [Ln(HO)](OTf). Anhydrous lanthanide triflates, Ln(OTf), are also easily obtained as described below. The metal triflate complex is strongly electrophilic, thus acts as a strong Lewis acid.\n\nLanthanide triflates are synthesized from lanthanide oxide and aqueous triflic acid. In a typical preparation, a 1:1 (v/v) solution of trilfic acid in water is added to a slight stoichiometric excess of lanthanide oxide. The mixture is stirred and heated at 100 °C for a few hours, and the excess lanthanide oxide is filtered off. The excess oxide ensures all of the triflic acid is consumed. The water is removed under reduced pressure (or simply boiled away) to leave a hydrated lanthanide triflate, Ln(HO)(OTf).\n\nIn simplified form the reaction is\n\nLnO + 6HOTf → 2Ln(OTf) + 3HO\n\nSince the reaction takes place in aqueous solution, more accurately,\n\nLnO + 6HOTf + 18HO → 2[Ln(HO)](OTf) + 3HO\n\nAnhydrous lanthanide triflates can be produced by dehydrating their hydrated counterparts by heating between 180 and 200 °C under reduced pressure for 48 hrs. This is a major advantage of lanthanide triflates compared to lanthanide halides, whose anhydrous forms require more tedious synthetic procedures because they cannot be obtained by dehydrating their hydrates (because of oxyhalide formation).\n\n[Ln(HO)](OTf) → Ln(OTf) + 9HO (180-200 °C, ~10 - 10 torr, 48 hrs)\n\nLewis acids are used to catalyse a wide variety of reactions. The mechanism steps are:\n\nCommon Lewis acids include aluminium chloride, ferric chloride and boron trifluoride. These reactions are usually carried out in organic solvents; AlCl, for example, reacts violently with water. Typical solvents are dichloromethane and benzene.\n\nLanthanide triflates can replace conventional Lewis acids in various types of reactions. One important class is Friedel-Crafts acylations and alkylations, which are one of few ways to add C-C bonds to aromatics. The synthesized products are used in many products including pharmaceuticals and agrochemicals.\n\nThese reactions are usually carried out with AlCl as the catalyst, in an organic solvent. In the acylation reaction, AlCl complexes with the product. It must be added in large excess and is destroyed during product recovery, so atom efficiency is poor. The reaction is quenched with water, creating large volumes of corrosive aluminous, acidic waste- 3 mol HCl per mol AlCl. In one example, Clark et al. estimate 0.9 kg of AlCl is wasted per kilogram of dimethyl acetophenone produced. Product separation can also be difficult.\n\nLanthanide triflates can dramatically cut the impact of these syntheses. They are able to achieve high conversion using small quantities. These catalysts are stable in water, so avoid the need for organic solvents; some reaction rates are even enhanced by aqueous systems. They don’t complex with products, so separation is simple, and the catalyst is easily recovered- in many cases the solution is simply reused.\n\nLa(OTf) catalysts can also reduce the number of processing steps and use greener reagents; Walker et al. reported successful acylation yields using carboxylic acid directly, rather than acyl chloride. Their process generates only a small volume of aqueous sodium bicarbonate waste. Similar results have been cited for the direct acetylation of alcohols.\n\nLa(OTf) catalysts have been used for many other carbon-carbon bond forming reactions, such as Diels-Alder, aldol, and allylation reactions. Some reactions require a mixed solvent, such as aqueous formaldehyde, although Kobayashi et al. have developed alternative surfactant-water systems.\n\nMichael additions are another very important industrial method for creating new carbon-carbon bonds, often with particular functional groups attached. Addition reactions are inherently atom efficient, so are preferred synthesis pathways. La(OTf) catalysts not only enable these reactions to be carried out in water, but can also achieve asymmetric catalysis, yielding a desired enantio-specific or diastereo-specific product.\n\nLewis acids are also used to catalyse many C-N bond-forming reactions. Pyridine compounds are common in biology and have many applications. Normally, pyridine is synthesized from acetaldehyde, formaldehyde and ammonia under high temperatures and pressures. Lanthanide triflates can be used to synthesize pyridine by catalysing either the condensation of aldehydes and amines, or the aza Diels-Alder reaction catalytic synthesis. Again, water can be used as a solvent, and high yields can be achieved under mild conditions.\n\nNitro compounds are common in pharmaceuticals, explosives, dyes, and plastics. As for carbon compounds, catalysed Michael additions and aldol reactions can be used. For aromatic nitro compounds, synthesis is via a substitution reaction. The standard synthesis is carried out in a solution of nitric acid, mixed with excess sulfuric acid to create nitronium ions. These are then substituted on to the aromatic species. Often, the para-isomer is the desired product, but standard systems have poor selectivity. As for acylation, the reaction is normally quenched with water, and creates copious acidic waste. Using a La(OTf) catalyst in place of sulfuric acid reduces this waste considerably. Clark et al. report 90% conversion using just 1 mol% of ytterbium triflate in weak nitric acid, generating only a small volume of acidic waste.\n\nLa(OTf) catalysts have also been used for cyanations, and three-component reactions of aldehydes, amines & nucleophiles.\n\nThe substitution of organic solvents by water reduces the amount of waste and the metals are recoverable and hence reusable.\n\nGenerally, the benefits of these catalysts include:\n\n\nLanthanide triflates are one of the most promising green chemistry catalysts. Unlike most conventional catalysts, these compounds are stable in water, so avoid the need for organic solvents, and can be recovered for reuse. Since leading researcher Kobayashi’s 1991 paper on their catalytic effect in water, the range of researched applications for La(OTf) catalysts has exploded. The commercialisation of these techniques has the potential to significantly reduce the environmental impact of the chemical industries.\n\nThe main disadvantages of these new catalysts compared with conventional ones are less industrial experience, reduced availability and increased purchase cost. As they contain rare metals and sulfonate ions, the production of these catalysts may itself be a polluting or hazardous process. For example, metal extraction usually requires large quantities of sulfuric acid. Since the catalyst is recoverable, these disadvantages would be less over time, and the cost savings from reduced waste treatment and better product separation may be substantially greater.\n\nThe toxicity of individual lanthanides vary. One vendor MSDS lists safety considerations including dermal/eye/respiratory/GI burns on contact. It also lists possible hazardous decomposition products including CO, CO, HF and SO. The compounds are hygroscopic, so care is required for storage and handling. However, these considerations also apply to the more common catalysts.\n\nThese possible disadvantages are difficult to quantify, as essentially all public domain publications on their use are by research chemists, and do not include Life Cycle Analysis or budgetary considerations. Future work in these areas would greatly encourage their uptake by industry.\n\nResearchers are continually finding new applications where it can replace other less efficient, more toxic Lewis acids. Recently it has been tested in synthesizing epoxies and other polymerisation reactions, and in polysaccharide synthesis. It has also been trialled in green solvents other than water, such as ionic liquids and supercritical carbon dioxide. To enhance recovery, researchers have developed La(OTf) catalysts stabilised by ion exchange resin or polymer backbones, which can be separated by ultrafiltration. Solvent-free systems are also possible with solid-supported catalysts.\n"}
{"id": "46400855", "url": "https://en.wikipedia.org/wiki?curid=46400855", "title": "Lev Binzumovich Leviev", "text": "Lev Binzumovich Leviev\n\nLev Binzumovich Leviev (born June 22, 1984, Volgograd) is a Israeli-Russian entrepreneur and investor, co-founder of Russia's largest social network \"VK.com\" (originally \"VKontakte\") and the \"Selectel\" data center network.\n\nLev Leviev grew up in the family of a Volgograd entrepreneur and went to an American school in Herzliya, Israel, where he met his future business partner Vyacheslav Mirilashvili. In 2006, he graduated with a bachelor of Commerce degree in Finance and Accounting at McGill University in Canada.\n\nMarried. \n\nIn 2012, a Hopes&Fears magazine established his net worth to be $218 mln.\n\nIn 2014, he ranked 66th in the rating of the financial magazine “Delovoy Peterburg” with ₽11,4 bln, in 2015 - 42nd with ₽20 bln and in 2016 — 43rd with ₽25,2 bln.\n\nAfter graduating in 2006, he moved to Saint Petersburg and founded \"VK.com\" with his friends Vyacheslav Mirilashvili and Pavel Durov.\n\nLev and Vyacheslav invested tens of thousands of dollars in the project. The money was borrowed from Mirilashvili-Sr. Leviev’s share was 10%. From the moment of founding the company till 2012 he was the Chief Operating Officer of VK.\n\nYuri Milner's \"Digital Sky Technologies\" fund was the company’s first external investor. He bought a quarter of the network in 2007 and later merged DST’s shareholdings into the \"Mail.Ru Group\" later. In the end of 2010, the holding increased its VK shares by 7,5% - from 24,99% to 32,49%. In addition, the new shareholder secured the option of buying another 7,5% of VK.com in 2011.\nIn July, 2011 Mail.ru exercised the option and increased their shareholding to 39,99% which decreased the total share of the partners from 55,5% to 48,01% making Lev’s share either 6% or 8%, according to different sources.\n\nHaving learned about negotiations between co-founders and Alisher Usmanov in March 2012, Durov deleted their profiles codice_1 and codice_2. Leviev and Mirilashvili were planning to exit VK investment via the IPO for $3 bln, but in the end of March, Durov announced that social network will not IPO for an undefined period.\n\nIn April 2013, It is estimated that Ilya Sherbovich investment fund \"United Capital Partners\" payed $840 mln for a partner’s share, assuming the whole network’s worth at $1,75 bln. Leviev could get $105-140 mln.\n\nDuring the conflict between \"UCP\" and Pavel Durov, the fund considered Lev Leviev as a potential CEO of VK.\n\nIn 2007 Lev Leviev and Vyacheslav Mirilashvili founded \"Selectel\" data center to provide for \"VK\"’s needs in processing and storing servers. By 2009, \"VK.com\"’s full server capacity was managed by \"Selectel\". In 2012, \"VK\" opened its own data center, but it still remains to be a client of \"Selectel\".\n\nAfter selling his \"VK\" shares in September 2014, Lev Leviev became CEO at \"Selectel\".\n\nIn May 2014 it was reported that \"Selectel\" was investing ₽1 bln in a technopark in Saint Petersburg that would include a data center, offices and warehouses.\nOn December 17 2015, in the presence of Saint Petersburg governor Georgi Poltavchenko, Leviev opened the largest data-centre in the North-West of Russia, “Tsvetochnaya 2”.\n\nIn the end of 2016 \"Selectel\" ranked fourth largest IaaS provider for public and hybrid cloud in Russia based on revenue.\n\nIn 2017, the company was one of the largest IaaS providers in Russia, with a market share of 7%. \n\nIn the end of 2017, Lev stepped down from the CEO position, while remaining the chairman of the board of directors.\n\nIn 2014, Lev co-founded \"BlockTrail\" with his long time friend, Boaz Bechar. Lev set up the holding company \"BlockCorp\" which made an initial investment of 500k euros in the \"BlockTrail\" project. The company developed block explorer, bitcoin transaction analytic tools and multi-platform bitcoin wallets.\n\nIn 2016 the project was bought by a Chinese producer of equipment for mining bitcoins \"Bitmain\" and renamed to \"BTC Wallet\" (btc.com).\n\nSince 2011, Lev Leviev has actively invested in the Russian technological sector both as a private investor and as a partner of the \"Vaizra Capital\" fund.\n\nSuch investments include:\n\nLev Leviev has also invested in international projects, such as:\n\nLev Leviev is an investors of \"DST Global II\" fund and \"DST Global IV\" fund of Yuri Milner.\n\n\"DST Global II owns shares of \"Facebook\", \"Twitter\", \"Airbnb\", \"Spotify\", \"Alibaba\" and \"Xiaomi\".\n\nAmong the famous investments of \"DST Global IV\" are an Indian car service \"Ola Cabs\", an Indian online shop \"Flipkart\" and a developer of the corporate messenger Slack.\n"}
{"id": "37851018", "url": "https://en.wikipedia.org/wiki?curid=37851018", "title": "List of Swiss inventions and discoveries", "text": "List of Swiss inventions and discoveries\n\nThe following list is composed of items, techniques and processes that were invented by or discovered by people from Switzerland.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nList of Swiss inventors and discoverers\n"}
{"id": "200884", "url": "https://en.wikipedia.org/wiki?curid=200884", "title": "List of banned films", "text": "List of banned films\n\nThis is a list of banned films.\n\nFor nearly the entire history of film production, certain films have been banned by film censorship or review organizations for political or moral reasons or for controversial content, such as racism. Censorship standards vary widely by country, and can vary within an individual country over time due to political or moral change.\n\nMany countries have government-appointed or private commissions to censor and rate productions for film and television exhibition. While it is common for films to be edited to fall into certain rating classifications, this list includes only films that have been explicitly prohibited from public screening.\n\n\n\n"}
{"id": "55624901", "url": "https://en.wikipedia.org/wiki?curid=55624901", "title": "MagnaReady", "text": "MagnaReady\n\nMagnaReady is an American clothing technology and e-commerce brand based in Raleigh, North Carolina that produces adaptive clothing for those with dexterity issues. Maura Horton, adaptive clothing pioneer, created MagnaReady in 2013 after her husband, Don Horton struggled buttoning shirts. MagnaReady is the original magnetic shirt technology and it is patented. MagnaReady was the first adaptive clothing technology to reach mass market, with the technology licensed to products available at many online retailers.\n\nIn 2009, Don Horton, a football coach at North Carolina State University, struggled to button his shirt in the locker room due to Parkinson's disease. That day his shirt was buttoned by Russell Wilson, but his wife, Maura Horton, wanted a better solution for her husband. A former children's clothing designer, she decided to sew magnets into her husband's shirts for ease of use. In 2015, a patent was granted on the technology developed.\n\nIn early 2013, after a few years of research, design, and sourcing, the MagnaReady technology was used in shirts launched under a brand by the same namesake. The initial small run of shirts was targeted to elderly men with mobility issues.\n\nIn 2016, PVH Corp., producer of Van Heusen, Tommy Hilfiger, Calvin Klein, and IZOD, licensed the MagnaReady technology in order to bring the adaptive shirts to a mass-market audience through stores and e-commerce. In September 2016, a co-branded line of VanHeusen MagnaClick shirts were unveiled and marketed to men suffering from Parkinson's disease.\n\nIn September 2017, the MagnaReady technology was licensed in a partnership with LF Americas, a division of Li & Fung, to bring the adaptive products to a larger retail audience.\n\nIn October 2017, a shirt using MagnaReady technology was featured by New York’s Museum of Modern Art in the \"Items: Is Fashion Modern?\" exhibit as the modern version of a male dress shirt. The exhibit is scheduled to run through January 28, 2017.\n\nMagnaClick is an adaptive clothing brand based on the MagnaReady technology developed by Maura Horton that is distributed and sold via licensing of the patented technology.\n\nThe MagnaClick brand was born in 2016 when MagnaReady technology was licensed to PVH Corp. to create a line of Van Heusen MagnaClick dress shirts for men. PVH billed it as \"a game-changing product that offers a stylish, high quality solution for consumers with limited dexterity or those seeking an alternative to buttons.” The shirts were to be sold by select retailers in-store and online in the fall of 2016, including Amazon, Belk, J.C. Penney and Kohl’s.\n\nIn 2017, MagnaClick expanded through a partnership with LF Americas, a division of Li & Fung Limited. The partnership will initially expand the brand to men's and women's shirting as well as children's school uniforms. The new MagnaClick line will debut with LF Americas retail partners in 2018.\n"}
{"id": "23062020", "url": "https://en.wikipedia.org/wiki?curid=23062020", "title": "Marketing information system", "text": "Marketing information system\n\nA marketing information system (MKIS) is a management information system (MIS) designed to support marketing decision making. Jobber (2007) defines it as a \"system in which marketing data is formally gathered, stored, analysed and distributed to managers in accordance with their informational needs on a regular basis.\" In addition, the online business dictionary defines Marketing Information System (MKIS) as \"a system that analyzes and assesses marketing information, gathered continuously from sources inside and outside an organization or a store.\" Furthermore, \"an overall Marketing Information System can be defined as a set structure of procedures and methods for the regular, planned collection, analysis and presentation of information for use in making marketing decisions.\" (Kotler, at al, 2006)\n\nReid and Bojanic(2010) claimed that, \" The term market research informs relatively narrowerly than Marketing Information System(MkIS) which is altered from the term management information systemization. Market research indicates that information is not collected for a specific reason or project; the major objective is a one-time use. \"\n\n\"A marketing information system, which continuously collects the initial, routine and systematic data, is not only used for one particular topic but is designed for monitoring the degree of the marketing success to ensure the achievable of the operation as well.\"\n\nDeveloping a MKIS system is becoming extremely important as the strength of economies rely on services and to better understand the specific needs of customers. Kotler, et al. (2006) defined it more broadly as \"people, equipment, and procedures to gather, sort, analyze, evaluate, and distribute needed, timely, and accurate information to marketing decision makers.\"\n\nInsofar as an economy focuses on services, marketing is important to \"monitor the marketing environment for changes in buyer behavior competition, technology, economic conditions, and government policies.\" In this sense, the role of marketing is becoming pivotal for an organization to \"adapt to changes in the market environment.\" (Harmon, 2003)\n\nAs an economy relies on the acquisition of knowledge, MkIS systems are necessary to be able to define and differentiate the value proposition that one organization provides with respect to another, as well as to define their competitive advantage. (Harmon, 2003)\n\nThe main benefit of MkIS systems is to integrate market-monitoring systems with strategy development and the strategic implementation of policies and processes that help capture and act on customer management applications with marketing decision support systems. This area constitute Marketing intelligence that supports the analysis and market based activities that support customer relations and customer service with real time information with real time applications that support market based approaches.\n\nShajahan and arya(2004) stated that, \"Demands for the MkIS can be expressed by three crucial developments. Firstly, when companies expand and diversify into new markets, both the companies and customer's point of view are needed to be handled by the marketing managers. Therefore, there would be greater need for marketing information. Secondly, when consumers obtain an increment in the level of their income, it causes a tendency for them to be more discriminating during the purchasing procedure. A full awareness of the points that drive a consumer prefer a brand and the points that distinguished his brand from that of the rivals should be obtained by the marketers. This awareness is possible only with the help of a well- designed effective MkIS. Thirdly, the development of the markets and the movement from price to non-price grounds of competition lead to an increase in the importance of adoption and implementation by the competitors and finding the response of the consumers towards them. Analyzing the needs for MkIS from a third person's angle, three more factors come to the forefront viz., the information explosion, increasing complexity in decision making and the technological developments. \" \n\nIn addition, \"Great demand of information gathering for marketing decisions results in the need of attention by themselves. Though marketing research information can be generated by studies, which are normally conducted in the market place whereas marketing information systems are designed to gather, integrate, process and distribute marketing information comprehensively from all sources, including that from marketing research. The contrasting characteristics of MkIS and MR are presented in Table 5.1 as shown below:\n\nTable 5.1 Showing contrasting characteristic of MR and MkIS\n\nThe business function of marketing is concerned more with the planning, promotion and sale of products in existing markets and the development of new products and new markets. Thus marketing performs a vital function in the operation of a business enterprise. Business firms who turned to computers have been able to perform vital marketing function effectively for organizations' growth in the face of global competition.\"\n\nAccording to Robert Jamon (2003), MkIS systems are decomposed on four components: (1) user interfaces, (2) application software, (3) databases, and (4) system support. The following is a description of each one of these components.\n\n1. User interfaces. The essential element of the MAkINAS is the managers who will use the system and the interface they need to effectively analyze and use marketing information. The design of the system will depend on what type of decision managers need to make.\n\n2. Application software. These are the programs that marketing decision makers use to collect, analyze, and manage data for the purpose of developing the information necessary for marketing decisions.\n\n3. Database marketing. A marketing database is a system in which marketing data files are organized and stored.\n\n4. System support. This component consists of system managers who manage and maintain the system assets including software and hardware network, monitor its activities and ensure compliance with organizational policies.\n\nAlong with these components, MkIS systems include Marketing Decision Support Systems (MDSS), which in turn rely on simple systems such as Microsoft Excel, SPSS, and on-line analytical tools that help collect data. Data compiled for analysis is stored and processed from a data warehouse, which is simply a data repository system that helps store and further process data collected internally and externally. (Harmon, 2003)\n\nFrom Pride and Ferrell (2010), \"Internal database is a part of the most marketing information systems. In addition, it's relatively convenient for access and retrieve of information. A databases allow marketers to tap into an abundance of information useful in making marketing decisions: internal sales reports, newspaper articles, company news releases, government economic reports, bibliographies, and more, often accessed through a computer system.\"\n\nIn with Birn(2004), \" internal data is a part of the data that is needed to be collect and handled by the marketing information system. Further more, managers regard this as a command to make effective operation.But getting the information that is really needed from a marketing information system depends on what the information is and how it is used. The following internal operating data are essential:\n\nSandhusen(2000) defined that, environmental scanning is a display of the nature of MIS processed. \" It gives assistance for the marketers to develop the strategies, policies, plans and to make programs and budgets through dealing with the ongoing information on trends.\"\n\nAccording to Philip Kotler, the four components that comprise the MkIS system are Internal Reports (Records) System, Marketing Research System, Marketing Intelligence System, and Marketing Decision Support System\n\n1.Internal Reports System: It records various data from different department of a company, which is regarded as a major source of information.\n\n2.Marketing Intelligence System: It is a main source used by managers for gaining daily information of the external environment, hence assists the managers to react to the changing rapidly.\n\n3.Marketing Research System: It is used to collect primary and secondary data, and displays the results in forms of reports.\n\n4.Marketing Decision Support System: Compared to the supply of the data by the three previous systems, it focuses more on processing the data.\n\nBhasin stated that,\"With an increasingly competitive and expanding market, the amount of information needed daily by an organization is profound. So they have to establish a Marketing Information system. There are several advantages of Marketing information systems\n\n\n\"Nevertheless, the collection of marketing information should obey a high-frequent manner due to the rapid change in the external market.\" The possible risks the business may face if they disobey the manner according to Bhasin are:\n\nMaintenance, complexity and setting up a MkIS are one of the major hindrances to Marketing information systems. Furthermore, wrong information being fed in MkIS can become cumbersome and appropriate filters need to be established.\n\nKotler and Philip have said that \"both primary and secondary researches offer loads of the data and information needed for the marketers, whereas the secondary data sources are relatively superior in quick provision of data at lower cost. Simultaneously, a firm cannot find all the data required by itself, but sometimes can be done with the help of secondary research. However, researchers must assess those data collected from both primary and secondary data sources to enable the accuracy, updates and fairness. Each primary data collection method – observational, survey, and experimental – has its own advantages and disadvantages. Similarly, each of the various research contact methods – mail, telephone, personal interview, and online – also has its own advantages and drawbacks.\" \n\nA RuMIS is necessary not only for corporate organizations engaged in marketing of agricultural goods and manufactured goods intended for sales in rural areas. RuMIS is required also by the agriculturists and farmers who have enormous decis!ion-making to do.\n"}
{"id": "426916", "url": "https://en.wikipedia.org/wiki?curid=426916", "title": "Model year", "text": "Model year\n\nThe model year (MY) of a product is a number used worldwide, but with a high level of prominence in North America, to describe approximately when a product was produced, and it usually indicates the coinciding base specification (design revision number) of that product.\n\nThe model year and the actual calendar year of production rarely coincide. For example, a North American 2015 model year automobile is available during most of the 2015 calendar year, but is usually also available from the third quarter of 2014 because production of the 2015 model began in July or August 2014, continuing to May/June/July 2015. \n\nThe variables of build date and design revision number are semi-independent. There is no natural law that forces one to be strictly correlated to the other, other than that:\n\nAlfred P. Sloan extended the idea of yearly fashion-change from clothing to automobiles in the 1920s. His company, General Motors, was the first to introduce planned obsolescence (in cars) by means of making the production date, and thus the car's newness or lack of it, visually discernible.\n\nEuropean and Japanese automakers can utilise the term \"model year\" in respect of model availability dates in North American markets: these often receive updated models significantly later than domestic markets, especially in the event of unforeseen slow sales causing an inventory build-up of earlier versions. \n\nThe practice of identifying revisions of automobiles by their model year is strongest in Canada and the United States. Typically, complete vehicle redesigns of long-standing models occur in cycles of at least five years, with one or two facelifts during the model cycle, and manufacturers introduce such redesigns at various times throughout a calendar year.\n\nIntroductions of new models are often phased in around the world, meaning that a 2004 model of a particular vehicle may actually refer to two entirely different vehicles in different countries. Therefore, the more common practice for enthusiasts and motoring writers in other countries is to identify major revisions using the manufacturer's identifier for each revision.\n\nFor instance, aficionados will classify the Holden Commodore (a popular Australian car) according to the following series: VB (introduced in 1978), VC (1980), VH (1981), VK (1984), VL (1986), VN (1988), VP (1991), VR (1993), VS (1995), VT (1997), VX (2000), VY (2002), VZ (2004), VE (2006) and VF (2013). This is done for the simple reason of making the cars more easily distinguished.\n\nIn the automotive industry the model year is absolutely defined only by the manufacturer, and not by any local vehicle registration practices or marketing opinions. \n\nIndustry practice varies between markets according both to the level of exports to North America, and to the extent to which US-owned subsidiaries dominate the domestic automarket. In the 1960s and 1970s, many new models were traditionally introduced at the London or Paris motor shows during October, and manufacturers owned by US corporations as well as domestically controlled UK auto-makers tended to follow US auto-industry conventions in respect of model years. The concept was never so universally applied in Europe as in North America, however, and since the 1980s, the more commercially critical European Motor Shows have been the March Geneva Motor Show and the September Frankfurt Motor Show or Paris Motor Show. New models have increasingly been launched in June or July even in the UK, where the two remaining US-owned subsidiaries no longer design and build distinctively British Ford and Vauxhall models. All this has left the US-style model-year concept increasingly absent from the European domestic automarkets.\n\nAn automotive model year is categorically defined by the 10th digit of the vehicle identification number (VIN), and simply indicates any manufacturer-specified evolution in mid-cycle of a model range - such as revised paint options, trim options or any other minor specification change. The 10th VIN digit does not relate to the calendar year which the car is built, although the two may coincide. For example, a vehicle produced between July 2006 and June 2007 may have a 7 as the 10th digit of the VIN, and another vehicle produced between July 2007 and June 2008 may have an 8 in the 10th digit - with the change-over date varying depending on manufacturer, model and year.\n\nIn the United States, automobile model-year sales traditionally begin with the fourth quarter of the preceding year. So \"model year\" refers to the sales model year; for example, vehicles sold during the period from October 1 to September 30 of the following year belong to a single model year. In addition, the launch of the new model-year has long been coordinated to the launch of the traditional new television season (as defined by A.C. Nielsen) in late September, because of the heavy dependence between television to offer products from automakers to advertise, and the car companies to launch their new models at a high-profile time of year.\n\nIn other cases, products of a previous model year can continue production, especially if a newer model hasn't yet been released. In that case, the model year remains the same until a new model is introduced. This is to ensure that the model will be seen by the public, and will actually sell a number of vehicles before a new vehicle-model is produced, and people will look at the newer model rather than the previous one. \n\nIn the United States, for regulation purposes (such as VIN numbering and EPA emissions certification), government authorities allow cars of a given model year to be sold starting on January 1 of the previous calendar year. For example, this means that a 2019 model year vehicle can legally go on sale on January 1, 2018. This has resulted in a few cars in the following model year being introduced in advertisements during the NFL's Super Bowl in February. A notable example of an \"early\" model year launch would be the Ford Mustang, introduced as an early 1965 model (informally referred to as \"1964½\") in April 1964\nat the World's Fair, several months before the usual start of the 1965 model year in August 1964.\n\nIn addition to automobiles and bicycles, some other products that often have model years include:\n\n"}
{"id": "4858011", "url": "https://en.wikipedia.org/wiki?curid=4858011", "title": "Muddler", "text": "Muddler\n\nA muddler is a bartender's tool, used like a pestle to mash—or muddle—fruits, herbs and spices in the bottom of a glass to release their flavor. \n\nCocktails that require the use of a muddler include:\n\n"}
{"id": "37800449", "url": "https://en.wikipedia.org/wiki?curid=37800449", "title": "Mónica Zetzsche", "text": "Mónica Zetzsche\n\nMónica Susana López de Zetzsche is an Argentine engineer.\n\nZetzsche studied Engineering at the University of Buenos Aires.\n\nSince 1992 she presides López Castro SRL.\n\nShe has been President of YWCA (2003-2007).\n"}
{"id": "40006269", "url": "https://en.wikipedia.org/wiki?curid=40006269", "title": "NeoSpeech", "text": "NeoSpeech\n\nNeoSpeech is a company that specializes in text-to-speech (TTS) software for embedded devices, mobile, desktop, and network/server applications. NeoSpeech was founded by two speech engineers in Fremont, California, in 2002. NeoSpeech is privately held, headquartered in Santa Clara, California. \n\nStephen Hawking was a well-known NeoSpeech TTS user. Adobe Systems has selected NeoSpeech Speech synthesis for their e-learning authoring suite Adobe Captivate.\n\nVoiceText speech synthesis is the NeoSpeech software component that generates synthesized speech from input text. NeoSpeech uses Unit Selection Synthesis (USS), which utilizes large databases of recorded sound segments to create synthesized speech. The VoiceText TTS Engine is mainly used to build custom stand-alone TTS applications such as AAC (Augmentative and alternative communication) products, gaming software, automated loud speaker/paging systems, educational software, and language learning apps. It also can be used simply to output a voice from an input text using a provided desktop TTS program.\n\nLanguages include US and UK variants of English, Mexican Spanish, Canadian French, Chinese, Korean, and Japanese, with a variety of male and female voices.\n\nThe software is available for\n\n"}
{"id": "14196954", "url": "https://en.wikipedia.org/wiki?curid=14196954", "title": "Oliver Typewriter Company", "text": "Oliver Typewriter Company\n\nThe Oliver Typewriter Company was an American typewriter manufacturer headquartered in Chicago, Illinois. The Oliver Typewriter was the first effective \"visible print\" typewriter, meaning text was visible to the typist as it was entered. Oliver typewriters were marketed heavily for home use, using local distributors and sales on credit. Oliver produced more than one million machines between 1895 and 1928 and licensed its designs to several international firms.\n\nCompetitive pressure and financial troubles resulted in the company's liquidation in 1928. The company’s assets were purchased by investors who formed The British Oliver Typewriter Company, which manufactured and licensed the machines until its own closure in the late 1950s. The last Oliver typewriter was produced in 1959.\n\nThomas Oliver was born in Woodstock, Ontario, Canada, on August 1, 1852. Having become interested in religion, Oliver moved to Monticello, Iowa, after the death of his mother, to serve as a Methodist minister. In 1888, Oliver began to develop his first typewriter, made from strips of tin cans, as a means of producing more legible sermons. He was awarded his first typewriter patent, US Patent No. 450,107, on April 7, 1891. After four years of development, a \"crude working model\" composed of 500 parts had been produced. Oliver resigned his ministry and moved to Epworth, Iowa, where he found investors willing to provide $15,000 ($ in 2018) of capital, and leased a building in which to manufacture his machines.\n\nWhile visiting Chicago to promote the machine, Oliver encountered businessman Delavan Smith, who became interested in the typewriter and bought the stock held by the Iowa investors. Oliver was given a 65% interest in the company and retained to continue development of the typewriter, at an annual salary of $3,000 ($ per year in 2018). Oliver died suddenly of heart disease on February 9, 1909, aged 56.\n\nThe Oliver Typewriter Company had begun operating in 1895, with its headquarters on the ninth floor of a building on the corner of Clark and Randolph Street in Chicago. In 1896, manufacturing moved from Iowa to Woodstock, Illinois, when the City of Woodstock donated a vacant factory once used by the Wheeler and Tappan Company on the condition that the Oliver Typewriter Company remain there at least five years. Manufacturing was divided into six departments: type bar, carriage, assembly, tabulators and adjustment, inspection, and an aligning room. The company's headquarters moved to the Oliver Building, now a Chicago landmark on the National Register of Historic Places, when it was completed in 1907.\nStarting in 1899, the company established sales networks by encouraging customers to become local distributors. This method of marketing relied on word of mouth and emphasized sales made directly to neighbors (door-to-door) and, after 1905, sales on credit. In response to increased competition in the late 1910s, however, the company eliminated its network of local salesman and used the resulting savings in commissions to reduce the typewriter's $100 ($ in 2018) price by half. Sales increased and, at its peak, the company's labor force of 875 was producing 375 machines daily.\n\nIn addition to its offices in Illinois, the company had branch offices in Baltimore, Buffalo, Cleveland, Kansas City, Minneapolis, New York City, Omaha, St. Louis, San Francisco and Seattle, all of which closed when Oliver shifted to mail order sales in March 1917. A minor recession in 1921–22 caused a large number of customers to default on their payments, resulting in the repossession of their typewriters. The company opted not to borrow money and, in 1926, the board of directors voted to liquidate the company. Only one employee, Chester Nelson, was retained to oversee the company's liquidation.\n\nIn 1928, the Oliver Typewriter Company was sold to investors who formed the British Oliver Typewriter Company in Croydon, England. Production of Oliver’s original, three-rowed keyboard design was discontinued in 1931 when the company began to produce a rebranded model of the \"Fortuna\" typewriter, a four-rowed German design. In 1935, the company began to produce the Halda-Norden standard typewriter, another licensed design, as model No. 20. The company, however, had to retool its machines and return to the original Oliver design when the British government placed large orders for the three-rowed No. 15 at the outbreak of World War II.\n\nProduction of the No. 20 resumed around 1947, at which time the company began to license the Oliver name to several European manufacturing companies. The standard desktop machine was eventually discontinued in favor of portable models; the company began to sell a German design, the Siemag Standard, as the Oliver standard. In 1958, Oliver purchased the Byron Typewriter Company, previously the Barlock Typewriter Company, of Nottingham. The licensing ventures were ultimately unsuccessful, and the company's machine tools were transferred to a factory in Germany. Production of all Oliver typewriters ended in May 1959.\n\nThe general design of Oliver typewriters remained mostly unchanged throughout the company's history. The Olivers are \"down strike\" typewriters, meaning the typebars strike the platen (also known as the roller) from above, rather than from below (\"up strike\") or from the front (\"front strike\"). Unlike the \"up strike\" method, which prints text out of sight on the underside of the platen, the \"down strike\" is a \"visible print\" design, meaning the full page is visible to the typist as the text is being entered. The relatively greater striking power of the \"down strike\" design led Olivers to be preferred for specialty uses such as stencil cutting or \"manifolding\" (copying using carbon paper). The \"front strike\" method, a competing \"visible print\" design, was patented around the same time (1889–91), but an effective machine that did not interfere with the typist’s line of sight was not available until 1897 when, roughly three years after the introduction of the Oliver No. 1, the Underwood No. 1 appeared on the market.\n\nThe Oliver’s typebars are bent in a bow (forming an inverted \"U\" shape) and rest in \"towers\" on the sides of the typewriter. This design limited the machine to a three-row QWERTY keyboard as the typebars were stacked such that they grew progressively larger as more were added. The size and usability implications of adding additional keys and thus, more typebars, precluded the addition of a fourth keyboard row dedicated to numbers. Although a four-row prototype was designed in 1922, it was shelved due to the company’s financial troubles at that time. The No. 20, No. 21 and portable models produced by the British Oliver Typewriter Company had four-row keyboards.\n\nOliver typewriters were finished with olive green paint or nickel-plating and white or black keyboards, depending on customer preference. Beginning with model No. 3, machines were painted green except some variants to be exported to warm or damp regions, which were chrome-plated. The color was changed from green to black on the introduction of model No. 11. Oliver typewriters made for the British war effort were supplied with a \"war finish\".\n\nThe following models were produced in the United States between 1894 and 1928:\nWith the exception of model No. 2, even-numbered models were produced with extra keys (32 versus 28 keys) for sale in countries with accented languages.\n\nThe following models were produced by the British Oliver Typewriter Company between 1930 and 1942:\nOliver typewriter designs were licensed for production in several countries. Variants of model No. 3 were produced by The Linotype Company of Montreal and A. Greger & Co. of Vienna. Models produced by licensees were marketed under various names including \"Courier\" (Austria), \"Fiver\" (Germany), \"Stolzenberg\" (continental Europe) and \"Revilo\" (Argentina). The Argentinian licensee used Revilo, Oliver backwards, to avoid royalty payments on the Oliver name, which had already been registered in Argentina.\n\n"}
{"id": "799436", "url": "https://en.wikipedia.org/wiki?curid=799436", "title": "Pitchfork", "text": "Pitchfork\n\nA pitchfork is an agricultural tool with a long handle and tynes used to lift and pitch or throw loose material, such as hay, straw or leaves.\n\nA pitchfork is an agricultural tool with a long handle and long, thick, widely separated pointed tynes used to lift and pitch or throw loose material, such as hay, straw or leaves. True pitchforks typically have only two or three tynes, while manure forks have four or more. However, some forks with more than three tynes are also used for handling loose material such as hay or silage. Other forks have up to ten tynes with different lengths and spacing depending on purpose. They are usually made of steel with a long wooden handle, but may also be made from wood, wrought iron, bamboo, or alloy. In some parts of England a pitchfork is known as a \"prong\" and, in parts of Ireland, a \"sprong\" refers to a four-pronged pitchfork. The pitchfork is similar to the shorter and sturdier garden fork.\n\nPitchforks and scythes have frequently been used as weapons by those who could not afford or did not have access to more expensive weapons such as swords, or, later, guns. As a result, pitchforks and scythes are stereotypically carried by angry mobs or gangs of enraged peasants.\n\nIn Europe, the pitchfork was first used in the early Middle Ages, at about the same time as the harrow. The pitchfork was originally made entirely of wood; today, the tynes are usually made of hard metal.\n\nA notable American artistic display of a three-pronged pitchfork is in \"American Gothic\", the painting by Grant Wood. In this painting it symbolizes hand labour. There are other paintings by various artists which depict a wide variety of pitchforks and other tools in use and at rest.\n\nBecause of its association with peasantry, the pitchfork is often a populist symbol and part of the nickname of populist leaders, thus:\n\nThe Gangster Disciples, a street gang in the midwestern United States, use a three-pointed pitchfork as one of their symbols.\n\nThe pitchfork is often used in lieu of the trident in satire of Christian demonology in popular media, especially in early humorous cartoons where a popular joke was a caricature of an angel and a demon supposeeldly wielding a \"pitchfork\" (actually a trident) sitting on the shoulders of the protagonist.\n\nThe Hellenistic deity Pluto wields a bident, a two-pronged weapon strikingly similar in form to a pitchfork but actually related to the trident in design and purpose.\n\n"}
{"id": "3917034", "url": "https://en.wikipedia.org/wiki?curid=3917034", "title": "Premixed flame", "text": "Premixed flame\n\nA premixed flame is a flame formed under certain conditions during the combustion of a premixed charge (also called pre-mixture) of fuel and oxidiser. Since the fuel and oxidiser—the key chemical reactants of combustion—are available throughout a homogeneous stoichiometric premixed charge, the combustion process once initiated sustains itself by way of its own heat release. The majority of the chemical transformation in such a combustion process occurs primarily in a thin interfacial region which separates the unburned and the burned gases. The premixed flame interface propagates through the mixture until the entire charge is depleted. The propagation speed of a premixed flame is known as the flame speed (or burning velocity) which depends on the convection-diffusion-reaction balance within the flame, i.e. on its inner chemical structure. The premixed flame is characterised as laminar or turbulent depending on the velocity distribution in the unburned pre-mixture (which provides the medium of propagation for the flame). \n\nUnder controlled conditions (typically in a laboratory) a laminar flame may be formed in one of several possible flame configurations. The inner structure of a laminar premixed flame is composed of layers over which the decomposition, reaction and complete oxidation of fuel occurs. These chemical processes are much faster than the physical processes such as vortex motion in the flow and, hence, the inner structure of a laminar flame remains intact in most circumstances. The constitutive layers of the inner structure correspond to specified intervals over which the temperature increases from the specified unburned mixture up to as high as the adiabatic flame temperature (AFT). In the presence of volumetric heat transfer and/or aerodynamic stretch, or under the development intrinsic flame instabilities, the extent of reaction and, hence, the temperature attained across the flame may be different from the AFT.\n\nFor a one-step irreversible chemistry, i.e., formula_1, the planar, adiabatic flame has explicit expression for the burning velocity derived from activation energy asymptotics when the Zel'dovich number formula_2 The reaction rate formula_3 (number of moles of fuel consumed per unit volume per unit time) is taken to be Arrhenius form,\n\nwhere formula_5 is the pre-exponential factor, formula_6 is the density, formula_7 is the fuel mass fraction, formula_8 is the oxidizer mass fraction, formula_9 is the activation energy, formula_10 is the universal gas constant, formula_11 is the temperature, formula_12 are the molecular weights of fuel and oxidizer, respectively and formula_13 are the reaction orders. Let the unburnt conditions far ahead of the flame be denoted with subscript formula_14 and similarly, the burnt gas conditions by formula_15, then we can define an equivalence ratio formula_16 for the unburnt mixture as\n\nThen the planar laminar burning velocity for fuel-rich mixture (formula_18) is given by\n\nwhere \n\nand formula_21. Here formula_22 is the thermal conductivity, formula_23 is the specific heat at constant pressure and formula_24 is the Lewis number. Similarly one can write the formula for lean formula_25 mixtures. This result is first obtained by T. Mitani in 1980. Second order correction to this formula with more complicated transport properties were derived by Forman A. Williams and co-workers in the 80s.\n\nVariations in local propagation speed of a laminar flame arise due to what is called flame stretch. Flame stretch can happen due to the straining by outer flow velocity field or the curvature of flame; the difference in the propagation speed from the corresponding laminar speed is a function of these effects and may be written as:\n\nwhere formula_27 is the laminar flame thickness, formula_28 is the flame curvature, formula_29 is the unit normal on the flame surface pointing towards the unburnt gas side, formula_30 is the flow velocity and formula_31 are the respective Markstein numbers of curvature and strain.\n\nIn practical scenarios, turbulence is inevitable and, under moderate conditions, turbulence aids the premixed burning process as it enhances the mixing process of fuel and oxidiser. If the premixed charge of gases is not homogeneously mixed, the variations on equivalence ratio may affect the propagation speed of the flame. In some cases, this is desirable as in stratified combustion of blended fuels. \n\nA turbulent premixed flame can be assumed to propagate as a surface composed of an ensemble of laminar flames so long as the processes that determine the inner structure of the flame are not affected. Under such conditions, the flame surface is wrinkled by virtue of turbulent motion in the premixed gases increasing the surface area of the flame. The wrinkling process increases the burning velocity of the turbulent premixed flame in comparison to its laminar counterpart. \n\nThe propagation of such a premixed flame may be analysed using the field equation called as G equation for a scalar formula_32 as:\n\nwhich is defined such that the level-sets of G represent the various interfaces within the premixed flame propagating with a local velocity formula_34. This, however, is typically not the case as the propagation speed of the interface (with resect to unburned mixture) varies from point to point due to the aerodynamic stretch induced due to gradients in the velocity field. \n\nUnder contrasting conditions, however, the inner structure of the premixed flame may be entirely disrupted causing the flame to extinguish either locally (known as local extinction) or globally (known as global extinction or blow-off). Such opposing cases govern the operation of practical combustion devices such as SI engines as well as aero-engine afterburners. The prediction of the extent to which the inner structure of flame is affected in turbulent flow is a topic of extensive research. \n\nThe flow configuration of premixed gases affects the stabilization and burning characteristics of the \n\nIn a Bunsen flame, a steady flow rate is provided which matches the flame speed so as to stabilize the flame. If the flow rate is below the flame speed, the flame will move upstream until the fuel is consumed or until it encounters a flame holder. If the flow rate is equal to the flame speed, we would expect a stationary flat flame front normal to the flow direction. If the flow rate is above the flame speed, the flame front will become conical such that the component of the velocity vector normal to the flame front is equal to the flame speed. \n\nHere, the pre-mixed gases flow in such a way so as to form a region of stagnation (zero velocity) where the flame may be stabilized.\n\nIn this configuration, the flame is typically initiated by way of a spark within a homogeneous pre-mixture. The subsequent propagation of the developed premixed flame occurs as a spherical front until the mixture is transformed entirely or the walls of the combustion vessel are reached.\n\nSince the equivalence ratio of the premixed gases may be controlled, premixed combustion offers a means to attain low temperatures and, thereby, reduce NO emissions. Due to improved mixing in comparison with diffusion flames, soot formation is mitigated as well. Premixed combustion has therefore gained significance in recent times. The uses involve lean-premixed-prevaporized (LPP) gas turbines and SI engines.\n\n"}
{"id": "1094276", "url": "https://en.wikipedia.org/wiki?curid=1094276", "title": "Schwinn Bicycle Company", "text": "Schwinn Bicycle Company\n\nThe Schwinn Bicycle Company was founded by German-born mechanical engineer Ignaz Schwinn (1860–1945) in Chicago in 1895. It became the dominant manufacturer of American bicycles through most of the 20th century. After declaring bankruptcy in 1992, Schwinn has since been a sub-brand of Pacific Cycle, owned by the multi-national conglomerate, Dorel Industries.\n\nIgnaz Schwinn was born in Hardheim, Baden, Germany, in 1860 and worked on two-wheeled ancestors of the modern bicycle that appeared in 19th century Europe. Schwinn emigrated to the United States in 1891. In 1895, with the financial backing of fellow German American Adolph Frederick William Arnold (a meat packer), he founded Arnold, Schwinn & Company. Schwinn's new company coincided with a sudden bicycle craze in America. Chicago became the center of the American bicycle industry, with thirty factories turning out thousands of bikes every day. Bicycle output in the United States grew to over a million units per year by the turn of the 20th century.\n\nThe boom in bicycle sales was short lived, saturating the market years before motor vehicles were common on American streets. By 1905, bicycle annual sales had fallen to only 25% of that reached in 1900. Many smaller companies were absorbed by larger firms or went bankrupt; in Chicago, only twelve bicycle makers remained in business. Competition became intense, both for parts suppliers and for contracts from the major department stores, which retailed the majority of bicycles produced in those days. Realizing he needed to grow the company, Ignaz Schwinn purchased several smaller bicycle firms, building a modern factory on Chicago's west side to mass-produce bicycles at lower cost. He finalized a purchase of Excelsior Company in 1912, and in 1917 added the Henderson Company to form Excelsior-Henderson. In an atmosphere of general decline elsewhere in the industry, Schwinn's new motorcycle division thrived, and by 1928 was in third place behind Indian and Harley-Davidson.\n\nAt the close of the 1920s, the stock market crash decimated the American motorcycle industry, taking Excelsior-Henderson with it. Arnold, Schwinn, & Co. (as it remained until 1967) was on the verge of bankruptcy. With no buyers, Excelsior-Henderson motorcycles were discontinued in 1931. Ignaz's son, Frank W. \"F. W.\" Schwinn, took over day-to-day operations at Schwinn. Putting all company efforts towards bicycles, he succeeded in developing a low-cost model that brought Schwinn recognition as an innovative company, as well as a product that would continue to sell during the inevitable downturns in business cycles. After traveling to Europe to get ideas, F. W. Schwinn returned to Chicago and in 1933 introduced the Schwinn B-10E Motorbike, actually a youth's bicycle designed to imitate a motorcycle. The company revised the model the next year and renamed it the \"Aerocycle\". For the \"Aerocycle\", F. W. Schwinn persuaded American Rubber Co. to make balloon tires, while adding streamlined fenders, an imitation \"gas tank\", a streamlined, chrome-plated headlight, and a push-button bicycle bell. The bicycle would eventually come to be known as a \"paperboy bike\" or \"cruiser\".\n\nSchwinn was soon sponsoring a bicycle racing team headed by Emil Wastyn, who designed the team bikes, and the company competed in six-day racing across the United States with riders such as Jerry Rodman and Russell Allen. In 1938, Frank W. Schwinn officially introduced the \"Paramount\" series. Developed from experiences gained in racing, Schwinn established \"Paramount\" as their answer to high-end, professional competition bicycles. The \"Paramount\" used high-strength chrome-molybdenum steel alloy tubing and expensive brass lug-brazed construction. During the next twenty years, most of the \"Paramount\" bikes would be built in limited numbers at a small frame shop headed by Wastyn, in spite of Schwinn's continued efforts to bring all frame production into the factory.\n\nOn 17 May 1941, Alfred Letourneur was able to beat the motor-paced world speed record on a bicycle, reaching on a Schwinn Paramount bicycle riding behind a car in Bakersfield, California.\n\nBy 1950, Schwinn had decided the time was right to grow the brand. At the time, most bicycle manufacturers in the United States sold in bulk to department stores, which in turn sold them as store brand models. Schwinn decided to try something different. With the exception of B. F. Goodrich bicycles, sold in tire stores, Schwinn eliminated the practice of rebranding in 1950, insisting that the Schwinn brand and guarantee appear on all products. In exchange for ensuring the presence of the Schwinn name, distributors retained the right to distribute Schwinn bikes to any hardware store, toy store, or bicycle shop that ordered them. In 1952, F. W. Schwinn tasked a new team to plan future business strategy, consisting of marketing supervisor Ray Burch, general manager Bill Stoeffhaas, and design supervisor Al Fritz.\n\nIn the 1950s, Schwinn began to aggressively cultivate bicycle retailers, persuading them to sell Schwinns as their predominant, if not exclusive brand. During this period, bicycle sales enjoyed relatively slow growth, with the bulk of sales going to youth models. In 1900, during the height of the first bicycle boom, annual United States sales by all bicycle manufacturers had briefly topped one million. By 1960, annual sales had reached just 4.4 million. Nevertheless, Schwinn's share of the market was increasing, and would reach in excess of 1 million bicycles per year by the end of the decade.\n\nIn 1946, imports of foreign-made bicycles had increased tenfold over the previous year, to 46,840 bicycles; of that total, 95 per cent were from Great Britain. The postwar appearance of imported \"English racers\" (actually three-speed \"sport\" roadsters from Great Britain and West Germany) found a ready market among United States buyers seeking bicycles for exercise and recreation in the suburbs. Though substantially heavier than later European-style \"racer\" or sport/touring bikes, Americans found them a revelation, as they were still much lighter than existing models produced by Schwinn and other American bicycle manufacturers. Imports of foreign-made \"English racers\", sports roadsters, and recreational bicycles steadily increased through the early 1950s. Schwinn first responded to the new challenge by producing its own \"middleweight\" version of the \"English racer\". The middleweight incorporated most of the features of the English racer, but had wider tires and wheels.\n\nThe company also joined with other United States bicycle manufacturers in a campaign to raise tariffs across the board on all imported bicycles. In August 1955, the Eisenhower administration implemented a 22.5% tariff rate for three out of four categories of bicycles. However, the most popular adult category, lightweight or \"racer\" bicycles, were only raised to 11.25%. The administration noted that the United States industry offered no direct competition in this category, and that lightweight bikes competed only indirectly with balloon-tire or cruiser bicycles. The share of the United States market taken by foreign-made bicycles dropped to 28.5% of the market, and remained under 30% through 1964. Despite the increased tariff, the only structural change in foreign imports during this period was a temporary decline in bicycles imported from Great Britain in favor of lower-priced models from the Netherlands and Germany. In 1961, after a successful appeal by bicycle importers, the Eisenhower tariffs were declared invalid by the Court of United States Customs Appeals, and President Kennedy imposed a new tariff rate at 50% on foreign-made bicycles, a rate which remained in place until 1964.\n\nWhile every large bicycle manufacturer sponsored or participated in bicycle racing competition of some sort to keep up with the newest trends in technology, Schwinn had restricted its racing activities to events inside the United States, where Schwinn bicycles predominated. As a result, Schwinns became increasingly dated in both styling and technology. By 1957, the \"Paramount\" series, once a premier racing bicycle, had atrophied from a lack of attention and modernization. Aside from some new frame lug designs, the designs, methods and tooling were the same as had been used in the 1930s. After a crash-course in new frame-building techniques and derailleur technology, Schwinn introduced an updated \"Paramount\" with Reynolds 531 double-butted tubing, Nervex lugsets and bottom bracket shells, as well as Campagnolo derailleur dropouts. The \"Paramount\" continued as a limited production model, built in small numbers in a small apportioned area of the old Chicago assembly factory. The new frame and component technology incorporated in the \"Paramount\" largely failed to reach Schwinn's mass-market bicycle lines. Another change occurred in 1963 following the death of F. W. Schwinn, when grandson Frank Valentine Schwinn took over management of the company.\n\nBy the late 1950s, Schwinn's exclusive marketing practices were well entrenched in the United States, practices that had ensured a dominant position in the United States bicycle market. In order to prevent competition among its wholesalers, Schwinn assisted them by dividing up the national market. Schwinn also strengthened its dealer network, shrinking the number of authorized dealers. Since Schwinn could decide who got their bikes and who didn't, the company rewarded the highest volume dealers with location exclusivity, as well as mandating service standards and layouts. In response, the company was sued by the Department of Justice in 1957 for restraint of trade. In a ten-year legal battle, many of Schwinn's practices were upheld by the courts: judges ruled they had the right to have their bicycles sold by retailers equipped to service the bikes as well as sell them. However, in a ruling by the Supreme Court of the United States in 1967, \"U.S. v. Arnold, Schwinn & Co.\", Schwinn was found guilty of restraint of trade by preventing distributors shipping bicycles to unapproved dealers. Though the \"Arnold\" decision would be essentially overturned in later rulings, the company stopped working solely through independent local distributors and constructed four regional warehouses from which bicycles would — legally — be sent to shops. While this solved the problem of unfair trade practice with the courts, the new warehouses and distribution system cost millions of dollars at a time of rising competition from foreign manufacturers. It also made it more difficult for the company to stay informed of customer complaints regarding manufacturing or assembly problems.\nDuring the 1960s, Schwinn aggressively campaigned to retain and expand its dominance of the child and youth bicycle markets. The company advertised heavily on television, and was an early sponsor (from 1958) of the children's television program \"Captain Kangaroo\". The Captain himself was enlisted to regularly hawk Schwinn-brand bicycles to the show's audience, typically six years old and under. As these children matured, it was believed they would ask for Schwinn bicycles from their parents. By 1971, United States government councils had objected to Schwinn's marketing practices. In response, Schwinn had \"Captain Kangaroo\" alter its format. The Captain no longer insisted that viewers buy a Schwinn, but instead made regular on-air consultations of a new character, \"Mr. Schwinn Dealer\".\n\nSchwinn developed the Corvette in 1954, after their catalog, for that year, had been in use. Therefore, with the release of a single photograph, the Corvette was introduced. The picture showed company executives standing behind their new product, that would remain in production for 10 years. 1955 was the first year in which the Corvette appeared in the Schwinn catalog; it was Schwinn's top listing in their \"middleweight\" category.\n\nFrom the 1950s to the 1980s, Schwinn produced a series of lightweight tandem bicycles known as the Schwinn Twinn. They came in three different models: the single speed Twinn, a two speed semi-automatic, and the five speed Deluxe Twinn.\n\nIn 1962, Schwinn's designer Al Fritz heard about a new youth trend centered in California for retrofitting bicycles with the accoutrements of motorcycles customized in the \"bobber\" or \"chopper\" style, including high-rise, \"ape-hanger\" handlebars and low-rider \"banana seats\". Inspired, he designed a mass-production bike for the youth market known as \"Project J-38\". The result, a wheelie bike, was introduced to the public as the Schwinn \"Sting-Ray\" in June 1963. It had ape-hanger handlebars, Persons's Solo Polo Seat banana seat and 20-inch tires. Sales were initially slow, as many parents desiring a bicycle for their children did not find the Sting-Ray appealing in the least. However, after a few appeared on America's streets and neighborhoods, many young riders would accept nothing else, and sales took off. In the December 1963 Schwinn Reporter Schwinn announced the arrival of the Deluxe Sting-Ray. This model included Fenders, white-wall tires, and a padded Solo polo seat. Next, in July 1964 Schwinn announced the arrival of the Super Deluxe Sting-Ray. This model included a front spring-fork, and a new sleeker Sting-Ray banana seat, and a Person's Hi-loop Sissy bar. Also, the Super Deluxe gave the rider a choice of White wall tires or the new Yellow oval rear Slik tire paired with a front black wall Westwind tire. By 1965, a host of American and foreign manufacturers were offering their own version of the \"Sting-Ray\".\n\nA growing number of teens and young adults were purchasing imported European sport racing or sport touring bicycles, many fitted with multiple derailleur-shifted gears. Schwinn decided to meet the challenge by developing two lines of sport or road 'racer' bicycles. One was already in the catalog — the limited production \"Paramount\" series. As always, the \"Paramount\" spared no expense; the bicycles were given high-quality lightweight lugged steel frames using double-butted tubes of Reynolds 531 and fitted with quality European components including Campagnolo derailleurs, hubs, and gears. The Paramount series had limited production numbers, making vintage examples quite rare today. Starting in 1960, for the rest of the market, Schwinn offered the Schwinn \"Varsity\" and \"Continental\", now equipped as multi-geared sport bikes (\"10-speeds\"), and designed to imitate the style of the new narrow-tired 'racing' and sport bikes from Europe, though not their performance. The 1960 Varsity was introduced as an 8-speed bike, but in mid-1961 was upgraded to 10 speeds. Other road bikes were introduced by Schwinn in the early and mid 1960s, such as the Superior, Sierra, and Super Continental, but these were only produced for a few years. The Varsity and Continental sold in large numbers through the 1960s and early 1970s, becoming Scwhinn's leading models. The major difference between the two models was the use of a tubular front fork on the Continental -- both bikes used the same frame design, a lugless, steel unit, using Schwinn's standard Ashtabula cranksets and welded in such a way that the joints were smoothly filled (similar to the joints in 21st-century composite frames). The wheel rims were likewise robust, chromed, stamped steel with a unique profile designed to hold the tire bead securely, even if pressure were low or lost.\n\nIn the late 1960s, the Varsity and Continental pioneered the use of auxiliary brake levers, which allowed the rider to rest hands on the straight, horizontal center section of the ram's horn handlebars, yet still have braking control. To further improve control from this more-erect riding position, the levers used to move the derailleurs (shifting the chain from one sprocket to the next) were moved from the traditional position on the \"down tube\" to the top of the headset, on a ring which would turn with the handlebar stem. This feature, attractive to older riders, soon found its way to other Schwinn models, especially those intended for senior citizens. \n\nBy the mid-1970s, competition from lightweight and feature-rich imported bikes was making strong inroads in the budget-priced and beginners' market. While Schwinn's popular lines were far more durable than the budget bikes, they were also far heavier and more expensive, and parents were realizing that most of the budget bikes would outlast most kids' interest in bicycling. Although the Varsity and Continental series would still be produced in large numbers into the 1980s, even Schwinn recognized the growing market in young adults and environmentally-oriented purchasers, devoting the bulk of their marketing to lighter models intended to pull sales back from the imports.\n\nThe \"Sting-Ray\" sales boom of the 1960s accelerated in 1970, with United States bicycle sales doubling over a period of two years. However, there were clear warning signs on the horizon.\n\nDespite a huge increase in popularity of lightweight European sport or \"road racing bicycles\" in the United States, Schwinn adhered to its existing strategy in the lightweight adult road bike market. For those unable to afford the \"Paramount\", this meant a Schwinn 'sports' bike with a heavy steel electro-forged frame along with steel components such as wheels, stems, cranks, and handlebars from the company's established United States suppliers. Though weighing slightly less, the mid-priced Schwinn \"Superior\" or \"Sports Tourer\" was almost indistinguishable from Schwinn's other heavy, mass-produced models, such as the \"Varsity\" and \"Continental\". While competitive in the 1960s, by 1972 these bicycles were much heavier and less responsive in comparison to the new sport and racing bicycles arriving from England, France, Italy, and increasingly, Japan.\n\nAnother problem was Schwinn's failure to design and market its bicycles to specific, identifiable buyers, especially the growing number of cyclists interested in road racing or touring. Instead, most Schwinn derailleur bikes were marketed to the general leisure market, equipped with heavy \"old timer\" accessories such as kickstands that cycling aficionados had long since abandoned. More and more cyclists, especially younger buyers, began to insist on stronger steel alloys (which allowed for lighter frames), responsive frame geometry, aluminum components, advanced derailleur shifting, and multiple gears. When they failed to find what they wanted at Schwinn, they went elsewhere. While the \"Paramount\" still sold in limited numbers to this market, the model's customer base began to age, changing from primarily bike racers to older, wealthier riders looking for the ultimate bicycle. Schwinn sold an impressive 1.5 million bicycles in 1974, but would pay the price for failing to keep up with new developments in bicycle technology and buying trends.\n\nWith their aging product line, Schwinn failed to dominate the huge sport bike boom of 1971–1975, which saw millions of \"10-speed\" bicycles sold to new cyclists. Schwinn did allow some dealers to sell imported road racing bikes, and by 1973 was using the Schwinn name on the \"Le Tour\", a Japanese-made low-cost sport/touring 10-speed bicycle. Schwinn developed strong trading relationships with two Japanese bicycle manufacturers in particular, Bridgestone and National/Panasonic. Though these met initial dealer resistance as \"imports\" and were not included in the Schwinn consumer catalog, it was soon realized that the Panasonic and Bridgestone 'Schwinn' bicycles were fully the equal of the American-made versions in quality and performance. Schwinn soon had a range of low, mid- and upper-level bicycles all imported from Japan. Schwinn's standard road bike model from Panasonic was the \"World Traveler\", which had a high-quality lugged steel frame and Shimano components. Schwinn also marketed a top-shelf touring model from Panasonic, the \"World Voyager\", lugged with butted Tange chrome-molybdenum alloy tubing, Shimano derailleurs, and SunTour bar-end shifters, a serious challenge to the Paramount series at half the price.\n\nBy 1975, bicycle customers interested in medium-priced road and touring bicycles had largely gravitated towards Japanese or European brands. Unlike Schwinn, many of these brands were perennial participants in professional bicycle racing, and their production road bicycles at least possessed the cachet and visual lineage of their racing heritage, if not always their componentry. One example was Peugeot, which won several Tour de France victories using race bikes with frames occasionally constructed by small race-oriented framebuilders such as Masi, suitably repainted in Team Peugeot colors. In reality, mass-market French manufacturers such as Peugeot were not infrequently criticized for material and assembly quality — as well as stagnant technology — in their low- and mid-level product lines. Nevertheless, Peugeot proudly advertised its victorious racing heritage at every opportunity. While not as prominent at the winner's podium, Japanese brands such as Fuji and Panasonic offered consistently high quality, reasonable prices, and state-of-the-art-derailleur, crankset, and gearing design. Unlike Schwinn, most Japanese bicycle manufacturers were quick to adopt the latest European road racing geometries, new steel alloys, and modern manufacturing techniques. As a result, their moderately-priced bicycles, equipped with the same Japanese-made components, usually weighed less and performed better than competitive models made by Schwinn. Schwinn brand loyalty began to suffer as huge numbers of buyers came to retailers asking for the latest sport and racing road bikes from European or Japanese manufacturers. By 1979, even the \"Paramount\" had been passed, technologically speaking, by a new generation of American as well as foreign custom bicycle manufacturers.\n\nSchwinn also largely failed to capitalize on a new trend in Southern California: BMX racing. After first claiming it to be a dangerous sport, management changed their tune — too late — when they introduced the \"Scrambler\" in 1975, which evolved into a BMX design in the late 1970s, but it was heavier than designs from other manufacturers. The Sting-Ray based Scrambler spawned the light weight, fully competition capable, chrome-molybdenum-tubed \"Competition Scrambler\" in 1977, \"Scrambler 36/36\", the \"Mag Scrambler\" in 1981, and the \"Sting\" with full Reynolds, double butted chrome-molybdenum frame that was made in the same assembly area as the Paramount road racing frames.\n\nSchwinn followed the Scrambler line with the \"Predator\" in 1982, their first competitive step into the modern BMX market. A latecomer, the Predator took just eight percent of the BMX market. Schwinn also had a very successful BMX racing team made up of some of the best riders in the day. They were even used for an episode of the TV show CHiPs.\n\nBy the late 1970s, a new bicycle sport begun by enthusiasts in Northern California had grown into a new type of all-terrain bicycle, the mountain bike. Originally based on Schwinn balloon-tired cruiser bicycles fitted with derailleur gears, called \"Klunkers\", a few participants had begun designing and building small numbers of mountain bikes with frames made out of modern butted chrome-molybdenum alloy steel. When the sport's original inventors demonstrated their new frame design, Schwinn marketing personnel initially discounted the growing popularity of the mountain bike, concluding that it would become a short-lived fad. The company briefly (1978–1979) produced a bicycle styled after the California mountain bikes, the \"Klunker 5\". Using the standard electro-forged cantilever frame, and fitted with five-speed derailleur gears and knobby tires, the \"Klunker 5\" was never heavily marketed, and was not even listed in the Schwinn product catalog. Unlike its progenitors, the \"Klunker\" proved incapable of withstanding hard off-road use, and after an unsuccessful attempt to reintroduce the model as the \"Spitfire 5\", it was dropped from production.\n\nThe company's next answer to requests for a Schwinn mountain bike was the \"King Sting\" and the \"Sidewinder\", inexpensive BMX-derived bicycles fabricated from existing electro-forged frame designs, and using off-the-shelf BMX parts. This proved to be a major miscalculation, as several new United States startup companies began producing high-quality frames designed from the ground up, and sourced from new, modern plants in Japan and Taiwan using new mass-production technologies such as TIG welding. Schwinn's new competitors such as Specialized and Fisher MountainBikes were soon selling hundreds of thousands of mountain bikes at competitive prices to eager customers, setting sales records in a market niche that soon grew to enormous proportions.\n\nBy this time, Schwinn's bicycle factory was completely outmoded in comparison to modern bicycle manufacturing centers in Japan and Taiwan, who had continually invested in new and up-to-date manufacturing techniques and materials, including new joinery techniques and the latest lightweight chrome-molybdenum alloy steel, and later, aluminum. The company considered relocating to a single facility in Tulsa, Oklahoma, but financing the project would have required outside investors, perhaps even foreign ones. Schwinn's board of directors rejected the new plant in 1978.\n\nIn October 1979, Edward R. Schwinn, Jr. took over the presidency of Schwinn from his uncle Frank, ensuring continuity of Schwinn family in the operations of the company. However, worker dissatisfaction, seldom a problem in the early years, grew with steep increases in inflation. In late 1980, the Schwinn Chicago factory workers voted to affiliate with the United Auto Workers. Plant assembly workers began a strike for higher pay in September 1980, and 1,400 assembly workers walked off the job for thirteen weeks. Although the strike ended in February 1981, only about 65% of the prior workforce was recalled to work. By this time, increasingly stiff competition from lower-cost competition in Asia resulted in declining market share. These problems were exacerbated by the inefficiency of producing modern bicycles in the 80-year-old Chicago factory equipped with outdated equipment and ancient inventory and information systems. After numerous meetings, the board of directors voted to source most Schwinn bicycle production from their established bicycle supplier in Japan, Panasonic Bicycle. As Schwinn's first outsourced bicycles, Panasonic had been the only vendor to meet Schwinn's production requirements. Later, Schwinn would sign a production supply agreement with Giant Bicycles of Taiwan. As time passed, Schwinn would import more and more Asian-made bicycles to carry the Schwinn brand, eventually becoming more a marketer than a maker of bikes.\n\nIn an attempt to preserve remaining market share and avoid a unionized workforce, Schwinn later moved remaining United States bicycle production to a new plant in Greenville, Mississippi, where bicycles could be assembled at lower cost using parts sourced from Asia. The Greenville plant was not a success, as it was remote from both the corporate headquarters as well as the West coast ports where the material components arrived from Taiwan and Japan. Additionally, Asian manufacturers could still produce and assemble high-quality bicycles at a far lower per-unit cost than Schwinn at its plant in Mississippi, which had to import parts, then assemble them using higher-priced United States labor. The Greenville manufacturing facility, which had lost money each year of its operation, finally closed in 1991, laying off 250 workers in the process.\nAfter a series of production cuts and labor force reductions, Schwinn was able to restructure its operations. The company renegotiated loans by putting up the company and the name as collateral, and increased production of the \"Airdyne\" exercise bicycle, a moneymaker even in bad times. The company took advantage of the continued demand for mountain bikes, redesigning its product line with Schwinn-designed chrome-molybdenum alloy steel frames. Supplied by manufacturers in Asia, the new arrangement enabled Schwinn to reduce costs and stay competitive with Asian bicycle companies. In Taiwan, Schwinn was able to conclude a new production agreement with Giant Bicycles, transferring Schwinn's frame design and manufacturing expertise to Giant in the process. With this partnership, Schwinn increased their bicycle sales to 500,000 per year by 1985. Schwinn annual sales soon neared the million mark, and the company turned a profit in the late 1980s. However, after unsuccessfully attempting to purchase a minority share in Giant Bicycles, Edward Schwinn Jr. negotiated a separate deal with the China Bicycle Co. (CBC) to produce bicycles to be sold under the Schwinn brand. In retaliation, Giant introduced its own line of Giant-branded bikes for sale to retailers carrying Schwinn bikes. Both Giant and CBC used the dies, plans, and technological expertise from Schwinn to greatly expand the market share of bicycles made under their own proprietary brands, first in Europe, and later in the United States.\n\nBy 1990, other United States bicycle companies with reputations for excellence in design such as Trek, Specialized, and Cannondale had cut further into Schwinn's market. Unable to produce bicycles in the United States at a competitive cost, by the end of 1991 Schwinn was sourcing its bicycles from overseas manufacturers. This period in Schwinn's history plays a cameo role in a novel by Dave Eggers, \"A Hologram for the King\" (2012). Seeking to increase its brand recognition, Schwinn established additional company-operated shops, a move that alienated existing independent bike retailers in cities where the company stores had opened. This in turn led to further inroads by domestic and foreign competitors. Faced with a downward sales spiral, Schwinn went into bankruptcy in 1992. The company and name were bought by the Zell/Chilmark Fund, an investment group, in 1993. Zell moved Schwinn's corporate headquarters to Boulder, Colorado.\n\nIn 1993, Richard Schwinn, great-grandson of Ignaz Schwinn, with business partner Marc Muller, purchased the Schwinn Paramount plant in Waterford, Wisconsin, where Paramounts were built since 1980. They founded Waterford Precision Cycles, which is still in operation. In 2003 they employed 18 workers building lightweight bicycles.\nIn late 1997, Questor Partners Fund, led by Jay Alix and Dan Lufkin, purchased Schwinn Bicycles. Questor/Schwinn later purchased GT Bicycles in 1998 for $8 a share in cash, roughly $80 million. The new company produced a series of well-regarded mountain bikes bearing the Schwinn name, called the Homegrown series. In 2001, Schwinn/GT declared bankruptcy.\n\nIn September 2001, the Schwinn Company, its assets, and the rights to the brand, together with that of the GT Bicycle, was purchased at a bankruptcy auction by Pacific Cycle, a company previously known for mass-market brands owned by Wind Point Partners. In 2004, Pacific Cycle was in turn acquired by Dorel Industries. Once America's preeminent bicycle manufacturer, the Schwinn brand was now affixed to bicycles fabricated entirely in China, fueling most of its corporate parent's growth. In 2010, Dorel launched a major advertising campaign to revive and contemporize the Schwinn brand by associating it with consumer childhood memories of the iconic company, including a wildly popular reintroduction of the Schwinn \"Sting-Ray\".\n\nDirect Focus, Inc., a marketing company for fitness and healthy lifestyle products, acquired the assets of Schwinn/GT's fitness equipment division. Direct Focus, Inc. subsequently became Nautilus, Inc.\n\nSchwinn sells essentially two lines of bicycles. One is a line of discount bikes offered through mass-merchandisers such as Wal-Mart, Sears and Kmart. The other line known as the Signature Series, featured on the website, are higher-end models sold through specialty shops. Schwinn produces the following types of bicycles:\n\nStarting in 2005, Schwinn also marketed Motorscooters under the Schwinn Motorsports brand. Production ceased in 2011 \n(approx).\n\nSchwinn also produces the following gear: Helmets & Pads, Pumps, Saddles, Lights, Storage, Extras, Repair, Bike trailers, and Jogging strollers.\n\n"}
{"id": "27696", "url": "https://en.wikipedia.org/wiki?curid=27696", "title": "Semiconductor device fabrication", "text": "Semiconductor device fabrication\n\nSemiconductor device fabrication is the process used to create the integrated circuits that are present in everyday electrical and electronic devices. It is a multiple-step sequence of photolithographic and chemical processing steps during which electronic circuits are gradually created on a wafer made of pure semiconducting material. Silicon is almost always used, but various compound semiconductors are used for specialized applications. \n\nThe entire manufacturing process, from start to packaged chips ready for shipment, takes six to eight weeks and is performed in highly specialized facilities referred to as foundries or fabs. In more advanced semiconductor devices, such as modern 14/10/7 nm nodes, fabrication can take up to 15 weeks with 11–13 weeks being the industry average.\n\nBy industry standard, each generation of the semiconductor manufacturing process, also known as \"technology node\", is designated by the process’s \"minimum feature size\". Technology nodes, also known as \"process technologies\" or simply \"nodes\", are typically indicated by the size in nanometers (or historically micrometers) of the process's gate length.\n\nAs of 2018, 14 nanometer process chips are commonly in mass production, with 10 nanometer class chips about to begin production.\n\nSemiconductor device manufacturing has spread from Texas and California in the 1960s to the rest of the world, including Europe, the Middle East, and Asia. It is a global business today. The leading semiconductor manufacturers typically have facilities all over the world. Intel, the world's largest manufacturer, has facilities in Europe and Asia as well as the U.S. Samsung, Qualcomm, and Broadcom, among the biggest semiconductor manufacturers, also have facilities spread in different countries.\n\nWhen feature widths were far greater than about 10 micrometres, semiconductor purity was not as big an issue as it is today in device manufacturing. As devices became more integrated, cleanrooms became even cleaner. Today, fabrication plants are pressurized with filtered air to remove even the smallest particles, which could come to rest on the wafers and contribute to defects. The workers in a semiconductor fabrication facility are required to wear cleanroom suits to protect the devices from human contamination.\n\nA typical wafer is made out of extremely pure silicon that is grown into mono-crystalline cylindrical ingots (boules) up to 300 mm (slightly less than 12 inches) in diameter using the Czochralski process. These ingots are then sliced into wafers about 0.75 mm thick and polished to obtain a very regular and flat surface.\n\nIn semiconductor device fabrication, the various processing steps fall into four general categories: deposition, removal, patterning, and modification of electrical properties.\nModern chips have up to eleven metal levels produced in over 300 sequenced processing steps.\n\nFEOL processing refers to the formation of the transistors directly in the silicon. The raw wafer is engineered by the growth of an ultrapure, virtually defect-free silicon layer through epitaxy. In the most advanced logic devices, \"prior\" to the silicon epitaxy step, tricks are performed to improve the performance of the transistors to be built. One method involves introducing a \"straining step\" wherein a silicon variant such as silicon-germanium (SiGe) is deposited. Once the epitaxial silicon is deposited, the crystal lattice becomes stretched somewhat, resulting in improved electronic mobility. Another method, called \"silicon on insulator\" technology involves the insertion of an insulating layer between the raw silicon wafer and the thin layer of subsequent silicon epitaxy. This method results in the creation of transistors with reduced parasitic effects.\n\nFront-end surface engineering is followed by growth of the gate dielectric (traditionally silicon dioxide), patterning of the gate, patterning of the source and drain regions, and subsequent implantation or diffusion of dopants to obtain the desired complementary electrical properties. In dynamic random-access memory (DRAM) devices, storage capacitors are also fabricated at this time, typically stacked above the access transistor (the now defunct DRAM manufacturer Qimonda implemented these capacitors with trenches etched deep into the silicon surface).\n\nOnce the various semiconductor devices have been created, they must be interconnected to form the desired electrical circuits. This occurs in a series of wafer processing steps collectively referred to as BEOL (not to be confused with \"back end\" of chip fabrication, which refers to the packaging and testing stages). BEOL processing involves creating metal interconnecting wires that are isolated by dielectric layers. The insulating material has traditionally been a form of SiO or a silicate glass, but recently new low dielectric constant materials are being used (such as silicon oxycarbide), typically providing dielectric constants around 2.7 (compared to 3.82 for SiO), although materials with constants as low as 2.2 are being offered to chipmakers.\n\nHistorically, the metal wires have been composed of aluminum. In this approach to wiring (often called \"subtractive aluminum\"), blanket films of aluminum are deposited first, patterned, and then etched, leaving isolated wires. Dielectric material is then deposited over the exposed wires. The various metal layers are interconnected by etching holes (called \"\"vias\")\" in the insulating material and then depositing tungsten in them with a CVD technique; this approach is still used in the fabrication of many memory chips such as dynamic random-access memory (DRAM), because the number of interconnect levels is small (currently no more than four).\n\nMore recently, as the number of interconnect levels for logic has substantially increased due to the large number of transistors that are now interconnected in a modern microprocessor, the timing delay in the wiring has become so significant as to prompt a change in wiring material (from aluminum to copper interconnect layer) and a change in dielectric material (from silicon dioxides to newer low-K insulators). This performance enhancement also comes at a reduced cost via damascene processing, which eliminates processing steps. As the number of interconnect levels increases, planarization of the previous layers is required to ensure a flat surface prior to subsequent lithography. Without it, the levels would become increasingly crooked, extending outside the depth of focus of available lithography, and thus interfering with the ability to pattern. CMP (chemical-mechanical planarization) is the primary processing method to achieve such planarization, although dry \"etch back\" is still sometimes employed when the number of interconnect levels is no more than three.\n\nThe highly serialized nature of wafer processing has increased the demand for metrology in between the various processing steps. For example, thin film metrology based on ellipsometry or reflectometry is used to tightly control the thickness of gate oxide, as well as the thickness, refractive index and extinction coefficient of photoresist and other coatings. Wafer test metrology equipment is used to verify that the wafers haven't been damaged by previous processing steps up until testing; if too many dies on one wafer have failed, the entire wafer is scrapped to avoid the costs of further processing. Virtual metrology has been used to predict wafer properties based on statistical methods without performing the physical measurement itself.\n\nOnce the front-end process has been completed, the semiconductor devices are subjected to a variety of electrical tests to determine if they function properly. The proportion of devices on the wafer found to perform properly is referred to as the yield. Manufacturers are typically secretive about their yields, but it can be as low as 30%. Process variation is one among many reasons for low yield.\n\nThe fab tests the chips on the wafer with an electronic tester that presses tiny probes against the chip. The machine marks each bad chip with a drop of dye. Currently, electronic dye marking is possible if wafer test data is logged into a central computer database and chips are \"binned\" (i.e. sorted into virtual bins) according to the predetermined test limits. The resulting binning data can be graphed, or logged, on a wafer map to trace manufacturing defects and mark bad chips. This map can also be used during wafer assembly and packaging.\n\nChips are also tested again after packaging, as the bond wires may be missing, or analog performance may be altered by the package. This is referred to as the \"final test\".\n\nUsually, the fab charges for testing time, with prices in the order of cents per second. Testing times vary from a few milliseconds to a couple of seconds, and the test software is optimized for reduced testing time. Multiple chip (multi-site) testing is also possible, because many testers have the resources to perform most or all of the tests in parallel.\n\nChips are often designed with \"testability features\" such as scan chains or a \"built-in self-test\" to speed testing, and reduce testing costs. In certain designs that use specialized analog fab processes, wafers are also laser-trimmed during the testing, in order to achieve tightly-distributed resistance values as specified by the design.\n\nGood designs try to test and statistically manage \"corners\" (extremes of silicon behavior caused by a high operating temperature combined with the extremes of fab processing steps). Most designs cope with at least 64 corners.\n\nOnce tested, a wafer is typically reduced in thickness in a process also known as \"backlap\", \"backfinish\" or \"wafer thinning\".\n\nbefore the wafer is scored and then broken into individual dice, a process known as wafer dicing. Only the good, unmarked chips are packaged.\n\nPlastic or ceramic packaging involves mounting the die, connecting the die pads to the pins on the package, and sealing the die. Tiny wires are used to connect the pads to the pins. In the old days, wires were attached by hand, but now specialized machines perform the task. Traditionally, these wires have been composed of gold, leading to a lead frame (pronounced \"leed frame\") of solder-plated copper; lead is poisonous, so lead-free \"lead frames\" are now mandated by RoHS.\n\nChip scale package (CSP) is another packaging technology. A plastic dual in-line package, like most packages, is many times larger than the actual die hidden inside, whereas CSP chips are nearly the size of the die; a CSP can be constructed for each die \"before\" the wafer is diced.\n\nThe packaged chips are retested to ensure that they were not damaged during packaging and that the die-to-pin interconnect operation was performed correctly. A laser then etches the chip's name and numbers on the package.\n\nThis is a list of processing techniques that are employed numerous times throughout the construction of a modern electronic device; this list does not necessarily imply a specific order.\n\nMany toxic materials are used in the fabrication process. These include:\n\n\nIt is vital that workers should not be directly exposed to these dangerous substances. The high degree of automation common in the IC fabrication industry helps to reduce the risks of exposure. Most fabrication facilities employ exhaust management systems, such as wet scrubbers, combustors, heated absorber cartridges, etc., to control the risk to workers and to the environment.\n\n\n\n"}
{"id": "26043962", "url": "https://en.wikipedia.org/wiki?curid=26043962", "title": "Sheeri Cabral", "text": "Sheeri Cabral\n\nSheeri Cabral (born 17 September 1978), née Kritzer, is a MySQL community contributor. She was chosen as the first Oracle ACE Director for MySQL. She won the MySQL Community Advocate, Communicator and Facilitator award in 2007 and again in 2008 for her frequent blog posts, community work, and conference/user group presentations; this sparked a keynote presentation for the 2009 MySQL User Conference & Expo on \"How to be a Community Superhero\". She delivered another community keynote entitled, \"Under New Management: Next Steps for the Community\" at the same conference in 2010. In 2012, she won the MySQL Community Award again for her work founding and co-hosting the OurSQL podcast.\n\nCabral wrote the \"MySQL Administrator's Bible\", and has edited the O'Reilly books \"SQL Hacks\"(2007), \"High Performance MySQL 2nd edition\"(2008), and C.J. Date's \"How to Write Accurate SQL Code\". Cabral developed a new version of mysqltuner (with permission from Major Hayden for the name), which led to developing the mysql_health check Nagios plugin.\n\nCabral has a master's degree in Computer Science from Brandeis University and is MySQL 5.0 DBA Certified and MySQL Core Certified.\n\n\nCabral has worked as a Systems Administrator for Tufts University; a Database Administrator for Guardium, Inc, Manhunt.net and The Pythian Group, a Database Operations Manager for PalominoDB, Inc., and a Senior Database Administrator/Architect, then Data Team Manager at Mozilla. She currently works as a Senior Database Administrator for Salesforce .\n"}
{"id": "10321360", "url": "https://en.wikipedia.org/wiki?curid=10321360", "title": "Short-term conflict alert", "text": "Short-term conflict alert\n\nShort-term conflict alert (STCA) is an automated warning system for air traffic controllers (ATCO). It is a ground-based safety net intended to assist the controller in preventing collision between aircraft by generating, in a timely manner, an alert of a potential or actual infringement of separation minima.\n\nICAO Doc 4444 requires that radar systems should provide for the display of safety-related alerts including the presentation of actual and predicted conflict. It is worth mentioning that ICAO Doc 4444 does neither provide definitions of the term STCA nor \"conflict alert\". Instead the term STCA is ambiguously used in ATC community to identify such alerts as well as for data processing systems providing the alert function.\n\nAs an implementation STCA is part of the predictive safety net functions. It uses surveillance information derived from radars, ADS-B or multilateration as well as environmental data and optional flight plan information in order to predict the movement of aircraft. This process is usually working unnoticeably to the air traffic controller unless a (potential) separation infringement is identified. In this case STCA will generate an alarm to inform the air traffic controller about the hazardous situation identifying the conflicting aircraft. Due to the uncertainty of trajectory prediction the look ahead time of STCA system is typically limited to approx. 2 minutes. Extending the look ahead time is not beneficial as more and more nuisance alerts will be generated.\n\nIn extend to STCA other ground-based safety net functions are typically implemented to support the ATCO. These in include\n\nThe equivalent system on board an aircraft is TCAS. This system alerts pilots to possible conflicts, and suggests remedial actions, in the form of a climb or descent. Unlike TCAS, STCA does not normally suggest remedial action. If action is required, the controller will normally give a turn command to the aircraft, eliminating the possibility that his command will contradict that given by TCAS.\n\nOther concepts of air safety are:\n\n\n"}
{"id": "21399789", "url": "https://en.wikipedia.org/wiki?curid=21399789", "title": "Silicon Saxony", "text": "Silicon Saxony\n\nSilicon Saxony is a registered industry association of nearly 300 companies in the microelectronics and related sectors in Saxony, Germany, with around 40,000 employees. Many, but not all, of those firms are situated in the north of Dresden. \n\nWith a name chosen referring to Silicon Valley, the area and the union — in many aspects — represent the only meaningful European center of microelectronics. Many of those firms have very research and capital intensive business models competing with subsidized global players, mainly from Asia.\n\nThe companies develop and produce computer calculation and memory chips or new materials and electronics for solar companies. The developed and produced small semiconductors chips are used in all kinds of cars, mobile phones, TV sets and so on.\n\nEven before Germany's reunification, Dresden was a major center of microelectronics in the Eastern bloc with 3,500 employees. While mechanical engineering, which has a long history in the south of eastern Germany, suffered after the collapse of the Soviet Union, the microelectronics industry was, with public help from the state, one of the first industrial sectors in Saxony to recover. Although having many more employees today than before 1990, the sector is constantly under pressure because South Korea in particular is very keen to attract the industry. Saxony and Germany are however bound to the competition laws of the European Union, but was able to keep and expand most of the research parts of the industry that it had started with. These parts are seen as successful, but also as very risky whenever a larger company has serious problems because the sector demands a high concentration of resources to succeed.\n\nDresden, as core-region of Silicon Saxony and yet without the headquarters of many of today's big companies, is nevertheless a very remarkable technology center with one large Technical University (German TU), ten other universities and most of all an unparalleled density of semi-public institutes of applied high-technologies in many fields (for example the Max Planck Society, Fraunhofer Society, Leibniz institutes, Helmholtz Association and other German academic elite institutions).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "26980", "url": "https://en.wikipedia.org/wiki?curid=26980", "title": "Sun Microsystems", "text": "Sun Microsystems\n\nSun Microsystems, Inc. was an American company that sold computers, computer components, software, and information technology services and created the Java programming language, the Solaris operating system, ZFS, the Network File System (NFS), and SPARC. Sun contributed significantly to the evolution of several key computing technologies, among them Unix, RISC processors, thin client computing, and virtualized computing. Sun was founded on February 24, 1982. At its height, the Sun headquarters were in Santa Clara, California (part of Silicon Valley), on the former west campus of the Agnews Developmental Center.\n\nOn April 20, 2009, it was announced that Oracle Corporation would acquire Sun for 7.4 billion. The deal was completed on January 27, 2010.\n\nSun products included computer servers and workstations built on its own RISC-based SPARC processor architecture, as well as on x86-based AMD Opteron and Intel Xeon processors. Sun also developed its own storage systems and a suite of software products, including the Solaris operating system, developer tools, Web infrastructure software, and identity management applications. Other technologies included the Java platform and NFS. In general, Sun was a proponent of open systems, particularly Unix. It was also a major contributor to open-source software, as evidenced by its $1 billion purchase, in 2008, of MySQL, an open-source relational database management system. At various times, Sun had manufacturing facilities in several locations worldwide, including Newark, California; Hillsboro, Oregon; and Linlithgow, Scotland. However, by the time the company was acquired by Oracle, it had outsourced most manufacturing responsibilities.\n\nThe initial design for what became Sun's first Unix workstation, the Sun-1, was conceived by Andy Bechtolsheim when he was a graduate student at Stanford University in Palo Alto, California. Bechtolsheim originally designed the SUN workstation for the Stanford University Network communications project as a personal CAD workstation. It was designed around the Motorola 68000 processor with an advanced memory management unit (MMU) to support the Unix operating system with virtual memory support. He built the first ones from spare parts obtained from Stanford's Department of Computer Science and Silicon Valley supply houses.\n\nOn February 24, 1982, Vinod Khosla, Andy Bechtolsheim, and Scott McNealy, all Stanford graduate students, founded \"Sun Microsystems\". Bill Joy of Berkeley, a primary developer of the Berkeley Software Distribution (BSD), joined soon after and is counted as one of the original founders. The Sun name is derived from the initials of the Stanford University Network. Sun was profitable from its first quarter in July 1982.\n\nBy 1983 Sun was known for producing 68k-based systems with high-quality graphics that were the only computers other than DEC's VAX to run 4.2BSD. It licensed the computer design to other manufacturers, which typically used it to build Multibus-based systems running Unix from UniSoft. Sun's initial public offering was in 1986 under the stock symbol \"SUNW\", for \"Sun Workstations\" (later \"Sun Worldwide\"). The symbol was changed in 2007 to \"JAVA\"; Sun stated that the brand awareness associated with its Java platform better represented the company's current strategy.\n\nSun's logo, which features four interleaved copies of the word \"sun\" in the form of a rotationally symmetric ambigram, was designed by professor Vaughan Pratt, also of Stanford. The initial version of the logo was orange and had the sides oriented horizontally and vertically, but it was subsequently rotated to stand on one corner and re-colored purple, and later blue.\n\nIn the dot-com bubble, Sun began making much more money, and its shares rose dramatically. It also began spending much more, hiring workers and building itself out. Some of this was because of genuine demand, but much was from web start-up companies anticipating business that would never happen. In 2000, the bubble burst. Sales in Sun's important hardware division went into free-fall as customers closed shop and auctioned high-end servers.\n\nSeveral quarters of steep losses led to executive departures, rounds of layoffs, and other cost cutting. In December 2001, the stock fell to the 1998, pre-bubble level of about $100. But it kept falling, faster than many other tech companies. A year later it had dipped below $10 (a tenth of what it was even in 1990) but bounced back to $20. In mid-2004, Sun closed their Newark, California, factory and consolidated all manufacturing to Hillsboro, Oregon. In 2006, the rest of the Newark campus was put on the market.\n\nIn 2004, Sun canceled two major processor projects which emphasized high instruction-level parallelism and operating frequency. Instead, the company chose to concentrate on processors optimized for multi-threading and multiprocessing, such as the UltraSPARC T1 processor (codenamed \"Niagara\"). The company also announced a collaboration with Fujitsu to use the Japanese company's processor chips in mid-range and high-end Sun servers. These servers were announced on April 17, 2007, as the M-Series, part of the SPARC Enterprise series.\n\nIn February 2005, Sun announced the Sun Grid, a grid computing deployment on which it offered utility computing services priced at US$1 per CPU/hour for processing and per GB/month for storage. This offering built upon an existing 3,000-CPU server farm used for internal R&D for over 10 years, which Sun marketed as being able to achieve 97% utilization. In August 2005, the first commercial use of this grid was announced for financial risk simulations which was later launched as its first software as a service product.\n\nIn January 2005, Sun reported a net profit of $19 million for fiscal 2005 second quarter, for the first time in three years. This was followed by net loss of $9 million on GAAP basis for the third quarter 2005, as reported on April 14, 2005. In January 2007, Sun reported a net GAAP profit of $126 million on revenue of $3.337 billion for its fiscal second quarter. Shortly following that news, it was announced that Kohlberg Kravis Roberts (KKR) would invest $700 million in the company.\n\nSun had engineering groups in Bangalore, Beijing, Dublin, Grenoble, Hamburg, Prague, St. Petersburg, Tel Aviv, Tokyo, and Trondheim.\n\nIn 2007–2008, Sun posted revenue of $13.8 billion and had $2 billion in cash. First-quarter 2008 losses were $1.68 billion; revenue fell 7% to $12.99 billion. Sun's stock lost 80% of its value November 2007 to November 2008, reducing the company's market value to $3 billion. With falling sales to large corporate clients, Sun announced plans to lay off 5,000 to 6,000 workers, or 15–18% of its work force. It expected to save $700 million to $800 million a year as a result of the moves, while also taking up to $600 million in charges.\n\n \n\n\nAs of May 11, 2009, the following shareholders held over 100,000 common shares of Sun and at $9.50 per share offered by Oracle, they received the amounts indicated when the acquisition closed.\nFor the first decade of Sun's history, the company positioned its products as technical workstations, competing successfully as a low-cost vendor during the Workstation Wars of the 1980s. It then shifted its hardware product line to emphasize servers and storage. High-level telecom control systems such as Operational Support Systems service predominantly used Sun equipment.\n\nSun originally used Motorola 68000 family central processing units for the Sun-1 through Sun-3 computer series. The Sun-1 employed a 68000 CPU, the Sun-2 series, a 68010. The Sun-3 series was based on the 68020, with the later Sun-3x using the 68030.\n\nIn 1987, the company began using \"SPARC\", a RISC processor architecture of its own design, in its computer systems, starting with the Sun-4 line. SPARC was initially a 32-bit architecture (SPARC V7) until the introduction of the SPARC V9 architecture in 1995, which added 64-bit extensions.\n\nSun has developed several generations of SPARC-based computer systems, including the SPARCstation, Ultra and Sun Blade series of workstations, and the SPARCserver, Netra, Enterprise and Sun Fire line of servers.\n\nIn the early 1990s the company began to extend its product line to include large-scale symmetric multiprocessing servers, starting with the four-processor SPARCserver 600MP. This was followed by the 8-processor SPARCserver 1000 and 20-processor SPARCcenter 2000, which were based on work done in conjunction with Xerox PARC. In 1995 the company introduced Sun Ultra series machines that were equipped with the first 64-bit implementation of SPARC processors (UltraSPARC). In the late 1990s the transformation of product line in favor of large 64-bit SMP systems was accelerated by the acquisition of Cray Business Systems Division from Silicon Graphics. Their 32-bit, 64-processor Cray Superserver 6400, related to the SPARCcenter, led to the 64-bit Sun Enterprise 10000 high-end server (otherwise known as \"Starfire\").\n\nIn September 2004 Sun made available systems with UltraSPARC IV which was the first multi-core SPARC processor. It was followed by UltraSPARC IV+ in September 2005 and its revisions with higher clock speeds in 2007. These CPUs were used in the most powerful, enterprise class high-end CC-NUMA servers developed by Sun, such as Sun Fire E25K.\n\nIn November 2005 Sun launched the UltraSPARC T1, notable for its ability to concurrently run 32 threads of execution on 8 processor cores. Its intent was to drive more efficient use of CPU resources, which is of particular importance in data centers, where there is an increasing need to reduce power and air conditioning demands, much of which comes from the heat generated by CPUs. The T1 was followed in 2007 by the UltraSPARC T2, which extended the number of threads per core from 4 to 8. Sun has open sourced the design specifications of both the T1 and T2 processors via the OpenSPARC project.\n\nIn 2006, Sun ventured into the \"blade server\" (high density rack-mounted systems) market with the Sun Blade (distinct from the Sun Blade workstation).\n\nIn April 2007 Sun released the SPARC Enterprise server products, jointly designed by Sun and Fujitsu and based on Fujitsu SPARC64 VI and later processors. The \"M-class\" SPARC Enterprise systems include high-end reliability and availability features. Later T-series servers have also been badged SPARC Enterprise rather than Sun Fire.\n\nIn April 2008 Sun released servers with UltraSPARC T2 Plus, which is an SMP capable version of UltraSPARC T2, available in 2 or 4 processor configurations. It was the first CoolThreads CPU with multi-processor capability and it made possible to build standard rack-mounted servers that could simultaneously process up to massive 256 CPU threads in hardware (Sun SPARC Enterprise T5440), which is considered a record in the industry.\n\nSince 2010, all further development of Sun machines based on SPARC architecture (including new SPARC T-Series servers, SPARC T3 and T4 chips) is done as a part of Oracle Corporation hardware division.\n\nIn the late 1980s, Sun also marketed an Intel 80386-based machine, the Sun386i; this was designed to be a hybrid system, running SunOS but at the same time supporting DOS applications. This only remained on the market for a brief time. A follow-up \"486i\" upgrade was announced but only a few prototype units were ever manufactured.\n\nSun's brief first foray into x86 systems ended in the early 1990s, as it decided to concentrate on SPARC and retire the last Motorola systems and 386i products, a move dubbed by McNealy as \"all the wood behind one arrowhead\". Even so, Sun kept its hand in the x86 world, as a release of Solaris for PC compatibles began shipping in 1993.\n\nIn 1997 Sun acquired Diba, Inc., followed later by the acquisition of Cobalt Networks in 2000, with the aim of building \"network appliances\" (single function computers meant for consumers). Sun also marketed a Network Computer (a term popularized and eventually trademarked by Oracle); the JavaStation was a diskless system designed to run Java applications.\n\nAlthough none of these business initiatives were particularly successful, the Cobalt purchase gave Sun a toehold for its return to the x86 hardware market. In 2002, Sun introduced its first general purpose x86 system, the LX50, based in part on previous Cobalt system expertise. This was also Sun's first system announced to support Linux as well as Solaris.\n\nIn 2003, Sun announced a strategic alliance with AMD to produce x86/x64 servers based on AMD's Opteron processor; this was followed shortly by Sun's acquisition of Kealia, a startup founded by original Sun founder Andy Bechtolsheim, which had been focusing on high-performance AMD-based servers.\n\nThe following year, Sun launched the Opteron-based Sun Fire V20z and V40z servers, and the Java Workstation W1100z and W2100z workstations.\n\nOn September 12, 2005, Sun unveiled a new range of Opteron-based servers: the Sun Fire X2100, X4100 and X4200 servers. These were designed from scratch by a team led by Bechtolsheim to address heat and power consumption issues commonly faced in data centers. In July 2006, the Sun Fire X4500 and X4600 systems were introduced, extending a line of x64 systems that support not only Solaris, but also Linux and Microsoft Windows.\n\nOn January 22, 2007, Sun announced a broad strategic alliance with Intel. Intel endorsed Solaris as a mainstream operating system and as its mission critical Unix for its Xeon processor-based systems, and contributed engineering resources to OpenSolaris. Sun began using the Intel Xeon processor in its x64 server line, starting with the Sun Blade X6250 server module introduced in June 2007.\n\nOn May 5, 2008, AMD announced its Operating System Research Center (OSRC) expanded its focus to include optimization to Sun's OpenSolaris and xVM virtualization products for AMD based processors.\n\nAlthough Sun was initially known as a hardware company, its software history began with its founding in 1982; co-founder Bill Joy was one of the leading Unix developers of the time, having contributed the vi editor, the C shell, and significant work developing TCP/IP and the BSD Unix OS. Sun later developed software such as the Java programming language and acquired software such as StarOffice, VirtualBox and MySQL.\n\nSun used community-based and open-source licensing of its major technologies, and for its support of its products with other open source technologies. GNOME-based desktop software called Java Desktop System (originally code-named \"Madhatter\") was distributed for the Solaris operating system, and at one point for Linux. Sun supported its Java Enterprise System (a middleware stack) on Linux. It released the source code for Solaris under the open-source Common Development and Distribution License, via the OpenSolaris community. Sun's positioning includes a commitment to indemnify users of some software from intellectual property disputes concerning that software. It offers support services on a variety of pricing bases, including per-employee and per-socket.\n\nA 2006 report prepared for the EU by UNU-MERIT stated that Sun was the largest corporate contributor to open source movements in the world. According to this report, Sun's open source contributions exceed the combined total of the next five largest commercial contributors.\n\nSun is best known for its Unix systems, which have a reputation for system stability and a consistent design philosophy.\n\nSun's first workstation shipped with UniSoft V7 Unix. Later in 1982 Sun began providing SunOS, a customized 4.1BSD Unix, as the operating system for its workstations.\n\nIn the late 1980s, AT&T tapped Sun to help them develop the next release of their branded UNIX, and in 1988 announced they would purchase up to a 20% stake in Sun. UNIX System V Release 4 (SVR4) was jointly developed by AT&T and Sun; Sun used SVR4 as the foundation for Solaris 2.x, which became the successor to SunOS 4.1.x (later retrospectively named Solaris 1.x). By the mid-1990s, the ensuing Unix wars had largely subsided, AT&T had sold off their Unix interests, and the relationship between the two companies was significantly reduced.\n\nFrom 1992 Sun also sold Interactive Unix, an operating system it acquired when it bought Interactive Systems Corporation from Eastman Kodak Company. This was a popular Unix variant for the PC platform and a major competitor to market leader SCO UNIX. Sun's focus on Interactive Unix diminished in favor of Solaris on both SPARC and x86 systems; it was dropped as a product in 2001.\n\nSun dropped the Solaris 2.x version numbering scheme after the Solaris 2.6 release (1997); the following version was branded Solaris 7. This was the first 64-bit release, intended for the new UltraSPARC CPUs based on the SPARC V9 architecture. Within the next four years, the successors Solaris 8 and Solaris 9 were released in 2000 and 2002 respectively.\n\nFollowing several years of difficult competition and loss of server market share to competitors' Linux-based systems, Sun began to include Linux as part of its strategy in 2002. Sun supported both Red Hat Enterprise Linux and SUSE Linux Enterprise Server on its x64 systems; companies such as Canonical Ltd., Wind River Systems and MontaVista also supported their versions of Linux on Sun's SPARC-based systems.\n\nIn 2004, after having cultivated a reputation as one of Microsoft's most vocal antagonists, Sun entered into a joint relationship with them, resolving various legal entanglements between the two companies and receiving US$1.95 billion in settlement payments from them. Sun supported Microsoft Windows on its x64 systems, and announced other collaborative agreements with Microsoft, including plans to support each other's virtualization environments.\n\nIn 2005, the company released Solaris 10. The new version included a large number of enhancements to the operating system, as well as very novel features, previously unseen in the industry. Solaris 10 update releases continued through the next 8 years, the last release from Sun Microsystems being Solaris 10 10/09. The following updates were released by Oracle under the new license agreement; the final release is Solaris 10 1/13.\n\nPreviously, Sun offered a separate variant of Solaris called Trusted Solaris, which included augmented security features such as multilevel security and a least privilege access model. Solaris 10 included many of the same capabilities as Trusted Solaris at the time of its initial release; Solaris 10 11/06 included Solaris Trusted Extensions, which give it the remaining capabilities needed to make it the functional successor to Trusted Solaris.\n\nAfter releasing Solaris 10, its source code was opened under CDDL free software license and developed in open with contributing Opensolaris community through SXCE that used SVR4 .pkg packaging and supported Opensolaris releases that used IPS.\nFollowing acquisition of Sun by Oracle , Opensolaris continued to develop in open under illumos with illumos distributions.\n\nOracle Corporation continued to develop OpenSolaris into next Solaris release, changing back the license to proprietary, and released it as Oracle Solaris 11 in November 2011.\n\nThe Java platform was developed at Sun by James Gosling in the early 1990s with the objective of allowing programs to function regardless of the device they were used on, sparking the slogan \"Write once, run anywhere\" (WORA). While this objective was not entirely achieved (prompting the riposte \"Write once, debug everywhere\"), Java is regarded as being largely hardware- and operating system-independent.\n\nJava was initially promoted as a platform for client-side \"applets\" running inside web browsers. Early examples of Java applications were the HotJava web browser and the HotJava Views suite. However, since then Java has been more successful on the server side of the Internet.\n\nThe platform consists of three major parts: the Java programming language, the Java Virtual Machine (JVM), and several Java Application Programming Interfaces (APIs). The design of the Java platform is controlled by the vendor and user community through the Java Community Process (JCP).\n\nJava is an object-oriented programming language. Since its introduction in late 1995, it became one of the world's most popular programming languages.\n\nJava programs are compiled to byte code, which can be executed by any JVM, regardless of the environment.\n\nThe Java APIs provide an extensive set of library routines. These APIs evolved into the \"Standard Edition\" (Java SE), which provides basic infrastructure and GUI functionality; the \"Enterprise Edition\" (Java EE), aimed at large software companies implementing enterprise-class application servers; and the \"Micro Edition\" (Java ME), used to build software for devices with limited resources, such as mobile devices.\n\nOn November 13, 2006, Sun announced it would be licensing its Java implementation under the GNU General Public License; it released its Java compiler and JVM at that time.\n\nIn February 2009 Sun entered a battle with Microsoft and Adobe Systems, which promoted rival platforms to build software applications for the Internet. JavaFX was a development platform for music, video and other applications that builds on the Java programming language.\n\nIn 1999, Sun acquired the German software company Star Division and with it the office suite StarOffice, which Sun later released as OpenOffice.org under both GNU LGPL and the SISSL (Sun Industry Standards Source License). OpenOffice.org supported Microsoft Office file formats (though not perfectly), was available on many platforms (primarily Linux, Microsoft Windows, Mac OS X, and Solaris) and was used in the open source community.\n\nThe principal differences between StarOffice and OpenOffice.org were that StarOffice was supported by Sun, was available as either a single-user retail box kit or as per-user blocks of licensing for the enterprise, and included a wider range of fonts and document templates and a commercial quality spellchecker. StarOffice also contained commercially licensed functions and add-ons; in OpenOffice.org these were either replaced by open-source or free variants, or are not present at all. Both packages had native support for the OpenDocument format.\n\nIn 2007, Sun announced the Sun xVM virtualization and datacenter automation product suite for commodity hardware. Sun also acquired VirtualBox in 2008. Earlier virtualization technologies from Sun like \"Dynamic System Domains\" and \"Dynamic Reconfiguration\" were specifically designed for high-end SPARC servers, and Logical Domains only supports the UltraSPARC T1/T2/T2 Plus server platforms. Sun marketed \"Sun Ops Center\" provisioning software for datacenter automation.\n\nOn the client side, Sun offered virtual desktop solutions. Desktop environments and applications could be hosted in a datacenter, with users accessing these environments from a wide range of client devices, including Microsoft Windows PCs, Sun Ray virtual display clients, Apple Macintoshes, PDAs or any combination of supported devices. A variety of networks were supported, from LAN to WAN or the public Internet. Virtual desktop products included Sun Ray Server Software, Sun Secure Global Desktop and Sun Virtual Desktop Infrastructure.\n\nSun acquired MySQL AB, the developer of the MySQL database in 2008 for US$1 billion. CEO Jonathan Schwartz mentioned in his blog that optimizing the performance of MySQL was one of the priorities of the acquisition. In February 2008, Sun began to publish results of the MySQL performance optimization work. Sun contributed to the PostgreSQL project. On the Java platform, Sun contributed to and supported Java DB.\n\nSun offered other software products for software development and infrastructure services. Many were developed in house; others came from acquisitions, including Tarantella, Waveset Technologies, SeeBeyond, and Vaau. Sun acquired many of the Netscape non-browser software products as part a deal involving Netscape's merger with AOL. These software products were initially offered under the \"iPlanet\" brand; once the Sun-Netscape alliance ended, they were re-branded as \"Sun ONE\" (Sun Open Network Environment), and then the \"Sun Java System\".\n\nSun's middleware product was branded as the \"Java Enterprise System\" (or JES), and marketed for web and application serving, communication, calendaring, directory, identity management and service-oriented architecture. Sun's Open ESB and other software suites were available free of charge on systems running Solaris, Red Hat Enterprise Linux, HP-UX, and Windows, with support available optionally.\n\nSun developed data center management software products, which included the \"Solaris Cluster\" high availability software, and a grid management package called \"Sun Grid Engine\" and firewall software such as SunScreen.\nFor Network Equipment Providers and telecommunications customers, Sun developed the Sun Netra High-Availability Suite.\n\nSun produced compilers and development tools under the \"Sun Studio\" brand, for building and developing Solaris and Linux applications.\nSun entered the software as a service (SaaS) market with zembly, a social cloud-based computing platform and Project Kenai, an open-source project hosting service.\n\nSun sold its own storage systems to complement its system offerings; it has also made several storage-related acquisitions.\nOn June 2, 2005, Sun announced it would purchase Storage Technology Corporation (StorageTek) for US$4.1 billion in cash, or $37.00 per share, a deal completed in August 2005.\n\nIn 2006, Sun introduced the Sun StorageTek 5800 System, the first application-aware programmable storage solution. In 2008, Sun contributed the source code of the StorageTek 5800 System under the BSD license.\n\nSun announced the Sun Open Storage platform in 2008 built with open source technologies.\nIn late 2008 Sun announced the Sun Storage 7000 Unified Storage systems (codenamed Amber Road). Transparent placement of data in the systems' solid-state drives (SSD) and conventional hard drives was managed by ZFS to take advantage of the speed of SSDs and the economy of conventional hard disks.\n\nOther storage products included Sun Fire X4500 storage server and SAM-QFS filesystem and storage management software.\n\nSun marketed the Sun Constellation System for high-performance computing (HPC). Even before the introduction of the Sun Constellation System in 2007, Sun's products were in use in many of the TOP500 systems and supercomputing centers:\n\nThe \"Sun HPC ClusterTools\" product was a set of Message Passing Interface (MPI) libraries and tools for running parallel jobs on Solaris HPC clusters. Beginning with version 7.0, Sun switched from its own implementation of MPI to Open MPI, and donated engineering resources to the Open MPI project.\n\nSun was a participant in the OpenMP language committee. Sun Studio compilers and tools implemented the OpenMP specification for shared memory parallelization.\n\nIn 2006, Sun built the \"TSUBAME supercomputer\", which was until June 2008 the fastest supercomputer in Asia. Sun built \"Ranger\" at the Texas Advanced Computing Center (TACC) in 2007. Ranger had a peak performance of over 500 TFLOPS, and was the 6th most powerful supercomputer on the TOP500 list in November 2008.\nSun announced an OpenSolaris distribution that integrated Sun's HPC products with others.\n\nNotable Sun employees included John Gilmore, Whitfield Diffie, Radia Perlman, and Marc Tremblay. Sun was an early advocate of Unix-based networked computing, promoting TCP/IP and especially NFS, as reflected in the company's motto \"The Network Is The Computer\", coined by John Gage. James Gosling led the team which developed the Java programming language. Jon Bosak led the creation of the XML specification at W3C.\n\nSun staff published articles on the company's blog site. Staff were encouraged to use the site to blog on any aspect of their work or personal life, with few restrictions placed on staff, other than commercially confidential material. Jonathan I. Schwartz was one of the first CEOs of large companies to regularly blog; his postings were frequently quoted and analyzed in the press. In 2005, Sun Microsystems was one of the first Fortune 500 companies that instituted a formal Social Media program.\n\nSun was sold to Oracle Corporation in 2009.\nSun's staff were asked to share anecdotes about their experiences at Sun. A web site containing videos, stories, and photographs from 27 years at Sun was made available on September 2, 2009.\nIn October, Sun announced a second round of thousands of employees to be laid off, blamed partially on delays in approval of the merger.\nThe transaction was completed in early 2010.\nIn January 2011, Oracle agreed to pay $46 million to settle charges that it submitted false claims to US federal government agencies and paid \"kickbacks\" to systems integrators.\nIn February 2011, Sun's former Menlo Park, California, campus of about was sold, and it was announced that it would become headquarters for Facebook.\nThe sprawling facility built around an enclosed courtyard had been nicknamed \"Sun Quentin\". On September 1, 2011, Sun India legally became part of Oracle. It had been delayed due to legal issues in Indian court.\n\n\n"}
{"id": "7251197", "url": "https://en.wikipedia.org/wiki?curid=7251197", "title": "The Trouble with Bubbles", "text": "The Trouble with Bubbles\n\n\"The Trouble With Bubbles\" is a 1953 science fiction short story by American writer Philip K. Dick. The story first appeared in \"If\" magazine, September 1953, and was first printed in book form in \"Second Variety\", volume two of the five-volume \"The Collected Stories of Philip K. Dick\", in 1987.\n\nThe story is set in a future where mankind has attempted to reach other intelligent lifeforms through space exploration, and found nothing. In light of this yearning to connect with other lifeforms, people can buy a plastic bubble known as a \"Worldcraft\", the tagline of which reads \"Own Your Own World!\". The owner of the \"Worldcraft\" is able to create a whole universe, controlling all the variables inherent to its development. Within the universe, lifeforms just like humans exist.\n\nIn the story we see Nathan Hull, the protagonist, attending a contest to judge who has created the best \"Worldcraft\" universe. A contestant subsequently smashes and destroys her bubble after being announced the winner. Hull, feeling the immorality of the control owners have over the lives within the bubbles, works to have laws passed against creating any more \"Worldcrafts\". At the end of the story, Hull is about to drive through a newly built underground tunnel to Asia when an unexpected earthquake breaks it up, killing scores of people.\n\n"}
{"id": "23680", "url": "https://en.wikipedia.org/wiki?curid=23680", "title": "There's Plenty of Room at the Bottom", "text": "There's Plenty of Room at the Bottom\n\n\"There's Plenty of Room at the Bottom: An Invitation to Enter a New Field of Physics\" was a lecture given by physicist Richard Feynman at the annual American Physical Society meeting at Caltech on December 29, 1959. Feynman considered the possibility of direct manipulation of individual atoms as a more powerful form of synthetic chemistry than those used at the time. Versions of the talk were printed in a few popular magazines within a year and newspapers covered the winning of the presented challenges in 1960 and again in 1985. The talk went unnoticed and did not inspire the conceptual beginnings of the field, but nanotechnology research advocates began citing it in the 1990s to establish the scientific credibility of their work.\n\nFeynman considered a number of interesting ramifications of a general ability to manipulate matter on an atomic scale. He was particularly interested in the possibilities of denser computer circuitry, and microscopes that could see things much smaller than is possible with scanning electron microscopes. These ideas were later realized by the use of the scanning tunneling microscope, the atomic force microscope and other examples of scanning probe microscopy and storage systems such as Millipede, created by researchers at IBM.\n\nFeynman also suggested that it should be possible, in principle, to make nanoscale machines that \"arrange the atoms the way we want\", and do chemical synthesis by mechanical manipulation.\n\nHe also presented the possibility of \"swallowing the doctor\", an idea that he credited in the essay to his friend and graduate student Albert Hibbs. This concept involved building a tiny, swallowable surgical robot.\n\nAs a thought experiment he proposed developing a set of one-quarter-scale manipulator hands slaved to the operator's hands to build one-quarter scale machine tools analogous to those found in any machine shop. This set of small tools would then be used by the small hands to build and operate ten sets of one-sixteenth-scale hands and tools, and so forth, culminating in perhaps a billion tiny factories to achieve massively parallel operations. He uses the analogy of a pantograph as a way of scaling down items. This idea was anticipated in part, down to the microscale, by science fiction author Robert A. Heinlein in his 1942 story \"Waldo\".\nAs the sizes got smaller, one would have to redesign some tools, because the relative strength of various forces would change. Although gravity would become unimportant, surface tension would become more important, Van der Waals attraction would become important, etc. Feynman mentioned these scaling issues during his talk. Nobody has yet attempted to implement this thought experiment, although it has been noted that some types of biological enzymes and enzyme complexes (especially ribosomes) function chemically in a way close to Feynman's vision. Feynman also mentioned in his lecture that it might be better eventually to use glass or plastic because their greater uniformity would avoid problems in the very small scale (metals and crystals are separated into domains where the lattice structure prevails). This could be a good reason to make machines and also electronics out of glass and plastic. At the present time, there are electronic components made of both materials. In glass, there are optical fiber cables that amplify the light pulses at regular intervals, using glass doped with the rare-earth element erbium. The doped glass is spliced into the fiber and pumped by a laser operating at a different frequency. In plastic, field effect transistors are being made with polythiophene, a plastic invented by Alan J. Heeger et al. that becomes an electrical conductor when oxidized. At this time, a factor of just 20 in electron mobility separates plastic from silicon.\n\nAt the meeting Feynman concluded his talk with two challenges, and he offered a prize of $1000 for the first individuals to solve each one. The first challenge involved the construction of a tiny motor, which, to Feynman's surprise, was achieved by November 1960 by Caltech graduate, William McLellan, a meticulous craftsman, using conventional tools. The motor met the conditions, but did not advance the art. The second challenge involved the possibility of scaling down letters small enough so as to be able to fit the entire \"Encyclopædia Britannica\" on the head of a pin, by writing the information from a book page on a surface 1/25,000 smaller in linear scale. In 1985, Tom Newman, a Stanford graduate student, successfully reduced the first paragraph of \"A Tale of Two Cities\" by 1/25,000, and collected the second Feynman prize. Newman's thesis adviser, R. Fabian Pease, had read the paper back in 1966; but it was another grad student in the lab, Ken Polasko, who had recently read it who suggested attempting the challenge. Newman was looking for some arbitrary random pattern for demonstrating their technology. Newman said, \"Text was ideal because it has so many different shapes.\"\n\n\"The New Scientist\" reported \"the scientific audience was captivated.\" Feynman had \"spun the idea off the top of his mind\" without even \"notes from beforehand\". There were no copies of the speech for those asking for copies. A \"foresighted admirer\" brought a tape recorder and an edited transcript, without Feynman's jokes, was made for publication by Caltech. In February 1960, Caltech's \"Engineering and Science\" published the speech. In addition to excerpts in \"The New Scientist\", versions were printed in \"The Saturday Review\" and \"Popular Science\". Newspapers announced the winning of the first challenge. It was included as the final chapter in the 1961 book, \"Miniaturization\".\n\nK. Eric Drexler later took the Feynman concept of a billion tiny factories and added the idea that they could make more copies of themselves, via computer control instead of control by a human operator, in his 1986 book \"Engines of Creation: The Coming Era of Nanotechnology\".\n\nAfter Feynman's death, scholars studying the historical development of nanotechnology have concluded that his actual role in catalyzing nanotechnology research was limited based on recollections from many of the people active in the nascent field in the 1980s and 1990s. Chris Toumey, a cultural anthropologist at the University of South Carolina, has reconstructed the history of the publication and republication of Feynman's talk, along with the record of citations to “Plenty of Room” in the scientific literature. In Toumey's 2008 article, \"Reading Feynman into Nanotechnology\", he found 11 versions of the publication of “Plenty of Room\", plus two instances of a closely related talk by Feynman, “Infinitesimal Machinery,” which Feynman called “Plenty of Room, Revisited.” Also in Toumey's references are videotapes of that second talk.\n\nToumey found that the published versions of Feynman's talk had a negligible influence in the twenty years after it was first published, as measured by citations in the scientific literature, and not much more influence in the decade after the Scanning Tunneling Microscope was invented in 1981. Subsequently, interest in “Plenty of Room” in the scientific literature greatly increased in the early 1990s. This is probably because the term “nanotechnology” gained serious attention just before that time, following its use by Drexler in his 1986 book, \"Engines of Creation: The Coming Era of Nanotechnology\", which cited Feynman, and in a cover article headlined \"Nanotechnology\", published later that year in a mass-circulation science-oriented magazine, \"OMNI\". The journal \"Nanotechnology\" was launched in 1989; the famous Eigler-Schweizer experiment, precisely manipulating 35 xenon atoms, was published in \"Nature\" in April 1990; and \"Science\" had a special issue on nanotechnology in November 1991. These and other developments hint that the retroactive rediscovery of Feynman's “Plenty of Room” gave nanotechnology a packaged history that provided an early date of December 1959, plus a connection to the charisma and genius of Richard Feynman.\n\nToumey's analysis also includes comments from distinguished scientists in nanotechnology who say that “Plenty of Room” did not influence their early work, and in fact most of them had not read it until a later date.\n\nFeynman's stature as a Nobel laureate and as an iconic figure in 20th century science surely helped advocates of nanotechnology and provided a valuable intellectual link to the past. More concretely, his stature and concept of atomically precise fabrication played a role in securing funding for nanotechnology research, illustrated by President Clinton's January 2000 speech calling for a Federal program:\n\nWhile the version of the Nanotechnology Research and Development Act that was passed by the House in May 2003 called for a study of the technical feasibility of molecular manufacturing, this study was removed to safeguard funding of less controversial research before the Act was passed by the Senate and finally signed into law by President Bush on December 3, 2003.\n\n\n\n"}
{"id": "46301241", "url": "https://en.wikipedia.org/wiki?curid=46301241", "title": "TiE Silicon Valley", "text": "TiE Silicon Valley\n\nTiE Silicon Valley (TiE SV) is the largest and founding chapter of the TiE brand, a non-profit organization dedicated to fostering entrepreneurship. It provides technology entrepreneurs with mentoring services, networking opportunities, startup-related education, funding, and incubating.\n\nTiE SV was founded in 1992 by a group of successful entrepreneurs, corporate executives, and senior professionals with roots in the South Asian or Indus region and was named TiE for \"The Indus Entrepreneurs.\" It has since moved away from that focus and is open and inclusive.\n\nTiE SV received the 2014 Innovation Catalyst Award by VC Taskforce, which recognizes venture community leaders for being catalysts of innovation and entrepreneurship. Past recipients of this award include female venture capitalist Ann Winblad, the Draper family, and Reid Hoffman.\n\nTiE SV is a network of general members, Charter Members, and sponsors.\n\nCharter members are successful, veteran entrepreneurs who are looking to give back and assist the next generation of entrepreneurs by offering their time, knowledge, and resources. As of December 2014, TiE SV has more than 300 Charter members. This membership level is by invitation only. Since inception, this group has created upwards of a quarter trillion dollars of value worldwide.\n\nTiEcon is TiE SV's flagship annual conference. Since 2008, more than 4,000 people attend the conference from over 40 countries. It is widely considered the world's largest conference for entrepreneurs. The conference features two full days of networking and programming with thousands of entrepreneurs, venture capitalists, industry executives, and thought leaders.\n\nEach TiEcon, the world's 50 most promising technology startups are honored as the \"TiE50.\" These companies are selected from more than 1,600 companies screened worldwide. As of 2011, 94% of TiE50 companies had been funded, attracted over $20 billion in investments, and 42 of the companies exited. At TiEcon 2011, Cloudera, the leading provider of Apache Hadoop-based data management software and services, was announced as a TiE50 winner in the software/cloud computing category.\n\nTiEcon was listed by Worth Magazine in their September 2011 issue to be among the 10 Best Conferences for Ideas and Entrepreneurship.\n\nTiE Angels is an early stage Angel investment group formed in 2010 by Charter Members of TiE SV. There are about 100 investors that invest through TiE Angels. There is no TiE SV fund and individuals invest in their personal capacity. TiE Angels was ranked by CB Insights as one of the Top 20 Angel groups in the nation in August 2014.\n\nMost of TiE Angels investments are under $1 million, with a focus on enterprise solutions that leverage the technological expertise of TiE members. In its first year of existence, TiE Angels invested in 11 companies with a total of about $4.5 million. CloudVolumes, which was purchased by VMware in August 2014, was backed by TiE Angels and several individual Angel investors. TiE Angels also backed CRISI Medical which was acquired by BD Medical in March 2015.\n\nTiE LaunchPad is TiE SV's accelerator program for early stage startups. LaunchPad accepts eight companies per batch, and startups are seeded with $50,000 in convertible notes and offered optional working space, infrastructure, and additional support services for a five month duration. Companies also get assistance in fundraising by presenting to TiE's network of investors at a Demo Day at the end of the program. More than 50 Charter members serve as mentors to LaunchPad companies.\n\nThe Billion Dollar Babies Program is an initiative through TiE SV to mentor product companies out of India who are achieving significant domestic traction and wish to scale their products globally. It is managed by BV Jagadeesh, Raju Reddy (founder of Sierra Atlantic), and TiE SV President Venktesh Shukla. The pilot round of this program began January 2015.\n"}
{"id": "54158006", "url": "https://en.wikipedia.org/wiki?curid=54158006", "title": "ULT-160", "text": "ULT-160\n\nThe Ult 160 is a front loader that was produced by IMK 14. oktobar Kruševac in Kruševac, Serbia. Ult 160 is successor of Ult 150 front loaders.\n"}
{"id": "5761185", "url": "https://en.wikipedia.org/wiki?curid=5761185", "title": "Universal powerline bus", "text": "Universal powerline bus\n\nUniversal Powerline Bus (UPB) is a proprietary software protocol for power-line communication between devices used for home automation. Household electrical wiring is used to send digital data between UPB devices via pulse-position modulation.\n\nCommunication can be peer to peer, with no central controller necessary.\n\nUPB addressing allows 250 devices per house and 250 houses per transformer, allowing over 64,000 total device addresses, and switches can co-exist with other powerline carrier systems within the same house.\n\nWhile UPB may be more efficient than X10, it has far fewer products available on the market.\n\n, control of UPB devices is partially supported by the openHAB software project.\n"}
{"id": "708506", "url": "https://en.wikipedia.org/wiki?curid=708506", "title": "WWOOF", "text": "WWOOF\n\nWorld Wide Opportunities on Organic Farms (WWOOF, ), or Willing Workers on Organic Farms, is a hospitality service operated by a loose network of national organizations that facilitate homestays on organic farms. Australia with 2,600 hosts has the most host farms and enterprises, followed by New Zealand with 2,340 and United States with 2,052 hosts. The UK has 688 WWOOF hosts. While there are WWOOF hosts in 210 countries around the world, no central list or organization encompasses all WWOOF hosts. As there is no single international WWOOF membership, all recognised WWOOF country organizations strive to maintain similar standards, and work together to promote the aims of WWOOF.\n\nWWOOF aims to provide volunteers (often called \"WWOOFers\" or \"woofers\", ) with first-hand experience in organic and ecologically sound growing methods, to help the organic movement; and to let volunteers experience life in a rural setting or a different country. WWOOF volunteers generally do not receive money in exchange for services. The host provides food, lodging, and opportunities to learn, in exchange for assistance with farming or gardening activities.\n\nThe duration of the visit can range from a few days to years. Workdays average five to six hours, and participants interact with WWOOFers from other countries. WWOOF farms include private gardens through smallholdings, allotments, and commercial farms. Farms become WWOOF hosts by enlisting with their national organization. In countries with no WWOOF organization, farms enlist with WWOOF Independents:\n\nWWOOF originally stood for \"Working Weekends On Organic Farms\" and began in England in 1971. Sue Coppard, a woman working as a secretary in London, wanted to provide urban dwellers with access to the countryside, while supporting the organic movement. Her idea started with trial working weekends for four people at the biodynamic farm at Emerson College in Sussex.\n\nPeople soon started volunteering for longer periods than just weekends, so the name was changed to Willing Workers On Organic Farms, but then the word \"work\" caused problems with some countries' labour laws and immigration authorities, who tended to treat WWOOFers as migrant workers and oppose foreigners competing for local jobs. (Many WWOOFers enter countries on tourist visas, which is illegal in countries such as the United States.) Both in an attempt to circumvent this and also in recognition of WWOOFing's worldwide scope, the name was changed again in 2000 to \"World Wide Opportunities on Organic Farms\". Some WWOOF groups (such as Australia) choose to retain the older name, however.\n\nVolunteers choose what country they would like to visit and volunteer in and contact arrange the dates and duration of their stay at selected farms. The duration of a volunteer's stay can range from days to months, but is typically one to two weeks. Volunteers can expect to work for 4–6 hours a day for a full day's food and accommodation. Volunteers could be asked to help with a variety of tasks, including: sowing seed, making compost, gardening, planting, cutting wood, weeding, harvesting, packing, milking, feeding, fencing, making mud-bricks, wine making, cheese making and bread baking. \n\n\n"}
{"id": "24225619", "url": "https://en.wikipedia.org/wiki?curid=24225619", "title": "Waffle slab foundation", "text": "Waffle slab foundation\n\nA waffle slab foundation, also called a ribbed slab foundation, is an above-ground type of foundation used to provide load-bearing capacity in expansive, rocky or hydro collapsible soils. The foundation is created by placing a series of single-use plastic forms set directly on grade to create a grid of ribs, and then monolithically pouring a post tensioned, rebar or Fiber reinforced concrete slab, usually 4 to 8 inches thick between the ribs. Sometimes, expanded polystyrene blocks are used instead of plastic forms, to prevent creating an air space under the slab. The monolithic pour creates concrete beams running throughout the footprint and perimeter of the foundation, with voids between, in one operation. The completed slab then sits on the ground bearing on the ribs created between the forms. The void areas underneath the slab allow for soil movement.\n\nThe waffle slab foundation is very stiff, with strength to resist differential swelling resulting from landscaping practices, surface drainage, or flooding from any source. It does not require presoaking underlying soil pads, and there is no need for footings, meaning no earth spoils. And, since the slab section is typically 14 to 20 inches above grade, it typically does not require a capillary break or moisture barrier.\n\nCurrent design practice provides post-tensioned on-grade slabs with stiffness equal to or better than other post-tensioned slab types, but with less susceptibility to swell pressures exerted by expansive soils. An on-grade mat foundation provides all of the elements of the in-ground rib and uniform thickness slabs, but with greater performance provided by its geometry and smaller contact area.\n\nWaffle slab foundations adhere to International Building Code requirements. By 2008, most states put into effect the changes adopted in the 2006 IBC and, in regards to foundations, the on-grade mat foundation has become a more attractive design because, as an engineered system, it already accommodates the 2008 design recommendations, and required no major modifications to bring it into compliance. In 2008, the Post-Tensioning Institute (PTI) approved two key specifications for waffle-slab foundations and incorporated them into the PTI Manual, which is frequently referenced by building codes for post-tensioned slab design. \n\n\nAn engineer designing an on-grade slab makes the same calculations and follows the same requirements used in the design of traditional post-tensioned slabs on grade, and then applies them to the on-grade mat foundation ensuring the system possesses equal or greater stiffness.\n\nThe higher contact pressures along the base of the ribs and the voids or low pressure areas in the system limit deformations of soil due to moisture variation to the void spaces, reducing the impact of the soil's volume change on the on-grade mat slabs.\n\nEnvironmental engineers note reduced carbon emissions and air quality emissions are usually of the same magnitude as the reduction in concrete needed for any foundation project. Since use of an on-grade mat foundation typically results in a 20% - 30% reduction in concrete, a similar or even greater reduction in carbon emissions and air emissions will also occur. Because a waffle slab uses less raw materials (cement, iron, fuel, water, aggregate, and sand) than traditional slab-on-grade foundations, the system is also more environmentally sustainable.\n\n\n"}
{"id": "14569490", "url": "https://en.wikipedia.org/wiki?curid=14569490", "title": "World Communication Awards", "text": "World Communication Awards\n\nThe World Communication Awards (WCA) were established in 1999 to recognise excellence amongst global telecom operators. The first awards were presented in Geneva during ITU Telecom '99 and were held at the Espace Sécheron More recent awards have been presented in London drawing an audience of around 500 senior executives from the telecommunications industry.\n\nOver the years, the World Communication Awards have evolved from being purely for telecom operators to encompass the broader telecom and ICT industry, with categories applicable to telecom operators and service providers, as well as vendors. In 2011 a sister event, the Asia Communication Awards was launched and is held annually in Singapore. \n\nThe World Communication Awards are organised by Total Telecom and their owners Terrapinn. It celebrated its 10th year in 2008 with fifteen categories being presented, and with the chairman of the judges being David Molony, former editor-in-chief of \"Total Telecom\" and now an analyst at consultants Ovum.\n\nOver the years the WCA have become more wide-ranging and international, with the 2007 winners including Bharti Airtel, Minick, BT, NTT Comm, SpinVox, Afsat, Orange, ip.access, Botswana Telecom, TeliaSonera, and Vivian Reding.\n\nIn 2016, Vodafone Carrier Services received the \"Best Network transformation Initiative\" award during the WCA, in London. \n\nThe 2017 edition of the WCA was marked by the nomination of Ernest Cu -President and CEO of Globe Telecom- as the \"CEO of the year\".\n\n\n\n"}
