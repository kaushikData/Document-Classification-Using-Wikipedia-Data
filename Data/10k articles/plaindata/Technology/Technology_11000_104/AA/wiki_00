{"id": "51682297", "url": "https://en.wikipedia.org/wiki?curid=51682297", "title": "Antique Woodworking Tools", "text": "Antique Woodworking Tools\n\nAntique Woodworking Tools: Their Craftsmanship from Earliest Times to the Twentieth Century is David Russell's account of the history of woodworking tools illustrated profusely with items from his extensive collection of British, continental European and North American hand tools. \nPlanes are given special attention and British makers, among them Holtzapffel, Norris, Mathieson and Spiers, are discussed in depth.\n\nA wide array of edge and boring tools provides a broad survey of hand tool-making from prehistory to today. Writing in \"The Times\", Huon Mallalieu encapsulated the function of the book: \"Over the past 35 years [David Russell] has amassed probably the world’s largest collection of antique woodworking tools from the Stone Age to the 20th century ... The catalogue not only lists and lavishly illustrates 1556 items, but also makers’ stamps and associated material ...\"\n\nAfter looking at a range of tools from prehistory to the Romans, the book examines in detail more recent hand tools by function: from saws to drills and braces; from rules and gauges to bevels, squares and levels. Much of the book, however, is devoted to an extensive selection of wooden and metal planes and highlights their manifold functions. These planes are arranged within chapters on continental European, British and American models, with some of the great British makers from the eighteenth to the early twentieth century discussed in depth. A short chapter focuses on spurious and altered items, drawing the reader's attention to some of the pitfalls of collecting vintage tools.\n\nThe book has been widely acclaimed in both the general and specialized press. According to the \"Sheffield Telegraph\", \"the book not only celebrates the collection but is considered the most serious work of reference of its kind to date and destined to become a 'bible' in its field\".\nLooking at the book from another angle, Eve Kahn in the \"New York Times\" stated that the book was \"intended to glamorize unsung innovations\". Carl Duguay, writing in \"Canadian Woodworking & Home Improvement\", declared that the book was \"Lavish, stunning, outstanding, magnificent ... superlatives just don't do justice to [it].\"\n\nJournals of some of the leading tool societies have been generous in their praise. \"David Russell’s book is a vehicle for sharing his fabulous collection with the world,\" enthused John Wells in the \"Chronicle\", the journal of the Early American Industries Association. \"His unerring eye has sought out the most interesting tools available over the past 40 years, resulting in one of the world’s greatest collections of antique woodworking tools.\" The late Frank Ham, writing in the Australian journal \"Tool Chest\", declared the book to be \"the most impressive record of tools\" he had ever seen.\n\nFocusing on the illustrations, Mark Bridge commented in \"Antiques Trade Gazette\" on how James Austin, the book's photographer, had \"managed to capture the elusive qualities of balance, texture and patina which make the finest tools a pleasure to handle, frequently lifting them into the realm of folk art\".\n\n"}
{"id": "6076142", "url": "https://en.wikipedia.org/wiki?curid=6076142", "title": "Association for Software Testing", "text": "Association for Software Testing\n\nThe Association for Software Testing, commonly referred to as the AST, is dedicated to advancing the understanding of the science and practice of software testing according to context-driven principles. AST's membership consists of scholars, students and practitioners who are interested in the advancement of the field of software testing. The group was founded in the United States in 2004 by Cem Kaner. \n\nAST has multiple objectives including:\n\nThe AST's first conference, named \"CAST\" for the Conference of the Association for Software Testing, was held in Indianapolis, Indiana in 2006 and had the theme \"Influencing the Practice\".\n\n\nThe AST offers a series of online training courses in black box software testing (BBST), based on videos from Florida Institute of Technology's Center for Software Testing Education & Research (CSTER) with additional study aids and support from live instructors. \n\nThe initial set of courses enhances materials developed under a series of grants from the National Science Foundation. These materials are used in traditional university courses and in courses for practitioners, such as those offered by AST. The AST courses run 4 weeks each and focus on a single topic or test technique. AST is planning new courses by additional instructors.\n\n\n"}
{"id": "347002", "url": "https://en.wikipedia.org/wiki?curid=347002", "title": "Audio equipment", "text": "Audio equipment\n\nAudio equipment refers to devices that reproduce, record, or process sound. This includes microphones, radio receivers, AV receivers, CD players, tape recorders, amplifiers, mixing consoles, effects units, and loudspeakers.\n\n"}
{"id": "308137", "url": "https://en.wikipedia.org/wiki?curid=308137", "title": "Avionics software", "text": "Avionics software\n\nAvionics software is embedded software with legally mandated safety and reliability concerns used in avionics. The main difference between avionic software and conventional embedded software is that the development process is \"required by law\" and is \"optimized for safety.\"\nIt is claimed that the process described below is only slightly slower and more costly (perhaps 15 percent) than the normal \"ad hoc\" processes used for commercial software. Since most software fails because of mistakes, eliminating the mistakes at the earliest possible step is also a relatively inexpensive, and reliable way to produce software. In some projects however, mistakes in the specifications may not be detected until deployment. At that point, they can be very expensive to fix.\n\nThe basic idea of any software development model is that each step of the design process has outputs called \"deliverables.\" If the deliverables are tested for correctness and fixed, then normal human mistakes can not easily grow into dangerous or expensive problems. Most manufacturers follow the waterfall model to coordinate the design product, but almost all explicitly permit earlier work to be revised. The result is more often closer to a spiral model.\n\nFor an overview of embedded software see embedded system and software development models. The rest of this article assumes familiarity with that information, and discusses differences between commercial embedded systems and commercial development models.\n\nSince most avionics manufacturers see software as a way to add value without adding weight, the importance of embedded software in avionic systems is increasing.\n\nMost modern commercial aircraft with auto-pilots use flight computers and so called flight management systems(FMS) that can fly the aircraft without the pilot's active intervention during certain phases of flight. Also under development or in production are unmanned vehicles: missiles and drones which can take off, cruise and land without airborne pilot intervention.\n\nIn many of these systems, failure is unacceptable. The reliability of the software running in airborne vehicles (civil or military) is shown by the fact that most air borne accidents occur due to manual errors. Unfortunately reliable software is not necessarily easy to use or intuitive, poor user interface design has been a contributing cause of many aerospace accidents and deaths.\n\nDue to safety requirements, most nations regulate avionics, or at least adopt standards in use by a group of allies or a customs union. The three regulatory organizations that most affect international aviation development are the U.S, the E.U. and Russia.\n\nIn the U.S., avionic and other aircraft components have safety and reliability standards mandated by the Federal Aviation Regulations, Part 25 for Transport Airplanes, Part 23 for Small Airplanes, and Parts 27 and 29 for Rotorcraft. These standards are enforced by \"designated engineering representatives\" of the FAA who are usually paid by a manufacturer and certified by the FAA.\n\nIn the European Union the IEC describes \"recommended\" requirements for safety-critical systems, which are usually adopted without change by governments. A safe, reliable piece of avionics has a \"CE Mark.\" The regulatory arrangement is remarkably similar to fire safety in the U.S. and Canada. The government certifies testing laboratories, and the laboratories certify both manufactured items and organizations. Essentially, the oversight of the engineering is outsourced from the government and manufacturer to the testing laboratory.\n\nTo assure safety and reliability, national regulatory authorities (e.g. the FAA, CAA, or DOD) require software development standards. Some representative standards include MIL-STD-2167 for military systems, or RTCA DO-178B and its successor DO-178C for civil aircraft.\n\nThe regulatory requirements for this software can be expensive compared to other software, but they are usually the minimum that is required to produce the necessary safety.\n\nThe main difference between avionics software and other embedded systems is that the actual standards are often far more detailed and rigorous than commercial standards, usually described by documents with hundreds of pages. It is usually runs on a real time operating system.\n\nSince the process is legally required, most processes have documents or software to trace requirements from numbered paragraphs in the specifications and designs to exact pieces of code, with exact tests for each, and a box on the final certification checklist. This is specifically to prove conformance to the legally mandated standard.\n\nDeviations from a specific project to the processes described here can occur due to usage of alternative methods or low safety level requirements.\n\nAlmost all software development standards describe how to perform and improve specifications, designs, coding, and testing (See software development model). However avionics software development standards add some steps to the development for safety and certification:\n\nProjects with substantial human interfaces are usually prototyped or simulated. The videotape is usually retained, but the prototype retired immediately after testing, because otherwise senior management and customers can believe the system is complete. A major goal is to find human-interface issues that can affect safety and usability.\n\nSafety-critical avionics usually have a hazard analysis. The early stages of the project, already have at least a vague idea of the main parts of the project. An engineer then takes each block of a block diagram and considers the things that could go wrong with that block, and how they affect the system as a whole. Subsequently, the severity and probability of the hazards are estimated. The problems then become requirements that feed into the design's specifications.\n\nProjects involving military cryptographic security usually include a security analysis, using methods very like the hazard analysis.\n\nAs soon as the engineering specification is complete, writing the maintenance manual can start. A maintenance manual is essential to repairs, and of course, if the system can't be fixed, it will not be safe.\n\nThere are several levels to most standards. A low-safety product such as an in-flight entertainment unit (a flying TV) may escape with a schematic and procedures for installation and adjustment. A navigation system, autopilot or engine may have thousands of pages of procedures, inspections and rigging instructions. Documents are now (2003) routinely delivered on CD-ROM, in standard formats that include text and pictures.\n\nOne of the odder documentation requirements is that most commercial contracts require an assurance that system documentation will be available indefinitely. The normal commercial method of providing this assurance is to form and fund a small foundation or trust. The trust then maintains a mailbox and deposits copies (usually in ultrafiche) in a secure location, such as rented space in a university's library (managed as a special collection), or (more rarely now) buried in a cave or a desert location.\n\nThese are usually much like those in other software development models. A crucial difference is that requirements are usually traced as described above. In large projects, requirements-traceability is such a large expensive task that it requires large, expensive computer programs to manage it.\n\nThe code is written, then usually reviewed by a programmer (or group of programmers, usually independently) that did not write it originally (another legal requirement). Special organizations also usually conduct code reviews with a checklist of possible mistakes. When a new type of mistake is found it is added to the checklist, and fixed throughout the code.\n\nThe code is also often examined by special programs that analyze correctness (Static code analysis), such as SPARK examiner for the SPARK (a subset of the Ada programming language) or lint for the C-family of programming languages (primarily C, though).\nThe compilers or special checking programs like \"lint\" check to see if types of data are compatible with the operations on them, also such tools are regularly used to enforce strict usage of valid programming language subsets and programming styles.\nAnother set of programs measure software metrics, to look for parts of the code that are likely to have mistakes.\nAll the problems are fixed, or at least understood and double-checked.\n\nSome code, such as digital filters, graphical user interfaces and inertial navigation systems, are so well understood that software tools have been developed to write the software. In these cases, specifications are developed and reliable software is produced automatically.\n\n\"Unit test\" code is written to exercise every instruction of the code at least once to get 100% code coverage. A \"coverage\" tool is often used to verify that every instruction is executed, and then the test coverage is documented as well, for legal reasons.\n\nThis test is among the most powerful. It forces detailed review of the program logic, and detects most coding, compiler and some design errors. Some organizations write the unit tests \"before\" writing the code, using the software design as a module specification. The unit test code is executed, and all the problems are fixed.\n\nAs pieces of code become available, they are added to a skeleton of code, and tested in place to make sure each interface works. Usually the built-in-tests of the electronics should be finished first, to begin burn-in and radio emissions tests of the electronics.\n\nNext, the most valuable features of the software are integrated. It is very convenient for the integrators to have a way to run small selected pieces of code, perhaps from a simple menu system.\n\nSome program managers try to arrange this integration process so that after some minimal level of function is achieved, the system becomes deliverable at any following date, with increasing numbers of features as time passes.\n\nMeanwhile, the test engineers usually begin assembling a test rig, and releasing preliminary tests for use by the software engineers. At some point, the tests cover all of the functions of the engineering specification. At this point, testing of the entire avionic unit begins. The object of the acceptance testing is to prove that the unit is safe and reliable in operation.\n\nThe first test of the software, and one of the most difficult to meet in a tight schedule, is a realistic test of the unit's radio emissions. This usually must be started early in the project to assure that there is time to make any necessary changes to the design of the electronics.\nThe software is also subjected to a structural coverage analysis, where test's are run and code coverage is collected and analysed.\n\nEach step produces a deliverable, either a document, code, or a test report. When the software passes all of its tests (or enough to be sold safely), these are bound into a certification report, that can literally have thousands of pages. The designated engineering representative, who has been striving for completion, then decides if the result is acceptable. If it is, he signs it, and the avionic software is certified.\n\n\n"}
{"id": "1040310", "url": "https://en.wikipedia.org/wiki?curid=1040310", "title": "Bill Inmon", "text": "Bill Inmon\n\nWilliam H. (Bill) Inmon (born 1945) is an American computer scientist, recognized by many as the father of the data warehouse. Inmon wrote the first book, held the first conference (with Arnie Barnett), wrote the first column in a magazine and was the first to offer classes in data warehousing. Inmon created the accepted definition of what a data warehouse is - a subject oriented, nonvolatile, integrated, time variant collection of data in support of management's decisions. Compared with the approach of the other pioneering architect of data warehousing, Ralph Kimball, Inmon's approach is often characterized as a top-down approach.\n\nWilliam H. Inmon was born July 20, 1945 in San Diego, California. He received his Bachelor of Science degree in mathematics from Yale University, and his Master of Science degree in computer science from New Mexico State University.\n\nHe worked for American Management Systems and Coopers & Lybrand before 1991, when he founded the company Prism Solutions, which he took public. In 1995 he founded Pine Cone Systems, which was renamed Ambeo later on. In 1999, he created a corporate information factory web site for his consulting business. \n\nInmon coined terms such as the government information factory, as well as data warehousing 2.0. Inmon promotes building, usage, and maintenance of data warehouses and related topics. His books include \"Building the Data Warehouse\" (1992, with later editions) and \"DW 2.0: The Architecture for the Next Generation of Data Warehousing\" (2008).\n\nIn July 2007, Inmon was named by Computerworld as one of the ten people that most influenced the first 40 years of the computer industry.\n\nInmon's association with data warehousing stems from the fact that he wrote the first book on data warehousing he held the first conference on data warehousing (with Arnie Barnett), he wrote the first column in a magazine on data warehousing, he has written over 1,000 articles on data warehousing in journals and newsletters, he created the first fold out wall chart for data warehousing and he conducted the first classes on data warehousing. \n\nIn 2012, Inmon developed and made public technology known as \"textual disambiguation\". Textual disambiguation applies context to raw text and reformats the raw text and context into a standard data base format. Once raw text is passed through textual disambiguation, it can easily and efficiently be accessed and analyzed by standard business intelligence technology. Textual disambiguation is accomplished through the execution of textual ETL.\n\nIn 2017, KDNuggets, a leading Data Science platform, published his article on \"Hearing the Voices of your Customer\". He was also interviewed in \"Data Podcast\" by Rajib Bahar, & Shabnam Khan about his latest work and how Big Data fits in the world of Data-warehousing.\n\nInmon published more than 55 books and 2,000 articles on data warehousing and data management. A selection:\n\n"}
{"id": "50864475", "url": "https://en.wikipedia.org/wiki?curid=50864475", "title": "Billingham Bags", "text": "Billingham Bags\n\nBillingham Bags (M Billingham & Co Ltd) is a British brand of professional bags and vests for carrying cameras, lenses, laptops and photography accessories. The company's headquarters are in Cradley Heath, England.\n\nBillingham Bags (M Billingham & Co Ltd) was founded in 1973 by Martin Billingham, and is still owned and run by the Billingham family. Originally a manufacturer of fishing bags, in 1978 Billingham discovered that a large number of their bags were being sold to a photographer in New York City. Within a year production had switched almost entirely to specialist camera bags. Billingham Bags have worldwide distribution and are still hand made in Cradley Heath, England. Billingham bags are notable for their process of bonding the fabric of the bag to butyl rubber for water resistance. Billingham have had partnerships with well known camera manufacturers Leica and Hasselblad, making custom camera bags for both companies. They have also had a number of collaborations with British fashion and design house Pedlars. The company celebrated its 40th anniversary in 2013.\n\nWhile Billingham produce rucksacks, vests and laptop/tablet accessories, they are most widely known for their range of shoulder bags which they have been producing for photographers since 1978. The bags are well regarded by professional photographers, photojournalists and travel writers due to their traditional construction of canvas and leather, although some also use synthetic materials. Users of Billingham bags include television presenters Richard Hammond, who described his as 'a sort of comfort blanket', and Matt James.\n\n"}
{"id": "39836304", "url": "https://en.wikipedia.org/wiki?curid=39836304", "title": "Bitmessage", "text": "Bitmessage\n\nBitmessage is a decentralized, encrypted, peer-to-peer, trustless communications protocol that can be used by one person to send encrypted messages to another person, or to multiple subscribers. Bitmessage encrypts each user's message inbox using public-key cryptography and replicates it inside its P2P network, mixing it with inboxes of other users in order to conceal user's identity, prevent eavesdropping and allow the network to operate in a decentralized manner. The Bitmessage communications protocol avoids sender-spoofing through authentication, and hides metadata from wiretapping systems.\n\nIn June 2013, the software experienced a surge of new adoptions after news reports of email surveillance by the US National Security Agency.\n\n, the network processes several thousand private messages per day.\n\nPyBitmessage is the official instant messaging client designed for Bitmessage.\n\nBitpost is an alternate client for OSX users.\n\nA number of services provide email endpoints to the BitMessage network. Bitmessage.ch is a service that supports sending and receiving Bitmessages over the email protocol.\n\nA number of applications provide bridges between the PyBitmessage client and email applications via the IMAP/POP and SMTP protocols. BitMail is an application that bridges the IMAP, POP, and SMTP protocols.\n\nBitmessage works by encrypting all the incoming and outgoing messages using public-key cryptography so that only the receiver of the message is capable of decrypting it. In order to achieve anonymity:\n\n\nBitmessage can be accessed via Tor or via I2P\n\nStarting from version 0.3.5, Bitmessage introduced an additional feature called a \"chan\", a decentralized anonymous mailing list. Unlike traditional mailing lists used via email:\n\nA number of publicly known chans currently exists dedicated to the topics ranging from online privacy to politics to chess games.\n\nThe concept for Bitmessage was conceived by software developer Jonathan Warren, who based its design on the decentralized digital currency, bitcoin. The software was released in November 2012 under the MIT license.\n\nThe source code is written in Python and uses the Qt cross-platform application framework as well as OpenSSL for cryptographic functions. It is available for Microsoft Windows, macOS, and Linux.\n\nBitmessage has gained a reputation for being out of reach of warrantless wiretapping conducted by the National Security Agency (NSA) due to the decentralized nature of the protocol, and its encryption being difficult to crack. As a result, downloads of the Bitmessage program increased fivefold during June 2013 after news broke of classified email surveillance activities conducted by the NSA.\n\nBitmessage has also been mentioned as an experimental alternative to email by \"Popular Science\" and CNET.\n\nSome ransomware programs instruct affected users to use Bitmessage to communicate with the attackers.\n\nBitMessage's security has not been independently audited. The official Bitmessage website states: \"Bitmessage is in need of an independent audit to verify its security. If you are a researcher capable of reviewing the source code, please email the lead developer...\"\n\n\n\n"}
{"id": "1645689", "url": "https://en.wikipedia.org/wiki?curid=1645689", "title": "Cinema Products Corporation", "text": "Cinema Products Corporation\n\nCinema Products Corporation was an American manufacturer of motion picture camera equipment.\n\nThe company was formed in 1968 by Ed DiGiulio, a former director and vice-president of the Mitchell Camera Corporation. Their first product was a Silent Pellicle Reflex conversion of the Mitchell BNC 35 mm Motion picture camera.\n\nThe company expanded into the 16-millimeter news camera market with the introduction of the CP-16.\n\nIn the 50th Academy Awards, Garrett Brown and the Cinema Products Corporation Engineering Staff under the supervision of John Jurgens received a Scientific or Technical Award, Class I for the invention and development of the Steadicam.\n\nIn motion picture equipment, the Mitchell BNC conversion to reflex was followed by the studio quiet XR35. The Cinema Products XR35 had a Mitchell NC camera inside a lightweight housing or blimp. The blimp was so close in size to the original camera, it looked small compared to the blimps made for Mitchell or Arriflex cameras. The XR35 was a crystal-controlled 35mm motion picture camera considerably lighter than the Hollywood studio–owned blimped Mitchells. The X stood for crystal, the R for reflex. The reflex system was based on a spinning mirror shutter. During the mirrors' revolution at one point the film would be exposed, then the operator would view the image in the mirror as the film was advanced to the next frame, at 24 times a second. Cinema Products did their best to buy up all available 35mm Mitchell NC cameras on the market as the XR went into production. Later, Cinema Products sold their remaining Mitchell inventory to a Japanese company when the XR35 was challenged by competitors but still selling well.\n\nIn 1972 Panavision and Arriflex came to market with their lighter-weight 35mm cameras. Panavision's Panaflex and the German Arriflex 35BL-I. These cameras were not blimped in the sense they had a camera in a housing; these cameras were designed from the ground up to be quiet. \n\nThe light and ergonomic Arri 35BL-I gave European film makers (and eventually the American \"Brats\"), the ability to shoot studio-quality (double system) sync sound movies, but faster, on real locations – and even handheld – and with smaller crews and support equipment. (Due to the limited resources of the 1940s and 1950s the Italian Neo realists and French New Wave had evolved around the approach of shooting wild synch or \"Noisy-synch\" and then completely post-replacing all sound and dialog.) In America, The Panaflex became the industry standard motion picture camera, displacing the Mitchell legacy.\nThe studio quiet 16mm Cinema Products GSMO was introduced in the mid-1970s. It had quick loading coaxial magazines, an 'in camera' light meter viewable in the eyepiece and an on-camera battery. The GSMO stood for \"gun sight man operated\". (Cinema Products would often develop products under government contracts, then adapt them for industry wide marketing.)\n\nThe GSMO was popular among documentarians and low-budget independent producers. Jon Jost produced feature films shot with the GSMO. The PBS documentary film Post No Bills was also shot by Clay Walker using Jost's GSMO camera.\n\nThe GSMO had crystal speeds of 12, 16, 24, 25, 32, 48, 64 FPS. Besides the standard 400-foot magazine, the GSMO offered a novel and rare 100-foot magazine. The 100-foot mag was the height of the camera, so the camera with mag would be only 5 inches tall. The GSMO did not have video assist, a way of viewing what the cameraman was seeing on a video screen. TV commercial producers and directors wanted video assist, and the GSMO fell behind the competition in that feature. (After-market video assist is now available for the GSMO).\n\nDuring pre-production for the 1975 film \"Barry Lyndon\", director-producer Stanley Kubrick had a requirement for a large aperture \"high speed\" cine lens to facilitate shooting scenes by candlelight. At the time, the largest aperture \"fastest\" cine lenses available for reflex 35mm cine cameras had a f1.4 aperture. High Speed (also called \"Super Speed\") f1.2 prime lenses were not available at the time.\n\nKubrick sourced a Carl Zeiss Planar f0.7/50mm lens, an aperture two f-stops larger than f1.4. This was a still camera lens originally developed by Carl Zeiss for NASA's Apollo program. Ed DiGulio reluctantly agreed to take on the very difficult process of adapting this lens to a cine camera, which required modifying the lens and permanently modifying a Mitchell BNC camera to work with this lens. \nDirector of photography John Alcott was honored at the 48th Academy Awards with the Best Cinematography award for his work on Barry Lyndon. One of the modified Mitchell BNC cameras, and two of the modified f0.7 lenses are on display with the Stanley Kubrick Exhibition.\nIn the early 1980s, Cinema Products introduced the CP35, a nonquiet 35mm camera. With a BNCR lens mount, it was to partner with the studio quiet XR35 that had the same BNCR mount. The CP35 had video assist, but it was not as integrally designed as the competition's. The CP35 had multiple crystal speeds like the GSMO ranging from 6 to 120FPS.\n\nThe FX35 was introduced in 1987. It had a wider body but resembled the CP35. They shared magazines. The FX35 had integral video assist. It used the PL lens mount Arriflex had introduced. The camera's electronics were cutting edge for the day with special effects and motion control underlining the electronics design. From the switch-mode power supply to the 36-pin computer interface, the FX35 offered features unavailable on cameras at that time. The speeds were thumb-wheel selected in .01 increments. A CRT computer monitor with 72.06 hertz could be filmed with no roll bar, the black bar visible when a 24 or 25 FPS camera records a TV or computer monitor due to the difference in refresh rates. The FX35 was originally designed for a motion picture and video camera rental company in Great Britain. The production rights and remaining inventory of the CP35 and FX35 were sold to Redicam in 1992.\n\nIn its last years, Cinema Products was still innovative. A film to HD video transfer machine was introduced, novel in that the HD camera was not part of the transfer machine but mounted on it. An upgrade would be easy, just change the HD camera, the film transport deck stayed the same. A fiber optic–based 35 mm ground glass to video chip reducer was patented and sold to a competitor. A consumer-oriented Steadicam unit designed for small mini DV cameras was added to the Steadicam line. The Steadicam Jr. incorporated an 8-layer non-glare LCD video monitor comparable to the professional Steadicam rigs. The Steadicam line became the company's leading marketable product. Tiffen Filter bought the rights to make the Steadicam when Cinema Products Corporation went out of business in 2000.\n"}
{"id": "794226", "url": "https://en.wikipedia.org/wiki?curid=794226", "title": "Coalbed methane", "text": "Coalbed methane\n\nCoalbed methane (CBM or coal-bed methane), coalbed gas, coal seam gas (CSG), or coal-mine methane (CMM) is a form of natural gas extracted from coal beds. In recent decades it has become an important source of energy in United States, Canada, Australia, and other countries.\n\nThe term refers to methane adsorbed into the solid matrix of the coal. It is called 'sweet gas' because of its lack of hydrogen sulfide. The presence of this gas is well known from its occurrence in underground coal mining, where it presents a serious safety risk. Coalbed methane is distinct from a typical sandstone or other conventional gas reservoir, as the methane is stored within the coal by a process called adsorption. The methane is in a near-liquid state, lining the inside of pores within the coal (called the matrix). The open fractures in the coal (called the cleats) can also contain free gas or can be saturated with water.\n\nUnlike much natural gas from conventional reservoirs, coalbed methane contains very little heavier hydrocarbons such as propane or butane, and no natural-gas condensate. It often contains up to a few percent carbon dioxide.\n\nCoalbed methane grew out of venting methane from coal seams. Some coal beds have long been known to be \"gassy,\" and as a safety measure, boreholes were drilled into the seams from the surface, and the methane allowed to vent before mining.\n\nCoalbed methane as a natural-gas resource received a major push from the US federal government in the late 1970s. Federal price controls were discouraging natural gas drilling by keeping natural gas prices below market levels; at the same time, the government wanted to encourage more gas production. The US Department of Energy funded research into a number of unconventional gas sources, including coalbed methane. Coalbed methane was exempted from federal price controls, and was also given a federal tax credit.\n\nIn Australia, commercial extraction of coal seam gas began in 1996 in the Bowen Basin of Queensland.\n\nGas contained in coal bed methane is mainly methane and trace quantities of ethane, nitrogen, carbon dioxide and few other gases. Intrinsic properties of coal as found in nature determine the amount of gas that can be recovered.\n\nCoalbed methane reservoirs are considered as a dual-porosity reservoirs. Dual porosity reservoirs are reservoirs in which porosity related to cleats (natural fractures) are responsible for flow behavior and reservoir porosity of the matrix is responsible for the storage of gas. The porosity of a coalbed methane reservoir can vary from 10%-20 %; However, the cleat porosity of the reservoir is estimated to be in the range of 0.1%-1 % \n\nAdsorption capacity of coal is defined as the volume of gas adsorbed per unit mass of coal usually expressed in SCF (\"standard cubic feet\", the volume at standard pressure and temperature conditions) gas/ton of coal. The capacity to adsorb depends on the rank and quality of coal. The range is usually between 100 and 800 SCF/ton for most coal seams found in the US. Most of the gas in coal beds is in the adsorbed form. When the reservoir is put into production, water in the fracture spaces is pumped off first. This leads to a reduction of pressure enhancing desorption of gas from the matrix.\n\nAs discussed before, the fracture permeability acts as the major channel for the gas to flow. The higher the permeability, the higher the gas production. For most coal seams found in the US, the permeability lies in the range of 0.1–50 milliDarcys. The permeability of fractured reservoirs changes with the stress applied to them. Coal displays a stress-sensitive permeability and this process plays an important role during stimulation and production operations. Fracture permeability in Coalbed methane reservoir tends to increase with depletion of gas; in contrast to conventional reservoirs. This unique behavior is because of shrinking of coal, when methane is released from its matrix, which results in opening up of fractures and increased permeability. It is also believed that due to shrinkage of coal matrix at lower reservoir pressures, there is a loss of horizontal stress in the reservoir which induces in-situ failure of coal. Such a failure has been attributed to sudden decrease in the fracture permeability of the reservoir\n\nThe thickness of the formation may not be directly proportional to the volume of gas produced in some areas.\n\nFor example, it has been observed in the Cherokee Basin in Southeast Kansas that a well with a single zone of of pay can produce excellent gas rates, whereas an alternative formation with twice the thickness can produce next to nothing. Some coal (and shale) formations may have high gas concentrations regardless of the formation's thickness, probably due to other factors of the area's geology.\n\nThe pressure difference between the well block and the sand face should be as high as possible as is the case with any producing reservoir in general.\n\nOther affecting parameters include coal density, initial gas-phase concentration, critical gas saturation, irreducible water saturation, relative permeability to water and gas at conditions of Sw = 1.0 and Sg = 1-Swirreducible respectively.\n\nTo extract the gas, a steel-encased hole is drilled into the coal seam below ground. As the pressure within the coal seam declines due to natural production or the pumping of water from the coalbed, both gas and \"produced water\" come to the surface through tubing. Then the gas is sent to a compressor station and into natural gas pipelines. The produced water is either reinjected into isolated formations, released into streams, used for irrigation, or sent to evaporation ponds. The water typically contains dissolved solids such as sodium bicarbonate and chloride but varies depending on the formation geology.\n\nCoalbed methane wells often produce at lower gas rates than conventional reservoirs, typically peaking at near per day (about 0.100 m³/s), and can have large initial costs. The production profiles of CBM wells are typically characterized by a \"negative decline\" in which the gas production rate initially increases as the water is pumped off and gas begins to desorb and flow. A dry CBM well is similar to a standard gas well.\n\nThe methane desorption process follows a curve (of gas content vs. reservoir pressure) called a Langmuir isotherm. The isotherm can be analytically described by a maximum gas content (at infinite pressure), and the pressure at which half that gas exists within the coal. These parameters (called the Langmuir volume and Langmuir pressure, respectively) are properties of the coal, and vary widely. A coal in Alabama and a coal in Colorado may have radically different Langmuir parameters, despite otherwise similar coal properties.\n\nAs production occurs from a coal reservoir, the changes in pressure are believed to cause changes in the porosity and permeability of the coal. This is commonly known as matrix shrinkage/swelling. As the gas is desorbed, the pressure exerted by the gas inside the pores decreases, causing them to shrink in size and restricting gas flow through the coal. As the pores shrink, the overall matrix shrinks as well, which may eventually increase the space the gas can travel through (the cleats), increasing gas flow.\n\nThe potential of a particular coalbed as a CBM source depends on the following criteria. Cleat density/intensity: cleats are joints confined within coal sheets. They impart permeability to the coal seam. A high cleat density is required for profitable exploitation of CBM. Also important is the maceral composition: maceral is a microscopic, homogeneous, petrographic entity of a corresponding sedimentary rock. A high vitrinite composition is ideal for CBM extraction, while inertinite hampers the same.\n\nThe rank of coal has also been linked to CBM content: a vitrinite reflectance of 0.8–1.5% has been found to imply higher productivity of the coalbed.\n\nThe gas composition must be considered, because natural gas appliances are designed for gas with a heating value of about 1,000 BTU (British thermal units) per cubic foot, or nearly pure methane. If the gas contains more than a few percent non-flammable gases such as nitrogen or carbon dioxide, either these will have to be removed or it will have to be blended with higher-BTU gas to achieve \"pipeline quality\". If the methane composition of the coalbed gas is less than 92%, it may not be commercially marketable.\n\nAs with all carbon based fossil fuels, burning coalbed methane releases carbon dioxide (CO) into the atmosphere. Its effect as greenhouse gas was firstly analyzed by chemist and physicist Svante Arrhenius. CBM production also entails leaks of fugitive methane into the atmosphere. Methane is rated as having 72 times the effect on global warming per unit of mass than CO over 20 years, reducing to 25 times over 100 years and 7.5 times over 500 years. Analysis of life-cycle greenhouse gas emissions of energy sources indicates that generating electricity from CBM, as with conventional natural gas, has less than half the greenhouse gas effect of coal.\n\nIn the United States, methane escaping from coal during mining amounts to 10 percent of total methane emissions. Recovery of coal mine methane in advance of mining is seen as a major opportunity to reduce methane emissions. \n\nCBM wells are connected by a network of roads, pipelines, and compressor stations. Over time, wells may be spaced more closely in order to extract the remaining methane.\n\nThe produced water brought to the surface as a byproduct of gas extraction varies greatly in quality from area to area, but may contain undesirable concentrations of dissolved substances such as salts, naturally present chemicals, heavy metals and radionuclides. In many producing regions the water is treated, such as through a Reverse Osmosis plant and used beneficially for irrigation, water for livestock, urban and industrial uses, or dust suppression.\n\nIn 2012 Eastern Star Gas was fined for \"discharging polluting water containing high levels of salt into Bohena Creek\" in the Pilliga Scrub. There were \"16 spills or leaks of contaminated water\" including \"serious spills of saline water into woodland and a creek.\" In 2012, a NSW Legislative Council inquiry criticised the use of open holding ponds, recommending that \"the NSW Government ban the open storage of produced water.\"\n\nNot all coalbed methane produced water is saline or otherwise undesirable. Water from coalbed methane wells in the Powder River Basin of Wyoming, US, commonly meets federal drinking water standards, and is widely used in the area to water livestock. Its use for irrigation is limited by its relatively high sodium adsorption ratio.\n\nDepending on aquifer connectivity, water withdrawal may depress aquifers over a large area and affect groundwater flows. In Australia, the CBM industry estimates extraction of to of groundwater per year; while the National Water Commission estimates extraction above a year.\n\nCoal Seam Gas resources are in the major coal basins in Queensland and New South Wales, with further potential resources in South Australia. Commercial recovery of coal seam gas (CSG) began in Australia in 1996. As of 2014, coal seam gas, from Queensland and New South Wales, made up about ten percent of Australia's gas production. Demonstrated reserves were estimated to be 33 trillion cubic feet (35 905 petajoules) as of January 2014.\n\n\nIn Canada, British Columbia is estimated to have approximately of coalbed gas. Alberta, in 2013, was the only province with commercial coalbed methane wells and is estimated to have approximately of economically recoverable coalbed methane, with overall reserves totaling up to .\n\nCoalbed methane is considered a non-renewable resource, although the Alberta Research Council, Alberta Geological Survey and others have argued coalbed methane is a renewable resource because the bacterial action that formed the methane is ongoing. This is subject to debate since it has also been shown that the dewatering that accompanies CBM production destroys the conditions needed for the bacteria to produce methane and the rate of formation of additional methane is undetermined. This debate is currently causing a right of ownership issue in the Canadian province of Alberta, as only non-renewable resources can legally be owned by the province.\n\n\nAlthough gas in place in Britain's coal fields has been estimated to be 2,900 billion cubic meters, it may be that as little as one percent might be economically recoverable. Britain's CBM potential is largely untested. Some methane is extracted by coal mine venting operations, and burned to generate electricity. Assessment by private industry of coalbed methane wells independent of mining began in 2008, when 55 onshore exploration licences were issued, covering 7,000 square kilometers of potential coalbed methane areas. IGas Energy became the first in the UK to commercially extract coalbed methane separate from mine venting; as of 2012, the Igas coalbed methane wells at Doe Green, extracting gas for electrical generation, were the only commercial CBM wells in the UK.\n\nUnited States coalbed methane production in 2011 was 1.76 trillion cubic feet (TCF), 7.3 percent of all US dry gas production that year. The 2011 production was down from the peak of 1.97 TCF in 2008. Most CBM production came from the Rocky Mountain states of Colorado, Wyoming, and New Mexico.\n\nKazakhstan could witness the development of a large coalbed methane (CBM) sector over the coming decades, according to industry professionals. Preliminary research suggests there may be as much as 900 billion m3 of gas in Kazakhstan’s main coalfields – 85% of all reserves in Kazakhstan.\n\nWith the completion of the drilling of 23 vertical production wells by Great Eastern Energy (GEECL), coalbed methane would be available in India for commercial sale purpose from 14 July 2007 priced at ₹ 30 per kg for CNG. Initially 90% of the CBM would be distributed among vehicles as CNG gas.\nGEECL is also setting up the first CBM station in Southeast Asia and the same will be located in India in the city of Asansol in West Bengal. GEECL is the first company whose first field development plan has been approved.Essar is also producing and investing in CBM.\n\nPrashant Modi, President and Chief Operating Officer of GEECL, said, \"We are proud to be India’s first private sector company that has ventured into Coal Bed Methane exploration, production, marketing and distribution. With the nation requiring higher energy sources to sustain its development pace, we are confident that CBM will play an important role as one of the prime energy source for the future generations.\"\n\n"}
{"id": "56416139", "url": "https://en.wikipedia.org/wiki?curid=56416139", "title": "Cogital", "text": "Cogital\n\nCogital Group is a British multinational accounting and business services company.\n\nCogital Group is headquartered at 2 Babmaes Street, St James's, London SW1.\n\nIt was founded in August 2016 by John Connolly, the former senior partner and chief executive of Deloitte in the UK until his retirement in June 2011, with the financial backing of the private equity firm Hg Capital.\n\nCogital has made over 20 acquisitions, and as of October 2017 has 58,000 clients, with 4,600 staff in 137 offices in seven countries. Subsidiaries include Campbell Dallas in Scotland, Azets, Baldwins and Blick Rothenberg.\n\nIn July 2018 Cogital announced the acquisition of UK top 20 firm Wilkins Kennedy LLP.\n"}
{"id": "6159218", "url": "https://en.wikipedia.org/wiki?curid=6159218", "title": "Conversion rate optimization", "text": "Conversion rate optimization\n\nIn internet marketing, conversion optimization, or conversion rate optimization (CRO) is a system for increasing the percentage of visitors to a website that convert into customers, or more generally, take any desired action on a webpage. It is commonly referred to as CRO.\n\nOnline conversion rate optimization (or website optimization) was born out of the need of e-commerce marketers to improve their website's performance in the aftermath of the dot-com bubble. As competition grew on the web during the early 2000s, website analysis tools and an awareness of website usability prompted internet marketers to produce measurables for their tactics and improve their website's user experience. \n\nIn 2004, new tools enabled internet marketers to experiment with website design and content variations to determine which layouts, copy text, offers, and images perform best. This form of optimization accelerated in 2007 with the introduction of the free Google Website Optimizer. Today optimization and conversion are key aspects of many digital marketing campaigns. A research study conducted among internet marketers in 2014, for example, showed that 59% of respondents thought that CRO was \"crucial to their overall digital marketing strategy\".\n\nConversion rate optimization shares many principles with direct response marketing – a marketing approach that emphasizes tracking, testing, and on-going improvement. Direct marketing was popularized in the early twentieth century and supported by the formation of industry groups such as the Direct Marketing Association, which formed in 1917.\n\nLike modern day conversion rate optimization, direct response marketers also practice A/B split-testing, response tracking, and audience testing to optimize mail, radio, and print campaigns.\n\nFrequently, when marketers study a lift in an ad campaign, they discover customer behavior is not consistent. Online marketing response rates fluctuate widely from hour to hour, segment to segment, and offer to offer .\n\nThis phenomenon can be traced to the difficulty humans have separating chance events from real effects. Using the haystack process, at any given time, marketers are limited to examining and drawing conclusions from small data samples. However, psychologists (led by Daniel Kahneman and Amos Tversky) have documented tendencies to find spurious patterns in small samples to explain why poor decisions are made. Statistical methodologies can be leveraged to study large samples, mitigating the urge to see patterns where none exist.\n\nThese methodologies, or \"conversion optimization\" methods, are then taken a step further to run in a real-time environment. The real-time data collection and subsequent messaging increases the scale and effectiveness of the online campaign.\n\nReaching a statistically significant result in itself is not enough. Conversion optimization practitioners must ensure that their sample size accounts for important variables. For example, a test may appear statistically significant well before seasonal factors (time of day, day of week, time of year) have been adequately reflected in the data sample. One variation may appeal to one season more than others and ultimately misguide the result.\n\nIt is equally important to understand how various segments affect tests and results. Different user segments (e.g. device type, location, new vs. returning visitor) will respond differently to each variation.. Analyzing results without accounting for different segments can cause a significant improvement for one segment; or many variations can offset poor results for another segment. For example, uplift in desktop conversion-rate could offset a decreased conversion-rate on mobile devices. In this instance, only the desktop version should be declared a ‘winning’ test.\n\nConversion rate optimization seeks to increase the percentage of website visitors that take a specific action (often submitting a web form, making a purchase, signing up for a trial, etc.) by methodically testing alternate versions of a page or process. In doing so, businesses are able to generate more leads or sales without investing more money on website traffic, hence increasing their marketing return on investment and overall profitability.\n\nA conversion rate is defined as the percentage of visitors who complete a goal, as set by the site owner. Some test methods, such as split testing or A/B testing, enable one to monitor which headlines, copy, images, social proof elements, and content help convert visitors into customers.\n\nThere are several approaches to conversion optimization with two main schools of thought prevailing in the last few years. One school is more focused on testing to discover the best way to increase website, campaign, or landing page conversion rates. The other school is focused on the pretesting stage of the optimization process. In this second approach, the optimization company will invest a considerable amount of time understanding the audience and then creating a targeted message that appeals to that particular audience. Only then would it be willing to deploy testing mechanisms to increase conversion rates.\n\nConversion optimization platforms for content, campaigns, and delivery consist of the following elements:\n\nThe platform must process hundreds of variables and automatically discover which subsets have the greatest predictive power, including any multivariate relationship. A combination of pre- and post-screening methods is employed, dropping irrelevant or redundant data as appropriate. A flexible data warehouse environment accepts customer data as well as data aggregated by third parties.\n\nThis means it's essential to ensure the data is as 'clean' as possible, before undertaking any data analysis. For example, eliminating activity from bots, staging websites, or incorrect configurations of tools such as Google Analytics.\n\nData can be numeric or text-based, nominal or ordinal. Bad or missing values are handled gracefully.\n\nData may be geographic, contextual, frequential, demographic, behavioral, customer based, etc.\n\nAfter data collection, forming a hypothesis is the next step. This process forms the foundation of why changes are made. Hypotheses are made based on observation and deduction. It is important that each hypothetical situation be measurable. Without these no conclusions can be derived.\n\nThe official definition of \"optimization\" is the discipline of applying advanced analytical methods to make better decisions. Under this framework, business goals are explicitly defined and then decisions are calibrated to optimize those goals. The methodologies have a long record of success in a wide variety of industries, such as airline scheduling, supply chain management, financial planning, military logistics and telecommunications routing. Goals should include maximization of conversions, revenues, profits, LTV or any combination thereof.\n\nArbitrary business rules must be handled under one optimization framework. Using such a platform entails that one should understand these and other business rules, then adapt targeting rules accordingly.\n\nOnce mathematical models have been built, ad/content servers use an audience screen method to place visitors into segments and select the best offers, in real time. Business goals are optimized while business rules are enforced simultaneously. Mathematical models can be refreshed at any time to reflect changes in business goals or rules.\n\nEnsuring results are repeatable by employing a wide array of statistical methodologies. Variable selection, validation testing, simulation, control groups and other techniques together help to distinguish true effects from chance events. A champion/challenger framework ensures that the best mathematical models are deployed always. In addition, performance is enhanced by the ability to analyze huge datasets and to retain historical learning.\n\n"}
{"id": "28132162", "url": "https://en.wikipedia.org/wiki?curid=28132162", "title": "Dicing tape", "text": "Dicing tape\n\nDicing tape is a backing tape used during wafer dicing, the cutting apart of pieces of semiconductor material following wafer microfabrication. The tape holds the pieces of semiconductor, known as dice, together during the cutting process, mounting them to a thin metal frame. The dice are removed from the dicing tape later on in the electronics manufacturing process.\n\nDicing tape can be made of PVC, polyolefin, or polyethylene backing material with an adhesive to hold the dice in place. In some cases dicing tape will have a release liner that will be removed prior to mounting the tape to the backside of the wafer. It is available in a variety of thicknesses, from 75 to 150 micrometers, with a variety of adhesive strengths, designed for various chip sizes and materials. UV tapes are dicing tapes in which the adhesive bond is broken by exposure to UV light after dicing, allowing the adhesive to be stronger during cutting while still allowing clean and easy removal. UV equipment can range from low power (a few mW/cm2) to high power (more than 200 mW/cm2). Higher power results in a more complete cure, lower adhesion and reduced adhesive residue. .\n"}
{"id": "31417867", "url": "https://en.wikipedia.org/wiki?curid=31417867", "title": "Dimefox", "text": "Dimefox\n\nDimefox was an organophosphate pesticide. In its pure form it is a colourless liquid with a fishy odour. Dimefox was first produced in 1940 by the group of Gerhard Schrader in Germany. It was historically used as a pesticide, but has been deemed obsolete or discontinued for use by the World Health Organization. However, they do not guarantee that all commercial use of this compound ceased. But in most countries it is no longer registered for use as a pesticide. It is considered an extremely hazardous substance as defined by the United States Emergency Planning and Community Right-to-Know Act.\n"}
{"id": "13013549", "url": "https://en.wikipedia.org/wiki?curid=13013549", "title": "Esko (company)", "text": "Esko (company)\n\nEsko, formerly called \"EskoArtwork\", is a graphic arts company producing prepress software and hardware for the packaging and labels, sign and display and publishing industries. \n\nEsko was the result of a merger between \"Barco Graphics\" and \"Purup-Eskofot A/S\" in 2001. The merged company was called Esko-Graphics but was renamed Esko in 2006. In the fall of 2005, Esko became fully owned by Axcel A/S, a Danish private equity investment company.\n\nIn August 2007 Esko announced that it was 'joining forces' with Artwork Systems Group NV (AWS), its chief competitor in the packaging prepress market. Esko initially bought 76.69% of AWS shares for €196 million. Enfocus, a brand of PDF pre-flighting and workflow software originally acquired by Artwork Systems in 2000, became a subsidiary of the combined EskoArtwork company.\n\nReflecting the merger, Esko changed its name to EskoArtwork. It also introduced a new logo, though it is visually very close to the Esko original.\n\nIn January 2011, 100% of EskoArtwork shares have been transferred to Danaher. In January 2012, the name changed back to Esko, the logo was also updated. Esko acquired CAPE Systems (a palletization software vendor) in 2013, MediaBeacon (a Digital Asset Management vendor) in 2015 and Blue Software, LLC (a label and artwork management software vendor) in 2018.\n\nEsko is headquartered in Ghent, Belgium.\n"}
{"id": "53365733", "url": "https://en.wikipedia.org/wiki?curid=53365733", "title": "Femtech", "text": "Femtech\n\nFemtech (or Female technology) is a term applied to a category of software, diagnostics, products, and services that use technology often to focus on women's health. This sector includes fertility solutions, period-tracking apps, pregnancy and nursing care, women’s sexual wellness, and reproductive system health care. \n\nFemtech was coined by Ida Tin, a Danish entrepreneur who founded Clue, a period- and fertility-tracking app. As an industry, femtech largely encompasses any digital or standard health tools aimed at women's health, including wearables, internet-connected medical devices, mobile apps, hygiene products, and others. The concept of a digital women's health category is relatively new. In 2015, Femtech startups raised around $82 million in funding from investment firms. In March 2017, the total amount of funding raised by femtech companies since 2014 had reached $1.1 billion. In March 2018, Frost & Sullivan released new data, predicting a market potential of $50 billion by 2025 Estimates suggest that around $200 billion is being spent on femtech products each year.\n\nThere are numerous femtech companies offering a variety of different products throughout the world. Companies that produce period- and/or fertility-tracking mobile apps include, Clue, Glow, Eve, Cycles, My Calendar, Life, FertilityIQ, Extend Fertility, Forte Medical and others. Companies that offer services like IVF, egg freezing, and medical treatments include Univfy, Progyny and Prelude Fertility. Similarly, the fertility company, Ava, produces a wearable that tracks fertility. By contrast, Nurx provides a telemedicine service where women can get birth control prescribed via an app, and have the pills delivered.\n\nSeveral companies also produce internet-connected medical devices that are often paired with mobile apps to track specific data. For instance, Naya Health produces a connected breast pump while Elvie offers a kegel tracking device. Lioness produces a smart vibrator. Other medical devices and implements produced in the femtech category may or may not use an internet connection. Joylux, Inc. is a global women’s health technology company creating innovative medical and feminine wellness devices under the vSculpt and vFit brands.Willow Pump produces a hands-free breast pump that works automatically. Companies like L. and Flex offer alternatives to standard tampon and condom products. Thinx sells reusable underwear that absorbs menstrual blood.\n"}
{"id": "4916318", "url": "https://en.wikipedia.org/wiki?curid=4916318", "title": "First Oil Well, Bahrain", "text": "First Oil Well, Bahrain\n\nAs its name suggests, it is the first oil well in the Arabian side of the Persian Gulf and is located in Bahrain. The well is situated below Jebel Dukhan. It was discovered and operated by Bahrain Petroleum Company (BAPCO), established in 1929 in Canada by Standard Oil Company of California. \n\nOil first spurted from this well on 16 October 1931, and the well finally began to blow heads of oil on the morning of 2 June 1932. The initial oil flow rate was ; by the 1970s the well produced , and after that it stabilized at about . In 1980, BAPCO was taken over by the Government of Bahrain. Close to the well, which has been reconstructed to its first appearance, is a stable.\n\nBahrain was the first place on the Arabian side of the Persian Gulf where oil was discovered, and it coincided with the collapse of the world pearl market.\n"}
{"id": "2397535", "url": "https://en.wikipedia.org/wiki?curid=2397535", "title": "Ghost Mine", "text": "Ghost Mine\n\nA ghost mine is a pyrotechnic device which projects a large, ethereal-looking colored fireball into the sky. The effect is produced by mixing methyl alcohol with a pyrotechnic colorant. Since alcohol burns with a nearly invisible flame, all that is seen by the audience is a cloud of glowing color (the colorant) taking the shape of the invisible fireball. It was invented by Chris Spurrell, a research chemist from Hawthorne, California.\n"}
{"id": "185490", "url": "https://en.wikipedia.org/wiki?curid=185490", "title": "Gottlieb Daimler", "text": "Gottlieb Daimler\n\nGottlieb Wilhelm Daimler (; 17 March 1834 – 6 March 1900) was an engineer, industrial designer and industrialist born in Schorndorf (Kingdom of Württemberg, a federal state of the German Confederation), in what is now Germany. He was a pioneer of internal-combustion engines and automobile development. He invented the high-speed liquid petroleum fueled engine.\n\nDaimler and his lifelong business partner Wilhelm Maybach were two inventors whose goal was to create small, high-speed engines to be mounted in any kind of locomotion device. In 1883 they designed a horizontal cylinder layout compressed charge liquid petroleum engine that fulfilled Daimler's desire for a high speed engine which could be throttled, making it useful in transportation applications. This engine was called Daimler's Dream.\n\nIn 1885 they designed a vertical cylinder version of this engine which they subsequently fitted to a two-wheeler, the first internal combustion motorcycle which was named the Petroleum Reitwagen (Riding Car) and, in the next year, to a coach, and a boat. Daimler called this engine the grandfather clock engine (\"Standuhr\") because of its resemblance to a large pendulum clock.\n\nIn 1890, they converted their partnership into a stock company Daimler Motoren Gesellschaft (DMG, in English—Daimler Motors Corporation). They sold their first automobile in 1892. Daimler fell ill and took a break from the business. Upon his return he experienced difficulty with the other stockholders that led to his resignation in 1893. This was reversed in 1894. Maybach resigned at the same time, and also returned. In 1900 Daimler died and Wilhelm Maybach quit DMG in 1907.\n\nGottlieb Wilhelm Daimler was the son of a baker named Johannes Däumler (Daimler) and his wife Frederika, from the town of Schorndorf near Stuttgart, Württemberg. By the age of 13 (1847), he had completed six years of primary studies in Lateinschule and became interested in engineering.\n\nAfter completing secondary school in 1848, Daimler had trained as a gunsmith under Master Gunsmith Hermann Raithel. In 1852 he ended the training with the trade examination. He graduated in 1852, passing the craft test with a pair of engraved double-barreled pistols. The same year, at eighteen, Daimler decided to take up mechanical engineering, abandoning gunsmithing, and left his hometown.\n\nSigning up at Stuttgart's School for Advanced Training in the Industrial Arts, under the tutelage of . Daimler was studious, even taking extra Sunday morning classes. In 1853, Daimler, with Steinbeis' assistance, got work at \"the factory college\", \"Rollé und Schwilque\" (R&S) in Grafenstaden, so-called because its manager, Friedrich Messmer, had been an instructor at the University of Karlsruhe. Daimler performed well, and when Rollé und Schwilque began making railway locomotives in 1856, Daimler, then 22, was named foreman.\n\nInstead of staying, Daimler took two years at Stuttgart's Polytechnic Institute to hone his skills, gaining in-depth grasp of steam locomotives, as well as \"a profound conviction\" steam was destined to be superseded. He conceived small, cheap, simple engines for light industrial use, possibly inspired by the newly developed gas engines of that era.\n\nIn 1861, he resigned from R&S, visiting Paris, then went on to England, working with the country's top engineering firms, becoming knowledgeable with machine tools. He spent from autumn 1861 to summer 1863 in England, then regarded as \"the motherland of technology\", at Beyer, Peacock and Company of Gorton, Manchester. Beyer was from Saxony. While in London, he visited the 1862 International Exhibition, where one of the exhibits was a steam carriage. These carriages did not evidently inspire him, however, for his wish was to produce machine tools and woodworking machinery.\n\nDaimler went to work for Maschinenfabrik Daniel Straub, Geislingen an der Steige, where he designed tools, mills, and turbines. In 1863, he joined the \"Bruderhaus Reutlingen\", a Christian Socialist toolmaker, as inspector and later executive. While there, he met Wilhelm Maybach, then a 15-year-old orphan. Thanks to Daimler's organizational skills, the factory managed to show a profit, but he quit in frustration in 1869, joining Maschinenbau Gesellschaft Karlsruhe in July.\n\nWhen in 1872 N.A. Otto and Cie reorganized as Gasmotoren-Fabrik Deutz, management picked Daimler as factory manager, bypassing even Otto, and Daimler joined the company in August, bringing in Maybach as chief designer. While Daimler managed to improve production, the weakness in the Otto's vertical piston design, coupled to Daimler's stubborn insistence on atmospheric engines, led the company to an impasse. Neither Otto nor Daimler would give way, and when Daimler was offered the choice of founding a Deutz branch in St. Petersburg or resigning, he resigned to set up shop in Cannstatt (financed by savings and shares in Deutz), where he was shortly joined by Maybach.\n\nIn 1872 at age 38, Daimler and Maybach moved to work at the world's largest manufacturer of stationary engines at the time, the Deutz-AG-Gasmotorenfabrik in Cologne. It was half-owned by Nikolaus Otto, who was looking for a new technical director. As directors, both Daimler and Otto focused on gas-engine development while Maybach was chief designer.\n\nIn 1876, Otto developed a gaseous fuel, compressed charge four-stroke cycle, (also known as the Otto Cycle) engine after 14 years of effort, a system characterized by four piston strokes (intake, compression, power, and exhaust). Otto intended that his invention would replace the steam engines predominant in those years, even though his engine was still primitive and inefficient.\n\nOtto's engine was patented in 1877, but one of his 25 patents was soon challenged and overturned. Daimler who wanted to make his own engine, feared Otto's patent would prevent it. Daimler hired an attorney who found that a \"previous art\" patent for a four stroke engine had been issued in Paris in 1862 to Beau De Rochas, a French public works engineer.\n\nMeanwhile, serious personal differences arose between Daimler and Otto, reportedly with Otto being jealous of Daimler, because of his university background and knowledge. Daimler wanted to build small engines that could be applied to transportation but Otto had no interest in this. When Otto excluded Daimler from his engine patents there was great animosity between the two. Daimler was fired in 1880, receiving 112,000 Gold marks in Deutz-AG shares in compensation for the patents of both Daimler and Maybach. Maybach resigned later and followed Daimler.\n\nAt Cannstatt, Daimler and the more creative thinking Maybach devised their engine. At Daimler's insistence, it eliminated \"the clumsy, complicated slide-valve ignition\", in favor of a hot tube system invented by an Englishman named Watson, since electrical systems functioned too slowly.\n\nIn the summer of 1882 Daimler moved to Cannstatt just outside of Stuttgart at that time, purchasing a cottage in Cannstatt's Taubenheimstrasse, with 75,000 Gold marks from the compensation from Deutz-AG. Maybach followed in September of that year. In the garden, they added a brick extension to the roomy glass-fronted summer house and this became their workshop. Their activities alarmed the neighbors who reported them to the police as suspected counterfeiters. The police obtained a key from the gardener and raided the house in their absence, but found only engines.\n\nDaimler and Maybach spent long hours debating how best to fuel Otto's four-stroke design, and turned to a commonly available petroleum fraction. The main distillates of petroleum at the time were lubricating oil, kerosene (burned as lamp fuel), and ligroin (Petroleum Naptha), which up to then was used mainly as a cleaner and was sold in pharmacies. \"Leichtbenzin, wie es damals üblich und in der Apotheke zu bekommen war\", blickt Oldtimer-Experte Michael Plag zurück. \"Das ist ein verbrennungsfähiger Kraftstoff - Hexan N.\" [English]\"Mineral spirits were common and easy to get at the pharmacy\", recalls classic car expert Michael Plag. \"This is a combustion-efficient fuel - hexane N.\"\n\nIn late 1883, Daimler and Maybach patented the first of their engines fueled by ligroin. This engine was patented on December 16, 1883. It achieved Daimler's goal of being small and running fast enough to be useful at 750 rpm. Improved designs in the next four years brought that up to 900 rpm. Daimler had three engines built to this design early in 1884, and a flywheel was included in one of the engines. This design was smaller and lighter than engines by other inventors of the time. Daimler relied on hot tube ignition, until 1897, when he adopted the electrical ignition designed by Bosch.\n\nThe engine with the flywheel included was built into a light vehicle, called the Reitwagen, the first vehicle powered by an internal combustion engine.\n\nIt took considerable effort and experimentation, but eventually, the duo perfected a vertical single, which was fitted in the \"Reitwagen\", a purpose-built two-wheeler chassis with two spring-loaded stabilizerss.\n\nFeatures of the 1885 Engine included:\n\nIn 1885, they created a carburetor which mixed gasoline with air allowing its use as fuel. In the same year Daimler and Maybach assembled a larger version of their engine, still relatively compact, but now with a vertical cylinder of 100 cc displacement and an output of 1 hp at 600 rpm (patent DRP-28-022: \"non-cooled, heat insulated engine with unregulated hot-tube ignition\"). It was baptized the \"Standuhr\" (\"grandfather clock\"), because Daimler thought it resembled an old pendulum clock.\n\nIn November 1885, Daimler installed a smaller version of this engine in a wooden two wheeler frame with two outrigger wheels, creating the first internal combustion motorcycle (Patent 36-423impff & Sohn \"Vehicle with gas or petroleum drive machine\"). It was named the \"Reitwagen\" (riding car). Maybach rode it for three kilometers (two miles) alongside the river Neckar, from Cannstatt to Untertürkheim, reaching .\n\nIndependently of each other, Karl Benz and Gottlieb Daimler each produced an automobile in 1886, both in Germany, about 60 miles apart.\nAbout sixty miles away in Mannheim, Karl Benz built an automobile using an integral design for a motorized vehicle with one of his own engines. He was granted a patent for his \"motorwagen\" on 29 January 1886.\n\nWhen this proved the engine capable of driving a vehicle, Daimler devised a single and ordered a Wimpff und Soehne four-seater phaeton to house it. Daimler's engine was installed by Maschinenfabrik Esslingen and drove the rear wheels through a dual-ratio belt drive.\n\nOn 8 March 1886, Daimler and Maybach secretly brought an American Model coach made by Wilhelm Wimpff and Sohn into the house, telling the neighbors it was a birthday gift for Mrs. Daimler. Maybach supervised the installation of a larger 1.1 hp () version of the Grandfather Clock engine into this stagecoach and it became the first four-wheeled vehicle to reach . The engine power was transmitted by a set of belts. As with the motorcycle, it was tested on the road to Untertürkheim where nowadays the Mercedes-Benz Arena, formerly called the Gottlieb-Daimler-Stadion, is situated.\n\nDriven by Daimler's desire to use the engine as many ways as possible, Daimler and Maybach used the engine in other types of transport including:\n\nThey sold their first foreign licenses for engines in 1887 and Maybach went as their representative to the 1889 Paris Exposition to show their achievements.\n\nEngine sales increased, mostly for use in boats, and in June 1887, Daimler bought another property at Seelberg hill, Cannstatt. It was located some distance from the town on Ludwigstraße 67 because Cannstatt's mayor did not approve of the workshop. Built at a cost 30,200 goldmarks, the new premises had room for 23 employees. Daimler managed the commercial issues while Maybach ran the engine design department.\n\nIn 1889, Daimler and Maybach built the \"Stahlradwagen\", their first automobile that did not involve adapting a horse-drawn carriage with their engine, but which was somewhat influenced by bicycle designs. There was no production in Germany, but it was licensed to be built in France and presented to the public in Paris in October 1889 by both engineers. The same year, Daimler's wife, Emma Kunz, died.\n\nWith demand for engines growing, for uses in everything from motorboats to railcars, Maybach and Daimler expanded. With funding from gunpowder maker Max Duttenhofer, industrialist, and banker Kilian von Steiner, and munitions manufactuer , \"Daimler Motoren Gesellschaft\" was founded 28 November 1890, with Maybach as chief designer. Its purpose was the construction of small, high-speed engines for use on land, water, and air transport. The three uses were expressed by Daimler in a sketch that became the basis for a logo with a three-pointed star.\n\nFrom 1882 until 1890 Daimler had resisted making his company into an incorporation or stock company. He had seen what happened to too many engineers who had pioneered a capital invention as he had. Many of them were forced out of their own companies by stock holders who \"knew better\" about how to run the company that they had just purchased than the man who created it. This is a very common occurrence in the business world. It happened to Henry Ford, Ransom E. Olds, Karl Benz, August Horch (Audi), Gottlieb Daimler and many others.\n\nMany German historians consider this Daimler's \"pact with the devil\".\n\nDaimler hated having to incorporate his company. Unable to obtain majority control, he sold out and then resigned. DMG expanded, but it changed. The newcomers, not believing in automobile production, ordered the creation of additional stationary engine building capacity, and considered merging DMG with Otto's \"Deutz-AG\".\n\nDaimler and Maybach preferred plans to produce automobiles and reacted against Duttenhofer and Lorenz. Maybach was denied a seat on the board and on 11 February 1891, he left the business. He continued his design work as a freelance in Cannstatt from his own house, with Daimler's support, moving to the closed Hermann Hotel in the autumn of 1892. He used its ballroom and winter garden as workshops, employing twelve workers and five apprentices.\n\nThe new company developed the high-speed inline-two \"Phönix\", for which Maybach invented a spray carburettor. This was fitted in a singularly ugly car, which entered production in 1895 after a cessation of hostilities between Daimler, Maybach, and the DMG board.\n\nIn 1892, DMG finally sold its first automobile. Gottlieb Daimler, aged 58, had heart problems and suffered a collapse in the winter of 1892–1893. His doctor prescribed a trip to Florence, where he met Lina Hartmann, a widow 22 years his junior who was the owner of the hotel where he was staying. They married on 8 July 1893, honeymooning in Chicago during its World Fair.\n\nReturning from the 1893 World's Fair in Chicago with his new wife, Daimler had vowed to purchase enough shares of DMG to regain control. This effort failed. Daimler sold all his shares and patents and resigned from the Company. Maybach had left earlier.\n\nThe disputes with Lorenz continued. Daimler attempted to buy 102 extra shares to get a majority holding, but was forced out of his post as technical director. The corporation was 400,000 Gold marks in debt. The other directors threatened to declare bankruptcy if Daimler didn't sell them all his shares and all his personal patent rights from the previous thirty years. Daimler accepted the offer, receiving 66,666 Gold Marks, and resigned in 1893.\n\nIn 1894 at the Hermann Hotel, Maybach together with Daimler and his son Paul designed a third engine called the \"Phoenix\" and had DMG make it. It featured:\n\nThis is probably the same internal-combustion engine referred to by the American author and historian Henry Brooks Adams, who describes the \"Daimler motor\" and its great speed from his visit to the 1900 Paris Exposition in his autobiography.\n\nDaimler and Maybach continued to work together. They built a four-cylinder engine with Maybach' spray nozzle carburetor. It was in the first organized automobile race, the \"Paris to Rouen\" and defeated all the entries from DMG. Frederick Simms, German-born long-time friend of Gottlieb Daimler insisted that Daimler be brought back into the company making it a condition of his payment of £17,500 for the transfer of his Daimler licenses to the British Daimler Company which would stabilize the corporation's finances, that Daimler, now aged sixty, should return to DMG. Gottlieb Daimler received 200,000 goldmarks in shares, plus a 100,000 bonus. Simms received the right to use the name \"Daimler\" as his brand name for Daimler Company products. In 1895, the year DMG assembled its 1,000th engine, Maybach returned as General Inspector, receiving 30,000 shares.\n\nDuring this period, they agreed to licenses to build Daimler engines around the world, which included:\n\nDaimler died in 1900, and in 1907 Maybach resigned from DMG.\n\nDaimler had developed the first liquid petroleum vehicle in 1885 and Karl Benz had developed the first purpose built automobile using a 2 cycle engine of his own design a few months later. Daimler never met Karl Benz during the period of invention. In 1896 Daimler (DMG) sued Benz & Cie for violating his 1883 patent on hot tube ignition. Daimler won and Benz had to pay royalties to DMG. Daimler did not meet Karl Benz while they were in court in Mannheim. Later at the founding of the Central European Motor Car Association Daimler and Benz still did not speak to each other.\n\nYears after Daimler died, the two companies did cooperate in many ways. After many years of cooperation, on June 28, 1926 representatives of Daimler-Motoren-Gesellschaft (DMG) and Benz & Cie signed the agreement for the merger of the two oldest automobile manufacturers in the world. The resulting new company was named Daimler-Benz.\n\nGottlieb Daimler was accepted into the Automotive Hall of Fame in 1978. Between 1993 and July 2008 Daimler had a stadium named after him in Stuttgart, Germany. The Mercedes-Benz Arena was the venue for six matches in the 2006 FIFA World Cup in Germany.\n\nGottlieb Daimler's motto was \"Das Beste oder nichts\" (\"The best or nothing at all\"; \"Nothing but the best\"). Mercedes-Benz adopted this motto as their slogan in 2010.\n\n\n\n"}
{"id": "11756603", "url": "https://en.wikipedia.org/wiki?curid=11756603", "title": "History of trams", "text": "History of trams\n\nThe history of trams, streetcars or trolleys began in early nineteenth century. It can be divided up into several discrete periods defined by the principal means of motive power used.\n\nThe world's first passenger tram was the Swansea and Mumbles Railway, in Wales, UK. The Mumbles Railway Act was passed by the British Parliament in 1804, and this first horse-drawn passenger tramway started operating in 1807. It was worked by steam from 1877, and then, from 1929, by very large (106-seater) electric tramcars, until closure in 1961.\n\nThe first streetcar in America, developed by John Stephenson, began service in the year 1832. This was the New York and Harlem Railroad's Fourth Avenue Line which ran along the Bowery and Fourth Avenue in New York City. These trams were an animal railway, usually using horses and sometimes mules to haul the cars, usually two as a team. Rarely, other animals were tried, including humans in emergency circumstances. It was followed in 1835 by New Orleans, Louisiana, which is the oldest continuously operating street railway system in the world, according to the American Society of Mechanical Engineers.\n\nThe first tram in Continental Europe opened in France in 1839 between Montbrison and Montrond, on the streets inside the towns, and on the roadside outside town. It had permission for steam traction, but was entirely run with horse traction. In 1848, it was closed down after repeated economic failure. The tram developed in numerous cities of Europe (some of the most extensive systems were found in Berlin, Budapest, Birmingham, Leningrad, Lisbon, London, Manchester, Paris).\n\nThe first tram in South America opened in 1858 in Santiago, Chile. The first trams in Australia opened in 1860 in Sydney. Africa's first tram service started in Alexandria on 8 January 1863. The first trams in Asia opened in 1869 in Batavia (now Jakarta), Netherlands East Indies (now Indonesia).\n\nProblems with horsecars included the fact that any given animal could only work so many hours on a given day, had to be housed, groomed, fed and cared for day in and day out, and produced prodigious amounts of manure, which the streetcar company was charged with storing and then disposing. Since a typical horse pulled a streetcar for about a dozen miles a day and worked for four or five hours, many systems needed ten or more horses in stable for each horsecar.\n\nHorsecars were largely replaced by electric-powered trams following the improvement of an overhead trolley system on trams for collecting electricity from overhead wires by Frank J. Sprague. His spring-loaded trolley pole used a wheel to travel along the wire. In late 1887 and early 1888, using his trolley system, Sprague installed the first successful large electric street railway system in Richmond, Virginia. Within a year, the economy of electric power had replaced more costly horsecars in many cities. By 1889, 110 electric railways incorporating Sprague's equipment had been begun or planned on several continents.\n\nHorses continued to be used for light shunting well into the 20th century. Many large metropolitan lines lasted well into the early twentieth century. New York City had a regular horsecar service on the Bleecker Street Line until its closure in 1917. Pittsburgh, had its Sarah Street line drawn by horses until 1923. The last regular mule-drawn cars in the US ran in Sulphur Rock, Arkansas, until 1926 and were commemorated by a U.S. postage stamp issued in 1983. The last mule tram service in Mexico City ended in 1932, and a mule tram in Celaya, Mexico, survived until 1954. The last horse-drawn tram to be withdrawn from public service in the UK took passengers from Fintona railway station to Fintona Junction one mile away on the main Omagh to Enniskillen railway in Northern Ireland. The tram made its last journey on 30 September 1957 when the Omagh to Enniskillen line closed. The \"van\" now lies at the Ulster Transport Museum.\n\nHorse-drawn trams still operate on the 1876-built Douglas Bay Horse Tramway in the Isle of Man, and at the 1894-built Victor Harbor Horse Drawn Tram, in Adelaide, South Australia. New horse-drawn systems have been established at the Hokkaidō Museum in Japan and also in Disneyland.\n\nThe first mechanical trams were powered by steam. Generally, there were two types of steam tram. The first and most common had a small steam locomotive (called a tram engine in the UK) at the head of a line of one or more carriages, similar to a small train. Systems with such steam trams included Christchurch, New Zealand; Adelaide, South Australia; Sydney, Australia and other city systems in New South Wales; Munich, Germany (from August 1883 on), British India (Pakistan) (from 1885) and the Dublin & Blessington Steam Tramway (from 1888) in Ireland. Steam tramways also were used on the suburban tramway lines around Milan and Padua; the last \"Gamba de Legn\" (\"Peg-Leg\") tramway ran on the Milan-Magenta-Castano Primo route in late 1958.\n\nThe other style of steam tram had the steam engine in the body of the tram, referred to as a tram engine (UK) or steam dummy (US). The most notable system to adopt such trams was in Paris. French-designed steam trams also operated in Rockhampton, in the Australian state of Queensland between 1909 and 1939. Stockholm, Sweden, had a steam tram line at the island of Södermalm between 1887 and 1901.\n\nTram engines usually had modifications to make them suitable for street running in residential areas. The wheels, and other moving parts of the machinery, were usually enclosed for safety reasons and to make the engines quieter. Measures were often taken to prevent the engines from emitting visible smoke or steam. Usually the engines used coke rather than coal as fuel to avoid emitting smoke; condensers or superheating were used to avoid emitting visible steam. A major drawback of this style of tram was the limited space for the engine, so that these trams were usually underpowered. Steam tram engines faded out around 1890s to 1900s, being replaced by electric trams.\n\nAnother motive system for trams was the cable car, which was pulled along a fixed track by a moving steel cable. The power to move the cable was normally provided at a \"powerhouse\" site a distance away from the actual vehicle.\n\nThe London and Blackwall Railway, which opened for passengers in east London, England, in 1840 used such a system.\n\nThe first practical cable car line was tested in San Francisco, in 1873. Part of its success is attributed to the development of an effective and reliable cable grip mechanism, to grab and release the moving cable without damage. The second city to operate cable trams was Dunedin in New Zealand, from 1881 to 1957.\n\nThe most extensive cable system in the US was built in Chicago between 1882 and 1906. New York City developed at least seven cable car lines. Los Angeles also had several cable car lines, including the Second Street Cable Railroad, which operated from 1885 to 1889, and the Temple Street Cable Railway, which operated from 1886 to 1898.\nFrom 1885 to 1940, the city of Melbourne, Victoria, Australia operated one of the largest cable systems in the world, at its peak running 592 trams on of track. There were also two isolated cable lines in Sydney, New South Wales, Australia; the North Sydney line from 1886 to 1900, and the King Street line from 1892 to 1905.\n\nIn Dresden, Germany, in 1901 an elevated suspended cable car following the \"Eugen Langen one-railed floating tram system\" started operating. Cable cars operated on Highgate Hill in North London and Kennington to Brixton Hill In South London. They also worked around \"Upper Douglas\" in the Isle of Man from 1897 to 1929 (cable car 72/73 is the sole survivor of the fleet).\n\nCable cars suffered from high infrastructure costs, since an expensive system of cables, pulleys, stationary engines and lengthy underground vault structures beneath the rails had to be provided. They also required physical strength and skill to operate, and alert operators to avoid obstructions and other cable cars. The cable had to be disconnected (\"dropped\") at designated locations to allow the cars to coast by inertia, for example when crossing another cable line. The cable would then have to be \"picked up\" to resume progress, the whole operation requiring precise timing to avoid damage to the cable and the grip mechanism. Breaks and frays in the cable, which occurred frequently, required the complete cessation of services over a cable route while the cable was repaired. Due to overall wear, the entire length of cable (typically several kilometres) would have to be replaced on a regular schedule. After the development of reliable electrically powered trams, the costly high-maintenance cable car systems were rapidly replaced in most locations.\n\nCable cars remained especially effective in hilly cities, since their nondriven wheels would not lose traction as they climbed or descended a steep hill. The moving cable would physically pull the car up the hill at a steady pace, unlike a low-powered steam or horse-drawn car. Cable cars do have wheel brakes and track brakes, but the cable also helps restrain the car to going downhill at a constant speed. Performance in steep terrain partially explains the survival of cable cars in San Francisco.\n\nThe San Francisco cable cars, though significantly reduced in number, continue to perform a regular transportation function, in addition to being a well-known tourist attraction. A single cable line also survives in Wellington, New Zealand (rebuilt in 1979 as a funicular but still called the \"Wellington Cable Car\"). Another system, actually two separate cable lines with a shared power station in the middle, operates from the Welsh town of Llandudno up to the top of the Great Orme hill in North Wales, UK.\n\nIn the late 19th and early 20th centuries a number of systems in various parts of the world employed trams powered by gas, naphtha gas or coal gas in particular. Gas trams are known to have operated between Alphington and Clifton Hill in the northern suburbs of Melbourne, Australia (1886–1888); in Berlin and Dresden, Germany; in Estonia (1920s–1930); between Jelenia Góra, Cieplice, and Sobieszów in Poland (from 1897); and in the UK at Lytham St Annes, Neath (1896–1920), and Trafford Park, Manchester (1897–1908).\n\nOn 29 December 1886 the Melbourne newspaper \"The Argus\" reprinted a report from the San Francisco Bulletin that Mr Noble had demonstrated a new 'motor car' for tramways 'with success'. The tramcar 'exactly similar in size, shape, and capacity to a cable grip car' had the 'motive power' of gas 'with which the reservoir is to be charged once a day at power stations by means of a rubber hose'. The car also carried an electricity generator for 'lighting up the tram and also for driving the engine on steep grades and effecting a start'.\n\nComparatively little has been published about gas trams. However, research on the subject was carried out for an article in the October 2011 edition of \"The Times\", the historical journal of the Australian Association of Timetable Collectors, now the Australian Timetable Association.\n\nA tram system powered by compressed natural gas was due to open in Malaysia in 2012, but the news about the project appears to have dried up.\n\nThe world's first experimental electric tramway was built by Russian inventor Fyodor Pirotsky near St Petersburg in 1880. The first commercially-successful electric tram line operated in Lichterfelde near Berlin, Germany, in 1881. It was built by Werner von Siemens (see Berlin Straßenbahn). It initially drew current from the rails, with overhead wire being installed in 1883.\n\nIn Britain, Volk's electric railway was opened in 1883 in Brighton (see Volk's Electric Railway). This two kilometer line, re-gauged to in 1884, remains in service to this day, and is the oldest operating electric tramway in the world. Also in 1883, Mödling and Hinterbrühl Tram was opened near Vienna in Austria. It was the first tram in the world in regular service that was run with electricity served by an overhead line with pantograph current collectors. The Blackpool Tramway, was opened in Blackpool, UK on 29 September 1885 using conduit collection along Blackpool Promenade. This system is still in operation in a modernised form.\n\nEarliest tram system in Canada was by John Joseph Wright, brother of the famous mining entrepreneur Whitaker Wright, in Toronto in 1883. In the US, multiple functioning experimental electric trams were exhibited at the 1884 World Cotton Centennial World's Fair in New Orleans, Louisiana, but they were not deemed good enough to replace the Lamm fireless engines then propelling the St. Charles Avenue Streetcar in that city. The first commercial installation of an electric streetcar in the United States was built in 1884 in Cleveland, Ohio and operated for a period of one year by the East Cleveland Street Railway Company. Trams were operated in Richmond, Virginia, in 1888, on the Richmond Union Passenger Railway built by Frank J. Sprague. Sprague later developed multiple unit control, first demonstrated in Chicago in 1897, allowing multiple cars to be coupled together and operated by a single motorman. This gave birth to the modern subway train. Following the improvement of an overhead trolley system on streetcars for collecting electricity from overhead wires by Frank J. Sprague, electric tram systems were rapidly adopted across the world.\n\nEarlier installations proved difficult or unreliable. Siemens' line, for example, provided power through a live rail and a return rail, like a model train, limiting the voltage that could be used, and providing electric shocks to people and animals crossing the tracks. Siemens later designed his own version of overhead current collection, called the bow collector, and Thorold, Ontario, opened in 1887, and was considered quite successful at the time. While this line proved quite versatile as one of the earliest fully functional electric streetcar installations, it required horse-drawn support while climbing the Niagara Escarpment and for two months of the winter when hydroelectricity was not available. It continued in service in its original form into the 1950s.\n\nSidney Howe Short designed and produced the first electric motor that operated a streetcar without gears. The motor had its armature direct-connected to the streetcar's axle for the driving force. Short pioneered \"use of a conduit system of concealed feed\" thereby eliminating the necessity of overhead wire, trolley poles and a trolley for street cars and railways. While at the University of Denver he conducted important experiments which established that multiple unit powered cars were a better way to operate trains and trolleys.\n\nSarajevo built a citywide system of electric trams in 1885. Budapest established its tramway system in 1887, and its ring line has grown to be the busiest tram line in Europe, with a tram running every 60 seconds at rush hour. Bucharest and Belgrade ran a regular service from 1894. Ljubljana introduced its tram system in 1901 – it closed in 1958.\n\nThe first electric tramway in Australia was a Sprague system demonstrated at the 1888 Melbourne Centennial Exhibition in Melbourne; afterwards, this was installed as a commercial venture operating between the outer Melbourne suburbs of Box Hill and Doncaster from 1889 to 1896. As well, electric systems were built in Adelaide, Ballarat, Bendigo, Brisbane, Fremantle, Geelong, Hobart, Kalgoorlie, Launceston, Leonora, Newcastle, Perth, and Sydney. By the 1970s, the only tramway system remaining in Australia was the Melbourne tram system other than a few single lines remaining elsewhere: the Glenelg Tram, connecting Adelaide to the beachside suburb of Glenelg, and tourist trams in the Victorian Goldfields cities of Bendigo and Ballarat. In recent years the Melbourne system, generally recognised as one of the largest in the world, has been considerably modernised and expanded. The Adelaide line has also been extended to the Entertainment Centre, and there are plans to expand further.\n\nIn Japan, the Kyoto Electric railroad was the first tram system, starting operation in 1895. By 1932, the network had grown to 82 railway companies in 65 cities, with a total network length of . By the 1960s the tram had generally died out in Japan.\n\nTwo rare but significant alternatives were conduit current collection, which was widely used in London, Washington, D.C. and New York City, and the surface contact collection method, used in Wolverhampton (the Lorain system), Torquay and Hastings in the UK (the Dolter stud system), and currently in Bordeaux, France (the ground-level power supply system).\n\nThe convenience and economy of electricity resulted in its rapid adoption once the technical problems of production and transmission of electricity were solved. Electric trams largely replaced animal power and other forms of motive power including cable and steam, in the late 19th and early 20th centuries.\n\nThere is one particular hazard associated with trams powered from a trolley off an overhead line. Since the tram relies on contact with the rails for the current return path, a problem arises if the tram is derailed or (more usually) if it halts on a section of track that has been particularly heavily sanded by a previous tram, and the tram loses electrical contact with the rails. In this event, the underframe of the tram, by virtue of a circuit path through ancillary loads (such as saloon lighting), is live at the full supply voltage, typically 600 volts. In British terminology such a tram was said to be ‘grounded’—not to be confused with the US English use of the term, which means the exact opposite. Any person stepping off the tram completed the earth return circuit and could receive a nasty electric shock. In such an event the driver was required to jump off the tram (avoiding simultaneous contact with the tram and the ground) and pull down the trolley before allowing passengers off the tram. Unless derailed, the tram could usually be recovered by running water down the running rails from a point higher than the tram. The water providing a conducting bridge between the tram and the rails.\n\nIn the 2000s, two companies introduced catenary-free designs. Alstom's Citadis line uses a third rail, and Bombardier's PRIMOVE LRV is charged by contactless induction plates embedded in the trackway.\n\nAs early as 1834, Thomas Davenport, a Vermont blacksmith, had invented a battery-powered electric motor which he later patented. The following year he used it to operate a small model electric car on a short section of track four feet in diameter.\n\nAttempts to use batteries as a source of electricity were made from the 1880s and 1890s, with unsuccessful trials conducted in among other places Bendigo and Adelaide in Australia, and for about 14 years as The Hague \"accutram\" of HTM in the Netherlands. The first trams in Bendigo, Australia, in 1892, were battery-powered but within as little as three months they were replaced with horse-drawn trams. In New York City some minor lines also used storage batteries. Then, comparatively recently, during the 1950s, a longer battery-operated tramway line ran from Milan to Bergamo. In China there is a Nanjing battery Tram line and has been running since 2014.\n\nIn some places, other forms of power were used to power the tram.\n\nHastings and some other tramways, for example Stockholms Spårvägar in Sweden and some lines in Karachi, used petrol trams. Paris operated trams that were powered by compressed air using the Mekarski system.\n\nGalveston Island Trolley in Texas operated diesel trams due to the city's hurricane-prone location, which would result in frequent damage to an electrical supply system. Although Portland, Victoria promotes its tourist tram as being a cable car it actually operates using a hidden diesel motor. The tram, which runs on a circular route around the town of Portland, uses dummies and salons formerly used on the extensive Melbourne cable tramway system and now beautifully restored.\n\nIn March 2015, China South Rail Corporation (CSR) demonstrated the world's first hydrogen fuel cell vehicle tramcar at an assembly facility in Qingdao. The chief engineer of the CSR subsidiary CSR Sifang Co Ltd., Liang Jianying, said that the company is studying how to reduce the running costs of the tram.\n\nThe Trieste–Opicina tramway in Trieste operates a hybrid funicular tramway system. Conventional electric trams are operated in street running and on reserved track for most of their route. However, on one steep segment of track, they are assisted by cable tractors, which push the trams uphill and act as brakes for the downhill run. For safety, the cable tractors are always deployed on the downhill side of the tram vehicle.\n\nSimilar systems were used elsewhere in the past, notably on the Queen Anne Counterbalance in Seattle and the Darling Street wharf line in Sydney.\n\nAt first the rails protruded above street level, causing accidents and problems for pedestrians. They were supplanted in 1852 by grooved rails or girder rails, invented by Alphonse Loubat. Loubat, inspired by Stephenson, built the first tramline in Paris, France. The line was inaugurated on 21 November 1853, in connection with the 1855 World Fair, running on a trial basis from Place de la Concorde to Pont de Sèvres and later to the village of Boulogne.\n\nThe Toronto streetcar system is one of the few in North America still operating in the classic style on street trackage shared with car traffic, where streetcars stop on demand at frequent stops like buses rather than having fixed stations. Known as Red Rockets because of their colour, they have been operating since the mid-19th century – horsecar service started in 1856 and electric service in 1892.\n\nThe advent of personal motor vehicles and the improvements in motorized buses caused the rapid disappearance of the tram from most western and Asian countries by the end of the 1950s (for example the first major UK city to completely abandon its trams was Manchester by January 1949). Continuing technical and reliability improvements in buses made them a serious competitor to trams because they did not require the construction of costly infrastructure. However, the demise of the streetcar came when lines were torn out of the major cities by \"bus manufacturing or oil marketing companies for the specific purpose of replacing rail service with buses.\"\n\nIn many cases postwar buses were cited as providing a smoother ride and a faster journey than the older, prewar trams. For example, the tram network survived in Budapest but for a considerable period of time bus fares were higher to recognize the superior quality of the buses. However, many riders protested against the replacement of streetcars arguing that buses weren't as smooth or efficient and polluted the air. In the United States, there have been allegations that the Great American streetcar scandal was responsible for the replacement of trains with buses, but critics of this theory point to evidence that larger economic forces were driving conversion before General Motors' actions and outside of its reach. Certainly the oldest system of all, the Swansea and Mumbles Railway of 1807, was purchased by The South Wales Transport Company (which operated a large motor bus fleet in the area) and despite vociferous local opposition, closed down in 1960.\n\nGovernments thus put investment principally into bus networks. Indeed, infrastructure for roads and highways meant for the automobile were perceived as a mark of progress. The priority given to roads is illustrated in the proposal of French president Georges Pompidou who declared in 1971 that \"the city must adapt to the car\". Tram networks were no longer maintained or modernized, a state of affairs that served to discredit them in the eyes of the public. Old lines, considered archaic, were then gradually replaced by buses.\n\nTram networks disappeared almost completely from France, the UK, and altogether from Ireland, Denmark, Spain, as well as being completely removed from cities such as Sydney, which had one of the largest networks in the world with route length and Brisbane. The vast majority of tram networks also disappeared in North America, but American cities Boston, Philadelphia, Newark, San Francisco, New Orleans, Pittsburgh, Cleveland, Canadian Toronto and Mexico City still retained trams. This situation occurred in Italy and Netherlands, too. There are preserved system in Milan, Rome, Naples, Turin, Ritten and between Trieste and Opicina, and in Amsterdam, Rotterdam and The Hague. On the other hand, tram systems were generally retained or modernized in most communist countries, as well as Switzerland, West Germany, Austria, Belgium, Norway, Portugal, Sweden, Japan etc. though cuts and closures of entire systems also happened there as the example of Hamburg shows. In France, only the networks in Lille, Saint-Étienne and Marseille, survive from this period, but they all suffered significant reduction from their original size. In Great Britain, only the Blackpool Tramway kept running, with an extensive system which includes some street running in Blackpool, and a long stretch of segregated track to nearby Fleetwood.\n\nWhile many networks closed down during the postwar decades, the rolling stock on remaining systems kept developing, with multi-car trains (or articulated trams) with double-end designs and automatic control systems, allowing a single driver to serve more passengers. Passenger and driver comfort have improved with stuffed seats and cabin heating. Advertising on trams, including all-over striping, became common.\n\nWith the resurgence in the late 20th and 21st century, low-floor trams, with regenerative braking have been developed.\n\nThe priority given to personal vehicles and notably to the automobile led to a loss in quality of life, particularly in large cities where smog, traffic congestion, sound pollution and parking became problematic. Acknowledging this, some authorities saw fit to redefine their transport policies. Rapid transit required a heavy investment and presented problems in terms of subterranean spaces that required constant security. For rapid transit, the investment was mainly in underground construction, which made it impossible in some cities (with underground water reserves, archaeological remains, etc.). Metro construction thus was not a universal panacea.\n\nThe advantages of the tram thus became once again visible. At the end of the 1970s, some governments studied, and then built new tram lines. The renaissance of light rail in North America began in 1978 when the Canadian city of Edmonton, Alberta adopted the German Siemens-Duewag U2 system, followed three years later by Calgary, Alberta and San Diego, California.\n\nBritain began replacing its run-down local railways with light rail in the 1980s, starting with the Tyne and Wear Metro in Tyneside and followed by the Docklands Light Railway in London. The trend to light rail in the United Kingdom was firmly established with the success of the Manchester Metrolink system and Sheffield Supertram in 1992, followed by Midland Metro in Birmingham in 1999, and Tramlink in London in 2000.\n\nIn France, Nantes and Grenoble lead the way in terms of the modern tram, and new systems were inaugurated in 1985 and 1988. In 1994 Strasbourg opened a system with novel British-built trams, specified by the city, with the goal of breaking with the archaic conceptual image that was held by the public.\n\nA great example of this shift in ideology is the city of Munich, which began replacing its tram network with a metro a few years before the 1972 Summer Olympics. When the metro network was finished in the 1990s the city began to tear out the tram network (which had become rather old and decrepit), but now faced opposition from many citizens who enjoyed the enhanced mobility of the mixed network—the metro lines deviate from the tram lines to a significant degree. New rolling stock was purchased and the system was modernized, and a new line was proposed in 2003.\n\nThe Olympic Games of 2004 that prompted the redevelopment of trams as part of the Athens Mass Transit System. The tramways in Athens are integrated with the revived Athens Metro system, as well as the buses, trolleybuses and suburban trains.\n\nIn Melbourne, Australia, the already extensive tramway system continues to be extended. In 2004 the Mont Albert line was extended several kilometres to Box Hill, whilst in 2005 the Burwood East line was extended several kilometres to Vermont South. In Sydney, trams returned in the form of light rail with the opening of the Inner West Light Rail line in 1997, which has seen extensions and now covers .\n\nIn Scotland, Edinburgh relaunched its tram network on 31 May 2014 after delayed development which began in 2008. Edinburgh previously had an extensive tram network which began closure in the 1950s. The new network is significantly smaller, 8.7 miles, compared to the previous tram network, 47.25 miles.\n\nSystems such as tram-trains are bringing rail based transit to areas that never had it and would not otherwise have gotten it. The Karlsruhe model was one of the first in the modern era and provided one seat rides where several connections would have been necessary before, increasing ridership by significant amounts upon opening of service compared to prior bus or local train routes.\n\n"}
{"id": "10463746", "url": "https://en.wikipedia.org/wiki?curid=10463746", "title": "IPC (electronics)", "text": "IPC (electronics)\n\nIPC, the Association Connecting Electronics Industries, is a trade association whose aim is to standardize the assembly and production requirements of electronic equipment and assemblies. It was founded in 1957 as the Institute for Printed Circuits. Its name was later changed to the Institute for Interconnecting and Packaging Electronic Circuits to highlight the expansion from bare boards to packaging and electronic assemblies. In 1999, the organization formally changed its name to IPC with the accompanying tagline, \"Association Connecting Electronics Industries\".\n\nIPC is accredited by the American National Standards Institute (ANSI) as a standards developing organization and is known globally for its standards. It publishes the most widely used acceptability standards in the electronics industry.\n\nIPC is headquartered in Bannockburn, Illinois, United States and maintains additional offices in Washington, D.C.; Taos, New Mexico; Arlington County, Virginia, in the United States; Stockholm, Sweden; Brussels, Belgium; Moscow, Russia; Bangalore, India; and Shanghai, Shenzhen and Beijing, China.\n\nIPC standards are used by the electronics manufacturing industry. IPC-A-610, \"Acceptability of Electronic Assemblies\", is used worldwide by original equipment manufacturers and EMS companies. There are more than 3600 trainers worldwide who are certified to train and test on the standard. Standards are created by committees of industry volunteers. Task groups have been formed in China, the United States, and Denmark.\n\nStandards published by IPC include:\n\n\n\n\n\n\nIPC members are eligible to participate in IPC’s statistical programs, which provide free monthly or quarterly reports for specific industry and product markets. Statistical programs cover the electronics manufacturing services (EMS), printed circuit board (PCB), laminate, process consumables, solder and assembly equipment segments.\n\nComprehensive annual reports are distributed for the EMS and PCB segments, covering market size and sales growth, with breakdowns by product type and product mix as well as revenue trends from value-added services, trends in materials, financial metrics, and forecasts for total production in the Americas and the world.\n\nMonthly market reports for the EMS and PCB segments provide recent data on market size, sales and order growth, book-to-bill ratios and near-term forecasts.\n\n"}
{"id": "9558533", "url": "https://en.wikipedia.org/wiki?curid=9558533", "title": "Industrial Property Digital Library", "text": "Industrial Property Digital Library\n\nThe Industrial Property Digital Library (IPDL) is a free online service for searching Japanese patents, patent applications, utility models, designs and trademarks. It makes available to the public the intellectual property Gazettes of the Japan Patent Office (JPO). The IPDL provides around 55.5 million documents and their relevant information as published since the end of the 19th century.\n\nThe service was originally developed by the JPO, which had provided it since March 1999. The information is now available from the National Center for Industrial Property Information and Training (INPIT), since October 1, 2004.\n\nThe Patent Abstracts of Japan (PAJ) are accessible through the IPDL web site, and provide access to English abstracts of Japanese patent documents. The PAJ is published since 1976. The PAJ includes the legal status information since January 1993.\n\n"}
{"id": "52164321", "url": "https://en.wikipedia.org/wiki?curid=52164321", "title": "Joan Ball", "text": "Joan Ball\n\nJoan Ball was a computer dating pioneer who started the first computer dating service in England, in 1964. Ball's computer dating service also pre-dated the earliest American computer dating services, like Operation Match at Harvard.\n\nJoan Ball was born in 1934 and was the 6th child in her family. She was an unwanted child born to a poor, working-class family. She was briefly abandoned by her mother when she was very young. World War II started when she was only five years old, resulting in her being evacuated from London to the countryside to escape the aerial bombardments of London three times during the war. Although this may have saved her life, each foster family differed greatly and she was sexually harassed by one of the foster families with whom she lived. When the war was over she was able to go home to her family in London again.\n\nJoan Ball was dyslexic and struggled in school. She went through most of her life suffering from dyslexia, before it was known as such. She was not officially diagnosed until 1973, at the age of 39. As a coping mechanism she became the class clown when she was in school, so that she could make sure people \"laughed with [her]\" and not at her. During her school years she had a difficult home life: her mother often called her \"a pig-headed bitch\", and blamed Joan for her failing marriage. In 1949, Ball finished her last year of school and got a job as a shop assistant at The London Co-operative Society. Because of her dyslexia she had problems with writing and counting money.\n\nIn 1953, Ball was hospitalized after a suicide attempt and when she got out she went to live with her aunt Maud and uncle Ted. The same year, at the age of 19, she got hired at Bourne & Hollingsworth. In 1954, she left and started working in a store's dress department. She found this string of jobs unfulfilling and difficult: at the time, the most interesting parts of the fashion industry—in Ball's view—were still a man's world and she could not do the kind of work she was interested in, like design. Shortly thereafter, however, she was able to start working for Berkertex, a leading fashion house in London.\n\nIn 1961, when she was 27, she decided to leave Berkertex. Though she had intended to manage a shop in Cambridge she found herself out of a job until the shop was ready to open. Needing to pay rent, she took a job at a marriage bureau. It was here that she decided to start her own marriage bureau. She founded the Eros Friendship Bureau Ltd in 1962 and discovered she had a knack for helping people make connections. Though her company would go on to be successful for a decade, she had trouble advertising her service early on because of the fact marriage bureaus were seen as slightly suspect at the time: There was a widespread belief that marriage bureaus were actually fronts for prostitution. Because she could not advertise in print easily Ball relied on placing radio ads with the \"Pop Pirates\"—the pirate radio stations that operated just off the coast of Britain in the 1960s playing rock and roll music that the BBC had banned. Ball's company focused on long term match-ups and relationships—primarily trying to achieve marriages for clients—and catered to an older crowd who were looking to settle down or who had been previously divorced.\n\nIn 1961, she met a man she refers to in her memoir as Kenneth. Kenneth would later become her sexual partner and would help her in her business, though they were never married.\n\nJoan changed the name of her marriage bureau to the St. James Computer Dating Service in 1964 and the bureau ran its first set of computer match ups in 1964. This made Ball's service the first commercially successful computer dating service in either the UK or the US, as historian Marie Hicks points out in a recent article on the history of computer dating. \n\nIn 1965, Ball merged her company with another marriage bureau run by a woman and together they formed Com-Pat, or Computer Dating Services Ltd. Shortly after the merger, the owner of the other marriage bureau sold out her share in the company to Joan and Joan became the sole proprietor of Com-Pat.\n\nDateline, founded by John Richard Patterson in 1966, was a rival to Com-Pat. With this new rivalry, Ball saw the greater need for more advertising. Looking at questionnaires from Dateline and Operation Match in the USA, she learned that they emphasized questions about sex, which she and her employees thought would not lead to good matches. By 1969, her company was receiving a good response to their ads in News of the World, but Ball still felt she had to overcome the mindset that people had about computer dating being slightly odd or untoward. Newspapers at the time implied the people who used these services were lonely, sad or dysfunctional. Joan believed that this type of computer dating service was, on the contrary, a fun and intelligent way to meet people. Though newspapers sometimes painted a negative picture, Joan's company was generally well received by the public. This led her to advertise in The Sunday Express, Evening Standard, and The Observer—all major British newspapers at the time. At this time, Ball was running both Com-Pat and Eros. Soon she decided to sell Eros and focus on Com-Pat. She realized how important the future of computerized dating was and saw the potential growth of a service like Com-Pat.\n\nIn 1970, Com-Pat Two was launched. Joan and her company were ahead of the game, because they were using the most advanced matching system created at the time. They were able to change the whole system with 50,000 members in a single weekend without any problems. The system used a questionnaire, and gave a list of four of the top matches at the end.\n\nThough Joan had success with Com-Pat Two, she and her partner Ken began to run into economic and personal problems. Because Joan and Ken weren't married, Ball felt she had no sense of security with him. She eventually moved into her own flat after living with Ken for eight years. This new place gave her a sense of independence, security, and pride because of what she had needed to accomplish to get it.\n\nUnfortunately troubled times were ahead for her company. Ball realized that their telephone number and address had been printed incorrectly in one of her major advertisements. Their telephone number had also been removed from the directory. This forced her to get a new phone number. At the same time, Dateline was becoming more and more successful and was able to leverage the fact the newspapers already took Com-Pat's advertisements to place its own ads in the same papers without the difficulties that Ball had faced earlier. In 1971, there was a Post Office strike which halted all mail. It lasted almost eight weeks and Ball's business couldn't do anything during that time. Everything hit an all time low when the Daily Telegraph, the company's most successful advertising venue, refused to continue printing ads for Com-Pat because the paper had changed their advertising policy. Joan became depressed and felt unable to cope. At the same time, the UK was wracked with major strikes and economic problems: The miners' strike was causing chaos nationwide by disrupting the country's ability to produce electricity and power the government, businesses and industries that kept the economy functioning.\n\nIn 1973, when she was 39, she was finally diagnosed with dyslexia. Not many people knew the word, so she stopped using it when no one else knew what she was talking about. She had trouble coming to terms with her own illness. By this time, the recession had worsened. She had been fighting to keep her company afloat but by 1974 she was in debt and decided to sell her company. She called John Paterson of Dateline and offered Com-Pat to him, if her would agree to pay all of the company's debts as part of the purchase. Seeing that this was a way to monopolize the computer dating market in the UK by doing away with Dateline's only major competitor, Patterson quickly agreed.\n\nAfter a series of personal difficulties, Ball converted to Buddhism and began to come to terms with her illnesses and setbacks. Ball found herself with many regrets and came to the conclusion that she had locked herself away in her own emotional dungeon even though she had run a company focused on making new emotional connections between other people.\n\nBall was a successful entrepreneur who was the first person of any gender to run a commercially viable computer dating service in either the UK or the USA. Her company predated Harvard's \"Operation Match\" by a year and preceded the other major British computer dating company, Dateline (run by John Patterson). Com-Pat operated under Ball's management for nearly a decade, until she was eventually bought out by Dateline in 1974. Ball's experience shows that, contrary to popular narratives on the web, women were in fact early pioneers in the field of computer dating and social networking by computer. The fact that Ball has remained mostly unknown until now also reflects how gendered stereotypes have resulted in the historical submersion of women's contributions in computing. Janet Abbate, a historian of computing and professor at Virginia Tech, theorized in her book Recoding Gender--a history of women in computing—that \"women who did make significant contributions were not always inclined, by temperament or socialization, to trumpet their accomplishments\". Historians Nathan Ensmenger, Marie Hicks, Margot Lee Shetterly, and Jennifer Light have all shown, in their scholarship on gender in the history of computing, how structural inequality in both the present and the past has altered our view of historical reality when it comes to computing. The existence of these social dynamics in both the past and present has left many parts of computing history untold. Currently, historians are beginning to correct these oversights and to show how women like Joan Ball were important in the history of computer dating, and computing more generally.\n"}
{"id": "10885319", "url": "https://en.wikipedia.org/wiki?curid=10885319", "title": "Lion Corporation", "text": "Lion Corporation\n\n\n"}
{"id": "49474395", "url": "https://en.wikipedia.org/wiki?curid=49474395", "title": "MOPP (electrical safety)", "text": "MOPP (electrical safety)\n\nMeans Of Patient Protection, or MOPP, is a concept introduced in the standard for medical electrical equipment IEC 60601-1.\n"}
{"id": "10455478", "url": "https://en.wikipedia.org/wiki?curid=10455478", "title": "Marata Vision", "text": "Marata Vision\n\nMarata is a brand owned by Polaron Controls, part of Cooper Controls. Marata's principal business activity is distribution of video display, integration and control equipment for domestic and commercial use.\n\nMarata Vision is based in Watford, Herts, UK, close by the Polaron headquarters.\n\nMarata Vision was purchased outright by Polaron Controls in July 2004, at the time when the parent company Polaron Plc was launched on the stock market. Polaron Plc was acquired by Cooper Controls (UK) Ltd, a subsidiary of Cooper Industries Ltd., in March 2007.\n\n\n"}
{"id": "53294594", "url": "https://en.wikipedia.org/wiki?curid=53294594", "title": "Media Standard Print", "text": "Media Standard Print\n\nMedia Standard Print is a publication of the Bundesverband Druck und Medien (bvdm, German Printing and Media Industries Federation, Berlin), available on its website. The standard contains instructions on how to produce data and proofs that are to be sent to a printer. It is based on ProcessStandard Offset and therefore on the ISO Standards ISO 12647 and ISO 15930. As such, it serves as the foundation for smooth cooperation between customer, prepress service provider and printer during media production, covering data formats, colour formats, printing conditions, workflows, means of proofing, standards, black composition and much more.\n\nOnly those printing conditions adopted in ISO 12647-2 to -6 are permitted. In terms of data formats, only PDF files (ideally PDF/X-4 or PDF/X-1a) and TIFFs should be used for the delivery of individual images. Open files should be avoided. ICC profiles and the reference printing condition must be embedded with media neutral data or made available to the recipient.\n\nA Media Standard Print conforming contract proof must contain the FOGRA media wedge, the measurement record, the colour profiles used, the time and date of the proof. The print of the media wedge should be measured. Colour measurement should be carried out in accordance with ISO 13655:2009 in measurement mode M1 on a white backing and the visual evaluation of the proof including its comparison with printed copies should be under a standard illuminant in accordance with ISO 3664:2009 (confirmed 2015).\n\nMedia Standard Print proposes three possible workflows: a 'media neutral' one, a 'media specific' one and a 'classic media specific' one. The media neutral workflow (RGB colours, Lab colours and so on; PDF/X-4) offers advantages if it has not yet been decided what press will be used for printing, allowing the black composition to be adjusted. The disadvantage of the ‘media neutral’ workflow is a degree of rendering uncertainty, since the gamut mapping should be carried out using the unstandardized perceptual Rendering intent. However, in practice this has turned out to be of little relevance. The media specific workflow (CMYK and spot colours; PDF/X-1a) offers a degree of production security, especially against unexpected conversions (RGB black in vector elements to CMYK deep black). Experts do not currently agree over which variant to prefer. As experience is gained, the majority of users are opting for the media neutral workflow, which entails considerably less effort during the design process. What remains to be seen is how fast this switch will take place.\n\nThe eighth German edition was published in August 2016 and supersedes the 2010 edition. Media Standard Print 2016 – the English translation of the new German edition – was published in February 2017. Inter alia, it covers the switch to the new standard printing conditions for offset printing that were defined in 2013 and that for the first time take the effect of optical brighteners into account and so improve production quality. It therefore lists old printing conditions or ones that are valid for the time being in parallel with the new ones. Part 7 (Proofs) of the ISO 12647 standard is treated in greater detail than previously and in October 2016 use of the CIEDE2000 colour difference formula was made obligatory for proofs. The change in colour difference formula, which offers a better description of the visual uniformity of the colour space, also changes the previous figures for aim values and tolerances. However, in practice, the room for manoeuvre remains largely the same.\n\nThe description of the standard printing conditions for the various printing methods of offset, gravure, flexo, newspaper and screen has been expanded through the addition of five typical digital printing applications.\n\nFurthermore, Media Standard Print refers to ISO 15937 and this is the first such reference to a standard that covers the key values for paper-based substrates. The standardized listing and communication of paper parameters had been neglected for many years but the standard adopted in 2014 should now be disseminated more widely and become indispensable for professional communication in printed product planning.\n\nMedia Standard print is also being produced in a new format. In response to the current prevalence of mobile end devices the 78 page PDF document has been produced in landscape format in order to fit display screens, whilst internal hypertext links simplify navigation through the document. References to the corresponding chapter of ProcessStandard Offset or its revision published in July 2016 direct the reader to more detailed information.\n\nMedia Standard Print 2016 is the first English language translation of the German Medienstandard Druck since 2006. Regrettably, the bvdm is not planning to publish an English translation of the German edition of Process Standard Offset 2012/2016, which is recognized beyond the borders of Germany and Europe. This makes the English language edition of Media Standard Print 2016 all the more important for technical communication, since it refers to the same ISO Standards.\n\nThe 2018 edition (substituted the 2016 edition in March, 2018) promptly responds to changes in the ongoing standardization process. For the first time, standards and means for special colour and multi-colour applications are described.\n\nSpecifically, the following additions have been made:\n\n"}
{"id": "43234622", "url": "https://en.wikipedia.org/wiki?curid=43234622", "title": "Methode Electronics", "text": "Methode Electronics\n\nMethode Electronics (NYSE: MEI ) is an American Multinational company headquartered in Chicago, Illinois, with Engineering, Manufacturing and Sales Operations in more than 14 locations in 10 countries. The company employs around 4,566 people worldwide.\n"}
{"id": "29816230", "url": "https://en.wikipedia.org/wiki?curid=29816230", "title": "Microbiofuel", "text": "Microbiofuel\n\nMicrobiofuels are next generation biofuels produced by microorganisms like bacteria, cyanobacteria, microalgae, fungi, etc. The term was first defined by Asen Nenov at TEDxBG event on 9 January, 2010.\n\n"}
{"id": "50815714", "url": "https://en.wikipedia.org/wiki?curid=50815714", "title": "Milène Guermont", "text": "Milène Guermont\n\nMilène Guermont (born 1981 in France) is an artist.\n\nShe has diplomas in both art and engineering. To materialize her ideas, she has developed several innovations.\n\nThe artist uses her \"Polysensual Concrete\" to make sculptures that interact (sound, light, vibration) when you touch them.\n\nGuermont creates public artworks from a few grams to several tons that respond to environments like INSTANTS (installed since June 2014 on Utah Beach) in the Atlantic Wall or like \"PHARES\" imagined as a dialogue with the Obelisk of Louxor (installed from October 2015 till April 2016 on Place de la Concorde, Paris) or A BEAT on the Eiffel Tower in February 2016.\n\nIn July 2016, her artwork \"CAUSSE\", commissioned by an eminent scientist, was installed permanently in the preservation area of the Montparnasse Cemetery in Paris. This sculpture is made of made of high-performance concrete and light.\n\nShe collaborates with people from different fields (the architect Claude Parent imagines a \"folie\" with her or the theatre director Jean Lambert-wild conceives a play with some of her artworks).\n\nHer first personal exhibition into a museum was at the National Archives of France in 2012 and her most recent one was at the Mineralogy Museum Mines ParisTech in 2016.\n\nIn 2017, Milène was selected to represent the French engineers at the World Federation of Engineering Organizations (WFEO), UNESCO's partner. Her sculpture made of Polysensual Concrete, MINI AGUA, is the artwork shown at the French Pavilion of the International Exhibition ASTANA 2017.\n\nShe receives in Brussels the artprize of NOVA XX, international competition of women artists who use hi-tech.\n\n"}
{"id": "20272", "url": "https://en.wikipedia.org/wiki?curid=20272", "title": "Minicomputer", "text": "Minicomputer\n\nA minicomputer, or colloquially mini, is a class of smaller computers that was developed in the mid-1960s and sold for much less than mainframe and mid-size computers from IBM and its direct competitors. In a 1970 survey, \"The New York Times\" suggested a consensus definition of a minicomputer as a machine costing less than (), with an input-output device such as a teleprinter and at least four thousand words of memory, that is capable of running programs in a higher level language, such as Fortran or BASIC. The class formed a distinct group with its own software architectures and operating systems. Minis were designed for control, instrumentation, human interaction, and communication switching as distinct from calculation and record keeping. Many were sold indirectly to original equipment manufacturers (OEMs) for final end use application. During the two decade lifetime of the minicomputer class (1965–1985), almost 100 companies formed and only a half dozen remained.\n\nWhen single-chip CPU microprocessors appeared, beginning with the Intel 4004 in 1971, the term \"minicomputer\" came to mean a machine that lies in the middle range of the computing spectrum, in between the smallest mainframe computers and the microcomputers. The term \"minicomputer\" is little used today; the contemporary term for this class of system is \"midrange computer\", such as the higher-end SPARC, Power Architecture and Itanium-based systems from Oracle, IBM and Hewlett-Packard.\n\nThe term \"minicomputer\" developed in the 1960s to describe the smaller computers that became possible with the use of transistors and core memory technologies, minimal instructions sets and less expensive peripherals such as the ubiquitous Teletype Model 33 ASR. They usually took up one or a few 19-inch rack cabinets, compared with the large mainframes that could fill a room.\n\nThe definition of minicomputer is vague with the consequence that there are a number of candidates for the \"first\" minicomputer. An early and highly successful minicomputer was Digital Equipment Corporation's (DEC) 12-bit PDP-8, which was built using discrete transistors and cost from upwards when launched in 1964. Later versions of the PDP-8 took advantage of small-scale integrated circuits. The important precursors of the PDP-8 include the PDP-5, LINC, the TX-0, the TX-2, and the PDP-1. DEC gave rise to a number of minicomputer companies along Massachusetts Route 128, including Data General, Wang Laboratories, Apollo Computer, and Prime Computer.\n\nMinicomputers were also known as midrange computers. They grew to have relatively high processing power and capacity. They were used in manufacturing process control, telephone switching and to control laboratory equipment. In the 1970s, they were the hardware that was used to launch the computer-aided design (CAD) industry and other similar industries where a smaller dedicated system was needed.\n\nThe 7400 series of TTL integrated circuits started appearing in minicomputers in the late 1960s. The 74181 arithmetic logic unit (ALU) was commonly used in the CPU data paths. Each 74181 had a bus width of four bits, hence the popularity of \"bit-slice\" architecture. Some scientific computers, such as the Nicolet 1080, would use the 7400 series in groups of five ICs (parallel) for their uncommon twenty bits architecture. The 7400 series offered data-selectors, multiplexers, three-state buffers, memories, etc. in dual in-line packages with one-tenth inch spacing, making major system components and architecture evident to the naked eye. Starting in the 1980s, many minicomputers used VLSI circuits.\n\nAt the launch of the MITS Altair 8800 in 1975, \"Radio Electronics\" magazine referred to the system as a \"minicomputer\", although the term microcomputer soon became usual for personal computers based on single-chip microprocessors. At the time, microcomputers were 8-bit single-user, relatively simple machines running simple program-launcher operating systems like CP/M or MS-DOS, while minis were much more powerful systems that ran full multi-user, multitasking operating systems, such as VMS and Unix, and although the classical mini was a 16-bit computer, the emerging higher performance superminis were 32-bit.\n\nThe decline of the minis happened due to the lower cost of microprocessor-based hardware, the emergence of inexpensive and easily deployable local area network systems, the emergence of the 68020, 80286 and the 80386 microprocessors, and the desire of end-users to be less reliant on inflexible minicomputer manufacturers and IT departments or \"data centers\". The result was that minicomputers and computer terminals were replaced by networked workstations, file servers and PCs in some installations, beginning in the latter half of the 1980s.\n\nDuring the 1990s, the change from minicomputers to inexpensive PC networks was cemented by the development of several versions of Unix and Unix-like systems that ran on the Intel x86 microprocessor architecture, including Solaris, Linux, FreeBSD, NetBSD and OpenBSD. Also, the Microsoft Windows series of operating systems, beginning with [Windows NT], now included server versions that supported preemptive multitasking and other features required for servers.\n\nAs microprocessors have become more powerful, the CPUs built up from multiple components – once the distinguishing feature differentiating mainframes and midrange systems from microcomputers – have become increasingly obsolete, even in the largest mainframe computers.\n\nDigital Equipment Corporation (DEC) was once the leading minicomputer manufacturer, at one time the second-largest computer company after IBM. But as the minicomputer declined in the face of generic Unix servers and Intel-based PCs, not only DEC, but almost every other minicomputer company including Data General, Prime, Computervision, Honeywell and Wang Laboratories, many based in New England (hence the end of the Massachusetts Miracle), also collapsed or merged. DEC was sold to Compaq in 1998, while Data General was acquired by EMC Corporation.\n\nToday only a few proprietary minicomputer architectures survive. The IBM System/38 operating system, which introduced many advanced concepts, lives on with IBM's AS/400. Realising the importance of the myriad lines of 'legacy code' (programs) written, 'AS' stands for 'Application System'. Great efforts were made by IBM to enable programs originally written for the System/34 and System/36 to be moved to the AS/400. The AS/400 was replaced by the iSeries, which was subsequently replaced by the System i. In 2008, the System i was replaced by the IBM Power Systems. By contrast, competing proprietary computing architectures from the early 1980s, such as DEC's VAX, Wang VS and Hewlett Packard's HP3000 have long been discontinued without a compatible upgrade path. OpenVMS runs HP Alpha and Intel IA64 (Itanium) CPU architectures.\n\nTandem Computers, which specialized in reliable large-scale computing, was acquired by Compaq, and a few years afterward the combined entity merged with Hewlett Packard. The NSK-based NonStop product line was re-ported from MIPS processors to Itanium-based processors branded as 'HP Integrity NonStop Servers'. As in the earlier migration from stack machines to MIPS microprocessors, all customer software was carried forward without source changes. Integrity NonStop continues to be HP's answer for the extreme scaling needs of its very largest customers. The NSK operating system, now termed NonStop OS, continues as the base software environment for the NonStop Servers, and has been extended to include support for Java and integration with popular development tools like Visual Studio and Eclipse.\n\nA variety of companies emerged that built turnkey systems around minicomputers with specialized software and, in many cases, custom peripherals that addressed specialized problems such as computer-aided design, computer-aided manufacturing, process control, manufacturing resource planning, and so on. Many if not most minicomputers were sold through these original equipment manufacturers and value-added resellers.\n\nSeveral pioneering computer companies first built minicomputers, such as DEC, Data General, and Hewlett-Packard (HP) (who now refers to its HP3000 minicomputers as \"servers\" rather than \"minicomputers\"). And although today's PCs and servers are clearly microcomputers physically, architecturally their CPUs and operating systems have developed largely by integrating features from minicomputers.\n\nIn the software context, the relatively simple OSs for early microcomputers were usually inspired by minicomputer OSs (such as CP/M's similarity to Digital's single user OS/8 and RT-11 and multi-user RSTS time-sharing system). Also, the multiuser OSs of today are often either inspired by, or directly descended from, minicomputer OSs. UNIX was originally a minicomputer OS, while Windows NT kernel—the foundation for all current versions of Microsoft Windows-borrowed design ideas liberally from VMS. Many of the first generation of PC programmers were educated on minicomputer systems.\n\n\n\n"}
{"id": "20257647", "url": "https://en.wikipedia.org/wiki?curid=20257647", "title": "Mining archaeology in the British Isles", "text": "Mining archaeology in the British Isles\n\nMining archaeology is a specific field well-developed in the British Isles during recent decades. A reason of ongoing interest in this field is the particular bond between regional history and the exploitation of metals. References to mines in the area exist in Strabo's works. However the first accomplished study on the topic was attempted by Oliver Davies in 1935. Other momentous researches were that of geologist John S. Jackson about mines in Ireland and Lewis, Jones in Dolaucothi goldmine in Wales, and the pioneering work of Ronald F. Tylecote. Moreover, in the 1980s and 1990s a new generation of amateurs and scientists began investigations in different locations in the British Isles, including Duncan James on the Great Orme's Head, Simon Timberlake with the Early Mines Research Group at sites in Wales and William O'Brien in Ireland.\n\nSigns of Bronze Age metal extraction have been identified from several locations in the British Isles; this has been certified with carbon-14 analysis. Oliver Davies has accomplished the most intensive archaeological investigation in central Wales at Cwmystwyth. The first investigation conducted in 1935, however in 1986 a group of scientists instituted the Early Mines Research Group and reinvestigate the Copa Hill region including Cwmystwyth. Even though lead deposits are the main concentration the first metal extracted in the area was copper. The main lead lode is at \"Comet lode\" where a large opencast was excavated. At the walls of the opencast, revealed entrances of tunnels, which were constructed to follow smaller veins. At one of them, a wooden \"pipe\" was found. Moreover, in the same area a considerable amount of dump was exposed including stone hammers and lead ores. Charcoal samples from the site give several different dates from 2000–1900 BC to 1400 BC.\n\nOther two significant sites are Parys Mountain and Nantyreira mine located in mid-Wales. Copper was the reason for their early exploitation even if Nantyreira's main lode contained predominantly lead ores. S.Timberlake and the Early Mines Research Group in 1986 explored them. The excavations had as a result the discovery of dump in both sites. Charcoal and stonehammers were found inside the tip. The C14 samples place both areas at the Early Bronze Age 2000–1500 BC.\n\nThe Great Orme mine exploitation, on the North Wales coast began in the Bronze Age and continued until the nineteenth century. According to remains, mine workings have been traced in the Bryniau, Poethion and Pyllau valley. The dolomitised limestone deposits are rich in copper which early miners must extract mostly by malachite. Because of ground composition, the extraction was sufficiently easy, this explains also the scale of the operations.\nIn 1976 Duncan James revealed in Great Orme a shaft which included a firesetting in connection with stone hammers, bone tools and rock dump. The deposit was placed by radiocarbon-dating to 1395–935 BC. Andy Lewis continued the research in the area at the late 1980s. It is believed that the operations in the location ended shortly after 1000 BC.\nExtractions techniques with visible remains are the opencasts at the surface and group of shafts and caverns underground. The underground complex system was accessible by many different openings which simultaneously used as a ventilation system for the tunnels. The tools in the site constitute mainly by pointed bone tools and stonehammers. Other stone tools revealed at the locations were stone mortars and pestles, which indicate another stage in the ores exploitation. Moreover, a unique find for British Isles were the giant hammers.\n\nEvidence for early quarrying was also discovered in Alderley Edge though industrial operations in the 19th century destroyed a big part of the earlier deposits.\n\nIreland also has many areas related with mining activities from the prehistoric period (O'Brien 2003). However, the two important mines are Mount Gabriel and Ross Island mines.\nRoss Island lies near Killarney. Inside its area they have been exposed two primitive mines. O'Brien excavate \"Danish mines\" and revealed a mine cave and a huge spoil concentration nearby thus after the excavation of the latter, another unknown mine also appeared. Furthermore, he investigates pits and dips in the bedrock, which also considered primitive. The feature that differentiates this site is the discovery of a Beaker settlement very close with metallurgical pits, hammers and rock waste. This finds in combination with an early phase in 2400 BC makes the site and the settlement very important for mining Archaeology in the British Isles.\n\nMount Gabriel located close to west Cork provides useful evidence for the exploitation of copper ore in the Early Bronze Age about 1700 BC. Through research thirty-two areas of activity were underlined. Shallow concaves and significant amount of dump with charcoal and tools are the evidences of Bronze Age copper extraction in the region. Mount Gabriel constitute until now the only locations, where primitive assemblages remained undisturbed by 19th century deeds due to the low quality of its veins.\n\nWith the beginning of the Iron Age about 700 BC operations associated with ore exploitations spread around the British Isles. A representative example of the period are Puzzlewood's surface mines. The site prospered especially in the Romano-British period and the late Middle Ages. The limonite ores represent a small part of the local Carboniferous Limestone. The archaeological remains of mining which can be detected in the area are opencasts, known as Scowles Holes. It's important to underline the discovery of habitations areas in close proximity, dated around 100–400 AD.\n\nDuring the Roman period massive veins exploitation took part in the Mendips and Dolaucothi . Further metallic lead pigs originate from Peak District in Derbyshire has been discovered but the exact position of the mines remains unknown.\n\nIt is possible that the Mendip sources were already exploited in Late Bronze Age and some evidence earthworks are associated with British Iron Age activity, but the peak of production is linked with Roman era. Even if we do not have many actual evidences about the mines, through the examination of the archaeological sites in the area is known to us that the Charterhouse Roman Town were guarded by a fort and similar conditions may occurred in Green mines also at least for a period.\n\nThough the most acquainted site is the Dolaucothi Gold Mines near Pumpsaint in Wales. The gold mines were investigated by Jones and Lewis in 1969. The mines were in use until nowadays and their utilisation is obvious towards the surface of the site but also underground. The Roman presence in the area is dated from the beginning of their establishment in Great Britain and for a period of 300 years. The remains of mine workings former than 19th century are concentrated in five areas Ogofau, Niagara, Allt Cwmhenog, Pen-lan-wen and Cwrt-y-Cillion trenches. Furthermore, in the Ogofau region a number of pits came to light. Despite the concentrations of dump and posterior workings the opencasts of Roman period are visible and well preserved. The main one had preserved a depth of 24 metres at least other two opencasts are dated in the same period the co-called \"Roman pit\" and the \"Mitchell pit\". Likewise a second location with possible Roman dated exploration is Pen-lan-wen where a group of adits was found, traces of chisels and picks were obvious at the surfaces of the ambit's walls but the evidence are tenuous.\n\nThe Middle Ages was a flourishing period for the exploitations of metal in general, a prime mover for this was the inference of monasteries in extraction of minerals. A famous archaeological site of this period is the northern Pennines at Brownhill, Cumbria, where lead ores were extracted from argentiferous lopes. The mine was under the jurisdiction of the Crown. The lead ores were obtained by opencasts that took a semi-ellipsoid shape thus they called \"bell-pits\". Evidences of medieval exploitation are preserved also at Copa hill were small parts of a leat system came to light. Further Ross Island excavations displayed a smelting site connected with a settlement nearby the local mines but the contemporary workings are untraceable. As far as tin industry concerns \"lode back pits\" at Godolphin have identified as medieval.\n\nTo shape an overall image for mines in antiquity we have to consider in mind many different factors not only the architectural remains. Social context is one of these factors. The term includes the social status of the miners, their way of life, the relationships with adjoined communities due to archaeological record, the symbolic value of the ore which was reflected also at the finished objects and in general to recreate the past society in which these operations took part. Yet in collaboration with experimental archaeology important observations have occur as far as primitive techniques of extraction and their traceable residues or ways in which mining tools were used their properties and the distinctive marks of their usages. Moreover, scientific analytical methods can submit important data about chemical composition of minerals, slag and artefacts allowing archaeologists to build correlations or identify provenance. Further the science of geology and pollen analysis can give us an image of landscape per eras. Finally documents and inscriptions as well offer valuable help for the historical periods.\n\n\n"}
{"id": "9772040", "url": "https://en.wikipedia.org/wiki?curid=9772040", "title": "Normand Roger", "text": "Normand Roger\n\nNormand Roger (born 1949 in Montreal, Quebec) is a Canadian composer, sound editor and sound designer. He is particularly known for his work as a composer of soundtracks for animated films, having composed more than 200 such works since 1970. He has also worked on the creation of music for documentaries, feature films, television dramas, children's series, commercials, and new technologies with 3D and virtual reality. He is the composer of many original soundtracks for Frédéric Back, Paul Driessen, Michaël Dudok de Wit, Caroline Leaf and Aleksandr Petrov. Thirteen of his works have been nominated for Academy Awards, of which six have won. He also notably wrote the theme for the PBS's \"Mystery!\". Roger lectures throughout the world on music and sound for animation.\n\nRoger has spent nearly 40 years creating soundtracks for the National Film Board of Canada (NFB) in his hometown of Montreal, after first being hired for its animation department at the age of 22. His extensive NFB credits include \"Every Child\" and \"The Sand Castle\", both winners of the Academy Award for Best Animated Short Film.\n\nHe is married to animation film director and producer Marcy Page, whom he met while working with on her film, \"Paradisia\".\n\n\n"}
{"id": "27121313", "url": "https://en.wikipedia.org/wiki?curid=27121313", "title": "Novero", "text": "Novero\n\nNovero is a company making Telematics products for automotive clients. Novero has customers including Audi, Bentley, BMW, Ford of Europe, Jaguar, Land Rover, Mercedes-Benz, Volkswagen, and others.\n\nFounded in 2008 by Romanian entrepreneur Razvan Olosu, via a management buyout of Nokia’s Automotive Group, Novero is headquartered in Düsseldorf, Germany with a main R&D center in Bochum and other business units in Toronto and Dabendorf.\n\nOriginally, Novero had both consumer products and automotive products in its portfolio. Since the management change in November 2013, Novero is solely focusing on the Automotive Business.\n\nIn November 2012, Novero acquired Funkwerk Dabendorf, a former company from the Funkwerk AG. Funkwerk Dabendorf was first re-branded to novero Dabendorf and later – after the corporate identity change in 2013 – simply to Novero. The Dabendorf business unit is specialized in wireless charging, antenna coupling, Near Field Communication and is well known for the Compenser technology.\n\n"}
{"id": "13359122", "url": "https://en.wikipedia.org/wiki?curid=13359122", "title": "OpenLearn", "text": "OpenLearn\n\nOpenLearn is an educational website. It is the UK's Open University's contribution to the Open educational resources (OER) project and the home of free, open learning from The Open University. The original project was part-funded by the William and Flora Hewlett Foundation.\n\nOpenLearn is a member of the OpenCourseWare Consortium (OCWC).\n\nOpenLearn dates back to 1999, when Open2.net, an Open University-BBC collaboration, gave a first home to free learning resources that the public could interact with without the need to sign up to study a university course.\n\nThe Open University launched the OpenLearn brand with the LearningSpace website in October 2006 to provide free access to extracts of educational materials generated as part of course production. The publication of such structured learning materials, designed for distance education, is unique in the field of open educational resources.\n\nLearningSpace and Open2.net came together under the same OpenLearn brand in 2010, creating a single home for all free learning from The Open University.\n\nIt also aggregates videos and audio made available via other Open University channels, such as iTunesU, YouTube and AudioBoo.\n\nSince 2014, it has also been republishing The Open University's courses from FutureLearn, providing a space where learners unwilling or unable to commit to FutureLearn's weekly learning model can follow courses to their own timetable.\n\nOpen Education materials make three contributions. They make new knowledge available to all (not just the few who can pay for it). They allow users to download, modify, translate and adapt to their culture to the material to enhance its usefulness. They provide the opportunity for people to work together to co-modify, co-produce, test and co-produce again, retesting derivative material which generates a cycle of rapid continuous improvement. Using technology Open Educational Resources aim to remove access barriers to knowledge and educational opportunities around the world.\n\nThrough the Moodle-based virtual learning environment, learners are offered over 600 structured media-rich study units, supported by a number of learning and communication tools in the Free Courses area. Personal profiles, learning journals and rating options empower learners to become self publishers and reviewers, tagging their entries to provide a means by which others can find and connect with their ideas. Knowledge mapping software enables learners to visually represent resources and the links between them, to construct arguments and frame debates. By publishing their work online, they share their own pathways through the material with other visitors to the website.\n\nThe OpenLearn website also provides a standalone experience for the learner, but is also one that can be taken apart and remixed to take on a new form. The Web 2.0 approach to an open and collaborative LearningSpace primarily for learners, is complemented by OpenLearn Create(formerly Labspace and OpenLearnWorks), an area for experimentation, where educational practitioners are encouraged to download, amend and adapt both current and archived course materials. Published under an Attribution-ShareAlike-NonCommercial Creative Commons license, the Open University media-rich materials can be reused in alternative educational settings, repurposed for a local context, translated and built upon to form a larger open repository of derivative educational materials. Collaborators are encouraged to form their own areas within the LabSpace to personalise the materials, increasing the relevance of the content for specific learning communities and to test out course ideas and develop materials based on user feedback.\n\nOpenLearn enables viral content not just through its licensing model, but also through a commitment to open technologies. The use of an open source virtual learning environment, along with the ability for people to download and upload materials in various formats (from an RSS to a print to an IMS Common Cartridge) encourages replication of the content and enables interoperability with other provider's content management systems. Innovators have already re-published OpenLearn materials in new environments by implementing a variety of freely available technologies. The materials have been replicated in offline desktop libraries to provide access for remote communities around the world. RSS feeds enable the content to be easily embedded in web based widgets and RSS readers, allowing the engagement with the content to happen away from OpenLearn.\n\nBy the end of the first phase of funding (30 April 2008), OpenLearn hosted more than five thousand hours of core OU materials and additional user generated content in the LabSpace area of the site.\n\nIn 2012, the LabSpace area was overhauled to give a better user experience and a tighter focus on collaboration with partners. The area was rebranded OpenLearn Works. The site has since been further developed and redesigned, changing its name to OpenLearn Create in 2017. \n\n"}
{"id": "3342041", "url": "https://en.wikipedia.org/wiki?curid=3342041", "title": "Open Mobile Terminal Platform", "text": "Open Mobile Terminal Platform\n\nThe Open Mobile Terminal Platform (OMTP) was a forum created by mobile network operators to discuss standards with manufacturers of mobile phones and other mobile devices. During its lifetime, the OMTP included manufacturers such as Huawei, LG Electronics, Motorola, Nokia, Samsung and Sony Ericsson.\n\nOMTP was originally set up by leading mobile operators. At the time it transitioned into the Wholesale Applications Community at the end of June 2010, there were nine full members: AT&T, Deutsche Telekom AG, KT, Orange, Smart Communications, Telecom Italia, Telefónica, Telenor and Vodafone. OMTP also had the support of two sponsors, Ericsson and Nokia.\n\nOMTP recommendations have hugely helped to standardise mobile operator terminal requirements, and its work has gone towards helping to defragment and deoptionalise operators' recommendations. OMTP’s focus was on gathering and driving mobile terminal requirements, and publishing their findings in their Recommendations. OMTP was technology neutral, with its recommendations intended for deployment across the range of technology platforms, operating systems (OS) and middleware layers.\n\nOMTP is perhaps best known for its work in the field of mobile security, but its work encompassed the full range of mobile device capabilities. OMTP published recommendations in 2007 and early 2008 on areas such as Positioning Enablers, Advanced Device Management, IMS and Mobile VoIP. Later, the Advanced Trusted Environment: OMTP TR1 and its supporting document, 'Security Threats on Embedded Consumer Devices' were released, with the endorsement of the UK Home Secretary, Jacqui Smith.\n\nOMTP also published requirements document addressing support for advanced SIM cards. This document defines also advanced profiles for Smart Card Web Server, High Speed Protocol, Mobile TV and Contactless.\n\nOMTP has also made significant progress in getting support for the use of micro-USB as a standard connector for data and power. A full list of their recommendations can be found at http://www.gsma.com/newsroom/technical-documents/omtp-documents/\n\nIn 2008, OMTP launched a new initiative called BONDI (named after the Australian beach); the initiative defined new interfaces (Javascript APIs) and a security framework (based on XACML policy description) to enable the access to mobile phone functionalities (Application Invocation, Application Settings, Camera, Communications Log, Gallery, Location, Messaging, Persistent Data, Personal Information, Phone Status, User Interaction) from browser and widget engine in a secure way. The BONDI initiative also had an open source Reference Implementation at https://web.archive.org/web/20130509121758/https://web.archive.org/web/20130509121758/http://bondi.omtp.org//. An Approved Release 1.0 of BONDI was issued in June 2009.\nAn open source project for a comprehensive BONDI SDK was started at http://bondisdk.org.\n\nIn February 2009, OMTP expanded its Local Connectivity specification (based on micro-USB) to describe requirements for a common charger and common connector to enable sharing the same battery charger through different phones. The OMTP Common Charging and Local Data Connectivity was adopted by GSM Association in the Universal Charging System (UCS) initiative. This has been further endorsed by the CTIA and the ITU. In June, 2009 the European Commission reached an agreement with several major mobile phone providers on requirements for a common External Power Supply (EPS) to be compatible with new data-enabled phones sold in the European Union. The EPS shares most of the key attributes of the UCS charger.\n\nIn June 2010, the OMTP transitioned itself into the new Wholesale Applications Community. All OMTP activities ceased at that time and were either taken over within the WAC organisation or other standards or industry associations. In turn, in July 2012 WAC itself was closed, with the OMTP standards being transferred to GSMA, and other assets and personnel transferring to Apigee.\n\n\n"}
{"id": "22804", "url": "https://en.wikipedia.org/wiki?curid=22804", "title": "Operational amplifier", "text": "Operational amplifier\n\nAn operational amplifier (often op-amp or opamp) is a DC-coupled high-gain electronic voltage amplifier with a differential input and, usually, a single-ended output. In this configuration, an op-amp produces an output potential (relative to circuit ground) that is typically hundreds of thousands of times larger than the potential difference between its input terminals.\nOperational amplifiers had their origins in analog computers, where they were used to perform mathematical operations in many linear, non-linear, and frequency-dependent circuits. \n\nThe popularity of the op-amp as a building block in analog circuits is due to its versatility. By using negative feedback, the characteristics of an op-amp circuit, its gain, input and output impedance, bandwidth etc. are determined by external components and have little dependence on temperature coefficients or engineering tolerance in the op-amp itself.\n\nOp-amps are among the most widely used electronic devices today, being used in a vast array of consumer, industrial, and scientific devices. Many standard IC op-amps cost only a few cents in moderate production volume; however, some integrated or hybrid operational amplifiers with special performance specifications may cost over in small quantities. Op-amps may be packaged as components or used as elements of more complex integrated circuits.\n\nThe op-amp is one type of differential amplifier. Other types of differential amplifier include the fully differential amplifier (similar to the op-amp, but with two outputs), the instrumentation amplifier (usually built from three op-amps), the isolation amplifier (similar to the instrumentation amplifier, but with tolerance to common-mode voltages that would destroy an ordinary op-amp), and negative-feedback amplifier (usually built from one or more op-amps and a resistive feedback network).\n\nThe amplifier's differential inputs consist of a non-inverting input (+) with voltage \"V\" and an inverting input (–) with voltage \"V\"; ideally the op-amp amplifies only the difference in voltage between the two, which is called the \"differential input voltage\". The output voltage of the op-amp \"V\" is given by the equation\nwhere \"A\" is the open-loop gain of the amplifier (the term \"open-loop\" refers to the absence of a feedback loop from the output to the input).\n\nThe magnitude of \"A\" is typically very large (100,000 or more for integrated circuit op-amps), and therefore even a quite small difference between \"V\" and \"V\" drives the amplifier output nearly to the supply voltage. Situations in which the output voltage is equal to or greater than the supply voltage are referred to as \"saturation\" of the amplifier. The magnitude of \"A\" is not well controlled by the manufacturing process, and so it is impractical to use an open-loop amplifier as a stand-alone differential amplifier.\n\nWithout negative feedback, and perhaps with positive feedback for regeneration, an op-amp acts as a comparator. If the inverting input is held at ground (0 V) directly or by a resistor \"R\", and the input voltage \"V\" applied to the non-inverting input is positive, the output will be maximum positive; if \"V\" is negative, the output will be maximum negative. Since there is no feedback from the output to either input, this is an \"open-loop\" circuit acting as a comparator.\n\nIf predictable operation is desired, negative feedback is used, by applying a portion of the output voltage to the inverting input. The \"closed-loop\" feedback greatly reduces the gain of the circuit. When negative feedback is used, the circuit's overall gain and response becomes determined mostly by the feedback network, rather than by the op-amp characteristics. If the feedback network is made of components with values small relative to the op amp's input impedance, the value of the op-amp's open-loop response \"A\" does not seriously affect the circuit's performance. The response of the op-amp circuit with its input, output, and feedback circuits to an input is characterized mathematically by a transfer function; designing an op-amp circuit to have a desired transfer function is in the realm of electrical engineering. The transfer functions are important in most applications of op-amps, such as in analog computers. High input impedance at the input terminals and low output impedance at the output terminal(s) are particularly useful features of an op-amp.\n\nIn the non-inverting amplifier on the right, the presence of negative feedback via the voltage divider \"R\", \"R\" determines the \"closed-loop gain\" \"A\" = \"V\" / \"V\". Equilibrium will be established when \"V\" is just sufficient to \"reach around and pull\" the inverting input to the same voltage as \"V\". The voltage gain of the entire circuit is thus 1 + \"R\"/\"R\". As a simple example, if \"V\" = 1 V and R = \"R\", \"V\" will be 2 V, exactly the amount required to keep \"V\" at 1 V. Because of the feedback provided by the \"R\", \"R\" network, this is a \"closed-loop\" circuit.\n\nAnother way to analyze this circuit proceeds by making the following (usually valid) assumptions:\n\nThe input signal \"V\" appears at both (+) and (−) pins, resulting in a current \"i\" through \"R\" equal to \"V\"/\"R\":\nSince Kirchhoff's current law states that the same current must leave a node as enter it, and since the impedance into the (−) pin is near infinity, we can assume practically all of the same current \"i\" flows through \"R\", creating an output voltage\nBy combining terms, we determine the closed-loop gain \"A\":\n\nAn ideal op-amp is usually considered to have the following characteristics:\n\nThese ideals can be summarized by the two \"golden rules\":\n\nThe first rule only applies in the usual case where the op-amp is used in a closed-loop design (negative feedback, where there is a signal path of some sort feeding back from the output to the inverting input). These rules are commonly used as a good first approximation for analyzing or designing op-amp circuits.\n\nNone of these ideals can be perfectly realized. A real op-amp may be modeled with non-infinite or non-zero parameters using equivalent resistors and capacitors in the op-amp model. The designer can then include these effects into the overall performance of the final circuit. Some parameters may turn out to have negligible effect on the final design while others represent actual limitations of the final performance that must be evaluated.\n\nReal op-amps differ from the ideal model in various aspects.\n\nReal operational amplifiers suffer from several non-ideal effects:\n\n\n\n\n\n\n\n\n\n\nThe op-amp gain calculated at DC does not apply at higher frequencies. Thus, for high-speed operation, more sophisticated considerations must be used in an op-amp circuit design.\n\n\n\n\n\n\n\n\n\n\nModern integrated FET or MOSFET op-amps approximate more closely the ideal op-amp than bipolar ICs when it comes to input impedance and input bias currents. Bipolars are generally better when it comes to input \"voltage\" offset, and often have lower noise. Generally, at room temperature, with a fairly large signal, and limited bandwidth, FET and MOSFET op-amps now offer better performance.\n\nSourced by many manufacturers, and in multiple similar products, an example of a bipolar transistor operational amplifier is the 741 integrated circuit designed in 1968 by David Fullagar at Fairchild Semiconductor after Bob Widlar's LM301 integrated circuit design. \nIn this discussion, we use the parameters of the Hybrid-pi model to characterize the small-signal, grounded emitter characteristics of a transistor. In this model, the current gain of a transistor is denoted \"h\", more commonly called the β.\n\nA small-scale integrated circuit, the 741 op-amp shares with most op-amps an internal structure consisting of three gain stages:\nAdditionally, it contains current mirror (outlined red) bias circuitry and compensation capacitor (30 pF).\n\nThe input stage consists of a cascaded differential amplifier (outlined in blue) followed by a current-mirror active load. This constitutes a transconductance amplifier, turning a differential voltage signal at the bases of Q1, Q2 into a current signal into the base of Q15.\n\nIt entails two cascaded transistor pairs, satisfying conflicting requirements. \nThe first stage consists of the matched NPN emitter follower pair Q1, Q2 that provide high input impedance. \nThe second is the matched PNP common-base pair Q3, Q4 that eliminates the undesirable Miller effect; it drives an active load Q7 plus matched pair Q5, Q6.\n\nThat active load is implemented as a modified Wilson current mirror; its role is to convert the (differential) input current signal to a single-ended signal without the attendant 50% losses (increasing the op-amp's open-loop gain by 3 dB). \nThus, a small-signal differential current in Q3 versus Q4 appears summed (doubled) at the base of Q15, the input of the voltage gain stage. \nThe (class-A) voltage gain stage (outlined in magenta) consists of the two NPN transistors Q15/Q19 connected in a Darlington configuration and uses the output side of current mirror Q12/Q13 as its collector (dynamic) load to achieve its high voltage gain. The output sink transistor Q20 receives its base drive from the common collectors of Q15 and Q19; the level-shifter Q16 provides base drive for the output source transistor Q14. \n\nThe transistor Q22 prevents this stage from delivering excessive current to Q20 and thus limits the output sink current.\n\nThe output stage (Q14, Q20, outlined in cyan) is a Class AB complementary-symmetry amplifier. It provides an output drive with impedance of ≈50Ω, in essence, current gain. \nTransistor Q16 (outlined in green) provides the quiescent current for the output transistors, and Q16 provides output current limiting. \nProvide appropriate quiescent current for each stage of the op-amp.\n\nThe resistor (39 kΩ) connecting the (diode-connected) Q11 and Q12, and the given supply voltage (\"V\" − \"V\"), determine the current in the current mirrors, (matched pairs) Q10/Q11 and Q12/Q13. The collector current of Q11, \"i\" × 39 kΩ = \"V\" − \"V\" − 2 \"V\". For the typical \"V\" = ±20 V, the standing current in Q11/Q12 (as well as in Q13) would be ~1 mA. A supply current for a typical 741 of about 2 mA agrees with the notion that these two bias currents dominate the quiescent supply current.\n\nTransistors Q11 and Q10 form a Widlar current mirror, with quiescent current in Q10 \"i\" such that ln(\"i\" / \"i\") = \"i\" × 5 kΩ / 28 mV, where 5 kΩ represents the emitter resistor of Q10, and 28 mV is V, the thermal voltage at room temperature. In this case \"i\" ≈ 20 μA.\n\nThe biasing circuit of this stage is set by a feedback loop that forces the collector currents of Q10 and Q9 to (nearly) match. The small difference in these currents provides the drive for the common base of Q3/Q4 (note that the base drive for input transistors Q1/Q2 is the input bias current and must be sourced externally). The summed quiescent currents of Q1/Q3 plus Q2/Q4 is mirrored from Q8 into Q9, where it is summed with the collector current in Q10, the result being applied to the bases of Q3/Q4.\n\nThe quiescent currents of Q1/Q3 (resp., Q2/Q4) \"i\" will thus be half of \"i\", of order ~10 μA. Input bias current for the base of Q1 (resp. Q2) will amount to \"i\" / β; typically ~50 nA, implying a current gain \"h\" ≈ 200 for Q1(Q2).\n\nThis feedback circuit tends to draw the common base node of Q3/Q4 to a voltage \"V\" − 2 \"V\", where \"V\" is the input common-mode voltage. At the same time, the magnitude of the quiescent current is relatively insensitive to the characteristics of the components Q1–Q4, such as \"h\", that would otherwise cause temperature dependence or part-to-part variations.\n\nTransistor Q7 drives Q5 and Q6 into conduction until their (equal) collector currents match that of Q1/Q3 and Q2/Q4. The quiescent current in Q7 is \"V\" / 50 kΩ, about 35 μA, as is the quiescent current in Q15, with its matching operating point. Thus, the quiescent currents are pairwise matched in Q1/Q2, Q3/Q4, Q5/Q6, and Q7/Q15. \n\nQuiescent currents in Q16 and Q19 are set by the current mirror Q12/Q13, which is running at ~1 mA. Through some mechanism, the collector current in Q19 tracks that standing current.\n\nIn the circuit involving Q16 (variously named rubber diode or \"V\" multiplier), the 4.5 kΩ resistor must be conducting about 100 μA, with the Q16 \"V\" roughly 700 mV. Then the \"V\" must be about 0.45 V and \"V\" at about 1.0 V. Because the Q16 collector is driven by a current source and the Q16 emitter drives into the Q19 collector current sink, the Q16 transistor establishes a voltage difference between Q14 base and Q20 base of ~1 V, regardless of the common-mode voltage of Q14/Q20 base. The standing current in Q14/Q20 will be a factor exp(100 mV / V) ≈ 36 smaller than the 1 mA quiescent current in the class A portion of the op amp. This (small) standing current in the output transistors establishes the output stage in class AB operation and reduces the crossover distortion of this stage. \nA small differential input voltage signal gives rise, through multiple stages of current amplification, to a much larger voltage signal on output.\n\nThe input stage with Q1 and Q3 is similar to an emitter-coupled pair (long-tailed pair), with Q2 and Q4 adding some degenerating impedance. The input impedance is relatively high because of the small current through Q1-Q4.\nA typical 741 op amp has a differential input impedance of about 2 MΩ. \nThe common mode input impedance is even higher, as the input stage works at an essentially constant current.\n\nA differential voltage \"V\" at the op-amp inputs (pins 3 and 2, respectively) gives rise to a small differential current in the bases of Q1 and Q2 \"i\" ≈ \"V\" / (2 \"h\" × \"h\"). \nThis differential base current causes a change in the differential collector current in each leg by \"i\" × \"h\". Introducing the transconductance of Q1, \"g\" = \"h\" / \"h\", the (small-signal) current at the base of Q15 (the input of the voltage gain stage) is \"V\" × \"g\" / 2.\n\nThis portion of the op amp cleverly changes a differential signal at the op amp inputs to a single-ended signal at the base of Q15, and in a way that avoids wastefully discarding the signal in either leg. To see how, notice that a small negative change in voltage at the inverting input (Q2 base) drives it out of conduction, and this incremental decrease in current passes directly from Q4 collector to its emitter, resulting in a decrease in base drive for Q15. On the other hand, a small positive change in voltage at the non-inverting input (Q1 base) drives this transistor into conduction, reflected in an increase in current at the collector of Q3. This current drives Q7 further into conduction, which turns on current mirror Q5/Q6. Thus, the increase in Q3 emitter current is mirrored in an increase in Q6 collector current; the increased collector currents shunts more from the collector node and results in a decrease in base drive current for Q15. Besides avoiding wasting 3 dB of gain here, this technique decreases common-mode gain and feedthrough of power supply noise. \nA current signal \"i\" at Q15's base gives rise to a current in Q19 of order \"i\" × β (the product of the \"h\" of each of Q15 and Q19, which are connected in a Darlington pair). This current signal develops a voltage at the bases of output transistors Q14/Q20 proportional to the \"h\" of the respective transistor.\n\nOutput transistors Q14 and Q20 are each configured as an emitter follower, so no voltage gain occurs there; instead, this stage provides current gain, equal to the \"h\" of Q14 (resp. Q20).\n\nThe output impedance is not zero, as it would be in an ideal op-amp, but with negative feedback it approaches zero at low frequencies.\n\nThe net open-loop small-signal voltage gain of the op amp involves the product of the current gain \"h\" of some 4 transistors. \nIn practice, the voltage gain for a typical 741-style op amp is of order 200,000, and the current gain, the ratio of input impedance (≈2−6 MΩ) to output impedance (≈50Ω) provides yet more (power) gain.\n\nThe ideal op amp has infinite common-mode rejection ratio, or zero common-mode gain.\n\nIn the present circuit, if the input voltages change in the same direction, the negative feedback makes Q3/Q4 base voltage follow (with 2\"V\" below) the input voltage variations. Now the output part (Q10) of Q10-Q11 current mirror keeps up the common current through Q9/Q8 constant in spite of varying voltage. Q3/Q4 collector currents, and accordingly the output current at the base of Q15, remain unchanged.\n\nIn the typical 741 op amp, the common-mode rejection ratio is 90 dB, implying an open-loop common-mode voltage gain of about 6.\n\nThe innovation of the Fairchild μA741 was the introduction of frequency compensation via an on-chip (monolithic) capacitor, simplifying application of the op amp by eliminating the need for external components for this function. \nThe 30 pF capacitor stabilizes the amplifier via Miller compensation and functions in a manner similar to an op-amp integrator circuit. Also known as 'dominant pole compensation' because it introduces a pole that masks (dominates) the effects of other poles into the open loop frequency response; in a 741 op amp this pole can be as low as 10 Hz (where it causes a −3 dB loss of open loop voltage gain).\n\nThis internal compensation is provided to achieve unconditional stability of the amplifier in negative feedback configurations where the feedback network is non-reactive and the closed loop gain is unity or higher. \nBy contrast, amplifiers requiring external compensation, such as the μA748, may require external compensation or closed-loop gains significantly higher than unity.\n\nThe \"offset null\" pins may be used to place external resistors (typically in the form of the two ends of a potentiometer, with the slider connected to \"V\") in parallel with the emitter resistors of Q5 and Q6, to adjust the balance of the Q5/Q6 current mirror. The potentiometer is adjusted such that the output is null (midrange) when the inputs are shorted together.\n\nThe transistors Q3, Q4 help to increase the reverse \"V\" rating: the base-emitter junctions of the NPN transistors Q1 and Q2 break down at around 7V, but the PNP transistors Q3 and Q4 have \"V\" breakdown voltages around 50 V.\n\nVariations in the quiescent current with temperature, or between parts with the same type number, are common, so crossover distortion and quiescent current may be subject to significant variation.\n\nThe output range of the amplifier is about one volt less than the supply voltage, owing in part to \"V\" of the output transistors Q14 and Q20.\n\nThe 25 Ω resistor at the Q14 emitter, along with Q17, acts to limit Q14 current to about 25 mA; otherwise, Q17 conducts no current.\n\nCurrent limiting for Q20 is performed in the voltage gain stage: Q22 senses the voltage across Q19's emitter resistor (50Ω); as it turns on, it diminishes the drive current to Q15 base.\n\nLater versions of this amplifier schematic may show a somewhat different method of output current limiting.\n\nWhile the 741 was historically used in audio and other sensitive equipment, such use is now rare because of the improved noise performance of more modern op-amps. Apart from generating noticeable hiss, 741s and other older op-amps may have poor common-mode rejection ratios and so will often introduce cable-borne mains hum and other common-mode interference, such as switch 'clicks', into sensitive equipment.\n\nThe \"741\" has come to often mean a generic op-amp IC (such as μA741, LM301, 558, LM324, TBA221 — or a more modern replacement such as the TL071). The description of the 741 output stage is qualitatively similar for many other designs (that may have quite different input stages), except:\n\nOp-amps may be classified by their construction:\nIC op-amps may be classified in many ways, including:\n\nThe use of op-amps as circuit blocks is much easier and clearer than specifying all their individual circuit elements (transistors, resistors, etc.), whether the amplifiers used are integrated or discrete circuits. In the first approximation op-amps can be used as if they were ideal differential gain blocks; at a later stage limits can be placed on the acceptable range of parameters for each op-amp.\n\nCircuit design follows the same lines for all electronic circuits. A specification is drawn up governing what the circuit is required to do, with allowable limits. For example, the gain may be required to be 100 times, with a tolerance of 5% but drift of less than 1% in a specified temperature range; the input impedance not less than one megohm; etc.\n\nA basic circuit is designed, often with the help of circuit modeling (on a computer). Specific commercially available op-amps and other components are then chosen that meet the design criteria within the specified tolerances at acceptable cost. If not all criteria can be met, the specification may need to be modified.\n\nA prototype is then built and tested; changes to meet or improve the specification, alter functionality, or reduce the cost, may be made.\n\nThat is, the op-amp is being used as a voltage comparator. Note that a device designed primarily as a comparator may be better if, for instance, speed is important or a wide range of input voltages may be found, since such devices can quickly recover from full on or full off (\"saturated\") states.\n\nA \"voltage level detector\" can be obtained if a reference voltage \"V\" is applied to one of the op-amp's inputs. This means that the op-amp is set up as a comparator to detect a positive voltage. If the voltage to be sensed, \"E\", is applied to op amp's (+) input, the result is a noninverting positive-level detector: when \"E\" is above \"V\", \"V\" equals +\"V\"; when \"E\" is below \"V\", \"V\" equals −\"V\". If \"E\" is applied to the inverting input, the circuit is an inverting positive-level detector: When \"E\" is above \"V\", \"V\" equals −\"V\".\n\nA \"zero voltage level detector\" (\"E\" = 0) can convert, for example, the output of a sine-wave from a function generator into a variable-frequency square wave. If \"E\" is a sine wave, triangular wave, or wave of any other shape that is symmetrical around zero, the zero-crossing detector's output will be square. Zero-crossing detection may also be useful in triggering TRIACs at the best time to reduce mains interference and current spikes.\n\nAnother typical configuration of op-amps is with positive feedback, which takes a fraction of the output signal back to the non-inverting input. An important application of it is the comparator with hysteresis, the Schmitt trigger. Some circuits may use \"positive\" feedback and \"negative\" feedback around the same amplifier, for example triangle-wave oscillators and active filters.\n\nBecause of the wide slew range and lack of positive feedback, the response of all the open-loop level detectors described above will be relatively slow. External overall positive feedback may be applied, but (unlike internal positive feedback that may be applied within the latter stages of a purpose-designed comparator) this markedly affects the accuracy of the zero-crossing detection point. Using a general-purpose op-amp, for example, the frequency of \"E\" for the sine to square wave converter should probably be below 100 Hz.\n\nIn a non-inverting amplifier, the output voltage changes in the same direction as the input voltage.\n\nThe gain equation for the op-amp is\n\nHowever, in this circuit \"V\" is a function of \"V\" because of the negative feedback through the \"R\" \"R\" network. \"R\" and \"R\" form a voltage divider, and as \"V\" is a high-impedance input, it does not load it appreciably. Consequently\n\nwhere\n\nSubstituting this into the gain equation, we obtain\n\nSolving for formula_9:\n\nIf formula_11 is very large, this simplifies to\n\nThe non-inverting input of the operational amplifier needs a path for DC to ground; if the signal source does not supply a DC path, or if that source requires a given load impedance, then the circuit will require another resistor from the non-inverting input to ground. When the operational amplifier's input bias currents are significant, then the DC source resistances driving the inputs should be balanced. The ideal value for the feedback resistors (to give minimal offset voltage) will be such that the two resistances in parallel roughly equal the resistance to ground at the non-inverting input pin. That ideal value assumes the bias currents are well matched, which may not be true for all op-amps.\n\nIn an inverting amplifier, the output voltage changes in an opposite direction to the input voltage.\n\nAs with the non-inverting amplifier, we start with the gain equation of the op-amp:\n\nThis time, \"V\" is a function of both \"V\" and \"V\" due to the voltage divider formed by \"R\" and \"R\". Again, the op-amp input does not apply an appreciable load, so\n\nSubstituting this into the gain equation and solving for formula_9:\n\nIf formula_11 is very large, this simplifies to\n\nA resistor is often inserted between the non-inverting input and ground (so both inputs \"see\" similar resistances), reducing the input offset voltage due to different voltage drops due to bias current, and may reduce distortion in some op-amps.\n\nA DC-blocking capacitor may be inserted in series with the input resistor when a frequency response down to DC is not needed and any DC voltage on the input is unwanted. That is, the capacitive component of the input impedance inserts a DC zero and a low-frequency pole that gives the circuit a bandpass or high-pass characteristic.\n\nThe potentials at the operational amplifier inputs remain virtually constant (near ground) in the inverting configuration. The constant operating potential typically results in distortion levels that are lower than those attainable with the non-inverting topology.\n\n\nMost single, dual and quad op-amps available have a standardized pin-out which permits one type to be substituted for another without wiring changes. A specific op-amp may be chosen for its open loop gain, bandwidth, noise performance, input impedance, power consumption, or a compromise between any of these factors.\n\n1941: A vacuum tube op-amp. An op-amp, defined as a general-purpose, DC-coupled, high gain, inverting feedback amplifier, is first found in \"Summing Amplifier\" filed by Karl D. Swartzel Jr. of Bell Labs in 1941. This design used three vacuum tubes to achieve a gain of and operated on voltage rails of . It had a single inverting input rather than differential inverting and non-inverting inputs, as are common in today's op-amps. Throughout World War II, Swartzel's design proved its value by being liberally used in the M9 artillery director designed at Bell Labs. This artillery director worked with the SCR584 radar system to achieve extraordinary hit rates (near 90%) that would not have been possible otherwise.\n\n1947: An op-amp with an explicit non-inverting input. In 1947, the operational amplifier was first formally defined and named in a paper by John R. Ragazzini of Columbia University. In this same paper a footnote mentioned an op-amp design by a student that would turn out to be quite significant. This op-amp, designed by Loebe Julie, was superior in a variety of ways. It had two major innovations. Its input stage used a long-tailed triode pair with loads matched to reduce drift in the output and, far more importantly, it was the first op-amp design to have two inputs (one inverting, the other non-inverting). The differential input made a whole range of new functionality possible, but it would not be used for a long time due to the rise of the chopper-stabilized amplifier.\n\n1949: A chopper-stabilized op-amp. In 1949, Edwin A. Goldberg designed a chopper-stabilized op-amp. This set-up uses a normal op-amp with an additional AC amplifier that goes alongside the op-amp. The chopper gets an AC signal from DC by switching between the DC voltage and ground at a fast rate (60 Hz or 400 Hz). This signal is then amplified, rectified, filtered and fed into the op-amp's non-inverting input. This vastly improved the gain of the op-amp while significantly reducing the output drift and DC offset. Unfortunately, any design that used a chopper couldn't use their non-inverting input for any other purpose. Nevertheless, the much improved characteristics of the chopper-stabilized op-amp made it the dominant way to use op-amps. Techniques that used the non-inverting input regularly would not be very popular until the 1960s when op-amp ICs started to show up in the field.\n\n1953: A commercially available op-amp. In 1953, vacuum tube op-amps became commercially available with the release of the model K2-W from George A. Philbrick Researches, Incorporated. The designation on the devices shown, GAP/R, is an acronym for the complete company name. Two nine-pin 12AX7 vacuum tubes were mounted in an octal package and had a model K2-P chopper add-on available that would effectively \"use up\" the non-inverting input. This op-amp was based on a descendant of Loebe Julie's 1947 design and, along with its successors, would start the widespread use of op-amps in industry.\n\n1961: A discrete IC op-amp. With the birth of the transistor in 1947, and the silicon transistor in 1954, the concept of ICs became a reality. The introduction of the planar process in 1959 made transistors and ICs stable enough to be commercially useful. By 1961, solid-state, discrete op-amps were being produced. These op-amps were effectively small circuit boards with packages such as edge connectors. They usually had hand-selected resistors in order to improve things such as voltage offset and drift. The P45 (1961) had a gain of 94 dB and ran on ±15 V rails. It was intended to deal with signals in the range of .\n\n1961: A varactor bridge op-amp. There have been many different directions taken in op-amp design. Varactor bridge op-amps started to be produced in the early 1960s. They were designed to have extremely small input current and are still amongst the best op-amps available in terms of common-mode rejection with the ability to correctly deal with hundreds of volts at their inputs.\n\n1962: An op-amp in a potted module. By 1962, several companies were producing modular potted packages that could be plugged into printed circuit boards. These packages were crucially important as they made the operational amplifier into a single black box which could be easily treated as a component in a larger circuit.\n\n1963: A monolithic IC op-amp. In 1963, the first monolithic IC op-amp, the μA702 designed by Bob Widlar at Fairchild Semiconductor, was released. Monolithic ICs consist of a single chip as opposed to a chip and discrete parts (a discrete IC) or multiple chips bonded and connected on a circuit board (a hybrid IC). Almost all modern op-amps are monolithic ICs; however, this first IC did not meet with much success. Issues such as an uneven supply voltage, low gain and a small dynamic range held off the dominance of monolithic op-amps until 1965 when the μA709 (also designed by Bob Widlar) was released.\n\n1968: Release of the μA741. The popularity of monolithic op-amps was further improved upon the release of the LM101 in 1967, which solved a variety of issues, and the subsequent release of the μA741 in 1968. The μA741 was extremely similar to the LM101 except that Fairchild's facilities allowed them to include a 30 pF compensation capacitor inside the chip instead of requiring external compensation. This simple difference has made the 741 \"the\" canonical op-amp and many modern amps base their pinout on the 741s. The μA741 is still in production, and has become ubiquitous in electronics—many manufacturers produce a version of this classic chip, recognizable by part numbers containing \"741\". The same part is manufactured by several companies.\n\n1970: First high-speed, low-input current FET design.\nIn the 1970s high speed, low-input current designs started to be made by using FETs. These would be largely replaced by op-amps made with MOSFETs in the 1980s. \n1972: Single sided supply op-amps being produced. A single sided supply op-amp is one where the input and output voltages can be as low as the negative power supply voltage instead of needing to be at least two volts above it. The result is that it can operate in many applications with the negative supply pin on the op-amp being connected to the signal ground, thus eliminating the need for a separate negative power supply.\n\nThe LM324 (released in 1972) was one such op-amp that came in a quad package (four separate op-amps in one package) and became an industry standard. In addition to packaging multiple op-amps in a single package, the 1970s also saw the birth of op-amps in hybrid packages. These op-amps were generally improved versions of existing monolithic op-amps. As the properties of monolithic op-amps improved, the more complex hybrid ICs were quickly relegated to systems that are required to have extremely long service lives or other specialty systems.\n\nRecent trends. Recently supply voltages in analog circuits have decreased (as they have in digital logic) and low-voltage op-amps have been introduced reflecting this. Supplies of 5 V and increasingly 3.3 V (sometimes as low as 1.8 V) are common. To maximize the signal range modern op-amps commonly have rail-to-rail output (the output signal can range from the lowest supply voltage to the highest) and sometimes rail-to-rail inputs. Recent \"boomer\" amplifiers such as the LM4871 and 8002 also have a shutdown feature, an internal power supply for biasing, and a bypass pin to connect a bypass capacitor for that power supply.\n\n\n\n\n"}
{"id": "299592", "url": "https://en.wikipedia.org/wiki?curid=299592", "title": "Optical disc drive", "text": "Optical disc drive\n\nIn computing, an optical disc drive (ODD) is a disc drive that uses laser light or electromagnetic waves within or near the visible light spectrum as part of the process of reading or writing data to or from optical discs. Some drives can only read from certain discs, but recent drives can both read and record, also called burners or writers. Compact discs, DVDs, and Blu-ray discs are common types of optical media which can be read and recorded by such drives. Optical disc drives that are no longer in production include CD-ROM drive, CD writer drive, combo (CD-RW/DVD-ROM) drive, and DVD writer drive supporting certain recordable and rewritable DVD formats (such as DVD-R(W) only, DVD+R(W) only, DVD-RAM only, and all DVD formats except DVD-R DL). , DVD writer drive supporting all existing recordable and rewritable DVD formats is the most common for desktop PCs and laptops. There are also the DVD-ROM drive, BD-ROM drive, Blu-ray Disc combo (BD-ROM/DVD±RW/CD-RW) drive, and Blu-ray Disc writer drive.\n\nOptical disc drives are an integral part of standalone appliances such as CD players, DVD players, Blu-ray disc players, DVD recorders, certain desktop video game consoles, such as Sony PlayStation 4, Microsoft Xbox One, Nintendo Wii U, and Sony PlayStation 3, and certain portable video game consoles, such as Sony PlayStation Portable. They are also very commonly used in computers to read software and consumer media distributed on disc, and to record discs for archival and data exchange purposes. Floppy disk drives, with capacity of 1.44 MB, have been made obsolete: optical media are cheap and have vastly higher capacity to handle the large files used since the days of floppy discs, and the vast majority of computers and much consumer entertainment hardware have optical writers. USB flash drives, high-capacity, small, and inexpensive, are suitable where read/write capability is required.\n\nDisc recording is restricted to storing files playable on consumer appliances (films, music, etc.), relatively small volumes of data (e.g. a standard DVD holds 4.7 gigabytes) for local use, and data for distribution, but only on a small scale; mass-producing large numbers of identical discs is cheaper and faster than individual recording.\n\nOptical discs are used to back up relatively small volumes of data, but backing up of entire hard drives, which typically contain many hundreds of gigabytes or even multiple terabytes, is less practical. Large backups are often instead made on external hard drives, as their price has dropped to a level making this viable; in professional environments magnetic tape drives are also used.\n\nThe first laser disc, demonstrated in 1972, was the \"Laservision\" 12-inch video disc. The video signal was stored as an analog format like a video cassette. The first digitally recorded optical disc was a 5-inch audio compact disc (CD) in a read-only format created by Sony and Philips in 1975.\n\nThe first erasable optical disc drives were announced in 1983, by Matsushita (Panasonic), Sony, and Kokusai Denshin Denwa (KDDI). Sony eventually released the first commercial erasable and rewritable 5.25-inch optical disc drive in 1987, with dual-sided discs capable of holding 325 MB per side.\n\nThe CD-ROM format was developed by Sony and Denon, introduced in 1984, as an extension of Compact Disc Digital Audio and adapted to hold any form of digital data. The CD-ROM format has a storage capacity of 650 MB. Also in 1984, Sony introduced a LaserDisc data storage format, with a larger data capacity of 3.28 GB. The DVD format, developed by Panasonic, Sony, and Toshiba, was released in 1995, and was capable of holding 4.7 GB per layer.\n\nThe first Blu-Ray prototype was unveiled by Sony in October 2000, and the first commercial recording device was released to market on April 10, 2003. In January 2005, TDK announced that they had developed an ultra-hard yet very thin polymer coating (\"Durabis\") for Blu-ray discs; this was a significant technical advance because better protection was desired for the consumer market to protect bare discs against scratching and damage compared to DVD. Technically Blu-ray Disc also required a thinner layer for the narrower beam and shorter wavelength 'blue' laser. The first BD-ROM players (Samsung BD-P1000) were shipped in mid-June 2006. The first Blu-ray Disc titles were released by Sony and MGM on June 20, 2006. The first mass-market Blu-ray Disc rewritable drive for the PC was the BWU-100A, released by Sony on July 18, 2006.\n\nThe most important part of an optical disc drive is an \"optical path\", placed in a \"pickup head\" (\"PUH\"), usually consisting of a semiconductor laser, a lens for focusing the laser beam, and photodiodes for detecting the light reflected from the disc's surface.\n\nInitially, CD-type lasers with a wavelength of 780 nm (within the infrared) were used. For DVDs, the wavelength was reduced to 650 nm (red color), and for Blu-ray Disc this was reduced even further to 405 nm (violet color).\n\nTwo main servomechanisms are used, the first to maintain the proper distance between lens and disc, to ensure the laser beam is focused as a small \"laser spot\" on the disc. The second servo moves the pickup head along the disc's radius, keeping the beam on the \"track\", a continuous spiral data path. Optical disc media are 'read' beginning at the inner radius to the outer edge.\n\nOn \"read only media\" (ROM), during the manufacturing process the tracks are formed by pressing a thermoplastic resin into a glass 'master' with raised 'bumps' on a flat surface, creating \"pits\" and \"lands\" in the plastic disk. Because the depth of the pits is approximately one-quarter to one-sixth of the laser's wavelength, the reflected beam's phase is shifted in relation to the incoming beam, causing mutual destructive interference and reducing the reflected beam's intensity. This is detected by photodiodes that create corresponding electrical signals.\n\nAn optical disk recorder encodes (also known as burning) data onto a recordable CD-R, DVD-R, DVD+R, or BD-R disc (called a \"blank\") by selectively heating parts of an organic dye layer with a laser. This changes the reflectivity of the dye, thereby creating marks that can be read like the pits and lands on pressed discs. For recordable discs, the process is permanent and the media can be written to only once. While the reading laser is usually not stronger than 5 mW, the writing laser is considerably more powerful. The higher the writing speed, the less time a laser has to heat a point on the media, thus its power has to increase proportionally. DVD burners' lasers often peak at about 200 mW, either in continuous wave and pulses, although some have been driven up to 400 mW before the diode fails.\n\nFor rewritable CD-RW, DVD-RW, DVD+RW, DVD-RAM, or BD-RE media, the laser is used to melt a crystalline metal alloy in the recording layer of the disc. Depending on the amount of power applied, the substance may be allowed to melt back (change the phase back) into crystalline form or left in an amorphous form, enabling marks of varying reflectivity to be created.\n\n\"Double-sided\" media may be used, but they are not easily accessed with a standard drive, as they must be physically turned over to access the data on the other side.\n\n\"Double layer\" (DL) media have two independent data layers separated by a semi-reflective layer. Both layers are accessible from the same side, but require the optics to change the laser's focus. Traditional \"single layer\" (SL) writable media are produced with a spiral groove molded in the protective polycarbonate layer (not in the data recording layer), to lead and synchronize the speed of recording head. Double-layered writable media have: a first polycarbonate layer with a (shallow) groove, a first data layer, a semi-reflective layer, a second (spacer) polycarbonate layer with another (deep) groove, and a second data layer. The first groove spiral usually starts on the inner edge and extends outwards, while the second groove starts on the outer edge and extends inwards.\n\nSome drives support Hewlett-Packard's LightScribe photothermal printing technology for labeling specially coated discs.\n\nThe rotational mechanism in an optical drive differs considerably from that of a hard disk drive's, in that the latter keeps a constant angular velocity (CAV), in other words a constant number of revolutions per minute (RPM). With CAV, a higher throughput is generally achievable at the outer disc compared to the inner.\n\nOn the other hand, optical drives were developed with an assumption of achieving a constant throughput, in CD drives initially equal to 150 KiB/s. It was a feature important for streaming audio data that always tend to require a constant bit rate. But to ensure no disc capacity was wasted, a head had to transfer data at a maximum linear rate at all times too, without slowing on the outer rim of disc. This led to optical drives—until recently—operating with a constant linear velocity (CLV). The spiral \"groove\" of the disc passed under its head at a constant speed. The implication of CLV, as opposed to CAV, is that disc angular velocity is no longer constant, and the spindle motor needed to be designed to vary its speed from between 200 RPM on the outer rim and 500 RPM on the inner.\n\nLater CD drives kept the CLV paradigm, but evolved to achieve higher rotational speeds, popularly described in multiples of a base speed. As a result, a 4× drive, for instance, would rotate at 800-2000 RPM, while transferring data steadily at 600 KiB/s, which is equal to 4 × 150 KiB/s.\n\nFor DVDs, base or 1× speed is 1.385 MB/s, equal to 1.32 MiB/s, approximately nine times faster than the CD base speed. For Blu-ray drives, base speed is 6.74 MB/s, equal to 6.43 MiB/s.\n\nBecause keeping a constant transfer rate for the whole disc is not so important in most contemporary CD uses, a pure CLV approach had to be abandoned to keep the rotational speed of the disc safely low while maximizing data rate. Some drives work in a partial CLV (PCLV) scheme, by switching from CLV to CAV only when a rotational limit is reached. But switching to CAV requires considerable changes in hardware design, so instead most drives use the zoned constant linear velocity (Z-CLV) scheme. This divides the disc into several zones, each having its own constant linear velocity. A Z-CLV recorder rated at \"52×\", for example, would write at 20× on the innermost zone and then progressively increase the speed in several discrete steps up to 52× at the outer rim. Without higher rotational speeds, increased read performance may be attainable by simultaneously reading more than one point of a data groove, but drives with such mechanisms are more expensive, less compatible, and very uncommon.\n\nBoth DVDs and CDs have been known to explode when damaged or spun at excessive speed. This imposes a constraint on the maximum speed (56× for CDs or around 18× in the case of DVDs) at which drives can operate.\n\nCurrent optical drives use either a \"tray-loading\" mechanism, where the disc is loaded onto a motorized or manually operated tray, or a \"slot-loading\" mechanism, where the disc is slid into a slot and drawn in by motorized rollers. With both types of mechanism, if a CD or DVD is left in the drive after the computer is turned off, the disc cannot be ejected using the normal eject mechanism of the drive. However, tray-loading drives account for this situation by providing a small hole where one can insert a straightened paperclip to manually open the drive tray to retrieve the disc. Slot-loading optical disc drives have the disadvantages that they cannot usually accept the smaller 80 mm discs (unless 80 mm optical disc adapter is used) or any non-standard sizes, usually have no emergency eject hole or eject button, and therefore have to be disassembled if the optical disc cannot be ejected normally. However, the Nintendo Wii, because of backward compatibility with Nintendo GameCube games, and PlayStation 3 video game consoles are able to load standard size DVDs and 80 mm discs in the same slot-loading drive.\n\nA small number of drive models, mostly compact portable units, have a \"top-loading\" mechanism where the drive lid is opened upwards and the disc is placed directly onto the spindle (for example, all PlayStation One consoles, portable CD players, and some standalone CD recorders all feature top-loading drives). These sometimes have the advantage of using spring-loaded ball bearings to hold the disc in place, minimizing damage to the disc if the drive is moved while it is spun up.\n\nSome early CD-ROM drives used a mechanism where CDs had to be inserted into special cartridges or caddies, somewhat similar in appearance to a 3.5\" floppy diskette. This was intended to protect the disc from accidental damage by enclosing it in a tougher plastic casing, but did not gain wide acceptance due to the additional cost and compatibility concerns—such drives would also inconveniently require \"bare\" discs to be manually inserted into an openable caddy before use. Ultra Density Optical and Universal Media Disc use optical disc cartridges.\n\nThere were also some early CD-ROM drives for desktop PCs in which its tray-loading mechanism will eject slightly and user has to pull out the tray manually to load CD, similar to the tray ejecting method used in internal optical disc drives of modern laptops and modern external slim portable optical disc drives. Like the top-loading mechanism, they have spring-loaded ball bearings on the spindle.\n\nMost internal drives for personal computers, servers and workstations are designed to fit in a standard 5.25\" drive bay and connect to their host via an ATA or SATA interface. Additionally, there may be digital and analog outputs for audio. The outputs may be connected via a header cable to the sound card or the motherboard. At one time, computer software resembling CD players controlled playback of the CD. Today the information is extracted from the disc as data, to be played back or converted to other file formats.\n\nExternal drives usually have USB or FireWire interfaces. Some portable versions for laptops power themselves from batteries or directly from their interface bus.\n\nDrives with SCSI interface were made, but they are less common and tend to be more expensive, because of the cost of their interface chipsets, more complex SCSI connectors, and small volume of sales.\n\nWhen the optical disc drive was first developed, it was not easy to add to computer systems. Some computers such as the IBM PS/2 were standardizing on the 3.5\" floppy and 3.5\" hard disk, and did not include a place for a large internal device. Also IBM PCs and clones at first only included a single (parallel) ATA drive interface, which by the time the CDROM was introduced, was already being used to support two hard drives. Early laptops simply had no built-in high-speed interface for supporting an external storage device.\n\nThis was solved through several techniques:\n\nThe optical drives in the photos are shown right side up; the disc would sit on top of them. The laser and optical system scans the underside of the disc.\n\nWith reference to the top photo, just to the right of image center is the disc motor, a metal cylinder, with a gray centering hub and black rubber drive ring on top. There is a disc-shaped round clamp, loosely held inside the cover and free to rotate; it's not in the photo. After the disc tray stops moving inward, as the motor and its attached parts rise, a magnet near the top of the rotating assembly contacts and strongly attracts the clamp to hold and center the disc. This motor is an \"outrunner\"-style brushless DC motor which has an external rotor – every visible part of it spins.\n\nTwo parallel guide rods that run between upper left and lower right in the photo carry the \"sled\", the moving optical read-write head. As shown, this \"sled\" is close to, or at the position where it reads or writes at the edge of the disc. To move the \"sled\" during continuous read or write operations, a stepper motor rotates a leadscrew to move the \"sled\" throughout its total travel range. The motor, itself, is the short gray cylinder just to the left of the most-distant shock mount; its shaft is parallel to the support rods. The leadscrew is the rod with evenly-spaced darker details; these are the helical grooves that engage a pin on the \"sled\".\n\nIn contrast, the mechanism shown in the second photo, which comes from a cheaply made DVD player, uses less accurate and less efficient brushed DC motors to both move the sled and spin the disc. Some older drives use a DC motor to move the sled, but also have a magnetic rotary encoder to keep track of the position. Most drives in computers use stepper motors.\n\nThe gray metal chassis is shock-mounted at its four corners to reduce sensitivity to external shocks, and to reduce drive noise from residual imbalance when running fast. The soft shock mount grommets are just below the brass-colored screws at the four corners (the left one is obscured).\n\nIn the third photo, the components under the cover of the lens mechanism are visible. The two permanent magnets on either side of the lens holder as well as the coils that move the lens can be seen. This allows the lens to be moved up, down, forwards, and backwards to stabilize the focus of the beam.\n\nIn the fourth photo, the inside of the optics package can be seen. Note that since this is a CD-ROM drive, there is only one laser, which is the black component mounted to the bottom left of the assembly. Just above the laser are the first focusing lens and prism that direct the beam at the disc. The tall, thin object in the center is a half-silvered mirror that splits the laser beam in multiple directions. To the bottom right of the mirror is the main photodiode that senses the beam reflected off the disc. Above the main photodiode is a second photodiode that is used to sense and regulate the power of the laser.\n\nThe irregular orange material is flexible etched copper foil supported by thin sheet plastic; these are \"flexible printed circuits\" that connect everything to the electronics (which is not shown).\n\nMost optical drives are backward compatible with their ancestors up to CD, although this is not required by standards.\n\nCompared to a CD's 1.2 mm layer of polycarbonate, a DVD's laser beam only has to penetrate 0.6 mm in order to reach the recording surface. This allows a DVD drive to focus the beam on a smaller spot size and to read smaller pits. DVD lens supports a different focus for CD or DVD media with same laser. With the newer Blu-ray disc drives, the laser only has to penetrate 0.1 mm of material. Thus the optical assembly would normally have to have an even greater focus range. In practice, the Blu-ray optical system is separate from the DVD/CD system.\n\nDuring the times of CD writer drives, they are often marked with three different speed ratings. In these cases, the first speed is for write-once (R) operations, the second speed for re-write (RW) operations, and the last speed for read-only (ROM) operations. For example, a 40×/16×/48× CD writer drive is capable of writing to CD-R media at speed of 40× (6,000 KB/s), writing to CD-RW media at speed of 16× (2,400 KB/s), and reading from a CD-ROM media at speed of 48× (7,200 KB/s).\n\nDuring the times of combo (CD-RW/DVD-ROM) drives, an additional speed rating (e.g. the 16× in 52×/32×/52×/16×) is designated for DVD-ROM media reading operations.\n\nFor DVD writer drives, Blu-ray disc combo drives, and Blu-ray disc writer drives, the writing and reading speed of their respective optical media are specified in its retail box, user's manual, or bundled brochures or pamphlets.\n\nIn the late 1990s, \"buffer underruns\" became a very common problem as high-speed CD recorders began to appear in home and office computers, which—for a variety of reasons—often could not muster the I/O performance to keep the data stream to the recorder steadily fed. The recorder, should it run short, would be forced to halt the recording process, leaving a truncated track that usually renders the disc useless.\n\nIn response, manufacturers of CD recorders began shipping drives with \"buffer underrun protection\" (under various trade names, such as Sanyo's \"BURN-Proof\", Ricoh's \"JustLink\" and Yamaha's \"Lossless Link\"). These can suspend and resume the recording process in such a way that the gap the stoppage produces can be dealt with by the error-correcting logic built into CD players and CD-ROM drives. The first of these drives were rated at 12× and 16×.\n\nWhile drives are burning DVD+R, DVD+RW and all Blu-ray formats, they do not require any such error correcting recovery as the recorder is able to place the new data exactly on the end of the suspended write effectively producing a continuous track (this is what the DVD+ technology achieved). Although later interfaces were able to stream data at the required speed, many drives now write in a 'zoned constant linear velocity'. This means that the drive has to temporarily suspend the write operation while it changes speed and then recommence it once the new speed is attained. This is handled in the same manner as a buffer underrun.\n\nThe internal buffer of optical disc writer drives is: 8 MiB or 4 MiB when recording BD-R, BD-R DL, BD-RE, or BD-RE DL media; 2 MiB when recording DVD-R, DVD-RW, DVD-R DL, DVD+R, DVD+RW, DVD+RW DL, DVD-RAM, CD-R, or CD-RW media.\n\nCD recording on personal computers was originally a batch-oriented task in that it required specialised authoring software to create an \"image\" of the data to record, and to record it to disc in the one session. This was acceptable for archival purposes, but limited the general convenience of CD-R and CD-RW discs as a removable storage medium.\n\nPacket writing is a scheme in which the recorder writes incrementally to disc in short bursts, or packets. Sequential packet writing fills the disc with packets from bottom up. To make it readable in CD-ROM and DVD-ROM drives, the disc can be \"closed\" at any time by writing a final table-of-contents to the start of the disc; thereafter, the disc cannot be packet-written any further. Packet writing, together with support from the operating system and a file system like UDF, can be used to mimic random write-access as in media like flash memory and magnetic disks.\n\nFixed-length packet writing (on CD-RW and DVD-RW media) divides up the disc into padded, fixed-size packets. The padding reduces the capacity of the disc, but allows the recorder to start and stop recording on an individual packet without affecting its neighbours. These resemble the block-writable access offered by magnetic media closely enough that many conventional file systems will work as-is. Such discs, however, are not readable in most CD-ROM and DVD-ROM drives or on most operating systems without additional third-party drivers. The division into packets is not as reliable as it may seem as CD-R(W) and DVD-R(W) drives can only locate data to within a data block. Although generous gaps (the padding referred to above) are left between blocks, the drive nevertheless can occasionally miss and either destroy some existing data or even render the disc unreadable.\n\nThe DVD+RW disc format eliminates this unreliability by embedding more accurate timing hints in the data groove of the disc and allowing individual data blocks (or even bytes) to be replaced without affecting backward compatibility (a feature dubbed \"lossless linking\"). The format itself was designed to deal with discontinuous recording because it was expected to be widely used in digital video recorders. Many such DVRs use variable-rate video compression schemes which require them to record in short bursts; some allow simultaneous playback and recording by alternating quickly between recording to the tail of the disc whilst reading from elsewhere. The Blu-ray disc system also encompasses this technology.\n\nMount Rainier aims to make packet-written CD-RW and DVD+RW discs as convenient to use as that of removable magnetic media by having the firmware format new discs in the background and manage media defects (by automatically mapping parts of the disc which have been worn out by erase cycles to reserve space elsewhere on the disc). As of February 2007, support for Mount Rainier is natively supported in Windows Vista. All previous versions of Windows require a third-party solution, as does Mac OS X.\n\nOwing to pressure from the music industry, as represented by the IFPI and RIAA, Philips developed the \"Recorder Identification Code\" (RID) to allow media to be uniquely associated with the recorder that has written it. This standard is contained in the Rainbow Books. The RID-Code consists of a supplier code (e.g. \"PHI\" for Philips), a model number and the unique ID of the recorder. Quoting Philips, the RID \"enables a trace for each disc back to the exact machine on which it was made using coded information in the recording itself. The use of the RID code is mandatory.\"\n\nAlthough the RID was introduced for music and video industry purposes, the RID is included on every disc written by every drive, including data and backup discs. The value of the RID is questionable as it is (currently) impossible to locate any individual recorder due to there being no database.\n\nThe Source IDentification Code (SID) is an eight character supplier code that is placed on optical discs by the manufacturer. The SID identifies not only manufacturer, but also the individual factory and machine that produced the disc.\n\nAccording to Phillips, the administrator of the SID codes, the SID code provides an optical disc production facility with the means to identify all discs mastered or replicated in its plant, including the specific Laser Beam Recorder (LBR) signal processor or mould that produced a particular stamper or disc.\n\nThe standard use of RID and SID mean that each disc written contains a record of the machine that produced a disc (the SID), and which drive wrote it (the RID). This combined knowledge may be very useful to law enforcement, to investigative agencies, and to private or corporate investigators.\n\n"}
{"id": "41759128", "url": "https://en.wikipedia.org/wiki?curid=41759128", "title": "PSSC Labs", "text": "PSSC Labs\n\nPSSC Labs is a California-based company that provides supercomputing solutions in the United States and internationally. Its products include \"high-performance\" servers, clusters, workstations, and RAID storage systems for scientific research, government and military, entertainment content creators, developers, and private clouds. The company has implemented clustering software from NASA Goddard's Beowulf project in its supercomputers designed for bioinformatics, medical imaging, computational chemistry and other scientific applications.\n\nPSSC Labs was founded in 1984 by Larry Lesser. In 1998, it manufactured the Aeneas Supercomputer for Dr. Herbert Hamber of the University of California, Irvine (the physics and astronomy department); it was based on Linux and had a maximum speed of 20.1 Gigaflops.\n\nIn 2001, the company developed CBeST, software packages, utilities and custom scripts used to ease the cluster administration process.\n\nIn 2003 the company released the third version of its cluster management software with support for 32-bit and 64-bit AMD and Intel processors, Linux kernel and other open source tools.\n\nIn 2005, PSSC Labs demonstrated its new water-cooling technology for high-performance computers at the ACM/IEEE Supercomputing Conference in Seattle, Washington.\n\nIn 2007 the company focused on supercomputer development for life sciences researchers and announced its technological solution for full-genome data analysis, including assembly, read mapping, and analysis of large amounts of high-throughput DNA and RNA sequencing data.\n\nIn 2008 PSSC Labs designed the Powerserve Quattro I/A 4000 supercomputer for genome sequencing. In 2013 it released CloudOOP Server Platform for Big Data Analytics / Hadoop Server which offers up to 50TB of storage space in just 1RU.\n\nThe company Joined Cloudera Partner Program the following year and certified the CloudOOP 12000 in 2014 which is compatible with Cloudera Enterprise 5. In the same year MapR started using CloudOOP 12000 platform for record setting time series data base ingestion rate and the company Joined Hortonworks Partner Program.\n\nIn 2015 the company was CloudOOP 12000 certified which is Comaptible with Hortonworks HDP 2.2.\n"}
{"id": "40978256", "url": "https://en.wikipedia.org/wiki?curid=40978256", "title": "Petroleum microbiology", "text": "Petroleum microbiology\n\nPetroleum microbiology is a branch of microbiology that deals with the study of microorganisms that can metabolize or alter crude or refined petroleum products. These microorganisms, also called hydrocarbonoclastic microorganisms, can degrade hydrocarbons and, include a wide distribution of bacteria, methanogenic archaea, and some fungi. Not all hydrocarbonoclasic microbes depend on hydrocarbons to survive, but instead may use petroleum products as alternative carbon and energy sources. Interest in this field is growing due to the increasing role of bioremediation in oil spill cleanup.\n\n'Bioremediation' of oil contaminated soils, marine waters and oily sludges \"in situ\" is a feasible process as hydrocarbon degrading microorganisms are ubiquitous and are able to degrade most compounds in petroleum oil. In the simplest case, indigenous microbial communities can degrade the petroleum where the spill occurs. In more complicated cases, various methods of adding nutrients, air, or exogenous microorganisms to the contaminated site can be applied. For example, bioreactors involve the application of both natural and additional microorganisms in controlled growth conditions that yields high biodegradation rates and can be used with a wide range of media.\n\nCrude oils are composed of an array of chemical compounds, minor constituents, and trace metals. Making up 50-98% of these petroleum products are hydrocarbons with saturated, unsaturated, or aromatic structures which influence their biodegradability by hydronocarbonclasts. The rate of uptake and biodegradation by these hydrocarbon-oxidizing microbes not only depend on the chemical structure of the substrates, but is limited by biotic and abiotic factors such as temperature, salinity, and nutrient availability in the environment.\n\nA model microorganism studied for its role in bioremediation of oil-spill sites and hydrocarbon catabolism is the alpha-proteobacteria Alcanivorax, which degrades aliphatic alkanes through various metabolic activities.\nAlcanivorax borkumensis utilizes linear hydrocarbon chains in petroleum as its primary energy source under aerobic conditions. When further supplied with sufficient limiting nutrients such as nitrogen and phosphor, it grows and produces surfactant glucolipids to help reduce surface water tension and enhance hydrocarbon uptake.[5] For this reason, nitrates and phosphates are often commercially added to oil-spill sites to engage quiescent populations of A. borkumensis, allowing them to quickly outcompete other microbial populations and become the dominant species in the oil-infested environment.\n\nThe addition of rate-limiting nutrients promotes the microbe’s biodegrading pathways, including upregulation of genes encoding multiple alkane hydroxylases that oxidize various lengths of linear alkanes. These enzymes essentially remove the problematic hydrocarbon constituents of petroleum oil while A. borkumensis simutaneously increases synthesis of anionic glucoproteins, which are used to emulsify hydrocarbons in the environment and increase their bioavailability. The presence of crude oil along with appropriate levels of nitrogen and phosphor catalyzes the removal of petroleum either by mechanisms that enhance the efficiency of substrate uptake or by direct biodegradation of aliphatic chains.\n\nTwo well-known oil spills exemplify large scale marine bioremediation applications:\n\nIn 1989, the Exxon Valdez ran aground, spilling 41.6 million liters of crude oil, and launching one of the first major bioremediation efforts for an oil spill. Cleanup of Alaskan shorelines relied in part on fertilizer application to augment bacterial growth.\n\nIn 2010, the BP Deepwater Horizon oil spill released 779 million liters of oil into the Gulf of Mexico. This was the largest oil spill of all time and indigenous petroleum microorganisms played a major role in petroleum degradation and cleanup.\n\nThese are microbial-synthesized surface-active substances that allow for more efficient microbial biodegradation of hydrocarbons in bioremediation processes. There are two ways by which biosurfactants are involved in bioremediation. (1) Increase the surface area of hydrophobic water-insoluble substrates. Growth of microbes on hydrocarbons can be limited by available surface area of the water-oil interface. Emulsifiers produced by microbes can break up oil into smaller droplets, effectively increasing the available surface area. (2) Increase the bioavailability of hydrophobic water-insoluble substrates. Biosurfactants can enhance the availability of bound substrates by desorbing them from surfaces (e.g. soil) or by increasing their apparent solubility. Some biosurfactants have low critical micelle concentrations (CMCs), a property which increases the apparent solubility of hydrocarbons by sequestering hydrophobic molecules into the centres of micelles.\n\nMicrobial enhanced oil recovery (MEOR) is a technology in which microbial environments are manipulated to enhance oil recovery. Nutrients are injected \"in situ\" into porous media and indigenous or added microbes promote growth and/or generate products that mobilize oil into producing wells. Alternatively, oil-mobilizing products can be produced by fermentation and injected into the reservoir. Various products and microorganisms are useful in these applications and each will yield different results. The two general strategies for enhancing oil recovery are altering the surface properties of the interface and using bioclogging to change the flow behavior. Biomass, biosurfactants, biopolymers, solvents, acids, and gases are some of the products that are added to oil reservoirs to enhance recovery.\nOther resources for this application:\n\nMicrobial biosensors identify and quantify target compounds of interest through interactions with the microbes. For example, bacteria may be used to identify a pollutant by monitoring their response to the specific chemical. The biosensor system may simply use bacterial growth as a pollutant indicator, or rely on genetic assays wherein a reporter gene is induced by the chemical.\n\nMany analytical techniques require expensive treatment of soil samples and/or expensive equipment to detect the presence of pollutants. Bacterial biosensor systems offer the potential for cheap, robust detection systems that are selective and highly sensitive. One developed system uses \"Pseudomonas fluorescens\" HK44 to quantitatively assay for naphthalene using bioluminescence.\n\nOften in the process of degrading a pollutant, a microbe can create intermediates or byproducts that are also harmful, sometimes even more harmful than the original substrate. For example, some microbes produce hydrogen sulfide as a byproduct in the degradation of certain petroleum hydrocarbons and if those gases are not detoxified before escaping the system, they can be released into the atmosphere.\n\nThe pathways of degradation of different petroleum products vary depending on the substrate and the microorganism (i.e. aerobic/anaerobic). Specific degradation pathways of many hydrocarbon compounds can be found on the University of Minnesota Biocatalysis/Biodegradation Database.\n\n"}
{"id": "30366442", "url": "https://en.wikipedia.org/wiki?curid=30366442", "title": "Pharmaceutical technician", "text": "Pharmaceutical technician\n\nPharmaceutical Technician or Pharmaceutical Research Technician or Drug Technician is a job title for a laboratory assistant or research assistant employed in the pharmaceutical industry under the direct supervision of a physician, veterinarian, or scientist involved in the research and development of new or existing medications. In most cases, job responsibilities include supervising ongoing experiments, recording laboratory results, keeping records, testing for various compounds, and maintaining laboratory cleanliness. More responsibilities are typically given as the pharmaceutical technician gains experience in laboratory techniques and proper research methodology.\n\nMost pharmaceutical technicians have completed 2 years at a college or technical institute. Additional training in laboratory technique may be on-the-job. Some states in the United States offer 1 year training programs for pharmaceutical research technicians. In addition, some pharmaceutical technicians may be students majoring in pharmacy or biological sciences assisting research professors in their work.\n\n"}
{"id": "1324902", "url": "https://en.wikipedia.org/wiki?curid=1324902", "title": "Porsgrund", "text": "Porsgrund\n\nPorsgrund Porcelain Factory (\"Porsgrunds Porselænsfabrik\", abbreviated PP) is a porcelain flatware company located at Porsgrunn in Telemark county, Norway. \n\nThe company's production plant is a popular tourist attraction. The company was founded by Johan Jeremiassen in 1885 and has produced designs by Norwegian artists such as Ferdinand Finne, Theodor Kittelsen, Frans Widerberg and Odd Nerdrum. \n\nSince 1996 the factory has been owned by the Atle Brynestad company CG Holding AS. In contrast to its prosperous history, Porsgrund has since experienced a financial decline. After years of uncertain future, adjustments have been made to increase cost efficiency, by considerable restructuring to the production and sales processes.\n\n\nPorcelain manufacturing companies in Europe\n"}
{"id": "7420112", "url": "https://en.wikipedia.org/wiki?curid=7420112", "title": "Portal of the Folded Wings Shrine to Aviation", "text": "Portal of the Folded Wings Shrine to Aviation\n\nThe Portal of the Folded Wings Shrine to Aviation is in Los Angeles, California. The shrine is a structure of marble, mosaic, and sculpted figures and is the burial site for fifteen pioneers of aviation. It was built in 1924 as the entrance to Pierce Brothers Valhalla Memorial Park Cemetery. Aviation enthusiast James Gillette was impressed by the rotunda's close proximity to the airport and Lockheed Aircraft Company. He conceived a plan to use the structure as a shrine to aviation and worked to that end for two decades. It was dedicated in 1953 by aviation enthusiasts who wanted a final resting place for pilots, mechanics, and other pioneers of flight.\nDedicated to the honored dead of American aviation on the 50th anniversary of powered flight, December 17, 1953, by Lieutenant General Ira C. Eaker USAF (retired). Beneath the memorial tablets in this sacred portal rest the cremated remains of famous flyers who contributed so much to the history and development of aviation. The bronze plaques upon the marble walls memorialize beloved Americans who devoted their lives to the advancement of the air age. Administered under the auspices of the Brookins–Lahm–Wright Aeronautical Foundation, this shrine stands as a lasting tribute.\nOn May 27, 1996, it was rededicated by Dr. Tom Crouch, Chairman of the Aeronautics Department at the National Air and Space Museum of the Smithsonian Institution.\n\n\n\"Burbank Aviation Museum\" was presented on Sundays.\n"}
{"id": "1551497", "url": "https://en.wikipedia.org/wiki?curid=1551497", "title": "Pyro Studios", "text": "Pyro Studios\n\nPyro Mobile is a video game developer based in Madrid, Spain, established in 2012 as a merger between Play Wireless and Pyro Studios, most known for its real-time tactics games series, \"Commandos\".\n\nPyro Studios was founded in 1996 with the purpose of developing quality video games. The result of this commitment was the development of \"\", which was released in 1998. The success of this title led to the release of a disk containing new missions entitled \"\".\n\nIn October 2001, the Microsoft Windows version of \"\" was launched, followed by its release on Microsoft Xbox and Sony PlayStation 2, in September 2002. \"\" was released in October 2003. In total, the \"Commandos\" series has sold more than 5 million copies worldwide.\n\n\"Praetorians\", a 3D strategy game for Windows set at the time of Julius Caesar's campaigns was released in February 2003.\n\n\"Imperial Glory\" was released at the beginning of 2005 and its latest offering, \"\" released during the first months of 2006, is far more similar to the \"Medal of Honor\" or \"Call of Duty\" games than to earlier entries of the series. The game was heavily criticized and sold poorly; this led to the split with the publisher Eidos.\n\nIn late 2008, the studio cancelled an Xbox 360 and PS3 game named \"Cops\", laying off 30 employees. For its sister company's film \"Planet 51\", Pyro developed the console version of the game, released in November 2009.\n\nIn 2012, Pyro Studios merged with Play Wireless, establishing Pyro Mobile, a company to develop applications for smartphones, tablets and social media. Its first mobile game, \"The Moleys\", was released in December 2012.\n\n"}
{"id": "56039176", "url": "https://en.wikipedia.org/wiki?curid=56039176", "title": "Science and technology of the Yuan dynasty", "text": "Science and technology of the Yuan dynasty\n\nDuring the Mongol-ruled Yuan dynasty (1271–1368), many scientific and technological advancements were made in areas such as mathematics, medicine, printing technology, and gunpowder warfare.\n\nAdvances in polynomial algebra were made by mathematicians during the Yuan era. The mathematician Zhu Shijie (1249–1314) solved simultaneous equations with up to four unknowns using a rectangular array of coefficients, equivalent to modern matrices. Zhu used a method of elimination to reduce the simultaneous equations to a single equation with only one unknown. His method is described in the \"Jade Mirror of the Four Unknowns\", written in 1303. The opening pages contain a diagram of Pascal's triangle. The summation of a finite arithmetic series is also covered in the book.\n\nGuo Shoujing applied mathematics to the construction of calendars. He was one of the first mathematicians in China to work on spherical trigonometry. Gou derived a cubic interpolation formula for his astronomical calculations. His calender, the Shoushi Li (授時暦) or \"Calendar for Fixing the Seasons\", was disseminated in 1281 as the official calendar of the Yuan dynasty. The calendar may have been influenced solely by the work of Song dynasty astronomer Shen Kuo or possibly by the work of Arab astronomers. There are no explicit signs of Muslim influences in the Shoushi calendar, but Mongol rulers were known to be interested in Muslim calendars. Mathematical knowledge from the Middle East was introduced to China under the Mongols, and Muslim astronomers brought Arabic numerals to China in the 13th century.\n\nThe physicians of the Yuan court came from diverse cultures. Healers were divided into non-Mongol physicians called \"otachi\" and traditional Mongol shamans. The Mongols characterized \"otachi\" doctors by their use of herbal remedies, which was distinguished from the spiritual cures of Mongol shamanism. Physicians received official support from the Yuan government and were given special legal privileges. Kublai created the Imperial Academy of Medicine to manage medical treatises and the education of new doctors. Confucian scholars were attracted to the medical profession because it ensured a high income and medical ethics were compatible with Confucian virtues. \n\nThe Chinese medical tradition of the Yuan had \"Four Great Schools\" that the Yuan inherited from the Jin dynasty. All four schools were based on the same intellectual foundation, but advocated different theoretical approaches toward medicine. Under the Mongols, the practice of Chinese medicine spread to other parts of the empire. Chinese physicians were brought along military campaigns by the Mongols as they expanded towards the west. Chinese medical techniques such as acupuncture, moxibustion, pulse diagnosis, and various herbal drugs and elixirs were transmitted westward to the Middle East and the rest of the empire. Several medical advances were made in the Yuan period. The physician Wei Yilin (1277–1347) invented a suspension method for reducing dislocated joints, which he performed using anesthetics. The Mongol physician Hu Sihui described the importance of a healthy diet in a 1330 medical treatise. \n\nWestern medicine was also practiced in China by the Nestorian Christians of the Yuan court, where it was sometimes labeled as \"huihui\" or Muslim medicine. The Nestorian physician Jesus the Interpreter founded the Office of Western Medicine in 1263 during the reign of Kublai. Huihui doctors staffed at two imperial hospitals were responsible for treating the imperial family and members of the court. Chinese physicians opposed Western medicine because its humoral system contradicted the yin-yang and wuxing philosophy underlying traditional Chinese medicine. No Chinese translation of Western medical works is known, but it is possible that the Chinese had access to Avicenna's \"The Canon of Medicine\".\n\nThe Mongol rulers patronized the Yuan printing industry. Chinese printing technology was transferred to the Mongols through Uighur and Tibetan intermediaries. Some Yuan documents such as Wang Zhen's \"Nong Shu\" were printed with earthenware movable type, a technology invented in the 12th century. However, most published works were still produced through traditional block printing techniques. The publication of a Taoist text inscribed with the name of Töregene Khatun, Ögedei's wife, is one of the first printed works sponsored by the Mongols. In 1273, the Mongols created the Imperial Library Directorate, a government-sponsored printing office. The Yuan government established centers for printing throughout China. Local schools and government agencies were funded to support the publishing of books. \n\nPrivate printing businesses also flourished under the Yuan. They published a diverse range of works, and printed educational, literary, medical, religious, and historical texts. The volume of printed materials was vast. In 1312, 1,000 copies of a Buddhist text commented by Cosgi Odsir were printed just within Beijing. By 1328, annual sales of printed calendars and almanacs reached over three million in the Yuan dynasty. \nOne of the more notable applications of printing technology was the \"chao\", the paper money of the Yuan. Chao were made from the bark of mulberry trees. The Yuan government used woodblocks to print paper money, but switched to bronze plates in 1275. The Mongols experimented with establishing the Chinese-style paper monetary system in Mongol-controlled territories outside of China. The Yuan minister Bolad was sent to Iran, where he explained Yuan paper money to the Il-khanate court of Gaykhatu. The Il-khanate government issued paper money in 1294, but public distrust of the exotic new currency doomed the experiment.\n\nForeign observers took note of Yuan printing technology. Marco Polo documented the Yuan printing of paper money and almanac pamphlets called \"tacuini\". The vizier Rashid-al-Din recognized that printing was a valuable technological breakthrough, and expressed regret that the Mongol experiment with printing paper money had failed in the Muslim world. Rashid-al-Din's view was not shared by other chroniclers in the Middle East, who were critical of the experiment's disruptive impact on the Il-khanate.\n\n"}
{"id": "459163", "url": "https://en.wikipedia.org/wiki?curid=459163", "title": "Siphon", "text": "Siphon\n\nThe word siphon ( ; from \"pipe, tube\", also spelled syphon) is used to refer to a wide variety of devices that involve the flow of liquids through tubes. In a narrower sense, the word refers particularly to a tube in an inverted 'U' shape, which causes a liquid to flow upward, above the surface of a reservoir, with no pump, but powered by the fall of the liquid as it flows down the tube under the pull of gravity, then discharging at a level lower than the surface of the reservoir from which it came.\n\nThere are two leading theories about how siphons cause liquid to flow uphill, against gravity, without being pumped, and powered only by gravity. The traditional theory for centuries was that gravity pulling the liquid down on the exit side of the siphon resulted in reduced pressure at the top of the siphon. Then atmospheric pressure was able to push the liquid from the upper reservoir, up into the reduced pressure at the top of the siphon, like in a barometer or drinking straw, and then over. However, it has been demonstrated that siphons can operate in a vacuum and to heights exceeding the barometric height of the liquid. Consequently, the cohesion tension theory of siphon operation has been advocated, where the liquid is pulled over the siphon in a way similar to the chain model. It need not be one theory or the other that is correct, but rather both theories may be correct in different circumstances of ambient pressure. The atmospheric pressure with gravity theory obviously cannot explain siphons in vacuum, where there is no significant atmospheric pressure. But the cohesion tension with gravity theory cannot explain CO gas siphons, siphons working despite bubbles, and the flying droplet siphon, where gases do not exert significant pulling forces, and liquids not in contact cannot exert a cohesive tension force.\n\nAll known published theories in modern times recognize Bernoulli's equation as a decent approximation to idealized, friction-free siphon operation.\n\nEgyptian reliefs from 1500 BC depict siphons used to extract liquids from large storage jars.\n\nThere is physical evidence for the use of siphons by Greek engineers in the 3rd century BC at Pergamon.\n\nHero of Alexandria wrote extensively about siphons in the treatise \"Pneumatica\".\n\nThe Banu Musa brothers of 9th-century Baghdad invented a double-concentric siphon, which they described in their \"Book of Ingenious Devices\". The edition edited by Hill includes an analysis of the double-concentric siphon.\n\nSiphons were studied further in the 17th century, in the context of suction pumps (and the recently developed vacuum pumps), particularly with an eye to understanding the maximum height of pumps (and siphons) and the apparent vacuum at the top of early barometers. This was initially explained by Galileo Galilei via the theory of \"horror vacui\" (\"nature abhors a vacuum\"), which dates to Aristotle, and which Galileo restated as \"resintenza del vacuo,\" but this was subsequently disproved by later workers, notably Evangelista Torricelli and Blaise Pascal – see barometer: history.\n\nA practical siphon, operating at typical atmospheric pressures and tube heights, works because gravity pulling down on the taller column of liquid leaves reduced pressure at the top of the siphon (formally, hydrostatic pressure when the liquid is not moving). This reduced pressure at the top means gravity pulling down on the shorter column of liquid is not sufficient to keep the liquid stationary against the atmospheric pressure pushing it up into the reduced pressure zone at the top of the siphon. So the liquid flows from the higher pressure area of the upper reservoir, up to the lower pressure zone at the top of the siphon, over the top, and then with the help of gravity and a taller column of liquid, down to the higher pressure zone at the exit.\nThe chain model is a useful but not completely accurate conceptual model of a siphon. The chain model helps to understand how a siphon can cause liquid to flow uphill, powered only by the downward force of gravity. A siphon can sometimes be thought of a little like a chain hanging over a pulley, with one end of the chain piled on a higher surface than the other. Since the length of chain on the shorter side is lighter than the length of chain on the taller side, the heavier chain on the taller side will move down and pull up the chain on the lighter side. Similar to a siphon, the chain model is obviously just powered by gravity acting on the heavier side, and there is clearly no violation of conservation of energy, because the chain is ultimately just moving from a higher to a lower location, as the liquid does in a siphon.\n\nThere are a number of problems with the chain model of a siphon, and understanding these differences helps to explain the actual workings of siphons. First, unlike in the chain model of the siphon, it is not actually the \"weight\" on the taller side compared to the shorter side, that matters. Rather it is the difference in \"height\" from the reservoir surfaces to the top of the siphon, that determines the balance of pressure. For example, if the tube from the upper reservoir to the top of the siphon has a much larger diameter than the taller section of tube from the lower reservoir to the top of the siphon, the shorter upper section of the siphon may have a much larger weight of liquid in it, and yet the lighter volume of liquid in the down tube can pull liquid up the fatter up tube, and the siphon can function normally.\n\nAnother difference is that under most practical circumstances, dissolved gases, vapor pressure, and (sometimes) lack of adhesion with tube walls, conspire to render the tensile strength within the liquid ineffective for siphoning. Thus, unlike a chain which has significant tensile strength, liquids usually have little tensile strength under typical siphon conditions, and therefore the liquid on the rising side cannot be pulled up, in the way the chain is pulled up on the rising side.\n\nAn occasional misunderstanding of siphons is that they rely on the tensile strength of the liquid to pull the liquid up and over the rise. While water has been found to have a great deal of tensile strength in some experiments (such as with the z-tube), and siphons in vacuum rely on such cohesion, common siphons can easily be demonstrated to need no liquid tensile strength at all to function. Furthermore, since common siphons operate at positive pressures throughout the siphon, there is no contribution from liquid tensile strength, because the molecules are actually repelling each other in order to resist the pressure, rather than pulling on each other. To demonstrate, the longer lower leg of a common siphon can be plugged at the bottom and filled almost to the crest with liquid as in Figure 5, leaving the top and the shorter upper leg completely dry and containing only air. When the plug is removed and the liquid in the longer lower leg is allowed to fall, the liquid in the upper reservoir will then typically sweep the air bubble down and out of the tube. The apparatus will then continue to operate as a normal siphon. As there is no contact between the liquid on either side of the siphon at the beginning of this experiment, there can be no cohesion between the liquid molecules to pull the liquid over the rise. It has been suggested by advocates of the liquid tensile strength theory, that the air start siphon only demonstrates the effect as the siphon starts, but that the situation changes after the bubble is swept out and the siphon achieves steady flow. But a similar effect can be seen in the flying droplet siphon of figure 2. The flying droplet siphon works continuously without liquid tensile strength pulling the liquid up. The siphon in the video demonstration operated steadily for more than 28 minutes until the upper reservoir was empty. Another simple demonstration that liquid tensile strength isn't needed in the siphon is to simply introduce a bubble into the siphon during operation. The bubble can be large enough to entirely disconnect the liquids in the tube before and after the bubble, defeating any liquid tensile strength, and yet if the bubble isn't too big, the siphon will continue to operate with little change as it sweeps the bubble out.\n\nAnother common misconception about siphons, is that because the atmospheric pressure is virtually identical at the entrance and exit, the atmospheric pressure cancels, and therefore atmospheric pressure can't be pushing the liquid up the siphon. But equal and opposite forces may not completely cancel if there is an intervening force that counters some or all of one of the forces. In the siphon, the atmospheric pressure at the entrance and exit are both lessened by the force of gravity pulling down the liquid in each tube, but the pressure on the down side is lessened more by the taller column of liquid on the down side. In effect, the atmospheric pressure coming up the down side doesn't entirely \"make it\" to the top to cancel all of the atmospheric pressure pushing up the up side. This effect can be seen more easily in the example of two carts being pushed up opposite sides of a hill. As shown in the diagram, even though the person on the left seems to have his push canceled entirely by the equal and opposite push from the person on the right, the person on the left's seemingly canceled push is still the source of the force to push the left cart up.\nIn some situations siphons do function in the absence of atmospheric pressure and via tensile strength – see vacuum siphons – and in these situations the chain model can be instructive. Further, in other settings water transport does occur via tension, most significantly in transpirational pull in the xylem of vascular plants. Water and other liquids may seem to have no tensile strength because \nwhen a handful is scooped up and pulled on, the liquids narrow and pull \napart effortlessly. But liquid tensile strength in a siphon is possible \nwhen the liquid adheres to the tube walls and thereby resists narrowing. Any contamination on the tube\nwalls, such as grease or air bubbles, or other minor influences such as\nturbulence or vibration, can cause the liquid to detach from the walls \nand lose all tensile strength.\n\nIn more detail, one can look at how the hydrostatic pressure varies through a static siphon, considering in turn the vertical tube from the top reservoir, the vertical tube from the bottom reservoir, and the horizontal tube connecting them (assuming a U-shape). At liquid level in the top reservoir, the liquid is under atmospheric pressure, and as one goes up the siphon, the hydrostatic pressure decreases (under vertical pressure variation), since the weight of atmospheric pressure pushing the water up is counterbalanced by the column of water in the siphon pushing down (until one reaches the maximum height of a barometer/siphon, at which point the liquid cannot be pushed higher) – the hydrostatic pressure at the top of the tube is then lower than atmospheric pressure by an amount proportional to the height of the tube. Doing the same analysis on the tube rising from the lower reservoir yields the pressure at the top of that (vertical) tube; this pressure is lower because the tube is longer (there is more water pushing down), and requires that the lower reservoir is lower than the upper reservoir, or more generally that the discharge outlet simply be lower than the surface of the upper reservoir. Considering now the horizontal tube connecting them, one sees that the pressure at the top of the tube from the top reservoir is higher (since less water is being lifted), while the pressure at the top of the tube from the bottom reservoir is lower (since more water is being lifted), and since liquids move from high pressure to low pressure, the liquid flows across the horizontal tube from the top basin to the bottom basin. Note that the liquid is under positive pressure (compression) throughout the tube, not tension.\n\nBernoulli's equation is considered in the scientific literature to be a fair approximation to the operation of the siphon. In non-ideal fluids, compressibility, tensile strength and other characteristics of the working fluid (or multiple fluids) complicate Bernoulli's equation.\n\nOnce started, a siphon requires no additional energy to keep the liquid flowing up and out of the reservoir. The siphon will draw liquid out of the reservoir until the level falls below the intake, allowing air or other surrounding gas to break the siphon, or until the outlet of the siphon equals the level of the reservoir, whichever comes first.\n\nIn addition to atmospheric pressure, the density of the liquid, and gravity, the maximum height of the crest in practical siphons is limited by the vapour pressure of the liquid. When the pressure within the liquid drops to below the liquid's vapor pressure, tiny vapor bubbles can begin to form at the high point and the siphon effect will end. This effect depends on how efficiently the liquid can nucleate bubbles; in the absence of impurities or rough surfaces to act as easy nucleation sites for bubbles, siphons can temporarily exceed their standard maximum height during the extended time it takes bubbles to nucleate. One siphon of degassed water was demonstrated to 24 meters for an extended period of time and other controlled experiments to 10 meters. For water at standard atmospheric pressure, the maximum siphon height is approximately 10 m (32 feet); for mercury it is 76 cm (30 inches), which is the definition of standard pressure. This equals the maximum height of a suction pump, which operates by the same principle. The ratio of heights (about 13.6) equals the ratio of densities of water and mercury (at a given temperature), since the column of water (resp. mercury) is balancing with the column of air yielding atmospheric pressure, and indeed maximum height is (neglecting vapor pressure and velocity of liquid) inversely proportional to density of liquid.\n\nIn 1948, Malcolm Nokes investigated siphons working in both air pressure and in a partial vacuum, for siphons in vacuum he concluded that: \"The gravitational force on the column of liquid in the downtake tube less the gravitational force in the uptake tube causes the liquid to move. The liquid is therefore in tension and sustains a longitudinal strain which, in the absence of disturbing factors, is insufficient to break the column of liquid\". But for siphons of small uptake height working at atmospheric pressure, he concluded that: \"... the tension of the liquid column is neutralized and \"reversed\" by the compressive effect of the atmosphere on the opposite ends of the liquid column.\"\n\nPotter and Barnes at the University of Edinburgh revisited siphons in 1971. They re-examined the theories of the siphon and ran experiments on siphons in air pressure. Their conclusion was that; \"By now it should be clear that, despite a wealth of tradition, the basic mechanism of a siphon does not depend upon atmospheric pressure.\"\n\nGravity, pressure and molecular cohesion were the focus of work in 2010 by Hughes at the Queensland University of Technology. He used siphons at air pressure and his conclusion was that: \"The flow of water out of the bottom of a siphon depends on the difference in height between the inflow and outflow, and therefore cannot be dependent on atmospheric pressure…\"\nHughes did further work on siphons at air pressure in 2011 and concluded that: \"The experiments described above demonstrate that ordinary siphons at atmospheric pressure operate through gravity and not atmospheric pressure\".\n\nThe father and son researchers, Ramette and Ramette, successfully siphoned carbon dioxide under air pressure in 2011 and concluded that molecular cohesion is not required for the operation of a siphon but that: \"The basic explanation of siphon action is that, once the tube is filled, the flow is initiated by the greater pull of gravity on the fluid on the longer side compared with that on the short side. This creates a pressure drop throughout the siphon tube, in the same sense that 'sucking' on a straw reduces the pressure along its length all the way to the intake point. The ambient atmospheric pressure at the intake point responds to the reduced pressure by forcing the fluid upwards, sustaining the flow, just as in a steadily sucked straw in a milkshake.\"\n\nAgain in 2011, Richert and Binder (at the University of Hawaii) examined the siphon and concluded that molecular cohesion is not required for the operation of a siphon but relies upon gravity and a pressure differential, writing: \"As the fluid initially primed on the long leg of the siphon rushes down due to gravity, it leaves behind a partial vacuum that allows pressure on the entrance point of the higher container to push fluid up the leg on that side\".\n\nThe research team of Boatwright, Puttick, and Licence, all at the University of Nottingham, succeeded in running a siphon in high vacuum, also in 2011. They wrote that: \"It is widely believed that the siphon is principally driven by the force of atmospheric pressure. An experiment is described that shows that a siphon can function even under high-vacuum conditions. Molecular cohesion and gravity are shown to be contributing factors in the operation of a siphon; the presence of a positive atmospheric pressure is not required\".\n\nWriting in Physics Today in 2011, J. Dooley from Millersville University stated that both a pressure differential within the siphon tube and the tensile strength of the liquid are required for a siphon to operate.\n\nA researcher at Humboldt State University, A. McGuire, examined flow in siphons in 2012. Using the advanced general-purpose multiphysics simulation software package LS-DYNA he examined pressure initialisation, flow, and pressure propagation within a siphon. He concluded that: \"Pressure, gravity and molecular cohesion can all be driving forces in the operation of siphons\".\n\nIn 2014, Hughes and Gurung (at the Queensland University of Technology), ran a water siphon under varying air pressures ranging from sea level to 11.9 km () altitude. They noted that: \"Flow remained more or less constant during ascension indicating that siphon flow is independent of ambient barometric pressure\". They used Bernoulli's equation and the Poiseuille equation to examine pressure differentials and fluid flow within a siphon. Their conclusion was that: \"It follows from the above analysis that there must be a direct cohesive connection between water molecules flowing in and out of a siphon. This is true at all atmospheric pressures in which the pressure in the apex of the siphon is above the vapour pressure of water, an exception being ionic liquids\".\n\nA plain tube can be used as a siphon. An external pump has to be applied to start the liquid flowing and \"prime\" the siphon (in home use this is often done by a person inhaling through the tube until enough of it has filled with liquid; note this may pose danger to the user, depending on the liquid that is being siphoned). This is sometimes done with any leak-free hose to siphon gasoline from a motor vehicle's gasoline tank to an external tank. (Siphoning gasoline by mouth often results in the accidental swallowing of gasoline, or aspirating it into the lungs, which can cause death or lung damage.) If the tube is flooded with liquid before part of the tube is raised over the intermediate high point and care is taken to keep the tube flooded while it is being raised, no pump is required. Devices sold as siphons often come with a \"siphon pump\" to start the siphon process.\n\nIn some applications it can be helpful to use siphon tubing that is not much larger than necessary. Using piping of too great a diameter and then throttling the flow using valves or constrictive piping appears to increase the effect of previously cited concerns over gases or vapor collecting in the crest which serve to break the vacuum. If the vacuum is reduced too much, the siphon effect can be lost. Reducing the size of pipe used closer to requirements appears to reduce this effect and creates a more functional siphon that does not require constant re-priming and restarting. In this respect, where the requirement is to match a flow into a container with a flow out of said container (to maintain a constant level in a pond fed by a stream, for example) it would be preferable to utilize two or three smaller separate parallel pipes that can be started as required rather than attempting to use a single large pipe and attempting to throttle it.\n\nSiphons are sometimes employed as automatic machines, in situations where it is desirable to turn a continuous trickling flow or an irregular small surge flow into a large surge volume. A common example of this is a public restroom with urinals regularly flushed by an automatic siphon in a small water tank overhead. When the container is filled, all the stored liquid is released, emerging as a large surge volume that then resets and fills again. One way to do this intermittent action involves complex machinery such as floats, chains, levers, and valves, but these can corrode, wear out, or jam over time. An alternate method is with rigid pipes and chambers, using only the water itself in a siphon as the operating mechanism.\n\nA siphon used in an automatic unattended device needs to be able to function reliably without failure. This is different from the common demonstration self-starting siphons in that there are ways the siphon can fail to function which require manual intervention to return to normal surge flow operation.\n\nThe most common failure is for the liquid to dribble out slowly, matching the rate that the container is filling, and the siphon enters an undesired steady-state condition. Preventing dribbling typically involves pneumatic principles to trap one or more large air bubbles in various pipes, which are sealed by water traps. This method can fail if it can't start working intermittently without water already present in parts of the mechanism, and which will not be filled if the mechanism starts from a dry state.\n\nA second problem is that the trapped air pockets will shrink over time if the siphon is not operating due to no inflow. The air in pockets is absorbed by the liquid, which pulls liquid up into the piping until the air pocket disappears, and can cause activation of water flow outside the normal range of operating when the storage tank is not full, leading to loss of the liquid seal in lower parts of the mechanism.\n\nA third problem is where the lower end of the liquid seal is simply a U-trap bend in an outflow pipe. During vigorous emptying, the kinetic motion of the liquid out the outflow can propel too much liquid out, causing a loss of the sealing volume in the outflow trap and loss of the trapped air bubble to maintain intermittent operation.\n\nA fourth problem involves seep holes in the mechanism, intended to slowly refill these various sealing chambers when the siphon is dry. The seep holes can be plugged by debris and corrosion, requiring manual cleaning and intervention. To prevent this, the siphon may be restricted to pure liquid sources, free of solids or precipitate.\n\nMany automatic siphons have been invented going back to at least the 1850s, for automatic siphon mechanisms that attempt to overcome these problems using various pneumatic and hydrodynamic principles.\n\nWhen certain liquids needs to be purified, siphoning can help prevent either the bottom (dregs) or the top (foam and floaties) from being transferred out of one container into a new container. Siphoning is thus useful in the fermentation of wine and beer for this reason, since it can keep unwanted impurities out of the new container.\n\nSelf-constructed siphons, made of pipes or tubes, can be used to evacuate water from cellars after floodings. Between the flooded cellar and a deeper place outside a connection is built, using a tube or some pipes. They are filled with water through an intake valve (at the highest end of the construction). When the ends are opened, the water flows through the pipe into the sewer or the river.\nSiphoning is common in irrigated fields to transfer a controlled amount of water from a ditch, over the ditch wall, into furrows.\n\nLarge siphons may be used in municipal waterworks and industry. Their size requires control via valves at the intake, outlet and crest of the siphon. The siphon may be primed by closing the intake and outlets and filling the siphon at the crest. If intakes and outlets are submerged, a vacuum pump may be applied at the crest to prime the siphon. Alternatively the siphon may be primed by a pump at either the intake or outlet. Gas in the liquid is a concern in large siphons. The gas tends to accumulate at the crest and if enough accumulates to break the flow of liquid, the siphon stops working. The siphon itself will exacerbate the problem because as the liquid is raised through the siphon, the pressure drops, causing dissolved gases within the liquid to come out of solution. Higher temperature accelerates the release of gas from liquids so maintaining a constant, low temperature helps. The longer the liquid is in the siphon, the more gas is released, so a shorter siphon overall helps. Local high points will trap gas so the intake and outlet legs should have continuous slopes without intermediate high points. The flow of the liquid moves bubbles thus the intake leg can have a shallow slope as the flow will push the gas bubbles to the crest. Conversely, the outlet leg needs to have a steep slope to allow the bubbles to move against the liquid flow; though other designs call for a shallow slope in the outlet leg as well to allow the bubbles to be carried out of the siphon. At the crest the gas can be trapped in a chamber above the crest. The chamber needs to be occasionally primed again with liquid to remove the gas.\n\nA \"siphon rain gauge\" is a rain gauge that can record rainfall over an extended period. A siphon is used to automatically empty the gauge. It is often simply called a \"siphon gauge\" and is not to be confused with a siphon pressure gauge.\n\nA siphon spillway in a dam is usually not technically a siphon as it is generally used to drain elevated water levels. However, a siphon spillway operates as an actual siphon if it raises the flow higher than the surface of the source reservoir, as sometimes is the case when used in irrigation. In operation, a siphon spillway is considered to be 'pipe flow' or 'closed duct flow'. A normal spillway flow is pressurized by the height of the reservoir above the spillway whereas a siphon flow rate is governed by the difference in height of the inlet and outlet. Some designs make use of an automatic system that uses the flow of water in a spiral vortex to remove the air above to prime the siphon. Such a design includes the volute siphon.\n\nFlush toilets often have some siphon effect as the bowl empties.\n\nSome toilets also use the siphon principle to obtain the actual flush from the cistern. The flush is triggered by a lever or handle that operates a simple diaphragm-like piston pump that lifts enough water to the crest of the siphon to start the flow of water which then completely empties the contents of the cistern into the toilet bowl. The advantage of this system was that no water would leak from the cistern excepting when flushed. These were mandatory in the UK until 2011.\n\nEarly urinals incorporated a siphon in the cistern which would flush automatically on a regular cycle because there was a constant trickle of clean water being fed to the cistern by a slightly open valve.\n\nWhile if both ends of a siphon are at atmospheric pressure, liquid flows from high to low, if the bottom end of a siphon is pressurized, liquid can flow from low to high. If pressure is removed from the bottom end, the liquid flow will reverse, illustrating that it is pressure driving the siphon. An everyday illustration of this is the siphon coffee brewer, which works as follows (designs vary; this is a standard design, omitting coffee grounds):\nIn practice, the top vessel is filled with coffee grounds, and the heat is removed from the bottom vessel when the coffee has finished brewing. What vapor pressure means concretely is that the boiling water converts high-density water (a liquid) into low-density steam (a gas), which thus expands to take up more volume (in other words, the pressure increases). This pressure from the expanding steam then forces the liquid up the siphon; when the steam then condenses down to water the pressure decreases and the liquid flows back down.\n\nWhile a simple siphon cannot output liquid at a level higher than the source reservoir, a more complicated device utilizing an airtight metering chamber at the crest and a system of automatic valves, may discharge liquid on an ongoing basis, at a level higher than the source reservoir, without outside pumping energy being added. It can accomplish this despite what initially appears to be a violation of conservation of energy because it can take advantage of the energy of a large volume of liquid dropping some distance, to raise and discharge a small volume of liquid above the source reservoir. Thus it might be said to \"require\" a large quantity of falling liquid to power the dispensing of a small quantity. Such a system typically operates in a cyclical or start/stop but ongoing and self-powered manner. Ram pumps do not work in this way. These metering pumps are true siphon pumping devices which use siphons as their power source.\n\nAn \"inverted siphon\" is not a siphon but a term applied to pipes that must dip below an obstruction to form a \"U\" shaped flow path.\n\nLarge inverted siphons are used to convey water being carried in canals or flumes across valleys, for irrigation or gold mining. The Romans used inverted siphons of multiple lead pipes to cross valleys that were too big to construct an aqueduct.\n\n\"Inverted siphons\" are commonly called traps for their function in preventing smelly sewer gases from coming back out of drains and sometimes making dense objects like rings and electronic components retrievable after falling into a drain. Liquid flowing in one end simply forces liquid up and out the other end, but solids like sand will accumulate. This is especially important in sewage systems or culverts which must be routed under rivers or other deep obstructions where the better term is \"depressed sewer\".\n\n\"Back siphonage\" is a plumbing term applied to the reversal of normal water flow in a plumbing system due to sharply reduced or negative pressure on the water supply side, such as high demand on water supply by fire-fighting; it is not an actual siphon as it is suction. Back siphonage is rare as it depends on submerged inlets at the outlet (home) end and these are uncommon. Back siphonage is not to be confused with backflow; which is the reversed flow of water from the outlet end to the supply end caused by pressure occurring at the outlet end.\n\nBuilding codes often contain specific sections on back siphonage and especially for external faucets (See the sample building code quote, below). Backflow prevention devices such as \"anti-siphon valves\" are required in such designs. The reason is that external faucets may be attached to hoses which may be immersed in an external body of water, such as a garden pond, swimming pool, aquarium or washing machine. In these situations the flow is not actually a siphon but suction due to reduced pressure on the water supply side. Should the pressure within the water supply system fall, the external water may be returned by back pressure into the drinking water system through the faucet. Another possible contamination point is the water intake in the toilet tank. An anti-siphon valve is also required here to prevent pressure drops in the water supply line from suctioning water out of the toilet tank (which may contain additives such as \"toilet blue\") and contaminating the water system. Anti-siphon valves function as a one-direction check valve.\n\nAnti-siphon valves are also used medically. Hydrocephalus, or excess fluid in the brain, may be treated with a shunt which drains cerebrospinal fluid from the brain. All shunts have a valve to relieve excess pressure in the brain. The shunt may lead into the abdominal cavity such that the shunt outlet is significantly lower than the shunt intake when the patient is standing. Thus a siphon effect may take place and instead of simply relieving excess pressure, the shunt may act as a siphon, completely draining cerebrospinal fluid from the brain. The valve in the shunt may be designed to prevent this siphon action so that negative pressure on the drain of the shunt does not result in excess drainage. Only excess positive pressure from within the brain should result in drainage.\n\nNote that the anti-siphon valve in medical shunts is preventing excess forward flow of liquid. In plumbing systems, the anti-siphon valve is preventing backflow.\n\n\"Sample building code regulations regarding \"back siphonage\" from the Canadian province of Ontario\":\n\nAlong with anti-siphon valves, \"anti-siphoning devices\" also exist. The two are unrelated in application. Siphoning can be used to remove fuel from tanks. With the cost of fuel increasing, it has been linked in several countries to the rise in fuel theft. Trucks, with their large fuel tanks, are most vulnerable. The anti-siphon device prevents thieves from inserting a tube into the fuel tank.\n\nA \"siphon barometer\" is the term sometimes applied to the simplest of mercury barometers. A continuous U-shaped tube of the same diameter throughout is sealed on one end and filled with mercury. When placed into the upright, \"U\", position, mercury will flow away from the sealed end, forming a partial vacuum, until balanced by atmospheric pressure on the other end. The term \"siphon\" derives from the belief that air pressure is involved in the operation of a siphon. The difference in height of the fluid between the two arms of the U-shaped tube is the same as the maximum intermediate height of a siphon. When used to measure pressures other than atmospheric pressure, a siphon barometer is sometimes called a \"siphon gauge\"; these are not siphons but follow a standard 'U'-shaped design leading to the term. Siphon barometers are still produced as precision instruments. Siphon barometers should not be confused with a siphon rain gauge.,\n\nA \"siphon bottle\" (also called a \"soda syphon\" or, archaically, a \"siphoid\") is a pressurized bottle with a vent and a valve. It is not a siphon as pressure within the bottle drives the liquid up and out a tube. A special form was the \"gasogene\".\n\nA \"siphon cup\" is the (hanging) reservoir of paint attached to a spray gun, it is not a siphon as a vacuum pump extracts the paint. This name is to distinguish it from gravity-fed reservoirs. An archaic use of the term is a cup of oil in which the oil is transported out of the cup via a cotton wick or tube to a surface to be lubricated, this is not a siphon but an example of capillary action.\n\n\"Heron's siphon\" is not a siphon as it works as a gravity driven pressure pump, at first glance it appears to be a perpetual motion machine but will stop when the air in the priming pump is depleted. In a slightly differently configuration, it is also known as Heron's fountain.\n\nA venturi siphon, also known as an eductor, is not a siphon but a form of vacuum pump using the Venturi effect of fast flowing fluids (e.g. air), to produce low pressures to suction other fluids; a common example is the carburetor. See pressure head. The low pressure at the throat of the venturi is called a siphon when a second fluid is introduced, or an aspirator when the fluid is air, this is an example of the misconception that air pressure is the operating force for siphons.\n\nDespite the name, siphonic roof drainage does not work as a siphon; the technology makes use of gravity induced vacuum pumping to carry water horizontally from multiple roof drains to a single downpipe and to increase flow velocity. Metal baffles at the roof drain inlets reduce the injection of air which increases the efficiency of the system. One benefit to this drainage technique is reduced capital costs in construction compared to traditional roof drainage. Another benefit is the elimination of pipe pitch or gradient required for conventional roof drainage piping. However this system of gravity pumping is mainly suitable for large buildings and is not usually suitable for residential properties.\n\nThe term \"self-siphon\" is used in a number of ways. Liquids that are composed of long polymers can \"self-siphon\" and these liquids do not depend on atmospheric pressure. Self-siphoning polymer liquids work the same as the siphon-chain model where the lower part of the chain pulls the rest of the chain up and over the crest. This phenomenon is also called a \"tubeless siphon\".\n\n\"Self-siphon\" is also often used in sales literature by siphon manufacturers to describe portable siphons that contain a pump. With the pump, no external suction (e.g. from a person's mouth/lungs) is required to start the siphon and thus the product is described as a \"self-siphon\".\n\nIf the upper reservoir is such that the liquid there can rise above the height of the siphon crest, the rising liquid in the reservoir can \"self-prime\" the siphon and the whole apparatus be described as a \"self-siphon\". Once primed, such a siphon will continue to operate until the level of the upper reservoir falls below the intake of the siphon. Such self-priming siphons are useful in some rain gauges and dams.\n\nThe term \"siphon\" is used for a number of structures in human and animal anatomy, either because flowing liquids are involved or because the structure is shaped like a siphon, but in which no actual siphon effect is occurring: see Siphon (disambiguation).\n\nThere has been a debate if whether the siphon mechanism plays a role in blood circulation. However, in the 'closed loop' of circulation this was discounted; \"In contrast, in 'closed' systems, like the circulation, gravity does not hinder uphill flow nor does it cause downhill flow, because gravity acts equally on the ascending and descending limbs of the circuit\", but for \"historical reasons\", the term is used. One hypothesis (in 1989) was that a siphon existed in the circulation of the giraffe. But further research in 2004 found that, \"There is no hydrostatic gradient and since the 'fall' of fluid does not assist the ascending arm, there is no siphon. The giraffe’s high arterial pressure, which is sufficient to raise the blood 2 m from heart to head with sufficient remaining pressure to perfuse the brain, supports this concept.\" However, a paper written in 2005 urged more research on the hypothesis:\n\nThe principle of the siphon is not species specific and should be a fundamental principle of closed circulatory systems. Therefore, the controversy surrounding the role of the siphon principle may best be resolved by a comparative approach. Analyses of blood pressure on a variety of long-necked and long-bodied animals, which take into account phylogenetic relatedness, will be important. In addition experimental studies that combined measurements of arterial and venous blood pressures, with cerebral blood flow, under a variety of gravitational stresses (different head positions), will ultimately resolve this controversy.\nSome species are named after siphons because they resemble siphons in whole or in part. Geosiphons are fungi. There are species of alga belonging to the family Siphonocladaceae in the phylum Chlorophyta which have tube-like structures. \"Ruellia villosa\" is a tropical plant in the Acanthaceae family that is also known by the botanical synonym, \"'Siphonacanthus villosus\" Nees'.\n\nIn speleology, a siphon or a sump is that part of a cave passage that lies under water and through which cavers have to dive to progress further into the cave system, it is not an actual siphon.\n\nIn canoe watersport \"siphon\" is called the life-dangerous situation that a part of the waterflow of a river flows underneath a stone or somewhat else and can dangerously suck in a paddler and his boat. Both can clog or stick to the entering orifice of that flow. Similar is a seive.\n\nBernoulli's equation may be applied to a siphon to derive the flow rate and maximum height of the siphon.\n\nBernoulli's equation:\n\nApply Bernoulli's equation to the surface of the upper reservoir. The surface is technically falling as the upper reservoir is being drained. However, for this example we will assume the reservoir to be infinite and the velocity of the surface may be set to zero. Furthermore, the pressure at both the surface and the exit point C is atmospheric pressure. Thus:\n\nApply Bernoulli's equation to point A at the start of the siphon tube in the upper reservoir where \"P\" = \"P\", \"v\" = \"v\" and \"y\" = −\"d\"\n\nApply Bernoulli's equation to point B at the intermediate high point of the siphon tube where \"P\" = \"P\", \"v\" = \"v\" and \"y\" = \"h\"\n\nApply Bernoulli's equation to point C where the siphon empties. Where \"v\" = \"v\" and \"y\" = −\"h\". Furthermore, the pressure at the exit point is atmospheric pressure. Thus:\n\nAs the siphon is a single system, the constant in all four equations is the same. Setting equations 1 and 4 equal to each other gives:\n\nSolving for \"v\":\n\nThe velocity of the siphon is thus driven solely by the height difference between the surface of the upper reservoir and the drain point. The height of the intermediate high point, \"h\", does not affect the velocity of the siphon. However, as the siphon is a single system, \"v\" = \"v\" and the intermediate high point does limit the maximum velocity. The drain point cannot be lowered indefinitely to increase the velocity. Equation 3 will limit the velocity to a positive pressure at the intermediate high point to prevent cavitation. The maximum velocity may be calculated by combining equations 1 and 3:\n\nSetting \"P\" = 0 and solving for \"v\":\n\nThe depth, −\"d\", of the initial entry point of the siphon in the upper reservoir, does not affect the velocity of the siphon. No limit to the depth of the siphon start point is implied by Equation 2 as pressure \"P\" increases with depth \"d\". Both these facts imply the operator of the siphon may bottom skim or top skim the upper reservoir without impacting the siphon's performance.\n\nNote that this equation for the velocity is the same as that of any object falling height \"h\". Note also that this equation assumes \"P\" is atmospheric pressure. If the end of the siphon is below the surface, the height to the end of the siphon cannot be used; rather the height difference between the reservoirs should be used.\n\nAlthough siphons can exceed the barometric height of the liquid in special circumstances, e.g. when the liquid is degassed and the tube is clean and smooth, in general the practical maximum height can be found as follows.\n\nSetting equations 1 and 3 equal to each other gives:\n\nMaximum height of the intermediate high point occurs when it is so high that the pressure at the intermediate high point is zero; in typical scenarios this will cause the liquid to form bubbles and if the bubbles enlarge to fill the pipe then the siphon will \"break\". Setting \"P\" = 0:\n\nSolving for \"h\":\n\nThis means that the height of the intermediate high point is limited by pressure along the streamline being always greater than zero.\n\nThis is the maximum height that a siphon will work. Substituting values will give approximately 10 metres for water and, by definition of standard pressure, 0.76 metres () for mercury. The ratio of heights (about 13.6) equals the ratio of densities of water and mercury (at a given temperature). Note that as long as this condition is satisfied (pressure greater than zero), the flow at the output of the siphon is still only governed by the height difference between the source surface and the outlet. Volume of fluid in the apparatus is not relevant as long as the pressure head remains above zero in every section. Because pressure drops when velocity is increased, a static siphon (or manometer) can have a slightly higher height than a flowing siphon.\n\nExperiments have shown that siphons can operate in a vacuum, via cohesion and tensile strength between molecules, provided that the liquids are pure and degassed and surfaces are very clean.\n\nThe \"Oxford English Dictionary\" (OED) entry on \"siphon\", published in 1911, states that a siphon works by atmospheric pressure. Stephen Hughes of Queensland University of Technology criticized this in a 2010 article which was widely reported in the media. The OED editors stated, \"there is continuing debate among scientists as to which view is correct. ... We would expect to reflect this debate in the fully updated entry for siphon, due to be published later this year.\" Dr. Hughes continued to defend his view of the siphon in a late September post at the Oxford blog. The 2015 definition by the OED is:\nA tube used to convey liquid upwards from a reservoir and then down to a lower level of its own accord. Once the liquid has been forced into the tube, typically by suction or immersion, flow continues unaided.\n\nThe Encyclopædia Britannica currently describes a siphon as:\nSiphon, also spelled syphon, instrument, usually in the form of a tube bent to form two legs of unequal length, for conveying liquid over the edge of a vessel and delivering it at a lower level. Siphons may be of any size. The action depends upon the influence of gravity (not, as sometimes thought, on the difference in atmospheric pressure; a siphon will work in a vacuum) and upon the cohesive forces that prevent the columns of liquid in the legs of the siphon from breaking under their own weight. At sea level, water can be lifted a little more than 10 metres (33 feet) by a siphon.\n\nIn civil engineering, pipelines called inverted siphons are used to carry sewage or stormwater under streams, highway cuts, or other depressions in the ground. In an inverted siphon the liquid completely fills the pipe and flows under pressure, as opposed to the open-channel gravity flow that occurs in most sanitary or storm sewers.\n\n"}
{"id": "43347395", "url": "https://en.wikipedia.org/wiki?curid=43347395", "title": "Syneos Health", "text": "Syneos Health\n\nSyneos Health (formerly InVentiv Health Incorporated and INC Research) is a NASDAQ listed American multinational clinical studies contract research organization, based in Raleigh, North Carolina. In January 2018 INC Research merged with inVentiv Health, the parent company of a subsidiary called Syneos, and the resulting company was named Syneos Health.\n"}
{"id": "30990", "url": "https://en.wikipedia.org/wiki?curid=30990", "title": "Thermocouple", "text": "Thermocouple\n\nA thermocouple is an electrical device consisting of two dissimilar electrical conductors forming electrical junctions at differing temperatures. A thermocouple produces a temperature-dependent voltage as a result of the thermoelectric effect, and this voltage can be interpreted to measure temperature. Thermocouples are a widely used type of temperature sensor.\n\nCommercial thermocouples are inexpensive, interchangeable, are supplied with standard connectors, and can measure a wide range of temperatures. In contrast to most other methods of temperature measurement, thermocouples are self powered and require no external form of excitation. The main limitation with thermocouples is accuracy; system errors of less than one degree Celsius (°C) can be difficult to achieve.\n\nThermocouples are widely used in science and industry. Applications include temperature measurement for kilns, gas turbine exhaust, diesel engines, and other industrial processes. Thermocouples are also used in homes, offices and businesses as the temperature sensors in thermostats, and also as flame sensors in safety devices for gas-powered appliances.\n\nIn 1821, the German physicist Thomas Johann Seebeck discovered that when different metals are joined at the ends and there is a temperature difference between the joints, a magnetic field is observed. At the time, Seebeck referred to this consequence as thermo-magnetism. The magnetic field he observed was later shown to be due to thermo-electric current. In practical use, the voltage generated at a single junction of two different types of wire is what is of interest as this can be used to measure temperature at very high and low temperatures. The magnitude of the voltage depends on the types of wire being used. Generally, the voltage is in the microvolt range and care must be taken to obtain a usable measurement. Although very little current flows, power can be generated by a single thermocouple junction. Power generation using multiple thermocouples, as in a thermopile, is common.\n\nThe standard configuration for thermocouple usage is shown in the figure.\nBriefly, the desired temperature \"T\" is obtained using three inputs—the characteristic function \"E\"(\"T\") of the thermocouple, the measured voltage \"V\", and the reference junctions' temperature \"T\".\nThe solution to the equation \"E\"(\"T\") = \"V\" + \"E\"(\"T\") yields \"T\".\nThese details are often hidden from the user since the reference junction block (with \"T\" thermometer), voltmeter, and equation solver are combined into a single product.\n\nThe Seebeck effect refers to an electromotive force whenever there is a temperature gradient in a conductive material.\nUnder open-circuit conditions where there is no internal current flow, the gradient of voltage (formula_1) is directly proportional to the gradient in temperature (formula_2):\nwhere formula_4 is a temperature-dependent material property known as the Seebeck coefficient.\n\nThe standard measurement configuration shown in the figure shows four temperature regions and thus four voltage contributions:\n\nThe first and fourth contributions cancel out exactly, because these regions involve the same temperature change and an identical material.\nAs a result, formula_5 does not influence the measured voltage.\nThe second and third contributions do not cancel, as they involve different materials.\n\nThe measured voltage turns out to be\nwhere formula_15 and formula_16 are the Seebeck coefficients of the conductors attached to the positive and negative terminals of the voltmeter, respectively (chromel and alumel in the figure).\n\nAn integral does not need to be performed for every temperature measurement. Rather, the thermocouple's behaviour is captured by a characteristic function formula_17, which needs only to be consulted at two arguments:\nIn terms of the Seebeck coefficients, the characteristic function is defined by\nThe constant of integration in this indefinite integral has no significance, but is conventionally chosen such that formula_20.\n\nThermocouple manufacturers and metrology standards organizations such as NIST provide tables of the function formula_17 that have been measured and interpolated over a range of temperatures, for particular thermocouple types (see \"External links\" section for access to these tables).\n\nTo obtain the desired measurement of formula_8, it is not sufficient to just measure formula_23.\nThe temperature at the reference junctions formula_6 must be already known.\nTwo strategies are often used here:\n\nIn both cases the value formula_26 is calculated, then the function formula_17 is searched for a matching value. The argument where this match occurs is the value of formula_8.\n\nThermocouples ideally should be very simple measurement devices, with each type being characterized by a precise formula_17 curve, independent of any other details.\nIn reality, thermocouples are affected by issues such as alloy manufacturing uncertainties, aging effects, and circuit design mistakes/misunderstandings.\n\nA common error in thermocouple construction is related to cold junction compensation. If an error is made on the estimation of formula_30, the same error will be carried over to the temperature measurement. For the simplest measurements, thermocouple wires are connected to copper far away from the hot or cold point whose temperature is measured; the cold junction is then assumed to be at room temperature, but that temperature can vary.\n\nJunctions should be made in a reliable manner, but there are many possible approaches to accomplish this.\nFor low temperatures, junctions can be brazed or soldered, however it may be difficult to find a suitable flux and this may not be suitable at the sensing junction due to the solder's low melting point.\nReference and extension junctions are therefore usually made with screw terminal blocks.\nFor high temperatures, a common approach is a spot weld or crimp using a durable material.\nA common myth regarding thermocouples is that junctions must be made cleanly without involving a third metal, to avoid unwanted added emfs.\nThis may result from another common misunderstanding that the voltage is generated at the junction. In fact, the junctions should in principle have uniform internal temperature, therefore no voltage is generated at the junction. The voltage is generated in the thermal gradient, along the wire.\n\nA thermocouple produces small signals, often microvolts in magnitude. Precise measurements of this signal require an amplifier with low input offset voltage and with care taken to avoid thermal emfs from self-heating within the voltmeter itself. If the thermocouple wire has a high resistance for some reason (poor contact at junctions, or very thin wires used for fast thermal response), the measuring instrument should have high input impedance to prevent an offset in the measured voltage. A useful feature in thermocouple instrumentation will simultaneously measure resistance and detect faulty connections in the wiring or at thermocouple junctions.\n\nWhile a thermocouple wire type is often described by its chemical composition, the actual aim is to produce a pair of wires that follow a standardized formula_17 curve.\n\nImpurities affect each batch of metal differently, producing variable Seebeck coefficients.\nTo match the standard behaviour, thermocouple wire manufacturers will deliberately mix in additional impurities to \"dope\" the alloy, compensating for uncontrolled variations in source material.\nAs a result, there are standard and specialized grades of thermocouple wire, depending on the level of precision demanded in the thermocouple behaviour.\nPrecision grades may only be available in matched pairs, where one wire is modified to compensate for deficiencies in the other wire.\n\nA special case of thermocouple wire is known as \"extension grade\", designed to carry the thermoelectric circuit over a longer distance.\nExtension wires follow the stated formula_17 curve but for various reasons they are not designed to be used in extreme environments and so they cannot be used at the sensing junction in some applications.\nFor example, an extension wire may be in a different form, such as highly flexible with stranded construction and plastic insulation, or be part of a multi-wire cable for carrying many thermocouple circuits.\nWith expensive noble metal thermocouples, the extension wires may even be made of a completely different, cheaper material that mimics the standard type over a reduced temperature range.\n\nThermocouples are often used at high temperatures and in reactive furnace atmospheres. In this case, the practical lifetime is limited by thermocouple aging. The thermoelectric coefficients of the wires in a thermocouple that is used to measure very high temperatures may change with time, and the measurement voltage accordingly drops. The simple relationship between the temperature difference of the junctions and the measurement voltage is only correct if each wire is homogeneous (uniform in composition). As thermocouples age in a process, their conductors can lose homogeneity due to chemical and metallurgical changes caused by extreme or prolonged exposure to high temperatures. If the aged section of the thermocouple circuit is exposed to a temperature gradient, the measured voltage will differ, resulting in error.\n\nAged thermocouples are only partly modified, for example being unaffected in the parts outside the furnace. For this reason, aged thermocouples cannot be taken out of their installed location and recalibrated in a bath or test furnace to determine error. This also explains why error can sometimes be observed when an aged thermocouple is pulled partly out of a furnace—as the sensor is pulled back, aged sections may see exposure to increased temperature gradients from hot to cold as the aged section now passes through the cooler refractory area, contributing significant error to the measurement. Likewise, an aged thermocouple that is pushed deeper into the furnace might sometimes provide a more accurate reading if being pushed further into the furnace causes the temperature gradient to occur only in a fresh section.\n\nCertain combinations of alloys have become popular as industry standards. Selection of the combination is driven by cost, availability, convenience, melting point, chemical properties, stability, and output. Different types are best suited for different applications. They are usually selected on the basis of the temperature range and sensitivity needed. Thermocouples with low sensitivities (B, R, and S types) have correspondingly lower resolutions. Other selection criteria include the chemical inertness of the thermocouple material and whether it is magnetic or not. Standard thermocouple types are listed below with the positive electrode (assuming formula_33) first, followed by the negative electrode.\n\nType E (chromel–constantan) has a high output (68 µV/°C), which makes it well suited to cryogenic use. Additionally, it is non-magnetic.\nWide range is −50 °C to +740 °C\nand narrow range is −110 °C to +140 °C.\n\nType J (iron–constantan) has a more restricted range (−40 °C to +750 °C) than type K but higher sensitivity of about 50 µV/°C. The Curie point of the iron (770 °C) causes a smooth change in the characteristic, which determines the upper temperature limit.\n\nType K (chromel–alumel) is the most common general-purpose thermocouple with a sensitivity of approximately 41 µV/°C. It is inexpensive, and a wide variety of probes are available in its −200 °C to +1350 °C (−330 °F to +2460 °F) range. Type K was specified at a time when metallurgy was less advanced than it is today, and consequently characteristics may vary considerably between samples. One of the constituent metals, nickel, is magnetic; a characteristic of thermocouples made with magnetic material is that they undergo a deviation in output when the material reaches its Curie point, which occurs for type K thermocouples at around 185 °C.\n\nThey operate very well in oxidizing atmospheres. If, however, a mostly reducing atmosphere (such as hydrogen with a small amount of oxygen) comes into contact with the wires, the chromium in the chromel alloy oxidizes. This reduces the emf output, and the thermocouple reads low. This phenomenon is known as \"green rot\", due to the color of the affected alloy. Although not always distinctively green, the chromel wire will develop a mottled silvery skin and become magnetic. An easy way to check for this problem is to see whether the two wires are magnetic (normally, chromel is non-magnetic).\n\nHydrogen in the atmosphere is the usual cause of green rot. At high temperatures, it can diffuse through solid metals or an intact metal thermowell. Even a sheath of magnesium oxide insulating the thermocouple will not keep the hydrogen out.\n\nType M (82%Ni/18%Mo–99.2%Ni/0.8%Co, by weight) are used in vacuum furnaces for the same reasons as with type C (described below). Upper temperature is limited to 1400 °C. It is less commonly used than other types.\nType N (Nicrosil–Nisil) thermocouples are suitable for use between −270 °C and +1300 °C, owing to its stability and oxidation resistance. Sensitivity is about 39 µV/°C at 900 °C, slightly lower compared to type K.\n\nDesigned at the Defence Science and Technology Organisation (DSTO) of Australia, by Noel A. Burley, type-N thermocouples overcome the three principal characteristic types and causes of thermoelectric instability in the standard base-metal thermoelement materials:\n\nThe Nicrosil and Nisil thermocouple alloys show greatly enhanced thermoelectric stability relative to the other standard base-metal thermocouple alloys because their compositions substantially reduce the thermoelectric instabilities described above. This is achieved primarily by increasing component solute concentrations (chromium and silicon) in a base of nickel above those required to cause a transition from internal to external modes of oxidation, and by selecting solutes (silicon and magnesium) that preferentially oxidize to form a diffusion-barrier, and hence oxidation-inhibiting films.\n\nType T (copper–constantan) thermocouples are suited for measurements in the −200 to 350 °C range. Often used as a differential measurement, since only copper wire touches the probes. Since both conductors are non-magnetic, there is no Curie point and thus no abrupt change in characteristics. Type-T thermocouples have a sensitivity of about 43 µV/°C. Note that copper has a much higher thermal conductivity than the alloys generally used in thermocouple constructions, and so it is necessary to exercise extra care with thermally anchoring type-T thermocouples.\n\nTypes B, R, and S thermocouples use platinum or a platinum/rhodium alloy for each conductor. These are among the most stable thermocouples, but have lower sensitivity than other types, approximately 10 µV/°C. Type B, R, and S thermocouples are usually used only for high-temperature measurements due to their high cost and low sensitivity.\n\nType B (70%Pt/30%Rh–94%Pt/6%Rh, by weight) thermocouples are suited for use at up to 1800 °C. Type-B thermocouples produce the same output at 0 °C and 42 °C, limiting their use below about 50 °C. The emf function has a minimum around 21 °C, meaning that cold-junction compensation is easily performed, since the compensation voltage is essentially a constant for a reference at typical room temperatures.\n\nType R (87%Pt/13%Rh–Pt, by weight) thermocouples are used 0 to 1600 °C.\n\nType S (90%Pt/10%Rh–Pt, by weight) thermocouples, similar to type R, are used up to 1600 °C. Before the introduction of the International Temperature Scale of 1990 (ITS-90), precision type-S thermocouples were used as the practical standard thermometers for the range of 630 °C to 1064 °C, based on an interpolation between the freezing points of antimony, silver, and gold. Starting with ITS-90, platinum resistance thermometers have taken over this range as standard thermometers.\n\nThese thermocouples are well suited for measuring extremely high temperatures. Typical uses are hydrogen and inert atmospheres, as well as vacuum furnaces. They are not used in oxidizing environments at high temperatures because of embrittlement. A typical range is 0 to 2315 °C, which can be extended to 2760 °C in inert atmosphere and to 3000 °C for brief measurements.\n\n(95%W/5%Re–74%W/26%Re, by weight) maximum temperature will be measured by type-c thermocouple is 2329 ℃.\n\nIn these thermocouples (chromel–gold/iron alloy), the negative wire is gold with a small fraction (0.03–0.15 atom percent) of iron. The impure gold wire gives the thermocouple a high sensitivity at low temperatures (compared to other thermocouples at that temperature), whereas the chromel wire maintains the sensitivity near room temperature. It can be used for cryogenic applications (1.2–300 K and even up to 600 K). Both the sensitivity and the temperature range depend on the iron concentration. The sensitivity is typically around 15 µV/K at low temperatures, and the lowest usable temperature varies between 1.2 and 4.2 K.\n\nType P (55%Pd/31%Pt/14%Au–65%Au/35%Pd, by weight) thermocouples give a thermoelectric voltage that mimics the type K over the range 500 °C to 1400 °C, however they are constructed purely of noble metals and so shows enhanced corrosion resistance. This combination is also known as Platinel II.\n\nThermocouples of platinum/molybdenum-alloy (95%Pt/5%Mo–99.9%Pt/0.1%Mo, by weight) are sometimes used in nuclear reactors, since they show a low drift from nuclear transmutation induced by neutron irradiation, compared to the platinum/rhodium-alloy types.\n\nThe use of two wires of iridium/rhodium alloys can provide a thermocouple that can be used up to about 2000 °C in inert atmospheres.\n\nThermocouples made from two different, high-purity noble metals can show high accuracy even when uncalibrated, as well as low levels of drift. Two combinations in use are gold–platinum and platinum–palladium. Their main limitations are the low melting points of the metals involved (1064 °C for gold and 1555 °C for palladium). These thermocouples tend to be more accurate than type S, and due to their economy and simplicity are even regarded as competitive alternatives to the platinum resistance thermometers that are normally used as standard thermometers.\n\nNASA is developing a Multi-Mission Radioisotope Thermoelectric Generator in which the thermocouples would be made of skutterudite, which can function with a smaller temperature difference than the current tellurium designs. This would mean that an otherwise similar RTG would generate 25% more power at the beginning of a mission and at least 50% more after seventeen years. NASA hopes to use the design on the next New Frontiers mission.\n\nThe table below describes properties of several different thermocouple types. Within the tolerance columns, \"T\" represents the temperature of the hot junction, in degrees Celsius. For example, a thermocouple with a tolerance of ±0.0025×\"T\" would have a tolerance of ±2.5 °C at 1000 °C.\n\nThe wires that make up the thermocouple must be insulated from each other everywhere, except at the sensing junction. Any additional electrical contact between the wires, or contact of a wire to other conductive objects, can modify the voltage and give a false reading of temperature.\n\nPlastics are suitable insulators for low temperatures parts of a thermocouple, whereas ceramic insulation can be used up to around 1000 °C. Other concerns (abrasion and chemical resistance) also affect the suitability of materials.\n\nWhen wire insulation disintegrates, it can result in an unintended electrical contact at a different location from the desired sensing point. If such a damaged thermocouple is used in the closed loop control of a thermostat or other temperature controller, this can lead to a runaway overheating event and possibly severe damage, as the false temperature reading will typically be lower than the sensing junction temperature. Failed insulation will also typically outgas, which can lead to process contamination. For parts of thermocouples used at very high temperatures or in contamination-sensitive applications, the only suitable insulation may be vacuum or inert gas; the mechanical rigidity of the thermocouple wires is used to keep them separated.\n\nTemperature ratings for insulations may vary based on what the overall thermocouple construction cable consists of.\n\nNote: T300 is a new high-temperature material that was recently approved by UL for 300 °C operating temperatures.\n\nThermocouples are suitable for measuring over a large temperature range, from −270 up to 3000 °C (for a short time, in inert atmosphere). Applications include temperature measurement for kilns, gas turbine exhaust, diesel engines, other industrial processes and fog machines. They are less suitable for applications where smaller temperature differences need to be measured with high accuracy, for example the range 0–100 °C with 0.1 °C accuracy. For such applications thermistors, silicon bandgap temperature sensors and resistance thermometers are more suitable.\n\nType B, S, R and K thermocouples are used extensively in the steel and iron industries to monitor temperatures and chemistry throughout the steel making process. Disposable, immersible, type S thermocouples are regularly used in the electric arc furnace process to accurately measure the temperature of steel before tapping. The cooling curve of a small steel sample can be analyzed and used to estimate the carbon content of molten steel.\n\nMany gas-fed heating appliances such as ovens and water heaters make use of a pilot flame to ignite the main gas burner when required. If the pilot flame goes out, unburned gas may be released, which is an explosion risk and a health hazard. To prevent this, some appliances use a thermocouple in a fail-safe circuit to sense when the pilot light is burning. The tip of the thermocouple is placed in the pilot flame, generating a voltage which operates the supply valve which feeds gas to the pilot. So long as the pilot flame remains lit, the thermocouple remains hot, and the pilot gas valve is held open. If the pilot light goes out, the thermocouple temperature falls, causing the voltage across the thermocouple to drop and the valve to close.\n\nWhere the probe may be easily placed above the flame, a rectifying sensor may often be used instead. With part ceramic construction, they may also be known as flame rods, flame sensors or flame detection electrodes.\n\nSome combined main burner and pilot gas valves (mainly by Honeywell) reduce the power demand to within the range of a single universal thermocouple heated by a pilot (25 mV open circuit falling by half with the coil connected to a 10–12 mV, 0.2–0.25 A source, typically) by sizing the coil to be able to hold the valve open against a light spring, but only after the initial turning-on force is provided by the user pressing and holding a knob to compress the spring during lighting of the pilot. These systems are identifiable by the \"press and hold for x minutes\" in the pilot lighting instructions. (The holding current requirement of such a valve is much less than a bigger solenoid designed for pulling the valve in from a closed position would require.) Special test sets are made to confirm the valve let-go and holding currents, because an ordinary milliammeter cannot be used as it introduces more resistance than the gas valve coil. Apart from testing the open circuit voltage of the thermocouple, and the near short-circuit DC continuity through the thermocouple gas valve coil, the easiest non-specialist test is substitution of a known good gas valve.\n\nSome systems, known as millivolt control systems, extend the thermocouple concept to both open and close the main gas valve as well. Not only does the voltage created by the pilot thermocouple activate the pilot gas valve, it is also routed through a thermostat to power the main gas valve as well. Here, a larger voltage is needed than in a pilot flame safety system described above, and a thermopile is used rather than a single thermocouple. Such a system requires no external source of electricity for its operation and thus can operate during a power failure, provided that all the other related system components allow for this. This excludes common forced air furnaces because external electrical power is required to operate the blower motor, but this feature is especially useful for un-powered convection heaters. A similar gas shut-off safety mechanism using a thermocouple is sometimes employed to ensure that the main burner ignites within a certain time period, shutting off the main burner gas supply valve should that not happen.\n\nOut of concern about energy wasted by the standing pilot flame, designers of many newer appliances have switched to an electronically controlled pilot-less ignition, also called intermittent ignition. With no standing pilot flame, there is no risk of gas buildup should the flame go out, so these appliances do not need thermocouple-based pilot safety switches. As these designs lose the benefit of operation without a continuous source of electricity, standing pilots are still used in some appliances. The exception is later model instantaneous (aka \"tankless\") water heaters that use the flow of water to generate the current required to ignite the gas burner; these designs also use a thermocouple as a safety cut-off device in the event the gas fails to ignite, or if the flame is extinguished.\n\nThermopiles are used for measuring the intensity of incident radiation, typically visible or infrared light, which heats the hot junctions, while the cold junctions are on a heat sink. It is possible to measure radiative intensities of only a few μW/cm with commercially available thermopile sensors. For example, some laser power meters are based on such sensors; these are specifically known as thermopile laser sensor.\n\nThe principle of operation of a thermopile sensor is distinct from that of a bolometer, as the latter relies on a change in resistance.\n\nThermocouples can generally be used in the testing of prototype electrical and mechanical apparatus. For example, switchgear under test for its current carrying capacity may have thermocouples installed and monitored during a heat run test, to confirm that the temperature rise at rated current does not exceed designed limits.\n\nA thermocouple can produce current to drive some processes directly, without the need for extra circuitry and power sources. For example, the power from a thermocouple can activate a valve when a temperature difference arises. The electrical energy generated by a thermocouple is converted from the heat which must be supplied to the hot side to maintain the electric potential. A continuous transfer of heat is necessary because the current flowing through the thermocouple tends to cause the hot side to cool down and the cold side to heat up (the Peltier effect).\n\nThermocouples can be connected in series to form a thermopile, where all the hot junctions are exposed to a higher temperature and all the cold junctions to a lower temperature. The output is the sum of the voltages across the individual junctions, giving larger voltage and power output. In a radioisotope thermoelectric generator, the radioactive decay of transuranic elements as a heat source has been used to power spacecraft on missions too far from the Sun to use solar power.\n\nThermopiles heated by kerosene lamps were used to run batteryless radio receivers in isolated areas. There are commercially produced lanterns that use the heat from a candle to run several light-emitting diodes, and thermoelectrically-powered fans to improve air circulation and heat distribution in wood stoves.\n\nChemical production and petroleum refineries will usually employ computers for logging and for limit testing the many temperatures associated with a process, typically numbering in the hundreds. For such cases, a number of thermocouple leads will be brought to a common reference block (a large block of copper) containing the second thermocouple of each circuit. The temperature of the block is in turn measured by a thermistor. Simple computations are used to determine the temperature at each measured location.\n\nA thermocouple can be used as a vacuum gauge over the range of approximately 0.001 to 1 torr absolute pressure. In this pressure range, the mean free path of the gas is comparable to the dimensions of the vacuum chamber, and the flow regime is neither purely viscous nor purely molecular. In this configuration, the thermocouple junction is attached to the centre of a short heating wire, which is usually energised by a constant current of about 5 mA, and the heat is removed at a rate related to the thermal conductivity of the gas. \n\nThe temperature detected at the thermocouple junction depends on the thermal conductivity of the surrounding gas, which depends on the pressure of the gas. The potential difference measured by a thermocouple is proportional to the square of pressure over the low- to medium-vacuum range. At higher (viscous flow) and lower (molecular flow) pressures, the thermal conductivity of air or any other gas is essentially independent of pressure. The thermocouple was first used as a vacuum gauge by Voege in 1906. The mathematical model for the thermocouple as a vacuum gauge is quite complicated, as explained in detail by Van Atta, but can be simplified to:\nwhere \"P\" is the gas pressure, \"B\" is a constant that depends on the thermocouple temperature, the gas composition and the vacuum-chamber geometry, \"V\" is the thermocouple voltage at zero pressure (absolute), and \"V\" is the voltage indicated by the thermocouple.\n\nThe alternative is the Pirani gauge, which operates in a similar way, over approximately the same pressure range, but is only a 2-terminal device, sensing the change in resistance with temperature of a thin electrically heated wire, rather than using a thermocouple.\n\n\nThermocouple data tables:\n"}
{"id": "3183582", "url": "https://en.wikipedia.org/wiki?curid=3183582", "title": "Wire rope", "text": "Wire rope\n\nWire rope is several strands of metal wire twisted into a helix forming a composite \"rope\", in a pattern known as \"laid rope\". Larger diameter wire rope consists of multiple strands of such laid rope in a pattern known as \"cable laid\".\n\nIn stricter senses the term \"wire rope\" refers to diameter larger than 3/8 inch (9.52 mm), with smaller gauges designated cable or cords. Initially wrought iron wires were used, but today steel is the main material used for wire ropes.\n\nHistorically, wire rope evolved from wrought iron chains, which had a record of mechanical failure. While flaws in chain links or solid steel bars can lead to catastrophic failure, flaws in the wires making up a steel cable are less critical as the other wires easily take up the load. While friction between the individual wires and strands causes wear over the life of the rope, it also helps to compensate for minor failures in the short run.\n\nWire ropes were developed starting with mining hoist applications in the 1830s. Wire ropes are used dynamically for lifting and hoisting in cranes and elevators, and for transmission of mechanical power. Wire rope is also used to transmit force in mechanisms, such as a Bowden cable or the control surfaces of an airplane connected to levers and pedals in the cockpit. Only aircraft cables have WSC (wire strand core). Also, aircraft cables are available in smaller diameters than wire rope. For example, aircraft cables are available in 3/64 in. diameter while most wire ropes begin at a 1/4 in. diameter. Static wire ropes are used to support structures such as suspension bridges or as guy wires to support towers. An aerial tramway relies on wire rope to support and move cargo overhead.\n\nModern wire rope was invented by the German mining engineer Wilhelm Albert in the years between 1831 and 1834 for use in mining in the Harz Mountains in Clausthal, Lower Saxony, Germany. It was quickly accepted because it proved superior to ropes made of hemp or to metal chains, such as had been used before.\n\nWilhelm Albert's first ropes consisted of three strands consisting of four wires each. In 1840, Scotsman Robert Stirling Newall improved the process further. In America wire rope was manufactured by John A. Roebling, starting in 1841 and forming the basis for his success in suspension bridge building. Roebling introduced a number of innovations in the design, materials and manufacture of wire rope. Ever with an ear to technology developments in mining and railroading, Josiah White and Erskine Hazard, principal owners of the Lehigh Coal & Navigation Company (LC&N Co.) — as they had with the first blast furnaces in the Lehigh Valley — built a Wire Rope factory in Mauch Chunk, Pennsylvania in 1848, which provided lift cables for the Ashley Planes project, then the back track planes of the Summit Hill & Mauch Chunk Railroad, improving its attractiveness as a premier tourism destination, and vastly improving the throughput of the coal capacity since return of cars dropped from nearly four hours to less than 20 minutes. The decades were witness to a burgeoning increase in deep shaft mining in both Europe and North America as surface mineral deposits were exhausted and miners had to chase layers along inclined layers. The era was early in railroad development and steam engines lacked sufficient tractive effort to climb steep slopes, so incline plane railways were common. This pushed development of cable hoists rapidly in the United States as surface deposits in the Anthracite Coal Region north and south dove deeper every year, and even the rich deposits in the Panther Creek Valley required LC&N Co. to drive their first shafts into lower slopes beginning Lansford and its Schuylkill County twin-town Coaldale.\n\nThe German engineering firm of Adolf Bleichert & Co. was founded in 1874 and began to build bicable aerial tramways for mining in the Ruhr Valley. With important patents, and dozens of working systems in Europe, Bleichert dominated the global industry, later licensing its designs and manufacturing techniques to Trenton Iron Works, New Jersey, USA which built systems across America. Adolf Bleichert & Co. went on to build hundreds of aerial tramways around the world: from Alaska to Argentina, Australia and Spitsbergen. The Bleichert company also built hundreds of aerial tramways for both the Imperial German Army and the Wehrmacht.\n\nIn the last half of the 19th century, wire rope systems were used as a means of transmitting mechanical power including for the new cable cars. Wire rope systems cost one-tenth as much and had lower friction losses than line shafts. Because of these advantages, wire rope systems were used to transmit power for a distance of a few miles or kilometers.\n\nSteel wires for wire ropes are normally made of non-alloy carbon steel with a carbon content of 0.4 to 0.95%. The very high strength of the rope wires enables wire ropes to support large tensile forces and to run over sheaves with relatively small diameters.\n\nIn the so-called cross lay strands, the wires of the different layers cross each other.\nIn the mostly used parallel lay strands, the lay length of all the wire layers is equal and the wires of any two superimposed layers are parallel, resulting in linear contact. The wire of the outer layer is supported by two wires of the inner layer. These wires are neighbours along the whole length of the strand. Parallel lay strands are made in one operation. The endurance of wire ropes with this kind of strand is always much greater than of those (seldom used) with cross lay strands. Parallel lay strands with two wire layers have the construction Filler, Seale or Warrington.\n\nIn principle, spiral ropes are round strands as they have an assembly of layers of wires laid helically over a centre with at least one layer of wires being laid in the opposite direction to that of the outer layer. Spiral ropes can be dimensioned in such a way that they are non-rotating which means that under tension the rope torque is nearly zero. The open spiral rope consists only of round wires. The half-locked coil rope and the full-locked coil rope always have a centre made of round wires. The locked coil ropes have one or more outer layers of profile wires. They have the advantage that their construction prevents the penetration of dirt and water to a greater extent and it also protects them from loss of lubricant. In addition, they have one further very important advantage as the ends of a broken outer wire cannot leave the rope if it has the proper dimensions.\n\nStranded ropes are an assembly of several strands laid helically in one or more layers around a core. This core can be one of three types. The first is a fiber core, made up of synthetic material or natural fibers like Sysal. Synthetic fibers are stronger and more uniform but cannot absorb much lubricant. Natural fibers can absorb up to 15% of their weight in lubricant and so protect the inner wires much better from corrosion than synthetic fibers do. Fiber cores are the most flexible and elastic, but have the downside of getting crushed easily. The second type, wire strand core, is made up of one additional strand of wire, and is typically used for suspension. The third type is independent wire rope core (IWRC), which is the most durable in all types of environments. Most types of stranded ropes only have one strand layer over the core (fibre core or steel core). The lay direction of the strands in the rope can be right (symbol Z) or left (symbol S) and the lay direction of the wires can be right (symbol z) or left (symbol s). This kind of rope is called ordinary lay rope if the lay direction of the wires in the outer strands is in the opposite direction to the lay of the outer strands themselves. If both the wires in the outer strands and the outer strands themselves have the same lay direction, the rope is called a lang lay rope (from Dutch \"langslag\" contrary to \"kruisslag\", formerly Albert’s lay or langs lay). Regular lay means the individual wires were wrapped around the centers in one direction and the strands were wrapped around the core in the opposite direction.\n\nMulti-strand ropes are all more or less resistant to rotation and have at least two layers of strands laid helically around a centre. The direction of the outer strands is opposite to that of the underlying strand layers. Ropes with three strand layers can be nearly non-rotating. Ropes with two strand layers are mostly only low-rotating.\n\nDepending on where they are used, wire ropes have to fulfill different requirements. The main uses are:\n\nThere are technical regulations for the rope drives of cranes, elevators, rope ways and mining installations not exceeding a given tensile force and not falling short of a given diameter ratio D/d of sheave and rope diameters. A general dimensioning method of rope drives (and used besides the technical regulations) calculate the five limits \n\nThe calculation of the rope drive limits depends on:\n\nThe wire ropes are stressed by fluctuating forces, by wear, by corrosion and in seldom cases by extreme forces. The rope life is finite and the safety is only ensured by inspection for the detection of wire breaks on a reference rope length, of cross-section loss, as well as other failures so that the wire rope can be replaced before a dangerous situation occurs. Installations should be designed to facilitate the inspection of the wire ropes.\nLifting installations for passenger transportation require that a combination of several methods should be used to prevent a car from plunging downwards. Elevators must have redundant bearing ropes and a safety gear. Ropeways and mine hoistings must be permanently supervised by a responsible manager and the rope must be inspected by a magnetic method capable of detecting inner wire breaks.\n\nThe end of a wire rope tends to fray readily, and cannot be easily connected to plant and equipment. There are different ways of securing the ends of wire ropes to prevent fraying. The most common and useful type of end fitting for a wire rope is to turn the end back to form a loop. The loose end is then fixed back on the wire rope. Termination efficiencies vary from about 70% for a Flemish eye alone; to nearly 90% for a Flemish eye and splice; to 100% for potted ends and swagings.\n\nWhen the wire rope is terminated with a loop, there is a risk that it will bend too tightly, especially when the loop is connected to a device that concentrates the load on a relatively small area. A thimble can be installed inside the loop to preserve the natural shape of the loop, and protect the cable from pinching and abrading on the inside of the loop. The use of thimbles in loops is industry best practice. The thimble prevents the load from coming into direct contact with the wires.\n\nA wire rope clamp, also called a clip, is used to fix the loose end of the loop back to the wire rope. It usually consists of a U-shaped bolt, a forged saddle, and two nuts. The two layers of wire rope are placed in the U-bolt. The saddle is then fitted over the ropes on to the bolt (the saddle includes two holes to fit to the u-bolt). The nuts secure the arrangement in place. Three or more clamps are usually used to terminate a wire rope. As many as eight may be needed for a diameter rope.\n\nThere is an old adage; be sure not to \"saddle a dead horse\". This means that when installing clamps, the saddle portion of the clamp assembly is placed on the load-bearing or \"live\" side, not on the non-load-bearing or \"dead\" side of the cable. According to the US Navy Manual S9086-UU-STM-010, Chapter 613R3, Wire and Fiber rope and Rigging, \"This is to protect the live or stress-bearing end of the rope against crushing and abuse. The flat bearing seat and extended prongs of the body (saddle) are designed to protect the rope and are always placed against the live end.\"\n\nThe US Navy and most regulatory bodies do not recommend the use of such clips as permanent terminations.\n\n An eye splice may be used to terminate the loose end of a wire rope when forming a loop. The strands of the end of a wire rope are unwound a certain distance. The wire is then bent around so that the end of the unwrapped length forms an eye and the unwrapped strands are then plaited back into the wire rope, forming the loop, or an eye, called an eye splice.\n\nA Flemish eye, or Dutch Splice, involves un wrapping three strands (the strands need to be next to each other, not alternates) of the wire and keeping them off to one side. The remaining strands are bent around, until the end of the wire meets the \"V\" where the unwrapping finished, to form the eye. The strands kept to one side are now re-wrapped by wrapping from the end of the wire back to the V of the eye. These strands are effectively rewrapped along the wire in the opposite direction to their original lay. When this type of rope splice is used specifically on wire rope, it is called a \"Molly Hogan\", and, by some, a \"Dutch\" eye instead of a \"Flemish\" eye.\n\nSwaging is a method of wire rope termination that refers to the installation technique. The purpose of swaging wire rope fittings is to connect two wire rope ends together, or to otherwise terminate one end of wire rope to something else. A mechanical or hydraulic swager is used to compress and deform the fitting, creating a permanent connection. There are many types of swaged fittings. Threaded Studs, Ferrules, Sockets, and Sleeves are a few examples. Swaging ropes with fibre cores is not recommended.\n\nA wedge socket termination is useful when the fitting needs to be replaced frequently. For example, if the end of a wire rope is in a high-wear region, the rope may be periodically trimmed, requiring the termination hardware to be removed and reapplied. An example of this is on the ends of the drag ropes on a dragline. The end loop of the wire rope enters a tapered opening in the socket, wrapped around a separate component called the wedge. The arrangement is knocked in place, and load gradually eased onto the rope. As the load increases on the wire rope, the wedge become more secure, gripping the rope tighter.\n\nPoured sockets are used to make a high strength, permanent termination; they are created by inserting the wire rope into the narrow end of a conical cavity which is oriented in-line with the intended direction of strain. The individual wires are splayed out inside the cone or 'capel', and the cone is then filled with molten lead-antimony-tin (PbSbSn) solder or 'white metal capping', zinc, or now more commonly, an unsaturated polyester resin compound.\n\n\n"}
{"id": "38858718", "url": "https://en.wikipedia.org/wiki?curid=38858718", "title": "Wire rope spooling technology", "text": "Wire rope spooling technology\n\nWire rope spooling-Technology is the technology to prevent wire rope getting snagged when spooled especially in multiple layers on a drum.\n\nEver since the development of wire rope, comprising multiple wire strands, spooling the wire has presented technical challenges. When wrapped in multiple layers, the upper layers have a tendency to crush the lower layers, while the lower layers have a tendency to pinch upper layers. The rubbing of rope against rope also has a tendency to cause wear.\nThese problems were addressed by Frank L. LeBus Sr., a supplier of drilling equipment to the oilfields of Texas, USA, who in 1938, patented the use of a groove bar on hoisting drums to guide the spooling of rope. Grooved shape steel segments were simply welded or screwed to existing plain steel drums. \nEver since then, drum groovings have been widely used to guide the spooling of wire rope onto and off winch drums.\nIntroducing a continuous helical groove onto the drum, like the thread of a screw, provides a way to guide the rope when spooling onto or off a drum. However this has been shown to work effectively only when the rope is wrapped in a single layer. When the rope is wrapped in multiple layers, problems remain.\nFrank LeBus introduced a grooving pattern that put the groove parallel to the flanges of the drum, except for a single slanted section across the drum face to act as crossover point, moving the rope along by the width of the groove with every revolution.\n\nWhile the Lebus family business continues to produce this equipment today, patents have expired and other winch manufacturers also use the Lebus system. Any drum with a parallel groove and two cross-over points is often generically called ‘a Lebus drum’, regardless of the manufacturer.\n\nThe multilayer wire rope spooling system has undergone continuous refinement over the years and adapted for any application where long lengths of steel wire ropes must be wrapped in multiple layers quickly and smoothly. Examples include:\n\nWith the parallel groove system, rope wear is considerably reduced in multilayer spooling. \nWhen the first layer has filled the drum, the second layer then travels back across the drum with each wrap of rope sitting precisely along the groove of two wraps of the first layer.\nWith parallel grooving it is possible to calculate the exact forces that the rope imposes on the drum because the spooling is controlled. \nCross winding is reduced to approximately 20 percent of the circumference of the drum, and 80 percent remains parallel to the flanges in the inner layer rope groove.\nThis parallel grooving evenly distributes the load between the individual layers and has been show to increase substantially – by more than 500percent, tests have shown – the life of the wire rope. The system has been used to mount ropes up. \nIn offshore applications, huge lengths of rope are often housed on drums. The anchor winches on Saipem’s Semac 1 pipe laying barge, for example, each hold 2,800 metres of 76mm (3 inch) diameter wire rope in 14 layers. Saipem’s Castorone, the world’s largest pipe laying vessel uses a wire rope that is 3,850m long and 152mm in diameter. It weighs 420t. The rope is pulled by capstan and stored on a massive Rema traction winches that feature the parallel grooving system, with an approximately back tension of 40t on the capstan.\n\nTo maximise the benefits of the parallel grooving system, certain operating conditions are required. These include:\nEvery system should be tailored to the application for which it is used. The groove pattern is engineered to suit the rope's length, diameter and construction type.\nIn any multi-layer spooling application it is important that when the rope is first installed on the drum, it is done so under tension to avoid any slack on inner layers that can be crushed or nicked against the groove walls by outer layers.\nThe fleet angle is defined as the largest angle of the rope between the first sheave and the drum flange, relative to the centre line of the drum. With all type of drums, the rope is subject to a fleet angle which impacts on its behaviour and affects lifespan. \nFleet angle should be between 0.25° and 1.25°, depending on the rope construction. The fleet angle can be varied by moving the first sheave closer to or further away from the drum. If the sheave is too close to the drum, the fleet angle will be greater than 1.25°; if it is too far away, the fleet angle will be less than 0.25°.\n\nSometimes it is not possible to achieve the optimum fleet angle. Where there is no space to rig a sheave the requisite distance from the drum, two additional spooling devices are available. One is a fleet angle compensator, which is driven automatically by the rope tension. The other is a level winder that is mechanically driven. Both offer a solution to guide the cable along the drum between flanges, but each has its advantages and disadvantages.\n\nThe fleet angle compensator (FAC) is driven by the movement of the wire rope as it goes through the crossover sections of the drum. As the rope winds or unwinds, the FAC shaft automatically oscillates slowly, allowing its sheave to slide back and forth across the shaft to maintain an optimum fleet angle and guide the rope smoothly onto the drum.\n\nLevel winders can be hydraulically or electrically driven and computer controlled, or they can be simple mechanical devices. A mechanical level winder comprises a main shaft (the lead screw) with helical screw grooving along which the rope feeder travels. The rope feeder housing includes two vertical roller bars and one horizontal roller, or alternatively a wire rope sheave. The lateral movement of the housing is generated by a chain drive sprocket ratio between drum and lead screw, as shown in the image. The automatic level winder fitted is designed and engineered to be compatible with the grooving on the drum.\nAlternatively, a sheave can be integrated and installed within the housing frame. In this case, the system can be set up anywhere around the drum. \nOceanographic installations that spool rope up to 46 layers have demonstrated that level winders give synchronized and controlled spooling in the harshest, most testing conditions.\n\nGrooving systems for multilayer spooling can be carved onto steel shells that are mounted onto old drums, by either bolting or welding, as an outer sleeve. Called split sleeves, they can be retrofitted onto old drums or mounted on new drums to allow a future change of application.\n\n\n"}
{"id": "13055219", "url": "https://en.wikipedia.org/wiki?curid=13055219", "title": "Zero address arithmetic", "text": "Zero address arithmetic\n\nZero address arithmetic is a feature of a few innovative computer architectures, whereby the assignment to a physical address space is deferred until programming statement execution time. It eliminates the link step of conventional compile and link architectures, and more generally relocation.\n\nAll Burroughs large systems and medium systems had this property, as do their modern day successors that preserve the original physical architecture.\n\nThe 1960 announcement of the English Electric KDF9 is the first announcement of a zero-address instruction format computer, rapidly followed by the Burroughs B5000.\n"}
